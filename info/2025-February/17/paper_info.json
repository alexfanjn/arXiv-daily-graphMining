[
  {
    "id": "arXiv:2502.09624",
    "title": "Efficient and Trustworthy Block Propagation for Blockchain-enabled Mobile Embodied AI Networks: A Graph Resfusion Approach",
    "abstract": "           By synergistically integrating mobile networks and embodied artificial intelligence (AI), Mobile Embodied AI Networks (MEANETs) represent an advanced paradigm that facilitates autonomous, context-aware, and interactive behaviors within dynamic environments. Nevertheless, the rapid development of MEANETs is accompanied by challenges in trustworthiness and operational efficiency. Fortunately, blockchain technology, with its decentralized and immutable characteristics, offers promising solutions for MEANETs. However, existing block propagation mechanisms suffer from challenges such as low propagation efficiency and weak security for block propagation, which results in delayed transmission of vehicular messages or vulnerability to malicious tampering, potentially causing severe traffic accidents in blockchain-enabled MEANETs. Moreover, current block propagation strategies cannot effectively adapt to real-time changes of dynamic topology in MEANETs. Therefore, in this paper, we propose a graph Resfusion model-based trustworthy block propagation optimization framework for consortium blockchain-enabled MEANETs. Specifically, we propose an innovative trust calculation mechanism based on the trust cloud model, which comprehensively accounts for randomness and fuzziness in the miner trust evaluation. Furthermore, by leveraging the strengths of graph neural networks and diffusion models, we develop a graph Resfusion model to effectively and adaptively generate the optimal block propagation trajectory. Simulation results demonstrate that the proposed model outperforms other routing mechanisms in terms of block propagation efficiency and trustworthiness. Additionally, the results highlight its strong adaptability to dynamic environments, making it particularly suitable for rapidly changing MEANETs.         ",
    "url": "https://arxiv.org/abs/2502.09624",
    "authors": [
      "Jiawen Kang",
      "Jiana Liao",
      "Runquan Gao",
      "Jinbo Wen",
      "Huawei Huang",
      "Maomao Zhang",
      "Changyan Yi",
      "Tao Zhang",
      "Dusit Niyato",
      "Zibin Zheng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2502.09640",
    "title": "Online Social Support Detection in Spanish Social Media Texts",
    "abstract": "           The advent of social media has transformed communication, enabling individuals to share their experiences, seek support, and participate in diverse discussions. While extensive research has focused on identifying harmful content like hate speech, the recognition and promotion of positive and supportive interactions remain largely unexplored. This study proposes an innovative approach to detecting online social support in Spanish-language social media texts. We introduce the first annotated dataset specifically created for this task, comprising 3,189 YouTube comments classified as supportive or non-supportive. To address data imbalance, we employed GPT-4o to generate paraphrased comments and create a balanced dataset. We then evaluated social support classification using traditional machine learning models, deep learning architectures, and transformer-based models, including GPT-4o, but only on the unbalanced dataset. Subsequently, we utilized a transformer model to compare the performance between the balanced and unbalanced datasets. Our findings indicate that the balanced dataset yielded improved results for Task 2 (Individual and Group) and Task 3 (Nation, Other, LGBTQ, Black Community, Women, Religion), whereas GPT-4o performed best for Task 1 (Social Support and Non-Support). This study highlights the significance of fostering a supportive online environment and lays the groundwork for future research in automated social support detection.         ",
    "url": "https://arxiv.org/abs/2502.09640",
    "authors": [
      "Moein Shahiki Tash",
      "Luis Ramos",
      "Zahra Ahani",
      "Raul Monroy",
      "Olga kolesnikova",
      "Hiram Calvo",
      "Grigori Sidorov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2502.09646",
    "title": "Language Shift or Maintenance? An Intergenerational Study of the Tibetan Community in Saudi Arabia",
    "abstract": "           The present study provides the first-ever report on the language shift from Tibetan to Arabic among descendants of Tibetan families who migrated from the Tibet region to Saudi Arabia around 70 years ago. The aim of this study was to determine whether three age groups had adopted different practices in terms of maintaining Tibetan or shifting to Hijazi Arabic. To this end, 96 male and female members of the Tibetan community responded to a questionnaire in which they were asked about their code choice in different domains (home, neighbourhood, friends and relatives, expressing emotion, and performing religious rituals). The data revealed significant intergenerational differences between members of the community in terms of the extent of the shift to Arabic, with Tibetan rarely used by younger members and older members making only slightly more use of it. The difference between the three age groups was significant, at a p-value of .001.         ",
    "url": "https://arxiv.org/abs/2502.09646",
    "authors": [
      "Sumaiyah Turkistani Mohammad Almoaily"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2502.09669",
    "title": "Meta-INR: Efficient Encoding of Volumetric Data via Meta-Learning Implicit Neural Representation",
    "abstract": "           Implicit neural representation (INR) has emerged as a promising solution for encoding volumetric data, offering continuous representations and seamless compatibility with the volume rendering pipeline. However, optimizing an INR network from randomly initialized parameters for each new volume is computationally inefficient, especially for large-scale time-varying or ensemble volumetric datasets where volumes share similar structural patterns but require independent training. To close this gap, we propose Meta-INR, a pretraining strategy adapted from meta-learning algorithms to learn initial INR parameters from partial observation of a volumetric dataset. Compared to training an INR from scratch, the learned initial parameters provide a strong prior that enhances INR generalizability, allowing significantly faster convergence with just a few gradient updates when adapting to a new volume and better interpretability when analyzing the parameters of the adapted INRs. We demonstrate that Meta-INR can effectively extract high-quality generalizable features that help encode unseen similar volume data across diverse datasets. Furthermore, we highlight its utility in tasks such as simulation parameter analysis and representative timestep selection. The code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2502.09669",
    "authors": [
      "Maizhe Yang",
      "Kaiyuan Tang",
      "Chaoli Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2502.09675",
    "title": "Multi-level Conflict-Aware Network for Multi-modal Sentiment Analysis",
    "abstract": "           Multimodal Sentiment Analysis (MSA) aims to recognize human emotions by exploiting textual, acoustic, and visual modalities, and thus how to make full use of the interactions between different modalities is a central challenge of MSA. Interaction contains alignment and conflict aspects. Current works mainly emphasize alignment and the inherent differences between unimodal modalities, neglecting the fact that there are also potential conflicts between bimodal combinations. Additionally, multi-task learning-based conflict modeling methods often rely on the unstable generated labels. To address these challenges, we propose a novel multi-level conflict-aware network (MCAN) for multimodal sentiment analysis, which progressively segregates alignment and conflict constituents from unimodal and bimodal representations, and further exploits the conflict constituents with the conflict modeling branch. In the conflict modeling branch, we conduct discrepancy constraints at both the representation and predicted output levels, avoiding dependence on the generated labels. Experimental results on the CMU-MOSI and CMU-MOSEI datasets demonstrate the effectiveness of the proposed MCAN.         ",
    "url": "https://arxiv.org/abs/2502.09675",
    "authors": [
      "Yubo Gao",
      "Haotian Wu",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.09716",
    "title": "Genetic Data Governance in Crisis: Policy Recommendations for Safeguarding Privacy and Preventing Discrimination",
    "abstract": "           Genetic data collection has become ubiquitous today. The ability to meaningfully interpret genetic data has motivated its widespread use, providing crucial insights into human health and ancestry while driving important public health initiatives. Easy access to genetic testing has fueled a rapid expansion of recreational direct-to-consumer offerings. However, the growth of genetic datasets and their applications has created significant privacy and discrimination risks, as our understanding of the scientific basis for genetic traits continues to evolve. In this paper, we organize the uses of genetic data along four distinct \"pillars\": clinical practice, research, forensic and government use, and recreational use. Using our scientific understanding of genetics, genetic inference methods and their associated risks, and current public protections, we build a risk assessment framework that identifies key values that any governance system must preserve. We analyze case studies using this framework to assess how well existing regulatory frameworks preserve desired values. Our investigation reveals critical gaps in these frameworks and identifies specific threats to privacy and personal liberties, particularly through genetic discrimination. We propose comprehensive policy reforms to: (1) update the legal definition of genetic data to protect against modern technological capabilities, (2) expand the Genetic Information Nondiscrimination Act (GINA) to cover currently unprotected domains, and (3) establish a unified regulatory framework under a single governing body to oversee all applications of genetic data. We conclude with three open questions about genetic data: the challenges posed by its relational nature, including consent for relatives and minors; the complexities of international data transfer; and its potential integration into large language models.         ",
    "url": "https://arxiv.org/abs/2502.09716",
    "authors": [
      "Vivek Ramanan",
      "Ria Vinod",
      "Cole Williams",
      "Sohini Ramachandran",
      "Suresh Venkatasubramanian"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2502.09723",
    "title": "Making Them a Malicious Database: Exploiting Query Code to Jailbreak Aligned Large Language Models",
    "abstract": "           Recent advances in large language models (LLMs) have demonstrated remarkable potential in the field of natural language processing. Unfortunately, LLMs face significant security and ethical risks. Although techniques such as safety alignment are developed for defense, prior researches reveal the possibility of bypassing such defenses through well-designed jailbreak attacks. In this paper, we propose QueryAttack, a novel framework to systematically examine the generalizability of safety alignment. By treating LLMs as knowledge databases, we translate malicious queries in natural language into code-style structured query to bypass the safety alignment mechanisms of LLMs. We conduct extensive experiments on mainstream LLMs, ant the results show that QueryAttack achieves high attack success rates (ASRs) across LLMs with different developers and capabilities. We also evaluate QueryAttack's performance against common defenses, confirming that it is difficult to mitigate with general defensive techniques. To defend against QueryAttack, we tailor a defense method which can reduce ASR by up to 64\\% on GPT-4-1106. The code of QueryAttack can be found on this https URL.         ",
    "url": "https://arxiv.org/abs/2502.09723",
    "authors": [
      "Qingsong Zou",
      "Jingyu Xiao",
      "Qing Li",
      "Zhi Yan",
      "Yuhang Wang",
      "Li Xu",
      "Wenxuan Wang",
      "Kuofeng Gao",
      "Ruoyu Li",
      "Yong Jiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2502.09724",
    "title": "Navigating the Social Welfare Frontier: Portfolios for Multi-objective Reinforcement Learning",
    "abstract": "           In many real-world applications of reinforcement learning (RL), deployed policies have varied impacts on different stakeholders, creating challenges in reaching consensus on how to effectively aggregate their preferences. Generalized $p$-means form a widely used class of social welfare functions for this purpose, with broad applications in fair resource allocation, AI alignment, and decision-making. This class includes well-known welfare functions such as Egalitarian, Nash, and Utilitarian welfare. However, selecting the appropriate social welfare function is challenging for decision-makers, as the structure and outcomes of optimal policies can be highly sensitive to the choice of $p$. To address this challenge, we study the concept of an $\\alpha$-approximate portfolio in RL, a set of policies that are approximately optimal across the family of generalized $p$-means for all $p \\in [-\\infty, 1]$. We propose algorithms to compute such portfolios and provide theoretical guarantees on the trade-offs among approximation factor, portfolio size, and computational efficiency. Experimental results on synthetic and real-world datasets demonstrate the effectiveness of our approach in summarizing the policy space induced by varying $p$ values, empowering decision-makers to navigate this landscape more effectively.         ",
    "url": "https://arxiv.org/abs/2502.09724",
    "authors": [
      "Cheol Woo Kim",
      "Jai Moondra",
      "Shresth Verma",
      "Madeleine Pollack",
      "Lingkai Kong",
      "Milind Tambe",
      "Swati Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.09726",
    "title": "Analysis of Robust and Secure DNS Protocols for IoT Devices",
    "abstract": "           The DNS (Domain Name System) protocol has been in use since the early days of the Internet. Although DNS as a de facto networking protocol had no security considerations in its early years, there have been many security enhancements, such as DNSSec (Domain Name System Security Extensions), DoT (DNS over Transport Layer Security), DoH (DNS over HTTPS) and DoQ (DNS over QUIC). With all these security improvements, it is not yet clear what resource-constrained Internet-of-Things (IoT) devices should be used for robustness. In this paper, we investigate different DNS security approaches using an edge DNS resolver implemented as a Virtual Network Function (VNF) to replicate the impact of the protocol from an IoT perspective and compare their performances under different conditions. We present our results for cache-based and non-cached responses and evaluate the corresponding security benefits. Our results and framework can greatly help consumers, manufacturers, and the research community decide and implement their DNS protocols depending on the given dynamic network conditions and enable robust Internet access via DNS for different devices.         ",
    "url": "https://arxiv.org/abs/2502.09726",
    "authors": [
      "Abdullah Aydeger",
      "Sanzida Hoque",
      "Engin Zeydan",
      "Kapal Dev"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2502.09731",
    "title": "A CNN Approach to Automated Detection and Classification of Brain Tumors",
    "abstract": "           Brain tumors require an assessment to ensure timely diagnosis and effective patient treatment. Morphological factors such as size, location, texture, and variable appearance com- plicate tumor inspection. Medical imaging presents challenges, including noise and incomplete images. This research article presents a methodology for processing Magnetic Resonance Imag- ing (MRI) data, encompassing techniques for image classification and denoising. The effective use of MRI images allows medical professionals to detect brain disorders, including tumors. This research aims to categorize healthy brain tissue and brain tumors by analyzing the provided MRI data. Unlike alternative methods like Computed Tomography (CT), MRI technology offers a more detailed representation of internal anatomical components, mak- ing it a suitable option for studying data related to brain tumors. The MRI picture is first subjected to a denoising technique utilizing an Anisotropic diffusion filter. The dataset utilized for the models creation is a publicly accessible and validated Brain Tumour Classification (MRI) database, comprising 3,264 brain MRI scans. SMOTE was employed for data augmentation and dataset balancing. Convolutional Neural Networks(CNN) such as ResNet152V2, VGG, ViT, and EfficientNet were employed for the classification procedure. EfficientNet attained an accuracy of 98%, the highest recorded.         ",
    "url": "https://arxiv.org/abs/2502.09731",
    "authors": [
      "Md. Zahid Hasan",
      "Abdullah Tamim",
      "D.M. Asadujjaman",
      "Md. Mahfujur Rahman",
      "Md. Abu Ahnaf Mollick",
      "Nosin Anjum Dristi",
      "Abdullah-Al-Noman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2502.09744",
    "title": "Fine-Tuning Foundation Models with Federated Learning for Privacy Preserving Medical Time Series Forecasting",
    "abstract": "           Federated Learning (FL) provides a decentralized machine learning approach, where multiple devices or servers collaboratively train a model without sharing their raw data, thus enabling data privacy. This approach has gained significant interest in academia and industry due to its privacy-preserving properties, which are particularly valuable in the medical domain where data availability is often protected under strict regulations. A relatively unexplored area is the use of FL to fine-tune Foundation Models (FMs) for time series forecasting, potentially enhancing model efficacy by overcoming data limitation while maintaining privacy. In this paper, we fine-tuned time series FMs with Electrocardiogram (ECG) and Impedance Cardiography (ICG) data using different FL techniques. We then examined various scenarios and discussed the challenges FL faces under different data heterogeneity configurations. Our empirical results demonstrated that while FL can be effective for fine-tuning FMs on time series forecasting tasks, its benefits depend on the data distribution across clients. We highlighted the trade-offs in applying FL to FM fine-tuning.         ",
    "url": "https://arxiv.org/abs/2502.09744",
    "authors": [
      "Mahad Ali",
      "Curtis Lisle",
      "Patrick W. Moore",
      "Tammer Barkouki",
      "Brian J. Kirkwood",
      "Laura J. Brattain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2502.09754",
    "title": "Robust Adaptive Meshing, Mesh Density Functions, and Nonlocal Observations for Ensemble Based Data Assimilation",
    "abstract": "           Adaptive spatial meshing has proven invaluable for the accurate, efficient computation of solutions of time dependent partial differential equations. In a DA context the use of adaptive spatial meshes addresses several factors that place increased demands on meshing; these include the location and relative importance of observations and the use of ensemble solutions. To increase the efficiency of adaptive meshes for data assimilation, robust look ahead meshes are developed that fix the same adaptive mesh for all ensemble members for the entire time interval of the forecasts and that incorporates the observations at the next analysis time. This allows for increased vectorization of the ensemble forecasts while minimizing interpolation of solutions between different meshes. The techniques to determine these robust meshes are based upon combining metric tensors or mesh density functions to define nonuniform meshes. We illustrate the robust ensemble look ahead meshes using traveling wave solutions of a bistable reaction-diffusion equation. Observation operators based on convolution type integrals and their associated metric tensors are derived. These further the goals of making efficient use of adaptive meshes in ensemble based DA techniques, developing and employing robust meshes that are effective for a range of similar behaviors in both the ensembles and the observations, and the integration with advanced numerical PDE techniques (a quasi-Lagrangian moving mesh DG technique employing embedded pairs for time stepping). Numerical experiments with different observation scenarios are presented for a 2D inviscid Burgers' equation, a multi-component system, a 2D Shallow Water model, and for a coupled system of two 1D Kuramoto-Sivashinsky equations.         ",
    "url": "https://arxiv.org/abs/2502.09754",
    "authors": [
      "Jeremiah Buenger",
      "Weizhang Huang",
      "Erik Van Vleck"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2502.09755",
    "title": "Enhancing Jailbreak Attacks via Compliance-Refusal-Based Initialization",
    "abstract": "           Jailbreak attacks aim to exploit large language models (LLMs) and pose a significant threat to their proper conduct; they seek to bypass models' safeguards and often provoke transgressive behaviors. However, existing automatic jailbreak attacks require extensive computational resources and are prone to converge on suboptimal solutions. In this work, we propose \\textbf{C}ompliance \\textbf{R}efusal \\textbf{I}nitialization (CRI), a novel, attack-agnostic framework that efficiently initializes the optimization in the proximity of the compliance subspace of harmful prompts. By narrowing the initial gap to the adversarial objective, CRI substantially improves adversarial success rates (ASR) and drastically reduces computational overhead -- often requiring just a single optimization step. We evaluate CRI on the widely-used AdvBench dataset over the standard jailbreak attacks of GCG and AutoDAN. Results show that CRI boosts ASR and decreases the median steps to success by up to \\textbf{\\(\\times 60\\)}. The project page, along with the reference implementation, is publicly available at \\texttt{this https URL}.         ",
    "url": "https://arxiv.org/abs/2502.09755",
    "authors": [
      "Amit Levi",
      "Rom Himelstein",
      "Yaniv Nemcovsky",
      "Avi Mendelson",
      "Chaim Baskin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.09763",
    "title": "SoK: Come Together -- Unifying Security, Information Theory, and Cognition for a Mixed Reality Deception Attack Ontology & Analysis Framework",
    "abstract": "           We present a primary attack ontology and analysis framework for deception attacks in Mixed Reality (MR). This is achieved through multidisciplinary Systematization of Knowledge (SoK), integrating concepts from MR security, information theory, and cognition. While MR grows in popularity, it presents many cybersecurity challenges, particularly concerning deception attacks and their effects on humans. In this paper, we use the Borden-Kopp model of deception to develop a comprehensive ontology of MR deception attacks. Further, we derive two models to assess impact of MR deception attacks on information communication and decision-making. The first, an information-theoretic model, mathematically formalizes the effects of attacks on information communication. The second, a decision-making model, details the effects of attacks on interlaced cognitive processes. Using our ontology and models, we establish the MR Deception Analysis Framework (DAF) to assess the effects of MR deception attacks on information channels, perception, and attention. Our SoK uncovers five key findings for research and practice and identifies five research gaps to guide future work.         ",
    "url": "https://arxiv.org/abs/2502.09763",
    "authors": [
      "Ali Teymourian",
      "Andrew M. Webb",
      "Taha Gharaibeh",
      "Arushi Ghildiyal",
      "Ibrahim Baggili"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2502.09767",
    "title": "Non-Markovian Discrete Diffusion with Causal Language Models",
    "abstract": "           Discrete diffusion models have emerged as a flexible and controllable paradigm for structured sequence modeling, yet they still lag behind causal language models in expressiveness. To bridge the gap between two paradigms, we introduce CaDDi, a causal discrete diffusion model that unifies sequential and temporal modeling within a non-Markovian diffusion framework. Unlike conventional diffusion models that operate step by step with no access to prior states, CaDDi integrates the temporal trajectory, enabling more expressive and controllable generation. Our approach also treats causal language models as a special case, allowing seamless adoption of pretrained large language models (LLMs) for discrete diffusion without the need for architectural modifications. Empirically, we demonstrate that CaDDi outperforms state-of-the-art discrete diffusion models on both natural language and biological sequence tasks, narrowing the gap between diffusion-based methods and large-scale autoregressive transformers.         ",
    "url": "https://arxiv.org/abs/2502.09767",
    "authors": [
      "Yangtian Zhang",
      "Sizhuang He",
      "Daniel Levine",
      "Lawrence Zhao",
      "David Zhang",
      "Syed A Rizvi",
      "Emanuele Zappala",
      "Rex Ying",
      "David van Dijk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2502.09768",
    "title": "Complex Network Modelling with Power-law Activating Patterns and Its Evolutionary Dynamics",
    "abstract": "           Complex network theory provides a unifying framework for the study of structured dynamic systems. The current literature emphasizes a widely reported phenomenon of intermittent interaction among network vertices. In this paper, we introduce a complex network model that considers the stochastic switching of individuals between activated and quiescent states at power-law rates and the corresponding evolutionary dynamics. By using the Markov chain and renewal theory, we discover a homogeneous stationary distribution of activated sizes in the network with power-law activating patterns and infer some statistical characteristics. To better understand the effect of power-law activating patterns, we study the two-person-two-strategy evolutionary game dynamics, demonstrate the absorbability of strategies, and obtain the critical cooperation conditions for prisoner's dilemmas in homogeneous networks without mutation. The evolutionary dynamics in real networks are also discussed. Our results provide a new perspective to analyze and understand social physics in time-evolving network systems.         ",
    "url": "https://arxiv.org/abs/2502.09768",
    "authors": [
      "Ziyan Zeng",
      "Minyu Feng",
      "Pengfei Liu",
      "Jurgen Kurths"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2502.09771",
    "title": "Knowledge-Enhanced Program Repair for Data Science Code",
    "abstract": "           This paper introduces DSrepair, a knowledge-enhanced program repair method designed to repair the buggy code generated by LLMs in the data science domain. DSrepair uses knowledge graph based RAG for API knowledge retrieval as well as bug knowledge enrichment to construct repair prompts for LLMs. Specifically, to enable knowledge graph based API retrieval, we construct DS-KG (Data Science Knowledge Graph) for widely used data science libraries. For bug knowledge enrichment, we employ an abstract syntax tree (AST) to localize errors at the AST node level. DSrepair's effectiveness is evaluated against five state-of-the-art LLM-based repair baselines using four advanced LLMs on the DS-1000 dataset. The results show that DSrepair surpasses all five baselines. Specifically, when compared to the second-best baseline, DSrepair demonstrates significant improvements, fixing 44.4%, 14.2%, 20.6%, and 32.1% more buggy code snippets for each of the four evaluated LLMs, respectively. Additionally, it achieves greater efficiency, reducing the number of tokens required per code task by 17.49%, 34.24%, 24.71%, and 17.59%, respectively.         ",
    "url": "https://arxiv.org/abs/2502.09771",
    "authors": [
      "Shuyin Ouyang",
      "Jie M. Zhang",
      "Zeyu Sun",
      "Albert Merono Penuela"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2502.09781",
    "title": "Medical Applications of Graph Convolutional Networks Using Electronic Health Records: A Survey",
    "abstract": "           Graph Convolutional Networks (GCNs) have emerged as a promising approach to machine learning on Electronic Health Records (EHRs). By constructing a graph representation of patient data and performing convolutions on neighborhoods of nodes, GCNs can capture complex relationships and extract meaningful insights to support medical decision making. This survey provides an overview of the current research in applying GCNs to EHR data. We identify the key medical domains and prediction tasks where these models are being utilized, common benchmark datasets, and architectural patterns to provide a comprehensive survey of this field. While this is a nascent area of research, GCNs demonstrate strong potential to leverage the complex information hidden in EHRs. Challenges and opportunities for future work are also discussed.         ",
    "url": "https://arxiv.org/abs/2502.09781",
    "authors": [
      "Garrik Hoyt",
      "Noyonica Chatterjee",
      "Fortunato Battaglia",
      "Paramita Basu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.09782",
    "title": "Improving Acoustic Side-Channel Attacks on Keyboards Using Transformers and Large Language Models",
    "abstract": "           The increasing prevalence of microphones in everyday devices and the growing reliance on online services have amplified the risk of acoustic side-channel attacks (ASCAs) targeting keyboards. This study explores deep learning techniques, specifically vision transformers (VTs) and large language models (LLMs), to enhance the effectiveness and applicability of such attacks. We present substantial improvements over prior research, with the CoAtNet model achieving state-of-the-art performance. Our CoAtNet shows a 5.0% improvement for keystrokes recorded via smartphone (Phone) and 5.9% for those recorded via Zoom compared to previous benchmarks. We also evaluate transformer architectures and language models, with the best VT model matching CoAtNet's performance. A key advancement is the introduction of a noise mitigation method for real-world scenarios. By using LLMs for contextual understanding, we detect and correct erroneous keystrokes in noisy environments, enhancing ASCA performance. Additionally, fine-tuned lightweight language models with Low-Rank Adaptation (LoRA) deliver comparable performance to heavyweight models with 67X more parameters. This integration of VTs and LLMs improves the practical applicability of ASCA mitigation, marking the first use of these technologies to address ASCAs and error correction in real-world scenarios.         ",
    "url": "https://arxiv.org/abs/2502.09782",
    "authors": [
      "Jin Hyun Park",
      "Seyyed Ali Ayati",
      "Yichen Cai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2502.09783",
    "title": "SLICES, a scientific instrument for the networking community",
    "abstract": "           A science is defined by a set of encyclopedic knowledge related to facts or phenomena following rules or evidenced by experimentally-driven observations. Computer Science and in particular computer networks is a relatively new scientific domain maturing over years and adopting the best practices inherited from more fundamental disciplines. The design of past, present and future networking components and architectures have been assisted, among other methods, by experimentally-driven research and in particular by the deployment of test platforms, usually named as testbeds. However, often experimentally-driven networking research used scattered methodologies, based on ad-hoc, small-sized testbeds, producing hardly repeatable results. We believe that computer networks needs to adopt a more structured methodology, supported by appropriate instruments, to produce credible experimental results supporting radical and incremental innovations. This paper reports lessons learned from the design and operation of test platforms for the scientific community dealing with digital infrastructures. We introduce the SLICES initiative as the outcome of several years of evolution of the concept of a networking test platform transformed into a scientific instrument. We address the challenges, requirements and opportunities that our community is facing to manage the full research-life cycle necessary to support a scientific methodology.         ",
    "url": "https://arxiv.org/abs/2502.09783",
    "authors": [
      "Serge Fdida",
      "Nikos Makris",
      "Thanasis Korakis",
      "Raffaele Bruno",
      "Andrea Passarella",
      "Panayiotis Andreou",
      "Bartosz Belter",
      "Cedric Crettaz",
      "Walid Dabbous",
      "Yuri Demchenko",
      "Raymond Knopp"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2502.09788",
    "title": "MANTIS: Detection of Zero-Day Malicious Domains Leveraging Low Reputed Hosting Infrastructure",
    "abstract": "           Internet miscreants increasingly utilize short-lived disposable domains to launch various attacks. Existing detection mechanisms are either too late to catch such malicious domains due to limited information and their short life spans or unable to catch them due to evasive techniques such as cloaking and captcha. In this work, we investigate the possibility of detecting malicious domains early in their life cycle using a content-agnostic approach. We observe that attackers often reuse or rotate hosting infrastructures to host multiple malicious domains due to increased utilization of automation and economies of scale. Thus, it gives defenders the opportunity to monitor such infrastructure to identify newly hosted malicious domains. However, such infrastructures are often shared hosting environments where benign domains are also hosted, which could result in a prohibitive number of false positives. Therefore, one needs innovative mechanisms to better distinguish malicious domains from benign ones even when they share hosting infrastructures. In this work, we build MANTIS, a highly accurate practical system that not only generates daily blocklists of malicious domains but also is able to predict malicious domains on-demand. We design a network graph based on the hosting infrastructure that is accurate and generalizable over time. Consistently, our models achieve a precision of 99.7%, a recall of 86.9% with a very low false positive rate (FPR) of 0.1% and on average detects 19K new malicious domains per day, which is over 5 times the new malicious domains flagged daily in VirusTotal. Further, MANTIS predicts malicious domains days to weeks before they appear in popular blocklists.         ",
    "url": "https://arxiv.org/abs/2502.09788",
    "authors": [
      "Fatih Deniz",
      "Mohamed Nabeel",
      "Ting Yu",
      "Issa Khalil"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2502.09801",
    "title": "Unit Testing Past vs. Present: Examining LLMs' Impact on Defect Detection and Efficiency",
    "abstract": "           The integration of Large Language Models (LLMs), such as ChatGPT and GitHub Copilot, into software engineering workflows has shown potential to enhance productivity, particularly in software testing. This paper investigates whether LLM support improves defect detection effectiveness during unit testing. Building on prior studies comparing manual and tool-supported testing, we replicated and extended an experiment where participants wrote unit tests for a Java-based system with seeded defects within a time-boxed session, supported by LLMs. Comparing LLM supported and manual testing, results show that LLM support significantly increases the number of unit tests generated, defect detection rates, and overall testing efficiency. These findings highlight the potential of LLMs to improve testing and defect detection outcomes, providing empirical insights into their practical application in software testing.         ",
    "url": "https://arxiv.org/abs/2502.09801",
    "authors": [
      "Rudolf Ramler",
      "Philipp Straubinger",
      "Reinhold Pl\u00f6sch",
      "Dietmar Winkler"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2502.09808",
    "title": "VIRGOS: Secure Graph Convolutional Network on Vertically Split Data from Sparse Matrix Decomposition",
    "abstract": "           Securely computing graph convolutional networks (GCNs) is critical for applying their analytical capabilities to privacy-sensitive data like social/credit networks. Multiplying a sparse yet large adjacency matrix of a graph in GCN--a core operation in training/inference--poses a performance bottleneck in secure GCNs. Consider a GCN with $|V|$ nodes and $|E|$ edges; it incurs a large $O(|V|^2)$ communication overhead. Modeling bipartite graphs and leveraging the monotonicity of non-zero entry locations, we propose a co-design harmonizing secure multi-party computation (MPC) with matrix sparsity. Our sparse matrix decomposition transforms an arbitrary sparse matrix into a product of structured matrices. Specialized MPC protocols for oblivious permutation and selection multiplication are then tailored, enabling our secure sparse matrix multiplication ($(SM)^2$) protocol, optimized for secure multiplication of these structured matrices. Together, these techniques take $O(|E|)$ communication in constant rounds. Supported by $(SM)^2$, we present Virgos, a secure 2-party framework that is communication-efficient and memory-friendly on standard vertically-partitioned graph datasets. Performance of Virgos has been empirically validated across diverse network conditions.         ",
    "url": "https://arxiv.org/abs/2502.09808",
    "authors": [
      "Yu Zheng",
      "Qizhi Zhang",
      "Lichun Li",
      "Kai Zhou",
      "Shan Yin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2502.09811",
    "title": "Inclusive Avatar Guidelines for People with Disabilities: Supporting Disability Representation in Social Virtual Reality",
    "abstract": "           Avatar is a critical medium for identity representation in social virtual reality (VR). However, options for disability expression are highly limited on current avatar interfaces. Improperly designed disability features may even perpetuate misconceptions about people with disabilities (PWD). As more PWD use social VR, there is an emerging need for comprehensive design standards that guide developers and designers to create inclusive avatars. Our work aim to advance the avatar design practices by delivering a set of centralized, comprehensive, and validated design guidelines that are easy to adopt, disseminate, and update. Through a systematic literature review and interview with 60 participants with various disabilities, we derived 20 initial design guidelines that cover diverse disability expression methods through five aspects, including avatar appearance, body dynamics, assistive technology design, peripherals around avatars, and customization control. We further evaluated the guidelines via a heuristic evaluation study with 10 VR practitioners, validating the guideline coverage, applicability, and actionability. Our evaluation resulted in a final set of 17 design guidelines with recommendation levels.         ",
    "url": "https://arxiv.org/abs/2502.09811",
    "authors": [
      "Kexin Zhang",
      "Edward Glenn Scott Spencer",
      "Abijith Manikandan",
      "Andric Li",
      "Ang Li",
      "Yaxing Yao",
      "Yuhang Zhao"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2502.09814",
    "title": "INJONGO: A Multicultural Intent Detection and Slot-filling Dataset for 16 African Languages",
    "abstract": "           Slot-filling and intent detection are well-established tasks in Conversational AI. However, current large-scale benchmarks for these tasks often exclude evaluations of low-resource languages and rely on translations from English benchmarks, thereby predominantly reflecting Western-centric concepts. In this paper, we introduce Injongo -- a multicultural, open-source benchmark dataset for 16 African languages with utterances generated by native speakers across diverse domains, including banking, travel, home, and dining. Through extensive experiments, we benchmark the fine-tuning multilingual transformer models and the prompting large language models (LLMs), and show the advantage of leveraging African-cultural utterances over Western-centric utterances for improving cross-lingual transfer from the English language. Experimental results reveal that current LLMs struggle with the slot-filling task, with GPT-4o achieving an average performance of 26 F1-score. In contrast, intent detection performance is notably better, with an average accuracy of 70.6%, though it still falls behind the fine-tuning baselines. Compared to the English language, GPT-4o and fine-tuning baselines perform similarly on intent detection, achieving an accuracy of approximately 81%. Our findings suggest that the performance of LLMs is still behind for many low-resource African languages, and more work is needed to further improve their downstream performance.         ",
    "url": "https://arxiv.org/abs/2502.09814",
    "authors": [
      "Hao Yu",
      "Jesujoba O. Alabi",
      "Andiswa Bukula",
      "Jian Yun Zhuang",
      "En-Shiun Annie Lee",
      "Tadesse Kebede Guge",
      "Israel Abebe Azime",
      "Happy Buzaaba",
      "Blessing Kudzaishe Sibanda",
      "Godson K. Kalipe",
      "Jonathan Mukiibi",
      "Salomon Kabongo Kabenamualu",
      "Mmasibidi Setaka",
      "Lolwethu Ndolela",
      "Nkiruka Odu",
      "Rooweither Mabuya",
      "Shamsuddeen Hassan Muhammad",
      "Salomey Osei",
      "Sokhar Samb",
      "Juliet W. Murage",
      "Dietrich Klakow",
      "David Ifeoluwa Adelani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2502.09815",
    "title": "Statistical Coherence Alignment for Large Language Model Representation Learning Through Tensor Field Convergence",
    "abstract": "           Representation learning plays a central role in structuring internal embeddings to capture the statistical properties of language, influencing the coherence and contextual consistency of generated text. Statistical Coherence Alignment is introduced as a method to enforce structured token representations through tensor field convergence, guiding embeddings to reflect statistical dependencies inherent in linguistic data. A mathematical framework is established to quantify coherence alignment, integrating a loss function that optimizes representational consistency across training iterations. Empirical evaluations demonstrate that applying coherence constraints improves perplexity, enhances classification accuracy, and refines rare word embeddings, contributing to a more stable representation space. Comparative analyses with baseline models reveal that the proposed method fosters a more interpretable internal structure, ensuring that embeddings retain contextual dependencies while mitigating representation collapse. The impact on coherence score distributions suggests that the alignment mechanism strengthens semantic integrity across diverse linguistic constructs, leading to a more balanced organization of learned embeddings. Computational assessments indicate that while the method introduces additional memory and training costs, the structured optimization process justifies the trade-offs in applications requiring heightened contextual fidelity. Experimental results validate the effectiveness of coherence alignment in optimizing token representations, providing insights into how statistical dependencies can be leveraged to improve language model training.         ",
    "url": "https://arxiv.org/abs/2502.09815",
    "authors": [
      "Jonathan Gale",
      "Godfrey Aldington",
      "Harriet Thistlewood",
      "Thomas Tattershall",
      "Basil Wentworth",
      "Vincent Enoasmo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2502.09818",
    "title": "On the robustness of multimodal language model towards distractions",
    "abstract": "           Although vision-language models (VLMs) have achieved significant success in various applications such as visual question answering, their resilience to prompt variations remains an under-explored area. Understanding how distractions affect VLMs is crucial for improving their real-world applicability, as inputs could have noisy and irrelevant information in many practical scenarios. This paper aims to assess the robustness of VLMs against both visual and textual distractions in the context of science question answering. Built on the ScienceQA dataset, we developed a new benchmark that introduces distractions in both the visual and textual contexts to evaluate the reasoning capacity of VLMs amid these distractions. Our findings reveal that most-of-the-art VLMs, including GPT-4, are vulnerable to various types of distractions, experiencing noticeable degradation in reasoning capabilities when confronted with distractions. Notably, models such as InternVL2 demonstrate a higher degree of robustness to these distractions. We also found that models exhibit greater sensitivity to textual distractions than visual ones. Additionally, we explored various mitigation strategies, such as prompt engineering, to counteract the impact of distractions. While these strategies improved solution accuracy, our analysis shows that there remain significant opportunities for improvement.         ",
    "url": "https://arxiv.org/abs/2502.09818",
    "authors": [
      "Ming Liu",
      "Hao Chen",
      "Jindong Wang",
      "Wensheng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2502.09822",
    "title": "ATM-Net: Adaptive Termination and Multi-Precision Neural Networks for Energy-Harvested Edge Intelligence",
    "abstract": "           ATM-Net is a novel neural network architecture tailored for energy-harvested IoT devices, integrating adaptive termination points with multi-precision computing. It dynamically adjusts computational precision (32/8/4-bit) and network depth based on energy availability via early exit points. An energy-aware task scheduler optimizes the energy-accuracy trade-off. Experiments on CIFAR-10, PlantVillage, and TissueMNIST show ATM-Net achieves up to 96.93% accuracy while reducing power consumption by 87.5% with Q4 quantization compared to 32-bit operations. The power-delay product improves from 13.6J to 0.141J for DenseNet-121 and from 10.3J to 0.106J for ResNet-18, demonstrating its suitability for energy-harvesting systems.         ",
    "url": "https://arxiv.org/abs/2502.09822",
    "authors": [
      "Neeraj Solanki",
      "Sepehr Tabrizchi",
      "Samin Sohrabi",
      "Jason Schmidt",
      "Arman Roohi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.09833",
    "title": "Decentralized Entropy-Based Ransomware Detection Using Autonomous Feature Resonance",
    "abstract": "           The increasing sophistication of cyber threats has necessitated the development of advanced detection mechanisms capable of identifying malicious activities with high precision and efficiency. A novel approach, termed Autonomous Feature Resonance, is introduced to address the limitations of traditional ransomware detection methods through the analysis of entropy-based feature interactions within system processes. The proposed method achieves an overall detection accuracy of 97.3\\%, with false positive and false negative rates of 1.8\\% and 2.1\\%, respectively, outperforming existing techniques such as signature-based detection and behavioral analysis. Its decentralized architecture enables local processing of data, reducing latency and improving scalability, while a self-learning mechanism ensures continuous adaptation to emerging threats. Experimental results demonstrate consistent performance across diverse ransomware families, including LockBit 3.0, BlackCat, and Royal, with low detection latency and efficient resource utilization. The method's reliance on entropy as a distinguishing feature provides robustness against obfuscation techniques, making it suitable for real-time deployment in high-throughput environments. These findings highlight the potential of entropy-based approaches to enhance cybersecurity frameworks, offering a scalable and adaptive solution for modern ransomware detection challenges.         ",
    "url": "https://arxiv.org/abs/2502.09833",
    "authors": [
      "Barnaby Quince",
      "Levi Gareth",
      "Sophie Larkspur",
      "Thaddeus Wobblethorn",
      "Thomas Quibble"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2502.09838",
    "title": "HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation",
    "abstract": "           We present HealthGPT, a powerful Medical Large Vision-Language Model (Med-LVLM) that integrates medical visual comprehension and generation capabilities within a unified autoregressive paradigm. Our bootstrapping philosophy is to progressively adapt heterogeneous comprehension and generation knowledge to pre-trained large language models (LLMs). This is achieved through a novel heterogeneous low-rank adaptation (H-LoRA) technique, which is complemented by a tailored hierarchical visual perception approach and a three-stage learning strategy. To effectively learn the HealthGPT, we devise a comprehensive medical domain-specific comprehension and generation dataset called VL-Health. Experimental results demonstrate exceptional performance and scalability of HealthGPT in medical visual unified tasks. Our project can be accessed at this https URL.         ",
    "url": "https://arxiv.org/abs/2502.09838",
    "authors": [
      "Tianwei Lin",
      "Wenqiao Zhang",
      "Sijing Li",
      "Yuqian Yuan",
      "Binhe Yu",
      "Haoyuan Li",
      "Wanggui He",
      "Hao Jiang",
      "Mengze Li",
      "Xiaohui Song",
      "Siliang Tang",
      "Jun Xiao",
      "Hui Lin",
      "Yueting Zhuang",
      "Beng Chin Ooi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2502.09842",
    "title": "Efficient, Accurate, and Robust Penalty-Projection Algorithm for Parameterized Stochastic Navier-Stokes Flow Problems",
    "abstract": "           This paper presents and analyzes a fast, robust, efficient, and optimally accurate fully discrete splitting algorithm for the Uncertainty Quantification (UQ) of parameterized Stochastic Navier-Stokes Equations (SNSEs) flow problems those occur in the convection-dominated regimes. The time-stepping algorithm is an implicit backward-Euler linearized method, grad-div and Ensemble Eddy Viscosity (EEV) regularized, and split using discrete Hodge decomposition. Additionally, the scheme's sub-problems are all designed to have different Right-Hand-Side (RHS) vectors but the same system matrix for all realizations at each time-step. The stability of the algorithm is rigorously proven, and it has been shown that appropriately large grad-div stabilization parameters vanish the splitting error. The proposed UQ algorithm is then combined with the Stochastic Collocation Methods (SCMs). Several numerical experiments are given to verify this superior scheme's predicted convergence rates and performance on benchmark problems for high expected Reynolds numbers ($Re$).         ",
    "url": "https://arxiv.org/abs/2502.09842",
    "authors": [
      "Neethu Suma Raveendran",
      "Md. Abdul Aziz",
      "Sivaguru S. Ravindran",
      "Muhammad Mohebujjaman"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2502.09846",
    "title": "Robust Event-Triggered Integrated Communication and Control with Graph Information Bottleneck Optimization",
    "abstract": "           Integrated communication and control serves as a critical ingredient in Multi-Agent Reinforcement Learning. However, partial observability limitations will impair collaboration effectiveness, and a potential solution is to establish consensus through well-calibrated latent variables obtained from neighboring agents. Nevertheless, the rigid transmission of less informative content can still result in redundant information exchanges. Therefore, we propose a Consensus-Driven Event-Based Graph Information Bottleneck (CDE-GIB) method, which integrates the communication graph and information flow through a GIB regularizer to extract more concise message representations while avoiding the high computational complexity of inner-loop operations. To further minimize the communication volume required for establishing consensus during interactions, we also develop a variable-threshold event-triggering mechanism. By simultaneously considering historical data and current observations, this mechanism capably evaluates the importance of information to determine whether an event should be triggered. Experimental results demonstrate that our proposed method outperforms existing state-of-the-art methods in terms of both efficiency and adaptability.         ",
    "url": "https://arxiv.org/abs/2502.09846",
    "authors": [
      "Ziqiong Wang",
      "Xiaoxue Yu",
      "Rongpeng Li",
      "Zhifeng Zhao"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2502.09850",
    "title": "Elastic Representation: Mitigating Spurious Correlations for Group Robustness",
    "abstract": "           Deep learning models can suffer from severe performance degradation when relying on spurious correlations between input features and labels, making the models perform well on training data but have poor prediction accuracy for minority groups. This problem arises especially when training data are limited or imbalanced. While most prior work focuses on learning invariant features (with consistent correlations to y), it overlooks the potential harm of spurious correlations between features. We hereby propose Elastic Representation (ElRep) to learn features by imposing Nuclear- and Frobenius-norm penalties on the representation from the last layer of a neural network. Similar to the elastic net, ElRep enjoys the benefits of learning important features without losing feature diversity. The proposed method is simple yet effective. It can be integrated into many deep learning approaches to mitigate spurious correlations and improve group robustness. Moreover, we theoretically show that ElRep has minimum negative impacts on in-distribution predictions. This is a remarkable advantage over approaches that prioritize minority groups at the cost of overall performance.         ",
    "url": "https://arxiv.org/abs/2502.09850",
    "authors": [
      "Tao Wen",
      "Zihan Wang",
      "Quan Zhang",
      "Qi Lei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.09863",
    "title": "Solvable Dynamics of Self-Supervised Word Embeddings and the Emergence of Analogical Reasoning",
    "abstract": "           The remarkable success of large language models relies on their ability to implicitly learn structured latent representations from the pretraining corpus. As a simpler surrogate for representation learning in language modeling, we study a class of solvable contrastive self-supervised algorithms which we term quadratic word embedding models. These models resemble the word2vec algorithm and perform similarly on downstream tasks. Our main contributions are analytical solutions for both the training dynamics (under certain hyperparameter choices) and the final word embeddings, given in terms of only the corpus statistics. Our solutions reveal that these models learn orthogonal linear subspaces one at a time, each one incrementing the effective rank of the embeddings until model capacity is saturated. Training on WikiText, we find that the top subspaces represent interpretable concepts. Finally, we use our dynamical theory to predict how and when models acquire the ability to complete analogies.         ",
    "url": "https://arxiv.org/abs/2502.09863",
    "authors": [
      "Dhruva Karkada",
      "James B. Simon",
      "Yasaman Bahri",
      "Michael R. DeWeese"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2502.09864",
    "title": "U Can Touch This! Microarchitectural Timing Attacks via Machine Clears",
    "abstract": "           Microarchitectural timing attacks exploit subtle timing variations caused by hardware behaviors to leak sensitive information. In this paper, we introduce MCHammer, a novel side-channel technique that leverages machine clears induced by self-modifying code detection mechanisms. Unlike most traditional techniques, MCHammer does not require memory access or waiting periods, making it highly efficient. We compare MCHammer to the classical Flush+Reload technique, improving in terms of trace granularity, providing a powerful side-channel attack vector. Using MCHammer, we successfully recover keys from a deployed implementation of a cryptographic tool. Our findings highlight the practical implications of MCHammer and its potential impact on real-world systems.         ",
    "url": "https://arxiv.org/abs/2502.09864",
    "authors": [
      "Billy Bob Brumley"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2502.09872",
    "title": "Learning to Calibrate for Reliable Visual Fire Detection",
    "abstract": "           Fire is characterized by its sudden onset and destructive power, making early fire detection crucial for ensuring human safety and protecting property. With the advancement of deep learning, the application of computer vision in fire detection has significantly improved. However, deep learning models often exhibit a tendency toward overconfidence, and most existing works focus primarily on enhancing classification performance, with limited attention given to uncertainty modeling. To address this issue, we propose transforming the Expected Calibration Error (ECE), a metric for measuring uncertainty, into a differentiable ECE loss function. This loss is then combined with the cross-entropy loss to guide the training process of multi-class fire detection models. Additionally, to achieve a good balance between classification accuracy and reliable decision, we introduce a curriculum learning-based approach that dynamically adjusts the weight of the ECE loss during training. Extensive experiments are conducted on two widely used multi-class fire detection datasets, DFAN and EdgeFireSmoke, validating the effectiveness of our uncertainty modeling method.         ",
    "url": "https://arxiv.org/abs/2502.09872",
    "authors": [
      "Ziqi Zhang",
      "Xiuzhuang Zhou",
      "Xiangyang Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.09885",
    "title": "Comprehensive Review of Neural Differential Equations for Time Series Analysis",
    "abstract": "           Time series modeling and analysis has become critical in various domains. Conventional methods such as RNNs and Transformers, while effective for discrete-time and regularly sampled data, face significant challenges in capturing the continuous dynamics and irregular sampling patterns inherent in real-world scenarios. Neural Differential Equations (NDEs) represent a paradigm shift by combining the flexibility of neural networks with the mathematical rigor of differential equations. This paper presents a comprehensive review of NDE-based methods for time series analysis, including neural ordinary differential equations, neural controlled differential equations, and neural stochastic differential equations. We provide a detailed discussion of their mathematical formulations, numerical methods, and applications, highlighting their ability to model continuous-time dynamics. Furthermore, we address key challenges and future research directions. This survey serves as a foundation for researchers and practitioners seeking to leverage NDEs for advanced time series analysis.         ",
    "url": "https://arxiv.org/abs/2502.09885",
    "authors": [
      "YongKyung Oh",
      "Seungsu Kam",
      "Jonghun Lee",
      "Dong-Young Lim",
      "Sungil Kim",
      "Alex Bui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2502.09897",
    "title": "Artificial Intelligence in Spectroscopy: Advancing Chemistry from Prediction to Generation and Beyond",
    "abstract": "           The rapid advent of machine learning (ML) and artificial intelligence (AI) has catalyzed major transformations in chemistry, yet the application of these methods to spectroscopic and spectrometric data, referred to as Spectroscopy Machine Learning (SpectraML), remains relatively underexplored. Modern spectroscopic techniques (MS, NMR, IR, Raman, UV-Vis) generate an ever-growing volume of high-dimensional data, creating a pressing need for automated and intelligent analysis beyond traditional expert-based workflows. In this survey, we provide a unified review of SpectraML, systematically examining state-of-the-art approaches for both forward tasks (molecule-to-spectrum prediction) and inverse tasks (spectrum-to-molecule inference). We trace the historical evolution of ML in spectroscopy, from early pattern recognition to the latest foundation models capable of advanced reasoning, and offer a taxonomy of representative neural architectures, including graph-based and transformer-based methods. Addressing key challenges such as data quality, multimodal integration, and computational scalability, we highlight emerging directions such as synthetic data generation, large-scale pretraining, and few- or zero-shot learning. To foster reproducible research, we also release an open-source repository containing recent papers and their corresponding curated datasets (this https URL). Our survey serves as a roadmap for researchers, guiding progress at the intersection of spectroscopy and AI.         ",
    "url": "https://arxiv.org/abs/2502.09897",
    "authors": [
      "Kehan Guo",
      "Yili Shen",
      "Gisela Abigail Gonzalez-Montiel",
      "Yue Huang",
      "Yujun Zhou",
      "Mihir Surve",
      "Zhichun Guo",
      "Prayel Das",
      "Nitesh V Chawla",
      "Olaf Wiest",
      "Xiangliang Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.09926",
    "title": "Robust Anomaly Detection via Tensor Chidori Pseudoskeleton Decomposition",
    "abstract": "           Anomaly detection plays a critical role in modern data-driven applications, from identifying fraudulent transactions and safeguarding network infrastructure to monitoring sensor systems for irregular patterns. Traditional approaches, such as distance, density, or cluster-based methods, face significant challenges when applied to high dimensional tensor data, where complex interdependencies across dimensions amplify noise and computational complexity. To address these limitations, this paper leverages Tensor Chidori pseudoskeleton decomposition within a tensor-robust principal component analysis framework to extract low Tucker rank structure while isolating sparse anomalies, ensuring robustness to anomaly detection. We establish theoretical results regarding convergence, and estimation error, demonstrating the stability and accuracy of the proposed approach. Numerical experiments on real-world spatiotemporal data from New York City taxi trip records validate the superiority of the proposed method in detecting anomalous urban events compared to existing benchmark methods. The results underscore the potential of Tensor Chidori pseudoskeleton decomposition to enhance anomaly detection for large-scale, high-dimensional data.         ",
    "url": "https://arxiv.org/abs/2502.09926",
    "authors": [
      "Bowen Su"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.09928",
    "title": "Deep Tree Tensor Networks for Image Recognition",
    "abstract": "           Originating in quantum physics, tensor networks (TNs) have been widely adopted as exponential machines and parameter decomposers for recognition tasks. Typical TN models, such as Matrix Product States (MPS), have not yet achieved successful application in natural image processing. When employed, they primarily serve to compress parameters within off-the-shelf networks, thus losing their distinctive capability to enhance exponential-order feature interactions. This paper introduces a novel architecture named \\textit{\\textbf{D}eep \\textbf{T}ree \\textbf{T}ensor \\textbf{N}etwork} (DTTN), which captures $2^L$-order multiplicative interactions across features through multilinear operations, while essentially unfolding into a \\emph{tree}-like TN topology with the parameter-sharing property. DTTN is stacked with multiple antisymmetric interacting modules (AIMs), and this design facilitates efficient implementation. Moreover, we theoretically reveal the equivalency among quantum-inspired TN models and polynomial and multilinear networks under certain conditions, and we believe that DTTN can inspire more interpretable studies in this field. We evaluate the proposed model against a series of benchmarks and achieve excellent performance compared to its peers and cutting-edge architectures. Our code will soon be publicly available.         ",
    "url": "https://arxiv.org/abs/2502.09928",
    "authors": [
      "Chang Nie",
      "Junfang Chen",
      "Yajie Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2502.09932",
    "title": "AffectSRNet : Facial Emotion-Aware Super-Resolution Network",
    "abstract": "           Facial expression recognition (FER) systems in low-resolution settings face significant challenges in accurately identifying expressions due to the loss of fine-grained facial details. This limitation is especially problematic for applications like surveillance and mobile communications, where low image resolution is common and can compromise recognition accuracy. Traditional single-image face super-resolution (FSR) techniques, however, often fail to preserve the emotional intent of expressions, introducing distortions that obscure the original affective content. Given the inherently ill-posed nature of single-image super-resolution, a targeted approach is required to balance image quality enhancement with emotion retention. In this paper, we propose AffectSRNet, a novel emotion-aware super-resolution framework that reconstructs high-quality facial images from low-resolution inputs while maintaining the intensity and fidelity of facial expressions. Our method effectively bridges the gap between image resolution and expression accuracy by employing an expression-preserving loss function, specifically tailored for FER applications. Additionally, we introduce a new metric to assess emotion preservation in super-resolved images, providing a more nuanced evaluation of FER system performance in low-resolution scenarios. Experimental results on standard datasets, including CelebA, FFHQ, and Helen, demonstrate that AffectSRNet outperforms existing FSR approaches in both visual quality and emotion fidelity, highlighting its potential for integration into practical FER applications. This work not only improves image clarity but also ensures that emotion-driven applications retain their core functionality in suboptimal resolution environments, paving the way for broader adoption in FER systems.         ",
    "url": "https://arxiv.org/abs/2502.09932",
    "authors": [
      "Syed Sameen Ahmad Rizvi",
      "Soham Kumar",
      "Aryan Seth",
      "Pratik Narang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2502.09941",
    "title": "A Lightweight and Effective Image Tampering Localization Network with Vision Mamba",
    "abstract": "           Current image tampering localization methods primarily rely on Convolutional Neural Networks (CNNs) and Transformers. While CNNs suffer from limited local receptive fields, Transformers offer global context modeling at the expense of quadratic computational complexity. Recently, the state space model Mamba has emerged as a competitive alternative, enabling linear-complexity global dependency modeling. Inspired by it, we propose a lightweight and effective FORensic network based on vision MAmba (ForMa) for blind image tampering localization. Firstly, ForMa captures multi-scale global features that achieves efficient global dependency modeling through linear complexity. Then the pixel-wise localization map is generated by a lightweight decoder, which employs a parameter-free pixel shuffle layer for upsampling. Additionally, a noise-assisted decoding strategy is proposed to integrate complementary manipulation traces from tampered images, boosting decoder sensitivity to forgery cues. Experimental results on 10 standard datasets demonstrate that ForMa achieves state-of-the-art generalization ability and robustness, while maintaining the lowest computational complexity. Code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2502.09941",
    "authors": [
      "Kun Guo",
      "Gang Cao",
      "Zijie Lou",
      "Xianglin Huang",
      "Jiaoyun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2502.09944",
    "title": "Self-Supervised Learning for Neural Topic Models with Variance-Invariance-Covariance Regularization",
    "abstract": "           In our study, we propose a self-supervised neural topic model (NTM) that combines the power of NTMs and regularized self-supervised learning methods to improve performance. NTMs use neural networks to learn latent topics hidden behind the words in documents, enabling greater flexibility and the ability to estimate more coherent topics compared to traditional topic models. On the other hand, some self-supervised learning methods use a joint embedding architecture with two identical networks that produce similar representations for two augmented versions of the same input. Regularizations are applied to these representations to prevent collapse, which would otherwise result in the networks outputting constant or redundant representations for all inputs. Our model enhances topic quality by explicitly regularizing latent topic representations of anchor and positive samples. We also introduced an adversarial data augmentation method to replace the heuristic sampling method. We further developed several variation models including those on the basis of an NTM that incorporates contrastive learning with both positive and negative samples. Experimental results on three datasets showed that our models outperformed baselines and state-of-the-art models both quantitatively and qualitatively.         ",
    "url": "https://arxiv.org/abs/2502.09944",
    "authors": [
      "Weiran Xu",
      "Kengo Hirami",
      "Koji Eguchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2502.09954",
    "title": "On Space Folds of ReLU Neural Networks",
    "abstract": "           Recent findings suggest that the consecutive layers of ReLU neural networks can be understood geometrically as space folding transformations of the input space, revealing patterns of self-similarity. In this paper, we present the first quantitative analysis of this space folding phenomenon in ReLU neural networks. Our approach focuses on examining how straight paths in the Euclidean input space are mapped to their counterparts in the Hamming activation space. In this process, the convexity of straight lines is generally lost, giving rise to non-convex folding behavior. To quantify this effect, we introduce a novel measure based on range metrics, similar to those used in the study of random walks, and provide the proof for the equivalence of convexity notions between the input and activation spaces. Furthermore, we provide empirical analysis on a geometrical analysis benchmark (CantorNet) as well as an image classification benchmark (MNIST). Our work advances the understanding of the activation space in ReLU neural networks by leveraging the phenomena of geometric folding, providing valuable insights on how these models process input information.         ",
    "url": "https://arxiv.org/abs/2502.09954",
    "authors": [
      "Michal Lewandowski",
      "Hamid Eghbalzadeh",
      "Bernhard Heinzl",
      "Raphael Pisoni",
      "Bernhard A.Moser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2502.09956",
    "title": "KGGen: Extracting Knowledge Graphs from Plain Text with Language Models",
    "abstract": "           Recent interest in building foundation models for KGs has highlighted a fundamental challenge: knowledge-graph data is relatively scarce. The best-known KGs are primarily human-labeled, created by pattern-matching, or extracted using early NLP techniques. While human-generated KGs are in short supply, automatically extracted KGs are of questionable quality. We present a solution to this data scarcity problem in the form of a text-to-KG generator (KGGen), a package that uses language models to create high-quality graphs from plaintext. Unlike other KG extractors, KGGen clusters related entities to reduce sparsity in extracted KGs. KGGen is available as a Python library (\\texttt{pip install kg-gen}), making it accessible to everyone. Along with KGGen, we release the first benchmark, Measure of of Information in Nodes and Edges (MINE), that tests an extractor's ability to produce a useful KG from plain text. We benchmark our new tool against existing extractors and demonstrate far superior performance.         ",
    "url": "https://arxiv.org/abs/2502.09956",
    "authors": [
      "Belinda Mo",
      "Kyssen Yu",
      "Joshua Kazdan",
      "Proud Mpala",
      "Lisa Yu",
      "Chris Cundy",
      "Charilaos Kanatsoulis",
      "Sanmi Koyejo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.09969",
    "title": "Data Valuation using Neural Networks for Efficient Instruction Fine-Tuning",
    "abstract": "           Influence functions provide crucial insights into model training, but existing methods suffer from large computational costs and limited generalization. Particularly, recent works have proposed various metrics and algorithms to calculate the influence of data using language models, which do not scale well with large models and datasets. This is because of the expensive forward and backward passes required for computation, substantial memory requirements to store large models, and poor generalization of influence estimates to new data. In this paper, we explore the use of small neural networks -- which we refer to as the InfluenceNetwork -- to estimate influence values, achieving up to 99% cost reduction. Our evaluation demonstrates that influence values can be estimated with models just 0.0027% the size of full language models (we use 7B and 8B versions). We apply our algorithm of estimating influence values (called NN-CIFT: Neural Networks for effiCient Instruction Fine-Tuning) to the downstream task of subset selection for general instruction fine-tuning. In our study, we include four state-of-the-art influence functions and show no compromise in performance, despite large speedups, between NN-CIFT and the original influence functions. We provide an in-depth hyperparameter analyses of NN-CIFT. The code for our method can be found here: this https URL.         ",
    "url": "https://arxiv.org/abs/2502.09969",
    "authors": [
      "Ishika Agarwal",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2502.09975",
    "title": "DPM-Bench: Benchmark for Distributed Process Mining Algorithms on Cyber-Physical Systems",
    "abstract": "           Process Mining is established in research and industry systems to analyze and optimize processes based on event data from information systems. Within this work, we accomodate process mining techniques to Cyber-Physical Systems. To capture the distributed and heterogeneous characteristics of data, computational resources, and network communication in CPS, the todays process mining algorithms and techniques must be augmented. Specifically, there is a need for new Distributed Process Mining algorithms that enable computations to be performed directly on edge resources, eliminating the need for moving all data to central cloud systems. This paper introduces the DPM-Bench benchmark for comparing such Distributed Process Mining algorithms. DPM-Bench is used to compare algorithms deployed in different computational topologies. The results enable information system engineers to assess whether the existing infrastructure is sufficient to perform distributed process mining, or to identify required improvements in algorithms and hardware. We present and discuss an experimental evaluation with DPM-Bench.         ",
    "url": "https://arxiv.org/abs/2502.09975",
    "authors": [
      "Hendrik Reiter",
      "Patrick Rathje",
      "Olaf Landsiedel",
      "Wilhelm Hasselbring"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2502.09981",
    "title": "Exploring Neural Granger Causality with xLSTMs: Unveiling Temporal Dependencies in Complex Data",
    "abstract": "           Causality in time series can be difficult to determine, especially in the presence of non-linear dependencies. The concept of Granger causality helps analyze potential relationships between variables, thereby offering a method to determine whether one time series can predict-Granger cause-future values of another. Although successful, Granger causal methods still struggle with capturing long-range relations between variables. To this end, we leverage the recently successful Extended Long Short-Term Memory (xLSTM) architecture and propose Granger causal xLSTMs (GC-xLSTM). It first enforces sparsity between the time series components by using a novel dynamic lass penalty on the initial projection. Specifically, we adaptively improve the model and identify sparsity candidates. Our joint optimization procedure then ensures that the Granger causal relations are recovered in a robust fashion. Our experimental evaluations on three datasets demonstrate the overall efficacy of our proposed GC-xLSTM model.         ",
    "url": "https://arxiv.org/abs/2502.09981",
    "authors": [
      "Harsh Poonia",
      "Felix Divo",
      "Kristian Kersting",
      "Devendra Singh Dhami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.10011",
    "title": "InterGridNet: An Electric Network Frequency Approach for Audio Source Location Classification Using Convolutional Neural Networks",
    "abstract": "           A novel framework, called InterGridNet, is introduced, leveraging a shallow RawNet model for geolocation classification of Electric Network Frequency (ENF) signatures in the SP Cup 2016 dataset. During data preparation, recordings are sorted into audio and power groups based on inherent characteristics, further divided into 50 Hz and 60 Hz groups via spectrogram analysis. Residual blocks within the classification model extract frame-level embeddings, aiding decision-making through softmax activation. The topology and the hyperparameters of the shallow RawNet are optimized using a Neural Architecture Search. The overall accuracy of InterGridNet in the test recordings is 92%, indicating its effectiveness against the state-of-the-art methods tested in the SP Cup 2016. These findings underscore InterGridNet's effectiveness in accurately classifying audio recordings from diverse power grids, advancing state-of-the-art geolocation estimation methods.         ",
    "url": "https://arxiv.org/abs/2502.10011",
    "authors": [
      "Christos Korgialas",
      "Ioannis Tsingalis",
      "Georgios Tzolopoulos",
      "Constantine Kotropoulos"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2502.10027",
    "title": "Heterogeneous Resource Allocation with Multi-task Learning for Wireless Networks",
    "abstract": "           The optimal solution to an optimization problem depends on the problem's objective function, constraints, and size. While deep neural networks (DNNs) have proven effective in solving optimization problems, changes in the problem's size, objectives, or constraints often require adjustments to the DNN architecture to maintain effectiveness, or even retraining a new DNN from scratch. Given the dynamic nature of wireless networks, which involve multiple and diverse objectives that can have conflicting requirements and constraints, we propose a multi-task learning (MTL) framework to enable a single DNN to jointly solve a range of diverse optimization problems. In this framework, optimization problems with varying dimensionality values, objectives, and constraints are treated as distinct tasks. To jointly address these tasks, we propose a conditional computation-based MTL approach with routing. The multi-task DNN consists of two components, the base DNN (bDNN), which is the single DNN used to extract the solutions for all considered optimization problems, and the routing DNN (rDNN), which manages which nodes and layers of the bDNN to be used during the forward propagation of each task. The output of the rDNN is a binary vector which is multiplied with all bDNN's weights during the forward propagation, creating a unique computational path through the bDNN for each task. This setup allows the tasks to either share parameters or use independent ones, with the decision controlled by the rDNN. The proposed framework supports both supervised and unsupervised learning scenarios. Numerical results demonstrate the efficiency of the proposed MTL approach in solving diverse optimization problems. In contrast, benchmark DNNs lacking the rDNN mechanism were unable to achieve similar levels of performance, highlighting the effectiveness of the proposed architecture.         ",
    "url": "https://arxiv.org/abs/2502.10027",
    "authors": [
      "Nikos A. Mitsiou",
      "Pavlos S. Bouzinis",
      "Panagiotis G. Sarigiannidis",
      "George K. Karagiannidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.10028",
    "title": "ManiTrend: Bridging Future Generation and Action Prediction with 3D Flow for Robotic Manipulation",
    "abstract": "           Language-conditioned manipulation is a vital but challenging robotic task due to the high-level abstraction of language. To address this, researchers have sought improved goal representations derived from natural language. In this paper, we highlight 3D flow - representing the motion trend of 3D particles within a scene - as an effective bridge between language-based future image generation and fine-grained action prediction. To this end, we develop ManiTrend, a unified framework that models the dynamics of 3D particles, vision observations and manipulation actions with a causal transformer. Within this framework, features for 3D flow prediction serve as additional conditions for future image generation and action prediction, alleviating the complexity of pixel-wise spatiotemporal modeling and providing seamless action guidance. Furthermore, 3D flow can substitute missing or heterogeneous action labels during large-scale pretraining on cross-embodiment demonstrations. Experiments on two comprehensive benchmarks demonstrate that our method achieves state-of-the-art performance with high efficiency. Our code and model checkpoints will be available upon acceptance.         ",
    "url": "https://arxiv.org/abs/2502.10028",
    "authors": [
      "Yuxin He",
      "Qiang Nie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2502.10033",
    "title": "Phi-FEM-FNO: a new approach to train a Neural Operator as a fast PDE solver for variable geometries",
    "abstract": "           In this paper, we propose a way to solve partial differential equations (PDEs) by combining machine learning techniques and the finite element method called Phi-FEM. For that, we use the Fourier Neural Operator (FNO), a learning mapping operator. The purpose of this paper is to provide numerical evidence to show the effectiveness of this technique. We will focus here on the resolution of two equations: the Poisson-Dirichlet equation and the non-linear elasticity equations. The key idea of our method is to address the challenging scenario of varying domains, where each problem is solved on a different geometry. The considered domains are defined by level-set functions due to the use of the Phi-FEM approach. We will first recall the idea of $\\varphi$-FEM and of the Fourier Neural Operator. Then, we will explain how to combine these two methods. We will finally illustrate the efficiency of this combination with some numerical results on three test cases. In addition, in the last test case, we propose a new numerical scheme for hyperelastic materials following the Phi-FEM paradigm.         ",
    "url": "https://arxiv.org/abs/2502.10033",
    "authors": [
      "Michel Duprez",
      "Vanessa Lleras",
      "Alexei Lozinski",
      "Vincent Vigon",
      "Killian Vuillemot"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2502.10038",
    "title": "POI-Enhancer: An LLM-based Semantic Enhancement Framework for POI Representation Learning",
    "abstract": "           POI representation learning plays a crucial role in handling tasks related to user mobility data. Recent studies have shown that enriching POI representations with multimodal information can significantly enhance their task performance. Previously, the textual information incorporated into POI representations typically involved only POI categories or check-in content, leading to relatively weak textual features in existing methods. In contrast, large language models (LLMs) trained on extensive text data have been found to possess rich textual knowledge. However leveraging such knowledge to enhance POI representation learning presents two key challenges: first, how to extract POI-related knowledge from LLMs effectively, and second, how to integrate the extracted information to enhance POI representations. To address these challenges, we propose POI-Enhancer, a portable framework that leverages LLMs to improve POI representations produced by classic POI learning models. We first design three specialized prompts to extract semantic information from LLMs efficiently. Then, the Dual Feature Alignment module enhances the quality of the extracted information, while the Semantic Feature Fusion module preserves its integrity. The Cross Attention Fusion module then fully adaptively integrates such high-quality information into POI representations and Multi-View Contrastive Learning further injects human-understandable semantic information into these representations. Extensive experiments on three real-world datasets demonstrate the effectiveness of our framework, showing significant improvements across all baseline representations.         ",
    "url": "https://arxiv.org/abs/2502.10038",
    "authors": [
      "Jiawei Cheng",
      "Jingyuan Wang",
      "Yichuan Zhang",
      "Jiahao Ji",
      "Yuanshao Zhu",
      "Zhibo Zhang",
      "Xiangyu Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2502.10042",
    "title": "Scaling Law Tradeoff Between Throughput and Sensing Distance in Large ISAC Networks",
    "abstract": "           In this paper, we investigate the fundamental tradeoff between communication and sensing performance of \\emph{ad hoc} integrated sensing and communication (ISAC) wireless networks. Specifically, we consider that $n$ nodes are randomly located in an extended network with area $n$ and transmit ISAC signals. Under the pure path loss channel gain model and the condition that the transmission power scales according to the communication distance, we fully characterize the optimal scaling law tradeoff between throughput and sensing distance by proposing an achievable scheme and proving its converse. Our results can be interpreted as follows: by reducing the throughput by a factor of a function of $n$, the sensing range order improves according to the same function of $n$, raised to the power of the ratio between the path loss factors in communication and sensing. We prove that the same result also holds true for ISAC networks with random fading, despite the uncertainty on the connectivity and power level created by random fading. In addition, we show that the scaling law tradeoff cannot be improved by allowing the transmission power and communication distance to scale freely. To the best of our knowledge, this is the first work formally formulating and characterizing the communication and sensing performance scaling law tradeoff of \\emph{ad hoc} ISAC networks.         ",
    "url": "https://arxiv.org/abs/2502.10042",
    "authors": [
      "Min Qiu",
      "Ming-Chun Lee",
      "Yu-Chih Huang",
      "Jinhong Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2502.10047",
    "title": "Janus: Collaborative Vision Transformer Under Dynamic Network Environment",
    "abstract": "           Vision Transformers (ViTs) have outperformed traditional Convolutional Neural Network architectures and achieved state-of-the-art results in various computer vision tasks. Since ViTs are computationally expensive, the models either have to be pruned to run on resource-limited edge devices only or have to be executed on remote cloud servers after receiving the raw data transmitted over fluctuating networks. The resulting degraded performance or high latency all hinder their widespread applications. In this paper, we present Janus, the first framework for low-latency cloud-device collaborative Vision Transformer inference over dynamic networks. Janus overcomes the intrinsic model limitations of ViTs and realizes collaboratively executing ViT models on both cloud and edge devices, achieving low latency, high accuracy, and low communication overhead. Specifically, Janus judiciously combines token pruning techniques with a carefully designed fine-to-coarse model splitting policy and non-static mixed pruning policy. It attains a balance between accuracy and latency by dynamically selecting the optimal pruning level and split point. Experimental results across various tasks demonstrate that Janus enhances throughput by up to 5.15 times and reduces latency violation ratios by up to 98.7% when compared with baseline approaches under various network environments.         ",
    "url": "https://arxiv.org/abs/2502.10047",
    "authors": [
      "Linyi Jiang",
      "Silvery D. Fu",
      "Yifei Zhu",
      "Bo Li"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2502.10059",
    "title": "RealCam-I2V: Real-World Image-to-Video Generation with Interactive Complex Camera Control",
    "abstract": "           Recent advancements in camera-trajectory-guided image-to-video generation offer higher precision and better support for complex camera control compared to text-based approaches. However, they also introduce significant usability challenges, as users often struggle to provide precise camera parameters when working with arbitrary real-world images without knowledge of their depth nor scene scale. To address these real-world application issues, we propose RealCam-I2V, a novel diffusion-based video generation framework that integrates monocular metric depth estimation to establish 3D scene reconstruction in a preprocessing step. During training, the reconstructed 3D scene enables scaling camera parameters from relative to absolute values, ensuring compatibility and scale consistency across diverse real-world images. In inference, RealCam-I2V offers an intuitive interface where users can precisely draw camera trajectories by dragging within the 3D scene. To further enhance precise camera control and scene consistency, we propose scene-constrained noise shaping, which shapes high-level noise and also allows the framework to maintain dynamic, coherent video generation in lower noise stages. RealCam-I2V achieves significant improvements in controllability and video quality on the RealEstate10K and out-of-domain images. We further enables applications like camera-controlled looping video generation and generative frame interpolation. We will release our absolute-scale annotation, codes, and all checkpoints. Please see dynamic results in this https URL.         ",
    "url": "https://arxiv.org/abs/2502.10059",
    "authors": [
      "Teng Li",
      "Guangcong Zheng",
      "Rui Jiang",
      "Shuigenzhan",
      "Tao Wu",
      "Yehao Lu",
      "Yining Lin",
      "Xi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2502.10066",
    "title": "Augmenting Plane Straight-Line Graphs to Meet Parity Constraints",
    "abstract": "           Given a plane geometric graph $G$ on $n$ vertices, we want to augment it so that given parity constraints of the vertex degrees are met. In other words, given a subset $R$ of the vertices, we are interested in a plane geometric supergraph $G'$ such that exactly the vertices of $R$ have odd degree in $G'\\setminus G$. We show that the question whether such a supergraph exists can be decided in polynomial time for two interesting cases. First, when the vertices are in convex position, we present a linear-time algorithm. Building on this insight, we solve the case when $G$ is a plane geometric path in $O(n \\log n)$ time. This solves an open problem posed by Catana, Olaverri, Tejel, and Urrutia (Appl. Math. Comput. 2020).         ",
    "url": "https://arxiv.org/abs/2502.10066",
    "authors": [
      "Aleksander Bj\u00f8rn Grodt Christiansen",
      "Linda Kleist",
      "Irene Parada",
      "Eva Rotenberg"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2502.10070",
    "title": "Topological Neural Networks over the Air",
    "abstract": "           Topological neural networks (TNNs) are information processing architectures that model representations from data lying over topological spaces (e.g., simplicial or cell complexes) and allow for decentralized implementation through localized communications over different neighborhoods. Existing TNN architectures have not yet been considered in realistic communication scenarios, where channel effects typically introduce disturbances such as fading and noise. This paper aims to propose a novel TNN design, operating on regular cell complexes, that performs over-the-air computation, incorporating the wireless communication model into its architecture. Specifically, during training and inference, the proposed method considers channel impairments such as fading and noise in the topological convolutional filtering operation, which takes place over different signal orders and neighborhoods. Numerical results illustrate the architecture's robustness to channel impairments during testing and the superior performance with respect to existing architectures, which are either communication-agnostic or graph-based.         ",
    "url": "https://arxiv.org/abs/2502.10070",
    "authors": [
      "Simone Fiorellino",
      "Claudio Battiloro",
      "Paolo Di Lorenzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.10076",
    "title": "Classification of Temporal Graphs using Persistent Homology",
    "abstract": "           Temporal graphs effectively model dynamic systems by representing interactions as timestamped edges. However, analytical tools for temporal graphs are limited compared to static graphs. We propose a novel method for analyzing temporal graphs using Persistent Homology. Our approach leverages $\\delta$-temporal motifs (recurrent subgraphs) to capture temporal dynamics %without aggregation . By evolving these motifs, we define the \\textit{average filtration} and compute PH on the associated clique complex. This method captures both local and global temporal structures and is stable with respect to reference models. We demonstrate the applicability of our approach to the temporal graph classification task. Experiments verify the effectiveness of our approach, achieving over 92\\% accuracy, with some cases reaching 100\\%. Unlike existing methods that require node classes, our approach is node class free, offering flexibility for a wide range of temporal graph analysis.         ",
    "url": "https://arxiv.org/abs/2502.10076",
    "authors": [
      "Siddharth Pritam",
      "Rohit Roy",
      "Madhav Cherupilil Sajeev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2502.10077",
    "title": "Towards Empowerment Gain through Causal Structure Learning in Model-Based RL",
    "abstract": "           In Model-Based Reinforcement Learning (MBRL), incorporating causal structures into dynamics models provides agents with a structured understanding of the environments, enabling efficient decision. Empowerment as an intrinsic motivation enhances the ability of agents to actively control their environments by maximizing the mutual information between future states and actions. We posit that empowerment coupled with causal understanding can improve controllability, while enhanced empowerment gain can further facilitate causal reasoning in MBRL. To improve learning efficiency and controllability, we propose a novel framework, Empowerment through Causal Learning (ECL), where an agent with the awareness of causal dynamics models achieves empowerment-driven exploration and optimizes its causal structure for task learning. Specifically, ECL operates by first training a causal dynamics model of the environment based on collected data. We then maximize empowerment under the causal structure for exploration, simultaneously using data gathered through exploration to update causal dynamics model to be more controllable than dense dynamics model without causal structure. In downstream task learning, an intrinsic curiosity reward is included to balance the causality, mitigating overfitting. Importantly, ECL is method-agnostic and is capable of integrating various causal discovery methods. We evaluate ECL combined with 3 causal discovery methods across 6 environments including pixel-based tasks, demonstrating its superior performance compared to other causal MBRL methods, in terms of causal discovery, sample efficiency, and asymptotic performance.         ",
    "url": "https://arxiv.org/abs/2502.10077",
    "authors": [
      "Hongye Cao",
      "Fan Feng",
      "Meng Fang",
      "Shaokang Dong",
      "Tianpei Yang",
      "Jing Huo",
      "Yang Gao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.10095",
    "title": "Representation Learning on Out of Distribution in Tabular Data",
    "abstract": "           The open-world assumption in model development suggests that a model might lack sufficient information to adequately handle data that is entirely distinct or out of distribution (OOD). While deep learning methods have shown promising results in handling OOD data through generalization techniques, they often require specialized hardware that may not be accessible to all users. We present TCL, a lightweight yet effective solution that operates efficiently on standard CPU hardware. Our approach adapts contrastive learning principles specifically for tabular data structures, incorporating full matrix augmentation and simplified loss calculation. Through comprehensive experiments across 10 diverse datasets, we demonstrate that TCL outperforms existing models, including FT-Transformer and ResNet, particularly in classification tasks, while maintaining competitive performance in regression problems. TCL achieves these results with significantly reduced computational requirements, making it accessible to users with limited hardware capabilities. This study also provides practical guidance for detecting and evaluating OOD data through straightforward experiments and visualizations. Our findings show that TCL offers a promising balance between performance and efficiency in handling OOD prediction tasks, which is particularly beneficial for general machine learning practitioners working with computational constraints.         ",
    "url": "https://arxiv.org/abs/2502.10095",
    "authors": [
      "Achmad Ginanjar",
      "Xue Li",
      "Priyanka Singh",
      "Wen Hua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.10097",
    "title": "Causal Information Prioritization for Efficient Reinforcement Learning",
    "abstract": "           Current Reinforcement Learning (RL) methods often suffer from sample-inefficiency, resulting from blind exploration strategies that neglect causal relationships among states, actions, and rewards. Although recent causal approaches aim to address this problem, they lack grounded modeling of reward-guided causal understanding of states and actions for goal-orientation, thus impairing learning efficiency. To tackle this issue, we propose a novel method named Causal Information Prioritization (CIP) that improves sample efficiency by leveraging factored MDPs to infer causal relationships between different dimensions of states and actions with respect to rewards, enabling the prioritization of causal information. Specifically, CIP identifies and leverages causal relationships between states and rewards to execute counterfactual data augmentation to prioritize high-impact state features under the causal understanding of the environments. Moreover, CIP integrates a causality-aware empowerment learning objective, which significantly enhances the agent's execution of reward-guided actions for more efficient exploration in complex environments. To fully assess the effectiveness of CIP, we conduct extensive experiments across 39 tasks in 5 diverse continuous control environments, encompassing both locomotion and manipulation skills learning with pixel-based and sparse reward settings. Experimental results demonstrate that CIP consistently outperforms existing RL methods across a wide range of scenarios.         ",
    "url": "https://arxiv.org/abs/2502.10097",
    "authors": [
      "Hongye Cao",
      "Fan Feng",
      "Tianpei Yang",
      "Jing Huo",
      "Yang Gao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.10108",
    "title": "NeuroXVocal: Detection and Explanation of Alzheimer's Disease through Non-invasive Analysis of Picture-prompted Speech",
    "abstract": "           The early diagnosis of Alzheimer's Disease (AD) through non invasive methods remains a significant healthcare challenge. We present NeuroXVocal, a novel dual-component system that not only classifies but also explains potential AD cases through speech analysis. The classification component (Neuro) processes three distinct data streams: acoustic features capturing speech patterns and voice characteristics, textual features extracted from speech transcriptions, and precomputed embeddings representing linguistic patterns. These streams are fused through a custom transformer-based architecture that enables robust cross-modal interactions. The explainability component (XVocal) implements a Retrieval-Augmented Generation (RAG) approach, leveraging Large Language Models combined with a domain-specific knowledge base of AD research literature. This architecture enables XVocal to retrieve relevant clinical studies and research findings to generate evidence-based context-sensitive explanations of the acoustic and linguistic markers identified in patient speech. Using the IS2021 ADReSSo Challenge benchmark dataset, our system achieved state-of-the-art performance with 95.77% accuracy in AD classification, significantly outperforming previous approaches. The explainability component was qualitatively evaluated using a structured questionnaire completed by medical professionals, validating its clinical relevance. NeuroXVocal's unique combination of high-accuracy classification and interpretable, literature-grounded explanations demonstrates its potential as a practical tool for supporting clinical AD diagnosis.         ",
    "url": "https://arxiv.org/abs/2502.10108",
    "authors": [
      "Nikolaos Ntampakis",
      "Konstantinos Diamantaras",
      "Ioanna Chouvarda",
      "Magda Tsolaki",
      "Vasileios Argyriou",
      "Panagiotis Sarigianndis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2502.10111",
    "title": "COMBINEX: A Unified Counterfactual Explainer for Graph Neural Networks via Node Feature and Structural Perturbations",
    "abstract": "           Counterfactual explanations have emerged as a powerful tool to unveil the opaque decision-making processes of graph neural networks (GNNs). However, existing techniques primarily focus on edge modifications, often overlooking the crucial role of node feature perturbations in shaping model predictions. To address this limitation, we propose COMBINEX, a novel GNN explainer that generates counterfactual explanations for both node and graph classification tasks. Unlike prior methods, which treat structural and feature-based changes independently, COMBINEX optimally balances modifications to edges and node features by jointly optimizing these perturbations. This unified approach ensures minimal yet effective changes required to flip a model's prediction, resulting in realistic and interpretable counterfactuals. Additionally, COMBINEX seamlessly handles both continuous and discrete node features, enhancing its versatility across diverse datasets and GNN architectures. Extensive experiments on real-world datasets and various GNN architectures demonstrate the effectiveness and robustness of our approach over existing baselines.         ",
    "url": "https://arxiv.org/abs/2502.10111",
    "authors": [
      "Flavio Giorgi",
      "Fabrizio Silvestri",
      "Gabriele Tolomei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.10118",
    "title": "Image Embedding Sampling Method for Diverse Captioning",
    "abstract": "           Image Captioning for state-of-the-art VLMs has significantly improved over time; however, this comes at the cost of increased computational complexity, making them less accessible for resource-constrained applications such as mobile devices and assistive technologies. Alternatively, smaller VLMs prioritize high-level scene descriptions, overlooking finer details that contribute to a richer understanding of an image. In this paper, we introduce a training-free framework that enhances caption diversity and informativeness by explicitly attending to distinct image regions using a comparably small VLM, BLIP, as the backbone. Our approach leverages structured segmentation to produce hierarchical representations that capture both global and localized semantics. Without requiring additional model training, we demonstrate that our method allows smaller VLMs to achieve performance comparable to larger models in terms of image-caption alignment, semantic integrity, and diversity. We evaluate our framework on MSCOCO, Flickr30k, and Nocaps test datasets, achieving a Div-2 score of 0.735, 0.750, and 0.748 for each dataset respectively, while maintaining strong image-caption relevancy and semantic integrity with the human-annotated captions.         ",
    "url": "https://arxiv.org/abs/2502.10118",
    "authors": [
      "Sania Waheed",
      "Na Min An"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2502.10122",
    "title": "Modern Hopfield Networks with Continuous-Time Memories",
    "abstract": "           Recent research has established a connection between modern Hopfield networks (HNs) and transformer attention heads, with guarantees of exponential storage capacity. However, these models still face challenges scaling storage efficiently. Inspired by psychological theories of continuous neural resource allocation in working memory, we propose an approach that compresses large discrete Hopfield memories into smaller, continuous-time memories. Leveraging continuous attention, our new energy function modifies the update rule of HNs, replacing the traditional softmax-based probability mass function with a probability density, over the continuous memory. This formulation aligns with modern perspectives on human executive function, offering a principled link between attractor dynamics in working memory and resource-efficient memory allocation. Our framework maintains competitive performance with HNs while leveraging a compressed memory, reducing computational costs across synthetic and video datasets.         ",
    "url": "https://arxiv.org/abs/2502.10122",
    "authors": [
      "Saul Santos",
      "Ant\u00f3nio Farinhas",
      "Daniel C. McNamee",
      "Andr\u00e9 F.T. Martins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.10127",
    "title": "Leveraging V2X for Collaborative HD Maps Construction Using Scene Graph Generation",
    "abstract": "           High-Definition (HD) maps play a crucial role in autonomous vehicle navigation, complementing onboard perception sensors for improved accuracy and safety. Traditional HD map generation relies on dedicated mapping vehicles, which are costly and fail to capture real-time infrastructure changes. This paper presents HDMapLaneNet, a novel framework leveraging V2X communication and Scene Graph Generation to collaboratively construct a localized geometric layer of HD maps. The approach extracts lane centerlines from front-facing camera images, represents them as graphs, and transmits the data for global aggregation to the cloud via V2X. Preliminary results on the nuScenes dataset demonstrate superior association prediction performance compared to a state-of-the-art method.         ",
    "url": "https://arxiv.org/abs/2502.10127",
    "authors": [
      "Gamal Elghazaly",
      "Raphael Frank"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2502.10157",
    "title": "SessionRec: Next Session Prediction Paradigm For Generative Sequential Recommendation",
    "abstract": "           We introduce SessionRec, a novel next-session prediction paradigm (NSPP) for generative sequential recommendation, addressing the fundamental misalignment between conventional next-item prediction paradigm (NIPP) and real-world recommendation scenarios. Unlike NIPP's item-level autoregressive generation that contradicts actual session-based user interactions, our framework introduces a session-aware representation learning through hierarchical sequence aggregation (intra/inter-session), reducing attention computation complexity while enabling implicit modeling of massive negative interactions, and a session-based prediction objective that better captures users' diverse interests through multi-item recommendation in next sessions. Moreover, we found that incorporating a rank loss for items within the session under the next session prediction paradigm can significantly improve the ranking effectiveness of generative sequence recommendation models. We also verified that SessionRec exhibits clear power-law scaling laws similar to those observed in LLMs. Extensive experiments conducted on public datasets and online A/B test in Meituan App demonstrate the effectiveness of SessionRec. The proposed paradigm establishes new foundations for developing industrial-scale generative recommendation systems through its model-agnostic architecture and computational efficiency.         ",
    "url": "https://arxiv.org/abs/2502.10157",
    "authors": [
      "Lei Huang",
      "Hao Guo",
      "Linzhi Peng",
      "Long Zhang",
      "Xiaoteng Wang",
      "Daoyuan Wang",
      "Shichao Wang",
      "Jinpeng Wang",
      "Lei Wang",
      "Sheng Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2502.10183",
    "title": "Doing More With Less: Towards More Data-Efficient Syndrome-Based Neural Decoders",
    "abstract": "           While significant research efforts have been directed toward developing more capable neural decoding architectures, comparatively little attention has been paid to the quality of training data. In this study, we address the challenge of constructing effective training datasets to maximize the potential of existing syndrome-based neural decoder architectures. We emphasize the advantages of using fixed datasets over generating training data dynamically and explore the problem of selecting appropriate training targets within this framework. Furthermore,we propose several heuristics for selecting training samples and present experimental evidence demonstrating that, with carefully curated datasets, it is possible to train neural decoders to achieve superior performance while requiring fewer training examples.         ",
    "url": "https://arxiv.org/abs/2502.10183",
    "authors": [
      "Ahmad Ismail",
      "Rapha\u00ebl Le Bidan",
      "Elsa Dupraz",
      "Charbel Abdel-Nour"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2502.10201",
    "title": "Prediction hubs are context-informed frequent tokens in LLMs",
    "abstract": "           Hubness, the tendency for few points to be among the nearest neighbours of a disproportionate number of other points, commonly arises when applying standard distance measures to high-dimensional data, often negatively impacting distance-based analysis. As autoregressive large language models (LLMs) operate on high-dimensional representations, we ask whether they are also affected by hubness. We first show, theoretically, that the only representation comparison operation performed by LLMs, namely that between context and unembedding vectors to determine continuation probabilities, is not characterized by the concentration of distances phenomenon that typically causes the appeareance of nuisance hubness. We then empirically show that this comparison still leads to a high degree of hubness, but the hubs in this case do not constitute a disturbance. They are rather the result of context-modulated frequent tokens often appearing in the pool of likely candidates for next token prediction. On the other hand, when other distance computations involving LLM representations are performed, we do not have the same theoretical guarantees, and, indeed, we see nuisance hubs appear. In summary, our work highlights, on the one hand, how hubness, while omnipresent in high-dimensional spaces, is not always a negative property that needs to be mitigated, and, on the other hand, it shows that various widely-used LLMs have developed a guessing strategy that consists in constantly assigning a high probability to frequent tokens.         ",
    "url": "https://arxiv.org/abs/2502.10201",
    "authors": [
      "Beatrix M. G. Nielsen",
      "Iuri Macocco",
      "Marco Baroni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2502.10208",
    "title": "SGS-GNN: A Supervised Graph Sparsification method for Graph Neural Networks",
    "abstract": "           We propose SGS-GNN, a novel supervised graph sparsifier that learns the sampling probability distribution of edges and samples sparse subgraphs of a user-specified size to reduce the computational costs required by GNNs for inference tasks on large graphs. SGS-GNN employs regularizers in the loss function to enhance homophily in sparse subgraphs, boosting the accuracy of GNNs on heterophilic graphs, where a significant number of the neighbors of a node have dissimilar labels. SGS-GNN also supports conditional updates of the probability distribution learning module based on a prior, which helps narrow the search space for sparse graphs. SGS-GNN requires fewer epochs to obtain high accuracies since it learns the search space of subgraphs more effectively than methods using fixed distributions such as random sampling. Extensive experiments using 33 homophilic and heterophilic graphs demonstrate the following: (i) with only 20% of edges retained in the sparse subgraphs, SGS-GNN improves the F1-scores by a geometric mean of 4% relative to the original graph; on heterophilic graphs, the prediction accuracy is better up to 30%. (ii) SGS-GNN outperforms state-of-the-art methods with improvement in F1-scores of 4-7% in geometric mean with similar sparsities in the sampled subgraphs, and (iii) compared to sparsifiers that employ fixed distributions, SGS-GNN requires about half the number of epochs to converge.         ",
    "url": "https://arxiv.org/abs/2502.10208",
    "authors": [
      "Siddhartha Shankar Das",
      "Naheed Anjum Arafat",
      "Muftiqur Rahman",
      "S M Ferdous",
      "Alex Pothen",
      "Mahantesh M Halappanavar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.10211",
    "title": "Control-flow anomaly detection by process mining-based feature extraction and dimensionality reduction",
    "abstract": "           The business processes of organizations may deviate from normal control flow due to disruptive anomalies, including unknown, skipped, and wrongly-ordered activities. To identify these control-flow anomalies, process mining can check control-flow correctness against a reference process model through conformance checking, an explainable set of algorithms that allows linking any deviations with model elements. However, the effectiveness of conformance checking-based techniques is negatively affected by noisy event data and low-quality process models. To address these shortcomings and support the development of competitive and explainable conformance checking-based techniques for control-flow anomaly detection, we propose a novel process mining-based feature extraction approach with alignment-based conformance checking. This variant aligns the deviating control flow with a reference process model; the resulting alignment can be inspected to extract additional statistics such as the number of times a given activity caused mismatches. We integrate this approach into a flexible and explainable framework for developing techniques for control-flow anomaly detection. The framework combines process mining-based feature extraction and dimensionality reduction to handle high-dimensional feature sets, achieve detection effectiveness, and support explainability. The results show that the framework techniques implementing our approach outperform the baseline conformance checking-based techniques while maintaining the explainable nature of conformance checking. We also provide an explanation of why existing conformance checking-based techniques may be ineffective.         ",
    "url": "https://arxiv.org/abs/2502.10211",
    "authors": [
      "Francesco Vitale",
      "Marco Pegoraro",
      "Wil M. P. van der Aalst",
      "Nicola Mazzocca"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.10216",
    "title": "Forget the Data and Fine-Tuning! Just Fold the Network to Compress",
    "abstract": "           We introduce model folding, a novel data-free model compression technique that merges structurally similar neurons across layers, significantly reducing the model size without the need for fine-tuning or access to training data. Unlike existing methods, model folding preserves data statistics during compression by leveraging k-means clustering, and using novel data-free techniques to prevent variance collapse or explosion. Our theoretical framework and experiments across standard benchmarks, including ResNet18 and LLaMA-7B, demonstrate that model folding achieves comparable performance to data-driven compression techniques and outperforms recently proposed data-free methods, especially at high sparsity levels. This approach is particularly effective for compressing large-scale models, making it suitable for deployment in resource-constrained environments.         ",
    "url": "https://arxiv.org/abs/2502.10216",
    "authors": [
      "Dong Wang",
      "Haris \u0160iki\u0107",
      "Lothar Thiele",
      "Olga Saukh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2502.10224",
    "title": "Comparison of Deep Recurrent Neural Networks and Bayesian Neural Networks for Detecting Electric Motor Damage Through Sound Signal Analysis",
    "abstract": "           Fault detection in electric motors is a critical challenge in various industries, where failures can result in significant operational disruptions. This study investigates the use of Recurrent Neural Networks (RNNs) and Bayesian Neural Networks (BNNs) for diagnosing motor damage using acoustic signal analysis. A novel approach is proposed, leveraging frequency domain representation of sound signals for enhanced diagnostic accuracy. The architectures of both RNNs and BNNs are designed and evaluated on real-world acoustic data collected from household appliances using smartphones. Experimental results demonstrate that BNNs provide superior fault detection performance, particularly for imbalanced datasets, offering more robust and interpretable predictions compared to traditional methods. The findings suggest that BNNs, with their ability to incorporate uncertainty, are well-suited for industrial diagnostic applications. Further analysis and benchmarks are suggested to explore resource efficiency and classification capabilities of these architectures.         ",
    "url": "https://arxiv.org/abs/2502.10224",
    "authors": [
      "Waldemar Bauer",
      "Jerzy Baranowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.10283",
    "title": "Anomaly Detection with LWE Encrypted Control",
    "abstract": "           Detecting attacks using encrypted signals is challenging since encryption hides its information content. We present a novel mechanism for anomaly detection over Learning with Errors (LWE) encrypted signals without using decryption, secure channels, nor complex communication schemes. Instead, the detector exploits the homomorphic property of LWE encryption to perform hypothesis tests on transformations of the encrypted samples. The specific transformations are determined by solutions to a hard lattice-based minimization problem. While the test's sensitivity deteriorates with suboptimal solutions, similar to the exponential deterioration of the (related) test that breaks the cryptosystem, we show that the deterioration is polynomial for our test. This rate gap can be exploited to pick parameters that lead to somewhat weaker encryption but large gains in detection capability. Finally, we conclude the paper by presenting a numerical example that simulates anomaly detection, demonstrating the effectiveness of our method in identifying attacks.         ",
    "url": "https://arxiv.org/abs/2502.10283",
    "authors": [
      "Rijad Alisic",
      "Junsoo Kim",
      "Henrik Sandberg"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2502.10288",
    "title": "Adversarial Mixup Unlearning",
    "abstract": "           Machine unlearning is a critical area of research aimed at safeguarding data privacy by enabling the removal of sensitive information from machine learning models. One unique challenge in this field is catastrophic unlearning, where erasing specific data from a well-trained model unintentionally removes essential knowledge, causing the model to deviate significantly from a retrained one. To address this, we introduce a novel approach that regularizes the unlearning process by utilizing synthesized mixup samples, which simulate the data susceptible to catastrophic effects. At the core of our approach is a generator-unlearner framework, MixUnlearn, where a generator adversarially produces challenging mixup examples, and the unlearner effectively forgets target information based on these synthesized data. Specifically, we first introduce a novel contrastive objective to train the generator in an adversarial direction: generating examples that prompt the unlearner to reveal information that should be forgotten, while losing essential knowledge. Then the unlearner, guided by two other contrastive loss terms, processes the synthesized and real data jointly to ensure accurate unlearning without losing critical knowledge, overcoming catastrophic effects. Extensive evaluations across benchmark datasets demonstrate that our method significantly outperforms state-of-the-art approaches, offering a robust solution to machine unlearning. This work not only deepens understanding of unlearning mechanisms but also lays the foundation for effective machine unlearning with mixup augmentation.         ",
    "url": "https://arxiv.org/abs/2502.10288",
    "authors": [
      "Zhuoyi Peng",
      "Yixuan Tang",
      "Yi Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.10307",
    "title": "SPIRIT: Short-term Prediction of solar IRradIance for zero-shot Transfer learning using Foundation Models",
    "abstract": "           Traditional solar forecasting models are based on several years of site-specific historical irradiance data, often spanning five or more years, which are unavailable for newer photovoltaic farms. As renewable energy is highly intermittent, building accurate solar irradiance forecasting systems is essential for efficient grid management and enabling the ongoing proliferation of solar energy, which is crucial to achieve the United Nations' net zero goals. In this work, we propose SPIRIT, a novel approach leveraging foundation models for solar irradiance forecasting, making it applicable to newer solar installations. Our approach outperforms state-of-the-art models in zero-shot transfer learning by about 70%, enabling effective performance at new locations without relying on any historical data. Further improvements in performance are achieved through fine-tuning, as more location-specific data becomes available. These findings are supported by statistical significance, further validating our approach. SPIRIT represents a pivotal step towards rapid, scalable, and adaptable solar forecasting solutions, advancing the integration of renewable energy into global power systems.         ",
    "url": "https://arxiv.org/abs/2502.10307",
    "authors": [
      "Aditya Mishra",
      "Ravindra T",
      "Srinivasan Iyengar",
      "Shivkumar Kalyanaraman",
      "Ponnurangam Kumaraguru"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2502.10310",
    "title": "Object Detection and Tracking",
    "abstract": "           Efficient and accurate object detection is an important topic in the development of computer vision systems. With the advent of deep learning techniques, the accuracy of object detection has increased significantly. The project aims to integrate a modern technique for object detection with the aim of achieving high accuracy with real-time performance. The reliance on other computer vision algorithms in many object identification systems, which results in poor and ineffective performance, is a significant obstacle. In this research, we solve the end-to-end object detection problem entirely using deep learning techniques. The network is trained using the most difficult publicly available dataset, which is used for an annual item detection challenge. Applications that need object detection can benefit the system's quick and precise finding.         ",
    "url": "https://arxiv.org/abs/2502.10310",
    "authors": [
      "Md Pranto",
      "Omar Faruk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2502.10324",
    "title": "Analysis and Prediction of Coverage and Channel Rank for UAV Networks in Rural Scenarios with Foliage",
    "abstract": "           Unmanned aerial vehicles (UAVs) are expected to play a key role in 6G-enabled vehicular-to-everything (V2X) communications requiring high data rates, low latency, and reliable connectivity for mission-critical applications. Multi-input multi-output (MIMO) technology is essential for meeting these demands. However, UAV link performance is significantly affected by environmental factors such as signal attenuation, multipath propagation, and blockage from obstacles, particularly dense foliage in rural areas. In this paper, we investigate RF coverage and channel rank over UAV channels in foliage-dominated rural environments using ray tracing (RT) simulations. We conduct RT-based channel rank and RF coverage analysis over Lake Wheeler Field Labs at NC State University to examine the impact on UAV links. Custom-modeled trees are integrated into the RT simulations using NVIDIA Sionna, Blender, and Open Street Map (OSM) database to capture realistic blockage effects. Results indicate that tree-induced blockage impacts RF coverage and channel rank at lower UAV altitudes. We also propose a Kriging interpolation-based 3D channel rank interpolation scheme, leveraging the observed spatial correlation of channel rank in the given environments. The accuracy of the proposed scheme is evaluated using the mean absolute error (MAE) metric and compared against baseline interpolation methods. Finally, we compare the RT-based received signal strength (RSS) and channel rank results with real-world measurements from the NSF AERPAW testbed demonstrating reasonable consistency between simulation results and the measurements.         ",
    "url": "https://arxiv.org/abs/2502.10324",
    "authors": [
      "Donggu Lee",
      "Ozgur Ozdemir",
      "Asokan Ram",
      "Ismail Guvenc"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2502.10329",
    "title": "VocalCrypt: Novel Active Defense Against Deepfake Voice Based on Masking Effect",
    "abstract": "           The rapid advancements in AI voice cloning, fueled by machine learning, have significantly impacted text-to-speech (TTS) and voice conversion (VC) fields. While these developments have led to notable progress, they have also raised concerns about the misuse of AI VC technology, causing economic losses and negative public perceptions. To address this challenge, this study focuses on creating active defense mechanisms against AI VC systems. We propose a novel active defense method, VocalCrypt, which embeds pseudo-timbre (jamming information) based on SFS into audio segments that are imperceptible to the human ear, thereby forming systematic fragments to prevent voice cloning. This approach protects the voice without compromising its quality. In comparison to existing methods, such as adversarial noise incorporation, VocalCrypt significantly enhances robustness and real-time performance, achieving a 500\\% increase in generation speed while maintaining interference effectiveness. Unlike audio watermarking techniques, which focus on post-detection, our method offers preemptive defense, reducing implementation costs and enhancing feasibility. Extensive experiments using the Zhvoice and VCTK Corpus datasets show that our AI-cloned speech defense system performs excellently in automatic speaker verification (ASV) tests while preserving the integrity of the protected audio.         ",
    "url": "https://arxiv.org/abs/2502.10329",
    "authors": [
      "Qingyuan Fei",
      "Wenjie Hou",
      "Xuan Hai",
      "Xin Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2502.10330",
    "title": "DiOpt: Self-supervised Diffusion for Constrained Optimization",
    "abstract": "           Recent advances in diffusion models show promising potential for learning-based optimization by leveraging their multimodal sampling capability to escape local optima. However, existing diffusion-based optimization approaches, often reliant on supervised training, lacks a mechanism to ensure strict constraint satisfaction which is often required in real-world applications. One resulting observation is the distributional misalignment, i.e. the generated solution distribution often exhibits small overlap with the feasible domain. In this paper, we propose DiOpt, a novel diffusion paradigm that systematically learns near-optimal feasible solution distributions through iterative self-training. Our framework introduces several key innovations: a target distribution specifically designed to maximize overlap with the constrained solution manifold; a bootstrapped self-training mechanism that adaptively weights candidate solutions based on the severity of constraint violations and optimality gaps; and a dynamic memory buffer that accelerates convergence by retaining high-quality solutions over training iterations. To our knowledge, DiOpt represents the first successful integration of self-supervised diffusion with hard constraint satisfaction. Evaluations on diverse tasks, including power grid control, motion retargeting, wireless allocation demonstrate its superiority in terms of both optimality and constraint satisfaction.         ",
    "url": "https://arxiv.org/abs/2502.10330",
    "authors": [
      "Shutong Ding",
      "Yimiao Zhou",
      "Ke Hu",
      "Xi Yao",
      "Junchi Yan",
      "Xiaoying Tang",
      "Ye Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.10334",
    "title": "Ocular Disease Classification Using CNN with Deep Convolutional Generative Adversarial Network",
    "abstract": "           The Convolutional Neural Network (CNN) has shown impressive performance in image classification because of its strong learning capabilities. However, it demands a substantial and balanced dataset for effective training. Otherwise, networks frequently exhibit over fitting and struggle to generalize to new examples. Publicly available dataset of fundus images of ocular disease is insufficient to train any classification model to achieve satisfactory accuracy. So, we propose Generative Adversarial Network(GAN) based data generation technique to synthesize dataset for training CNN based classification model and later use original disease containing ocular images to test the model. During testing the model classification accuracy with the original ocular image, the model achieves an accuracy rate of 78.6% for myopia, 88.6% for glaucoma, and 84.6% for cataract, with an overall classification accuracy of 84.6%.         ",
    "url": "https://arxiv.org/abs/2502.10334",
    "authors": [
      "Arun Kunwar",
      "Dibakar Raj Pant",
      "Jukka Heikkonen",
      "Rajeev Kanth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2502.10348",
    "title": "On Incremental Approximate Shortest Paths in Directed Graphs",
    "abstract": "           In this paper, we show new data structures maintaining approximate shortest paths in sparse directed graphs with polynomially bounded non-negative edge weights under edge insertions. We give more efficient incremental $(1+\\epsilon)$-approximate APSP data structures that work against an adaptive adversary: a deterministic one with $\\tilde{O}(m^{3/2}n^{3/4})$ total update time and a randomized one with $\\tilde{O}(m^{4/3}n^{5/6})$ total update time. For sparse graphs, these both improve polynomially upon the best-known bound against an adaptive adversary. To achieve that, building on the ideas of [Chechik-Zhang, SODA'21] and [Kyng-Meierhans-Probst Gutenberg, SODA'22], we show a near-optimal $(1+\\epsilon)$-approximate incremental SSSP data structure for a special case when all edge updates are adjacent to the source, that might be of independent interest. We also describe a very simple and near-optimal \\emph{offline} incremental $(1+\\epsilon)$-approximate SSSP data structure. While online near-linear partially dynamic SSSP data structures have been elusive so far (except for dense instances), our result excludes using certain types of impossibility arguments to rule them out. Additionally, our offline solution leads to near-optimal and deterministic all-pairs bounded-leg shortest paths data structure for sparse graphs.         ",
    "url": "https://arxiv.org/abs/2502.10348",
    "authors": [
      "Adam G\u00f3rkiewicz",
      "Adam Karczmarz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2502.10374",
    "title": "Robustness tests for biomedical foundation models should tailor to specification",
    "abstract": "           Existing regulatory frameworks for biomedical AI include robustness as a key component but lack detailed implementational guidance. The recent rise of biomedical foundation models creates new hurdles in testing and certification given their broad capabilities and susceptibility to complex distribution shifts. To balance test feasibility and effectiveness, we suggest a priority-based, task-oriented approach to tailor robustness evaluation objectives to a predefined specification. We urge concrete policies to adopt a granular categorization of robustness concepts in the specification. Our approach promotes the standardization of risk assessment and monitoring, which guides technical developments and mitigation efforts.         ",
    "url": "https://arxiv.org/abs/2502.10374",
    "authors": [
      "R. Patrick Xian",
      "Noah R. Baker",
      "Tom David",
      "Qiming Cui",
      "A. Jay Holmgren",
      "Stefan Bauer",
      "Madhumita Sushil",
      "Reza Abbasi-Asl"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2502.10378",
    "title": "Unknown Word Detection for English as a Second Language (ESL) Learners Using Gaze and Pre-trained Language Models",
    "abstract": "           English as a Second Language (ESL) learners often encounter unknown words that hinder their text comprehension. Automatically detecting these words as users read can enable computing systems to provide just-in-time definitions, synonyms, or contextual explanations, thereby helping users learn vocabulary in a natural and seamless manner. This paper presents EyeLingo, a transformer-based machine learning method that predicts the probability of unknown words based on text content and eye gaze trajectory in real time with high accuracy. A 20-participant user study revealed that our method can achieve an accuracy of 97.6%, and an F1-score of 71.1%. We implemented a real-time reading assistance prototype to show the effectiveness of EyeLingo. The user study shows improvement in willingness to use and usefulness compared to baseline methods.         ",
    "url": "https://arxiv.org/abs/2502.10378",
    "authors": [
      "Jiexin Ding",
      "Bowen Zhao",
      "Yuntao Wang",
      "Xinyun Liu",
      "Rui Hao",
      "Ishan Chatterjee",
      "Yuanchun Shi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2502.10383",
    "title": "Representation and Interpretation in Artificial and Natural Computing",
    "abstract": "           Artificial computing machinery transforms representations through an objective process, to be interpreted subjectively by humans, so the machine and the interpreter are different entities, but in the putative natural computing both processes are performed by the same agent. The method or process that transforms a representation is called here \\emph{the mode of computing}. The mode used by digital computers is the algorithmic one, but there are others, such as quantum computers and diverse forms of non-conventional computing, and there is an open-ended set of representational formats and modes that could be used in artificial and natural computing. A mode based on a notion of computing different from Turing's may perform feats beyond what the Turing Machine does but the modes would not be of the same kind and could not be compared. For a mode of computing to be more powerful than the algorithmic one, it ought to compute functions lacking an effective algorithm, and Church Thesis would not hold. Here, a thought experiment including a computational demon using a hypothetical mode for such an effect is presented. If there is natural computing, there is a mode of natural computing whose properties may be causal to the phenomenological experience. Discovering it would come with solving the hard problem of consciousness; but if it turns out that such a mode does not exist, there is no such thing as natural computing, and the mind is not a computational process.         ",
    "url": "https://arxiv.org/abs/2502.10383",
    "authors": [
      "Luis A. Pineda"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2502.10388",
    "title": "Aspect-Oriented Summarization for Psychiatric Short-Term Readmission Prediction",
    "abstract": "           Recent progress in large language models (LLMs) has enabled the automated processing of lengthy documents even without supervised training on a task-specific dataset. Yet, their zero-shot performance in complex tasks as opposed to straightforward information extraction tasks remains suboptimal. One feasible approach for tasks with lengthy, complex input is to first summarize the document and then apply supervised fine-tuning to the summary. However, the summarization process inevitably results in some loss of information. In this study we present a method for processing the summaries of long documents aimed to capture different important aspects of the original document. We hypothesize that LLM summaries generated with different aspect-oriented prompts contain different \\textit{information signals}, and we propose methods to measure these differences. We introduce approaches to effectively integrate signals from these different summaries for supervised training of transformer models. We validate our hypotheses on a high-impact task -- 30-day readmission prediction from a psychiatric discharge -- using real-world data from four hospitals, and show that our proposed method increases the prediction performance for the complex task of predicting patient outcome.         ",
    "url": "https://arxiv.org/abs/2502.10388",
    "authors": [
      "WonJin Yoon",
      "Boyu Ren",
      "Spencer Thomas",
      "Chanwhi Kim",
      "Guergana Savova",
      "Mei-Hua Hall",
      "Timothy Miller"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2502.09626",
    "title": "On the Bias, Fairness, and Bias Mitigation for a Wearable-based Freezing of Gait Detection in Parkinson's Disease",
    "abstract": "           Freezing of gait (FOG) is a debilitating feature of Parkinson's disease (PD), which is a cause of injurious falls among PD patients. Recent advances in wearable-based human activity recognition (HAR) technology have enabled the detection of FOG subtypes across benchmark datasets. Since FOG manifestation is heterogeneous, developing models that quantify FOG consistently across patients with varying demographics, FOG types, and PD conditions is important. Bias and fairness in FOG models remain understudied in HAR, with research focused mainly on FOG detection using single benchmark datasets. We evaluated the bias and fairness of HAR models for wearable-based FOG detection across demographics and PD conditions using multiple datasets and the effectiveness of transfer learning as a potential bias mitigation approach. Our evaluation using demographic parity ratio (DPR) and equalized odds ratio (EOR) showed model bias (DPR & EOR < 0.8) for all stratified demographic variables, including age, sex, and disease duration. Our experiments demonstrated that transfer learning from multi-site datasets and generic human activity representations significantly improved fairness (average change in DPR +0.027, +0.039, respectively) and performance (average change in F1-score +0.026, +0.018, respectively) across attributes, supporting the hypothesis that generic human activity representations learn fairer representations applicable to health analytics.         ",
    "url": "https://arxiv.org/abs/2502.09626",
    "authors": [
      "Timothy Odonga",
      "Christine D. Esper",
      "Stewart A. Factor",
      "J. Lucas McKay",
      "Hyeokhyen Kwon"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.09631",
    "title": "Volumetric Temporal Texture Synthesis for Smoke Stylization using Neural Cellular Automata",
    "abstract": "           Artistic stylization of 3D volumetric smoke data is still a challenge in computer graphics due to the difficulty of ensuring spatiotemporal consistency given a reference style image, and that within reasonable time and computational resources. In this work, we introduce Volumetric Neural Cellular Automata (VNCA), a novel model for efficient volumetric style transfer that synthesizes, in real-time, multi-view consistent stylizing features on the target smoke with temporally coherent transitions between stylized simulation frames. VNCA synthesizes a 3D texture volume with color and density stylization and dynamically aligns this volume with the intricate motion patterns of the smoke simulation under the Eulerian framework. Our approach replaces the explicit fluid advection modeling and the inter-frame smoothing terms with the self-emerging motion of the underlying cellular automaton, thus reducing the training time by over an order of magnitude. Beyond smoke simulations, we demonstrate the versatility of our approach by showcasing its applicability to mesh stylization.         ",
    "url": "https://arxiv.org/abs/2502.09631",
    "authors": [
      "Dongqing Wang",
      "Ehsan Pajouheshgar",
      "Yitao Xu",
      "Tong Zhang",
      "Sabine S\u00fcsstrunk"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2502.09654",
    "title": "Heterogeneous Mixture of Experts for Remote Sensing Image Super-Resolution",
    "abstract": "           Remote sensing image super-resolution (SR) aims to reconstruct high-resolution remote sensing images from low-resolution inputs, thereby addressing limitations imposed by sensors and imaging conditions. However, the inherent characteristics of remote sensing images, including diverse ground object types and complex details, pose significant challenges to achieving high-quality reconstruction. Existing methods typically employ a uniform structure to process various types of ground objects without distinction, making it difficult to adapt to the complex characteristics of remote sensing images. To address this issue, we introduce a Mixture of Experts (MoE) model and design a set of heterogeneous experts. These experts are organized into multiple expert groups, where experts within each group are homogeneous while being heterogeneous across groups. This design ensures that specialized activation parameters can be employed to handle the diverse and intricate details of ground objects effectively. To better accommodate the heterogeneous experts, we propose a multi-level feature aggregation strategy to guide the routing process. Additionally, we develop a dual-routing mechanism to adaptively select the optimal expert for each pixel. Experiments conducted on the UCMerced and AID datasets demonstrate that our proposed method achieves superior SR reconstruction accuracy compared to state-of-the-art methods. The code will be available at this https URL.         ",
    "url": "https://arxiv.org/abs/2502.09654",
    "authors": [
      "Bowen Chen",
      "Keyan Chen",
      "Mohan Yang",
      "Zhengxia Zou",
      "Zhenwei Shi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2502.09656",
    "title": "Multi-Omics Fusion with Soft Labeling for Enhanced Prediction of Distant Metastasis in Nasopharyngeal Carcinoma Patients after Radiotherapy",
    "abstract": "           Omics fusion has emerged as a crucial preprocessing approach in the field of medical image processing, providing significant assistance to several studies. One of the challenges encountered in the integration of omics data is the presence of unpredictability arising from disparities in data sources and medical imaging equipment. In order to overcome this challenge and facilitate the integration of their joint application to specific medical objectives, this study aims to develop a fusion methodology that mitigates the disparities inherent in omics data. The utilization of the multi-kernel late-fusion method has gained significant popularity as an effective strategy for addressing this particular challenge. An efficient representation of the data may be achieved by utilizing a suitable single-kernel function to map the inherent features and afterward merging them in a space with a high number of dimensions. This approach effectively addresses the differences noted before. The inflexibility of label fitting poses a constraint on the use of multi-kernel late-fusion methods in complex nasopharyngeal carcinoma (NPC) datasets, hence affecting the efficacy of general classifiers in dealing with high-dimensional characteristics. This innovative methodology aims to increase the disparity between the two cohorts, hence providing a more flexible structure for the allocation of labels. The examination of the NPC-ContraParotid dataset demonstrates the model's robustness and efficacy, indicating its potential as a valuable tool for predicting distant metastases in patients with nasopharyngeal carcinoma (NPC).         ",
    "url": "https://arxiv.org/abs/2502.09656",
    "authors": [
      "Jiabao Sheng",
      "SaiKit Lam",
      "Jiang Zhang",
      "Yuanpeng Zhang",
      "Jing Cai"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2502.09832",
    "title": "Algorithmic contiguity from low-degree conjecture and applications in correlated random graphs",
    "abstract": "           In this paper, assuming a natural strengthening of the low-degree conjecture, we provide evidence of computational hardness for two problems: (1) the (partial) matching recovery problem in the sparse correlated Erd\u0151s-R\u00e9nyi graphs $\\mathcal G(n,q;\\rho)$ when the edge-density $q=n^{-1+o(1)}$ and the correlation $\\rho<\\sqrt{\\alpha}$ lies below the Otter's threshold, solving a remaining problem in \\cite{DDL23+}; (2) the detection problem between the correlated sparse stochastic block model $\\mathcal S(n,\\tfrac{\\lambda}{n};k,\\epsilon;s)$ and a pair of independent stochastic block models $\\mathcal S(n,\\tfrac{\\lambda s}{n};k,\\epsilon)$ when $\\epsilon^2 \\lambda s<1$ lies below the Kesten-Stigum (KS) threshold and $s<\\sqrt{\\alpha}$ lies below the Otter's threshold, solving a remaining problem in \\cite{CDGL24+}. One of the main ingredient in our proof is to derive certain forms of \\emph{algorithmic contiguity} between two probability measures based on bounds on their low-degree advantage. To be more precise, consider the high-dimensional hypothesis testing problem between two probability measures $\\mathbb{P}$ and $\\mathbb{Q}$ based on the sample $\\mathsf Y$. We show that if the low-degree advantage $\\mathsf{Adv}_{\\leq D} \\big( \\frac{\\mathrm{d}\\mathbb{P}}{\\mathrm{d}\\mathbb{Q}} \\big)=O(1)$, then (assuming the low-degree conjecture) there is no efficient algorithm $\\mathcal A$ such that $\\mathbb{Q}(\\mathcal A(\\mathsf Y)=0)=1-o(1)$ and $\\mathbb{P}(\\mathcal A(\\mathsf Y)=1)=\\Omega(1)$. This framework provides a useful tool for performing reductions between different inference tasks.         ",
    "url": "https://arxiv.org/abs/2502.09832",
    "authors": [
      "Zhangsong Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2502.10161",
    "title": "Revisiting the Berkeley Admissions data: Statistical Tests for Causal Hypotheses",
    "abstract": "           Reasoning about fairness through correlation-based notions is rife with pitfalls. The 1973 University of California, Berkeley graduate school admissions case from Bickel et. al. (1975) is a classic example of one such pitfall, namely Simpson's paradox. The discrepancy in admission rates among males and female applicants, in the aggregate data over all departments, vanishes when admission rates per department are examined. We reason about the Berkeley graduate school admissions case through a causal lens. In the process, we introduce a statistical test for causal hypothesis testing based on Pearl's instrumental-variable inequalities (Pearl 1995). We compare different causal notions of fairness that are based on graphical, counterfactual and interventional queries on the causal model, and develop statistical tests for these notions that use only observational data. We study the logical relations between notions, and show that while notions may not be equivalent, their corresponding statistical tests coincide for the case at hand. We believe that a thorough case-based causal analysis helps develop a more principled understanding of both causal hypothesis testing and fairness.         ",
    "url": "https://arxiv.org/abs/2502.10161",
    "authors": [
      "Sourbh Bhadane",
      "Joris M. Mooij",
      "Philip Boeken",
      "Onno Zoeter"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Computers and Society (cs.CY)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2502.10163",
    "title": "Enhancing anomaly detection with topology-aware autoencoders",
    "abstract": "           Anomaly detection in high-energy physics is essential for identifying new physics beyond the Standard Model. Autoencoders provide a signal-agnostic approach but are limited by the topology of their latent space. This work explores topology-aware autoencoders, embedding phase-space distributions onto compact manifolds that reflect energy-momentum conservation. We construct autoencoders with spherical ($S^n$), product ($S^2 \\otimes S^2$), and projective ($\\mathbb{RP}^2$) latent spaces and compare their anomaly detection performance against conventional Euclidean embeddings. Our results show that autoencoders with topological priors significantly improve anomaly separation by preserving the global structure of the data manifold and reducing spurious reconstruction errors. Applying our approach to simulated hadronic top-quark decays, we show that latent spaces with appropriate topological constraints enhance sensitivity and robustness in detecting anomalous events. This study establishes topology-aware autoencoders as a powerful tool for unsupervised searches for new physics in particle-collision data.         ",
    "url": "https://arxiv.org/abs/2502.10163",
    "authors": [
      "Vishal S. Ngairangbam",
      "B\u0142a\u017cej Rozwoda",
      "Kazuki Sakurai",
      "Michael Spannowsky"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2502.10213",
    "title": "Network fault costs based on minimum leaf spanning trees",
    "abstract": "           We study the fault-tolerance of networks from both the structural and computational point of view using the minimum leaf number of the corresponding graph $G$, i.e. the minimum number of leaves of the spanning trees of $G$, and its vertex-deleted subgraphs. We investigate networks that are leaf-guaranteed, i.e. which satisfy a certain stability condition with respect to minimum leaf numbers and vertex-deletion. Next to this, our main notion is the so-called fault cost, which is based on the number of vertices that have different degrees in minimum leaf spanning trees of the network and its vertex-deleted subgraphs. We characterise networks with vanishing fault cost via leaf-guaranteed graphs and describe, for any given network $N$, leaf-guaranteed networks containing $N$. We determine for all non-negative integers $k \\le 8$ except $1$ the smallest network with fault cost $k$. We also give a detailed treatment of the fault cost $1$ case, prove that there are infinitely many $3$-regular networks with fault cost $3$, and show that for any non-negative integer $k$ there exists a network with fault cost exactly $k$.         ",
    "url": "https://arxiv.org/abs/2502.10213",
    "authors": [
      "Jan Goedgebeur",
      "Jarne Renders",
      "G\u00e1bor Wiener",
      "Carol T. Zamfirescu"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2212.02895",
    "title": "Training Neural Networks on Data Sources with Unknown Reliability",
    "abstract": "           When data is generated by multiple sources, conventional training methods update models assuming equal reliability for each source and do not consider their individual data quality. However, in many applications, sources have varied levels of reliability that can have negative effects on the performance of a neural network. A key issue is that often the quality of the data for individual sources is not known during training. Previous methods for training models in the presence of noisy data do not make use of the additional information that the source label can provide. Focusing on supervised learning, we aim to train neural networks on each data source for a number of steps proportional to the source's estimated reliability by using a dynamic re-weighting strategy motivated by likelihood tempering. This way, we allow training on all sources during the warm-up and reduce learning on less reliable sources during the final training stages, when it has been shown that models overfit to noise. We show through diverse experiments that this can significantly improve model performance when trained on mixtures of reliable and unreliable data sources, and maintain performance when models are trained on reliable sources only.         ",
    "url": "https://arxiv.org/abs/2212.02895",
    "authors": [
      "Alexander Capstick",
      "Francesca Palermo",
      "Tianyu Cui",
      "Payam Barnaghi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.01581",
    "title": "Learning to Decouple Complex Systems",
    "abstract": "           A complex system with cluttered observations may be a coupled mixture of multiple simple sub-systems corresponding to latent entities. Such sub-systems may hold distinct dynamics in the continuous-time domain; therein, complicated interactions between sub-systems also evolve over time. This setting is fairly common in the real world but has been less considered. In this paper, we propose a sequential learning approach under this setting by decoupling a complex system for handling irregularly sampled and cluttered sequential observations. Such decoupling brings about not only subsystems describing the dynamics of each latent entity but also a meta-system capturing the interaction between entities over time. Specifically, we argue that the meta-system evolving within a simplex is governed by projected differential equations (ProjDEs). We further analyze and provide neural-friendly projection operators in the context of Bregman divergence. Experimental results on synthetic and real-world datasets show the advantages of our approach when facing complex and cluttered sequential data compared to the state-of-the-art.         ",
    "url": "https://arxiv.org/abs/2302.01581",
    "authors": [
      "Zihan Zhou",
      "Tianshu Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.02833",
    "title": "Applying Process Mining on Scientific Workflows: a Case Study on High Performance Computing Data",
    "abstract": "           Computer-based scientific experiments are becoming increasingly data-intensive, necessitating the use of High-Performance Computing (HPC) clusters to handle large scientific workflows. These workflows result in complex data and control flows within the system, making analysis challenging. This paper focuses on the extraction of case IDs from SLURM-based HPC cluster logs, a crucial step for applying mainstream process mining techniques. The core contribution is the development of methods to correlate jobs in the system, whether their interdependencies are explicitly specified or not. We present our log extraction and correlation techniques, supported by experiments that validate our approach, enabling comprehensive documentation of workflows and identification of performance bottlenecks.         ",
    "url": "https://arxiv.org/abs/2307.02833",
    "authors": [
      "Zahra Sadeghibogar",
      "Alessandro Berti",
      "Marco Pegoraro",
      "Wil M.P. van der Aalst"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2310.11573",
    "title": "A polynomial bound on the number of minimal separators and potential maximal cliques in $P_6$-free graphs of bounded clique number",
    "abstract": "           In this note we show a polynomial bound on the number of minimal separators and potential maximal cliques in $P_6$-free graphs of bounded clique number.         ",
    "url": "https://arxiv.org/abs/2310.11573",
    "authors": [
      "Marcin Pilipczuk",
      "Pawe\u0142 Rz\u0105\u017cewski"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2311.02076",
    "title": "Universal Sharpness Dynamics in Neural Network Training: Fixed Point Analysis, Edge of Stability, and Route to Chaos",
    "abstract": "           In gradient descent dynamics of neural networks, the top eigenvalue of the loss Hessian (sharpness) displays a variety of robust phenomena throughout training. This includes early time regimes where the sharpness may decrease during early periods of training (sharpness reduction), and later time behavior such as progressive sharpening and edge of stability. We demonstrate that a simple $2$-layer linear network (UV model) trained on a single training example exhibits all of the essential sharpness phenomenology observed in real-world scenarios. By analyzing the structure of dynamical fixed points in function space and the vector field of function updates, we uncover the underlying mechanisms behind these sharpness trends. Our analysis reveals (i) the mechanism behind early sharpness reduction and progressive sharpening, (ii) the required conditions for edge of stability, (iii) the crucial role of initialization and parameterization, and (iv) a period-doubling route to chaos on the edge of stability manifold as learning rate is increased. Finally, we demonstrate that various predictions from this simplified model generalize to real-world scenarios and discuss its limitations.         ",
    "url": "https://arxiv.org/abs/2311.02076",
    "authors": [
      "Dayal Singh Kalra",
      "Tianyu He",
      "Maissam Barkeshli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Chaotic Dynamics (nlin.CD)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2312.01001",
    "title": "Learning county from pixels: Corn yield prediction with attention-weighted multiple instance learning",
    "abstract": "           Remote sensing technology has become a promising tool in yield prediction. Most prior work employs satellite imagery for county-level corn yield prediction by spatially aggregating all pixels within a county into a single value, potentially overlooking the detailed information and valuable insights offered by more granular data. To this end, this research examines each county at the pixel level and applies multiple instance learning to leverage detailed information within a county. In addition, our method addresses the \"mixed pixel\" issue caused by the inconsistent resolution between feature datasets and crop mask, which may introduce noise into the model and therefore hinder accurate yield prediction. Specifically, the attention mechanism is employed to automatically assign weights to different pixels, which can mitigate the influence of mixed pixels. The experimental results show that the developed model outperforms four other machine learning models over the past five years in the U.S. corn belt and demonstrates its best performance in 2022, achieving a coefficient of determination (R2) value of 0.84 and a root mean square error (RMSE) of 0.83. This paper demonstrates the advantages of our approach from both spatial and temporal perspectives. Furthermore, through an in-depth study of the relationship between mixed pixels and attention, it is verified that our approach can capture critical feature information while filtering out noise from mixed pixels.         ",
    "url": "https://arxiv.org/abs/2312.01001",
    "authors": [
      "Xiaoyu Wang",
      "Yuchi Ma",
      "Qunying Huang",
      "Zhengwei Yang",
      "Zhou Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.13740",
    "title": "Uncertainty-Aware Explanations Through Probabilistic Self-Explainable Neural Networks",
    "abstract": "           The lack of transparency of Deep Neural Networks continues to be a limitation that severely undermines their reliability and usage in high-stakes applications. Promising approaches to overcome such limitations are Prototype-Based Self-Explainable Neural Networks (PSENNs), whose predictions rely on the similarity between the input at hand and a set of prototypical representations of the output classes, offering therefore a deep, yet transparent-by-design, architecture. In this paper, we introduce a probabilistic reformulation of PSENNs, called Prob-PSENN, which replaces point estimates for the prototypes with probability distributions over their values. This provides not only a more flexible framework for an end-to-end learning of prototypes, but can also capture the explanatory uncertainty of the model, which is a missing feature in previous approaches. In addition, since the prototypes determine both the explanation and the prediction, Prob-PSENNs allow us to detect when the model is making uninformed or uncertain predictions, and to obtain valid explanations for them. Our experiments demonstrate that Prob-PSENNs provide more meaningful and robust explanations than their non-probabilistic counterparts, while remaining competitive in terms of predictive performance, thus enhancing the explainability and reliability of the models.         ",
    "url": "https://arxiv.org/abs/2403.13740",
    "authors": [
      "Jon Vadillo",
      "Roberto Santana",
      "Jose A. Lozano",
      "Marta Kwiatkowska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.10008",
    "title": "Solving the enigma: Enhancing faithfulness and comprehensibility in explanations of deep networks",
    "abstract": "           The accelerated progress of artificial intelligence (AI) has popularized deep learning models across various domains, yet their inherent opacity poses challenges, particularly in critical fields like healthcare, medicine, and the geosciences. Explainable AI (XAI) has emerged to shed light on these 'black box' models, aiding in deciphering their decision-making processes. However, different XAI methods often produce significantly different explanations, leading to high inter-method variability that increases uncertainty and undermines trust in deep networks' predictions. In this study, we address this challenge by introducing a novel framework designed to enhance the explainability of deep networks through a dual focus on maximizing both accuracy and comprehensibility in the explanations. Our framework integrates outputs from multiple established XAI methods and leverages a non-linear neural network model, termed the 'explanation optimizer,' to construct a unified, optimal explanation. The optimizer evaluates explanations using two key metrics: faithfulness (accuracy in reflecting the network's decisions) and complexity (comprehensibility). By balancing these, it provides accurate and accessible explanations, addressing a key XAI limitation. Experiments on multi-class and binary classification in 2D object and 3D neuroscience imaging confirm its efficacy. Our optimizer achieved faithfulness scores 155% and 63% higher than the best XAI methods in 3D and 2D tasks, respectively, while also reducing complexity for better understanding. These results demonstrate that optimal explanations based on specific quality criteria are achievable, offering a solution to the issue of inter-method variability in the current XAI literature and supporting more trustworthy deep network predictions         ",
    "url": "https://arxiv.org/abs/2405.10008",
    "authors": [
      "Michail Mamalakis",
      "Antonios Mamalakis",
      "Ingrid Agartz",
      "Lynn Egeland M\u00f8rch-Johnsen",
      "Graham Murray",
      "John Suckling",
      "Pietro Lio"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2405.11345",
    "title": "City-Scale Multi-Camera Vehicle Tracking System with Improved Self-Supervised Camera Link Model",
    "abstract": "           Multi-Target Multi-Camera Tracking (MTMCT) has broad applications and forms the basis for numerous future city-wide systems (e.g. traffic management, crash detection, etc.). However, the challenge of matching vehicle trajectories across different cameras based solely on feature extraction poses significant difficulties. This article introduces an innovative multi-camera vehicle tracking system that utilizes a self-supervised camera link model. In contrast to related works that rely on manual spatial-temporal annotations, our model automatically extracts crucial multi-camera relationships for vehicle matching. The camera link is established through a pre-matching process that evaluates feature similarities, pair numbers, and time variance for high-quality tracks. This process calculates the probability of spatial linkage for all camera combinations, selecting the highest scoring pairs to create camera links. Our approach significantly improves deployment times by eliminating the need for human annotation, offering substantial improvements in efficiency and cost-effectiveness when it comes to real-world application. This pairing process supports cross camera matching by setting spatial-temporal constraints, reducing the searching space for potential vehicle matches. According to our experimental results, the proposed method achieves a new state-of-the-art among automatic camera-link based methods in CityFlow V2 benchmarks with 61.07% IDF1 Score.         ",
    "url": "https://arxiv.org/abs/2405.11345",
    "authors": [
      "Yuqiang Lin",
      "Sam Lockyer",
      "Nic Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2405.14135",
    "title": "Space-aware Socioeconomic Indicator Inference with Heterogeneous Graphs",
    "abstract": "           Regional socioeconomic indicators are critical across various domains, yet their acquisition can be costly. Inferring global socioeconomic indicators from a limited number of regional samples is essential for enhancing management and sustainability in urban areas and human settlements. Current inference methods typically rely on spatial interpolation based on the assumption of spatial continuity, which does not adequately address the complex variations present within regional spaces. In this paper, we present GeoHG, the first space-aware socioeconomic indicator inference method that utilizes a heterogeneous graph-based structure to represent geospace for non-continuous inference. Extensive experiments demonstrate the effectiveness of GeoHG in comparison to existing methods, achieving an $R^2$ score exceeding 0.8 under extreme data scarcity with a masked ratio of 95\\%.         ",
    "url": "https://arxiv.org/abs/2405.14135",
    "authors": [
      "Xingchen Zou",
      "Jiani Huang",
      "Xixuan Hao",
      "Yuhao Yang",
      "Haomin Wen",
      "Yibo Yan",
      "Chao Huang",
      "Chen Chao",
      "Yuxuan Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2405.15568",
    "title": "OMNI-EPIC: Open-endedness via Models of human Notions of Interestingness with Environments Programmed in Code",
    "abstract": "           Open-ended and AI-generating algorithms aim to continuously generate and solve increasingly complex tasks indefinitely, offering a promising path toward more general intelligence. To accomplish this grand vision, learning must occur within a vast array of potential tasks. Existing approaches to automatically generating environments are constrained within manually predefined, often narrow distributions of environment, limiting their ability to create any learning environment. To address this limitation, we introduce a novel framework, OMNI-EPIC, that augments previous work in Open-endedness via Models of human Notions of Interestingness (OMNI) with Environments Programmed in Code (EPIC). OMNI-EPIC leverages foundation models to autonomously generate code specifying the next learnable (i.e., not too easy or difficult for the agent's current skill set) and interesting (e.g., worthwhile and novel) tasks. OMNI-EPIC generates both environments (e.g., an obstacle course) and reward functions (e.g., progress through the obstacle course quickly without touching red objects), enabling it, in principle, to create any simulatable learning task. We showcase the explosive creativity of OMNI-EPIC, which continuously innovates to suggest new, interesting learning challenges. We also highlight how OMNI-EPIC can adapt to reinforcement learning agents' learning progress, generating tasks that are of suitable difficulty. Overall, OMNI-EPIC can endlessly create learnable and interesting environments, further propelling the development of self-improving AI systems and AI-Generating Algorithms. Project website with videos: this https URL ",
    "url": "https://arxiv.org/abs/2405.15568",
    "authors": [
      "Maxence Faldor",
      "Jenny Zhang",
      "Antoine Cully",
      "Jeff Clune"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2405.15842",
    "title": "Model Cascading for Code: A Cascaded Black-Box Multi-Model Framework for Cost-Efficient Code Completion with Self-Testing",
    "abstract": "           The rapid advancement of large language models (LLMs) has significantly improved code completion tasks, yet the trade-off between accuracy and computational cost remains a critical challenge. While using larger models and incorporating inference-time self-testing algorithms can significantly improve output accuracy, they incur substantial computational expenses at the same time. Furthermore, servers in real-world scenarios usually have a dynamic preference on the cost-accuracy tradeoff, depending on the budget, bandwidth, the concurrent user volume, and users' sensitivity to wrong answers. In this work, we introduce a novel framework combining model cascading and inference-time self-feedback algorithms to find multiple near-optimal self-testing options on the cost-accuracy tradeoff in LLM-based code generation. Our approach leverages self-generated tests to both enhance accuracy and evaluate model cascading decisions. As a blackbox inference-time method, it requires no access to internal model parameters. We further propose a threshold-based algorithm to determine when to deploy larger models and a heuristic to optimize the number of solutions, test cases, and test lines generated per model, based on budget constraints. Experimental results show that our cascading approach reduces costs by an average of 26%, and up to 70% in the best case, across various model families and datasets, while maintaining or improving accuracy in natural language generation tasks compared to both random and optimal single-model self-testing schemes. To our knowledge, this is the first work to provide a series of choices for optimizing the cost-accuracy trade-off in LLM code generation with self-testing.         ",
    "url": "https://arxiv.org/abs/2405.15842",
    "authors": [
      "Boyuan Chen",
      "Mingzhi Zhu",
      "Brendan Dolan-Gavitt",
      "Muhammad Shafique",
      "Siddharth Garg"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.18649",
    "title": "LeDex: Training LLMs to Better Self-Debug and Explain Code",
    "abstract": "           In the domain of code generation, self-debugging is crucial. It allows LLMs to refine their generated code based on execution feedback. This is particularly important because generating correct solutions in one attempt proves challenging for complex tasks. Prior works on self-debugging mostly focus on prompting methods by providing LLMs with few-shot examples, which work poorly on small open-sourced LLMs. In this work, we propose LeDex, a training framework that significantly improves the self-debugging capability of LLMs. Intuitively, we observe that a chain of explanations on the wrong code followed by code refinement helps LLMs better analyze the wrong code and do refinement. We thus propose an automated pipeline to collect a high-quality dataset for code explanation and refinement by generating a number of explanations and refinement trajectories from the LLM itself or a larger teacher model and filtering via execution verification. We perform supervised fine-tuning (SFT) and further reinforcement learning (RL) on both success and failure trajectories with a novel reward design considering code explanation and refinement quality. SFT improves the pass@1 by up to 15.92% and pass@10 by 9.30% over four benchmarks. RL training brings additional up to 3.54% improvement on pass@1 and 2.55% improvement on pass@10. The trained LLMs show iterative refinement ability and can keep refining code continuously. Lastly, our human evaluation shows that the LLMs trained with our framework generate more useful code explanations and help developers better understand bugs in source code.         ",
    "url": "https://arxiv.org/abs/2405.18649",
    "authors": [
      "Nan Jiang",
      "Xiaopeng Li",
      "Shiqi Wang",
      "Qiang Zhou",
      "Soneya Binta Hossain",
      "Baishakhi Ray",
      "Varun Kumar",
      "Xiaofei Ma",
      "Anoop Deoras"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2406.00625",
    "title": "SAM-LAD: Segment Anything Model Meets Zero-Shot Logic Anomaly Detection",
    "abstract": "           Visual anomaly detection is vital in real-world applications, such as industrial defect detection and medical diagnosis. However, most existing methods focus on local structural anomalies and fail to detect higher-level functional anomalies under logical conditions. Although recent studies have explored logical anomaly detection, they can only address simple anomalies like missing or addition and show poor generalizability due to being heavily data-driven. To fill this gap, we propose SAM-LAD, a zero-shot, plug-and-play framework for logical anomaly detection in any scene. First, we obtain a query image's feature map using a pre-trained backbone. Simultaneously, we retrieve the reference images and their corresponding feature maps via the nearest neighbor search of the query image. Then, we introduce the Segment Anything Model (SAM) to obtain object masks of the query and reference images. Each object mask is multiplied with the entire image's feature map to obtain object feature maps. Next, an Object Matching Model (OMM) is proposed to match objects in the query and reference images. To facilitate object matching, we further propose a Dynamic Channel Graph Attention (DCGA) module, treating each object as a keypoint and converting its feature maps into feature vectors. Finally, based on the object matching relations, an Anomaly Measurement Model (AMM) is proposed to detect objects with logical anomalies. Structural anomalies in the objects can also be detected. We validate our proposed SAM-LAD using various benchmarks, including industrial datasets (MVTec Loco AD, MVTec AD), and the logical dataset (DigitAnatomy). Extensive experimental results demonstrate that SAM-LAD outperforms existing SoTA methods, particularly in detecting logical anomalies.         ",
    "url": "https://arxiv.org/abs/2406.00625",
    "authors": [
      "Yun Peng",
      "Xiao Lin",
      "Nachuan Ma",
      "Jiayuan Du",
      "Chuangwei Liu",
      "Chengju Liu",
      "Qijun Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.03519",
    "title": "Noise-Aware Algorithm for Heterogeneous Differentially Private Federated Learning",
    "abstract": "           High utility and rigorous data privacy are of the main goals of a federated learning (FL) system, which learns a model from the data distributed among some clients. The latter has been tried to achieve by using differential privacy in FL (DPFL). There is often heterogeneity in clients privacy requirements, and existing DPFL works either assume uniform privacy requirements for clients or are not applicable when server is not fully trusted (our setting). Furthermore, there is often heterogeneity in batch and/or dataset size of clients, which as shown, results in extra variation in the DP noise level across clients model updates. With these sources of heterogeneity, straightforward aggregation strategies, e.g., assigning clients aggregation weights proportional to their privacy parameters will lead to lower utility. We propose Robust-HDP, which efficiently estimates the true noise level in clients model updates and reduces the noise-level in the aggregated model updates considerably. Robust-HDP improves utility and convergence speed, while being safe to the clients that may maliciously send falsified privacy parameter to server. Extensive experimental results on multiple datasets and our theoretical analysis confirm the effectiveness of Robust-HDP. Our code can be found here.         ",
    "url": "https://arxiv.org/abs/2406.03519",
    "authors": [
      "Saber Malekmohammadi",
      "Yaoliang Yu",
      "Yang Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2407.01163",
    "title": "Benchmarking Predictive Coding Networks -- Made Simple",
    "abstract": "           In this work, we tackle the problems of efficiency and scalability for predictive coding networks (PCNs) in machine learning. To do so, we propose a library, called PCX, that focuses on performance and simplicity, and use it to implement a large set of standard benchmarks for the community to use for their experiments. As most works in the field propose their own tasks and architectures, do not compare one against each other, and focus on small-scale tasks, a simple and fast open-source library and a comprehensive set of benchmarks would address all these concerns. Then, we perform extensive tests on such benchmarks using both existing algorithms for PCNs, as well as adaptations of other methods popular in the bio-plausible deep learning community. All this has allowed us to (i) test architectures much larger than commonly used in the literature, on more complex datasets; (ii)~reach new state-of-the-art results in all of the tasks and datasets provided; (iii)~clearly highlight what the current limitations of PCNs are, allowing us to state important future research directions. With the hope of galvanizing community efforts towards one of the main open problems in the field, scalability, we release code, tests, and benchmarks. Link to the library: this https URL ",
    "url": "https://arxiv.org/abs/2407.01163",
    "authors": [
      "Luca Pinchetti",
      "Chang Qi",
      "Oleh Lokshyn",
      "Gaspard Olivers",
      "Cornelius Emde",
      "Mufeng Tang",
      "Amine M'Charrak",
      "Simon Frieder",
      "Bayar Menzat",
      "Rafal Bogacz",
      "Thomas Lukasiewicz",
      "Tommaso Salvatori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2407.02452",
    "title": "A Hardware-Friendly Shuffling Countermeasure Against Side-Channel Attacks for Kyber",
    "abstract": "           CRYSTALS-Kyber has been standardized as the only key-encapsulation mechanism (KEM) scheme by NIST to withstand attacks by large-scale quantum computers. However, the side-channel attacks (SCAs) on its implementation are still needed to be well considered for the upcoming migration. In this brief, we propose a secure and efficient hardware implementation for Kyber by incorporating a novel compact shuffling architecture. First of all, we modify the Fisher-Yates shuffle to make it more hardware-friendly. We then design an optimized shuffling architecture for the well-known open-source Kyber hardware implementation to enhance the security of all known and potential side-channel leakage points. Finally, we implement the modified Kyber design on FPGA and evaluate its security and performance. The security is verified by conducting correlation power analysis (CPA) and test vector leakage assessment (TVLA) on the hardware. Meanwhile, FPGA place-and-route results show that the proposed design reports only 8.7% degradation on the hardware efficiency compared with the original unprotected version, much better than existing hardware hiding schemes.         ",
    "url": "https://arxiv.org/abs/2407.02452",
    "authors": [
      "Dejun Xu",
      "Kai Wang",
      "Jing Tian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2407.08952",
    "title": "Detect, Investigate, Judge and Determine: A Knowledge-guided Framework for Few-shot Fake News Detection",
    "abstract": "           Few-Shot Fake News Detection (FS-FND) aims to distinguish inaccurate news from real ones in extremely low-resource scenarios. This task has garnered increased attention due to the widespread dissemination and harmful impact of fake news on social media. Large Language Models (LLMs) have demonstrated competitive performance with the help of their rich prior knowledge and excellent in-context learning abilities. However, existing methods face significant limitations, such as the Understanding Ambiguity and Information Scarcity, which significantly undermine the potential of LLMs. To address these shortcomings, we propose a Dual-perspective Knowledge-guided Fake News Detection (DKFND) model, designed to enhance LLMs from both inside and outside perspectives. Specifically, DKFND first identifies the knowledge concepts of each news article through a Detection Module. Subsequently, DKFND creatively designs an Investigation Module to retrieve inside and outside valuable information concerning to the current news, followed by another Judge Module to evaluate the relevance and confidence of them. Finally, a Determination Module further derives two respective predictions and obtain the final result. Extensive experiments on two public datasets show the efficacy of our proposed method, particularly in low-resource settings.         ",
    "url": "https://arxiv.org/abs/2407.08952",
    "authors": [
      "Ye Liu",
      "Jiajun Zhu",
      "Xukai Liu",
      "Haoyu Tang",
      "Yanghai Zhang",
      "Kai Zhang",
      "Xiaofang Zhou",
      "Enhong Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2407.16115",
    "title": "Transformer-based Graph Neural Networks for Battery Range Prediction in AIoT Battery-Swap Services",
    "abstract": "           The concept of the sharing economy has gained broad recognition, and within this context, Sharing E-Bike Battery (SEB) have emerged as a focal point of societal interest. Despite the popularity, a notable discrepancy remains between user expectations regarding the remaining battery range of SEBs and the reality, leading to a pronounced inclination among users to find an available SEB during emergency situations. In response to this challenge, the integration of Artificial Intelligence of Things (AIoT) and battery-swap services has surfaced as a viable solution. In this paper, we propose a novel structural Transformer-based model, referred to as the SEB-Transformer, designed specifically for predicting the battery range of SEBs. The scenario is conceptualized as a dynamic heterogeneous graph that encapsulates the interactions between users and bicycles, providing a comprehensive framework for analysis. Furthermore, we incorporate the graph structure into the SEB-Transformer to facilitate the estimation of the remaining e-bike battery range, in conjunction with mean structural similarity, enhancing the prediction accuracy. By employing the predictions made by our model, we are able to dynamically adjust the optimal cycling routes for users in real-time, while also considering the strategic locations of charging stations, thereby optimizing the user experience. Empirically our results on real-world datasets demonstrate the superiority of our model against nine competitive baselines. These innovations, powered by AIoT, not only bridge the gap between user expectations and the physical limitations of battery range but also significantly improve the operational efficiency and sustainability of SEB services. Through these advancements, the shared electric bicycle ecosystem is evolving, making strides towards a more reliable, user-friendly, and sustainable mode of transportation.         ",
    "url": "https://arxiv.org/abs/2407.16115",
    "authors": [
      "Zhao Li",
      "Yang Liu",
      "Chuan Zhou",
      "Xuanwu Liu",
      "Xuming Pan",
      "Buqing Cao",
      "Xindong Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2407.20908",
    "title": "Dynamic Scene Understanding through Object-Centric Voxelization and Neural Rendering",
    "abstract": "           Learning object-centric representations from unsupervised videos is challenging. Unlike most previous approaches that focus on decomposing 2D images, we present a 3D generative model named DynaVol-S for dynamic scenes that enables object-centric learning within a differentiable volume rendering framework. The key idea is to perform object-centric voxelization to capture the 3D nature of the scene, which infers per-object occupancy probabilities at individual spatial locations. These voxel features evolve through a canonical-space deformation function and are optimized in an inverse rendering pipeline with a compositional NeRF. Additionally, our approach integrates 2D semantic features to create 3D semantic grids, representing the scene through multiple disentangled voxel grids. DynaVol-S significantly outperforms existing models in both novel view synthesis and unsupervised decomposition tasks for dynamic scenes. By jointly considering geometric structures and semantic features, it effectively addresses challenging real-world scenarios involving complex object interactions. Furthermore, once trained, the explicitly meaningful voxel features enable additional capabilities that 2D scene decomposition methods cannot achieve, such as novel scene generation through editing geometric shapes or manipulating the motion trajectories of objects.         ",
    "url": "https://arxiv.org/abs/2407.20908",
    "authors": [
      "Yanpeng Zhao",
      "Yiwei Hao",
      "Siyu Gao",
      "Yunbo Wang",
      "Xiaokang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.10464",
    "title": "Improved Community Detection using Stochastic Block Models",
    "abstract": "           Community detection approaches resolve complex networks into smaller groups (communities) that are expected to be relatively edge-dense and well-connected. The stochastic block model (SBM) is one of several approaches used to uncover community structure in graphs. In this study, we demonstrate that SBM software applied to various real-world and synthetic networks produces poorly-connected to disconnected clusters. We present simple modifications to improve the connectivity of SBM clusters, and show that the modifications improve accuracy using simulated networks.         ",
    "url": "https://arxiv.org/abs/2408.10464",
    "authors": [
      "Minhyuk Park",
      "Daniel Wang Feng",
      "Siya Digra",
      "The-Anh Vu-Le",
      "George Chacko",
      "Tandy Warnow"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2408.10919",
    "title": "CrossFi: A Cross Domain Wi-Fi Sensing Framework Based on Siamese Network",
    "abstract": "           In recent years, Wi-Fi sensing has garnered significant attention due to its numerous benefits, such as privacy protection, low cost, and penetration ability. Extensive research has been conducted in this field, focusing on areas such as gesture recognition, people identification, and fall detection. However, many data-driven methods encounter challenges related to domain shift, where the model fails to perform well in environments different from the training data. One major factor contributing to this issue is the limited availability of Wi-Fi sensing datasets, which makes models learn excessive irrelevant information and over-fit to the training set. Unfortunately, collecting large-scale Wi-Fi sensing datasets across diverse scenarios is a challenging task. To address this problem, we propose CrossFi, a siamese network-based approach that excels in both in-domain scenario and cross-domain scenario, including few-shot, zero-shot scenarios, and even works in few-shot new-class scenario where testing set contains new categories. The core component of CrossFi is a sample-similarity calculation network called CSi-Net, which improves the structure of the siamese network by using an attention mechanism to capture similarity information, instead of simply calculating the distance or cosine similarity. Based on it, we develop an extra Weight-Net that can generate a template for each class, so that our CrossFi can work in different scenarios. Experimental results demonstrate that our CrossFi achieves state-of-the-art performance across various scenarios. In gesture recognition task, our CrossFi achieves an accuracy of 98.17% in in-domain scenario, 91.72% in one-shot cross-domain scenario, 64.81% in zero-shot cross-domain scenario, and 84.75% in one-shot new-class scenario. The code for our model is publicly available at this https URL.         ",
    "url": "https://arxiv.org/abs/2408.10919",
    "authors": [
      "Zijian Zhao",
      "Tingwei Chen",
      "Zhijie Cai",
      "Xiaoyang Li",
      "Hang Li",
      "Qimei Chen",
      "Guangxu Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2409.02375",
    "title": "How Privacy-Savvy Are Large Language Models? A Case Study on Compliance and Privacy Technical Review",
    "abstract": "           The recent advances in large language models (LLMs) have significantly expanded their applications across various fields such as language generation, summarization, and complex question answering. However, their application to privacy compliance and technical privacy reviews remains under-explored, raising critical concerns about their ability to adhere to global privacy standards and protect sensitive user data. This paper seeks to address this gap by providing a comprehensive case study evaluating LLMs' performance in privacy-related tasks such as privacy information extraction (PIE), legal and regulatory key point detection (KPD), and question answering (QA) with respect to privacy policies and data protection regulations. We introduce a Privacy Technical Review (PTR) framework, highlighting its role in mitigating privacy risks during the software development life-cycle. Through an empirical assessment, we investigate the capacity of several prominent LLMs, including BERT, GPT-3.5, GPT-4, and custom models, in executing privacy compliance checks and technical privacy reviews. Our experiments benchmark the models across multiple dimensions, focusing on their precision, recall, and F1-scores in extracting privacy-sensitive information and detecting key regulatory compliance points. While LLMs show promise in automating privacy reviews and identifying regulatory discrepancies, significant gaps persist in their ability to fully comply with evolving legal standards. We provide actionable recommendations for enhancing LLMs' capabilities in privacy compliance, emphasizing the need for robust model improvements and better integration with legal and regulatory requirements. This study underscores the growing importance of developing privacy-aware LLMs that can both support businesses in compliance efforts and safeguard user privacy rights.         ",
    "url": "https://arxiv.org/abs/2409.02375",
    "authors": [
      "Yang Liu",
      "Xichou Zhu",
      "Zhou Shen",
      "Yi Liu",
      "Min Li",
      "Yujun Chen",
      "Benzi John",
      "Zhenzhen Ma",
      "Tao Hu",
      "Zhi Li",
      "Bolong Yang",
      "Manman Wang",
      "Zongxing Xie",
      "Peng Liu",
      "Dan Cai",
      "Junhui Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2409.04796",
    "title": "Local-Prompt: Extensible Local Prompts for Few-Shot Out-of-Distribution Detection",
    "abstract": "           Out-of-Distribution (OOD) detection, aiming to distinguish outliers from known categories, has gained prominence in practical scenarios. Recently, the advent of vision-language models (VLM) has heightened interest in enhancing OOD detection for VLM through few-shot tuning. However, existing methods mainly focus on optimizing global prompts, ignoring refined utilization of local information with regard to outliers. Motivated by this, we freeze global prompts and introduce Local-Prompt, a novel coarse-to-fine tuning paradigm to emphasize regional enhancement with local prompts. Our method comprises two integral components: global prompt guided negative augmentation and local prompt enhanced regional regularization. The former utilizes frozen, coarse global prompts as guiding cues to incorporate negative augmentation, thereby leveraging local outlier knowledge. The latter employs trainable local prompts and a regional regularization to capture local information effectively, aiding in outlier identification. We also propose regional-related metric to empower the enrichment of OOD detection. Moreover, since our approach explores enhancing local prompts only, it can be seamlessly integrated with trained global prompts during inference to boost the performance. Comprehensive experiments demonstrate the effectiveness and potential of our method. Notably, our method reduces average FPR95 by 5.17% against state-of-the-art method in 4-shot tuning on challenging ImageNet-1k dataset, even outperforming 16-shot results of previous methods. Code is released at this https URL.         ",
    "url": "https://arxiv.org/abs/2409.04796",
    "authors": [
      "Fanhu Zeng",
      "Zhen Cheng",
      "Fei Zhu",
      "Hongxin Wei",
      "Xu-Yao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2409.10075",
    "title": "Steinmetz Neural Networks for Complex-Valued Data",
    "abstract": "           We introduce a new approach to processing complex-valued data using DNNs consisting of parallel real-valued subnetworks with coupled outputs. Our proposed class of architectures, referred to as Steinmetz Neural Networks, incorporates multi-view learning to construct more interpretable representations in the latent space. Moreover, we present the Analytic Neural Network, which incorporates a consistency penalty that encourages analytic signal representations in the latent space of the Steinmetz neural network. This penalty enforces a deterministic and orthogonal relationship between the real and imaginary components. Using an information-theoretic construction, we demonstrate that the generalization gap upper bound posited by the analytic neural network is lower than that of the general class of Steinmetz neural networks. Our numerical experiments depict the improved performance and robustness to additive noise, afforded by our proposed networks on benchmark datasets and synthetic examples.         ",
    "url": "https://arxiv.org/abs/2409.10075",
    "authors": [
      "Shyam Venkatasubramanian",
      "Ali Pezeshki",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2409.12467",
    "title": "SurgPLAN++: Universal Surgical Phase Localization Network for Online and Offline Inference",
    "abstract": "           Surgical phase recognition is critical for assisting surgeons in understanding surgical videos. Existing studies focused more on online surgical phase recognition, by leveraging preceding frames to predict the current frame. Despite great progress, they formulated the task as a series of frame-wise classification, which resulted in a lack of global context of the entire procedure and incoherent predictions. Moreover, besides online analysis, accurate offline surgical phase recognition is also in significant clinical need for retrospective analysis, and existing online algorithms do not fully analyze the entire video, thereby limiting accuracy in offline analysis. To overcome these challenges and enhance both online and offline inference capabilities, we propose a universal Surgical Phase Localization Network, named SurgPLAN++, with the principle of temporal detection. To ensure a global understanding of the surgical procedure, we devise a phase localization strategy for SurgPLAN++ to predict phase segments across the entire video through phase proposals. For online analysis, to generate high-quality phase proposals, SurgPLAN++ incorporates a data augmentation strategy to extend the streaming video into a pseudo-complete video through mirroring, center-duplication, and down-sampling. For offline analysis, SurgPLAN++ capitalizes on its global phase prediction framework to continuously refine preceding predictions during each online inference step, thereby significantly improving the accuracy of phase recognition. We perform extensive experiments to validate the effectiveness, and our SurgPLAN++ achieves remarkable performance in both online and offline modes, which outperforms state-of-the-art methods. The source code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2409.12467",
    "authors": [
      "Zhen Chen",
      "Xingjian Luo",
      "Jinlin Wu",
      "Long Bai",
      "Zhen Lei",
      "Hongliang Ren",
      "Sebastien Ourselin",
      "Hongbin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2409.19363",
    "title": "Learning Strategy Representation for Imitation Learning in Multi-Agent Games",
    "abstract": "           The offline datasets for imitation learning (IL) in multi-agent games typically contain player trajectories exhibiting diverse strategies, which necessitate measures to prevent learning algorithms from acquiring undesirable behaviors. Learning representations for these trajectories is an effective approach to depicting the strategies employed by each demonstrator. However, existing learning strategies often require player identification or rely on strong assumptions, which are not appropriate for multi-agent games. Therefore, in this paper, we introduce the Strategy Representation for Imitation Learning (STRIL) framework, which (1) effectively learns strategy representations in multi-agent games, (2) estimates proposed indicators based on these representations, and (3) filters out sub-optimal data using the indicators. STRIL is a plug-in method that can be integrated into existing IL algorithms. We demonstrate the effectiveness of STRIL across competitive multi-agent scenarios, including Two-player Pong, Limit Texas Hold'em, and Connect Four. Our approach successfully acquires strategy representations and indicators, thereby identifying dominant trajectories and significantly enhancing existing IL performance across these environments.         ",
    "url": "https://arxiv.org/abs/2409.19363",
    "authors": [
      "Shiqi Lei",
      "Kanghoon Lee",
      "Linjing Li",
      "Jinkyoo Park"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.01888",
    "title": "Conformal Prediction Sets Can Cause Disparate Impact",
    "abstract": "           Conformal prediction is a statistically rigorous method for quantifying uncertainty in models by having them output sets of predictions, with larger sets indicating more uncertainty. However, prediction sets are not inherently actionable; many applications require a single output to act on, not several. To overcome this limitation, prediction sets can be provided to a human who then makes an informed decision. In any such system it is crucial to ensure the fairness of outcomes across protected groups, and researchers have proposed that Equalized Coverage be used as the standard for fairness. By conducting experiments with human participants, we demonstrate that providing prediction sets can lead to disparate impact in decisions. Disquietingly, we find that providing sets that satisfy Equalized Coverage actually increases disparate impact compared to marginal coverage. Instead of equalizing coverage, we propose to equalize set sizes across groups which empirically leads to lower disparate impact.         ",
    "url": "https://arxiv.org/abs/2410.01888",
    "authors": [
      "Jesse C. Cresswell",
      "Bhargava Kumar",
      "Yi Sui",
      "Mouloud Belbahri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2410.02095",
    "title": "DomainLynx: Leveraging Large Language Models for Enhanced Domain Squatting Detection",
    "abstract": "           Domain squatting poses a significant threat to Internet security, with attackers employing increasingly sophisticated techniques. This study introduces DomainLynx, an innovative compound AI system leveraging Large Language Models (LLMs) for enhanced domain squatting detection. Unlike existing methods focusing on predefined patterns for top-ranked domains, DomainLynx excels in identifying novel squatting techniques and protecting less prominent brands. The system's architecture integrates advanced data processing, intelligent domain pairing, and LLM-powered threat assessment. Crucially, DomainLynx incorporates specialized components that mitigate LLM hallucinations, ensuring reliable and context-aware detection. This approach enables efficient analysis of vast security data from diverse sources, including Certificate Transparency logs, Passive DNS records, and zone files. Evaluated on a curated dataset of 1,649 squatting domains, DomainLynx achieved 94.7\\% accuracy using Llama-3-70B. In a month-long real-world test, it detected 34,359 squatting domains from 2.09 million new domains, outperforming baseline methods by 2.5 times. This research advances Internet security by providing a versatile, accurate, and adaptable tool for combating evolving domain squatting threats. DomainLynx's approach paves the way for more robust, AI-driven cybersecurity solutions, enhancing protection for a broader range of online entities and contributing to a safer digital ecosystem.         ",
    "url": "https://arxiv.org/abs/2410.02095",
    "authors": [
      "Daiki Chiba",
      "Hiroki Nakano",
      "Takashi Koide"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2410.10646",
    "title": "DR-MPC: Deep Residual Model Predictive Control for Real-world Social Navigation",
    "abstract": "           How can a robot safely navigate around people with complex motion patterns? Deep Reinforcement Learning (DRL) in simulation holds some promise, but much prior work relies on simulators that fail to capture the nuances of real human motion. Thus, we propose Deep Residual Model Predictive Control (DR-MPC) to enable robots to quickly and safely perform DRL from real-world crowd navigation data. By blending MPC with model-free DRL, DR-MPC overcomes the DRL challenges of large data requirements and unsafe initial behavior. DR-MPC is initialized with MPC-based path tracking, and gradually learns to interact more effectively with humans. To further accelerate learning, a safety component estimates out-of-distribution states to guide the robot away from likely collisions. In simulation, we show that DR-MPC substantially outperforms prior work, including traditional DRL and residual DRL models. Hardware experiments show our approach successfully enables a robot to navigate a variety of crowded situations with few errors using less than 4 hours of training data.         ",
    "url": "https://arxiv.org/abs/2410.10646",
    "authors": [
      "James R. Han",
      "Hugues Thomas",
      "Jian Zhang",
      "Nicholas Rhinehart",
      "Timothy D. Barfoot"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.12261",
    "title": "CATCH: Channel-Aware multivariate Time Series Anomaly Detection via Frequency Patching",
    "abstract": "           Anomaly detection in multivariate time series is challenging as heterogeneous subsequence anomalies may occur. Reconstruction-based methods, which focus on learning normal patterns in the frequency domain to detect diverse abnormal subsequences, achieve promising results, while still falling short on capturing fine-grained frequency characteristics and channel correlations. To contend with the limitations, we introduce CATCH, a framework based on frequency patching. We propose to patchify the frequency domain into frequency bands, which enhances its ability to capture fine-grained frequency characteristics. To perceive appropriate channel correlations, we propose a Channel Fusion Module (CFM), which features a patch-wise mask generator and a masked-attention mechanism. Driven by a bi-level multi-objective optimization algorithm, the CFM is encouraged to iteratively discover appropriate patch-wise channel correlations, and to cluster relevant channels while isolating adverse effects from irrelevant channels. Extensive experiments on 10 real-world datasets and 12 synthetic datasets demonstrate that CATCH achieves state-of-the-art performance. We make our code and datasets available at this https URL.         ",
    "url": "https://arxiv.org/abs/2410.12261",
    "authors": [
      "Xingjian Wu",
      "Xiangfei Qiu",
      "Zhengyu Li",
      "Yihang Wang",
      "Jilin Hu",
      "Chenjuan Guo",
      "Hui Xiong",
      "Bin Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2410.12343",
    "title": "Federated Temporal Graph Clustering",
    "abstract": "           Temporal graph clustering is a complex task that involves discovering meaningful structures in dynamic graphs where relationships and entities change over time. Existing methods typically require centralized data collection, which poses significant privacy and communication challenges. In this work, we introduce a novel Federated Temporal Graph Clustering (FTGC) framework that enables decentralized training of graph neural networks (GNNs) across multiple clients, ensuring data privacy throughout the process. Our approach incorporates a temporal aggregation mechanism to effectively capture the evolution of graph structures over time and a federated optimization strategy to collaboratively learn high-quality clustering representations. By preserving data privacy and reducing communication overhead, our framework achieves competitive performance on temporal graph datasets, making it a promising solution for privacy-sensitive, real-world applications involving dynamic data.         ",
    "url": "https://arxiv.org/abs/2410.12343",
    "authors": [
      "Yang Liu",
      "Zihao Zhou",
      "Xianghong Xu",
      "Qian Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2410.13502",
    "title": "MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily Complex Proofs",
    "abstract": "           Large language models (LLMs) can solve arithmetic word problems with high accuracy, but little is known about how well they generalize to more complex problems. This is difficult to study, as (i) much of the available evaluation data has already been seen by the most capable models during training, and (ii) existing benchmarks do not capture how problem proofs may be arbitrarily complex in various ways. In this paper, we present a data-generation framework for evaluating LLMs on problems with arbitrarily complex arithmetic proofs, called MathGAP. MathGAP generates problem statements and chain-of-thought reasoning traces according to specifications about their arithmetic proof structure, enabling systematic studies on easy-to-hard generalization with respect to complexity of proof trees. Using MathGAP, we find that LLMs show a significant decrease in performance as proofs get deeper and wider. This effect is more pronounced in complex, nonlinear proof structures, which are challenging even for the most capable models. The models are also sensitive to simple changes in sentence ordering. However, they remain capable of solving some complex problems, suggesting that reasoning generalization is noisy.         ",
    "url": "https://arxiv.org/abs/2410.13502",
    "authors": [
      "Andreas Opedal",
      "Haruki Shirakami",
      "Bernhard Sch\u00f6lkopf",
      "Abulhair Saparov",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2410.14038",
    "title": "Sliding Puzzles Gym: A Scalable Benchmark for State Representation in Visual Reinforcement Learning",
    "abstract": "           Learning effective visual representations enables agents to extract meaningful information from raw sensory inputs, which is essential for generalizing across different tasks. However, evaluating representation learning separately from policy learning remains a challenge with most reinforcement learning (RL) benchmarks. To address this gap, we introduce the Sliding Puzzles Gym (SPGym), a novel benchmark that reimagines the classic 8-tile puzzle with a visual observation space of images sourced from arbitrarily large datasets. SPGym provides precise control over representation complexity through visual diversity, allowing researchers to systematically scale the representation learning challenge while maintaining consistent environment dynamics. Despite the apparent simplicity of the task, our experiments with both model-free and model-based RL algorithms reveal fundamental limitations in current methods. As we increase visual diversity by expanding the pool of possible images, all tested algorithms show significant performance degradation, with even state-of-the-art methods struggling to generalize across different visual inputs while maintaining consistent puzzle-solving capabilities. These results highlight critical gaps in visual representation learning for RL and provide clear directions for improving robustness and generalization in decision-making systems.         ",
    "url": "https://arxiv.org/abs/2410.14038",
    "authors": [
      "Bryan L. M. de Oliveira",
      "Murilo L. da Luz",
      "Bruno Brand\u00e3o",
      "Luana G. B. Martins",
      "Telma W. de L. Soares",
      "Luckeciano C. Melo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.19205",
    "title": "Overcoming Non-Submodularity: Towards Constant Approximation for Network Immunization",
    "abstract": "           Given a network with an ongoing epidemic, the network immunization problem seeks to identify a fixed number of nodes to immunize in order to maximize the number of infections prevented. A fundamental computational challenge in network immunization is that the objective function is generally neither submodular nor supermodular. Consequently, no efficient algorithm is known to consistently achieve a constant-factor approximation. Traditionally, this problem is partially addressed using proxy objectives that offer better approximation properties, but these indirect optimizations often introduce losses in effectiveness due to gaps between the proxy and natural objectives. In this paper, we overcome these fundamental barriers by leveraging the underlying stochastic structure of the diffusion process. Similar to the traditional influence objective, the immunization objective is an expectation expressed as a sum over deterministic instances. However, unlike the former, some of these terms are not submodular. Our key step is to prove that this sum has a bounded deviation from submodularity, enabling the classic greedy algorithm to achieve a constant-factor approximation for any sparse cascading network. We demonstrate that this approximation holds across various immunization settings and spread models.         ",
    "url": "https://arxiv.org/abs/2410.19205",
    "authors": [
      "Ajitesh Srivastava",
      "Shang-Hua Teng"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2410.20856",
    "title": "Strada-LLM: Graph LLM for traffic prediction",
    "abstract": "           Traffic prediction is a vital component of intelligent transportation systems. By reasoning about traffic patterns in both the spatial and temporal dimensions, accurate and interpretable predictions can be provided. A considerable challenge in traffic prediction lies in handling the diverse data distributions caused by vastly different traffic conditions occurring at different locations. LLMs have been a dominant solution due to their remarkable capacity to adapt to new datasets with very few labeled data samples, i.e., few-shot adaptability. However, existing forecasting techniques mainly focus on extracting local graph information and forming a text-like prompt, leaving LLM- based traffic prediction an open problem. This work presents a probabilistic LLM for traffic forecasting with three highlights. We propose a graph-aware LLM for traffic prediction that considers proximal traffic information. Specifically, by considering the traffic of neighboring nodes as covariates, our model outperforms the corresponding time-series LLM. Furthermore, we adopt a lightweight approach for efficient domain adaptation when facing new data distributions in few-shot fashion. The comparative experiment demonstrates the proposed method outperforms the state-of-the-art LLM-based methods and the traditional GNN- based supervised approaches. Furthermore, Strada-LLM can be easily adapted to different LLM backbones without a noticeable performance drop.         ",
    "url": "https://arxiv.org/abs/2410.20856",
    "authors": [
      "Seyed Mohamad Moghadas",
      "Yangxintong Lyu",
      "Bruno Cornelis",
      "Alexandre Alahi",
      "Adrian Munteanu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2411.06426",
    "title": "SequentialBreak: Large Language Models Can be Fooled by Embedding Jailbreak Prompts into Sequential Prompt Chains",
    "abstract": "           As the integration of the Large Language Models (LLMs) into various applications increases, so does their susceptibility to misuse, raising significant security concerns. Numerous jailbreak attacks have been proposed to assess the security defense of LLMs. Current jailbreak attacks mainly rely on scenario camouflage, prompt obfuscation, prompt optimization, and prompt iterative optimization to conceal malicious prompts. In particular, sequential prompt chains in a single query can lead LLMs to focus on certain prompts while ignoring others, facilitating context manipulation. This paper introduces SequentialBreak, a novel jailbreak attack that exploits this vulnerability. We discuss several scenarios, not limited to examples like Question Bank, Dialog Completion, and Game Environment, where the harmful prompt is embedded within benign ones that can fool LLMs into generating harmful responses. The distinct narrative structures of these scenarios show that SequentialBreak is flexible enough to adapt to various prompt formats beyond those discussed. Extensive experiments demonstrate that SequentialBreak uses only a single query to achieve a substantial gain of attack success rate over existing baselines against both open-source and closed-source models. Through our research, we highlight the urgent need for more robust and resilient safeguards to enhance LLM security and prevent potential misuse. All the result files and website associated with this research are available in this GitHub repository: this https URL.         ",
    "url": "https://arxiv.org/abs/2411.06426",
    "authors": [
      "Bijoy Ahmed Saiem",
      "MD Sadik Hossain Shanto",
      "Rakib Ahsan",
      "Md Rafi ur Rashid"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2411.07902",
    "title": "Bayes2IMC: In-Memory Computing for Bayesian Binary Neural Networks",
    "abstract": "           Bayesian Neural Networks (BNNs) provide superior estimates of uncertainty by generating an ensemble of predictive distributions. However, inference via ensembling is resource-intensive, requiring additional entropy sources to generate stochasticity which increases resource consumption. We introduce Bayes2IMC, an in-memory computing (IMC) architecture designed for binary Bayesian neural networks that leverage nanoscale device stochasticity to generate desired distributions. Our novel approach utilizes Phase-Change Memory (PCM) to harness inherent noise characteristics, enabling the creation of a binary neural network. This design eliminates the necessity for a pre-neuron Analog-to-Digital Converter (ADC), significantly improving power and area efficiency. We also develop a hardware-software co-optimized correction method applied solely on the logits in the final layer to reduce device-induced accuracy variations across deployments on hardware. Additionally, we devise a simple compensation technique that ensures no drop in classification accuracy despite conductance drift of PCM. We validate the effectiveness of our approach on the CIFAR-10 dataset with a VGGBinaryConnect model, achieving accuracy metrics comparable to ideal software implementations as well as results reported in the literature using other technologies. Finally, we present a complete core architecture and compare its projected power, performance, and area efficiency against an equivalent SRAM baseline, showing a $3.8$ to $9.6 \\times$ improvement in total efficiency (in GOPS/W/mm$^2$) and a $2.2 $ to $5.6 \\times$ improvement in power efficiency (in GOPS/W). In addition, the projected hardware performance of Bayes2IMC surpasses that of most of the BNN architectures based on memristive devices reported in the literature, and achieves up to $20\\%$ higher power efficiency compared to the state-of-the-art.         ",
    "url": "https://arxiv.org/abs/2411.07902",
    "authors": [
      "Prabodh Katti",
      "Clement Ruah",
      "Osvaldo Simeone",
      "Bashir M. Al-Hashimi",
      "Bipin Rajendran"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2411.09858",
    "title": "One Leaf Reveals the Season: Occlusion-Based Contrastive Learning with Semantic-Aware Views for Efficient Visual Representation",
    "abstract": "           This paper proposes a scalable and straightforward pre-training paradigm for efficient visual conceptual representation called occluded image contrastive learning (OCL). Our OCL approach is simple: we randomly mask patches to generate different views within an image and contrast them among a mini-batch of images. The core idea behind OCL consists of two designs. First, masked tokens have the potential to significantly diminish the conceptual redundancy inherent in images, and create distinct views with substantial fine-grained differences on the semantic concept level instead of the instance level. Second, contrastive learning is adept at extracting high-level semantic conceptual features during the pre-training, circumventing the high-frequency interference and additional costs associated with image reconstruction. Importantly, OCL learns highly semantic conceptual representations efficiently without relying on hand-crafted data augmentations or additional auxiliary modules. Empirically, OCL demonstrates high scalability with Vision Transformers, as the ViT-L/16 can complete pre-training in 133 hours using only 4 A100 GPUs, achieving 85.8\\% accuracy in downstream fine-tuning tasks. Code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2411.09858",
    "authors": [
      "Xiaoyu Yang",
      "Lijian Xu",
      "Hongsheng Li",
      "Shaoting Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2412.08098",
    "title": "What You See Is Not Always What You Get: An Empirical Study of Code Comprehension by Large Language Models",
    "abstract": "           Recent studies have demonstrated outstanding capabilities of large language models (LLMs) in software engineering tasks, including code generation and comprehension. While LLMs have shown significant potential in assisting with coding, it is perceived that LLMs are vulnerable to adversarial attacks. In this paper, we investigate the vulnerability of LLMs to imperceptible attacks, where hidden character manipulation in source code misleads LLMs' behaviour while remaining undetectable to human reviewers. We devise these attacks into four distinct categories and analyse their impacts on code analysis and comprehension tasks. These four types of imperceptible coding character attacks include coding reordering, invisible coding characters, code deletions, and code homoglyphs. To comprehensively benchmark the robustness of current LLMs solutions against the attacks, we present a systematic experimental evaluation on multiple state-of-the-art LLMs. Our experimental design introduces two key performance metrics, namely model confidence using log probabilities of response, and the response correctness. A set of controlled experiments are conducted using a large-scale perturbed and unperturbed code snippets as the primary prompt input. Our findings confirm the susceptibility of LLMs to imperceptible coding character attacks, while different LLMs present different negative correlations between perturbation magnitude and performance. These results highlight the urgent need for robust LLMs capable of manoeuvring behaviours under imperceptible adversarial conditions. We anticipate this work provides valuable insights for enhancing the security and trustworthiness of LLMs in software engineering applications.         ",
    "url": "https://arxiv.org/abs/2412.08098",
    "authors": [
      "Bangshuo Zhu",
      "Jiawen Wen",
      "Huaming Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2412.09057",
    "title": "PhishIntel: Toward Practical Deployment of Reference-Based Phishing Detection",
    "abstract": "           Phishing is a critical cyber threat, exploiting deceptive tactics to compromise victims and cause significant financial losses. While reference-based phishing detectors (RBPDs) have achieved notable advancements in detection accuracy, their real-world deployment is hindered by challenges such as high latency and inefficiency in URL analysis. To address these limitations, we present PhishIntel, an end-to-end phishing detection system for real-world deployment. PhishIntel intelligently determines whether a URL can be processed immediately or not, segmenting the detection process into two distinct tasks: a fast task that checks against local blacklists and result cache, and a slow task that conducts online blacklist verification, URL crawling, and webpage analysis using an RBPD. This fast-slow task system architecture ensures low response latency while retaining the robust detection capabilities of RBPDs for zero-day phishing threats. Furthermore, we develop two downstream applications based on PhishIntel: a phishing intelligence platform and a phishing email detection plugin for Microsoft Outlook, demonstrating its practical efficacy and utility.         ",
    "url": "https://arxiv.org/abs/2412.09057",
    "authors": [
      "Yuexin Li",
      "Hiok Kuek Tan",
      "Qiaoran Meng",
      "Mei Lin Lock",
      "Tri Cao",
      "Shumin Deng",
      "Nay Oo",
      "Hoon Wei Lim",
      "Bryan Hooi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2412.09954",
    "title": "$\\textrm{A}^{\\textrm{2}}$RNet: Adversarial Attack Resilient Network for Robust Infrared and Visible Image Fusion",
    "abstract": "           Infrared and visible image fusion (IVIF) is a crucial technique for enhancing visual performance by integrating unique information from different modalities into one fused image. Exiting methods pay more attention to conducting fusion with undisturbed data, while overlooking the impact of deliberate interference on the effectiveness of fusion results. To investigate the robustness of fusion models, in this paper, we propose a novel adversarial attack resilient network, called $\\textrm{A}^{\\textrm{2}}$RNet. Specifically, we develop an adversarial paradigm with an anti-attack loss function to implement adversarial attacks and training. It is constructed based on the intrinsic nature of IVIF and provide a robust foundation for future research advancements. We adopt a Unet as the pipeline with a transformer-based defensive refinement module (DRM) under this paradigm, which guarantees fused image quality in a robust coarse-to-fine manner. Compared to previous works, our method mitigates the adverse effects of adversarial perturbations, consistently maintaining high-fidelity fusion results. Furthermore, the performance of downstream tasks can also be well maintained under adversarial attacks. Code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2412.09954",
    "authors": [
      "Jiawei Li",
      "Hongwei Yu",
      "Jiansheng Chen",
      "Xinlong Ding",
      "Jinlong Wang",
      "Jinyuan Liu",
      "Bochao Zou",
      "Huimin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2412.11550",
    "title": "THESAURUS: Contrastive Graph Clustering by Swapping Fused Gromov-Wasserstein Couplings",
    "abstract": "           Graph node clustering is a fundamental unsupervised task. Existing methods typically train an encoder through selfsupervised learning and then apply K-means to the encoder output. Some methods use this clustering result directly as the final assignment, while others initialize centroids based on this initial clustering and then finetune both the encoder and these learnable centroids. However, due to their reliance on K-means, these methods inherit its drawbacks when the cluster separability of encoder output is low, facing challenges from the Uniform Effect and Cluster Assimilation. We summarize three reasons for the low cluster separability in existing methods: (1) lack of contextual information prevents discrimination between similar nodes from different clusters; (2) training tasks are not sufficiently aligned with the downstream clustering task; (3) the cluster information in the graph structure is not appropriately exploited. To address these issues, we propose conTrastive grapH clustEring by SwApping fUsed gRomov-wasserstein coUplingS (THESAURUS). Our method introduces semantic prototypes to provide contextual information, and employs a cross-view assignment prediction pretext task that aligns well with the downstream clustering task. Additionally, it utilizes Gromov-Wasserstein Optimal Transport (GW-OT) along with the proposed prototype graph to thoroughly exploit cluster information in the graph structure. To adapt to diverse real-world data, THESAURUS updates the prototype graph and the prototype marginal distribution in OT by using momentum. Extensive experiments demonstrate that THESAURUS achieves higher cluster separability than the prior art, effectively mitigating the Uniform Effect and Cluster Assimilation issues         ",
    "url": "https://arxiv.org/abs/2412.11550",
    "authors": [
      "Bowen Deng",
      "Tong Wang",
      "Lele Fu",
      "Sheng Huang",
      "Chuan Chen",
      "Tao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2412.16264",
    "title": "Continual Learning with Strategic Selection and Forgetting for Network Intrusion Detection",
    "abstract": "           Intrusion Detection Systems (IDS) are crucial for safeguarding digital infrastructure. In dynamic network environments, both threat landscapes and normal operational behaviors are constantly changing, resulting in concept drift. While continuous learning mitigates the adverse effects of concept drift, insufficient attention to drift patterns and excessive preservation of outdated knowledge can still hinder the IDS's adaptability. In this paper, we propose SSF (Strategic Selection and Forgetting), a novel continual learning method for IDS, providing continuous model updates with a constantly refreshed memory buffer. Our approach features a strategic sample selection algorithm to select representative new samples and a strategic forgetting mechanism to drop outdated samples. The proposed strategic sample selection algorithm prioritizes new samples that cause the `drifted' pattern, enabling the model to better understand the evolving landscape. Additionally, we introduce strategic forgetting upon detecting significant drift by discarding outdated samples to free up memory, allowing the incorporation of more recent data. SSF captures evolving patterns effectively and ensures the model is aligned with the change of data patterns, significantly enhancing the IDS's adaptability to concept drift. The state-of-the-art performance of SSF on NSL-KDD and UNSW-NB15 datasets demonstrates its superior adaptability to concept drift for network intrusion detection. The code is released at this https URL.         ",
    "url": "https://arxiv.org/abs/2412.16264",
    "authors": [
      "Xinchen Zhang",
      "Running Zhao",
      "Zhihan Jiang",
      "Handi Chen",
      "Yulong Ding",
      "Edith C.H. Ngai",
      "Shuang-Hua Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2412.16482",
    "title": "Learn2Mix: Training Neural Networks Using Adaptive Data Integration",
    "abstract": "           Accelerating model convergence within resource-constrained environments is critical to ensure fast and efficient neural network training. This work presents learn2mix, a novel training strategy that adaptively adjusts class proportions within batches, focusing on classes with higher error rates. Unlike classical training methods that use static class proportions, learn2mix continually adapts class proportions during training, leading to faster convergence. Empirical evaluations conducted on benchmark datasets show that neural networks trained with learn2mix converge faster than those trained with existing approaches, achieving improved results for classification, regression, and reconstruction tasks under limited training resources and with imbalanced classes. Our empirical findings are supported by theoretical analysis.         ",
    "url": "https://arxiv.org/abs/2412.16482",
    "authors": [
      "Shyam Venkatasubramanian",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2412.17853",
    "title": "Zero Shot Time Series Forecasting Using Kolmogorov Arnold Networks",
    "abstract": "           Accurate energy price forecasting is crucial for participants in day-ahead energy markets, as it significantly influences their decision-making processes. While machine learning-based approaches have shown promise in enhancing these forecasts, they often remain confined to the specific markets on which they are trained, thereby limiting their adaptability to new or unseen markets. In this paper, we introduce a cross-domain adaptation model designed to forecast energy prices by learning market-invariant representations across different markets during the training phase. We propose a doubly residual N-BEATS network with Kolmogorov Arnold networks at its core for time series forecasting. These networks, grounded in the Kolmogorov-Arnold representation theorem, offer a powerful way to approximate multivariate continuous functions. The cross domain adaptation model was generated with an adversarial framework. The model's effectiveness was tested in predicting day-ahead electricity prices in a zero shot fashion. In comparison with baseline models, our proposed framework shows promising results. By leveraging the Kolmogorov-Arnold networks, our model can potentially enhance its ability to capture complex patterns in energy price data, thus improving forecast accuracy across diverse market conditions. This addition not only enriches the model's representational capacity but also contributes to a more robust and flexible forecasting tool adaptable to various energy markets.         ",
    "url": "https://arxiv.org/abs/2412.17853",
    "authors": [
      "Abhiroop Bhattacharya",
      "Nandinee Haq"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2412.18047",
    "title": "Uncertainty-Aware Critic Augmentation for Hierarchical Multi-Agent EV Charging Control",
    "abstract": "           The advanced bidirectional EV charging and discharging technology, aimed at supporting grid stability and emergency operations, has driven a growing interest in workplace applications. It not only reduces electricity expenses but also enhances the resilience in handling practical matters, such as peak power limitation, fluctuating energy prices, and unpredictable EV departures. Considering these factors systematically can benefit energy efficiency in office buildings and for EV users simultaneously. To employ AI to address these issues, we propose HUCA, a novel real-time charging control for regulating energy demands for both the building and EVs. HUCA employs hierarchical actor-critic networks to dynamically reduce electricity costs in buildings, accounting for the needs of EV charging in the dynamic pricing scenario. To tackle the uncertain EV departures, we introduce a new critic augmentation to account for departure uncertainties in evaluating the charging decisions, while maintaining the robustness of the charging control. Experiments on real-world electricity datasets under both simulated certain and uncertain departure scenarios demonstrate that HUCA outperforms baselines in terms of total electricity costs while maintaining competitive performance in fulfilling EV charging requirements. A case study also manifests that HUCA effectively balances energy supply between the building and EVs based on real-time information, showcasing its potential as a key AI-driven solution for vehicle charging control.         ",
    "url": "https://arxiv.org/abs/2412.18047",
    "authors": [
      "Lo Pang-Yun Ting",
      "Ali \u015eenol",
      "Huan-Yang Wang",
      "Hsu-Chao Lai",
      "Kun-Ta Chuang",
      "Huan Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2501.02074",
    "title": "A Comprehensive Framework to Operationalize Social Stereotypes for Responsible AI Evaluations",
    "abstract": "           Societal stereotypes are at the center of a myriad of responsible AI interventions targeted at reducing the generation and propagation of potentially harmful outcomes. While these efforts are much needed, they tend to be fragmented and often address different parts of the issue without taking in a unified or holistic approach about social stereotypes and how they impact various parts of the machine learning pipeline. As a result, it fails to capitalize on the underlying mechanisms that are common across different types of stereotypes, and to anchor on particular aspects that are relevant in certain cases. In this paper, we draw on social psychological research, and build on NLP data and methods, to propose a unified framework to operationalize stereotypes in generative AI evaluations. Our framework identifies key components of stereotypes that are crucial in AI evaluation, including the target group, associated attribute, relationship characteristics, perceiving group, and relevant context. We also provide considerations and recommendations for its responsible use.         ",
    "url": "https://arxiv.org/abs/2501.02074",
    "authors": [
      "Aida Davani",
      "Sunipa Dev",
      "H\u00e9ctor P\u00e9rez-Urbina",
      "Vinodkumar Prabhakaran"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2501.08648",
    "title": "MAGNET: Augmenting Generative Decoders with Representation Learning and Infilling Capabilities",
    "abstract": "           While originally designed for unidirectional generative modeling, decoder-only large language models (LLMs) are increasingly being adapted for bidirectional modeling. However, unidirectional and bidirectional models are typically trained separately with distinct objectives (generation and representation learning). This separation overlooks the opportunity for developing a more versatile language model and for these objectives to complement each other. In this work, we propose MAGNET, a method for adapting decoder-only LLMs to generate robust representations and infill missing text spans. MAGNET employs three self-supervised training objectives and introduces an attention mechanism that combines bidirectional and causal attention, enabling unified training across all objectives. Our results demonstrate that LLMs adapted with MAGNET (1) surpass strong text encoders on token-level and sentence-level representation learning tasks, (2) generate contextually appropriate text infills by leveraging past and future contexts, (3) perform open-ended text generation without excessive repetition of words or phrases, and (4) preserve the knowledge and reasoning capability gained by the LLM during pretraining.         ",
    "url": "https://arxiv.org/abs/2501.08648",
    "authors": [
      "Savya Khosla",
      "Aditi Tiwari",
      "Kushal Kafle",
      "Simon Jenni",
      "Handong Zhao",
      "John Collomosse",
      "Jing Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2501.12690",
    "title": "Growth strategies for arbitrary DAG neural architectures",
    "abstract": "           Deep learning has shown impressive results obtained at the cost of training huge neural networks. However, the larger the architecture, the higher the computational, financial, and environmental costs during training and inference. We aim at reducing both training and inference durations. We focus on Neural Architecture Growth, which can increase the size of a small model when needed, directly during training using information from the backpropagation. We expand existing work and freely grow neural networks in the form of any Directed Acyclic Graph by reducing expressivity bottlenecks in the architecture. We explore strategies to reduce excessive computations and steer network growth toward more parameter-efficient architectures.         ",
    "url": "https://arxiv.org/abs/2501.12690",
    "authors": [
      "Stella Douka",
      "Manon Verbockhaven",
      "Th\u00e9o Rudkiewicz",
      "St\u00e9phane Rivaud",
      "Fran\u00e7ois P. Landes",
      "Sylvain Chevallier",
      "Guillaume Charpiat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2501.13238",
    "title": "Fast-Locking and High-Resolution Mixed-Mode DLL with Binary Search and Clock Failure Detection for Wide Frequency Ranges in 3-nm FinFET CMOS",
    "abstract": "           This paper presents a mixed-mode delay-locked loop (MM-DLL) with binary search (BS) locking, designed to cover a broad frequency range from 533 MHz to 4.26 GHz. The BS locking scheme optimizes the locking time, reducing it from a linear to a logarithmic function, completing in B+1 cycles, where B represents the digital-to-analog (DAC) resolution controlling the voltage-controlled delay line (VCDL). At the start of the BS process, large step sizes can cause significant bias overshoots, potentially leading to clock failure conditions (i.e., clocks fail to propagate through the VCDL). To address this issue, a toggle detector is introduced to monitor clock activity and adjust the binary search controller. Upon detecting a stalled clock, the controller reverts the DAC code to the previous working code and resumes the BS with a reduced step size. Fabricated in a 3-nm FinFET CMOS process, the proposed MM-DLL achieves a locking time of under 10.5 ns while consuming 5.4 mW from a 0.75 V supply at 4.26 GHz. The measured performance includes a high resolution of 0.73 ps, with a static phase error of 0.73 ps, RMS jitter of 1.2 ps, and peak-to-peak jitter of 4.9 ps. The proposed MM-DLL achieves state-of-the-art power figure of merit (FoM) of 0.82 pJ and DLL locking FoM of 0.01 $pJ\\cdot ns^2$.         ",
    "url": "https://arxiv.org/abs/2501.13238",
    "authors": [
      "Nicol\u00e1s Wainstein",
      "Eran Avitay",
      "Eugene Avner"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2501.14349",
    "title": "Online Inverse Linear Optimization: Improved Regret Bound, Robustness to Suboptimality, and Toward Tight Regret Analysis",
    "abstract": "           We study an online learning problem where, over $T$ rounds, a learner observes both time-varying sets of feasible actions and an agent's optimal actions, selected by solving linear optimization over the feasible actions. The learner sequentially makes predictions of the agent's underlying linear objective function, and their quality is measured by the regret, the cumulative gap between optimal objective values and those achieved by following the learner's predictions. A seminal work by B\u00e4rmann et al. (ICML 2017) showed that online learning methods can be applied to this problem to achieve regret bounds of $O(\\sqrt{T})$. Recently, Besbes et al. (COLT 2021, Oper. Res. 2023) significantly improved the result by achieving an $O(n^4\\ln T)$ regret bound, where $n$ is the dimension of the ambient space of objective vectors. Their method, based on the ellipsoid method, runs in polynomial time but is inefficient for large $n$ and $T$. In this paper, we obtain an $O(n\\ln T)$ regret bound, improving upon the previous bound of $O(n^4\\ln T)$ by a factor of $n^3$. Our method is simple and efficient: we apply the online Newton step (ONS) to appropriate exp-concave loss functions. Moreover, for the case where the agent's actions are possibly suboptimal, we establish an $O(n\\ln T+\\sqrt{\\Delta_Tn\\ln T})$ regret bound, where $\\Delta_T$ is the cumulative suboptimality of the agent's actions. This bound is achieved by using MetaGrad, which runs ONS with $\\Theta(\\ln T)$ different learning rates in parallel. We also provide a simple instance that implies an $\\Omega(n)$ lower bound, showing that our $O(n\\ln T)$ bound is tight up to an $O(\\ln T)$ factor. This gives rise to a natural question: can the $O(\\ln T)$ factor in the upper bound be removed? For the special case of $n=2$, we show that an $O(1)$ regret bound is possible, while we delineate challenges in extending this result to higher dimensions.         ",
    "url": "https://arxiv.org/abs/2501.14349",
    "authors": [
      "Shinsaku Sakaue",
      "Taira Tsuchiya",
      "Han Bao",
      "Taihei Oki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2501.14497",
    "title": "Evaluating and Improving Graph to Text Generation with Large Language Models",
    "abstract": "           Large language models (LLMs) have demonstrated immense potential across various tasks. However, research for exploring and improving the capabilities of LLMs in interpreting graph structures remains limited. To address this gap, we conduct a comprehensive evaluation of prompting current open-source LLMs on graph-to-text generation tasks. Although we explored the optimal prompting strategies and proposed a novel and effective diversity-difficulty-based few-shot sample selection method, we found that the improvements from tuning-free approaches were incremental, as LLMs struggle with planning on complex graphs, particularly those with a larger number of triplets. To further improve LLMs in planning with graph sequences and grounding in truth, we introduce a new graph-to-text dataset, PlanGTG, annotated with two sub-tasks: reordering and attribution. Through extensive automatic and human evaluations, we demonstrate significant improvements in the quality of generated text from both few-shot learning and fine-tuning perspectives using the PlanGTG dataset. Our study paves the way for new research directions in graph-to-text generation. PlanGTG datasets can be found in this https URL.         ",
    "url": "https://arxiv.org/abs/2501.14497",
    "authors": [
      "Jie He",
      "Yijun Yang",
      "Wanqiu Long",
      "Deyi Xiong",
      "Victor Gutierrez-Basulto",
      "Jeff Z. Pan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2501.14679",
    "title": "Surface Vision Mamba: Leveraging Bidirectional State Space Model for Efficient Spherical Manifold Representation",
    "abstract": "           Attention-based methods have demonstrated exceptional performance in modelling long-range dependencies on spherical cortical surfaces, surpassing traditional Geometric Deep Learning (GDL) models. However, their extensive inference time and high memory demands pose challenges for application to large datasets with limited computing resources. Inspired by the state space model in computer vision, we introduce the attention-free Vision Mamba (Vim) to spherical surfaces, presenting a domain-agnostic architecture for analyzing data on spherical manifolds. Our method achieves surface patching by representing spherical data as a sequence of triangular patches derived from a subdivided icosphere. The proposed Surface Vision Mamba (SiM) is evaluated on multiple neurodevelopmental phenotype regression tasks using cortical surface metrics from neonatal brains. Experimental results demonstrate that SiM outperforms both attention- and GDL-based methods, delivering 4.8 times faster inference and achieving 91.7% lower memory consumption compared to the Surface Vision Transformer (SiT) under the Ico-4 grid partitioning. Sensitivity analysis further underscores the potential of SiM to identify subtle cognitive developmental patterns. The code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2501.14679",
    "authors": [
      "Rongzhao He",
      "Weihao Zheng",
      "Leilei Zhao",
      "Ying Wang",
      "Dalin Zhu",
      "Dan Wu",
      "Bin Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2501.15451",
    "title": "STATE ToxiCN: A Benchmark for Span-level Target-Aware Toxicity Extraction in Chinese Hate Speech Detection",
    "abstract": "           The proliferation of hate speech has caused significant harm to society. The intensity and directionality of hate are closely tied to the target and argument it is associated with. However, research on hate speech detection in Chinese has lagged behind, and existing datasets lack span-level fine-grained annotations. Furthermore, the lack of research on Chinese hateful slang poses a significant challenge. In this paper, we provide a solution for fine-grained detection of Chinese hate speech. First, we construct a dataset containing Target-Argument-Hateful-Group quadruples (STATE ToxiCN), which is the first span-level Chinese hate speech dataset. Secondly, we evaluate the span-level hate speech detection performance of existing models using STATE ToxiCN. Finally, we conduct the first study on Chinese hateful slang and evaluate the ability of LLMs to detect such expressions. Our work contributes valuable resources and insights to advance span-level hate speech detection in Chinese.         ",
    "url": "https://arxiv.org/abs/2501.15451",
    "authors": [
      "Zewen Bai",
      "Yuanyuan Sun",
      "Shengdi Yin",
      "Junyu Lu",
      "Jingjie Zeng",
      "Haohao Zhu",
      "Liang Yang",
      "Hongfei Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2501.18959",
    "title": "Enhancing Neural Function Approximation: The XNet Outperforming KAN",
    "abstract": "           XNet is a single-layer neural network architecture that leverages Cauchy integral-based activation functions for high-order function approximation. Through theoretical analysis, we show that the Cauchy activation functions used in XNet can achieve arbitrary-order polynomial convergence, fundamentally outperforming traditional MLPs and Kolmogorov-Arnold Networks (KANs) that rely on increased depth or B-spline activations. Our extensive experiments on function approximation, PDE solving, and reinforcement learning demonstrate XNet's superior performance - reducing approximation error by up to 50000 times and accelerating training by up to 10 times compared to existing approaches. These results establish XNet as a highly efficient architecture for both scientific computing and AI applications.         ",
    "url": "https://arxiv.org/abs/2501.18959",
    "authors": [
      "Xin Li",
      "Xiaotao Zheng",
      "Zhihong Xia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2502.00686",
    "title": "Improved Community Detection using Stochastic Block Models",
    "abstract": "           Identifying edge-dense communities that are also well-connected is an important aspect of understanding community structure. Prior work has shown that community detection methods can produce poorly connected communities, and some can even produce internally disconnected communities. In this study we evaluate the connectivity of communities obtained using Stochastic Block Models. We find that SBMs produce internally disconnected communities from real-world networks. We present a simple technique, Well-Connected Clusters (WCC), which repeatedly removes small edge cuts until the communities meet a user-specified threshold for well-connectivity. Our study using a large collection of synthetic networks based on clustered real-world networks shows that using WCC as a post-processing tool with SBM community detection typically improves clustering accuracy. WCC is fast enough to use on networks with millions of nodes and is freely available in open source form.         ",
    "url": "https://arxiv.org/abs/2502.00686",
    "authors": [
      "Minhyuk Park",
      "Daniel Wang Feng",
      "Siya Digra",
      "The-Anh Vu-Le",
      "Lahari Anne",
      "George Chacko",
      "Tandy Warnow"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2502.00735",
    "title": "`Do as I say not as I do': A Semi-Automated Approach for Jailbreak Prompt Attack against Multimodal LLMs",
    "abstract": "           Large Language Models (LLMs) have seen widespread applications across various domains due to their growing ability to process diverse types of input data, including text, audio, image and video. While LLMs have demonstrated outstanding performance in understanding and generating contexts for different scenarios, they are vulnerable to prompt-based attacks, which are mostly via text input. In this paper, we introduce the first voice-based jailbreak attack against multimodal LLMs, termed as Flanking Attack, which can process different types of input simultaneously towards the multimodal LLMs. Our work is motivated by recent advancements in monolingual voice-driven large language models, which have introduced new attack surfaces beyond traditional text-based vulnerabilities for LLMs. To investigate these risks, we examine the state-of-the-art multimodal LLMs, which can be accessed via different types of inputs such as audio input, focusing on how adversarial prompts can bypass its defense mechanisms. We propose a novel strategy, in which the disallowed prompt is flanked by benign, narrative-driven prompts. It is integrated in the Flanking Attack which attempts to humanizes the interaction context and execute the attack through a fictional setting. Further, to better evaluate the attack performance, we present a semi-automated self-assessment framework for policy violation detection. We demonstrate that Flanking Attack is capable of manipulating state-of-the-art LLMs into generating misaligned and forbidden outputs, which achieves an average attack success rate ranging from 0.67 to 0.93 across seven forbidden scenarios.         ",
    "url": "https://arxiv.org/abs/2502.00735",
    "authors": [
      "Chun Wai Chiu",
      "Linghan Huang",
      "Bo Li",
      "Huaming Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2502.01360",
    "title": "A Relative Homology Theory of Representation in Neural Networks",
    "abstract": "           Previous research has proven that the set of maps implemented by neural networks with a ReLU activation function is identical to the set of piecewise linear continuous maps. Furthermore, such networks induce a hyperplane arrangement splitting the input domain into convex polyhedra $G_J$ over which the network $\\Phi$ operates in an affine manner. In this work, we leverage these properties to define the equivalence class of inputs $\\sim_\\Phi$, which can be split into two sets related to the local rank of $\\Phi_J$ and the intersections $\\cap \\text{Im}\\Phi_{J_i}$. We refer to the latter as the overlap decomposition $O_\\Phi$ and prove that if the intersections between each polyhedron and the input manifold are convex, the homology groups of neural representations are isomorphic to relative homology groups $H_k(\\Phi(M)) \\simeq H_k(M,O_\\Phi)$. This lets us compute Betti numbers without the choice of an external metric. We develop methods to numerically compute the overlap decomposition through linear programming and a union-find algorithm. Using this framework, we perform several experiments on toy datasets showing that, compared to standard persistent homology, our relative homology-based computation of Betti numbers tracks purely topological rather than geometric features. Finally, we study the evolution of the overlap decomposition during training on various classification problems while varying network width and depth and discuss some shortcomings of our method.         ",
    "url": "https://arxiv.org/abs/2502.01360",
    "authors": [
      "Kosio Beshkov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2502.02844",
    "title": "Wolfpack Adversarial Attack for Robust Multi-Agent Reinforcement Learning",
    "abstract": "           Traditional robust methods in multi-agent reinforcement learning (MARL) often struggle against coordinated adversarial attacks in cooperative scenarios. To address this limitation, we propose the Wolfpack Adversarial Attack framework, inspired by wolf hunting strategies, which targets an initial agent and its assisting agents to disrupt cooperation. Additionally, we introduce the Wolfpack-Adversarial Learning for MARL (WALL) framework, which trains robust MARL policies to defend against the proposed Wolfpack attack by fostering system-wide collaboration. Experimental results underscore the devastating impact of the Wolfpack attack and the significant robustness improvements achieved by WALL.         ",
    "url": "https://arxiv.org/abs/2502.02844",
    "authors": [
      "Sunwoo Lee",
      "Jaebak Hwang",
      "Yonghyeon Jo",
      "Seungyul Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2502.03146",
    "title": "Symmetry-Aware Bayesian Flow Networks for Crystal Generation",
    "abstract": "           The discovery of new crystalline materials is essential to scientific and technological progress. However, traditional trial-and-error approaches are inefficient due to the vast search space. Recent advancements in machine learning have enabled generative models to predict new stable materials by incorporating structural symmetries and to condition the generation on desired properties. In this work, we introduce SymmBFN, a novel symmetry-aware Bayesian Flow Network (BFN) for crystalline material generation that accurately reproduces the distribution of space groups found in experimentally observed crystals. SymmBFN substantially improves efficiency, generating stable structures at least 50 times faster than the next-best method. Furthermore, we demonstrate its capability for property-conditioned generation, enabling the design of materials with tailored properties. Our findings establish BFNs as an effective tool for accelerating the discovery of crystalline materials.         ",
    "url": "https://arxiv.org/abs/2502.03146",
    "authors": [
      "Laura Ruple",
      "Luca Torresi",
      "Henrik Schopmans",
      "Pascal Friederich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)"
    ]
  },
  {
    "id": "arXiv:2502.03391",
    "title": "Explain Yourself, Briefly! Self-Explaining Neural Networks with Concise Sufficient Reasons",
    "abstract": "           *Minimal sufficient reasons* represent a prevalent form of explanation - the smallest subset of input features which, when held constant at their corresponding values, ensure that the prediction remains unchanged. Previous *post-hoc* methods attempt to obtain such explanations but face two main limitations: (1) Obtaining these subsets poses a computational challenge, leading most scalable methods to converge towards suboptimal, less meaningful subsets; (2) These methods heavily rely on sampling out-of-distribution input assignments, potentially resulting in counterintuitive behaviors. To tackle these limitations, we propose in this work a self-supervised training approach, which we term *sufficient subset training* (SST). Using SST, we train models to generate concise sufficient reasons for their predictions as an integral part of their output. Our results indicate that our framework produces succinct and faithful subsets substantially more efficiently than competing post-hoc methods, while maintaining comparable predictive performance.         ",
    "url": "https://arxiv.org/abs/2502.03391",
    "authors": [
      "Shahaf Bassan",
      "Ron Eliav",
      "Shlomit Gur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2502.03752",
    "title": "PRISM: A Robust Framework for Skill-based Meta-Reinforcement Learning with Noisy Demonstrations",
    "abstract": "           Meta-reinforcement learning (Meta-RL) facilitates rapid adaptation to unseen tasks but faces challenges in long-horizon environments. Skill-based approaches tackle this by decomposing state-action sequences into reusable skills and employing hierarchical decision-making. However, these methods are highly susceptible to noisy offline demonstrations, resulting in unstable skill learning and degraded performance. To overcome this, we propose Prioritized Refinement for Skill-Based Meta-RL (PRISM), a robust framework that integrates exploration near noisy data to generate online trajectories and combines them with offline data. Through prioritization, PRISM extracts high-quality data to learn task-relevant skills effectively. By addressing the impact of noise, our method ensures stable skill learning and achieves superior performance in long-horizon tasks, even with noisy and sub-optimal data.         ",
    "url": "https://arxiv.org/abs/2502.03752",
    "authors": [
      "Sanghyeon Lee",
      "Sangjun Bae",
      "Yisak Park",
      "Seungyul Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2502.05679",
    "title": "Federated Learning with Reservoir State Analysis for Time Series Anomaly Detection",
    "abstract": "           With a growing data privacy concern, federated learning has emerged as a promising framework to train machine learning models without sharing locally distributed data. In federated learning, local model training by multiple clients and model integration by a server are repeated only through model parameter sharing. Most existing federated learning methods assume training deep learning models, which are often computationally demanding. To deal with this issue, we propose federated learning methods with reservoir state analysis to seek computational efficiency and data privacy protection simultaneously. Specifically, our method relies on Mahalanobis Distance of Reservoir States (MD-RS) method targeting time series anomaly detection, which learns a distribution of reservoir states for normal inputs and detects anomalies based on a deviation from the learned distribution. Iterative updating of statistical parameters in the MD-RS enables incremental federated learning (IncFed MD-RS). We evaluate the performance of IncFed MD-RS using benchmark datasets for time series anomaly detection. The results show that IncFed MD-RS outperforms other federated learning methods with deep learning and reservoir computing models particularly when clients' data are relatively short and heterogeneous. We demonstrate that IncFed MD-RS is robust against reduced sample data compared to other methods. We also show that the computational cost of IncFed MD-RS can be reduced by subsampling from the reservoir states without performance degradation. The proposed method is beneficial especially in anomaly detection applications where computational efficiency, algorithm simplicity, and low communication cost are required.         ",
    "url": "https://arxiv.org/abs/2502.05679",
    "authors": [
      "Keigo Nogami",
      "Hiroto Tamura",
      "Gouhei Tanaka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.06153",
    "title": "Low Tensor-Rank Adaptation of Kolmogorov--Arnold Networks",
    "abstract": "           Kolmogorov--Arnold networks (KANs) have demonstrated their potential as an alternative to multi-layer perceptions (MLPs) in various domains, especially for science-related tasks. However, transfer learning of KANs remains a relatively unexplored area. In this paper, inspired by Tucker decomposition of tensors and evidence on the low tensor-rank structure in KAN parameter updates, we develop low tensor-rank adaptation (LoTRA) for fine-tuning KANs. We study the expressiveness of LoTRA based on Tucker decomposition approximations. Furthermore, we provide a theoretical analysis to select the learning rates for each LoTRA component to enable efficient training. Our analysis also shows that using identical learning rates across all components leads to inefficient training, highlighting the need for an adaptive learning rate strategy. Beyond theoretical insights, we explore the application of LoTRA for efficiently solving various partial differential equations (PDEs) by fine-tuning KANs. Additionally, we propose Slim KANs that incorporate the inherent low-tensor-rank properties of KAN parameter tensors to reduce model size while maintaining superior performance. Experimental results validate the efficacy of the proposed learning rate selection strategy and demonstrate the effectiveness of LoTRA for transfer learning of KANs in solving PDEs. Further evaluations on Slim KANs for function representation and image classification tasks highlight the expressiveness of LoTRA and the potential for parameter reduction through low tensor-rank decomposition.         ",
    "url": "https://arxiv.org/abs/2502.06153",
    "authors": [
      "Yihang Gao",
      "Michael K. Ng",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2502.06292",
    "title": "Occupancy-SLAM: An Efficient and Robust Algorithm for Simultaneously Optimizing Robot Poses and Occupancy Map",
    "abstract": "           Joint optimization of poses and features has been extensively studied and demonstrated to yield more accurate results in feature-based SLAM problems. However, research on jointly optimizing poses and non-feature-based maps remains limited. Occupancy maps are widely used non-feature-based environment representations because they effectively classify spaces into obstacles, free areas, and unknown regions, providing robots with spatial information for various tasks. In this paper, we propose Occupancy-SLAM, a novel optimization-based SLAM method that enables the joint optimization of robot trajectory and the occupancy map through a parameterized map representation. The key novelty lies in optimizing both robot poses and occupancy values at different cell vertices simultaneously, a significant departure from existing methods where the robot poses need to be optimized first before the map can be estimated. Evaluations using simulations and practical 2D laser datasets demonstrate that the proposed approach can robustly obtain more accurate robot trajectories and occupancy maps than state-of-the-art techniques with comparable computational time. Preliminary results in the 3D case further confirm the potential of the proposed method in practical 3D applications, achieving more accurate results than existing methods.         ",
    "url": "https://arxiv.org/abs/2502.06292",
    "authors": [
      "Yingyu Wang",
      "Liang Zhao",
      "Shoudong Huang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2502.07964",
    "title": "New tools for comparing classical and neural ODE models for tumor growth",
    "abstract": "           A new computational tool TumorGrowth$.$jl for modeling tumor growth is introduced. The tool allows the comparison of standard textbook models, such as General Bertalanffy and Gompertz, with some newer models, including, for the first time, neural ODE models. As an application, we revisit a human meta-study of non-small cell lung cancer and bladder cancer lesions, in patients undergoing two different treatment options, to determine if previously reported performance differences are statistically significant, and if newer, more complex models perform any better. In a population of examples with at least four time-volume measurements available for calibration, and an average of about 6.3, our main conclusion is that the General Bertalanffy model has superior performance, on average. However, where more measurements are available, we argue that more complex models, capable of capturing rebound and relapse behavior, may be better choices.         ",
    "url": "https://arxiv.org/abs/2502.07964",
    "authors": [
      "Anthony D. Blaom",
      "Samuel Okon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2502.08346",
    "title": "Graph Foundation Models for Recommendation: A Comprehensive Survey",
    "abstract": "           Recommender systems (RS) serve as a fundamental tool for navigating the vast expanse of online information, with deep learning advancements playing an increasingly important role in improving ranking accuracy. Among these, graph neural networks (GNNs) excel at extracting higher-order structural information, while large language models (LLMs) are designed to process and comprehend natural language, making both approaches highly effective and widely adopted. Recent research has focused on graph foundation models (GFMs), which integrate the strengths of GNNs and LLMs to model complex RS problems more efficiently by leveraging the graph-based structure of user-item relationships alongside textual understanding. In this survey, we provide a comprehensive overview of GFM-based RS technologies by introducing a clear taxonomy of current approaches, diving into methodological details, and highlighting key challenges and future directions. By synthesizing recent advancements, we aim to offer valuable insights into the evolving landscape of GFM-based recommender systems.         ",
    "url": "https://arxiv.org/abs/2502.08346",
    "authors": [
      "Bin Wu",
      "Yihang Wang",
      "Yuanhao Zeng",
      "Jiawei Liu",
      "Jiashu Zhao",
      "Cheng Yang",
      "Yawen Li",
      "Long Xia",
      "Dawei Yin",
      "Chuan Shi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.08644",
    "title": "Rhythmic sharing: A bio-inspired paradigm for zero-shot adaptation and learning in neural networks",
    "abstract": "           The brain can rapidly adapt to new contexts and learn from limited data, a coveted characteristic that artificial intelligence algorithms have struggled to mimic. Inspired by oscillatory rhythms of the mechanical structures of neural cells, we developed a learning paradigm that is based on oscillations in link strengths and associates learning with the coordination of these oscillations. We find that this paradigm yields rapid adaptation and learning in artificial neural networks. Link oscillations can rapidly change coordination, endowing the network with the ability to sense subtle context changes in an unsupervised manner. In other words, the network generates the missing contextual tokens required to perform as a generalist AI architecture capable of predicting dynamics in multiple contexts. Oscillations also allow the network to extrapolate dynamics to never-seen-before contexts. These capabilities make our learning paradigm a powerful starting point for novel models of learning and cognition. Furthermore, learning through link coordination is agnostic to the specifics of the neural network architecture, hence our study opens the door for introducing rapid adaptation and learning capabilities into leading AI models.         ",
    "url": "https://arxiv.org/abs/2502.08644",
    "authors": [
      "Hoony Kang",
      "Wolfgang Losert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Biological Physics (physics.bio-ph)"
    ]
  },
  {
    "id": "arXiv:2502.08659",
    "title": "Deployment-friendly Lane-changing Intention Prediction Powered by Brain-inspired Spiking Neural Networks",
    "abstract": "           Accurate and real-time prediction of surrounding vehicles' lane-changing intentions is a critical challenge in deploying safe and efficient autonomous driving systems in open-world scenarios. Existing high-performing methods remain hard to deploy due to their high computational cost, long training times, and excessive memory requirements. Here, we propose an efficient lane-changing intention prediction approach based on brain-inspired Spiking Neural Networks (SNN). By leveraging the event-driven nature of SNN, the proposed approach enables us to encode the vehicle's states in a more efficient manner. Comparison experiments conducted on HighD and NGSIM datasets demonstrate that our method significantly improves training efficiency and reduces deployment costs while maintaining comparable prediction accuracy. Particularly, compared to the baseline, our approach reduces training time by 75% and memory usage by 99.9%. These results validate the efficiency and reliability of our method in lane-changing predictions, highlighting its potential for safe and efficient autonomous driving systems while offering significant advantages in deployment, including reduced training time, lower memory usage, and faster inference.         ",
    "url": "https://arxiv.org/abs/2502.08659",
    "authors": [
      "Shuqi Shen",
      "Junjie Yang",
      "Hui Zhong",
      "Qiming Zhang",
      "Hongliang Lu",
      "Hai Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2502.08865",
    "title": "Siren Song: Manipulating Pose Estimation in XR Headsets Using Acoustic Attacks",
    "abstract": "           Extended Reality (XR) experiences involve interactions between users, the real world, and virtual content. A key step to enable these experiences is the XR headset sensing and estimating the user's pose in order to accurately place and render virtual content in the real world. XR headsets use multiple sensors (e.g., cameras, inertial measurement unit) to perform pose estimation and improve its robustness, but this provides an attack surface for adversaries to interfere with the pose estimation process. In this paper, we create and study the effects of acoustic attacks that create false signals in the inertial measurement unit (IMU) on XR headsets, leading to adverse downstream effects on XR applications. We generate resonant acoustic signals on a HoloLens 2 and measure the resulting perturbations in the IMU readings, and also demonstrate both fine-grained and coarse attacks on the popular ORB-SLAM3 and an open-source XR system (ILLIXR). With the knowledge gleaned from attacking these open-source frameworks, we demonstrate four end-to-end proof-of-concept attacks on a HoloLens 2: manipulating user input, clickjacking, zone invasion, and denial of user interaction. Our experiments show that current commercial XR headsets are susceptible to acoustic attacks, raising concerns for their security.         ",
    "url": "https://arxiv.org/abs/2502.08865",
    "authors": [
      "Zijian Huang",
      "Yicheng Zhang",
      "Sophie Chen",
      "Nael Abu-Ghazaleh",
      "Jiasi Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2502.08966",
    "title": "RTBAS: Defending LLM Agents Against Prompt Injection and Privacy Leakage",
    "abstract": "           Tool-Based Agent Systems (TBAS) allow Language Models (LMs) to use external tools for tasks beyond their standalone capabilities, such as searching websites, booking flights, or making financial transactions. However, these tools greatly increase the risks of prompt injection attacks, where malicious content hijacks the LM agent to leak confidential data or trigger harmful actions. Existing defenses (OpenAI GPTs) require user confirmation before every tool call, placing onerous burdens on users. We introduce Robust TBAS (RTBAS), which automatically detects and executes tool calls that preserve integrity and confidentiality, requiring user confirmation only when these safeguards cannot be ensured. RTBAS adapts Information Flow Control to the unique challenges presented by TBAS. We present two novel dependency screeners, using LM-as-a-judge and attention-based saliency, to overcome these challenges. Experimental results on the AgentDojo Prompt Injection benchmark show RTBAS prevents all targeted attacks with only a 2% loss of task utility when under attack, and further tests confirm its ability to obtain near-oracle performance on detecting both subtle and direct privacy leaks.         ",
    "url": "https://arxiv.org/abs/2502.08966",
    "authors": [
      "Peter Yong Zhong",
      "Siyuan Chen",
      "Ruiqi Wang",
      "McKenna McCall",
      "Ben L. Titzer",
      "Heather Miller",
      "Phillip B. Gibbons"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2502.08987",
    "title": "Neural Force Field: Learning Generalized Physical Representation from a Few Examples",
    "abstract": "           Physical reasoning is a remarkable human ability that enables rapid learning and generalization from limited experience. Current AI models, despite extensive training, still struggle to achieve similar generalization, especially in Out-of-distribution (OOD) settings. This limitation stems from their inability to abstract core physical principles from observations. A key challenge is developing representations that can efficiently learn and generalize physical dynamics from minimal data. Here we present Neural Force Field (NFF) a modeling framework built on Neural Ordinary Differential Equation (NODE) that learns interpretable force field representations which can be efficiently integrated through an Ordinary Differential Equation ( ODE) solver to predict object trajectories. Unlike existing approaches that rely on high-dimensional latent spaces, NFF captures fundamental physical concepts such as gravity, support, and collision in an interpretable manner. Experiments on two challenging physical reasoning tasks demonstrate that NFF, trained with only a few examples, achieves strong generalization to unseen scenarios. This physics-grounded representation enables efficient forward-backward planning and rapid adaptation through interactive refinement. Our work suggests that incorporating physics-inspired representations into learning systems can help bridge the gap between artificial and human physical reasoning capabilities.         ",
    "url": "https://arxiv.org/abs/2502.08987",
    "authors": [
      "Shiqian Li",
      "Ruihong Shen",
      "Chi Zhang",
      "Yixin Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2502.09048",
    "title": "The Social Construction of Visualizations: Practitioner Challenges and Experiences of Visualizing Race and Gender Demographic Data",
    "abstract": "           Data visualizations are increasingly seen as socially constructed, with several recent studies positing that perceptions and interpretations of visualization artifacts are shaped through complex sets of interactions between members of a community. However, most of these works have focused on audiences and researchers, and little is known about if and how practitioners account for the socially constructed framing of data visualization. In this paper, we study and analyze how visualization practitioners understand the influence of their beliefs, values, and biases in their design processes and the challenges they experience. In 17 semi-structured interviews with designers working with race and gender demographic data, we find that a complex mix of factors interact to inform how practitioners approach their design process, including their personal experiences, values, and their understandings of power, neutrality, and politics. Based on our findings, we suggest a series of implications for research and practice in this space.         ",
    "url": "https://arxiv.org/abs/2502.09048",
    "authors": [
      "Priya Dhawka",
      "Sayamindu Dasgupta"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2502.09268",
    "title": "GEVRM: Goal-Expressive Video Generation Model For Robust Visual Manipulation",
    "abstract": "           With the rapid development of embodied artificial intelligence, significant progress has been made in vision-language-action (VLA) models for general robot decision-making. However, the majority of existing VLAs fail to account for the inevitable external perturbations encountered during deployment. These perturbations introduce unforeseen state information to the VLA, resulting in inaccurate actions and consequently, a significant decline in generalization performance. The classic internal model control (IMC) principle demonstrates that a closed-loop system with an internal model that includes external input signals can accurately track the reference input and effectively offset the disturbance. We propose a novel closed-loop VLA method GEVRM that integrates the IMC principle to enhance the robustness of robot visual manipulation. The text-guided video generation model in GEVRM can generate highly expressive future visual planning goals. Simultaneously, we evaluate perturbations by simulating responses, which are called internal embeddings and optimized through prototype contrastive learning. This allows the model to implicitly infer and distinguish perturbations from the external environment. The proposed GEVRM achieves state-of-the-art performance on both standard and perturbed CALVIN benchmarks and shows significant improvements in realistic robot tasks.         ",
    "url": "https://arxiv.org/abs/2502.09268",
    "authors": [
      "Hongyin Zhang",
      "Pengxiang Ding",
      "Shangke Lyu",
      "Ying Peng",
      "Donglin Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2502.09271",
    "title": "LiSA: Leveraging Link Recommender to Attack Graph Neural Networks via Subgraph Injection",
    "abstract": "           Graph Neural Networks (GNNs) have demonstrated remarkable proficiency in modeling data with graph structures, yet recent research reveals their susceptibility to adversarial attacks. Traditional attack methodologies, which rely on manipulating the original graph or adding links to artificially created nodes, often prove impractical in real-world settings. This paper introduces a novel adversarial scenario involving the injection of an isolated subgraph to deceive both the link recommender and the node classifier within a GNN system. Specifically, the link recommender is mislead to propose links between targeted victim nodes and the subgraph, encouraging users to unintentionally establish connections and that would degrade the node classification accuracy, thereby facilitating a successful attack. To address this, we present the LiSA framework, which employs a dual surrogate model and bi-level optimization to simultaneously meet two adversarial objectives. Extensive experiments on real-world datasets demonstrate the effectiveness of our method.         ",
    "url": "https://arxiv.org/abs/2502.09271",
    "authors": [
      "Wenlun Zhang",
      "Enyan Dai",
      "Kentaro Yoshioka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2502.09313",
    "title": "Delay Performance Analysis with Short Packets in Intelligent Machine Network",
    "abstract": "           With the rapid development of delay-sensitive services happened in industrial manufacturing, Internet of Vehicles, and smart logistics, more stringent delay requirements are put forward for the intelligent machine (IM) network. Short packet transmissions are widely adopted to reduce delay in IM networks. However, the delay performance of an IM network has not been sufficiently analyzed. This paper applies queuing theory and stochastic geometry to construct network model and transmission model for downlink communication, respectively, proposes and derives the following three metrics, e.g., the transmission success probability (with delay as the threshold), expected delay, and delay jitter. To accurately characterize the transmission delay with short packets, the finite blocklength capacity is used to measure the channel transmission rate. Simulation results show that the increase of packet length and IM density significantly deteriorates the three metrics. Short packets are needed to improve the three metrics, especially in high IM density scenarios. The outcomes of this paper provide an important theoretical basis for the optimization design and performance improvement of IM networks.         ",
    "url": "https://arxiv.org/abs/2502.09313",
    "authors": [
      "Wenyan Xu",
      "Zhiqing Wei",
      "Zhiqun Song",
      "Yixin Zhang",
      "Haotian Liu",
      "Ying Zhou",
      "Xiaoyu Yang",
      "Yashan Pang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2502.09386",
    "title": "Code Style Sheets: CSS for Code",
    "abstract": "           Program text is rendered using impoverished typographic styles. Beyond choice of fonts and syntax-highlighting colors, code editors and related tools utilize very few text decorations. These limited styles are, furthermore, applied in monolithic fashion, regardless of the programs and tasks at hand. We present the notion of code style sheets for styling the textual representation of programs. Motivated by analogy to cascading style sheets (CSS) for styling HTML documents, code style sheets provide mechanisms for defining rules to select and style abstract syntax trees (ASTs). Technically, code style sheets generalize essential notions from CSS over untyped HTML trees to a programming-language setting with algebraic data types (such as ASTs). Practically, code style sheets allow ASTs to be styled granularly, based on semantic information -- such as the structure of abstract syntax, static type information, and corresponding run-time values -- as well as design choices on the part of authors and readers of a program. In this paper, we design and implement a code style sheets system for a subset of Haskell, using it to illustrate several use cases involving code presentation and visualization tasks. These examples demonstrate that code style sheets provide a uniform framework for rendering programs in multivarious ways.         ",
    "url": "https://arxiv.org/abs/2502.09386",
    "authors": [
      "Sam Cohen",
      "Ravi Chugh"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2404.09750",
    "title": "Layered Uploading for Quantum Convolutional Neural Networks",
    "abstract": "           Continuing our analysis of quantum machine learning applied to our use-case of malware detection, we investigate the potential of quantum convolutional neural networks. More precisely, we propose a new architecture where data is uploaded all along the quantum circuit. This allows us to use more features from the data, hence giving to the algorithm more information, without having to increase the number of qubits that we use for the quantum circuit. This approach is motivated by the fact that we do not always have great amounts of data, and that quantum computers are currently restricted in their number of logical qubits.         ",
    "url": "https://arxiv.org/abs/2404.09750",
    "authors": [
      "Gr\u00e9goire Barru\u00e9",
      "Tony Quertier",
      "Orlane Zang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2409.11731",
    "title": "Performance and Robustness of Signal-Dependent vs. Signal-Independent Binaural Signal Matching with Wearable Microphone Arrays",
    "abstract": "           The increasing popularity of spatial audio in applications such as teleconferencing, entertainment, and virtual reality has led to the recent developments of binaural reproduction methods. However, only a few of these methods are well-suited for wearable and mobile arrays, which typically consist of a small number of microphones. One such method is binaural signal matching (BSM), which has been shown to produce high-quality binaural signals for wearable arrays. However, BSM may be suboptimal in cases of high direct-to-reverberant ratio (DRR) as it is based on the diffuse sound field assumption. To overcome this limitation, previous studies incorporated sound-field models other than diffuse. However, performance may be sensitive to signal estimation errors. This paper aims to provide a systematic and comprehensive analysis of signal-dependent vs. signal-independent BSM, so that the benefits and limitations of the methods become clearer. Two signal-dependent BSM-based methods designed for high DRR scenarios that incorporate a sound field model composed of direct and reverberant components are investigated mathematically, using simulations, and finally validated by a listening test, and compared to the signal-independent BSM. The results show that signal-dependent BSM can significantly improve performance, in particular in the direction of the source, while presenting only a negligible degradation in other directions. Furthermore, when source direction estimation is inaccurate, performance of of the signal-dependent BSM degrade to equal that of the signal-independent BSM, presenting a desired robustness quality.         ",
    "url": "https://arxiv.org/abs/2409.11731",
    "authors": [
      "Ami Berger",
      "Vladimir Tourbabin",
      "Jacob Donley",
      "Zamir Ben-Hur",
      "Boaz Rafaely"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2410.09470",
    "title": "Exploring Channel Distinguishability in Local Neighborhoods of the Model Space in Quantum Neural Networks",
    "abstract": "           With the increasing interest in Quantum Machine Learning, Quantum Neural Networks (QNNs) have emerged and gained significant attention. These models have, however, been shown to be notoriously difficult to train, which we hypothesize is partially due to the architectures, called ansatzes, that are hardly studied at this point. Therefore, in this paper, we take a step back and analyze ansatzes. We initially consider their expressivity, i.e., the space of operations they are able to express, and show that the closeness to being a 2-design, the primarily used measure, fails at capturing this property. Hence, we look for alternative ways to characterize ansatzes by considering the local neighborhood of the model space, in particular, analyzing model distinguishability upon small perturbation of parameters. We derive an upper bound on their distinguishability, showcasing that QNNs with few parameters are hardly discriminable upon update. Our numerical experiments support our bounds and further indicate that there is a significant degree of variability, which stresses the need for warm-starting or clever initialization. Altogether, our work provides an ansatz-centric perspective on training dynamics and difficulties in QNNs, ultimately suggesting that iterative training of small quantum models may not be effective, which contrasts their initial motivation.         ",
    "url": "https://arxiv.org/abs/2410.09470",
    "authors": [
      "Sabrina Herbst",
      "Sandeep Suresh Cranganore",
      "Vincenzo De Maio",
      "Ivona Brandic"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2412.07223",
    "title": "A Consolidated Volatility Prediction with Back Propagation Neural Network and Genetic Algorithm",
    "abstract": "           This paper provides a unique approach with AI algorithms to predict emerging stock markets volatility. Traditionally, stock volatility is derived from historical volatility,Monte Carlo simulation and implied volatility as well. In this paper, the writer designs a consolidated model with back-propagation neural network and genetic algorithm to predict future volatility of emerging stock markets and found that the results are quite accurate with low errors.         ",
    "url": "https://arxiv.org/abs/2412.07223",
    "authors": [
      "Zong Ke",
      "Jingyu Xu",
      "Zizhou Zhang",
      "Yu Cheng",
      "Wenjun Wu"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2502.05674",
    "title": "Less is More for Synthetic Speech Detection in the Wild",
    "abstract": "           Driven by advances in self-supervised learning for speech, state-of-the-art synthetic speech detectors have achieved low error rates on popular benchmarks such as ASVspoof. However, prior benchmarks do not address the wide range of real-world variability in speech. Are reported error rates realistic in real-world conditions? To assess detector failure modes and robustness under controlled distribution shifts, we introduce ShiftySpeech, a benchmark with more than 3000 hours of synthetic speech from 7 domains, 6 TTS systems, 12 vocoders, and 3 languages. We found that all distribution shifts degraded model performance, and contrary to prior findings, training on more vocoders, speakers, or with data augmentation did not guarantee better generalization. In fact, we found that training on less diverse data resulted in better generalization, and that a detector fit using samples from a single carefully selected vocoder and a small number of speakers, without data augmentations, achieved state-of-the-art results on the challenging In-the-Wild benchmark.         ",
    "url": "https://arxiv.org/abs/2502.05674",
    "authors": [
      "Ashi Garg",
      "Zexin Cai",
      "Henry Li Xinyuan",
      "Leibny Paola Garc\u00eda-Perera",
      "Kevin Duh",
      "Sanjeev Khudanpur",
      "Matthew Wiesner",
      "Nicholas Andrews"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  }
]