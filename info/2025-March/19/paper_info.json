[
  {
    "id": "arXiv:2503.13449",
    "title": "Network Analysis, Plot Theory: Revisiting French Literature through Character Networks",
    "abstract": "           Character recognition is a technique that enables the automated extraction of characters from texts, while coreference resolution establishes connections between various mentions of the same character, collectively facilitating the creation of expansive character networks (Moretti, 2011). Together, these technologies make it possible to navigate and analyze large literary corpora, opening new avenues for in-depth exploration and understanding of literature. We have created a system specifically for the French language, based on BookNLP-fr (the French counterpart of BookNLP) and NetworkX (a Python package for the manipulation and visualization of complex networks). This allows us to establish connections between series of literary works based on structural features (such as typical relationships between characters) or specific subgenres (for instance, adventure novels featuring a group of young heroes). In this paper, as an illustration, we show the networks obtained at different stages of the short novel Boule de Suif from Maupassant (a French 19th century novelist). These figures effectively illustrate how the relationships between the characters develop over the course of the story.         ",
    "url": "https://arxiv.org/abs/2503.13449",
    "authors": [
      "Newman Chen",
      "Fr\u00e9d\u00e9rique M\u00e9lanie-Becquet",
      "Jean Barr\u00e9",
      "Thierry Poibeau"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2503.13455",
    "title": "Modeling and Analysis of Non-Terrestrial Networks by Spherical Stochastic Geometry",
    "abstract": "           Non-terrestrial networks (NTNs) are anticipated to be indispensable in extending coverage and enabling global communication access in next-generation wireless networks. With the extensive deployment of non-terrestrial platforms, evaluating the performance of NTN-enabled communication systems becomes a challenging task. Spherical stochastic geometry (SG) is a recently proposed analytical framework that has garnered increasing attention. Due to its suitability for modeling large-scale dynamic topologies and its ability to provide an analytical framework for interference analysis and low-complexity performance evaluation, spherical SG has been widely applied in NTN performance analysis. This paper surveys the modeling and analysis of NTN networks based on spherical SG. We begin by introducing the spherical SG framework, detailing its history and development. Next, we categorize existing spherical SG models into three types based on orbital modeling methods and provide algorithm implementations for common models. Furthermore, we investigate the accuracy and necessity of spherical modeling through case studies. On the topology level, concepts such as association strategy, central angle, zenith angle, contact angle, and availability probability are introduced, with simple derivations provided. On the channel level, we detail the modeling of large-scale fading, small-scale fading, and beam gain for different channel links. Finally, we discuss several advanced topics that have not been fully explored but have strong motivation and research potential, and we predict future research directions.         ",
    "url": "https://arxiv.org/abs/2503.13455",
    "authors": [
      "Ruibo Wang",
      "Mustafa A. Kishk",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2503.13461",
    "title": "CARDS: A collection of package, revision, and miscellaneous dependency graphs",
    "abstract": "           CARDS (Corpus of Acyclic Repositories and Dependency Systems) is a collection of directed graphs which express dependency relations, extracted from diverse real-world sources such as package managers, version control systems, and event graphs. Each graph contains anywhere from thousands to hundreds of millions of nodes and edges, which are normalized into a simple, unified format. Both cyclic and acyclic variants are included (as some graphs, such as citation networks, are not entirely acyclic). The dataset is suitable for studying the structure of different kinds of dependencies, enabling the characterization and distinction of various dependency graph types. It has been utilized for developing and testing efficient algorithms which leverage the specificities of source version control graphs. The collection is publicly available at this http URL.         ",
    "url": "https://arxiv.org/abs/2503.13461",
    "authors": [
      "Euxane Tran-Girard",
      "Laurent Bulteau",
      "Pierre-Yves David"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2503.13485",
    "title": "A Causal Inference Approach for Quantifying Research Impact",
    "abstract": "           Deep learning has had a great impact on various fields of computer science by enabling data-driven representation learning in a decade. Because science and technology policy decisions for a nation can be made on the impact of each technology, quantifying research impact is an important task. The number of citations and impact factor can be used to measure the impact for individual research. What would have happened without the research, however, is fundamentally a counterfactual phenomenon. Thus, we propose an approach based on causal inference to quantify the research impact of a specific technical topic. We leverage difference-in-difference to quantify the research impact by applying to bibliometric data. First, we identify papers of a specific technical topic using keywords or category tags from Microsoft Academic Graph, which is one of the largest academic publication dataset. Next, we build a paper citation network between each technical field. Then, we aggregate the cross-field citation count for each research field. Finally, the impact of a specific technical topic for each research field is estimated by applying difference-in-difference. Evaluation results show that deep learning significantly affects computer vision and natural language processing. Besides, deep learning significantly affects cross-field citation especially for speech recognition to computer vision and natural language processing to computer vision. Moreover, our method revealed that the impact of deep learning was 3.1 times of the impact of interpretability for ML models.         ",
    "url": "https://arxiv.org/abs/2503.13485",
    "authors": [
      "Keiichi Ochiai",
      "Yutaka Matsuo"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.13499",
    "title": "Leveraging Knowledge Graphs and LLMs for Context-Aware Messaging",
    "abstract": "           Personalized messaging plays an essential role in improving communication in areas such as healthcare, education, and professional engagement. This paper introduces a framework that uses the Knowledge Graph (KG) to dynamically rephrase written communications by integrating individual and context-specific data. The knowledge graph represents individuals, locations, and events as critical nodes, linking entities mentioned in messages to their corresponding graph nodes. The extraction of relevant information, such as preferences, professional roles, and cultural norms, is then combined with the original message and processed through a large language model (LLM) to generate personalized responses. The framework demonstrates notable message acceptance rates in various domains: 42% in healthcare, 53% in education, and 78% in professional recruitment. By integrating entity linking, event detection, and language modeling, this approach offers a structured and scalable solution for context-aware, audience-specific communication, facilitating advanced applications in diverse fields.         ",
    "url": "https://arxiv.org/abs/2503.13499",
    "authors": [
      "Rajeev Kumar",
      "Harishankar Kumar",
      "Kumari Shalini"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.13505",
    "title": "Ensemble Learning for Large Language Models in Text and Code Generation: A Survey",
    "abstract": "           Generative pretrained transformers (GPT) are the common large language models (LLMs) used for generating text from natural language inputs. However, the fixed properties of language parameters in individual LLMs can lead to inconsistencies in the generated outputs. This limitation also restricts the models' ability to represent diverse language patterns due to inherent biases. Moreover, many powerful LLMs are closed-source. This prevents organizations from integrating their data into these systems, raising concerns about data privacy and limiting industry applications. Inspired by the successful application of LLM ensemble models in text generation, recent literature has also investigated their potential in code generation. This article reviews these emerging LLM ensemble approaches. Our goal is to enhance readers' understanding of existing techniques and encourage further research and practical implementation, aiming to expand the real-world applications of LLM ensemble models in both text and code generation. We categorize these approaches into seven main methods: weight merging, knowledge fusion, mixture of experts, reward ensemble, output ensemble, routing, and cascading. From this list, we focus on four methods and models that show strong performance and potential for broader applications. We analyze their modeling steps, training methods, and output features to provide a clear understanding of their capabilities. Our findings highlight the benefits of LLM ensemble techniques. These include better representation of diversity, improved output quality, and greater flexibility in applications. This information offers valuable insights for selecting models for various real-world tasks involving text and code generation, and potentially applying methods to multimodal LLMs.         ",
    "url": "https://arxiv.org/abs/2503.13505",
    "authors": [
      "Mari Ashiga",
      "Wei Jie",
      "Fan Wu",
      "Vardan Voskanyan",
      "Fateme Dinmohammadi",
      "Paul Brookes",
      "Jingzhi Gong",
      "Zheng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.13514",
    "title": "RAG-KG-IL: A Multi-Agent Hybrid Framework for Reducing Hallucinations and Enhancing LLM Reasoning through RAG and Incremental Knowledge Graph Learning Integration",
    "abstract": "           This paper presents RAG-KG-IL, a novel multi-agent hybrid framework designed to enhance the reasoning capabilities of Large Language Models (LLMs) by integrating Retrieval-Augmented Generation (RAG) and Knowledge Graphs (KGs) with an Incremental Learning (IL) approach. Despite recent advancements, LLMs still face significant challenges in reasoning with structured data, handling dynamic knowledge evolution, and mitigating hallucinations, particularly in mission-critical domains. Our proposed RAG-KG-IL framework addresses these limitations by employing a multi-agent architecture that enables continuous knowledge updates, integrates structured knowledge, and incorporates autonomous agents for enhanced explainability and reasoning. The framework utilizes RAG to ensure the generated responses are grounded in verifiable information, while KGs provide structured domain knowledge for improved consistency and depth of understanding. The Incremental Learning approach allows for dynamic updates to the knowledge base without full retraining, significantly reducing computational overhead and improving the model's adaptability. We evaluate the framework using real-world case studies involving health-related queries, comparing it to state-of-the-art models like GPT-4o and a RAG-only baseline. Experimental results demonstrate that our approach significantly reduces hallucination rates and improves answer completeness and reasoning accuracy. The results underscore the potential of combining RAG, KGs, and multi-agent systems to create intelligent, adaptable systems capable of real-time knowledge integration and reasoning in complex domains.         ",
    "url": "https://arxiv.org/abs/2503.13514",
    "authors": [
      "Hong Qing Yu",
      "Frank McQuade"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2503.13537",
    "title": "FedTilt: Towards Multi-Level Fairness-Preserving and Robust Federated Learning",
    "abstract": "           Federated Learning (FL) is an emerging decentralized learning paradigm that can partly address the privacy concern that cannot be handled by traditional centralized and distributed learning. Further, to make FL practical, it is also necessary to consider constraints such as fairness and robustness. However, existing robust FL methods often produce unfair models, and existing fair FL methods only consider one-level (client) fairness and are not robust to persistent outliers (i.e., injected outliers into each training round) that are common in real-world FL settings. We propose \\texttt{FedTilt}, a novel FL that can preserve multi-level fairness and be robust to outliers. In particular, we consider two common levels of fairness, i.e., \\emph{client fairness} -- uniformity of performance across clients, and \\emph{client data fairness} -- uniformity of performance across different classes of data within a client. \\texttt{FedTilt} is inspired by the recently proposed tilted empirical risk minimization, which introduces tilt hyperparameters that can be flexibly tuned. Theoretically, we show how tuning tilt values can achieve the two-level fairness and mitigate the persistent outliers, and derive the convergence condition of \\texttt{FedTilt} as well. Empirically, our evaluation results on a suite of realistic federated datasets in diverse settings show the effectiveness and flexibility of the \\texttt{FedTilt} framework and the superiority to the state-of-the-arts.         ",
    "url": "https://arxiv.org/abs/2503.13537",
    "authors": [
      "Binghui Zhang",
      "Luis Mares De La Cruz",
      "Binghui Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2503.13540",
    "title": "MSCMHMST: A traffic flow prediction model based on Transformer",
    "abstract": "           This study proposes a hybrid model based on Transformers, named MSCMHMST, aimed at addressing key challenges in traffic flow prediction. Traditional single-method approaches show limitations in traffic prediction tasks, whereas hybrid methods, by integrating the strengths of different models, can provide more accurate and robust predictions. The MSCMHMST model introduces a multi-head, multi-scale attention mechanism, allowing the model to parallel process different parts of the data and learn its intrinsic representations from multiple perspectives, thereby enhancing the model's ability to handle complex situations. This mechanism enables the model to capture features at various scales effectively, understanding both short-term changes and long-term trends. Verified through experiments on the PeMS04/08 dataset with specific experimental settings, the MSCMHMST model demonstrated excellent robustness and accuracy in long, medium, and short-term traffic flow predictions. The results indicate that this model has significant potential, offering a new and effective solution for the field of traffic flow prediction.         ",
    "url": "https://arxiv.org/abs/2503.13540",
    "authors": [
      "Weiyang Geng",
      "Yiming Pan",
      "Zhecong Xing",
      "Dongyu Liu",
      "Rui Liu",
      "Yuan Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.13542",
    "title": "HAR-DoReMi: Optimizing Data Mixture for Self-Supervised Human Activity Recognition Across Heterogeneous IMU Datasets",
    "abstract": "           Cross-dataset Human Activity Recognition (HAR) suffers from limited model generalization, hindering its practical deployment. To address this critical challenge, inspired by the success of DoReMi in Large Language Models (LLMs), we introduce a data mixture optimization strategy for pre-training HAR models, aiming to improve the recognition performance across heterogeneous datasets. However, directly applying DoReMi to the HAR field encounters new challenges due to the continuous, multi-channel and intrinsic heterogeneous characteristics of IMU sensor data. To overcome these limitations, we propose a novel framework HAR-DoReMi, which introduces a masked reconstruction task based on Mean Squared Error (MSE) loss. By raplacing the discrete language sequence prediction task, which relies on the Negative Log-Likelihood (NLL) loss, in the original DoReMi framework, the proposed framework is inherently more appropriate for handling the continuous and multi-channel characteristics of IMU data. In addition, HAR-DoReMi integrates the Mahony fusion algorithm into the self-supervised HAR pre-training, aiming to mitigate the heterogeneity of varying sensor orientation. This is achieved by estimating the sensor orientation within each dataset and facilitating alignment with a unified coordinate system, thereby improving the cross-dataset generalization ability of the HAR model. Experimental evaluation on multiple cross-dataset HAR transfer tasks demonstrates that HAR-DoReMi improves the accuracy by an average of 6.51%, compared to the current state-of-the-art method with only approximately 30% to 50% of the data usage. These results confirm the effectiveness of HAR-DoReMi in improving the generalization and data efficiency of pre-training HAR models, underscoring its significant potential to facilitate the practical deployment of HAR technology.         ",
    "url": "https://arxiv.org/abs/2503.13542",
    "authors": [
      "Lulu Ban",
      "Tao Zhu",
      "Xiangqing Lu",
      "Qi Qiu",
      "Wenyong Han",
      "Shuangjian Li",
      "Liming Chen",
      "Kevin I-Kai Wang",
      "Mingxing Nie",
      "Yaping Wan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.13543",
    "title": "Enhancing Visual Representation with Textual Semantics: Textual Semantics-Powered Prototypes for Heterogeneous Federated Learning",
    "abstract": "           Federated Prototype Learning (FedPL) has emerged as an effective strategy for handling data heterogeneity in Federated Learning (FL). In FedPL, clients collaboratively construct a set of global feature centers (prototypes), and let local features align with these prototypes to mitigate the effects of data heterogeneity. The performance of FedPL highly depends on the quality of prototypes. Existing methods assume that larger inter-class distances among prototypes yield better performance, and thus design different methods to increase these distances. However, we observe that while these methods increase prototype distances to enhance class discrimination, they inevitably disrupt essential semantic relationships among classes, which are crucial for model generalization. This raises an important question: how to construct prototypes that inherently preserve semantic relationships among classes? Directly learning these relationships from limited and heterogeneous client data can be problematic in FL. Recently, the success of pre-trained language models (PLMs) demonstrates their ability to capture semantic relationships from vast textual corpora. Motivated by this, we propose FedTSP, a novel method that leverages PLMs to construct semantically enriched prototypes from the textual modality, enabling more effective collaboration in heterogeneous data settings. We first use a large language model (LLM) to generate fine-grained textual descriptions for each class, which are then processed by a PLM on the server to form textual prototypes. To address the modality gap between client image models and the PLM, we introduce trainable prompts, allowing prototypes to adapt better to client tasks. Extensive experiments demonstrate that FedTSP mitigates data heterogeneity while significantly accelerating convergence.         ",
    "url": "https://arxiv.org/abs/2503.13543",
    "authors": [
      "Xinghao Wu",
      "Jianwei Niu",
      "Xuefeng Liu",
      "Guogang Zhu",
      "Jiayuan Zhang",
      "Shaojie Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.13544",
    "title": "Semi-Decision-Focused Learning with Deep Ensembles: A Practical Framework for Robust Portfolio Optimization",
    "abstract": "           I propose Semi-Decision-Focused Learning, a practical adaptation of Decision-Focused Learning for portfolio optimization. Rather than directly optimizing complex financial metrics, I employ simple target portfolios (Max-Sortino or One-Hot) and train models with a convex, cross-entropy loss. I further incorporate Deep Ensemble methods to reduce variance and stabilize performance. Experiments on two universes (one upward-trending and another range-bound) show consistent outperformance over baseline portfolios, demonstrating the effectiveness and robustness of my approach. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2503.13544",
    "authors": [
      "Juhyeong Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)",
      "Portfolio Management (q-fin.PM)"
    ]
  },
  {
    "id": "arXiv:2503.13548",
    "title": "Fuzzy Rule-based Differentiable Representation Learning",
    "abstract": "           Representation learning has emerged as a crucial focus in machine and deep learning, involving the extraction of meaningful and useful features and patterns from the input data, thereby enhancing the performance of various downstream tasks such as classification, clustering, and prediction. Current mainstream representation learning methods primarily rely on non-linear data mining techniques such as kernel methods and deep neural networks to extract abstract knowledge from complex datasets. However, most of these methods are black-box, lacking transparency and interpretability in the learning process, which constrains their practical utility. To this end, this paper introduces a novel representation learning method grounded in an interpretable fuzzy rule-based model. Specifically, it is built upon the Takagi-Sugeno-Kang fuzzy system (TSK-FS) to initially map input data to a high-dimensional fuzzy feature space through the antecedent part of the TSK-FS. Subsequently, a novel differentiable optimization method is proposed for the consequence part learning which can preserve the model's interpretability and transparency while further exploring the nonlinear relationships within the data. This optimization method retains the essence of traditional optimization, with certain parts of the process parameterized corresponding differentiable modules constructed, and a deep optimization process implemented. Consequently, this method not only enhances the model's performance but also ensures its interpretability. Moreover, a second-order geometry preservation method is introduced to further improve the robustness of the proposed method. Extensive experiments conducted on various benchmark datasets validate the superiority of the proposed method, highlighting its potential for advancing representation learning methodologies.         ",
    "url": "https://arxiv.org/abs/2503.13548",
    "authors": [
      "Wei Zhang",
      "Zhaohong Deng",
      "Guanjin Wang",
      "Kup-Sze Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.13552",
    "title": "Fast data augmentation for battery degradation prediction",
    "abstract": "           Degradation prediction for lithium-ion batteries using data-driven methods requires high-quality aging data. However, generating such data, whether in the laboratory or the field, is time- and resource-intensive. Here, we propose a method for the synthetic generation of capacity fade curves based on limited battery tests or operation data without the need for invasive battery characterization, aiming to augment the datasets used by data-driven models for degradation prediction. We validate our method by evaluating the performance of both shallow and deep learning models using diverse datasets from laboratory and field applications. These datasets encompass various chemistries and realistic conditions, including cell-to-cell variations, measurement noise, varying charge-discharge conditions, and capacity recovery. Our results show that it is possible to reduce cell-testing efforts by at least 50% by substituting synthetic data into an existing dataset. This paper highlights the effectiveness of our synthetic data augmentation method in supplementing existing methodologies in battery health prognostics while dramatically reducing the expenditure of time and resources on battery aging experiments.         ",
    "url": "https://arxiv.org/abs/2503.13552",
    "authors": [
      "Weihan Li",
      "Harshvardhan Samsukha",
      "Bruis van Vlijmen",
      "Lisen Yan",
      "Samuel Greenbank",
      "Simona Onori",
      "Venkat Viswanathan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2503.13557",
    "title": "APF+: Boosting adaptive-potential function reinforcement learning methods with a W-shaped network for high-dimensional games",
    "abstract": "           Studies in reward shaping for reinforcement learning (RL) have flourished in recent years due to its ability to speed up training. Our previous work proposed an adaptive potential function (APF) and showed that APF can accelerate the Q-learning with a Multi-layer Perceptron algorithm in the low-dimensional domain. This paper proposes to extend APF with an encoder (APF+) for RL state representation, allowing applying APF to the pixel-based Atari games using a state-encoding method that projects high-dimensional game's pixel frames to low-dimensional embeddings. We approach by designing the state-representation encoder as a W-shaped network (W-Net), by using which we are able to encode both the background as well as the moving entities in the game frames. Specifically, the embeddings derived from the pre-trained W-Net consist of two latent vectors: One represents the input state, and the other represents the deviation of the input state's representation from itself. We then incorporate W-Net into APF to train a downstream Dueling Deep Q-Network (DDQN), obtain the APF-WNet-DDQN, and demonstrate its effectiveness in Atari game-playing tasks. To evaluate the APF+W-Net module in such high-dimensional tasks, we compare with two types of baseline methods: (i) the basic DDQN; and (ii) two encoder-replaced APF-DDQN methods where we replace W-Net by (a) an unsupervised state representation method called Spatiotemporal Deep Infomax (ST-DIM) and (b) a ground truth state representation provided by the Atari Annotated RAM Interface (ARI). The experiment results show that out of 20 Atari games, APF-WNet-DDQN outperforms DDQN (14/20 games) and APF-STDIM-DDQN (13/20 games) significantly. In comparison against the APF-ARI-DDQN which employs embeddings directly of the detailed game-internal state information, the APF-WNet-DDQN achieves a comparable performance.         ",
    "url": "https://arxiv.org/abs/2503.13557",
    "authors": [
      "Yifei Chen",
      "Lambert Schomaker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.13567",
    "title": "Graph Discovery and Source Detection in Temporal Graphs",
    "abstract": "           Researchers, policy makers, and engineers need to make sense of data on spreading processes as diverse as viral infections, water contamination, and misinformation in social networks. Classical questions include predicting infection behavior in a given network or deducing the structure of a network from infection data. We study two central problems in this area. In graph discovery, we aim to fully reconstruct the structure of a graph from infection data. In source detection, we observe a limited subset of the infections and aim to deduce the source of the infection chain. These questions have received considerable attention and have been analyzed in many settings (e.g., under different models of spreading processes), yet all previous work shares the assumption that the network has the same structure at every point in time. For example, if we consider how a disease spreads, it is unrealistic to assume that two people can either never or always infect each other, rather such an infection is possible precisely when they meet. Temporal graphs, in which connections change over time, have recently been used as a more realistic graph model to study infections. Despite this recent attention, we are the first to study graph discovery or source detection in temporal graphs. We propose models for temporal graph discovery and source detection that are consistent with previous work on static graphs and extend it to embrace the stronger expressiveness of temporal graphs. For this, we employ the standard susceptible-infected-resistant model of spreading processes, which is particularly often used to study diseases. We provide algorithms, lower bounds, and some experimental evaluation.         ",
    "url": "https://arxiv.org/abs/2503.13567",
    "authors": [
      "Ben Bals"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2503.13576",
    "title": "A Comprehensive Survey on Visual Concept Mining in Text-to-image Diffusion Models",
    "abstract": "           Text-to-image diffusion models have made significant advancements in generating high-quality, diverse images from text prompts. However, the inherent limitations of textual signals often prevent these models from fully capturing specific concepts, thereby reducing their controllability. To address this issue, several approaches have incorporated personalization techniques, utilizing reference images to mine visual concept representations that complement textual inputs and enhance the controllability of text-to-image diffusion models. Despite these advances, a comprehensive, systematic exploration of visual concept mining remains limited. In this paper, we categorize existing research into four key areas: Concept Learning, Concept Erasing, Concept Decomposition, and Concept Combination. This classification provides valuable insights into the foundational principles of Visual Concept Mining (VCM) techniques. Additionally, we identify key challenges and propose future research directions to propel this important and interesting field forward.         ",
    "url": "https://arxiv.org/abs/2503.13576",
    "authors": [
      "Ziqiang Li",
      "Jun Li",
      "Lizhi Xiong",
      "Zhangjie Fu",
      "Zechao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.13583",
    "title": "Stability results for MIMO LTI systems via Scaled Relative Graphs",
    "abstract": "           This paper proposes a new approach for stability analysis of multi-input, multi-output (MIMO) feedback systems through Scaled Relative Graphs (SRGs). Unlike traditional methods, such as the Generalized Nyquist Criterion (GNC), which relies on a coupled analysis that requires the multiplication of models, our approach enables the evaluation of system stability in a decoupled fashion and provides an intuitive, visual representation of system behavior. Our results provide conditions for certifying the stability of feedback MIMO Linear Time-Invariant (LTI) systems.         ",
    "url": "https://arxiv.org/abs/2503.13583",
    "authors": [
      "Eder Baron-Prada",
      "Adolfo Anta",
      "Alberto Padoan",
      "Florian D\u00f6rfler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2503.13584",
    "title": "Sustainability Analysis Patterns for Process Mining and Process Modelling Approaches",
    "abstract": "           Business Process Management (BPM) has the potential to help companies manage and reduce their activities' negative social and environmental impacts. However, so far, only limited capabilities for analysing the sustainability impacts of processes have been integrated into established BPM methods and tools. One of the main challenges of existing Sustainable BPM approaches is the lack of a sound conception of sustainability impacts. This paper describes a set of sustainability analysis patterns that integrate BPM concepts with concepts from existing sustainability analysis methods to address this challenge. The patterns provide a framework to evaluate and develop process modelling and process mining approaches for discovering, analysing and improving the sustainability impacts of processes. It is shown how the patterns can be used to evaluate existing process modelling and process mining approaches.         ",
    "url": "https://arxiv.org/abs/2503.13584",
    "authors": [
      "Andreas Fritsch"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2503.13652",
    "title": "Web Artifact Attacks Disrupt Vision Language Models",
    "abstract": "           Vision-language models (VLMs) (e.g., CLIP, LLaVA) are trained on large-scale, lightly curated web datasets, leading them to learn unintended correlations between semantic concepts and unrelated visual signals. These associations degrade model accuracy by causing predictions to rely on incidental patterns rather than genuine visual understanding. Prior work has weaponized these correlations as an attack vector to manipulate model predictions, such as inserting a deceiving class text onto the image in a typographic attack. These attacks succeed due to VLMs' text-heavy bias-a result of captions that echo visible words rather than describing content. However, this attack has focused solely on text that matches the target class exactly, overlooking a broader range of correlations, including non-matching text and graphical symbols, which arise from the abundance of branding content in web-scale data. To address this gap, we introduce artifact-based attacks: a novel class of manipulations that mislead models using both non-matching text and graphical elements. Unlike typographic attacks, these artifacts are not predefined, making them harder to defend against but also more challenging to find. We address this by framing artifact attacks as a search problem and demonstrate their effectiveness across five datasets, with some artifacts reinforcing each other to reach 100% attack success rates. These attacks transfer across models with up to 90% effectiveness, making it possible to attack unseen models. To defend against these attacks, we extend prior work's artifact aware prompting to the graphical setting. We see a moderate reduction of success rates of up to 15% relative to standard prompts, suggesting a promising direction for enhancing model robustness.         ",
    "url": "https://arxiv.org/abs/2503.13652",
    "authors": [
      "Maan Qraitem",
      "Piotr Teterwak",
      "Kate Saenko",
      "Bryan A. Plummer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.13654",
    "title": "SOSecure: Safer Code Generation with RAG and StackOverflow Discussions",
    "abstract": "           Large Language Models (LLMs) are widely used for automated code generation. Their reliance on infrequently updated pretraining data leaves them unaware of newly discovered vulnerabilities and evolving security standards, making them prone to producing insecure code. In contrast, developer communities on Stack Overflow (SO) provide an ever-evolving repository of knowledge, where security vulnerabilities are actively discussed and addressed through collective expertise. These community-driven insights remain largely untapped by LLMs. This paper introduces SOSecure, a Retrieval-Augmented Generation (RAG) system that leverages the collective security expertise found in SO discussions to improve the security of LLM-generated code. We build a security-focused knowledge base by extracting SO answers and comments that explicitly identify vulnerabilities. Unlike common uses of RAG, SOSecure triggers after code has been generated to find discussions that identify flaws in similar code. These are used in a prompt to an LLM to consider revising the code. Evaluation across three datasets (SALLM, LLMSecEval, and LMSys) show that SOSecure achieves strong fix rates of 71.7%, 91.3%, and 96.7% respectively, compared to prompting GPT-4 without relevant discussions (49.1%, 56.5%, and 37.5%), and outperforms multiple other baselines. SOSecure operates as a language-agnostic complement to existing LLMs, without requiring retraining or fine-tuning, making it easy to deploy. Our results underscore the importance of maintaining active developer forums, which have dropped substantially in usage with LLM adoptions.         ",
    "url": "https://arxiv.org/abs/2503.13654",
    "authors": [
      "Manisha Mukherjee",
      "Vincent J. Hellendoorn"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2503.13694",
    "title": "Branch Prediction Analysis of Morris-Pratt and Knuth-Morris-Pratt Algorithms",
    "abstract": "           We analyze the classical Morris-Pratt and Knuth-Morris-Pratt pattern matching algorithms through the lens of computer architecture, investigating the impact of incorporating a simple branch prediction mechanism into the model of computation. Assuming a fixed pattern and a random text, we derive precise estimates of the number of mispredictions these algorithms produce using local predictors. Our approach is based on automata theory and Markov chains, providing a foundation for the theoretical analysis of other text algorithms and more advanced branch prediction strategies.         ",
    "url": "https://arxiv.org/abs/2503.13694",
    "authors": [
      "Cyril Nicaud",
      "Carine Pivoteau",
      "St\u00e9phane Vialette"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2503.13695",
    "title": "Mitigating Spectral Bias in Neural Operators via High-Frequency Scaling for Physical Systems",
    "abstract": "           Neural operators have emerged as powerful surrogates for modeling complex physical problems. However, they suffer from spectral bias making them oblivious to high-frequency modes, which are present in multiscale physical systems. Therefore, they tend to produce over-smoothed solutions, which is particularly problematic in modeling turbulence and for systems with intricate patterns and sharp gradients such as multi-phase flow systems. In this work, we introduce a new approach named high-frequency scaling (HFS) to mitigate spectral bias in convolutional-based neural operators. By integrating HFS with proper variants of UNet neural operators, we demonstrate a higher prediction accuracy by mitigating spectral bias in single and two-phase flow problems. Unlike Fourier-based techniques, HFS is directly applied to the latent space, thus eliminating the computational cost associated with the Fourier transform. Additionally, we investigate alternative spectral bias mitigation through diffusion models conditioned on neural operators. While the diffusion model integrated with the standard neural operator may still suffer from significant errors, these errors are substantially reduced when the diffusion model is integrated with a HFS-enhanced neural operator.         ",
    "url": "https://arxiv.org/abs/2503.13695",
    "authors": [
      "Siavash Khodakarami",
      "Vivek Oommen",
      "Aniruddha Bora",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2503.13710",
    "title": "Improving Geometric Consistency for 360-Degree Neural Radiance Fields in Indoor Scenarios",
    "abstract": "           Photo-realistic rendering and novel view synthesis play a crucial role in human-computer interaction tasks, from gaming to path planning. Neural Radiance Fields (NeRFs) model scenes as continuous volumetric functions and achieve remarkable rendering quality. However, NeRFs often struggle in large, low-textured areas, producing cloudy artifacts known as ''floaters'' that reduce scene realism, especially in indoor environments with featureless architectural surfaces like walls, ceilings, and floors. To overcome this limitation, prior work has integrated geometric constraints into the NeRF pipeline, typically leveraging depth information derived from Structure from Motion or Multi-View Stereo. Yet, conventional RGB-feature correspondence methods face challenges in accurately estimating depth in textureless regions, leading to unreliable constraints. This challenge is further complicated in 360-degree ''inside-out'' views, where sparse visual overlap between adjacent images further hinders depth estimation. In order to address these issues, we propose an efficient and robust method for computing dense depth priors, specifically tailored for large low-textured architectural surfaces in indoor environments. We introduce a novel depth loss function to enhance rendering quality in these challenging, low-feature regions, while complementary depth-patch regularization further refines depth consistency across other areas. Experiments with Instant-NGP on two synthetic 360-degree indoor scenes demonstrate improved visual fidelity with our method compared to standard photometric loss and Mean Squared Error depth supervision.         ",
    "url": "https://arxiv.org/abs/2503.13710",
    "authors": [
      "Iryna Repinetska",
      "Anna Hilsmann",
      "Peter Eisert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.13733",
    "title": "CoDet-M4: Detecting Machine-Generated Code in Multi-Lingual, Multi-Generator and Multi-Domain Settings",
    "abstract": "           Large language models (LLMs) have revolutionized code generation, automating programming with remarkable efficiency. However, these advancements challenge programming skills, ethics, and assessment integrity, making the detection of LLM-generated code essential for maintaining accountability and standards. While, there has been some research on this problem, it generally lacks domain coverage and robustness, and only covers a small number of programming languages. To this end, we propose a framework capable of distinguishing between human- and LLM-written code across multiple programming languages, code generators, and domains. We use a large-scale dataset from renowned platforms and LLM-based code generators, alongside applying rigorous data quality checks, feature engineering, and comparative analysis using evaluation of traditional machine learning models, pre-trained language models (PLMs), and LLMs for code detection. We perform an evaluation on out-of-domain scenarios, such as detecting the authorship and hybrid authorship of generated code and generalizing to unseen models, domains, and programming languages. Moreover, our extensive experiments show that our framework effectively distinguishes human- from LLM-written code and sets a new benchmark for this task.         ",
    "url": "https://arxiv.org/abs/2503.13733",
    "authors": [
      "Daniil Orel",
      "Dilshod Azizov",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2503.13737",
    "title": "AccelGen: Heterogeneous SLO-Guaranteed High-Throughput LLM Inference Serving for Diverse Applications",
    "abstract": "           In this paper, we consider a mixed-prompt scenario for a large language model (LLM) inference serving system that supports diverse applications with both short prompts and long prompts and heterogeneous SLOs for iteration time. To improve throughput when handling long prompts, previous research introduces a chunking method, but has not addressed heterogeneous SLOs. To address the limitation, we propose AccelGen, a high-throughput LLM inference serving system with heterogeneous SLO guarantees for diverse applications. AccelGen introduces four core components: (1) SLO-guaranteed dynamic chunking, which dynamically adjusts chunk sizes to maximize GPU compute utilization while meeting iteration-level SLOs; (2) Iteration-level SLO-based task prioritization, which prioritizes tight-SLO requests and batches requests with similar SLOs; (3) Multi-resource-aware batching, which selects queued requests to maximize the utilizations of both GPU compute resource and key-value cache (KVC). Trace-driven real experiments demonstrate that AccelGen achieves 1.42-11.21X higher throughput, 1.43-13.71X higher goodput, 37-90% higher SLO attainment, and 1.61-12.22X lower response latency compared to the state-of-the-art approaches. It achieves performance near the Oracle, which optimally maximizes goodput.         ",
    "url": "https://arxiv.org/abs/2503.13737",
    "authors": [
      "Haiying Shen",
      "Tanmoy Sen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2503.13739",
    "title": "Learning from Synchronization: Self-Supervised Uncalibrated Multi-View Person Association in Challenging Scenes",
    "abstract": "           Multi-view person association is a fundamental step towards multi-view analysis of human activities. Although the person re-identification features have been proven effective, they become unreliable in challenging scenes where persons share similar appearances. Therefore, cross-view geometric constraints are required for a more robust association. However, most existing approaches are either fully-supervised using ground-truth identity labels or require calibrated camera parameters that are hard to obtain. In this work, we investigate the potential of learning from synchronization, and propose a self-supervised uncalibrated multi-view person association approach, Self-MVA, without using any annotations. Specifically, we propose a self-supervised learning framework, consisting of an encoder-decoder model and a self-supervised pretext task, cross-view image synchronization, which aims to distinguish whether two images from different views are captured at the same time. The model encodes each person's unified geometric and appearance features, and we train it by utilizing synchronization labels for supervision after applying Hungarian matching to bridge the gap between instance-wise and image-wise distances. To further reduce the solution space, we propose two types of self-supervised linear constraints: multi-view re-projection and pairwise edge association. Extensive experiments on three challenging public benchmark datasets (WILDTRACK, MVOR, and SOLDIERS) show that our approach achieves state-of-the-art results, surpassing existing unsupervised and fully-supervised approaches. Code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2503.13739",
    "authors": [
      "Keqi Chen",
      "Vinkle Srivastav",
      "Didier Mutter",
      "Nicolas Padoy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.13743",
    "title": "MonoCT: Overcoming Monocular 3D Detection Domain Shift with Consistent Teacher Models",
    "abstract": "           We tackle the problem of monocular 3D object detection across different sensors, environments, and camera setups. In this paper, we introduce a novel unsupervised domain adaptation approach, MonoCT, that generates highly accurate pseudo labels for self-supervision. Inspired by our observation that accurate depth estimation is critical to mitigating domain shifts, MonoCT introduces a novel Generalized Depth Enhancement (GDE) module with an ensemble concept to improve depth estimation accuracy. Moreover, we introduce a novel Pseudo Label Scoring (PLS) module by exploring inner-model consistency measurement and a Diversity Maximization (DM) strategy to further generate high-quality pseudo labels for self-training. Extensive experiments on six benchmarks show that MonoCT outperforms existing SOTA domain adaptation methods by large margins (~21% minimum for AP Mod.) and generalizes well to car, traffic camera and drone views.         ",
    "url": "https://arxiv.org/abs/2503.13743",
    "authors": [
      "Johannes Meier",
      "Louis Inchingolo",
      "Oussema Dhaouadi",
      "Yan Xia",
      "Jacques Kaiser",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.13752",
    "title": "Beyond the Individual: A Community-Engaged Framework for Ethical Online Community Research",
    "abstract": "           Online community research routinely poses minimal risk to individuals, but does the same hold true for online communities? In response to high-profile breaches of online community trust and increased debate in the social computing research community on the ethics of online community research, this paper investigates community-level harms and benefits of research. Through 9 participatory-inspired workshops with four critical online communities (Wikipedia, InTheRooms, CaringBridge, and r/AskHistorians) we found researchers should engage more directly with communities' primary purpose by rationalizing their methods and contributions in the context of community goals to equalize the beneficiaries of community research. To facilitate deeper alignment of these expectations, we present the FACTORS (Functions for Action with Communities: Teaching, Overseeing, Reciprocating, and Sustaining) framework for ethical online community research. Finally, we reflect on our findings by providing implications for researchers and online communities to identify and implement functions for navigating community-level harms and benefits.         ",
    "url": "https://arxiv.org/abs/2503.13752",
    "authors": [
      "Matthew Zent",
      "Seraphina Yong",
      "Dhruv Bala",
      "Stevie Chancellor",
      "Joseph A. Konstan",
      "Loren Terveen",
      "Svetlana Yarosh"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2503.13753",
    "title": "Compact routing schemes in undirected and directed graphs",
    "abstract": "           In this paper, we study the problem of compact routing schemes in weighted undirected and directed graphs. For weighted undirected graphs, more than a decade ago, Chechik [PODC 2013] presented a \\(3.68k\\)-stretch compact routing scheme that uses \\(\\tilde{O}(n^{1/k} \\log D)\\) local storage, where \\(D\\) is the normalized diameter, for every \\(k>1\\). We improve the \\(3.68k\\)-stretch to \\(2.64k\\)-stretch by allowing every vertex to use \\(\\tilde{O}(n^{1/k})\\) local storage on average. This resolves a key open question by demonstrating the existence of a routing scheme with stretch \\(c \\cdot k\\) for some constant \\(c<3\\). More than two decades ago, Thorup and Zwick [SPAA 2001] considered compact routing schemes that establish a communication session using a handshake. In their handshake-based compact routing scheme, the handshake is routed along a \\((4k-5)\\)-stretch path, and the rest of the communication session is routed along an optimal \\((2k-1)\\)-stretch path. It is straightforward to improve the \\((4k-5)\\)-stretch path of the handshake to \\(3.68k\\)-stretch using the compact routing scheme of Chechik [PODC 2013]. We improve the handshake stretch to the optimal \\((2k-1)\\), by introducing the concept of roundtrip routing in undirected graphs and developing an optimal \\((2k-1)\\)-stretch compact roundtrip routing scheme, which is of independent interest. For weighted directed graphs, more than two decades ago, Roditty, Thorup, and Zwick [SODA 2002, TALG 2008] presented a \\((4k+\\varepsilon)\\)-stretch compact roundtrip routing scheme that uses \\(\\tilde{O}(n^{1/k})\\) local storage for every \\(k\\ge 3\\). For \\(k=3\\), this gives a \\((12+\\varepsilon)\\)-roundtrip stretch using \\(\\tilde{O}(n^{1/3})\\) local storage. We improve the stretch by developing a \\(7\\)-roundtrip stretch routing scheme with \\(\\tilde{O}(n^{1/3})\\) local storage.         ",
    "url": "https://arxiv.org/abs/2503.13753",
    "authors": [
      "Avi Kadria",
      "Liam Roditty"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2503.13756",
    "title": "Fast alignment of heterogeneous images in sliced Wasserstein distance",
    "abstract": "           Many applications of computer vision rely on the alignment of similar but non-identical images. We present a fast algorithm for aligning heterogeneous images based on optimal transport. Our approach combines the speed of fast Fourier methods with the robustness of sliced probability metrics and allows us to efficiently compute the alignment between two $L \\times L$ images using the sliced 2-Wasserstein distance in $O(L^2 \\log L)$ operations. We show that our method is robust to translations, rotations and deformations in the images.         ",
    "url": "https://arxiv.org/abs/2503.13756",
    "authors": [
      "Yunpeng Shi",
      "Amit Singer",
      "Eric J. Verbeke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2503.13763",
    "title": "Neural Edge Histogram Descriptors for Underwater Acoustic Target Recognition",
    "abstract": "           Numerous maritime applications rely on the ability to recognize acoustic targets using passive sonar. While there is a growing reliance on pre-trained models for classification tasks, these models often require extensive computational resources and may not perform optimally when transferred to new domains due to dataset variations. To address these challenges, this work adapts the neural edge histogram descriptors (NEHD) method originally developed for image classification, to classify passive sonar signals. We conduct a comprehensive evaluation of statistical and structural texture features, demonstrating that their combination achieves competitive performance with large pre-trained models. The proposed NEHD-based approach offers a lightweight and efficient solution for underwater target recognition, significantly reducing computational costs while maintaining accuracy.         ",
    "url": "https://arxiv.org/abs/2503.13763",
    "authors": [
      "Atharva Agashe",
      "Davelle Carreiro",
      "Alexandra Van Dine",
      "Joshua Peeples"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2503.13784",
    "title": "SwarmUpdate: Hierarchical Software Updates and Deep Learning Model Patching for Heterogeneous UAV Swarms",
    "abstract": "           Heterogeneous unmanned aerial vehicle (UAV) swarms consist of dozens to hundreds of drones with different roles and varying hardware and software requirements collaborating towards a shared mission. While traditional approaches for synchronized software updates assume swarms to be unstructured and homogeneous, the heterogeneous nature of modern swarms and the emerging need of drones to update their deep learning (perception) models with new objectives or data as a mission unfolds, has made efficient software update methods crucial for swarms to adapt to dynamic environments. To address these challenges, we introduce the SwarmUpdate framework for software updates in heterogeneous UAV swarms, composed of two key components: SwarmSync and SwarmModelPatch. SwarmSync is a hierarchical software update synchronization strategy to distribute a software update to the right subset of drones within a swarm, while SwarmModelPatch is a deep learning model patching method that reduces the size of a (deep learning model) update by only allowing some layers of the model to be updated (freezing the other layers). In this paper, we systematically evaluate the performance of SwarmSync through large-scale simulations in the ARGoS swarm simulator, comparing SwarmSync to auction-based (SOUL) and gossip-based rebroadcasting (Gossip) baselines, and SwarmModelPatch to a non-incremental model patching strategy.         ",
    "url": "https://arxiv.org/abs/2503.13784",
    "authors": [
      "Lin Geng",
      "Hao Li",
      "Sidney Givigi",
      "Bram Adams"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2503.13794",
    "title": "LED: LLM Enhanced Open-Vocabulary Object Detection without Human Curated Data Generation",
    "abstract": "           Large foundation models trained on large-scale visual-text data can significantly enhance Open Vocabulary Object Detection (OVD) through data generation. However, this may lead to biased synthetic data and overfitting to specific configurations. It can sidestep biases of manually curated data generation by directly leveraging hidden states of Large Language Models (LLMs), which is surprisingly rarely explored. This paper presents a systematic method to enhance visual grounding by utilizing decoder layers of the LLM of a MLLM. We introduce a zero-initialized cross-attention adapter to enable efficient knowledge transfer from LLMs to object detectors, an new approach called LED (LLM Enhanced Open-Vocabulary Object Detection). We demonstrate that intermediate hidden states from early LLM layers retain strong spatial-semantic correlations that are beneficial to grounding tasks. Experiments show that our adaptation strategy significantly enhances the performance on complex free-form text queries while remaining the same on plain categories. With our adaptation, Qwen2-0.5B with Swin-T as the vision encoder improves GroundingDINO by 2.33% on Omnilabel, at the overhead of 8.7% more GFLOPs. Qwen2-0.5B with a larger vision encoder can further boost the performance by 6.22%. We further validate our design by ablating on varied adapter architectures, sizes of LLMs, and which layers to add adaptation.         ",
    "url": "https://arxiv.org/abs/2503.13794",
    "authors": [
      "Yang Zhou",
      "Shiyu Zhao",
      "Yuxiao Chen",
      "Zhenting Wang",
      "Dimitris N. Metaxas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.13798",
    "title": "AI-Powered Prediction of Nanoparticle Pharmacokinetics: A Multi-View Learning Approach",
    "abstract": "           The clinical translation of nanoparticle-based treatments remains limited due to the unpredictability of (nanoparticle) NP pharmacokinetics$\\unicode{x2014}$how they distribute, accumulate, and clear from the body. Predicting these behaviours is challenging due to complex biological interactions and the difficulty of obtaining high-quality experimental datasets. Existing AI-driven approaches rely heavily on data-driven learning but fail to integrate crucial knowledge about NP properties and biodistribution mechanisms. We introduce a multi-view deep learning framework that enhances pharmacokinetic predictions by incorporating prior knowledge of key NP properties such as size and charge into a cross-attention mechanism, enabling context-aware feature selection and improving generalization despite small datasets. To further enhance prediction robustness, we employ an ensemble learning approach, combining deep learning with XGBoost (XGB) and Random Forest (RF), which significantly outperforms existing AI models. Our interpretability analysis reveals key physicochemical properties driving NP biodistribution, providing biologically meaningful insights into possible mechanisms governing NP behaviour in vivo rather than a black-box model. Furthermore, by bridging machine learning with physiologically based pharmacokinetic (PBPK) modelling, this work lays the foundation for data-efficient AI-driven drug discovery and precision nanomedicine.         ",
    "url": "https://arxiv.org/abs/2503.13798",
    "authors": [
      "Amirhossein Khakpour",
      "Lucia Florescu",
      "Richard Tilley",
      "Haibo Jiang",
      "K. Swaminathan Iyer",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.13802",
    "title": "Multi-Harmonic Gridded 3D Deconvolution (MH3D) for Robust and Accurate Image Reconstruction in MPI for Single Axis Drive Field Scanners",
    "abstract": "           This article presents a new robust model for image reconstruction in magnetic particle imaging (MPI) for single-axis drive field scans, which is based on the deconvolution of gridded harmonic data. Gridded harmonic data, used commonly in MPI, does not map to underlying iron density but rather to the iron density convolved with the harmonic point-spread functions. We refer to the gridded harmonic data as harmonic portraits, since they only represent a portrait-like representation of the iron density, and a deconvolution method is implemented to reconstruct the true underlying density. The advantage of this new method is primarily in the intermediate data analysis that comes in the harmonic portrait domain, where we are able to perform artifact correction, parameter selection, and general data assessment and calibrations efficiently. Furthermore, we show with several examples that our new method closely compares qualitatively with current state-of-the-art image reconstruction models in MPI. While the general concept of gridding harmonic data in MPI is not new, the complete modeling and characterization in order to use the data for image reconstruction has remained an ongoing area of research. We provide detailed analysis, theoretical insights, and many nuanced techniques that make our new methodology and algorithm accurate and robust.         ",
    "url": "https://arxiv.org/abs/2503.13802",
    "authors": [
      "Toby Sanders",
      "Justin J. Konkle",
      "Erica E. Mason",
      "Patrick W. Goodwill"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2503.13805",
    "title": "Text-Guided Image Invariant Feature Learning for Robust Image Watermarking",
    "abstract": "           Ensuring robustness in image watermarking is crucial for and maintaining content integrity under diverse transformations. Recent self-supervised learning (SSL) approaches, such as DINO, have been leveraged for watermarking but primarily focus on general feature representation rather than explicitly learning invariant features. In this work, we propose a novel text-guided invariant feature learning framework for robust image watermarking. Our approach leverages CLIP's multimodal capabilities, using text embeddings as stable semantic anchors to enforce feature invariance under distortions. We evaluate the proposed method across multiple datasets, demonstrating superior robustness against various image transformations. Compared to state-of-the-art SSL methods, our model achieves higher cosine similarity in feature consistency tests and outperforms existing watermarking schemes in extraction accuracy under severe distortions. These results highlight the efficacy of our method in learning invariant representations tailored for robust deep learning-based watermarking.         ",
    "url": "https://arxiv.org/abs/2503.13805",
    "authors": [
      "Muhammad Ahtesham",
      "Xin Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2503.13828",
    "title": "Scale-Aware Contrastive Reverse Distillation for Unsupervised Medical Anomaly Detection",
    "abstract": "           Unsupervised anomaly detection using deep learning has garnered significant research attention due to its broad applicability, particularly in medical imaging where labeled anomalous data are scarce. While earlier approaches leverage generative models like autoencoders and generative adversarial networks (GANs), they often fall short due to overgeneralization. Recent methods explore various strategies, including memory banks, normalizing flows, self-supervised learning, and knowledge distillation, to enhance discrimination. Among these, knowledge distillation, particularly reverse distillation, has shown promise. Following this paradigm, we propose a novel scale-aware contrastive reverse distillation model that addresses two key limitations of existing reverse distillation methods: insufficient feature discriminability and inability to handle anomaly scale variations. Specifically, we introduce a contrastive student-teacher learning approach to derive more discriminative representations by generating and exploring out-of-normal distributions. Further, we design a scale adaptation mechanism to softly weight contrastive distillation losses at different scales to account for the scale variation issue. Extensive experiments on benchmark datasets demonstrate state-of-the-art performance, validating the efficacy of the proposed method. Code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2503.13828",
    "authors": [
      "Chunlei Li",
      "Yilei Shi",
      "Jingliang Hu",
      "Xiao Xiang Zhu",
      "Lichao Mou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.13837",
    "title": "Self-Vocabularizing Training for Neural Machine Translation",
    "abstract": "           Past vocabulary learning techniques identify relevant vocabulary before training, relying on statistical and entropy-based assumptions that largely neglect the role of model training. Empirically, we observe that trained translation models are induced to use a byte-pair encoding (BPE) vocabulary subset distinct from the original BPE vocabulary, leading to performance improvements when retrained with the induced vocabulary. In this paper, we analyze this discrepancy in neural machine translation by examining vocabulary and entropy shifts during self-training--where each iteration generates a labeled dataset by pairing source sentences with the model's predictions to define a new vocabulary. Building on these insights, we propose self-vocabularizing training, an iterative method that self-selects a smaller, more optimal vocabulary, yielding up to a 1.49 BLEU improvement. Moreover, we find that deeper model architectures lead to both an increase in unique token usage and a 6-8% reduction in vocabulary size.         ",
    "url": "https://arxiv.org/abs/2503.13837",
    "authors": [
      "Pin-Jie Lin",
      "Ernie Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.13844",
    "title": "Spotting Persuasion: A Low-cost Model for Persuasion Detection in Political Ads on Social Media",
    "abstract": "           In the realm of political advertising, persuasion operates as a pivotal element within the broader framework of propaganda, exerting profound influences on public opinion and electoral outcomes. In this paper, we (1) introduce a lightweight model for persuasive text detection that achieves state-of-the-art performance in Subtask 3 of SemEval 2023 Task 3, while significantly reducing the computational resource requirements; and (2) leverage the proposed model to gain insights into political campaigning strategies on social media platforms by applying it to a real-world dataset we curated, consisting of Facebook political ads from the 2022 Australian Federal election campaign. Our study shows how subtleties can be found in persuasive political advertisements and presents a pragmatic approach to detect and analyze such strategies with limited resources, enhancing transparency in social media political campaigns.         ",
    "url": "https://arxiv.org/abs/2503.13844",
    "authors": [
      "Elyas Meguellati",
      "Stefano Civelli",
      "Pietro Bernardelle",
      "Shazia Sadiq",
      "Gianluca Demartini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.13848",
    "title": "FlexStep: Enabling Flexible Error Detection in Multi/Many-core Real-time Systems",
    "abstract": "           Reliability and real-time responsiveness in safety-critical systems have traditionally been achieved using error detection mechanisms, such as LockStep, which require pre-configured checker cores,strict synchronisation between main and checker cores, static error detection regions, or limited preemption capabilities. However, these core-bound hardware mechanisms often lead to significant resource over-provisioning, and diminished real-time responsiveness, particularly in modern systems where tasks with varying reliability requirements are consolidated on shared processors to improve efficiency, reduce costs, and save power. To address these challenges, this work presents FlexStep, a systematic solution that integrates hardware and software across the SoC, ISA, and OS scheduling layers. FlexStep features a novel microarchitecture that supports dynamic core configuration and asynchronous, preemptive error detection. The FlexStep architecture naturally allows for flexible task scheduling and error detection, enabling new scheduling algorithms that enhance both resource efficiency and real-time schedulability. We publicly release FlexStep's source code, at this https URL.         ",
    "url": "https://arxiv.org/abs/2503.13848",
    "authors": [
      "Tinglue Wang",
      "Yiming Li",
      "Wei Tang",
      "Jiapeng Guan",
      "Zhenghui Guo",
      "Renshuang Jiang",
      "Ran Wei",
      "Jing Li",
      "Zhe Jiang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2503.13862",
    "title": "HySurvPred: Multimodal Hyperbolic Embedding with Angle-Aware Hierarchical Contrastive Learning and Uncertainty Constraints for Survival Prediction",
    "abstract": "           Multimodal learning that integrates histopathology images and genomic data holds great promise for cancer survival prediction. However, existing methods face key limitations: 1) They rely on multimodal mapping and metrics in Euclidean space, which cannot fully capture the hierarchical structures in histopathology (among patches from different resolutions) and genomics data (from genes to pathways). 2) They discretize survival time into independent risk intervals, which ignores its continuous and ordinal nature and fails to achieve effective optimization. 3) They treat censorship as a binary indicator, excluding censored samples from model optimization and not making full use of them. To address these challenges, we propose HySurvPred, a novel framework for survival prediction that integrates three key modules: Multimodal Hyperbolic Mapping (MHM), Angle-aware Ranking-based Contrastive Loss (ARCL) and Censor-Conditioned Uncertainty Constraint (CUC). Instead of relying on Euclidean space, we design the MHM module to explore the inherent hierarchical structures within each modality in hyperbolic space. To better integrate multimodal features in hyperbolic space, we introduce the ARCL module, which uses ranking-based contrastive learning to preserve the ordinal nature of survival time, along with the CUC module to fully explore the censored data. Extensive experiments demonstrate that our method outperforms state-of-the-art methods on five benchmark datasets. The source code is to be released.         ",
    "url": "https://arxiv.org/abs/2503.13862",
    "authors": [
      "Jiaqi Yang",
      "Wenting Chen",
      "Xiaohan Xing",
      "Sean He",
      "Xiaoling Luo",
      "Xinheng Lyu",
      "Linlin Shen",
      "Guoping Qiu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.13869",
    "title": "Robust3D-CIL: Robust Class-Incremental Learning for 3D Perception",
    "abstract": "           3D perception plays a crucial role in real-world applications such as autonomous driving, robotics, and AR/VR. In practical scenarios, 3D perception models must continuously adapt to new data and emerging object categories, but retraining from scratch incurs prohibitive costs. Therefore, adopting class-incremental learning (CIL) becomes particularly essential. However, real-world 3D point cloud data often include corrupted samples, which poses significant challenges for existing CIL methods and leads to more severe forgetting on corrupted data. To address these challenges, we consider the scenario in which a CIL model can be updated using point clouds with unknown corruption to better simulate real-world conditions. Inspired by Farthest Point Sampling, we propose a novel exemplar selection strategy that effectively preserves intra-class diversity when selecting replay exemplars, mitigating forgetting induced by data corruption. Furthermore, we introduce a point cloud downsampling-based replay method to utilize the limited replay buffer memory more efficiently, thereby further enhancing the model's continual learning ability. Extensive experiments demonstrate that our method improves the performance of replay-based CIL baselines by 2% to 11%, proving its effectiveness and promising potential for real-world 3D applications.         ",
    "url": "https://arxiv.org/abs/2503.13869",
    "authors": [
      "Jinge Ma",
      "Jiangpeng He",
      "Fengqing Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.13872",
    "title": "Empirical Calibration and Metric Differential Privacy in Language Models",
    "abstract": "           NLP models trained with differential privacy (DP) usually adopt the DP-SGD framework, and privacy guarantees are often reported in terms of the privacy budget $\\epsilon$. However, $\\epsilon$ does not have any intrinsic meaning, and it is generally not possible to compare across variants of the framework. Work in image processing has therefore explored how to empirically calibrate noise across frameworks using Membership Inference Attacks (MIAs). However, this kind of calibration has not been established for NLP. In this paper, we show that MIAs offer little help in calibrating privacy, whereas reconstruction attacks are more useful. As a use case, we define a novel kind of directional privacy based on the von Mises-Fisher (VMF) distribution, a metric DP mechanism that perturbs angular distance rather than adding (isotropic) Gaussian noise, and apply this to NLP architectures. We show that, even though formal guarantees are incomparable, empirical privacy calibration reveals that each mechanism has different areas of strength with respect to utility-privacy trade-offs.         ",
    "url": "https://arxiv.org/abs/2503.13872",
    "authors": [
      "Pedro Faustini",
      "Natasha Fernandes",
      "Annabelle McIver",
      "Mark Dras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2503.13873",
    "title": "Joint Transmission and Control in a Goal-oriented NOMA Network",
    "abstract": "           Goal-oriented communication shifts the focus from merely delivering timely information to maximizing decision-making effectiveness by prioritizing the transmission of high-value information. In this context, we introduce the Goal-oriented Tensor (GoT), a novel closed-loop metric designed to directly quantify the ultimate utility in Goal-oriented systems, capturing how effectively the transmitted information meets the underlying application's objectives. Leveraging the GoT, we model a Goal-oriented Non-Orthogonal Multiple Access (NOMA) network comprising multiple transmission-control loops. Operating under a pull-based framework, we formulate the joint optimization of transmission and control as a Partially Observable Markov Decision Process (POMDP), which we solve by deriving the belief state and training a Double-Dueling Deep Q-Network (D3QN). This framework enables adaptive decision-making for power allocation and control actions. Simulation results reveal a fundamental trade-off between transmission efficiency and control fidelity. Additionally, the superior utility of NOMA over Orthogonal Multiple Access (OMA) in multi-loop remote control scenarios is demonstrated.         ",
    "url": "https://arxiv.org/abs/2503.13873",
    "authors": [
      "Kunpeng Liu",
      "Shaohua Wu",
      "Aimin Li",
      "Qinyu Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2503.13874",
    "title": "Multi-label feature selection based on binary hashing learning and dynamic graph constraints",
    "abstract": "           Multi-label learning poses significant challenges in extracting reliable supervisory signals from the label space. Existing approaches often employ continuous pseudo-labels to replace binary labels, improving supervisory information representation. However, these methods can introduce noise from irrelevant labels and lead to unreliable graph structures. To overcome these limitations, this study introduces a novel multi-label feature selection method called Binary Hashing and Dynamic Graph Constraint (BHDG), the first method to integrate binary hashing into multi-label learning. BHDG utilizes low-dimensional binary hashing codes as pseudo-labels to reduce noise and improve representation robustness. A dynamically constrained sample projection space is constructed based on the graph structure of these binary pseudo-labels, enhancing the reliability of the dynamic graph. To further enhance pseudo-label quality, BHDG incorporates label graph constraints and inner product minimization within the sample space. Additionally, an $l_{2,1}$-norm regularization term is added to the objective function to facilitate the feature selection process. The augmented Lagrangian multiplier (ALM) method is employed to optimize binary variables effectively. Comprehensive experiments on 10 benchmark datasets demonstrate that BHDG outperforms ten state-of-the-art methods across six evaluation metrics. BHDG achieves the highest overall performance ranking, surpassing the next-best method by an average of at least 2.7 ranks per metric, underscoring its effectiveness and robustness in multi-label feature selection.         ",
    "url": "https://arxiv.org/abs/2503.13874",
    "authors": [
      "Cong Guo",
      "Changqin Huang",
      "Wenhua Zhou",
      "Xiaodi Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.13879",
    "title": "Bridging Social Psychology and LLM Reasoning: Conflict-Aware Meta-Review Generation via Cognitive Alignment",
    "abstract": "           The rapid growth of scholarly submissions has overwhelmed traditional peer review systems, driving the need for intelligent automation to preserve scientific rigor. While large language models (LLMs) show promise in automating manuscript critiques, their ability to synthesize high-stakes meta-reviews, which require conflict-aware reasoning and consensus derivation, remains underdeveloped. Existing methods fail to effectively handle conflicting viewpoints within differing opinions, and often introduce additional cognitive biases, such as anchoring effects and conformity this http URL overcome these limitations, we propose the Cognitive Alignment Framework (CAF), a dual-process architecture that transforms LLMs into adaptive scientific arbitrators. By operationalizing Kahneman's dual-process theory, CAF introduces a three-step cognitive pipeline: review initialization, incremental integration, and cognitive this http URL validation shows that CAF outperforms existing LLM-based methods, with sentiment consistency gains reaching up to 19.47\\% and content consistency improving by as much as 12.95\\%.         ",
    "url": "https://arxiv.org/abs/2503.13879",
    "authors": [
      "Wei Chen",
      "Han Ding",
      "Meng Yuan",
      "Zhao Zhang",
      "Deqing Wang",
      "Fuzhen Zhuang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.13883",
    "title": "YOLO-LLTS: Real-Time Low-Light Traffic Sign Detection via Prior-Guided Enhancement and Multi-Branch Feature Interaction",
    "abstract": "           Detecting traffic signs effectively under low-light conditions remains a significant challenge. To address this issue, we propose YOLO-LLTS, an end-to-end real-time traffic sign detection algorithm specifically designed for low-light environments. Firstly, we introduce the High-Resolution Feature Map for Small Object Detection (HRFM-TOD) module to address indistinct small-object features in low-light scenarios. By leveraging high-resolution feature maps, HRFM-TOD effectively mitigates the feature dilution problem encountered in conventional PANet frameworks, thereby enhancing both detection accuracy and inference speed. Secondly, we develop the Multi-branch Feature Interaction Attention (MFIA) module, which facilitates deep feature interaction across multiple receptive fields in both channel and spatial dimensions, significantly improving the model's information extraction capabilities. Finally, we propose the Prior-Guided Enhancement Module (PGFE) to tackle common image quality challenges in low-light environments, such as noise, low contrast, and blurriness. This module employs prior knowledge to enrich image details and enhance visibility, substantially boosting detection performance. To support this research, we construct a novel dataset, the Chinese Nighttime Traffic Sign Sample Set (CNTSSS), covering diverse nighttime scenarios, including urban, highway, and rural environments under varying weather conditions. Experimental evaluations demonstrate that YOLO-LLTS achieves state-of-the-art performance, outperforming the previous best methods by 2.7% mAP50 and 1.6% mAP50:95 on TT100K-night, 1.3% mAP50 and 1.9% mAP50:95 on CNTSSS, and achieving superior results on the CCTSDB2021 dataset. Moreover, deployment experiments on edge devices confirm the real-time applicability and effectiveness of our proposed approach.         ",
    "url": "https://arxiv.org/abs/2503.13883",
    "authors": [
      "Ziyu Lin",
      "Yunfan Wu",
      "Yuhang Ma",
      "Junzhou Chen",
      "Ronghui Zhang",
      "Jiaming Wu",
      "Guodong Yin",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.13885",
    "title": "COMM:Concentrated Margin Maximization for Robust Document-Level Relation Extraction",
    "abstract": "           Document-level relation extraction (DocRE) is the process of identifying and extracting relations between entities that span multiple sentences within a document. Due to its realistic settings, DocRE has garnered increasing research attention in recent years. Previous research has mostly focused on developing sophisticated encoding models to better capture the intricate patterns between entity pairs. While these advancements are undoubtedly crucial, an even more foundational challenge lies in the data itself. The complexity inherent in DocRE makes the labeling process prone to errors, compounded by the extreme sparsity of positive relation samples, which is driven by both the limited availability of positive instances and the broad diversity of positive relation types. These factors can lead to biased optimization processes, further complicating the task of accurate relation extraction. Recognizing these challenges, we have developed a robust framework called \\textit{\\textbf{COMM}} to better solve DocRE. \\textit{\\textbf{COMM}} operates by initially employing an instance-aware reasoning method to dynamically capture pertinent information of entity pairs within the document and extract relational features. Following this, \\textit{\\textbf{COMM}} takes into account the distribution of relations and the difficulty of samples to dynamically adjust the margins between prediction logits and the decision threshold, a process we call Concentrated Margin Maximization. In this way, \\textit{\\textbf{COMM}} not only enhances the extraction of relevant relational features but also boosts DocRE performance by addressing the specific challenges posed by the data. Extensive experiments and analysis demonstrate the versatility and effectiveness of \\textit{\\textbf{COMM}}, especially its robustness when trained on low-quality data (achieves \\textgreater 10\\% performance gains).         ",
    "url": "https://arxiv.org/abs/2503.13885",
    "authors": [
      "Zhichao Duan",
      "Tengyu Pan",
      "Zhenyu Li",
      "Xiuxing Li",
      "Jianyong Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2503.13895",
    "title": "Exploiting Inherent Class Label: Towards Robust Scribble Supervised Semantic Segmentation",
    "abstract": "           Scribble-based weakly supervised semantic segmentation leverages only a few annotated pixels as labels to train a segmentation model, presenting significant potential for reducing the human labor involved in the annotation process. This approach faces two primary challenges: first, the sparsity of scribble annotations can lead to inconsistent predictions due to limited supervision; second, the variability in scribble annotations, reflecting differing human annotator preferences, can prevent the model from consistently capturing the discriminative regions of objects, potentially leading to unstable predictions. To address these issues, we propose a holistic framework, the class-driven scribble promotion network, for robust scribble-supervised semantic segmentation. This framework not only utilizes the provided scribble annotations but also leverages their associated class labels to generate reliable pseudo-labels. Within the network, we introduce a localization rectification module to mitigate noisy labels and a distance perception module to identify reliable regions surrounding scribble annotations and pseudo-labels. In addition, we introduce new large-scale benchmarks, ScribbleCOCO and ScribbleCityscapes, accompanied by a scribble simulation algorithm that enables evaluation across varying scribble styles. Our method demonstrates competitive performance in both accuracy and robustness, underscoring its superiority over existing approaches. The datasets and the codes will be made publicly available.         ",
    "url": "https://arxiv.org/abs/2503.13895",
    "authors": [
      "Xinliang Zhang",
      "Lei Zhu",
      "Shuang Zeng",
      "Hangzhou He",
      "Ourui Fu",
      "Zhengjian Yao",
      "Zhaoheng Xie",
      "Yanye Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.13903",
    "title": "TGBFormer: Transformer-GraphFormer Blender Network for Video Object Detection",
    "abstract": "           Video object detection has made significant progress in recent years thanks to convolutional neural networks (CNNs) and vision transformers (ViTs). Typically, CNNs excel at capturing local features but struggle to model global representations. Conversely, ViTs are adept at capturing long-range global features but face challenges in representing local feature details. Off-the-shelf video object detection methods solely rely on CNNs or ViTs to conduct feature aggregation, which hampers their capability to simultaneously leverage global and local information, thereby resulting in limited detection performance. In this paper, we propose a Transformer-GraphFormer Blender Network (TGBFormer) for video object detection, with three key technical improvements to fully exploit the advantages of transformers and graph convolutional networks while compensating for their limitations. First, we develop a spatial-temporal transformer module to aggregate global contextual information, constituting global representations with long-range feature dependencies. Second, we introduce a spatial-temporal GraphFormer module that utilizes local spatial and temporal relationships to aggregate features, generating new local representations that are complementary to the transformer outputs. Third, we design a global-local feature blender module to adaptively couple transformer-based global representations and GraphFormer-based local representations. Extensive experiments demonstrate that our TGBFormer establishes new state-of-the-art results on the ImageNet VID dataset. Particularly, our TGBFormer achieves 86.5% mAP while running at around 41.0 FPS on a single Tesla A100 GPU.         ",
    "url": "https://arxiv.org/abs/2503.13903",
    "authors": [
      "Qiang Qi",
      "Xiao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.13906",
    "title": "HSOD-BIT-V2: A New Challenging Benchmarkfor Hyperspectral Salient Object Detection",
    "abstract": "           Salient Object Detection (SOD) is crucial in computer vision, yet RGB-based methods face limitations in challenging scenes, such as small objects and similar color features. Hyperspectral images provide a promising solution for more accurate Hyperspectral Salient Object Detection (HSOD) by abundant spectral information, while HSOD methods are hindered by the lack of extensive and available datasets. In this context, we introduce HSOD-BIT-V2, the largest and most challenging HSOD benchmark dataset to date. Five distinct challenges focusing on small objects and foreground-background similarity are designed to emphasize spectral advantages and real-world complexity. To tackle these challenges, we propose Hyper-HRNet, a high-resolution HSOD network. Hyper-HRNet effectively extracts, integrates, and preserves effective spectral information while reducing dimensionality by capturing the self-similar spectral features. Additionally, it conveys fine details and precisely locates object contours by incorporating comprehensive global information and detailed object saliency representations. Experimental analysis demonstrates that Hyper-HRNet outperforms existing models, especially in challenging scenarios.         ",
    "url": "https://arxiv.org/abs/2503.13906",
    "authors": [
      "Yuhao Qiu",
      "Shuyan Bai",
      "Tingfa Xu",
      "Peifu Liu",
      "Haolin Qin",
      "Jianan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.13909",
    "title": "Quantification of Uncertainties in Probabilistic Deep Neural Network by Implementing Boosting of Variational Inference",
    "abstract": "           Modern neural network architectures have achieved remarkable accuracies but remain highly dependent on their training data, often lacking interpretability in their learned mappings. While effective on large datasets, they tend to overfit on smaller ones. Probabilistic neural networks, such as those utilizing variational inference, address this limitation by incorporating uncertainty estimation through weight distributions rather than point estimates. However, standard variational inference often relies on a single-density approximation, which can lead to poor posterior estimates and hinder model performance. We propose Boosted Bayesian Neural Networks (BBNN), a novel approach that enhances neural network weight distribution approximations using Boosting Variational Inference (BVI). By iteratively constructing a mixture of densities, BVI expands the approximating family, enabling a more expressive posterior that leads to improved generalization and uncertainty estimation. While this approach increases computational complexity, it significantly enhances accuracy an essential tradeoff, particularly in high-stakes applications such as medical diagnostics, where false negatives can have severe consequences. Our experimental results demonstrate that BBNN achieves ~5% higher accuracy compared to conventional neural networks while providing superior uncertainty quantification. This improvement highlights the effectiveness of leveraging a mixture-based variational family to better approximate the posterior distribution, ultimately advancing probabilistic deep learning.         ",
    "url": "https://arxiv.org/abs/2503.13909",
    "authors": [
      "Pavia Bera",
      "Sanjukta Bhanja"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2503.13911",
    "title": "Incorporating Attributes and Multi-Scale Structures for Heterogeneous Graph Contrastive Learning",
    "abstract": "           Heterogeneous graphs (HGs) are composed of multiple types of nodes and edges, making it more effective in capturing the complex relational structures inherent in the real world. However, in real-world scenarios, labeled data is often difficult to obtain, which limits the applicability of semi-supervised approaches. Self-supervised learning aims to enable models to automatically learn useful features from data, effectively addressing the challenge of limited labeling data. In this paper, we propose a novel contrastive learning framework for heterogeneous graphs (ASHGCL), which incorporates three distinct views, each focusing on node attributes, high-order and low-order structural information, respectively, to effectively capture attribute information, high-order structures, and low-order structures for node representation learning. Furthermore, we introduce an attribute-enhanced positive sample selection strategy that combines both structural information and attribute information, effectively addressing the issue of sampling bias. Extensive experiments on four real-world datasets show that ASHGCL outperforms state-of-the-art unsupervised baselines and even surpasses some supervised benchmarks.         ",
    "url": "https://arxiv.org/abs/2503.13911",
    "authors": [
      "Ruobing Jiang",
      "Yacong Li",
      "Haobing Liu",
      "Yanwei Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2503.13912",
    "title": "KANITE: Kolmogorov-Arnold Networks for ITE estimation",
    "abstract": "           We introduce KANITE, a framework leveraging Kolmogorov-Arnold Networks (KANs) for Individual Treatment Effect (ITE) estimation under multiple treatments setting in causal inference. By utilizing KAN's unique abilities to learn univariate activation functions as opposed to learning linear weights by Multi-Layer Perceptrons (MLPs), we improve the estimates of ITEs. The KANITE framework comprises two key architectures: this http URL Probability Metric (IPM) architecture: This employs an IPM loss in a specialized manner to effectively align towards ITE estimation across multiple treatments. 2. Entropy Balancing (EB) architecture: This uses weights for samples that are learned by optimizing entropy subject to balancing the covariates across treatment groups. Extensive evaluations on benchmark datasets demonstrate that KANITE outperforms state-of-the-art algorithms in both $\\epsilon_{\\text{PEHE}}$ and $\\epsilon_{\\text{ATE}}$ metrics. Our experiments highlight the advantages of KANITE in achieving improved causal estimates, emphasizing the potential of KANs to advance causal inference methodologies across diverse application areas.         ",
    "url": "https://arxiv.org/abs/2503.13912",
    "authors": [
      "Eshan Mehendale",
      "Abhinav Thorat",
      "Ravi Kolla",
      "Niranjan Pedanekar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2503.13914",
    "title": "PSA-SSL: Pose and Size-aware Self-Supervised Learning on LiDAR Point Clouds",
    "abstract": "           Self-supervised learning (SSL) on 3D point clouds has the potential to learn feature representations that can transfer to diverse sensors and multiple downstream perception tasks. However, recent SSL approaches fail to define pretext tasks that retain geometric information such as object pose and scale, which can be detrimental to the performance of downstream localization and geometry-sensitive 3D scene understanding tasks, such as 3D semantic segmentation and 3D object detection. We propose PSA-SSL, a novel extension to point cloud SSL that learns object pose and size-aware (PSA) features. Our approach defines a self-supervised bounding box regression pretext task, which retains object pose and size information. Furthermore, we incorporate LiDAR beam pattern augmentation on input point clouds, which encourages learning sensor-agnostic features. Our experiments demonstrate that with a single pretrained model, our light-weight yet effective extensions achieve significant improvements on 3D semantic segmentation with limited labels across popular autonomous driving datasets (Waymo, nuScenes, SemanticKITTI). Moreover, our approach outperforms other state-of-the-art SSL methods on 3D semantic segmentation (using up to 10 times less labels), as well as on 3D object detection. Our code will be released on this https URL.         ",
    "url": "https://arxiv.org/abs/2503.13914",
    "authors": [
      "Barza Nisar",
      "Steven L. Waslander"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.13917",
    "title": "Robust Machine Unlearning for Quantized Neural Networks via Adaptive Gradient Reweighting with Similar Labels",
    "abstract": "           Model quantization enables efficient deployment of deep neural networks on edge devices through low-bit parameter representation, yet raises critical challenges for implementing machine unlearning (MU) under data privacy regulations. Existing MU methods designed for full-precision models fail to address two fundamental limitations in quantized networks: 1) Noise amplification from label mismatch during data processing, and 2) Gradient imbalance between forgotten and retained data during training. These issues are exacerbated by quantized models' constrained parameter space and discrete optimization. We propose Q-MUL, the first dedicated unlearning framework for quantized models. Our method introduces two key innovations: 1) Similar Labels assignment replaces random labels with semantically consistent alternatives to minimize noise injection, and 2) Adaptive Gradient Reweighting dynamically aligns parameter update contributions from forgotten and retained data. Through systematic analysis of quantized model vulnerabilities, we establish theoretical foundations for these mechanisms. Extensive evaluations on benchmark datasets demonstrate Q-MUL's superiority over existing approaches.         ",
    "url": "https://arxiv.org/abs/2503.13917",
    "authors": [
      "Yujia Tong",
      "Yuze Wang",
      "Jingling Yuan",
      "Chuang Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.13934",
    "title": "COLSON: Controllable Learning-Based Social Navigation via Diffusion-Based Reinforcement Learning",
    "abstract": "           Mobile robot navigation in dynamic environments with pedestrian traffic is a key challenge in the development of autonomous mobile service robots. Recently, deep reinforcement learning-based methods have been actively studied and have outperformed traditional rule-based approaches owing to their optimization capabilities. Among these, methods that assume a continuous action space typically rely on a Gaussian distribution assumption, which limits the flexibility of generated actions. Meanwhile, the application of diffusion models to reinforcement learning has advanced, allowing for more flexible action distributions compared with Gaussian distribution-based approaches. In this study, we applied a diffusion-based reinforcement learning approach to social navigation and validated its effectiveness. Furthermore, by leveraging the characteristics of diffusion models, we propose an extension that enables post-training action smoothing and adaptation to static obstacle scenarios not considered during the training steps.         ",
    "url": "https://arxiv.org/abs/2503.13934",
    "authors": [
      "Yuki Tomita",
      "Kohei Matsumoto",
      "Yuki Hyodo",
      "Ryo Kurazume"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.13940",
    "title": "Multi-Modal Self-Supervised Semantic Communication",
    "abstract": "           Semantic communication is emerging as a promising paradigm that focuses on the extraction and transmission of semantic meanings using deep learning techniques. While current research primarily addresses the reduction of semantic communication overhead, it often overlooks the training phase, which can incur significant communication costs in dynamic wireless environments. To address this challenge, we propose a multi-modal semantic communication system that leverages multi-modal self-supervised learning to enhance task-agnostic feature extraction. The proposed approach employs self-supervised learning during the pre-training phase to extract task-agnostic semantic features, followed by supervised fine-tuning for downstream tasks. This dual-phase strategy effectively captures both modality-invariant and modality-specific features while minimizing training-related communication overhead. Experimental results on the NYU Depth V2 dataset demonstrate that the proposed method significantly reduces training-related communication overhead while maintaining or exceeding the performance of existing supervised learning approaches. The findings underscore the advantages of multi-modal self-supervised learning in semantic communication, paving the way for more efficient and scalable edge inference systems.         ",
    "url": "https://arxiv.org/abs/2503.13940",
    "authors": [
      "Hang Zhao",
      "Hongru Li",
      "Dongfang Xu",
      "Shenghui Song",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2503.13942",
    "title": "Structured Knowledge Accumulation: An Autonomous Framework for Layer-Wise Entropy Reduction in Neural Learning",
    "abstract": "           We introduce the Structured Knowledge Accumulation (SKA) framework, which reinterprets entropy as a dynamic, layer-wise measure of knowledge alignment in neural networks. Instead of relying on traditional gradient-based optimization, SKA defines entropy in terms of knowledge vectors and their influence on decision probabilities across multiple layers. This formulation naturally leads to the emergence of activation functions such as the sigmoid as a consequence of entropy minimization. Unlike conventional backpropagation, SKA allows each layer to optimize independently by aligning its knowledge representation with changes in decision probabilities. As a result, total network entropy decreases in a hierarchical manner, allowing knowledge structures to evolve progressively. This approach provides a scalable, biologically plausible alternative to gradient-based learning, bridging information theory and artificial intelligence while offering promising applications in resource-constrained and parallel computing environments.         ",
    "url": "https://arxiv.org/abs/2503.13942",
    "authors": [
      "Bouarfa Mahi Quantiota"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2503.13947",
    "title": "Conformal Prediction and MLLM aided Uncertainty Quantification in Scene Graph Generation",
    "abstract": "           Scene Graph Generation (SGG) aims to represent visual scenes by identifying objects and their pairwise relationships, providing a structured understanding of image content. However, inherent challenges like long-tailed class distributions and prediction variability necessitate uncertainty quantification in SGG for its practical viability. In this paper, we introduce a novel Conformal Prediction (CP) based framework, adaptive to any existing SGG method, for quantifying their predictive uncertainty by constructing well-calibrated prediction sets over their generated scene graphs. These scene graph prediction sets are designed to achieve statistically rigorous coverage guarantees. Additionally, to ensure these prediction sets contain the most practically interpretable scene graphs, we design an effective MLLM-based post-processing strategy for selecting the most visually and semantically plausible scene graphs within these prediction sets. We show that our proposed approach can produce diverse possible scene graphs from an image, assess the reliability of SGG methods, and improve overall SGG performance.         ",
    "url": "https://arxiv.org/abs/2503.13947",
    "authors": [
      "Sayak Nag",
      "Udita Ghosh",
      "Sarosij Bose",
      "Calvin-Khang Ta",
      "Jiachen Li",
      "Amit K Roy Chowdhury"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.13951",
    "title": "FrustumFusionNets: A Three-Dimensional Object Detection Network Based on Tractor Road Scene",
    "abstract": "           To address the issues of the existing frustum-based methods' underutilization of image information in road three-dimensional object detection as well as the lack of research on agricultural scenes, we constructed an object detection dataset using an 80-line Light Detection And Ranging (LiDAR) and a camera in a complex tractor road scene and proposed a new network called FrustumFusionNets (FFNets). Initially, we utilize the results of image-based two-dimensional object detection to narrow down the search region in the three-dimensional space of the point cloud. Next, we introduce a Gaussian mask to enhance the point cloud information. Then, we extract the features from the frustum point cloud and the crop image using the point cloud feature extraction pipeline and the image feature extraction pipeline, respectively. Finally, we concatenate and fuse the data features from both modalities to achieve three-dimensional object detection. Experiments demonstrate that on the constructed test set of tractor road data, the FrustumFusionNetv2 achieves 82.28% and 95.68% accuracy in the three-dimensional object detection of the two main road objects, cars and people, respectively. This performance is 1.83% and 2.33% better than the original model. It offers a hybrid fusion-based multi-object, high-precision, real-time three-dimensional object detection technique for unmanned agricultural machines in tractor road scenarios. On the Karlsruhe Institute of Technology and Toyota Technological Institute (KITTI) Benchmark Suite validation set, the FrustumFusionNetv2 also demonstrates significant superiority in detecting road pedestrian objects compared with other frustum-based three-dimensional object detection methods.         ",
    "url": "https://arxiv.org/abs/2503.13951",
    "authors": [
      "Lili Yang",
      "Mengshuai Chang",
      "Xiao Guo",
      "Yuxin Feng",
      "Yiwen Mei",
      "Caicong Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.13954",
    "title": "Enhanced High-Dimensional Data Visualization through Adaptive Multi-Scale Manifold Embedding",
    "abstract": "           To address the dual challenges of the curse of dimensionality and the difficulty in separating intra-cluster and inter-cluster structures in high-dimensional manifold embedding, we proposes an Adaptive Multi-Scale Manifold Embedding (AMSME) algorithm. By introducing ordinal distance to replace traditional Euclidean distances, we theoretically demonstrate that ordinal distance overcomes the constraints of the curse of dimensionality in high-dimensional spaces, effectively distinguishing heterogeneous samples. We design an adaptive neighborhood adjustment method to construct similarity graphs that simultaneously balance intra-cluster compactness and inter-cluster separability. Furthermore, we develop a two-stage embedding framework: the first stage achieves preliminary cluster separation while preserving connectivity between structurally similar clusters via the similarity graph, and the second stage enhances inter-cluster separation through a label-driven distance reweighting. Experimental results demonstrate that AMSME significantly preserves intra-cluster topological structures and improves inter-cluster separation on real-world datasets. Additionally, leveraging its multi-resolution analysis capability, AMSME discovers novel neuronal subtypes in the mouse lumbar dorsal root ganglion scRNA-seq dataset, with marker gene analysis revealing their distinct biological roles.         ",
    "url": "https://arxiv.org/abs/2503.13954",
    "authors": [
      "Tianhao Ni",
      "Bingjie Li",
      "Zhigang Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.13957",
    "title": "DIFFVSGG: Diffusion-Driven Online Video Scene Graph Generation",
    "abstract": "           Top-leading solutions for Video Scene Graph Generation (VSGG) typically adopt an offline pipeline. Though demonstrating promising performance, they remain unable to handle real-time video streams and consume large GPU memory. Moreover, these approaches fall short in temporal reasoning, merely aggregating frame-level predictions over a temporal context. In response, we introduce DIFFVSGG, an online VSGG solution that frames this task as an iterative scene graph update problem. Drawing inspiration from Latent Diffusion Models (LDMs) which generate images via denoising a latent feature embedding, we unify the decoding of object classification, bounding box regression, and graph generation three tasks using one shared feature embedding. Then, given an embedding containing unified features of object pairs, we conduct a step-wise Denoising on it within LDMs, so as to deliver a clean embedding which clearly indicates the relationships between objects. This embedding then serves as the input to task-specific heads for object classification, scene graph generation, etc. DIFFVSGG further facilitates continuous temporal reasoning, where predictions for subsequent frames leverage results of past frames as the conditional inputs of LDMs, to guide the reverse diffusion process for current frames. Extensive experiments on three setups of Action Genome demonstrate the superiority of DIFFVSGG.         ",
    "url": "https://arxiv.org/abs/2503.13957",
    "authors": [
      "Mu Chen",
      "Liulei Li",
      "Wenguan Wang",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.13962",
    "title": "Survey of Adversarial Robustness in Multimodal Large Language Models",
    "abstract": "           Multimodal Large Language Models (MLLMs) have demonstrated exceptional performance in artificial intelligence by facilitating integrated understanding across diverse modalities, including text, images, video, audio, and speech. However, their deployment in real-world applications raises significant concerns about adversarial vulnerabilities that could compromise their safety and reliability. Unlike unimodal models, MLLMs face unique challenges due to the interdependencies among modalities, making them susceptible to modality-specific threats and cross-modal adversarial manipulations. This paper reviews the adversarial robustness of MLLMs, covering different modalities. We begin with an overview of MLLMs and a taxonomy of adversarial attacks tailored to each modality. Next, we review key datasets and evaluation metrics used to assess the robustness of MLLMs. After that, we provide an in-depth review of attacks targeting MLLMs across different modalities. Our survey also identifies critical challenges and suggests promising future research directions.         ",
    "url": "https://arxiv.org/abs/2503.13962",
    "authors": [
      "Chengze Jiang",
      "Zhuangzhuang Wang",
      "Minjing Dong",
      "Jie Gui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.13969",
    "title": "SoccerSynth Field: enhancing field detection with synthetic data from virtual soccer simulator",
    "abstract": "           Field detection in team sports is an essential task in sports video analysis. However, collecting large-scale and diverse real-world datasets for training detection models is often cost and time-consuming. Synthetic datasets, which allow controlled variability in lighting, textures, and camera angles, will be a promising alternative for addressing these problems. This study addresses the challenges of high costs and difficulties in collecting real-world datasets by investigating the effectiveness of pretraining models using synthetic datasets. In this paper, we propose the effectiveness of using a synthetic dataset (SoccerSynth-Field) for soccer field detection. A synthetic soccer field dataset was created to pretrain models, and the performance of these models was compared with models trained on real-world datasets. The results demonstrate that models pretrained on the synthetic dataset exhibit superior performance in detecting soccer fields. This highlights the effectiveness of synthetic data in enhancing model robustness and accuracy, offering a cost-effective and scalable solution for advancing detection tasks in sports field detection.         ",
    "url": "https://arxiv.org/abs/2503.13969",
    "authors": [
      "HaoBin Qin",
      "Jiale Fang",
      "Keisuke Fujii"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.13991",
    "title": "GraphTEN: Graph Enhanced Texture Encoding Network",
    "abstract": "           Texture recognition is a fundamental problem in computer vision and pattern recognition. Recent progress leverages feature aggregation into discriminative descriptions based on convolutional neural networks (CNNs). However, modeling non-local context relations through visual primitives remains challenging due to the variability and randomness of texture primitives in spatial distributions. In this paper, we propose a graph-enhanced texture encoding network (GraphTEN) designed to capture both local and global features of texture primitives. GraphTEN models global associations through fully connected graphs and captures cross-scale dependencies of texture primitives via bipartite graphs. Additionally, we introduce a patch encoding module that utilizes a codebook to achieve an orderless representation of texture by encoding multi-scale patch features into a unified feature space. The proposed GraphTEN achieves superior performance compared to state-of-the-art methods across five publicly available datasets.         ",
    "url": "https://arxiv.org/abs/2503.13991",
    "authors": [
      "Bo Peng",
      "Jintao Chen",
      "Mufeng Yao",
      "Chenhao Zhang",
      "Jianghui Zhang",
      "Mingmin Chi",
      "Jiang Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.13992",
    "title": "The KoLMogorov Test: Compression by Code Generation",
    "abstract": "           Compression is at the heart of intelligence. A theoretically optimal way to compress any sequence of data is to find the shortest program that outputs that sequence and then halts. However, such 'Kolmogorov compression' is uncomputable, and code generating LLMs struggle to approximate this theoretical ideal, as it requires reasoning, planning and search capabilities beyond those of current models. In this work, we introduce the KoLMogorov-Test (KT), a compression-as-intelligence test for code generating LLMs. In KT a model is presented with a sequence of data at inference time, and asked to generate the shortest program that produces the sequence. We identify several benefits of KT for both evaluation and training: an essentially infinite number of problem instances of varying difficulty is readily available, strong baselines already exist, the evaluation metric (compression) cannot be gamed, and pretraining data contamination is highly unlikely. To evaluate current models, we use audio, text, and DNA data, as well as sequences produced by random synthetic programs. Current flagship models perform poorly - both GPT4-o and Llama-3.1-405B struggle on our natural and synthetic sequences. On our synthetic distribution, we are able to train code generation models with lower compression rates than previous approaches. Moreover, we show that gains on synthetic data generalize poorly to real data, suggesting that new innovations are necessary for additional gains on KT.         ",
    "url": "https://arxiv.org/abs/2503.13992",
    "authors": [
      "Ori Yoran",
      "Kunhao Zheng",
      "Fabian Gloeckle",
      "Jonas Gehring",
      "Gabriel Synnaeve",
      "Taco Cohen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2503.13996",
    "title": "Robust Safety Critical Control Under Multiple State and Input Constraints: Volume Control Barrier Function Method",
    "abstract": "           In this paper, the safety-critical control problem for uncertain systems under multiple control barrier function (CBF) constraints and input constraints is investigated. A novel framework is proposed to generate a safety filter that minimizes changes to reference inputs when safety risks arise, ensuring a balance between safety and performance. A nonlinear disturbance observer (DOB) based on the robust integral of the sign of the error (RISE) is used to estimate system uncertainties, ensuring that the estimation error converges to zero exponentially. This error bound is integrated into the safety-critical controller to reduce conservativeness while ensuring safety. To further address the challenges arising from multiple CBF and input constraints, a novel Volume CBF (VCBF) is proposed by analyzing the feasible space of the quadratic programming (QP) problem. % ensuring solution feasibility by keeping the volume as a positive value. To ensure that the feasible space does not vanish under disturbances, a DOB-VCBF-based method is introduced, ensuring system safety while maintaining the feasibility of the resulting QP. Subsequently, several groups of simulation and experimental results are provided to validate the effectiveness of the proposed controller.         ",
    "url": "https://arxiv.org/abs/2503.13996",
    "authors": [
      "Jinyang Dong",
      "Shizhen Wu",
      "Rui Liu",
      "Xiao Liang",
      "Biao Lu",
      "Yongchun Fang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2503.13998",
    "title": "Augmenting Software Bills of Materials with Software Vulnerability Description: A Preliminary Study on GitHub",
    "abstract": "           Software Bills of Material (SBOMs) are becoming a consolidated, often enforced by governmental regulations, way to describe software composition. However, based on recent studies, SBOMs suffer from limited support for their consumption and lack information beyond simple dependencies, especially regarding software vulnerabilities. This paper reports the results of a preliminary study in which we augmented SBOMs of 40 open-source projects with information about Common Vulnerabilities and Exposures (CVE) exposed by project dependencies. Our augmented SBOMs have been evaluated by submitting pull requests and by asking project owners to answer a survey. Although, in most cases, augmented SBOMs were not directly accepted because owners required a continuous SBOM update, the received feedback shows the usefulness of the suggested SBOM augmentation.         ",
    "url": "https://arxiv.org/abs/2503.13998",
    "authors": [
      "Davide Fucci",
      "Massimiliano Di Penta",
      "Simone Romano",
      "Giuseppe Scannielllo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2503.13999",
    "title": "BI-RADS prediction of mammographic masses using uncertainty information extracted from a Bayesian Deep Learning model",
    "abstract": "           The BI_RADS score is a probabilistic reporting tool used by radiologists to express the level of uncertainty in predicting breast cancer based on some morphological features in mammography images. There is a significant variability in describing masses which sometimes leads to BI_RADS misclassification. Using a BI_RADS prediction system is required to support the final radiologist decisions. In this study, the uncertainty information extracted by a Bayesian deep learning model is utilized to predict the BI_RADS score. The investigation results based on the pathology information demonstrate that the f1-scores of the predictions of the radiologist are 42.86%, 48.33% and 48.28%, meanwhile, the f1-scores of the model performance are 73.33%, 59.60% and 59.26% in the BI_RADS 2, 3 and 5 dataset samples, respectively. Also, the model can distinguish malignant from benign samples in the BI_RADS 0 category of the used dataset with an accuracy of 75.86% and correctly identify all malignant samples as BI_RADS 5. The Grad-CAM visualization shows the model pays attention to the morphological features of the lesions. Therefore, this study shows the uncertainty-aware Bayesian Deep Learning model can report his uncertainty about the malignancy of a lesion based on morphological features, like a radiologist.         ",
    "url": "https://arxiv.org/abs/2503.13999",
    "authors": [
      "Mohaddeseh Chegini",
      "Ali Mahloojifar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.14001",
    "title": "Multimodal Feature-Driven Deep Learning for the Prediction of Duck Body Dimensions and Weight",
    "abstract": "           Accurate body dimension and weight measurements are critical for optimizing poultry management, health assessment, and economic efficiency. This study introduces an innovative deep learning-based model leveraging multimodal data-2D RGB images from different views, depth images, and 3D point clouds-for the non-invasive estimation of duck body dimensions and weight. A dataset of 1,023 Linwu ducks, comprising over 5,000 samples with diverse postures and conditions, was collected to support model training. The proposed method innovatively employs PointNet++ to extract key feature points from point clouds, extracts and computes corresponding 3D geometric features, and fuses them with multi-view convolutional 2D features. A Transformer encoder is then utilized to capture long-range dependencies and refine feature interactions, thereby enhancing prediction robustness. The model achieved a mean absolute percentage error (MAPE) of 6.33% and an R2 of 0.953 across eight morphometric parameters, demonstrating strong predictive capability. Unlike conventional manual measurements, the proposed model enables high-precision estimation while eliminating the necessity for physical handling, thereby reducing animal stress and broadening its application scope. This study marks the first application of deep learning techniques to poultry body dimension and weight estimation, providing a valuable reference for the intelligent and precise management of the livestock industry with far-reaching practical significance.         ",
    "url": "https://arxiv.org/abs/2503.14001",
    "authors": [
      "Yi Xiao",
      "Qiannan Han",
      "Guiping Liang",
      "Hongyan Zhang",
      "Song Wang",
      "Zhihao Xu",
      "Weican Wan",
      "Chuang Li",
      "Guitao Jiang",
      "Wenbo Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.14012",
    "title": "LEGNet: Lightweight Edge-Gaussian Driven Network for Low-Quality Remote Sensing Image Object Detection",
    "abstract": "           Remote sensing object detection (RSOD) faces formidable challenges in complex visual environments. Aerial and satellite images inherently suffer from limitations such as low spatial resolution, sensor noise, blurred objects, low-light degradation, and partial occlusions. These degradation factors collectively compromise the feature discriminability in detection models, resulting in three key issues: (1) reduced contrast that hampers foreground-background separation, (2) structural discontinuities in edge representations, and (3) ambiguous feature responses caused by variations in illumination. These collectively weaken model robustness and deployment feasibility. To address these challenges, we propose LEGNet, a lightweight network that incorporates a novel edge-Gaussian aggregation (EGA) module specifically designed for low-quality remote sensing images. Our key innovation lies in the synergistic integration of Scharr operator-based edge priors with uncertainty-aware Gaussian modeling: (a) The orientation-aware Scharr filters preserve high-frequency edge details with rotational invariance; (b) The uncertainty-aware Gaussian layers probabilistically refine low-confidence features through variance estimation. This design enables precision enhancement while maintaining architectural simplicity. Comprehensive evaluations across four RSOD benchmarks (DOTA-v1.0, v1.5, DIOR-R, FAIR1M-v1.0) and a UAV-view dataset (VisDrone2019) demonstrate significant improvements. LEGNet achieves state-of-the-art performance across five benchmark datasets while ensuring computational efficiency, making it well-suited for deployment on resource-constrained edge devices in real-world remote sensing applications. The code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2503.14012",
    "authors": [
      "Wei Lu",
      "Si-Bao Chen",
      "Hui-Dong Li",
      "Qing-Ling Shu",
      "Chris H. Q. Ding",
      "Jin Tang",
      "Bin Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.14023",
    "title": "Synthetic Data Generation Using Large Language Models: Advances in Text and Code",
    "abstract": "           Large language models (LLMs) have unlocked new possibilities for generating synthetic training data in both natural language and code. By producing artificial but task-relevant examples, these models can significantly augment or even replace real-world datasets, especially when labeled data is scarce or sensitive. This paper surveys recent advances in using LLMs to create synthetic text and code, emphasizing prompt-based generation, retrieval-augmented pipelines, and iterative self-refinement. We show how these methods enrich low-resource tasks such as classification and question answering, as well as code-centric applications such as instruction tuning, code translation, and bug repair, by enabling automated verification of functional correctness. Alongside potential benefits like cost-effectiveness, broad coverage, and controllable diversity, we address challenges such as factual inaccuracies in generated text, lack of stylistic realism, and the risk of bias amplification. Proposed mitigations include filtering and weighting outputs and reinforcement learning with execution feedback for code. We conclude with open research directions like automated prompt engineering, cross-modal data synthesis, and robust evaluation frameworks, highlighting the importance of LLM-generated synthetic data in advancing AI while emphasizing ethical and quality safeguards.         ",
    "url": "https://arxiv.org/abs/2503.14023",
    "authors": [
      "Mihai Nadas",
      "Laura Diosan",
      "Andreea Tomescu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2503.14035",
    "title": "A Revisit to the Decoder for Camouflaged Object Detection",
    "abstract": "           Camouflaged object detection (COD) aims to generate a fine-grained segmentation map of camouflaged objects hidden in their background. Due to the hidden nature of camouflaged objects, it is essential for the decoder to be tailored to effectively extract proper features of camouflaged objects and extra-carefully generate their complex boundaries. In this paper, we propose a novel architecture that augments the prevalent decoding strategy in COD with Enrich Decoder and Retouch Decoder, which help to generate a fine-grained segmentation map. Specifically, the Enrich Decoder amplifies the channels of features that are important for COD using channel-wise attention. Retouch Decoder further refines the segmentation maps by spatially attending to important pixels, such as the boundary regions. With extensive experiments, we demonstrate that ENTO shows superior performance using various encoders, with the two novel components playing their unique roles that are mutually complementary.         ",
    "url": "https://arxiv.org/abs/2503.14035",
    "authors": [
      "Seung Woo Ko",
      "Joopyo Hong",
      "Suyoung Kim",
      "Seungjai Bang",
      "Sungzoon Cho",
      "Nojun Kwak",
      "Hyung-Sin Kim",
      "Joonseok Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.14049",
    "title": "A Modular Edge Device Network for Surgery Digitalization",
    "abstract": "           Future surgical care demands real-time, integrated data to drive informed decision-making and improve patient outcomes. The pressing need for seamless and efficient data capture in the OR motivates our development of a modular solution that bridges the gap between emerging machine learning techniques and interventional medicine. We introduce a network of edge devices, called Data Hubs (DHs), that interconnect diverse medical sensors, imaging systems, and robotic tools via optical fiber and a centralized network switch. Built on the NVIDIA Jetson Orin NX, each DH supports multiple interfaces (HDMI, USB-C, Ethernet) and encapsulates device-specific drivers within Docker containers using the Isaac ROS framework and ROS2. A centralized user interface enables straightforward configuration and real-time monitoring, while an Nvidia DGX computer provides state-of-the-art data processing and storage. We validate our approach through an ultrasound-based 3D anatomical reconstruction experiment that combines medical imaging, pose tracking, and RGB-D data acquisition.         ",
    "url": "https://arxiv.org/abs/2503.14049",
    "authors": [
      "Vincent Schorp",
      "Fr\u00e9d\u00e9ric Giraud",
      "Gianluca Parg\u00e4tzi",
      "Michael W\u00e4spe",
      "Lorenzo von Ritter-Zahony",
      "Marcel Wegmann",
      "John Garcia Henao",
      "Dominique Cachin",
      "Sebastiano Caprara",
      "Philipp F\u00fcrnstahl",
      "Fabio Carrillo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Hardware Architecture (cs.AR)",
      "Human-Computer Interaction (cs.HC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2503.14063",
    "title": "Effect of Hotspot Traffic on Blocking Probability in Elastic Optical Networks",
    "abstract": "           In a circuit-switched network, traffic can be characterized by several factors that define how communication resources are allocated and utilized during a connection. The amount of traffic basically determines how frequently connection requests arrive, how long the setup connection remains active, and the bandwidth used. The Poisson Arrival Process models traffic arrival events at random intervals. It assumes that events happen independently of one another. This model is ideal for simulating traffic in networks where arrivals happen independently and randomly, such as the start of phone calls, data requests, or packet transmissions. The Poisson Arrival Process and uniformly choosing source and destination pair is been used most commonly by researchers to generate traffic in a network to test various promising routing and spectrum assignment algorithms. It checks the algorithm in uniformly loaded conditions and estimate its baseline performance. In real real-world scenario, a bunch of network nodes can start experiencing heavy data traffic compared to the rest of the network. This can lead to latency issues, or even outages if the network is not optimized to handle the load at these nodes which are also called hotspots. In other terms, hotspot in a network is an area or set of nodes within the network that have a higher likelihood of being involved in communication or data transmission compared to other areas. In this paper, we have tried to find what are the various factors involved in increasing the blocking probability in hotspot traffic scenarios. We have also compared the results with the uniform traffic load conditions in same topology.         ",
    "url": "https://arxiv.org/abs/2503.14063",
    "authors": [
      "Paresh Upadhyay",
      "Yatindra Nath Singh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2503.14074",
    "title": "Limb-Aware Virtual Try-On Network with Progressive Clothing Warping",
    "abstract": "           Image-based virtual try-on aims to transfer an in-shop clothing image to a person image. Most existing methods adopt a single global deformation to perform clothing warping directly, which lacks fine-grained modeling of in-shop clothing and leads to distorted clothing appearance. In addition, existing methods usually fail to generate limb details well because they are limited by the used clothing-agnostic person representation without referring to the limb textures of the person image. To address these problems, we propose Limb-aware Virtual Try-on Network named PL-VTON, which performs fine-grained clothing warping progressively and generates high-quality try-on results with realistic limb details. Specifically, we present Progressive Clothing Warping (PCW) that explicitly models the location and size of in-shop clothing and utilizes a two-stage alignment strategy to progressively align the in-shop clothing with the human body. Moreover, a novel gravity-aware loss that considers the fit of the person wearing clothing is adopted to better handle the clothing edges. Then, we design Person Parsing Estimator (PPE) with a non-limb target parsing map to semantically divide the person into various regions, which provides structural constraints on the human body and therefore alleviates texture bleeding between clothing and body regions. Finally, we introduce Limb-aware Texture Fusion (LTF) that focuses on generating realistic details in limb regions, where a coarse try-on result is first generated by fusing the warped clothing image with the person image, then limb textures are further fused with the coarse result under limb-aware guidance to refine limb details. Extensive experiments demonstrate that our PL-VTON outperforms the state-of-the-art methods both qualitatively and quantitatively.         ",
    "url": "https://arxiv.org/abs/2503.14074",
    "authors": [
      "Shengping Zhang",
      "Xiaoyu Han",
      "Weigang Zhang",
      "Xiangyuan Lan",
      "Hongxun Yao",
      "Qingming Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.14104",
    "title": "Sheaf-Theoretic Causal Emergence for Resilience Analysis in Distributed Systems",
    "abstract": "           Distributed systems often exhibit emergent behaviors that impact their resilience (Franz-Kaiser et al., 2020; Adilson E. Motter, 2002; Jianxi Gao, 2016). This paper presents a theoretical framework combining attributed graph models, flow-on-graph simulation, and sheaf-theoretic causal emergence analysis to evaluate system resilience. We model a distributed system as a graph with attributes (capturing component state and connections) and use sheaf theory to formalize how local interactions compose into global states. A flow simulation on this graph propagates functional loads and failures. To assess resilience, we apply the concept of causal emergence, quantifying whether macro-level dynamics (coarse-grained groupings) exhibit stronger causal efficacy (via effective information) than micro-level dynamics. The novelty lies in uniting sheaf-based formalization with causal metrics to identify emergent resilient structures. We discuss limitless potential applications (illustrated by microservices, neural networks, and power grids) and outline future steps toward implementing this framework (Lake et al., 2015).         ",
    "url": "https://arxiv.org/abs/2503.14104",
    "authors": [
      "Anatoly A. Krasnovsky"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Discrete Mathematics (cs.DM)",
      "Information Theory (cs.IT)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2503.14106",
    "title": "Reliable uncertainty quantification for 2D/3D anatomical landmark localization using multi-output conformal prediction",
    "abstract": "           Automatic anatomical landmark localization in medical imaging requires not just accurate predictions but reliable uncertainty quantification for effective clinical decision support. Current uncertainty quantification approaches often fall short, particularly when combined with normality assumptions, systematically underestimating total predictive uncertainty. This paper introduces conformal prediction as a framework for reliable uncertainty quantification in anatomical landmark localization, addressing a critical gap in automatic landmark localization. We present two novel approaches guaranteeing finite-sample validity for multi-output prediction: Multi-output Regression-as-Classification Conformal Prediction (M-R2CCP) and its variant Multi-output Regression to Classification Conformal Prediction set to Region (M-R2C2R). Unlike conventional methods that produce axis-aligned hyperrectangular or ellipsoidal regions, our approaches generate flexible, non-convex prediction regions that better capture the underlying uncertainty structure of landmark predictions. Through extensive empirical evaluation across multiple 2D and 3D datasets, we demonstrate that our methods consistently outperform existing multi-output conformal prediction approaches in both validity and efficiency. This work represents a significant advancement in reliable uncertainty estimation for anatomical landmark localization, providing clinicians with trustworthy confidence measures for their diagnoses. While developed for medical imaging, these methods show promise for broader applications in multi-output regression problems.         ",
    "url": "https://arxiv.org/abs/2503.14106",
    "authors": [
      "Jef Jonkers",
      "Frank Coopman",
      "Luc Duchateau",
      "Glenn Van Wallendael",
      "Sofie Van Hoecke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2503.14109",
    "title": "Operational Change Detection for Geographical Information: Overview and Challenges",
    "abstract": "           Rapid evolution of territories due to climate change and human impact requires prompt and effective updates to geospatial databases maintained by the National Mapping Agency. This paper presents a comprehensive overview of change detection methods tailored for the operational updating of large-scale geographic databases. This review first outlines the fundamental definition of change, emphasizing its multifaceted nature, from temporal to semantic characterization. It categorizes automatic change detection methods into four main families: rule-based, statistical, machine learning, and simulation methods. The strengths, limitations, and applicability of every family are discussed in the context of various input data. Then, key applications for National Mapping Agencies are identified, particularly the optimization of geospatial database updating, change-based phenomena, and dynamics monitoring. Finally, the paper highlights the current challenges for leveraging change detection such as the variability of change definition, the missing of relevant large-scale datasets, the diversity of input data, the unstudied no-change detection, the human in the loop integration and the operational constraints. The discussion underscores the necessity for ongoing innovation in change detection techniques to address the future needs of geographic information systems for national mapping agencies.         ",
    "url": "https://arxiv.org/abs/2503.14109",
    "authors": [
      "Nicolas Gonthier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.14111",
    "title": "Towards properties of adversarial image perturbations",
    "abstract": "           Using stochastic gradient approach we study the properties of adversarial perturbations resulting in noticeable growth of VMAF image quality metric. The structure of the perturbations is investigated depending on the acceptable PSNR values and based on the Fourier power spectrum computations for the perturbations. It is demonstrated that moderate variation of image brightness ($\\sim 10$ pixel units in a restricted region of an image can result in VMAF growth by $\\sim 60\\%$). Unlike some other methods demonstrating similar VMAF growth, the subjective quality of an image remains almost unchanged. It is also shown that the adversarial perturbations may demonstrate approximately linear dependence of perturbation amplitudes on the image brightness. The perturbations are studied based on the direct VMAF optimization in PyTorch. The significant discrepancies between the metric values and subjective judgements are also demonstrated when image restoration from noise is carried out using the same direct VMAF optimization.         ",
    "url": "https://arxiv.org/abs/2503.14111",
    "authors": [
      "Egor Kuznetsov",
      "Kirill Aistov",
      "Maxim Koroteev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.14112",
    "title": "Condensing Action Segmentation Datasets via Generative Network Inversion",
    "abstract": "           This work presents the first condensation approach for procedural video datasets used in temporal action segmentation. We propose a condensation framework that leverages generative prior learned from the dataset and network inversion to condense data into compact latent codes with significant storage reduced across temporal and channel aspects. Orthogonally, we propose sampling diverse and representative action sequences to minimize video-wise redundancy. Our evaluation on standard benchmarks demonstrates consistent effectiveness in condensing TAS datasets and achieving competitive performances. Specifically, on the Breakfast dataset, our approach reduces storage by over 500$\\times$ while retaining 83% of the performance compared to training with the full dataset. Furthermore, when applied to a downstream incremental learning task, it yields superior performance compared to the state-of-the-art.         ",
    "url": "https://arxiv.org/abs/2503.14112",
    "authors": [
      "Guodong Ding",
      "Rongyu Chen",
      "Angela Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.14114",
    "title": "Enhancing Kubernetes Resilience through Anomaly Detection and Prediction",
    "abstract": "           Kubernetes, in recent years, has become widely used for the deployment and management of software projects on cloud infrastructure. Due to the execution of these applications across numerous Nodes, each one with its unique specifications, it has become a challenge to identify problems and ensure the smooth operation of the application. Effective supervision of the cluster remains a challenging and resource intensive task. This research work focuses on providing a novel framework system maintainer in order to overview all the possible resources in Kubernetes and pay the attention to specific parts of the cluster that may be showcasing problematic behavior. The novelty of this component rises from the use of cluster graphical representation where features, e.g. graph edges and neighboring nodes, are used for anomaly detection. The proposed framework defines the normality in the dynamic enviroment of Kubernetes and the output feeds the supervised models for abnormaliry detection presented in user-friendly graph interface. A variety of model combinations are evaluated and tested in real-life environment.         ",
    "url": "https://arxiv.org/abs/2503.14114",
    "authors": [
      "V. Anemogiannis",
      "B. Andreou",
      "K. Myrtollari",
      "K. Panagidi",
      "S. Hadjiefthymiades"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2503.14126",
    "title": "Hardware Implementation of Ring Oscillator Networks Coupled by BEOL Integrated ReRAM for Associative Memory Tasks",
    "abstract": "           We demonstrate the first hardware implementation of an oscillatory neural network (ONN) utilizing resistive memory (ReRAM) for coupling elements. A ReRAM crossbar array chip, integrated into the Back End of Line (BEOL) of CMOS technology, is leveraged to establish dense coupling elements between oscillator neurons, allowing phase-encoded analog information to be processed in-memory. We also realize an ONN architecture design with the coupling ReRAM array. To validate the architecture experimentally, we present a conductive metal oxide (CMO)/HfOx ReRAM array chip integrated with a 2-by-2 ring oscillator-based network. The system successfully retrieves patterns through correct binary phase locking. This proof of concept underscores the potential of ReRAM technology for large-scale, integrated ONNs.         ",
    "url": "https://arxiv.org/abs/2503.14126",
    "authors": [
      "Wooseok Choi",
      "Thomas van Bodegraven",
      "Jelle Verest",
      "Olivier Maher",
      "Donato Francesco Falcone",
      "Antonio La Porta",
      "Daniel Jubin",
      "Bert Jan Offrein",
      "Siegfried Karg",
      "Valeria Bragaglia",
      "Aida Todri-Sanial"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2503.14162",
    "title": "EIAD: Explainable Industrial Anomaly Detection Via Multi-Modal Large Language Models",
    "abstract": "           Industrial Anomaly Detection (IAD) is critical to ensure product quality during manufacturing. Although existing zero-shot defect segmentation and detection methods have shown effectiveness, they cannot provide detailed descriptions of the defects. Furthermore, the application of large multi-modal models in IAD remains in its infancy, facing challenges in balancing question-answering (QA) performance and mask-based grounding capabilities, often owing to overfitting during the fine-tuning process. To address these challenges, we propose a novel approach that introduces a dedicated multi-modal defect localization module to decouple the dialog functionality from the core feature extraction. This decoupling is achieved through independent optimization objectives and tailored learning strategies. Additionally, we contribute to the first multi-modal industrial anomaly detection training dataset, named Defect Detection Question Answering (DDQA), encompassing a wide range of defect types and industrial scenarios. Unlike conventional datasets that rely on GPT-generated data, DDQA ensures authenticity and reliability and offers a robust foundation for model training. Experimental results demonstrate that our proposed method, Explainable Industrial Anomaly Detection Assistant (EIAD), achieves outstanding performance in defect detection and localization tasks. It not only significantly enhances accuracy but also improves interpretability. These advancements highlight the potential of EIAD for practical applications in industrial settings.         ",
    "url": "https://arxiv.org/abs/2503.14162",
    "authors": [
      "Zongyun Zhang",
      "Jiacheng Ruan",
      "Xian Gao",
      "Ting Liu",
      "Yuzhuo Fu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.14182",
    "title": "Bridging Past and Future: End-to-End Autonomous Driving with Historical Prediction and Planning",
    "abstract": "           End-to-end autonomous driving unifies tasks in a differentiable framework, enabling planning-oriented optimization and attracting growing attention. Current methods aggregate historical information either through dense historical bird's-eye-view (BEV) features or by querying a sparse memory bank, following paradigms inherited from detection. However, we argue that these paradigms either omit historical information in motion planning or fail to align with its multi-step nature, which requires predicting or planning multiple future time steps. In line with the philosophy of future is a continuation of past, we propose BridgeAD, which reformulates motion and planning queries as multi-step queries to differentiate the queries for each future time step. This design enables the effective use of historical prediction and planning by applying them to the appropriate parts of the end-to-end system based on the time steps, which improves both perception and motion planning. Specifically, historical queries for the current frame are combined with perception, while queries for future frames are integrated with motion planning. In this way, we bridge the gap between past and future by aggregating historical insights at every time step, enhancing the overall coherence and accuracy of the end-to-end autonomous driving pipeline. Extensive experiments on the nuScenes dataset in both open-loop and closed-loop settings demonstrate that BridgeAD achieves state-of-the-art performance.         ",
    "url": "https://arxiv.org/abs/2503.14182",
    "authors": [
      "Bozhou Zhang",
      "Nan Song",
      "Xin Jin",
      "Li Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.14198",
    "title": "RoGSplat: Learning Robust Generalizable Human Gaussian Splatting from Sparse Multi-View Images",
    "abstract": "           This paper presents RoGSplat, a novel approach for synthesizing high-fidelity novel views of unseen human from sparse multi-view images, while requiring no cumbersome per-subject optimization. Unlike previous methods that typically struggle with sparse views with few overlappings and are less effective in reconstructing complex human geometry, the proposed method enables robust reconstruction in such challenging conditions. Our key idea is to lift SMPL vertices to dense and reliable 3D prior points representing accurate human body geometry, and then regress human Gaussian parameters based on the points. To account for possible misalignment between SMPL model and images, we propose to predict image-aligned 3D prior points by leveraging both pixel-level features and voxel-level features, from which we regress the coarse Gaussians. To enhance the ability to capture high-frequency details, we further render depth maps from the coarse 3D Gaussians to help regress fine-grained pixel-wise Gaussians. Experiments on several benchmark datasets demonstrate that our method outperforms state-of-the-art methods in novel view synthesis and cross-dataset generalization. Our code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2503.14198",
    "authors": [
      "Junjin Xiao",
      "Qing Zhang",
      "Yonewei Nie",
      "Lei Zhu",
      "Wei-Shi Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.14201",
    "title": "Why Personalizing Deep Learning-Based Code Completion Tools Matters",
    "abstract": "           Deep learning (DL)-based code completion tools have transformed software development by enabling advanced code generation. These tools leverage models trained on vast amounts of code from numerous repositories, capturing general coding patterns. However, the impact of fine-tuning these models for specific organizations or developers to boost their performance on such subjects remains unexplored. In this work, we fill this gap by presenting solid empirical evidence answering this question. More specifically, we consider 136 developers from two organizations (Apache and Spring), two model architectures (T5 and Code Llama), and three model sizes (60M, 750M, and 7B trainable parameters). T5 models (60M, 750M) were pre-trained and fine-tuned on over 2,000 open-source projects, excluding the subject organizations' data, and compared against versions fine-tuned on organization- and developer-specific datasets. For the Code Llama model (7B), we compared the performance of the already pre-trained model publicly available online with the same model fine-tuned via parameter-efficient fine-tuning on organization- and developer-specific datasets. Our results show that there is a boost in prediction capabilities provided by both an organization-specific and a developer-specific additional fine-tuning, with the former being particularly performant. Such a finding generalizes across (i) the two subject organizations (i.e., Apache and Spring) and (ii) models of completely different magnitude (from 60M to 7B trainable parameters). Finally, we show that DL models fine-tuned on an organization-specific dataset achieve the same completion performance of pre-trained code models used out of the box and being $\\sim$10$\\times$ larger, with consequent savings in terms of deployment and inference cost (e.g., smaller GPUs needed).         ",
    "url": "https://arxiv.org/abs/2503.14201",
    "authors": [
      "Alessandro Giagnorio",
      "Alberto Martin-Lopez",
      "Gabriele Bavota"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2503.14203",
    "title": "Stochastic Trajectory Prediction under Unstructured Constraints",
    "abstract": "           Trajectory prediction facilitates effective planning and decision-making, while constrained trajectory prediction integrates regulation into prediction. Recent advances in constrained trajectory prediction focus on structured constraints by constructing optimization objectives. However, handling unstructured constraints is challenging due to the lack of differentiable formal definitions. To address this, we propose a novel method for constrained trajectory prediction using a conditional generative paradigm, named Controllable Trajectory Diffusion (CTD). The key idea is that any trajectory corresponds to a degree of conformity to a constraint. By quantifying this degree and treating it as a condition, a model can implicitly learn to predict trajectories under unstructured constraints. CTD employs a pre-trained scoring model to predict the degree of conformity (i.e., a score), and uses this score as a condition for a conditional diffusion model to generate trajectories. Experimental results demonstrate that CTD achieves high accuracy on the ETH/UCY and SDD benchmarks. Qualitative analysis confirms that CTD ensures adherence to unstructured constraints and can predict trajectories that satisfy combinatorial constraints.         ",
    "url": "https://arxiv.org/abs/2503.14203",
    "authors": [
      "Hao Ma",
      "Zhiqiang Pu",
      "Shijie Wang",
      "Boyin Liu",
      "Huimu Wang",
      "Yanyan Liang",
      "Jianqiang Yi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.14209",
    "title": "AI-Driven Diabetic Retinopathy Diagnosis Enhancement through Image Processing and Salp Swarm Algorithm-Optimized Ensemble Network",
    "abstract": "           Diabetic retinopathy is a leading cause of blindness in diabetic patients and early detection plays a crucial role in preventing vision loss. Traditional diagnostic methods are often time-consuming and prone to errors. The emergence of deep learning techniques has provided innovative solutions to improve diagnostic efficiency. However, single deep learning models frequently face issues related to extracting key features from complex retinal images. To handle this problem, we present an effective ensemble method for DR diagnosis comprising four main phases: image pre-processing, selection of backbone pre-trained models, feature enhancement, and optimization. Our methodology initiates with the pre-processing phase, where we apply CLAHE to enhance image contrast and Gamma correction is then used to adjust the brightness for better feature recognition. We then apply Discrete Wavelet Transform (DWT) for image fusion by combining multi-resolution details to create a richer dataset. Then, we selected three pre-trained models with the best performance named DenseNet169, MobileNetV1, and Xception for diverse feature extraction. To further improve feature extraction, an improved residual block is integrated into each model. Finally, the predictions from these base models are then aggregated using weighted ensemble approach, with the weights optimized by using Salp Swarm Algorithm (SSA).SSA intelligently explores the weight space and finds the optimal configuration of base architectures to maximize the performance of the ensemble model. The proposed model is evaluated on the multiclass Kaggle APTOS 2019 dataset and obtained 88.52% accuracy.         ",
    "url": "https://arxiv.org/abs/2503.14209",
    "authors": [
      "Saif Ur Rehman Khan",
      "Muhammad Nabeel Asim",
      "Sebastian Vollmer",
      "Andreas Dengel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.14213",
    "title": "Rolling Forward: Enhancing LightGCN with Causal Graph Convolution for Credit Bond Recommendation",
    "abstract": "           Graph Neural Networks have significantly advanced research in recommender systems over the past few years. These methods typically capture global interests using aggregated past interactions and rely on static embeddings of users and items over extended periods of time. While effective in some domains, these methods fall short in many real-world scenarios, especially in finance, where user interests and item popularity evolve rapidly over time. To address these challenges, we introduce a novel extension to Light Graph Convolutional Network (LightGCN) designed to learn temporal node embeddings that capture dynamic interests. Our approach employs causal convolution to maintain a forward-looking model architecture. By preserving the chronological order of user-item interactions and introducing a dynamic update mechanism for embeddings through a sliding window, the proposed model generates well-timed and contextually relevant recommendations. Extensive experiments on a real-world dataset from BNP Paribas demonstrate that our approach significantly enhances the performance of LightGCN while maintaining the simplicity and efficiency of its architecture. Our findings provide new insights into designing graph-based recommender systems in time-sensitive applications, particularly for financial product recommendations.         ",
    "url": "https://arxiv.org/abs/2503.14213",
    "authors": [
      "Ashraf Ghiye",
      "Baptiste Barreau",
      "Laurent Carlier",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)"
    ]
  },
  {
    "id": "arXiv:2503.14219",
    "title": "Segmentation-Guided Neural Radiance Fields for Novel Street View Synthesis",
    "abstract": "           Recent advances in Neural Radiance Fields (NeRF) have shown great potential in 3D reconstruction and novel view synthesis, particularly for indoor and small-scale scenes. However, extending NeRF to large-scale outdoor environments presents challenges such as transient objects, sparse cameras and textures, and varying lighting conditions. In this paper, we propose a segmentation-guided enhancement to NeRF for outdoor street scenes, focusing on complex urban environments. Our approach extends ZipNeRF and utilizes Grounded SAM for segmentation mask generation, enabling effective handling of transient objects, modeling of the sky, and regularization of the ground. We also introduce appearance embeddings to adapt to inconsistent lighting across view sequences. Experimental results demonstrate that our method outperforms the baseline ZipNeRF, improving novel view synthesis quality with fewer artifacts and sharper details.         ",
    "url": "https://arxiv.org/abs/2503.14219",
    "authors": [
      "Yizhou Li",
      "Yusuke Monno",
      "Masatoshi Okutomi",
      "Yuuichi Tanaka",
      "Seiichi Kataoka",
      "Teruaki Kosiba"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2503.14228",
    "title": "Panoramic Distortion-Aware Tokenization for Person Detection and Localization Using Transformers in Overhead Fisheye Images",
    "abstract": "           Person detection methods are used widely in applications including visual surveillance, pedestrian detection, and robotics. However, accurate detection of persons from overhead fisheye images remains an open challenge because of factors including person rotation and small-sized persons. To address the person rotation problem, we convert the fisheye images into panoramic images. For smaller people, we focused on the geometry of the panoramas. Conventional detection methods tend to focus on larger people because these larger people yield large significant areas for feature maps. In equirectangular panoramic images, we find that a person's height decreases linearly near the top of the images. Using this finding, we leverage the significance values and aggregate tokens that are sorted based on these values to balance the significant areas. In this leveraging process, we introduce panoramic distortion-aware tokenization. This tokenization procedure divides a panoramic image using self-similarity figures that enable determination of optimal divisions without gaps, and we leverage the maximum significant values in each tile of token groups to preserve the significant areas of smaller people. To achieve higher detection accuracy, we propose a person detection and localization method that combines panoramic-image remapping and the tokenization procedure. Extensive experiments demonstrated that our method outperforms conventional methods when applied to large-scale datasets.         ",
    "url": "https://arxiv.org/abs/2503.14228",
    "authors": [
      "Nobuhiko Wakai",
      "Satoshi Sato",
      "Yasunori Ishii",
      "Takayoshi Yamashita"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.14240",
    "title": "Persistent Homology-induced Graph Ensembles for Time Series Regressions",
    "abstract": "           The effectiveness of Spatio-temporal Graph Neural Networks (STGNNs) in time-series applications is often limited by their dependence on fixed, hand-crafted input graph structures. Motivated by insights from the Topological Data Analysis (TDA) paradigm, of which real-world data exhibits multi-scale patterns, we construct several graphs using \\textit{Persistent Homology Filtration} -- a mathematical framework describing the multiscale structural properties of data points. Then, we use the constructed graphs as an input to create an ensemble of Graph Neural Networks. The ensemble aggregates the signals from the individual learners via an attention-based routing mechanism, thus systematically encoding the inherent multiscale structures of data. Four different real-world experiments on seismic activity prediction and traffic forecasting (PEMS-BAY, METR-LA) demonstrate that our approach consistently outperforms single-graph baselines while providing interpretable insights.         ",
    "url": "https://arxiv.org/abs/2503.14240",
    "authors": [
      "Viet The Nguyen",
      "Duy Anh Pham",
      "An Thai Le",
      "Jans Peter",
      "Gunther Gust"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.14247",
    "title": "GeoFlow-SLAM: A Robust Tightly-Coupled RGBD-Inertial Fusion SLAM for Dynamic Legged Robotics",
    "abstract": "           This paper presents GeoFlow-SLAM, a robust and effective Tightly-Coupled RGBD-inertial SLAM for legged robots operating in highly dynamic this http URL integrating geometric consistency, legged odometry constraints, and dual-stream optical flow (GeoFlow), our method addresses three critical challenges:feature matching and pose initialization failures during fast locomotion and visual feature scarcity in texture-less this http URL, in rapid motion scenarios, feature matching is notably enhanced by leveraging dual-stream optical flow, which combines prior map points and poses. Additionally, we propose a robust pose initialization method for fast locomotion and IMU error in legged robots, integrating IMU/Legged odometry, inter-frame Perspective-n-Point (PnP), and Generalized Iterative Closest Point (GICP). Furthermore, a novel optimization framework that tightly couples depth-to-map and GICP geometric constraints is first introduced to improve the robustness and accuracy in long-duration, visually texture-less environments. The proposed algorithms achieve state-of-the-art (SOTA) on collected legged robots and open-source datasets. To further promote research and development, the open-source datasets and code will be made publicly available at this https URL ",
    "url": "https://arxiv.org/abs/2503.14247",
    "authors": [
      "Tingyang Xiao",
      "Xiaolin Zhou",
      "Liu Liu",
      "Wei Sui",
      "Wei Feng",
      "Jiaxiong Qiu",
      "Xinjie Wang",
      "Zhizhong Su"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.14248",
    "title": "Joint Channel Bandwidth Assignment and Relay Positioning for Predictive Flying Networks",
    "abstract": "           Flying Networks (FNs) have emerged as a promising solution to provide on-demand wireless connectivity when network coverage is insufficient or the communications infrastructure is compromised, such as in disaster management scenarios. Despite extensive research on Unmanned Aerial Vehicle (UAV) positioning and radio resource allocation, the challenge of ensuring reliable traffic relay through backhaul links in predictive FNs remains unexplored. This work proposes Simulated Annealing for predictive FNs (SAFnet), an innovative algorithm that optimizes network performance under positioning constraints, limited bandwidth and minimum rate requirements. Our algorithm uniquely leverages prior knowledge of the first-tier node trajectories to assign bandwidth and dynamically adjust the position of the second-tier flying relay. Building upon Simulated Annealing, our approach enhances this well-known AI algorithm with penalty functions, achieving performance levels comparable to exhaustive search while significantly reducing computational complexity.         ",
    "url": "https://arxiv.org/abs/2503.14248",
    "authors": [
      "Ruben Queiros",
      "Megumi Kaneko",
      "Helder Fontes",
      "Rui Campos"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2503.14263",
    "title": "Conversational Agents as Catalysts for Critical Thinking: Challenging Social Influence in Group Decision-making",
    "abstract": "           Group decision-making processes frequently suffer when social influence and power dynamics suppress minority viewpoints, leading to compliance and groupthink. Conversational agents can counteract these harmful dynamics by encouraging critical thinking. This study investigates how LLM-powered devil's advocate systems affect psychological safety, opinion expression, and satisfaction in power-imbalanced group dynamics. We conducted an experiment with 48 participants in 12 four-person groups, each containing three high-power (senior) and one low-power (junior) member. Each group completed decision tasks in both baseline and AI intervention conditions. Results show AI counterarguments fostered a more flexible atmosphere and significantly enhanced both process and outcome satisfaction for all participants, with particularly notable improvements for minority members. Cognitive workload increased slightly, though not significantly. This research contributes empirical evidence on how AI systems can effectively navigate power hierarchies to foster more inclusive decision-making environments, highlighting the importance of balancing intervention frequency, maintaining conversational flow, and preserving group cohesion.         ",
    "url": "https://arxiv.org/abs/2503.14263",
    "authors": [
      "Soohwan Lee",
      "Seoyeong Hwang",
      "Dajung Kim",
      "Kyungho Lee"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2503.14271",
    "title": "Video Streaming with Kairos: An MPC-Based ABR with Streaming-Aware Throughput Prediction",
    "abstract": "           In this paper, we present Kairos, a model predictive control (MPC)-based adaptive bitrate (ABR) scheme that integrates streaming-aware throughput predictions to enhance video streaming quality. Kairos features an attention-based throughput predictor with buffer-aware uncertainty control, improving prediction accuracy and adaptability to network conditions. Specifically, we introduce a multi-time attention network to handle the irregularly sampled sequences in streaming data, creating uniformly spaced latent representations. Additionally, we design a separate prediction network that estimates future throughput at multiple percentiles and incorporates a buffer-aware uncertainty adjustment module. This module dynamically selects the appropriate throughput percentile based on the buffer size, enhancing robustness to varying network conditions. Lastly, to mitigate QoE smoothness penalties caused by predictors focused solely on accuracy, we introduce a smoothness regularizer. By embedding streaming-aware characteristics, such as sampling irregularity, buffer occupancy, and smoothness, into the throughput predictor design, Kairos significantly improves bitrate decision-making within the MPC framework. Extensive trace-driven and real-world experiments demonstrate that Kairos outperforms state-of-the-art ABR schemes, achieving an average QoE improvement of 1.52% to 7.28% under various network conditions.         ",
    "url": "https://arxiv.org/abs/2503.14271",
    "authors": [
      "Ziyu Zhong",
      "Mufan Liu",
      "Le Yang",
      "Yifan Wang",
      "Yiling Xu",
      "Jenq-Neng Hwang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2503.14279",
    "title": "Anti-Tamper Radio meets Reconfigurable Intelligent Surface for System-Level Tamper Detection",
    "abstract": "           Many computing systems need to be protected against physical attacks using active tamper detection based on sensors. One technical solution is to employ an ATR (Anti-Tamper Radio) approach, analyzing the radio wave propagation effects within a protected device to detect unauthorized physical alterations. However, ATR systems face key challenges in terms of susceptibility to signal manipulation attacks, limited reliability due to environmental noise, and regulatory constraints from wide bandwidth usage. In this work, we propose and experimentally evaluate an ATR system complemented by an RIS to dynamically reconfigure the wireless propagation environment. We show that this approach can enhance resistance against signal manipulation attacks, reduce bandwidth requirements from several~GHz down to as low as 20 MHz, and improve robustness to environmental disturbances such as internal fan movements. Our work demonstrates that RIS integration can strengthen the ATR performance to enhance security, sensitivity, and robustness, recognizing the potential of smart radio environments for ATR-based tamper detection         ",
    "url": "https://arxiv.org/abs/2503.14279",
    "authors": [
      "Maryam Shaygan Tabar",
      "Johannes Kortz",
      "Paul Staat",
      "Harald Elders-Boll",
      "Christof Paar",
      "Christian Zenger"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2503.14281",
    "title": "XOXO: Stealthy Cross-Origin Context Poisoning Attacks against AI Coding Assistants",
    "abstract": "           AI coding assistants are widely used for tasks like code generation, bug detection, and comprehension. These tools now require large and complex contexts, automatically sourced from various origins$\\unicode{x2014}$across files, projects, and contributors$\\unicode{x2014}$forming part of the prompt fed to underlying LLMs. This automatic context-gathering introduces new vulnerabilities, allowing attackers to subtly poison input to compromise the assistant's outputs, potentially generating vulnerable code, overlooking flaws, or introducing critical errors. We propose a novel attack, Cross-Origin Context Poisoning (XOXO), that is particularly challenging to detect as it relies on adversarial code modifications that are semantically equivalent. Traditional program analysis techniques struggle to identify these correlations since the semantics of the code remain correct, making it appear legitimate. This allows attackers to manipulate code assistants into producing incorrect outputs, including vulnerabilities or backdoors, while shifting the blame to the victim developer or tester. We introduce a novel, task-agnostic black-box attack algorithm GCGS that systematically searches the transformation space using a Cayley Graph, achieving an 83.09% attack success rate on average across five tasks and eleven models, including GPT-4o and Claude 3.5 Sonnet v2 used by many popular AI coding assistants. Furthermore, existing defenses, including adversarial fine-tuning, are ineffective against our attack, underscoring the need for new security measures in LLM-powered coding tools.         ",
    "url": "https://arxiv.org/abs/2503.14281",
    "authors": [
      "Adam \u0160torek",
      "Mukur Gupta",
      "Noopur Bhatt",
      "Aditya Gupta",
      "Janie Kim",
      "Prashast Srivastava",
      "Suman Jana"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2503.14284",
    "title": "Entente: Cross-silo Intrusion Detection on Network Log Graphs with Federated Learning",
    "abstract": "           Graph-based Network Intrusion Detection System (GNIDS) has gained significant momentum in detecting sophisticated cyber-attacks, like Advanced Persistent Threat (APT), in an organization or across organizations. Though achieving satisfying detection accuracy and adapting to ever-changing attacks and normal patterns, all prior GNIDSs assume the centralized data settings directly, but non-trivial data collection is not always practical under privacy regulations nowadays. We argue that training a GNIDS model has to consider privacy regulations, and propose to leverage federated learning (FL) to address this prominent challenge. Yet, directly applying FL to GNIDS is unlikely to succeed, due to issues like non-IID (independent and identically distributed) graph data over clients and the diverse design choices taken by different GNIDS. We address these issues with a set of novel techniques tailored to the graph datasets, including reference graph synthesis, graph sketching and adaptive contribution scaling, and develop a new system Entente. We evaluate Entente on the large-scale LANL, OpTC and Pivoting datasets. The result shows Entente outperforms the other baseline FL algorithms and sometimes even the non-FL GNIDS. We also evaluate Entente under FL poisoning attacks tailored to the GNIDS setting, and show Entente is able to bound the attack success rate to low values. Overall, our result suggests building cross-silo GNIDS is feasible and we hope to encourage more efforts in this direction.         ",
    "url": "https://arxiv.org/abs/2503.14284",
    "authors": [
      "Jiacen Xu",
      "Chenang Li",
      "Yu Zheng",
      "Zhou Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2503.14297",
    "title": "Improved Scalable Lipschitz Bounds for Deep Neural Networks",
    "abstract": "           Computing tight Lipschitz bounds for deep neural networks is crucial for analyzing their robustness and stability, but existing approaches either produce relatively conservative estimates or rely on semidefinite programming (SDP) formulations (namely the LipSDP condition) that face scalability issues. Building upon ECLipsE-Fast, the state-of-the-art Lipschitz bound method that avoids SDP formulations, we derive a new family of improved scalable Lipschitz bounds that can be combined to outperform ECLipsE-Fast. Specifically, we leverage more general parameterizations of feasible points of LipSDP to derive various closed-form Lipschitz bounds, avoiding the use of SDP solvers. In addition, we show that our technique encompasses ECLipsE-Fast as a special case and leads to a much larger class of scalable Lipschitz bounds for deep neural networks. Our empirical study shows that our bounds improve ECLipsE-Fast, further advancing the scalability and precision of Lipschitz estimation for large neural networks.         ",
    "url": "https://arxiv.org/abs/2503.14297",
    "authors": [
      "Usman Syed",
      "Bin Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2503.14298",
    "title": "Recursive Self-Similarity in Deep Weight Spaces of Neural Architectures: A Fractal and Coarse Geometry Perspective",
    "abstract": "           This paper conceptualizes the Deep Weight Spaces (DWS) of neural architectures as hierarchical, fractal-like, coarse geometric structures observable at discrete integer scales through recursive dilation. We introduce a coarse group action termed the fractal transformation, $T_{r_k} $, acting under the symmetry group $G = (\\mathbb{Z}, +) $, to analyze neural parameter matrices or tensors, by segmenting the underlying discrete grid $\\Omega$ into $N(r_k)$ fractals across varying observation scales $ r_k $. This perspective adopts a box count technique, commonly used to assess the hierarchical and scale-related geometry of physical structures, which has been extensively formalized under the topic of fractal geometry. We assess the structural complexity of neural layers by estimating the Hausdorff-Besicovitch dimension of their layers and evaluating a degree of self-similarity. The fractal transformation features key algebraic properties such as linearity, identity, and asymptotic invertibility, which is a signature of coarse structures. We show that the coarse group action exhibits a set of symmetries such as Discrete Scale Invariance (DSI) under recursive dilation, strong invariance followed by weak equivariance to permutations, alongside respecting the scaling equivariance of activation functions, defined by the intertwiner group relations. Our framework targets large-scale structural properties of DWS, deliberately overlooking minor inconsistencies to focus on significant geometric characteristics of neural networks. Experiments on CIFAR-10 using ResNet-18, VGG-16, and a custom CNN validate our approach, demonstrating effective fractal segmentation and structural analysis.         ",
    "url": "https://arxiv.org/abs/2503.14298",
    "authors": [
      "Ambarish Moharil",
      "Indika Kumara",
      "Damian Andrew Tamburri",
      "Majid Mohammadi",
      "Willem-Jan van den Heuvel"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Algebraic Geometry (math.AG)",
      "Group Theory (math.GR)"
    ]
  },
  {
    "id": "arXiv:2503.14299",
    "title": "Unveiling the Role of Randomization in Multiclass Adversarial Classification: Insights from Graph Theory",
    "abstract": "           Randomization as a mean to improve the adversarial robustness of machine learning models has recently attracted significant attention. Unfortunately, much of the theoretical analysis so far has focused on binary classification, providing only limited insights into the more complex multiclass setting. In this paper, we take a step toward closing this gap by drawing inspiration from the field of graph theory. Our analysis focuses on discrete data distributions, allowing us to cast the adversarial risk minimization problems within the well-established framework of set packing problems. By doing so, we are able to identify three structural conditions on the support of the data distribution that are necessary for randomization to improve robustness. Furthermore, we are able to construct several data distributions where (contrarily to binary classification) switching from a deterministic to a randomized solution significantly reduces the optimal adversarial risk. These findings highlight the crucial role randomization can play in enhancing robustness to adversarial attacks in multiclass classification.         ",
    "url": "https://arxiv.org/abs/2503.14299",
    "authors": [
      "Lucas Gnecco-Heredia",
      "Matteo Sammut",
      "Muni Sreenivas Pydi",
      "Rafael Pinot",
      "Benjamin Negrevergne",
      "Yann Chevaleyre"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.14329",
    "title": "EvolvingGrasp: Evolutionary Grasp Generation via Efficient Preference Alignment",
    "abstract": "           Dexterous robotic hands often struggle to generalize effectively in complex environments due to the limitations of models trained on low-diversity data. However, the real world presents an inherently unbounded range of scenarios, making it impractical to account for every possible variation. A natural solution is to enable robots learning from experience in complex environments, an approach akin to evolution, where systems improve through continuous feedback, learning from both failures and successes, and iterating toward optimal performance. Motivated by this, we propose EvolvingGrasp, an evolutionary grasp generation method that continuously enhances grasping performance through efficient preference alignment. Specifically, we introduce Handpose wise Preference Optimization (HPO), which allows the model to continuously align with preferences from both positive and negative feedback while progressively refining its grasping strategies. To further enhance efficiency and reliability during online adjustments, we incorporate a Physics-aware Consistency Model within HPO, which accelerates inference, reduces the number of timesteps needed for preference finetuning, and ensures physical plausibility throughout the process. Extensive experiments across four benchmark datasets demonstrate state of the art performance of our method in grasp success rate and sampling efficiency. Our results validate that EvolvingGrasp enables evolutionary grasp generation, ensuring robust, physically feasible, and preference-aligned grasping in both simulation and real scenarios.         ",
    "url": "https://arxiv.org/abs/2503.14329",
    "authors": [
      "Yufei Zhu",
      "Yiming Zhong",
      "Zemin Yang",
      "Peishan Cong",
      "Jingyi Yu",
      "Xinge Zhu",
      "Yuexin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.14333",
    "title": "Revealing higher-order neural representations with generative artificial intelligence",
    "abstract": "           Studies often aim to reveal how neural representations encode aspects of an observer's environment, such as its contents or structure. These are ``first-order\" representations (FORs), because they're ``about\" the external world. A less-common target is ``higher-order\" representations (HORs), which are ``about\" FORs -- their contents, stability, or uncertainty. HORs of uncertainty appear critically involved in adaptive behaviors including learning under uncertainty, influencing learning rates and internal model updating based on environmental feedback. However, HORs about uncertainty are unlikely to be direct ``read-outs\" of FOR characteristics, instead reflecting estimation processes which may be lossy, bias-prone, or distortive and which may also incorporate estimates of distributions of uncertainty the observer is likely to experience. While some research has targeted neural representations of ``instantaneously\" estimated uncertainty, how the brain represents \\textit{distributions} of expected uncertainty remains largely unexplored. Here, we propose a novel reinforcement learning (RL) based generative artificial intelligence (genAI) approach to explore neural representations of uncertainty distributions. We use existing functional magnetic resonance imaging data, where humans learned to `de-noise' their brain states to achieve target neural patterns, to train denoising diffusion genAI models with RL algorithms to learn noise distributions similar to how humans might learn to do the same. We then explore these models' learned noise-distribution HORs compared to control models trained with traditional backpropagation. Results reveal model-dependent differences in noise distribution representations -- with the RL-based model offering much higher explanatory power for human behavior -- offering an exciting path towards using genAI to explore neural noise-distribution HORs.         ",
    "url": "https://arxiv.org/abs/2503.14333",
    "authors": [
      "Hojjat Azimi Asrari",
      "Megan A. K. Peters"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2503.14338",
    "title": "Higher-Order Graphon Neural Networks: Approximation and Cut Distance",
    "abstract": "           Graph limit models, like graphons for limits of dense graphs, have recently been used to study size transferability of graph neural networks (GNNs). While most literature focuses on message passing GNNs (MPNNs), in this work we attend to the more powerful higher-order GNNs. First, we extend the $k$-WL test for graphons (B\u00f6ker, 2023) to the graphon-signal space and introduce signal-weighted homomorphism densities as a key tool. As an exemplary focus, we generalize Invariant Graph Networks (IGNs) to graphons, proposing Invariant Graphon Networks (IWNs) defined via a subset of the IGN basis corresponding to bounded linear operators. Even with this restricted basis, we show that IWNs of order $k$ are at least as powerful as the $k$-WL test, and we establish universal approximation results for graphon-signals in $L^p$ distances. This significantly extends the prior work of Cai & Wang (2022), showing that IWNs--a subset of their IGN-small--retain effectively the same expressivity as the full IGN basis in the limit. In contrast to their approach, our blueprint of IWNs also aligns better with the geometry of graphon space, for example facilitating comparability to MPNNs. We highlight that, while typical higher-order GNNs are discontinuous w.r.t. cut distance--which causes their lack of convergence and is inherently tied to the definition of $k$-WL--their transferability remains comparable to MPNNs.         ",
    "url": "https://arxiv.org/abs/2503.14338",
    "authors": [
      "Daniel Herbst",
      "Stefanie Jegelka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.14341",
    "title": "Spatio-Temporal Graph Neural Networks for Infant Language Acquisition Prediction",
    "abstract": "           Predicting the words that a child is going to learn next can be useful for boosting language acquisition, and such predictions have been shown to be possible with both neural network techniques (looking at changes in the vocabulary state over time) and graph model (looking at data pertaining to the relationships between words). However, these models do not fully capture the complexity of the language learning process of an infant when used in isolation. In this paper, we examine how a model of language acquisition for infants and young children can be constructed and adapted for use in a Spatio-Temporal Graph Convolutional Network (STGCN), taking into account the different types of linguistic relationships that occur during child language learning. We introduce a novel approach for predicting child vocabulary acquisition, and evaluate the efficacy of such a model with respect to the different types of linguistic relationships that occur during language acquisition, resulting in insightful observations on model calibration and norm selection. An evaluation of this model found that the mean accuracy of models for predicting new words when using sensorimotor relationships (0.733) and semantic relationships (0.729) were found to be superior to that observed with a 2-layer Feed-forward neural network. Furthermore, the high recall for some relationships suggested that some relationships (e.g. visual) were superior in identifying a larger proportion of relevant words that a child should subsequently learn than others (such as auditory).         ",
    "url": "https://arxiv.org/abs/2503.14341",
    "authors": [
      "Andrew Roxburgh",
      "Floriana Grasso",
      "Terry R. Payne"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.14356",
    "title": "Benchmarking community drug response prediction models: datasets, models, tools, and metrics for cross-dataset generalization analysis",
    "abstract": "           Deep learning (DL) and machine learning (ML) models have shown promise in drug response prediction (DRP), yet their ability to generalize across datasets remains an open question, raising concerns about their real-world applicability. Due to the lack of standardized benchmarking approaches, model evaluations and comparisons often rely on inconsistent datasets and evaluation criteria, making it difficult to assess true predictive capabilities. In this work, we introduce a benchmarking framework for evaluating cross-dataset prediction generalization in DRP models. Our framework incorporates five publicly available drug screening datasets, six standardized DRP models, and a scalable workflow for systematic evaluation. To assess model generalization, we introduce a set of evaluation metrics that quantify both absolute performance (e.g., predictive accuracy across datasets) and relative performance (e.g., performance drop compared to within-dataset results), enabling a more comprehensive assessment of model transferability. Our results reveal substantial performance drops when models are tested on unseen datasets, underscoring the importance of rigorous generalization assessments. While several models demonstrate relatively strong cross-dataset generalization, no single model consistently outperforms across all datasets. Furthermore, we identify CTRPv2 as the most effective source dataset for training, yielding higher generalization scores across target datasets. By sharing this standardized evaluation framework with the community, our study aims to establish a rigorous foundation for model comparison, and accelerate the development of robust DRP models for real-world applications.         ",
    "url": "https://arxiv.org/abs/2503.14356",
    "authors": [
      "Alexander Partin",
      "Priyanka Vasanthakumari",
      "Oleksandr Narykov",
      "Andreas Wilke",
      "Natasha Koussa",
      "Sara E. Jones",
      "Yitan Zhu",
      "Jamie C. Overbeek",
      "Rajeev Jain",
      "Gayara Demini Fernando",
      "Cesar Sanchez-Villalobos",
      "Cristina Garcia-Cardona",
      "Jamaludin Mohd-Yusof",
      "Nicholas Chia",
      "Justin M. Wozniak",
      "Souparno Ghosh",
      "Ranadip Pal",
      "Thomas S. Brettin",
      "M. Ryan Weil",
      "Rick L. Stevens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2503.14357",
    "title": "Wasserstein-based Kernels for Clustering: Application to Power Distribution Graphs",
    "abstract": "           Many data clustering applications must handle objects that cannot be represented as vector data. In this context, the bag-of-vectors representation can be leveraged to describe complex objects through discrete distributions, and the Wasserstein distance can effectively measure the dissimilarity between them. Additionally, kernel methods can be used to embed data into feature spaces that are easier to analyze. Despite significant progress in data clustering, a method that simultaneously accounts for distributional and vectorial dissimilarity measures is still lacking. To tackle this gap, this work explores kernel methods and Wasserstein distance metrics to develop a computationally tractable clustering framework. The compositional properties of kernels allow the simultaneous handling of different metrics, enabling the integration of both vectors and discrete distributions for object representation. This approach is flexible enough to be applied in various domains, such as graph analysis and image processing. The framework consists of three main components. First, we efficiently approximate pairwise Wasserstein distances using multiple reference distributions. Second, we employ kernel functions based on Wasserstein distances and present ways of composing kernels to express different types of information. Finally, we use the kernels to cluster data and evaluate the quality of the results using scalable and distance-agnostic validity indices. A case study involving two datasets of 879 and 34,920 power distribution graphs demonstrates the framework's effectiveness and efficiency.         ",
    "url": "https://arxiv.org/abs/2503.14357",
    "authors": [
      "Alfredo Oneto",
      "Blazhe Gjorgiev",
      "Giovanni Sansavini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2503.14388",
    "title": "Vexed by VEX tools: Consistency evaluation of container vulnerability scanners",
    "abstract": "           This paper presents a study that analyzed state-of-the-art vulnerability scanning tools applied to containers. We have focused the work on tools following the Vulnerability Exploitability eXchange (VEX) format, which has been introduced to complement Software Bills of Material (SBOM) with security advisories of known vulnerabilities. Being able to get an accurate understanding of vulnerabilities found in the dependencies of third-party software is critical for secure software development and risk analysis. Accepting the overwhelming challenge of estimating the precise accuracy and precision of a vulnerability scanner, we have in this study instead set out to explore how consistently different tools perform. By doing this, we aim to assess the maturity of the VEX tool field as a whole (rather than any particular tool). We have used the Jaccard and Tversky indices to produce similarity scores of tool performance for several different datasets created from container images. Overall, our results show a low level of consistency among the tools, thus indicating a low level of maturity in VEX tool space. We have performed a number of experiments to find and explanation to our results, but largely they are inconclusive and further research is needed to understand the underlying causalities of our findings.         ",
    "url": "https://arxiv.org/abs/2503.14388",
    "authors": [
      "Yekatierina Churakova Mathias Ekstedt"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2503.14405",
    "title": "DUNE: Distilling a Universal Encoder from Heterogeneous 2D and 3D Teachers",
    "abstract": "           Recent multi-teacher distillation methods have unified the encoders of multiple foundation models into a single encoder, achieving competitive performance on core vision tasks like classification, segmentation, and depth estimation. This led us to ask: Could similar success be achieved when the pool of teachers also includes vision models specialized in diverse tasks across both 2D and 3D perception? In this paper, we define and investigate the problem of heterogeneous teacher distillation, or co-distillation, a challenging multi-teacher distillation scenario where teacher models vary significantly in both (a) their design objectives and (b) the data they were trained on. We explore data-sharing strategies and teacher-specific encoding, and introduce DUNE, a single encoder excelling in 2D vision, 3D understanding, and 3D human perception. Our model achieves performance comparable to that of its larger teachers, sometimes even outperforming them, on their respective tasks. Notably, DUNE surpasses MASt3R in Map-free Visual Relocalization with a much smaller encoder.         ",
    "url": "https://arxiv.org/abs/2503.14405",
    "authors": [
      "Mert Bulent Sariyildiz",
      "Philippe Weinzaepfel",
      "Thomas Lucas",
      "Pau de Jorge",
      "Diane Larlus",
      "Yannis Kalantidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.14411",
    "title": "Unifying Text Semantics and Graph Structures for Temporal Text-attributed Graphs with Large Language Models",
    "abstract": "           Temporal graph neural networks (TGNNs) have shown remarkable performance in temporal graph modeling. However, real-world temporal graphs often possess rich textual information, giving rise to temporal text-attributed graphs (TTAGs). Such combination of dynamic text semantics and evolving graph structures introduces heightened complexity. Existing TGNNs embed texts statically and rely heavily on encoding mechanisms that biasedly prioritize structural information, overlooking the temporal evolution of text semantics and the essential interplay between semantics and structures for synergistic reinforcement. To tackle these issues, we present \\textbf{Cross}, a novel framework that seamlessly extends existing TGNNs for TTAG modeling. The key idea is to employ the advanced large language models (LLMs) to extract the dynamic semantics in text space and then generate expressive representations unifying both semantics and structures. Specifically, we propose a Temporal Semantics Extractor in the {Cross} framework, which empowers the LLM to offer the temporal semantic understanding of node's evolving contexts of textual neighborhoods, facilitating semantic dynamics. Subsequently, we introduce the Semantic-structural Co-encoder, which collaborates with the above Extractor for synthesizing illuminating representations by jointly considering both semantic and structural information while encouraging their mutual reinforcement. Extensive experimental results on four public datasets and one practical industrial dataset demonstrate {Cross}'s significant effectiveness and robustness.         ",
    "url": "https://arxiv.org/abs/2503.14411",
    "authors": [
      "Siwei Zhang",
      "Yun Xiong",
      "Yateng Tang",
      "Xi Chen",
      "Zian Jia",
      "Zehao Gu",
      "Jiarong Xu",
      "Jiawei Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.14418",
    "title": "Decentralized RISE-based Control for Exponential Heterogeneous Multi-Agent Target Tracking of Second-Order Nonlinear Systems",
    "abstract": "           This work presents a decentralized implementation of a Robust Integral of the Sign of the Error (RISE) controller for multi-agent target tracking problems with exponential convergence guarantees. Previous RISE-based approaches for multi-agent systems required 2-hop communication, limiting practical applicability. New insights from a Lyapunov-based design-analysis approach are used to eliminate the need for multi-hop communication required in previous literature, while yielding exponential target tracking. The new insights include the development of a new P-function which is developed which works in tandem with the inclusion of the interaction matrix in the Lyapunov function. Nonsmooth Lyapunov-based stability analysis methods are used to yield semi-global exponential convergence to the target agent state despite the presence of bounded disturbances with bounded derivatives. The resulting outcome is a controller that achieves exponential target tracking with only local information exchange between neighboring agents.         ",
    "url": "https://arxiv.org/abs/2503.14418",
    "authors": [
      "Cristian F. Nino",
      "Omkar Sudhir Patil",
      "Sage C. Edwards",
      "Warren E. Dixon"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2503.14421",
    "title": "ExDDV: A New Dataset for Explainable Deepfake Detection in Video",
    "abstract": "           The ever growing realism and quality of generated videos makes it increasingly harder for humans to spot deepfake content, who need to rely more and more on automatic deepfake detectors. However, deepfake detectors are also prone to errors, and their decisions are not explainable, leaving humans vulnerable to deepfake-based fraud and misinformation. To this end, we introduce ExDDV, the first dataset and benchmark for Explainable Deepfake Detection in Video. ExDDV comprises around 5.4K real and deepfake videos that are manually annotated with text descriptions (to explain the artifacts) and clicks (to point out the artifacts). We evaluate a number of vision-language models on ExDDV, performing experiments with various fine-tuning and in-context learning strategies. Our results show that text and click supervision are both required to develop robust explainable models for deepfake videos, which are able to localize and describe the observed artifacts. Our novel dataset and code to reproduce the results are available at this https URL.         ",
    "url": "https://arxiv.org/abs/2503.14421",
    "authors": [
      "Vlad Hondru",
      "Eduard Hogea",
      "Darian Onchis",
      "Radu Tudor Ionescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2503.14434",
    "title": "LLM-FE: Automated Feature Engineering for Tabular Data with LLMs as Evolutionary Optimizers",
    "abstract": "           Automated feature engineering plays a critical role in improving predictive model performance for tabular learning tasks. Traditional automated feature engineering methods are limited by their reliance on pre-defined transformations within fixed, manually designed search spaces, often neglecting domain knowledge. Recent advances using Large Language Models (LLMs) have enabled the integration of domain knowledge into the feature engineering process. However, existing LLM-based approaches use direct prompting or rely solely on validation scores for feature selection, failing to leverage insights from prior feature discovery experiments or establish meaningful reasoning between feature generation and data-driven performance. To address these challenges, we propose LLM-FE, a novel framework that combines evolutionary search with the domain knowledge and reasoning capabilities of LLMs to automatically discover effective features for tabular learning tasks. LLM-FE formulates feature engineering as a program search problem, where LLMs propose new feature transformation programs iteratively, and data-driven feedback guides the search process. Our results demonstrate that LLM-FE consistently outperforms state-of-the-art baselines, significantly enhancing the performance of tabular prediction models across diverse classification and regression benchmarks.         ",
    "url": "https://arxiv.org/abs/2503.14434",
    "authors": [
      "Nikhil Abhyankar",
      "Parshin Shojaee",
      "Chandan K. Reddy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2503.14442",
    "title": "Inducing Causal Structure for Interpretable Neural Networks Applied to Glucose Prediction for T1DM Patients",
    "abstract": "           Causal abstraction techniques such as Interchange Intervention Training (IIT) have been proposed to infuse neural network with expert knowledge encoded in causal models, but their application to real-world problems remains limited. This article explores the application of IIT in predicting blood glucose levels in Type 1 Diabetes Mellitus (T1DM) patients. The study utilizes an acyclic version of the simglucose simulator approved by the FDA to train a Multi-Layer Perceptron (MLP) model, employing IIT to impose causal relationships. Results show that the model trained with IIT effectively abstracted the causal structure and outperformed the standard one in terms of predictive performance across different prediction horizons (PHs) post-meal. Furthermore, the breakdown of the counterfactual loss can be leveraged to explain which part of the causal mechanism are more or less effectively captured by the model. These preliminary results suggest the potential of IIT in enhancing predictive models in healthcare by effectively complying with expert knowledge.         ",
    "url": "https://arxiv.org/abs/2503.14442",
    "authors": [
      "Ana Esponera",
      "Giovanni Cin\u00e0"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2503.14493",
    "title": "State Space Model Meets Transformer: A New Paradigm for 3D Object Detection",
    "abstract": "           DETR-based methods, which use multi-layer transformer decoders to refine object queries iteratively, have shown promising performance in 3D indoor object detection. However, the scene point features in the transformer decoder remain fixed, leading to minimal contributions from later decoder layers, thereby limiting performance improvement. Recently, State Space Models (SSM) have shown efficient context modeling ability with linear complexity through iterative interactions between system states and inputs. Inspired by SSMs, we propose a new 3D object DEtection paradigm with an interactive STate space model (DEST). In the interactive SSM, we design a novel state-dependent SSM parameterization method that enables system states to effectively serve as queries in 3D indoor detection tasks. In addition, we introduce four key designs tailored to the characteristics of point cloud and SSM: The serialization and bidirectional scanning strategies enable bidirectional feature interaction among scene points within the SSM. The inter-state attention mechanism models the relationships between state points, while the gated feed-forward network enhances inter-channel correlations. To the best of our knowledge, this is the first method to model queries as system states and scene points as system inputs, which can simultaneously update scene point features and query features with linear complexity. Extensive experiments on two challenging datasets demonstrate the effectiveness of our DEST-based method. Our method improves the GroupFree baseline in terms of AP50 on ScanNet V2 (+5.3) and SUN RGB-D (+3.2) datasets. Based on the VDETR baseline, Our method sets a new SOTA on the ScanNetV2 and SUN RGB-D datasets.         ",
    "url": "https://arxiv.org/abs/2503.14493",
    "authors": [
      "Chuxin Wang",
      "Wenfei Yang",
      "Xiang Liu",
      "Tianzhu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.13457",
    "title": "Man-in-the-Middle Attacks Targeting Quantum Cryptography",
    "abstract": "           The development of the Willow quantum chip by Google has sparked significant interest in quantum computing, ushering in a new wave of advancements in the field. As quantum computing technology continues to mature, secure quantum communication has garnered increasing attention. To establish secure communication, several quantum key distribution (QKD) protocols have been proposed, such as the BB84 protocol, which leverages the principles of quantum superposition and other quantum properties to ensure secure transmission. However, existing QKD protocols may face vulnerabilities under certain conditions. This study proposes two types of man-in-the-middle (MITM) attack techniques and demonstrates their potential to compromise quantum cryptography through practical case studies. Furthermore, this study proposes strategies to counteract these MITM attacks and proposes methods to enhance the security of quantum cryptographic systems. The findings offer valuable insights for the future implementation and deployment of secure quantum communication systems.         ",
    "url": "https://arxiv.org/abs/2503.13457",
    "authors": [
      "Abel C. H. Chen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2503.13473",
    "title": "Robust Detection of Extremely Thin Lines Using 0.2mm Piano Wire",
    "abstract": "           This study developed an algorithm capable of detecting a reference line (a 0.2 mm thick piano wire) to accurately determine the position of an automated installation robot within an elevator shaft. A total of 3,245 images were collected from the experimental tower of H Company, the leading elevator manufacturer in South Korea, and the detection performance was evaluated using four experimental approaches (GCH, GSCH, GECH, FCH). During the initial image processing stage, Gaussian blurring, sharpening filter, embossing filter, and Fourier Transform were applied, followed by Canny Edge Detection and Hough Transform. Notably, the method was developed to accurately extract the reference line by averaging the x-coordinates of the lines detected through the Hough Transform. This approach enabled the detection of the 0.2 mm thick piano wire with high accuracy, even in the presence of noise and other interfering factors (e.g., concrete cracks inside the elevator shaft or safety bars for filming equipment). The experimental results showed that Experiment 4 (FCH), which utilized Fourier Transform in the preprocessing stage, achieved the highest detection rate for the LtoL, LtoR, and RtoL datasets. Experiment 2(GSCH), which applied Gaussian blurring and a sharpening filter, demonstrated superior detection performance on the RtoR dataset. This study proposes a reference line detection algorithm that enables precise position calculation and control of automated robots in elevator shaft installation. Moreover, the developed method shows potential for applicability even in confined working spaces. Future work aims to develop a line detection algorithm equipped with machine learning-based hyperparameter tuning capabilities.         ",
    "url": "https://arxiv.org/abs/2503.13473",
    "authors": [
      "Jisoo Hong",
      "Youngjin Jung",
      "Jihwan Bae",
      "Seungho Song",
      "Sung-Woo Kang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2503.13477",
    "title": "Periodontal Bone Loss Analysis via Keypoint Detection With Heuristic Post-Processing",
    "abstract": "           Calculating percentage bone loss is a critical test for periodontal disease staging but is sometimes imprecise and time consuming when manually calculated. This study evaluates the application of a deep learning keypoint and object detection model, YOLOv8-pose, for the automatic identification of localised periodontal bone loss landmarks, conditions and staging. YOLOv8-pose was fine-tuned on 193 annotated periapical radiographs. We propose a keypoint detection metric, Percentage of Relative Correct Keypoints (PRCK), which normalises the metric to the average tooth size of teeth in the image. We propose a heuristic post-processing module that adjusts certain keypoint predictions to align with the edge of the related tooth, using a supporting instance segmentation model trained on an open source auxiliary dataset. The model can sufficiently detect bone loss keypoints, tooth boxes, and alveolar ridge resorption, but has insufficient performance at detecting detached periodontal ligament and furcation involvement. The model with post-processing demonstrated a PRCK 0.25 of 0.726 and PRCK 0.05 of 0.401 for keypoint detection, mAP 0.5 of 0.715 for tooth object detection, mesial dice score of 0.593 for periodontal staging, and dice score of 0.280 for furcation involvement. Our annotation methodology provides a stage agnostic approach to periodontal disease detection, by ensuring most keypoints are present for each tooth in the image, allowing small imbalanced datasets. Our PRCK metric allows accurate evaluation of keypoints in dental domains. Our post-processing module adjusts predicted keypoints correctly but is dependent on a minimum quality of prediction by the pose detection and segmentation models. Code: https:// this http URL. Dataset: this https URL.         ",
    "url": "https://arxiv.org/abs/2503.13477",
    "authors": [
      "Ryan Banks",
      "Vishal Thengane",
      "Mar\u00eda Eugenia Guerrero",
      "Nelly Maria Garc\u00eda-Madue\u00f1o",
      "Yunpeng Li",
      "Hongying Tang",
      "Akhilanand Chaurasia"
    ],
    "subjectives": [
      "Tissues and Organs (q-bio.TO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.13488",
    "title": "Onboard Terrain Classification via Stacked Intelligent Metasurface-Diffractive Deep Neural Networks from SAR Level-0 Raw Data",
    "abstract": "           This paper introduces a novel approach for real-time onboard terrain classification from Sentinel-1 (S1) level-0 raw In-phase/Quadrature (IQ) data, leveraging a Stacked Intelligent Metasurface (SIM) to perform inference directly in the analog wave domain. Unlike conventional digital deep neural networks, the proposed multi-layer Diffractive Deep Neural Network (D$^2$NN) setup implements automatic feature extraction as electromagnetic waves propagate through stacked metasurface layers. This design not only reduces reliance on expensive downlink bandwidth and high-power computing at terrestrial stations but also achieves performance levels around 90\\% directly from the real raw IQ data, in terms of accuracy, precision, recall, and F1 Score. Our method therefore helps bridge the gap between next-generation remote sensing tasks and in-orbit processing needs, paving the way for computationally efficient remote sensing applications.         ",
    "url": "https://arxiv.org/abs/2503.13488",
    "authors": [
      "Mengbing Liu",
      "Xin Li",
      "Jiancheng An",
      "Chau Yuen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.13490",
    "title": "Cascade of one-class classifier ensemble and dynamic naive Bayes classifier applied to the myoelectric-based upper limb prosthesis control with contaminated channels detection",
    "abstract": "           Modern upper limb bioprostheses are typically controlled by sEMG signals using a pattern recognition scheme in the control process. Unfortunately, the sEMG signal is very susceptible to contamination that deteriorates the quality of the control system and reduces the usefulness of the prosthesis in the patient's everyday life. In the paper, the authors propose a new recognition system intended for sEMG-based control of the hand prosthesis with detection of contaminated sEMG signals. The originality of the proposed solution lies in the co-operation of two recognition systems working in a cascade structure: (1) an ensemble of one-class classifiers used to recognise contaminated signals and (2) a naive Bayes classifier (NBC) which recognises the patient's intentions using the information about contaminations produced by the ensemble. Although in the proposed approach, the NBC model is changed dynamically, due to the multiplicative form of the classification functions, training can be performed in a one-shot procedure. Experimental studies were conducted using real sEMG signals. The results obtained confirm the hypothesis that the use of the one-class classifier ensemble and the dynamic NBC model leads to improved classification quality.         ",
    "url": "https://arxiv.org/abs/2503.13490",
    "authors": [
      "Pawel Trajdos",
      "Marek Kurzynski"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.13491",
    "title": "FLP-XR: Future Location Prediction on Extreme Scale Maritime Data in Real-time",
    "abstract": "           Movements of maritime vessels are inherently complex and challenging to model due to the dynamic and often unpredictable nature of maritime operations. Even within structured maritime environments, such as shipping lanes and port approaches, where vessels adhere to navigational rules and predefined sea routes, uncovering underlying patterns is far from trivial. The necessity for accurate modeling of the mobility of maritime vessels arises from the numerous applications it serves, including risk assessment for collision avoidance, optimization of shipping routes, and efficient port management. This paper introduces FLP-XR, a model that leverages maritime mobility data to construct a robust framework that offers precise predictions while ensuring extremely fast training and inference capabilities. We demonstrate the efficiency of our approach through an extensive experimental study using three real-world AIS datasets. According to the experimental results, FLP-XR outperforms the current state-of-the-art in many cases, whereas it performs 2-3 orders of magnitude faster in terms of training and inference.         ",
    "url": "https://arxiv.org/abs/2503.13491",
    "authors": [
      "George S. Theodoropoulos",
      "Andreas Patakis",
      "Andreas Tritsarolis",
      "Yannis Theodoridis"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.13493",
    "title": "Analysis of Learning-based Offshore Wind Power Prediction Models with Various Feature Combinations",
    "abstract": "           Accurate wind speed prediction is crucial for designing and selecting sites for offshore wind farms. This paper investigates the effectiveness of various machine learning models in predicting offshore wind power for a site near the Gulf of Mexico by analyzing meteorological data. After collecting and preprocessing meteorological data, nine different input feature combinations were designed to assess their impact on wind power predictions at multiple heights. The results show that using wind speed as the output feature improves prediction accuracy by approximately 10% compared to using wind power as the output. In addition, the improvement of multi-feature input compared with single-feature input is not obvious mainly due to the poor correlation among key features and limited generalization ability of models. These findings underscore the importance of selecting appropriate output features and highlight considerations for using machine learning in wind power forecasting, offering insights that could guide future wind power prediction models and conversion techniques.         ",
    "url": "https://arxiv.org/abs/2503.13493",
    "authors": [
      "Linhan Fang",
      "Fan Jiang",
      "Ann Mary Toms",
      "Xingpeng Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2503.13522",
    "title": "Advanced Deep Learning Methods for Protein Structure Prediction and Design",
    "abstract": "           After AlphaFold won the Nobel Prize, protein prediction with deep learning once again became a hot topic. We comprehensively explore advanced deep learning methods applied to protein structure prediction and design. It begins by examining recent innovations in prediction architectures, with detailed discussions on improvements such as diffusion based frameworks and novel pairwise attention modules. The text analyses key components including structure generation, evaluation metrics, multiple sequence alignment processing, and network architecture, thereby illustrating the current state of the art in computational protein modelling. Subsequent chapters focus on practical applications, presenting case studies that range from individual protein predictions to complex biomolecular interactions. Strategies for enhancing prediction accuracy and integrating deep learning techniques with experimental validation are thoroughly explored. The later sections review the industry landscape of protein design, highlighting the transformative role of artificial intelligence in biotechnology and discussing emerging market trends and future challenges. Supplementary appendices provide essential resources such as databases and open source tools, making this volume a valuable reference for researchers and students.         ",
    "url": "https://arxiv.org/abs/2503.13522",
    "authors": [
      "Weikun Wu",
      "Tianyang Wang",
      "Yichao Zhang",
      "Ningyuan Deng",
      "Xinyuan Song",
      "Ziqian Bi",
      "Zheyu Yao",
      "Keyu Chen",
      "Ming Li",
      "Qian Niu",
      "Junyu Liu",
      "Benji Peng",
      "Sen Zhang",
      "Ming Liu",
      "Li Zhang",
      "Xuanhe Pan",
      "Jinlang Wang",
      "Pohsun Feng",
      "Yizhu Wen",
      "Lawrence KQ Yan",
      "Hongming Tseng",
      "Yan Zhong",
      "Yunze Wang",
      "Ziyuan Qin",
      "Bowen Jing",
      "Junjie Yang",
      "Jun Zhou",
      "Chia Xin Liang",
      "Junhao Song"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.13578",
    "title": "Convolutional neural network for early detection of lameness and irregularity in horses using an IMU sensor",
    "abstract": "           Lameness and gait irregularities are significant concerns in equine health management, affecting performance, welfare, and economic value. Traditional observational methods rely on subjective expert assessments, which can lead to inconsistencies in detecting subtle or early-stage lameness. While AI-based approaches have emerged, many require multiple sensors, force plates, or video systems, making them costly and impractical for field deployment. In this applied research study, we present a stride-level classification system that utilizes a single inertial measurement unit (IMU) and a one-dimensional convolutional neural network (1D CNN) to objectively differentiate between sound and lame horses, with a primary focus on the trot gait. The proposed system was tested under real-world conditions, achieving a 90% session-level accuracy with no false positives, demonstrating its robustness for practical applications. By employing a single, non-intrusive, and readily available sensor, our approach significantly reduces the complexity and cost of hardware requirements while maintaining high classification performance. These results highlight the potential of our CNN-based method as a field-tested, scalable solution for automated lameness detection. By enabling early diagnosis, this system offers a valuable tool for preventing minor gait irregularities from developing into severe conditions, ultimately contributing to improved equine welfare and performance in veterinary and equestrian practice.         ",
    "url": "https://arxiv.org/abs/2503.13578",
    "authors": [
      "Beno\u00eet Savoini",
      "Jonathan Bertolaccini",
      "St\u00e9phane Montavon",
      "Michel Deriaz"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.13581",
    "title": "Subgroup Performance of a Commercial Digital Breast Tomosynthesis Model for Breast Cancer Detection",
    "abstract": "           While research has established the potential of AI models for mammography to improve breast cancer screening outcomes, there have not been any detailed subgroup evaluations performed to assess the strengths and weaknesses of commercial models for digital breast tomosynthesis (DBT) imaging. This study presents a granular evaluation of the Lunit INSIGHT DBT model on a large retrospective cohort of 163,449 screening mammography exams from the Emory Breast Imaging Dataset (EMBED). Model performance was evaluated in a binary context with various negative exam types (162,081 exams) compared against screen detected cancers (1,368 exams) as the positive class. The analysis was stratified across demographic, imaging, and pathologic subgroups to identify potential disparities. The model achieved an overall AUC of 0.91 (95% CI: 0.90-0.92) with a precision of 0.08 (95% CI: 0.08-0.08), and a recall of 0.73 (95% CI: 0.71-0.76). Performance was found to be robust across demographics, but cases with non-invasive cancers (AUC: 0.85, 95% CI: 0.83-0.87), calcifications (AUC: 0.80, 95% CI: 0.78-0.82), and dense breast tissue (AUC: 0.90, 95% CI: 0.88-0.91) were associated with significantly lower performance compared to other groups. These results highlight the need for detailed evaluation of model characteristics and vigilance in considering adoption of new tools for clinical deployment.         ",
    "url": "https://arxiv.org/abs/2503.13581",
    "authors": [
      "Beatrice Brown-Mulry",
      "Rohan Satya Isaac",
      "Sang Hyup Lee",
      "Ambika Seth",
      "KyungJee Min",
      "Theo Dapamede",
      "Frank Li",
      "Aawez Mansuri",
      "MinJae Woo",
      "Christian Allison Fauria-Robinson",
      "Bhavna Paryani",
      "Judy Wawira Gichoya",
      "Hari Trivedi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.13833",
    "title": "Causal Discovery from Data Assisted by Large Language Models",
    "abstract": "           Knowledge driven discovery of novel materials necessitates the development of the causal models for the property emergence. While in classical physical paradigm the causal relationships are deduced based on the physical principles or via experiment, rapid accumulation of observational data necessitates learning causal relationships between dissimilar aspects of materials structure and functionalities based on observations. For this, it is essential to integrate experimental data with prior domain knowledge. Here we demonstrate this approach by combining high-resolution scanning transmission electron microscopy (STEM) data with insights derived from large language models (LLMs). By fine-tuning ChatGPT on domain-specific literature, such as arXiv papers on ferroelectrics, and combining obtained information with data-driven causal discovery, we construct adjacency matrices for Directed Acyclic Graphs (DAGs) that map the causal relationships between structural, chemical, and polarization degrees of freedom in Sm-doped BiFeO3 (SmBFO). This approach enables us to hypothesize how synthesis conditions influence material properties, particularly the coercive field (E0), and guides experimental validation. The ultimate objective of this work is to develop a unified framework that integrates LLM-driven literature analysis with data-driven discovery, facilitating the precise engineering of ferroelectric materials by establishing clear connections between synthesis conditions and their resulting material properties.         ",
    "url": "https://arxiv.org/abs/2503.13833",
    "authors": [
      "Kamyar Barakati",
      "Alexander Molak",
      "Chris Nelson",
      "Xiaohang Zhang",
      "Ichiro Takeuchi",
      "Sergei V. Kalinin"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.14019",
    "title": "Monoidal Rips: Stable Multiparameter Filtrations of Directed Networks",
    "abstract": "           We introduce the monoidal Rips filtration, a filtered simplicial set for weighted directed graphs and other lattice-valued networks. Our construction generalizes the Vietoris-Rips filtration for metric spaces by replacing the maximum operator, determining the filtration values, with a more general monoidal product. We establish interleaving guarantees for the monoidal Rips persistent homology, capturing existing stability results for real-valued networks. When the lattice is a product of totally ordered sets, we are in the setting of multiparameter persistence. Here, the interleaving distance is bounded in terms of a generalized network distance. We use this to prove a novel stability result for the sublevel Rips bifiltration. Our experimental results show that our method performs better than flagser in a graph regression task, and that combining different monoidal products in point cloud classification can improve performance.         ",
    "url": "https://arxiv.org/abs/2503.14019",
    "authors": [
      "Nello Blaser",
      "Morten Brun",
      "Odin Hoff Gardaa",
      "Lars M. Salbu"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2503.14034",
    "title": "Shift, Scale and Rotation Invariant Multiple Object Detection using Balanced Joint Transform Correlator",
    "abstract": "           The Polar Mellin Transform (PMT) is a well-known technique that converts images into shift, scale and rotation invariant signatures for object detection using opto-electronic correlators. However, this technique cannot be properly applied when there are multiple targets in a single input. Here, we propose a Segmented PMT (SPMT) that extends this methodology for cases where multiple objects are present within the same frame. Simulations show that this SPMT can be integrated into an opto-electronic joint transform correlator to create a correlation system capable of detecting multiple objects simultaneously, presenting robust detection capabilities across various transformation conditions, with remarkable discrimination between matching and non-matching targets.         ",
    "url": "https://arxiv.org/abs/2503.14034",
    "authors": [
      "Xi Shen",
      "Julian Gamboa",
      "Tabassom Hamidfar",
      "Shamima Mitu",
      "Selim M. Shahriar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.14095",
    "title": "Towards Location-Specific Precipitation Projections Using Deep Neural Networks",
    "abstract": "           Accurate precipitation estimates at individual locations are crucial for weather forecasting and spatial analysis. This study presents a paradigm shift by leveraging Deep Neural Networks (DNNs) to surpass traditional methods like Kriging for station-specific precipitation approximation. We propose two innovative NN architectures: one utilizing precipitation, elevation, and location, and another incorporating additional meteorological parameters like humidity, temperature, and wind speed. Trained on a vast dataset (1980-2019), these models outperform Kriging across various evaluation metrics (correlation coefficient, root mean square error, bias, and skill score) on a five-year validation set. This compelling evidence demonstrates the transformative power of deep learning for spatial prediction, offering a robust and precise alternative for station-specific precipitation estimation.         ",
    "url": "https://arxiv.org/abs/2503.14095",
    "authors": [
      "Bipin Kumar",
      "Bhvisy Kumar Yadav",
      "Soumypdeep Mukhopadhyay",
      "Rakshit Rohan",
      "Bhupendra Bahadur Singh",
      "Rajib Chattopadhyay",
      "Nagraju Chilukoti",
      "Atul Kumar Sahai"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.14253",
    "title": "CINNAMON: A hybrid approach to change point detection and parameter estimation in single-particle tracking data",
    "abstract": "           Change point detection has become an important part of the analysis of the single-particle tracking data, as it allows one to identify moments, in which the motion patterns of observed particles undergo significant changes. The segmentation of diffusive trajectories based on those moments may provide insight into various phenomena in soft condensed matter and biological physics. In this paper, we propose CINNAMON, a hybrid approach to classifying single-particle tracking trajectories, detecting change points within them, and estimating diffusion parameters in the segments between the change points. Our method is based on a combination of neural networks, feature-based machine learning, and statistical techniques. It has been benchmarked in the second Anomalous Diffusion Challenge. The method offers a high level of interpretability due to its analytical and feature-based components. A potential use of features from topological data analysis is also discussed.         ",
    "url": "https://arxiv.org/abs/2503.14253",
    "authors": [
      "Jakub Malinowski",
      "Marcin Kostrzewa",
      "Micha\u0142 Balcerek",
      "Weronika Tomczuk",
      "Janusz Szwabi\u0144ski"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.14287",
    "title": "Cross-Environment Transfer Learning for Location-Aided Beam Prediction in 5G and Beyond Millimeter-Wave Networks",
    "abstract": "           Millimeter-wave (mm-wave) communications requirebeamforming and consequent precise beam alignmentbetween the gNodeB (gNB) and the user equipment (UE) toovercome high propagation losses. This beam alignment needs tobe constantly updated for different UE locations based on beamsweepingradio frequency measurements, leading to significantbeam management overhead. One potential solution involvesusing machine learning (ML) beam prediction algorithms thatleverage UE position information to select the serving beamwithout the overhead of beam sweeping. However, the highlysite-specific nature of mm-wave propagation means that MLmodels require training from scratch for each scenario, whichis inefficient in practice. In this paper, we propose a robustcross-environment transfer learning solution for location-aidedbeam prediction, whereby the ML model trained on a referencegNB is transferred to a target gNB by fine-tuning with a limiteddataset. Extensive simulation results based on ray-tracing in twourban environments show the effectiveness of our solution forboth inter- and intra-city model transfer. Our results show thatby training the model on a reference gNB and transferring themodel by fine-tuning with only 5% of the target gNB dataset,we can achieve 80% accuracy in predicting the best beamfor the target gNB. Importantly, our approach improves thepoor generalization accuracy of transferring the model to newenvironments without fine-tuning by around 75 percentage this http URL demonstrates that transfer learning enables high predictionaccuracy while reducing the computational and training datasetcollection burden of ML-based beam prediction, making itpractical for 5G-and-beyond deployments.         ",
    "url": "https://arxiv.org/abs/2503.14287",
    "authors": [
      "Enrico Tosi",
      "Panwei Hu",
      "Aleksandar Ichkov",
      "Marina Petrova",
      "Ljiljana Simi\u0107"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2503.14292",
    "title": "Computing the Wave: Where the Gravitational Wave Community benefits from High-Energy Physics, and where it differs ?",
    "abstract": "           High-Energy Physics (HEP) and Gravitational Wave (GW) communities serve different scientific purposes. However, their methodologies might potentially offer mutual enrichment through common software developments. A suite of libraries is currently being prototyped and made available at this https URL, extending at no cost the CERN ROOT data analysis framework toward advanced signal processing. We will also present a performance benchmark comparing the FFTW and KFR library performances.         ",
    "url": "https://arxiv.org/abs/2503.14292",
    "authors": [
      "Marco Meyer-Conde",
      "Nobuyuki Kanda",
      "Hirotaka Takahashi",
      "Ken-ichi Oohara",
      "Kazuki Sakai"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Software Engineering (cs.SE)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2503.14343",
    "title": "Multi-Prototype Embedding Refinement for Semi-Supervised Medical Image Segmentation",
    "abstract": "           Medical image segmentation aims to identify anatomical structures at the voxel-level. Segmentation accuracy relies on distinguishing voxel differences. Compared to advancements achieved in studies of the inter-class variance, the intra-class variance receives less attention. Moreover, traditional linear classifiers, limited by a single learnable weight per class, struggle to capture this finer distinction. To address the above challenges, we propose a Multi-Prototype-based Embedding Refinement method for semi-supervised medical image segmentation. Specifically, we design a multi-prototype-based classification strategy, rethinking the segmentation from the perspective of structural relationships between voxel embeddings. The intra-class variations are explored by clustering voxels along the distribution of multiple prototypes in each class. Next, we introduce a consistency constraint to alleviate the limitation of linear classifiers. This constraint integrates different classification granularities from a linear classifier and the proposed prototype-based classifier. In the thorough evaluation on two popular benchmarks, our method achieves superior performance compared with state-of-the-art methods. Code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2503.14343",
    "authors": [
      "Yali Bi",
      "Enyu Che",
      "Yinan Chen",
      "Yuanpeng He",
      "Jingwei Qu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.14377",
    "title": "Advancing Medical Representation Learning Through High-Quality Data",
    "abstract": "           Despite the growing scale of medical Vision-Language datasets, the impact of dataset quality on model performance remains under-explored. We introduce Open-PMC, a high-quality medical dataset from PubMed Central, containing 2.2 million image-text pairs, enriched with image modality annotations, subfigures, and summarized in-text references. Notably, the in-text references provide richer medical context, extending beyond the abstract information typically found in captions. Through extensive experiments, we benchmark Open-PMC against larger datasets across retrieval and zero-shot classification tasks. Our results show that dataset quality-not just size-drives significant performance gains. We complement our benchmark with an in-depth analysis of feature representation. Our findings highlight the crucial role of data curation quality in advancing multimodal medical AI. We release Open-PMC, along with the trained models and our codebase.         ",
    "url": "https://arxiv.org/abs/2503.14377",
    "authors": [
      "Negin Baghbanzadeh",
      "Adibvafa Fallahpour",
      "Yasaman Parhizkar",
      "Franklin Ogidi",
      "Shuvendu Roy",
      "Sajad Ashkezari",
      "Vahid Reza Khazaie",
      "Michael Colacci",
      "Ali Etemad",
      "Arash Afkanpour",
      "Elham Dolatabadi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2503.14395",
    "title": "Weakly Supervised Spatial Implicit Neural Representation Learning for 3D MRI-Ultrasound Deformable Image Registration in HDR Prostate Brachytherapy",
    "abstract": "           Purpose: Accurate 3D MRI-ultrasound (US) deformable registration is critical for real-time guidance in high-dose-rate (HDR) prostate brachytherapy. We present a weakly supervised spatial implicit neural representation (SINR) method to address modality differences and pelvic anatomy challenges. Methods: The framework uses sparse surface supervision from MRI/US segmentations instead of dense intensity matching. SINR models deformations as continuous spatial functions, with patient-specific surface priors guiding a stationary velocity field for biologically plausible deformations. Validation included 20 public Prostate-MRI-US-Biopsy cases and 10 institutional HDR cases, evaluated via Dice similarity coefficient (DSC), mean surface distance (MSD), and 95% Hausdorff distance (HD95). Results: The proposed method achieved robust registration. For the public dataset, prostate DSC was $0.93 \\pm 0.05$, MSD $0.87 \\pm 0.10$ mm, and HD95 $1.58 \\pm 0.37$ mm. For the institutional dataset, prostate CTV achieved DSC $0.88 \\pm 0.09$, MSD $1.21 \\pm 0.38$ mm, and HD95 $2.09 \\pm 1.48$ mm. Bladder and rectum performance was lower due to ultrasound's limited field of view. Visual assessments confirmed accurate alignment with minimal discrepancies. Conclusion: This study introduces a novel weakly supervised SINR-based approach for 3D MRI-US deformable registration. By leveraging sparse surface supervision and spatial priors, it achieves accurate, robust, and computationally efficient registration, enhancing real-time image guidance in HDR prostate brachytherapy and improving treatment precision.         ",
    "url": "https://arxiv.org/abs/2503.14395",
    "authors": [
      "Jing Wang",
      "Ruirui Liu",
      "Yu Lei",
      "Michael J. Baine",
      "Tian Liu",
      "Yang Lei"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.14448",
    "title": "Pauli Network Circuit Synthesis with Reinforcement Learning",
    "abstract": "           We introduce a Reinforcement Learning (RL)-based method for re-synthesis of quantum circuits containing arbitrary Pauli rotations alongside Clifford operations. By collapsing each sub-block to a compact representation and then synthesizing it step-by-step through a learned heuristic, we obtain circuits that are both shorter and compliant with hardware connectivity constraints. We find that the method is fast enough and good enough to work as an optimization procedure: in direct comparisons on 6-qubit random Pauli Networks against state-of-the-art heuristic methods, our RL approach yields over 2x reduction in two-qubit gate count, while executing in under 10 milliseconds per circuit. We further integrate the method into a collect-and-re-synthesize pipeline, applied as a Qiskit transpiler pass, where we observe average improvements of 20% in two-qubit gate count and depth, reaching up to 60% for many instances, across the Benchpress benchmark. These results highlight the potential of RL-driven synthesis to significantly improve circuit quality in realistic, large-scale quantum transpilation workloads.         ",
    "url": "https://arxiv.org/abs/2503.14448",
    "authors": [
      "Ayushi Dubal",
      "David Kremer",
      "Simon Martiel",
      "Victor Villar",
      "Derek Wang",
      "Juan Cruz-Benito"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.14459",
    "title": "Doubly robust identification of treatment effects from multiple environments",
    "abstract": "           Practical and ethical constraints often require the use of observational data for causal inference, particularly in medicine and social sciences. Yet, observational datasets are prone to confounding, potentially compromising the validity of causal conclusions. While it is possible to correct for biases if the underlying causal graph is known, this is rarely a feasible ask in practical scenarios. A common strategy is to adjust for all available covariates, yet this approach can yield biased treatment effect estimates, especially when post-treatment or unobserved variables are present. We propose RAMEN, an algorithm that produces unbiased treatment effect estimates by leveraging the heterogeneity of multiple data sources without the need to know or learn the underlying causal graph. Notably, RAMEN achieves doubly robust identification: it can identify the treatment effect whenever the causal parents of the treatment or those of the outcome are observed, and the node whose parents are observed satisfies an invariance assumption. Empirical evaluations on synthetic and real-world datasets show that our approach outperforms existing methods.         ",
    "url": "https://arxiv.org/abs/2503.14459",
    "authors": [
      "Piersilvio De Bartolomeis",
      "Julia Kostin",
      "Javier Abad",
      "Yixin Wang",
      "Fanny Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2503.14473",
    "title": "EnQode: Fast Amplitude Embedding for Quantum Machine Learning Using Classical Data",
    "abstract": "           Amplitude embedding (AE) is essential in quantum machine learning (QML) for encoding classical data onto quantum circuits. However, conventional AE methods suffer from deep, variable-length circuits that introduce high output error due to extensive gate usage and variable error rates across samples, resulting in noise-driven inconsistencies that degrade model accuracy. We introduce EnQode, a fast AE technique based on symbolic representation that addresses these limitations by clustering dataset samples and solving for cluster mean states through a low-depth, machine-specific ansatz. Optimized to reduce physical gates and SWAP operations, EnQode ensures all samples face consistent, low noise levels by standardizing circuit depth and composition. With over 90% fidelity in data mapping, EnQode enables robust, high-performance QML on noisy intermediate-scale quantum (NISQ) devices. Our open-source solution provides a scalable and efficient alternative for integrating classical data with quantum models.         ",
    "url": "https://arxiv.org/abs/2503.14473",
    "authors": [
      "Jason Han",
      "Nicholas S. DiBrita",
      "Younghyun Cho",
      "Hengrui Luo",
      "Tirthak Patel"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.06492",
    "title": "FNDaaS: Content-agnostic Detection of Fake News sites",
    "abstract": "           Automatic fake news detection is a challenging problem in misinformation spreading, and it has tremendous real-world political and social impacts. Past studies have proposed machine learning-based methods for detecting such fake news, focusing on different properties of the published news articles, such as linguistic characteristics of the actual content, which however have limitations due to the apparent language barriers. Departing from such efforts, we propose Fake News Detection-as-a Service (FNDaaS), the first automatic, content-agnostic fake news detection method, that considers new and unstudied features such as network and structural characteristics per news website. This method can be enforced as-a-Service, either at the ISP-side for easier scalability and maintenance, or user-side for better end-user privacy. We demonstrate the efficacy of our method using more than 340K datapoints crawled from existing lists of 637 fake and 1183 real news websites, and by building and testing a proof of concept system that materializes our proposal. Our analysis of data collected from these websites shows that the vast majority of fake news domains are very young and appear to have lower time periods of an IP associated with their domain than real news ones. By conducting various experiments with machine learning classifiers, we demonstrate that FNDaaS can achieve an AUC score of up to 0.967 on past sites, and up to 77-92% accuracy on newly-flagged ones.         ",
    "url": "https://arxiv.org/abs/2212.06492",
    "authors": [
      "Panagiotis Papadopoulos",
      "Dimitris Spithouris",
      "Evangelos P. Markatos",
      "Nicolas Kourtellis"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.05751",
    "title": "Dynamic Demand-Aware Link Scheduling for Reconfigurable Datacenters",
    "abstract": "           Emerging reconfigurable datacenters allow to dynamically adjust the network topology in a demand-aware manner. These datacenters rely on optical switches which can be reconfigured to provide direct connectivity between racks, in the form of edge-disjoint matchings. While state-of-the-art optical switches in principle support microsecond reconfigurations, the demand-aware topology optimization constitutes a bottleneck. This paper proposes a dynamic algorithms approach to improve the performance of reconfigurable datacenter networks, by supporting faster reactions to changes in the traffic demand. This approach leverages the temporal locality of traffic patterns in order to update the interconnecting matchings incrementally, rather than recomputing them from scratch. In particular, we present six (batch-)dynamic algorithms and compare them to static ones. We conduct an extensive empirical evaluation on 176 synthetic and 39 real-world traces, and find that dynamic algorithms can both significantly improve the running time and reduce the number of changes to the configuration, especially in networks with high temporal locality, while retaining matching weight.         ",
    "url": "https://arxiv.org/abs/2301.05751",
    "authors": [
      "Kathrin Hanauer",
      "Monika Henzinger",
      "Lara Ost",
      "Stefan Schmid"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2301.12351",
    "title": "Emerging Synergies in Causality and Deep Generative Models: A Survey",
    "abstract": "           In the field of artificial intelligence (AI), the quest to understand and model data-generating processes (DGPs) is of paramount importance. Deep generative models (DGMs) have proven adept in capturing complex data distributions but often fall short in generalization and interpretability. On the other hand, causality offers a structured lens to comprehend the mechanisms driving data generation and highlights the causal-effect dynamics inherent in these processes. While causality excels in interpretability and the ability to extrapolate, it grapples with intricacies of high-dimensional spaces. Recognizing the synergistic potential, we delve into the confluence of causality and DGMs. We elucidate the integration of causal principles within DGMs, investigate causal identification using DGMs, and navigate an emerging research frontier of causality in large-scale generative models, particularly generative large language models (LLMs). We offer insights into methodologies, highlight open challenges, and suggest future directions, positioning our comprehensive review as an essential guide in this swiftly emerging and evolving area.         ",
    "url": "https://arxiv.org/abs/2301.12351",
    "authors": [
      "Guanglin Zhou",
      "Shaoan Xie",
      "Guang-Yuan Hao",
      "Shiming Chen",
      "Biwei Huang",
      "Xiwei Xu",
      "Chen Wang",
      "Liming Zhu",
      "Lina Yao",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15598",
    "title": "ReLU Neural Networks with Linear Layers are Biased Towards Single- and Multi-Index Models",
    "abstract": "           Neural networks often operate in the overparameterized regime, in which there are far more parameters than training samples, allowing the training data to be fit perfectly. That is, training the network effectively learns an interpolating function, and properties of the interpolant affect predictions the network will make on new samples. This manuscript explores how properties of such functions learned by neural networks of depth greater than two layers. Our framework considers a family of networks of varying depths that all have the same capacity but different representation costs. The representation cost of a function induced by a neural network architecture is the minimum sum of squared weights needed for the network to represent the function; it reflects the function space bias associated with the architecture. Our results show that adding additional linear layers to the input side of a shallow ReLU network yields a representation cost favoring functions with low mixed variation -- that is, it has limited variation in directions orthogonal to a low-dimensional subspace and can be well approximated by a single- or multi-index model. This bias occurs because minimizing the sum of squared weights of the linear layers is equivalent to minimizing a low-rank promoting Schatten quasi-norm of a single \"virtual\" weight matrix. Our experiments confirm this behavior in standard network training regimes. They additionally show that linear layers can improve generalization and the learned network is well-aligned with the true latent low-dimensional linear subspace when data is generated using a multi-index model.         ",
    "url": "https://arxiv.org/abs/2305.15598",
    "authors": [
      "Suzanna Parkinson",
      "Greg Ongie",
      "Rebecca Willett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.00637",
    "title": "On Embedding B-Splines in Recursive State Estimation",
    "abstract": "           We present a principled study on establishing a probabilistic framework for continuous-time state estimation. B-splines are embedded into state-space modeling as a continuous-time intermediate, linking the state of recurrent control points with asynchronous sensor measurements. Based thereon, the spline-embedded recursive estimation scheme is established w.r.t. common sensor fusion tasks, and corresponding technique for modeling uncertain motion estimates is introduced. We evaluate the proposed estimation scheme using real-world-based synthesized data in a range-inertial setting. Numerical results demonstrate several advantages of spline embedding in recursive state estimation compared to classical discrete-time filtering approaches.         ",
    "url": "https://arxiv.org/abs/2307.00637",
    "authors": [
      "Kailai Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.05304",
    "title": "Evidence of social learning across symbolic cultural barriers in sperm whales",
    "abstract": "           We provide quantitative evidence suggesting social learning in sperm whales across socio-cultural boundaries, using acoustic data from the Pacific and Atlantic Oceans. Traditionally, sperm whale populations are categorized into clans based on their vocal repertoire: the rhythmically patterned click sequences (codas) that they use. Among these codas, identity codas function as symbolic markers for each clan, accounting for 35-60% of codas they produce. We introduce a computational method to model whale speech, which encodes rhythmic micro-variations within codas, capturing their vocal style. We find that vocal style-clans closely align with repertoire-clans. However, contrary to vocal repertoire, we show that sympatry increases vocal style similarity between clans for non-identity codas, i.e. most codas, suggesting social learning across cultural boundaries. More broadly, this subcoda structure model offers a framework for comparing communication systems in other species, with potential implications for deeper understanding of vocal and cultural transmission within animal societies.         ",
    "url": "https://arxiv.org/abs/2307.05304",
    "authors": [
      "Ant\u00f3nio Leit\u00e3o",
      "Maxime Lucas",
      "Simone Poetto",
      "Taylor A. Hersh",
      "Shane Gero",
      "David Gruber",
      "Michael Bronstein",
      "Giovanni Petri"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2308.02000",
    "title": "Bridging Neural and Symbolic Representations with Transitional Dictionary Learning",
    "abstract": "           This paper introduces a novel Transitional Dictionary Learning (TDL) framework that can implicitly learn symbolic knowledge, such as visual parts and relations, by reconstructing the input as a combination of parts with implicit relations. We propose a game-theoretic diffusion model to decompose the input into visual parts using the dictionaries learned by the Expectation Maximization (EM) algorithm, implemented as the online prototype clustering, based on the decomposition results. Additionally, two metrics, clustering information gain, and heuristic shape score are proposed to evaluate the model. Experiments are conducted on three abstract compositional visual object datasets, which require the model to utilize the compositionality of data instead of simply exploiting visual features. Then, three tasks on symbol grounding to predefined classes of parts and relations, as well as transfer learning to unseen classes, followed by a human evaluation, were carried out on these datasets. The results show that the proposed method discovers compositional patterns, which significantly outperforms the state-of-the-art unsupervised part segmentation methods that rely on visual features from pre-trained backbones. Furthermore, the proposed metrics are consistent with human evaluations.         ",
    "url": "https://arxiv.org/abs/2308.02000",
    "authors": [
      "Junyan Cheng",
      "Peter Chin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.15329",
    "title": "BASED: Bundle-Adjusting Surgical Endoscopic Dynamic Video Reconstruction using Neural Radiance Fields",
    "abstract": "           Reconstruction of deformable scenes from endoscopic videos is important for many applications such as intraoperative navigation, surgical visual perception, and robotic surgery. It is a foundational requirement for realizing autonomous robotic interventions for minimally invasive surgery. However, previous approaches in this domain have been limited by their modular nature and are confined to specific camera and scene settings. Our work adopts the Neural Radiance Fields (NeRF) approach to learning 3D implicit representations of scenes that are both dynamic and deformable over time, and furthermore with unknown camera poses. We demonstrate this approach on endoscopic surgical scenes from robotic surgery. This work removes the constraints of known camera poses and overcomes the drawbacks of the state-of-the-art unstructured dynamic scene reconstruction technique, which relies on the static part of the scene for accurate reconstruction. Through several experimental datasets, we demonstrate the versatility of our proposed model to adapt to diverse camera and scene settings, and show its promise for both current and future robotic surgical systems.         ",
    "url": "https://arxiv.org/abs/2309.15329",
    "authors": [
      "Shreya Saha",
      "Zekai Liang",
      "Shan Lin",
      "Jingpei Lu",
      "Michael Yip",
      "Sainan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07649",
    "title": "Automated Layout and Control Co-Design of Robust Multi-UAV Transportation Systems",
    "abstract": "           The joint optimization of physical parameters and controllers in robotic systems is challenging. This is due to the difficulties of predicting the effect that changes in physical parameters have on final performances. At the same time, physical and morphological modifications can improve robot capabilities, perhaps completely unlocking new skills and tasks. We present a novel approach to co-optimize the physical layout and the control of a cooperative aerial transportation system. The goal is to achieve the most precise and robust flight when carrying a payload. We assume the agents are connected to the payload through rigid attachments, essentially transforming the whole system into a larger flying object with ``thrust modules\" at the attachment locations of the quadcopters. We investigate the optimal arrangement of the thrust modules around the payload, so that the resulting system achieves the best disturbance rejection capabilities. We propose a novel metric of robustness inspired by H2 control, and propose an algorithm to optimize the layout of the vehicles around the object and their controller altogether. We experimentally validate the effectiveness of our approach using fleets of three and four quadcopters and payloads of diverse shapes.         ",
    "url": "https://arxiv.org/abs/2310.07649",
    "authors": [
      "Carlo Bosio",
      "Mark W. Mueller"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.07684",
    "title": "Hypergraph Neural Networks through the Lens of Message Passing: A Common Perspective to Homophily and Architecture Design",
    "abstract": "           Most of the current hypergraph learning methodologies and benchmarking datasets in the hypergraph realm are obtained by lifting procedures from their graph analogs, leading to overshadowing specific characteristics of hypergraphs. This paper attempts to confront some pending questions in that regard: Q1 Can the concept of homophily play a crucial role in Hypergraph Neural Networks (HNNs)? Q2 Is there room for improving current HNN architectures by carefully addressing specific characteristics of higher-order networks? Q3 Do existing datasets provide a meaningful benchmark for HNNs? To address them, we first introduce a novel conceptualization of homophily in higher-order networks based on a Message Passing (MP) scheme, unifying both the analytical examination and the modeling of higher-order networks. Further, we investigate some natural, yet mostly unexplored, strategies for processing higher-order structures within HNNs such as keeping hyperedge-dependent node representations, or performing node/hyperedge stochastic samplings, leading us to the most general MP formulation up to date -MultiSet-, as well as to an original architecture design, MultiSetMixer. Finally, we conduct an extensive set of experiments that contextualize our proposals and successfully provide insights about our inquiries.         ",
    "url": "https://arxiv.org/abs/2310.07684",
    "authors": [
      "Lev Telyatnikov",
      "Maria Sofia Bucarelli",
      "Guillermo Bernardez",
      "Olga Zaghen",
      "Simone Scardapane",
      "Pietro Lio"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.17042",
    "title": "Stochastic Gradient Sampling for Enhancing Neural Networks Training",
    "abstract": "           In this paper, we introduce StochGradAdam, a novel optimizer designed as an extension of the Adam algorithm, incorporating stochastic gradient sampling techniques to improve computational efficiency while maintaining robust performance. StochGradAdam optimizes by selectively sampling a subset of gradients during training, reducing the computational cost while preserving the advantages of adaptive learning rates and bias corrections found in Adam. Our experimental results, applied to image classification and segmentation tasks, demonstrate that StochGradAdam can achieve comparable or superior performance to Adam, even when using fewer gradient updates per iteration. By focusing on key gradient updates, StochGradAdam offers stable convergence and enhanced exploration of the loss landscape, while mitigating the impact of noisy gradients. The results suggest that this approach is particularly effective for large-scale models and datasets, providing a promising alternative to traditional optimization techniques for deep learning applications.         ",
    "url": "https://arxiv.org/abs/2310.17042",
    "authors": [
      "Juyoung Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2401.10785",
    "title": "Composite learning backstepping control with guaranteed exponential stability and robustness",
    "abstract": "           Adaptive backstepping control provides a feasible solution to achieve asymptotic tracking for mismatched uncertain nonlinear systems. However, input-to-state stability depends on high-gain feedback generated by nonlinear damping terms, and closed-loop exponential stability with parameter convergence involves a stringent condition named persistent excitation (PE). This paper proposes a composite learning backstepping control (CLBC) strategy based on modular backstepping and high-order tuners to compensate for the transient process of parameter estimation and achieve closed-loop exponential stability without the nonlinear damping terms and the PE condition. A novel composite learning mechanism that maximizes the staged exciting strength is designed for parameter estimation, such that parameter convergence can be achieved under a condition of interval excitation (IE) or even partial IE that is strictly weaker than PE. An extra prediction error is employed in the adaptive law to ensure the transient performance without nonlinear damping terms. The exponential stability of the closed-loop system is proved rigorously under the partial IE or IE condition. Simulations have demonstrated the effectiveness and superiority of the proposed method in both parameter estimation and control compared to state-of-the-art methods.         ",
    "url": "https://arxiv.org/abs/2401.10785",
    "authors": [
      "Tian Shi",
      "Changyun Wen",
      "Yongping Pan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2403.12029",
    "title": "Align and Distill: Unifying and Improving Domain Adaptive Object Detection",
    "abstract": "           Object detectors often perform poorly on data that differs from their training set. Domain adaptive object detection (DAOD) methods have recently demonstrated strong results on addressing this challenge. Unfortunately, we identify systemic benchmarking pitfalls that call past results into question and hamper further progress: (a) Overestimation of performance due to underpowered baselines, (b) Inconsistent implementation practices preventing transparent comparisons of methods, and (c) Lack of generality due to outdated backbones and lack of diversity in benchmarks. We address these problems by introducing: (1) A unified benchmarking and implementation framework, Align and Distill (ALDI), enabling comparison of DAOD methods and supporting future development, (2) A fair and modern training and evaluation protocol for DAOD that addresses benchmarking pitfalls, (3) A new DAOD benchmark dataset, CFC-DAOD, enabling evaluation on diverse real-world data, and (4) A new method, ALDI++, that achieves state-of-the-art results by a large margin. ALDI++ outperforms the previous state-of-the-art by +3.5 AP50 on Cityscapes to Foggy Cityscapes, +5.7 AP50 on Sim10k to Cityscapes (where ours is the only method to outperform a fair baseline), and +0.6 AP50 on CFC Kenai to Channel. ALDI and ALDI++ are architecture-agnostic, setting a new state-of-the-art for YOLO and DETR-based DAOD as well without additional hyperparameter tuning. Our framework, dataset, and state-of-the-art method offer a critical reset for DAOD and provide a strong foundation for future research. Code and data are available: this https URL and this https URL.         ",
    "url": "https://arxiv.org/abs/2403.12029",
    "authors": [
      "Justin Kay",
      "Timm Haucke",
      "Suzanne Stathatos",
      "Siqi Deng",
      "Erik Young",
      "Pietro Perona",
      "Sara Beery",
      "Grant Van Horn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2405.14099",
    "title": "Automatic Differentiation is Essential in Training Neural Networks for Solving Differential Equations",
    "abstract": "           Neural network-based approaches have recently shown significant promise in solving partial differential equations (PDEs) in science and engineering, especially in scenarios featuring complex domains or incorporation of empirical data. One advantage of the neural network methods for PDEs lies in its automatic differentiation (AD), which necessitates only the sample points themselves, unlike traditional finite difference (FD) approximations that require nearby local points to compute derivatives. In this paper, we quantitatively demonstrate the advantage of AD in training neural networks. The concept of truncated entropy is introduced to characterize the training property. Specifically, through comprehensive experimental and theoretical analyses conducted on random feature models and two-layer neural networks, we discover that the defined truncated entropy serves as a reliable metric for quantifying the residual loss of random feature models and the training speed of neural networks for both AD and FD methods. Our experimental and theoretical analyses demonstrate that, from a training perspective, AD outperforms FD in solving PDEs.         ",
    "url": "https://arxiv.org/abs/2405.14099",
    "authors": [
      "Chuqi Chen",
      "Yahong Yang",
      "Yang Xiang",
      "Wenrui Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2405.18770",
    "title": "Multimodal Adversarial Defense for Vision-Language Models by Leveraging One-To-Many Relationships",
    "abstract": "           Pre-trained vision-language (VL) models are highly vulnerable to adversarial attacks. However, existing defense methods primarily focus on image classification, overlooking two key aspects of VL tasks: multimodal attacks, where both image and text can be perturbed, and the one-to-many relationship of images and texts, where a single image can correspond to multiple textual descriptions and vice versa (1:N and N:1). This work is the first to explore defense strategies against multimodal attacks in VL tasks, whereas prior VL defense methods focus on vision robustness. We propose multimodal adversarial training (MAT), which incorporates adversarial perturbations in both image and text modalities during training, significantly outperforming existing unimodal defenses. Furthermore, we discover that MAT is limited by deterministic one-to-one (1:1) image-text pairs in VL training data. To address this, we conduct a comprehensive study on leveraging one-to-many relationships to enhance robustness, investigating diverse augmentation techniques. Our analysis shows that, for a more effective defense, augmented image-text pairs should be well-aligned, diverse, yet avoid distribution shift -- conditions overlooked by prior research. Our experiments show that MAT can effectively be applied to different VL models and tasks to improve adversarial robustness, outperforming previous efforts. Our code will be made public upon acceptance.         ",
    "url": "https://arxiv.org/abs/2405.18770",
    "authors": [
      "Futa Waseda",
      "Antonio Tejero-de-Pablos",
      "Isao Echizen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2406.01384",
    "title": "Extending Structural Causal Models for Autonomous Vehicles to Simplify Temporal System Construction & Enable Dynamic Interactions Between Agents",
    "abstract": "           In this work we aim to bridge the divide between autonomous vehicles and causal reasoning. Autonomous vehicles have come to increasingly interact with human drivers, and in many cases may pose risks to the physical or mental well-being of those they interact with. Meanwhile causal models, despite their inherent transparency and ability to offer contrastive explanations, have found limited usage within such systems. As such, we first identify the challenges that have limited the integration of structural causal models within autonomous vehicles. We then introduce a number of theoretical extensions to the structural causal model formalism in order to tackle these challenges. This augments these models to possess greater levels of modularisation and encapsulation, as well presenting temporal causal model representation with constant space complexity. We also prove through the extensions we have introduced that dynamically mutable sets (e.g. varying numbers of autonomous vehicles across time) can be used within a structural causal model while maintaining a relaxed form of causal stationarity. Finally we discuss the application of the extensions in the context of the autonomous vehicle and service robotics domain along with potential directions for future work.         ",
    "url": "https://arxiv.org/abs/2406.01384",
    "authors": [
      "Rhys Howard",
      "Lars Kunze"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2406.04746",
    "title": "PQPP: A Joint Benchmark for Text-to-Image Prompt and Query Performance Prediction",
    "abstract": "           Text-to-image generation has recently emerged as a viable alternative to text-to-image retrieval, driven by the visually impressive results of generative diffusion models. Although query performance prediction is an active research topic in information retrieval, to the best of our knowledge, there is no prior study that analyzes the difficulty of queries (referred to as prompts) in text-to-image generation, based on human judgments. To this end, we introduce the first dataset of prompts which are manually annotated in terms of image generation performance. Additionally, we extend these evaluations to text-to-image retrieval by collecting manual annotations that represent retrieval performance. We thus establish the first joint benchmark for prompt and query performance prediction (PQPP) across both tasks, comprising over 10K queries. Our benchmark enables (i) the comparative assessment of prompt/query difficulty in both image generation and image retrieval, and (ii) the evaluation of prompt/query performance predictors addressing both generation and retrieval. We evaluate several pre- and post-generation/retrieval performance predictors, thus providing competitive baselines for future research. Our benchmark and code are publicly available at this https URL.         ",
    "url": "https://arxiv.org/abs/2406.04746",
    "authors": [
      "Eduard Poesina",
      "Adriana Valentina Costache",
      "Adrian-Gabriel Chifu",
      "Josiane Mothe",
      "Radu Tudor Ionescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.06652",
    "title": "Improving Generalization of Neural Vehicle Routing Problem Solvers Through the Lens of Model Architecture",
    "abstract": "           Neural models produce promising results when solving Vehicle Routing Problems (VRPs), but often fall short in generalization. Recent attempts to enhance model generalization often incur unnecessarily large training cost or cannot be directly applied to other models solving different VRP variants. To address these issues, we take a novel perspective on model architecture in this study. Specifically, we propose a plug-and-play Entropy-based Scaling Factor (ESF) and a Distribution-Specific (DS) decoder to enhance the size and distribution generalization, respectively. ESF adjusts the attention weight pattern of the model towards familiar ones discovered during training when solving VRPs of varying sizes. The DS decoder explicitly models VRPs of multiple training distribution patterns through multiple auxiliary light decoders, expanding the model representation space to encompass a broader range of distributional scenarios. We conduct extensive experiments on both synthetic and widely recognized real-world benchmarking datasets and compare the performance with seven baseline models. The results demonstrate the effectiveness of using ESF and DS decoder to obtain a more generalizable model and showcase their applicability to solve different VRP variants, i.e., travelling salesman problem and capacitated VRP. Notably, our proposed generic components require minimal computational resources, and can be effortlessly integrated into conventional generalization strategies to further elevate model generalization.         ",
    "url": "https://arxiv.org/abs/2406.06652",
    "authors": [
      "Yubin Xiao",
      "Di Wang",
      "Xuan Wu",
      "Yuesong Wu",
      "Boyang Li",
      "Wei Du",
      "Liupu Wang",
      "You Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2406.06918",
    "title": "HumanEvo: An Evolution-aware Benchmark for More Realistic Evaluation of Repository-level Code Generation",
    "abstract": "           To evaluate the repository-level code generation capabilities of Large Language Models (LLMs) in complex real-world software development scenarios, many evaluation methods have been developed. These methods typically leverage contextual code from the latest version of a project to assist LLMs in accurately generating the desired function. However, such evaluation methods fail to consider the dynamic evolution of software projects over time, which we refer to as evolution-ignored settings. This in turn results in inaccurate evaluation of LLMs' performance. In this paper, we conduct an empirical study to deeply understand LLMs' code generation performance within settings that reflect the evolution nature of software development. To achieve this, we first construct an evolution-aware repository-level code generation dataset, namely HumanEvo, equipped with an automated execution-based evaluation tool. Second, we manually categorize HumanEvo according to dependency levels to more comprehensively analyze the model's performance in generating functions with different dependency levels. Third, we conduct extensive experiments on HumanEvo with seven representative and diverse LLMs to verify the effectiveness of the proposed benchmark. We obtain several important findings through our experimental study. For example, we find that previous evolution-ignored evaluation methods result in inflated performance of LLMs, with performance overestimations ranging from 10.0% to 61.1% under different context acquisition methods, compared to the evolution-aware evaluation approach. Based on the findings, we give actionable suggestions for more realistic evaluation of LLMs on code generation. We also build a shared evolution-aware code generation toolbox to facilitate future research.         ",
    "url": "https://arxiv.org/abs/2406.06918",
    "authors": [
      "Dewu Zheng",
      "Yanlin Wang",
      "Ensheng Shi",
      "Ruikai Zhang",
      "Yuchi Ma",
      "Hongyu Zhang",
      "Zibin Zheng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2406.09123",
    "title": "Can I introduce my boyfriend to my grandmother? Evaluating Large Language Models Capabilities on Iranian Social Norm Classification",
    "abstract": "           Creating globally inclusive AI systems demands datasets reflecting diverse social norms. Iran, with its unique cultural blend, offers an ideal case study, with Farsi adding linguistic complexity. In this work, we introduce the Iranian Social Norms (ISN) dataset, a novel collection of 1,699 Iranian social norms, including environments, demographic features, and scope annotation, alongside English translations. Our evaluation of 6 Large Language Models (LLMs) in classifying Iranian social norms, using a variety of prompts, uncovered critical insights into the impact of geographic and linguistic context. Results revealed a substantial performance gap in LLMs' comprehension of Iranian norms. Notably, while the geographic context in English prompts enhanced the performance, this effect was absent in Farsi, pointing to nuanced linguistic challenges. Particularly, performance was significantly worse for Iran-specific norms, emphasizing the importance of culturally tailored datasets. As the first Farsi dataset for social norm classification, ISN will facilitate crucial cross-cultural analyses, shedding light on how values differ across contexts and cultures.         ",
    "url": "https://arxiv.org/abs/2406.09123",
    "authors": [
      "Hamidreza Saffari",
      "Mohammadamin Shafiei",
      "Donya Rooein",
      "Francesco Pierri",
      "Debora Nozza"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2406.18326",
    "title": "PaCoST: Paired Confidence Significance Testing for Benchmark Contamination Detection in Large Language Models",
    "abstract": "           Large language models (LLMs) are known to be trained on vast amounts of data, which may unintentionally or intentionally include data from commonly used benchmarks. This inclusion can lead to cheatingly high scores on model leaderboards, yet result in disappointing performance in real-world applications. To address this benchmark contamination problem, we first propose a set of requirements that practical contamination detection methods should follow. Following these proposed requirements, we introduce PaCoST, a Paired Confidence Significance Testing to effectively detect benchmark contamination in LLMs. Our method constructs a counterpart for each piece of data with the same distribution, and performs statistical analysis of the corresponding confidence to test whether the model is significantly more confident under the original benchmark. We validate the effectiveness of PaCoST and apply it on popular open-source models and benchmarks. We find that almost all models and benchmarks we tested are suspected contaminated more or less. We finally call for new LLM evaluation methods.         ",
    "url": "https://arxiv.org/abs/2406.18326",
    "authors": [
      "Huixuan Zhang",
      "Yun Lin",
      "Xiaojun Wan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2407.07066",
    "title": "Explainable Differential Privacy-Hyperdimensional Computing for Balancing Privacy and Transparency in Additive Manufacturing Monitoring",
    "abstract": "           Machine Learning (ML) models integrated with in-situ sensing offer transformative solutions for defect detection in Additive Manufacturing (AM), but this integration brings critical challenges in safeguarding sensitive data, such as part designs and material compositions. Differential Privacy (DP), which introduces mathematically controlled noise, provides a balance between data utility and privacy. However, black-box Artificial Intelligence (AI) models often obscure how this noise impacts model accuracy, complicating the optimization of privacy-accuracy trade-offs. This study introduces the Differential Privacy-Hyperdimensional Computing (DP-HD) framework, a novel approach combining Explainable AI (XAI) and vector symbolic paradigms to quantify and predict noise effects on accuracy using a Signal-to-Noise Ratio (SNR) metric. DP-HD enables precise tuning of DP noise levels, ensuring an optimal balance between privacy and performance. The framework has been validated using real-world AM data, demonstrating its applicability to industrial environments. Experimental results demonstrate DP-HD's capability to achieve state-of-the-art accuracy (94.43%) with robust privacy protections in anomaly detection for AM, even under significant noise conditions. Beyond AM, DP-HD holds substantial promise for broader applications in privacy-sensitive domains such as healthcare, financial services, and government data management, where securing sensitive data while maintaining high ML performance is paramount.         ",
    "url": "https://arxiv.org/abs/2407.07066",
    "authors": [
      "Fardin Jalil Piran",
      "Prathyush P. Poduval",
      "Hamza Errahmouni Barkam",
      "Mohsen Imani",
      "Farhad Imani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2407.07357",
    "title": "A deep graph model for the signed interaction prediction in biological network",
    "abstract": "           Predicting signed interactions in biological networks is crucial for understanding drug mechanisms and facilitating drug repurposing. While deep graph models have demonstrated success in modeling complex biological systems, existing approaches often fail to distinguish between positive and negative interactions, limiting their utility for precise pharmacological predictions. In this study, we propose a novel deep graph model, \\textbf{RGCNTD} (Relational Graph Convolutional Network with Tensor Decomposition), designed to predict both polar (e.g., activation, inhibition) and non-polar (e.g., binding, affect) chemical-gene interactions. Our model integrates graph convolutional networks with tensor decomposition to enhance feature representation and incorporates a conflict-aware sampling strategy to resolve polarity ambiguities. We introduce new evaluation metrics, \\textit{AUC\\textsubscript{polarity}} and \\textit{CP@500}, to assess the model's ability to differentiate interaction types. Experimental results demonstrate that \\textbf{RGCNTD} outperforms baseline models, achieving superior classification accuracy and improved discrimination of polar edges. Furthermore, we analyze the impact of subgraph components on predictive performance, revealing that additional network structures do not always enhance accuracy. These findings highlight the importance of polarity-aware modeling in drug discovery and network pharmacology, providing a robust framework for predicting complex biological interactions.         ",
    "url": "https://arxiv.org/abs/2407.07357",
    "authors": [
      "Shuyi Jin",
      "Mengji Zhang",
      "Meijie Wang",
      "Lun Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Molecular Networks (q-bio.MN)"
    ]
  },
  {
    "id": "arXiv:2407.10094",
    "title": "Work From Home and Privacy Challenges: What Do Workers Face and What are They Doing About it?",
    "abstract": "           The COVID-19 pandemic has reshaped the way people work, normalizing the practice of working from home. However, work from home (WFH) can cause a blurring of personal and professional boundaries, surfacing new privacy issues, especially when workers take work meetings from their homes. As WFH arrangements are now standard practice in many organizations, addressing the associated privacy concerns should be a key part of creating healthy work environments for workers. To this end, we conducted a scenario-based survey with 214 US-based workers who currently work from home regularly. Our results suggest that privacy invasions are commonly experienced while working from home and cause discomfort to many workers. However, only a minority said that the discomfort escalated to cause harm to them or others and that the harm was almost always minor and psychological. While scenarios that restrict worker autonomy (prohibit turning off camera or microphone) are the least experienced scenarios, they are associated with the highest reported discomfort. In addition, participants reported measures that violated or would violate their employer's autonomy-restricting rules to protect their privacy. We also find that conference tool settings that can prevent privacy invasions are not widely used compared to manual privacy-protective measures. Our findings provide a better understanding of the privacy challenges landscape that WFH workers face and how they address them, providing useful insights to organizations' policymakers and technology designers for areas of improvements, to provide healthier work environments to workers.         ",
    "url": "https://arxiv.org/abs/2407.10094",
    "authors": [
      "Eman Alashwali",
      "Joanne Peca",
      "Mandy Lanyon",
      "Lorrie Cranor"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2407.19310",
    "title": "Ensembling convolutional neural networks for human skin segmentation",
    "abstract": "           Detecting and segmenting human skin regions in digital images is an intensively explored topic of computer vision with a variety of approaches proposed over the years that have been found useful in numerous practical applications. The first methods were based on pixel-wise skin color modeling and they were later enhanced with context-based analysis to include the textural and geometrical features, recently extracted using deep convolutional neural networks. It has been also demonstrated that skin regions can be segmented from grayscale images without using color information at all. However, the possibility to combine these two sources of information has not been explored so far and we address this research gap with the contribution reported in this paper. We propose to train a convolutional network using the datasets focused on different features to create an ensemble whose individual outcomes are effectively combined using yet another convolutional network trained to produce the final segmentation map. The experimental results clearly indicate that the proposed approach outperforms the basic classifiers, as well as an ensemble based on the voting scheme. We expect that this study will help in developing new ensemble-based techniques that will improve the performance of semantic segmentation systems, reaching beyond the problem of detecting human skin.         ",
    "url": "https://arxiv.org/abs/2407.19310",
    "authors": [
      "Patryk Kuban",
      "Michal Kawulok"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.00777",
    "title": "CATD: Unified Representation Learning for EEG-to-fMRI Cross-Modal Generation",
    "abstract": "           Multi-modal neuroimaging analysis is crucial for a comprehensive understanding of brain function and pathology, as it allows for the integration of different imaging techniques, thus overcoming the limitations of individual modalities. However, the high costs and limited availability of certain modalities pose significant challenges. To address these issues, this paper proposed the Condition-Aligned Temporal Diffusion (CATD) framework for end-to-end cross-modal synthesis of neuroimaging, enabling the generation of functional magnetic resonance imaging (fMRI)-detected Blood Oxygen Level Dependent (BOLD) signals from more accessible Electroencephalography (EEG) signals. By constructing Conditionally Aligned Block (CAB), heterogeneous neuroimages are aligned into a potential space, achieving a unified representation that provides the foundation for cross-modal transformation in neuroimaging. The combination with the constructed Dynamic Time-Frequency Segmentation (DTFS) module also enables the use of EEG signals to improve the temporal resolution of BOLD signals, thus augmenting the capture of the dynamic details of the brain. Experimental validation demonstrated the effectiveness of the framework in improving the accuracy of neural activity prediction, identifying abnormal brain regions, and enhancing the temporal resolution of BOLD signals. The proposed framework establishes a new paradigm for cross-modal synthesis of neuroimaging by unifying heterogeneous neuroimaging data into a potential representation space, showing promise in medical applications such as improving Parkinson's disease prediction and identifying abnormal brain regions.         ",
    "url": "https://arxiv.org/abs/2408.00777",
    "authors": [
      "Weiheng Yao",
      "Zhihan Lyu",
      "Mufti Mahmud",
      "Ning Zhong",
      "Baiying Lei",
      "Shuqiang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2408.03742",
    "title": "Limitations of the decoding-to-LPN reduction via code smoothing",
    "abstract": "           The Learning Parity with Noise (LPN) problem underlines several classic cryptographic primitives. Researchers have attempted to demonstrate the algorithmic hardness of this problem by finding reductions from the decoding problem of linear codes, for which several hardness results exist. Earlier studies used code smoothing as a tool to achieve reductions for codes with vanishing rate. This has left open the question of attaining a reduction with positive-rate codes. Addressing this case, we characterize the efficiency of the reduction in terms of the parameters of the decoding and LPN problems. As a conclusion, we isolate the parameter regimes for which a meaningful reduction is possible and the regimes for which its existence is unlikely.         ",
    "url": "https://arxiv.org/abs/2408.03742",
    "authors": [
      "Madhura Pathegama",
      "Alexander Barg"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2408.09174",
    "title": "TableBench: A Comprehensive and Complex Benchmark for Table Question Answering",
    "abstract": "           Recent advancements in Large Language Models (LLMs) have markedly enhanced the interpretation and processing of tabular data, introducing previously unimaginable capabilities. Despite these achievements, LLMs still encounter significant challenges when applied in industrial scenarios, particularly due to the increased complexity of reasoning required with real-world tabular data, underscoring a notable disparity between academic benchmarks and practical applications. To address this discrepancy, we conduct a detailed investigation into the application of tabular data in industrial scenarios and propose a comprehensive and complex benchmark TableBench, including 18 fields within four major categories of table question answering (TableQA) capabilities. Furthermore, we introduce TableLLM, trained on our meticulously constructed training set TableInstruct, achieving comparable performance with GPT-3.5. Massive experiments conducted on TableBench indicate that both open-source and proprietary LLMs still have significant room for improvement to meet real-world demands, where the most advanced model, GPT-4, achieves only a modest score compared to humans.         ",
    "url": "https://arxiv.org/abs/2408.09174",
    "authors": [
      "Xianjie Wu",
      "Jian Yang",
      "Linzheng Chai",
      "Ge Zhang",
      "Jiaheng Liu",
      "Xinrun Du",
      "Di Liang",
      "Daixin Shu",
      "Xianfu Cheng",
      "Tianzhen Sun",
      "Guanglin Niu",
      "Tongliang Li",
      "Zhoujun Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2408.10641",
    "title": "A Review of Human-Object Interaction Detection",
    "abstract": "           Human-object interaction (HOI) detection plays a key role in high-level visual understanding, facilitating a deep comprehension of human activities. Specifically, HOI detection aims to locate the humans and objects involved in interactions within images or videos and classify the specific interactions between them. The success of this task is influenced by several key factors, including the accurate localization of human and object instances, as well as the correct classification of object categories and interaction relationships. This paper systematically summarizes and discusses the recent work in image-based HOI detection. First, the mainstream datasets involved in HOI relationship detection are introduced. Furthermore, starting with two-stage methods and end-to-end one-stage detection approaches, this paper comprehensively discusses the current developments in image-based HOI detection, analyzing the strengths and weaknesses of these two methods. Additionally, the advancements of zero-shot learning, weakly supervised learning, and the application of large-scale language models in HOI detection are discussed. Finally, the current challenges in HOI detection are outlined, and potential research directions and future trends are explored.         ",
    "url": "https://arxiv.org/abs/2408.10641",
    "authors": [
      "Yuxiao Wang",
      "Yu Lei",
      "Li Cui",
      "Weiying Xue",
      "Qi Liu",
      "Zhenao Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2409.08786",
    "title": "Modular Neural Wiretap Codes for Fading Channels",
    "abstract": "           The wiretap channel is a well-studied problem in the physical layer security literature. Although it is proven that the decoding error probability and information leakage can be made arbitrarily small in the asymptotic regime, further research on finite-blocklength codes is required on the path towards practical, secure communication systems. This work provides the first experimental characterization of a deep learning-based, finite-blocklength code construction for multi-tap fading wiretap channels without channel state information. In addition to the evaluation of the average probability of error and information leakage, we examine the designed codes in the presence of fading in terms of the equivocation rate and illustrate the influence of (i) the number of fading taps, (ii) differing variances of the fading coefficients, and (iii) the seed selection for the hash function-based security layer.         ",
    "url": "https://arxiv.org/abs/2409.08786",
    "authors": [
      "Daniel Seifert",
      "Onur G\u00fcnl\u00fc",
      "Rafael F. Schaefer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2409.13881",
    "title": "Investigation of Time-Frequency Feature Combinations with Histogram Layer Time Delay Neural Networks",
    "abstract": "           While deep learning has reduced the prevalence of manual feature extraction, transformation of data via feature engineering remains essential for improving model performance, particularly for underwater acoustic signals. The methods by which audio signals are converted into time-frequency representations and the subsequent handling of these spectrograms can significantly impact performance. This work demonstrates the performance impact of using different combinations of time-frequency features in a histogram layer time delay neural network. An optimal set of features is identified with results indicating that specific feature combinations outperform single data features.         ",
    "url": "https://arxiv.org/abs/2409.13881",
    "authors": [
      "Amirmohammad Mohammadi",
      "Iren'e Masabarakiza",
      "Ethan Barnes",
      "Davelle Carreiro",
      "Alexandra Van Dine",
      "Joshua Peeples"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2409.14020",
    "title": "Point Cloud Structural Similarity-based Underwater Sonar Loop Detection",
    "abstract": "           In this letter, we propose a point cloud structural similarity-based loop detection method for underwater Simultaneous Localization and Mapping using sonar sensors. Existing sonar-based loop detection approaches often rely on 2D projection and keypoint extraction, which can lead to data loss and poor performance in feature-scarce environments. Additionally, methods based on neural networks or Bag-of-Words require extensive preprocessing, such as model training or vocabulary creation, reducing adaptability to new environments. To address these challenges, our method directly utilizes 3D sonar point clouds without projection and computes point-wise structural feature maps based on geometry, normals, and curvature. By leveraging rotation-invariant similarity comparisons, the proposed approach eliminates the need for keypoint detection and ensures robust loop detection across diverse underwater terrains. We validate our method using two real-world datasets: the Antarctica dataset obtained from deep underwater and the Seaward dataset collected from rivers and lakes. Experimental results show that our method achieves the highest loop detection performance compared to existing keypointbased and learning-based approaches while requiring no additional training or preprocessing. Our code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2409.14020",
    "authors": [
      "Donghwi Jung",
      "Andres Pulido",
      "Jane Shin",
      "Seong-Woo Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2410.09408",
    "title": "C-Adapter: Adapting Deep Classifiers for Efficient Conformal Prediction Sets",
    "abstract": "           Conformal prediction, as an emerging uncertainty quantification technique, typically functions as post-hoc processing for the outputs of trained classifiers. To optimize the classifier for maximum predictive efficiency, Conformal Training rectifies the training objective with a regularization that minimizes the average prediction set size at a specific error rate. However, the regularization term inevitably deteriorates the classification accuracy and leads to suboptimal efficiency of conformal predictors. To address this issue, we introduce \\textbf{Conformal Adapter} (C-Adapter), an adapter-based tuning method to enhance the efficiency of conformal predictors without sacrificing accuracy. In particular, we implement the adapter as a class of intra order-preserving functions and tune it with our proposed loss that maximizes the discriminability of non-conformity scores between correctly and randomly matched data-label pairs. Using C-Adapter, the model tends to produce extremely high non-conformity scores for incorrect labels, thereby enhancing the efficiency of prediction sets across different coverage rates. Extensive experiments demonstrate that C-Adapter can effectively adapt various classifiers for efficient prediction sets, as well as enhance the conformal training method.         ",
    "url": "https://arxiv.org/abs/2410.09408",
    "authors": [
      "Kangdao Liu",
      "Hao Zeng",
      "Jianguo Huang",
      "Huiping Zhuang",
      "Chi-Man Vong",
      "Hongxin Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.12360",
    "title": "Towards Neural Scaling Laws for Time Series Foundation Models",
    "abstract": "           Scaling laws offer valuable insights into the design of time series foundation models (TSFMs). However, previous research has largely focused on the scaling laws of TSFMs for in-distribution (ID) data, leaving their out-of-distribution (OOD) scaling behavior and the influence of model architectures less explored. In this work, we examine two common TSFM architectures, encoder-only and decoder-only Transformers, and investigate their scaling behavior on both ID and OOD data. These models are trained and evaluated across varying parameter counts, compute budgets, and dataset sizes. Our experiments reveal that the log-likelihood loss of TSFMs exhibits similar scaling behavior in both OOD and ID settings. We further compare the scaling properties across different architectures, incorporating two state-of-the-art TSFMs as case studies, showing that model architecture plays a significant role in scaling. The encoder-only Transformers demonstrate better scalability than the decoder-only Transformers, while the architectural enhancements in the two advanced TSFMs primarily improve ID performance but reduce OOD scalability. While scaling up TSFMs is expected to drive performance breakthroughs, the lack of a comprehensive understanding of TSFM scaling laws has hindered the development of a robust framework to guide model scaling. We fill this gap in this work by synthesizing our findings and providing practical guidelines for designing and scaling larger TSFMs with enhanced model capabilities.         ",
    "url": "https://arxiv.org/abs/2410.12360",
    "authors": [
      "Qingren Yao",
      "Chao-Han Huck Yang",
      "Renhe Jiang",
      "Yuxuan Liang",
      "Ming Jin",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2410.12730",
    "title": "Counterfactual Generative Modeling with Variational Causal Inference",
    "abstract": "           Estimating an individual's counterfactual outcomes under interventions is a challenging task for traditional causal inference and supervised learning approaches when the outcome is high-dimensional (e.g. gene expressions, facial images) and covariates are relatively limited. In this case, to predict one's outcomes under counterfactual treatments, it is crucial to leverage individual information contained in the observed outcome in addition to the covariates. Prior works using variational inference in counterfactual generative modeling have been focusing on neural adaptations and model variants within the conditional variational autoencoder formulation, which we argue is fundamentally ill-suited to the notion of counterfactual in causal inference. In this work, we present a novel variational Bayesian causal inference framework and its theoretical backings to properly handle counterfactual generative modeling tasks, through which we are able to conduct counterfactual supervision end-to-end during training without any counterfactual samples, and encourage disentangled exogenous noise abduction that aids the correct identification of causal effect in counterfactual generations. In experiments, we demonstrate the advantage of our framework compared to state-of-the-art models in counterfactual generative modeling on multiple benchmarks.         ",
    "url": "https://arxiv.org/abs/2410.12730",
    "authors": [
      "Yulun Wu",
      "Louie McConnell",
      "Claudia Iriondo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2411.10182",
    "title": "Some Thoughts on Graph Similarity",
    "abstract": "           We give an overview of different approaches to measuring the similarity of, or the distance between, two graphs, highlighting connections between these approaches. We also discuss the complexity of computing the distances.         ",
    "url": "https://arxiv.org/abs/2411.10182",
    "authors": [
      "Martin Grohe"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2411.17002",
    "title": "Words Matter: Leveraging Individual Text Embeddings for Code Generation in CLIP Test-Time Adaptation",
    "abstract": "           Vision-language foundation models, such as CLIP, have shown unprecedented zero-shot performance across a wide range of tasks. Nevertheless, these models may be unreliable under distributional shifts, as their performance is significantly degraded. In this work, we explore how to efficiently leverage class text information to mitigate these distribution drifts encountered by large pre-trained vision-language models (VLMs) during test-time inference. In particular, we propose to generate pseudo-labels for the test-time samples by exploiting generic class text embeddings as fixed centroids of a label assignment problem, which is efficiently solved with Optimal Transport. Furthermore, the proposed adaptation method (CLIP-OT) integrates a multiple template knowledge distillation approach, which replicates multi-view contrastive learning strategies in unsupervised representation learning but without incurring additional computational complexity. Extensive experiments on multiple popular test-time adaptation benchmarks presenting diverse complexity empirically show the superiority of CLIP-OT, achieving performance gains of up to 7% over recent state-of-the-art methods, yet being computationally and memory efficient.         ",
    "url": "https://arxiv.org/abs/2411.17002",
    "authors": [
      "Shambhavi Mishra",
      "Julio Silva-Rodr\u0131guez",
      "Ismail Ben Ayed",
      "Marco Pedersoli",
      "Jose Dolz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2411.18425",
    "title": "Streamlining Prediction in Bayesian Deep Learning",
    "abstract": "           The rising interest in Bayesian deep learning (BDL) has led to a plethora of methods for estimating the posterior distribution. However, efficient computation of inferences, such as predictions, has been largely overlooked with Monte Carlo integration remaining the standard. In this work we examine streamlining prediction in BDL through a single forward pass without sampling. For this we use local linearisation on activation functions and local Gaussian approximations at linear layers. Thus allowing us to analytically compute an approximation to the posterior predictive distribution. We showcase our approach for both MLP and transformers, such as ViT and GPT-2, and assess its performance on regression and classification tasks.         ",
    "url": "https://arxiv.org/abs/2411.18425",
    "authors": [
      "Rui Li",
      "Marcus Klasson",
      "Arno Solin",
      "Martin Trapp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2411.19108",
    "title": "Timestep Embedding Tells: It's Time to Cache for Video Diffusion Model",
    "abstract": "           As a fundamental backbone for video generation, diffusion models are challenged by low inference speed due to the sequential nature of denoising. Previous methods speed up the models by caching and reusing model outputs at uniformly selected timesteps. However, such a strategy neglects the fact that differences among model outputs are not uniform across timesteps, which hinders selecting the appropriate model outputs to cache, leading to a poor balance between inference efficiency and visual quality. In this study, we introduce Timestep Embedding Aware Cache (TeaCache), a training-free caching approach that estimates and leverages the fluctuating differences among model outputs across timesteps. Rather than directly using the time-consuming model outputs, TeaCache focuses on model inputs, which have a strong correlation with the modeloutputs while incurring negligible computational cost. TeaCache first modulates the noisy inputs using the timestep embeddings to ensure their differences better approximating those of model outputs. TeaCache then introduces a rescaling strategy to refine the estimated differences and utilizes them to indicate output caching. Experiments show that TeaCache achieves up to 4.41x acceleration over Open-Sora-Plan with negligible (-0.07% Vbench score) degradation of visual quality.         ",
    "url": "https://arxiv.org/abs/2411.19108",
    "authors": [
      "Feng Liu",
      "Shiwei Zhang",
      "Xiaofeng Wang",
      "Yujie Wei",
      "Haonan Qiu",
      "Yuzhong Zhao",
      "Yingya Zhang",
      "Qixiang Ye",
      "Fang Wan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2412.01782",
    "title": "Quantifying the Reliability of Predictions in Detection Transformers: Object-Level Calibration and Image-Level Uncertainty",
    "abstract": "           DEtection TRansformer (DETR) has emerged as a promising architecture for object detection, offering an end-to-end prediction pipeline. In practice, however, DETR generates hundreds of predictions that far outnumber the actual number of objects present in an image. This raises the question: can we trust and use all of these predictions? Addressing this concern, we present empirical evidence highlighting how different predictions within the same image play distinct roles, resulting in varying reliability levels across those predictions. More specifically, while multiple predictions are often made for a single object, our findings show that most often one such prediction is well-calibrated, and the others are poorly calibrated. Based on these insights, we demonstrate that identifying a reliable subset of DETR's predictions is crucial for accurately assessing the reliability of the model at both object and image levels. Building on this viewpoint, we first address the shortcomings of widely used performance and calibration metrics, such as average precision and various forms of expected calibration error. Specifically, they are inadequate for determining which subset of DETR's predictions should be trusted and utilized. In response, we present Object-level Calibration Error (OCE), which assesses the calibration quality more effectively and is suitable for both ranking different models and identifying the most reliable predictions within a specific model. As a final contribution, we introduce a post hoc uncertainty quantification (UQ) framework that predicts the accuracy of the model on a per-image basis. By contrasting the average confidence scores of positive (i.e., likely to be matched) and negative predictions determined by OCE, our framework assesses the reliability of the DETR model for each test image.         ",
    "url": "https://arxiv.org/abs/2412.01782",
    "authors": [
      "Young-Jin Park",
      "Carson Sobolewski",
      "Navid Azizan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2412.02114",
    "title": "Beyond Generation: Unlocking Universal Editing via Self-Supervised Fine-Tuning",
    "abstract": "           Recent advances in video generation have outpaced progress in video editing, which remains constrained by several limiting factors, namely: (a) the task's dependency on supervision severely limits generality, (b) an unnecessary artificial separation between the generation and editing task, and (c) the high computational costs of training a video model. In this work, we propose UES (Unlocking Universal Editing via Self-Supervision), a lightweight self-supervised fine-tuning strategy that transforms generation models into unified generation-editing systems through self-supervised semantic alignment. Our approach establishes a dual-conditioning mechanism where original video-text pairs jointly provide visual and textual semantics, enabling structured learning of intrinsic spatiotemporal correspondences. Key advantages include: (i) Universality through supervision-free adaptation to diverse editing tasks, (ii) Unification of generation and editing applicable to most text(+image)-to-video model, and (iii) Efficiency via lightweight fine-tune that reduces tunable parameters by 92.67%. To enable systematic evaluation, we introduce OmniBench-99, a comprehensive benchmark spanning 99 videos across humans/animals, environments, and objects, comprising 4 editing types and 8 scenarios. Extensive experiments show UES enables models without inherent editing capability to perform powerful and universal editing while preserving or even enhancing their original generation performance.         ",
    "url": "https://arxiv.org/abs/2412.02114",
    "authors": [
      "Harold Haodong Chen",
      "Harry Yang",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2412.06352",
    "title": "SeFENet: Robust Deep Homography Estimation via Semantic-Driven Feature Enhancement",
    "abstract": "           Images captured in harsh environments often exhibit blurred details, reduced contrast, and color distortion, which hinder feature detection and matching, thereby affecting the accuracy and robustness of homography estimation. While visual enhancement can improve contrast and clarity, it may introduce visual-tolerant artifacts that obscure the structural integrity of images. Considering the resilience of semantic information against environmental interference, we propose a semantic-driven feature enhancement network for robust homography estimation, dubbed SeFENet. Concretely, we first introduce an innovative hierarchical scale-aware module to expand the receptive field by aggregating multi-scale information, thereby effectively extracting image features under diverse harsh conditions. Subsequently, we propose a semantic-guided constraint module combined with a high-level perceptual framework to achieve degradation-tolerant with semantic feature. A meta-learning-based training strategy is introduced to mitigate the disparity between semantic and structural features. By internal-external alternating optimization, the proposed network achieves implicit semantic-wise feature enhancement, thereby improving the robustness of homography estimation in adverse environments by strengthening the local feature comprehension and context information extraction. Experimental results under both normal and harsh conditions demonstrate that SeFENet significantly outperforms SOTA methods, reducing point match error by at least 41% on the large-scale datasets.         ",
    "url": "https://arxiv.org/abs/2412.06352",
    "authors": [
      "Zeru Shi",
      "Zengxi Zhang",
      "Kemeng Cui",
      "Ruizhe An",
      "Jinyuan Liu",
      "Zhiying Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2412.07612",
    "title": "ViewDelta: Text-Prompted Change Detection in Unaligned Images",
    "abstract": "           Detecting changes between images is fundamental in applications such as infrastructure assessment, environmental monitoring, and industrial automation. Existing supervised models demonstrate strong performance but are inherently limited by the scope of their training data, requiring retraining to recognize novel changes. To overcome this limitation, we introduce a novel change detection task utilizing textual prompts alongside two potentially unaligned images to produce binary segmentations highlighting user-relevant changes. This text-conditioned framework significantly broadens the scope of change detection, enabling unparalleled flexibility and straightforward scalability by incorporating diverse future datasets without restriction to specific change types. As a first approach to address this challenge, we propose ViewDelta, a multimodal architecture extending the vision transformer into the domain of text-conditioned change detection. ViewDelta establishes a robust baseline, demonstrating flexibility across various scenarios and achieving competitive results compared to specialized, fine-tuned models trained on aligned images. Moreover, we create and release the first text-prompt-conditioned change detection dataset, comprising 501,153 image pairs with corresponding textual prompts and annotated labels. Extensive experiments confirm the robustness and versatility of our model across diverse environments, including indoor, outdoor, street-level, synthetic, and satellite imagery. this https URL ",
    "url": "https://arxiv.org/abs/2412.07612",
    "authors": [
      "Subin Varghese",
      "Joshua Gao",
      "Vedhus Hoskere"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2412.08116",
    "title": "Diffusion-based Data Augmentation and Knowledge Distillation with Generated Soft Labels Solving Data Scarcity Problems of SAR Oil Spill Segmentation",
    "abstract": "           Oil spills pose severe environmental risks, making early detection crucial for effective response and mitigation. As Synthetic Aperture Radar (SAR) images operate under all-weather conditions, SAR-based oil spill segmentation enables fast and robust monitoring. However, when using deep learning models, SAR oil spill segmentation often struggles in training due to the scarcity of labeled data. To address this limitation, we propose a diffusion-based data augmentation with knowledge transfer (DAKTer) strategy. Our DAKTer strategy enables a diffusion model to generate SAR oil spill images along with soft label pairs, which offer richer class probability distributions than segmentation masks (i.e. hard labels). Also, for reliable joint generation of high-quality SAR images and well-aligned soft labels, we introduce an SNR-based balancing factor aligning the noise corruption process of both modalilties in diffusion models. By leveraging the generated SAR images and soft labels, a student segmentation model can learn robust feature representations without teacher models trained for the same task, improving its ability to segment oil spill regions. Extensive experiments demonstrate that our DAKTer strategy effectively transfers the knowledge of per-pixel class probabilities to the student segmentation model to distinguish the oil spill regions from other look-alike regions in the SAR images. Our DAKTer strategy boosts various segmentation models to achieve superior performance with large margins compared to other generative data augmentation methods.         ",
    "url": "https://arxiv.org/abs/2412.08116",
    "authors": [
      "Jaeho Moon",
      "Jeonghwan Yun",
      "Jaehyun Kim",
      "Jaehyup Lee",
      "Munchurl Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2412.08897",
    "title": "Neural Interactive Proofs",
    "abstract": "           We consider the problem of how a trusted, but computationally bounded agent (a 'verifier') can learn to interact with one or more powerful but untrusted agents ('provers') in order to solve a given task. More specifically, we study the case in which agents are represented using neural networks and refer to solutions of this problem as neural interactive proofs. First we introduce a unifying framework based on prover-verifier games, which generalises previously proposed interaction protocols. We then describe several new protocols for generating neural interactive proofs, and provide a theoretical comparison of both new and existing approaches. Finally, we support this theory with experiments in two domains: a toy graph isomorphism problem that illustrates the key ideas, and a code validation task using large language models. In so doing, we aim to create a foundation for future work on neural interactive proofs and their application in building safer AI systems.         ",
    "url": "https://arxiv.org/abs/2412.08897",
    "authors": [
      "Lewis Hammond",
      "Sam Adam-Day"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2412.12370",
    "title": "Scam Detection for Ethereum Smart Contracts: Leveraging Graph Representation Learning for Secure Blockchain",
    "abstract": "           Due to the increasing abuse of fraudulent activities that result in significant financial and reputational harm, Ethereum smart contracts face a significant problem in detecting fraud. Existing monitoring methods typically rely on lease code analysis or physically extracted features, which suffer from scalability and adaptability limitations. In this study, we use graph representation learning to observe purchase trends and find fraudulent deals. We can achieve powerful categorisation performance by using innovative machine learning versions and transforming Ethereum invoice data into graph structures. Our method addresses label imbalance through SMOTE-ENN techniques and evaluates models like Multi-Layer Perceptron ( MLP ) and Graph Convolutional Networks ( GCN). Experimental results show that the MLP type surpasses the GCN in this environment, with domain-specific assessments closely aligned with real-world assessments. This study provides a scalable and efficient way to improve Ethereum's ecosystem's confidence and security.         ",
    "url": "https://arxiv.org/abs/2412.12370",
    "authors": [
      "Yihong Jin",
      "Ze Yang",
      "Xinhe Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2501.05661",
    "title": "TAMER: A Test-Time Adaptive MoE-Driven Framework for EHR Representation Learning",
    "abstract": "           We propose TAMER, a Test-time Adaptive MoE-driven framework for Electronic Health Record (EHR) Representation learning. TAMER introduces a framework where a Mixture-of-Experts (MoE) architecture is co-designed with Test-Time Adaptation (TTA) to jointly mitigate the intertwined challenges of patient heterogeneity and distribution shifts in EHR modeling. The MoE focuses on latent patient subgroups through domain-aware expert specialization, while TTA enables real-time adaptation to evolving health status distributions when new patient samples are introduced. Extensive experiments across four real-world EHR datasets demonstrate that TAMER consistently improves predictive performance for both mortality and readmission risk tasks when combined with diverse EHR modeling backbones. TAMER offers a promising approach for dynamic and personalized EHR-based predictions in practical clinical settings.         ",
    "url": "https://arxiv.org/abs/2501.05661",
    "authors": [
      "Yinghao Zhu",
      "Xiaochen Zheng",
      "Ahmed Allam",
      "Michael Krauthammer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2501.08238",
    "title": "CodecFake+: A Large-Scale Neural Audio Codec-Based Deepfake Speech Dataset",
    "abstract": "           With the rapid advancement of neural audio codecs, codec-based speech generation (CoSG) systems have become highly powerful. Unfortunately, CoSG also enables the creation of highly realistic deepfake speech, making it easier to mimic an individual's voice and spread misinformation. We refer to this emerging deepfake speech generated by CoSG systems as CodecFake. Detecting such CodecFake is an urgent challenge, yet most existing systems primarily focus on detecting fake speech generated by traditional speech synthesis models. In this paper, we introduce CodecFake+, a large-scale dataset designed to advance CodecFake detection. To our knowledge, CodecFake+ is the largest dataset encompassing the most diverse range of codec architectures. The training set is generated through re-synthesis using 31 publicly available open-source codec models, while the evaluation set includes web-sourced data from 17 advanced CoSG models. We also propose a comprehensive taxonomy that categorizes codecs by their root components: vector quantizer, auxiliary objectives, and decoder types. Our proposed dataset and taxonomy enable detailed analysis at multiple levels to discern the key factors for successful CodecFake detection. At the individual codec level, we validate the effectiveness of using codec re-synthesized speech (CoRS) as training data for large-scale CodecFake detection. At the taxonomy level, we show that detection performance is strongest when the re-synthesis model incorporates disentanglement auxiliary objectives or a frequency-domain decoder. Furthermore, from the perspective of using all the CoRS training data, we show that our proposed taxonomy can be used to select better training data for improving detection performance. Overall, we envision that CodecFake+ will be a valuable resource for both general and fine-grained exploration to develop better anti-spoofing models against CodecFake.         ",
    "url": "https://arxiv.org/abs/2501.08238",
    "authors": [
      "Xuanjun Chen",
      "Jiawei Du",
      "Haibin Wu",
      "Lin Zhang",
      "I-Ming Lin",
      "I-Hsiang Chiu",
      "Wenze Ren",
      "Yuan Tseng",
      "Yu Tsao",
      "Jyh-Shing Roger Jang",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2501.08880",
    "title": "SLC$^2$-SLAM: Semantic-guided Loop Closure using Shared Latent Code for NeRF SLAM",
    "abstract": "           Targeting the notorious cumulative drift errors in NeRF SLAM, we propose a Semantic-guided Loop Closure using Shared Latent Code, dubbed SLC$^2$-SLAM. We argue that latent codes stored in many NeRF SLAM systems are not fully exploited, as they are only used for better reconstruction. In this paper, we propose a simple yet effective way to detect potential loops using the same latent codes as local features. To further improve the loop detection performance, we use the semantic information, which are also decoded from the same latent codes to guide the aggregation of local features. Finally, with the potential loops detected, we close them with a graph optimization followed by bundle adjustment to refine both the estimated poses and the reconstructed scene. To evaluate the performance of our SLC$^2$-SLAM, we conduct extensive experiments on Replica and ScanNet datasets. Our proposed semantic-guided loop closure significantly outperforms the pre-trained NetVLAD and ORB combined with Bag-of-Words, which are used in all the other NeRF SLAM with loop closure. As a result, our SLC$^2$-SLAM also demonstrated better tracking and reconstruction performance, especially in larger scenes with more loops, like ScanNet.         ",
    "url": "https://arxiv.org/abs/2501.08880",
    "authors": [
      "Yuhang Ming",
      "Di Ma",
      "Weichen Dai",
      "Han Yang",
      "Rui Fan",
      "Guofeng Zhang",
      "Wanzeng Kong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2501.09129",
    "title": "Deep Self-Supervised Disturbance Mapping with the OPERA Sentinel-1 Radiometric Terrain Corrected SAR Backscatter Product",
    "abstract": "           Mapping land surface disturbances supports disaster response, resource and ecosystem management, and climate adaptation efforts. Synthetic aperture radar (SAR) is an invaluable tool for disturbance mapping, providing consistent time-series images of the ground regardless of weather or illumination conditions. Despite SAR's potential for disturbance mapping, processing SAR data to an analysis-ready format requires expertise and significant compute resources, particularly for large-scale global analysis. In October 2023, NASA's Observational Products for End-Users from Remote Sensing Analysis (OPERA) project released the near-global Radiometric Terrain Corrected SAR backscatter from Sentinel-1 (RTC-S1) dataset, providing publicly available, analysis-ready SAR imagery. In this work, we utilize this new dataset to systematically analyze land surface disturbances. As labeling SAR data is often prohibitively time-consuming, we train a self-supervised vision transformer - which requires no labels to train - on OPERA RTC-S1 data to estimate a per-pixel distribution from the set of baseline imagery and assess disturbances when there is significant deviation from the modeled distribution. To test our model's capability and generality, we evaluate three different natural disasters - which represent high-intensity, abrupt disturbances - from three different regions of the world. Across events, our approach yields high quality delineations: F1 scores exceeding 0.6 and Areas Under the Precision-Recall Curve exceeding 0.65, consistently outperforming existing SAR disturbance methods. Our findings suggest that a self-supervised vision transformer is well-suited for global disturbance mapping and can be a valuable tool for operational, near-global disturbance monitoring, particularly when labeled data does not exist.         ",
    "url": "https://arxiv.org/abs/2501.09129",
    "authors": [
      "Harris Hardiman-Mostow",
      "Charles Marshak",
      "Alexander L. Handwerger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2501.09292",
    "title": "To Retrieve or Not to Retrieve? Uncertainty Detection for Dynamic Retrieval Augmented Generation",
    "abstract": "           Retrieval-Augmented Generation equips large language models with the capability to retrieve external knowledge, thereby mitigating hallucinations by incorporating information beyond the model's intrinsic abilities. However, most prior works have focused on invoking retrieval deterministically, which makes it unsuitable for tasks such as long-form question answering. Instead, dynamically performing retrieval by invoking it only when the underlying LLM lacks the required knowledge can be more efficient. In this context, we delve deeper into the question, \"To Retrieve or Not to Retrieve?\" by exploring multiple uncertainty detection methods. We evaluate these methods for the task of long-form question answering, employing dynamic retrieval, and present our comparisons. Our findings suggest that uncertainty detection metrics, such as Degree Matrix Jaccard and Eccentricity, can reduce the number of retrieval calls by almost half, with only a slight reduction in question-answering accuracy.         ",
    "url": "https://arxiv.org/abs/2501.09292",
    "authors": [
      "Kaustubh D. Dhole"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2501.10266",
    "title": "MutualForce: Mutual-Aware Enhancement for 4D Radar-LiDAR 3D Object Detection",
    "abstract": "           Radar and LiDAR have been widely used in autonomous driving as LiDAR provides rich structure information, and radar demonstrates high robustness under adverse weather. Recent studies highlight the effectiveness of fusing radar and LiDAR point clouds. However, challenges remain due to the modality misalignment and information loss during feature extractions. To address these issues, we propose a 4D radar-LiDAR framework to mutually enhance their representations. Initially, the indicative features from radar are utilized to guide both radar and LiDAR geometric feature learning. Subsequently, to mitigate their sparsity gap, the shape information from LiDAR is used to enrich radar BEV features. Extensive experiments on the View-of-Delft (VoD) dataset demonstrate our approach's superiority over existing methods, achieving the highest mAP of 71.76% across the entire area and 86.36\\% within the driving corridor. Especially for cars, we improve the AP by 4.17% and 4.20% due to the strong indicative features and symmetric shapes.         ",
    "url": "https://arxiv.org/abs/2501.10266",
    "authors": [
      "Xiangyuan Peng",
      "Huawei Sun",
      "Kay Bierzynski",
      "Anton Fischbacher",
      "Lorenzo Servadei",
      "Robert Wille"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2501.14009",
    "title": "Scalable and Interpretable Verification of Image-based Neural Network Controllers for Autonomous Vehicles",
    "abstract": "           Existing formal verification methods for image-based neural network controllers in autonomous vehicles often struggle with high-dimensional inputs, computational inefficiency, and a lack of explainability. These challenges make it difficult to ensure safety and reliability, as processing high-dimensional image data is computationally intensive and neural networks are typically treated as black boxes. To address these issues, we propose SEVIN (Scalable and Explainable Verification of Image-Based Neural Network Controllers), a framework that leverages a Variational Autoencoders (VAE) to encode high-dimensional images into a lower-dimensional, explainable latent space. By annotating latent variables with corresponding control actions, we generate convex polytopes that serve as structured input spaces for verification, significantly reducing computational complexity and enhancing scalability. Integrating the VAE's decoder with the neural network controller allows for formal and robustness verification using these explainable polytopes. Our approach also incorporates robustness verification under real-world perturbations by augmenting the dataset and retraining the VAE to capture environmental variations. Experimental results demonstrate that SEVIN achieves efficient and scalable verification while providing explainable insights into controller behavior, bridging the gap between formal verification techniques and practical applications in safety-critical systems.         ",
    "url": "https://arxiv.org/abs/2501.14009",
    "authors": [
      "Aditya Parameshwaran",
      "Yue Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2502.06769",
    "title": "Enhancing Trust in Language Model-Based Code Optimization through RLHF: A Research Design",
    "abstract": "           With the rapid advancement of AI, software engineering increasingly relies on AI-driven approaches, particularly language models (LMs), to enhance code performance. However, the trustworthiness and reliability of LMs remain significant challenges due to the potential for hallucinations - unreliable or incorrect responses. To fill this gap, this research aims to develop reliable, LM-powered methods for code optimization that effectively integrate human feedback. This work aligns with the broader objectives of advancing cooperative and human-centric aspects of software engineering, contributing to the development of trustworthy AI-driven solutions.         ",
    "url": "https://arxiv.org/abs/2502.06769",
    "authors": [
      "Jingzhi Gong"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2502.16793",
    "title": "VGFL-SA: Vertical Graph Federated Learning Structure Attack Based on Contrastive Learning",
    "abstract": "           Graph Neural Networks (GNNs) have gained attention for their ability to learn representations from graph data. Due to privacy concerns and conflicts of interest that prevent clients from directly sharing graph data with one another, Vertical Graph Federated Learning (VGFL) frameworks have been developed. Recent studies have shown that VGFL is vulnerable to adversarial attacks that degrade performance. However, it is a common problem that client nodes are often unlabeled in the realm of VGFL. Consequently, the existing attacks, which rely on the availability of labeling information to obtain gradients, are inherently constrained in their applicability. This limitation precludes their deployment in practical, real-world environments. To address the above problems, we propose a novel graph adversarial attack against VGFL, referred to as VGFL-SA, to degrade the performance of VGFL by modifying the local clients structure without using labels. Specifically, VGFL-SA uses a contrastive learning method to complete the attack before the local clients are trained. VGFL-SA first accesses the graph structure and node feature information of the poisoned clients, and generates the contrastive views by node-degree-based edge augmentation and feature shuffling augmentation. Then, VGFL-SA uses the shared graph encoder to get the embedding of each view, and the gradients of the adjacency matrices are obtained by the contrastive function. Finally, perturbed edges are generated using gradient modification rules. We validated the performance of VGFL-SA by performing a node classification task on real-world datasets, and the results show that VGFL-SA achieves good attack effectiveness and transferability.         ",
    "url": "https://arxiv.org/abs/2502.16793",
    "authors": [
      "Yang Chen",
      "Bin Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2502.17371",
    "title": "Sustainable Greenhouse Microclimate Modeling: A Comparative Analysis of Recurrent and Graph Neural Networks",
    "abstract": "           The integration of photovoltaic (PV) systems into greenhouses not only optimizes land use but also enhances sustainable agricultural practices by enabling dual benefits of food production and renewable energy generation. However, accurate prediction of internal environmental conditions is crucial to ensure optimal crop growth while maximizing energy production. This study introduces a novel application of Spatio-Temporal Graph Neural Networks (STGNNs) to greenhouse microclimate modeling, comparing their performance with traditional Recurrent Neural Networks (RNNs). While RNNs excel at temporal pattern recognition, they cannot explicitly model the directional relationships between environmental variables. Our STGNN approach addresses this limitation by representing these relationships as directed graphs, enabling the model to capture both environmental dependencies and their directionality. Using high-frequency data collected at 15-minute intervals from a greenhouse in Volos, Greece, we demonstrate that RNNs achieve exceptional accuracy in winter conditions ($R^2 = 0.985$) but show limitations during summer cooling system operation. Though STGNNs currently show lower performance (winter $R^2 = 0.947$), their architecture offers greater potential for integrating additional variables such as PV generation and crop growth indicators.         ",
    "url": "https://arxiv.org/abs/2502.17371",
    "authors": [
      "Emiliano Seri",
      "Marcello Petitta",
      "Cristina Cornaro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2502.19848",
    "title": "One-for-More: Continual Diffusion Model for Anomaly Detection",
    "abstract": "           With the rise of generative models, there is a growing interest in unifying all tasks within a generative framework. Anomaly detection methods also fall into this scope and utilize diffusion models to generate or reconstruct normal samples when given arbitrary anomaly images. However, our study found that the diffusion model suffers from severe ``faithfulness hallucination'' and ``catastrophic forgetting'', which can't meet the unpredictable pattern increments. To mitigate the above problems, we propose a continual diffusion model that uses gradient projection to achieve stable continual learning. Gradient projection deploys a regularization on the model updating by modifying the gradient towards the direction protecting the learned knowledge. But as a double-edged sword, it also requires huge memory costs brought by the Markov process. Hence, we propose an iterative singular value decomposition method based on the transitive property of linear representation, which consumes tiny memory and incurs almost no performance loss. Finally, considering the risk of ``over-fitting'' to normal images of the diffusion model, we propose an anomaly-masked network to enhance the condition mechanism of the diffusion model. For continual anomaly detection, ours achieves first place in 17/18 settings on MVTec and VisA. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2502.19848",
    "authors": [
      "Xiaofan Li",
      "Xin Tan",
      "Zhuo Chen",
      "Zhizhong Zhang",
      "Ruixin Zhang",
      "Rizen Guo",
      "Guanna Jiang",
      "Yulong Chen",
      "Yanyun Qu",
      "Lizhuang Ma",
      "Yuan Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2502.20528",
    "title": "ConfuGuard: Using Metadata to Detect Active and Stealthy Package Confusion Attacks Accurately and at Scale",
    "abstract": "           Package confusion attacks such as typosquatting threaten software supply chains. Attackers make packages with names that syntactically or semantically resemble legitimate ones, tricking engineers into installing malware. While prior work has developed defenses against package confusions in some software package registries, notably NPM, PyPI, and RubyGems, gaps remain: high false-positive rates; generalization to more software package ecosystems; and insights from real-world deployment. In this work, we introduce ConfuGuard, a solution designed to address the challenges posed by package confusion threats. We begin by presenting the first empirical analysis of benign signals derived from prior package confusion data, uncovering their threat patterns, engineering practices, and measurable attributes. We observed that 13.3% of real package confusion attacks are initially stealthy, so we take that into consideration and refined the definitions. Building on state-of-the-art approaches, we extend support from three to six software package registries, and leverage package metadata to distinguish benign packages. Our approach significantly reduces 64% false-positive (from 77% to 13%), with acceptable additional overhead to filter out benign packages by analyzing the package metadata. ConfuGuard is in production at our industry partner, whose analysts have already confirmed 301 packages detected by ConfuGuard as real attacks. We share lessons learned from production and provide insights to researchers.         ",
    "url": "https://arxiv.org/abs/2502.20528",
    "authors": [
      "Wenxin Jiang",
      "Berk \u00c7akar",
      "Mikola Lysenko",
      "James C. Davis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2503.03586",
    "title": "Benchmarking LLMs and LLM-based Agents in Practical Vulnerability Detection for Code Repositories",
    "abstract": "           Large Language Models (LLMs) have shown promise in software vulnerability detection, particularly on function-level benchmarks like Devign and BigVul. However, real-world detection requires interprocedural analysis, as vulnerabilities often emerge through multi-hop function calls rather than isolated functions. While repository-level benchmarks like ReposVul and VulEval introduce interprocedural context, they remain computationally expensive, lack pairwise evaluation of vulnerability fixes, and explore limited context retrieval, limiting their practicality. We introduce JitVul, a JIT vulnerability detection benchmark linking each function to its vulnerability-introducing and fixing commits. Built from 879 CVEs spanning 91 vulnerability types, JitVul enables comprehensive evaluation of detection capabilities. Our results show that ReAct Agents, leveraging thought-action-observation and interprocedural context, perform better than LLMs in distinguishing vulnerable from benign code. While prompting strategies like Chain-of-Thought help LLMs, ReAct Agents require further refinement. Both methods show inconsistencies, either misidentifying vulnerabilities or over-analyzing security guards, indicating significant room for improvement.         ",
    "url": "https://arxiv.org/abs/2503.03586",
    "authors": [
      "Alperen Yildiz",
      "Sin G. Teo",
      "Yiling Lou",
      "Yebo Feng",
      "Chong Wang",
      "Dinil M. Divakaran"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2503.04833",
    "title": "Adversarial Training for Multimodal Large Language Models against Jailbreak Attacks",
    "abstract": "           Multimodal large language models (MLLMs) have made remarkable strides in cross-modal comprehension and generation tasks. However, they remain vulnerable to jailbreak attacks, where crafted perturbations bypass security guardrails and elicit harmful outputs. In this paper, we present the first adversarial training (AT) paradigm tailored to defend against jailbreak attacks during the MLLM training phase. Extending traditional AT to this domain poses two critical challenges: efficiently tuning massive parameters and ensuring robustness against attacks across multiple modalities. To address these challenges, we introduce Projection Layer Against Adversarial Training (ProEAT), an end-to-end AT framework. ProEAT incorporates a projector-based adversarial training architecture that efficiently handles large-scale parameters while maintaining computational feasibility by focusing adversarial training on a lightweight projector layer instead of the entire model; additionally, we design a dynamic weight adjustment mechanism that optimizes the loss function's weight allocation based on task demands, streamlining the tuning process. To enhance defense performance, we propose a joint optimization strategy across visual and textual modalities, ensuring robust resistance to jailbreak attacks originating from either modality. Extensive experiments conducted on five major jailbreak attack methods across three mainstream MLLMs demonstrate the effectiveness of our approach. ProEAT achieves state-of-the-art defense performance, outperforming existing baselines by an average margin of +34% across text and image modalities, while incurring only a 1% reduction in clean accuracy. Furthermore, evaluations on real-world embodied intelligent systems highlight the practical applicability of our framework, paving the way for the development of more secure and reliable multimodal systems.         ",
    "url": "https://arxiv.org/abs/2503.04833",
    "authors": [
      "Liming Lu",
      "Shuchao Pang",
      "Siyuan Liang",
      "Haotian Zhu",
      "Xiyu Zeng",
      "Aishan Liu",
      "Yunhuai Liu",
      "Yongbin Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2503.04843",
    "title": "Self-Supervised Z-Slice Augmentation for 3D Bio-Imaging via Knowledge Distillation",
    "abstract": "           Three-dimensional biological microscopy has significantly advanced our understanding of complex biological structures. However, limitations due to microscopy techniques, sample properties or phototoxicity often result in poor z-resolution, hindering accurate cellular measurements. Here, we introduce ZAugNet, a fast, accurate, and self-supervised deep learning method for enhancing z-resolution in biological images. By performing nonlinear interpolation between consecutive slices, ZAugNet effectively doubles resolution with each iteration. Compared on several microscopy modalities and biological objects, it outperforms competing methods on most metrics. Our method leverages a generative adversarial network (GAN) architecture combined with knowledge distillation to maximize prediction speed without compromising accuracy. We also developed ZAugNet+, an extended version enabling continuous interpolation at arbitrary distances, making it particularly useful for datasets with nonuniform slice spacing. Both ZAugNet and ZAugNet+ provide high-performance, scalable z-slice augmentation solutions for large-scale 3D imaging. They are available as open-source frameworks in PyTorch, with an intuitive Colab notebook interface for easy access by the scientific community.         ",
    "url": "https://arxiv.org/abs/2503.04843",
    "authors": [
      "Alessandro Pasqui",
      "Sajjad Mahdavi",
      "Benoit Vianay",
      "Alexandra Colin",
      "Alex McDougall",
      "R\u00e9mi Dumollard",
      "Yekaterina A. Miroshnikova",
      "Elsa Labrune",
      "Herv\u00e9 Turlier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2503.09033",
    "title": "RFUAV: A Benchmark Dataset for Unmanned Aerial Vehicle Detection and Identification",
    "abstract": "           In this paper, we propose RFUAV as a new benchmark dataset for radio-frequency based (RF-based) unmanned aerial vehicle (UAV) identification and address the following challenges: Firstly, many existing datasets feature a restricted variety of drone types and insufficient volumes of raw data, which fail to meet the demands of practical applications. Secondly, existing datasets often lack raw data covering a broad range of signal-to-noise ratios (SNR), or do not provide tools for transforming raw data to different SNR levels. This limitation undermines the validity of model training and evaluation. Lastly, many existing datasets do not offer open-access evaluation tools, leading to a lack of unified evaluation standards in current research within this field. RFUAV comprises approximately 1.3 TB of raw frequency data collected from 37 distinct UAVs using the Universal Software Radio Peripheral (USRP) device in real-world environments. Through in-depth analysis of the RF data in RFUAV, we define a drone feature sequence called RF drone fingerprint, which aids in distinguishing drone signals. In addition to the dataset, RFUAV provides a baseline preprocessing method and model evaluation tools. Rigorous experiments demonstrate that these preprocessing methods achieve state-of-the-art (SOTA) performance using the provided evaluation tools. The RFUAV dataset and baseline implementation are publicly available at this https URL.         ",
    "url": "https://arxiv.org/abs/2503.09033",
    "authors": [
      "Rui Shi",
      "Xiaodong Yu",
      "Shengming Wang",
      "Yijia Zhang",
      "Lu Xu",
      "Peng Pan",
      "Chunlai Ma"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.09101",
    "title": "The Shape of Attraction in UMAP: Exploring the Embedding Forces in Dimensionality Reduction",
    "abstract": "           Uniform manifold approximation and projection (UMAP) is among the most popular neighbor embedding methods. The method relies on attractive and repulsive forces among high-dimensional data points to obtain a low-dimensional embedding. In this paper, we analyze the forces to reveal their effects on cluster formations and visualization. Repulsion emphasizes differences, controlling cluster boundaries and inter-cluster distance. Attraction is more subtle, as attractive tension between points can manifest simultaneously as attraction and repulsion in the lower-dimensional mapping. This explains the need for learning rate annealing and motivates the different treatments between attractive and repulsive terms. Moreover, by modifying attraction, we improve the consistency of cluster formation under random initialization. Overall, our analysis makes UMAP and similar embedding methods more interpretable, more robust, and more accurate.         ",
    "url": "https://arxiv.org/abs/2503.09101",
    "authors": [
      "Mohammad Tariqul Islam",
      "Jason W. Fleischer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.09496",
    "title": "Robust Multimodal Survival Prediction with the Latent Differentiation Conditional Variational AutoEncoder",
    "abstract": "           The integrative analysis of histopathological images and genomic data has received increasing attention for survival prediction of human cancers. However, the existing studies always hold the assumption that full modalities are available. As a matter of fact, the cost for collecting genomic data is high, which sometimes makes genomic data unavailable in testing samples. A common way of tackling such incompleteness is to generate the genomic representations from the pathology images. Nevertheless, such strategy still faces the following two challenges: (1) The gigapixel whole slide images (WSIs) are huge and thus hard for representation. (2) It is difficult to generate the genomic embeddings with diverse function categories in a unified generative framework. To address the above challenges, we propose a Conditional Latent Differentiation Variational AutoEncoder (LD-CVAE) for robust multimodal survival prediction, even with missing genomic data. Specifically, a Variational Information Bottleneck Transformer (VIB-Trans) module is proposed to learn compressed pathological representations from the gigapixel WSIs. To generate different functional genomic features, we develop a novel Latent Differentiation Variational AutoEncoder (LD-VAE) to learn the common and specific posteriors for the genomic embeddings with diverse functions. Finally, we use the product-of-experts technique to integrate the genomic common posterior and image posterior for the joint latent distribution estimation in LD-CVAE. We test the effectiveness of our method on five different cancer datasets, and the experimental results demonstrate its superiority in both complete and missing modality scenarios.         ",
    "url": "https://arxiv.org/abs/2503.09496",
    "authors": [
      "Junjie Zhou",
      "Jiao Tang",
      "Yingli Zuo",
      "Peng Wan",
      "Daoqiang Zhang",
      "Wei Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.10253",
    "title": "PIMRL: Physics-Informed Multi-Scale Recurrent Learning for Spatiotemporal Prediction",
    "abstract": "           Simulation of spatiotemporal systems governed by partial differential equations is widely applied in fields such as biology, chemistry, aerospace dynamics, and meteorology. Traditional numerical methods incur high computational costs due to the requirement of small time steps for accurate predictions. While machine learning has reduced these costs, long-term predictions remain challenged by error accumulation, particularly in scenarios with insufficient data or varying time scales, where stability and accuracy are compromised. Existing methods often neglect the effective utilization of multi-scale data, leading to suboptimal robustness in predictions. To address these issues, we propose a novel multi-scale learning framework, namely, the Physics-Informed Multi-Scale Recurrent Learning (PIMRL), to effectively leverage multi-scale data for spatiotemporal dynamics prediction. The PIMRL framework comprises two modules: the micro-scale module embeds physical knowledge into neural networks via pretraining, and the macro-scale module adopts a data-driven approach to learn the temporal evolution of physics in the latent space. Experimental results demonstrate that the PIMRL framework consistently achieves state-of-the-art performance across five benchmark datasets ranging from one to three dimensions, showing average improvements of over 9\\% in both RMSE and MAE evaluation metrics, with maximum enhancements reaching up to 80%.         ",
    "url": "https://arxiv.org/abs/2503.10253",
    "authors": [
      "Han Wan",
      "Qi Wang",
      "Yuan Mi",
      "Hao Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.11709",
    "title": "Conformal Prediction and Human Decision Making",
    "abstract": "           Methods to quantify uncertainty in predictions from arbitrary models are in demand in high-stakes domains like medicine and finance. Conformal prediction has emerged as a popular method for producing a set of predictions with specified average coverage, in place of a single prediction and confidence value. However, the value of conformal prediction sets to assist human decisions remains elusive due to the murky relationship between coverage guarantees and decision makers' goals and strategies. How should we think about conformal prediction sets as a form of decision support? We outline a decision theoretic framework for evaluating predictive uncertainty as informative signals, then contrast what can be said within this framework about idealized use of calibrated probabilities versus conformal prediction sets. Informed by prior empirical results and theories of human decisions under uncertainty, we formalize a set of possible strategies by which a decision maker might use a prediction set. We identify ways in which conformal prediction sets and posthoc predictive uncertainty quantification more broadly are in tension with common goals and needs in human-AI decision making. We give recommendations for future research in predictive uncertainty quantification to support human decision makers.         ",
    "url": "https://arxiv.org/abs/2503.11709",
    "authors": [
      "Jessica Hullman",
      "Yifan Wu",
      "Dawei Xie",
      "Ziyang Guo",
      "Andrew Gelman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2503.11714",
    "title": "Conversation Networks",
    "abstract": "           Picture a community torn over a proposed zoning law. Some are angry, others defensive, and misunderstandings abound. On social media, they broadcast insults at one another; every nuanced perspective is reduced to a viral soundbite. Yet, when they meet face-to-face and start speaking, something changes: residents begin listening more than speaking, and people begin testing ideas together. Misunderstandings fade, and trust begins to form. By the end of their discussion, they have not only softened their hostility, but discovered actionable plans that benefit everyone. This is the kind of meaningful discourse our society desperately needs. Yet our digital platforms -- designed primarily for maximizing engagement through provocative content -- have pulled us away from these core community endeavours. As a constructive path forward, we introduce the idea of conversation networks as a basis for civic communication infrastructure that combines interoperable digital apps with the thoughtful integration of AI guided by human agency.         ",
    "url": "https://arxiv.org/abs/2503.11714",
    "authors": [
      "Deb Roy",
      "Lawrence Lessig",
      "Audrey Tang"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2503.11737",
    "title": "Multi-View Node Pruning for Accurate Graph Representation",
    "abstract": "           Graph pooling, which compresses a whole graph into a smaller coarsened graph, is an essential component of graph representation learning. To efficiently compress a given graph, graph pooling methods often drop their nodes with attention-based scoring with the task loss. However, this often results in simply removing nodes with lower degrees without consideration of their feature-level relevance to the given task. To fix this problem, we propose a Multi-View Pruning(MVP), a graph pruning method based on a multi-view framework and reconstruction loss. Given a graph, MVP first constructs multiple graphs for different views either by utilizing the predefined modalities or by randomly partitioning the input features, to consider the importance of each node in diverse perspectives. Then, it learns the score for each node by considering both the reconstruction and the task loss. MVP can be incorporated with any hierarchical pooling framework to score the nodes. We validate MVP on multiple benchmark datasets by coupling it with two graph pooling methods, and show that it significantly improves the performance of the base graph pooling method, outperforming all baselines. Further analysis shows that both the encoding of multiple views and the consideration of reconstruction loss are the key to the success of MVP, and that it indeed identifies nodes that are less important according to domain knowledge.         ",
    "url": "https://arxiv.org/abs/2503.11737",
    "authors": [
      "Jiseong Park",
      "Hanjin Kim",
      "Seojin Kim",
      "Jueun Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.11741",
    "title": "BioMamba: Leveraging Spectro-Temporal Embedding in Bidirectional Mamba for Enhanced Biosignal Classification",
    "abstract": "           Biological signals, such as electroencephalograms (EEGs) and electrocardiograms (ECGs), play a pivotal role in numerous clinical practices, such as diagnosing brain and cardiac arrhythmic diseases. Existing methods for biosignal classification rely on Attention-based frameworks with dense Feed Forward layers, which lead to inefficient learning, high computational overhead, and suboptimal performance. In this work, we introduce BioMamba, a Spectro-Temporal Embedding strategy applied to the Bidirectional Mamba framework with Sparse Feed Forward layers to enable effective learning of biosignal sequences. By integrating these three key components, BioMamba effectively addresses the limitations of existing methods. Extensive experiments demonstrate that BioMamba significantly outperforms state-of-the-art methods with marked improvement in classification performance. The advantages of the proposed BioMamba include (1) Reliability: BioMamba consistently delivers robust results, confirmed across six evaluation metrics. (2) Efficiency: We assess both model and training efficiency, the BioMamba demonstrates computational effectiveness by reducing model size and resource consumption compared to existing approaches. (3) Generality: With the capacity to effectively classify a diverse set of tasks, BioMamba demonstrates adaptability and effectiveness across various domains and applications.         ",
    "url": "https://arxiv.org/abs/2503.11741",
    "authors": [
      "Jian Qian",
      "Teck Lun Goh",
      "Bingyu Xie",
      "Chengyao Zhu",
      "Biao Wan",
      "Yawen Guan",
      "Patrick Yin Chiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.12009",
    "title": "UniMamba: Unified Spatial-Channel Representation Learning with Group-Efficient Mamba for LiDAR-based 3D Object Detection",
    "abstract": "           Recent advances in LiDAR 3D detection have demonstrated the effectiveness of Transformer-based frameworks in capturing the global dependencies from point cloud spaces, which serialize the 3D voxels into the flattened 1D sequence for iterative self-attention. However, the spatial structure of 3D voxels will be inevitably destroyed during the serialization process. Besides, due to the considerable number of 3D voxels and quadratic complexity of Transformers, multiple sequences are grouped before feeding to Transformers, leading to a limited receptive field. Inspired by the impressive performance of State Space Models (SSM) achieved in the field of 2D vision tasks, in this paper, we propose a novel Unified Mamba (UniMamba), which seamlessly integrates the merits of 3D convolution and SSM in a concise multi-head manner, aiming to perform \"local and global\" spatial context aggregation efficiently and simultaneously. Specifically, a UniMamba block is designed which mainly consists of spatial locality modeling, complementary Z-order serialization and local-global sequential aggregator. The spatial locality modeling module integrates 3D submanifold convolution to capture the dynamic spatial position embedding before serialization. Then the efficient Z-order curve is adopted for serialization both horizontally and vertically. Furthermore, the local-global sequential aggregator adopts the channel grouping strategy to efficiently encode both \"local and global\" spatial inter-dependencies using multi-head SSM. Additionally, an encoder-decoder architecture with stacked UniMamba blocks is formed to facilitate multi-scale spatial learning hierarchically. Extensive experiments are conducted on three popular datasets: nuScenes, Waymo and Argoverse 2. Particularly, our UniMamba achieves 70.2 mAP on the nuScenes dataset.         ",
    "url": "https://arxiv.org/abs/2503.12009",
    "authors": [
      "Xin Jin",
      "Haisheng Su",
      "Kai Liu",
      "Cong Ma",
      "Wei Wu",
      "Fei Hui",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.12821",
    "title": "From Head to Tail: Towards Balanced Representation in Large Vision-Language Models through Adaptive Data Calibration",
    "abstract": "           Large Vision-Language Models (LVLMs) have achieved significant progress in combining visual comprehension with language generation. Despite this success, the training data of LVLMs still suffers from Long-Tail (LT) problems, where the data distribution is highly imbalanced. Previous works have mainly focused on traditional VLM architectures, i.e., CLIP or ViT, and specific tasks such as recognition and classification. Nevertheless, the exploration of LVLM (e.g. LLaVA) and more general tasks (e.g. Visual Question Answering and Visual Reasoning) remains under-explored. In this paper, we first conduct an in-depth analysis of the LT issues in LVLMs and identify two core causes: the overrepresentation of head concepts and the underrepresentation of tail concepts. Based on the above observation, we propose an $\\textbf{A}$daptive $\\textbf{D}$ata $\\textbf{R}$efinement Framework ($\\textbf{ADR}$), which consists of two stages: $\\textbf{D}$ata $\\textbf{R}$ebalancing ($\\textbf{DR}$) and $\\textbf{D}$ata $\\textbf{S}$ynthesis ($\\textbf{DS}$). In the DR stage, we adaptively rebalance the redundant data based on entity distributions, while in the DS stage, we leverage Denoising Diffusion Probabilistic Models (DDPMs) and scarce images to supplement underrepresented portions. Through comprehensive evaluations across eleven benchmarks, our proposed ADR effectively mitigates the long-tail problem in the training data, improving the average performance of LLaVA 1.5 relatively by 4.36%, without increasing the training data volume.         ",
    "url": "https://arxiv.org/abs/2503.12821",
    "authors": [
      "Mingyang Song",
      "Xiaoye Qu",
      "Jiawei Zhou",
      "Yu Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2503.12827",
    "title": "GSBA$^K$: $top$-$K$ Geometric Score-based Black-box Attack",
    "abstract": "           Existing score-based adversarial attacks mainly focus on crafting $top$-1 adversarial examples against classifiers with single-label classification. Their attack success rate and query efficiency are often less than satisfactory, particularly under small perturbation requirements; moreover, the vulnerability of classifiers with multi-label learning is yet to be studied. In this paper, we propose a comprehensive surrogate free score-based attack, named \\b geometric \\b score-based \\b black-box \\b attack (GSBA$^K$), to craft adversarial examples in an aggressive $top$-$K$ setting for both untargeted and targeted attacks, where the goal is to change the $top$-$K$ predictions of the target classifier. We introduce novel gradient-based methods to find a good initial boundary point to attack. Our iterative method employs novel gradient estimation techniques, particularly effective in $top$-$K$ setting, on the decision boundary to effectively exploit the geometry of the decision boundary. Additionally, GSBA$^K$ can be used to attack against classifiers with $top$-$K$ multi-label learning. Extensive experimental results on ImageNet and PASCAL VOC datasets validate the effectiveness of GSBA$^K$ in crafting $top$-$K$ adversarial examples.         ",
    "url": "https://arxiv.org/abs/2503.12827",
    "authors": [
      "Md Farhamdur Reza",
      "Richeng Jin",
      "Tianfu Wu",
      "Huaiyu Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.12874",
    "title": "Evolution-based Region Adversarial Prompt Learning for Robustness Enhancement in Vision-Language Models",
    "abstract": "           Large pre-trained vision-language models (VLMs), such as CLIP, demonstrate impressive generalization but remain highly vulnerable to adversarial examples (AEs). Previous work has explored robust text prompts through adversarial training, achieving some improvement in both robustness and generalization. However, they primarily rely on singlegradient direction perturbations (e.g., PGD) to generate AEs, which lack diversity, resulting in limited improvement in adversarial robustness. To address these limitations, we propose an evolution-based region adversarial prompt tuning method called ER-APT, which combines gradient methods with genetic evolution to generate more diverse and challenging AEs. In each training iteration, we first generate AEs using traditional gradient-based methods. Subsequently, a genetic evolution mechanism incorporating selection, mutation, and crossover is applied to optimize the AEs, ensuring a broader and more aggressive perturbation this http URL final evolved AEs are used for prompt tuning, achieving region-based adversarial optimization instead of conventional single-point adversarial prompt tuning. We also propose a dynamic loss weighting method to adjust prompt learning efficiency for accuracy and robustness. Experimental evaluations on various benchmark datasets demonstrate the superiority of our proposed method, outperforming stateof-the-art APT methods. The code is released at this https URL.         ",
    "url": "https://arxiv.org/abs/2503.12874",
    "authors": [
      "Xiaojun Jia",
      "Sensen Gao",
      "Simeng Qin",
      "Ke Ma",
      "Xinfeng Li",
      "Yihao Huang",
      "Wei Dong",
      "Yang Liu",
      "Xiaochun Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.12924",
    "title": "Social Media Journeys -- Mapping Platform Migration",
    "abstract": "           As people engage with the social media landscape, popular platforms rise and fall. As current research uncovers the experiences people have on various platforms, rarely do we engage with the sociotechnical migration processes when joining and leaving them. In this paper, we asked 32 visitors of a science communication festival to draw out artifacts that we call Social Media Journey Maps about the social media platforms they frequented, and why. By combining qualitative content analysis with a graph representation of Social Media Journeys, we present how social media migration processes are motivated by the interplay of environmental and platform factors. We find that peer-driven popularity, the timing of feature adoption, and personal perceptions of migration causes - such as security - shape individuals' reasoning for migrating between social media platforms. With this work, we aim to pave the way for future social media platforms that foster meaningful and enriching online experiences for users.         ",
    "url": "https://arxiv.org/abs/2503.12924",
    "authors": [
      "Artur Solomonik",
      "Hendrik Heuer"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2305.17998",
    "title": "Infinite Eulerian paths are computable on graphs with vertices of infinite degree",
    "abstract": "           The Erd\u0151s, Gr\u00fcnwald, and Weiszfeld theorem is a characterization of those infinite graphs which are Eulerian. That is, infinite graphs that admit infinite Eulerian paths. In this article we prove an effective version of the Erd\u0151s, Gr\u00fcnwald, and Weiszfeld theorem for a class of graphs where vertices of infinite degree are allowed, generalizing a theorem of this http URL. Our results are obtained from a characterization of those finite paths in a graph that can be extended to infinite Eulerian paths.         ",
    "url": "https://arxiv.org/abs/2305.17998",
    "authors": [
      "Nicanor Carrasco-Vargas"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)",
      "Group Theory (math.GR)",
      "Logic (math.LO)"
    ]
  },
  {
    "id": "arXiv:2312.01061",
    "title": "Spectral-wise Implicit Neural Representation for Hyperspectral Image Reconstruction",
    "abstract": "           Coded Aperture Snapshot Spectral Imaging (CASSI) reconstruction aims to recover the 3D spatial-spectral signal from 2D measurement. Existing methods for reconstructing Hyperspectral Image (HSI) typically involve learning mappings from a 2D compressed image to a predetermined set of discrete spectral bands. However, this approach overlooks the inherent continuity of the spectral information. In this study, we propose an innovative method called Spectral-wise Implicit Neural Representation (SINR) as a pioneering step toward addressing this limitation. SINR introduces a continuous spectral amplification process for HSI reconstruction, enabling spectral super-resolution with customizable magnification factors. To achieve this, we leverage the concept of implicit neural representation. Specifically, our approach introduces a spectral-wise attention mechanism that treats individual channels as distinct tokens, thereby capturing global spectral dependencies. Additionally, our approach incorporates two components, namely a Fourier coordinate encoder and a spectral scale factor module. The Fourier coordinate encoder enhances the SINR's ability to emphasize high-frequency components, while the spectral scale factor module guides the SINR to adapt to the variable number of spectral channels. Notably, the SINR framework enhances the flexibility of CASSI reconstruction by accommodating an unlimited number of spectral bands in the desired output. Extensive experiments demonstrate that our SINR outperforms baseline methods. By enabling continuous reconstruction within the CASSI framework, we take the initial stride toward integrating implicit neural representation into the field.         ",
    "url": "https://arxiv.org/abs/2312.01061",
    "authors": [
      "Huan Chen",
      "Wangcai Zhao",
      "Tingfa Xu",
      "Shiyun Zhou",
      "Peifu Liu",
      "Jianan Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.00261",
    "title": "Finite groups with geodetic Cayley graphs",
    "abstract": "           A connected undirected graph is called \\emph{geodetic} if for every pair of vertices there is a unique shortest path connecting them. It has been conjectured that for finite groups, the only geodetic Cayley graphs are odd cycles and complete graphs. In this article we present a series of theoretical results which contribute to a computer search verifying this conjecture for all groups of size up to 1024. The conjecture is also verified for several infinite families of groups including dihedral and some families of nilpotent groups. Two key results which enable the computer search to reach as far as it does are: if the center of a group has even order, then the conjecture holds (this eliminates all $2$-groups from our computer search); if a Cayley graph is geodetic then there are bounds relating the size of the group, generating set and center (which significantly cuts down the number of generating sets which must be searched).         ",
    "url": "https://arxiv.org/abs/2406.00261",
    "authors": [
      "Murray Elder",
      "Adam Piggott",
      "Florian Stober",
      "Alexander Thumm",
      "Armin Wei\u00df"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2408.16121",
    "title": "Degree-balanced decompositions of cubic graphs",
    "abstract": "           We show that every cubic graph on $n$ vertices contains a spanning subgraph in which the number of vertices of each degree deviates from $\\frac{n}{4}$ by at most $\\frac{1}{2}$, up to three exceptions. This resolves the conjecture of Alon and Wei (Irregular subgraphs, Combin. Probab. Comput. 32(2) (2023), 269--283) for cubic graphs.         ",
    "url": "https://arxiv.org/abs/2408.16121",
    "authors": [
      "Borut Lu\u017ear",
      "Jakub Przyby\u0142o",
      "Roman Sot\u00e1k"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2409.06034",
    "title": "Reconstructing semi-directed level-1 networks using few quarnets",
    "abstract": "           Semi-directed networks are partially directed graphs that model evolution where the directed edges represent reticulate evolutionary events. We present an algorithm that reconstructs binary $n$-leaf semi-directed level-1 networks in $O( n^2)$ time from its quarnets (4-leaf subnetworks). Our method assumes we have direct access to all quarnets, yet uses only an asymptotically optimal number of $O(n \\log n)$ quarnets. When the network is assumed to contain no triangles, our method instead relies only on four-cycle quarnets and the splits of the other quarnets. A variant of our algorithm works with quartets rather than quarnets and we show that it reconstructs most of a semi-directed level-1 network from an asymptotically optimal $O(n \\log n)$ of the quartets it displays. Additionally, we provide an $O(n^3)$ time algorithm that reconstructs the tree-of-blobs of any binary $n$-leaf semi-directed network with unbounded level from $O(n^3)$ splits of its quarnets.         ",
    "url": "https://arxiv.org/abs/2409.06034",
    "authors": [
      "Martin Frohn",
      "Niels Holtgrefe",
      "Leo van Iersel",
      "Mark Jones",
      "Steven Kelk"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2409.17273",
    "title": "Targeted Neural Architectures in Multi-Objective Frameworks for Complete Glioma Characterization from Multimodal MRI",
    "abstract": "           Brain tumors result from abnormal cell growth in brain tissue. If undiagnosed, they cause neurological deficits, including cognitive impairment, motor dysfunction, and sensory loss. As tumors grow, intracranial pressure increases, potentially leading to fatal complications such as brain herniation. Early diagnosis and treatment are crucial to controlling these effects and slowing tumor progression. Deep learning (DL) and artificial intelligence (AI) are increasingly used to assist doctors in early diagnosis through magnetic resonance imaging (MRI) scans. Our research proposes targeted neural architectures within multi-objective frameworks that can localize, segment, and classify the grade of these gliomas from multimodal MRI images to solve this critical issue. Our localization framework utilizes a targeted architecture that enhances the LinkNet framework with an encoder inspired by VGG19 for better multimodal feature extraction from the tumor along with spatial and graph attention mechanisms that sharpen feature focus and inter-feature relationships. For the segmentation objective, we deployed a specialized framework using the SeResNet101 CNN model as the encoder backbone integrated into the LinkNet architecture, achieving an IoU Score of 96%. The classification objective is addressed through a distinct framework implemented by combining the SeResNet152 feature extractor with Adaptive Boosting classifier, reaching an accuracy of 98.53%. Our multi-objective approach with targeted neural architectures demonstrated promising results for complete glioma characterization, with the potential to advance medical AI by enabling early diagnosis and providing more accurate treatment options for patients.         ",
    "url": "https://arxiv.org/abs/2409.17273",
    "authors": [
      "Shravan Venkatraman",
      "Pandiyaraju V",
      "Abeshek A",
      "Aravintakshan S A",
      "Pavan Kumar S",
      "Kannan A",
      "Madhan S"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2410.12819",
    "title": "Deep Adversarial Learning with Activity-Based User Discrimination Task for Human Activity Recognition",
    "abstract": "           We present a new adversarial deep learning framework for the problem of human activity recognition (HAR) using inertial sensors worn by people. Our framework incorporates a novel adversarial activity-based discrimination task that addresses inter-person variability-i.e., the fact that different people perform the same activity in different ways. Overall, our proposed framework outperforms previous approaches on three HAR datasets using a leave-one-(person)-out cross-validation (LOOCV) benchmark. Additional results demonstrate that our discrimination task yields better classification results compared to previous tasks within the same adversarial framework.         ",
    "url": "https://arxiv.org/abs/2410.12819",
    "authors": [
      "Francisco M. Calatrava-Nicol\u00e1s",
      "Shoko Miyauchi",
      "Oscar Martinez Mozos"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2412.20173",
    "title": "Debiased Nonparametric Regression for Statistical Inference and Distributionally Robustness",
    "abstract": "           This study proposes a debiasing method for smooth nonparametric estimators. While machine learning techniques such as random forests and neural networks have demonstrated strong predictive performance, their theoretical properties remain relatively underexplored. In particular, many modern algorithms lack guarantees of pointwise and uniform risk convergence, as well as asymptotic normality. These properties are essential for statistical inference and robust estimation and have been well-established for classical methods such as Nadaraya-Watson regression. To ensure these properties for various nonparametric regression estimators, we introduce a model-free debiasing method. By incorporating a correction term that estimates the conditional expected residual of the original estimator, or equivalently, its estimation error, into the initial nonparametric regression estimator, we obtain a debiased estimator that satisfies pointwise and uniform risk convergence, along with asymptotic normality, under mild smoothness conditions. These properties facilitate statistical inference and enhance robustness to covariate shift, making the method broadly applicable to a wide range of nonparametric regression problems.         ",
    "url": "https://arxiv.org/abs/2412.20173",
    "authors": [
      "Masahiro Kato"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2502.20762",
    "title": "Towards Practical Real-Time Neural Video Compression",
    "abstract": "           We introduce a practical real-time neural video codec (NVC) designed to deliver high compression ratio, low latency and broad versatility. In practice, the coding speed of NVCs depends on 1) computational costs, and 2) non-computational operational costs, such as memory I/O and the number of function calls. While most efficient NVCs prioritize reducing computational cost, we identify operational cost as the primary bottleneck to achieving higher coding speed. Leveraging this insight, we introduce a set of efficiency-driven design improvements focused on minimizing operational costs. Specifically, we employ implicit temporal modeling to eliminate complex explicit motion modules, and use single low-resolution latent representations rather than progressive downsampling. These innovations significantly accelerate NVC without sacrificing compression quality. Additionally, we implement model integerization for consistent cross-device coding and a module-bank-based rate control scheme to improve practical adaptability. Experiments show our proposed DCVC-RT achieves an impressive average encoding/decoding speed at 125.2/112.8 fps (frames per second) for 1080p video, while saving an average of 21% in bitrate compared to H.266/VTM. The code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2502.20762",
    "authors": [
      "Zhaoyang Jia",
      "Bin Li",
      "Jiahao Li",
      "Wenxuan Xie",
      "Linfeng Qi",
      "Houqiang Li",
      "Yan Lu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2503.13050",
    "title": "E-Values Expand the Scope of Conformal Prediction",
    "abstract": "           Conformal prediction is a powerful framework for distribution-free uncertainty quantification. The standard approach to conformal prediction relies on comparing the ranks of prediction scores: under exchangeability, the rank of a future test point cannot be too extreme relative to a calibration set. This rank-based method can be reformulated in terms of p-values. In this paper, we explore an alternative approach based on e-values, known as conformal e-prediction. E-values offer key advantages that cannot be achieved with p-values, enabling new theoretical and practical capabilities. In particular, we present three applications that leverage the unique strengths of e-values: batch anytime-valid conformal prediction, fixed-size conformal sets with data-dependent coverage, and conformal prediction under ambiguous ground truth. Overall, these examples demonstrate that e-value-based constructions provide a flexible expansion of the toolbox of conformal prediction.         ",
    "url": "https://arxiv.org/abs/2503.13050",
    "authors": [
      "Etienne Gauthier",
      "Francis Bach",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  }
]