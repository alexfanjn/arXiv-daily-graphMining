[
  {
    "id": "arXiv:2408.00768",
    "title": "Comparing Optical Flow and Deep Learning to Enable Computationally Efficient Traffic Event Detection with Space-Filling Curves",
    "abstract": "           Gathering data and identifying events in various traffic situations remains an essential challenge for the systematic evaluation of a perception system's performance. Analyzing large-scale, typically unstructured, multi-modal, time series data obtained from video, radar, and LiDAR is computationally demanding, particularly when meta-information or annotations are missing. We compare Optical Flow (OF) and Deep Learning (DL) to feed computationally efficient event detection via space-filling curves on video data from a forward-facing, in-vehicle camera. Our first approach leverages unexpected disturbances in the OF field from vehicle surroundings; the second approach is a DL model trained on human visual attention to predict a driver's gaze to spot potential event locations. We feed these results to a space-filling curve to reduce dimensionality and achieve computationally efficient event retrieval. We systematically evaluate our concept by obtaining characteristic patterns for both approaches from a large-scale virtual dataset (SMIRK) and applied our findings to the Zenseact Open Dataset (ZOD), a large multi-modal, real-world dataset, collected over two years in 14 different European countries. Our results yield that the OF approach excels in specificity and reduces false positives, while the DL approach demonstrates superior sensitivity. Both approaches offer comparable processing speed, making them suitable for real-time applications.         ",
    "url": "https://arxiv.org/abs/2408.00768",
    "authors": [
      "Tayssir Bouraffa",
      "Elias Kjellberg Carlson",
      "Erik Wessman",
      "Ali Nouri",
      "Pierre Lamart",
      "Christian Berger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.00771",
    "title": "2D Neural Fields with Learned Discontinuities",
    "abstract": "           Effective representation of 2D images is fundamental in digital image processing, where traditional methods like raster and vector graphics struggle with sharpness and textural complexity respectively. Current neural fields offer high-fidelity and resolution independence but require predefined meshes with known discontinuities, restricting their utility. We observe that by treating all mesh edges as potential discontinuities, we can represent the magnitude of discontinuities with continuous variables and optimize. Based on this observation, we introduce a novel discontinuous neural field model that jointly approximate the target image and recovers discontinuities. Through systematic evaluations, our neural field demonstrates superior performance in denoising and super-resolution tasks compared to InstantNGP, achieving improvements of over 5dB and 10dB, respectively. Our model also outperforms Mumford-Shah-based methods in accurately capturing discontinuities, with Chamfer distances 3.5x closer to the ground truth. Additionally, our approach shows remarkable capability in handling complex artistic drawings and natural images.         ",
    "url": "https://arxiv.org/abs/2408.00771",
    "authors": [
      "Chenxi Liu",
      "Siqi Wang",
      "Matthew Fisher",
      "Deepali Aneja",
      "Alec Jacobson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2408.00775",
    "title": "Dilated convolution neural operator for multiscale partial differential equations",
    "abstract": "           This paper introduces a data-driven operator learning method for multiscale partial differential equations, with a particular emphasis on preserving high-frequency information. Drawing inspiration from the representation of multiscale parameterized solutions as a combination of low-rank global bases (such as low-frequency Fourier modes) and localized bases over coarse patches (analogous to dilated convolution), we propose the Dilated Convolutional Neural Operator (DCNO). The DCNO architecture effectively captures both high-frequency and low-frequency features while maintaining a low computational cost through a combination of convolution and Fourier layers. We conduct experiments to evaluate the performance of DCNO on various datasets, including the multiscale elliptic equation, its inverse problem, Navier-Stokes equation, and Helmholtz equation. We show that DCNO strikes an optimal balance between accuracy and computational cost and offers a promising solution for multiscale operator learning.         ",
    "url": "https://arxiv.org/abs/2408.00775",
    "authors": [
      "Bo Xu",
      "Xinliang Liu",
      "Lei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2408.00777",
    "title": "CATD: Unified Representation Learning for EEG-to-fMRI Cross-Modal Generation",
    "abstract": "           Multi-modal neuroimaging analysis is crucial for a comprehensive understanding of brain function and pathology, as it allows for the integration of different imaging techniques, thus overcoming the limitations of individual modalities. However, the high costs and limited availability of certain modalities pose significant challenges. To address these issues, this paper proposed the Condition-Aligned Temporal Diffusion (CATD) framework for end-to-end cross-modal synthesis of neuroimaging, enabling the generation of functional magnetic resonance imaging (fMRI)-detected Blood Oxygen Level Dependent (BOLD) signals from more accessible Electroencephalography (EEG) signals. By constructing Conditionally Aligned Block (CAB), heterogeneous neuroimages are aligned into a potential space, achieving a unified representation that provides the foundation for cross-modal transformation in neuroimaging. The combination with the constructed Dynamic Time-Frequency Segmentation (DTFS) module also enables the use of EEG signals to improve the temporal resolution of BOLD signals, thus augmenting the capture of the dynamic details of the brain. Experimental validation demonstrated the effectiveness of the framework in improving the accuracy of neural activity prediction, identifying abnormal brain regions, and enhancing the temporal resolution of BOLD signals. The proposed framework establishes a new paradigm for cross-modal synthesis of neuroimaging by unifying heterogeneous neuroimaging data into a potential representation space, showing promise in medical applications such as improving Parkinson's disease prediction and identifying abnormal brain regions.         ",
    "url": "https://arxiv.org/abs/2408.00777",
    "authors": [
      "Weiheng Yao",
      "Shuqiang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2408.00788",
    "title": "SpikeVoice: High-Quality Text-to-Speech Via Efficient Spiking Neural Network",
    "abstract": "           Brain-inspired Spiking Neural Network (SNN) has demonstrated its effectiveness and efficiency in vision, natural language, and speech understanding tasks, indicating their capacity to \"see\", \"listen\", and \"read\". In this paper, we design \\textbf{SpikeVoice}, which performs high-quality Text-To-Speech (TTS) via SNN, to explore the potential of SNN to \"speak\". A major obstacle to using SNN for such generative tasks lies in the demand for models to grasp long-term dependencies. The serial nature of spiking neurons, however, leads to the invisibility of information at future spiking time steps, limiting SNN models to capture sequence dependencies solely within the same time step. We term this phenomenon \"partial-time dependency\". To address this issue, we introduce Spiking Temporal-Sequential Attention STSA in the SpikeVoice. To the best of our knowledge, SpikeVoice is the first TTS work in the SNN field. We perform experiments using four well-established datasets that cover both Chinese and English languages, encompassing scenarios with both single-speaker and multi-speaker configurations. The results demonstrate that SpikeVoice can achieve results comparable to Artificial Neural Networks (ANN) with only 10.5 energy consumption of ANN.         ",
    "url": "https://arxiv.org/abs/2408.00788",
    "authors": [
      "Kexin Wang",
      "Jiahong Zhang",
      "Yong Ren",
      "Man Yao",
      "Di Shang",
      "Bo Xu",
      "Guoqi Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.00790",
    "title": "Improving Air Mobility for Pre-Disaster Planning with Neural Network Accelerated Genetic Algorithm",
    "abstract": "           Weather disaster related emergency operations pose a great challenge to air mobility in both aircraft and airport operations, especially when the impact is gradually approaching. We propose an optimized framework for adjusting airport operational schedules for such pre-disaster scenarios. We first, aggregate operational data from multiple airports and then determine the optimal count of evacuation flights to maximize the impacted airport's outgoing capacity without impeding regular air traffic. We then propose a novel Neural Network (NN) accelerated Genetic Algorithm(GA) for evacuation planning. Our experiments show that integration yielded comparable results but with smaller computational overhead. We find that the utilization of a NN enhances the efficiency of a GA, facilitating more rapid convergence even when operating with a reduced population size. This effectiveness persists even when the model is trained on data from airports different from those under test.         ",
    "url": "https://arxiv.org/abs/2408.00790",
    "authors": [
      "Kamal Acharya",
      "Alvaro Velasquez",
      "Yongxin Liu",
      "Dahai Liu",
      "Liang Sun",
      "Houbing Song"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.00792",
    "title": "A Scalable and Generalized Deep Learning Framework for Anomaly Detection in Surveillance Videos",
    "abstract": "           Anomaly detection in videos is challenging due to the complexity, noise, and diverse nature of activities such as violence, shoplifting, and vandalism. While deep learning (DL) has shown excellent performance in this area, existing approaches have struggled to apply DL models across different anomaly tasks without extensive retraining. This repeated retraining is time-consuming, computationally intensive, and unfair. To address this limitation, a new DL framework is introduced in this study, consisting of three key components: transfer learning to enhance feature generalization, model fusion to improve feature representation, and multi-task classification to generalize the classifier across multiple tasks without training from scratch when new task is introduced. The framework's main advantage is its ability to generalize without requiring retraining from scratch for each new task. Empirical evaluations demonstrate the framework's effectiveness, achieving an accuracy of 97.99% on the RLVS dataset (violence detection), 83.59% on the UCF dataset (shoplifting detection), and 88.37% across both datasets using a single classifier without retraining. Additionally, when tested on an unseen dataset, the framework achieved an accuracy of 87.25%. The study also utilizes two explainability tools to identify potential biases, ensuring robustness and fairness. This research represents the first successful resolution of the generalization issue in anomaly detection, marking a significant advancement in the field.         ",
    "url": "https://arxiv.org/abs/2408.00792",
    "authors": [
      "Sabah Abdulazeez Jebur",
      "Khalid A. Hussein",
      "Haider Kadhim Hoomod",
      "Laith Alzubaidi",
      "Ahmed Ali Saihood",
      "YuanTong Gu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.00794",
    "title": "CCSRP: Robust Pruning of Spiking Neural Networks through Cooperative Coevolution",
    "abstract": "           Spiking neural networks (SNNs) have shown promise in various dynamic visual tasks, yet those ready for practical deployment often lack the compactness and robustness essential in resource-limited and safety-critical settings. Prior research has predominantly concentrated on enhancing the compactness or robustness of artificial neural networks through strategies like network pruning and adversarial training, with little exploration into similar methodologies for SNNs. Robust pruning of SNNs aims to reduce computational overhead while preserving both accuracy and robustness. Current robust pruning approaches generally necessitate expert knowledge and iterative experimentation to establish suitable pruning criteria or auxiliary modules, thus constraining their broader application. Concurrently, evolutionary algorithms (EAs) have been employed to automate the pruning of artificial neural networks, delivering remarkable outcomes yet overlooking the aspect of robustness. In this work, we propose CCSRP, an innovative robust pruning method for SNNs, underpinned by cooperative co-evolution. Robust pruning is articulated as a tri-objective optimization challenge, striving to balance accuracy, robustness, and compactness concurrently, resolved through a cooperative co-evolutionary pruning framework that independently prunes filters across layers using EAs. Our experiments on CIFAR-10 and SVHN demonstrate that CCSRP can match or exceed the performance of the latest methodologies.         ",
    "url": "https://arxiv.org/abs/2408.00794",
    "authors": [
      "Zichen Song",
      "Jiakang Li",
      "Songning Lai",
      "Sitan Huang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.00818",
    "title": "Y Social: an LLM-powered Social Media Digital Twin",
    "abstract": "           In this paper we introduce Y, a new-generation digital twin designed to replicate an online social media platform. Digital twins are virtual replicas of physical systems that allow for advanced analyses and experimentation. In the case of social media, a digital twin such as Y provides a powerful tool for researchers to simulate and understand complex online interactions. {\\tt Y} leverages state-of-the-art Large Language Models (LLMs) to replicate sophisticated agent behaviors, enabling accurate simulations of user interactions, content dissemination, and network dynamics. By integrating these aspects, Y offers valuable insights into user engagement, information spread, and the impact of platform policies. Moreover, the integration of LLMs allows Y to generate nuanced textual content and predict user responses, facilitating the study of emergent phenomena in online environments. To better characterize the proposed digital twin, in this paper we describe the rationale behind its implementation, provide examples of the analyses that can be performed on the data it enables to be generated, and discuss its relevance for multidisciplinary research.         ",
    "url": "https://arxiv.org/abs/2408.00818",
    "authors": [
      "Giulio Rossetti",
      "Massimo Stella",
      "R\u00e9my Cazabet",
      "Katherine Abramski",
      "Erica Cau",
      "Salvatore Citraro",
      "Andrea Failla",
      "Riccardo Improta",
      "Virginia Morini",
      "Valentina Pansanella"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2408.00860",
    "title": "UlRe-NeRF: 3D Ultrasound Imaging through Neural Rendering with Ultrasound Reflection Direction Parameterization",
    "abstract": "           Three-dimensional ultrasound imaging is a critical technology widely used in medical diagnostics. However, traditional 3D ultrasound imaging methods have limitations such as fixed resolution, low storage efficiency, and insufficient contextual connectivity, leading to poor performance in handling complex artifacts and reflection characteristics. Recently, techniques based on NeRF (Neural Radiance Fields) have made significant progress in view synthesis and 3D reconstruction, but there remains a research gap in high-quality ultrasound imaging. To address these issues, we propose a new model, UlRe-NeRF, which combines implicit neural networks and explicit ultrasound volume rendering into an ultrasound neural rendering architecture. This model incorporates reflection direction parameterization and harmonic encoding, using a directional MLP module to generate view-dependent high-frequency reflection intensity estimates, and a spatial MLP module to produce the medium's physical property parameters. These parameters are used in the volume rendering process to accurately reproduce the propagation and reflection behavior of ultrasound waves in the medium. Experimental results demonstrate that the UlRe-NeRF model significantly enhances the realism and accuracy of high-fidelity ultrasound image reconstruction, especially in handling complex medium structures.         ",
    "url": "https://arxiv.org/abs/2408.00860",
    "authors": [
      "Ziwen Guo",
      "Zi Fang",
      "Zhuang Fu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.00863",
    "title": "UniMoT: Unified Molecule-Text Language Model with Discrete Token Representation",
    "abstract": "           The remarkable success of Large Language Models (LLMs) across diverse tasks has driven the research community to extend their capabilities to molecular applications. However, most molecular LLMs employ adapter-based architectures that do not treat molecule and text modalities equally and lack a supervision signal for the molecule modality. To address these issues, we introduce UniMoT, a Unified Molecule-Text LLM adopting a tokenizer-based architecture that expands the vocabulary of LLM with molecule tokens. Specifically, we introduce a Vector Quantization-driven tokenizer that incorporates a Q-Former to bridge the modality gap between molecule and text. This tokenizer transforms molecules into sequences of molecule tokens with causal dependency, encapsulating high-level molecular and textual information. Equipped with this tokenizer, UniMoT can unify molecule and text modalities under a shared token representation and an autoregressive training paradigm, enabling it to interpret molecules as a foreign language and generate them as text. Following a four-stage training scheme, UniMoT emerges as a multi-modal generalist capable of performing both molecule-to-text and text-to-molecule tasks. Extensive experiments demonstrate that UniMoT achieves state-of-the-art performance across a wide range of molecule comprehension and generation tasks.         ",
    "url": "https://arxiv.org/abs/2408.00863",
    "authors": [
      "Juzheng Zhang",
      "Yatao Bian",
      "Yongqiang Chen",
      "Quanming Yao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.00872",
    "title": "Online Detection of Anomalies in Temporal Knowledge Graphs with Interpretability",
    "abstract": "           Temporal knowledge graphs (TKGs) are valuable resources for capturing evolving relationships among entities, yet they are often plagued by noise, necessitating robust anomaly detection mechanisms. Existing dynamic graph anomaly detection approaches struggle to capture the rich semantics introduced by node and edge categories within TKGs, while TKG embedding methods lack interpretability, undermining the credibility of anomaly detection. Moreover, these methods falter in adapting to pattern changes and semantic drifts resulting from knowledge updates. To tackle these challenges, we introduce AnoT, an efficient TKG summarization method tailored for interpretable online anomaly detection in TKGs. AnoT begins by summarizing a TKG into a novel rule graph, enabling flexible inference of complex patterns in TKGs. When new knowledge emerges, AnoT maps it onto a node in the rule graph and traverses the rule graph recursively to derive the anomaly score of the knowledge. The traversal yields reachable nodes that furnish interpretable evidence for the validity or the anomalous of the new knowledge. Overall, AnoT embodies a detector-updater-monitor architecture, encompassing a detector for offline TKG summarization and online scoring, an updater for real-time rule graph updates based on emerging knowledge, and a monitor for estimating the approximation error of the rule graph. Experimental results on four real-world datasets demonstrate that AnoT surpasses existing methods significantly in terms of accuracy and interoperability. All of the raw datasets and the implementation of AnoT are provided in this https URL.         ",
    "url": "https://arxiv.org/abs/2408.00872",
    "authors": [
      "Jiasheng Zhang",
      "Jie Shao",
      "Rex Ying"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.00882",
    "title": "Benchmarking Attacks on Learning with Errors",
    "abstract": "           Lattice cryptography schemes based on the learning with errors (LWE) hardness assumption have been standardized by NIST for use as post-quantum cryptosystems, and by this http URL for encrypted compute on sensitive data. Thus, understanding their concrete security is critical. Most work on LWE security focuses on theoretical estimates of attack performance, which is important but may overlook attack nuances arising in real-world implementations. The sole existing concrete benchmarking effort, the Darmstadt Lattice Challenge, does not include benchmarks relevant to the standardized LWE parameter choices - such as small secret and small error distributions, and Ring-LWE (RLWE) and Module-LWE (MLWE) variants. To improve our understanding of concrete LWE security, we provide the first benchmarks for LWE secret recovery on standardized parameters, for small and low-weight (sparse) secrets. We evaluate four LWE attacks in these settings to serve as a baseline: the Search-LWE attacks uSVP, SALSA, and Cool & Cruel, and the Decision-LWE attack: Dual Hybrid Meet-in-the-Middle (MitM). We extend the SALSA and Cool & Cruel attacks in significant ways, and implement and scale up MitM attacks for the first time. For example, we recover hamming weight $9-11$ binomial secrets for KYBER ($\\kappa=2$) parameters in $28-36$ hours with SALSA and Cool\\&Cruel, while we find that MitM can solve Decision-LWE instances for hamming weights up to $4$ in under an hour for Kyber parameters, while uSVP attacks do not recover any secrets after running for more than $1100$ hours. We also compare concrete performance against theoretical estimates. Finally, we open source the code to enable future research.         ",
    "url": "https://arxiv.org/abs/2408.00882",
    "authors": [
      "Emily Wenger",
      "Eshika Saxena",
      "Mohamed Malhou",
      "Ellie Thieu",
      "Kristin Lauter"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2408.00901",
    "title": "A value-focused thinking approach to measure community resilience",
    "abstract": "           Community resilience refers to the ability to prepare for, absorb, recover from, and adapt to disruptive events, but specific definitions and measures for resilience can vary widely from researcher to researcher or from discipline to discipline. Community resilience is often measured using a set of indicators based on census, socioeconomic, and community organizational data, but these metrics and measures for community resilience provide little guidance for policymakers to determine how best to increase the community resilience. This article proposes to measure community resilience based on value focused thinking. We propose an objectives hierarchy that begins with a community decision makers' fundamental objective for resilience. Six high level objectives for community resilience, including social resilience, economic resilience, infrastructure resilience, environmental resilience, availability of resources, and functionality of critical services, are broken down into measurable attributes that focus on specific outcomes that a decision maker would like to achieve if a disruption occurs. This new way of assessing resilience is applied to measure the resilience of an illustrative community to an improvised explosive device, a cyberattack, a tornado, a flood, and a winter storm. Keywords: Community Resilience, Resiliency, Risk Analysis         ",
    "url": "https://arxiv.org/abs/2408.00901",
    "authors": [
      "Rohit Suresh",
      "Parastoo Akbari",
      "Cameron A MacKenzie"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Optimization and Control (math.OC)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2408.00905",
    "title": "High-Impact Innovations and Hidden Gender Disparities in Inventor-Evaluator Networks",
    "abstract": "           We study of millions of scientific, technological, and artistic innovations and find that the innovation gap faced by women is far from universal. No gap exists for conventional innovations. Rather, the gap is pervasively rooted in innovations that combine ideas in unexpected ways - innovations most critical to scientific breakthroughs. Further, at the USPTO we find that female examiners reject up to 33 percent more unconventional innovations by women inventors than do male examiners, suggesting that gender discrimination weakly explains this innovation gap. Instead, new data indicate that a configuration of institutional practices explains the innovation gap. These practices compromise the expertise women examiners need to accurately assess unconventional innovations and then \"over-assign\" women examiners to women innovators, undermining women's innovations. These institutional impediments negatively impact innovation rates in science but have the virtue of being more amenable to actionable policy changes than does culturally ingrained gender discrimination.         ",
    "url": "https://arxiv.org/abs/2408.00905",
    "authors": [
      "Tara Sowrirajan",
      "Ryan Whalen",
      "Brian Uzzi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2408.00906",
    "title": "Parkinson's Disease Detection from Resting State EEG using Multi-Head Graph Structure Learning with Gradient Weighted Graph Attention Explanations",
    "abstract": "           Parkinson's disease (PD) is a debilitating neurodegenerative disease that has severe impacts on an individual's quality of life. Compared with structural and functional MRI-based biomarkers for the disease, electroencephalography (EEG) can provide more accessible alternatives for clinical insights. While deep learning (DL) techniques have provided excellent outcomes, many techniques fail to model spatial information and dynamic brain connectivity, and face challenges in robust feature learning, limited data sizes, and poor explainability. To address these issues, we proposed a novel graph neural network (GNN) technique for explainable PD detection using resting state EEG. Specifically, we employ structured global convolutions with contrastive learning to better model complex features with limited data, a novel multi-head graph structure learner to capture the non-Euclidean structure of EEG data, and a head-wise gradient-weighted graph attention explainer to offer neural connectivity insights. We developed and evaluated our method using the UC San Diego Parkinson's disease EEG dataset, and achieved 69.40% detection accuracy in subject-wise leave-one-out cross-validation while generating intuitive explanations for the learnt graph topology.         ",
    "url": "https://arxiv.org/abs/2408.00906",
    "authors": [
      "Christopher Neves",
      "Yong Zeng",
      "Yiming Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.00914",
    "title": "Granting GPT-4 License and Opportunity: Enhancing Accuracy and Confidence Estimation for Few-Shot Event Detection",
    "abstract": "           Large Language Models (LLMs) such as GPT-4 have shown enough promise in the few-shot learning context to suggest use in the generation of \"silver\" data and refinement of new ontologies through iterative application and review. Such workflows become more effective with reliable confidence estimation. Unfortunately, confidence estimation is a documented weakness of models such as GPT-4, and established methods to compensate require significant additional complexity and computation. The present effort explores methods for effective confidence estimation with GPT-4 with few-shot learning for event detection in the BETTER ontology as a vehicle. The key innovation is expanding the prompt and task presented to GPT-4 to provide License to speculate when unsure and Opportunity to quantify and explain its uncertainty (L&O). This approach improves accuracy and provides usable confidence measures (0.759 AUC) with no additional machinery.         ",
    "url": "https://arxiv.org/abs/2408.00914",
    "authors": [
      "Steven Fincke",
      "Adrien Bibal",
      "Elizabeth Boschee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2408.00918",
    "title": "Safety-Critical Control with Offline-Online Neural Network Inference",
    "abstract": "           This paper presents a safety-critical control framework for an ego agent moving among other agents. The approach infers the dynamics of the other agents, and incorporates the inferred quantities into the design of control barrier function (CBF)-based controllers for the ego agent. The inference method combines offline and online learning with radial basis function neural networks (RBFNNs). The RBFNNs are initially trained offline using collected datasets. To enhance the generalization of the RBFNNs, the weights are then updated online with new observations, without requiring persistent excitation conditions in order to enhance the applicability of the method. Additionally, we employ adaptive conformal prediction to quantify the estimation error of the RBFNNs for the other agents' dynamics, generating prediction sets to cover the true value with high probability. Finally, we formulate a CBF-based controller for the ego agent to guarantee safety with the desired confidence level by accounting for the prediction sets of other agents' dynamics in the sampled-data CBF conditions. Simulation results are provided to demonstrate the effectiveness of the proposed method.         ",
    "url": "https://arxiv.org/abs/2408.00918",
    "authors": [
      "Junhui Zhang",
      "Sze Zheng Yong",
      "Dimitra Panagou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2408.00920",
    "title": "Towards Certified Unlearning for Deep Neural Networks",
    "abstract": "           In the field of machine unlearning, certified unlearning has been extensively studied in convex machine learning models due to its high efficiency and strong theoretical guarantees. However, its application to deep neural networks (DNNs), known for their highly nonconvex nature, still poses challenges. To bridge the gap between certified unlearning and DNNs, we propose several simple techniques to extend certified unlearning methods to nonconvex objectives. To reduce the time complexity, we develop an efficient computation method by inverse Hessian approximation without compromising certification guarantees. In addition, we extend our discussion of certification to nonconvergence training and sequential unlearning, considering that real-world users can send unlearning requests at different time points. Extensive experiments on three real-world datasets demonstrate the efficacy of our method and the advantages of certified unlearning in DNNs.         ",
    "url": "https://arxiv.org/abs/2408.00920",
    "authors": [
      "Binchi Zhang",
      "Yushun Dong",
      "Tianhao Wang",
      "Jundong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2408.00949",
    "title": "Equivariant neural networks and piecewise linear representation theory",
    "abstract": "           Equivariant neural networks are neural networks with symmetry. Motivated by the theory of group representations, we decompose the layers of an equivariant neural network into simple representations. The nonlinear activation functions lead to interesting nonlinear equivariant maps between simple representations. For example, the rectified linear unit (ReLU) gives rise to piecewise linear maps. We show that these considerations lead to a filtration of equivariant neural networks, generalizing Fourier series. This observation might provide a useful tool for interpreting equivariant neural networks.         ",
    "url": "https://arxiv.org/abs/2408.00949",
    "authors": [
      "Joel Gibson",
      "Daniel Tubbenhauer",
      "Geordie Williamson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Group Theory (math.GR)",
      "Representation Theory (math.RT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2408.00950",
    "title": "PrivateGaze: Preserving User Privacy in Black-box Mobile Gaze Tracking Services",
    "abstract": "           Eye gaze contains rich information about human attention and cognitive processes. This capability makes the underlying technology, known as gaze tracking, a critical enabler for many ubiquitous applications and has triggered the development of easy-to-use gaze estimation services. Indeed, by utilizing the ubiquitous cameras on tablets and smartphones, users can readily access many gaze estimation services. In using these services, users must provide their full-face images to the gaze estimator, which is often a black box. This poses significant privacy threats to the users, especially when a malicious service provider gathers a large collection of face images to classify sensitive user attributes. In this work, we present PrivateGaze, the first approach that can effectively preserve users' privacy in black-box gaze tracking services without compromising gaze estimation performance. Specifically, we proposed a novel framework to train a privacy preserver that converts full-face images into obfuscated counterparts, which are effective for gaze estimation while containing no privacy information. Evaluation on four datasets shows that the obfuscated image can protect users' private information, such as identity and gender, against unauthorized attribute classification. Meanwhile, when used directly by the black-box gaze estimator as inputs, the obfuscated images lead to comparable tracking performance to the conventional, unprotected full-face images.         ",
    "url": "https://arxiv.org/abs/2408.00950",
    "authors": [
      "Lingyu Du",
      "Jinyuan Jia",
      "Xucong Zhang",
      "Guohao Lan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.00981",
    "title": "Cross-domain Named Entity Recognition via Graph Matching",
    "abstract": "           Cross-domain NER is a practical yet challenging problem since the data scarcity in the real-world scenario. A common practice is first to learn a NER model in a rich-resource general domain and then adapt the model to specific domains. Due to the mismatch problem between entity types across domains, the wide knowledge in the general domain can not effectively transfer to the target domain NER model. To this end, we model the label relationship as a probability distribution and construct label graphs in both source and target label spaces. To enhance the contextual representation with label structures, we fuse the label graph into the word embedding output by BERT. By representing label relationships as graphs, we formulate cross-domain NER as a graph matching problem. Furthermore, the proposed method has good applicability with pre-training methods and is potentially capable of other cross-domain prediction tasks. Empirical results on four datasets show that our method outperforms a series of transfer learning, multi-task learning, and few-shot learning methods.         ",
    "url": "https://arxiv.org/abs/2408.00981",
    "authors": [
      "Junhao Zheng",
      "Haibin Chen",
      "Qianli Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2408.00985",
    "title": "Reconstructing Richtmyer-Meshkov instabilities from noisy radiographs using low dimensional features and attention-based neural networks",
    "abstract": "           A trained attention-based transformer network can robustly recover the complex topologies given by the Richtmyer-Meshkoff instability from a sequence of hydrodynamic features derived from radiographic images corrupted with blur, scatter, and noise. This approach is demonstrated on ICF-like double shell hydrodynamic simulations. The key component of this network is a transformer encoder that acts on a sequence of features extracted from noisy radiographs. This encoder includes numerous self-attention layers that act to learn temporal dependencies in the input sequences and increase the expressiveness of the model. This approach is demonstrated to exhibit an excellent ability to accurately recover the Richtmyer-Meshkov instability growth rates, even despite the gas-metal interface being greatly obscured by radiographic noise.         ",
    "url": "https://arxiv.org/abs/2408.00985",
    "authors": [
      "Daniel A. Serino",
      "Marc L. Klasky",
      "Balasubramanya T. Nadiga",
      "Xiaojian Xu",
      "Trevor Wilcox"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2408.00986",
    "title": "A SAT-based approach to rigorous verification of Bayesian networks",
    "abstract": "           Recent advancements in machine learning have accelerated its widespread adoption across various real-world applications. However, in safety-critical domains, the deployment of machine learning models is riddled with challenges due to their complexity, lack of interpretability, and absence of formal guarantees regarding their behavior. In this paper, we introduce a verification framework tailored for Bayesian networks, designed to address these drawbacks. Our framework comprises two key components: (1) a two-step compilation and encoding scheme that translates Bayesian networks into Boolean logic literals, and (2) formal verification queries that leverage these literals to verify various properties encoded as constraints. Specifically, we introduce two verification queries: if-then rules (ITR) and feature monotonicity (FMO). We benchmark the efficiency of our verification scheme and demonstrate its practical utility in real-world scenarios.         ",
    "url": "https://arxiv.org/abs/2408.00986",
    "authors": [
      "Ignacy St\u0119pka",
      "Nicholas Gisolfi",
      "Artur Dubrawski"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2408.00994",
    "title": "ArchCode: Incorporating Software Requirements in Code Generation with Large Language Models",
    "abstract": "           This paper aims to extend the code generation capability of large language models (LLMs) to automatically manage comprehensive software requirements from given textual descriptions. Such requirements include both functional (i.e. achieving expected behavior for inputs) and non-functional (e.g., time/space performance, robustness, maintainability) requirements. However, textual descriptions can either express requirements verbosely or may even omit some of them. We introduce ARCHCODE, a novel framework that leverages in-context learning to organize requirements observed in descriptions and to extrapolate unexpressed requirements from them. ARCHCODE generates requirements from given descriptions, conditioning them to produce code snippets and test cases. Each test case is tailored to one of the requirements, allowing for the ranking of code snippets based on the compliance of their execution results with the requirements. Public benchmarks show that ARCHCODE enhances to satisfy functional requirements, significantly improving Pass@k scores. Furthermore, we introduce HumanEval-NFR, the first evaluation of LLMs' non-functional requirements in code generation, demonstrating ARCHCODE's superiority over baseline methods. The implementation of ARCHCODE and the HumanEval-NFR benchmark are both publicly accessible.         ",
    "url": "https://arxiv.org/abs/2408.00994",
    "authors": [
      "Hojae Han",
      "Jaejin Kim",
      "Jaeseok Yoo",
      "Youngwon Lee",
      "Seung-won Hwang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2408.00999",
    "title": "Community Cellular Networks Coverage Visualizer",
    "abstract": "           The community cellular networks volunteers and researchers currently rarely have an access to information about the networks for each site. This makes it difficult for them to evaluate network performance, identify outrages and downtimes, or even to show the current site locations. In this paper, we propose the Community Cellular Networks Coverage Visualizer, a performance dashboard to help reduce the workload of technicians and gain trust from illustrating the reliability of the networks. The map displays the overall and in-depth performance for each current and future CCNs sites with privacy-focused implementation, while the multi-series line chart emphasizes on providing the capability of network overtime. Not only it will help users identify locations that have stronger and reliable signals nearby, but our applicaiton will also be an essential tool for volunteers and engineers to determine the optimal locations to install a new site and quickly identify possible network failures.         ",
    "url": "https://arxiv.org/abs/2408.00999",
    "authors": [
      "Chanwut Kittivorawong",
      "Sirapop Theeranantachai",
      "Nussara Tieanklin",
      "Esther Han Beol Jang",
      "Kurtis Heimerl"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2408.01016",
    "title": "IBB Traffic Graph Data: Benchmarking and Road Traffic Prediction Model",
    "abstract": "           Road traffic congestion prediction is a crucial component of intelligent transportation systems, since it enables proactive traffic management, enhances suburban experience, reduces environmental impact, and improves overall safety and efficiency. Although there are several public datasets, especially for metropolitan areas, these datasets may not be applicable to practical scenarios due to insufficiency in the scale of data (i.e. number of sensors and road links) and several external factors like different characteristics of the target area such as urban, highways and the data collection location. To address this, this paper introduces a novel IBB Traffic graph dataset as an alternative benchmark dataset to mitigate these limitations and enrich the literature with new geographical characteristics. IBB Traffic graph dataset covers the sensor data collected at 2451 distinct locations. Moreover, we propose a novel Road Traffic Prediction Model that strengthens temporal links through feature engineering, node embedding with GLEE to represent inter-related relationships within the traffic network, and traffic prediction with ExtraTrees. The results indicate that the proposed model consistently outperforms the baseline models, demonstrating an average accuracy improvement of 4%.         ",
    "url": "https://arxiv.org/abs/2408.01016",
    "authors": [
      "Eren Olug",
      "Kiymet Kaya",
      "Resul Tugay",
      "Sule Gunduz Oguducu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2408.01018",
    "title": "GNN-MolKAN: Harnessing the Power of KAN to Advance Molecular Representation Learning with GNNs",
    "abstract": "           Effective molecular representation learning is crucial for molecular property prediction and drug design. However, existing approaches struggle with limitations in insufficient annotations and suboptimal architecture design. For instance, Graph Neural Networks (GNNs) suffer from over-squashing, causing the loss of important structural details in molecules, thus impairing molecular representations. In this work, we propose a new class of GNNs, GNN-MolKAN and its augmented variant, GNN-MolKAN+, that integrate the Kolmogorov-Arnold Networks (KAN) architecture from AI + Science into GNNs to address these challenges. Additionally, we introduce Adaptive FastKAN (AdFastKAN), an advanced KAN that offers increased stability and speed, further enhancing the performance of standard GNNs. Notably, our approach holds three key benefits: 1) Superior Performance: GNN-MolKAN and GNN-MolKAN+ demonstrate superior prediction ability, robust generalization to unseen scaffolds, and versatile transferability across different GNN architectures. 2) Efficiency: These models require less computational time and fewer parameters while matching or surpassing the state-of-the-art (SOTA) self-supervised methods. 3) Few-shot Learning Ability: GNN-MolKAN demonstrates great potential in few-shot learning scenarios, achieving an average improvement of 6.97% across few-shot benchmarks. Overall, we validate our architecture on 6 classification datasets, 6 regression datasets, and 4 few-shot learning datasets, consistently achieving highly competitive results across all of them.         ",
    "url": "https://arxiv.org/abs/2408.01018",
    "authors": [
      "Ruifeng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.01037",
    "title": "MambaST: A Plug-and-Play Cross-Spectral Spatial-Temporal Fuser for Efficient Pedestrian Detection",
    "abstract": "           This paper proposes MambaST, a plug-and-play cross-spectral spatial-temporal fusion pipeline for efficient pedestrian detection. Several challenges exist for pedestrian detection in autonomous driving applications. First, it is difficult to perform accurate detection using RGB cameras under dark or low-light conditions. Cross-spectral systems must be developed to integrate complementary information from multiple sensor modalities, such as thermal and visible cameras, to improve the robustness of the detections. Second, pedestrian detection models are latency-sensitive. Efficient and easy-to-scale detection models with fewer parameters are highly desirable for real-time applications such as autonomous driving. Third, pedestrian video data provides spatial-temporal correlations of pedestrian movement. It is beneficial to incorporate temporal as well as spatial information to enhance pedestrian detection. This work leverages recent advances in the state space model (Mamba) and proposes a novel Multi-head Hierarchical Patching and Aggregation (MHHPA) structure to extract both fine-grained and coarse-grained information from both RGB and thermal imagery. Experimental results show that the proposed MHHPA is an effective and efficient alternative to a Transformer model for cross-spectral pedestrian detection. Our proposed model also achieves superior performance on small-scale pedestrian detection. The code is available at this https URL}{this https URL.         ",
    "url": "https://arxiv.org/abs/2408.01037",
    "authors": [
      "Xiangbo Gao",
      "Asiegbu Miracle Kanu-Asiegbu",
      "Xiaoxiao Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.01038",
    "title": "UNER: A Unified Prediction Head for Named Entity Recognition in Visually-rich Documents",
    "abstract": "           The recognition of named entities in visually-rich documents (VrD-NER) plays a critical role in various real-world scenarios and applications. However, the research in VrD-NER faces three major challenges: complex document layouts, incorrect reading orders, and unsuitable task formulations. To address these challenges, we propose a query-aware entity extraction head, namely UNER, to collaborate with existing multi-modal document transformers to develop more robust VrD-NER models. The UNER head considers the VrD-NER task as a combination of sequence labeling and reading order prediction, effectively addressing the issues of discontinuous entities in documents. Experimental evaluations on diverse datasets demonstrate the effectiveness of UNER in improving entity extraction performance. Moreover, the UNER head enables a supervised pre-training stage on various VrD-NER datasets to enhance the document transformer backbones and exhibits substantial knowledge transfer from the pre-training stage to the fine-tuning stage. By incorporating universal layout understanding, a pre-trained UNER-based model demonstrates significant advantages in few-shot and cross-linguistic scenarios and exhibits zero-shot entity extraction abilities.         ",
    "url": "https://arxiv.org/abs/2408.01038",
    "authors": [
      "Yi Tu",
      "Chong Zhang",
      "Ya Guo",
      "Huan Chen",
      "Jinyang Tang",
      "Huijia Zhu",
      "Qi Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2408.01044",
    "title": "Boosting Gaze Object Prediction via Pixel-level Supervision from Vision Foundation Model",
    "abstract": "           Gaze object prediction (GOP) aims to predict the category and location of the object that a human is looking at. Previous methods utilized box-level supervision to identify the object that a person is looking at, but struggled with semantic ambiguity, ie, a single box may contain several items since objects are close together. The Vision foundation model (VFM) has improved in object segmentation using box prompts, which can reduce confusion by more precisely locating objects, offering advantages for fine-grained prediction of gaze objects. This paper presents a more challenging gaze object segmentation (GOS) task, which involves inferring the pixel-level mask corresponding to the object captured by human gaze behavior. In particular, we propose that the pixel-level supervision provided by VFM can be integrated into gaze object prediction to mitigate semantic ambiguity. This leads to our gaze object detection and segmentation framework that enables accurate pixel-level predictions. Different from previous methods that require additional head input or ignore head features, we propose to automatically obtain head features from scene features to ensure the model's inference efficiency and flexibility in the real world. Moreover, rather than directly fuse features to predict gaze heatmap as in existing methods, which may overlook spatial location and subtle details of the object, we develop a space-to-object gaze regression method to facilitate human-object gaze interaction. Specifically, it first constructs an initial human-object spatial connection, then refines this connection by interacting with semantically clear features in the segmentation branch, ultimately predicting a gaze heatmap for precise localization. Extensive experiments on GOO-Synth and GOO-Real datasets demonstrate the effectiveness of our method.         ",
    "url": "https://arxiv.org/abs/2408.01044",
    "authors": [
      "Yang Jin",
      "Lei Zhang",
      "Shi Yan",
      "Bin Fan",
      "Binglu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.01085",
    "title": "Effect of Fog Particle Size Distribution on 3D Object Detection Under Adverse Weather Conditions",
    "abstract": "           LiDAR-based sensors employing optical spectrum signals play a vital role in providing significant information about the target objects in autonomous driving vehicle systems. However, the presence of fog in the atmosphere severely degrades the overall system's performance. This manuscript analyzes the role of fog particle size distributions in 3D object detection under adverse weather conditions. We utilise Mie theory and meteorological optical range (MOR) to calculate the attenuation and backscattering coefficient values for point cloud generation and analyze the overall system's accuracy in Car, Cyclist, and Pedestrian case scenarios under easy, medium and hard detection difficulties. Gamma and Junge (Power-Law) distributions are employed to mathematically model the fog particle size distribution under strong and moderate advection fog environments. Subsequently, we modified the KITTI dataset based on the backscattering coefficient values and trained it on the PV-RCNN++ deep neural network model for Car, Cyclist, and Pedestrian cases under different detection difficulties. The result analysis shows a significant variation in the system's accuracy concerning the changes in target object dimensionality, the nature of the fog environment and increasing detection difficulties, with the Car exhibiting the highest accuracy of around 99% and the Pedestrian showing the lowest accuracy of around 73%.         ",
    "url": "https://arxiv.org/abs/2408.01085",
    "authors": [
      "Ajinkya Shinde",
      "Gaurav Sharma",
      "Manisha Pattanaik",
      "Sri Niwas Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.01088",
    "title": "Bridging Information Gaps in Dialogues With Grounded Exchanges Using Knowledge Graphs",
    "abstract": "           Knowledge models are fundamental to dialogue systems for enabling conversational interactions, which require handling domain-specific knowledge. Ensuring effective communication in information-providing conversations entails aligning user understanding with the knowledge available to the system. However, dialogue systems often face challenges arising from semantic inconsistencies in how information is expressed in natural language compared to how it is represented within the system's internal knowledge. To address this problem, we study the potential of large language models for conversational grounding, a mechanism to bridge information gaps by establishing shared knowledge between dialogue participants. Our approach involves annotating human conversations across five knowledge domains to create a new dialogue corpus called BridgeKG. Through a series of experiments on this dataset, we empirically evaluate the capabilities of large language models in classifying grounding acts and identifying grounded information items within a knowledge graph structure. Our findings offer insights into how these models use in-context learning for conversational grounding tasks and common prediction errors, which we illustrate with examples from challenging dialogues. We discuss how the models handle knowledge graphs as a semantic layer between unstructured dialogue utterances and structured information items.         ",
    "url": "https://arxiv.org/abs/2408.01088",
    "authors": [
      "Phillip Schneider",
      "Nektarios Machner",
      "Kristiina Jokinen",
      "Florian Matthes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2408.01094",
    "title": "An Encoding--Searching Separation Perspective on Bi-Encoder Neural Search",
    "abstract": "           This paper reviews, analyzes, and proposes a new perspective on the bi-encoder architecture for neural search. While the bi-encoder architecture is widely used due to its simplicity and scalability at test time, it has some notable issues such as low performance on seen datasets and weak zero-shot performance on new datasets. In this paper, we analyze these issues and summarize two main critiques: the encoding information bottleneck problem and limitations of the basic assumption of embedding search. We then construct a thought experiment to logically analyze the encoding and searching operations and challenge the basic assumption of embedding search. Building on these observations, we propose a new perspective on the bi-encoder architecture called the \\textit{encoding--searching separation} perspective, which conceptually and practically separates the encoding and searching operations. This new perspective is applied to explain the root cause of the identified issues and discuss ways to mitigate the problems. Finally, we discuss the implications of the ideas underlying the new perspective, the design surface that it exposes and the potential research directions arising from it.         ",
    "url": "https://arxiv.org/abs/2408.01094",
    "authors": [
      "Hung-Nghiep Tran",
      "Akiko Aizawa",
      "Atsuhiro Takasu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2408.01118",
    "title": "IAI Group at CheckThat! 2024: Transformer Models and Data Augmentation for Checkworthy Claim Detection",
    "abstract": "           This paper describes IAI group's participation for automated check-worthiness estimation for claims, within the framework of the 2024 CheckThat! Lab \"Task 1: Check-Worthiness Estimation\". The task involves the automated detection of check-worthy claims in English, Dutch, and Arabic political debates and Twitter data. We utilized various pre-trained generative decoder and encoder transformer models, employing methods such as few-shot chain-of-thought reasoning, fine-tuning, data augmentation, and transfer learning from one language to another. Despite variable success in terms of performance, our models achieved notable placements on the organizer's leaderboard: ninth-best in English, third-best in Dutch, and the top placement in Arabic, utilizing multilingual datasets for enhancing the generalizability of check-worthiness detection. Despite a significant drop in performance on the unlabeled test dataset compared to the development test dataset, our findings contribute to the ongoing efforts in claim detection research, highlighting the challenges and potential of language-specific adaptations in claim verification systems.         ",
    "url": "https://arxiv.org/abs/2408.01118",
    "authors": [
      "Peter R\u00f8ysland Aarnes",
      "Vinay Setty",
      "Petra Galu\u0161\u010d\u00e1kov\u00e1"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2408.01137",
    "title": "PGNeXt: High-Resolution Salient Object Detection via Pyramid Grafting Network",
    "abstract": "           We present an advanced study on more challenging high-resolution salient object detection (HRSOD) from both dataset and network framework perspectives. To compensate for the lack of HRSOD dataset, we thoughtfully collect a large-scale high resolution salient object detection dataset, called UHRSD, containing 5,920 images from real-world complex scenarios at 4K-8K resolutions. All the images are finely annotated in pixel-level, far exceeding previous low-resolution SOD datasets. Aiming at overcoming the contradiction between the sampling depth and the receptive field size in the past methods, we propose a novel one-stage framework for HR-SOD task using pyramid grafting mechanism. In general, transformer-based and CNN-based backbones are adopted to extract features from different resolution images independently and then these features are grafted from transformer branch to CNN branch. An attention-based Cross-Model Grafting Module (CMGM) is proposed to enable CNN branch to combine broken detailed information more holistically, guided by different source feature during decoding process. Moreover, we design an Attention Guided Loss (AGL) to explicitly supervise the attention matrix generated by CMGM to help the network better interact with the attention from different branches. Comprehensive experiments on UHRSD and widely-used SOD datasets demonstrate that our method can simultaneously locate salient object and preserve rich details, outperforming state-of-the-art methods. To verify the generalization ability of the proposed framework, we apply it to the camouflaged object detection (COD) task. Notably, our method performs superior to most state-of-the-art COD methods without bells and whistles.         ",
    "url": "https://arxiv.org/abs/2408.01137",
    "authors": [
      "Changqun Xia",
      "Chenxi Xie",
      "Zhentao He",
      "Tianshu Yu",
      "Jia Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.01139",
    "title": "Interpreting Global Perturbation Robustness of Image Models using Axiomatic Spectral Importance Decomposition",
    "abstract": "           Perturbation robustness evaluates the vulnerabilities of models, arising from a variety of perturbations, such as data corruptions and adversarial attacks. Understanding the mechanisms of perturbation robustness is critical for global interpretability. We present a model-agnostic, global mechanistic interpretability method to interpret the perturbation robustness of image models. This research is motivated by two key aspects. First, previous global interpretability works, in tandem with robustness benchmarks, e.g. mean corruption error (mCE), are not designed to directly interpret the mechanisms of perturbation robustness within image models. Second, we notice that the spectral signal-to-noise ratios (SNR) of perturbed natural images exponentially decay over the frequency. This power-law-like decay implies that: Low-frequency signals are generally more robust than high-frequency signals -- yet high classification accuracy can not be achieved by low-frequency signals alone. By applying Shapley value theory, our method axiomatically quantifies the predictive powers of robust features and non-robust features within an information theory framework. Our method, dubbed as \\textbf{I-ASIDE} (\\textbf{I}mage \\textbf{A}xiomatic \\textbf{S}pectral \\textbf{I}mportance \\textbf{D}ecomposition \\textbf{E}xplanation), provides a unique insight into model robustness mechanisms. We conduct extensive experiments over a variety of vision models pre-trained on ImageNet to show that \\textbf{I-ASIDE} can not only \\textbf{measure} the perturbation robustness but also \\textbf{provide interpretations} of its mechanisms.         ",
    "url": "https://arxiv.org/abs/2408.01139",
    "authors": [
      "R\u00f3is\u00edn Luo",
      "James McDermott",
      "Colm O'Riordan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.01144",
    "title": "Enhanced Prediction of Ventilator-Associated Pneumonia in Patients with Traumatic Brain Injury Using Advanced Machine Learning Techniques",
    "abstract": "           Background: Ventilator-associated pneumonia (VAP) in traumatic brain injury (TBI) patients poses a significant mortality risk and imposes a considerable financial burden on patients and healthcare systems. Timely detection and prognostication of VAP in TBI patients are crucial to improve patient outcomes and alleviate the strain on healthcare resources. Methods: We implemented six machine learning models using the MIMIC-III database. Our methodology included preprocessing steps, such as feature selection with CatBoost and expert opinion, addressing class imbalance with the Synthetic Minority Oversampling Technique (SMOTE), and rigorous model tuning through 5-fold cross-validation to optimize hyperparameters. Key models evaluated included SVM, Logistic Regression, Random Forest, XGBoost, ANN, and AdaBoost. Additionally, we conducted SHAP analysis to determine feature importance and performed an ablation study to assess feature impacts on model performance. Results: XGBoost outperformed the baseline models and the best existing literature. We used metrics, including AUC, Accuracy, Specificity, Sensitivity, F1 Score, PPV, and NPV. XGBoost demonstrated the highest performance with an AUC of 0.940 and an Accuracy of 0.875, which are 23.4% and 23.5% higher than the best results in the existing literature, with an AUC of 0.706 and an Accuracy of 0.640, respectively. This enhanced performance underscores the models' effectiveness in clinical settings. Conclusions: This study enhances the predictive modeling of VAP in TBI patients, improving early detection and intervention potential. Refined feature selection and advanced ensemble techniques significantly boosted model accuracy and reliability, offering promising directions for future clinical applications and medical diagnostics research.         ",
    "url": "https://arxiv.org/abs/2408.01144",
    "authors": [
      "Negin Ashrafi",
      "Armin Abdollahi",
      "Maryam Pishgar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.01154",
    "title": "DERA: Dense Entity Retrieval for Entity Alignment in Knowledge Graphs",
    "abstract": "           Entity Alignment (EA) aims to match equivalent entities in different Knowledge Graphs (KGs), which is essential for knowledge fusion and integration. Recently, embedding-based EA has attracted significant attention and many approaches have been proposed. Early approaches primarily focus on learning entity embeddings from the structural features of KGs, defined by relation triples. Later methods incorporated entities' names and attributes as auxiliary information to enhance embeddings for EA. However, these approaches often used different techniques to encode structural and attribute information, limiting their interaction and mutual enhancement. In this work, we propose a dense entity retrieval framework for EA, leveraging language models to uniformly encode various features of entities and facilitate nearest entity search across KGs. Alignment candidates are first generated through entity retrieval, which are subsequently reranked to determine the final alignments. We conduct comprehensive experiments on both cross-lingual and monolingual EA datasets, demonstrating that our approach achieves state-of-the-art performance compared to existing EA methods.         ",
    "url": "https://arxiv.org/abs/2408.01154",
    "authors": [
      "Zhichun Wang",
      "Xuan Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.01159",
    "title": "Robust Curve Detection in Volumetric Medical Imaging via Attraction Field",
    "abstract": "           Understanding body part geometry is crucial for precise medical diagnostics. Curves effectively describe anatomical structures and are widely used in medical imaging applications related to cardiovascular, respiratory, and skeletal diseases. Traditional curve detection methods are often task-specific, relying heavily on domain-specific features, limiting their broader applicability. This paper introduces a novel approach for detecting non-branching curves, which does not require prior knowledge of the object's orientation, shape, or position. Our method uses neural networks to predict (1) an attraction field, which offers subpixel accuracy, and (2) a closeness map, which limits the region of interest and essentially eliminates outliers far from the desired curve. We tested our curve detector on several clinically relevant tasks with diverse morphologies and achieved impressive subpixel-level accuracy results that surpass existing methods, highlighting its versatility and robustness. Additionally, to support further advancements in this field, we provide our private annotations of aortic centerlines and masks, which can serve as a benchmark for future research. The dataset can be found at this https URL.         ",
    "url": "https://arxiv.org/abs/2408.01159",
    "authors": [
      "Farukh Yaushev",
      "Daria Nogina",
      "Valentin Samokhin",
      "Mariya Dugova",
      "Ekaterina Petrash",
      "Dmitry Sevryukov",
      "Mikhail Belyaev",
      "Maxim Pisov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.01166",
    "title": "Continuous-Time Neural Networks Can Stably Memorize Random Spike Trains",
    "abstract": "           The paper explores the capability of continuous-time recurrent neural networks to store and recall precisely timed spike patterns. We show (by numerical experiments) that this is indeed possible: within some range of parameters, any random score of spike trains (for all neurons in the network) can be robustly memorized and autonomously reproduced with stable accurate relative timing of all spikes, with probability close to one. We also demonstrate associative recall under noisy conditions. In these experiments, the required synaptic weights are computed offline, to satisfy a template that encourages temporal stability.         ",
    "url": "https://arxiv.org/abs/2408.01166",
    "authors": [
      "Hugo Aguettaz",
      "Hans-Andrea Loeliger"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2408.01178",
    "title": "EmoBack: Backdoor Attacks Against Speaker Identification Using Emotional Prosody",
    "abstract": "           Speaker identification (SI) determines a speaker's identity based on their spoken utterances. Previous work indicates that SI deep neural networks (DNNs) are vulnerable to backdoor attacks. Backdoor attacks involve embedding hidden triggers in DNNs' training data, causing the DNN to produce incorrect output when these triggers are present during inference. This is the first work that explores SI DNNs' vulnerability to backdoor attacks using speakers' emotional prosody, resulting in dynamic, inconspicuous triggers. %Such an attack could have real-world implications in forensics, authentication, and surveillance. We conducted a parameter study using three different datasets and DNN architectures to determine the impact of emotions as backdoor triggers on the accuracy of SI systems. Additionally, we have explored the robustness of our attacks by applying defenses like pruning, STRIP-ViTA, and three popular preprocessing techniques: quantization, median filtering, and squeezing. Our findings show that the aforementioned models are prone to our attack, indicating that emotional triggers (sad and neutral prosody) can be effectively used to compromise the integrity of SI systems. However, the results of our pruning experiments suggest potential solutions for reinforcing the models against our attacks, decreasing the attack success rate up to 40%.         ",
    "url": "https://arxiv.org/abs/2408.01178",
    "authors": [
      "Coen Schoof",
      "Stefanos Koffas",
      "Mauro Conti",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2408.01215",
    "title": "ZNorm: Z-Score Gradient Normalization for Accelerating Neural Network Training",
    "abstract": "           The rapid advancements in deep learning necessitate efficient training methods for deep neural networks (DNNs). As models grow in complexity, vanishing and exploding gradients impede convergence and performance. We propose Z-Score Normalization for Gradient Descent (ZNorm), an innovative technique that adjusts only the gradients to enhance training efficiency and improve model performance. ZNorm normalizes the overall gradients, providing consistent gradient scaling across layers, thereby reducing the risks of vanishing and exploding gradients. Our extensive experiments on CIFAR-10 and medical datasets demonstrate that ZNorm not only accelerates convergence but also enhances performance metrics. ZNorm consistently outperforms existing methods, achieving superior results using the same computational settings. In medical imaging applications, ZNorm improves tumor prediction and segmentation performances, underscoring its practical utility. These findings highlight ZNorm's potential as a robust and versatile tool for improving the efficiency and effectiveness of deep neural network training across a wide range of architectures and applications.         ",
    "url": "https://arxiv.org/abs/2408.01215",
    "authors": [
      "Juyoung Yun",
      "Hoyoung Kim",
      "Suin Cho",
      "Hangil Kang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.01221",
    "title": "Rubric-based Learner Modelling via Noisy Gates Bayesian Networks for Computational Thinking Skills Assessment",
    "abstract": "           In modern and personalised education, there is a growing interest in developing learners' competencies and accurately assessing them. In a previous work, we proposed a procedure for deriving a learner model for automatic skill assessment from a task-specific competence rubric, thus simplifying the implementation of automated assessment tools. The previous approach, however, suffered two main limitations: (i) the ordering between competencies defined by the assessment rubric was only indirectly modelled; (ii) supplementary skills, not under assessment but necessary for accomplishing the task, were not included in the model. In this work, we address issue (i) by introducing dummy observed nodes, strictly enforcing the skills ordering without changing the network's structure. In contrast, for point (ii), we design a network with two layers of gates, one performing disjunctive operations by noisy-OR gates and the other conjunctive operations through logical ANDs. Such changes improve the model outcomes' coherence and the modelling tool's flexibility without compromising the model's compact parametrisation, interpretability and simple experts' elicitation. We used this approach to develop a learner model for Computational Thinking (CT) skills assessment. The CT-cube skills assessment framework and the Cross Array Task (CAT) are used to exemplify it and demonstrate its feasibility.         ",
    "url": "https://arxiv.org/abs/2408.01221",
    "authors": [
      "Giorgia Adorni",
      "Francesca Mangili",
      "Alberto Piatti",
      "Claudio Bonesana",
      "Alessandro Antonucci"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2408.01225",
    "title": "Reality Fusion: Robust Real-time Immersive Mobile Robot Teleoperation with Volumetric Visual Data Fusion",
    "abstract": "           We introduce Reality Fusion, a novel robot teleoperation system that localizes, streams, projects, and merges a typical onboard depth sensor with a photorealistic, high resolution, high framerate, and wide field of view (FoV) rendering of the complex remote environment represented as 3D Gaussian splats (3DGS). Our framework enables robust egocentric and exocentric robot teleoperation in immersive VR, with the 3DGS effectively extending spatial information of a depth sensor with limited FoV and balancing the trade-off between data streaming costs and data visual quality. We evaluated our framework through a user study with 24 participants, which revealed that Reality Fusion leads to significantly better user performance, situation awareness, and user preferences. To support further research and development, we provide an open-source implementation with an easy-to-replicate custom-made telepresence robot, a high-performance virtual reality 3DGS renderer, and an immersive robot control package. (Source code: this https URL)         ",
    "url": "https://arxiv.org/abs/2408.01225",
    "authors": [
      "Ke Li",
      "Reinhard Bacher",
      "Susanne Schmidt",
      "Wim Leemans",
      "Frank Steinicke"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2408.01226",
    "title": "Regular Grammars for Graph Sets of Tree-Width $\\leq2$",
    "abstract": "           Regular and context-free languages form a central pillar of formal language theory. This is because a variety of formalisms are known that define these classes of languages. For example, we have that finite automata, monoids, algebraic recognizability, regular expressions, regular grammars, monadic-second order logic, etc., can be used to represent regular word languages. However, the situation is less clear for formal languages over graphs, and open problems persist. This is because generalizing notions from words to graphs has been more successful for some of the cited formalisms than for the other ones. Bruno Courcelle has introduced hyper-edge replacement (\\hr) algebras for generalizing the notion of context-free languages from words to graphs. At the same time, \\hr-algebras support the generalization of algebraic recognizability from words to graphs, a notion that has been proven to be equivalent to definability in (counting) monadic-second order logic (\\cmso) over graphs of bounded tree-width. In this paper, we deal with generalizing regular word grammars to graphs. We propose regular grammars for (unordered and unranked) trees, series-parallel graphs, and graphs of tree-width $\\le 2$, where the qualifier regular is justified because these grammars define exactly the recognizable resp. \\cmso-definable subsets of the respective graph classes.         ",
    "url": "https://arxiv.org/abs/2408.01226",
    "authors": [
      "Marius Bozga",
      "Radu Iosif",
      "Florian Zuleger"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2408.01228",
    "title": "The Phantom Menace: Unmasking Privacy Leakages in Vision-Language Models",
    "abstract": "           Vision-Language Models (VLMs) combine visual and textual understanding, rendering them well-suited for diverse tasks like generating image captions and answering visual questions across various domains. However, these capabilities are built upon training on large amount of uncurated data crawled from the web. The latter may include sensitive information that VLMs could memorize and leak, raising significant privacy concerns. In this paper, we assess whether these vulnerabilities exist, focusing on identity leakage. Our study leads to three key findings: (i) VLMs leak identity information, even when the vision-language alignment and the fine-tuning use anonymized data; (ii) context has little influence on identity leakage; (iii) simple, widely used anonymization techniques, like blurring, are not sufficient to address the problem. These findings underscore the urgent need for robust privacy protection strategies when deploying VLMs. Ethical awareness and responsible development practices are essential to mitigate these risks.         ",
    "url": "https://arxiv.org/abs/2408.01228",
    "authors": [
      "Simone Caldarella",
      "Massimiliano Mancini",
      "Elisa Ricci",
      "Rahaf Aljundi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.01233",
    "title": "CLIP4Sketch: Enhancing Sketch to Mugshot Matching through Dataset Augmentation using Diffusion Models",
    "abstract": "           Forensic sketch-to-mugshot matching is a challenging task in face recognition, primarily hindered by the scarcity of annotated forensic sketches and the modality gap between sketches and photographs. To address this, we propose CLIP4Sketch, a novel approach that leverages diffusion models to generate a large and diverse set of sketch images, which helps in enhancing the performance of face recognition systems in sketch-to-mugshot matching. Our method utilizes Denoising Diffusion Probabilistic Models (DDPMs) to generate sketches with explicit control over identity and style. We combine CLIP and Adaface embeddings of a reference mugshot, along with textual descriptions of style, as the conditions to the diffusion model. We demonstrate the efficacy of our approach by generating a comprehensive dataset of sketches corresponding to mugshots and training a face recognition model on our synthetic data. Our results show significant improvements in sketch-to-mugshot matching accuracy over training on an existing, limited amount of real face sketch data, validating the potential of diffusion models in enhancing the performance of face recognition systems across modalities. We also compare our dataset with datasets generated using GAN-based methods to show its superiority.         ",
    "url": "https://arxiv.org/abs/2408.01233",
    "authors": [
      "Kushal Kumar Jain",
      "Steve Grosz",
      "Anoop M. Namboodiri",
      "Anil K. Jain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.01239",
    "title": "Tailoring Graph Neural Network-based Flow-guided Localization to Individual Bloodstreams and Activities",
    "abstract": "           Flow-guided localization using in-body nanodevices in the bloodstream is expected to be beneficial for early disease detection, continuous monitoring of biological conditions, and targeted treatment. The nanodevices face size and power constraints that produce erroneous raw data for localization purposes. On-body anchors receive this data, and use it to derive the locations of diagnostic events of interest. Different Machine Learning (ML) approaches have been recently proposed for this task, yet they are currently restricted to a reference bloodstream of a resting patient. As such, they are unable to deal with the physical diversity of patients' bloodstreams and cannot provide continuous monitoring due to changes in individual patient's activities. Toward addressing these issues for the current State-of-the-Art (SotA) flow-guided localization approach based on Graph Neural Networks (GNNs), we propose a pipeline for GNN adaptation based on individual physiological indicators including height, weight, and heart rate. Our results indicate that the proposed adaptions are beneficial in reconciling the individual differences between bloodstreams and activities.         ",
    "url": "https://arxiv.org/abs/2408.01239",
    "authors": [
      "Pablo Galv\u00e1n",
      "Filip Lemic",
      "Gerard Calvo Bartra",
      "Sergi Abadal",
      "Xavier Costa P\u00e9rez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2408.01254",
    "title": "TrIM: Triangular Input Movement Systolic Array for Convolutional Neural Networks -- Part I: Dataflow and Analytical Modelling",
    "abstract": "           In order to follow the ever-growing computational complexity and data intensity of state-of-the-art AI models, new computing paradigms are being proposed. These paradigms aim at achieving high energy efficiency, by mitigating the Von Neumann bottleneck that relates to the energy cost of moving data between the processing cores and the memory. Convolutional Neural Networks (CNNs) are particularly susceptible to this bottleneck, given the massive data they have to manage. Systolic Arrays (SAs) are promising architectures to mitigate the data transmission cost, thanks to high data utilization carried out by an array of Processing Elements (PEs). These PEs continuously exchange and process data locally based on specific dataflows (like weight stationary and row stationary), in turn reducing the number of memory accesses to the main memory. The hardware specialization of SAs can meet different workloads, ranging from matrix multiplications to multi-dimensional convolutions. In this paper, we propose TrIM: a novel dataflow for SAs based on a Triangular Input Movement and compatible with CNN computing. When compared to state-of-the-art SA dataflows, like weight stationary and row stationary, the high data utilization offered by TrIM guarantees ~10x less memory access. Furthermore, considering that PEs continuously overlap multiplications and accumulations, TrIM achieves high throughput (up to 81.8% higher than row stationary), other than requiring a limited number of registers (up to 15.6x fewer registers than row stationary).         ",
    "url": "https://arxiv.org/abs/2408.01254",
    "authors": [
      "Cristian Sestito",
      "Shady Agwa",
      "Themis Prodromakis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2408.01257",
    "title": "Detection and Characterization of Coordinated Online Behavior: A Survey",
    "abstract": "           Coordination is a fundamental aspect of life. The advent of social media has made it integral also to online human interactions, such as those that characterize thriving online communities and social movements. At the same time, coordination is also core to effective disinformation, manipulation, and hate campaigns. This survey collects, categorizes, and critically discusses the body of work produced as a result of the growing interest on coordinated online behavior. We reconcile industry and academic definitions, propose a comprehensive framework to study coordinated online behavior, and review and critically discuss the existing detection and characterization methods. Our analysis identifies open challenges and promising directions of research, serving as a guide for scholars, practitioners, and policymakers in understanding and addressing the complexities inherent to online coordination.         ",
    "url": "https://arxiv.org/abs/2408.01257",
    "authors": [
      "Lorenzo Mannocci",
      "Michele Mazza",
      "Anna Monreale",
      "Maurizio Tesconi",
      "Stefano Cresci"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.01271",
    "title": "HRFT: Mining High-Frequency Risk Factor Collections End-to-End via Transformer",
    "abstract": "           In quantitative trading, it is common to find patterns in short term volatile trends of the market. These patterns are known as High Frequency (HF) risk factors, serving as key indicators of future stock price volatility. Traditionally, these risk factors were generated by financial models relying heavily on domain-specific knowledge manually added rather than extensive market data. Inspired by symbolic regression (SR), which infers mathematical laws from data, we treat the extraction of formulaic risk factors from high-frequency trading (HFT) market data as an SR task. In this paper, we challenge the manual construction of risk factors and propose an end-to-end methodology, Intraday Risk Factor Transformer (IRFT), to directly predict complete formulaic factors, including constants. We use a hybrid symbolic-numeric vocabulary where symbolic tokens represent operators/stock features and numeric tokens represent constants. We train a Transformer model on the HFT dataset to generate complete formulaic HF risk factors without relying on a predefined skeleton of operators. It determines the general shape of the stock volatility law up to a choice of constants. We refine the predicted constants (a, b) using the Broyden Fletcher Goldfarb Shanno algorithm (BFGS) to mitigate non-linear issues. Compared to the 10 approaches in SRBench, a living benchmark for SR, IRFT gains a 30% excess investment return on the HS300 and SP500 datasets, with inference times orders of magnitude faster than theirs in HF risk factor mining tasks.         ",
    "url": "https://arxiv.org/abs/2408.01271",
    "authors": [
      "Wenyan Xu",
      "Rundong Wang",
      "Chen Li",
      "Yonghong Hu",
      "Zhonghua Lu"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2408.01272",
    "title": "Does This Have a Particular Meaning? Interactive Pattern Explanation for Network Visualizations",
    "abstract": "           This paper presents an interactive technique to explain visual patterns in network visualizations to analysts who do not understand these visualizations and who are learning to read them. Learning a visualization requires mastering its visual grammar and decoding information presented through visual marks, graphical encodings, and spatial configurations. To help people learn network visualization designs and extract meaningful information, we introduce the concept of interactive pattern explanation that allows viewers to select an arbitrary area in a visualization, then automatically mines the underlying data patterns, and explains both visual and data patterns present in the viewer's selection. In a qualitative and a quantitative user study with a total of 32 participants, we compare interactive pattern explanations to textual-only and visual-only (cheatsheets) explanations. Our results show that interactive explanations increase learning of i) unfamiliar visualizations, ii) patterns in network science, and iii) the respective network terminology.         ",
    "url": "https://arxiv.org/abs/2408.01272",
    "authors": [
      "Xinhuan Shu",
      "Alexis Pister",
      "Junxiu Tang",
      "Fanny Chevalier",
      "Benjamin Bach"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2408.01273",
    "title": "Certified Robust Invariant Polytope Training in Neural Controlled ODEs",
    "abstract": "           We consider a nonlinear control system modeled as an ordinary differential equation subject to disturbance, with a state feedback controller parameterized as a feedforward neural network. We propose a framework for training controllers with certified robust forward invariant polytopes, where any trajectory initialized inside the polytope remains within the polytope, regardless of the disturbance. First, we parameterize a family of lifted control systems in a higher dimensional space, where the original neural controlled system evolves on an invariant subspace of each lifted system. We use interval analysis and neural network verifiers to further construct a family of lifted embedding systems, carefully capturing the knowledge of this invariant subspace. If the vector field of any lifted embedding system satisfies a sign constraint at a single point, then a certain convex polytope of the original system is robustly forward invariant. Treating the neural network controller and the lifted system parameters as variables, we propose an algorithm to train controllers with certified forward invariant polytopes in the closed-loop control system. Through two examples, we demonstrate how the simplicity of the sign constraint allows our approach to scale with system dimension to over $50$ states, and outperform state-of-the-art Lyapunov-based sampling approaches in runtime.         ",
    "url": "https://arxiv.org/abs/2408.01273",
    "authors": [
      "Akash Harapanahalli",
      "Samuel Coogan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2408.01284",
    "title": "Out-Of-Distribution Detection for Audio-visual Generalized Zero-Shot Learning: A General Framework",
    "abstract": "           Generalized Zero-Shot Learning (GZSL) is a challenging task requiring accurate classification of both seen and unseen classes. Within this domain, Audio-visual GZSL emerges as an extremely exciting yet difficult task, given the inclusion of both visual and acoustic features as multi-modal inputs. Existing efforts in this field mostly utilize either embedding-based or generative-based methods. However, generative training is difficult and unstable, while embedding-based methods often encounter domain shift problem. Thus, we find it promising to integrate both methods into a unified framework to leverage their advantages while mitigating their respective disadvantages. Our study introduces a general framework employing out-of-distribution (OOD) detection, aiming to harness the strengths of both approaches. We first employ generative adversarial networks to synthesize unseen features, enabling the training of an OOD detector alongside classifiers for seen and unseen classes. This detector determines whether a test feature belongs to seen or unseen classes, followed by classification utilizing separate classifiers for each feature type. We test our framework on three popular audio-visual datasets and observe a significant improvement comparing to existing state-of-the-art works. Codes can be found in this https URL.         ",
    "url": "https://arxiv.org/abs/2408.01284",
    "authors": [
      "Liuyuan Wen"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2408.01286",
    "title": "Improving Energy Efficiency in Federated Learning Through the Optimization of Communication Resources Scheduling of Wireless IoT Networks",
    "abstract": "           Federated Learning (FL) allows devices to train a global machine learning model without sharing data. In the context of wireless networks, the inherently unreliable nature of the transmission channel introduces delays and errors that compromise the regularity of updating the global model. Furthermore, limited resources and energy consumption of devices are factors that affect FL performance. Therefore, this work proposes a new FL algorithm called FL-E2WS that considers both the requirements of federated training and a wireless network within the scope of the Internet of Things. To reduce the energy cost of devices, FL-E2WS schedules communication resources to allocate the ideal bandwidth and power for the transmission of models under certain device selection and uplink resource block allocation, meeting delay requirements, power consumption, and packet error rate. The simulation results demonstrate that FL-E2WS reduces energy consumption by up to 70.12% and enhances the accuracy of the global model by up to 10.21% compared to the FL algorithms that lacks transmission channel knowledge. Additionally, when compared to FL versions that scale communication resources, FL-E2WS achieves up to a 38.61% reduction in energy consumption and improves the accuracy of the global model by up to 1.61%.         ",
    "url": "https://arxiv.org/abs/2408.01286",
    "authors": [
      "Renan R. de Oliveira",
      "Kleber V. Cardoso",
      "Antonio Oliveira-Jr"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2408.01293",
    "title": "Underwater Object Detection Enhancement via Channel Stabilization",
    "abstract": "           The complex marine environment exacerbates the challenges of object detection manifold. Marine trash endangers the aquatic ecosystem, presenting a persistent challenge. Accurate detection of marine deposits is crucial for mitigating this harm. Our work addresses underwater object detection by enhancing image quality and evaluating detection methods. We use Detectron2's backbone with various base models and configurations for this task. We propose a novel channel stabilization technique alongside a simplified image enhancement model to reduce haze and color cast in training images, improving multi-scale object detection. Following image processing, we test different Detectron2 backbones for optimal detection accuracy. Additionally, we apply a sharpening filter with augmentation techniques to highlight object profiles for easier recognition. Results are demonstrated on the TrashCan Dataset, both instance and material versions. The best-performing backbone method incorporates our channel stabilization and augmentation techniques. We also compare our Detectron2 detection results with the Deformable Transformer. In the instance version of TrashCan 1.0, our method achieves a 9.53% absolute increase in average precision for small objects and a 7% absolute gain in bounding box detection compared to the baseline. The code will be available on Code: this https URL Object-Detection-via-Channel-Stablization         ",
    "url": "https://arxiv.org/abs/2408.01293",
    "authors": [
      "Muhammad Ali",
      "Salman Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.01303",
    "title": "A Systematic Mapping Study on SDN Controllers for Enhancing Security in IoT Networks",
    "abstract": "           Context: The increase in Internet of Things (IoT) devices gives rise to an increase in deceptive manipulations by malicious actors. These actors should be prevented from targeting the IoT networks. Cybersecurity threats have evolved and become dynamically sophisticated, such that they could exploit any vulnerability found in IoT networks. However, with the introduction of the Software Defined Network (SDN) in the IoT networks as the central monitoring unit, IoT networks are less vulnerable and less prone to threats. %Although, the SDN itself is vulnerable to several threats. Objective: To present a comprehensive and unbiased overview of the state-of-the-art on IoT networks security enhancement using SDN controllers. Method: We review the current body of knowledge on enhancing the security of IoT networks using SDN with a Systematic Mapping Study (SMS) following the established guidelines. Results: The SMS result comprises 33 primary studies analyzed against four major research questions. The SMS highlights current research trends and identifies gaps in the SDN-IoT network security. Conclusion: We conclude that the SDN controller architecture commonly used for securing IoT networks is the centralized controller architecture. However, this architecture is not without its limitations. Additionally, the predominant technique utilized for risk mitigation is machine learning.         ",
    "url": "https://arxiv.org/abs/2408.01303",
    "authors": [
      "Charles Oredola",
      "Adnan Ashraf"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2408.01310",
    "title": "PsybORG+: Cognitive Modeling for Triggering and Detection of Cognitive Biases of Advanced Persistent Threats",
    "abstract": "           Advanced Persistent Threats (APTs) bring significant challenge to cybersecurity due to their sophisticated and stealthy nature. Traditional cybersecurity measures fail to defend against APTs. Cognitive vulnerabilities can significantly influence attackers' decision-making processes, which presents an opportunity for defenders to exploit these weaknesses. This paper introduces PsybORG, a multi-agent cybersecurity simulation environment designed to model APT behaviors influenced by cognitive vulnerabilities. PsybORG uses a Hidden Markov Model (HMM) to simulate attacker behaviors. We use Bayesian inference and decision tree analysis of action sequences to do cognitive vulnerabilities inference. In addition, a system called PsybORG+ is built for generating synthetic data. We also design a trigger to stimulate the sunk cost fallacy in attackers. Our contributions include the mathematical modeling of APTs, the development of PsybORG, and the implementation of techniques to infer attackers' cognitive vulnerabilities.         ",
    "url": "https://arxiv.org/abs/2408.01310",
    "authors": [
      "Shuo Huang",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2408.01328",
    "title": "Coloring bridge-free antiprismatic graphs",
    "abstract": "           The coloring problem is a well-research topic and its complexity is known for several classes of graphs. However, the question of its complexity remains open for the class of antiprismatic graphs, which are the complement of prismatic graphs and one of the four remaining cases highlighted by Lozin and Malishev. In this article we focus on the equivalent question of the complexity of the clique cover problem in prismatic graphs. A graph $G$ is prismatic if for every triangle $T$ of $G$, every vertex of $G$ not in $T$ has a unique neighbor in $T$. A graph is co-bridge-free if it has no $C_4+2K_1$ as induced subgraph. We give a polynomial time algorithm that solves the clique cover problem in co-bridge-free prismatic graphs. It relies on the structural description given by Chudnovsky and Seymour, and on later work of Preissmann, Robin and Trotignon. We show that co-bridge-free prismatic graphs have a bounded number of disjoint triangles and that implies that the algorithm presented by Preissmann et al. applies.         ",
    "url": "https://arxiv.org/abs/2408.01328",
    "authors": [
      "Cl\u00e9oph\u00e9e Robin",
      "Eileen Robinson"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2408.01331",
    "title": "UnifiedNN: Efficient Neural Network Training on the Cloud",
    "abstract": "           Nowadays, cloud-based services are widely favored over the traditional approach of locally training a Neural Network (NN) model. Oftentimes, a cloud service processes multiple requests from users--thus training multiple NN models concurrently. However, training NN models concurrently is a challenging process, which typically requires significant amounts of available computing resources and takes a long time to complete. In this paper, we present UnifiedNN to effectively train multiple NN models concurrently on the cloud. UnifiedNN effectively \"combines\" multiple NN models and features several memory and time conservation mechanisms to train multiple NN models simultaneously without impacting the accuracy of the training process. Specifically, UnifiedNN merges multiple NN models and creates a large singular unified model in order to efficiently train all models at once. We have implemented a prototype of UnifiedNN in PyTorch and we have compared its performance with relevant state-of-the-art frameworks. Our experimental results demonstrate that UnifiedNN can reduce memory consumption by up to 53% and training time by up to 81% when compared with vanilla PyTorch without impacting the model training and testing accuracy. Finally, our results indicate that UnifiedNN can reduce memory consumption by up to 52% and training time by up to 41% when compared to state-of-the-art frameworks when training multiple models concurrently.         ",
    "url": "https://arxiv.org/abs/2408.01331",
    "authors": [
      "Sifat Ut Taki",
      "Spyridon Mastorakis",
      "Arthi Padmanabhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.01332",
    "title": "HMDN: Hierarchical Multi-Distribution Network for Click-Through Rate Prediction",
    "abstract": "           As the recommendation service needs to address increasingly diverse distributions, such as multi-population, multi-scenario, multitarget, and multi-interest, more and more recent works have focused on multi-distribution modeling and achieved great progress. However, most of them only consider modeling in a single multi-distribution manner, ignoring that mixed multi-distributions often coexist and form hierarchical relationships. To address these challenges, we propose a flexible modeling paradigm, named Hierarchical Multi-Distribution Network (HMDN), which efficiently models these hierarchical relationships and can seamlessly integrate with existing multi-distribution methods, such as Mixture of-Experts (MoE) and Dynamic-Weight (DW) models. Specifically, we first design a hierarchical multi-distribution representation refinement module, employing a multi-level residual quantization to obtain fine-grained hierarchical representation. Then, the refined hierarchical representation is integrated into the existing single multi-distribution models, seamlessly expanding them into mixed multi-distribution models. Experimental results on both public and industrial datasets validate the effectiveness and flexibility of HMDN.         ",
    "url": "https://arxiv.org/abs/2408.01332",
    "authors": [
      "Xingyu Lou",
      "Yu Yang",
      "Kuiyao Dong",
      "Heyuan Huang",
      "Wenyi Yu",
      "Ping Wang",
      "Xiu Li",
      "Jun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.01342",
    "title": "Leveraging Knowledge Graph Embedding for Effective Conversational Recommendation",
    "abstract": "           Conversational recommender system (CRS), which combines the techniques of dialogue system and recommender system, has obtained increasing interest recently. In contrast to traditional recommender system, it learns the user preference better through interactions (i.e. conversations), and then further boosts the recommendation performance. However, existing studies on CRS ignore to address the relationship among attributes, users, and items effectively, which might lead to inappropriate questions and inaccurate recommendations. In this view, we propose a knowledge graph based conversational recommender system (referred as KG-CRS). Specifically, we first integrate the user-item graph and item-attribute graph into a dynamic graph, i.e., dynamically changing during the dialogue process by removing negative items or attributes. We then learn informative embedding of users, items, and attributes by also considering propagation through neighbors on the graph. Extensive experiments on three real datasets validate the superiority of our method over the state-of-the-art approaches in terms of both the recommendation and conversation tasks.         ",
    "url": "https://arxiv.org/abs/2408.01342",
    "authors": [
      "Yunwen Xia",
      "Hui Fang",
      "Jie Zhang",
      "Chong Long"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.01346",
    "title": "Prompt Refinement or Fine-tuning? Best Practices for using LLMs in Computational Social Science Tasks",
    "abstract": "           Large Language Models are expressive tools that enable complex tasks of text understanding within Computational Social Science. Their versatility, while beneficial, poses a barrier for establishing standardized best practices within the field. To bring clarity on the values of different strategies, we present an overview of the performance of modern LLM-based classification methods on a benchmark of 23 social knowledge tasks. Our results point to three best practices: select models with larger vocabulary and pre-training corpora; avoid simple zero-shot in favor of AI-enhanced prompting; fine-tune on task-specific data, and consider more complex forms instruction-tuning on multiple datasets only when only training data is more abundant.         ",
    "url": "https://arxiv.org/abs/2408.01346",
    "authors": [
      "Anders Giovanni M\u00f8ller",
      "Luca Maria Aiello"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2408.01354",
    "title": "MCGMark: An Encodable and Robust Online Watermark for LLM-Generated Malicious Code",
    "abstract": "           With the advent of large language models (LLMs), numerous software service providers (SSPs) are dedicated to developing LLMs customized for code generation tasks, such as CodeLlama and Copilot. However, these LLMs can be leveraged by attackers to create malicious software, which may pose potential threats to the software ecosystem. For example, they can automate the creation of advanced phishing malware. To address this issue, we first conduct an empirical study and design a prompt dataset, MCGTest, which involves approximately 400 person-hours of work and consists of 406 malicious code generation tasks. Utilizing this dataset, we propose MCGMark, the first robust, code structure-aware, and encodable watermarking approach to trace LLM-generated code. We embed encodable information by controlling the token selection and ensuring the output quality based on probabilistic outliers. Additionally, we enhance the robustness of the watermark by considering the structural features of malicious code, preventing the embedding of the watermark in easily modified positions, such as comments. We validate the effectiveness and robustness of MCGMark on the DeepSeek-Coder. MCGMark achieves an embedding success rate of 88.9% within a maximum output limit of 400 tokens. Furthermore, it also demonstrates strong robustness and has minimal impact on the quality of the output code. Our approach assists SSPs in tracing and holding responsible parties accountable for malicious code generated by LLMs.         ",
    "url": "https://arxiv.org/abs/2408.01354",
    "authors": [
      "Kaiwen Ning",
      "Jiachi Chen",
      "Qingyuan Zhong",
      "Tao Zhang",
      "Yanlin Wang",
      "Wei Li",
      "Yu Zhang",
      "Weizhe Zhang",
      "Zibin Zheng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2408.01374",
    "title": "Hybrid Coordinate Descent for Efficient Neural Network Learning Using Line Search and Gradient Descent",
    "abstract": "           This paper presents a novel coordinate descent algorithm leveraging a combination of one-directional line search and gradient information for parameter updates for a squared error loss function. Each parameter undergoes updates determined by either the line search or gradient method, contingent upon whether the modulus of the gradient of the loss with respect to that parameter surpasses a predefined threshold. Notably, a larger threshold value enhances algorithmic efficiency. Despite the potentially slower nature of the line search method relative to gradient descent, its parallelizability facilitates computational time reduction. Experimental validation conducted on a 2-layer Rectified Linear Unit network with synthetic data elucidates the impact of hyperparameters on convergence rates and computational efficiency.         ",
    "url": "https://arxiv.org/abs/2408.01374",
    "authors": [
      "Yen-Che Hsiao",
      "Abhishek Dutta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.01380",
    "title": "Coalitions of Large Language Models Increase the Robustness of AI Agents",
    "abstract": "           The emergence of Large Language Models (LLMs) have fundamentally altered the way we interact with digital systems and have led to the pursuit of LLM powered AI agents to assist in daily workflows. LLMs, whilst powerful and capable of demonstrating some emergent properties, are not logical reasoners and often struggle to perform well at all sub-tasks carried out by an AI agent to plan and execute a workflow. While existing studies tackle this lack of proficiency by generalised pretraining at a huge scale or by specialised fine-tuning for tool use, we assess if a system comprising of a coalition of pretrained LLMs, each exhibiting specialised performance at individual sub-tasks, can match the performance of single model agents. The coalition of models approach showcases its potential for building robustness and reducing the operational costs of these AI agents by leveraging traits exhibited by specific models. Our findings demonstrate that fine-tuning can be mitigated by considering a coalition of pretrained models and believe that this approach can be applied to other non-agentic systems which utilise LLMs.         ",
    "url": "https://arxiv.org/abs/2408.01380",
    "authors": [
      "Prattyush Mangal",
      "Carol Mak",
      "Theo Kanakis",
      "Timothy Donovan",
      "Dave Braines",
      "Edward Pyzer-Knapp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2408.01382",
    "title": "Explaining a probabilistic prediction on the simplex with Shapley compositions",
    "abstract": "           Originating in game theory, Shapley values are widely used for explaining a machine learning model's prediction by quantifying the contribution of each feature's value to the prediction. This requires a scalar prediction as in binary classification, whereas a multiclass probabilistic prediction is a discrete probability distribution, living on a multidimensional simplex. In such a multiclass setting the Shapley values are typically computed separately on each class in a one-vs-rest manner, ignoring the compositional nature of the output distribution. In this paper, we introduce Shapley compositions as a well-founded way to properly explain a multiclass probabilistic prediction, using the Aitchison geometry from compositional data analysis. We prove that the Shapley composition is the unique quantity satisfying linearity, symmetry and efficiency on the Aitchison simplex, extending the corresponding axiomatic properties of the standard Shapley value. We demonstrate this proper multiclass treatment in a range of scenarios.         ",
    "url": "https://arxiv.org/abs/2408.01382",
    "authors": [
      "Paul-Gauthier No\u00e9",
      "Miquel Perell\u00f3-Nieto",
      "Jean-Fran\u00e7ois Bonastre",
      "Peter Flach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2408.01394",
    "title": "Improving Multilingual Neural Machine Translation by Utilizing Semantic and Linguistic Features",
    "abstract": "           The many-to-many multilingual neural machine translation can be regarded as the process of integrating semantic features from the source sentences and linguistic features from the target sentences. To enhance zero-shot translation, models need to share knowledge across languages, which can be achieved through auxiliary tasks for learning a universal representation or cross-lingual mapping. To this end, we propose to exploit both semantic and linguistic features between multiple languages to enhance multilingual translation. On the encoder side, we introduce a disentangling learning task that aligns encoder representations by disentangling semantic and linguistic features, thus facilitating knowledge transfer while preserving complete information. On the decoder side, we leverage a linguistic encoder to integrate low-level linguistic features to assist in the target language generation. Experimental results on multilingual datasets demonstrate significant improvement in zero-shot translation compared to the baseline system, while maintaining performance in supervised translation. Further analysis validates the effectiveness of our method in leveraging both semantic and linguistic features. The code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2408.01394",
    "authors": [
      "Mengyu Bu",
      "Shuhao Gu",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2408.01408",
    "title": "Derivation of Back-propagation for Graph Convolutional Networks using Matrix Calculus and its Application to Explainable Artificial Intelligence",
    "abstract": "           This paper provides a comprehensive and detailed derivation of the backpropagation algorithm for graph convolutional neural networks using matrix calculus. The derivation is extended to include arbitrary element-wise activation functions and an arbitrary number of layers. The study addresses two fundamental problems, namely node classification and link prediction. To validate our method, we compare it with reverse-mode automatic differentiation. The experimental results demonstrate that the median sum of squared errors of the updated weight matrices, when comparing our method to the approach using reverse-mode automatic differentiation, falls within the range of $10^{-18}$ to $10^{-14}$. These outcomes are obtained from conducting experiments on a five-layer graph convolutional network, applied to a node classification problem on Zachary's karate club social network and a link prediction problem on a drug-drug interaction network. Finally, we show how the derived closed-form solution can facilitate the development of explainable AI and sensitivity analysis.         ",
    "url": "https://arxiv.org/abs/2408.01408",
    "authors": [
      "Yen-Che Hsiao",
      "Rongting Yue",
      "Abhishek Dutta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.01416",
    "title": "The Quest for the Right Mediator: A History, Survey, and Theoretical Grounding of Causal Interpretability",
    "abstract": "           Interpretability provides a toolset for understanding how and why neural networks behave in certain ways. However, there is little unity in the field: most studies employ ad-hoc evaluations and do not share theoretical foundations, making it difficult to measure progress and compare the pros and cons of different techniques. Furthermore, while mechanistic understanding is frequently discussed, the basic causal units underlying these mechanisms are often not explicitly defined. In this paper, we propose a perspective on interpretability research grounded in causal mediation analysis. Specifically, we describe the history and current state of interpretability taxonomized according to the types of causal units (mediators) employed, as well as methods used to search over mediators. We discuss the pros and cons of each mediator, providing insights as to when particular kinds of mediators and search methods are most appropriate depending on the goals of a given study. We argue that this framing yields a more cohesive narrative of the field, as well as actionable insights for future work. Specifically, we recommend a focus on discovering new mediators with better trade-offs between human-interpretability and compute-efficiency, and which can uncover more sophisticated abstractions from neural networks than the primarily linear mediators employed in current work. We also argue for more standardized evaluations that enable principled comparisons across mediator types, such that we can better understand when particular causal units are better suited to particular use cases.         ",
    "url": "https://arxiv.org/abs/2408.01416",
    "authors": [
      "Aaron Mueller",
      "Jannik Brinkmann",
      "Millicent Li",
      "Samuel Marks",
      "Koyena Pal",
      "Nikhil Prakash",
      "Can Rager",
      "Aruna Sankaranarayanan",
      "Arnab Sen Sharma",
      "Jiuding Sun",
      "Eric Todd",
      "David Bau",
      "Yonatan Belinkov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.00772",
    "title": "Hybrid Deep Learning Framework for Enhanced Melanoma Detection",
    "abstract": "           Cancer is a leading cause of death worldwide, necessitating advancements in early detection and treatment technologies. In this paper, we present a novel and highly efficient melanoma detection framework that synergistically combines the strengths of U-Net for segmentation and EfficientNet for the classification of skin images. The primary objective of our study is to enhance the accuracy and efficiency of melanoma detection through an innovative hybrid approach. We utilized the HAM10000 dataset to meticulously train the U-Net model, enabling it to precisely segment cancerous regions. Concurrently, we employed the ISIC 2020 dataset to train the EfficientNet model, optimizing it for the binary classification of skin cancer. Our hybrid model demonstrates a significant improvement in performance, achieving a remarkable accuracy of 99.01% on the ISIC 2020 dataset. This exceptional result underscores the superiority of our approach compared to existing model structures. By integrating the precise segmentation capabilities of U-Net with the advanced classification prowess of EfficientNet, our framework offers a comprehensive solution for melanoma detection. The results of our extensive experiments highlight the high accuracy and reliability of our method in both segmentation and classification tasks. This indicates the potential of our hybrid approach to significantly enhance cancer detection, providing a robust tool for medical professionals in the early diagnosis and treatment of melanoma. We believe that our framework can set a new benchmark in the field of automated skin cancer detection, encouraging further research and development in this crucial area of medical imaging.         ",
    "url": "https://arxiv.org/abs/2408.00772",
    "authors": [
      "Peng Zhang",
      "Divya Chaudhary"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.00773",
    "title": "Spike Talk: Genesis and Neural Coding Scheme Translations",
    "abstract": "           Although digitalization of future power grids offer several coordination incentives, the reliability and security of information and communication technologies (ICT) hinders its overall performance. In this paper, we introduce a novel architecture Spike Talk via a unified representation of power and information as a means of data normalization using spikes for coordinated control of microgrids. This grid-edge technology allows each distributed energy resource (DER) to execute decentralized secondary control philosophy independently by interacting among each other using power flow along the tie-lines. Inspired from the field of computational neuroscience, Spike Talk basically builds on a fine-grained parallelism on the information transfer theory in our brains, particularly when neurons (modeled as DERs) transmit information (inferred from power streams measurable at each DER) through synapses (modeled as tie-lines). Not only does Spike Talk simplify and address the current bottlenecks of the cyber-physical architectural operation by dismissing the ICT layer, it provides intrinsic operational and cost-effective opportunities in terms of infrastructure development, computations and modeling. Hence, this paper provides a pedagogic illustration of the key concepts and design theories. Since we focus on coordinated control of microgrids in this paper, the signaling accuracy and system performance is studied for several neural coding schemes responsible for converting the real-valued local measurements into spikes.         ",
    "url": "https://arxiv.org/abs/2408.00773",
    "authors": [
      "Subham Sahoo"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2408.00791",
    "title": "Improving Audio Spectrogram Transformers for Sound Event Detection Through Multi-Stage Training",
    "abstract": "           This technical report describes the CP-JKU team's submission for Task 4 Sound Event Detection with Heterogeneous Training Datasets and Potentially Missing Labels of the DCASE 24 Challenge. We fine-tune three large Audio Spectrogram Transformers, PaSST, BEATs, and ATST, on the joint DESED and MAESTRO datasets in a two-stage training procedure. The first stage closely matches the baseline system setup and trains a CRNN model while keeping the large pre-trained transformer model frozen. In the second stage, both CRNN and transformer are fine-tuned using heavily weighted self-supervised losses. After the second stage, we compute strong pseudo-labels for all audio clips in the training set using an ensemble of all three fine-tuned transformers. Then, in a second iteration, we repeat the two-stage training process and include a distillation loss based on the pseudo-labels, boosting single-model performance substantially. Additionally, we pre-train PaSST and ATST on the subset of AudioSet that comes with strong temporal labels, before fine-tuning them on the Task 4 datasets.         ",
    "url": "https://arxiv.org/abs/2408.00791",
    "authors": [
      "Florian Schmid",
      "Paul Primus",
      "Tobias Morocutti",
      "Jonathan Greif",
      "Gerhard Widmer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2408.00995",
    "title": "Sandwiching Random Geometric Graphs and Erdos-Renyi with Applications: Sharp Thresholds, Robust Testing, and Enumeration",
    "abstract": "           The distribution $\\mathsf{RGG}(n,\\mathbb{S}^{d-1},p)$ is formed by sampling independent vectors $\\{V_i\\}_{i = 1}^n$ uniformly on $\\mathbb{S}^{d-1}$ and placing an edge between pairs of vertices $i$ and $j$ for which $\\langle V_i,V_j\\rangle \\ge \\tau^p_d,$ where $\\tau^p_d$ is such that the expected density is $p.$ Our main result is a poly-time implementable coupling between Erd\u0151s-R\u00e9nyi and $\\mathsf{RGG}$ such that $\\mathsf{G}(n,p(1 - \\tilde{O}(\\sqrt{np/d})))\\subseteq \\mathsf{RGG}(n,\\mathbb{S}^{d-1},p)\\subseteq \\mathsf{G}(n,p(1 + \\tilde{O}(\\sqrt{np/d})))$ edgewise with high probability when $d\\gg np.$ We apply the result to: 1) Sharp Thresholds: We show that for any monotone property having a sharp threshold with respect to the Erd\u0151s-R\u00e9nyi distribution and critical probability $p^c_n,$ random geometric graphs also exhibit a sharp threshold when $d\\gg np^c_n,$ thus partially answering a question of Perkins. 2) Robust Testing: The coupling shows that testing between $\\mathsf{G}(n,p)$ and $\\mathsf{RGG}(n,\\mathbb{S}^{d-1},p)$ with $\\epsilon n^2p$ adversarially corrupted edges for any constant $\\epsilon>0$ is information-theoretically impossible when $d\\gg np.$ We match this lower bound with an efficient (constant degree SoS) spectral refutation algorithm when $d\\ll np.$ 3) Enumeration: We show that the number of geometric graphs in dimension $d$ is at least $\\exp(dn\\log^{-7}n)$, recovering (up to the log factors) the sharp result of Sauermann.         ",
    "url": "https://arxiv.org/abs/2408.00995",
    "authors": [
      "Kiril Bangachev",
      "Guy Bresler"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2408.01023",
    "title": "Distilling interpretable causal trees from causal forests",
    "abstract": "           Machine learning methods for estimating treatment effect heterogeneity promise greater flexibility than existing methods that test a few pre-specified hypotheses. However, one problem these methods can have is that it can be challenging to extract insights from complicated machine learning models. A high-dimensional distribution of conditional average treatment effects may give accurate, individual-level estimates, but it can be hard to understand the underlying patterns; hard to know what the implications of the analysis are. This paper proposes the Distilled Causal Tree, a method for distilling a single, interpretable causal tree from a causal forest. This compares well to existing methods of extracting a single tree, particularly in noisy data or high-dimensional data where there are many correlated features. Here it even outperforms the base causal forest in most simulations. Its estimates are doubly robust and asymptotically normal just as those of the causal forest are.         ",
    "url": "https://arxiv.org/abs/2408.01023",
    "authors": [
      "Patrick Rehill"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.01066",
    "title": "Stabilization of synchronous tridiagonal network motion",
    "abstract": "           We consider a network of identical agents, coupled through linear asymmetric coupling. An important case is when each agent has an asymptotically stable periodic orbit, so that the full network inherits a synchronous periodic orbit, but also chaotic trajectories are of interest. In this work, we will restrict to \"nearest-neighbor\" type of couplings. The Master Stability Function (MSF) is a powerful tool to establish local stability of the synchronous orbit, in particular a negative MSF implies asymptotic stability. But not every network structure gives a negative MSF. Moreover, there are many situations where in order to obtain a negative MSF, symmetric networks need a coupling strength so large, that the model bears little physical interest. We make two main contributions: (i) Given a tridiagonal nearest neighbor topology, we show how it is possible to choose appropriate coupling so that the synchronous orbit is stable, and (ii) we show that this stability comes without the need of a large coupling strength if the structure is not symmetric. Our construction is based on solving inverse eigenvalue problems. We will see that the coupling of the agents cannot always be chosen to be symmetric so that the underlying graph structure is that of a directed graph with edges having different weights. We provide numerical implementation of our technique on networks of van der Pol and of chaotic R\u00f6ssler oscillators, where the standard symmetric nearest neighbor coupling fails to give stability of the synchronous orbit.         ",
    "url": "https://arxiv.org/abs/2408.01066",
    "authors": [
      "Luca Dieci",
      "Cinzia Elia",
      "Alessandro Pugliese"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2408.01200",
    "title": "Certifiably Robust Encoding Schemes",
    "abstract": "           Quantum machine learning uses principles from quantum mechanics to process data, offering potential advances in speed and performance. However, previous work has shown that these models are susceptible to attacks that manipulate input data or exploit noise in quantum circuits. Following this, various studies have explored the robustness of these models. These works focus on the robustness certification of manipulations of the quantum states. We extend this line of research by investigating the robustness against perturbations in the classical data for a general class of data encoding schemes. We show that for such schemes, the addition of suitable noise channels is equivalent to evaluating the mean value of the noiseless classifier at the smoothed data, akin to Randomized Smoothing from classical machine learning. Using our general framework, we show that suitable additions of phase-damping noise channels improve empirical and provable robustness for the considered class of encoding schemes.         ",
    "url": "https://arxiv.org/abs/2408.01200",
    "authors": [
      "Aman Saxena",
      "Tom Wollschl\u00e4ger",
      "Nicola Franco",
      "Jeanette Miriam Lorenz",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.01268",
    "title": "Rumour Spreading Depends on the Latent Geometry and Degree Distribution in Social Network Models",
    "abstract": "           We study push-pull rumour spreading in small-world models for social networks where the degrees follow a power-law. In a non-geometric setting Fountoulakis, Panagiotou and Sauerwald have shown that rumours always spread fast (SODA 2012). On the other hand, Janssen and Mehrabian have found that rumours spread slowly in a spatial preferential attachment model (SIDMA 2017). We study the question systematically for the model of geometric inhomogeneous random graphs (GIRGs), which has been found to be a good theoretical and empirical fit for social networks. Our result is two-fold: with classical Euclidean geometry both slow and fast rumour spreading may occur, depending on the exponent of the power law and the prevalence of weak ties in the networks, and we fully characterise the phase boundaries between those two regimes. Depending on the parameters, fast spreading may either mean polylogarithmic time or even doubly logarithmic time. Secondly, we show that rumour spreading is always fast in a non-metric geometry. The considered non-metric geometry allows to model social connections where resemblance of vertices in a single attribute, such as familial kinship, already strongly indicates the presence of an edge. Classical Euclidean Geometry fails to capture such ties. For some regimes in the Euclidean setting, the efficient pathways for spreading rumours differ from previously identified paths. A vertex of degree $d$ can transmit the rumour efficiently to a vertex of larger degree by a chain of length $3$, where one of the two intermediaries has constant degree, and the other has degree $d^{c}$ for some constant $c<1$.         ",
    "url": "https://arxiv.org/abs/2408.01268",
    "authors": [
      "Marc Kaufmann",
      "Kostas Lakis",
      "Johannes Lengler",
      "Raghu Raman Ravi",
      "Ulysse Schaller",
      "Konstantin Sturm"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Social and Information Networks (cs.SI)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2408.01292",
    "title": "3DPX: Progressive 2D-to-3D Oral Image Reconstruction with Hybrid MLP-CNN Networks",
    "abstract": "           Panoramic X-ray (PX) is a prevalent modality in dental practice for its wide availability and low cost. However, as a 2D projection image, PX does not contain 3D anatomical information, and therefore has limited use in dental applications that can benefit from 3D information, e.g., tooth angular misa-lignment detection and classification. Reconstructing 3D structures directly from 2D PX has recently been explored to address limitations with existing methods primarily reliant on Convolutional Neural Networks (CNNs) for direct 2D-to-3D mapping. These methods, however, are unable to correctly infer depth-axis spatial information. In addition, they are limited by the in-trinsic locality of convolution operations, as the convolution kernels only capture the information of immediate neighborhood pixels. In this study, we propose a progressive hybrid Multilayer Perceptron (MLP)-CNN pyra-mid network (3DPX) for 2D-to-3D oral PX reconstruction. We introduce a progressive reconstruction strategy, where 3D images are progressively re-constructed in the 3DPX with guidance imposed on the intermediate recon-struction result at each pyramid level. Further, motivated by the recent ad-vancement of MLPs that show promise in capturing fine-grained long-range dependency, our 3DPX integrates MLPs and CNNs to improve the semantic understanding during reconstruction. Extensive experiments on two large datasets involving 464 studies demonstrate that our 3DPX outperforms state-of-the-art 2D-to-3D oral reconstruction methods, including standalone MLP and transformers, in reconstruction quality, and also im-proves the performance of downstream angular misalignment classification tasks.         ",
    "url": "https://arxiv.org/abs/2408.01292",
    "authors": [
      "Xiaoshuang Li",
      "Mingyuan Meng",
      "Zimo Huang",
      "Lei Bi",
      "Eduardo Delamare",
      "Dagan Feng",
      "Bin Sheng",
      "Jinman Kim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.01300",
    "title": "Assessing Robustness of Machine Learning Models using Covariate Perturbations",
    "abstract": "           As machine learning models become increasingly prevalent in critical decision-making models and systems in fields like finance, healthcare, etc., ensuring their robustness against adversarial attacks and changes in the input data is paramount, especially in cases where models potentially overfit. This paper proposes a comprehensive framework for assessing the robustness of machine learning models through covariate perturbation techniques. We explore various perturbation strategies to assess robustness and examine their impact on model predictions, including separate strategies for numeric and non-numeric variables, summaries of perturbations to assess and compare model robustness across different scenarios, and local robustness diagnosis to identify any regions in the data where a model is particularly unstable. Through empirical studies on real world dataset, we demonstrate the effectiveness of our approach in comparing robustness across models, identifying the instabilities in the model, and enhancing model robustness.         ",
    "url": "https://arxiv.org/abs/2408.01300",
    "authors": [
      "Arun Prakash R",
      "Anwesha Bhattacharyya",
      "Joel Vaughan",
      "Vijayan N. Nair"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.01316",
    "title": "Synergistic pathways of modulation enable robust task packing within neural dynamics",
    "abstract": "           Understanding how brain networks learn and manage multiple tasks simultaneously is of interest in both neuroscience and artificial intelligence. In this regard, a recent research thread in theoretical neuroscience has focused on how recurrent neural network models and their internal dynamics enact multi-task learning. To manage different tasks requires a mechanism to convey information about task identity or context into the model, which from a biological perspective may involve mechanisms of neuromodulation. In this study, we use recurrent network models to probe the distinctions between two forms of contextual modulation of neural dynamics, at the level of neuronal excitability and at the level of synaptic strength. We characterize these mechanisms in terms of their functional outcomes, focusing on their robustness to context ambiguity and, relatedly, their efficiency with respect to packing multiple tasks into finite size networks. We also demonstrate distinction between these mechanisms at the level of the neuronal dynamics they induce. Together, these characterizations indicate complementarity and synergy in how these mechanisms act, potentially over multiple time-scales, toward enhancing robustness of multi-task learning.         ",
    "url": "https://arxiv.org/abs/2408.01316",
    "authors": [
      "Giacomo Vedovati",
      "ShiNung Ching"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.01318",
    "title": "Point Prediction for Streaming Data",
    "abstract": "           We present two new approaches for point prediction with streaming data. One is based on the Count-Min sketch (CMS) and the other is based on Gaussian process priors with a random bias. These methods are intended for the most general predictive problems where no true model can be usefully formulated for the data stream. In statistical contexts, this is often called the $\\mathcal{M}$-open problem class. Under the assumption that the data consists of i.i.d samples from a fixed distribution function $F$, we show that the CMS-based estimates of the distribution function are consistent. We compare our new methods with two established predictors in terms of cumulative $L^1$ error. One is based on the Shtarkov solution (often called the normalized maximum likelihood) in the normal experts setting and the other is based on Dirichlet process priors. These comparisons are for two cases. The first is one-pass meaning that the updating of the predictors is done using the fact that the CMS is a sketch. For predictors that are not one-pass, we use streaming $K$-means to give a representative subset of fixed size that can be updated as data accumulate. Preliminary computational work suggests that the one-pass median version of the CMS method is rarely outperformed by the other methods for sufficiently complex data. We also find that predictors based on Gaussian process priors with random biases perform well. The Shtarkov predictors we use here did not perform as well probably because we were only using the simplest example. The other predictors seemed to perform well mainly when the data did not look like they came from an M-open data generator.         ",
    "url": "https://arxiv.org/abs/2408.01318",
    "authors": [
      "Aleena Chanda",
      "N. V. Vinodchandran",
      "Bertrand Clarke"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2012.13617",
    "title": "A New Perspective to Node Influence Evaluation in Complex Network Using Subgraph Tr-Centrality",
    "abstract": "           There is great significance in evaluating a node's Influence ranking in complex networks. Over the years, many researchers have presented different measures for quantifying node interconnectedness within networks. Therefore, this paper introduces a centrality measure called Tr-centrality which focuses on using the node triangle structure and the node neighborhood information to define the strength of a node, which is defined as the summation of Gruebler's Equation of the node's one-hop triangle neighborhood to the number of all the edges in the subgraph. Furthermore, we socially consider it as the local trust of a node. To verify the validity of Tr-centrality [1], we apply it to four real-world networks with different densities and shapes, and Tr-centrality has proven to yield better results.         ",
    "url": "https://arxiv.org/abs/2012.13617",
    "authors": [
      "Auwal Tijjani Amshi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2207.09339",
    "title": "Vision Transformers: From Semantic Segmentation to Dense Prediction",
    "abstract": "           The emergence of vision transformers (ViTs) in image classification has shifted the methodologies for visual representation learning. In particular, ViTs learn visual representation at full receptive field per layer across all the image patches, in comparison to the increasing receptive fields of CNNs across layers and other alternatives (e.g., large kernels and atrous convolution). In this work, for the first time we explore the global context learning potentials of ViTs for dense visual prediction (e.g., semantic segmentation). Our motivation is that through learning global context at full receptive field layer by layer, ViTs may capture stronger long-range dependency information, critical for dense prediction tasks. We first demonstrate that encoding an image as a sequence of patches, a vanilla ViT without local convolution and resolution reduction can yield stronger visual representation for semantic segmentation. For example, our model, termed as SEgmentation TRansformer (SETR), excels on ADE20K (50.28% mIoU, the first position in the test leaderboard on the day of submission) and performs competitively on Cityscapes. However, the basic ViT architecture falls short in broader dense prediction applications, such as object detection and instance segmentation, due to its lack of a pyramidal structure, high computational demand, and insufficient local context. For tackling general dense visual prediction tasks in a cost-effective manner, we further formulate a family of Hierarchical Local-Global (HLG) Transformers, characterized by local attention within windows and global-attention across windows in a pyramidal architecture. Extensive experiments show that our methods achieve appealing performance on a variety of dense prediction tasks (e.g., object detection and instance segmentation and semantic segmentation) as well as image classification.         ",
    "url": "https://arxiv.org/abs/2207.09339",
    "authors": [
      "Li Zhang",
      "Jiachen Lu",
      "Sixiao Zheng",
      "Xinxuan Zhao",
      "Xiatian Zhu",
      "Yanwei Fu",
      "Tao Xiang",
      "Jianfeng Feng",
      "Philip H.S. Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12653",
    "title": "Robust Millimeter Beamforming via Self-Supervised Hybrid Deep Learning",
    "abstract": "           Beamforming with large-scale antenna arrays has been widely used in recent years, which is acknowledged as an important part in 5G and incoming 6G. Thus, various techniques are leveraged to improve its performance, e.g., deep learning, advanced optimization algorithms, etc. Although its performance in many previous research scenarios with deep learning is quite attractive, usually it drops rapidly when the environment or dataset is changed. Therefore, designing effective beamforming network with strong robustness is an open issue for the intelligent wireless communications. In this paper, we propose a robust beamforming self-supervised network, and verify it in two kinds of different datasets with various scenarios. Simulation results show that the proposed self-supervised network with hybrid learning performs well in both classic DeepMIMO and new WAIR-D dataset with the strong robustness under the various environments. Also, we present the principle to explain the rationality of this kind of hybrid learning, which is instructive to apply with more kinds of datasets.         ",
    "url": "https://arxiv.org/abs/2303.12653",
    "authors": [
      "Fenghao Zhu",
      "Bohao Wang",
      "Zhaohui Yang",
      "Chongwen Huang",
      "Zhaoyang Zhang",
      "George C.Alexandropoulos",
      "Chau Yuen",
      "Merouane Debbah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.11857",
    "title": "Accurate and Efficient Event-based Semantic Segmentation Using Adaptive Spiking Encoder-Decoder Network",
    "abstract": "           Spiking neural networks (SNNs), known for their low-power, event-driven computation and intrinsic temporal dynamics, are emerging as promising solutions for processing dynamic, asynchronous signals from event-based sensors. Despite their potential, SNNs face challenges in training and architectural design, resulting in limited performance in challenging event-based dense prediction tasks compared to artificial neural networks (ANNs). In this work, we develop an efficient spiking encoder-decoder network (SpikingEDN) for large-scale event-based semantic segmentation tasks. To enhance the learning efficiency from dynamic event streams, we harness the adaptive threshold which improves network accuracy, sparsity and robustness in streaming inference. Moreover, we develop a dual-path Spiking Spatially-Adaptive Modulation module, which is specifically tailored to enhance the representation of sparse events and multi-modal inputs, thereby considerably improving network performance. Our SpikingEDN attains a mean intersection over union (MIoU) of 72.57\\% on the DDD17 dataset and 58.32\\% on the larger DSEC-Semantic dataset, showing competitive results to the state-of-the-art ANNs while requiring substantially fewer computational resources. Our results shed light on the untapped potential of SNNs in event-based vision applications. The source code will be made publicly available.         ",
    "url": "https://arxiv.org/abs/2304.11857",
    "authors": [
      "Rui Zhang",
      "Luziwei Leng",
      "Kaiwei Che",
      "Hu Zhang",
      "Jie Cheng",
      "Qinghai Guo",
      "Jiangxing Liao",
      "Ran Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2306.07292",
    "title": "SARN: Structurally-Aware Recurrent Network for Spatio-Temporal Disaggregation",
    "abstract": "           Open data is frequently released spatially aggregated, usually to comply with privacy policies. But coarse, heterogeneous aggregations complicate learning and integration for downstream AI/ML systems. In this work, we consider models to disaggregate spatio-temporal data from a low-resolution, irregular partition (e.g., census tract) to a high-resolution, irregular partition (e.g., city block). We propose an overarching model named the Structurally-Aware Recurrent Network (SARN), which integrates structurally-aware spatial attention (SASA) layers into the Gated Recurrent Unit (GRU) model. The spatial attention layers capture spatial interactions among regions, while the gated recurrent module captures the temporal dependencies. Each SASA layer calculates both global and structural attention -- global attention facilitates comprehensive interactions between different geographic levels, while structural attention leverages the containment relationship between different geographic levels (e.g., a city block being wholly contained within a census tract) to ensure coherent and consistent results. For scenarios with limited historical training data, we explore transfer learning and show that a model pre-trained on one city variable can be fine-tuned for another city variable using only a few hundred samples. Evaluating these techniques on two mobility datasets, we find that on both datasets, SARN significantly outperforms other neural models (5% and 1%) and typical heuristic methods (40% and 14%), enabling us to generate realistic, high-quality fine-grained data for downstream applications.         ",
    "url": "https://arxiv.org/abs/2306.07292",
    "authors": [
      "Bin Han",
      "Bill Howe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.02572",
    "title": "Design Tasks and Their Complexity for the European Train Control System with Hybrid Train Detection",
    "abstract": "           Railway networks have become increasingly important in recent times, especially to move freight and public transportation from road traffic and planes to more environmentally friendly trains. Since expanding the global railway network is time and resource-consuming, maximizing the rail capacity on the existing infrastructure is desirable. However, simply running more trains is infeasible as certain constraints enforced by the train control system must be satisfied. The capacity of a network depends (amongst others) on the distance between trains allowed by this safety system. While most signaling systems rely on fixed blocks defined by costly hardware, new specifications provided by Level 2 with Hybrid Train Detection of the European Train Control System (ETCS L2 HTD), formerly known as ETCS Hybrid Level 3, allow the usage of virtual subsections. This additional degree of freedom allows for shorter train following times and, thus, more trains on existing railway tracks. On the other hand, new design tasks arise on which automated methods might be helpful for designers of modern railway networks. However, although first approaches exist that solve design problems arising within ETCS L2 HTD, neither formal descriptions nor results on the computational complexity of the corresponding design tasks exist. In this paper, we fill this gap by providing a formal description of design tasks for ETCS L2 HTD and proof that these tasks are NP-complete or NP-hard, respectively. By that, we are providing a solid basis for the future development of methods to solve those tasks, which will be integrated into the Munich Train Control Toolkit available open-source on GitHub at this https URL.         ",
    "url": "https://arxiv.org/abs/2308.02572",
    "authors": [
      "Stefan Engels",
      "Tom Peham",
      "Judith Przigoda",
      "Nils Przigoda",
      "Robert Wille"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2308.14250",
    "title": "Rule-Based Error Detection and Correction to Operationalize Movement Trajectory Classification",
    "abstract": "           Classification of movement trajectories has many applications in transportation and is a key component for large-scale movement trajectory generation and anomaly detection which has key safety applications in the aftermath of a disaster or other external shock. However, the current state-of-the-art (SOTA) are based on supervised deep learning - which leads to challenges when the distribution of trajectories changes due to such a shock. We provide a neuro-symbolic rule-based framework to conduct error correction and detection of these models to integrate into our movement trajectory platform. We provide a suite of experiments on several recent SOTA models where we show highly accurate error detection, the ability to improve accuracy with a changing test distribution, and accuracy improvement for the base use case in addition to a suite of theoretical properties that informed algorithm development. Specifically, we show an F1 scores for predicting errors of up to 0.984, significant performance increase for out-of distribution accuracy (8.51% improvement over SOTA for zero-shot accuracy), and accuracy improvement over the SOTA model.         ",
    "url": "https://arxiv.org/abs/2308.14250",
    "authors": [
      "Bowen Xi",
      "Kevin Scaria",
      "Divyagna Bavikadi",
      "Paulo Shakarian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2309.03452",
    "title": "Multimodal Guidance Network for Missing-Modality Inference in Content Moderation",
    "abstract": "           Multimodal deep learning, especially vision-language models, have gained significant traction in recent years, greatly improving performance on many downstream tasks, including content moderation and violence detection. However, standard multimodal approaches often assume consistent modalities between training and inference, limiting applications in many real-world use cases, as some modalities may not be available during inference. While existing research mitigates this problem through reconstructing the missing modalities, they unavoidably increase unnecessary computational cost, which could be just as critical, especially for large, deployed infrastructures in industry. To this end, we propose a novel guidance network that promotes knowledge sharing during training, taking advantage of the multimodal representations to train better single-modality models to be used for inference. Real-world experiments in violence detection shows that our proposed framework trains single-modality models that significantly outperform traditionally trained counterparts, while avoiding increases in computational cost for inference.         ",
    "url": "https://arxiv.org/abs/2309.03452",
    "authors": [
      "Zhuokai Zhao",
      "Harish Palani",
      "Tianyi Liu",
      "Lena Evans",
      "Ruth Toner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.09170",
    "title": "A Unifying Privacy Analysis Framework for Unknown Domain Algorithms in Differential Privacy",
    "abstract": "           There are many existing differentially private algorithms for releasing histograms, i.e. counts with corresponding labels, in various settings. Our focus in this survey is to revisit some of the existing differentially private algorithms for releasing histograms over unknown domains, i.e. the labels of the counts that are to be released are not known beforehand. The main practical advantage of releasing histograms over an unknown domain is that the algorithm does not need to fill in missing labels because they are not present in the original histogram but in a hypothetical neighboring dataset could appear in the histogram. However, the challenge in designing differentially private algorithms for releasing histograms over an unknown domain is that some outcomes can clearly show which input was used, clearly violating privacy. The goal then is to show that the differentiating outcomes occur with very low probability. We present a unified framework for the privacy analyses of several existing algorithms. Furthermore, our analysis uses approximate concentrated differential privacy from Bun and Steinke'16, which can improve the privacy loss parameters rather than using differential privacy directly, especially when composing many of these algorithms together in an overall system.         ",
    "url": "https://arxiv.org/abs/2309.09170",
    "authors": [
      "Ryan Rogers"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.05243",
    "title": "A higher-order transformation approach to the formalization and analysis of BPMN using graph transformation systems",
    "abstract": "           The Business Process Modeling Notation (BPMN) is a widely used standard notation for defining intra- and inter-organizational workflows. However, the informal description of the BPMN execution semantics leads to different interpretations of BPMN elements and difficulties in checking behavioral properties. In this article, we propose a formalization of the execution semantics of BPMN that, compared to existing approaches, covers more BPMN elements while also facilitating property checking. Our approach is based on a higher-order transformation from BPMN models to graph transformation systems. To show the capabilities of our approach, we implemented it as an open-source web-based tool.         ",
    "url": "https://arxiv.org/abs/2311.05243",
    "authors": [
      "Tim Kr\u00e4uter",
      "Adrian Rutle",
      "Harald K\u00f6nig",
      "Yngve Lamo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2311.09004",
    "title": "Incremental Object-Based Novelty Detection with Feedback Loop",
    "abstract": "           Object-based Novelty Detection (ND) aims to identify unknown objects that do not belong to classes seen during training by an object detection model. The task is particularly crucial in real-world applications, as it allows to avoid potentially harmful behaviours, e.g. as in the case of object detection models adopted in a self-driving car or in an autonomous robot. Traditional approaches to ND focus on one time offline post processing of the pretrained object detection output, leaving no possibility to improve the model robustness after training and discarding the abundant amount of out-of-distribution data encountered during deployment. In this work, we propose a novel framework for object-based ND, assuming that human feedback can be requested on the predicted output and later incorporated to refine the ND model without negatively affecting the main object detection performance. This refinement operation is repeated whenever new feedback is available. To tackle this new formulation of the problem for object detection, we propose a lightweight ND module attached on top of a pre-trained object detection model, which is incrementally updated through a feedback loop. We also propose a new benchmark to evaluate methods on this new setting and test extensively our ND approach against baselines, showing increased robustness and a successful incorporation of the received feedback.         ",
    "url": "https://arxiv.org/abs/2311.09004",
    "authors": [
      "Simone Caldarella",
      "Elisa Ricci",
      "Rahaf Aljundi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.13186",
    "title": "Applications of Spiking Neural Networks in Visual Place Recognition",
    "abstract": "           In robotics, Spiking Neural Networks (SNNs) are increasingly recognized for their largely-unrealized potential energy efficiency and low latency particularly when implemented on neuromorphic hardware. Our paper highlights three advancements for SNNs in Visual Place Recognition (VPR). Firstly, we propose Modular SNNs, where each SNN represents a set of non-overlapping geographically distinct places, enabling scalable networks for large environments. Secondly, we present Ensembles of Modular SNNs, where multiple networks represent the same place, significantly enhancing accuracy compared to single-network models. Each of our Modular SNN modules is compact, comprising only 1500 neurons and 474k synapses, making them ideally suited for ensembling due to their small size. Lastly, we investigate the role of sequence matching in SNN-based VPR, a technique where consecutive images are used to refine place recognition. We analyze the responsiveness of SNNs to ensembling and sequence matching compared to other VPR techniques. Our contributions highlight the viability of SNNs for VPR, offering scalable and robust solutions, and paving the way for their application in various energy-sensitive robotic tasks.         ",
    "url": "https://arxiv.org/abs/2311.13186",
    "authors": [
      "Somayeh Hussaini",
      "Michael Milford",
      "Tobias Fischer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.17804",
    "title": "The Importance of Downstream Networks in Digital Pathology Foundation Models",
    "abstract": "           Digital pathology has significantly advanced disease detection and pathologist efficiency through the analysis of gigapixel whole-slide images (WSI). In this process, WSIs are first divided into patches, for which a feature extractor model is applied to obtain feature vectors, which are subsequently processed by an aggregation model to predict the respective WSI label. With the rapid evolution of representation learning, numerous new feature extractor models, often termed foundational models, have emerged. Traditional evaluation methods rely on a static downstream aggregation model setup, encompassing a fixed architecture and hyperparameters, a practice we identify as potentially biasing the results. Our study uncovers a sensitivity of feature extractor models towards aggregation model configurations, indicating that performance comparability can be skewed based on the chosen configurations. By accounting for this sensitivity, we find that the performance of many current feature extractor models is notably similar. We support this insight by evaluating seven feature extractor models across three different datasets with 162 different aggregation model configurations. This comprehensive approach provides a more nuanced understanding of the feature extractors' sensitivity to various aggregation model configurations, leading to a fairer and more accurate assessment of new foundation models in digital pathology.         ",
    "url": "https://arxiv.org/abs/2311.17804",
    "authors": [
      "Gustav Bredell",
      "Marcel Fischer",
      "Przemyslaw Szostak",
      "Samaneh Abbasi-Sureshjani",
      "Alvaro Gomariz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2312.08372",
    "title": "SAM-guided Graph Cut for 3D Instance Segmentation",
    "abstract": "           This paper addresses the challenge of 3D instance segmentation by simultaneously leveraging 3D geometric and multi-view image information. Many previous works have applied deep learning techniques to 3D point clouds for instance segmentation. However, these methods often failed to generalize to various types of scenes due to the scarcity and low-diversity of labeled 3D point cloud data. Some recent works have attempted to lift 2D instance segmentations to 3D within a bottom-up framework. The inconsistency in 2D instance segmentations among views can substantially degrade the performance of 3D segmentation. In this work, we introduce a novel 3D-to-2D query framework to effectively exploit 2D segmentation models for 3D instance segmentation. Specifically, we pre-segment the scene into several superpoints in 3D, formulating the task into a graph cut problem. The superpoint graph is constructed based on 2D segmentation models, where node features are obtained from multi-view image features and edge weights are computed based on multi-view segmentation results, enabling the better generalization ability. To process the graph, we train a graph neural network using pseudo 3D labels from 2D segmentation models. Experimental results on the ScanNet, ScanNet++ and KITTI-360 datasets demonstrate that our method achieves robust segmentation performance and can generalize across different types of scenes. Our project page is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2312.08372",
    "authors": [
      "Haoyu Guo",
      "He Zhu",
      "Sida Peng",
      "Yuang Wang",
      "Yujun Shen",
      "Ruizhen Hu",
      "Xiaowei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.06542",
    "title": "Robustness-Aware 3D Object Detection in Autonomous Driving: A Review and Outlook",
    "abstract": "           In the realm of modern autonomous driving, the perception system is indispensable for accurately assessing the state of the surrounding environment, thereby enabling informed prediction and planning. The key step to this system is related to 3D object detection that utilizes vehicle-mounted sensors such as LiDAR and cameras to identify the size, the category, and the location of nearby objects. Despite the surge in 3D object detection methods aimed at enhancing detection precision and efficiency, there is a gap in the literature that systematically examines their resilience against environmental variations, noise, and weather changes. This study emphasizes the importance of robustness, alongside accuracy and latency, in evaluating perception systems under practical scenarios. Our work presents an extensive survey of camera-only, LiDAR-only, and multi-modal 3D object detection algorithms, thoroughly evaluating their trade-off between accuracy, latency, and robustness, particularly on datasets like KITTI-C and nuScenes-C to ensure fair comparisons. Among these, multi-modal 3D detection approaches exhibit superior robustness, and a novel taxonomy is introduced to reorganize the literature for enhanced clarity. This survey aims to offer a more practical perspective on the current capabilities and the constraints of 3D object detection algorithms in real-world applications, thus steering future research towards robustness-centric advancements.         ",
    "url": "https://arxiv.org/abs/2401.06542",
    "authors": [
      "Ziying Song",
      "Lin Liu",
      "Feiyang Jia",
      "Yadan Luo",
      "Guoxin Zhang",
      "Lei Yang",
      "Li Wang",
      "Caiyan Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.09714",
    "title": "Robust virtual element methods for coupled stress-assisted diffusion problems",
    "abstract": "           This paper aims first to perform robust continuous analysis of a mixed nonlinear formulation for stress-assisted diffusion of a solute that interacts with an elastic material, and second to propose and analyse a virtual element formulation of the model problem. The two-way coupling mechanisms between the Herrmann formulation for linear elasticity and the reaction-diffusion equation (written in mixed form) consist of diffusion-induced active stress and stress-dependent diffusion. The two sub-problems are analysed using the extended Babu\u0161ka--Brezzi--Braess theory for perturbed saddle-point problems. The well-posedness of the nonlinearly coupled system is established using a Banach fixed-point strategy under the smallness assumption on data. The virtual element formulations for the uncoupled sub-problems are proven uniquely solvable by a fixed-point argument in conjunction with appropriate projection operators. We derive the a priori error estimates, and test the accuracy and performance of the proposed method through computational simulations.         ",
    "url": "https://arxiv.org/abs/2401.09714",
    "authors": [
      "Rekha Khot",
      "Andres E. Rubiano",
      "Ricardo Ruiz-Baier"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2401.09786",
    "title": "Adaptive Self-training Framework for Fine-grained Scene Graph Generation",
    "abstract": "           Scene graph generation (SGG) models have suffered from inherent problems regarding the benchmark datasets such as the long-tailed predicate distribution and missing annotation problems. In this work, we aim to alleviate the long-tailed problem of SGG by utilizing unannotated triplets. To this end, we introduce a Self-Training framework for SGG (ST-SGG) that assigns pseudo-labels for unannotated triplets based on which the SGG models are trained. While there has been significant progress in self-training for image recognition, designing a self-training framework for the SGG task is more challenging due to its inherent nature such as the semantic ambiguity and the long-tailed distribution of predicate classes. Hence, we propose a novel pseudo-labeling technique for SGG, called Class-specific Adaptive Thresholding with Momentum (CATM), which is a model-agnostic framework that can be applied to any existing SGG models. Furthermore, we devise a graph structure learner (GSL) that is beneficial when adopting our proposed self-training framework to the state-of-the-art message-passing neural network (MPNN)-based SGG models. Our extensive experiments verify the effectiveness of ST-SGG on various SGG models, particularly in enhancing the performance on fine-grained predicate classes.         ",
    "url": "https://arxiv.org/abs/2401.09786",
    "authors": [
      "Kibum Kim",
      "Kanghoon Yoon",
      "Yeonjun In",
      "Jinyoung Moon",
      "Donghyun Kim",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.11660",
    "title": "Differentiable Tree Search Network",
    "abstract": "           In decision-making problems with limited training data, policy functions approximated using deep neural networks often exhibit suboptimal performance. An alternative approach involves learning a world model from the limited data and determining actions through online search. However, the performance is adversely affected by compounding errors arising from inaccuracies in the learned world model. While methods like TreeQN have attempted to address these inaccuracies by incorporating algorithmic inductive biases into the neural network architectures, the biases they introduce are often weak and insufficient for complex decision-making tasks. In this work, we introduce Differentiable Tree Search Network (D-TSN), a novel neural network architecture that significantly strengthens the inductive bias by embedding the algorithmic structure of a best-first online search algorithm. D-TSN employs a learned world model to conduct a fully differentiable online search. The world model is jointly optimized with the search algorithm, enabling the learning of a robust world model and mitigating the effect of prediction inaccuracies. Further, we note that a naive incorporation of best-first search could lead to a discontinuous loss function in the parameter space. We address this issue by adopting a stochastic tree expansion policy, formulating search tree expansion as another decision-making task, and introducing an effective variance reduction technique for the gradient computation. We evaluate D-TSN in an offline-RL setting with a limited training data scenario on Procgen games and grid navigation task, and demonstrate that D-TSN outperforms popular model-free and model-based baselines.         ",
    "url": "https://arxiv.org/abs/2401.11660",
    "authors": [
      "Dixant Mittal",
      "Wee Sun Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.19879",
    "title": "MAC: Graph Sparsification by Maximizing Algebraic Connectivity",
    "abstract": "           Simultaneous localization and mapping (SLAM) is a critical capability in autonomous navigation, but memory and computational limits make long-term application of common SLAM techniques impractical; a robot must be able to determine what information should be retained and what can safely be forgotten. In graph-based SLAM, the number of edges (measurements) in a pose graph determines both the memory requirements of storing a robot's observations and the computational expense of algorithms deployed for performing state estimation using those observations, both of which can grow unbounded during long-term navigation. Motivated by these challenges, we propose a new general purpose approach to sparsify graphs in a manner that maximizes algebraic connectivity, a key spectral property of graphs which has been shown to control the estimation error of pose graph SLAM solutions. Our algorithm, MAC (for maximizing algebraic connectivity), is simple and computationally inexpensive, and admits formal post hoc performance guarantees on the quality of the solution that it provides. In application to the problem of pose-graph SLAM, we show on several benchmark datasets that our approach quickly produces high-quality sparsification results which retain the connectivity of the graph and, in turn, the quality of corresponding SLAM solutions.         ",
    "url": "https://arxiv.org/abs/2403.19879",
    "authors": [
      "Kevin Doherty",
      "Alan Papalia",
      "Yewei Huang",
      "David Rosen",
      "Brendan Englot",
      "John Leonard"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2404.12501",
    "title": "SPIdepth: Strengthened Pose Information for Self-supervised Monocular Depth Estimation",
    "abstract": "           Self-supervised monocular depth estimation has garnered considerable attention for its applications in autonomous driving and robotics. While recent methods have made strides in leveraging techniques like the Self Query Layer (SQL) to infer depth from motion, they often overlook the potential of strengthening pose information. In this paper, we introduce SPIdepth, a novel approach that prioritizes enhancing the pose network for improved depth estimation. Building upon the foundation laid by SQL, SPIdepth emphasizes the importance of pose information in capturing fine-grained scene structures. By enhancing the pose network's capabilities, SPIdepth achieves remarkable advancements in scene understanding and depth estimation. Experimental results on benchmark datasets such as KITTI, Cityscapes, and Make3D showcase SPIdepth's state-of-the-art performance, surpassing previous methods by significant margins. Specifically, SPIdepth tops the self-supervised KITTI benchmark. Additionally, SPIdepth achieves the lowest AbsRel (0.029), SqRel (0.069), and RMSE (1.394) on KITTI, establishing new state-of-the-art results. On Cityscapes, SPIdepth shows improvements over SQLdepth of 21.7% in AbsRel, 36.8% in SqRel, and 16.5% in RMSE, even without using motion masks. On Make3D, SPIdepth in zero-shot outperforms all other models. Remarkably, SPIdepth achieves these results using only a single image for inference, surpassing even methods that utilize video sequences for inference, thus demonstrating its efficacy and efficiency in real-world applications. Our approach represents a significant leap forward in self-supervised monocular depth estimation, underscoring the importance of strengthening pose information for advancing scene understanding in real-world applications.         ",
    "url": "https://arxiv.org/abs/2404.12501",
    "authors": [
      "Mykola Lavreniuk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2404.12631",
    "title": "Breaching the Bottleneck: Evolutionary Transition from Reward-Driven Learning to Reward-Agnostic Domain-Adapted Learning in Neuromodulated Neural Nets",
    "abstract": "           Advanced biological intelligence learns efficiently from an information-rich stream of stimulus information, even when feedback on behaviour quality is sparse or absent. Such learning exploits implicit assumptions about task domains. We refer to such learning as Domain-Adapted Learning (DAL). In contrast, AI learning algorithms rely on explicit externally provided measures of behaviour quality to acquire fit behaviour. This imposes an information bottleneck that precludes learning from diverse non-reward stimulus information, limiting learning efficiency. We consider the question of how biological evolution circumvents this bottleneck to produce DAL. We propose that species first evolve the ability to learn from reward signals, providing inefficient (bottlenecked) but broad adaptivity. From there, integration of non-reward information into the learning process can proceed via gradual accumulation of biases induced by such information on specific task domains. This scenario provides a biologically plausible pathway towards bottleneck-free, domain-adapted learning. Focusing on the second phase of this scenario, we set up a population of NNs with reward-driven learning modelled as Reinforcement Learning (A2C), and allow evolution to improve learning efficiency by integrating non-reward information into the learning process using a neuromodulatory update mechanism. On a navigation task in continuous 2D space, evolved DAL agents show a 300-fold increase in learning speed compared to pure RL agents. Evolution is found to eliminate reliance on reward information altogether, allowing DAL agents to learn from non-reward information exclusively, using local neuromodulation-based connection weight updates only. Code available at this http URL.         ",
    "url": "https://arxiv.org/abs/2404.12631",
    "authors": [
      "Solvi Arnold",
      "Reiji Suzuki",
      "Takaya Arita",
      "Kimitoshi Yamazaki"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2404.18849",
    "title": "MiPa: Mixed Patch Infrared-Visible Modality Agnostic Object Detection",
    "abstract": "           In real-world scenarios, using multiple modalities like visible (RGB) and infrared (IR) can greatly improve the performance of a predictive task such as object detection (OD). Multimodal learning is a common way to leverage these modalities, where multiple modality-specific encoders and a fusion module are used to improve performance. In this paper, we tackle a different way to employ RGB and IR modalities, where only one modality or the other is observed by a single shared vision encoder. This realistic setting requires a lower memory footprint and is more suitable for applications such as autonomous driving and surveillance, which commonly rely on RGB and IR data. However, when learning a single encoder on multiple modalities, one modality can dominate the other, producing uneven recognition results. This work investigates how to efficiently leverage RGB and IR modalities to train a common transformer-based OD vision encoder, while countering the effects of modality imbalance. For this, we introduce a novel training technique to Mix Patches (MiPa) from the two modalities, in conjunction with a patch-wise modality agnostic module, for learning a common representation of both modalities. Our experiments show that MiPa can learn a representation to reach competitive results on traditional RGB/IR benchmarks while only requiring a single modality during inference. Our code is available at: this https URL.         ",
    "url": "https://arxiv.org/abs/2404.18849",
    "authors": [
      "Heitor R. Medeiros",
      "David Latortue",
      "Eric Granger",
      "Marco Pedersoli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2405.03585",
    "title": "The Sociotechnical Stack: Opportunities for Social Computing Research in Non-consensual Intimate Media",
    "abstract": "           Non-consensual intimate media (NCIM) involves sharing intimate content without the depicted person's consent, including \"revenge porn\" and sexually explicit deepfakes. While NCIM has received attention in legal, psychological, and communication fields over the past decade, it is not sufficiently addressed in computing scholarship. This paper addresses this gap by linking NCIM harms to the specific technological components that facilitate them. We introduce the sociotechnical stack, a conceptual framework designed to map the technical stack to its corresponding social impacts. The sociotechnical stack allows us to analyze sociotechnical problems like NCIM, and points toward opportunities for computing research. We propose a research roadmap for computing and social computing communities to deter NCIM perpetration and support victim-survivors through building and rebuilding technologies.         ",
    "url": "https://arxiv.org/abs/2405.03585",
    "authors": [
      "Li Qiwei",
      "Allison McDonald",
      "Oliver L. Haimson",
      "Sarita Schoenebeck",
      "Eric Gilbert"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2405.05495",
    "title": "PARSAC: Fast, Human-quality Floorplanning for Modern SoCs with Complex Design Constraints",
    "abstract": "           The floorplanning of Systems-on-a-Chip (SoCs) and of chip sub-systems is a crucial step in the physical design flow as it determines the optimal shapes and locations of the blocks that make up the system. Simulated Annealing (SA) has been the method of choice for tackling classical floorplanning problems where the objective is to minimize wire-length and the total placement area. The goal in industry-relevant floorplanning problems, however, is not only to minimize area and wire-length, but to do that while respecting hard placement constraints that specify the general area and/or the specific locations for the placement of some blocks. We show that simply incorporating these constraints into the SA objective function leads to sub-optimal, and often illegal, solutions. We propose the Constraints-Aware Simulated Annealing (CA-SA) method and show that it strongly outperforms vanilla SA in floorplanning problems with hard placement constraints. We developed a new floorplanning tool on top of CA-SA: PARSAC (Parallel Simulated Annealing with Constraints). PARSAC is an efficient, easy-to-use, and massively parallel floorplanner. Unlike current SA-based or learning-based floorplanning tools that cannot effectively incorporate hard placement-constraints, PARSAC can quickly construct the Pareto-optimal legal solutions front for constrained floorplanning problems. PARSAC also outperforms traditional SA on legacy floorplanning benchmarks. PARSAC is available as an open-source repository for researchers to replicate and build on our result.         ",
    "url": "https://arxiv.org/abs/2405.05495",
    "authors": [
      "Hesham Mostafa",
      "Uday Mallappa",
      "Mikhail Galkin",
      "Mariano Phielipp",
      "Somdeb Majumdar"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ]
  },
  {
    "id": "arXiv:2405.10912",
    "title": "Synthesis of Temporal Causality",
    "abstract": "           We present an automata-based algorithm to synthesize omega-regular causes for omega-regular effects on executions of a reactive system, such as counterexamples uncovered by a model checker. Our theory is a generalization of temporal causality, which has recently been proposed as a framework for drawing causal relationships between trace properties on a given trace. So far, algorithms exist only for verifying a single causal relationship and, as an extension, cause synthesis through enumeration, which is complete only for a small fragment of effect properties. This work presents the first complete cause-synthesis algorithm for the class of omega-regular effects. We show that in this case, causes are guaranteed to be omega-regular themselves and can be computed as, e.g., nondeterministic B\u00fcchi automata. We demonstrate the practical feasibility of this algorithm with a prototype tool and evaluate its performance for cause synthesis and cause checking.         ",
    "url": "https://arxiv.org/abs/2405.10912",
    "authors": [
      "Bernd Finkbeiner",
      "Hadar Frenkel",
      "Niklas Metzger",
      "Julian Siber"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2405.13071",
    "title": "A Novel Method for News Article Event-Based Embedding",
    "abstract": "           Embedding news articles is a crucial tool for multiple fields, such as media bias detection, identifying fake news, and making news recommendations. However, existing news embedding methods are not optimized to capture the latent context of news events. Most embedding methods rely on full-text information and neglect time-relevant embedding generation. In this paper, we propose a novel lightweight method that optimizes news embedding generation by focusing on entities and themes mentioned in articles and their historical connections to specific events. We suggest a method composed of three stages. First, we process and extract events, entities, and themes from the given news articles. Second, we generate periodic time embeddings for themes and entities by training time-separated GloVe models on current and historical data. Lastly, we concatenate the news embeddings generated by two distinct approaches: Smooth Inverse Frequency (SIF) for article-level vectors and Siamese Neural Networks for embeddings with nuanced event-related information. We leveraged over 850,000 news articles and 1,000,000 events from the GDELT project to test and evaluate our method. We conducted a comparative analysis of different news embedding generation methods for validation. Our experiments demonstrate that our approach can both improve and outperform state-of-the-art methods on shared event detection tasks.         ",
    "url": "https://arxiv.org/abs/2405.13071",
    "authors": [
      "Koren Ishlach",
      "Itzhak Ben-David",
      "Michael Fire",
      "Lior Rokach"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2405.13586",
    "title": "Bond Graphs for multi-physics informed Neural Networks for multi-variate time series",
    "abstract": "           In the trend of hybrid Artificial Intelligence techniques, Physical-Informed Machine Learning has seen a growing interest. It operates mainly by imposing data, learning, or architecture bias with simulation data, Partial Differential Equations, or equivariance and invariance properties. While it has shown great success on tasks involving one physical domain, such as fluid dynamics, existing methods are not adapted to tasks with complex multi-physical and multi-domain phenomena. In addition, it is mainly formulated as an end-to-end learning scheme. To address these challenges, we propose to leverage Bond Graphs, a multi-physics modeling approach, together with Message Passing Graph Neural Networks. We propose a Neural Bond graph Encoder (NBgE) producing multi-physics-informed representations that can be fed into any task-specific model. It provides a unified way to integrate both data and architecture biases in deep learning. Our experiments on two challenging multi-domain physical systems - a Direct Current Motor and the Respiratory System - demonstrate the effectiveness of our approach on a multivariate time-series forecasting task.         ",
    "url": "https://arxiv.org/abs/2405.13586",
    "authors": [
      "Alexis-Raja Brachet",
      "Pierre-Yves Richard",
      "C\u00e9line Hudelot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2406.01659",
    "title": "Limits of isotropic damage models for complex load paths -- beyond stress triaxiality and Lode angle parameter",
    "abstract": "           The stress triaxiality and the Lode angle parameter are two well established stress invariants for the characterization of damage evolution. This work assesses the limits of this tuple by using it for damage predictions in a continuum damage mechanics framework. Isotropic and anisotropic formulations of two well-established models are used to avoid model-specific restrictions. The damage evolution is analyzed for different load paths, while the stress triaxiality and the Lode angle parameter are controlled. The equivalent plastic strain is moreover added as a third parameter, but still does not suffice to uniquely define the damage state. As a consequence, well-established concepts such as fracture surfaces depending on this triple have to be taken with care, if complex paths are to be investgated. These include, e.g., load paths observed during metal forming applications with varying load directions or multiple stages.         ",
    "url": "https://arxiv.org/abs/2406.01659",
    "authors": [
      "K. Feike",
      "P. Kurzeja",
      "J. Mosler",
      "K. Langenfeld"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2407.02659",
    "title": "LLMs Plagiarize: Ensuring Responsible Sourcing of Large Language Model Training Data Through Knowledge Graph Comparison",
    "abstract": "           In light of recent legal allegations brought by publishers, newspapers, and other creators of copyrighted corpora against large language model developers who use their copyrighted materials for training or fine-tuning purposes, we propose a novel system, a variant of a plagiarism detection system, that assesses whether a knowledge source has been used in the training or fine-tuning of a large language model. Unlike current methods, we utilize an approach that uses Resource Description Framework (RDF) triples to create knowledge graphs from both a source document and an LLM continuation of that document. These graphs are then analyzed with respect to content using cosine similarity and with respect to structure using a normalized version of graph edit distance that shows the degree of isomorphism. Unlike traditional plagiarism systems that focus on content matching and keyword identification between a source and a target corpus, our approach enables a broader and more accurate evaluation of similarity between a source document and LLM continuation by focusing on relationships between ideas and their organization with regards to others. Additionally, our approach does not require access to LLM metrics like perplexity that may be unavailable in closed large language model \"black-box\" systems, as well as the training corpus. We thus assess whether an LLM has \"plagiarized\" a corpus in its continuation through similarity measures. A prototype of our system will be found on a hyperlinked GitHub repository.         ",
    "url": "https://arxiv.org/abs/2407.02659",
    "authors": [
      "Devam Mondal",
      "Carlo Lipizzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2407.15902",
    "title": "Revisiting the Robust Alignment of Circuit Breakers",
    "abstract": "           Over the past decade, adversarial training has emerged as one of the few reliable methods for enhancing model robustness against adversarial attacks [Szegedy et al., 2014, Madry et al., 2018, Xhonneux et al., 2024], while many alternative approaches have failed to withstand rigorous subsequent evaluations. Recently, an alternative defense mechanism, namely \"circuit breakers\" [Zou et al., 2024], has shown promising results for aligning LLMs. In this report, we show that the robustness claims of \"Improving Alignment and Robustness with Circuit Breakers\" against unconstraint continuous attacks in the embedding space of the input tokens may be overestimated [Zou et al., 2024]. Specifically, we demonstrate that by implementing a few simple changes to embedding space attacks [Schwinn et al., 2024a,b], we achieve 100% attack success rate (ASR) against circuit breaker models. Without conducting any further hyperparameter tuning, these adjustments increase the ASR by more than 80% compared to the original evaluation. Code is accessible at: this https URL ",
    "url": "https://arxiv.org/abs/2407.15902",
    "authors": [
      "Leo Schwinn",
      "Simon Geisler"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2407.19397",
    "title": "Domain Adaptive Lung Nodule Detection in X-ray Image",
    "abstract": "           Medical images from different healthcare centers exhibit varied data distributions, posing significant challenges for adapting lung nodule detection due to the domain shift between training and application phases. Traditional unsupervised domain adaptive detection methods often struggle with this shift, leading to suboptimal outcomes. To overcome these challenges, we introduce a novel domain adaptive approach for lung nodule detection that leverages mean teacher self-training and contrastive learning. First, we propose a hierarchical contrastive learning strategy to refine nodule representations and enhance the distinction between nodules and background. Second, we introduce a nodule-level domain-invariant feature learning (NDL) module to capture domain-invariant features through adversarial learning across different domains. Additionally, we propose a new annotated dataset of X-ray images to aid in advancing lung nodule detection research. Extensive experiments conducted on multiple X-ray datasets demonstrate the efficacy of our approach in mitigating domain shift impacts.         ",
    "url": "https://arxiv.org/abs/2407.19397",
    "authors": [
      "Haifeng Zhao",
      "Lixiang Jiang",
      "Leilei Ma",
      "Dengdi Sun",
      "Yanping Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2407.20240",
    "title": "Social and Ethical Risks Posed by General-Purpose LLMs for Settling Newcomers in Canada",
    "abstract": "           The non-profit settlement sector in Canada supports newcomers in achieving successful integration. This sector faces increasing operational pressures amidst rising immigration targets, which highlights a need for enhanced efficiency and innovation, potentially through reliable AI solutions. The ad-hoc use of general-purpose generative AI, such as ChatGPT, might become a common practice among newcomers and service providers to address this need. However, these tools are not tailored for the settlement domain and can have detrimental implications for immigrants and refugees. We explore the risks that these tools might pose on newcomers to first, warn against the unguarded use of generative AI, and second, to incentivize further research and development in creating AI literacy programs as well as customized LLMs that are aligned with the preferences of the impacted communities. Crucially, such technologies should be designed to integrate seamlessly into the existing workflow of the settlement sector, ensuring human oversight, trustworthiness, and accountability.         ",
    "url": "https://arxiv.org/abs/2407.20240",
    "authors": [
      "Isar Nejadgholi",
      "Maryam Molamohammadi",
      "Samir Bakhtawar"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2407.21310",
    "title": "MSMA: Multi-agent Trajectory Prediction in Connected and Autonomous Vehicle Environment with Multi-source Data Integration",
    "abstract": "           The prediction of surrounding vehicle trajectories is crucial for collision-free path planning. In this study, we focus on a scenario where a connected and autonomous vehicle (CAV) serves as the central agent, utilizing both sensors and communication technologies to perceive its surrounding traffics consisting of autonomous vehicles (AVs), connected vehicles (CVs), and human-driven vehicles (HDVs). Our trajectory prediction task is aimed at all the detected surrounding vehicles. To effectively integrate the multi-source data from both sensor and communication technologies, we propose a deep learning framework called MSMA utilizing a cross-attention module for multi-source data fusion. Vector map data is utilized to provide contextual information. The trajectory dataset is collected in CARLA simulator with synthesized data errors introduced. Numerical experiments demonstrate that in a mixed traffic flow scenario, the integration of data from different sources enhances our understanding of the environment. This notably improves trajectory prediction accuracy, particularly in situations with a high CV market penetration rate. The code is available at: this https URL.         ",
    "url": "https://arxiv.org/abs/2407.21310",
    "authors": [
      "Xi Chen",
      "Rahul Bhadani",
      "Zhanbo Sun",
      "Larry Head"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2407.21450",
    "title": "Forecasting Future Videos from Novel Views via Disentangled 3D Scene Representation",
    "abstract": "           Video extrapolation in space and time (VEST) enables viewers to forecast a 3D scene into the future and view it from novel viewpoints. Recent methods propose to learn an entangled representation, aiming to model layered scene geometry, motion forecasting and novel view synthesis together, while assuming simplified affine motion and homography-based warping at each scene layer, leading to inaccurate video extrapolation. Instead of entangled scene representation and rendering, our approach chooses to disentangle scene geometry from scene motion, via lifting the 2D scene to 3D point clouds, which enables high quality rendering of future videos from novel views. To model future 3D scene motion, we propose a disentangled two-stage approach that initially forecasts ego-motion and subsequently the residual motion of dynamic objects (e.g., cars, people). This approach ensures more precise motion predictions by reducing inaccuracies from entanglement of ego-motion with dynamic object motion, where better ego-motion forecasting could significantly enhance the visual outcomes. Extensive experimental analysis on two urban scene datasets demonstrate superior performance of our proposed method in comparison to strong baselines.         ",
    "url": "https://arxiv.org/abs/2407.21450",
    "authors": [
      "Sudhir Yarram",
      "Junsong Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.00374",
    "title": "Conformal Trajectory Prediction with Multi-View Data Integration in Cooperative Driving",
    "abstract": "           Current research on trajectory prediction primarily relies on data collected by onboard sensors of an ego vehicle. With the rapid advancement in connected technologies, such as vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communication, valuable information from alternate views becomes accessible via wireless networks. The integration of information from alternative views has the potential to overcome the inherent limitations associated with a single viewpoint, such as occlusions and limited field of view. In this work, we introduce V2INet, a novel trajectory prediction framework designed to model multi-view data by extending existing single-view models. Unlike previous approaches where the multi-view data is manually fused or formulated as a separate training stage, our model supports end-to-end training, enhancing both flexibility and performance. Moreover, the predicted multimodal trajectories are calibrated by a post-hoc conformal prediction module to get valid and efficient confidence regions. We evaluated the entire framework using the real-world V2I dataset V2X-Seq. Our results demonstrate superior performance in terms of Final Displacement Error (FDE) and Miss Rate (MR) using a single GPU. The code is publicly available at: \\url{this https URL}.         ",
    "url": "https://arxiv.org/abs/2408.00374",
    "authors": [
      "Xi Chen",
      "Rahul Bhadani",
      "Larry Head"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.00655",
    "title": "SentenceVAE: Faster, Longer and More Accurate Inference with Next-sentence Prediction for Large Language Models",
    "abstract": "           Contemporary large language models (LLMs) primarily rely on next-token prediction method for inference, which significantly impedes their processing speed. In this paper, we introduce a novel inference methodology termed next-sentence prediction, aimed at enhancing the inference efficiency of LLMs. We present Sentence Variational Autoencoder (SentenceVAE), a tiny model consisting of a Sentence Encoder and a Sentence Decoder. The encoder effectively condenses the information within a sentence into a singular token, while the decoder reconstructs this compressed data back into its original sentential form. By integrating SentenceVAE into the input and output layers of LLMs, we develop Sentence-level LLMs (SLLMs) that employ a sentence-by-sentence inference approach, markedly accelerating inference speeds. SentenceVAE also maintains the integrity of the original semantic content by segmenting the text into sentences, thereby improving accuracy while boosting inference speeds. Compared to published LLMs, SLLMs process fewer tokens over equivalent context lengths, significantly reducing memory demands for self-attention computations and facilitating the handling of longer contexts. Our experimental findings reveal that this method can accelerate inference speeds by 204~365%, reduce perplexity (PPL) to 46~75% of its original metric, and decrease memory overhead by 86~91% for the same context length, compared to the token-by-token method. Moreover, the benefits of this approach become even more pronounced as model parameters increase.         ",
    "url": "https://arxiv.org/abs/2408.00655",
    "authors": [
      "Hongjun An",
      "Yifan Chen",
      "Xiaozhen Qiao",
      "Zhe Sun",
      "Xuelong Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2010.15727",
    "title": "Amortized Probabilistic Detection of Communities in Graphs",
    "abstract": "           Learning community structures in graphs has broad applications across scientific domains. While graph neural networks (GNNs) have been successful in encoding graph structures, existing GNN-based methods for community detection are limited by requiring knowledge of the number of communities in advance, in addition to lacking a proper probabilistic formulation to handle uncertainty. We propose a simple framework for amortized community detection, which addresses both of these issues by combining the expressive power of GNNs with recent methods for amortized clustering. Our models consist of a graph representation backbone that extracts structural information and an amortized clustering network that naturally handles variable numbers of clusters. Both components combine into well-defined models of the posterior distribution of graph communities and are jointly optimized given labeled graphs. At inference time, the models yield parallel samples from the posterior of community labels, quantifying uncertainty in a principled way. We evaluate several models from our framework on synthetic and real datasets, and demonstrate improved performance compared to previous methods. As a separate contribution, we extend recent amortized probabilistic clustering architectures by adding attention modules, which yield further improvements on community detection tasks.         ",
    "url": "https://arxiv.org/abs/2010.15727",
    "authors": [
      "Yueqi Wang",
      "Yoonho Lee",
      "Pallab Basu",
      "Juho Lee",
      "Yee Whye Teh",
      "Liam Paninski",
      "Ari Pakman"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.15501",
    "title": "Doubly Robust Interval Estimation for Optimal Policy Evaluation in Online Learning",
    "abstract": "           Evaluating the performance of an ongoing policy plays a vital role in many areas such as medicine and economics, to provide crucial instructions on the early-stop of the online experiment and timely feedback from the environment. Policy evaluation in online learning thus attracts increasing attention by inferring the mean outcome of the optimal policy (i.e., the value) in real-time. Yet, such a problem is particularly challenging due to the dependent data generated in the online environment, the unknown optimal policy, and the complex exploration and exploitation trade-off in the adaptive experiment. In this paper, we aim to overcome these difficulties in policy evaluation for online learning. We explicitly derive the probability of exploration that quantifies the probability of exploring non-optimal actions under commonly used bandit algorithms. We use this probability to conduct valid inference on the online conditional mean estimator under each action and develop the doubly robust interval estimation (DREAM) method to infer the value under the estimated optimal policy in online learning. The proposed value estimator provides double protection for consistency and is asymptotically normal with a Wald-type confidence interval provided. Extensive simulation studies and real data applications are conducted to demonstrate the empirical validity of the proposed DREAM method.         ",
    "url": "https://arxiv.org/abs/2110.15501",
    "authors": [
      "Ye Shen",
      "Hengrui Cai",
      "Rui Song"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2301.13557",
    "title": "On locating and neighbor-locating colorings of sparse graphs",
    "abstract": "           A proper $k$-coloring of a graph $G$ is a \\emph{neighbor-locating $k$-coloring} if for each pair of vertices in the same color class, the two sets of colors found in their respective neighborhoods are different. The \\textit{neighbor-locating chromatic number} $\\chi_{NL}(G)$ is the minimum $k$ for which $G$ admits a neighbor-locating $k$-coloring. A proper $k$-vertex-coloring of a graph $G$ is a \\emph{locating $k$-coloring} if for each pair of vertices $x$ and $y$ in the same color-class, there exists a color class $S_i$ such that $d(x,S_i)\\neq d(y,S_i)$. The locating chromatic number $\\chi_{L}(G)$ is the minimum $k$ for which $G$ admits a locating $k$-coloring. Our main results concern the largest possible order of a sparse graph of given neighbor-locating chromatic number. More precisely, we prove that if $G$ has order $n$, neighbor-locating chromatic number $k$ and average degree at most $2a$, where $2a\\le k-1$ is a positive integer, then $n$ is upper-bounded by $\\mathcal{O}(a^2(k^{2a+1}))$. We also design a family of graphs of bounded maximum degree whose order is close to reaching this upper bound. Our upper bound generalizes two previous bounds from the literature, which were obtained for graphs of bounded maximum degree and graphs of bounded cycle rank, respectively. Also, we prove that determining whether $\\chi_L(G)\\le k$ and $\\chi_{NL}(G)\\le k$ are NP-complete for sparse graphs: more precisely, for graphs with average degree at most 7, maximum average degree at most 20 and that are $4$-partite. We also study the possible relation between the ordinary chromatic number, the locating chromatic number and the neighbor-locating chromatic number of a graph.         ",
    "url": "https://arxiv.org/abs/2301.13557",
    "authors": [
      "Dipayan Chakraborty",
      "Florent Foucaud",
      "Soumen Nandi",
      "Sagnik Sen",
      "D K Supraja"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2308.11635",
    "title": "Semi-Supervised Dual-Stream Self-Attentive Adversarial Graph Contrastive Learning for Cross-Subject EEG-based Emotion Recognition",
    "abstract": "           Electroencephalography (EEG) is an objective tool for emotion recognition with promising applications. However, the scarcity of labeled data remains a major challenge in this field, limiting the widespread use of EEG-based emotion recognition. In this paper, a semi-supervised Dual-stream Self-Attentive Adversarial Graph Contrastive learning framework (termed as DS-AGC) is proposed to tackle the challenge of limited labeled data in cross-subject EEG-based emotion recognition. The DS-AGC framework includes two parallel streams for extracting non-structural and structural EEG features. The non-structural stream incorporates a semi-supervised multi-domain adaptation method to alleviate distribution discrepancy among labeled source domain, unlabeled source domain, and unknown target domain. The structural stream develops a graph contrastive learning method to extract effective graph-based feature representation from multiple EEG channels in a semi-supervised manner. Further, a self-attentive fusion module is developed for feature fusion, sample selection, and emotion recognition, which highlights EEG features more relevant to emotions and data samples in the labeled source domain that are closer to the target domain. Extensive experiments conducted on two benchmark databases (SEED and SEED-IV) using a semi-supervised cross-subject leave-one-subject-out cross-validation evaluation scheme show that the proposed model outperforms existing methods under different incomplete label conditions (with an average improvement of 5.83% on SEED and 6.99% on SEED-IV), demonstrating its effectiveness in addressing the label scarcity problem in cross-subject EEG-based emotion recognition.         ",
    "url": "https://arxiv.org/abs/2308.11635",
    "authors": [
      "Weishan Ye",
      "Zhiguo Zhang",
      "Fei Teng",
      "Min Zhang",
      "Jianhong Wang",
      "Dong Ni",
      "Fali Li",
      "Peng Xu",
      "Zhen Liang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.02529",
    "title": "ReLUs Are Sufficient for Learning Implicit Neural Representations",
    "abstract": "           Motivated by the growing theoretical understanding of neural networks that employ the Rectified Linear Unit (ReLU) as their activation function, we revisit the use of ReLU activation functions for learning implicit neural representations (INRs). Inspired by second order B-spline wavelets, we incorporate a set of simple constraints to the ReLU neurons in each layer of a deep neural network (DNN) to remedy the spectral bias. This in turn enables its use for various INR tasks. Empirically, we demonstrate that, contrary to popular belief, one can learn state-of-the-art INRs based on a DNN composed of only ReLU neurons. Next, by leveraging recent theoretical works which characterize the kinds of functions ReLU neural networks learn, we provide a way to quantify the regularity of the learned function. This offers a principled approach to selecting the hyperparameters in INR architectures. We substantiate our claims through experiments in signal representation, super resolution, and computed tomography, demonstrating the versatility and effectiveness of our method. The code for all experiments can be found at this https URL.         ",
    "url": "https://arxiv.org/abs/2406.02529",
    "authors": [
      "Joseph Shenouda",
      "Yamin Zhou",
      "Robert D. Nowak"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.02652",
    "title": "RepCNN: Micro-sized, Mighty Models for Wakeword Detection",
    "abstract": "           Always-on machine learning models require a very low memory and compute footprint. Their restricted parameter count limits the model's capacity to learn, and the effectiveness of the usual training algorithms to find the best parameters. Here we show that a small convolutional model can be better trained by first refactoring its computation into a larger redundant multi-branched architecture. Then, for inference, we algebraically re-parameterize the trained model into the single-branched form with fewer parameters for a lower memory footprint and compute cost. Using this technique, we show that our always-on wake-word detector model, RepCNN, provides a good trade-off between latency and accuracy during inference. RepCNN re-parameterized models are 43% more accurate than a uni-branch convolutional model while having the same runtime. RepCNN also meets the accuracy of complex architectures like BC-ResNet, while having 2x lesser peak memory usage and 10x faster runtime.         ",
    "url": "https://arxiv.org/abs/2406.02652",
    "authors": [
      "Arnav Kundu",
      "Prateeth Nayak",
      "Priyanka Padmanabhan",
      "Devang Naik"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.08782",
    "title": "Hybrid Spatial-spectral Neural Network for Hyperspectral Image Denoising",
    "abstract": "           Hyperspectral image (HSI) denoising is an essential procedure for HSI applications. Unfortunately, the existing Transformer-based methods mainly focus on non-local modeling, neglecting the importance of locality in image denoising. Moreover, deep learning methods employ complex spectral learning mechanisms, thus introducing large computation costs. To address these problems, we propose a hybrid spatial-spectral denoising network (HSSD), in which we design a novel hybrid dual-path network inspired by CNN and Transformer characteristics, leading to capturing both local and non-local spatial details while suppressing noise efficiently. Furthermore, to reduce computational complexity, we adopt a simple but effective decoupling strategy that disentangles the learning of space and spectral channels, where multilayer perception with few parameters is utilized to learn the global correlations among spectra. The synthetic and real experiments demonstrate that our proposed method outperforms state-of-the-art methods on spatial and spectral reconstruction. The code and details are available on this https URL.         ",
    "url": "https://arxiv.org/abs/2406.08782",
    "authors": [
      "Hao Liang",
      "Chengjie",
      "Kun Li",
      "Xin Tian"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2407.08092",
    "title": "Extending DD-$\\alpha$AMG on heterogeneous machines",
    "abstract": "           Multigrid solvers are the standard in modern scientific computing simulations. Domain Decomposition Aggregation-Based Algebraic Multigrid, also known as the DD-$\\alpha$AMG solver, is a successful realization of an algebraic multigrid solver for lattice quantum chromodynamics. Its CPU implementation has made it possible to construct, for some particular discretizations, simulations otherwise computationally unfeasible, and furthermore it has motivated the development and improvement of other algebraic multigrid solvers in the area. From an existing version of DD-$\\alpha$AMG already partially ported via CUDA to run some finest-level operations of the multigrid solver on Nvidia GPUs, we translate the CUDA code here by using HIP to run on the ORISE supercomputer. We moreover extend the smoothers available in DD-$\\alpha$AMG, paying particular attention to Richardson smoothing, which in our numerical experiments has led to a multigrid solver faster than smoothing with GCR and only 10% slower compared to SAP smoothing. Then we port the odd-even-preconditioned versions of GMRES and Richardson via CUDA. Finally, we extend some computationally intensive coarse-grid operations via advanced vectorization.         ",
    "url": "https://arxiv.org/abs/2407.08092",
    "authors": [
      "Lianhua He",
      "Gustavo Ramirez-Hidalgo",
      "Ke-Long Zhang"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ]
  }
]