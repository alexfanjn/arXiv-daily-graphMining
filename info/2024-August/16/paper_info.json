[
  {
    "id": "arXiv:2408.07705",
    "title": "Enhancing Supply Chain Visibility with Knowledge Graphs and Large Language Models",
    "abstract": "           In today's globalized economy, comprehensive supply chain visibility is crucial for effective risk management. Achieving visibility remains a significant challenge due to limited information sharing among supply chain partners. This paper presents a novel framework leveraging Knowledge Graphs (KGs) and Large Language Models (LLMs) to enhance supply chain visibility without relying on direct stakeholder information sharing. Our zero-shot, LLM-driven approach automates the extraction of supply chain information from diverse public sources and constructs KGs to capture complex interdependencies between supply chain entities. We employ zero-shot prompting for Named Entity Recognition (NER) and Relation Extraction (RE) tasks, eliminating the need for extensive domain-specific training. We validate the framework with a case study on electric vehicle supply chains, focusing on tracking critical minerals for battery manufacturing. Results show significant improvements in supply chain mapping, extending visibility beyond tier-2 suppliers. The framework reveals critical dependencies and alternative sourcing options, enhancing risk management and strategic planning. With high accuracy in NER and RE tasks, it provides an effective tool for understanding complex, multi-tiered supply networks. This research offers a scalable, flexible method for constructing domain-specific supply chain KGs, addressing longstanding challenges in visibility and paving the way for advancements in digital supply chain surveillance.         ",
    "url": "https://arxiv.org/abs/2408.07705",
    "authors": [
      "Sara AlMahri",
      "Liming Xu",
      "Alexandra Brintrup"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2408.07718",
    "title": "Impact of Inaccurate Contamination Ratio on Robust Unsupervised Anomaly Detection",
    "abstract": "           Training data sets intended for unsupervised anomaly detection, typically presumed to be anomaly-free, often contain anomalies (or contamination), a challenge that significantly undermines model performance. Most robust unsupervised anomaly detection models rely on contamination ratio information to tackle contamination. However, in reality, contamination ratio may be inaccurate. We investigate on the impact of inaccurate contamination ratio information in robust unsupervised anomaly detection. We verify whether they are resilient to misinformed contamination ratios. Our investigation on 6 benchmark data sets reveals that such models are not adversely affected by exposure to misinformation. In fact, they can exhibit improved performance when provided with such inaccurate contamination ratios.         ",
    "url": "https://arxiv.org/abs/2408.07718",
    "authors": [
      "Jordan F. Masakuna",
      "DJeff Kanda Nkashama",
      "Arian Soltani",
      "Marc Frappier",
      "Pierre-Martin Tardif",
      "Froduald Kabanza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.07719",
    "title": "Operator Feature Neural Network for Symbolic Regression",
    "abstract": "           Symbolic regression is a task aimed at identifying patterns in data and representing them through mathematical expressions, generally involving skeleton prediction and constant optimization. Many methods have achieved some success, however they treat variables and symbols merely as characters of natural language without considering their mathematical essence. This paper introduces the operator feature neural network (OF-Net) which employs operator representation for expressions and proposes an implicit feature encoding method for the intrinsic mathematical operational logic of operators. By substituting operator features for numeric loss, we can predict the combination of operators of target expressions. We evaluate the model on public datasets, and the results demonstrate that the model achieves superior recovery rates and high $R^2$ scores. With the discussion of the results, we analyze the merit and demerit of OF-Net and propose optimizing schemes.         ",
    "url": "https://arxiv.org/abs/2408.07719",
    "authors": [
      "Yusong Deng",
      "Min Wu",
      "Lina Yu",
      "Jingyi Liu",
      "Shu Wei",
      "Yanjie Li",
      "Weijun Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.07720",
    "title": "Re-Thinking Process Mining in the AI-Based Agents Era",
    "abstract": "           Large Language Models (LLMs) have emerged as powerful conversational interfaces, and their application in process mining (PM) tasks has shown promising results. However, state-of-the-art LLMs struggle with complex scenarios that demand advanced reasoning capabilities. In the literature, two primary approaches have been proposed for implementing PM using LLMs: providing textual insights based on a textual abstraction of the process mining artifact, and generating code executable on the original artifact. This paper proposes utilizing the AI-Based Agents Workflow (AgWf) paradigm to enhance the effectiveness of PM on LLMs. This approach allows for: i) the decomposition of complex tasks into simpler workflows, and ii) the integration of deterministic tools with the domain knowledge of LLMs. We examine various implementations of AgWf and the types of AI-based tasks involved. Additionally, we discuss the CrewAI implementation framework and present examples related to process mining.         ",
    "url": "https://arxiv.org/abs/2408.07720",
    "authors": [
      "Alessandro Berti",
      "Mayssa Maatallah",
      "Urszula Jessen",
      "Michal Sroka",
      "Sonia Ayachi Ghannouchi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2408.07726",
    "title": "Graph neural network surrogate for strategic transport planning",
    "abstract": "           As the complexities of urban environments continue to grow, the modelling of transportation systems become increasingly challenging. This paper explores the application of advanced Graph Neural Network (GNN) architectures as surrogate models for strategic transport planning. Building upon a prior work that laid the foundation with graph convolution networks (GCN), our study delves into the comparative analysis of established GCN with the more expressive Graph Attention Network (GAT). Additionally, we propose a novel GAT variant (namely GATv3) to address over-smoothing issues in graph-based models. Our investigation also includes the exploration of a hybrid model combining both GCN and GAT architectures, aiming to investigate the performance of the mixture. The three models are applied to various experiments to understand their limits. We analyse hierarchical regression setups, combining classification and regression tasks, and introduce fine-grained classification with a proposal of a method to convert outputs to precise values. Results reveal the superior performance of the new GAT in classification tasks. To the best of the authors' knowledge, this is the first GAT model in literature to achieve larger depths. Surprisingly, the fine-grained classification task demonstrates the GCN's unexpected dominance with additional training data. This shows that synthetic data generators can increase the training data, without overfitting issues whilst improving model performance. In conclusion, this research advances GNN based surrogate modelling, providing insights for refining GNN architectures. The findings open avenues for investigating the potential of the newly proposed GAT architecture and the modelling setups for other transportation problems.         ",
    "url": "https://arxiv.org/abs/2408.07726",
    "authors": [
      "Nikita Makarov",
      "Santhanakrishnan Narayanan",
      "Constantinos Antoniou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.07729",
    "title": "Extending Network Intrusion Detection with Enhanced Particle Swarm Optimization Techniques",
    "abstract": "           The present research investigates how to improve Network Intrusion Detection Systems (NIDS) by combining Machine Learning (ML) and Deep Learning (DL) techniques, addressing the growing challenge of cybersecurity threats. A thorough process for data preparation, comprising activities like cleaning, normalization, and segmentation into training and testing sets, lays the framework for model training and evaluation. The study uses the CSE-CIC-IDS 2018 and LITNET-2020 datasets to compare ML methods (Decision Trees, Random Forest, XGBoost) and DL models (CNNs, RNNs, DNNs, MLP) against key performance metrics (Accuracy, Precision, Recall, and F1-Score). The Decision Tree model performed better across all measures after being fine-tuned with Enhanced Particle Swarm Optimization (EPSO), demonstrating the model's ability to detect network breaches effectively. The findings highlight EPSO's importance in improving ML classifiers for cybersecurity, proposing a strong framework for NIDS with high precision and dependability. This extensive analysis not only contributes to the cybersecurity arena by providing a road to robust intrusion detection solutions, but it also proposes future approaches for improving ML models to combat the changing landscape of network threats.         ",
    "url": "https://arxiv.org/abs/2408.07729",
    "authors": [
      "Surasit Songma",
      "Watcharakorn Netharn",
      "Siriluck Lorpunmanee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2408.07731",
    "title": "Polarization dynamics: a study of individuals shifting between political communities on social media",
    "abstract": "           Individuals engaging on social media often tend to establish online communities where interactions predominantly occur among like-minded peers. While considerable efforts have been devoted to studying and delineating these communities, there has been limited attention directed towards individuals who diverge from these patterns. In this study, we examine the community structure of re-post networks within the context of a polarized political environment at two different times. We specifically identify individuals who consistently switch between opposing communities and analyze the key features that distinguish them. Our investigation focuses on two crucial aspects of these users: the topological properties of their interactions and the political bias in the content of their posts. Our analysis is based on a dataset comprising 2 million tweets related to US President Donald Trump, coupled with data from over 100 000 individual user accounts spanning the 2020 US presidential election year. Our findings indicate that individuals who switch communities exhibit disparities compared to those who remain within the same communities, both in terms of the topological aspects of their interaction patterns (pagerank, degree, betweenness centrality.) and in the sentiment bias of their content towards Donald Trump.         ",
    "url": "https://arxiv.org/abs/2408.07731",
    "authors": [
      "Federico Albanese",
      "Esteban Feuerstein",
      "Pablo Balenzuela"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2408.07733",
    "title": "Enhancing Adversarial Attacks via Parameter Adaptive Adversarial Attack",
    "abstract": "           In recent times, the swift evolution of adversarial attacks has captured widespread attention, particularly concerning their transferability and other performance attributes. These techniques are primarily executed at the sample level, frequently overlooking the intrinsic parameters of models. Such neglect suggests that the perturbations introduced in adversarial samples might have the potential for further reduction. Given the essence of adversarial attacks is to impair model integrity with minimal noise on original samples, exploring avenues to maximize the utility of such perturbations is imperative. Against this backdrop, we have delved into the complexities of adversarial attack algorithms, dissecting the adversarial process into two critical phases: the Directional Supervision Process (DSP) and the Directional Optimization Process (DOP). While DSP determines the direction of updates based on the current samples and model parameters, it has been observed that existing model parameters may not always be conducive to adversarial attacks. The impact of models on adversarial efficacy is often overlooked in current research, leading to the neglect of DSP. We propose that under certain conditions, fine-tuning model parameters can significantly enhance the quality of DSP. For the first time, we propose that under certain conditions, fine-tuning model parameters can significantly improve the quality of the DSP. We provide, for the first time, rigorous mathematical definitions and proofs for these conditions, and introduce multiple methods for fine-tuning model parameters within DSP. Our extensive experiments substantiate the effectiveness of the proposed P3A method. Our code is accessible at: https://anonymous.4open.science/r/P3A-A12C/         ",
    "url": "https://arxiv.org/abs/2408.07733",
    "authors": [
      "Zhibo Jin",
      "Jiayu Zhang",
      "Zhiyu Zhu",
      "Chenyu Zhang",
      "Jiahao Huang",
      "Jianlong Zhou",
      "Fang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2408.07776",
    "title": "Knowledge-based Neural Ordinary Differential Equations for Cosserat Rod-based Soft Robots",
    "abstract": "           Soft robots have many advantages over rigid robots thanks to their compliant and passive nature. However, it is generally challenging to model the dynamics of soft robots due to their high spatial dimensionality, making it difficult to use model-based methods to accurately control soft robots. It often requires direct numerical simulation of partial differential equations to simulate soft robots. This not only requires an accurate numerical model, but also makes soft robot modeling slow and expensive. Deep learning algorithms have shown promises in data-driven modeling of soft robots. However, these algorithms usually require a large amount of data, which are difficult to obtain in either simulation or real-world experiments of soft robots. In this work, we propose KNODE-Cosserat, a framework that combines first-principle physics models and neural ordinary differential equations. We leverage the best from both worlds -- the generalization ability of physics-based models and the fast speed of deep learning methods. We validate our framework in both simulation and real-world experiments. In both cases, we show that the robot model significantly improves over the baseline models under different metrics.         ",
    "url": "https://arxiv.org/abs/2408.07776",
    "authors": [
      "Tom Z. Jiahao",
      "Ryan Adolf",
      "Cynthia Sung",
      "M. Ani Hsieh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.07785",
    "title": "NeuroPapyri: A Deep Attention Embedding Network for Handwritten Papyri Retrieval",
    "abstract": "           The intersection of computer vision and machine learning has emerged as a promising avenue for advancing historical research, facilitating a more profound exploration of our past. However, the application of machine learning approaches in historical palaeography is often met with criticism due to their perceived ``black box'' nature. In response to this challenge, we introduce NeuroPapyri, an innovative deep learning-based model specifically designed for the analysis of images containing ancient Greek papyri. To address concerns related to transparency and interpretability, the model incorporates an attention mechanism. This attention mechanism not only enhances the model's performance but also provides a visual representation of the image regions that significantly contribute to the decision-making process. Specifically calibrated for processing images of papyrus documents with lines of handwritten text, the model utilizes individual attention maps to inform the presence or absence of specific characters in the input image. This paper presents the NeuroPapyri model, including its architecture and training methodology. Results from the evaluation demonstrate NeuroPapyri's efficacy in document retrieval, showcasing its potential to advance the analysis of historical manuscripts.         ",
    "url": "https://arxiv.org/abs/2408.07785",
    "authors": [
      "Giuseppe De Gregorio",
      "Simon Perrin",
      "Rodrigo C. G. Pena",
      "Isabelle Marthot-Santaniello",
      "Harold Mouch\u00e8re"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2408.07815",
    "title": "Algebraic Representations for Faster Predictions in Convolutional Neural Networks",
    "abstract": "           Convolutional neural networks (CNNs) are a popular choice of model for tasks in computer vision. When CNNs are made with many layers, resulting in a deep neural network, skip connections may be added to create an easier gradient optimization problem while retaining model expressiveness. In this paper, we show that arbitrarily complex, trained, linear CNNs with skip connections can be simplified into a single-layer model, resulting in greatly reduced computational requirements during prediction time. We also present a method for training nonlinear models with skip connections that are gradually removed throughout training, giving the benefits of skip connections without requiring computational overhead during during prediction time. These results are demonstrated with practical examples on Residual Networks (ResNet) architecture.         ",
    "url": "https://arxiv.org/abs/2408.07815",
    "authors": [
      "Johnny Joyce",
      "Jan Verschelde"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Symbolic Computation (cs.SC)"
    ]
  },
  {
    "id": "arXiv:2408.07817",
    "title": "MyoGestic: EMG Interfacing Framework for Decoding Multiple Spared Degrees of Freedom of the Hand in Individuals with Neural Lesions",
    "abstract": "           Restoring limb motor function in individuals with spinal cord injury (SCI), stroke, or amputation remains a critical challenge, one which affects millions worldwide. Recent studies show through surface electromyography (EMG) that spared motor neurons can still be voluntarily controlled, even without visible limb movement . These signals can be decoded and used for motor intent estimation; however, current wearable solutions lack the necessary hardware and software for intuitive interfacing of the spared degrees of freedom after neural injuries. To address these limitations, we developed a wireless, high-density EMG bracelet, coupled with a novel software framework, MyoGestic. Our system allows rapid and tailored adaptability of machine learning models to the needs of the users, facilitating real-time decoding of multiple spared distinctive degrees of freedom. In our study, we successfully decoded the motor intent from two participants with SCI, two with spinal stroke , and three amputees in real-time, achieving several controllable degrees of freedom within minutes after wearing the EMG bracelet. We provide a proof-of-concept that these decoded signals can be used to control a digitally rendered hand, a wearable orthosis, a prosthesis, or a 2D cursor. Our framework promotes a participant-centered approach, allowing immediate feedback integration, thus enhancing the iterative development of myocontrol algorithms. The proposed open-source software framework, MyoGestic, allows researchers and patients to focus on the augmentation and training of the spared degrees of freedom after neural lesions, thus potentially bridging the gap between research and clinical application and advancing the development of intuitive EMG interfaces for diverse neural lesions.         ",
    "url": "https://arxiv.org/abs/2408.07817",
    "authors": [
      "Raul C. S\u00eempetru",
      "Dominik I. Braun",
      "Arndt U. Simon",
      "Michael M\u00e4rz",
      "Vlad Cnejevici",
      "Daniela Souza de Oliveira",
      "Nico Weber",
      "Jonas Walter",
      "J\u00f6rg Franke",
      "Daniel H\u00f6glinger",
      "Cosima Prahm",
      "Matthias Ponfick",
      "Alessandro Del Vecchio"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2408.07819",
    "title": "Regularized Contrastive Partial Multi-view Outlier Detection",
    "abstract": "           In recent years, multi-view outlier detection (MVOD) methods have advanced significantly, aiming to identify outliers within multi-view datasets. A key point is to better detect class outliers and class-attribute outliers, which only exist in multi-view data. However, existing methods either is not able to reduce the impact of outliers when learning view-consistent information, or struggle in cases with varying neighborhood structures. Moreover, most of them do not apply to partial multi-view data in real-world scenarios. To overcome these drawbacks, we propose a novel method named Regularized Contrastive Partial Multi-view Outlier Detection (RCPMOD). In this framework, we utilize contrastive learning to learn view-consistent information and distinguish outliers by the degree of consistency. Specifically, we propose (1) An outlier-aware contrastive loss with a potential outlier memory bank to eliminate their bias motivated by a theoretical analysis. (2) A neighbor alignment contrastive loss to capture the view-shared local structural correlation. (3) A spreading regularization loss to prevent the model from overfitting over outliers. With the Cross-view Relation Transfer technique, we could easily impute the missing view samples based on the features of neighbors. Experimental results on four benchmark datasets demonstrate that our proposed approach could outperform state-of-the-art competitors under different settings.         ",
    "url": "https://arxiv.org/abs/2408.07819",
    "authors": [
      "Yijia Wang",
      "Qianqian Xu",
      "Yangbangyan Jiang",
      "Siran Dai",
      "Qingming Huang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.07840",
    "title": "ONSEP: A Novel Online Neural-Symbolic Framework for Event Prediction Based on Large Language Model",
    "abstract": "           In the realm of event prediction, temporal knowledge graph forecasting (TKGF) stands as a pivotal technique. Previous approaches face the challenges of not utilizing experience during testing and relying on a single short-term history, which limits adaptation to evolving data. In this paper, we introduce the Online Neural-Symbolic Event Prediction (ONSEP) framework, which innovates by integrating dynamic causal rule mining (DCRM) and dual history augmented generation (DHAG). DCRM dynamically constructs causal rules from real-time data, allowing for swift adaptation to new causal relationships. In parallel, DHAG merges short-term and long-term historical contexts, leveraging a bi-branch approach to enrich event prediction. Our framework demonstrates notable performance enhancements across diverse datasets, with significant Hit@k (k=1,3,10) improvements, showcasing its ability to augment large language models (LLMs) for event prediction without necessitating extensive retraining. The ONSEP framework not only advances the field of TKGF but also underscores the potential of neural-symbolic approaches in adapting to dynamic data environments.         ",
    "url": "https://arxiv.org/abs/2408.07840",
    "authors": [
      "Xuanqing Yu",
      "Wangtao Sun",
      "Jingwei Li",
      "Kang Liu",
      "Chengbao Liu",
      "Jie Tan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Symbolic Computation (cs.SC)"
    ]
  },
  {
    "id": "arXiv:2408.07862",
    "title": "Zero Day Ransomware Detection with Pulse: Function Classification with Transformer Models and Assembly Language",
    "abstract": "           Finding automated AI techniques to proactively defend against malware has become increasingly critical. The ability of an AI model to correctly classify novel malware is dependent on the quality of the features it is trained with and the authenticity of the features is dependent on the analysis tool. Peekaboo, a Dynamic Binary Instrumentation tool defeats evasive malware to capture its genuine behavior. The ransomware Assembly instructions captured by Peekaboo, follow Zipf's law, a principle also observed in natural languages, indicating Transformer models are particularly well suited to binary classification. We propose Pulse, a novel framework for zero day ransomware detection with Transformer models and Assembly language. Pulse, trained with the Peekaboo ransomware and benign software data, uniquely identify truly new samples with high accuracy. Pulse eliminates any familiar functionality across the test and training samples, forcing the Transformer model to detect malicious behavior based solely on context and novel Assembly instruction combinations.         ",
    "url": "https://arxiv.org/abs/2408.07862",
    "authors": [
      "Matthew Gaber",
      "Mohiuddin Ahmed",
      "Helge Janicke"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2408.07869",
    "title": "A Systematic Evaluation of Generated Time Series and Their Effects in Self-Supervised Pretraining",
    "abstract": "           Self-supervised Pretrained Models (PTMs) have demonstrated remarkable performance in computer vision and natural language processing tasks. These successes have prompted researchers to design PTMs for time series data. In our experiments, most self-supervised time series PTMs were surpassed by simple supervised models. We hypothesize this undesired phenomenon may be caused by data scarcity. In response, we test six time series generation methods, use the generated data in pretraining in lieu of the real data, and examine the effects on classification performance. Our results indicate that replacing a real-data pretraining set with a greater volume of only generated samples produces noticeable improvement.         ",
    "url": "https://arxiv.org/abs/2408.07869",
    "authors": [
      "Audrey Der",
      "Chin-Chia Michael Yeh",
      "Xin Dai",
      "Huiyuan Chen",
      "Yan Zheng",
      "Yujie Fan",
      "Zhongfang Zhuang",
      "Vivian Lai",
      "Junpeng Wang",
      "Liang Wang",
      "Wei Zhang",
      "Eamonn Keogh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.07889",
    "title": "MambaVT: Spatio-Temporal Contextual Modeling for robust RGB-T Tracking",
    "abstract": "           Existing RGB-T tracking algorithms have made remarkable progress by leveraging the global interaction capability and extensive pre-trained models of the Transformer architecture. Nonetheless, these methods mainly adopt imagepair appearance matching and face challenges of the intrinsic high quadratic complexity of the attention mechanism, resulting in constrained exploitation of temporal information. Inspired by the recently emerged State Space Model Mamba, renowned for its impressive long sequence modeling capabilities and linear computational complexity, this work innovatively proposes a pure Mamba-based framework (MambaVT) to fully exploit spatio-temporal contextual modeling for robust visible-thermal tracking. Specifically, we devise the long-range cross-frame integration component to globally adapt to target appearance variations, and introduce short-term historical trajectory prompts to predict the subsequent target states based on local temporal location clues. Extensive experiments show the significant potential of vision Mamba for RGB-T tracking, with MambaVT achieving state-of-the-art performance on four mainstream benchmarks while requiring lower computational costs. We aim for this work to serve as a simple yet strong baseline, stimulating future research in this field. The code and pre-trained models will be made available.         ",
    "url": "https://arxiv.org/abs/2408.07889",
    "authors": [
      "Simiao Lai",
      "Chang Liu",
      "Jiawen Zhu",
      "Ben Kang",
      "Yang Liu",
      "Dong Wang",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.07900",
    "title": "Network analysis reveals news press landscape and asymmetric user polarization",
    "abstract": "           Unlike traditional media, online news platforms allow users to consume content that suits their tastes and to facilitate interactions with other people. However, as more personalized consumption of information and interaction with like-minded users increase, ideological bias can inadvertently increase and contribute to the formation of echo chambers, reinforcing the polarization of opinions. Although the structural characteristics of polarization among different ideological groups in online spaces have been extensively studied, research into how these groups emotionally interact with each other has not been as thoroughly explored. From this perspective, we investigate both structural and affective polarization between news media user groups on Naver News, South Korea's largest online news portal, during the period of 2022 Korean presidential election. By utilizing the dataset comprising 333,014 articles and over 36 million user comments, we uncover two distinct groups of users characterized by opposing political leanings and reveal significant bias and polarization among them. Additionally, we reveal the existence of echo chambers within co-commenting networks and investigate the asymmetric affective interaction patterns between the two polarized groups. Classification task of news media articles based on the distinct comment response patterns support the notion that different political groups may employ distinct communication strategies. Our approach based on network analysis on large-scale comment dataset offers novel insights into characteristics of user polarization in the online news platforms and the nuanced interaction nature between user groups.         ",
    "url": "https://arxiv.org/abs/2408.07900",
    "authors": [
      "Byunghwee Lee",
      "Hyo-sun Ryu",
      "Jae Kook Lee",
      "Hawoong Jeong",
      "Beom Jun Kim"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2408.07907",
    "title": "AIE: Auction Information Enhanced Framework for CTR Prediction in Online Advertising",
    "abstract": "           Click-Through Rate (CTR) prediction is a fundamental technique for online advertising recommendation and the complex online competitive auction process also brings many difficulties to CTR optimization. Recent studies have shown that introducing posterior auction information contributes to the performance of CTR prediction. However, existing work doesn't fully capitalize on the benefits of auction information and overlooks the data bias brought by the auction, leading to biased and suboptimal results. To address these limitations, we propose Auction Information Enhanced Framework (AIE) for CTR prediction in online advertising, which delves into the problem of insufficient utilization of auction signals and first reveals the auction bias. Specifically, AIE introduces two pluggable modules, namely Adaptive Market-price Auxiliary Module (AM2) and Bid Calibration Module (BCM), which work collaboratively to excavate the posterior auction signals better and enhance the performance of CTR prediction. Furthermore, the two proposed modules are lightweight, model-agnostic, and friendly to inference latency. Extensive experiments are conducted on a public dataset and an industrial dataset to demonstrate the effectiveness and compatibility of AIE. Besides, a one-month online A/B test in a large-scale advertising platform shows that AIE improves the base model by 5.76% and 2.44% in terms of eCPM and CTR, respectively.         ",
    "url": "https://arxiv.org/abs/2408.07907",
    "authors": [
      "Yang Yang",
      "Bo Chen",
      "Chenxu Zhu",
      "Menghui Zhu",
      "Xinyi Dai",
      "Huifeng Guo",
      "Muyu Zhang",
      "Zhenhua Dong",
      "Ruiming Tang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2408.07908",
    "title": "Time-Dependent VAE for Building Latent Factor from Visual Neural Activity with Complex Dynamics",
    "abstract": "           Seeking high-quality neural latent representations to reveal the intrinsic correlation between neural activity and behavior or sensory stimulation has attracted much interest. Currently, some deep latent variable models rely on behavioral information (e.g., movement direction and position) as an aid to build expressive embeddings while being restricted by fixed time scales. Visual neural activity from passive viewing lacks clearly correlated behavior or task information, and high-dimensional visual stimulation leads to intricate neural dynamics. To cope with such conditions, we propose Time-Dependent SwapVAE, following the approach of separating content and style spaces in Swap-VAE, on the basis of which we introduce state variables to construct conditional distributions with temporal dependence for the above two spaces. Our model progressively generates latent variables along neural activity sequences, and we apply self-supervised contrastive learning to shape its latent space. In this way, it can effectively analyze complex neural dynamics from sequences of arbitrary length, even without task or behavioral data as auxiliary inputs. We compare TiDe-SwapVAE with alternative models on synthetic data and neural data from mouse visual cortex. The results show that our model not only accurately decodes complex visual stimuli but also extracts explicit temporal neural dynamics, demonstrating that it builds latent representations more relevant to visual stimulation.         ",
    "url": "https://arxiv.org/abs/2408.07908",
    "authors": [
      "Liwei Huang",
      "ZhengYu Ma",
      "Liutao Yu",
      "Huihui Zhou",
      "Yonghong Tian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2408.07911",
    "title": "CEGRL-TKGR: A Causal Enhanced Graph Representation Learning Framework for Improving Temporal Knowledge Graph Extrapolation Reasoning",
    "abstract": "           Temporal knowledge graph reasoning (TKGR) is increasingly gaining attention for its ability to extrapolate new events from historical data, thereby enriching the inherently incomplete temporal knowledge graphs. Existing graph-based representation learning frameworks have made significant strides in developing evolving representations for both entities and relational embeddings. Despite these achievements, there's a notable tendency in these models to inadvertently learn biased data representations and mine spurious correlations, consequently failing to discern the causal relationships between events. This often leads to incorrect predictions based on these false correlations. To address this, we propose an innovative causal enhanced graph representation learning framework for TKGR (named CEGRL-TKGR). This framework introduces causal structures in graph-based representation learning to unveil the essential causal relationships between events, ultimately enhancing task performance. Specifically, we first disentangle the evolutionary representations of entities and relations in a temporal graph sequence into two distinct components, namely causal representations and confounding representations. Then, drawing on causal intervention theory, we advocate the utilization of causal representations for predictions, aiming to mitigate the effects of erroneous correlations caused by confounding features, thus achieving more robust and accurate predictions. Finally, extensive experimental results on six benchmark datasets demonstrate the superior performance of our model in the link prediction task.         ",
    "url": "https://arxiv.org/abs/2408.07911",
    "authors": [
      "Jinze Sun",
      "Yongpan Sheng",
      "Lirong He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.07921",
    "title": "Physics-Informed Neural Network for Predicting Out-of-Training-Range TCAD Solution with Minimized Domain Expertise",
    "abstract": "           Machine learning (ML) is promising in assisting technology computer-aided design (TCAD) simulations to alleviate difficulty in convergence and prolonged simulation time. While ML is widely used in TCAD, they either require access to the internal solver, require extensive domain expertise, are only trained by terminal quantities such as currents and voltages, and/or lack out-of-training-range prediction capability. In this paper, using Si nanowire as an example, we demonstrate that it is possible to use a physics-informed neural network (PINN) to predict out-of-training-range TCAD solutions without accessing the internal solver and with minimal domain expertise. The machine not only can predict a 2.5 times larger range than the training but also can predict the inversion region by only being trained with subthreshold region data. The physics-informed module is also trained with data without the need for human-coded equations making this easier to be extended to more sophisticated systems.         ",
    "url": "https://arxiv.org/abs/2408.07921",
    "authors": [
      "Albert Lu",
      "Yu Foon Chau",
      "Hiu Yung Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.07945",
    "title": "Solving a Rubik's Cube Using its Local Graph Structure",
    "abstract": "           The Rubix Cube is a 3-dimensional single-player combination puzzle attracting attention in the reinforcement learning community. A Rubix Cube has six faces and twelve possible actions, leading to a small and unconstrained action space and a very large state space with only one goal state. Modeling such a large state space and storing the information of each state requires exceptional computational resources, which makes it challenging to find the shortest solution to a scrambled Rubix cube with limited resources. The Rubix Cube can be represented as a graph, where states of the cube are nodes and actions are edges. Drawing on graph convolutional networks, we design a new heuristic, weighted convolutional distance, for A star search algorithm to find the solution to a scrambled Rubix Cube. This heuristic utilizes the information of neighboring nodes and convolves them with attention-like weights, which creates a deeper search for the shortest path to the solved state.         ",
    "url": "https://arxiv.org/abs/2408.07945",
    "authors": [
      "Shunyu Yao",
      "Mitchy Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.07956",
    "title": "RandomNet: Clustering Time Series Using Untrained Deep Neural Networks",
    "abstract": "           Neural networks are widely used in machine learning and data mining. Typically, these networks need to be trained, implying the adjustment of weights (parameters) within the network based on the input data. In this work, we propose a novel approach, RandomNet, that employs untrained deep neural networks to cluster time series. RandomNet uses different sets of random weights to extract diverse representations of time series and then ensembles the clustering relationships derived from these different representations to build the final clustering results. By extracting diverse representations, our model can effectively handle time series with different characteristics. Since all parameters are randomly generated, no training is required during the process. We provide a theoretical analysis of the effectiveness of the method. To validate its performance, we conduct extensive experiments on all of the 128 datasets in the well-known UCR time series archive and perform statistical analysis of the results. These datasets have different sizes, sequence lengths, and they are from diverse fields. The experimental results show that the proposed method is competitive compared with existing state-of-the-art methods.         ",
    "url": "https://arxiv.org/abs/2408.07956",
    "authors": [
      "Xiaosheng Li",
      "Wenjie Xi",
      "Jessica Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.07970",
    "title": "The Causal Complementation Algorithm for Lifting Factorization of Perfect Reconstruction Multirate Filter Banks",
    "abstract": "           An intrinsically causal approach to lifting factorization, called the Causal Complementation Algorithm, is developed for arbitrary two-channel perfect reconstruction FIR filter banks. This addresses an engineering shortcoming of the inherently noncausal strategy of Daubechies and Sweldens for factoring discrete wavelet transforms, which was based on the Extended Euclidean Algorithm for Laurent polynomials. The Causal Complementation Algorithm reproduces all lifting factorizations created by the causal version of the Euclidean Algorithm approach and generates additional causal factorizations, which are not obtainable via the causal Euclidean Algorithm, possessing degree-reducing properties that generalize those furnished by the Euclidean Algorithm. In lieu of the Euclidean Algorithm, the new approach employs Gaussian elimination in matrix polynomials using a slight generalization of polynomial long division. It is shown that certain polynomial degree-reducing conditions are both necessary and sufficient for a causal elementary matrix decomposition to be obtainable using the Causal Complementation Algorithm, yielding a formal definition of ``lifting factorization'' that was missing from the work of Daubechies and Sweldens.         ",
    "url": "https://arxiv.org/abs/2408.07970",
    "authors": [
      "Christopher M. Brislawn"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2408.07996",
    "title": "Monte Carlo Path Tracing and Statistical Event Detection for Event Camera Simulation",
    "abstract": "           This paper presents a novel event camera simulation system fully based on physically based Monte Carlo path tracing with adaptive path sampling. The adaptive sampling performed in the proposed method is based on a statistical technique, hypothesis testing for the hypothesis whether the difference of logarithmic luminances at two distant periods is significantly larger than a predefined event threshold. To this end, our rendering system collects logarithmic luminances rather than raw luminance in contrast to the conventional rendering system imitating conventional RGB cameras. Then, based on the central limit theorem, we reasonably assume that the distribution of the population mean of logarithmic luminance can be modeled as a normal distribution, allowing us to model the distribution of the difference of logarithmic luminance as a normal distribution. Then, using Student's t-test, we can test the hypothesis and determine whether to discard the null hypothesis for event non-occurrence. When we sample a sufficiently large number of path samples to satisfy the central limit theorem and obtain a clean set of events, our method achieves significant speed up compared to a simple approach of sampling paths uniformly at every pixel. To our knowledge, we are the first to simulate the behavior of event cameras in a physically accurate manner using an adaptive sampling technique in Monte Carlo path tracing, and we believe this study will contribute to the development of computer vision applications using event cameras.         ",
    "url": "https://arxiv.org/abs/2408.07996",
    "authors": [
      "Yuichiro Manabe",
      "Tatsuya Yatagawa",
      "Shigeo Morishima",
      "Hiroyuki Kubo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.07999",
    "title": "Co-Fix3D: Enhancing 3D Object Detection with Collaborative Refinement",
    "abstract": "           In the realm of autonomous driving,accurately detecting occluded or distant objects,referred to as weak positive sample ,presents significant challenges. These challenges predominantly arise during query initialization, where an over-reliance on heatmap confidence often results in a high rate of false positives, consequently masking weaker detections and impairing system performance. To alleviate this issue, we propose a novel approach, Co-Fix3D, which employs a collaborative hybrid multi-stage parallel query generation mechanism for BEV representations. Our method incorporates the Local-Global Feature Enhancement (LGE) module, which refines BEV features to more effectively highlight weak positive samples. It uniquely leverages the Discrete Wavelet Transform (DWT) for accurate noise reduction and features refinement in localized areas, and incorporates an attention mechanism to more comprehensively optimize global BEV features. Moreover, our method increases the volume of BEV queries through a multi-stage parallel processing of the LGE, significantly enhancing the probability of selecting weak positive samples. This enhancement not only improves training efficiency within the decoder framework but also boosts overall system performance. Notably, Co-Fix3D achieves superior results on the stringent nuScenes benchmark, outperforming all previous models with a 69.1% mAP and 72.9% NDS on the LiDAR-based benchmark, and 72.3% mAP and 74.1% NDS on the multi-modality benchmark, without relying on test-time augmentation or additional datasets. The source code will be made publicly available upon acceptance.         ",
    "url": "https://arxiv.org/abs/2408.07999",
    "authors": [
      "Wenxuan Li",
      "Qin Zou",
      "Chi Chen",
      "Bo Du",
      "Long Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.08005",
    "title": "Inversion-DeepONet: A Novel DeepONet-Based Network with Encoder-Decoder for Full Waveform Inversion",
    "abstract": "           Full waveform inversion (FWI) plays a crucial role in the field of geophysics. There has been lots of research about applying deep learning (DL) methods to FWI. The success of DL-FWI relies significantly on the quantity and diversity of the datasets. Nevertheless, existing FWI datasets, like OpenFWI, where sources have fixed locations or identical frequencies, provide limited information and do not represent the complex real-world scene. For instance, low frequencies help in resolving larger-scale structures. High frequencies allow for a more detailed subsurface features. %A single source frequency is insufficient to describe subsurface structural properties. We consider that simultaneously using sources with different frequencies, instead of performing inversion using low frequencies data and then gradually introducing higher frequencies data, has rationale and potential advantages. Hence, we develop three enhanced datasets based on OpenFWI where each source have varying locations, frequencies or both. Moreover, we propose a novel deep operator network (DeepONet) architecture Inversion-DeepONet for FWI. We utilize convolutional neural network (CNN) to extract the features from seismic data in branch net. Source parameters, such as locations and frequencies, are fed to trunk net. Then another CNN is employed as the decoder of DeepONet to reconstruct the velocity models more effectively. Through experiments, we confirm the superior performance on accuracy and generalization ability of our network, compared with existing data-driven FWI methods.         ",
    "url": "https://arxiv.org/abs/2408.08005",
    "authors": [
      "Zekai Guo",
      "Lihui Chai",
      "Shengjun Huang",
      "Ye Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.08013",
    "title": "Adaptive Learning of Consistency and Inconsistency Information for Fake News Detection",
    "abstract": "           The rapid advancement of social media platforms has significantly reduced the cost of information dissemination, yet it has also led to a proliferation of fake news, posing a threat to societal trust and credibility. Most of fake news detection research focused on integrating text and image information to represent the consistency of multiple modes in news content, while paying less attention to inconsistent information. Besides, existing methods that leveraged inconsistent information often caused one mode overshadowing another, leading to ineffective use of inconsistent clue. To address these issues, we propose an adaptive multi-modal feature fusion network (MFF-Net). Inspired by human judgment processes for determining truth and falsity in news, MFF-Net focuses on inconsistent parts when news content is generally consistent and consistent parts when it is generally inconsistent. Specifically, MFF-Net extracts semantic and global features from images and texts respectively, and learns consistency information between modes through a multiple feature fusion module. To deal with the problem of modal information being easily masked, we design a single modal feature filtering strategy to capture inconsistent information from corresponding modes separately. Finally, similarity scores are calculated based on global features with adaptive adjustments made to achieve weighted fusion of consistent and inconsistent features. Extensive experimental results demonstrate that MFF-Net outperforms state-of-the-art methods across three public news datasets derived from real social medias.         ",
    "url": "https://arxiv.org/abs/2408.08013",
    "authors": [
      "Aohan Li",
      "Jiaxin Chen",
      "Xin Liao",
      "Dengyong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.08015",
    "title": "Asteroid: Resource-Efficient Hybrid Pipeline Parallelism for Collaborative DNN Training on Heterogeneous Edge Devices",
    "abstract": "           On-device Deep Neural Network (DNN) training has been recognized as crucial for privacy-preserving machine learning at the edge. However, the intensive training workload and limited onboard computing resources pose significant challenges to the availability and efficiency of model training. While existing works address these challenges through native resource management optimization, we instead leverage our observation that edge environments usually comprise a rich set of accompanying trusted edge devices with idle resources beyond a single terminal. We propose Asteroid, a distributed edge training system that breaks the resource walls across heterogeneous edge devices for efficient model training acceleration. Asteroid adopts a hybrid pipeline parallelism to orchestrate distributed training, along with a judicious parallelism planning for maximizing throughput under certain resource constraints. Furthermore, a fault-tolerant yet lightweight pipeline replay mechanism is developed to tame the device-level dynamics for training robustness and performance stability. We implement Asteroid on heterogeneous edge devices with both vision and language models, demonstrating up to 12.2x faster training than conventional parallelism methods and 2.1x faster than state-of-the-art hybrid parallelism methods through evaluations. Furthermore, Asteroid can recover training pipeline 14x faster than baseline methods while preserving comparable throughput despite unexpected device exiting and failure.         ",
    "url": "https://arxiv.org/abs/2408.08015",
    "authors": [
      "Shengyuan Ye",
      "Liekang Zeng",
      "Xiaowen Chu",
      "Guoliang Xing",
      "Xu Chen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2408.08019",
    "title": "Accelerating High-Fidelity Waveform Generation via Adversarial Flow Matching Optimization",
    "abstract": "           This paper introduces PeriodWave-Turbo, a high-fidelity and high-efficient waveform generation model via adversarial flow matching optimization. Recently, conditional flow matching (CFM) generative models have been successfully adopted for waveform generation tasks, leveraging a single vector field estimation objective for training. Although these models can generate high-fidelity waveform signals, they require significantly more ODE steps compared to GAN-based models, which only need a single generation step. Additionally, the generated samples often lack high-frequency information due to noisy vector field estimation, which fails to ensure high-frequency reproduction. To address this limitation, we enhance pre-trained CFM-based generative models by incorporating a fixed-step generator modification. We utilized reconstruction losses and adversarial feedback to accelerate high-fidelity waveform generation. Through adversarial flow matching optimization, it only requires 1,000 steps of fine-tuning to achieve state-of-the-art performance across various objective metrics. Moreover, we significantly reduce inference speed from 16 steps to 2 or 4 steps. Additionally, by scaling up the backbone of PeriodWave from 29M to 70M parameters for improved generalization, PeriodWave-Turbo achieves unprecedented performance, with a perceptual evaluation of speech quality (PESQ) score of 4.454 on the LibriTTS dataset. Audio samples, source code and checkpoints will be available at this https URL.         ",
    "url": "https://arxiv.org/abs/2408.08019",
    "authors": [
      "Sang-Hoon Lee",
      "Ha-Yeong Choi",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2408.08020",
    "title": "Robust Maneuver Planning With Scalable Prediction Horizons: A Move Blocking Approach",
    "abstract": "           Implementation of Model Predictive Control (MPC) on hardware with limited computational resources remains a challenge. Especially for long-distance maneuvers that require small sampling times, the necessary horizon lengths prevent its application on onboard computers. In this paper, we propose a computationally efficient tubebased shrinking horizon MPC that is scalable to long prediction horizons. Using move blocking, we ensure that a given number of decision inputs is efficiently used throughout the maneuver. Next, a method to substantially reduce the number of constraints is introduced. The approach is demonstrated with a helicopter landing on an inclined platform using a prediction horizon of 300 steps. The constraint reduction decreases the computation time by an order of magnitude with a slight increase in trajectory cost.         ",
    "url": "https://arxiv.org/abs/2408.08020",
    "authors": [
      "Philipp Schitz",
      "Johann C. Dauer",
      "Paolo Mercorelli"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2408.08023",
    "title": "Causal Discovery from Time-Series Data with Short-Term Invariance-Based Convolutional Neural Networks",
    "abstract": "           Causal discovery from time-series data aims to capture both intra-slice (contemporaneous) and inter-slice (time-lagged) causality between variables within the temporal chain, which is crucial for various scientific disciplines. Compared to causal discovery from non-time-series data, causal discovery from time-series data necessitates more serialized samples with a larger amount of observed time steps. To address the challenges, we propose a novel gradient-based causal discovery approach STIC, which focuses on \\textbf{S}hort-\\textbf{T}erm \\textbf{I}nvariance using \\textbf{C}onvolutional neural networks to uncover the causal relationships from time-series data. Specifically, STIC leverages both the short-term time and mechanism invariance of causality within each window observation, which possesses the property of independence, to enhance sample efficiency. Furthermore, we construct two causal convolution kernels, which correspond to the short-term time and mechanism invariance respectively, to estimate the window causal graph. To demonstrate the necessity of convolutional neural networks for causal discovery from time-series data, we theoretically derive the equivalence between convolution and the underlying generative principle of time-series data under the assumption that the additive noise model is identifiable. Experimental evaluations conducted on both synthetic and FMRI benchmark datasets demonstrate that our STIC outperforms baselines significantly and achieves the state-of-the-art performance, particularly when the datasets contain a limited number of observed time steps. Code is available at \\url{this https URL}.         ",
    "url": "https://arxiv.org/abs/2408.08023",
    "authors": [
      "Rujia Shen",
      "Boran Wang",
      "Chao Zhao",
      "Yi Guan",
      "Jingchi Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.08034",
    "title": "Centralized Network Utility Maximization with Accelerated Gradient Method",
    "abstract": "           Network utility maximization (NUM) is a well-studied problem for network traffic management and resource allocation. Because of the inherent decentralization and complexity of networks, most researches develop decentralized NUM this http URL recent years, the Software Defined Networking (SDN) architecture has been widely used, especially in cloud networks and inter-datacenter networks managed by large enterprises, promoting the design of centralized NUM algorithms. To cope with the large and increasing number of flows in such SDN networks, existing researches about centralized NUM focus on the scalability of the algorithm with respect to the number of flows, however the efficiency is ignored. In this paper, we focus on the SDN scenario, and derive a centralized, efficient and scalable algorithm for the NUM problem. By the designing of a smooth utility function and a smooth penalty function, we formulate the NUM problem with a smooth objective function, which enables the use of Nesterov's accelerated gradient method. We prove that the proposed method has $O(d/t^2)$ convergence rate, which is the fastest with respect to the number of iterations $t$, and our method is scalable with respect to the number of flows $d$ in the network. Experiments show that our method obtains accurate solutions with less iterations, and achieves close-to-optimal network utility.         ",
    "url": "https://arxiv.org/abs/2408.08034",
    "authors": [
      "Ying Tian",
      "Zhiliang Wang",
      "Xia Yin",
      "Xingang Shi",
      "Jiahai Yang",
      "Han Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2408.08045",
    "title": "Joint Message Detection, Channel, and User Position Estimation for Unsourced Random Access in Cell-Free Networks",
    "abstract": "           We consider unsourced random access (uRA) in user-centric cell-free (CF) wireless networks, where random access users send codewords from a common codebook during specifically dedicated random access channel (RACH) slots. The system is conceptually similar to the so-called 2-step RACH currently discussed in 3GPP standardization. In order to cope with the distributed and CF nature of the network, we propose to partition the network coverage area into zones (referred to as ''locations'') and assign an uRA codebook to each location, such that users in a certain location make use of the associated codebook. The centralized uRA decoder makes use of the multisource AMP algorithm recently proposed by the authors. This yields at once the list of active uRA codewords, an estimate of the corresponding channel vectors, and an estimate of the active users' position. We show excellent performance of this approach and perfect agreement with the rigorous theoretical ''state evolution'' analysis. We also show that the proposed ''location-based'' partitioned codebook approach significantly outperforms a baseline system with a single non-partitioned uRA codebook.         ",
    "url": "https://arxiv.org/abs/2408.08045",
    "authors": [
      "Eleni Gkiouzepi",
      "Burak \u00c7akmak",
      "Manfred Opper",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2408.08050",
    "title": "CamoTeacher: Dual-Rotation Consistency Learning for Semi-Supervised Camouflaged Object Detection",
    "abstract": "           Existing camouflaged object detection~(COD) methods depend heavily on large-scale pixel-level annotations.However, acquiring such annotations is laborious due to the inherent camouflage characteristics of the objects.Semi-supervised learning offers a promising solution to this challenge.Yet, its application in COD is hindered by significant pseudo-label noise, both pixel-level and instance-level.We introduce CamoTeacher, a novel semi-supervised COD framework, utilizing Dual-Rotation Consistency Learning~(DRCL) to effectively address these noise issues.Specifically, DRCL minimizes pseudo-label noise by leveraging rotation views' consistency in pixel-level and instance-level.First, it employs Pixel-wise Consistency Learning~(PCL) to deal with pixel-level noise by reweighting the different parts within the pseudo-label.Second, Instance-wise Consistency Learning~(ICL) is used to adjust weights for pseudo-labels, which handles instance-level noise.Extensive experiments on four COD benchmark datasets demonstrate that the proposed CamoTeacher not only achieves state-of-the-art compared with semi-supervised learning methods, but also rivals established fully-supervised learning methods.Our code will be available soon.         ",
    "url": "https://arxiv.org/abs/2408.08050",
    "authors": [
      "Xunfa Lai",
      "Zhiyu Yang",
      "Jie Hu",
      "Shengchuan Zhang",
      "Liujuan Cao",
      "Guannan Jiang",
      "Zhiyu Wang",
      "Songan Zhang",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.08055",
    "title": "COTODE: COntinuous Trajectory neural Ordinary Differential Equations for modelling event sequences",
    "abstract": "           Observation of the underlying actors that generate event sequences reveals that they often evolve continuously. Most modern methods, however, tend to model such processes through at most piecewise-continuous trajectories. To address this, we adopt a way of viewing events not as standalone phenomena but instead as observations of a Gaussian Process, which in turn governs the actor's dynamics. We propose integrating these obtained dynamics, resulting in a continuous-trajectory modification of the widely successful Neural ODE model. Through Gaussian Process theory, we were able to evaluate the uncertainty in an actor's representation, which arises from not observing them between events. This estimate led us to develop a novel, theoretically backed negative feedback mechanism. Empirical studies indicate that our model with Gaussian process interpolation and negative feedback achieves state-of-the-art performance, with improvements up to 20% AUROC against similar architectures.         ",
    "url": "https://arxiv.org/abs/2408.08055",
    "authors": [
      "Ilya Kuleshov",
      "Galina Boeva",
      "Vladislav Zhuzhel",
      "Evgenia Romanenkova",
      "Evgeni Vorsin",
      "Alexey Zaytsev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.08061",
    "title": "Security Challenges of Complex Space Applications: An Empirical Study",
    "abstract": "           Software applications in the space and defense industries have their unique characteristics: They are complex in structure, mission-critical, and often targets of state-of-the-art cyber attacks sponsored by adversary nation states. These applications have typically a high number of stakeholders in their software component supply chain, data supply chain, and user base. The aforementioned factors make such software applications potentially vulnerable to bad actors, as the widely adopted DevOps tools and practices were not designed for high-complexity and high-risk environments. In this study, I investigate the security challenges of the development and management of complex space applications, which differentiate the process from the commonly used practices. My findings are based on interviews with five domain experts from the industry and are further supported by a comprehensive review of relevant publications. To illustrate the dynamics of the problem, I present and discuss an actual software supply chain structure used by Thales Alenia Space, which is one of the largest suppliers of the European Space Agency. Subsequently, I discuss the four most critical security challenges identified by the interviewed experts: Verification of software artifacts, verification of the deployed application, single point of security failure, and data tampering by trusted stakeholders. Furthermore, I present best practices which could be used to overcome each of the given challenges, and whether the interviewed experts think their organization has access to the right tools to address them. Finally, I propose future research of new DevSecOps strategies, practices, and tools which would enable better methods of software integrity verification in the space and defense industries.         ",
    "url": "https://arxiv.org/abs/2408.08061",
    "authors": [
      "Tomas Paulik"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2408.08068",
    "title": "The Paradox of Spreadsheet Self-Efficacy: Social Incentives for Informal Knowledge Sharing in End-User Programming",
    "abstract": "           Informal Knowledge Sharing (KS) is vital for end-user programmers to gain expertise. To better understand how personal (self-efficacy), social (reputational gains, trust between colleagues), and software-related (codification effort) variables influence spreadsheet KS intention, we conducted a multiple regressions analysis based on survey data from spreadsheet users (\\textit{n}=100) in administrative and finance roles. We found that high levels of spreadsheet self-efficacy and a perception that sharing would result in reputational gains predicted higher KS intention, but individuals who found knowledge codification effortful showed lower KS intention. We also observed that regardless of occupation, users tended to report a lower sense of self-efficacy in their general spreadsheet proficiency, despite also reporting high self-efficacy in spreadsheet use for job-related contexts. Our findings suggest that acknowledging and designing for these social and personal variables can help avoid situations where experienced individuals refrain unnecessarily from sharing, with implications for spreadsheet design.         ",
    "url": "https://arxiv.org/abs/2408.08068",
    "authors": [
      "Qing",
      "Advait Sarkar",
      "Duncan P. Brumby",
      "Anna Cox"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2408.08078",
    "title": "Treat Stillness with Movement: Remote Sensing Change Detection via Coarse-grained Temporal Foregrounds Mining",
    "abstract": "           Current works focus on addressing the remote sensing change detection task using bi-temporal images. Although good performance can be achieved, however, seldom of they consider the motion cues which may also be vital. In this work, we revisit the widely adopted bi-temporal images-based framework and propose a novel Coarse-grained Temporal Mining Augmented (CTMA) framework. To be specific, given the bi-temporal images, we first transform them into a video using interpolation operations. Then, a set of temporal encoders is adopted to extract the motion features from the obtained video for coarse-grained changed region prediction. Subsequently, we design a novel Coarse-grained Foregrounds Augmented Spatial Encoder module to integrate both global and local information. We also introduce a motion augmented strategy that leverages motion cues as an additional output to aggregate with the spatial features for improved results. Meanwhile, we feed the input image pairs into the ResNet to get the different features and also the spatial blocks for fine-grained feature learning. More importantly, we propose a mask augmented strategy that utilizes coarse-grained changed regions, incorporating them into the decoder blocks to enhance the final changed prediction. Extensive experiments conducted on multiple benchmark datasets fully validated the effectiveness of our proposed framework for remote sensing image change detection. The source code of this paper will be released on this https URL ",
    "url": "https://arxiv.org/abs/2408.08078",
    "authors": [
      "Xixi Wang",
      "Zitian Wang",
      "Jingtao Jiang",
      "Lan Chen",
      "Xiao Wang",
      "Bo Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.08088",
    "title": "KGV: Integrating Large Language Models with Knowledge Graphs for Cyber Threat Intelligence Credibility Assessment",
    "abstract": "           Cyber threat intelligence is a critical tool that many organizations and individuals use to protect themselves from sophisticated, organized, persistent, and weaponized cyber attacks. However, few studies have focused on the quality assessment of threat intelligence provided by intelligence platforms, and this work still requires manual analysis by cybersecurity experts. In this paper, we propose a knowledge graph-based verifier, a novel Cyber Threat Intelligence (CTI) quality assessment framework that combines knowledge graphs and Large Language Models (LLMs). Our approach introduces LLMs to automatically extract OSCTI key claims to be verified and utilizes a knowledge graph consisting of paragraphs for fact-checking. This method differs from the traditional way of constructing complex knowledge graphs with entities as nodes. By constructing knowledge graphs with paragraphs as nodes and semantic similarity as edges, it effectively enhances the semantic understanding ability of the model and simplifies labeling requirements. Additionally, to fill the gap in the research field, we created and made public the first dataset for threat intelligence assessment from heterogeneous sources. To the best of our knowledge, this work is the first to create a dataset on threat intelligence reliability verification, providing a reference for future research. Experimental results show that KGV (Knowledge Graph Verifier) significantly improves the performance of LLMs in intelligence quality assessment. Compared with traditional methods, we reduce a large amount of data annotation while the model still exhibits strong reasoning capabilities. Finally, our method can achieve XXX accuracy in network threat assessment.         ",
    "url": "https://arxiv.org/abs/2408.08088",
    "authors": [
      "Zongzong Wu",
      "Fengxiao Tang",
      "Ming Zhao",
      "Yufeng Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2408.08089",
    "title": "AgentCourt: Simulating Court with Adversarial Evolvable Lawyer Agents",
    "abstract": "           In this paper, we present a simulation system called AgentCourt that simulates the entire courtroom process. The judge, plaintiff's lawyer, defense lawyer, and other participants are autonomous agents driven by large language models (LLMs). Our core goal is to enable lawyer agents to learn how to argue a case, as well as improving their overall legal skills, through courtroom process simulation. To achieve this goal, we propose an adversarial evolutionary approach for the lawyer-agent. Since AgentCourt can simulate the occurrence and development of court hearings based on a knowledge base and LLM, the lawyer agents can continuously learn and accumulate experience from real court cases. The simulation experiments show that after two lawyer-agents have engaged in a thousand adversarial legal cases in AgentCourt (which can take a decade for real-world lawyers), compared to their pre-evolutionary state, the evolved lawyer agents exhibit consistent improvement in their ability to handle legal tasks. To enhance the credibility of our experimental results, we enlisted a panel of professional lawyers to evaluate our simulations. The evaluation indicates that the evolved lawyer agents exhibit notable advancements in responsiveness, as well as expertise and logical rigor. This work paves the way for advancing LLM-driven agent technology in legal scenarios. Code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2408.08089",
    "authors": [
      "Guhong Chen",
      "Liyang Fan",
      "Zihan Gong",
      "Nan Xie",
      "Zixuan Li",
      "Ziqiang Liu",
      "Chengming Li",
      "Qiang Qu",
      "Shiwen Ni",
      "Min Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.08090",
    "title": "UV-Plane Beam Mapping for Non-Terrestrial Networks in 3GPP System-Level Simulations",
    "abstract": "           Due to the high altitudes and large beam sizes of satellites, the curvature of the Earth's surface can impact system-level performance. To consider this, 3GPP introduces the UV-plane beam mapping for system-level simulations of non-terrestrial networks (NTNs). This paper aims to provide a comprehensive understanding of how beams and user equipments (UEs) are placed on the UV-plane and subsequently mapped to the Earth's surface. We present a general process of projecting UEs on the UV-plane onto the Earth's surface. This process could offer a useful guideline for beam and UE deployment when evaluating the system-level performance of NTNs.         ",
    "url": "https://arxiv.org/abs/2408.08090",
    "authors": [
      "Dong-Hyun Jung",
      "Sucheol Kim",
      "Miyeon Lee",
      "Joon-Gyu Ryu",
      "Junil Choi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2408.08092",
    "title": "OC3D: Weakly Supervised Outdoor 3D Object Detection with Only Coarse Click Annotation",
    "abstract": "           LiDAR-based outdoor 3D object detection has received widespread attention. However, training 3D detectors from the LiDAR point cloud typically relies on expensive bounding box annotations. This paper presents OC3D, an innovative weakly supervised method requiring only coarse clicks on the bird' s eye view of the 3D point cloud. A key challenge here is the absence of complete geometric descriptions of the target objects from such simple click annotations. To address this problem, our proposed OC3D adopts a two-stage strategy. In the first stage, we initially design a novel dynamic and static classification strategy and then propose the Click2Box and Click2Mask modules to generate box-level and mask-level pseudo-labels for static and dynamic instances, respectively. In the second stage, we design a Mask2Box module, leveraging the learning capabilities of neural networks to update mask-level pseudo-labels, which contain less information, to box level pseudo-labels. Experimental results on the widely used KITTI and nuScenes datasets demonstrate that our OC3D with only coarse clicks achieves state-of-the-art performance compared to weakly-supervised 3D detection methods. Combining OC3D with a missing click mining strategy, we propose a OC3D++ pipeline, which requires only 0.2% annotation cost in the KITTI dataset to achieve performance comparable to fully supervised methods.         ",
    "url": "https://arxiv.org/abs/2408.08092",
    "authors": [
      "Qiming Xia",
      "Hongwei Lin",
      "Wei Ye",
      "Hai Wu",
      "Yadan Luo",
      "Shijia Zhao",
      "Xin Li",
      "Chenglu Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.08095",
    "title": "Evaluating Time-Dependent Methods and Seasonal Effects in Code Technical Debt Prediction",
    "abstract": "           Code Technical Debt prediction has become a popular research niche in recent software engineering literature. Technical Debt is an important metric in software projects as it measures professionals' effort to clean the code. Therefore, predicting its future behavior becomes a crucial task. However, no well-defined and consistent approach can completely capture the features that impact the evolution of Code Technical Debt. The goal of this study is to evaluate the impact of considering time-dependent techniques as well as seasonal effects in temporal data in the prediction performance within the context of Code Technical Debt. The study adopts existing, yet not extensively adopted, time-dependent prediction techniques and compares their prediction performance to commonly used Machine Learning models. Further, the study strengthens the evaluation of time-dependent methods by extending the analysis to capture the impact of seasonality in Code Technical Debt data. We trained 11 prediction models using the commit history of 31 open-source projects developed with Java. We predicted the future observations of the SQALE index to evaluate their predictive performance. Our study confirms the positive impact of considering time-dependent techniques. The adopted multivariate time series analysis model ARIMAX overcame the rest of the adopted models. Incorporating seasonal effects led to an enhancement in the predictive performance of the adopted time-dependent techniques. However, the impact of this effect was found to be relatively modest. The findings of this study corroborate our position in favor of implementing techniques that capture the existing time dependence within historical data of software metrics, specifically in the context of this study, namely, Code Technical Debt. This necessitates the utilization of techniques that can effectively address this evidence.         ",
    "url": "https://arxiv.org/abs/2408.08095",
    "authors": [
      "Mikel Robredo",
      "Nyyti Saarimaki",
      "Davide Taibi",
      "Rafael Penaloza",
      "Valentina Lenarduzzi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2408.08105",
    "title": "Multimodal Causal Reasoning Benchmark: Challenging Vision Large Language Models to Infer Causal Links Between Siamese Images",
    "abstract": "           Large Language Models (LLMs) have showcased exceptional ability in causal reasoning from textual information. However, will these causalities remain straightforward for Vision Large Language Models (VLLMs) when only visual hints are provided? Motivated by this, we propose a novel Multimodal Causal Reasoning benchmark, namely MuCR, to challenge VLLMs to infer semantic cause-and-effect relationship when solely relying on visual cues such as action, appearance, clothing, and environment. Specifically, we introduce a prompt-driven image synthesis approach to create siamese images with embedded semantic causality and visual cues, which can effectively evaluate VLLMs' causal reasoning capabilities. Additionally, we develop tailored metrics from multiple perspectives, including image-level match, phrase-level understanding, and sentence-level explanation, to comprehensively assess VLLMs' comprehension abilities. Our extensive experiments reveal that the current state-of-the-art VLLMs are not as skilled at multimodal causal reasoning as we might have hoped. Furthermore, we perform a comprehensive analysis to understand these models' shortcomings from different views and suggest directions for future research. We hope MuCR can serve as a valuable resource and foundational benchmark in multimodal causal reasoning research. The project is available at: this https URL ",
    "url": "https://arxiv.org/abs/2408.08105",
    "authors": [
      "Zhiyuan Li",
      "Heng Wang",
      "Dongnan Liu",
      "Chaoyi Zhang",
      "Ao Ma",
      "Jieting Long",
      "Weidong Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.08107",
    "title": "Communication-robust and Privacy-safe Distributed Estimation for Heterogeneous Community-level Behind-the-meter Solar Power Generation",
    "abstract": "           The rapid growth of behind-the-meter (BTM) solar power generation systems presents challenges for distribution system planning and scheduling due to invisible solar power generation. To address the data leakage problem of centralized machine-learning methods in BTM solar power generation estimation, the federated learning (FL) method has been investigated for its distributed learning capability. However, the conventional FL method has encountered various challenges, including heterogeneity, communication failures, and malicious privacy attacks. To overcome these challenges, this study proposes a communication-robust and privacy-safe distributed estimation method for heterogeneous community-level BTM solar power generation. Specifically, this study adopts multi-task FL as the main structure and learns the common and unique features of all communities. Simultaneously, it embeds an updated parameters estimation method into the multi-task FL, automatically identifies similarities between any two clients, and estimates the updated parameters for unavailable clients to mitigate the negative effects of communication failures. Finally, this study adopts a differential privacy mechanism under the dynamic privacy budget allocation strategy to combat malicious privacy attacks and improve model training efficiency. Case studies show that in the presence of heterogeneity and communication failures, the proposed method exhibits better estimation accuracy and convergence performance as compared with traditional FL and localized learning methods, while providing stronger privacy protection.         ",
    "url": "https://arxiv.org/abs/2408.08107",
    "authors": [
      "Jinglei Feng",
      "Zhengshuo Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2408.08108",
    "title": "Unsupervised Part Discovery via Dual Representation Alignment",
    "abstract": "           Object parts serve as crucial intermediate representations in various downstream tasks, but part-level representation learning still has not received as much attention as other vision tasks. Previous research has established that Vision Transformer can learn instance-level attention without labels, extracting high-quality instance-level representations for boosting downstream tasks. In this paper, we achieve unsupervised part-specific attention learning using a novel paradigm and further employ the part representations to improve part discovery performance. Specifically, paired images are generated from the same image with different geometric transformations, and multiple part representations are extracted from these paired images using a novel module, named PartFormer. These part representations from the paired images are then exchanged to improve geometric transformation invariance. Subsequently, the part representations are aligned with the feature map extracted by a feature map encoder, achieving high similarity with the pixel representations of the corresponding part regions and low similarity in irrelevant regions. Finally, the geometric and semantic constraints are applied to the part representations through the intermediate results in alignment for part-specific attention learning, encouraging the PartFormer to focus locally and the part representations to explicitly include the information of the corresponding parts. Moreover, the aligned part representations can further serve as a series of reliable detectors in the testing phase, predicting pixel masks for part discovery. Extensive experiments are carried out on four widely used datasets, and our results demonstrate that the proposed method achieves competitive performance and robustness due to its part-specific attention.         ",
    "url": "https://arxiv.org/abs/2408.08108",
    "authors": [
      "Jiahao Xia",
      "Wenjian Huang",
      "Min Xu",
      "Jianguo Zhang",
      "Haimin Zhang",
      "Ziyu Sheng",
      "Dong Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.08119",
    "title": "The Unreasonable Effectiveness of Solving Inverse Problems with Neural Networks",
    "abstract": "           Finding model parameters from data is an essential task in science and engineering, from weather and climate forecasts to plasma control. Previous works have employed neural networks to greatly accelerate finding solutions to inverse problems. Of particular interest are end-to-end models which utilize differentiable simulations in order to backpropagate feedback from the simulated process to the network weights and enable roll-out of multiple time steps. So far, it has been assumed that, while model inference is faster than classical optimization, this comes at the cost of a decrease in solution accuracy. We show that this is generally not true. In fact, neural networks trained to learn solutions to inverse problems can find better solutions than classical optimizers even on their training set. To demonstrate this, we perform both a theoretical analysis as well an extensive empirical evaluation on challenging problems involving local minima, chaos, and zero-gradient regions. Our findings suggest an alternative use for neural networks: rather than generalizing to new data for fast inference, they can also be used to find better solutions on known data.         ",
    "url": "https://arxiv.org/abs/2408.08119",
    "authors": [
      "Philipp Holl",
      "Nils Thuerey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.08131",
    "title": "Detection and Impact of Debit/Credit Card Fraud: Victims' Experiences",
    "abstract": "           It might be intuitive to expect that small or reimbursed financial loss resulting from credit or debit card fraud would have low or no financial impact on victims. However, little is known about the extent to which financial fraud impacts victims psychologically, how victims detect the fraud, which detection methods are most efficient, and how the fraud detection and reporting processes can be improved. To answer these questions, we conducted a 150-participant survey of debit/credit card fraud victims in the US. Our results show that significantly more participants reported that they were impacted psychologically than financially. However, we found no relationship between the amount of direct financial loss and psychological impact, suggesting that people are at risk of being psychologically impacted regardless of the amount lost to fraud. Despite the fact that bank or card issuer notifications were related to faster detection of fraud, more participants reported detecting the fraud after reviewing their card or account statements rather than from notifications. This suggests that notifications may be underutilized. Finally, we provide a set of recommendations distilled from victims' experiences to improve the debit/credit card fraud detection and reporting processes.         ",
    "url": "https://arxiv.org/abs/2408.08131",
    "authors": [
      "Eman Alashwali",
      "Ragashree Mysuru Chandrashekar",
      "Mandy Lanyon",
      "Lorrie Faith Cranor"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2408.08132",
    "title": "Heterogeneous System Design for Cell-Free Massive MIMO in Wideband Communications",
    "abstract": "           Cell-free massive multi-input multi-output (CFmMIMO) offers uniform service quality through distributed access points (APs), yet unresolved issues remain. This paper proposes a heterogeneous system design that goes beyond the original CFmMIMO architecture by exploiting the synergy of a base station (BS) and distributed APs. Users are categorized as near users (NUs) and far users (FUs) depending on their proximity to the BS. The BS serves the NUs, while the APs cater to the FUs. Through activating only the closest AP of each FU, the use of downlink pilots is enabled, thereby enhancing performance. This heterogeneous design outperforms other homogeneous massive MIMO configurations, demonstrating superior sum capacity while maintaining comparable user-experienced rates. Moreover, it lowers the costs associated with AP installations and reduces signaling overhead for the fronthaul network.         ",
    "url": "https://arxiv.org/abs/2408.08132",
    "authors": [
      "Wei Jiang",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2408.08133",
    "title": "EXPLAIN, AGREE, LEARN: Scaling Learning for Neural Probabilistic Logic",
    "abstract": "           Neural probabilistic logic systems follow the neuro-symbolic (NeSy) paradigm by combining the perceptive and learning capabilities of neural networks with the robustness of probabilistic logic. Learning corresponds to likelihood optimization of the neural networks. However, to obtain the likelihood exactly, expensive probabilistic logic inference is required. To scale learning to more complex systems, we therefore propose to instead optimize a sampling based objective. We prove that the objective has a bounded error with respect to the likelihood, which vanishes when increasing the sample count. Furthermore, the error vanishes faster by exploiting a new concept of sample diversity. We then develop the EXPLAIN, AGREE, LEARN (EXAL) method that uses this objective. EXPLAIN samples explanations for the data. AGREE reweighs each explanation in concordance with the neural component. LEARN uses the reweighed explanations as a signal for learning. In contrast to previous NeSy methods, EXAL can scale to larger problem sizes while retaining theoretical guarantees on the error. Experimentally, our theoretical claims are verified and EXAL outperforms recent NeSy methods when scaling up the MNIST addition and Warcraft pathfinding problems.         ",
    "url": "https://arxiv.org/abs/2408.08133",
    "authors": [
      "Victor Verreet",
      "Lennert De Smet",
      "Luc De Raedt",
      "Emanuele Sansone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.08141",
    "title": "Visual Integration of Static and Dynamic Software Analysis in Code Reviews via Software City Visualization",
    "abstract": "           Software visualization approaches for code reviews are often implemented as standalone applications, which use static code analysis. The goal is to visualize the structural changes introduced by a pull / merge request to facilitate the review process. In this way, for example, structural changes that hinder code evolution can be more easily identified, but understanding the changed program behavior is still mainly done by reading the code. For software visualization to be successful in code review, tools must be provided that go beyond an alternative representation of code changes and integrate well into the developers' daily workflow. In this paper, we report on the novel and in-progress design and implementation of a web-based approach capable of combining static and dynamic analysis data in software city visualizations. Our architectural tool design incorporates modern web technologies such as the integration into common Git hosting services. As a result, code reviewers can explore how the modified software evolves and execute its use cases, which is especially helpful for distributed software systems. In this context, developers can be directly linked from the Git hosting service's issue tracking system to the corresponding software city visualization. This approach eliminates the recurring action of manual data collection and setup. We implement our design by extending the web-based software visualization tool ExplorViz. We invite other researchers to extend our open source software and jointly research this approach. Video URL: this https URL ",
    "url": "https://arxiv.org/abs/2408.08141",
    "authors": [
      "Alexander Krause-Glau",
      "Lukas Damerau",
      "Malte Hansen",
      "Wilhelm Hasselbring"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2408.08143",
    "title": "Unlearnable Examples Detection via Iterative Filtering",
    "abstract": "           Deep neural networks are proven to be vulnerable to data poisoning attacks. Recently, a specific type of data poisoning attack known as availability attacks has led to the failure of data utilization for model learning by adding imperceptible perturbations to images. Consequently, it is quite beneficial and challenging to detect poisoned samples, also known as Unlearnable Examples (UEs), from a mixed dataset. In response, we propose an Iterative Filtering approach for UEs identification. This method leverages the distinction between the inherent semantic mapping rules and shortcuts, without the need for any additional information. We verify that when training a classifier on a mixed dataset containing both UEs and clean data, the model tends to quickly adapt to the UEs compared to the clean data. Due to the accuracy gaps between training with clean/poisoned samples, we employ a model to misclassify clean samples while correctly identifying the poisoned ones. The incorporation of additional classes and iterative refinement enhances the model's ability to differentiate between clean and poisoned samples. Extensive experiments demonstrate the superiority of our method over state-of-the-art detection approaches across various attacks, datasets, and poison ratios, significantly reducing the Half Total Error Rate (HTER) compared to existing methods.         ",
    "url": "https://arxiv.org/abs/2408.08143",
    "authors": [
      "Yi Yu",
      "Qichen Zheng",
      "Siyuan Yang",
      "Wenhan Yang",
      "Jun Liu",
      "Shijian Lu",
      "Yap-Peng Tan",
      "Kwok-Yan Lam",
      "Alex Kot"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.08146",
    "title": "KOALA: Enhancing Speculative Decoding for LLM via Multi-Layer Draft Heads with Adversarial Learning",
    "abstract": "           Large Language Models (LLMs) exhibit high inference latency due to their autoregressive decoding nature. While the draft head in speculative decoding mitigates this issue, its full potential remains unexplored. In this paper, we introduce KOALA (K-layer Optimized Adversarial Learning Architecture), an orthogonal approach to the draft head. By transforming the conventional single-layer draft head into a multi-layer architecture and incorporating adversarial learning into the traditional supervised training, KOALA significantly improves the accuracy of the draft head in predicting subsequent tokens, thus more closely mirroring the functionality of LLMs. Although this improvement comes at the cost of slightly increased drafting overhead, KOALA substantially unlocks the draft head's potential, greatly enhancing speculative decoding. We conducted comprehensive evaluations of KOALA, including both autoregressive and non-autoregressive draft heads across various tasks, demonstrating a latency speedup ratio improvement of 0.24x-0.41x, which is 10.57%-14.09% faster than the original draft heads.         ",
    "url": "https://arxiv.org/abs/2408.08146",
    "authors": [
      "Kaiqi Zhang",
      "Jing Zhao",
      "Rui Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2408.08148",
    "title": "Early Detection of Performance Regressions by Bridging Local Performance Data and Architectural Models",
    "abstract": "           During software development, developers often make numerous modifications to the software to address existing issues or implement new features. However, certain changes may inadvertently have a detrimental impact on the overall system performance. To ensure that the performance of new software releases does not degrade, existing practices rely on system-level performance testing, such as load testing, or component-level performance testing to detect performance regressions. However, performance testing for the entire system is often expensive and time-consuming, posing challenges to adapting to the rapid release cycles common in modern DevOps practices. System-level performance testing cannot be conducted until the system is fully built and deployed. On the other hand, component-level testing focuses on isolated components, neglecting overall system performance and the impact of system workloads. In this paper, we propose a novel approach to early detection of performance regressions by bridging the local performance data generated by component-level testing and the system-level architectural models. Our approach uses local performance data to identify deviations at the component level, and then propagate these deviations to the architectural model. We then use the architectural model to predict regressions in the performance of the overall system. We evaluate our approach on two open-source benchmark systems and show that it can effectively detect end-to-end system performance regressions from local performance deviations with different intensities and under various system workloads. More importantly, our approach can detect regressions as early as in the development phase, in contrast to existing approaches that require the system to be fully built and deployed. Our approach is lightweight and can complement traditional system performance testing when testing resources are scarce.         ",
    "url": "https://arxiv.org/abs/2408.08148",
    "authors": [
      "Lizhi Liao",
      "Simon Eismann",
      "Heng Li",
      "Cor-Paul Bezemer",
      "Diego Elias Costa",
      "Andre van Hoorn",
      "Weiyi Shang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2408.08179",
    "title": "Machine learning empowered Modulation detection for OFDM-based signals",
    "abstract": "           We propose a blind ML-based modulation detection for OFDM-based technologies. Unlike previous works that assume an ideal environment with precise knowledge of subcarrier count and cyclic prefix location, we consider blind modulation detection while accounting for realistic environmental parameters and imperfections. Our approach employs a ResNet network to simultaneously detect the modulation type and accurately locate the cyclic prefix. Specifically, after eliminating the environmental impact from the signal and accurately extracting the OFDM symbols, we convert these symbols into scatter plots. Due to their unique shapes, these scatter plots are then classified using ResNet. As a result, our proposed modulation classification method can be applied to any OFDM-based technology without prior knowledge of the transmitted signal. We evaluate its performance across various modulation schemes and subcarrier numbers. Simulation results show that our method achieves a modulation detection accuracy exceeding $80\\%$ at an SNR of $10$ dB and $95\\%$ at an SNR of $25$ dB.         ",
    "url": "https://arxiv.org/abs/2408.08179",
    "authors": [
      "Ali Pourranjbar",
      "Georges Kaddoum",
      "Verdier Assoume Mba",
      "Sahil Garg",
      "Satinder Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.08190",
    "title": "U-WNO: U-Net Enhanced Wavelet Neural Operator for Solving Parametric Partial Differential Equations",
    "abstract": "           Neural operators are effective tools for solving parametric partial differential equations (PDEs). They can predict solutions of PDEs with different initial and boundary conditions, as well as different input functions. The recently proposed Wavelet Neural Operator (WNO) utilizes the time-frequency localization of wavelets to capture spatial manifolds effectively. While WNO has shown promise as an operator learning method, it only parameterizes neural network weights under higher-order wavelet factorization. This approach avoids noise interference but may result in insufficient extraction of high-frequency features from the data. In this study, we propose a new network architecture called U-WNO. It incorporates the U-Net path and residual shortcut into the wavelet layer to enhance the extraction of high-frequency features and improve the learning of spatial manifolds. Additionally, we introduce the Adaptive Activation Function into the wavelet layer to address the spectral bias of the neural network. The effectiveness of U-WNO is demonstrated through numerical experiments on various problems, including the Burgers equation, Darcy flow, Navier-Stokes equation, Allen-Cahn equation, Non-homogeneous Poisson equation, and Wave advection equation. This study also includes a comparative analysis of existing operator learning frameworks.         ",
    "url": "https://arxiv.org/abs/2408.08190",
    "authors": [
      "Wei-Min Lei",
      "Hou-Biao Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2408.08193",
    "title": "\"I Try to Represent Myself as I Am\": Self-Presentation Preferences of People with Invisible Disabilities through Embodied Social VR Avatars",
    "abstract": "           With the increasing adoption of social virtual reality (VR), it is critical to design inclusive avatars. While researchers have investigated how and why blind and d/Deaf people wish to disclose their disabilities in VR, little is known about the preferences of many others with invisible disabilities (e.g., ADHD, dyslexia, chronic conditions). We filled this gap by interviewing 15 participants, each with one to three invisible disabilities, who represented 22 different invisible disabilities in total. We found that invisibly disabled people approached avatar-based disclosure through contextualized considerations informed by their prior experiences. For example, some wished to use VR's embodied affordances, such as facial expressions and body language, to dynamically represent their energy level or willingness to engage with others, while others preferred not to disclose their disability identity in any context. We define a binary framework for embodied invisible disability expression (public and private) and discuss three disclosure patterns (Activists, Non-Disclosers, and Situational Disclosers) to inform the design of future inclusive VR experiences.         ",
    "url": "https://arxiv.org/abs/2408.08193",
    "authors": [
      "Ria J. Gualano",
      "Lucy Jiang",
      "Kexin Zhang",
      "Tanisha Shende",
      "Andrea Stevenson Won",
      "Shiri Azenkot"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2408.08202",
    "title": "Towards Practical Human Motion Prediction with LiDAR Point Clouds",
    "abstract": "           Human motion prediction is crucial for human-centric multimedia understanding and interacting. Current methods typically rely on ground truth human poses as observed input, which is not practical for real-world scenarios where only raw visual sensor data is available. To implement these methods in practice, a pre-phrase of pose estimation is essential. However, such two-stage approaches often lead to performance degradation due to the accumulation of errors. Moreover, reducing raw visual data to sparse keypoint representations significantly diminishes the density of information, resulting in the loss of fine-grained features. In this paper, we propose \\textit{LiDAR-HMP}, the first single-LiDAR-based 3D human motion prediction approach, which receives the raw LiDAR point cloud as input and forecasts future 3D human poses directly. Building upon our novel structure-aware body feature descriptor, LiDAR-HMP adaptively maps the observed motion manifold to future poses and effectively models the spatial-temporal correlations of human motions for further refinement of prediction results. Extensive experiments show that our method achieves state-of-the-art performance on two public benchmarks and demonstrates remarkable robustness and efficacy in real-world deployments.         ",
    "url": "https://arxiv.org/abs/2408.08202",
    "authors": [
      "Xiao Han",
      "Yiming Ren",
      "Yichen Yao",
      "Yujing Sun",
      "Yuexin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.08205",
    "title": "A Multi-task Adversarial Attack Against Face Authentication",
    "abstract": "           Deep-learning-based identity management systems, such as face authentication systems, are vulnerable to adversarial attacks. However, existing attacks are typically designed for single-task purposes, which means they are tailored to exploit vulnerabilities unique to the individual target rather than being adaptable for multiple users or systems. This limitation makes them unsuitable for certain attack scenarios, such as morphing, universal, transferable, and counter attacks. In this paper, we propose a multi-task adversarial attack algorithm called MTADV that are adaptable for multiple users or systems. By interpreting these scenarios as multi-task attacks, MTADV is applicable to both single- and multi-task attacks, and feasible in the white- and gray-box settings. Furthermore, MTADV is effective against various face datasets, including LFW, CelebA, and CelebA-HQ, and can work with different deep learning models, such as FaceNet, InsightFace, and CurricularFace. Importantly, MTADV retains its feasibility as a single-task attack targeting a single user/system. To the best of our knowledge, MTADV is the first adversarial attack method that can target all of the aforementioned scenarios in one algorithm.         ",
    "url": "https://arxiv.org/abs/2408.08205",
    "authors": [
      "Hanrui Wang",
      "Shuo Wang",
      "Cunjian Chen",
      "Massimo Tistarelli",
      "Zhe Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2408.08212",
    "title": "Covert Bias: The Severity of Social Views' Unalignment Towards Implicit and Explicit Opinion",
    "abstract": "           While various approaches have recently been studied for bias identification, little is known about how implicit language that does not explicitly convey a viewpoint affects bias amplification in large language this http URL examine the severity of bias toward a view, we evaluated the performance of two downstream tasks where the implicit and explicit knowledge of social groups were used. First, we present a stress test evaluation by using a biased model in edge cases of excessive bias scenarios. Then, we evaluate how LLMs calibrate linguistically in response to both implicit and explicit opinions when they are aligned with conflicting viewpoints. Our findings reveal a discrepancy in LLM performance in identifying implicit and explicit opinions, with a general tendency of bias toward explicit opinions of opposing stances. Moreover, the bias-aligned models generate more cautious responses using uncertainty phrases compared to the unaligned (zero-shot) base models. The direct, incautious responses of the unaligned models suggest a need for further refinement of decisiveness by incorporating uncertainty markers to enhance their reliability, especially on socially nuanced topics with high subjectivity.         ",
    "url": "https://arxiv.org/abs/2408.08212",
    "authors": [
      "Abeer Aldayel",
      "Areej Alokaili",
      "Rehab Alahmadi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2408.08216",
    "title": "The Dawn of KAN in Image-to-Image (I2I) Translation: Integrating Kolmogorov-Arnold Networks with GANs for Unpaired I2I Translation",
    "abstract": "           Image-to-Image translation in Generative Artificial Intelligence (Generative AI) has been a central focus of research, with applications spanning healthcare, remote sensing, physics, chemistry, photography, and more. Among the numerous methodologies, Generative Adversarial Networks (GANs) with contrastive learning have been particularly successful. This study aims to demonstrate that the Kolmogorov-Arnold Network (KAN) can effectively replace the Multi-layer Perceptron (MLP) method in generative AI, particularly in the subdomain of image-to-image translation, to achieve better generative quality. Our novel approach replaces the two-layer MLP with a two-layer KAN in the existing Contrastive Unpaired Image-to-Image Translation (CUT) model, developing the KAN-CUT model. This substitution favors the generation of more informative features in low-dimensional vector representations, which contrastive learning can utilize more effectively to produce high-quality images in the target domain. Extensive experiments, detailed in the results section, demonstrate the applicability of KAN in conjunction with contrastive learning and GANs in Generative AI, particularly for image-to-image translation. This work suggests that KAN could be a valuable component in the broader generative AI domain.         ",
    "url": "https://arxiv.org/abs/2408.08216",
    "authors": [
      "Arpan Mahara",
      "Naphtali D. Rishe",
      "Liangdong Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.08217",
    "title": "RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science",
    "abstract": "           Large language models (LLMs) have enhanced our ability to rapidly analyze and classify unstructured natural language data. However, concerns regarding cost, network limitations, and security constraints have posed challenges for their integration into work processes. In this study, we adopt a systems design approach to employing LLMs as imperfect data annotators for downstream supervised learning tasks, introducing novel system intervention measures aimed at improving classification performance. Our methodology outperforms LLM-generated labels in seven of eight tests, demonstrating an effective strategy for incorporating LLMs into the design and deployment of specialized, supervised learning models present in many industry use cases.         ",
    "url": "https://arxiv.org/abs/2408.08217",
    "authors": [
      "David Farr",
      "Nico Manzonelli",
      "Iain Cruickshank",
      "Jevin West"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2408.08226",
    "title": "Predictive Multiplicity of Knowledge Graph Embeddings in Link Prediction",
    "abstract": "           Knowledge graph embedding (KGE) models are often used to predict missing links for knowledge graphs (KGs). However, multiple KG embeddings can perform almost equally well for link prediction yet suggest conflicting predictions for certain queries, termed \\textit{predictive multiplicity} in literature. This behavior poses substantial risks for KGE-based applications in high-stake domains but has been overlooked in KGE research. In this paper, we define predictive multiplicity in link prediction. We introduce evaluation metrics and measure predictive multiplicity for representative KGE methods on commonly used benchmark datasets. Our empirical study reveals significant predictive multiplicity in link prediction, with $8\\%$ to $39\\%$ testing queries exhibiting conflicting predictions. To address this issue, we propose leveraging voting methods from social choice theory, significantly mitigating conflicts by $66\\%$ to $78\\%$ according to our experiments.         ",
    "url": "https://arxiv.org/abs/2408.08226",
    "authors": [
      "Yuqicheng Zhu",
      "Nico Potyka",
      "Mojtaba Nayyeri",
      "Bo Xiong",
      "Yunjie He",
      "Evgeny Kharlamov",
      "Steffen Staab"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.08236",
    "title": "Derivatives on Graphs for the Positive Calculus of Relations with Transitive Closure",
    "abstract": "           We prove that the equational theory of the positive calculus of relations with transitive closure (PCoR*) is EXPSPACE-complete. PCoR* terms consist of the following standard operators on binary relations: identity, empty, universality, union, intersection, composition, converse, and reflexive-transitive closure (so, PCoR* terms subsume Kleene algebra terms and allegory terms as fragments). Additionally, we show that the equational theory of PCoR* extended with tests and nominals (in hybrid logic) is still EXPSPACE-complete; moreover, it is PSPACE-complete for its intersection-free fragment.         ",
    "url": "https://arxiv.org/abs/2408.08236",
    "authors": [
      "Yoshiki Nakamura"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2408.08248",
    "title": "Conformalized Answer Set Prediction for Knowledge Graph Embedding",
    "abstract": "           Knowledge graph embeddings (KGE) apply machine learning methods on knowledge graphs (KGs) to provide non-classical reasoning capabilities based on similarities and analogies. The learned KG embeddings are typically used to answer queries by ranking all potential answers, but rankings often lack a meaningful probabilistic interpretation - lower-ranked answers do not necessarily have a lower probability of being true. This limitation makes it difficult to distinguish plausible from implausible answers, posing challenges for the application of KGE methods in high-stakes domains like medicine. We address this issue by applying the theory of conformal prediction that allows generating answer sets, which contain the correct answer with probabilistic guarantees. We explain how conformal prediction can be used to generate such answer sets for link prediction tasks. Our empirical evaluation on four benchmark datasets using six representative KGE methods validates that the generated answer sets satisfy the probabilistic guarantees given by the theory of conformal prediction. We also demonstrate that the generated answer sets often have a sensible size and that the size adapts well with respect to the difficulty of the query.         ",
    "url": "https://arxiv.org/abs/2408.08248",
    "authors": [
      "Yuqicheng Zhu",
      "Nico Potyka",
      "Jiarong Pan",
      "Bo Xiong",
      "Yunjie He",
      "Evgeny Kharlamov",
      "Steffen Staab"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.08256",
    "title": "Palette Sparsification for Graphs with Sparse Neighborhoods",
    "abstract": "           A celebrated palette sparsification result of Assadi, Chen, and Khanna states that in every $n$-vertex graph of maximum degree $\\Delta$, sampling $\\Theta(\\log n)$ colors per vertex from $\\{1,\\ldots,\\Delta+1\\}$ almost certainly allows for a proper coloring from the sampled colors. Alon and Assadi extended this work proving a similar result for $O(\\Delta/\\log \\Delta)$-coloring triangle-free graphs. Apart from being interesting results from a combinatorial standpoint, their results have various applications to the design of graph coloring algorithms in different models of computation. In this work, we focus on graphs with sparse neighborhoods. We say a graph $G = (V,E)$ is $k$-locally-sparse if for each vertex $v \\in V$, the subgraph $G[N(v)]$ contains at most $k$ edges. A celebrated result of Alon, Krivelevich, and Sudakov shows that such graphs are $O(\\Delta/\\log (\\Delta/\\sqrt{k}))$-colorable. For any $\\alpha\\in(0,1)$ and $k\\ll\\Delta^{2\\alpha}$, let $G$ be a $k$-locally-sparse graph. We show the following for $q=\\Theta\\left(\\Delta/\\log\\left(\\Delta^\\alpha/\\sqrt{k}\\right)\\right)$: 1. Sampling $O(\\Delta^\\alpha+\\sqrt{\\log n})$ colors per vertex is sufficient to obtain a proper $q$-coloring of $G$ from the sampled colors. 2. There exists a single-pass streaming algorithm which computes a proper $q$-coloring of $G$ with high probability using $\\tilde O(n\\Delta^{2\\alpha})$ space. 3. There exists a randomized non-adaptive sublinear-time algorithm which computes a proper $q$-coloring of $G$ with high probability using at most $\\tilde O\\left(n^{\\frac32+\\frac{\\alpha}{2-2\\alpha}}\\right)$ queries. Our results recover and improve upon earlier work of Alon and Assadi. A key element in our proof is a proposition regarding correspondence coloring in the so-called color-degree setting, which improves upon recent work of Anderson, Kuchukova, and the author and is of independent interest.         ",
    "url": "https://arxiv.org/abs/2408.08256",
    "authors": [
      "Abhishek Dhawan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2408.08264",
    "title": "InVAErt networks for amortized inference and identifiability analysis of lumped parameter hemodynamic models",
    "abstract": "           Estimation of cardiovascular model parameters from electronic health records (EHR) poses a significant challenge primarily due to lack of identifiability. Structural non-identifiability arises when a manifold in the space of parameters is mapped to a common output, while practical non-identifiability can result due to limited data, model misspecification, or noise corruption. To address the resulting ill-posed inverse problem, optimization-based or Bayesian inference approaches typically use regularization, thereby limiting the possibility of discovering multiple solutions. In this study, we use inVAErt networks, a neural network-based, data-driven framework for enhanced digital twin analysis of stiff dynamical systems. We demonstrate the flexibility and effectiveness of inVAErt networks in the context of physiological inversion of a six-compartment lumped parameter hemodynamic model from synthetic data to real data with missing components.         ",
    "url": "https://arxiv.org/abs/2408.08264",
    "authors": [
      "Guoxiang Grayson Tong",
      "Carlos A. Sing Long",
      "Daniele E. Schiavazzi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.08270",
    "title": "HeightLane: BEV Heightmap guided 3D Lane Detection",
    "abstract": "           Accurate 3D lane detection from monocular images presents significant challenges due to depth ambiguity and imperfect ground modeling. Previous attempts to model the ground have often used a planar ground assumption with limited degrees of freedom, making them unsuitable for complex road environments with varying slopes. Our study introduces HeightLane, an innovative method that predicts a height map from monocular images by creating anchors based on a multi-slope assumption. This approach provides a detailed and accurate representation of the ground. HeightLane employs the predicted heightmap along with a deformable attention-based spatial feature transform framework to efficiently convert 2D image features into 3D bird's eye view (BEV) features, enhancing spatial understanding and lane structure recognition. Additionally, the heightmap is used for the positional encoding of BEV features, further improving their spatial accuracy. This explicit view transformation bridges the gap between front-view perceptions and spatially accurate BEV representations, significantly improving detection performance. To address the lack of the necessary ground truth (GT) height map in the original OpenLane dataset, we leverage the Waymo dataset and accumulate its LiDAR data to generate a height map for the drivable area of each scene. The GT heightmaps are used to train the heightmap extraction module from monocular images. Extensive experiments on the OpenLane validation set show that HeightLane achieves state-of-the-art performance in terms of F-score, highlighting its potential in real-world applications.         ",
    "url": "https://arxiv.org/abs/2408.08270",
    "authors": [
      "Chaesong Park",
      "Eunbin Seo",
      "Jongwoo Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.08286",
    "title": "Absence of Closed-Form Descriptions for Gradient Flow in Two-Layer Narrow Networks",
    "abstract": "           In the field of machine learning, comprehending the intricate training dynamics of neural networks poses a significant challenge. This paper explores the training dynamics of neural networks, particularly whether these dynamics can be expressed in a general closed-form solution. We demonstrate that the dynamics of the gradient flow in two-layer narrow networks is not an integrable system. Integrable systems are characterized by trajectories confined to submanifolds defined by level sets of first integrals (invariants), facilitating predictable and reducible dynamics. In contrast, non-integrable systems exhibit complex behaviors that are difficult to predict. To establish the non-integrability, we employ differential Galois theory, which focuses on the solvability of linear differential equations. We demonstrate that under mild conditions, the identity component of the differential Galois group of the variational equations of the gradient flow is non-solvable. This result confirms the system's non-integrability and implies that the training dynamics cannot be represented by Liouvillian functions, precluding a closed-form solution for describing these dynamics. Our findings highlight the necessity of employing numerical methods to tackle optimization problems within neural networks. The results contribute to a deeper understanding of neural network training dynamics and their implications for machine learning optimization strategies.         ",
    "url": "https://arxiv.org/abs/2408.08286",
    "authors": [
      "Yeachan Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2408.08291",
    "title": "The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community",
    "abstract": "           Human-model conversations provide a window into users' real-world scenarios, behavior, and needs, and thus are a valuable resource for model development and research. While for-profit companies collect user data through the APIs of their models, using it internally to improve their own models, the open source and research community lags behind. We introduce the ShareLM collection, a unified set of human conversations with large language models, and its accompanying plugin, a Web extension for voluntarily contributing user-model conversations. Where few platforms share their chats, the ShareLM plugin adds this functionality, thus, allowing users to share conversations from most platforms. The plugin allows the user to rate their conversations, both at the conversation and the response levels, and delete conversations they prefer to keep private before they ever leave the user's local storage. We release the plugin conversations as part of the ShareLM collection, and call for more community effort in the field of open human-model data. The code, plugin, and data are available.         ",
    "url": "https://arxiv.org/abs/2408.08291",
    "authors": [
      "Shachar Don-Yehiya",
      "Leshem Choshen",
      "Omri Abend"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2408.08301",
    "title": "VLPG-Nav: Object Navigation Using Visual Language Pose Graph and Object Localization Probability Maps",
    "abstract": "           We present VLPG-Nav, a visual language navigation method for guiding robots to specified objects within household scenes. Unlike existing methods primarily focused on navigating the robot toward objects, our approach considers the additional challenge of centering the object within the robot's camera view. Our method builds a visual language pose graph (VLPG) that functions as a spatial map of VL embeddings. Given an open vocabulary object query, we plan a viewpoint for object navigation using the VLPG. Despite navigating to the viewpoint, real-world challenges like object occlusion, displacement, and the robot's localization error can prevent visibility. We build an object localization probability map that leverages the robot's current observations and prior VLPG. When the object isn't visible, the probability map is updated and an alternate viewpoint is computed. In addition, we propose an object-centering formulation that locally adjusts the robot's pose to center the object in the camera view. We evaluate the effectiveness of our approach through simulations and real-world experiments, evaluating its ability to successfully view and center the object within the camera field of view. VLPG-Nav demonstrates improved performance in locating the object, navigating around occlusions, and centering the object within the robot's camera view, outperforming the selected baselines in the evaluation metrics.         ",
    "url": "https://arxiv.org/abs/2408.08301",
    "authors": [
      "Senthil Hariharan Arul",
      "Dhruva Kumar",
      "Vivek Sugirtharaj",
      "Richard Kim",
      "Xuewei",
      "Rajasimman Madhivanan",
      "Arnie Sen",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2408.07879",
    "title": "On Accelerating Large-Scale Robust Portfolio Optimization",
    "abstract": "           Solving large-scale robust portfolio optimization problems is challenging due to the high computational demands associated with an increasing number of assets, the amount of data considered, and market uncertainty. To address this issue, we propose an extended supporting hyperplane approximation approach for efficiently solving a class of distributionally robust portfolio problems for a general class of additively separable utility functions and polyhedral ambiguity distribution set, applied to a large-scale set of assets. Our technique is validated using a large-scale portfolio of the S&P 500 index constituents, demonstrating robust out-of-sample trading performance. More importantly, our empirical studies show that this approach significantly reduces computational time compared to traditional concave Expected Log-Growth (ELG) optimization, with running times decreasing from several thousand seconds to just a few. This method provides a scalable and practical solution to large-scale robust portfolio optimization, addressing both theoretical and practical challenges.         ",
    "url": "https://arxiv.org/abs/2408.07879",
    "authors": [
      "Chung-Han Hsieh",
      "Jie-Ling Lu"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Portfolio Management (q-fin.PM)"
    ]
  },
  {
    "id": "arXiv:2408.07890",
    "title": "Local Causal Discovery with Background Knowledge",
    "abstract": "           Causality plays a pivotal role in various fields of study. Based on the framework of causal graphical models, previous works have proposed identifying whether a variable is a cause or non-cause of a target in every Markov equivalent graph solely by learning a local structure. However, the presence of prior knowledge, often represented as a partially known causal graph, is common in many causal modeling applications. Leveraging this prior knowledge allows for the further identification of causal relationships. In this paper, we first propose a method for learning the local structure using all types of causal background knowledge, including direct causal information, non-ancestral information and ancestral information. Then we introduce criteria for identifying causal relationships based solely on the local structure in the presence of prior knowledge. We also apply out method to fair machine learning, and experiments involving local structure learning, causal relationship identification, and fair machine learning demonstrate that our method is both effective and efficient.         ",
    "url": "https://arxiv.org/abs/2408.07890",
    "authors": [
      "Qingyuan Zheng",
      "Yue Liu",
      "Yangbo He"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.07903",
    "title": "Deep Joint Denoising and Detection for Enhanced Intracellular Particle Analysis",
    "abstract": "           Reliable analysis of intracellular dynamic processes in time-lapse fluorescence microscopy images requires complete and accurate tracking of all small particles in all time frames of the image sequences. A fundamental first step towards this goal is particle detection. Given the small size of the particles, their detection is greatly affected by image noise. Recent studies have shown that applying image denoising as a preprocessing step indeed improves particle detection and their subsequent tracking. Deep learning based particle detection methods have shown superior results compared to traditional detection methods. However, they do not explicitly aim to remove noise from the images to facilitate detection. Thus we hypothesize that their performance could be further improved. In this paper, we propose a new deep neural network, called DENODET (denoising-detection network), which performs image denoising and particle detection simultaneously. We show that integrative denoising and detection yields more accurate detection results. Our method achieves superior results compared to state-of-the-art particle detection methods on the particle tracking challenge dataset and our own real fluorescence microscopy image data.         ",
    "url": "https://arxiv.org/abs/2408.07903",
    "authors": [
      "Yao Yao",
      "Ihor Smal",
      "Ilya Grigoriev",
      "Anna Akhmanova",
      "Erik Meijering"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.07941",
    "title": "Robust Offline Active Learning on Graphs",
    "abstract": "           We consider the problem of active learning on graphs, which has crucial applications in many real-world networks where labeling node responses is expensive. In this paper, we propose an offline active learning method that selects nodes to query by explicitly incorporating information from both the network structure and node covariates. Building on graph signal recovery theories and the random spectral sparsification technique, the proposed method adopts a two-stage biased sampling strategy that takes both informativeness and representativeness into consideration for node querying. Informativeness refers to the complexity of graph signals that are learnable from the responses of queried nodes, while representativeness refers to the capacity of queried nodes to control generalization errors given noisy node-level information. We establish a theoretical relationship between generalization error and the number of nodes selected by the proposed method. Our theoretical results demonstrate the trade-off between informativeness and representativeness in active learning. Extensive numerical experiments show that the proposed method is competitive with existing graph-based active learning methods, especially when node covariates and responses contain noises. Additionally, the proposed method is applicable to both regression and classification tasks on graphs.         ",
    "url": "https://arxiv.org/abs/2408.07941",
    "authors": [
      "Yuanchen Wu",
      "Yubai Yuan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.07977",
    "title": "Cortical network reconfiguration aligns with shifts of basal ganglia and cerebellar influence",
    "abstract": "           Mammalian functional architecture flexibly adapts, transitioning from integration where information is distributed across the cortex, to segregation where information is focal in densely connected communities of brain regions. This flexibility in cortical brain networks is hypothesized to be driven by control signals originating from subcortical pathways, with the basal ganglia shifting the cortex towards integrated processing states and the cerebellum towards segregated states. In a sample of healthy human participants (N=242), we used fMRI to measure temporal variation in global brain networks while participants performed two tasks with similar cognitive demands (Stroop and Multi-Source Inference Task (MSIT)). Using the modularity index, we determined cortical networks shifted from integration (low modularity) at rest to high modularity during easier i.e. congruent (segregation). Increased task difficulty (incongruent) resulted in lower modularity in comparison to the easier counterpart indicating more integration of the cortical network. Influence of basal ganglia and cerebellum was measured using eigenvector centrality. Results correlated with decreases and increases in cortical modularity respectively, with only the basal ganglia influence preceding cortical integration. Our results support the theory the basal ganglia shifts cortical networks to integrated states due to environmental demand. Cerebellar influence correlates with shifts to segregated cortical states, though may not play a causal role.         ",
    "url": "https://arxiv.org/abs/2408.07977",
    "authors": [
      "Kimberly Nestor",
      "Javier Rasero",
      "Richard Betzel",
      "Peter J. Gianaros",
      "Timothy Verstynen"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2408.08038",
    "title": "PI-Att: Topology Attention for Segmentation Networks through Adaptive Persistence Image Representation",
    "abstract": "           Segmenting multiple objects (e.g., organs) in medical images often requires an understanding of their topology, which simultaneously quantifies the shape of the objects and their positions relative to each other. This understanding is important for segmentation networks to generalize better with limited training data, which is common in medical image analysis. However, many popular networks were trained to optimize only pixel-wise performance, ignoring the topological correctness of the segmentation. In this paper, we introduce a new topology-aware loss function, which we call PI-Att, that explicitly forces the network to minimize the topological dissimilarity between the ground truth and prediction maps. We quantify the topology of each map by the persistence image representation, for the first time in the context of a segmentation network loss. Besides, we propose a new mechanism to adaptively calculate the persistence image at the end of each epoch based on the network's performance. This adaptive calculation enables the network to learn topology outline in the first epochs, and then topology details towards the end of training. The effectiveness of the proposed PI-Att loss is demonstrated on two different datasets for aorta and great vessel segmentation in computed tomography images.         ",
    "url": "https://arxiv.org/abs/2408.08038",
    "authors": [
      "Mehmet Bahadir Erden",
      "Sinan Unver",
      "Ilke Ali Gurses",
      "Rustu Turkay",
      "Cigdem Gunduz-Demir"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.08065",
    "title": "SPEED: Scalable Preprocessing of EEG Data for Self-Supervised Learning",
    "abstract": "           Electroencephalography (EEG) research typically focuses on tasks with narrowly defined objectives, but recent studies are expanding into the use of unlabeled data within larger models, aiming for a broader range of applications. This addresses a critical challenge in EEG research. For example, Kostas et al. (2021) show that self-supervised learning (SSL) outperforms traditional supervised methods. Given the high noise levels in EEG data, we argue that further improvements are possible with additional preprocessing. Current preprocessing methods often fail to efficiently manage the large data volumes required for SSL, due to their lack of optimization, reliance on subjective manual corrections, and validation processes or inflexible protocols that limit SSL. We propose a Python-based EEG preprocessing pipeline optimized for self-supervised learning, designed to efficiently process large-scale data. This optimization not only stabilizes self-supervised training but also enhances performance on downstream tasks compared to training with raw data.         ",
    "url": "https://arxiv.org/abs/2408.08065",
    "authors": [
      "Anders Gj\u00f8lbye",
      "Lina Skerath",
      "William Lehn-Schi\u00f8ler",
      "Nicolas Langer",
      "Lars Kai Hansen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.08228",
    "title": "Rethinking Medical Anomaly Detection in Brain MRI: An Image Quality Assessment Perspective",
    "abstract": "           Reconstruction-based methods, particularly those leveraging autoencoders, have been widely adopted to perform anomaly detection in brain MRI. While most existing works try to improve detection accuracy by proposing new model structures or algorithms, we tackle the problem through image quality assessment, an underexplored perspective in the field. We propose a fusion quality loss function that combines Structural Similarity Index Measure loss with l1 loss, offering a more comprehensive evaluation of reconstruction quality. Additionally, we introduce a data pre-processing strategy that enhances the average intensity ratio (AIR) between normal and abnormal regions, further improving the distinction of anomalies. By fusing the aforementioned two methods, we devise the image quality assessment (IQA) approach. The proposed IQA approach achieves significant improvements (>10%) in terms of Dice coefficient (DICE) and Area Under the Precision-Recall Curve (AUPRC) on the BraTS21 (T2, FLAIR) and MSULB datasets when compared with state-of-the-art methods. These results highlight the importance of invoking the comprehensive image quality assessment in medical anomaly detection and provide a new perspective for future research in this field.         ",
    "url": "https://arxiv.org/abs/2408.08228",
    "authors": [
      "Zixuan Pan",
      "Jun Xia",
      "Zheyu Yan",
      "Guoyue Xu",
      "Yawen Wu",
      "Zhenge Jia",
      "Jianxu Chen",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.00842",
    "title": "Robust Online Selection with Uncertain Offer Acceptance",
    "abstract": "           Online advertising has motivated interest in online selection problems. Displaying ads to the right users benefits both the platform (e.g., via pay-per-click) and the advertisers (by increasing their reach). In practice, not all users click on displayed ads, while the platform's algorithm may miss the users most disposed to do so. This mismatch decreases the platform's revenue and the advertiser's chances to reach the right customers. With this motivation, we propose a secretary problem where a candidate may or may not accept an offer according to a known probability $p$. Because we do not know the top candidate willing to accept an offer, the goal is to maximize a robust objective defined as the minimum over integers $k$ of the probability of choosing one of the top $k$ candidates, given that one of these candidates will accept an offer. Using Markov decision process theory, we derive a linear program for this max-min objective whose solution encodes an optimal policy. The derivation may be of independent interest, as it is generalizable and can be used to obtain linear programs for many online selection models. We further relax this linear program into an infinite counterpart, which we use to provide bounds for the objective and closed-form policies. For $p \\geq p^* \\approx 0.6$, an optimal policy is a simple threshold rule that observes the first $p^{1/(1-p)}$ fraction of candidates and subsequently makes offers to the best candidate observed so far.         ",
    "url": "https://arxiv.org/abs/2112.00842",
    "authors": [
      "Sebastian Perez-Salazar",
      "Mohit Singh",
      "Alejandro Toriello"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2207.09792",
    "title": "Unsupervised Industrial Anomaly Detection via Pattern Generative and Contrastive Networks",
    "abstract": "           It is hard to collect enough flaw images for training deep learning network in industrial production. Therefore, existing industrial anomaly detection methods prefer to use CNN-based unsupervised detection and localization network to achieve this task. However, these methods always fail when there are varieties happened in new signals since traditional end-to-end networks suffer barriers of fitting nonlinear model in high-dimensional space. Moreover, they have a memory library by clustering the feature of normal images essentially, which cause it is not robust to texture change. To this end, we propose the Vision Transformer based (VIT-based) unsupervised anomaly detection network. It utilizes a hierarchical task learning and human experience to enhance its interpretability. Our network consists of pattern generation and comparison networks. Pattern generation network uses two VIT-based encoder modules to extract the feature of two consecutive image patches, then uses VIT-based decoder module to learn the human designed style of these features and predict the third image patch. After this, we use the Siamese-based network to compute the similarity of the generation image patch and original image patch. Finally, we refine the anomaly localization by the bi-directional inference strategy. Comparison experiments on public dataset MVTec dataset show our method achieves 99.8% AUC, which surpasses previous state-of-the-art methods. In addition, we give a qualitative illustration on our own leather and cloth datasets. The accurate segment results strongly prove the accuracy of our method in anomaly detection.         ",
    "url": "https://arxiv.org/abs/2207.09792",
    "authors": [
      "Jianfeng Huang",
      "Chenyang Li",
      "Yimin Lin",
      "Shiguo Lian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.06357",
    "title": "Real-World Networks are Low-Dimensional: Theoretical and Practical Assessment",
    "abstract": "           Detecting the dimensionality of graphs is a central topic in machine learning. While the problem has been tackled empirically as well as theoretically, existing methods have several drawbacks. On the one hand, empirical tools are computationally heavy and lack theoretical foundation. On the other hand, theoretical approaches do not apply to graphs with heterogeneous degree distributions, which is often the case for complex real-world networks. To address these drawbacks, we consider geometric inhomogeneous random graphs (GIRGs) as a random graph model, which captures a variety of properties observed in practice. Our first result shows that the clustering coefficient of GIRGs scales inverse exponentially with respect to the number of dimensions, when the latter is at most logarithmic in $n$. This gives a first theoretical explanation for the low dimensionality of real-world networks as observed by Almagro et al. in 2022. We further use these insights to derive a linear-time algorithm for determining the dimensionality of a given GIRG and prove that our algorithm returns the correct number of dimensions with high probability GIRG. Our algorithm bridges the gap between theory and practice, as it not only comes with a rigorous proof of correctness but also yields results comparable to that of prior empirical approaches, as indicated by our experiments on real-world instances.         ",
    "url": "https://arxiv.org/abs/2302.06357",
    "authors": [
      "Tobias Friedrich",
      "Andreas G\u00f6bel",
      "Maximilian Katzmann",
      "Leon Schiller"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2303.06815",
    "title": "On Model Compression for Neural Networks: Framework, Algorithm, and Convergence Guarantee",
    "abstract": "           Model compression is a crucial part of deploying neural networks (NNs), especially when the memory and storage of computing devices are limited in many applications. This paper focuses on two model compression techniques: low-rank approximation and weight pruning in neural networks, which are very popular nowadays. However, training NN with low-rank approximation and weight pruning always suffers significant accuracy loss and convergence issues. In this paper, a holistic framework is proposed for model compression from a novel perspective of nonconvex optimization by designing an appropriate objective function. Then, we introduce NN-BCD, a block coordinate descent (BCD) algorithm to solve the nonconvex optimization. One advantage of our algorithm is that an efficient iteration scheme can be derived with closed-form, which is gradient-free. Therefore, our algorithm will not suffer from vanishing/exploding gradient problems. Furthermore, with the Kurdyka-\u0141ojasiewicz (K\u0141) property of our objective function, we show that our algorithm globally converges to a critical point at the rate of O(1/k), where k denotes the number of iterations. Lastly, extensive experiments with tensor train decomposition and weight pruning demonstrate the efficiency and superior performance of the proposed framework. Our code implementation is available at this https URL ",
    "url": "https://arxiv.org/abs/2303.06815",
    "authors": [
      "Chenyang Li",
      "Jihoon Chung",
      "Mengnan Du",
      "Haimin Wang",
      "Xianlian Zhou",
      "Bo Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.08815",
    "title": "Lane Graph as Path: Continuity-preserving Path-wise Modeling for Online Lane Graph Construction",
    "abstract": "           Online lane graph construction is a promising but challenging task in autonomous driving. Previous methods usually model the lane graph at the pixel or piece level, and recover the lane graph by pixel-wise or piece-wise connection, which breaks down the continuity of the lane and results in suboptimal performance. Human drivers focus on and drive along the continuous and complete paths instead of considering lane pieces. Autonomous vehicles also require path-specific guidance from lane graph for trajectory planning. We argue that the path, which indicates the traffic flow, is the primitive of the lane graph. Motivated by this, we propose to model the lane graph in a novel path-wise manner, which well preserves the continuity of the lane and encodes traffic information for planning. We present a path-based online lane graph construction method, termed LaneGAP, which end-to-end learns the path and recovers the lane graph via a Path2Graph algorithm. We qualitatively and quantitatively demonstrate the superior accuracy and efficiency of LaneGAP over conventional pixel-based and piece-based methods on the challenging nuScenes and Argoverse2 datasets under controllable and fair conditions. Compared to the recent state-of-the-art piece-wise method TopoNet on the OpenLane-V2 dataset, LaneGAP still outperforms by 1.6 mIoU, further validating the effectiveness of path-wise modeling. Abundant visualizations in the supplementary material show LaneGAP can cope with diverse traffic conditions. Code is released at \\url{this https URL}.         ",
    "url": "https://arxiv.org/abs/2303.08815",
    "authors": [
      "Bencheng Liao",
      "Shaoyu Chen",
      "Bo Jiang",
      "Tianheng Cheng",
      "Qian Zhang",
      "Wenyu Liu",
      "Chang Huang",
      "Xinggang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.10015",
    "title": "DyFFPAD: Dynamic Fusion of Convolutional and Handcrafted Features for Fingerprint Presentation Attack Detection",
    "abstract": "           Automatic fingerprint recognition systems suffer from the threat of presentation attacks due to their wide range of deployment in areas including national borders and commercial applications. A presentation attack can be performed by creating a spoof of a user's fingerprint with or without their consent. This paper presents a dynamic ensemble of deep CNN and handcrafted features to detect presentation attacks in known-material and unknown-material protocols of the livness detection competition. The proposed presentation attack detection model, in this way, utilizes the capabilities of both deep CNN and handcrafted features techniques and exhibits better performance than their individual performances. We have validated our proposed method on benchmark databases from the Liveness Detection Competition in 2015, 2017, and 2019, yielding overall accuracy of 96.10\\%, 96.49\\%, and 94.99\\% on them, respectively. The proposed method outperforms state-of-the-art methods in terms of classification accuracy.         ",
    "url": "https://arxiv.org/abs/2308.10015",
    "authors": [
      "Anuj Rai",
      "Parsheel Kumar Tiwari",
      "Jyotishna Baishya",
      "Ram Prakash Sharma",
      "Somnath Dey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.01069",
    "title": "Separable Hamiltonian Neural Networks",
    "abstract": "           Hamiltonian neural networks (HNNs) are state-of-the-art models that regress the vector field of a dynamical system under the learning bias of Hamilton's equations. A recent observation is that embedding a bias regarding the additive separability of the Hamiltonian reduces the regression complexity and improves regression performance. We propose separable HNNs that embed additive separability within HNNs using observational, learning, and inductive biases. We show that the proposed models are more effective than the HNN at regressing the Hamiltonian and the vector field. Consequently, the proposed models predict the dynamics and conserve the total energy of the Hamiltonian system more accurately.         ",
    "url": "https://arxiv.org/abs/2309.01069",
    "authors": [
      "Zi-Yu Khoo",
      "Dawen Wu",
      "Jonathan Sze Choong Low",
      "St\u00e9phane Bressan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.07443",
    "title": "Learning Tube-Certified Neural Robust Contraction Metrics",
    "abstract": "           Control design for general nonlinear robotic systems with guaranteed stability and/or safety in the presence of model uncertainties is a challenging problem. Recent efforts attempt to learn a controller and a certificate (e.g., a Lyapunov function or a contraction metric) jointly using neural networks (NNs), in which model uncertainties are generally ignored during the learning process. In this paper, for nonlinear systems subject to bounded disturbances, we present a framework for jointly learning a robust nonlinear controller and a contraction metric using a novel disturbance rejection objective that certifies a tube bound using NNs for user-specified variables (e.g. control inputs). The learned controller aims to minimize the effect of disturbances on the actual trajectories of state and/or input variables from their nominal counterparts while providing certificate tubes around nominal trajectories that are guaranteed to contain actual trajectories in the presence of disturbances. Experimental results demonstrate that our framework can generate tighter (smaller) tubes and a controller that is computationally efficient to implement.         ",
    "url": "https://arxiv.org/abs/2309.07443",
    "authors": [
      "Vivek Sharma",
      "Pan Zhao",
      "Naira Hovakimyan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2312.10237",
    "title": "A Distributed Privacy Preserving Model for the Detection of Alzheimer's Disease",
    "abstract": "           BACKGROUND: Segmentation of medical data, concerns about personal health information (PHI) breaches, and the direct and indirect costs of consolidating and managing such segmented date should motivate diagnostic machine learning (DML) researchers to identify privacy-preserving machine learning algorithms that can train on distributed or decentralized datasets of different modalities. Federated learning models provide such a decentralized machine learning framework in which multiple investigators in possession of disparate datasets and working on different devices or servers can train collaboratively a global machine learning models without ever having to exchange local data and thus can meet statutory PHI protections. To this end, a vertical federate learning model is devised and tested for efficacy in the detection of Alzheimer's Disease (AD). METHODS: The second version of Open Access Series of Imaging Studies -- with its panoply of demographic, imaging, and clinical assessment datasets -- was used to test a multimodal vertical federated learning (VFL) model for AD detection. RESULTS: By training and validating this VFL model on the demographic, clinical, and MRI data in OASIS-2, an 82.9\\% accuracy rate is achieved, consistent with previously reported results. CONCLUSIONS: The VFL architecture proposed herein offers a novel distributed architecture, enabling collaborative learning across diverse sources of medical data while respecting statutory privacy constraints. By leveraging multiple modalities of data, the robustness and accuracy of AD detection can be enhanced. This model not only contributes to the advancement of federated learning techniques but also holds promise for overcoming the hurdles posed by data segmentation in medical research.         ",
    "url": "https://arxiv.org/abs/2312.10237",
    "authors": [
      "Paul K. Mandal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2312.13511",
    "title": "Symmetry-enforcing neural networks with applications to constitutive modeling",
    "abstract": "           The use of machine learning techniques to homogenize the effective behavior of arbitrary microstructures has been shown to be not only efficient but also accurate. In a recent work, we demonstrated how to combine state-of-the-art micromechanical modeling and advanced machine learning techniques to homogenize complex microstructures exhibiting non-linear and history dependent behaviors (Logarzo et al., 2021). The resulting homogenized model, termed smart constitutive law (SCL), enables the adoption of microstructurally informed constitutive laws into finite element solvers at a fraction of the computational cost required by traditional concurrent multiscale approaches. In this work, the capabilities of SCLs are expanded via the introduction of a novel methodology that enforces material symmetries at the neuron level, applicable across various neural network architectures. This approach utilizes tensor-based features in neural networks, facilitating the concise and accurate representation of symmetry-preserving operations, and is general enough to be extend to problems beyond constitutive modeling. Details on the construction of these tensor-based neural networks and their application in learning constitutive laws are presented for both elastic and inelastic materials. The superiority of this approach over traditional neural networks is demonstrated in scenarios with limited data and strong symmetries, through comprehensive testing on various materials, including isotropic neo-Hookean materials and tensegrity lattice metamaterials. This work is concluded by a discussion on the potential of this methodology to discover symmetry bases in materials and by an outline of future research directions.         ",
    "url": "https://arxiv.org/abs/2312.13511",
    "authors": [
      "K\u00e9vin Garanger",
      "Julie Kraus",
      "Julian J. Rimoli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)"
    ]
  },
  {
    "id": "arXiv:2401.06542",
    "title": "Robustness-Aware 3D Object Detection in Autonomous Driving: A Review and Outlook",
    "abstract": "           In the realm of modern autonomous driving, the perception system is indispensable for accurately assessing the state of the surrounding environment, thereby enabling informed prediction and planning. The key step to this system is related to 3D object detection that utilizes vehicle-mounted sensors such as LiDAR and cameras to identify the size, the category, and the location of nearby objects. Despite the surge in 3D object detection methods aimed at enhancing detection precision and efficiency, there is a gap in the literature that systematically examines their resilience against environmental variations, noise, and weather changes. This study emphasizes the importance of robustness, alongside accuracy and latency, in evaluating perception systems under practical scenarios. Our work presents an extensive survey of camera-only, LiDAR-only, and multi-modal 3D object detection algorithms, thoroughly evaluating their trade-off between accuracy, latency, and robustness, particularly on datasets like KITTI-C and nuScenes-C to ensure fair comparisons. Among these, multi-modal 3D detection approaches exhibit superior robustness, and a novel taxonomy is introduced to reorganize the literature for enhanced clarity. This survey aims to offer a more practical perspective on the current capabilities and the constraints of 3D object detection algorithms in real-world applications, thus steering future research towards robustness-centric advancements.         ",
    "url": "https://arxiv.org/abs/2401.06542",
    "authors": [
      "Ziying Song",
      "Lin Liu",
      "Feiyang Jia",
      "Yadan Luo",
      "Guoxin Zhang",
      "Lei Yang",
      "Li Wang",
      "Caiyan Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2401.10239",
    "title": "Line zonotopes: a set representation suitable for unbounded systems and its application to set-based state estimation and active fault diagnosis of descriptor systems",
    "abstract": "           This paper proposes new methods for set-based state estimation and active fault diagnosis (AFD) of linear descriptor systems (LDS). In contrast to intervals, ellipsoids, and zonotopes, linear static constraints on the state variables, typical of descriptor systems, can be directly incorporated in the mathematical description of constrained zonotopes (CZs). Thanks to this feature, methods using CZs could provide less conservative enclosures than zonotope methods. However, an enclosure on the states should be known for all $k \\geq 0$, which is not true in the case of unstable or unobservable LDS. In this context, this paper proposes a new representation for unbounded sets, which allows to develop methods for state estimation and AFD of stable and unstable LDS. Unlike many other extensions of CZs, the proposed set inherits most of their properties, including polynomial time complexity reduction methods, while allowing to describe different classes of sets, such as strips, hyperplanes, and the entire $n$-dimensional Euclidean space. The advantages of the proposed approaches with respect to CZ methods are highlighted in numerical examples.         ",
    "url": "https://arxiv.org/abs/2401.10239",
    "authors": [
      "Brenner S. Rego",
      "Davide M. Raimondo",
      "Guilherme V. Raffo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2401.12214",
    "title": "Quality-Aware Hydraulic Control in Drinking Water Networks via Controllability Proxies",
    "abstract": "           The operation of water distribution networks is a complex procedure aimed at efficiently delivering consumers with adequate water quantity while ensuring its safe quality. An added challenge is the dependency of the water quality dynamics on the system's hydraulics, which influences the performance of the water quality controller. Prior research has addressed either solving the optimum operational hydraulic setting problem or regulating the water quality dynamics as separate problems. Additionally, there have been efforts to couple these two problems and solve one compact problem resulting in trade-offs between the contradictory objectives. In contrast, this paper takes a novel approach by examining the water quality dependency on the hydraulics from a control-theoretic standpoint. More specifically, we explore the influence of accountability for water quality controllability improvement when addressing the pump scheduling problem. We examine its effects on the cumulative cost of the interconnected systems as well as the subsequent performance of the water quality controller. To achieve this, we develop a framework that incorporates different controllability metrics within the operational hydraulic optimization problem; its aim is attaining an adequate level of water quality control across the system. We assess the aforementioned aspects' performance on various scaled networks with a wide range of numerical scenarios.         ",
    "url": "https://arxiv.org/abs/2401.12214",
    "authors": [
      "Salma M. Elsherif",
      "Mohamad H. Kazma",
      "Ahmad F. Taha"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2401.15931",
    "title": "EmoDM: A Diffusion Model for Evolutionary Multi-objective Optimization",
    "abstract": "           Evolutionary algorithms have been successful in solving multi-objective optimization problems (MOPs). However, as a class of population-based search methodology, evolutionary algorithms require a large number of evaluations of the objective functions, preventing them from being applied to a wide range of expensive MOPs. To tackle the above challenge, this work proposes for the first time a diffusion model that can learn to perform evolutionary multi-objective search, called EmoDM. This is achieved by treating the reversed convergence process of evolutionary search as the forward diffusion and learn the noise distributions from previously solved evolutionary optimization tasks. The pre-trained EmoDM can then generate a set of non-dominated solutions for a new MOP by means of its reverse diffusion without further evolutionary search, thereby significantly reducing the required function evaluations. To enhance the scalability of EmoDM, a mutual entropy-based attention mechanism is introduced to capture the decision variables that are most important for the objectives. Experimental results demonstrate the competitiveness of EmoDM in terms of both the search performance and computational efficiency compared with state-of-the-art evolutionary algorithms in solving MOPs having up to 5000 decision variables. The pre-trained EmoDM is shown to generalize well to unseen problems, revealing its strong potential as a general and efficient MOP solver.         ",
    "url": "https://arxiv.org/abs/2401.15931",
    "authors": [
      "Xueming Yan",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2401.17435",
    "title": "Can LLMs Replace Economic Choice Prediction Labs? The Case of Language-based Persuasion Games",
    "abstract": "           Human choice prediction in economic contexts is crucial for applications in marketing, finance, public policy, and more. This task, however, is often constrained by the difficulties in acquiring human choice data. With most experimental economics studies focusing on simple choice settings, the AI community has explored whether LLMs can substitute for humans in these predictions and examined more complex experimental economics settings. However, a key question remains: can LLMs generate training data for human choice prediction? We explore this in language-based persuasion games, a complex economic setting involving natural language in strategic interactions. Our experiments show that models trained on LLM-generated data can effectively predict human behavior in these games and even outperform models trained on actual human data.         ",
    "url": "https://arxiv.org/abs/2401.17435",
    "authors": [
      "Eilam Shapira",
      "Omer Madmon",
      "Roi Reichart",
      "Moshe Tennenholtz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Science and Game Theory (cs.GT)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2402.10686",
    "title": "On the Impact of Uncertainty and Calibration on Likelihood-Ratio Membership Inference Attacks",
    "abstract": "           In a membership inference attack (MIA), an attacker exploits the overconfidence exhibited by typical machine learning models to determine whether a specific data point was used to train a target model. In this paper, we analyze the performance of the state-of-the-art likelihood ratio attack (LiRA) within an information-theoretical framework that allows the investigation of the impact of the aleatoric uncertainty in the true data generation process, of the epistemic uncertainty caused by a limited training data set, and of the calibration level of the target model. We compare three different settings, in which the attacker receives decreasingly informative feedback from the target model: confidence vector (CV) disclosure, in which the output probability vector is released; true label confidence (TLC) disclosure, in which only the probability assigned to the true label is made available by the model; and decision set (DS) disclosure, in which an adaptive prediction set is produced as in conformal prediction. We derive bounds on the advantage of an MIA adversary with the aim of offering insights into the impact of uncertainty and calibration on the effectiveness of MIAs. Simulation results demonstrate that the derived analytical bounds predict well the effectiveness of MIAs.         ",
    "url": "https://arxiv.org/abs/2402.10686",
    "authors": [
      "Meiyi Zhu",
      "Caili Guo",
      "Chunyan Feng",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2402.13812",
    "title": "Voice-Driven Mortality Prediction in Hospitalized Heart Failure Patients: A Machine Learning Approach Enhanced with Diagnostic Biomarkers",
    "abstract": "           Addressing heart failure (HF) as a prevalent global health concern poses difficulties in implementing innovative approaches for enhanced patient care. Predicting mortality rates in HF patients, in particular, is difficult yet critical, necessitating individualized care, proactive management, and enabling educated decision-making to enhance outcomes. Recently, the significance of voice biomarkers coupled with Machine Learning (ML) has surged, demonstrating remarkable efficacy, particularly in predicting heart failure. The synergy of voice analysis and ML algorithms provides a non-invasive and easily accessible means to evaluate patients' health. However, there is a lack of voice biomarkers for predicting mortality rates among heart failure patients with standardized speech protocols. Here, we demonstrate a powerful and effective ML model for predicting mortality rates in hospitalized HF patients through the utilization of voice biomarkers. By seamlessly integrating voice biomarkers into routine patient monitoring, this strategy has the potential to improve patient outcomes, optimize resource allocation, and advance patient-centered HF management. In this study, a Machine Learning system, specifically a logistic regression model, is trained to predict patients' 5-year mortality rates using their speech as input. The model performs admirably and consistently, as demonstrated by cross-validation and statistical approaches (p-value < 0.001). Furthermore, integrating NT-proBNP, a diagnostic biomarker in HF, improves the model's predictive accuracy substantially.         ",
    "url": "https://arxiv.org/abs/2402.13812",
    "authors": [
      "Nihat Ahmadli",
      "Mehmet Ali Sarsil",
      "Berk Mizrak",
      "Kurtulus Karauzum",
      "Ata Shaker",
      "Erol Tulumen",
      "Didar Mirzamidinov",
      "Dilek Ural",
      "Onur Ergen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2402.15894",
    "title": "Multi-graph Graph Matching for Coronary Artery Semantic Labeling",
    "abstract": "           Coronary artery disease (CAD) stands as the leading cause of death worldwide, and invasive coronary angiography (ICA) remains the gold standard for assessing vascular anatomical information. However, deep learning-based methods encounter challenges in generating semantic labels for arterial segments, primarily due to the morphological similarity between arterial branches and varying anatomy of arterial system between different projection view angles and patients. To address this challenge, we model the vascular tree as a graph and propose a multi-graph graph matching (MGM) algorithm for coronary artery semantic labeling. The MGM algorithm assesses the similarity between arterials in multiple vascular tree graphs, considering the cycle consistency between each pair of graphs. As a result, the unannotated arterial segments are appropriately labeled by matching them with annotated segments. Through the incorporation of anatomical graph structure, radiomics features, and semantic mapping, the proposed MGM model achieves an impressive accuracy of 0.9471 for coronary artery semantic labeling using our multi-site dataset with 718 ICAs. With the semantic labeled arteries, an overall accuracy of 0.9155 was achieved for stenosis detection. The proposed MGM presents a novel tool for coronary artery analysis using multiple ICA-derived graphs, offering valuable insights into vascular health and pathology.         ",
    "url": "https://arxiv.org/abs/2402.15894",
    "authors": [
      "Chen Zhao",
      "Zhihui Xu",
      "Pukar Baral",
      "Michel Esposito",
      "Weihua Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2402.17514",
    "title": "Robust Zero-Shot Crowd Counting and Localization With Adaptive Resolution SAM",
    "abstract": "           The existing crowd counting models require extensive training data, which is time-consuming to annotate. To tackle this issue, we propose a simple yet effective crowd counting method by utilizing the Segment-Everything-Everywhere Model (SEEM), an adaptation of the Segmentation Anything Model (SAM), to generate pseudo-labels for training crowd counting models. However, our initial investigation reveals that SEEM's performance in dense crowd scenes is limited, primarily due to the omission of many persons in high-density areas. To overcome this limitation, we propose an adaptive resolution SEEM to handle the scale variations, occlusions, and overlapping of people within crowd scenes. Alongside this, we introduce a robust localization method, based on Gaussian Mixture Models, for predicting the head positions in the predicted people masks. Given the mask and point pseudo-labels, we propose a robust loss function, which is designed to exclude uncertain regions based on SEEM's predictions, thereby enhancing the training process of the counting networks. Finally, we propose an iterative method for generating pseudo-labels. This method aims at improving the quality of the segmentation masks by identifying more tiny persons in high-density regions, which are often missed in the first pseudo-labeling stage. Overall, our proposed method achieves the best unsupervised performance in crowd counting, while also being comparable results to some supervised methods. This makes it a highly effective and versatile tool for crowd counting, especially in situations where labeled data is not available.         ",
    "url": "https://arxiv.org/abs/2402.17514",
    "authors": [
      "Jia Wan",
      "Qiangqiang Wu",
      "Wei Lin",
      "Antoni B. Chan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.09039",
    "title": "Detecting Anomalies in Dynamic Graphs via Memory enhanced Normality",
    "abstract": "           Anomaly detection in dynamic graphs presents a significant challenge due to the temporal evolution of graph structures and attributes. The conventional approaches that tackle this problem typically employ an unsupervised learning framework, capturing normality patterns with exclusive normal data during training and identifying deviations as anomalies during testing. However, these methods face critical drawbacks: they either only depend on proxy tasks for representation without directly pinpointing normal patterns, or they neglect to differentiate between spatial and temporal normality patterns. More recent methods that use contrastive learning with negative sampling also face high computational costs, limiting their scalability to large graphs. To address these challenges, we introduce a novel Spatial-Temporal memories-enhanced graph autoencoder (STRIPE). Initially, STRIPE employs Graph Neural Networks (GNNs) and gated temporal convolution layers to extract spatial and temporal features. Then STRIPE incorporates separate spatial and temporal memory networks to capture and store prototypes of normal patterns, respectively. These stored patterns are retrieved and integrated with encoded graph embeddings through a mutual attention mechanism. Finally, the integrated features are fed into the decoder to reconstruct the graph streams which serve as the proxy task for anomaly detection. This comprehensive approach not only minimizes reconstruction errors but also emphasizes the compactness and distinctiveness of the embeddings w.r.t. the nearest memory prototypes. Extensive experiments on six benchmark datasets demonstrate the effectiveness and efficiency of STRIPE, where STRIPE significantly outperforms existing methods with 5.8% improvement in AUC scores and 4.62X faster in training time.         ",
    "url": "https://arxiv.org/abs/2403.09039",
    "authors": [
      "Jie Liu",
      "Xuequn Shang",
      "Xiaolin Han",
      "Kai Zheng",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2403.11192",
    "title": "Self-Supervised Video Desmoking for Laparoscopic Surgery",
    "abstract": "           Due to the difficulty of collecting real paired data, most existing desmoking methods train the models by synthesizing smoke, generalizing poorly to real surgical scenarios. Although a few works have explored single-image real-world desmoking in unpaired learning manners, they still encounter challenges in handling dense smoke. In this work, we address these issues together by introducing the self-supervised surgery video desmoking (SelfSVD). On the one hand, we observe that the frame captured before the activation of high-energy devices is generally clear (named pre-smoke frame, PS frame), thus it can serve as supervision for other smoky frames, making real-world self-supervised video desmoking practically feasible. On the other hand, in order to enhance the desmoking performance, we further feed the valuable information from PS frame into models, where a masking strategy and a regularization term are presented to avoid trivial solutions. In addition, we construct a real surgery video dataset for desmoking, which covers a variety of smoky scenes. Extensive experiments on the dataset show that our SelfSVD can remove smoke more effectively and efficiently while recovering more photo-realistic details than the state-of-the-art methods. The dataset, codes, and pre-trained models are available at \\url{this https URL}.         ",
    "url": "https://arxiv.org/abs/2403.11192",
    "authors": [
      "Renlong Wu",
      "Zhilu Zhang",
      "Shuohao Zhang",
      "Longfei Gou",
      "Haobin Chen",
      "Lei Zhang",
      "Hao Chen",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2403.15307",
    "title": "Strategic Network Creation for Enabling Greedy Routing",
    "abstract": "           Today we rely on networks that are created and maintained by smart devices. For such networks, there is no governing central authority but instead the network structure is shaped by the decisions of selfish intelligent agents. A key property of such communication networks is that they should be easy to navigate for routing data. For this, a common approach is greedy routing, where every device simply routes data to a neighbor that is closer to the respective destination. Networks of intelligent agents can be analyzed via a game-theoretic approach and in the last decades many variants of network creation games have been proposed and analyzed. In this paper we present the first game-theoretic network creation model that incorporates greedy routing, i.e., the strategic agents in our model are embedded in some metric space and strive for creating a network among themselves where all-pairs greedy routing is enabled. Besides this, the agents optimize their connection quality within the created network by aiming for greedy routing paths with low stretch. For our model, we analyze the existence of (approximate)-equilibria and the computational hardness in different underlying metric spaces. E.g., we characterize the set of equilibria in 1-2-metrics and tree metrics and show that Nash equilibria always exist. For Euclidean space, the setting which is most relevant in practice, we prove that equilibria are not guaranteed to exist but that the well-known $\\Theta$-graph construction yields networks having a low stretch that are game-theoretically almost stable. For general metric spaces, we show that approximate equilibria exist where the approximation factor depends on the cost of maintaining any link.         ",
    "url": "https://arxiv.org/abs/2403.15307",
    "authors": [
      "Julian Berger",
      "Tobias Friedrich",
      "Pascal Lenzner",
      "Paraskevi Machaira",
      "Janosch Ruff"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2404.11357",
    "title": "Detector Collapse: Physical-World Backdooring Object Detection to Catastrophic Overload or Blindness in Autonomous Driving",
    "abstract": "           Object detection tasks, crucial in safety-critical systems like autonomous driving, focus on pinpointing object locations. These detectors are known to be susceptible to backdoor attacks. However, existing backdoor techniques have primarily been adapted from classification tasks, overlooking deeper vulnerabilities specific to object detection. This paper is dedicated to bridging this gap by introducing Detector Collapse} (DC), a brand-new backdoor attack paradigm tailored for object detection. DC is designed to instantly incapacitate detectors (i.e., severely impairing detector's performance and culminating in a denial-of-service). To this end, we develop two innovative attack schemes: Sponge for triggering widespread misidentifications and Blinding for rendering objects invisible. Remarkably, we introduce a novel poisoning strategy exploiting natural objects, enabling DC to act as a practical backdoor in real-world environments. Our experiments on different detectors across several benchmarks show a significant improvement ($\\sim$10\\%-60\\% absolute and $\\sim$2-7$\\times$ relative) in attack efficacy over state-of-the-art attacks.         ",
    "url": "https://arxiv.org/abs/2404.11357",
    "authors": [
      "Hangtao Zhang",
      "Shengshan Hu",
      "Yichen Wang",
      "Leo Yu Zhang",
      "Ziqi Zhou",
      "Xianlong Wang",
      "Yanjun Zhang",
      "Chao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2404.19288",
    "title": "Training-free Graph Neural Networks and the Power of Labels as Features",
    "abstract": "           We propose training-free graph neural networks (TFGNNs), which can be used without training and can also be improved with optional training, for transductive node classification. We first advocate labels as features (LaF), which is an admissible but not explored technique. We show that LaF provably enhances the expressive power of graph neural networks. We design TFGNNs based on this analysis. In the experiments, we confirm that TFGNNs outperform existing GNNs in the training-free setting and converge with much fewer training iterations than traditional GNNs.         ",
    "url": "https://arxiv.org/abs/2404.19288",
    "authors": [
      "Ryoma Sato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2405.00514",
    "title": "Get Your Embedding Space in Order: Domain-Adaptive Regression for Forest Monitoring",
    "abstract": "           Image-level regression is an important task in Earth observation, where visual domain and label shifts are a core challenge hampering generalization. However, cross-domain regression within remote sensing data remains understudied due to the absence of suited datasets. We introduce a new dataset with aerial and satellite imagery in five countries with three forest-related regression tasks. To match real-world applicative interests, we compare methods through a restrictive setup where no prior on the target domain is available during training, and models are adapted with limited information during testing. Building on the assumption that ordered relationships generalize better, we propose manifold diffusion for regression as a strong baseline for transduction in low-data regimes. Our comparison highlights the comparative advantages of inductive and transductive methods in cross-domain regression.         ",
    "url": "https://arxiv.org/abs/2405.00514",
    "authors": [
      "Sizhuo Li",
      "Dimitri Gominski",
      "Martin Brandt",
      "Xiaoye Tong",
      "Philippe Ciais"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2405.09314",
    "title": "Themis: Automatic and Efficient Deep Learning System Testing with Strong Fault Detection Capability",
    "abstract": "           Deep Learning Systems (DLSs) have been widely applied in safety-critical tasks such as autopilot. However, when a perturbed input is fed into a DLS for inference, the DLS often has incorrect outputs (i.e., faults). DLS testing techniques (e.g., DeepXplore) detect such faults by generating perturbed inputs to explore data flows that induce faults. Since a DLS often has infinitely many data flows, existing techniques require developers to manually specify a set of activation values in a DLS's neurons for exploring fault-inducing data flows. Unfortunately, recent studies show that such manual effort is tedious and can detect only a tiny proportion of fault-inducing data flows. In this paper, we present Themis, the first automatic DLS testing system, which attains strong fault detection capability by ensuring a full coverage of fault-inducing data flows at a high probability. Themis carries a new workflow for automatically and systematically revealing data flows whose internal neurons' outputs vary substantially when the inputs are slightly perturbed, as these data flows are likely fault-inducing. We evaluated Themis on ten different DLSs and found that on average the number of faults detected by Themis was 3.78X more than four notable DLS testing techniques. By retraining all evaluated DLSs with the detected faults, Themis also increased (regained) these DLSs' accuracies on average 14.7X higher than all baselines.         ",
    "url": "https://arxiv.org/abs/2405.09314",
    "authors": [
      "Dong Huang",
      "Tsz On Li",
      "Xiaofei Xie",
      "Heming Cui"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2405.18458",
    "title": "Asymmetrical estimator for training encapsulated deep photonic neural networks",
    "abstract": "           Scalable isomorphic physical neural networks (PNNs) are emerging NN acceleration paradigms for their high-bandwidth, in-propagation computation. Despite backpropagation (BP)-based training is often the industry standard for its robustness and fast gradient convergences, existing BP-PNN training methods need to truncate the propagation of analogue signal at each layer and acquire accurate hidden neuron readouts for deep networks. This compromises the incentive of PNN for fast in-propagation processing. In addition, the required readouts introduce massive bottlenecks due to the conversions between the analogue-digital interfaces to shuttle information across. These factors limit both the time and energy efficiency during training. Here we introduce the asymmetrical training (AT) method, a BP-based method that can perform training on an encapsulated deep network, where the information propagation is maintained within the analogue domain until the output layer. AT's minimum information access bypass analogue-digital interface bottleneck wherever possible. For any deep network structure, AT offers significantly improved time and energy efficiency compared to existing BP-PNN methods, and scales well for large network sizes. We demonstrated AT's error-tolerant and calibration-free training for encapsulated integrated photonic deep networks to achieve near ideal BP performances. AT's well-behaved training is demonstrated repeatably across different datasets and network structures         ",
    "url": "https://arxiv.org/abs/2405.18458",
    "authors": [
      "Yizhi Wang",
      "Minjia Chen",
      "Chunhui Yao",
      "Jie Ma",
      "Ting Yan",
      "Richard Penty",
      "Qixiang Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2405.20770",
    "title": "Large Language Model Sentinel: LLM Agent for Adversarial Purification",
    "abstract": "           Over the past two years, the use of large language models (LLMs) has advanced rapidly. While these LLMs offer considerable convenience, they also raise security concerns, as LLMs are vulnerable to adversarial attacks by some well-designed textual perturbations. In this paper, we introduce a novel defense technique named Large LAnguage MOdel Sentinel (LLAMOS), which is designed to enhance the adversarial robustness of LLMs by purifying the adversarial textual examples before feeding them into the target LLM. Our method comprises two main components: a) Agent instruction, which can simulate a new agent for adversarial defense, altering minimal characters to maintain the original meaning of the sentence while defending against attacks; b) Defense guidance, which provides strategies for modifying clean or adversarial examples to ensure effective defense and accurate outputs from the target LLMs. Remarkably, the defense agent demonstrates robust defensive capabilities even without learning from adversarial examples. Additionally, we conduct an intriguing adversarial experiment where we develop two agents, one for defense and one for attack, and engage them in mutual confrontation. During the adversarial interactions, neither agent completely beat the other. Extensive experiments on both open-source and closed-source LLMs demonstrate that our method effectively defends against adversarial attacks, thereby enhancing adversarial robustness.         ",
    "url": "https://arxiv.org/abs/2405.20770",
    "authors": [
      "Guang Lin",
      "Qibin Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2406.12614",
    "title": "EUvsDisinfo: a Dataset for Multilingual Detection of Pro-Kremlin Disinformation in News Articles",
    "abstract": "           This work introduces EUvsDisinfo, a multilingual dataset of trustworthy and disinformation articles related to pro-Kremlin themes. It is sourced directly from the debunk articles written by experts leading the EUvsDisinfo project. Our dataset is the largest to-date resource in terms of the overall number of articles and distinct languages. It also provides the largest topical and temporal coverage. Using this dataset, we investigate the dissemination of pro-Kremlin disinformation across different languages, uncovering language-specific patterns targeting specific disinformation topics. We further analyse the evolution of topic distribution over an eight-year period, noting a significant surge in disinformation content before the full-scale invasion of Ukraine in 2022. Lastly, we demonstrate the dataset's applicability in training models to effectively distinguish between disinformation and trustworthy content in multilingual settings.         ",
    "url": "https://arxiv.org/abs/2406.12614",
    "authors": [
      "Jo\u00e3o A. Leite",
      "Olesya Razuvayevskaya",
      "Kalina Bontcheva",
      "Carolina Scarton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2406.14176",
    "title": "A Multi-Stream Fusion Approach with One-Class Learning for Audio-Visual Deepfake Detection",
    "abstract": "           This paper addresses the challenge of developing a robust audio-visual deepfake detection model. In practical use cases, new generation algorithms are continually emerging, and these algorithms are not encountered during the development of detection methods. This calls for the generalization ability of the method. Additionally, to ensure the credibility of detection methods, it is beneficial for the model to interpret which cues from the video indicate it is fake. Motivated by these considerations, we then propose a multi-stream fusion approach with one-class learning as a representation-level regularization technique. We study the generalization problem of audio-visual deepfake detection by creating a new benchmark by extending and re-splitting the existing FakeAVCeleb dataset. The benchmark contains four categories of fake videos (Real Audio-Fake Visual, Fake Audio-Fake Visual, Fake Audio-Real Visual, and Unsynchronized videos). The experimental results demonstrate that our approach surpasses the previous models by a large margin. Furthermore, our proposed framework offers interpretability, indicating which modality the model identifies as more likely to be fake. The source code is released at this https URL.         ",
    "url": "https://arxiv.org/abs/2406.14176",
    "authors": [
      "Kyungbok Lee",
      "You Zhang",
      "Zhiyao Duan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2406.16633",
    "title": "MLAAN: Scaling Supervised Local Learning with Multilaminar Leap Augmented Auxiliary Network",
    "abstract": "           Deep neural networks (DNNs) typically employ an end-to-end (E2E) training paradigm which presents several challenges, including high GPU memory consumption, inefficiency, and difficulties in model parallelization during training. Recent research has sought to address these issues, with one promising approach being local learning. This method involves partitioning the backbone network into gradient-isolated modules and manually designing auxiliary networks to train these local modules. Existing methods often neglect the interaction of information between local modules, leading to myopic issues and a performance gap compared to E2E training. To address these limitations, we propose the Multilaminar Leap Augmented Auxiliary Network (MLAAN). Specifically, MLAAN comprises Multilaminar Local Modules (MLM) and Leap Augmented Modules (LAM). MLM captures both local and global features through independent and cascaded auxiliary networks, alleviating performance issues caused by insufficient global features. However, overly simplistic auxiliary networks can impede MLM's ability to capture global information. To address this, we further design LAM, an enhanced auxiliary network that uses the Exponential Moving Average (EMA) method to facilitate information exchange between local modules, thereby mitigating the shortsightedness resulting from inadequate interaction. The synergy between MLM and LAM has demonstrated excellent performance. Our experiments on the CIFAR-10, STL-10, SVHN, and ImageNet datasets show that MLAAN can be seamlessly integrated into existing local learning frameworks, significantly enhancing their performance and even surpassing end-to-end (E2E) training methods, while also reducing GPU memory consumption.         ",
    "url": "https://arxiv.org/abs/2406.16633",
    "authors": [
      "Yuming Zhang",
      "Shouxin Zhang",
      "Peizhe Wang",
      "Feiyu Zhu",
      "Dongzhi Guan",
      "Junhao Su",
      "Jiabin Liu",
      "Changpeng Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2406.17342",
    "title": "Masked Generative Extractor for Synergistic Representation and 3D Generation of Point Clouds",
    "abstract": "           Representation and generative learning, as reconstruction-based methods, have demonstrated their potential for mutual reinforcement across various domains. In the field of point cloud processing, although existing studies have adopted training strategies from generative models to enhance representational capabilities, these methods are limited by their inability to genuinely generate 3D shapes. To explore the benefits of deeply integrating 3D representation learning and generative learning, we propose an innovative framework called \\textit{Point-MGE}. Specifically, this framework first utilizes a vector quantized variational autoencoder to reconstruct a neural field representation of 3D shapes, thereby learning discrete semantic features of point patches. Subsequently, we design a sliding masking ratios to smooth the transition from representation learning to generative learning. Moreover, our method demonstrates strong generalization capability in learning high-capacity models, achieving new state-of-the-art performance across multiple downstream tasks. In shape classification, Point-MGE achieved an accuracy of 94.2% (+1.0%) on the ModelNet40 dataset and 92.9% (+5.5%) on the ScanObjectNN dataset. Experimental results also confirmed that Point-MGE can generate high-quality 3D shapes in both unconditional and conditional settings.         ",
    "url": "https://arxiv.org/abs/2406.17342",
    "authors": [
      "Hongliang Zeng",
      "Ping Zhang",
      "Fang Li",
      "Jiahua Wang",
      "Tingyu Ye",
      "Pengteng Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2407.14073",
    "title": "LoAS: Fully Temporal-Parallel Datatflow for Dual-Sparse Spiking Neural Networks",
    "abstract": "           Spiking Neural Networks (SNNs) have gained significant research attention in the last decade due to their potential to drive resource-constrained edge devices. Though existing SNN accelerators offer high efficiency in processing sparse spikes with dense weights, opportunities are less explored in SNNs with sparse weights, i.e., dual-sparsity. In this work, we study the acceleration of dual-sparse SNNs, focusing on their core operation, sparse-matrix-sparse-matrix multiplication (spMspM). We observe that naively running a dual-sparse SNN on existing spMspM accelerators designed for dual-sparse Artificial Neural Networks (ANNs) exhibits sub-optimal efficiency. The main challenge is that processing timesteps, a natural property of SNNs, introduces an extra loop to ANN spMspM, leading to longer latency and more memory traffic. To address the problem, we propose a fully temporal-parallel (FTP) dataflow, which minimizes both data movement across timesteps and the end-to-end latency of dual-sparse SNNs. To maximize the efficiency of FTP dataflow, we propose an FTP-friendly spike compression mechanism that efficiently compresses single-bit spikes and ensures contiguous memory access. We further propose an FTP-friendly inner-join circuit that can lower the cost of the expensive prefix-sum circuits with almost no throughput penalty. All the above techniques for FTP dataflow are encapsulated in LoAS, a Low-latency inference Accelerator for dual-sparse SNNs. With FTP dataflow, compression, and inner-join, running dual-sparse SNN workloads on LoAS demonstrates significant speedup (up to $8.51\\times$) and energy reduction (up to $3.68\\times$) compared to running it on prior dual-sparse accelerators.         ",
    "url": "https://arxiv.org/abs/2407.14073",
    "authors": [
      "Ruokai Yin",
      "Youngeun Kim",
      "Di Wu",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2407.14463",
    "title": "SurvReLU: Inherently Interpretable Survival Analysis via Deep ReLU Networks",
    "abstract": "           Survival analysis models time-to-event distributions with censorship. Recently, deep survival models using neural networks have dominated due to their representational power and state-of-the-art performance. However, their \"black-box\" nature hinders interpretability, which is crucial in real-world applications. In contrast, \"white-box\" tree-based survival models offer better interpretability but struggle to converge to global optima due to greedy expansion. In this paper, we bridge the gap between previous deep survival models and traditional tree-based survival models through deep rectified linear unit (ReLU) networks. We show that a deliberately constructed deep ReLU network (SurvReLU) can harness the interpretability of tree-based structures with the representational power of deep survival models. Empirical studies on both simulated and real survival benchmark datasets show the effectiveness of the proposed SurvReLU in terms of performance and interoperability. The code is available at \\href{this https URL}{\\color{magenta}{ this https URL}}.         ",
    "url": "https://arxiv.org/abs/2407.14463",
    "authors": [
      "Xiaotong Sun",
      "Peijie Qiu",
      "Shengfan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2407.15588",
    "title": "Unsupervised Robust Cross-Lingual Entity Alignment via Neighbor Triple Matching with Entity and Relation Texts",
    "abstract": "           Cross-lingual entity alignment (EA) enables the integration of multiple knowledge graphs (KGs) across different languages, providing users with seamless access to diverse and comprehensive knowledge. Existing methods, mostly supervised, face challenges in obtaining labeled entity pairs. To address this, recent studies have shifted towards self-supervised and unsupervised frameworks. Despite their effectiveness, these approaches have limitations: (1) Relation passing: mainly focusing on the entity while neglecting the semantic information of relations, (2) Isomorphic assumption: assuming isomorphism between source and target graphs, which leads to noise and reduced alignment accuracy, and (3) Noise vulnerability: susceptible to noise in the textual features, especially when encountering inconsistent translations or Out-Of-Vocabulary (OOV) problems. In this paper, we propose ERAlign, an unsupervised and robust cross-lingual EA pipeline that jointly performs Entity-level and Relation-level Alignment by neighbor triple matching strategy using semantic textual features of relations and entities. Its refinement step iteratively enhances results by fusing entity-level and relation-level alignments based on neighbor triple matching. The additional verification step examines the entities' neighbor triples as the linearized text. This Align-then-Verify pipeline rigorously assesses alignment results, achieving near-perfect alignment even in the presence of noisy textual features of entities. Our extensive experiments demonstrate that the robustness and general applicability of ERAlign improved the accuracy and effectiveness of EA tasks, contributing significantly to knowledge-oriented applications.         ",
    "url": "https://arxiv.org/abs/2407.15588",
    "authors": [
      "Soojin Yoon",
      "Sungho Ko",
      "Tongyoung Kim",
      "SeongKu Kang",
      "Jinyoung Yeo",
      "Dongha Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.00738",
    "title": "Virchow2: Scaling Self-Supervised Mixed Magnification Models in Pathology",
    "abstract": "           Foundation models are rapidly being developed for computational pathology applications. However, it remains an open question which factors are most important for downstream performance with data scale and diversity, model size, and training algorithm all playing a role. In this work, we propose algorithmic modifications, tailored for pathology, and we present the result of scaling both data and model size, surpassing previous studies in both dimensions. We introduce two new models: Virchow2, a 632 million parameter vision transformer, and Virchow2G, a 1.9 billion parameter vision transformer, each trained with 3.1 million histopathology whole slide images, with diverse tissues, originating institutions, and stains. We achieve state of the art performance on 12 tile-level tasks, as compared to the top performing competing models. Our results suggest that data diversity and domain-specific methods can outperform models that only scale in the number of parameters, but, on average, performance benefits from the combination of domain-specific methods, data scale, and model scale.         ",
    "url": "https://arxiv.org/abs/2408.00738",
    "authors": [
      "Eric Zimmermann",
      "Eugene Vorontsov",
      "Julian Viret",
      "Adam Casson",
      "Michal Zelechowski",
      "George Shaikovski",
      "Neil Tenenholtz",
      "James Hall",
      "David Klimstra",
      "Razik Yousfi",
      "Thomas Fuchs",
      "Nicolo Fusi",
      "Siqi Liu",
      "Kristen Severson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.02906",
    "title": "Dual-View Pyramid Pooling in Deep Neural Networks for Improved Medical Image Classification and Confidence Calibration",
    "abstract": "           Spatial pooling (SP) and cross-channel pooling (CCP) operators have been applied to aggregate spatial features and pixel-wise features from feature maps in deep neural networks (DNNs), respectively. Their main goal is to reduce computation and memory overhead without visibly weakening the performance of DNNs. However, SP often faces the problem of losing the subtle feature representations, while CCP has a high possibility of ignoring salient feature representations, which may lead to both miscalibration of confidence issues and suboptimal medical classification results. To address these problems, we propose a novel dual-view framework, the first to systematically investigate the relative roles of SP and CCP by analyzing the difference between spatial features and pixel-wise features. Based on this framework, we propose a new pooling method, termed dual-view pyramid pooling (DVPP), to aggregate multi-scale dual-view features. DVPP aims to boost both medical image classification and confidence calibration performance by fully leveraging the merits of SP and CCP operators from a dual-axis perspective. Additionally, we discuss how to fulfill DVPP with five parameter-free implementations. Extensive experiments on six 2D/3D medical image classification tasks show that our DVPP surpasses state-of-the-art pooling methods in terms of medical image classification results and confidence calibration across different DNNs.         ",
    "url": "https://arxiv.org/abs/2408.02906",
    "authors": [
      "Xiaoqing Zhang",
      "Qiushi Nie",
      "Zunjie Xiao",
      "Jilu Zhao",
      "Xiao Wu",
      "Pengxin Guo",
      "Runzhi Li",
      "Jin Liu",
      "Yanjie Wei",
      "Yi Pan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.03388",
    "title": "A Non-negative VAE:the Generalized Gamma Belief Network",
    "abstract": "           The gamma belief network (GBN), often regarded as a deep topic model, has demonstrated its potential for uncovering multi-layer interpretable latent representations in text data. Its notable capability to acquire interpretable latent factors is partially attributed to sparse and non-negative gamma-distributed latent variables. However, the existing GBN and its variations are constrained by the linear generative model, thereby limiting their expressiveness and applicability. To address this limitation, we introduce the generalized gamma belief network (Generalized GBN) in this paper, which extends the original linear generative model to a more expressive non-linear generative model. Since the parameters of the Generalized GBN no longer possess an analytic conditional posterior, we further propose an upward-downward Weibull inference network to approximate the posterior distribution of the latent variables. The parameters of both the generative model and the inference network are jointly trained within the variational inference framework. Finally, we conduct comprehensive experiments on both expressivity and disentangled representation learning tasks to evaluate the performance of the Generalized GBN against state-of-the-art Gaussian variational autoencoders serving as baselines.         ",
    "url": "https://arxiv.org/abs/2408.03388",
    "authors": [
      "Zhibin Duan",
      "Tiansheng Wen",
      "Muyao Wang",
      "Bo Chen",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.05426",
    "title": "SAM-FNet: SAM-Guided Fusion Network for Laryngo-Pharyngeal Tumor Detection",
    "abstract": "           Laryngo-pharyngeal cancer (LPC) is a highly fatal malignant disease affecting the head and neck region. Previous studies on endoscopic tumor detection, particularly those leveraging dual-branch network architectures, have shown significant advancements in tumor detection. These studies highlight the potential of dual-branch networks in improving diagnostic accuracy by effectively integrating global and local (lesion) feature extraction. However, they are still limited in their capabilities to accurately locate the lesion region and capture the discriminative feature information between the global and local branches. To address these issues, we propose a novel SAM-guided fusion network (SAM-FNet), a dual-branch network for laryngo-pharyngeal tumor detection. By leveraging the powerful object segmentation capabilities of the Segment Anything Model (SAM), we introduce the SAM into the SAM-FNet to accurately segment the lesion region. Furthermore, we propose a GAN-like feature optimization (GFO) module to capture the discriminative features between the global and local branches, enhancing the fusion feature complementarity. Additionally, we collect two LPC datasets from the First Affiliated Hospital (FAHSYSU) and the Sixth Affiliated Hospital (SAHSYSU) of Sun Yat-sen University. The FAHSYSU dataset is used as the internal dataset for training the model, while the SAHSYSU dataset is used as the external dataset for evaluating the model's performance. Extensive experiments on both datasets of FAHSYSU and SAHSYSU demonstrate that the SAM-FNet can achieve competitive results, outperforming the state-of-the-art counterparts. The source code of SAM-FNet is available at the URL of this https URL.         ",
    "url": "https://arxiv.org/abs/2408.05426",
    "authors": [
      "Jia Wei",
      "Yun Li",
      "Meiyu Qiu",
      "Hongyu Chen",
      "Xiaomao Fan",
      "Wenbin Lei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.06467",
    "title": "Generalization Enhancement Strategies to Enable Cross-year Cropland Mapping with Convolutional Neural Networks Trained Using Historical Samples",
    "abstract": "           The accuracy of mapping agricultural fields across large areas is steadily improving with high-resolution satellite imagery and deep learning (DL) models, even in regions where fields are small and geometrically irregular. However, developing effective DL models often requires large, expensive label datasets, typically available only for specific years or locations. This limits the ability to create annual maps essential for agricultural monitoring, as domain shifts occur between years and regions due to changes in farming practices and environmental conditions. The challenge is to design a model flexible enough to account for these shifts without needing yearly labels. While domain adaptation techniques or semi-supervised training are common solutions, we explored enhancing the model's generalization power. Our results indicate that a holistic approach is essential, combining methods to improve generalization. Specifically, using an area-based loss function, such as Tversky-focal loss (TFL), significantly improved predictions across multiple years. The use of different augmentation techniques helped to encode different types of invariance, particularly photometric augmentations encoded invariance to brightness changes, though they increased false positives. The combination of photometric augmentation, TFL loss, and MC-dropout produced the best results, although dropout alone led to more false negatives in subsequent year predictions. Additionally, the choice of input normalization had a significant impact, with the best results obtained when statistics were calculated either locally or across the entire dataset over all bands (lab and gab). We developed a workflow that enabled a U-Net model to generate effective multi-year crop maps over large areas. Our code, available at: this https URL, will be regularly updated with improvements.         ",
    "url": "https://arxiv.org/abs/2408.06467",
    "authors": [
      "Sam Khallaghi",
      "Rahebe Abedi",
      "Hanan Abou Ali",
      "Mary Dziedzorm Asipunu",
      "Ismail Alatise",
      "Nguyen Ha",
      "Boka Luo",
      "Cat Mai",
      "Lei Song",
      "Amos Wussah",
      "Sitian Xiong",
      "Qi Zhang",
      "Lyndon D. Estes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.07278",
    "title": "Scene-wise Adaptive Network for Dynamic Cold-start Scenes Optimization in CTR Prediction",
    "abstract": "           In the realm of modern mobile E-commerce, providing users with nearby commercial service recommendations through location-based online services has become increasingly vital. While machine learning approaches have shown promise in multi-scene recommendation, existing methodologies often struggle to address cold-start problems in unprecedented scenes: the increasing diversity of commercial choices, along with the short online lifespan of scenes, give rise to the complexity of effective recommendations in online and dynamic scenes. In this work, we propose Scene-wise Adaptive Network (SwAN), a novel approach that emphasizes high-performance cold-start online recommendations for new scenes. Our approach introduces several crucial capabilities, including scene similarity learning, user-specific scene transition cognition, scene-specific information construction for the new scene, and enhancing the diverged logical information between scenes. We demonstrate SwAN's potential to optimize dynamic multi-scene recommendation problems by effectively online handling cold-start recommendations for any newly arrived scenes. More encouragingly, SwAN has been successfully deployed in Meituan's online catering recommendation service, which serves millions of customers per day, and SwAN has achieved a 5.64% CTR index improvement relative to the baselines and a 5.19% increase in daily order volume proportion.         ",
    "url": "https://arxiv.org/abs/2408.07278",
    "authors": [
      "Wenhao Li",
      "Jie Zhou",
      "Chuan Luo",
      "Chao Tang",
      "Kun Zhang",
      "Shixiong Zhao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.07364",
    "title": "Robust Active Learning (RoAL): Countering Dynamic Adversaries in Active Learning with Elastic Weight Consolidation",
    "abstract": "           Despite significant advancements in active learning and adversarial attacks, the intersection of these two fields remains underexplored, particularly in developing robust active learning frameworks against dynamic adversarial threats. The challenge of developing robust active learning frameworks under dynamic adversarial attacks is critical, as these attacks can lead to catastrophic forgetting within the active learning cycle. This paper introduces Robust Active Learning (RoAL), a novel approach designed to address this issue by integrating Elastic Weight Consolidation (EWC) into the active learning process. Our contributions are threefold: First, we propose a new dynamic adversarial attack that poses significant threats to active learning frameworks. Second, we introduce a novel method that combines EWC with active learning to mitigate catastrophic forgetting caused by dynamic adversarial attacks. Finally, we conduct extensive experimental evaluations to demonstrate the efficacy of our approach. The results show that RoAL not only effectively counters dynamic adversarial threats but also significantly reduces the impact of catastrophic forgetting, thereby enhancing the robustness and performance of active learning systems in adversarial environments.         ",
    "url": "https://arxiv.org/abs/2408.07364",
    "authors": [
      "Ricky Maulana Fajri",
      "Yulong Pei",
      "Lu Yin",
      "Mykola Pechenizkiy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2408.07440",
    "title": "BAPLe: Backdoor Attacks on Medical Foundational Models using Prompt Learning",
    "abstract": "           Medical foundation models are gaining prominence in the medical community for their ability to derive general representations from extensive collections of medical image-text pairs. Recent research indicates that these models are susceptible to backdoor attacks, which allow them to classify clean images accurately but fail when specific triggers are introduced. However, traditional backdoor attacks necessitate a considerable amount of additional data to maliciously pre-train a model. This requirement is often impractical in medical imaging applications due to the usual scarcity of data. Inspired by the latest developments in learnable prompts, this work introduces a method to embed a backdoor into the medical foundation model during the prompt learning phase. By incorporating learnable prompts within the text encoder and introducing imperceptible learnable noise trigger to the input images, we exploit the full capabilities of the medical foundation models (Med-FM). Our method, BAPLe, requires only a minimal subset of data to adjust the noise trigger and the text prompts for downstream tasks, enabling the creation of an effective backdoor attack. Through extensive experiments with four medical foundation models, each pre-trained on different modalities and evaluated across six downstream datasets, we demonstrate the efficacy of our approach. BAPLe achieves a high backdoor success rate across all models and datasets, outperforming the baseline backdoor attack methods. Our work highlights the vulnerability of Med-FMs towards backdoor attacks and strives to promote the safe adoption of Med-FMs before their deployment in real-world applications. Code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2408.07440",
    "authors": [
      "Asif Hanif",
      "Fahad Shamshad",
      "Muhammad Awais",
      "Muzammal Naseer",
      "Fahad Shahbaz Khan",
      "Karthik Nandakumar",
      "Salman Khan",
      "Rao Muhammad Anwer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2408.07576",
    "title": "MetaSeg: MetaFormer-based Global Contexts-aware Network for Efficient Semantic Segmentation",
    "abstract": "           Beyond the Transformer, it is important to explore how to exploit the capacity of the MetaFormer, an architecture that is fundamental to the performance improvements of the Transformer. Previous studies have exploited it only for the backbone network. Unlike previous studies, we explore the capacity of the Metaformer architecture more extensively in the semantic segmentation task. We propose a powerful semantic segmentation network, MetaSeg, which leverages the Metaformer architecture from the backbone to the decoder. Our MetaSeg shows that the MetaFormer architecture plays a significant role in capturing the useful contexts for the decoder as well as for the backbone. In addition, recent segmentation methods have shown that using a CNN-based backbone for extracting the spatial information and a decoder for extracting the global information is more effective than using a transformer-based backbone with a CNN-based decoder. This motivates us to adopt the CNN-based backbone using the MetaFormer block and design our MetaFormer-based decoder, which consists of a novel self-attention module to capture the global contexts. To consider both the global contexts extraction and the computational efficiency of the self-attention for semantic segmentation, we propose a Channel Reduction Attention (CRA) module that reduces the channel dimension of the query and key into the one dimension. In this way, our proposed MetaSeg outperforms the previous state-of-the-art methods with more efficient computational costs on popular semantic segmentation and a medical image segmentation benchmark, including ADE20K, Cityscapes, COCO-stuff, and Synapse. The code is available at this https URL.         ",
    "url": "https://arxiv.org/abs/2408.07576",
    "authors": [
      "Beoungwoo Kang",
      "Seunghun Moon",
      "Yubin Cho",
      "Hyunwoo Yu",
      "Suk-Ju Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2408.07673",
    "title": "Deep Learning: a Heuristic Three-stage Mechanism for Grid Searches to Optimize the Future Risk Prediction of Breast Cancer Metastasis Using EHR-based Clinical Data",
    "abstract": "           A grid search, at the cost of training and testing a large number of models, is an effective way to optimize the prediction performance of deep learning models. A challenging task concerning grid search is the time management. Without a good time management scheme, a grid search can easily be set off as a mission that will not finish in our lifetime. In this study, we introduce a heuristic three-stage mechanism for managing the running time of low-budget grid searches, and the sweet-spot grid search (SSGS) and randomized grid search (RGS) strategies for improving model prediction performance, in predicting the 5-year, 10-year, and 15-year risk of breast cancer metastasis. We develop deep feedforward neural network (DFNN) models and optimize them through grid searches. We conduct eight cycles of grid searches by applying our three-stage mechanism and SSGS and RGS strategies. We conduct various SHAP analyses including unique ones that interpret the importance of the DFNN-model hyperparameters. Our results show that grid search can greatly improve model prediction. The grid searches we conducted improved the risk prediction of 5-year, 10-year, and 15-year breast cancer metastasis by 18.6%, 16.3%, and 17.3% respectively, over the average performance of all corresponding models we trained using the RGS strategy. We not only demonstrate best model performance but also characterize grid searches from various aspects such as their capabilities of discovering decent models and the unit grid search time. The three-stage mechanism worked effectively. It made our low-budget grid searches feasible and manageable, and in the meantime helped improve model prediction performance. Our SHAP analyses identified both clinical risk factors important for the prediction of future risk of breast cancer metastasis, and DFNN-model hyperparameters important to the prediction of performance scores.         ",
    "url": "https://arxiv.org/abs/2408.07673",
    "authors": [
      "Xia Jiang",
      "Yijun Zhou",
      "Chuhan Xu",
      "Adam Brufsky",
      "Alan Wells"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2206.12532",
    "title": "Inferring Effect Ordering Without Causal Effect Estimation",
    "abstract": "           Predictive models are often employed to guide interventions across various domains, such as advertising, customer retention, and personalized medicine. These models often do not estimate the actual effects of interventions but serve as proxies, suggesting potential effectiveness based on predicted outcomes. Our paper addresses the critical question of when and how these predictive models can be interpreted causally, specifically focusing on using the models for inferring effect ordering rather than precise effect sizes. We formalize two assumptions, full latent mediation and latent monotonicity, that are jointly sufficient for inferring effect ordering without direct causal effect estimation. We explore the utility of these assumptions in assessing the feasibility of proxies for inferring effect ordering in scenarios where there is no data on how individuals behave when intervened or no data on the primary outcome of interest. Additionally, we provide practical guidelines for practitioners to make their own assessments about proxies. Our findings reveal not only when it is possible to reasonably infer effect ordering from proxies, but also conditions under which modeling these proxies can outperform direct effect estimation. This study underscores the importance of broadening causal inference to encompass alternative causal interpretations beyond effect estimation, offering a foundation for future research to enhance decision-making processes when direct effect estimation is not feasible.         ",
    "url": "https://arxiv.org/abs/2206.12532",
    "authors": [
      "Carlos Fern\u00e1ndez-Lor\u00eda",
      "Jorge Lor\u00eda"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.09712",
    "title": "Depth Degeneracy in Neural Networks: Vanishing Angles in Fully Connected ReLU Networks on Initialization",
    "abstract": "           Despite remarkable performance on a variety of tasks, many properties of deep neural networks are not yet theoretically understood. One such mystery is the depth degeneracy phenomenon: the deeper you make your network, the closer your network is to a constant function on initialization. In this paper, we examine the evolution of the angle between two inputs to a ReLU neural network as a function of the number of layers. By using combinatorial expansions, we find precise formulas for how fast this angle goes to zero as depth increases. These formulas capture microscopic fluctuations that are not visible in the popular framework of infinite width limits, and leads to qualitatively different predictions. We validate our theoretical results with Monte Carlo experiments and show that our results accurately approximate finite network behaviour. \\review{We also empirically investigate how the depth degeneracy phenomenon can negatively impact training of real networks.} The formulas are given in terms of the mixed moments of correlated Gaussians passed through the ReLU function. We also find a surprising combinatorial connection between these mixed moments and the Bessel numbers that allows us to explicitly evaluate these moments.         ",
    "url": "https://arxiv.org/abs/2302.09712",
    "authors": [
      "Cameron Jakub",
      "Mihai Nica"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2408.02558",
    "title": "Peer-induced Fairness: A Causal Approach to Reveal Algorithmic Unfairness",
    "abstract": "           This paper introduces a novel framework, \"peer-induced fairness\", to scientifically audit algorithmic fairness. It addresses a critical but often overlooked issue: distinguishing between adverse outcomes due to algorithmic discrimination and those resulting from individuals' insufficient capabilities. By utilizing counterfactual fairness and advanced causal inference techniques, such as the Single World Intervention Graph, this model-agnostic approach evaluates fairness at the individual level through peer comparisons and hypothesis testing. It also tackles challenges like data scarcity and imbalance, offering a flexible, plug-and-play self-audit tool for stakeholders and an external audit tool for regulators, while providing explainable feedback for those affected by unfavorable decisions.         ",
    "url": "https://arxiv.org/abs/2408.02558",
    "authors": [
      "Shiqi Fang",
      "Zexun Chen",
      "Jake Ansell"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computers and Society (cs.CY)",
      "Computational Finance (q-fin.CP)",
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (stat.ML)"
    ]
  }
]