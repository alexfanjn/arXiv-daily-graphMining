[
  {
    "id": "arXiv:2310.18338",
    "title": "Small Language Models Fine-tuned to Coordinate Larger Language Models  improve Complex Reasoning",
    "abstract": "Large Language Models (LLMs) prompted to generate chain-of-thought (CoT) exhibit impressive reasoning capabilities. Recent attempts at prompt decomposition toward solving complex, multi-step reasoning problems depend on the ability of the LLM to simultaneously decompose and solve the problem. A significant disadvantage is that foundational LLMs are typically not available for fine-tuning, making adaptation computationally prohibitive. We believe (and demonstrate) that problem decomposition and solution generation are distinct capabilites, better addressed in separate modules, than by one monolithic LLM. We introduce DaSLaM, which uses a decomposition generator to decompose complex problems into subproblems that require fewer reasoning steps. These subproblems are answered by a solver. We use a relatively small (13B parameters) LM as the decomposition generator, which we train using policy gradient optimization to interact with a solver LM (regarded as black-box) and guide it through subproblems, thereby rendering our method solver-agnostic. Evaluation on multiple different reasoning datasets reveal that with our method, a 175 billion parameter LM (text-davinci-003) can produce competitive or even better performance, compared to its orders-of-magnitude larger successor, GPT-4. Additionally, we show that DaSLaM is not limited by the solver's capabilities as a function of scale; e.g., solver LMs with diverse sizes give significant performance improvement with our solver-agnostic decomposition technique. Exhaustive ablation studies evince the superiority of our modular finetuning technique over exorbitantly large decomposer LLMs, based on prompting alone. ",
    "url": "https://arxiv.org/abs/2310.18338",
    "authors": [
      "Gurusha Juneja",
      "Subhabrata Dutta",
      "Soumen Chakrabarti",
      "Sunny Manchanda",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.18344",
    "title": "Chainpoll: A high efficacy method for LLM hallucination detection",
    "abstract": "Large language models (LLMs) have experienced notable advancements in generating coherent and contextually relevant responses. However, hallucinations - incorrect or unfounded claims - are still prevalent, prompting the creation of automated metrics to detect these in LLM outputs. Our contributions include: introducing ChainPoll, an innovative hallucination detection method that excels compared to its counterparts, and unveiling RealHall, a refined collection of benchmark datasets to assess hallucination detection metrics from recent studies. While creating RealHall, we assessed tasks and datasets from previous hallucination detection studies and observed that many are not suitable for the potent LLMs currently in use. Overcoming this, we opted for four datasets challenging for modern LLMs and pertinent to real-world scenarios. Using RealHall, we conducted a comprehensive comparison of ChainPoll with numerous hallucination metrics from recent studies. Our findings indicate that ChainPoll outperforms in all RealHall benchmarks, achieving an overall AUROC of 0.781. This surpasses the next best theoretical method by 11% and exceeds industry standards by over 23%. Additionally, ChainPoll is cost-effective and offers greater transparency than other metrics. We introduce two novel metrics to assess LLM hallucinations: Adherence and Correctness. Adherence is relevant to Retrieval Augmented Generation workflows, evaluating an LLM's analytical capabilities within given documents and contexts. In contrast, Correctness identifies logical and reasoning errors. ",
    "url": "https://arxiv.org/abs/2310.18344",
    "authors": [
      "Robert Friel",
      "Atindriyo Sanyal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18349",
    "title": "A Boundary Offset Prediction Network for Named Entity Recognition",
    "abstract": "Named entity recognition (NER) is a fundamental task in natural language processing that aims to identify and classify named entities in text. However, span-based methods for NER typically assign entity types to text spans, resulting in an imbalanced sample space and neglecting the connections between non-entity and entity spans. To address these issues, we propose a novel approach for NER, named the Boundary Offset Prediction Network (BOPN), which predicts the boundary offsets between candidate spans and their nearest entity spans. By leveraging the guiding semantics of boundary offsets, BOPN establishes connections between non-entity and entity spans, enabling non-entity spans to function as additional positive samples for entity detection. Furthermore, our method integrates entity type and span representations to generate type-aware boundary offsets instead of using entity types as detection targets. We conduct experiments on eight widely-used NER datasets, and the results demonstrate that our proposed BOPN outperforms previous state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2310.18349",
    "authors": [
      "Minghao Tang",
      "Yongquan He",
      "Yongxiu Xu",
      "Hongbo Xu",
      "Wenyuan Zhang",
      "Yang Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.18351",
    "title": "BioImage.IO Chatbot: A Personalized Assistant for BioImage Analysis  Augmented by Community Knowledge Base",
    "abstract": "The rapidly expanding landscape of bioimage analysis tools presents a navigational challenge for both experts and newcomers. Traditional search methods often fall short in assisting users in this complex environment. To address this, we introduce the BioImage.IO Chatbot, an AI-driven conversational assistant tailored for the bioimage community. Built upon large language models, this chatbot provides personalized, context-aware answers by aggregating and interpreting information from diverse databases, tool-specific documentation, and structured data sources. Enhanced by a community-contributed knowledge base and fine-tuned retrieval methods, the BioImage.IO Chatbot offers not just a personalized interaction but also a knowledge-enriched, context-aware experience. It fundamentally transforms the way biologists, bioimage analysts, and developers navigate and utilize advanced bioimage analysis tools, setting a new standard for community-driven, accessible scientific research. ",
    "url": "https://arxiv.org/abs/2310.18351",
    "authors": [
      "Wanlu Lei",
      "Caterina Fuster-Barcel\u00f3",
      "Arrate Mu\u00f1oz-Barrutia",
      "Wei Ouyang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2310.18359",
    "title": "DeSIQ: Towards an Unbiased, Challenging Benchmark for Social  Intelligence Understanding",
    "abstract": "Social intelligence is essential for understanding and reasoning about human expressions, intents and interactions. One representative benchmark for its study is Social Intelligence Queries (Social-IQ), a dataset of multiple-choice questions on videos of complex social interactions. We define a comprehensive methodology to study the soundness of Social-IQ, as the soundness of such benchmark datasets is crucial to the investigation of the underlying research problem. Our analysis reveals that Social-IQ contains substantial biases, which can be exploited by a moderately strong language model to learn spurious correlations to achieve perfect performance without being given the context or even the question. We introduce DeSIQ, a new challenging dataset, constructed by applying simple perturbations to Social-IQ. Our empirical analysis shows DeSIQ significantly reduces the biases in the original Social-IQ dataset. Furthermore, we examine and shed light on the effect of model size, model style, learning settings, commonsense knowledge, and multi-modality on the new benchmark performance. Our new dataset, observations and findings open up important research questions for the study of social intelligence. ",
    "url": "https://arxiv.org/abs/2310.18359",
    "authors": [
      "Xiao-Yu Guo",
      "Yuan-Fang Li",
      "Gholamreza Haffari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.18363",
    "title": "A Contextualized Real-Time Multimodal Emotion Recognition for  Conversational Agents using Graph Convolutional Networks in Reinforcement  Learning",
    "abstract": "Owing to the recent developments in Generative Artificial Intelligence (GenAI) and Large Language Models (LLM), conversational agents are becoming increasingly popular and accepted. They provide a human touch by interacting in ways familiar to us and by providing support as virtual companions. Therefore, it is important to understand the user's emotions in order to respond considerately. Compared to the standard problem of emotion recognition, conversational agents face an additional constraint in that recognition must be real-time. Studies on model architectures using audio, visual, and textual modalities have mainly focused on emotion classification using full video sequences that do not provide online features. In this work, we present a novel paradigm for contextualized Emotion Recognition using Graph Convolutional Network with Reinforcement Learning (conER-GRL). Conversations are partitioned into smaller groups of utterances for effective extraction of contextual information. The system uses Gated Recurrent Units (GRU) to extract multimodal features from these groups of utterances. More importantly, Graph Convolutional Networks (GCN) and Reinforcement Learning (RL) agents are cascade trained to capture the complex dependencies of emotion features in interactive scenarios. Comparing the results of the conER-GRL model with other state-of-the-art models on the benchmark dataset IEMOCAP demonstrates the advantageous capabilities of the conER-GRL architecture in recognizing emotions in real-time from multimodal conversational signals. ",
    "url": "https://arxiv.org/abs/2310.18363",
    "authors": [
      "Fathima Abdul Rahman",
      "Guang Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18371",
    "title": "In-Context Ability Transfer for Question Decomposition in Complex QA",
    "abstract": "Answering complex questions is a challenging task that requires question decomposition and multistep reasoning for arriving at the solution. While existing supervised and unsupervised approaches are specialized to a certain task and involve training, recently proposed prompt-based approaches offer generalizable solutions to tackle a wide variety of complex question-answering (QA) tasks. However, existing prompt-based approaches that are effective for complex QA tasks involve expensive hand annotations from experts in the form of rationales and are not generalizable to newer complex QA scenarios and tasks. We propose, icat (In-Context Ability Transfer) which induces reasoning capabilities in LLMs without any LLM fine-tuning or manual annotation of in-context samples. We transfer the ability to decompose complex questions to simpler questions or generate step-by-step rationales to LLMs, by careful selection from available data sources of related tasks. We also propose an automated uncertainty-aware exemplar selection approach for selecting examples from transfer data sources. Finally, we conduct large-scale experiments on a variety of complex QA tasks involving numerical reasoning, compositional complex QA, and heterogeneous complex QA which require decomposed reasoning. We show that ICAT convincingly outperforms existing prompt-based solutions without involving any model training, showcasing the benefits of re-using existing abilities. ",
    "url": "https://arxiv.org/abs/2310.18371",
    "authors": [
      "Venktesh V",
      "Sourangshu Bhattacharya",
      "Avishek Anand"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.18376",
    "title": "SQLformer: Deep Auto-Regressive Query Graph Generation for Text-to-SQL  Translation",
    "abstract": "In recent years, there has been growing interest in text-to-SQL translation, which is the task of converting natural language questions into executable SQL queries. This technology is important for its potential to democratize data extraction from databases. However, some of its key hurdles include domain generalisation, which is the ability to adapt to previously unseen databases, and alignment of natural language questions with the corresponding SQL queries. To overcome these challenges, we introduce SQLformer, a novel Transformer architecture specifically crafted to perform text-to-SQL translation tasks. Our model predicts SQL queries as abstract syntax trees (ASTs) in an autoregressive way, incorporating structural inductive bias in the encoder and decoder layers. This bias, guided by database table and column selection, aids the decoder in generating SQL query ASTs represented as graphs in a Breadth-First Search canonical order. Comprehensive experiments illustrate the state-of-the-art performance of SQLformer in the challenging text-to-SQL Spider benchmark. Our implementation is available at https://github.com/AdrianBZG/SQLformer ",
    "url": "https://arxiv.org/abs/2310.18376",
    "authors": [
      "Adri\u00e1n Bazaga",
      "Pietro Li\u00f2",
      "Gos Micklem"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18384",
    "title": "MicroNAS: Memory and Latency Constrained Hardware-Aware Neural  Architecture Search for Time Series Classification on Microcontrollers",
    "abstract": "This paper presents MicroNAS, a system designed to automatically search and generate neural network architectures capable of classifying time series data on resource-constrained microcontrollers (MCUs) and generating standard tf-lite ML models. MicroNAS takes into account user-defined constraints on execution latency and peak memory consumption on a target MCU. This approach ensures that the resulting neural network architectures are optimised for the specific constraints and requirements of the MCU on which they are implemented. To achieve this, MicroNAS uses a look-up table estimation approach for accurate execution latency calculations, with a minimum error of only 1.02ms. This accurate latency estimation on MCUs sets it apart from other hardware-aware neural architecture search (HW-NAS) methods that use less accurate estimation techniques. Finally, MicroNAS delivers performance close to that of state-of-the-art models running on desktop computers, achieving high classification accuracies on recognised datasets (93.93% on UCI-HAR and 96.33% on SkodaR) while running on a Cortex-M4 MCU. ",
    "url": "https://arxiv.org/abs/2310.18384",
    "authors": [
      "Tobias King",
      "Yexu Zhou",
      "Tobias R\u00f6ddiger",
      "Michael Beigl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18413",
    "title": "On the Fairness ROAD: Robust Optimization for Adversarial Debiasing",
    "abstract": "In the field of algorithmic fairness, significant attention has been put on group fairness criteria, such as Demographic Parity and Equalized Odds. Nevertheless, these objectives, measured as global averages, have raised concerns about persistent local disparities between sensitive groups. In this work, we address the problem of local fairness, which ensures that the predictor is unbiased not only in terms of expectations over the whole population, but also within any subregion of the feature space, unknown at training time. To enforce this objective, we introduce ROAD, a novel approach that leverages the Distributionally Robust Optimization (DRO) framework within a fair adversarial learning objective, where an adversary tries to infer the sensitive attribute from the predictions. Using an instance-level re-weighting strategy, ROAD is designed to prioritize inputs that are likely to be locally unfair, i.e. where the adversary faces the least difficulty in reconstructing the sensitive attribute. Numerical experiments demonstrate the effectiveness of our method: it achieves Pareto dominance with respect to local fairness and accuracy for a given global fairness level across three standard datasets, and also enhances fairness generalization under distribution shift. ",
    "url": "https://arxiv.org/abs/2310.18413",
    "authors": [
      "Vincent Grari",
      "Thibault Laugel",
      "Tatsunori Hashimoto",
      "Sylvain Lamprier",
      "Marcin Detyniecki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.18424",
    "title": "Fast Machine Learning Method with Vector Embedding on Orthonormal Basis  and Spectral Transform",
    "abstract": "This paper presents a novel fast machine learning method that leverages two techniques: Vector Embedding on Orthonormal Basis (VEOB) and Spectral Transform (ST). The VEOB converts the original data encoding into a vector embedding with coordinates projected onto orthonormal bases. The Singular Value Decomposition (SVD) technique is used to calculate the vector basis and projection coordinates, leading to an enhanced distance measurement in the embedding space and facilitating data compression by preserving the projection vectors associated with the largest singular values. On the other hand, ST transforms sequence of vector data into spectral space. By applying the Discrete Cosine Transform (DCT) and selecting the most significant components, it streamlines the handling of lengthy vector sequences. The paper provides examples of word embedding, text chunk embedding, and image embedding, implemented in Julia language with a vector database. It also investigates unsupervised learning and supervised learning using this method, along with strategies for handling large data volumes. ",
    "url": "https://arxiv.org/abs/2310.18424",
    "authors": [
      "Louis Yu Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.18431",
    "title": "SDOH-NLI: a Dataset for Inferring Social Determinants of Health from  Clinical Notes",
    "abstract": "Social and behavioral determinants of health (SDOH) play a significant role in shaping health outcomes, and extracting these determinants from clinical notes is a first step to help healthcare providers systematically identify opportunities to provide appropriate care and address disparities. Progress on using NLP methods for this task has been hindered by the lack of high-quality publicly available labeled data, largely due to the privacy and regulatory constraints on the use of real patients' information. This paper introduces a new dataset, SDOH-NLI, that is based on publicly available notes and which we release publicly. We formulate SDOH extraction as a natural language inference (NLI) task, and provide binary textual entailment labels obtained from human raters for a cross product of a set of social history snippets as premises and SDOH factors as hypotheses. Our dataset differs from standard NLI benchmarks in that our premises and hypotheses are obtained independently. We evaluate both \"off-the-shelf\" entailment models as well as models fine-tuned on our data, and highlight the ways in which our dataset appears more challenging than commonly used NLI datasets. ",
    "url": "https://arxiv.org/abs/2310.18431",
    "authors": [
      "Adam D. Lelkes",
      "Eric Loreaux",
      "Tal Schuster",
      "Ming-Jun Chen",
      "Alvin Rajkomar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.18434",
    "title": "Bridging Distributionally Robust Learning and Offline RL: An Approach to  Mitigate Distribution Shift and Partial Data Coverage",
    "abstract": "The goal of an offline reinforcement learning (RL) algorithm is to learn optimal polices using historical (offline) data, without access to the environment for online exploration. One of the main challenges in offline RL is the distribution shift which refers to the difference between the state-action visitation distribution of the data generating policy and the learning policy. Many recent works have used the idea of pessimism for developing offline RL algorithms and characterizing their sample complexity under a relatively weak assumption of single policy concentrability. Different from the offline RL literature, the area of distributionally robust learning (DRL) offers a principled framework that uses a minimax formulation to tackle model mismatch between training and testing environments. In this work, we aim to bridge these two areas by showing that the DRL approach can be used to tackle the distributional shift problem in offline RL. In particular, we propose two offline RL algorithms using the DRL framework, for the tabular and linear function approximation settings, and characterize their sample complexity under the single policy concentrability assumption. We also demonstrate the superior performance our proposed algorithm through simulation experiments. ",
    "url": "https://arxiv.org/abs/2310.18434",
    "authors": [
      "Kishan Panaganti",
      "Zaiyan Xu",
      "Dileep Kalathil",
      "Mohammad Ghavamzadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.18438",
    "title": "Exploring Shape Embedding for Cloth-Changing Person Re-Identification  via 2D-3D Correspondences",
    "abstract": "Cloth-Changing Person Re-Identification (CC-ReID) is a common and realistic problem since fashion constantly changes over time and people's aesthetic preferences are not set in stone. While most existing cloth-changing ReID methods focus on learning cloth-agnostic identity representations from coarse semantic cues (e.g. silhouettes and part segmentation maps), they neglect the continuous shape distributions at the pixel level. In this paper, we propose Continuous Surface Correspondence Learning (CSCL), a new shape embedding paradigm for cloth-changing ReID. CSCL establishes continuous correspondences between a 2D image plane and a canonical 3D body surface via pixel-to-vertex classification, which naturally aligns a person image to the surface of a 3D human model and simultaneously obtains pixel-wise surface embeddings. We further extract fine-grained shape features from the learned surface embeddings and then integrate them with global RGB features via a carefully designed cross-modality fusion module. The shape embedding paradigm based on 2D-3D correspondences remarkably enhances the model's global understanding of human body shape. To promote the study of ReID under clothing change, we construct 3D Dense Persons (DP3D), which is the first large-scale cloth-changing ReID dataset that provides densely annotated 2D-3D correspondences and a precise 3D mesh for each person image, while containing diverse cloth-changing cases over all four seasons. Experiments on both cloth-changing and cloth-consistent ReID benchmarks validate the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2310.18438",
    "authors": [
      "Yubin Wang",
      "Huimin Yu",
      "Yuming Yan",
      "Shuyi Song",
      "Biyang Liu",
      "Yichong Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18444",
    "title": "M3C: A Framework towards Convergent, Flexible, and Unsupervised Learning  of Mixture Graph Matching and Clustering",
    "abstract": "Existing graph matching methods typically assume that there are similar structures between graphs and they are matchable. However, these assumptions do not align with real-world applications. This work addresses a more realistic scenario where graphs exhibit diverse modes, requiring graph grouping before or along with matching, a task termed mixture graph matching and clustering. We introduce Minorize-Maximization Matching and Clustering (M3C), a learning-free algorithm that guarantees theoretical convergence through the Minorize-Maximization framework and offers enhanced flexibility via relaxed clustering. Building on M3C, we develop UM3C, an unsupervised model that incorporates novel edge-wise affinity learning and pseudo label selection. Extensive experimental results on public benchmarks demonstrate that our method outperforms state-of-the-art graph matching and mixture graph matching and clustering approaches in both accuracy and efficiency. Source code will be made publicly available. ",
    "url": "https://arxiv.org/abs/2310.18444",
    "authors": [
      "Jiaxin Lu",
      "Zetian Jiang",
      "Tianzhe Wang",
      "Junchi Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18458",
    "title": "Do Not Harm Protected Groups in Debiasing Language Representation Models",
    "abstract": "Language Representation Models (LRMs) trained with real-world data may capture and exacerbate undesired bias and cause unfair treatment of people in various demographic groups. Several techniques have been investigated for applying interventions to LRMs to remove bias in benchmark evaluations on, for example, word embeddings. However, the negative side effects of debiasing interventions are usually not revealed in the downstream tasks. We propose xGAP-DEBIAS, a set of evaluations on assessing the fairness of debiasing. In this work, We examine four debiasing techniques on a real-world text classification task and show that reducing biasing is at the cost of degrading performance for all demographic groups, including those the debiasing techniques aim to protect. We advocate that a debiasing technique should have good downstream performance with the constraint of ensuring no harm to the protected group. ",
    "url": "https://arxiv.org/abs/2310.18458",
    "authors": [
      "Chloe Qinyu Zhu",
      "Rickard Stureborg",
      "Brandon Fain"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.18469",
    "title": "Semi-Synthetic Dataset Augmentation for Application-Specific Gaze  Estimation",
    "abstract": "Although the number of gaze estimation datasets is growing, the application of appearance-based gaze estimation methods is mostly limited to estimating the point of gaze on a screen. This is in part because most datasets are generated in a similar fashion, where the gaze target is on a screen close to camera's origin. In other applications such as assistive robotics or marketing research, the 3D point of gaze might not be close to the camera's origin, meaning models trained on current datasets do not generalize well to these tasks. We therefore suggest generating a textured tridimensional mesh of the face and rendering the training images from a virtual camera at a specific position and orientation related to the application as a mean of augmenting the existing datasets. In our tests, this lead to an average 47% decrease in gaze estimation angular error. ",
    "url": "https://arxiv.org/abs/2310.18469",
    "authors": [
      "Cedric Leblond-Menard",
      "Gabriel Picard-Krashevski",
      "Sofiane Achiche"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18471",
    "title": "Causal disentanglement of multimodal data",
    "abstract": "Causal representation learning algorithms discover lower-dimensional representations of data that admit a decipherable interpretation of cause and effect; as achieving such interpretable representations is challenging, many causal learning algorithms utilize elements indicating prior information, such as (linear) structural causal models, interventional data, or weak supervision. Unfortunately, in exploratory causal representation learning, such elements and prior information may not be available or warranted. Alternatively, scientific datasets often have multiple modalities or physics-based constraints, and the use of such scientific, multimodal data has been shown to improve disentanglement in fully unsupervised settings. Consequently, we introduce a causal representation learning algorithm (causalPIMA) that can use multimodal data and known physics to discover important features with causal relationships. Our innovative algorithm utilizes a new differentiable parametrization to learn a directed acyclic graph (DAG) together with a latent space of a variational autoencoder in an end-to-end differentiable framework via a single, tractable evidence lower bound loss function. We place a Gaussian mixture prior on the latent space and identify each of the mixtures with an outcome of the DAG nodes; this novel identification enables feature discovery with causal relationships. Tested against a synthetic and a scientific dataset, our results demonstrate the capability of learning an interpretable causal structure while simultaneously discovering key features in a fully unsupervised setting. ",
    "url": "https://arxiv.org/abs/2310.18471",
    "authors": [
      "Elise Walker",
      "Jonas A. Actor",
      "Carianne Martinez",
      "Nathaniel Trask"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.18472",
    "title": "Parameter-Efficient Methods for Metastases Detection from Clinical Notes",
    "abstract": "Understanding the progression of cancer is crucial for defining treatments for patients. The objective of this study is to automate the detection of metastatic liver disease from free-style computed tomography (CT) radiology reports. Our research demonstrates that transferring knowledge using three approaches can improve model performance. First, we utilize generic language models (LMs), pretrained in a self-supervised manner. Second, we use a semi-supervised approach to train our model by automatically annotating a large unlabeled dataset; this approach substantially enhances the model's performance. Finally, we transfer knowledge from related tasks by designing a multi-task transfer learning methodology. We leverage the recent advancement of parameter-efficient LM adaptation strategies to improve performance and training efficiency. Our dataset consists of CT reports collected at Memorial Sloan Kettering Cancer Center (MSKCC) over the course of 12 years. 2,641 reports were manually annotated by domain experts; among them, 841 reports have been annotated for the presence of liver metastases. Our best model achieved an F1-score of 73.8%, a precision of 84%, and a recall of 65.8%. ",
    "url": "https://arxiv.org/abs/2310.18472",
    "authors": [
      "Maede Ashofteh Barabadi",
      "Xiaodan Zhu",
      "Wai Yip Chan",
      "Amber L. Simpson",
      "Richard K.G. Do"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18477",
    "title": "Understanding and Improving Ensemble Adversarial Defense",
    "abstract": "The strategy of ensemble has become popular in adversarial defense, which trains multiple base classifiers to defend against adversarial attacks in a cooperative manner. Despite the empirical success, theoretical explanations on why an ensemble of adversarially trained classifiers is more robust than single ones remain unclear. To fill in this gap, we develop a new error theory dedicated to understanding ensemble adversarial defense, demonstrating a provable 0-1 loss reduction on challenging sample sets in an adversarial defense scenario. Guided by this theory, we propose an effective approach to improve ensemble adversarial defense, named interactive global adversarial training (iGAT). The proposal includes (1) a probabilistic distributing rule that selectively allocates to different base classifiers adversarial examples that are globally challenging to the ensemble, and (2) a regularization term to rescue the severest weaknesses of the base classifiers. Being tested over various existing ensemble adversarial defense techniques, iGAT is capable of boosting their performance by increases up to 17% evaluated using CIFAR10 and CIFAR100 datasets under both white-box and black-box attacks. ",
    "url": "https://arxiv.org/abs/2310.18477",
    "authors": [
      "Yian Deng",
      "Tingting Mu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18480",
    "title": "Capacity, Collision Avoidance and Shopping Rate under a Social  Distancing Regime",
    "abstract": "Capacity restrictions in stores, maintained by mechanisms like spacing customer intake, became familiar features of retailing in the time of the pandemic. Shopping rates in a crowded store under a social distance regime is prone to considerable slowdown. Inspired by the random particle collision concepts of statistical mechanics, we introduce a dynamical model of the evolution of shopping rate as a function of a given customer intake rate. The slowdown of each individual customer is incorporated as an additive term to a baseline value shopping time, proportional to the number of other customers in the store. We determine analytically and by simulation the trajectory of the model as it approaches a Little's Law equilibrium, and identify the point beyond which equilibrium cannot be achieved. By relating customer shopping rate to the slowdown compared to the baseline, we can calculate the optimal intake rate leading to maximum equilibrium spending. This turns out to be the maximum rate compatible with equilibrium. The slowdown due to the largest possible number of shoppers is more than compensated for by the increased volume of shopping. This macroscopic model is validated by simulation experiments in which avoidance interactions between pairs of shoppers are responsible for shopping delays. ",
    "url": "https://arxiv.org/abs/2310.18480",
    "authors": [
      "Haitian Zhong",
      "David Sankoff"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2310.18518",
    "title": "Reconfiguration of plane trees in convex geometric graphs",
    "abstract": "A non-crossing spanning tree of a set of points in the plane is a spanning tree whose edges pairwise do not cross. Avis and Fukuda in 1996 proved that there always exists a flip sequence of length at most $2n-4$ between any pair of non-crossing spanning trees (where $n$ denotes the number of points). Hernando et al. proved that the length of a minimal flip sequence can be of length at least $\\frac 32 n$. Two recent results of Aichholzer et al. and Bousquet et al. improved the Avis and Fukuda upper bound by proving that there always exists a flip sequence of length respectively at most $2n - \\log n$ and $2n - \\sqrt{n}$. We improve the upper bound by a linear factor for the first time in 25 years by proving that there always exists a flip sequence between any pair of non-crossing spanning trees $T_1,T_2$ of length at most $c n$ where $c \\approx 1.95$. Our result is actually stronger since we prove that, for any two trees $T_1,T_2$, there exists a flip sequence from $T_1$ to $T_2$ of length at most $c |T_1 \\setminus T_2|$. We also improve the best lower bound in terms of the symmetric difference by proving that there exists a pair of trees $T_1,T_2$ such that a minimal flip sequence has length $\\frac 53 |T_1 \\setminus T_2|$, improving the lower bound of Hernando et al. by considering the symmetric difference instead of the number of vertices. We generalize this lower bound construction to non-crossing flips (where we close the gap between upper and lower bounds) and rotations. ",
    "url": "https://arxiv.org/abs/2310.18518",
    "authors": [
      "Nicolas Bousquet",
      "Lucas De Meyer",
      "Th\u00e9o Pierron",
      "Alexandra Wesolek"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2310.18523",
    "title": "Using convolutional neural networks for stereological characterization  of 3D hetero-aggregates based on synthetic STEM data",
    "abstract": "The structural characterization of hetero-aggregates in 3D is of great interest, e.g., for deriving process-structure or structure-property relationships. However, since 3D imaging techniques are often difficult to perform as well as time and cost intensive, a characterization of hetero-aggregates based on 2D image data is desirable, but often non-trivial. To overcome the issues of characterizing 3D structures from 2D measurements, a method is presented that relies on machine learning combined with methods of spatial stochastic modeling, where the latter are utilized for the generation of synthetic training data. This kind of training data has the advantage that time-consuming experiments for the synthesis of differently structured materials followed by their 3D imaging can be avoided. More precisely, a parametric stochastic 3D model is presented, from which a wide spectrum of virtual hetero-aggregates can be generated. Additionally, the virtual structures are passed to a physics-based simulation tool in order to generate virtual scanning transmission electron microscopy (STEM) images. The preset parameters of the 3D model together with the simulated STEM images serve as a database for the training of convolutional neural networks, which can be used to determine the parameters of the underlying 3D model and, consequently, to predict 3D structures of hetero-aggregates from 2D STEM images. Furthermore, an error analysis is performed to evaluate the prediction power of the trained neural networks with respect to structural descriptors, e.g. the hetero-coordination number. ",
    "url": "https://arxiv.org/abs/2310.18523",
    "authors": [
      "Lukas Fuchs",
      "Tom Kirstein",
      "Christoph Mahr",
      "Orkun Furat",
      "Valentin Baric",
      "Andreas Rosenauer",
      "Lutz Maedler",
      "Volker Schmidt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.18532",
    "title": "SkipAnalyzer: An Embodied Agent for Code Analysis with Large Language  Models",
    "abstract": "We introduce SkipAnalyzer, the first large language model (LLM)-powered embodied agent for static code analysis. It can detect bugs, filter false positive warnings, and patch the detected bugs without human intervention. SkipAnalyzer consists of three components, 1) an LLM-based static bug detector that scans source code and reports specific types of bugs, 2) an LLM-based false-positive filter that can identify false-positive bugs in the results of static bug detectors to improve detection accuracy, and 3) an LLM-based patch generator that can generate patches for the detected bugs above. As a proof-of-concept, SkipAnalyzer is built on ChatGPT, which has exhibited outstanding performance in various software engineering tasks. To evaluate SkipAnalyzer, we focus on two types of typical and critical bugs that are targeted by static bug detection, i.e., Null Dereference and Resource Leak as subjects. We employ Infer to aid the gathering of these two bug types from 10 open-source projects. Consequently, our experiment dataset contains 222 instances of Null Dereference bugs and 46 instances of Resource Leak bugs. Our study demonstrates that SkipAnalyzer achieves remarkable performance in the mentioned static analysis tasks, including bug detection, false-positive warning removal, and bug repair. In static bug detection, SkipAnalyzer achieves accuracy values of up to 68.37% for detecting Null Dereference bugs and 76.95% for detecting Resource Leak bugs, outperforming the current leading bug detector, Infer. For removing false-positive warnings, SkipAnalyzer can reach a precision of up to 93.88% for Null Dereference bugs and 63.33% for Resource Leak bugs. Additionally, SkipAnalyzer surpasses state-of-the-art false-positive warning removal tools. Furthermore, in bug repair, SkipAnalyzer can generate syntactically correct patches to fix its detected bugs with a success rate of up to 97.30%. ",
    "url": "https://arxiv.org/abs/2310.18532",
    "authors": [
      "Mohammad Mahdi Mohajer",
      "Reem Aleithan",
      "Nima Shiri Harzevili",
      "Moshi Wei",
      "Alvine Boaye Belle",
      "Hung Viet Pham",
      "Song Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.18541",
    "title": "ReConTab: Regularized Contrastive Representation Learning for Tabular  Data",
    "abstract": "Representation learning stands as one of the critical machine learning techniques across various domains. Through the acquisition of high-quality features, pre-trained embeddings significantly reduce input space redundancy, benefiting downstream pattern recognition tasks such as classification, regression, or detection. Nonetheless, in the domain of tabular data, feature engineering and selection still heavily rely on manual intervention, leading to time-consuming processes and necessitating domain expertise. In response to this challenge, we introduce ReConTab, a deep automatic representation learning framework with regularized contrastive learning. Agnostic to any type of modeling task, ReConTab constructs an asymmetric autoencoder based on the same raw features from model inputs, producing low-dimensional representative embeddings. Specifically, regularization techniques are applied for raw feature selection. Meanwhile, ReConTab leverages contrastive learning to distill the most pertinent information for downstream tasks. Experiments conducted on extensive real-world datasets substantiate the framework's capacity to yield substantial and robust performance improvements. Furthermore, we empirically demonstrate that pre-trained embeddings can seamlessly integrate as easily adaptable features, enhancing the performance of various traditional methods such as XGBoost and Random Forest. ",
    "url": "https://arxiv.org/abs/2310.18541",
    "authors": [
      "Suiyao Chen",
      "Jing Wu",
      "Naira Hovakimyan",
      "Handong Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.18545",
    "title": "Identifying Conspiracy Theories News based on Event Relation Graph",
    "abstract": "Conspiracy theories, as a type of misinformation, are narratives that explains an event or situation in an irrational or malicious manner. While most previous work examined conspiracy theory in social media short texts, limited attention was put on such misinformation in long news documents. In this paper, we aim to identify whether a news article contains conspiracy theories. We observe that a conspiracy story can be made up by mixing uncorrelated events together, or by presenting an unusual distribution of relations between events. Achieving a contextualized understanding of events in a story is essential for detecting conspiracy theories. Thus, we propose to incorporate an event relation graph for each article, in which events are nodes, and four common types of event relations, coreference, temporal, causal, and subevent relations, are considered as edges. Then, we integrate the event relation graph into conspiracy theory identification in two ways: an event-aware language model is developed to augment the basic language model with the knowledge of events and event relations via soft labels; further, a heterogeneous graph attention network is designed to derive a graph embedding based on hard labels. Experiments on a large benchmark dataset show that our approach based on event relation graph improves both precision and recall of conspiracy theory identification, and generalizes well for new unseen media sources. ",
    "url": "https://arxiv.org/abs/2310.18545",
    "authors": [
      "Yuanyuan Lei",
      "Ruihong Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.18548",
    "title": "MEDAVET: Traffic Vehicle Anomaly Detection Mechanism based on spatial  and temporal structures in vehicle traffic",
    "abstract": "Currently, there are computer vision systems that help us with tasks that would be dull for humans, such as surveillance and vehicle tracking. An important part of this analysis is to identify traffic anomalies. An anomaly tells us that something unusual has happened, in this case on the highway. This paper aims to model vehicle tracking using computer vision to detect traffic anomalies on a highway. We develop the steps of detection, tracking, and analysis of traffic: the detection of vehicles from video of urban traffic, the tracking of vehicles using a bipartite graph and the Convex Hull algorithm to delimit moving areas. Finally for anomaly detection we use two data structures to detect the beginning and end of the anomaly. The first is the QuadTree that groups vehicles that are stopped for a long time on the road and the second that approaches vehicles that are occluded. Experimental results show that our method is acceptable on the Track4 test set, with an F1 score of 85.7% and a mean squared error of 25.432. ",
    "url": "https://arxiv.org/abs/2310.18548",
    "authors": [
      "Ana Rosal\u00eda Huam\u00e1n Reyna",
      "Alex Josu\u00e9 Fl\u00f3rez Farf\u00e1n",
      "Geraldo Pereira Rocha Filho",
      "Sandra Sampaio",
      "Robson de Grande",
      "Luis Hideo",
      "Vasconcelos Nakamura",
      "Rodolfo Ipolito Meneguette"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.18549",
    "title": "Deep Intrinsic Decomposition with Adversarial Learning for Hyperspectral  Image Classification",
    "abstract": "Convolutional neural networks (CNNs) have been demonstrated their powerful ability to extract discriminative features for hyperspectral image classification. However, general deep learning methods for CNNs ignore the influence of complex environmental factor which enlarges the intra-class variance and decreases the inter-class variance. This multiplies the difficulty to extract discriminative features. To overcome this problem, this work develops a novel deep intrinsic decomposition with adversarial learning, namely AdverDecom, for hyperspectral image classification to mitigate the negative impact of environmental factors on classification performance. First, we develop a generative network for hyperspectral image (HyperNet) to extract the environmental-related feature and category-related feature from the image. Then, a discriminative network is constructed to distinguish different environmental categories. Finally, a environmental and category joint learning loss is developed for adversarial learning to make the deep model learn discriminative features. Experiments are conducted over three commonly used real-world datasets and the comparison results show the superiority of the proposed method. The implementation of the proposed method and other compared methods could be accessed at https://github.com/shendu-sw/Adversarial Learning Intrinsic Decomposition for the sake of reproducibility. ",
    "url": "https://arxiv.org/abs/2310.18549",
    "authors": [
      "Zhiqiang Gong",
      "Xian Zhou",
      "Wen Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.18550",
    "title": "MultiScale Spectral-Spatial Convolutional Transformer for Hyperspectral  Image Classification",
    "abstract": "Due to the powerful ability in capturing the global information, Transformer has become an alternative architecture of CNNs for hyperspectral image classification. However, general Transformer mainly considers the global spectral information while ignores the multiscale spatial information of the hyperspectral image. In this paper, we propose a multiscale spectral-spatial convolutional Transformer (MultiscaleFormer) for hyperspectral image classification. First, the developed method utilizes multiscale spatial patches as tokens to formulate the spatial Transformer and generates multiscale spatial representation of each band in each pixel. Second, the spatial representation of all the bands in a given pixel are utilized as tokens to formulate the spectral Transformer and generate the multiscale spectral-spatial representation of each pixel. Besides, a modified spectral-spatial CAF module is constructed in the MultiFormer to fuse cross-layer spectral and spatial information. Therefore, the proposed MultiFormer can capture the multiscale spectral-spatial information and provide better performance than most of other architectures for hyperspectral image classification. Experiments are conducted over commonly used real-world datasets and the comparison results show the superiority of the proposed method. ",
    "url": "https://arxiv.org/abs/2310.18550",
    "authors": [
      "Zhiqiang Gong",
      "Xian Zhou",
      "Wen Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18553",
    "title": "Affective Polarization in Social Networks",
    "abstract": "Affective polarization has grown dramatically in recent years, with surveys showing that liberals and conservatives not only disagree on policy issues but also dislike and distrust each other. While studies have implicated social media in amplifying polarization, there is a lack of agreement on the mechanisms driving affective polarization and methods to measure it. Our paper addresses these gaps. First, we directly measure affective polarization on social media by quantifying the emotional tone of reply interactions between users. As predicted by affective polarization, in-group interactions between same-partisanship users tend to be positive, while out-group interactions between opposite-partisanship users are characterized by negativity and toxicity. Second, we show that affective polarization generalizes beyond the in-group/out-group dichotomy and can be considered a structural property of social networks. Specifically, we show that emotions vary with network distance between users, with closer interactions eliciting positive emotions and more distant interactions leading to anger, disgust, and toxicity. These findings are consistent across diverse datasets and languages, spanning discussions on topics such as the Covid-19 pandemic, abortion, and the 2017 French Election. Our research provides new insights into the complex social dynamics of affective polarization in the digital age and its implications for political discourse. ",
    "url": "https://arxiv.org/abs/2310.18553",
    "authors": [
      "Dan Feldman",
      "Ashwin Rao",
      "Zihao He",
      "Kristina Lerman"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.18555",
    "title": "Group Robust Classification Without Any Group Information",
    "abstract": "Empirical risk minimization (ERM) is sensitive to spurious correlations in the training data, which poses a significant risk when deploying systems trained under this paradigm in high-stake applications. While the existing literature focuses on maximizing group-balanced or worst-group accuracy, estimating these accuracies is hindered by costly bias annotations. This study contends that current bias-unsupervised approaches to group robustness continue to rely on group information to achieve optimal performance. Firstly, these methods implicitly assume that all group combinations are represented during training. To illustrate this, we introduce a systematic generalization task on the MPI3D dataset and discover that current algorithms fail to improve the ERM baseline when combinations of observed attribute values are missing. Secondly, bias labels are still crucial for effective model selection, restricting the practicality of these methods in real-world scenarios. To address these limitations, we propose a revised methodology for training and validating debiased models in an entirely bias-unsupervised manner. We achieve this by employing pretrained self-supervised models to reliably extract bias information, which enables the integration of a logit adjustment training loss with our validation criterion. Our empirical analysis on synthetic and real-world tasks provides evidence that our approach overcomes the identified challenges and consistently enhances robust accuracy, attaining performance which is competitive with or outperforms that of state-of-the-art methods, which, conversely, rely on bias labels for validation. ",
    "url": "https://arxiv.org/abs/2310.18555",
    "authors": [
      "Christos Tsirigotis",
      "Joao Monteiro",
      "Pau Rodriguez",
      "David Vazquez",
      "Aaron Courville"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18564",
    "title": "A General Framework for Robust G-Invariance in G-Equivariant Networks",
    "abstract": "We introduce a general method for achieving robust group-invariance in group-equivariant convolutional neural networks ($G$-CNNs), which we call the $G$-triple-correlation ($G$-TC) layer. The approach leverages the theory of the triple-correlation on groups, which is the unique, lowest-degree polynomial invariant map that is also complete. Many commonly used invariant maps - such as the max - are incomplete: they remove both group and signal structure. A complete invariant, by contrast, removes only the variation due to the actions of the group, while preserving all information about the structure of the signal. The completeness of the triple correlation endows the $G$-TC layer with strong robustness, which can be observed in its resistance to invariance-based adversarial attacks. In addition, we observe that it yields measurable improvements in classification accuracy over standard Max $G$-Pooling in $G$-CNN architectures. We provide a general and efficient implementation of the method for any discretized group, which requires only a table defining the group's product structure. We demonstrate the benefits of this method for $G$-CNNs defined on both commutative and non-commutative groups - $SO(2)$, $O(2)$, $SO(3)$, and $O(3)$ (discretized as the cyclic $C8$, dihedral $D16$, chiral octahedral $O$ and full octahedral $O_h$ groups) - acting on $\\mathbb{R}^2$ and $\\mathbb{R}^3$ on both $G$-MNIST and $G$-ModelNet10 datasets. ",
    "url": "https://arxiv.org/abs/2310.18564",
    "authors": [
      "Sophia Sanborn",
      "Nina Miolane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18583",
    "title": "Self-Supervised Multi-Modality Learning for Multi-Label Skin Lesion  Classification",
    "abstract": "The clinical diagnosis of skin lesion involves the analysis of dermoscopic and clinical modalities. Dermoscopic images provide a detailed view of the surface structures whereas clinical images offer a complementary macroscopic information. The visual diagnosis of melanoma is also based on seven-point checklist which involves identifying different visual attributes. Recently, supervised learning approaches such as convolutional neural networks (CNNs) have shown great performances using both dermoscopic and clinical modalities (Multi-modality). The seven different visual attributes in the checklist are also used to further improve the the diagnosis. The performances of these approaches, however, are still reliant on the availability of large-scaled labeled data. The acquisition of annotated dataset is an expensive and time-consuming task, more so with annotating multi-attributes. To overcome this limitation, we propose a self-supervised learning (SSL) algorithm for multi-modality skin lesion classification. Our algorithm enables the multi-modality learning by maximizing the similarities between paired dermoscopic and clinical images from different views. In addition, we generate surrogate pseudo-multi-labels that represent seven attributes via clustering analysis. We also propose a label-relation-aware module to refine each pseudo-label embedding and capture the interrelationships between pseudo-multi-labels. We validated the effectiveness of our algorithm using well-benchmarked seven-point skin lesion dataset. Our results show that our algorithm achieved better performances than other state-of-the-art SSL counterparts. ",
    "url": "https://arxiv.org/abs/2310.18583",
    "authors": [
      "Hao Wang",
      "Euijoon Ahn",
      "Lei Bi",
      "Jinman Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18587",
    "title": "Assessing and Improving Syntactic Adversarial Robustness of Pre-trained  Models for Code Translation",
    "abstract": "Context: Pre-trained models (PTMs) have demonstrated significant potential in automatic code translation. However, the vulnerability of these models in translation tasks, particularly in terms of syntax, has not been extensively investigated. Objective: To fill this gap, our study aims to propose a novel approach CoTR to assess and improve the syntactic adversarial robustness of PTMs in code translation. Method: CoTR consists of two components: CoTR-A and CoTR-D. CoTR-A generates adversarial examples by transforming programs, while CoTR-D proposes a semantic distance-based sampling data augmentation method and adversarial training method to improve the model's robustness and generalization capabilities. The Pass@1 metric is used by CoTR to assess the performance of PTMs, which is more suitable for code translation tasks and offers a more precise evaluation in real world scenarios. Results: The effectiveness of CoTR is evaluated through experiments on real world Java to Python datasets. The results demonstrate that CoTR-A can significantly reduce the performance of existing PTMs, while CoTR-D effectively improves the robustness of PTMs. Conclusion: Our study identifies the limitations of current PTMs, including large language models, in code translation tasks. It highlights the potential of CoTR as an effective solution to enhance the robustness of PTMs for code translation tasks. ",
    "url": "https://arxiv.org/abs/2310.18587",
    "authors": [
      "Guang Yang",
      "Yu Zhou",
      "Xiangyu Zhang",
      "Xiang Chen",
      "Tingting Han",
      "Taolue Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.18603",
    "title": "Large Language Models Are Better Adversaries: Exploring Generative  Clean-Label Backdoor Attacks Against Text Classifiers",
    "abstract": "Backdoor attacks manipulate model predictions by inserting innocuous triggers into training and test data. We focus on more realistic and more challenging clean-label attacks where the adversarial training examples are correctly labeled. Our attack, LLMBkd, leverages language models to automatically insert diverse style-based triggers into texts. We also propose a poison selection technique to improve the effectiveness of both LLMBkd as well as existing textual backdoor attacks. Lastly, we describe REACT, a baseline defense to mitigate backdoor attacks via antidote training examples. Our evaluations demonstrate LLMBkd's effectiveness and efficiency, where we consistently achieve high attack success rates across a wide range of styles with little effort and no model training. ",
    "url": "https://arxiv.org/abs/2310.18603",
    "authors": [
      "Wencong You",
      "Zayd Hammoudeh",
      "Daniel Lowd"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18606",
    "title": "Where have you been? A Study of Privacy Risk for Point-of-Interest  Recommendation",
    "abstract": "As location-based services (LBS) have grown in popularity, the collection of human mobility data has become increasingly extensive to build machine learning (ML) models offering enhanced convenience to LBS users. However, the convenience comes with the risk of privacy leakage since this type of data might contain sensitive information related to user identities, such as home/work locations. Prior work focuses on protecting mobility data privacy during transmission or prior to release, lacking the privacy risk evaluation of mobility data-based ML models. To better understand and quantify the privacy leakage in mobility data-based ML models, we design a privacy attack suite containing data extraction and membership inference attacks tailored for point-of-interest (POI) recommendation models, one of the most widely used mobility data-based ML models. These attacks in our attack suite assume different adversary knowledge and aim to extract different types of sensitive information from mobility data, providing a holistic privacy risk assessment for POI recommendation models. Our experimental evaluation using two real-world mobility datasets demonstrates that current POI recommendation models are vulnerable to our attacks. We also present unique findings to understand what types of mobility data are more susceptible to privacy attacks. Finally, we evaluate defenses against these attacks and highlight future directions and challenges. ",
    "url": "https://arxiv.org/abs/2310.18606",
    "authors": [
      "Kunlin Cai",
      "Jinghuai Zhang",
      "Will Shand",
      "Zhiqing Hong",
      "Guang Wang",
      "Desheng Zhang",
      "Jianfeng Chi",
      "Yuan Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.18608",
    "title": "Embedding in Recommender Systems: A Survey",
    "abstract": "Recommender systems have become an essential component of many online platforms, providing personalized recommendations to users. A crucial aspect is embedding techniques that coverts the high-dimensional discrete features, such as user and item IDs, into low-dimensional continuous vectors and can enhance the recommendation performance. Applying embedding techniques captures complex entity relationships and has spurred substantial research. In this survey, we provide an overview of the recent literature on embedding techniques in recommender systems. This survey covers embedding methods like collaborative filtering, self-supervised learning, and graph-based techniques. Collaborative filtering generates embeddings capturing user-item preferences, excelling in sparse data. Self-supervised methods leverage contrastive or generative learning for various tasks. Graph-based techniques like node2vec exploit complex relationships in network-rich environments. Addressing the scalability challenges inherent to embedding methods, our survey delves into innovative directions within the field of recommendation systems. These directions aim to enhance performance and reduce computational complexity, paving the way for improved recommender systems. Among these innovative approaches, we will introduce Auto Machine Learning (AutoML), hash techniques, and quantization techniques in this survey. We discuss various architectures and techniques and highlight the challenges and future directions in these aspects. This survey aims to provide a comprehensive overview of the state-of-the-art in this rapidly evolving field and serve as a useful resource for researchers and practitioners working in the area of recommender systems. ",
    "url": "https://arxiv.org/abs/2310.18608",
    "authors": [
      "Xiangyu Zhao",
      "Maolin Wang",
      "Xinjian Zhao",
      "Jiansheng Li",
      "Shucheng Zhou",
      "Dawei Yin",
      "Qing Li",
      "Jiliang Tang",
      "Ruocheng Guo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.18612",
    "title": "Efficient kernel surrogates for neural network-based regression",
    "abstract": "Despite their immense promise in performing a variety of learning tasks, a theoretical understanding of the effectiveness and limitations of Deep Neural Networks (DNNs) has so far eluded practitioners. This is partly due to the inability to determine the closed forms of the learned functions, making it harder to assess their precise dependence on the training data and to study their generalization properties on unseen datasets. Recent work has shown that randomly initialized DNNs in the infinite width limit converge to kernel machines relying on a Neural Tangent Kernel (NTK) with known closed form. These results suggest, and experimental evidence corroborates, that empirical kernel machines can also act as surrogates for finite width DNNs. The high computational cost of assembling the full NTK, however, makes this approach infeasible in practice, motivating the need for low-cost approximations. In the current work, we study the performance of the Conjugate Kernel (CK), an efficient approximation to the NTK that has been observed to yield fairly similar results. For the regression problem of smooth functions and classification using logistic regression, we show that the CK performance is only marginally worse than that of the NTK and, in certain cases, is shown to be superior. In particular, we establish bounds for the relative test losses, verify them with numerical tests, and identify the regularity of the kernel as the key determinant of performance. In addition to providing a theoretical grounding for using CKs instead of NTKs, our framework provides insights into understanding the robustness of the various approximants and suggests a recipe for improving DNN accuracy inexpensively. We present a demonstration of this on the foundation model GPT-2 by comparing its performance on a classification task using a conventional approach and our prescription. ",
    "url": "https://arxiv.org/abs/2310.18612",
    "authors": [
      "Saad Qadeer",
      "Andrew Engel",
      "Adam Tsou",
      "Max Vargas",
      "Panos Stinis",
      "Tony Chiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18615",
    "title": "Temporally Disentangled Representation Learning under Unknown  Nonstationarity",
    "abstract": "In unsupervised causal representation learning for sequential data with time-delayed latent causal influences, strong identifiability results for the disentanglement of causally-related latent variables have been established in stationary settings by leveraging temporal structure. However, in nonstationary setting, existing work only partially addressed the problem by either utilizing observed auxiliary variables (e.g., class labels and/or domain indexes) as side information or assuming simplified latent causal dynamics. Both constrain the method to a limited range of scenarios. In this study, we further explored the Markov Assumption under time-delayed causally related process in nonstationary setting and showed that under mild conditions, the independent latent components can be recovered from their nonlinear mixture up to a permutation and a component-wise transformation, without the observation of auxiliary variables. We then introduce NCTRL, a principled estimation framework, to reconstruct time-delayed latent causal variables and identify their relations from measured sequential data only. Empirical evaluations demonstrated the reliable identification of time-delayed latent causal influences, with our methodology substantially outperforming existing baselines that fail to exploit the nonstationarity adequately and then, consequently, cannot distinguish distribution shifts. ",
    "url": "https://arxiv.org/abs/2310.18615",
    "authors": [
      "Xiangchen Song",
      "Weiran Yao",
      "Yewen Fan",
      "Xinshuai Dong",
      "Guangyi Chen",
      "Juan Carlos Niebles",
      "Eric Xing",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.18620",
    "title": "ODM3D: Alleviating Foreground Sparsity for Enhanced Semi-Supervised  Monocular 3D Object Detection",
    "abstract": "Monocular 3D object detection (M3OD) is a significant yet inherently challenging task in autonomous driving due to absence of implicit depth cues in a single RGB image. In this paper, we strive to boost currently underperforming monocular 3D object detectors by leveraging an abundance of unlabelled data via semi-supervised learning. Our proposed ODM3D framework entails cross-modal knowledge distillation at various levels to inject LiDAR-domain knowledge into a monocular detector during training. By identifying foreground sparsity as the main culprit behind existing methods' suboptimal training, we exploit the precise localisation information embedded in LiDAR points to enable more foreground-attentive and efficient distillation via the proposed BEV occupancy guidance mask, leading to notably improved knowledge transfer and M3OD performance. Besides, motivated by insights into why existing cross-modal GT-sampling techniques fail on our task at hand, we further design a novel cross-modal object-wise data augmentation strategy for effective RGB-LiDAR joint learning. Our method ranks 1st in both KITTI validation and test benchmarks, significantly surpassing all existing monocular methods, supervised or semi-supervised, on both BEV and 3D detection metrics. ",
    "url": "https://arxiv.org/abs/2310.18620",
    "authors": [
      "Weijia Zhang",
      "Dongnan Liu",
      "Chao Ma",
      "Weidong Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18622",
    "title": "Arbitrarily Scalable Environment Generators via Neural Cellular Automata",
    "abstract": "We study the problem of generating arbitrarily large environments to improve the throughput of multi-robot systems. Prior work proposes Quality Diversity (QD) algorithms as an effective method for optimizing the environments of automated warehouses. However, these approaches optimize only relatively small environments, falling short when it comes to replicating real-world warehouse sizes. The challenge arises from the exponential increase in the search space as the environment size increases. Additionally, the previous methods have only been tested with up to 350 robots in simulations, while practical warehouses could host thousands of robots. In this paper, instead of optimizing environments, we propose to optimize Neural Cellular Automata (NCA) environment generators via QD algorithms. We train a collection of NCA generators with QD algorithms in small environments and then generate arbitrarily large environments from the generators at test time. We show that NCA environment generators maintain consistent, regularized patterns regardless of environment size, significantly enhancing the scalability of multi-robot systems in two different domains with up to 2,350 robots. Additionally, we demonstrate that our method scales a single-agent reinforcement learning policy to arbitrarily large environments with similar patterns. We include the source code at \\url{https://github.com/lunjohnzhang/warehouse_env_gen_nca_public}. ",
    "url": "https://arxiv.org/abs/2310.18622",
    "authors": [
      "Yulun Zhang",
      "Matthew C. Fontaine",
      "Varun Bhatt",
      "Stefanos Nikolaidis",
      "Jiaoyang Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.18626",
    "title": "Benchmark Generation Framework with Customizable Distortions for Image  Classifier Robustness",
    "abstract": "We present a novel framework for generating adversarial benchmarks to evaluate the robustness of image classification models. Our framework allows users to customize the types of distortions to be optimally applied to images, which helps address the specific distortions relevant to their deployment. The benchmark can generate datasets at various distortion levels to assess the robustness of different image classifiers. Our results show that the adversarial samples generated by our framework with any of the image classification models, like ResNet-50, Inception-V3, and VGG-16, are effective and transferable to other models causing them to fail. These failures happen even when these models are adversarially retrained using state-of-the-art techniques, demonstrating the generalizability of our adversarial samples. We achieve competitive performance in terms of net $L_2$ distortion compared to state-of-the-art benchmark techniques on CIFAR-10 and ImageNet; however, we demonstrate our framework achieves such results with simple distortions like Gaussian noise without introducing unnatural artifacts or color bleeds. This is made possible by a model-based reinforcement learning (RL) agent and a technique that reduces a deep tree search of the image for model sensitivity to perturbations, to a one-level analysis and action. The flexibility of choosing distortions and setting classification probability thresholds for multiple classes makes our framework suitable for algorithmic audits. ",
    "url": "https://arxiv.org/abs/2310.18626",
    "authors": [
      "Soumyendu Sarkar",
      "Ashwin Ramesh Babu",
      "Sajad Mousavi",
      "Zachariah Carmichael",
      "Vineet Gundecha",
      "Sahand Ghorbanpour",
      "Ricardo Luna",
      "Gutierrez Antonio Guillen",
      "Avisek Naug"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18628",
    "title": "Personalised Distillation: Empowering Open-Sourced LLMs with Adaptive  Learning for Code Generation",
    "abstract": "With the rise of powerful closed-sourced LLMs (ChatGPT, GPT-4), there are increasing interests in distilling the capabilies of close-sourced LLMs to smaller open-sourced LLMs. Previous distillation methods usually prompt ChatGPT to generate a set of instructions and answers, for the student model to learn. However, such standard distillation approach neglects the merits and conditions of the student model. Inspired by modern teaching principles, we design a personalised distillation process, in which the student attempts to solve a task first, then the teacher provides an adaptive refinement for the student to improve. Instead of feeding the student with teacher's prior, personalised distillation enables personalised learning for the student model, as it only learns on examples it makes mistakes upon and learns to improve its own solution. On code generation, personalised distillation consistently outperforms standard distillation with only one third of the data. With only 2.5-3K personalised examples that incur a data-collection cost of 4-6$, we boost CodeGen-mono-16B by 7% to achieve 36.4% pass@1 and StarCoder by 12.2% to achieve 45.8% pass@1 on HumanEval. ",
    "url": "https://arxiv.org/abs/2310.18628",
    "authors": [
      "Hailin Chen",
      "Amrita Saha",
      "Steven Hoi",
      "Shafiq Joty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18634",
    "title": "SSL Framework for Causal Inconsistency between Structures and  Representations",
    "abstract": "The cross-pollination of deep learning and causal discovery has catalyzed a burgeoning field of research seeking to elucidate causal relationships within non-statistical data forms like images, videos, and text. Such data, often being named `indefinite data', exhibit unique challenges-inconsistency between causal structure and representation, which are not common in conventional data forms. To tackle this issue, we theoretically develop intervention strategies suitable for indefinite data and derive causal consistency condition (CCC). Moreover, we design a self-supervised learning (SSL) framework that considers interventions as `views' and CCC as a `philosophy' with two implement examples on Supervised Specialized Models (SSMs) and Large Language Models (LLMs), respectively. To evaluate pure inconsistency manifestations, we have prepared the first high-quality causal dialogue dataset-Causalogue. Evaluations are also performed on three other downstream tasks. Extensive experimentation has substantiated the efficacy of our methodology, illuminating how CCC could potentially play an influential role in various fields. ",
    "url": "https://arxiv.org/abs/2310.18634",
    "authors": [
      "Hang Chen",
      "Xinyu Yang",
      "Keqing Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18651",
    "title": "Local-Global Self-Supervised Visual Representation Learning",
    "abstract": "Self-supervised representation learning methods mainly focus on image-level instance discrimination. This study explores the potential benefits of incorporating patch-level discrimination into existing methods to enhance the quality of learned representations by simultaneously looking at local and global visual features. Towards this idea, we present a straightforward yet effective patch-matching algorithm that can find the corresponding patches across the augmented views of an image. The augmented views are subsequently fed into a self-supervised learning framework employing Vision Transformer (ViT) as its backbone. The result is the generation of both image-level and patch-level representations. Leveraging the proposed patch-matching algorithm, the model minimizes the representation distance between not only the CLS tokens but also the corresponding patches. As a result, the model gains a more comprehensive understanding of both the entirety of the image as well as its finer details. We pretrain the proposed method on small, medium, and large-scale datasets. It is shown that our approach could outperform state-of-the-art image-level representation learning methods on both image classification and downstream tasks. Keywords: Self-Supervised Learning; Visual Representations; Local-Global Representation Learning; Patch-Wise Representation Learning; Vision Transformer (ViT) ",
    "url": "https://arxiv.org/abs/2310.18651",
    "authors": [
      "Ali Javidani",
      "Mohammad Amin Sadeghi",
      "Babak Nadjar Araabi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18653",
    "title": "Feature Guided Masked Autoencoder for Self-supervised Learning in Remote  Sensing",
    "abstract": "Self-supervised learning guided by masked image modelling, such as Masked AutoEncoder (MAE), has attracted wide attention for pretraining vision transformers in remote sensing. However, MAE tends to excessively focus on pixel details, thereby limiting the model's capacity for semantic understanding, in particular for noisy SAR images. In this paper, we explore spectral and spatial remote sensing image features as improved MAE-reconstruction targets. We first conduct a study on reconstructing various image features, all performing comparably well or better than raw pixels. Based on such observations, we propose Feature Guided Masked Autoencoder (FG-MAE): reconstructing a combination of Histograms of Oriented Graidents (HOG) and Normalized Difference Indices (NDI) for multispectral images, and reconstructing HOG for SAR images. Experimental results on three downstream tasks illustrate the effectiveness of FG-MAE with a particular boost for SAR imagery. Furthermore, we demonstrate the well-inherited scalability of FG-MAE and release a first series of pretrained vision transformers for medium resolution SAR and multispectral images. ",
    "url": "https://arxiv.org/abs/2310.18653",
    "authors": [
      "Yi Wang",
      "Hugo Hern\u00e1ndez Hern\u00e1ndez",
      "Conrad M Albrecht",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18676",
    "title": "Efficient Object Detection in Optical Remote Sensing Imagery via  Attention-based Feature Distillation",
    "abstract": "Efficient object detection methods have recently received great attention in remote sensing. Although deep convolutional networks often have excellent detection accuracy, their deployment on resource-limited edge devices is difficult. Knowledge distillation (KD) is a strategy for addressing this issue since it makes models lightweight while maintaining accuracy. However, existing KD methods for object detection have encountered two constraints. First, they discard potentially important background information and only distill nearby foreground regions. Second, they only rely on the global context, which limits the student detector's ability to acquire local information from the teacher detector. To address the aforementioned challenges, we propose Attention-based Feature Distillation (AFD), a new KD approach that distills both local and global information from the teacher detector. To enhance local distillation, we introduce a multi-instance attention mechanism that effectively distinguishes between background and foreground elements. This approach prompts the student detector to focus on the pertinent channels and pixels, as identified by the teacher detector. Local distillation lacks global information, thus attention global distillation is proposed to reconstruct the relationship between various pixels and pass it from teacher to student detector. The performance of AFD is evaluated on two public aerial image benchmarks, and the evaluation results demonstrate that AFD in object detection can attain the performance of other state-of-the-art models while being efficient. ",
    "url": "https://arxiv.org/abs/2310.18676",
    "authors": [
      "Pourya Shamsolmoali",
      "Jocelyn Chanussot",
      "Huiyu Zhou",
      "Yue Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18681",
    "title": "DySurv: Dynamic Deep Learning Model for Survival Prediction in the ICU",
    "abstract": "Survival analysis helps approximate underlying distributions of time-to-events which in the case of critical care like in the ICU can be a powerful tool for dynamic mortality risk prediction. Extending beyond the classical Cox model, deep learning techniques have been leveraged over the last years relaxing the many constraints of their counterparts from statistical methods. In this work, we propose a novel conditional variational autoencoder-based method called DySurv which uses a combination of static and time-series measurements from patient electronic health records in estimating risk of death dynamically in the ICU. DySurv has been tested on standard benchmarks where it outperforms most existing methods including other deep learning methods and we evaluate it on a real-world patient database from MIMIC-IV. The predictive capacity of DySurv is consistent and the survival estimates remain disentangled across different datasets supporting the idea that dynamic deep learning models based on conditional variational inference in multi-task cases can be robust models for survival analysis. ",
    "url": "https://arxiv.org/abs/2310.18681",
    "authors": [
      "Munib Mesinovic",
      "Peter Watkinson",
      "Tingting Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18700",
    "title": "Empowering Collaborative Filtering with Principled Adversarial  Contrastive Loss",
    "abstract": "Contrastive Learning (CL) has achieved impressive performance in self-supervised learning tasks, showing superior generalization ability. Inspired by the success, adopting CL into collaborative filtering (CF) is prevailing in semi-supervised top-K recommendations. The basic idea is to routinely conduct heuristic-based data augmentation and apply contrastive losses (e.g., InfoNCE) on the augmented views. Yet, some CF-tailored challenges make this adoption suboptimal, such as the issue of out-of-distribution, the risk of false negatives, and the nature of top-K evaluation. They necessitate the CL-based CF scheme to focus more on mining hard negatives and distinguishing false negatives from the vast unlabeled user-item interactions, for informative contrast signals. Worse still, there is limited understanding of contrastive loss in CF methods, especially w.r.t. its generalization ability. To bridge the gap, we delve into the reasons underpinning the success of contrastive loss in CF, and propose a principled Adversarial InfoNCE loss (AdvInfoNCE), which is a variant of InfoNCE, specially tailored for CF methods. AdvInfoNCE adaptively explores and assigns hardness to each negative instance in an adversarial fashion and further utilizes a fine-grained hardness-aware ranking criterion to empower the recommender's generalization ability. Training CF models with AdvInfoNCE, we validate the effectiveness of AdvInfoNCE on both synthetic and real-world benchmark datasets, thus showing its generalization ability to mitigate out-of-distribution problems. Given the theoretical guarantees and empirical superiority of AdvInfoNCE over most contrastive loss functions, we advocate its adoption as a standard loss in recommender systems, particularly for the out-of-distribution tasks. Codes are available at https://github.com/LehengTHU/AdvInfoNCE. ",
    "url": "https://arxiv.org/abs/2310.18700",
    "authors": [
      "An Zhang",
      "Leheng Sheng",
      "Zhibo Cai",
      "Xiang Wang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.18706",
    "title": "ALERTA-Net: A Temporal Distance-Aware Recurrent Networks for Stock  Movement and Volatility Prediction",
    "abstract": "For both investors and policymakers, forecasting the stock market is essential as it serves as an indicator of economic well-being. To this end, we harness the power of social media data, a rich source of public sentiment, to enhance the accuracy of stock market predictions. Diverging from conventional methods, we pioneer an approach that integrates sentiment analysis, macroeconomic indicators, search engine data, and historical prices within a multi-attention deep learning model, masterfully decoding the complex patterns inherent in the data. We showcase the state-of-the-art performance of our proposed model using a dataset, specifically curated by us, for predicting stock market movements and volatility. ",
    "url": "https://arxiv.org/abs/2310.18706",
    "authors": [
      "Shengkun Wang",
      "YangXiao Bai",
      "Kaiqun Fu",
      "Linhan Wang",
      "Chang-Tien Lu",
      "Taoran Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18713",
    "title": "Episodic Multi-Task Learning with Heterogeneous Neural Processes",
    "abstract": "This paper focuses on the data-insufficiency problem in multi-task learning within an episodic training setup. Specifically, we explore the potential of heterogeneous information across tasks and meta-knowledge among episodes to effectively tackle each task with limited data. Existing meta-learning methods often fail to take advantage of crucial heterogeneous information in a single episode, while multi-task learning models neglect reusing experience from earlier episodes. To address the problem of insufficient data, we develop Heterogeneous Neural Processes (HNPs) for the episodic multi-task setup. Within the framework of hierarchical Bayes, HNPs effectively capitalize on prior experiences as meta-knowledge and capture task-relatedness among heterogeneous tasks, mitigating data-insufficiency. Meanwhile, transformer-structured inference modules are designed to enable efficient inferences toward meta-knowledge and task-relatedness. In this way, HNPs can learn more powerful functional priors for adapting to novel heterogeneous tasks in each meta-test episode. Experimental results show the superior performance of the proposed HNPs over typical baselines, and ablation studies verify the effectiveness of the designed inference modules. ",
    "url": "https://arxiv.org/abs/2310.18713",
    "authors": [
      "Jiayi Shen",
      "Xiantong Zhen",
      "Wang",
      "Marcel Worring"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18715",
    "title": "Robust Offline Policy Evaluation and Optimization with Heavy-Tailed  Rewards",
    "abstract": "This paper endeavors to augment the robustness of offline reinforcement learning (RL) in scenarios laden with heavy-tailed rewards, a prevalent circumstance in real-world applications. We propose two algorithmic frameworks, ROAM and ROOM, for robust off-policy evaluation (OPE) and offline policy optimization (OPO), respectively. Central to our frameworks is the strategic incorporation of the median-of-means method with offline RL, enabling straightforward uncertainty estimation for the value function estimator. This not only adheres to the principle of pessimism in OPO but also adeptly manages heavy-tailed rewards. Theoretical results and extensive experiments demonstrate that our two frameworks outperform existing methods on the logged dataset exhibits heavy-tailed reward distributions. ",
    "url": "https://arxiv.org/abs/2310.18715",
    "authors": [
      "Jin Zhu",
      "Runzhe Wan",
      "Zhengling Qi",
      "Shikai Luo",
      "Chengchun Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.18716",
    "title": "Laplacian Canonization: A Minimalist Approach to Sign and Basis  Invariant Spectral Embedding",
    "abstract": "Spectral embedding is a powerful graph embedding technique that has received a lot of attention recently due to its effectiveness on Graph Transformers. However, from a theoretical perspective, the universal expressive power of spectral embedding comes at the price of losing two important invariance properties of graphs, sign and basis invariance, which also limits its effectiveness on graph data. To remedy this issue, many previous methods developed costly approaches to learn new invariants and suffer from high computation complexity. In this work, we explore a minimal approach that resolves the ambiguity issues by directly finding canonical directions for the eigenvectors, named Laplacian Canonization (LC). As a pure pre-processing method, LC is light-weighted and can be applied to any existing GNNs. We provide a thorough investigation, from theory to algorithm, on this approach, and discover an efficient algorithm named Maximal Axis Projection (MAP) that works for both sign and basis invariance and successfully canonizes more than 90% of all eigenvectors. Experiments on real-world benchmark datasets like ZINC, MOLTOX21, and MOLPCBA show that MAP consistently outperforms existing methods while bringing minimal computation overhead. Code is available at https://github.com/PKU-ML/LaplacianCanonization. ",
    "url": "https://arxiv.org/abs/2310.18716",
    "authors": [
      "Jiangyan Ma",
      "Yifei Wang",
      "Yisen Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18725",
    "title": "The Evolution of the Interplay Between Input Distributions and Linear  Regions in Networks",
    "abstract": "It is commonly recognized that the expressiveness of deep neural networks is contingent upon a range of factors, encompassing their depth, width, and other relevant considerations. Currently, the practical performance of the majority of deep neural networks remains uncertain. For ReLU (Rectified Linear Unit) networks with piecewise linear activations, the number of linear convex regions serves as a natural metric to gauge the network's expressivity. In this paper, we count the number of linear convex regions in deep neural networks based on ReLU. In particular, we prove that for any one-dimensional input, there exists a minimum threshold for the number of neurons required to express it. We also empirically observe that for the same network, intricate inputs hinder its capacity to express linear regions. Furthermore, we unveil the iterative refinement process of decision boundaries in ReLU networks during training. We aspire for our research to serve as an inspiration for network optimization endeavors and aids in the exploration and analysis of the behaviors exhibited by deep networks. ",
    "url": "https://arxiv.org/abs/2310.18725",
    "authors": [
      "Xuan Qi",
      "Yi Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.18728",
    "title": "Online Multi-view Anomaly Detection with Disentangled Product-of-Experts  Modeling",
    "abstract": "Multi-view or even multi-modal data is appealing yet challenging for real-world applications. Detecting anomalies in multi-view data is a prominent recent research topic. However, most of the existing methods 1) are only suitable for two views or type-specific anomalies, 2) suffer from the issue of fusion disentanglement, and 3) do not support online detection after model deployment. To address these challenges, our main ideas in this paper are three-fold: multi-view learning, disentangled representation learning, and generative model. To this end, we propose dPoE, a novel multi-view variational autoencoder model that involves (1) a Product-of-Experts (PoE) layer in tackling multi-view data, (2) a Total Correction (TC) discriminator in disentangling view-common and view-specific representations, and (3) a joint loss function in wrapping up all components. In addition, we devise theoretical information bounds to control both view-common and view-specific representations. Extensive experiments on six real-world datasets demonstrate that the proposed dPoE outperforms baselines markedly. ",
    "url": "https://arxiv.org/abs/2310.18728",
    "authors": [
      "Hao Wang",
      "Zhi-Qi Cheng",
      "Jingdong Sun",
      "Xin Yang",
      "Xiao Wu",
      "Hongyang Chen",
      "Yan Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2310.18735",
    "title": "Curriculum Learning for Graph Neural Networks: Which Edges Should We  Learn First",
    "abstract": "Graph Neural Networks (GNNs) have achieved great success in representing data with dependencies by recursively propagating and aggregating messages along the edges. However, edges in real-world graphs often have varying degrees of difficulty, and some edges may even be noisy to the downstream tasks. Therefore, existing GNNs may lead to suboptimal learned representations because they usually treat every edge in the graph equally. On the other hand, Curriculum Learning (CL), which mimics the human learning principle of learning data samples in a meaningful order, has been shown to be effective in improving the generalization ability and robustness of representation learners by gradually proceeding from easy to more difficult samples during training. Unfortunately, existing CL strategies are designed for independent data samples and cannot trivially generalize to handle data dependencies. To address these issues, we propose a novel CL strategy to gradually incorporate more edges into training according to their difficulty from easy to hard, where the degree of difficulty is measured by how well the edges are expected given the model training status. We demonstrate the strength of our proposed method in improving the generalization ability and robustness of learned representations through extensive experiments on nine synthetic datasets and nine real-world datasets. The code for our proposed method is available at https://github.com/rollingstonezz/Curriculum_learning_for_GNNs. ",
    "url": "https://arxiv.org/abs/2310.18735",
    "authors": [
      "Zheng Zhang",
      "Junxiang Wang",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18769",
    "title": "Linear Mode Connectivity in Sparse Neural Networks",
    "abstract": "With the rise in interest of sparse neural networks, we study how neural network pruning with synthetic data leads to sparse networks with unique training properties. We find that distilled data, a synthetic summarization of the real data, paired with Iterative Magnitude Pruning (IMP) unveils a new class of sparse networks that are more stable to SGD noise on the real data, than either the dense model, or subnetworks found with real data in IMP. That is, synthetically chosen subnetworks often train to the same minima, or exhibit linear mode connectivity. We study this through linear interpolation, loss landscape visualizations, and measuring the diagonal of the hessian. While dataset distillation as a field is still young, we find that these properties lead to synthetic subnetworks matching the performance of traditional IMP with up to 150x less training points in settings where distilled data applies. ",
    "url": "https://arxiv.org/abs/2310.18769",
    "authors": [
      "Luke McDermott",
      "Daniel Cummings"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.18788",
    "title": "PrObeD: Proactive Object Detection Wrapper",
    "abstract": "Previous research in $2D$ object detection focuses on various tasks, including detecting objects in generic and camouflaged images. These works are regarded as passive works for object detection as they take the input image as is. However, convergence to global minima is not guaranteed to be optimal in neural networks; therefore, we argue that the trained weights in the object detector are not optimal. To rectify this problem, we propose a wrapper based on proactive schemes, PrObeD, which enhances the performance of these object detectors by learning a signal. PrObeD consists of an encoder-decoder architecture, where the encoder network generates an image-dependent signal termed templates to encrypt the input images, and the decoder recovers this template from the encrypted images. We propose that learning the optimum template results in an object detector with an improved detection performance. The template acts as a mask to the input images to highlight semantics useful for the object detector. Finetuning the object detector with these encrypted images enhances the detection performance for both generic and camouflaged. Our experiments on MS-COCO, CAMO, COD$10$K, and NC$4$K datasets show improvement over different detectors after applying PrObeD. Our models/codes are available at https://github.com/vishal3477/Proactive-Object-Detection. ",
    "url": "https://arxiv.org/abs/2310.18788",
    "authors": [
      "Vishal Asnani",
      "Abhinav Kumar",
      "Suya You",
      "Xiaoming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18789",
    "title": "Modeling Hybrid AC/DC Power Systems with the Complex Frequency Concept",
    "abstract": "The concept of complex frequency has been recently introduced on the IEEE Transactions on Power Systems to study bus voltage variations in magnitude and frequency and their link with complex power injections of a power system. In this paper, the complex frequency is applied to time-varying series connections, namely, RLC dynamic branches, regulating transformers and AC/DC converters. The proposed modeling approach allows deriving an explicit expression for the complex frequency of the voltage of a certain bus as a linear combination of three elements: net current injected by the devices connected to the bus, adjacent voltages, and time-varying series branches. The proposed formulation unifies the link between voltage and frequency dynamics in AC, DC, as well as hybrid AC/DC power systems. A variety of static and dynamic examples are presented to show the potential of the proposed formulation. Relevant applications of the proposed modeling approach are outlined. ",
    "url": "https://arxiv.org/abs/2310.18789",
    "authors": [
      "Ignacio Ponce",
      "Federico Milano"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.18792",
    "title": "Privacy as Contextual Integrity in Online Proctoring Systems in Higher  Education: A Scoping Review",
    "abstract": "Privacy is one of the key challenges to the adoption and implementation of online proctoring systems in higher education. To better understand this challenge, we adopt privacy as contextual integrity theory to conduct a scoping review of 17 papers. The results show different types of students' personal and sensitive information are collected and disseminated; this raises considerable privacy concerns. As well as the governing principles including transparency and fairness, consent and choice, information minimization, accountability, and information security and accuracy have been identified to address privacy problems. This study notifies a need to clarify how these principles should be implemented and sustained, and what privacy concerns and actors they relate to. Further, it calls for the need to clarify the responsibility of key actors in enacting and sustaining responsible adoption and use of OPS in higher education. ",
    "url": "https://arxiv.org/abs/2310.18792",
    "authors": [
      "Mutimukwe Chantal",
      "Han Shengnan",
      "Viberg Olga",
      "Cerratto-Pargman Teresa"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.18801",
    "title": "Integrated Relative-Measurement-Based Network Localization and Formation  Maneuver Control",
    "abstract": "This paper studies the problem of integrated distributed network localization and formation maneuver control. We develop an integrated relative-measurement-based scheme, which only uses relative positions, distances, bearings, angles, ratio-of-distances, or their combination to achieve distributed network localization and formation maneuver control in $\\mathbb{R}^d (d \\ge 2)$. By exploring the localizability and invariance of the target formation, the scale, rotation, and translation of the formation can be controlled simultaneously by only tuning the leaders' positions, i.e., the followers do not need to know parameters of the scale, rotation, and translation of the target formation. The proposed method can globally drive the formation errors to zero in finite time over multi-layer $d\\!+\\!1$-rooted graphs. A simulation example is given to illustrate the theoretical results. ",
    "url": "https://arxiv.org/abs/2310.18801",
    "authors": [
      "Xu Fang",
      "Lihua Xie",
      "Xiaolei Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.18807",
    "title": "OC-NMN: Object-centric Compositional Neural Module Network for  Generative Visual Analogical Reasoning",
    "abstract": "A key aspect of human intelligence is the ability to imagine -- composing learned concepts in novel ways -- to make sense of new scenarios. Such capacity is not yet attained for machine learning systems. In this work, in the context of visual reasoning, we show how modularity can be leveraged to derive a compositional data augmentation framework inspired by imagination. Our method, denoted Object-centric Compositional Neural Module Network (OC-NMN), decomposes visual generative reasoning tasks into a series of primitives applied to objects without using a domain-specific language. We show that our modular architectural choices can be used to generate new training tasks that lead to better out-of-distribution generalization. We compare our model to existing and new baselines in proposed visual reasoning benchmark that consists of applying arithmetic operations to MNIST digits. ",
    "url": "https://arxiv.org/abs/2310.18807",
    "authors": [
      "Rim Assouel",
      "Pau Rodriguez",
      "Perouz Taslakian",
      "David Vazquez",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18831",
    "title": "Paired 2-disjoint path covers of burnt pancake graphs with faulty  elements",
    "abstract": "The burnt pancake graph $BP_n$ is the Cayley graph of the hyperoctahedral group using prefix reversals as generators. Let $\\{u,v\\}$ and $\\{x,y\\}$ be any two pairs of distinct vertices of $BP_n$ for $n\\geq 4$. We show that there are $u-v$ and $x-y$ paths whose vertices partition the vertex set of $BP_n$ even if $BP_n$ has up to $n-4$ faulty elements. On the other hand, for every $n\\ge3$ there is a set of $n-2$ faulty edges or faulty vertices for which such a fault-free disjoint path cover does not exist. ",
    "url": "https://arxiv.org/abs/2310.18831",
    "authors": [
      "Tom\u00e1\u0161 Dvo\u0159\u00e1k",
      "Mei-Mei Gu"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2310.18834",
    "title": "Automating the Correctness Assessment of AI-generated Code for Security  Contexts",
    "abstract": "In this paper, we propose a fully automated method, named ACCA, to evaluate the correctness of AI-generated code for security purposes. The method uses symbolic execution to assess whether the AI-generated code behaves as a reference implementation. We use ACCA to assess four state-of-the-art models trained to generate security-oriented assembly code and compare the results of the evaluation with different baseline solutions, including output similarity metrics, widely used in the field, and the well-known ChatGPT, the AI-powered language model developed by OpenAI. Our experiments show that our method outperforms the baseline solutions and assesses the correctness of the AI-generated code similar to the human-based evaluation, which is considered the ground truth for the assessment in the field. Moreover, ACCA has a very strong correlation with human evaluation (Pearson's correlation coefficient r=0.84 on average). Finally, since it is a fully automated solution that does not require any human intervention, the proposed method performs the assessment of every code snippet in ~0.17s on average, which is definitely lower than the average time required by human analysts to manually inspect the code, based on our experience. ",
    "url": "https://arxiv.org/abs/2310.18834",
    "authors": [
      "Domenico Cotroneo",
      "Alessio Foggia",
      "Cristina Improta",
      "Pietro Liguori",
      "Roberto Natella"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.18846",
    "title": "INCODE: Implicit Neural Conditioning with Prior Knowledge Embeddings",
    "abstract": "Implicit Neural Representations (INRs) have revolutionized signal representation by leveraging neural networks to provide continuous and smooth representations of complex data. However, existing INRs face limitations in capturing fine-grained details, handling noise, and adapting to diverse signal types. To address these challenges, we introduce INCODE, a novel approach that enhances the control of the sinusoidal-based activation function in INRs using deep prior knowledge. INCODE comprises a harmonizer network and a composer network, where the harmonizer network dynamically adjusts key parameters of the activation function. Through a task-specific pre-trained model, INCODE adapts the task-specific parameters to optimize the representation process. Our approach not only excels in representation, but also extends its prowess to tackle complex tasks such as audio, image, and 3D shape reconstructions, as well as intricate challenges such as neural radiance fields (NeRFs), and inverse problems, including denoising, super-resolution, inpainting, and CT reconstruction. Through comprehensive experiments, INCODE demonstrates its superiority in terms of robustness, accuracy, quality, and convergence rate, broadening the scope of signal representation. Please visit the project's website for details on the proposed method and access to the code. ",
    "url": "https://arxiv.org/abs/2310.18846",
    "authors": [
      "Amirhossein Kazerouni",
      "Reza Azad",
      "Alireza Hosseini",
      "Dorit Merhof",
      "Ulas Bagci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18874",
    "title": "HDMNet: A Hierarchical Matching Network with Double Attention for  Large-scale Outdoor LiDAR Point Cloud Registration",
    "abstract": "Outdoor LiDAR point clouds are typically large-scale and complexly distributed. To achieve efficient and accurate registration, emphasizing the similarity among local regions and prioritizing global local-to-local matching is of utmost importance, subsequent to which accuracy can be enhanced through cost-effective fine registration. In this paper, a novel hierarchical neural network with double attention named HDMNet is proposed for large-scale outdoor LiDAR point cloud registration. Specifically, A novel feature consistency enhanced double-soft matching network is introduced to achieve two-stage matching with high flexibility while enlarging the receptive field with high efficiency in a patch-to patch manner, which significantly improves the registration performance. Moreover, in order to further utilize the sparse matching information from deeper layer, we develop a novel trainable embedding mask to incorporate the confidence scores of correspondences obtained from pose estimation of deeper layer, eliminating additional computations. The high-confidence keypoints in the sparser point cloud of the deeper layer correspond to a high-confidence spatial neighborhood region in shallower layer, which will receive more attention, while the features of non-key regions will be masked. Extensive experiments are conducted on two large-scale outdoor LiDAR point cloud datasets to demonstrate the high accuracy and efficiency of the proposed HDMNet. ",
    "url": "https://arxiv.org/abs/2310.18874",
    "authors": [
      "Weiyi Xue",
      "Fan Lu",
      "Guang Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.18882",
    "title": "Differentiable Learning of Generalized Structured Matrices for Efficient  Deep Neural Networks",
    "abstract": "This paper investigates efficient deep neural networks (DNNs) to replace dense unstructured weight matrices with structured ones that possess desired properties. The challenge arises because the optimal weight matrix structure in popular neural network models is obscure in most cases and may vary from layer to layer even in the same network. Prior structured matrices proposed for efficient DNNs were mostly hand-crafted without a generalized framework to systematically learn them. To address this issue, we propose a generalized and differentiable framework to learn efficient structures of weight matrices by gradient descent. We first define a new class of structured matrices that covers a wide range of structured matrices in the literature by adjusting the structural parameters. Then, the frequency-domain differentiable parameterization scheme based on the Gaussian-Dirichlet kernel is adopted to learn the structural parameters by proximal gradient descent. Finally, we introduce an effective initialization method for the proposed scheme. Our method learns efficient DNNs with structured matrices, achieving lower complexity and/or higher performance than prior approaches that employ low-rank, block-sparse, or block-low-rank matrices. ",
    "url": "https://arxiv.org/abs/2310.18882",
    "authors": [
      "Changwoo Lee",
      "Hun-Seok Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.18884",
    "title": "Simple and Asymmetric Graph Contrastive Learning without Augmentations",
    "abstract": "Graph Contrastive Learning (GCL) has shown superior performance in representation learning in graph-structured data. Despite their success, most existing GCL methods rely on prefabricated graph augmentation and homophily assumptions. Thus, they fail to generalize well to heterophilic graphs where connected nodes may have different class labels and dissimilar features. In this paper, we study the problem of conducting contrastive learning on homophilic and heterophilic graphs. We find that we can achieve promising performance simply by considering an asymmetric view of the neighboring nodes. The resulting simple algorithm, Asymmetric Contrastive Learning for Graphs (GraphACL), is easy to implement and does not rely on graph augmentations and homophily assumptions. We provide theoretical and empirical evidence that GraphACL can capture one-hop local neighborhood information and two-hop monophily similarity, which are both important for modeling heterophilic graphs. Experimental results show that the simple GraphACL significantly outperforms state-of-the-art graph contrastive learning and self-supervised learning methods on homophilic and heterophilic graphs. The code of GraphACL is available at https://github.com/tengxiao1/GraphACL. ",
    "url": "https://arxiv.org/abs/2310.18884",
    "authors": [
      "Teng Xiao",
      "Huaisheng Zhu",
      "Zhengyu Chen",
      "Suhang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.18885",
    "title": "A foundational neural operator that continuously learns without  forgetting",
    "abstract": "Machine learning has witnessed substantial growth, leading to the development of advanced artificial intelligence models crafted to address a wide range of real-world challenges spanning various domains, such as computer vision, natural language processing, and scientific computing. Nevertheless, the creation of custom models for each new task remains a resource-intensive undertaking, demanding considerable computational time and memory resources. In this study, we introduce the concept of the Neural Combinatorial Wavelet Neural Operator (NCWNO) as a foundational model for scientific computing. This model is specifically designed to excel in learning from a diverse spectrum of physics and continuously adapt to the solution operators associated with parametric partial differential equations (PDEs). The NCWNO leverages a gated structure that employs local wavelet experts to acquire shared features across multiple physical systems, complemented by a memory-based ensembling approach among these local wavelet experts. This combination enables rapid adaptation to new challenges. The proposed foundational model offers two key advantages: (i) it can simultaneously learn solution operators for multiple parametric PDEs, and (ii) it can swiftly generalize to new parametric PDEs with minimal fine-tuning. The proposed NCWNO is the first foundational operator learning algorithm distinguished by its (i) robustness against catastrophic forgetting, (ii) the maintenance of positive transfer for new parametric PDEs, and (iii) the facilitation of knowledge transfer across dissimilar tasks. Through an extensive set of benchmark examples, we demonstrate that the NCWNO can outperform task-specific baseline operator learning frameworks with minimal hyperparameter tuning at the prediction stage. We also show that with minimal fine-tuning, the NCWNO performs accurate combinatorial learning of new parametric PDEs. ",
    "url": "https://arxiv.org/abs/2310.18885",
    "authors": [
      "Tapas Tripura",
      "Souvik Chakraborty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18888",
    "title": "D2NO: Efficient Handling of Heterogeneous Input Function Spaces with  Distributed Deep Neural Operators",
    "abstract": "Neural operators have been applied in various scientific fields, such as solving parametric partial differential equations, dynamical systems with control, and inverse problems. However, challenges arise when dealing with input functions that exhibit heterogeneous properties, requiring multiple sensors to handle functions with minimal regularity. To address this issue, discretization-invariant neural operators have been used, allowing the sampling of diverse input functions with different sensor locations. However, existing frameworks still require an equal number of sensors for all functions. In our study, we propose a novel distributed approach to further relax the discretization requirements and solve the heterogeneous dataset challenges. Our method involves partitioning the input function space and processing individual input functions using independent and separate neural networks. A centralized neural network is used to handle shared information across all output functions. This distributed methodology reduces the number of gradient descent back-propagation steps, improving efficiency while maintaining accuracy. We demonstrate that the corresponding neural network is a universal approximator of continuous nonlinear operators and present four numerical examples to validate its performance. ",
    "url": "https://arxiv.org/abs/2310.18888",
    "authors": [
      "Zecheng Zhang",
      "Christian Moya",
      "Lu Lu",
      "Guang Lin",
      "Hayden Schaeffer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18891",
    "title": "Social Interaction-Aware Dynamical Models and Decision Making for  Autonomous Vehicles",
    "abstract": "Interaction-aware Autonomous Driving (IAAD) is a rapidly growing field of research that focuses on the development of autonomous vehicles (AVs) that are capable of interacting safely and efficiently with human road users. This is a challenging task, as it requires the autonomous vehicle to be able to understand and predict the behaviour of human road users. In this literature review, the current state of IAAD research is surveyed in this work. Commencing with an examination of terminology, attention is drawn to challenges and existing models employed for modelling the behaviour of drivers and pedestrians. Next, a comprehensive review is conducted on various techniques proposed for interaction modelling, encompassing cognitive methods, machine learning approaches, and game-theoretic methods. The conclusion is reached through a discussion of potential advantages and risks associated with IAAD, along with the illumination of pivotal research inquiries necessitating future exploration. ",
    "url": "https://arxiv.org/abs/2310.18891",
    "authors": [
      "Luca Crosato",
      "Kai Tian",
      "Hubert P. H Shum",
      "Edmond S. L. Ho",
      "Yafei Wang",
      "Chongfeng We"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.18894",
    "title": "Emergence of Shape Bias in Convolutional Neural Networks through  Activation Sparsity",
    "abstract": "Current deep-learning models for object recognition are known to be heavily biased toward texture. In contrast, human visual systems are known to be biased toward shape and structure. What could be the design principles in human visual systems that led to this difference? How could we introduce more shape bias into the deep learning models? In this paper, we report that sparse coding, a ubiquitous principle in the brain, can in itself introduce shape bias into the network. We found that enforcing the sparse coding constraint using a non-differential Top-K operation can lead to the emergence of structural encoding in neurons in convolutional neural networks, resulting in a smooth decomposition of objects into parts and subparts and endowing the networks with shape bias. We demonstrated this emergence of shape bias and its functional benefits for different network structures with various datasets. For object recognition convolutional neural networks, the shape bias leads to greater robustness against style and pattern change distraction. For the image synthesis generative adversary networks, the emerged shape bias leads to more coherent and decomposable structures in the synthesized images. Ablation studies suggest that sparse codes tend to encode structures, whereas the more distributed codes tend to favor texture. Our code is host at the github repository: \\url{https://github.com/Crazy-Jack/nips2023_shape_vs_texture} ",
    "url": "https://arxiv.org/abs/2310.18894",
    "authors": [
      "Tianqin Li",
      "Ziqi Wen",
      "Yangfan Li",
      "Tai Sing Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18902",
    "title": "NetPanorama: A Declarative Grammar for Network Construction,  Transformation, and Visualization",
    "abstract": "This paper introduces NetPanorama, a domain-specific language and declarative grammar for interactive network visualizations. Exploring complex networks with multivariate, geographical, or temporal information often require bespoke visualization designs, such as adjacency matrices, arc-diagrams, small multiples, timelines, or geographic map visualizations. However, creating these requires implementing data loading, data transformations, visualization, and interactivity, which is time-consuming and slows down the iterative exploration of this huge design space. With NetPanorama, a developer specifies a network visualization design as a pipeline of parameterizable steps. Our specification and reference implementation aims to facilitate visualization development and reuse; allow for easy design exploration and iteration; and make data transformation and visual mapping decisions transparent. Documentation, source code, examples, and an interactive online editor can be found online: https://netpanorama.netlify.app/ ",
    "url": "https://arxiv.org/abs/2310.18902",
    "authors": [
      "James Scott-Brown",
      "Benjamin Bach"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2310.18906",
    "title": "Stacking the Odds: Transformer-Based Ensemble for AI-Generated Text  Detection",
    "abstract": "This paper reports our submission under the team name `SynthDetectives' to the ALTA 2023 Shared Task. We use a stacking ensemble of Transformers for the task of AI-generated text detection. Our approach is novel in terms of its choice of models in that we use accessible and lightweight models in the ensemble. We show that ensembling the models results in an improved accuracy in comparison with using them individually. Our approach achieves an accuracy score of 0.9555 on the official test data provided by the shared task organisers. ",
    "url": "https://arxiv.org/abs/2310.18906",
    "authors": [
      "Duke Nguyen",
      "Khaing Myat Noe Naing",
      "Aditya Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.18912",
    "title": "Sentence Bag Graph Formulation for Biomedical Distant Supervision  Relation Extraction",
    "abstract": "We introduce a novel graph-based framework for alleviating key challenges in distantly-supervised relation extraction and demonstrate its effectiveness in the challenging and important domain of biomedical data. Specifically, we propose a graph view of sentence bags referring to an entity pair, which enables message-passing based aggregation of information related to the entity pair over the sentence bag. The proposed framework alleviates the common problem of noisy labeling in distantly supervised relation extraction and also effectively incorporates inter-dependencies between sentences within a bag. Extensive experiments on two large-scale biomedical relation datasets and the widely utilized NYT dataset demonstrate that our proposed framework significantly outperforms the state-of-the-art methods for biomedical distant supervision relation extraction while also providing excellent performance for relation extraction in the general text mining domain. ",
    "url": "https://arxiv.org/abs/2310.18912",
    "authors": [
      "Hao Zhang",
      "Yang Liu",
      "Xiaoyan Liu",
      "Tianming Liang",
      "Gaurav Sharma",
      "Liang Xue",
      "Maozu Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.18917",
    "title": "TiV-NeRF: Tracking and Mapping via Time-Varying Representation with  Dynamic Neural Radiance Fields",
    "abstract": "Previous attempts to integrate Neural Radiance Fields (NeRF) into Simultaneous Localization and Mapping (SLAM) framework either rely on the assumption of static scenes or treat dynamic objects as outliers. However, most of real-world scenarios is dynamic. In this paper, we propose a time-varying representation to track and reconstruct the dynamic scenes. Our system simultaneously maintains two processes, tracking process and mapping process. For tracking process, the entire input images are uniformly sampled and training of the RGB images are self-supervised. For mapping process, we leverage know masks to differentiate dynamic objects and static backgrounds, and we apply distinct sampling strategies for two types of areas. The parameters optimization for both processes are made up by two stages, the first stage associates time with 3D positions to convert the deformation field to the canonical field. And the second associates time with 3D positions in canonical field to obtain colors and Signed Distance Function (SDF). Besides, We propose a novel keyframe selection strategy based on the overlapping rate. We evaluate our approach on two publicly available synthetic datasets and validate that our method is more effective compared to current state-of-the-art dynamic mapping methods. ",
    "url": "https://arxiv.org/abs/2310.18917",
    "authors": [
      "Chengyao Duan",
      "Zhiliu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18918",
    "title": "Hyperbolic Graph Neural Networks at Scale: A Meta Learning Approach",
    "abstract": "The progress in hyperbolic neural networks (HNNs) research is hindered by their absence of inductive bias mechanisms, which are essential for generalizing to new tasks and facilitating scalable learning over large datasets. In this paper, we aim to alleviate these issues by learning generalizable inductive biases from the nodes' local subgraph and transfer them for faster learning over new subgraphs with a disjoint set of nodes, edges, and labels in a few-shot setting. We introduce a novel method, Hyperbolic GRAph Meta Learner (H-GRAM), that, for the tasks of node classification and link prediction, learns transferable information from a set of support local subgraphs in the form of hyperbolic meta gradients and label hyperbolic protonets to enable faster learning over a query set of new tasks dealing with disjoint subgraphs. Furthermore, we show that an extension of our meta-learning framework also mitigates the scalability challenges seen in HNNs faced by existing approaches. Our comparative analysis shows that H-GRAM effectively learns and transfers information in multiple challenging few-shot settings compared to other state-of-the-art baselines. Additionally, we demonstrate that, unlike standard HNNs, our approach is able to scale over large graph datasets and improve performance over its Euclidean counterparts. ",
    "url": "https://arxiv.org/abs/2310.18918",
    "authors": [
      "Nurendra Choudhary",
      "Nikhil Rao",
      "Chandan K. Reddy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.18920",
    "title": "Improving Multi-Person Pose Tracking with A Confidence Network",
    "abstract": "Human pose estimation and tracking are fundamental tasks for understanding human behaviors in videos. Existing top-down framework-based methods usually perform three-stage tasks: human detection, pose estimation and tracking. Although promising results have been achieved, these methods rely heavily on high-performance detectors and may fail to track persons who are occluded or miss-detected. To overcome these problems, in this paper, we develop a novel keypoint confidence network and a tracking pipeline to improve human detection and pose estimation in top-down approaches. Specifically, the keypoint confidence network is designed to determine whether each keypoint is occluded, and it is incorporated into the pose estimation module. In the tracking pipeline, we propose the Bbox-revision module to reduce missing detection and the ID-retrieve module to correct lost trajectories, improving the performance of the detection stage. Experimental results show that our approach is universal in human detection and pose estimation, achieving state-of-the-art performance on both PoseTrack 2017 and 2018 datasets. ",
    "url": "https://arxiv.org/abs/2310.18920",
    "authors": [
      "Zehua Fu",
      "Wenhang Zuo",
      "Zhenghui Hu",
      "Qingjie Liu",
      "Yunhong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18921",
    "title": "QWID: Quantized Weed Identification Deep neural network",
    "abstract": "In this paper, we present an efficient solution for weed classification in agriculture. We focus on optimizing model performance at inference while respecting the constraints of the agricultural domain. We propose a Quantized Deep Neural Network model that classifies a dataset of 9 weed classes using 8-bit integer (int8) quantization, a departure from standard 32-bit floating point (fp32) models. Recognizing the hardware resource limitations in agriculture, our model balances model size, inference time, and accuracy, aligning with practical requirements. We evaluate the approach on ResNet-50 and InceptionV3 architectures, comparing their performance against their int8 quantized versions. Transfer learning and fine-tuning are applied using the DeepWeeds dataset. The results show staggering model size and inference time reductions while maintaining accuracy in real-world production scenarios like Desktop, Mobile and Raspberry Pi. Our work sheds light on a promising direction for efficient AI in agriculture, holding potential for broader applications. Code: https://github.com/parikshit14/QNN-for-weed ",
    "url": "https://arxiv.org/abs/2310.18921",
    "authors": [
      "Parikshit Singh Rathore"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.18924",
    "title": "Remaining Useful Life Prediction of Lithium-ion Batteries using  Spatio-temporal Multimodal Attention Networks",
    "abstract": "Lithium-ion batteries are widely used in various applications, including electric vehicles and renewable energy storage. The prediction of the remaining useful life (RUL) of batteries is crucial for ensuring reliable and efficient operation, as well as reducing maintenance costs. However, determining the life cycle of batteries in real-world scenarios is challenging, and existing methods have limitations in predicting the number of cycles iteratively. In addition, existing works often oversimplify the datasets, neglecting important features of the batteries such as temperature, internal resistance, and material type. To address these limitations, this paper proposes a two-stage remaining useful life prediction scheme for Lithium-ion batteries using a spatio-temporal multimodal attention network (ST-MAN). The proposed model is designed to iteratively predict the number of cycles required for the battery to reach the end of its useful life, based on available data. The proposed ST-MAN is to capture the complex spatio-temporal dependencies in the battery data, including the features that are often neglected in existing works. Experimental results demonstrate that the proposed ST-MAN model outperforms existing CNN and LSTM-based methods, achieving state-of-the-art performance in predicting the remaining useful life of Li-ion batteries. The proposed method has the potential to improve the reliability and efficiency of battery operations and is applicable in various industries, including automotive and renewable energy. ",
    "url": "https://arxiv.org/abs/2310.18924",
    "authors": [
      "Sungho Suh",
      "Dhruv Aditya Mittal",
      "Hymalai Bello",
      "Bo Zhou",
      "Mayank Shekhar Jha",
      "Paul Lukowicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18926",
    "title": "CHAIN: Exploring Global-Local Spatio-Temporal Information for Improved  Self-Supervised Video Hashing",
    "abstract": "Compressing videos into binary codes can improve retrieval speed and reduce storage overhead. However, learning accurate hash codes for video retrieval can be challenging due to high local redundancy and complex global dependencies between video frames, especially in the absence of labels. Existing self-supervised video hashing methods have been effective in designing expressive temporal encoders, but have not fully utilized the temporal dynamics and spatial appearance of videos due to less challenging and unreliable learning tasks. To address these challenges, we begin by utilizing the contrastive learning task to capture global spatio-temporal information of videos for hashing. With the aid of our designed augmentation strategies, which focus on spatial and temporal variations to create positive pairs, the learning framework can generate hash codes that are invariant to motion, scale, and viewpoint. Furthermore, we incorporate two collaborative learning tasks, i.e., frame order verification and scene change regularization, to capture local spatio-temporal details within video frames, thereby enhancing the perception of temporal structure and the modeling of spatio-temporal relationships. Our proposed Contrastive Hashing with Global-Local Spatio-temporal Information (CHAIN) outperforms state-of-the-art self-supervised video hashing methods on four video benchmark datasets. Our codes will be released. ",
    "url": "https://arxiv.org/abs/2310.18926",
    "authors": [
      "Rukai Wei",
      "Yu Liu",
      "Jingkuan Song",
      "Heng Cui",
      "Yanzhao Xie",
      "Ke Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.18928",
    "title": "A transfer learning approach with convolutional neural network for Face  Mask Detection",
    "abstract": "Due to the epidemic of the coronavirus (Covid-19) and its rapid spread around the world, the world has faced an enormous crisis. To prevent the spread of the coronavirus, the World Health Organization (WHO) has introduced the use of masks and keeping social distance as the best preventive method. So, developing an automatic monitoring system for detecting facemasks in some crowded places is essential. To do this, we propose a mask recognition system based on transfer learning and Inception v3 architecture. In the proposed method, two datasets are used simultaneously for training including the Simulated Mask Face Dataset (SMFD) and MaskedFace-Net (MFN) This paper tries to increase the accuracy of the proposed system by optimally setting hyper-parameters and accurately designing the fully connected layers. The main advantage of the proposed method is that in addition to masked and unmasked faces, it can also detect cases of incorrect use of mask. Therefore, the proposed method classifies the input face images into three categories. Experimental results show the high accuracy and efficiency of the proposed method; so, this method has achieved an accuracy of 99.47% and 99.33% in training and test data respectively ",
    "url": "https://arxiv.org/abs/2310.18928",
    "authors": [
      "Abolfazl Younesi",
      "Reza Afrouzian",
      "Yousef Seyfari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18933",
    "title": "Label Poisoning is All You Need",
    "abstract": "In a backdoor attack, an adversary injects corrupted data into a model's training dataset in order to gain control over its predictions on images with a specific attacker-defined trigger. A typical corrupted training example requires altering both the image, by applying the trigger, and the label. Models trained on clean images, therefore, were considered safe from backdoor attacks. However, in some common machine learning scenarios, the training labels are provided by potentially malicious third-parties. This includes crowd-sourced annotation and knowledge distillation. We, hence, investigate a fundamental question: can we launch a successful backdoor attack by only corrupting labels? We introduce a novel approach to design label-only backdoor attacks, which we call FLIP, and demonstrate its strengths on three datasets (CIFAR-10, CIFAR-100, and Tiny-ImageNet) and four architectures (ResNet-32, ResNet-18, VGG-19, and Vision Transformer). With only 2% of CIFAR-10 labels corrupted, FLIP achieves a near-perfect attack success rate of 99.4% while suffering only a 1.8% drop in the clean test accuracy. Our approach builds upon the recent advances in trajectory matching, originally introduced for dataset distillation. ",
    "url": "https://arxiv.org/abs/2310.18933",
    "authors": [
      "Rishi D. Jha",
      "Jonathan Hayase",
      "Sewoong Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18935",
    "title": "Implicit Bias of Gradient Descent for Two-layer ReLU and Leaky ReLU  Networks on Nearly-orthogonal Data",
    "abstract": "The implicit bias towards solutions with favorable properties is believed to be a key reason why neural networks trained by gradient-based optimization can generalize well. While the implicit bias of gradient flow has been widely studied for homogeneous neural networks (including ReLU and leaky ReLU networks), the implicit bias of gradient descent is currently only understood for smooth neural networks. Therefore, implicit bias in non-smooth neural networks trained by gradient descent remains an open question. In this paper, we aim to answer this question by studying the implicit bias of gradient descent for training two-layer fully connected (leaky) ReLU neural networks. We showed that when the training data are nearly-orthogonal, for leaky ReLU activation function, gradient descent will find a network with a stable rank that converges to $1$, whereas for ReLU activation function, gradient descent will find a neural network with a stable rank that is upper bounded by a constant. Additionally, we show that gradient descent will find a neural network such that all the training data points have the same normalized margin asymptotically. Experiments on both synthetic and real data backup our theoretical findings. ",
    "url": "https://arxiv.org/abs/2310.18935",
    "authors": [
      "Yiwen Kou",
      "Zixiang Chen",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.18936",
    "title": "Adversarial Examples Are Not Real Features",
    "abstract": "The existence of adversarial examples has been a mystery for years and attracted much interest. A well-known theory by \\citet{ilyas2019adversarial} explains adversarial vulnerability from a data perspective by showing that one can extract non-robust features from adversarial examples and these features alone are useful for classification. However, the explanation remains quite counter-intuitive since non-robust features are mostly noise features to humans. In this paper, we re-examine the theory from a larger context by incorporating multiple learning paradigms. Notably, we find that contrary to their good usefulness under supervised learning, non-robust features attain poor usefulness when transferred to other self-supervised learning paradigms, such as contrastive learning, masked image modeling, and diffusion models. It reveals that non-robust features are not really as useful as robust or natural features that enjoy good transferability between these paradigms. Meanwhile, for robustness, we also show that naturally trained encoders from robust features are largely non-robust under AutoAttack. Our cross-paradigm examination suggests that the non-robust features are not really useful but more like paradigm-wise shortcuts, and robust features alone might be insufficient to attain reliable model robustness. Code is available at \\url{https://github.com/PKU-ML/AdvNotRealFeatures}. ",
    "url": "https://arxiv.org/abs/2310.18936",
    "authors": [
      "Ang Li",
      "Yifei Wang",
      "Yiwen Guo",
      "Yisen Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18944",
    "title": "S2F-NER: Exploring Sequence-to-Forest Generation for Complex Entity  Recognition",
    "abstract": "Named Entity Recognition (NER) remains challenging due to the complex entities, like nested, overlapping, and discontinuous entities. Existing approaches, such as sequence-to-sequence (Seq2Seq) generation and span-based classification, have shown impressive performance on various NER subtasks, but they are difficult to scale to datasets with longer input text because of either exposure bias issue or inefficient computation. In this paper, we propose a novel Sequence-to-Forest generation paradigm, S2F-NER, which can directly extract entities in sentence via a Forest decoder that decode multiple entities in parallel rather than sequentially. Specifically, our model generate each path of each tree in forest autoregressively, where the maximum depth of each tree is three (which is the shortest feasible length for complex NER and is far smaller than the decoding length of Seq2Seq). Based on this novel paradigm, our model can elegantly mitigates the exposure bias problem and keep the simplicity of Seq2Seq. Experimental results show that our model significantly outperforms the baselines on three discontinuous NER datasets and on two nested NER datasets, especially for discontinuous entity recognition. ",
    "url": "https://arxiv.org/abs/2310.18944",
    "authors": [
      "Yongxiu Xu",
      "Heyan Huang",
      "Yue Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.18951",
    "title": "A Multimodal Ecological Civilization Pattern Recommendation Method Based  on Large Language Models and Knowledge Graph",
    "abstract": "The Ecological Civilization Pattern Recommendation System (ECPRS) aims to recommend suitable ecological civilization patterns for target regions, promoting sustainable development and reducing regional disparities. However, the current representative recommendation methods are not suitable for recommending ecological civilization patterns in a geographical context. There are two reasons for this. Firstly, regions have spatial heterogeneity, and the (ECPRS)needs to consider factors like climate, topography, vegetation, etc., to recommend civilization patterns adapted to specific ecological environments, ensuring the feasibility and practicality of the recommendations. Secondly, the abstract features of the ecological civilization patterns in the real world have not been fully utilized., resulting in poor richness in their embedding representations and consequently, lower performance of the recommendation system. Considering these limitations, we propose the ECPR-MML method. Initially, based on the novel method UGPIG, we construct a knowledge graph to extract regional representations incorporating spatial heterogeneity features. Following that, inspired by the significant progress made by Large Language Models (LLMs) in the field of Natural Language Processing (NLP), we employ Large LLMs to generate multimodal features for ecological civilization patterns in the form of text and images. We extract and integrate these multimodal features to obtain semantically rich representations of ecological civilization. Through extensive experiments, we validate the performance of our ECPR-MML model. Our results show that F1@5 is 2.11% higher compared to state-of-the-art models, 2.02% higher than NGCF, and 1.16% higher than UGPIG. Furthermore, multimodal data can indeed enhance recommendation performance. However, the data generated by LLM is not as effective as real data to a certain extent. ",
    "url": "https://arxiv.org/abs/2310.18951",
    "authors": [
      "Zhihang Yu",
      "Shu Wang",
      "Yunqiang Zhu",
      "Zhiqiang Zou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.18955",
    "title": "Playing in the Dark: No-regret Learning with Adversarial Constraints",
    "abstract": "We study a generalization of the classic Online Convex Optimization (OCO) framework by considering additional long-term adversarial constraints. Specifically, after an online policy decides its action on a round, in addition to a convex cost function, the adversary also reveals a set of $k$ convex constraints. The cost and the constraint functions could change arbitrarily with time, and no information about the future functions is assumed to be available. In this paper, we propose a meta-policy that simultaneously achieves a sublinear cumulative constraint violation and a sublinear regret. This is achieved via a black box reduction of the constrained problem to the standard OCO problem for a recursively constructed sequence of surrogate cost functions. We show that optimal performance bounds can be achieved by solving the surrogate problem using any adaptive OCO policy enjoying a standard data-dependent regret bound. A new Lyapunov-based proof technique is presented that reveals a connection between regret and certain sequential inequalities through a novel decomposition result. We conclude the paper by highlighting applications to online multi-task learning and network control problems. ",
    "url": "https://arxiv.org/abs/2310.18955",
    "authors": [
      "Abhishek Sinha",
      "Rahul Vaze"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2310.18961",
    "title": "AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly  Detection",
    "abstract": "Zero-shot anomaly detection (ZSAD) requires detection models trained using auxiliary data to detect anomalies without any training sample in a target dataset. It is a crucial task when training data is not accessible due to various concerns, \\eg, data privacy, yet it is challenging since the models need to generalize to anomalies across different domains where the appearance of foreground objects, abnormal regions, and background features, such as defects/tumors on different products/organs, can vary significantly. Recently large pre-trained vision-language models (VLMs), such as CLIP, have demonstrated strong zero-shot recognition ability in various vision tasks, including anomaly detection. However, their ZSAD performance is weak since the VLMs focus more on modeling the class semantics of the foreground objects rather than the abnormality/normality in the images. In this paper we introduce a novel approach, namely AnomalyCLIP, to adapt CLIP for accurate ZSAD across different domains. The key insight of AnomalyCLIP is to learn object-agnostic text prompts that capture generic normality and abnormality in an image regardless of its foreground objects. This allows our model to focus on the abnormal image regions rather than the object semantics, enabling generalized normality and abnormality recognition on diverse types of objects. Large-scale experiments on 17 real-world anomaly detection datasets show that AnomalyCLIP achieves superior zero-shot performance of detecting and segmenting anomalies in datasets of highly diverse class semantics from various defect inspection and medical imaging domains. Code will be made available at https://github.com/zqhang/AnomalyCLIP. ",
    "url": "https://arxiv.org/abs/2310.18961",
    "authors": [
      "Qihang Zhou",
      "Guansong Pang",
      "Yu Tian",
      "Shibo He",
      "Jiming Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18964",
    "title": "LLMs and Finetuning: Benchmarking cross-domain performance for hate  speech detection",
    "abstract": "This paper compares different pre-trained and fine-tuned large language models (LLMs) for hate speech detection. Our research underscores challenges in LLMs' cross-domain validity and overfitting risks. Through evaluations, we highlight the need for fine-tuned models that grasp the nuances of hate speech through greater label heterogeneity. We conclude with a vision for the future of hate speech detection, emphasizing cross-domain generalizability and appropriate benchmarking practices. ",
    "url": "https://arxiv.org/abs/2310.18964",
    "authors": [
      "Ahmad Nasir",
      "Aadish Sharma",
      "Kokil Jaidka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.18969",
    "title": "Analyzing Vision Transformers for Image Classification in Class  Embedding Space",
    "abstract": "Despite the growing use of transformer models in computer vision, a mechanistic understanding of these networks is still needed. This work introduces a method to reverse-engineer Vision Transformers trained to solve image classification tasks. Inspired by previous research in NLP, we demonstrate how the inner representations at any level of the hierarchy can be projected onto the learned class embedding space to uncover how these networks build categorical representations for their predictions. We use our framework to show how image tokens develop class-specific representations that depend on attention mechanisms and contextual information, and give insights on how self-attention and MLP layers differentially contribute to this categorical composition. We additionally demonstrate that this method (1) can be used to determine the parts of an image that would be important for detecting the class of interest, and (2) exhibits significant advantages over traditional linear probing approaches. Taken together, our results position our proposed framework as a powerful tool for mechanistic interpretability and explainability research. ",
    "url": "https://arxiv.org/abs/2310.18969",
    "authors": [
      "Martina G. Vilas",
      "Timothy Schauml\u00f6ffel",
      "Gemma Roig"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.18975",
    "title": "Blacksmith: Fast Adversarial Training of Vision Transformers via a  Mixture of Single-step and Multi-step Methods",
    "abstract": "Despite the remarkable success achieved by deep learning algorithms in various domains, such as computer vision, they remain vulnerable to adversarial perturbations. Adversarial Training (AT) stands out as one of the most effective solutions to address this issue; however, single-step AT can lead to Catastrophic Overfitting (CO). This scenario occurs when the adversarially trained network suddenly loses robustness against multi-step attacks like Projected Gradient Descent (PGD). Although several approaches have been proposed to address this problem in Convolutional Neural Networks (CNNs), we found out that they do not perform well when applied to Vision Transformers (ViTs). In this paper, we propose Blacksmith, a novel training strategy to overcome the CO problem, specifically in ViTs. Our approach utilizes either of PGD-2 or Fast Gradient Sign Method (FGSM) randomly in a mini-batch during the adversarial training of the neural network. This will increase the diversity of our training attacks, which could potentially mitigate the CO issue. To manage the increased training time resulting from this combination, we craft the PGD-2 attack based on only the first half of the layers, while FGSM is applied end-to-end. Through our experiments, we demonstrate that our novel method effectively prevents CO, achieves PGD-2 level performance, and outperforms other existing techniques including N-FGSM, which is the state-of-the-art method in fast training for CNNs. ",
    "url": "https://arxiv.org/abs/2310.18975",
    "authors": [
      "Mahdi Salmani",
      "Alireza Dehghanpour Farashah",
      "Mohammad Azizmalayeri",
      "Mahdi Amiri",
      "Navid Eslami",
      "Mohammad Taghi Manzuri",
      "Mohammad Hossein Rohban"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18983",
    "title": "DCQA: Document-Level Chart Question Answering towards Complex Reasoning  and Common-Sense Understanding",
    "abstract": "Visually-situated languages such as charts and plots are omnipresent in real-world documents. These graphical depictions are human-readable and are often analyzed in visually-rich documents to address a variety of questions that necessitate complex reasoning and common-sense responses. Despite the growing number of datasets that aim to answer questions over charts, most only address this task in isolation, without considering the broader context of document-level question answering. Moreover, such datasets lack adequate common-sense reasoning information in their questions. In this work, we introduce a novel task named document-level chart question answering (DCQA). The goal of this task is to conduct document-level question answering, extracting charts or plots in the document via document layout analysis (DLA) first and subsequently performing chart question answering (CQA). The newly developed benchmark dataset comprises 50,010 synthetic documents integrating charts in a wide range of styles (6 styles in contrast to 3 for PlotQA and ChartQA) and includes 699,051 questions that demand a high degree of reasoning ability and common-sense understanding. Besides, we present the development of a potent question-answer generation engine that employs table data, a rich color set, and basic question templates to produce a vast array of reasoning question-answer pairs automatically. Based on DCQA, we devise an OCR-free transformer for document-level chart-oriented understanding, capable of DLA and answering complex reasoning and common-sense questions over charts in an OCR-free manner. Our DCQA dataset is expected to foster research on understanding visualizations in documents, especially for scenarios that require complex reasoning for charts in the visually-rich document. We implement and evaluate a set of baselines, and our proposed method achieves comparable results. ",
    "url": "https://arxiv.org/abs/2310.18983",
    "authors": [
      "Anran Wu",
      "Luwei Xiao",
      "Xingjiao Wu",
      "Shuwen Yang",
      "Junjie Xu",
      "Zisong Zhuang",
      "Nian Xie",
      "Cheng Jin",
      "Liang He"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.18987",
    "title": "NP-SBFL: Bridging the Gap Between Spectrum-Based Fault Localization and  Faulty Neural Pathways Diagnosis",
    "abstract": "Deep learning has revolutionized various real-world applications, but the quality of Deep Neural Networks (DNNs) remains a concern. DNNs are complex and have millions of parameters, making it difficult to determine their contributions to fulfilling a task. Moreover, the behavior of a DNN is highly influenced by the data used during training, making it challenging to collect enough data to exercise all potential DNN behavior under all possible scenarios. This paper proposes a novel NP-SBFL method that adapts spectrum-based fault localization (SBFL) to locate faulty neural pathways. Our method identifies critical neurons using the layer-wise relevance propagation (LRP) technique and determines which critical neurons are faulty. We propose a multi-stage gradient ascent (MGA), an extension of gradient ascent, to effectively activate a sequence of neurons one at a time while maintaining the activation of previous neurons. We evaluated the effectiveness of our method on two commonly used datasets, MNIST and CIFAR-10, two baselines DeepFault and NP-SBFL-GA, and three suspicious neuron measures, Tarantula, Ochiai, and Barinel. The empirical results showed that NP-SBFL-MGA is statistically more effective than the baselines at identifying suspicious paths and synthesizing adversarial inputs. Particularly, Tarantula on NP-SBFL-MGA had the highest fault detection rate at 96.75%, surpassing DeepFault on Ochiai (89.90%) and NP-SBFL-GA on Ochiai (60.61%). Our approach also yielded comparable results to the baselines in synthesizing naturalness inputs, and we found a positive correlation between the coverage of critical paths and the number of failed tests in DNN fault localization. ",
    "url": "https://arxiv.org/abs/2310.18987",
    "authors": [
      "Soroush Hashemifar",
      "Saeed Parsa",
      "Akram Kalaee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.18992",
    "title": "Bipartite Graph Pre-training for Unsupervised Extractive Summarization  with Graph Convolutional Auto-Encoders",
    "abstract": "Pre-trained sentence representations are crucial for identifying significant sentences in unsupervised document extractive summarization. However, the traditional two-step paradigm of pre-training and sentence-ranking, creates a gap due to differing optimization objectives. To address this issue, we argue that utilizing pre-trained embeddings derived from a process specifically designed to optimize cohensive and distinctive sentence representations helps rank significant sentences. To do so, we propose a novel graph pre-training auto-encoder to obtain sentence embeddings by explicitly modelling intra-sentential distinctive features and inter-sentential cohesive features through sentence-word bipartite graphs. These pre-trained sentence representations are then utilized in a graph-based ranking algorithm for unsupervised summarization. Our method produces predominant performance for unsupervised summarization frameworks by providing summary-worthy sentence representations. It surpasses heavy BERT- or RoBERTa-based sentence representations in downstream tasks. ",
    "url": "https://arxiv.org/abs/2310.18992",
    "authors": [
      "Qianren Mao",
      "Shaobo Zhao",
      "Jiarui Li",
      "Xiaolei Gu",
      "Shizhu He",
      "Bo Li",
      "Jianxin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.18999",
    "title": "DynPoint: Dynamic Neural Point For View Synthesis",
    "abstract": "The introduction of neural radiance fields has greatly improved the effectiveness of view synthesis for monocular videos. However, existing algorithms face difficulties when dealing with uncontrolled or lengthy scenarios, and require extensive training time specific to each new scenario. To tackle these limitations, we propose DynPoint, an algorithm designed to facilitate the rapid synthesis of novel views for unconstrained monocular videos. Rather than encoding the entirety of the scenario information into a latent representation, DynPoint concentrates on predicting the explicit 3D correspondence between neighboring frames to realize information aggregation. Specifically, this correspondence prediction is achieved through the estimation of consistent depth and scene flow information across frames. Subsequently, the acquired correspondence is utilized to aggregate information from multiple reference frames to a target frame, by constructing hierarchical neural point clouds. The resulting framework enables swift and accurate view synthesis for desired views of target frames. The experimental results obtained demonstrate the considerable acceleration of training time achieved - typically an order of magnitude - by our proposed method while yielding comparable outcomes compared to prior approaches. Furthermore, our method exhibits strong robustness in handling long-duration videos without learning a canonical representation of video content. ",
    "url": "https://arxiv.org/abs/2310.18999",
    "authors": [
      "Kaichen Zhou",
      "Jia-Xing Zhong",
      "Sangyun Shin",
      "Kai Lu",
      "Yiyuan Yang",
      "Andrew Markham",
      "Niki Trigoni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19025",
    "title": "An Improved Relaxation for Oracle-Efficient Adversarial Contextual  Bandits",
    "abstract": "We present an oracle-efficient relaxation for the adversarial contextual bandits problem, where the contexts are sequentially drawn i.i.d from a known distribution and the cost sequence is chosen by an online adversary. Our algorithm has a regret bound of $O(T^{\\frac{2}{3}}(K\\log(|\\Pi|))^{\\frac{1}{3}})$ and makes at most $O(K)$ calls per round to an offline optimization oracle, where $K$ denotes the number of actions, $T$ denotes the number of rounds and $\\Pi$ denotes the set of policies. This is the first result to improve the prior best bound of $O((TK)^{\\frac{2}{3}}(\\log(|\\Pi|))^{\\frac{1}{3}})$ as obtained by Syrgkanis et al. at NeurIPS 2016, and the first to match the original bound of Langford and Zhang at NeurIPS 2007 which was obtained for the stochastic case. ",
    "url": "https://arxiv.org/abs/2310.19025",
    "authors": [
      "Kiarash Banihashem",
      "MohammadTaghi Hajiaghayi",
      "Suho Shin",
      "Max Springer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.19034",
    "title": "ArBanking77: Intent Detection Neural Model and a New Dataset in Modern  and Dialectical Arabic",
    "abstract": "This paper presents the ArBanking77, a large Arabic dataset for intent detection in the banking domain. Our dataset was arabized and localized from the original English Banking77 dataset, which consists of 13,083 queries to ArBanking77 dataset with 31,404 queries in both Modern Standard Arabic (MSA) and Palestinian dialect, with each query classified into one of the 77 classes (intents). Furthermore, we present a neural model, based on AraBERT, fine-tuned on ArBanking77, which achieved an F1-score of 0.9209 and 0.8995 on MSA and Palestinian dialect, respectively. We performed extensive experimentation in which we simulated low-resource settings, where the model is trained on a subset of the data and augmented with noisy queries to simulate colloquial terms, mistakes and misspellings found in real NLP systems, especially live chat queries. The data and the models are publicly available at https://sina.birzeit.edu/arbanking77. ",
    "url": "https://arxiv.org/abs/2310.19034",
    "authors": [
      "Mustafa Jarrar",
      "Ahmet Birim",
      "Mohammed Khalilia",
      "Mustafa Erden",
      "Sana Ghanem"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.19035",
    "title": "Does Invariant Graph Learning via Environment Augmentation Learn  Invariance?",
    "abstract": "Invariant graph representation learning aims to learn the invariance among data from different environments for out-of-distribution generalization on graphs. As the graph environment partitions are usually expensive to obtain, augmenting the environment information has become the de facto approach. However, the usefulness of the augmented environment information has never been verified. In this work, we find that it is fundamentally impossible to learn invariant graph representations via environment augmentation without additional assumptions. Therefore, we develop a set of minimal assumptions, including variation sufficiency and variation consistency, for feasible invariant graph learning. We then propose a new framework Graph invAriant Learning Assistant (GALA). GALA incorporates an assistant model that needs to be sensitive to graph environment changes or distribution shifts. The correctness of the proxy predictions by the assistant model hence can differentiate the variations in spurious subgraphs. We show that extracting the maximally invariant subgraph to the proxy predictions provably identifies the underlying invariant subgraph for successful OOD generalization under the established minimal assumptions. Extensive experiments on datasets including DrugOOD with various graph distribution shifts confirm the effectiveness of GALA. ",
    "url": "https://arxiv.org/abs/2310.19035",
    "authors": [
      "Yongqiang Chen",
      "Yatao Bian",
      "Kaiwen Zhou",
      "Binghui Xie",
      "Bo Han",
      "James Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.19038",
    "title": "Boosting Decision-Based Black-Box Adversarial Attack with Gradient  Priors",
    "abstract": "Decision-based methods have shown to be effective in black-box adversarial attacks, as they can obtain satisfactory performance and only require to access the final model prediction. Gradient estimation is a critical step in black-box adversarial attacks, as it will directly affect the query efficiency. Recent works have attempted to utilize gradient priors to facilitate score-based methods to obtain better results. However, these gradient priors still suffer from the edge gradient discrepancy issue and the successive iteration gradient direction issue, thus are difficult to simply extend to decision-based methods. In this paper, we propose a novel Decision-based Black-box Attack framework with Gradient Priors (DBA-GP), which seamlessly integrates the data-dependent gradient prior and time-dependent prior into the gradient estimation procedure. First, by leveraging the joint bilateral filter to deal with each random perturbation, DBA-GP can guarantee that the generated perturbations in edge locations are hardly smoothed, i.e., alleviating the edge gradient discrepancy, thus remaining the characteristics of the original image as much as possible. Second, by utilizing a new gradient updating strategy to automatically adjust the successive iteration gradient direction, DBA-GP can accelerate the convergence speed, thus improving the query efficiency. Extensive experiments have demonstrated that the proposed method outperforms other strong baselines significantly. ",
    "url": "https://arxiv.org/abs/2310.19038",
    "authors": [
      "Han Liu",
      "Xingshuo Huang",
      "Xiaotong Zhang",
      "Qimai Li",
      "Fenglong Ma",
      "Wei Wang",
      "Hongyang Chen",
      "Hong Yu",
      "Xianchao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19046",
    "title": "Large Language Models as Evolutionary Optimizers",
    "abstract": "Evolutionary algorithms (EAs) have achieved remarkable success in tackling complex combinatorial optimization problems. However, EAs often demand carefully-designed operators with the aid of domain expertise to achieve satisfactory performance. In this work, we present the first study on large language models (LLMs) as evolutionary combinatorial optimizers. The main advantage is that it requires minimal domain knowledge and human efforts, as well as no additional training of the model. This approach is referred to as LLM-driven EA (LMEA). Specifically, in each generation of the evolutionary search, LMEA instructs the LLM to select parent solutions from current population, and perform crossover and mutation to generate offspring solutions. Then, LMEA evaluates these new solutions and include them into the population for the next generation. LMEA is equipped with a self-adaptation mechanism that controls the temperature of the LLM. This enables it to balance between exploration and exploitation and prevents the search from getting stuck in local optima. We investigate the power of LMEA on the classical traveling salesman problems (TSPs) widely used in combinatorial optimization research. Notably, the results show that LMEA performs competitively to traditional heuristics in finding high-quality solutions on TSP instances with up to 20 nodes. Additionally, we also study the effectiveness of LLM-driven crossover/mutation and the self-adaptation mechanism in evolutionary search. In summary, our results reveal the great potentials of LLMs as evolutionary optimizers for solving combinatorial problems. We hope our research shall inspire future explorations on LLM-driven EAs for complex optimization challenges. ",
    "url": "https://arxiv.org/abs/2310.19046",
    "authors": [
      "Shengcai Liu",
      "Caishun Chen",
      "Xinghua Qu",
      "Ke Tang",
      "Yew-Soon Ong"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.19054",
    "title": "Object-centric architectures enable efficient causal representation  learning",
    "abstract": "Causal representation learning has showed a variety of settings in which we can disentangle latent variables with identifiability guarantees (up to some reasonable equivalence class). Common to all of these approaches is the assumption that (1) the latent variables are represented as $d$-dimensional vectors, and (2) that the observations are the output of some injective generative function of these latent variables. While these assumptions appear benign, we show that when the observations are of multiple objects, the generative function is no longer injective and disentanglement fails in practice. We can address this failure by combining recent developments in object-centric learning and causal representation learning. By modifying the Slot Attention architecture arXiv:2006.15055, we develop an object-centric architecture that leverages weak supervision from sparse perturbations to disentangle each object's properties. This approach is more data-efficient in the sense that it requires significantly fewer perturbations than a comparable approach that encodes to a Euclidean space and we show that this approach successfully disentangles the properties of a set of objects in a series of simple image-based disentanglement experiments. ",
    "url": "https://arxiv.org/abs/2310.19054",
    "authors": [
      "Amin Mansouri",
      "Jason Hartford",
      "Yan Zhang",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19057",
    "title": "A Unique Training Strategy to Enhance Language Models Capabilities for  Health Mention Detection from Social Media Content",
    "abstract": "An ever-increasing amount of social media content requires advanced AI-based computer programs capable of extracting useful information. Specifically, the extraction of health-related content from social media is useful for the development of diverse types of applications including disease spread, mortality rate prediction, and finding the impact of diverse types of drugs on diverse types of diseases. Language models are competent in extracting the syntactic and semantics of text. However, they face a hard time extracting similar patterns from social media texts. The primary reason for this shortfall lies in the non-standardized writing style commonly employed by social media users. Following the need for an optimal language model competent in extracting useful patterns from social media text, the key goal of this paper is to train language models in such a way that they learn to derive generalized patterns. The key goal is achieved through the incorporation of random weighted perturbation and contrastive learning strategies. On top of a unique training strategy, a meta predictor is proposed that reaps the benefits of 5 different language models for discriminating posts of social media text into non-health and health-related classes. Comprehensive experimentation across 3 public benchmark datasets reveals that the proposed training strategy improves the performance of the language models up to 3.87%, in terms of F1-score, as compared to their performance with traditional training. Furthermore, the proposed meta predictor outperforms existing health mention classification predictors across all 3 benchmark datasets. ",
    "url": "https://arxiv.org/abs/2310.19057",
    "authors": [
      "Pervaiz Iqbal Khan",
      "Muhammad Nabeel Asim",
      "Andreas Dengel",
      "Sheraz Ahmed"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.19059",
    "title": "Escaping Saddle Points in Heterogeneous Federated Learning via  Distributed SGD with Communication Compression",
    "abstract": "We consider the problem of finding second-order stationary points of heterogeneous federated learning (FL). Previous works in FL mostly focus on first-order convergence guarantees, which do not rule out the scenario of unstable saddle points. Meanwhile, it is a key bottleneck of FL to achieve communication efficiency without compensating the learning accuracy, especially when local data are highly heterogeneous across different clients. Given this, we propose a novel algorithm Power-EF that only communicates compressed information via a novel error-feedback scheme. To our knowledge, Power-EF is the first distributed and compressed SGD algorithm that provably escapes saddle points in heterogeneous FL without any data homogeneity assumptions. In particular, Power-EF improves to second-order stationary points after visiting first-order (possibly saddle) points, using additional gradient queries and communication rounds only of almost the same order required by first-order convergence, and the convergence rate exhibits a linear speedup in terms of the number of workers. Our theory improves/recovers previous results, while extending to much more tolerant settings on the local data. Numerical experiments are provided to complement the theory. ",
    "url": "https://arxiv.org/abs/2310.19059",
    "authors": [
      "Sijin Chen",
      "Zhize Li",
      "Yuejie Chi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2310.19063",
    "title": "Feature Aggregation in Joint Sound Classification and Localization  Neural Networks",
    "abstract": "This study addresses the application of deep learning techniques in joint sound signal classification and localization networks. Current state-of-the-art sound source localization deep learning networks lack feature aggregation within their architecture. Feature aggregation enhances model performance by enabling the consolidation of information from different feature scales, thereby improving feature robustness and invariance. This is particularly important in SSL networks, which must differentiate direct and indirect acoustic signals. To address this gap, we adapt feature aggregation techniques from computer vision neural networks to signal detection neural networks. Additionally, we propose the Scale Encoding Network (SEN) for feature aggregation to encode features from various scales, compressing the network for more computationally efficient aggregation. To evaluate the efficacy of feature aggregation in SSL networks, we integrated the following computer vision feature aggregation sub-architectures into a SSL control architecture: Path Aggregation Network (PANet), Weighted Bi-directional Feature Pyramid Network (BiFPN), and SEN. These sub-architectures were evaluated using two metrics for signal classification and two metrics for direction-of-arrival regression. PANet and BiFPN are established aggregators in computer vision models, while the proposed SEN is a more compact aggregator. The results suggest that models incorporating feature aggregations outperformed the control model, the Sound Event Localization and Detection network (SELDnet), in both sound signal classification and localization. The feature aggregation techniques enhance the performance of sound detection neural networks, particularly in direction-of-arrival regression. ",
    "url": "https://arxiv.org/abs/2310.19063",
    "authors": [
      "Brendan Healy",
      "Patrick McNamee",
      "Zahra Nili Ahmadabadi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.19067",
    "title": "Expanding memory in recurrent spiking networks",
    "abstract": "Recurrent spiking neural networks (RSNNs) are notoriously difficult to train because of the vanishing gradient problem that is enhanced by the binary nature of the spikes. In this paper, we review the ability of the current state-of-the-art RSNNs to solve long-term memory tasks, and show that they have strong constraints both in performance, and for their implementation on hardware analog neuromorphic processors. We present a novel spiking neural network that circumvents these limitations. Our biologically inspired neural network uses synaptic delays, branching factor regularization and a novel surrogate derivative for the spiking function. The proposed network proves to be more successful in using the recurrent connections on memory tasks. ",
    "url": "https://arxiv.org/abs/2310.19067",
    "authors": [
      "Ismael Balafrej",
      "Fabien Alibart",
      "Jean Rouat"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.19070",
    "title": "Myriad: Large Multimodal Model by Applying Vision Experts for Industrial  Anomaly Detection",
    "abstract": "Existing industrial anomaly detection (IAD) methods predict anomaly scores for both anomaly detection and localization. However, they struggle to perform a multi-turn dialog and detailed descriptions for anomaly regions, e.g., color, shape, and categories of industrial anomalies. Recently, large multimodal (i.e., vision and language) models (LMMs) have shown eminent perception abilities on multiple vision tasks such as image captioning, visual understanding, visual reasoning, etc., making it a competitive potential choice for more comprehensible anomaly detection. However, the knowledge about anomaly detection is absent in existing general LMMs, while training a specific LMM for anomaly detection requires a tremendous amount of annotated data and massive computation resources. In this paper, we propose a novel large multi-modal model by applying vision experts for industrial anomaly detection (dubbed Myriad), which leads to definite anomaly detection and high-quality anomaly description. Specifically, we adopt MiniGPT-4 as the base LMM and design an Expert Perception module to embed the prior knowledge from vision experts as tokens which are intelligible to Large Language Models (LLMs). To compensate for the errors and confusions of vision experts, we introduce a domain adapter to bridge the visual representation gaps between generic and industrial images. Furthermore, we propose a Vision Expert Instructor, which enables the Q-Former to generate IAD domain vision-language tokens according to vision expert prior. Extensive experiments on MVTec-AD and VisA benchmarks demonstrate that our proposed method not only performs favorably against state-of-the-art methods under the 1-class and few-shot settings, but also provide definite anomaly prediction along with detailed descriptions in IAD domain. ",
    "url": "https://arxiv.org/abs/2310.19070",
    "authors": [
      "Yuanze Li",
      "Haolin Wang",
      "Shihao Yuan",
      "Ming Liu",
      "Yiwen Guo",
      "Chen Xu",
      "Guangming Shi",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19077",
    "title": "Near-Optimal Packet Scheduling in Multihop Networks with End-to-End  Deadline Constraints",
    "abstract": "Scheduling packets with end-to-end deadline constraints in multihop networks is an important problem that has been notoriously difficult to tackle. Recently, there has been progress on this problem in the worst-case traffic setting, with the objective of maximizing the number of packets delivered within their deadlines. Specifically, the proposed algorithms were shown to achieve $\\Omega(1/\\log(L))$ fraction of the optimal objective value if the minimum link capacity in the network is $C_{\\min}=\\Omega(\\log (L))$, where $L$ is the maximum length of a packet's route in the network (which is bounded by the packet's maximum deadline). However, such guarantees can be quite pessimistic due to the strict worst-case traffic assumption and may not accurately reflect real-world settings. In this work, we aim to address this limitation by exploring whether it is possible to design algorithms that achieve a constant fraction of the optimal value while relaxing the worst-case traffic assumption. We provide a positive answer by demonstrating that in stochastic traffic settings, such as i.i.d. packet arrivals, near-optimal, $(1-\\epsilon)$-approximation algorithms can be designed if $C_{\\min} = \\Omega\\big(\\frac{\\log (L/\\epsilon) } {\\epsilon^2}\\big)$. To the best of our knowledge, this is the first result that shows this problem can be solved near-optimally under nontrivial assumptions on traffic and link capacity. We further present extended simulations using real network traces with non-stationary traffic, which demonstrate that our algorithms outperform worst-case-based algorithms in practical settings. ",
    "url": "https://arxiv.org/abs/2310.19077",
    "authors": [
      "Christos Tsanikidis",
      "Javad Ghaderi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2310.19079",
    "title": "Digital Twin-Driven Network Architecture for Video Streaming",
    "abstract": "Digital twin (DT) is revolutionizing the emerging video streaming services through tailored network management. By integrating diverse advanced communication technologies, DTs are promised to construct a holistic virtualized network for better network management performance. To this end, we develop a DT-driven network architecture for video streaming (DTN4VS) to enable network virtualization and tailored network management. With the architecture, various types of DTs can characterize physical entities' status, separate the network management functions from the network controller, and empower the functions with emulated data and tailored strategies. To further enhance network management performance, three potential approaches are proposed, i.e., domain data exploitation, performance evaluation, and adaptive DT model update. We present a case study pertaining to DT-assisted network slicing for short video streaming, followed by some open research issues for DTN4VS. ",
    "url": "https://arxiv.org/abs/2310.19079",
    "authors": [
      "Xinyu Huang",
      "Haojun Yang",
      "Shisheng Hu",
      "Xuemin Shen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.19103",
    "title": "Proving Linear Mode Connectivity of Neural Networks via Optimal  Transport",
    "abstract": "The energy landscape of high-dimensional non-convex optimization problems is crucial to understanding the effectiveness of modern deep neural network architectures. Recent works have experimentally shown that two different solutions found after two runs of a stochastic training are often connected by very simple continuous paths (e.g., linear) modulo a permutation of the weights. In this paper, we provide a framework theoretically explaining this empirical observation. Based on convergence rates in Wasserstein distance of empirical measures, we show that, with high probability, two wide enough two-layer neural networks trained with stochastic gradient descent are linearly connected. Additionally, we express upper and lower bounds on the width of each layer of two deep neural networks with independent neuron weights to be linearly connected. Finally, we empirically demonstrate the validity of our approach by showing how the dimension of the support of the weight distribution of neurons, which dictates Wasserstein convergence rates is correlated with linear mode connectivity. ",
    "url": "https://arxiv.org/abs/2310.19103",
    "authors": [
      "Damien Ferbach",
      "Baptiste Goujaud",
      "Gauthier Gidel",
      "Aymeric Dieuleveut"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19105",
    "title": "Updated Standard for Secure Satellite Communications: Analysis of  Satellites, Attack Vectors, Existing Standards, and Enterprise and Security  Architectures",
    "abstract": "Satellites play a vital role in remote communication where traditional communication mediums struggle to provide benefits over associated costs and efficiency. In recent years, satellite communication has achieved utter interest in the industry due to the achievement of high data rates through the massive deployment of LEO satellites. Because of the complex diversity in types of satellites, communication methodologies, technological obstacles, environmental limitations, elements in the entire ecosystem, massive financial impact, geopolitical conflict and domination, easier access to satellite communications, and various other reasons, the threat vectors are rising in the threat landscape. To achieve resilience against those, only technological solutions are not enough. An effective approach will be through security standards. However, there is a considerable gap in the industry regarding a generic security standard framework for satellite communication and space data systems. A few countries and space agencies have their own standard framework and private policies. However, many of those are either private, serve the specific requirements of specific missions, or have not been updated for a long time. This project report will focus on identifying, categorizing, comparing, and assessing elements, threat landscape, enterprise security architectures, and available public standards of satellite communication and space data systems. After that, it will utilize the knowledge to propose an updated standard framework for secure satellite communications and space data systems. ",
    "url": "https://arxiv.org/abs/2310.19105",
    "authors": [
      "Rupok Chowdhury Protik"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.19119",
    "title": "Out-of-distribution Object Detection through Bayesian Uncertainty  Estimation",
    "abstract": "The superior performance of object detectors is often established under the condition that the test samples are in the same distribution as the training data. However, in many practical applications, out-of-distribution (OOD) instances are inevitable and usually lead to uncertainty in the results. In this paper, we propose a novel, intuitive, and scalable probabilistic object detection method for OOD detection. Unlike other uncertainty-modeling methods that either require huge computational costs to infer the weight distributions or rely on model training through synthetic outlier data, our method is able to distinguish between in-distribution (ID) data and OOD data via weight parameter sampling from proposed Gaussian distributions based on pre-trained networks. We demonstrate that our Bayesian object detector can achieve satisfactory OOD identification performance by reducing the FPR95 score by up to 8.19% and increasing the AUROC score by up to 13.94% when trained on BDD100k and VOC datasets as the ID datasets and evaluated on COCO2017 dataset as the OOD dataset. ",
    "url": "https://arxiv.org/abs/2310.19119",
    "authors": [
      "Tianhao Zhang",
      "Shenglin Wang",
      "Nidhal Bouaynaya",
      "Radu Calinescu",
      "Lyudmila Mihaylova"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19127",
    "title": "Unified Representation for Non-compositional and Compositional  Expressions",
    "abstract": "Accurate processing of non-compositional language relies on generating good representations for such expressions. In this work, we study the representation of language non-compositionality by proposing a language model, PIER, that builds on BART and can create semantically meaningful and contextually appropriate representations for English potentially idiomatic expressions (PIEs). PIEs are characterized by their non-compositionality and contextual ambiguity in their literal and idiomatic interpretations. Via intrinsic evaluation on embedding quality and extrinsic evaluation on PIE processing and NLU tasks, we show that representations generated by PIER result in 33% higher homogeneity score for embedding clustering than BART, whereas 3.12% and 3.29% gains in accuracy and sequence accuracy for PIE sense classification and span detection compared to the state-of-the-art IE representation model, GIEA. These gains are achieved without sacrificing PIER's performance on NLU tasks (+/- 1% accuracy) compared to BART. ",
    "url": "https://arxiv.org/abs/2310.19127",
    "authors": [
      "Ziheng Zeng",
      "Suma Bhat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.19142",
    "title": "MAG-GNN: Reinforcement Learning Boosted Graph Neural Network",
    "abstract": "While Graph Neural Networks (GNNs) recently became powerful tools in graph learning tasks, considerable efforts have been spent on improving GNNs' structural encoding ability. A particular line of work proposed subgraph GNNs that use subgraph information to improve GNNs' expressivity and achieved great success. However, such effectivity sacrifices the efficiency of GNNs by enumerating all possible subgraphs. In this paper, we analyze the necessity of complete subgraph enumeration and show that a model can achieve a comparable level of expressivity by considering a small subset of the subgraphs. We then formulate the identification of the optimal subset as a combinatorial optimization problem and propose Magnetic Graph Neural Network (MAG-GNN), a reinforcement learning (RL) boosted GNN, to solve the problem. Starting with a candidate subgraph set, MAG-GNN employs an RL agent to iteratively update the subgraphs to locate the most expressive set for prediction. This reduces the exponential complexity of subgraph enumeration to the constant complexity of a subgraph search algorithm while keeping good expressivity. We conduct extensive experiments on many datasets, showing that MAG-GNN achieves competitive performance to state-of-the-art methods and even outperforms many subgraph GNNs. We also demonstrate that MAG-GNN effectively reduces the running time of subgraph GNNs. ",
    "url": "https://arxiv.org/abs/2310.19142",
    "authors": [
      "Lecheng Kong",
      "Jiarui Feng",
      "Hao Liu",
      "Dacheng Tao",
      "Yixin Chen",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19152",
    "title": "BERT Lost Patience Won't Be Robust to Adversarial Slowdown",
    "abstract": "In this paper, we systematically evaluate the robustness of multi-exit language models against adversarial slowdown. To audit their robustness, we design a slowdown attack that generates natural adversarial text bypassing early-exit points. We use the resulting WAFFLE attack as a vehicle to conduct a comprehensive evaluation of three multi-exit mechanisms with the GLUE benchmark against adversarial slowdown. We then show our attack significantly reduces the computational savings provided by the three methods in both white-box and black-box settings. The more complex a mechanism is, the more vulnerable it is to adversarial slowdown. We also perform a linguistic analysis of the perturbed text inputs, identifying common perturbation patterns that our attack generates, and comparing them with standard adversarial text attacks. Moreover, we show that adversarial training is ineffective in defeating our slowdown attack, but input sanitization with a conversational model, e.g., ChatGPT, can remove perturbations effectively. This result suggests that future work is needed for developing efficient yet robust multi-exit models. Our code is available at: https://github.com/ztcoalson/WAFFLE ",
    "url": "https://arxiv.org/abs/2310.19152",
    "authors": [
      "Zachary Coalson",
      "Gabriel Ritter",
      "Rakesh Bobba",
      "Sanghyun Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.19156",
    "title": "Poisoning Retrieval Corpora by Injecting Adversarial Passages",
    "abstract": "Dense retrievers have achieved state-of-the-art performance in various information retrieval tasks, but to what extent can they be safely deployed in real-world applications? In this work, we propose a novel attack for dense retrieval systems in which a malicious user generates a small number of adversarial passages by perturbing discrete tokens to maximize similarity with a provided set of training queries. When these adversarial passages are inserted into a large retrieval corpus, we show that this attack is highly effective in fooling these systems to retrieve them for queries that were not seen by the attacker. More surprisingly, these adversarial passages can directly generalize to out-of-domain queries and corpora with a high success attack rate -- for instance, we find that 50 generated passages optimized on Natural Questions can mislead >94% of questions posed in financial documents or online forums. We also benchmark and compare a range of state-of-the-art dense retrievers, both unsupervised and supervised. Although different systems exhibit varying levels of vulnerability, we show they can all be successfully attacked by injecting up to 500 passages, a small fraction compared to a retrieval corpus of millions of passages. ",
    "url": "https://arxiv.org/abs/2310.19156",
    "authors": [
      "Zexuan Zhong",
      "Ziqing Huang",
      "Alexander Wettig",
      "Danqi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.19163",
    "title": "RAIFLE: Reconstruction Attacks on Interaction-based Federated Learning  with Active Data Manipulation",
    "abstract": "Federated learning (FL) has recently emerged as a privacy-preserving approach for machine learning in domains that rely on user interactions, particularly recommender systems (RS) and online learning to rank (OLTR). While there has been substantial research on the privacy of traditional FL, little attention has been paid to studying the privacy properties of these interaction-based FL (IFL) systems. In this work, we show that IFL can introduce unique challenges concerning user privacy, particularly when the central server has knowledge and control over the items that users interact with. Specifically, we demonstrate the threat of reconstructing user interactions by presenting RAIFLE, a general optimization-based reconstruction attack framework customized for IFL. RAIFLE employs Active Data Manipulation (ADM), a novel attack technique unique to IFL, where the server actively manipulates the training features of the items to induce adversarial behaviors in the local FL updates. We show that RAIFLE is more impactful than existing FL privacy attacks in the IFL context, and describe how it can undermine privacy defenses like secure aggregation and private information retrieval. Based on our findings, we propose and discuss countermeasure guidelines to mitigate our attack in the context of federated RS/OLTR specifically and IFL more broadly. ",
    "url": "https://arxiv.org/abs/2310.19163",
    "authors": [
      "Dzung Pham",
      "Shreyas Kulkarni",
      "Amir Houmansadr"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19170",
    "title": "A technique to avoid Blockchain Denial of Service (BDoS) and Selfish  Mining Attack",
    "abstract": "Blockchain denial of service (BDoS) and selfish mining are the two most crucial attacks on blockchain technology. A classical DoS attack targets the computer network to limit, restrict, or stop accessing the system of authorized users which is ineffective against renowned cryptocurrencies like Bitcoin, Ethereum, etc. Unlike the conventional DoS, the BDoS affects the system's mechanism design to manipulate the incentive structure to discourage honest miners to participate in the mining process. In contrast, in a selfish mining attack, the adversary miner keeps its discovered block private to fork the chain intentionally that aiming to increase the incentive of the adversary miner. This paper proposed a technique to successfully avoid BDoS and selfish mining attacks. The existing infrastructure of blockchain technology doesn't need to be changed a lot to incorporate the proposed solution. ",
    "url": "https://arxiv.org/abs/2310.19170",
    "authors": [
      "Md. Ahsan Habib",
      "Md. Motaleb Hossen Manik"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.19173",
    "title": "Can we Quantify Trust? Towards a Trust-based Resilient SIoT Network",
    "abstract": "The emerging yet promising paradigm of the Social Internet of Things (SIoT) integrates the notion of the Internet of Things with human social networks. In SIoT, objects, i.e., things, have the capability to socialize with the other objects in the SIoT network and can establish their social network autonomously by modeling human behaviour. The notion of trust is imperative in realizing these characteristics of socialization in order to assess the reliability of autonomous collaboration. The perception of trust is evolving in the era of SIoT as an extension to traditional security triads in an attempt to offer secure and reliable services, and is considered as an imperative aspect of any SIoT system for minimizing the probable risk of autonomous decision-making. This research investigates the idea of trust quantification by employing trust measurement in terms of direct trust, indirect trust as a recommendation, and the degree of SIoT relationships in terms of social similarities (community-of-interest, friendship, and co-work relationships). A weighted sum approach is subsequently employed to synthesize all the trust features in order to ascertain a single trust score. The experimental evaluation demonstrates the effectiveness of the proposed model in segregating trustworthy and untrustworthy objects and via identifying the dynamic behaviour (i.e., trust-related attacks) of the SIoT objects. ",
    "url": "https://arxiv.org/abs/2310.19173",
    "authors": [
      "Subhash Sagar",
      "Adnan Mahmood",
      "Quan Z. Sheng",
      "Munazza Zaib",
      "Farhan Sufyan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.19182",
    "title": "Fast Trainable Projection for Robust Fine-Tuning",
    "abstract": "Robust fine-tuning aims to achieve competitive in-distribution (ID) performance while maintaining the out-of-distribution (OOD) robustness of a pre-trained model when transferring it to a downstream task. Recently, projected gradient descent has been successfully used in robust fine-tuning by constraining the deviation from the initialization of the fine-tuned model explicitly through projection. However, algorithmically, two limitations prevent this method from being adopted more widely, scalability and efficiency. In this paper, we propose a new projection-based fine-tuning algorithm, Fast Trainable Projection (FTP) for computationally efficient learning of per-layer projection constraints, resulting in an average $35\\%$ speedup on our benchmarks compared to prior works. FTP can be combined with existing optimizers such as AdamW, and be used in a plug-and-play fashion. Finally, we show that FTP is a special instance of hyper-optimizers that tune the hyper-parameters of optimizers in a learnable manner through nested differentiation. Empirically, we show superior robustness on OOD datasets, including domain shifts and natural corruptions, across four different vision tasks with five different pre-trained models. Additionally, we demonstrate that FTP is broadly applicable and beneficial to other learning scenarios such as low-label and continual learning settings thanks to its easy adaptability. The code will be available at https://github.com/GT-RIPL/FTP.git. ",
    "url": "https://arxiv.org/abs/2310.19182",
    "authors": [
      "Junjiao Tian",
      "Yen-Cheng Liu",
      "James Seale Smith",
      "Zsolt Kira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19193",
    "title": "A Survey on Watching Social Issue Videos among YouTube and TikTok Users",
    "abstract": "The openness and influence of video-sharing platforms (VSPs) such as YouTube and TikTok attracted creators to share videos on various social issues. Although social issue videos (SIVs) affect public opinions and breed misinformation, how VSP users obtain information and interact with SIVs is under-explored. This work surveyed 659 YouTube and 127 TikTok users to understand the motives for consuming SIVs on VSPs. We found that VSP users are primarily motivated by the information and entertainment gratifications to use the platform. VSP users use SIVs for information-seeking purposes and find YouTube and TikTok convenient to interact with SIVs. VSP users moderately watch SIVs for entertainment and inactively engage in social interactions. SIV consumption is associated with information and socialization gratifications of the platform. VSP users appreciate the diversity of information and opinions but would also do their own research and are concerned about the misinformation and echo chamber problems. ",
    "url": "https://arxiv.org/abs/2310.19193",
    "authors": [
      "Shuo Niu",
      "Dilasha Shrestha",
      "Abhisan Ghimire",
      "Zhicong Lu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.19211",
    "title": "Investigative Pattern Detection Framework for Counterterrorism",
    "abstract": "Law-enforcement investigations aimed at preventing attacks by violent extremists have become increasingly important for public safety. The problem is exacerbated by the massive data volumes that need to be scanned to identify complex behaviors of extremists and groups. Automated tools are required to extract information to respond queries from analysts, continually scan new information, integrate them with past events, and then alert about emerging threats. We address challenges in investigative pattern detection and develop an Investigative Pattern Detection Framework for Counterterrorism (INSPECT). The framework integrates numerous computing tools that include machine learning techniques to identify behavioral indicators and graph pattern matching techniques to detect risk profiles/groups. INSPECT also automates multiple tasks for large-scale mining of detailed forensic biographies, forming knowledge networks, and querying for behavioral indicators and radicalization trajectories. INSPECT targets human-in-the-loop mode of investigative search and has been validated and evaluated using an evolving dataset on domestic jihadism. ",
    "url": "https://arxiv.org/abs/2310.19211",
    "authors": [
      "Shashika R. Muramudalige",
      "Benjamin W. K. Hung",
      "Rosanne Libretti",
      "Jytte Klausen",
      "Anura P. Jayasumana"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19216",
    "title": "Optimal Status Updates for Minimizing Age of Correlated Information in  IoT Networks with Energy Harvesting Sensors",
    "abstract": "Many real-time applications of the Internet of Things (IoT) need to deal with correlated information generated by multiple sensors. The design of efficient status update strategies that minimize the Age of Correlated Information (AoCI) is a key factor. In this paper, we consider an IoT network consisting of sensors equipped with the energy harvesting (EH) capability. We optimize the average AoCI at the data fusion center (DFC) by appropriately managing the energy harvested by sensors, whose true battery states are unobservable during the decision-making process. Particularly, we first formulate the dynamic status update procedure as a partially observable Markov decision process (POMDP), where the environmental dynamics are unknown to the DFC. In order to address the challenges arising from the causality of energy usage, unknown environmental dynamics, unobservability of sensors'true battery states, and large-scale discrete action space, we devise a deep reinforcement learning (DRL)-based dynamic status update algorithm. The algorithm leverages the advantages of the soft actor-critic and long short-term memory techniques. Meanwhile, it incorporates our proposed action decomposition and mapping mechanism. Extensive simulations are conducted to validate the effectiveness of our proposed algorithm by comparing it with available DRL algorithms for POMDPs. ",
    "url": "https://arxiv.org/abs/2310.19216",
    "authors": [
      "Chao Xu",
      "Xinyan Zhang",
      "Howard H.Yang",
      "Xijun Wang",
      "Nikolaos Pappas",
      "Dusit Niyato",
      "Tony Q.S.Quek"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.19223",
    "title": "Modular Anti-noise Deep Learning Network for Robotic Grasp Detection  Based on RGB Images",
    "abstract": "While traditional methods relies on depth sensors, the current trend leans towards utilizing cost-effective RGB images, despite their absence of depth cues. This paper introduces an interesting approach to detect grasping pose from a single RGB image. To this end, we propose a modular learning network augmented with grasp detection and semantic segmentation, tailored for robots equipped with parallel-plate grippers. Our network not only identifies graspable objects but also fuses prior grasp analyses with semantic segmentation, thereby boosting grasp detection precision. Significantly, our design exhibits resilience, adeptly handling blurred and noisy visuals. Key contributions encompass a trainable network for grasp detection from RGB images, a modular design facilitating feasible grasp implementation, and an architecture robust against common image distortions. We demonstrate the feasibility and accuracy of our proposed approach through practical experiments and evaluations. ",
    "url": "https://arxiv.org/abs/2310.19223",
    "authors": [
      "Zhaocong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19226",
    "title": "Knolling bot 2.0: Enhancing Object Organization with Self-supervised  Graspability Estimation",
    "abstract": "Building on recent advancements in transformer based approaches for domestic robots performing knolling, the art of organizing scattered items into neat arrangements. This paper introduces Knolling bot 2.0. Recognizing the challenges posed by piles of objects or items situated closely together, this upgraded system incorporates a self-supervised graspability estimation model. If objects are deemed ungraspable, an additional behavior will be executed to separate the objects before knolling the table. By integrating this grasp prediction mechanism with existing visual perception and transformer based knolling models, an advanced system capable of decluttering and organizing even more complex and densely populated table settings is demonstrated. Experimental evaluations demonstrate the effectiveness of this module, yielding a graspability prediction accuracy of 95.7%. ",
    "url": "https://arxiv.org/abs/2310.19226",
    "authors": [
      "Yuhang Hu",
      "Zhizhuo Zhang",
      "Hod Lipson"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.19247",
    "title": "Uncertainty-guided Boundary Learning for Imbalanced Social Event  Detection",
    "abstract": "Real-world social events typically exhibit a severe class-imbalance distribution, which makes the trained detection model encounter a serious generalization challenge. Most studies solve this problem from the frequency perspective and emphasize the representation or classifier learning for tail classes. While in our observation, compared to the rarity of classes, the calibrated uncertainty estimated from well-trained evidential deep learning networks better reflects model performance. To this end, we propose a novel uncertainty-guided class imbalance learning framework - UCL$_{SED}$, and its variant - UCL-EC$_{SED}$, for imbalanced social event detection tasks. We aim to improve the overall model performance by enhancing model generalization to those uncertain classes. Considering performance degradation usually comes from misclassifying samples as their confusing neighboring classes, we focus on boundary learning in latent space and classifier learning with high-quality uncertainty estimation. First, we design a novel uncertainty-guided contrastive learning loss, namely UCL and its variant - UCL-EC, to manipulate distinguishable representation distribution for imbalanced data. During training, they force all classes, especially uncertain ones, to adaptively adjust a clear separable boundary in the feature space. Second, to obtain more robust and accurate class uncertainty, we combine the results of multi-view evidential classifiers via the Dempster-Shafer theory under the supervision of an additional calibration method. We conduct experiments on three severely imbalanced social event datasets including Events2012\\_100, Events2018\\_100, and CrisisLexT\\_7. Our model significantly improves social event representation and classification tasks in almost all classes, especially those uncertain ones. ",
    "url": "https://arxiv.org/abs/2310.19247",
    "authors": [
      "Jiaqian Ren",
      "Hao Peng",
      "Lei Jiang",
      "Zhiwei Liu",
      "Jia Wu",
      "Zhengtao Yu",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.19251",
    "title": "Pre-trained Recommender Systems: A Causal Debiasing Perspective",
    "abstract": "Recent studies on pre-trained vision/language models have demonstrated the practical benefit of a new, promising solution-building paradigm in AI where models can be pre-trained on broad data describing a generic task space and then adapted successfully to solve a wide range of downstream tasks, even when training data is severely limited (e.g., in zero- or few-shot learning scenarios). Inspired by such progress, we investigate in this paper the possibilities and challenges of adapting such a paradigm to the context of recommender systems, which is less investigated from the perspective of pre-trained model. In particular, we propose to develop a generic recommender that captures universal interaction patterns by training on generic user-item interaction data extracted from different domains, which can then be fast adapted to improve few-shot learning performance in unseen new domains (with limited data). However, unlike vision/language data which share strong conformity in the semantic space, universal patterns underlying recommendation data collected across different domains (e.g., different countries or different E-commerce platforms) are often occluded by both in-domain and cross-domain biases implicitly imposed by the cultural differences in their user and item bases, as well as their uses of different e-commerce platforms. As shown in our experiments, such heterogeneous biases in the data tend to hinder the effectiveness of the pre-trained model. To address this challenge, we further introduce and formalize a causal debiasing perspective, which is substantiated via a hierarchical Bayesian deep learning model, named PreRec. Our empirical studies on real-world data show that the proposed model could significantly improve the recommendation performance in zero- and few-shot learning settings under both cross-market and cross-platform scenarios. ",
    "url": "https://arxiv.org/abs/2310.19251",
    "authors": [
      "Ziqian Lin",
      "Hao Ding",
      "Nghia Hoang",
      "Branislav Kveton",
      "Anoop Deoras",
      "Hao Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.19253",
    "title": "Flow-based Distributionally Robust Optimization",
    "abstract": "We present a computationally efficient framework, called \\texttt{FlowDRO}, for solving flow-based distributionally robust optimization (DRO) problems with Wasserstein uncertainty sets, when requiring the worst-case distribution (also called the Least Favorable Distribution, LFD) to be continuous so that the algorithm can be scalable to problems with larger sample sizes and achieve better generalization capability for the induced robust algorithms. To tackle the computationally challenging infinitely dimensional optimization problem, we leverage flow-based models, continuous-time invertible transport maps between the data distribution and the target distribution, and develop a Wasserstein proximal gradient flow type of algorithm. In practice, we parameterize the transport maps by a sequence of neural networks progressively trained in blocks by gradient descent. Our computational framework is general, can handle high-dimensional data with large sample sizes, and can be useful for various applications. We demonstrate its usage in adversarial learning, distributionally robust hypothesis testing, and a new mechanism for data-driven distribution perturbation differential privacy, where the proposed method gives strong empirical performance on real high-dimensional data. ",
    "url": "https://arxiv.org/abs/2310.19253",
    "authors": [
      "Chen Xu",
      "Jonghyeok Lee",
      "Xiuyuan Cheng",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.19257",
    "title": "A High-Resolution Dataset for Instance Detection with Multi-View  Instance Capture",
    "abstract": "Instance detection (InsDet) is a long-lasting problem in robotics and computer vision, aiming to detect object instances (predefined by some visual examples) in a cluttered scene. Despite its practical significance, its advancement is overshadowed by Object Detection, which aims to detect objects belonging to some predefined classes. One major reason is that current InsDet datasets are too small in scale by today's standards. For example, the popular InsDet dataset GMU (published in 2016) has only 23 instances, far less than COCO (80 classes), a well-known object detection dataset published in 2014. We are motivated to introduce a new InsDet dataset and protocol. First, we define a realistic setup for InsDet: training data consists of multi-view instance captures, along with diverse scene images allowing synthesizing training images by pasting instance images on them with free box annotations. Second, we release a real-world database, which contains multi-view capture of 100 object instances, and high-resolution (6k x 8k) testing images. Third, we extensively study baseline methods for InsDet on our dataset, analyze their performance and suggest future work. Somewhat surprisingly, using the off-the-shelf class-agnostic segmentation model (Segment Anything Model, SAM) and the self-supervised feature representation DINOv2 performs the best, achieving >10 AP better than end-to-end trained InsDet models that repurpose object detectors (e.g., FasterRCNN and RetinaNet). ",
    "url": "https://arxiv.org/abs/2310.19257",
    "authors": [
      "Qianqian Shen",
      "Yunhan Zhao",
      "Nahyun Kwon",
      "Jeeeun Kim",
      "Yanan Li",
      "Shu Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19258",
    "title": "Improving Online Source-free Domain Adaptation for Object Detection by  Unsupervised Data Acquisition",
    "abstract": "Effective object detection in mobile robots is challenged by deployment in diverse and unfamiliar environments. Online Source-Free Domain Adaptation (O-SFDA) offers real-time model adaptation using a stream of unlabeled data from a target domain. However, not all captured frames in mobile robotics contain information that is beneficial for adaptation, particularly when there is a strong domain shift. This paper introduces a novel approach to enhance O-SFDA for adaptive object detection in mobile robots via unsupervised data acquisition. Our methodology prioritizes the most informative unlabeled samples for inclusion in the online training process. Empirical evaluation on a real-world dataset reveals that our method outperforms existing state-of-the-art O-SFDA techniques, demonstrating the viability of unsupervised data acquisition for improving adaptive object detection in mobile robots. ",
    "url": "https://arxiv.org/abs/2310.19258",
    "authors": [
      "Xiangyu Shi",
      "Yanyuan Qiao",
      "Qi Wu",
      "Lingqiao Liu",
      "Feras Dayoub"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19263",
    "title": "A Metadata-Driven Approach to Understand Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have achieved remarkable success in various applications, but their performance can be sensitive to specific data properties of the graph datasets they operate on. Current literature on understanding the limitations of GNNs has primarily employed a $\\textit{model-driven}$ approach that leverage heuristics and domain knowledge from network science or graph theory to model the GNN behaviors, which is time-consuming and highly subjective. In this work, we propose a $\\textit{metadata-driven}$ approach to analyze the sensitivity of GNNs to graph data properties, motivated by the increasing availability of graph learning benchmarks. We perform a multivariate sparse regression analysis on the metadata derived from benchmarking GNN performance across diverse datasets, yielding a set of salient data properties. To validate the effectiveness of our data-driven approach, we focus on one identified data property, the degree distribution, and investigate how this property influences GNN performance through theoretical analysis and controlled experiments. Our theoretical findings reveal that datasets with more balanced degree distribution exhibit better linear separability of node representations, thus leading to better GNN performance. We also conduct controlled experiments using synthetic datasets with varying degree distributions, and the results align well with our theoretical findings. Collectively, both the theoretical analysis and controlled experiments verify that the proposed metadata-driven approach is effective in identifying critical data properties for GNNs. ",
    "url": "https://arxiv.org/abs/2310.19263",
    "authors": [
      "Ting Wei Li",
      "Qiaozhu Mei",
      "Jiaqi Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19267",
    "title": "Overview of the CLAIMSCAN-2023: Uncovering Truth in Social Media through  Claim Detection and Identification of Claim Spans",
    "abstract": "A significant increase in content creation and information exchange has been made possible by the quick development of online social media platforms, which has been very advantageous. However, these platforms have also become a haven for those who disseminate false information, propaganda, and fake news. Claims are essential in forming our perceptions of the world, but sadly, they are frequently used to trick people by those who spread false information. To address this problem, social media giants employ content moderators to filter out fake news from the actual world. However, the sheer volume of information makes it difficult to identify fake news effectively. Therefore, it has become crucial to automatically identify social media posts that make such claims, check their veracity, and differentiate between credible and false claims. In response, we presented CLAIMSCAN in the 2023 Forum for Information Retrieval Evaluation (FIRE'2023). The primary objectives centered on two crucial tasks: Task A, determining whether a social media post constitutes a claim, and Task B, precisely identifying the words or phrases within the post that form the claim. Task A received 40 registrations, demonstrating a strong interest and engagement in this timely challenge. Meanwhile, Task B attracted participation from 28 teams, highlighting its significance in the digital era of misinformation. ",
    "url": "https://arxiv.org/abs/2310.19267",
    "authors": [
      "Megha Sundriyal",
      "Md Shad Akhtar",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.19268",
    "title": "Moral Judgments in Narratives on Reddit: Investigating Moral Sparks via  Social Commonsense and Linguistic Signals",
    "abstract": "Given the increasing realism of social interactions online, social media offers an unprecedented avenue to evaluate real-life moral scenarios. We examine posts from Reddit, where authors and commenters share their moral judgments on who is blameworthy. We employ computational techniques to investigate factors influencing moral judgments, including (1) events activating social commonsense and (2) linguistic signals. To this end, we focus on excerpt-which we term moral sparks-from original posts that commenters include to indicate what motivates their moral judgments. By examining over 24,672 posts and 175,988 comments, we find that event-related negative personal traits (e.g., immature and rude) attract attention and stimulate blame, implying a dependent relationship between moral sparks and blameworthiness. Moreover, language that impacts commenters' cognitive processes to depict events and characters enhances the probability of an excerpt become a moral spark, while factual and concrete descriptions tend to inhibit this effect. ",
    "url": "https://arxiv.org/abs/2310.19268",
    "authors": [
      "Ruijie Xi",
      "Munindar P. Singh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.19272",
    "title": "NPCL: Neural Processes for Uncertainty-Aware Continual Learning",
    "abstract": "Continual learning (CL) aims to train deep neural networks efficiently on streaming data while limiting the forgetting caused by new tasks. However, learning transferable knowledge with less interference between tasks is difficult, and real-world deployment of CL models is limited by their inability to measure predictive uncertainties. To address these issues, we propose handling CL tasks with neural processes (NPs), a class of meta-learners that encode different tasks into probabilistic distributions over functions all while providing reliable uncertainty estimates. Specifically, we propose an NP-based CL approach (NPCL) with task-specific modules arranged in a hierarchical latent variable model. We tailor regularizers on the learned latent distributions to alleviate forgetting. The uncertainty estimation capabilities of the NPCL can also be used to handle the task head/module inference challenge in CL. Our experiments show that the NPCL outperforms previous CL approaches. We validate the effectiveness of uncertainty estimation in the NPCL for identifying novel data and evaluating instance-level model confidence. Code is available at \\url{https://github.com/srvCodes/NPCL}. ",
    "url": "https://arxiv.org/abs/2310.19272",
    "authors": [
      "Saurav Jha",
      "Dong Gong",
      "He Zhao",
      "Lina Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19274",
    "title": "Prediction of Effective Elastic Moduli of Rocks using Graph Neural  Networks",
    "abstract": "This study presents a Graph Neural Networks (GNNs)-based approach for predicting the effective elastic moduli of rocks from their digital CT-scan images. We use the Mapper algorithm to transform 3D digital rock images into graph datasets, encapsulating essential geometrical information. These graphs, after training, prove effective in predicting elastic moduli. Our GNN model shows robust predictive capabilities across various graph sizes derived from various subcube dimensions. Not only does it perform well on the test dataset, but it also maintains high prediction accuracy for unseen rocks and unexplored subcube sizes. Comparative analysis with Convolutional Neural Networks (CNNs) reveals the superior performance of GNNs in predicting unseen rock properties. Moreover, the graph representation of microstructures significantly reduces GPU memory requirements (compared to the grid representation for CNNs), enabling greater flexibility in the batch size selection. This work demonstrates the potential of GNN models in enhancing the prediction accuracy of rock properties and boosting the efficiency of digital rock analysis. ",
    "url": "https://arxiv.org/abs/2310.19274",
    "authors": [
      "Jaehong Chung",
      "Rasool Ahmad",
      "WaiChing Sun",
      "Wei Cai",
      "Tapan Mukerji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2310.19277",
    "title": "Clustering based Multiple Anchors High-Dimensional Model Representation",
    "abstract": "In this work, a cut high-dimensional model representation (cut-HDMR) expansion based on multiple anchors is constructed via the clustering method. Specifically, a set of random input realizations is drawn from the parameter space and grouped by the centroidal Voronoi tessellation (CVT) method. Then for each cluster, the centroid is set as the reference, thereby the corresponding zeroth-order term can be determined directly. While for non-zero order terms of each cut-HDMR, a set of discrete points is selected for each input component, and the Lagrange interpolation method is applied. For a new input, the cut-HDMR corresponding to the nearest centroid is used to compute its response. Numerical experiments with high-dimensional integral and elliptic stochastic partial differential equation as backgrounds show that the CVT based multiple anchors cut-HDMR can alleviate the negative impact of a single inappropriate anchor point, and has higher accuracy than the average of several expansions. ",
    "url": "https://arxiv.org/abs/2310.19277",
    "authors": [
      "Meixin Xiong",
      "Liuhong Chen",
      "Ju Ming"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.19285",
    "title": "Facilitating Graph Neural Networks with Random Walk on Simplicial  Complexes",
    "abstract": "Node-level random walk has been widely used to improve Graph Neural Networks. However, there is limited attention to random walk on edge and, more generally, on $k$-simplices. This paper systematically analyzes how random walk on different orders of simplicial complexes (SC) facilitates GNNs in their theoretical expressivity. First, on $0$-simplices or node level, we establish a connection between existing positional encoding (PE) and structure encoding (SE) methods through the bridge of random walk. Second, on $1$-simplices or edge level, we bridge edge-level random walk and Hodge $1$-Laplacians and design corresponding edge PE respectively. In the spatial domain, we directly make use of edge level random walk to construct EdgeRWSE. Based on the spectral analysis of Hodge $1$-Laplcians, we propose Hodge1Lap, a permutation equivariant and expressive edge-level positional encoding. Third, we generalize our theory to random walk on higher-order simplices and propose the general principle to design PE on simplices based on random walk and Hodge Laplacians. Inter-level random walk is also introduced to unify a wide range of simplicial networks. Extensive experiments verify the effectiveness of our random walk-based methods. ",
    "url": "https://arxiv.org/abs/2310.19285",
    "authors": [
      "Cai Zhou",
      "Xiyuan Wang",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2310.19289",
    "title": "AMLNet: Adversarial Mutual Learning Neural Network for  Non-AutoRegressive Multi-Horizon Time Series Forecasting",
    "abstract": "Multi-horizon time series forecasting, crucial across diverse domains, demands high accuracy and speed. While AutoRegressive (AR) models excel in short-term predictions, they suffer speed and error issues as the horizon extends. Non-AutoRegressive (NAR) models suit long-term predictions but struggle with interdependence, yielding unrealistic results. We introduce AMLNet, an innovative NAR model that achieves realistic forecasts through an online Knowledge Distillation (KD) approach. AMLNet harnesses the strengths of both AR and NAR models by training a deep AR decoder and a deep NAR decoder in a collaborative manner, serving as ensemble teachers that impart knowledge to a shallower NAR decoder. This knowledge transfer is facilitated through two key mechanisms: 1) outcome-driven KD, which dynamically weights the contribution of KD losses from the teacher models, enabling the shallow NAR decoder to incorporate the ensemble's diversity; and 2) hint-driven KD, which employs adversarial training to extract valuable insights from the model's hidden states for distillation. Extensive experimentation showcases AMLNet's superiority over conventional AR and NAR models, thereby presenting a promising avenue for multi-horizon time series forecasting that enhances accuracy and expedites computation. ",
    "url": "https://arxiv.org/abs/2310.19289",
    "authors": [
      "Yang Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19290",
    "title": "Analyzing eyebrow region for morphed image detection",
    "abstract": "Facial images in passports are designated as primary identifiers for the verification of travelers according to the International Civil Aviation Organization (ICAO). Hence, it is important to ascertain the sanctity of the facial images stored in the electronic Machine-Readable Travel Document (eMRTD). With the introduction of automated border control (ABC) systems that rely on face recognition for the verification of travelers, it is even more crucial to have a system to ensure that the image stored in the eMRTD is free from any alteration that can hinder or abuse the normal working of a facial recognition system. One such attack against these systems is the face-morphing attack. Even though many techniques exist to detect morphed images, morphing algorithms are also improving to evade these detections. In this work, we analyze the eyebrow region for morphed image detection. The proposed method is based on analyzing the frequency content of the eyebrow region. The method was evaluated on two datasets that each consisted of morphed images created using two algorithms. The findings suggest that the proposed method can serve as a valuable tool in morphed image detection, and can be used in various applications where image authenticity is critical. ",
    "url": "https://arxiv.org/abs/2310.19290",
    "authors": [
      "Abdullah Zafar",
      "Christoph Busch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.19292",
    "title": "Fusing Temporal Graphs into Transformers for Time-Sensitive Question  Answering",
    "abstract": "Answering time-sensitive questions from long documents requires temporal reasoning over the times in questions and documents. An important open question is whether large language models can perform such reasoning solely using a provided text document, or whether they can benefit from additional temporal information extracted using other systems. We address this research question by applying existing temporal information extraction systems to construct temporal graphs of events, times, and temporal relations in questions and documents. We then investigate different approaches for fusing these graphs into Transformer models. Experimental results show that our proposed approach for fusing temporal graphs into input text substantially enhances the temporal reasoning capabilities of Transformer models with or without fine-tuning. Additionally, our proposed method outperforms various graph convolution-based approaches and establishes a new state-of-the-art performance on SituatedQA and three splits of TimeQA. ",
    "url": "https://arxiv.org/abs/2310.19292",
    "authors": [
      "Xin Su",
      "Phillip Howard",
      "Nagib Hakim",
      "Steven Bethard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.19304",
    "title": "Privacy-Preserving Federated Learning over Vertically and Horizontally  Partitioned Data for Financial Anomaly Detection",
    "abstract": "The effective detection of evidence of financial anomalies requires collaboration among multiple entities who own a diverse set of data, such as a payment network system (PNS) and its partner banks. Trust among these financial institutions is limited by regulation and competition. Federated learning (FL) enables entities to collaboratively train a model when data is either vertically or horizontally partitioned across the entities. However, in real-world financial anomaly detection scenarios, the data is partitioned both vertically and horizontally and hence it is not possible to use existing FL approaches in a plug-and-play manner. Our novel solution, PV4FAD, combines fully homomorphic encryption (HE), secure multi-party computation (SMPC), differential privacy (DP), and randomization techniques to balance privacy and accuracy during training and to prevent inference threats at model deployment time. Our solution provides input privacy through HE and SMPC, and output privacy against inference time attacks through DP. Specifically, we show that, in the honest-but-curious threat model, banks do not learn any sensitive features about PNS transactions, and the PNS does not learn any information about the banks' dataset but only learns prediction labels. We also develop and analyze a DP mechanism to protect output privacy during inference. Our solution generates high-utility models by significantly reducing the per-bank noise level while satisfying distributed DP. To ensure high accuracy, our approach produces an ensemble model, in particular, a random forest. This enables us to take advantage of the well-known properties of ensembles to reduce variance and increase accuracy. Our solution won second prize in the first phase of the U.S. Privacy Enhancing Technologies (PETs) Prize Challenge. ",
    "url": "https://arxiv.org/abs/2310.19304",
    "authors": [
      "Swanand Ravindra Kadhe",
      "Heiko Ludwig",
      "Nathalie Baracaldo",
      "Alan King",
      "Yi Zhou",
      "Keith Houck",
      "Ambrish Rawat",
      "Mark Purcell",
      "Naoise Holohan",
      "Mikio Takeuchi",
      "Ryo Kawahara",
      "Nir Drucker",
      "Hayim Shaul",
      "Eyal Kushnir",
      "Omri Soceanu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19313",
    "title": "L2T-DLN: Learning to Teach with Dynamic Loss Network",
    "abstract": "With the concept of teaching being introduced to the machine learning community, a teacher model start using dynamic loss functions to teach the training of a student model. The dynamic intends to set adaptive loss functions to different phases of student model learning. In existing works, the teacher model 1) merely determines the loss function based on the present states of the student model, i.e., disregards the experience of the teacher; 2) only utilizes the states of the student model, e.g., training iteration number and loss/accuracy from training/validation sets, while ignoring the states of the loss function. In this paper, we first formulate the loss adjustment as a temporal task by designing a teacher model with memory units, and, therefore, enables the student learning to be guided by the experience of the teacher model. Then, with a dynamic loss network, we can additionally use the states of the loss to assist the teacher learning in enhancing the interactions between the teacher and the student model. Extensive experiments demonstrate our approach can enhance student learning and improve the performance of various deep models on real-world tasks, including classification, objective detection, and semantic segmentation scenarios. ",
    "url": "https://arxiv.org/abs/2310.19313",
    "authors": [
      "Zhoyang Hai",
      "Liyuan Pan",
      "Xiabi Liu",
      "Zhengzheng Liu",
      "Mirna Yunita"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19321",
    "title": "D4Explainer: In-Distribution GNN Explanations via Discrete Denoising  Diffusion",
    "abstract": "The widespread deployment of Graph Neural Networks (GNNs) sparks significant interest in their explainability, which plays a vital role in model auditing and ensuring trustworthy graph learning. The objective of GNN explainability is to discern the underlying graph structures that have the most significant impact on model predictions. Ensuring that explanations generated are reliable necessitates consideration of the in-distribution property, particularly due to the vulnerability of GNNs to out-of-distribution data. Unfortunately, prevailing explainability methods tend to constrain the generated explanations to the structure of the original graph, thereby downplaying the significance of the in-distribution property and resulting in explanations that lack reliability. To address these challenges, we propose D4Explainer, a novel approach that provides in-distribution GNN explanations for both counterfactual and model-level explanation scenarios. The proposed D4Explainer incorporates generative graph distribution learning into the optimization objective, which accomplishes two goals: 1) generate a collection of diverse counterfactual graphs that conform to the in-distribution property for a given instance, and 2) identify the most discriminative graph patterns that contribute to a specific class prediction, thus serving as model-level explanations. It is worth mentioning that D4Explainer is the first unified framework that combines both counterfactual and model-level explanations. Empirical evaluations conducted on synthetic and real-world datasets provide compelling evidence of the state-of-the-art performance achieved by D4Explainer in terms of explanation accuracy, faithfulness, diversity, and robustness. ",
    "url": "https://arxiv.org/abs/2310.19321",
    "authors": [
      "Jialin Chen",
      "Shirley Wu",
      "Abhijit Gupta",
      "Rex Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.19322",
    "title": "ProNet: Progressive Neural Network for Multi-Horizon Time Series  Forecasting",
    "abstract": "In this paper, we introduce ProNet, an novel deep learning approach designed for multi-horizon time series forecasting, adaptively blending autoregressive (AR) and non-autoregressive (NAR) strategies. Our method involves dividing the forecasting horizon into segments, predicting the most crucial steps in each segment non-autoregressively, and the remaining steps autoregressively. The segmentation process relies on latent variables, which effectively capture the significance of individual time steps through variational inference. In comparison to AR models, ProNet showcases remarkable advantages, requiring fewer AR iterations, resulting in faster prediction speed, and mitigating error accumulation. On the other hand, when compared to NAR models, ProNet takes into account the interdependency of predictions in the output space, leading to improved forecasting accuracy. Our comprehensive evaluation, encompassing four large datasets, and an ablation study, demonstrate the effectiveness of ProNet, highlighting its superior performance in terms of accuracy and prediction speed, outperforming state-of-the-art AR and NAR forecasting models. ",
    "url": "https://arxiv.org/abs/2310.19322",
    "authors": [
      "Yang Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19324",
    "title": "TempME: Towards the Explainability of Temporal Graph Neural Networks via  Motif Discovery",
    "abstract": "Temporal graphs are widely used to model dynamic systems with time-varying interactions. In real-world scenarios, the underlying mechanisms of generating future interactions in dynamic systems are typically governed by a set of recurring substructures within the graph, known as temporal motifs. Despite the success and prevalence of current temporal graph neural networks (TGNN), it remains uncertain which temporal motifs are recognized as the significant indications that trigger a certain prediction from the model, which is a critical challenge for advancing the explainability and trustworthiness of current TGNNs. To address this challenge, we propose a novel approach, called Temporal Motifs Explainer (TempME), which uncovers the most pivotal temporal motifs guiding the prediction of TGNNs. Derived from the information bottleneck principle, TempME extracts the most interaction-related motifs while minimizing the amount of contained information to preserve the sparsity and succinctness of the explanation. Events in the explanations generated by TempME are verified to be more spatiotemporally correlated than those of existing approaches, providing more understandable insights. Extensive experiments validate the superiority of TempME, with up to 8.21% increase in terms of explanation accuracy across six real-world datasets and up to 22.96% increase in boosting the prediction Average Precision of current TGNNs. ",
    "url": "https://arxiv.org/abs/2310.19324",
    "authors": [
      "Jialin Chen",
      "Rex Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.19331",
    "title": "AdapINT: A Flexible and Adaptive In-Band Network Telemetry System Based  on Deep Reinforcement Learning",
    "abstract": "In-band Network Telemetry (INT) has emerged as a promising network measurement technology. However, existing network telemetry systems lack the flexibility to meet diverse telemetry requirements and are also difficult to adapt to dynamic network environments. In this paper, we propose AdapINT, a versatile and adaptive in-band network telemetry framework assisted by dual-timescale probes, including long-period auxiliary probes (APs) and short-period dynamic probes (DPs). Technically, the APs collect basic network status information, which is used for the path planning of DPs. To achieve full network coverage, we propose an auxiliary probes path deployment (APPD) algorithm based on the Depth-First-Search (DFS). The DPs collect specific network information for telemetry tasks. To ensure that the DPs can meet diverse telemetry requirements and adapt to dynamic network environments, we apply the deep reinforcement learning (DRL) technique and transfer learning method to design the dynamic probes path deployment (DPPD) algorithm. The evaluation results show that AdapINT can redesign the telemetry system according to telemetry requirements and network environments. AdapINT can reduce telemetry latency by 75\\% in online games and video conferencing scenarios. For overhead-aware networks, AdapINT can reduce control overheads by 34\\% in cloud computing services. ",
    "url": "https://arxiv.org/abs/2310.19331",
    "authors": [
      "Penghui Zhang",
      "Hua Zhang",
      "Yibo Pi",
      "Zijian Cao",
      "Jingyu Wang",
      "Jianxin Liao"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.19342",
    "title": "Label-Only Model Inversion Attacks via Knowledge Transfer",
    "abstract": "In a model inversion (MI) attack, an adversary abuses access to a machine learning (ML) model to infer and reconstruct private training data. Remarkable progress has been made in the white-box and black-box setups, where the adversary has access to the complete model or the model's soft output respectively. However, there is very limited study in the most challenging but practically important setup: Label-only MI attacks, where the adversary only has access to the model's predicted label (hard label) without confidence scores nor any other model information. In this work, we propose LOKT, a novel approach for label-only MI attacks. Our idea is based on transfer of knowledge from the opaque target model to surrogate models. Subsequently, using these surrogate models, our approach can harness advanced white-box attacks. We propose knowledge transfer based on generative modelling, and introduce a new model, Target model-assisted ACGAN (T-ACGAN), for effective knowledge transfer. Our method casts the challenging label-only MI into the more tractable white-box setup. We provide analysis to support that surrogate models based on our approach serve as effective proxies for the target model for MI. Our experiments show that our method significantly outperforms existing SOTA Label-only MI attack by more than 15% across all MI benchmarks. Furthermore, our method compares favorably in terms of query budget. Our study highlights rising privacy threats for ML models even when minimal information (i.e., hard labels) is exposed. Our study highlights rising privacy threats for ML models even when minimal information (i.e., hard labels) is exposed. Our code, demo, models and reconstructed data are available at our project page: https://ngoc-nguyen-0.github.io/lokt/ ",
    "url": "https://arxiv.org/abs/2310.19342",
    "authors": [
      "Ngoc-Bao Nguyen",
      "Keshigeyan Chandrasegaran",
      "Milad Abdollahzadeh",
      "Ngai-Man Cheung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19351",
    "title": "Semi- and Weakly-Supervised Domain Generalization for Object Detection",
    "abstract": "Object detectors do not work well when domains largely differ between training and testing data. To solve this problem, domain generalization approaches, which require training data with ground-truth labels from multiple domains, have been proposed. However, it is time-consuming and labor-intensive to collect those data for object detection because not only class labels but also bounding boxes must be annotated. To overcome the problem of domain gap in object detection without requiring expensive annotations, we propose to consider two new problem settings: semi-supervised domain generalizable object detection (SS-DGOD) and weakly-supervised DGOD (WS-DGOD). In contrast to the conventional domain generalization for object detection that requires labeled data from multiple domains, SS-DGOD and WS-DGOD require labeled data only from one domain and unlabeled or weakly-labeled data from multiple domains for training. We show that object detectors can be effectively trained on the proposed settings with the same student-teacher learning framework, where a student network is trained with pseudo labels output from a teacher on the unlabeled or weakly-labeled data. The experimental results demonstrate that the object detectors trained on the proposed settings significantly outperform baseline detectors trained on one labeled domain data and perform comparably to or better than those trained on unsupervised domain adaptation (UDA) settings, while ours do not use target domain data for training in contrast to UDA. ",
    "url": "https://arxiv.org/abs/2310.19351",
    "authors": [
      "Ryosuke Furuta",
      "Yoichi Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19359",
    "title": "Introducing instance label correlation in multiple instance learning.  Application to cancer detection on histopathological images",
    "abstract": "In the last years, the weakly supervised paradigm of multiple instance learning (MIL) has become very popular in many different areas. A paradigmatic example is computational pathology, where the lack of patch-level labels for whole-slide images prevents the application of supervised models. Probabilistic MIL methods based on Gaussian Processes (GPs) have obtained promising results due to their excellent uncertainty estimation capabilities. However, these are general-purpose MIL methods that do not take into account one important fact: in (histopathological) images, the labels of neighboring patches are expected to be correlated. In this work, we extend a state-of-the-art GP-based MIL method, which is called VGPMIL-PR, to exploit such correlation. To do so, we develop a novel coupling term inspired by the statistical physics Ising model. We use variational inference to estimate all the model parameters. Interestingly, the VGPMIL-PR formulation is recovered when the weight that regulates the strength of the Ising term vanishes. The performance of the proposed method is assessed in two real-world problems of prostate cancer detection. We show that our model achieves better results than other state-of-the-art probabilistic MIL methods. We also provide different visualizations and analysis to gain insights into the influence of the novel Ising term. These insights are expected to facilitate the application of the proposed model to other research areas. ",
    "url": "https://arxiv.org/abs/2310.19359",
    "authors": [
      "Pablo Morales-\u00c1lvarez",
      "Arne Schmidt",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato",
      "Rafael Molina"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19360",
    "title": "Balance, Imbalance, and Rebalance: Understanding Robust Overfitting from  a Minimax Game Perspective",
    "abstract": "Adversarial Training (AT) has become arguably the state-of-the-art algorithm for extracting robust features. However, researchers recently notice that AT suffers from severe robust overfitting problems, particularly after learning rate (LR) decay. In this paper, we explain this phenomenon by viewing adversarial training as a dynamic minimax game between the model trainer and the attacker. Specifically, we analyze how LR decay breaks the balance between the minimax game by empowering the trainer with a stronger memorization ability, and show such imbalance induces robust overfitting as a result of memorizing non-robust features. We validate this understanding with extensive experiments, and provide a holistic view of robust overfitting from the dynamics of both the two game players. This understanding further inspires us to alleviate robust overfitting by rebalancing the two players by either regularizing the trainer's capacity or improving the attack strength. Experiments show that the proposed ReBalanced Adversarial Training (ReBAT) can attain good robustness and does not suffer from robust overfitting even after very long training. Code is available at https://github.com/PKU-ML/ReBAT. ",
    "url": "https://arxiv.org/abs/2310.19360",
    "authors": [
      "Yifei Wang",
      "Liangchen Li",
      "Jiansheng Yang",
      "Zhouchen Lin",
      "Yisen Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.19368",
    "title": "Color Equivariant Convolutional Networks",
    "abstract": "Color is a crucial visual cue readily exploited by Convolutional Neural Networks (CNNs) for object recognition. However, CNNs struggle if there is data imbalance between color variations introduced by accidental recording conditions. Color invariance addresses this issue but does so at the cost of removing all color information, which sacrifices discriminative power. In this paper, we propose Color Equivariant Convolutions (CEConvs), a novel deep learning building block that enables shape feature sharing across the color spectrum while retaining important color information. We extend the notion of equivariance from geometric to photometric transformations by incorporating parameter sharing over hue-shifts in a neural network. We demonstrate the benefits of CEConvs in terms of downstream performance to various tasks and improved robustness to color changes, including train-test distribution shifts. Our approach can be seamlessly integrated into existing architectures, such as ResNets, and offers a promising solution for addressing color-based domain shifts in CNNs. ",
    "url": "https://arxiv.org/abs/2310.19368",
    "authors": [
      "Attila Lengyel",
      "Ombretta Strafforello",
      "Robert-Jan Bruintjes",
      "Alexander Gielisse",
      "Jan van Gemert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19372",
    "title": "RGB-X Object Detection via Scene-Specific Fusion Modules",
    "abstract": "Multimodal deep sensor fusion has the potential to enable autonomous vehicles to visually understand their surrounding environments in all weather conditions. However, existing deep sensor fusion methods usually employ convoluted architectures with intermingled multimodal features, requiring large coregistered multimodal datasets for training. In this work, we present an efficient and modular RGB-X fusion network that can leverage and fuse pretrained single-modal models via scene-specific fusion modules, thereby enabling joint input-adaptive network architectures to be created using small, coregistered multimodal datasets. Our experiments demonstrate the superiority of our method compared to existing works on RGB-thermal and RGB-gated datasets, performing fusion using only a small amount of additional parameters. Our code is available at https://github.com/dsriaditya999/RGBXFusion. ",
    "url": "https://arxiv.org/abs/2310.19372",
    "authors": [
      "Sri Aditya Deevi",
      "Connor Lee",
      "Lu Gan",
      "Sushruth Nagesh",
      "Gaurav Pandey",
      "Soon-Jo Chung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.19373",
    "title": "Faster QUBO Brute-Force Solving using Gray Code",
    "abstract": "This article describes an improved brute-force solving strategy for Quadratic Unconstrained Binary Optimization (QUBO) problems that is faster than naive approaches and easily parallelizable. It exploits the Gray code ordering of natural numbers to allow for a more efficient evaluation of the QUBO objective function. The implementation in Python is discussed in detail, and an additional C implementation is provided. ",
    "url": "https://arxiv.org/abs/2310.19373",
    "authors": [
      "Sascha M\u00fccke"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2310.19391",
    "title": "Causal Fair Metric: Bridging Causality, Individual Fairness, and  Adversarial Robustness",
    "abstract": "Adversarial perturbation is used to expose vulnerabilities in machine learning models, while the concept of individual fairness aims to ensure equitable treatment regardless of sensitive attributes. Despite their initial differences, both concepts rely on metrics to generate similar input data instances. These metrics should be designed to align with the data's characteristics, especially when it is derived from causal structure and should reflect counterfactuals proximity. Previous attempts to define such metrics often lack general assumptions about data or structural causal models. In this research, we introduce a causal fair metric formulated based on causal structures that encompass sensitive attributes. For robustness analysis, the concept of protected causal perturbation is presented. Additionally, we delve into metric learning, proposing a method for metric estimation and deployment in real-world problems. The introduced metric has applications in the fields adversarial training, fair learning, algorithmic recourse, and causal reinforcement learning. ",
    "url": "https://arxiv.org/abs/2310.19391",
    "authors": [
      "Ahmad-Reza Ehyaei",
      "Golnoosh Farnadi",
      "Samira Samadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.19394",
    "title": "LightSAGE: Graph Neural Networks for Large Scale Item Retrieval in  Shopee's Advertisement Recommendation",
    "abstract": "Graph Neural Network (GNN) is the trending solution for item retrieval in recommendation problems. Most recent reports, however, focus heavily on new model architectures. This may bring some gaps when applying GNN in the industrial setup, where, besides the model, constructing the graph and handling data sparsity also play critical roles in the overall success of the project. In this work, we report how GNN is applied for large-scale e-commerce item retrieval at Shopee. We introduce our simple yet novel and impactful techniques in graph construction, modeling, and handling data skewness. Specifically, we construct high-quality item graphs by combining strong-signal user behaviors with high-precision collaborative filtering (CF) algorithm. We then develop a new GNN architecture named LightSAGE to produce high-quality items' embeddings for vector search. Finally, we design multiple strategies to handle cold-start and long-tail items, which are critical in an advertisement (ads) system. Our models bring improvement in offline evaluations, online A/B tests, and are deployed to the main traffic of Shopee's Recommendation Advertisement system. ",
    "url": "https://arxiv.org/abs/2310.19394",
    "authors": [
      "Dang Minh Nguyen",
      "Chenfei Wang",
      "Yan Shen",
      "Yifan Zeng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19405",
    "title": "Radar-Lidar Fusion for Object Detection by Designing Effective  Convolution Networks",
    "abstract": "Object detection is a core component of perception systems, providing the ego vehicle with information about its surroundings to ensure safe route planning. While cameras and Lidar have significantly advanced perception systems, their performance can be limited in adverse weather conditions. In contrast, millimeter-wave technology enables radars to function effectively in such conditions. However, relying solely on radar for building a perception system doesn't fully capture the environment due to the data's sparse nature. To address this, sensor fusion strategies have been introduced. We propose a dual-branch framework to integrate radar and Lidar data for enhanced object detection. The primary branch focuses on extracting radar features, while the auxiliary branch extracts Lidar features. These are then combined using additive attention. Subsequently, the integrated features are processed through a novel Parallel Forked Structure (PFS) to manage scale variations. A region proposal head is then utilized for object detection. We evaluated the effectiveness of our proposed method on the Radiate dataset using COCO metrics. The results show that it surpasses state-of-the-art methods by $1.89\\%$ and $2.61\\%$ in favorable and adverse weather conditions, respectively. This underscores the value of radar-Lidar fusion in achieving precise object detection and localization, especially in challenging weather conditions. ",
    "url": "https://arxiv.org/abs/2310.19405",
    "authors": [
      "Farzeen Munir",
      "Shoaib Azam",
      "Tomasz Kucner",
      "Ville Kyrki",
      "Moongu Jeon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.19409",
    "title": "Increased Multiplexing Gain with Reconfigurable Surfaces: Simultaneous  Channel Orthogonalization and Information Embedding",
    "abstract": "Reconfigurable surface (RS) has been shown to be an effective solution for improving wireless communication links in general multi-user multiple-input multiple-output (MU-MIMO) setting. Current research efforts have been largely directed towards the study of reconfigurable intelligent surface (RIS), which corresponds to an RS made of passive reconfigurable elements with only phase shifting capabilities. RIS constitutes a cost- and energy- efficient solution for increased beamforming gain since it allows to generate constructive interference towards desired directions, e.g., towards a base station (BS). However, in many situations, multiplexing gain may have greater impact on the achievable transmission rates and number of simultaneously connected devices, while RIS has only been able to achieve minor improvements in this aspect. Recent work has proposed the use of alternative RS technologies, namely amplitude-reconfigurable intelligent surface (ARIS) and fully-reconfigurable intelligent surface (FRIS), to achieve perfect orthogonalization of MU-MIMO channels, thus allowing for maximum multiplexing gain at reduced complexity. In this work we consider the use of ARIS and FRIS for simultaneously orthogonalizing a MU-MIMO channel, while embedding extra information in the orthogonalized channel. We show that the resulting achievable rates allow for full exploitation of the degrees of freedom in a MU-MIMO system with excess of BS antennas. ",
    "url": "https://arxiv.org/abs/2310.19409",
    "authors": [
      "Juan Vidal Alegria",
      "Joao Vieira",
      "Fredrik Rusek"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.19410",
    "title": "Generated Distributions Are All You Need for Membership Inference  Attacks Against Generative Models",
    "abstract": "Generative models have demonstrated revolutionary success in various visual creation tasks, but in the meantime, they have been exposed to the threat of leaking private information of their training data. Several membership inference attacks (MIAs) have been proposed to exhibit the privacy vulnerability of generative models by classifying a query image as a training dataset member or nonmember. However, these attacks suffer from major limitations, such as requiring shadow models and white-box access, and either ignoring or only focusing on the unique property of diffusion models, which block their generalization to multiple generative models. In contrast, we propose the first generalized membership inference attack against a variety of generative models such as generative adversarial networks, [variational] autoencoders, implicit functions, and the emerging diffusion models. We leverage only generated distributions from target generators and auxiliary non-member datasets, therefore regarding target generators as black boxes and agnostic to their architectures or application scenarios. Experiments validate that all the generative models are vulnerable to our attack. For instance, our work achieves attack AUC $>0.99$ against DDPM, DDIM, and FastDPM trained on CIFAR-10 and CelebA. And the attack against VQGAN, LDM (for the text-conditional generation), and LIIF achieves AUC $>0.90.$ As a result, we appeal to our community to be aware of such privacy leakage risks when designing and publishing generative models. ",
    "url": "https://arxiv.org/abs/2310.19410",
    "authors": [
      "Minxing Zhang",
      "Ning Yu",
      "Rui Wen",
      "Michael Backes",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19427",
    "title": "Refining Diffusion Planner for Reliable Behavior Synthesis by Automatic  Detection of Infeasible Plans",
    "abstract": "Diffusion-based planning has shown promising results in long-horizon, sparse-reward tasks by training trajectory diffusion models and conditioning the sampled trajectories using auxiliary guidance functions. However, due to their nature as generative models, diffusion models are not guaranteed to generate feasible plans, resulting in failed execution and precluding planners from being useful in safety-critical applications. In this work, we propose a novel approach to refine unreliable plans generated by diffusion models by providing refining guidance to error-prone plans. To this end, we suggest a new metric named restoration gap for evaluating the quality of individual plans generated by the diffusion model. A restoration gap is estimated by a gap predictor which produces restoration gap guidance to refine a diffusion planner. We additionally present an attribution map regularizer to prevent adversarial refining guidance that could be generated from the sub-optimal gap predictor, which enables further refinement of infeasible plans. We demonstrate the effectiveness of our approach on three different benchmarks in offline control settings that require long-horizon planning. We also illustrate that our approach presents explainability by presenting the attribution maps of the gap predictor and highlighting error-prone transitions, allowing for a deeper understanding of the generated plans. ",
    "url": "https://arxiv.org/abs/2310.19427",
    "authors": [
      "Kyowoon Lee",
      "Seongun Kim",
      "Jaesik Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.19432",
    "title": "Explaining the Decisions of Deep Policy Networks for Robotic  Manipulations",
    "abstract": "Deep policy networks enable robots to learn behaviors to solve various real-world complex tasks in an end-to-end fashion. However, they lack transparency to provide the reasons of actions. Thus, such a black-box model often results in low reliability and disruptive actions during the deployment of the robot in practice. To enhance its transparency, it is important to explain robot behaviors by considering the extent to which each input feature contributes to determining a given action. In this paper, we present an explicit analysis of deep policy models through input attribution methods to explain how and to what extent each input feature affects the decisions of the robot policy models. To this end, we present two methods for applying input attribution methods to robot policy networks: (1) we measure the importance factor of each joint torque to reflect the influence of the motor torque on the end-effector movement, and (2) we modify a relevance propagation method to handle negative inputs and outputs in deep policy networks properly. To the best of our knowledge, this is the first report to identify the dynamic changes of input attributions of multi-modal sensor inputs in deep policy networks online for robotic manipulation. ",
    "url": "https://arxiv.org/abs/2310.19432",
    "authors": [
      "Seongun Kim",
      "Jaesik Choi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19444",
    "title": "One-for-All: Bridge the Gap Between Heterogeneous Architectures in  Knowledge Distillation",
    "abstract": "Knowledge distillation~(KD) has proven to be a highly effective approach for enhancing model performance through a teacher-student training scheme. However, most existing distillation methods are designed under the assumption that the teacher and student models belong to the same model family, particularly the hint-based approaches. By using centered kernel alignment (CKA) to compare the learned features between heterogeneous teacher and student models, we observe significant feature divergence. This divergence illustrates the ineffectiveness of previous hint-based methods in cross-architecture distillation. To tackle the challenge in distilling heterogeneous models, we propose a simple yet effective one-for-all KD framework called OFA-KD, which significantly improves the distillation performance between heterogeneous architectures. Specifically, we project intermediate features into an aligned latent space such as the logits space, where architecture-specific information is discarded. Additionally, we introduce an adaptive target enhancement scheme to prevent the student from being disturbed by irrelevant information. Extensive experiments with various architectures, including CNN, Transformer, and MLP, demonstrate the superiority of our OFA-KD framework in enabling distillation between heterogeneous architectures. Specifically, when equipped with our OFA-KD, the student models achieve notable performance improvements, with a maximum gain of 8.0% on the CIFAR-100 dataset and 0.7% on the ImageNet-1K dataset. PyTorch code and checkpoints can be found at https://github.com/Hao840/OFAKD. ",
    "url": "https://arxiv.org/abs/2310.19444",
    "authors": [
      "Zhiwei Hao",
      "Jianyuan Guo",
      "Kai Han",
      "Yehui Tang",
      "Han Hu",
      "Yunhe Wang",
      "Chang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19453",
    "title": "ALT: Towards Fine-grained Alignment between Language and CTR Models for  Click-Through Rate Prediction",
    "abstract": "Click-through rate (CTR) prediction plays as a core function module in various personalized online services. According to the data modality and input format, the models for CTR prediction can be mainly classified into two categories. The first one is the traditional CTR models that take as inputs the one-hot encoded ID features of tabular modality, which aims to capture the collaborative signals via feature interaction modeling. The second category takes as inputs the sentences of textual modality obtained by hard prompt templates, where pretrained language models (PLMs) are adopted to extract the semantic knowledge. These two lines of research generally focus on different characteristics of the same input data (i.e., textual and tabular modalities), forming a distinct complementary relationship with each other. Therefore, in this paper, we propose to conduct fine-grained feature-level Alignment between Language and CTR models (ALT) for CTR prediction. Apart from the common CLIP-like instance-level contrastive learning, we further design a novel joint reconstruction pretraining task for both masked language and tabular modeling. Specifically, the masked data of one modality (i.e., tokens or features) has to be recovered with the help of the other modality, which establishes the feature-level interaction and alignment via sufficient mutual information extraction between dual modalities. Moreover, we propose three different finetuning strategies with the option to train the aligned language and CTR models separately or jointly for downstream CTR prediction tasks, thus accommodating the varying efficacy and efficiency requirements for industrial applications. Extensive experiments on three real-world datasets demonstrate that ALT outperforms SOTA baselines, and is highly compatible for various language and CTR models. ",
    "url": "https://arxiv.org/abs/2310.19453",
    "authors": [
      "Hangyu Wang",
      "Jianghao Lin",
      "Xiangyang Li",
      "Bo Chen",
      "Chenxu Zhu",
      "Ruiming Tang",
      "Weinan Zhang",
      "Yong Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.19454",
    "title": "MMM and MMMSynth: Clustering of heterogeneous tabular data, and  synthetic data generation",
    "abstract": "We provide new algorithms for two tasks relating to heterogeneous tabular datasets: clustering, and synthetic data generation. Tabular datasets typically consist of heterogeneous data types (numerical, ordinal, categorical) in columns, but may also have hidden cluster structure in their rows: for example, they may be drawn from heterogeneous (geographical, socioeconomic, methodological) sources, such that the outcome variable they describe (such as the presence of a disease) may depend not only on the other variables but on the cluster context. Moreover, sharing of biomedical data is often hindered by patient confidentiality laws, and there is current interest in algorithms to generate synthetic tabular data from real data, for example via deep learning. We demonstrate a novel EM-based clustering algorithm, MMM (``Madras Mixture Model''), that outperforms standard algorithms in determining clusters in synthetic heterogeneous data, and recovers structure in real data. Based on this, we demonstrate a synthetic tabular data generation algorithm, MMMsynth, that pre-clusters the input data, and generates cluster-wise synthetic data assuming cluster-specific data distributions for the input columns. We benchmark this algorithm by testing the performance of standard ML algorithms when they are trained on synthetic data and tested on real published datasets. Our synthetic data generation algorithm outperforms other literature tabular-data generators, and approaches the performance of training purely with real data. ",
    "url": "https://arxiv.org/abs/2310.19454",
    "authors": [
      "Chandrani Kumari",
      "Rahul Siddharthan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.19461",
    "title": "FoodFresh: Multi-Chain Design for an Inter-Institutional Food Supply  Chain Network",
    "abstract": "We consider the problem of supply chain data visibility in a blockchain-enabled supply chain network. Existing methods typically record transactions happening in a supply chain on a single blockchain and are limited in their ability to deal with different levels of data visibility. To address this limitation, we present FoodFresh -- a multi-chain consortium where organizations store immutable data on their blockchains. A decentralized hub coordinates the cross-chain exchange of digital assets among the heterogeneous blockchains. Mechanisms for enabling blockchain interoperability help to preserve the benefits of independent sovereign blockchains while allowing for data sharing across blockchain boundaries. ",
    "url": "https://arxiv.org/abs/2310.19461",
    "authors": [
      "Philipp Stangl",
      "Christoph P. Neumann"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.19464",
    "title": "Generative Neural Fields by Mixtures of Neural Implicit Functions",
    "abstract": "We propose a novel approach to learning the generative neural fields represented by linear combinations of implicit basis networks. Our algorithm learns basis networks in the form of implicit neural representations and their coefficients in a latent space by either conducting meta-learning or adopting auto-decoding paradigms. The proposed method easily enlarges the capacity of generative neural fields by increasing the number of basis networks while maintaining the size of a network for inference to be small through their weighted model averaging. Consequently, sampling instances using the model is efficient in terms of latency and memory footprint. Moreover, we customize denoising diffusion probabilistic model for a target task to sample latent mixture coefficients, which allows our final model to generate unseen data effectively. Experiments show that our approach achieves competitive generation performance on diverse benchmarks for images, voxel data, and NeRF scenes without sophisticated designs for specific modalities and domains. ",
    "url": "https://arxiv.org/abs/2310.19464",
    "authors": [
      "Tackgeun You",
      "Mijeong Kim",
      "Jungtaek Kim",
      "Bohyung Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19519",
    "title": "A General Neural Causal Model for Interactive Recommendation",
    "abstract": "Survivor bias in observational data leads the optimization of recommender systems towards local optima. Currently most solutions re-mines existing human-system collaboration patterns to maximize longer-term satisfaction by reinforcement learning. However, from the causal perspective, mitigating survivor effects requires answering a counterfactual problem, which is generally unidentifiable and inestimable. In this work, we propose a neural causal model to achieve counterfactual inference. Specifically, we first build a learnable structural causal model based on its available graphical representations which qualitatively characterizes the preference transitions. Mitigation of the survivor bias is achieved though counterfactual consistency. To identify the consistency, we use the Gumbel-max function as structural constrains. To estimate the consistency, we apply reinforcement optimizations, and use Gumbel-Softmax as a trade-off to get a differentiable function. Both theoretical and empirical studies demonstrate the effectiveness of our solution. ",
    "url": "https://arxiv.org/abs/2310.19519",
    "authors": [
      "Jialin Liu",
      "Xinyan Su",
      "Peng Zhou",
      "Xiangyu Zhao",
      "Jun Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2310.19536",
    "title": "Adversarial Batch Inverse Reinforcement Learning: Learn to Reward from  Imperfect Demonstration for Interactive Recommendation",
    "abstract": "Rewards serve as a measure of user satisfaction and act as a limiting factor in interactive recommender systems. In this research, we focus on the problem of learning to reward (LTR), which is fundamental to reinforcement learning. Previous approaches either introduce additional procedures for learning to reward, thereby increasing the complexity of optimization, or assume that user-agent interactions provide perfect demonstrations, which is not feasible in practice. Ideally, we aim to employ a unified approach that optimizes both the reward and policy using compositional demonstrations. However, this requirement presents a challenge since rewards inherently quantify user feedback on-policy, while recommender agents approximate off-policy future cumulative valuation. To tackle this challenge, we propose a novel batch inverse reinforcement learning paradigm that achieves the desired properties. Our method utilizes discounted stationary distribution correction to combine LTR and recommender agent evaluation. To fulfill the compositional requirement, we incorporate the concept of pessimism through conservation. Specifically, we modify the vanilla correction using Bellman transformation and enforce KL regularization to constrain consecutive policy updates. We use two real-world datasets which represent two compositional coverage to conduct empirical studies, the results also show that the proposed method relatively improves both effectiveness (2.3\\%) and efficiency (11.53\\%) ",
    "url": "https://arxiv.org/abs/2310.19536",
    "authors": [
      "Jialin Liu",
      "Xinyan Su",
      "Zeyu He",
      "Xiangyu Zhao",
      "Jun Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.19539",
    "title": "A Novel Representation to Improve Team Problem Solving in Real-Time",
    "abstract": "This paper proposes a novel representation to support computing metrics that help understanding and improving in real-time a team's behavior during problem solving in real-life. Even though teams are important in modern activities, there is little computing aid to improve their activity. The representation captures the different mental images developed, enhanced, and utilized during solving. A case study illustrates the representation. ",
    "url": "https://arxiv.org/abs/2310.19539",
    "authors": [
      "Alex Doboli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.19545",
    "title": "MENTOR: Human Perception-Guided Pretraining for Iris Presentation  Detection",
    "abstract": "Incorporating human salience into the training of CNNs has boosted performance in difficult tasks such as biometric presentation attack detection. However, collecting human annotations is a laborious task, not to mention the questions of how and where (in the model architecture) to efficiently incorporate this information into model's training once annotations are obtained. In this paper, we introduce MENTOR (huMan pErceptioN-guided preTraining fOr iris pResentation attack detection), which addresses both of these issues through two unique rounds of training. First, we train an autoencoder to learn human saliency maps given an input iris image (both real and fake examples). Once this representation is learned, we utilize the trained autoencoder in two different ways: (a) as a pre-trained backbone for an iris presentation attack detector, and (b) as a human-inspired annotator of salient features on unknown data. We show that MENTOR's benefits are threefold: (a) significant boost in iris PAD performance when using the human perception-trained encoder's weights compared to general-purpose weights (e.g. ImageNet-sourced, or random), (b) capability of generating infinite number of human-like saliency maps for unseen iris PAD samples to be used in any human saliency-guided training paradigm, and (c) increase in efficiency of iris PAD model training. Sources codes and weights are offered along with the paper. ",
    "url": "https://arxiv.org/abs/2310.19545",
    "authors": [
      "Colton R. Crum",
      "Adam Czajka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19582",
    "title": "Human-interpretable and deep features for image privacy classification",
    "abstract": "Privacy is a complex, subjective and contextual concept that is difficult to define. Therefore, the annotation of images to train privacy classifiers is a challenging task. In this paper, we analyse privacy classification datasets and the properties of controversial images that are annotated with contrasting privacy labels by different assessors. We discuss suitable features for image privacy classification and propose eight privacy-specific and human-interpretable features. These features increase the performance of deep learning models and, on their own, improve the image representation for privacy classification compared with much higher dimensional deep features. ",
    "url": "https://arxiv.org/abs/2310.19582",
    "authors": [
      "Darya Baranouskaya",
      "Andrea Cavallaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19590",
    "title": "Operator Learning Enhanced Physics-informed Neural Networks for Solving  Partial Differential Equations Characterized by Sharp Solutions",
    "abstract": "Physics-informed Neural Networks (PINNs) have been shown as a promising approach for solving both forward and inverse problems of partial differential equations (PDEs). Meanwhile, the neural operator approach, including methods such as Deep Operator Network (DeepONet) and Fourier neural operator (FNO), has been introduced and extensively employed in approximating solution of PDEs. Nevertheless, to solve problems consisting of sharp solutions poses a significant challenge when employing these two approaches. To address this issue, we propose in this work a novel framework termed Operator Learning Enhanced Physics-informed Neural Networks (OL-PINN). Initially, we utilize DeepONet to learn the solution operator for a set of smooth problems relevant to the PDEs characterized by sharp solutions. Subsequently, we integrate the pre-trained DeepONet with PINN to resolve the target sharp solution problem. We showcase the efficacy of OL-PINN by successfully addressing various problems, such as the nonlinear diffusion-reaction equation, the Burgers equation and the incompressible Navier-Stokes equation at high Reynolds number. Compared with the vanilla PINN, the proposed method requires only a small number of residual points to achieve a strong generalization capability. Moreover, it substantially enhances accuracy, while also ensuring a robust training process. Furthermore, OL-PINN inherits the advantage of PINN for solving inverse problems. To this end, we apply the OL-PINN approach for solving problems with only partial boundary conditions, which usually cannot be solved by the classical numerical methods, showing its capacity in solving ill-posed problems and consequently more complex inverse problems. ",
    "url": "https://arxiv.org/abs/2310.19590",
    "authors": [
      "Bin Lin",
      "Zhiping Mao",
      "Zhicheng Wang",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.19591",
    "title": "Prediction of Locally Stationary Data Using Expert Advice",
    "abstract": "The problem of continuous machine learning is studied. Within the framework of the game-theoretic approach, when for calculating the next forecast, no assumptions about the stochastic nature of the source that generates the data flow are used -- the source can be analog, algorithmic or probabilistic, its parameters can change at random times, when building a prognostic model, only structural assumptions are used about the nature of data generation. An online forecasting algorithm for a locally stationary time series is presented. An estimate of the efficiency of the proposed algorithm is obtained. ",
    "url": "https://arxiv.org/abs/2310.19591",
    "authors": [
      "Vladimir V'yugin",
      "Vladimir Trunov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.19602",
    "title": "DCHT: Deep Complex Hybrid Transformer for Speech Enhancement",
    "abstract": "Most of the current deep learning-based approaches for speech enhancement only operate in the spectrogram or waveform domain. Although a cross-domain transformer combining waveform- and spectrogram-domain inputs has been proposed, its performance can be further improved. In this paper, we present a novel deep complex hybrid transformer that integrates both spectrogram and waveform domains approaches to improve the performance of speech enhancement. The proposed model consists of two parts: a complex Swin-Unet in the spectrogram domain and a dual-path transformer network (DPTnet) in the waveform domain. We first construct a complex Swin-Unet network in the spectrogram domain and perform speech enhancement in the complex audio spectrum. We then introduce improved DPT by adding memory-compressed attention. Our model is capable of learning multi-domain features to reduce existing noise on different domains in a complementary way. The experimental results on the BirdSoundsDenoising dataset and the VCTK+DEMAND dataset indicate that our method can achieve better performance compared to state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2310.19602",
    "authors": [
      "Jialu Li",
      "Junhui Li",
      "Pu Wang",
      "Youshan Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.19608",
    "title": "On Feynman--Kac training of partial Bayesian neural networks",
    "abstract": "Recently, partial Bayesian neural networks (pBNNs), which only consider a subset of the parameters to be stochastic, were shown to perform competitively with full Bayesian neural networks. However, pBNNs are often multi-modal in the latent-variable space and thus challenging to approximate with parametric models. To address this problem, we propose an efficient sampling-based training strategy, wherein the training of a pBNN is formulated as simulating a Feynman--Kac model. We then describe variations of sequential Monte Carlo samplers that allow us to simultaneously estimate the parameters and the latent posterior distribution of this model at a tractable computational cost. We show on various synthetic and real-world datasets that our proposed training scheme outperforms the state of the art in terms of predictive performance. ",
    "url": "https://arxiv.org/abs/2310.19608",
    "authors": [
      "Zheng Zhao",
      "Sebastian Mair",
      "Thomas B. Sch\u00f6n",
      "Jens Sj\u00f6lund"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.19629",
    "title": "RayDF: Neural Ray-surface Distance Fields with Multi-view Consistency",
    "abstract": "In this paper, we study the problem of continuous 3D shape representations. The majority of existing successful methods are coordinate-based implicit neural representations. However, they are inefficient to render novel views or recover explicit surface points. A few works start to formulate 3D shapes as ray-based neural functions, but the learned structures are inferior due to the lack of multi-view geometry consistency. To tackle these challenges, we propose a new framework called RayDF. It consists of three major components: 1) the simple ray-surface distance field, 2) the novel dual-ray visibility classifier, and 3) a multi-view consistency optimization module to drive the learned ray-surface distances to be multi-view geometry consistent. We extensively evaluate our method on three public datasets, demonstrating remarkable performance in 3D surface point reconstruction on both synthetic and challenging real-world 3D scenes, clearly surpassing existing coordinate-based and ray-based baselines. Most notably, our method achieves a 1000x faster speed than coordinate-based methods to render an 800x800 depth image, showing the superiority of our method for 3D shape representation. Our code and data are available at https://github.com/vLAR-group/RayDF ",
    "url": "https://arxiv.org/abs/2310.19629",
    "authors": [
      "Zhuoman Liu",
      "Bo Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.19630",
    "title": "Convolutional Neural Networks for Automatic Detection of Intact  Adenovirus from TEM Imaging with Debris, Broken and Artefacts Particles",
    "abstract": "Regular monitoring of the primary particles and purity profiles of a drug product during development and manufacturing processes is essential for manufacturers to avoid product variability and contamination. Transmission electron microscopy (TEM) imaging helps manufacturers predict how changes affect particle characteristics and purity for virus-based gene therapy vector products and intermediates. Since intact particles can characterize efficacious products, it is beneficial to automate the detection of intact adenovirus against a non-intact-viral background mixed with debris, broken, and artefact particles. In the presence of such particles, detecting intact adenoviruses becomes more challenging. To overcome the challenge, due to such a presence, we developed a software tool for semi-automatic annotation and segmentation of adenoviruses and a software tool for automatic segmentation and detection of intact adenoviruses in TEM imaging systems. The developed semi-automatic tool exploited conventional image analysis techniques while the automatic tool was built based on convolutional neural networks and image analysis techniques. Our quantitative and qualitative evaluations showed outstanding true positive detection rates compared to false positive and negative rates where adenoviruses were nicely detected without mistaking them for real debris, broken adenoviruses, and/or staining artefacts. ",
    "url": "https://arxiv.org/abs/2310.19630",
    "authors": [
      "Olivier Rukundo",
      "Andrea Behanova",
      "Riccardo De Feo",
      "Seppo Ronkko",
      "Joni Oja",
      "Jussi Tohka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.19634",
    "title": "Iris: Dynamic Privacy Preserving Search in Structured Peer-to-Peer  Networks",
    "abstract": "In structured peer-to-peer networks like Chord, the users manage to retrieve the information they seek by asking other nodes from the network for the information they search. Revealing to other nodes the search target makes structured peer-to-peer networks unsuitable for applications that demand query privacy, i.e., hiding the query's target from the intermediate nodes that take part in the routing. This paper studies the query privacy of structured P2P networks, particularly the Chord protocol. We initially observe that already proposed privacy notions, such as $k$-anonymity, do not allow us to reason about the privacy guarantees of a query in Chord in the presence of a strong adversary. Thus, we introduce a new privacy notion that we call $(\\alpha,\\delta)$-privacy that allows us to evaluate the privacy guarantees even when considering the worst-case scenario regarding an attacker's background knowledge. We then design Iris, an algorithm that allows a requester to conceal the target of a query in Chord from the intermediate nodes that take part in the routing. Iris achieves that by having the requester query for other than the target addresses so as reaching each one of them allows the requester to get closer to the target address. We perform a security analysis of the proposed algorithm, based on the privacy notion we introduce. We also develop a prototype of the algorithm in Matlab and evaluate its performance. Our analysis proves Iris to be $(\\alpha,\\delta)$-private while introducing a modest performance overhead. ",
    "url": "https://arxiv.org/abs/2310.19634",
    "authors": [
      "Angeliki Aktypi",
      "Kasper Rasmussen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.19640",
    "title": "Mixed coordinate Node link Visualization for Co_authorship Hypergraph  Networks",
    "abstract": "We present an algorithmic technique for visualizing the co-authorship networks and other networks modeled with hypergraphs (set systems). As more than two researchers can co-author a paper, a direct representation of the interaction of researchers through their joint works cannot be adequately modeled with direct links between the author-nodes. A hypergraph representation of a co-authorship network treats researchers/authors as nodes and papers as hyperedges (sets of authors). The visualization algorithm that we propose is based on one of the well-studied approaches representing both authors and papers as nodes of different classes. Our approach resembles some known ones like anchored maps but introduces some special techniques for optimizing the vertex positioning. The algorithm involves both continuous (force-directed) optimization and discrete optimization for determining the node coordinates. Moreover, one of the novelties of this work is classifying nodes and links using different colors. This usage has a meaningful purpose that helps the viewer to obtain valuable information from the visualization and increases the readability of the layout. The algorithm is tuned to enable the viewer to answer questions specific to co-authorship network studies. ",
    "url": "https://arxiv.org/abs/2310.19640",
    "authors": [
      "Mohsen Nafar",
      "Hamed Azami Zenouzagh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2310.19650",
    "title": "KeyGen2Vec: Learning Document Embedding via Multi-label Keyword  Generation in Question-Answering",
    "abstract": "Representing documents into high dimensional embedding space while preserving the structural similarity between document sources has been an ultimate goal for many works on text representation learning. Current embedding models, however, mainly rely on the availability of label supervision to increase the expressiveness of the resulting embeddings. In contrast, unsupervised embeddings are cheap, but they often cannot capture implicit structure in target corpus, particularly for samples that come from different distribution with the pretraining source. Our study aims to loosen up the dependency on label supervision by learning document embeddings via Sequence-to-Sequence (Seq2Seq) text generator. Specifically, we reformulate keyphrase generation task into multi-label keyword generation in community-based Question Answering (cQA). Our empirical results show that KeyGen2Vec in general is superior than multi-label keyword classifier by up to 14.7% based on Purity, Normalized Mutual Information (NMI), and F1-Score metrics. Interestingly, although in general the absolute advantage of learning embeddings through label supervision is highly positive across evaluation datasets, KeyGen2Vec is shown to be competitive with classifier that exploits topic label supervision in Yahoo! cQA with larger number of latent topic labels. ",
    "url": "https://arxiv.org/abs/2310.19650",
    "authors": [
      "Iftitahu Ni'mah",
      "Samaneh Khoshrou",
      "Vlado Menkovski",
      "Mykola Pechenizkiy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.19658",
    "title": "Explaining Tree Model Decisions in Natural Language for Network  Intrusion Detection",
    "abstract": "Network intrusion detection (NID) systems which leverage machine learning have been shown to have strong performance in practice when used to detect malicious network traffic. Decision trees in particular offer a strong balance between performance and simplicity, but require users of NID systems to have background knowledge in machine learning to interpret. In addition, they are unable to provide additional outside information as to why certain features may be important for classification. In this work, we explore the use of large language models (LLMs) to provide explanations and additional background knowledge for decision tree NID systems. Further, we introduce a new human evaluation framework for decision tree explanations, which leverages automatically generated quiz questions that measure human evaluators' understanding of decision tree inference. Finally, we show LLM generated decision tree explanations correlate highly with human ratings of readability, quality, and use of background knowledge while simultaneously providing better understanding of decision boundaries. ",
    "url": "https://arxiv.org/abs/2310.19658",
    "authors": [
      "Noah Ziems",
      "Gang Liu",
      "John Flanagan",
      "Meng Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.19662",
    "title": "Generating synthetic power grids using exponential random graphs models",
    "abstract": "Synthetic power grids enable secure, real-world energy system simulations and are crucial for algorithm testing, resilience assessment, and policy formulation. We propose a novel method for the generation of synthetic transmission power grids using Exponential Random Graph (ERG) models. Our two main contributions are: (1) the formulation of an ERG model tailored specifically for capturing the topological nuances of power grids, and (2) a general procedure for estimating the parameters of such a model conditioned on working with connected graphs. From a modeling perspective, we identify the edge counts per bus type and $k$-triangles as crucial topological characteristics for synthetic power grid generation. From a technical perspective, we develop a rigorous methodology to estimate the parameters of an ERG constrained to the space of connected graphs. The proposed model is flexible, easy to implement, and successfully captures the desired topological properties of power grids. ",
    "url": "https://arxiv.org/abs/2310.19662",
    "authors": [
      "Francesco Giacomarra",
      "Gianmarco Bet",
      "Alessandro Zocca"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2310.19666",
    "title": "Dynamic Tensor Decomposition via Neural Diffusion-Reaction Processes",
    "abstract": "Tensor decomposition is an important tool for multiway data analysis. In practice, the data is often sparse yet associated with rich temporal information. Existing methods, however, often under-use the time information and ignore the structural knowledge within the sparsely observed tensor entries. To overcome these limitations and to better capture the underlying temporal structure, we propose Dynamic EMbedIngs fOr dynamic Tensor dEcomposition (DEMOTE). We develop a neural diffusion-reaction process to estimate dynamic embeddings for the entities in each tensor mode. Specifically, based on the observed tensor entries, we build a multi-partite graph to encode the correlation between the entities. We construct a graph diffusion process to co-evolve the embedding trajectories of the correlated entities and use a neural network to construct a reaction process for each individual entity. In this way, our model can capture both the commonalities and personalities during the evolution of the embeddings for different entities. We then use a neural network to model the entry value as a nonlinear function of the embedding trajectories. For model estimation, we combine ODE solvers to develop a stochastic mini-batch learning algorithm. We propose a stratified sampling method to balance the cost of processing each mini-batch so as to improve the overall efficiency. We show the advantage of our approach in both simulation study and real-world applications. The code is available at https://github.com/wzhut/Dynamic-Tensor-Decomposition-via-Neural-Diffusion-Reaction-Processes. ",
    "url": "https://arxiv.org/abs/2310.19666",
    "authors": [
      "Zheng Wang",
      "Shikai Fang",
      "Shibo Li",
      "Shandian Zhe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.19677",
    "title": "MoCa: Measuring Human-Language Model Alignment on Causal and Moral  Judgment Tasks",
    "abstract": "Human commonsense understanding of the physical and social world is organized around intuitive theories. These theories support making causal and moral judgments. When something bad happens, we naturally ask: who did what, and why? A rich literature in cognitive science has studied people's causal and moral intuitions. This work has revealed a number of factors that systematically influence people's judgments, such as the violation of norms and whether the harm is avoidable or inevitable. We collected a dataset of stories from 24 cognitive science papers and developed a system to annotate each story with the factors they investigated. Using this dataset, we test whether large language models (LLMs) make causal and moral judgments about text-based scenarios that align with those of human participants. On the aggregate level, alignment has improved with more recent LLMs. However, using statistical analyses, we find that LLMs weigh the different factors quite differently from human participants. These results show how curated, challenge datasets combined with insights from cognitive science can help us go beyond comparisons based merely on aggregate metrics: we uncover LLMs implicit tendencies and show to what extent these align with human intuitions. ",
    "url": "https://arxiv.org/abs/2310.19677",
    "authors": [
      "Allen Nie",
      "Yuhui Zhang",
      "Atharva Amdekar",
      "Chris Piech",
      "Tatsu H. Hashimoto",
      "Tobias Gerstenberg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.19680",
    "title": "Integrating Pre-trained Language Model into Neural Machine Translation",
    "abstract": "Neural Machine Translation (NMT) has become a significant technology in natural language processing through extensive research and development. However, the deficiency of high-quality bilingual language pair data still poses a major challenge to improving NMT performance. Recent studies are exploring the use of contextual information from pre-trained language model (PLM) to address this problem. Yet, the issue of incompatibility between PLM and NMT model remains unresolved. This study proposes a PLM-integrated NMT (PiNMT) model to overcome the identified problems. The PiNMT model consists of three critical components, PLM Multi Layer Converter, Embedding Fusion, and Cosine Alignment, each playing a vital role in providing effective PLM information to NMT. Furthermore, two training strategies, Separate Learning Rates and Dual Step Training, are also introduced in this paper. By implementing the proposed PiNMT model and training strategy, we achieved state-of-the-art performance on the IWSLT'14 En$\\leftrightarrow$De dataset. This study's outcomes are noteworthy as they demonstrate a novel approach for efficiently integrating PLM with NMT to overcome incompatibility and enhance performance. ",
    "url": "https://arxiv.org/abs/2310.19680",
    "authors": [
      "Soon-Jae Hwang",
      "Chang-Sung Jeong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19685",
    "title": "DGFN: Double Generative Flow Networks",
    "abstract": "Deep learning is emerging as an effective tool in drug discovery, with potential applications in both predictive and generative models. Generative Flow Networks (GFlowNets/GFNs) are a recently introduced method recognized for the ability to generate diverse candidates, in particular in small molecule generation tasks. In this work, we introduce double GFlowNets (DGFNs). Drawing inspiration from reinforcement learning and Double Deep Q-Learning, we introduce a target network used to sample trajectories, while updating the main network with these sampled trajectories. Empirical results confirm that DGFNs effectively enhance exploration in sparse reward domains and high-dimensional state spaces, both challenging aspects of de-novo design in drug discovery. ",
    "url": "https://arxiv.org/abs/2310.19685",
    "authors": [
      "Elaine Lau",
      "Nikhil Vemgal",
      "Doina Precup",
      "Emmanuel Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2310.19686",
    "title": "Can input reconstruction be used to directly estimate uncertainty of a  regression U-Net model? -- Application to proton therapy dose prediction for  head and neck cancer patients",
    "abstract": "Estimating the uncertainty of deep learning models in a reliable and efficient way has remained an open problem, where many different solutions have been proposed in the literature. Most common methods are based on Bayesian approximations, like Monte Carlo dropout (MCDO) or Deep ensembling (DE), but they have a high inference time (i.e. require multiple inference passes) and might not work for out-of-distribution detection (OOD) data (i.e. similar uncertainty for in-distribution (ID) and OOD). In safety critical environments, like medical applications, accurate and fast uncertainty estimation methods, able to detect OOD data, are crucial, since wrong predictions can jeopardize patients safety. In this study, we present an alternative direct uncertainty estimation method and apply it for a regression U-Net architecture. The method consists in the addition of a branch from the bottleneck which reconstructs the input. The input reconstruction error can be used as a surrogate of the model uncertainty. For the proof-of-concept, our method is applied to proton therapy dose prediction in head and neck cancer patients. Accuracy, time-gain, and OOD detection are analyzed for our method in this particular application and compared with the popular MCDO and DE. The input reconstruction method showed a higher Pearson correlation coefficient with the prediction error (0.620) than DE and MCDO (between 0.447 and 0.612). Moreover, our method allows an easier identification of OOD (Z-score of 34.05). It estimates the uncertainty simultaneously to the regression task, therefore requires less time or computational resources. ",
    "url": "https://arxiv.org/abs/2310.19686",
    "authors": [
      "Margerie Huet-Dastarac",
      "Dan Nguyen",
      "Steve Jiang",
      "John Lee",
      "Ana Barragan Montero"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2310.19691",
    "title": "Causal Context Connects Counterfactual Fairness to Robust Prediction and  Group Fairness",
    "abstract": "Counterfactual fairness requires that a person would have been classified in the same way by an AI or other algorithmic system if they had a different protected class, such as a different race or gender. This is an intuitive standard, as reflected in the U.S. legal system, but its use is limited because counterfactuals cannot be directly observed in real-world data. On the other hand, group fairness metrics (e.g., demographic parity or equalized odds) are less intuitive but more readily observed. In this paper, we use $\\textit{causal context}$ to bridge the gaps between counterfactual fairness, robust prediction, and group fairness. First, we motivate counterfactual fairness by showing that there is not necessarily a fundamental trade-off between fairness and accuracy because, under plausible conditions, the counterfactually fair predictor is in fact accuracy-optimal in an unbiased target distribution. Second, we develop a correspondence between the causal graph of the data-generating process and which, if any, group fairness metrics are equivalent to counterfactual fairness. Third, we show that in three common fairness contexts$\\unicode{x2013}$measurement error, selection on label, and selection on predictors$\\unicode{x2013}$counterfactual fairness is equivalent to demographic parity, equalized odds, and calibration, respectively. Counterfactual fairness can sometimes be tested by measuring relatively simple group fairness metrics. ",
    "url": "https://arxiv.org/abs/2310.19691",
    "authors": [
      "Jacy Reese Anthis",
      "Victor Veitch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.19694",
    "title": "Convolutional State Space Models for Long-Range Spatiotemporal Modeling",
    "abstract": "Effectively modeling long spatiotemporal sequences is challenging due to the need to model complex spatial correlations and long-range temporal dependencies simultaneously. ConvLSTMs attempt to address this by updating tensor-valued states with recurrent neural networks, but their sequential computation makes them slow to train. In contrast, Transformers can process an entire spatiotemporal sequence, compressed into tokens, in parallel. However, the cost of attention scales quadratically in length, limiting their scalability to longer sequences. Here, we address the challenges of prior methods and introduce convolutional state space models (ConvSSM) that combine the tensor modeling ideas of ConvLSTM with the long sequence modeling approaches of state space methods such as S4 and S5. First, we demonstrate how parallel scans can be applied to convolutional recurrences to achieve subquadratic parallelization and fast autoregressive generation. We then establish an equivalence between the dynamics of ConvSSMs and SSMs, which motivates parameterization and initialization strategies for modeling long-range dependencies. The result is ConvS5, an efficient ConvSSM variant for long-range spatiotemporal modeling. ConvS5 significantly outperforms Transformers and ConvLSTM on a long horizon Moving-MNIST experiment while training 3X faster than ConvLSTM and generating samples 400X faster than Transformers. In addition, ConvS5 matches or exceeds the performance of state-of-the-art methods on challenging DMLab, Minecraft and Habitat prediction benchmarks and enables new directions for modeling long spatiotemporal sequences. ",
    "url": "https://arxiv.org/abs/2310.19694",
    "authors": [
      "Jimmy T.H. Smith",
      "Shalini De Mello",
      "Jan Kautz",
      "Scott W. Linderman",
      "Wonmin Byeon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19697",
    "title": "A nonlinear spectral core-periphery detection method for multiplex  networks",
    "abstract": "Core-periphery detection aims to separate the nodes of a complex network into two subsets: a core that is densely connected to the entire network and a periphery that is densely connected to the core but sparsely connected internally. The definition of core-periphery structure in multiplex networks that record different types of interactions between the same set of nodes but on different layers is nontrivial since a node may belong to the core in some layers and to the periphery in others. The current state-of-the-art approach relies on linear combinations of individual layer degree vectors whose layer weights need to be chosen a-priori. We propose a nonlinear spectral method for multiplex networks that simultaneously optimizes a node and a layer coreness vector by maximizing a suitable nonconvex homogeneous objective function by an alternating fixed point iteration. We prove global optimality and convergence guarantees for admissible hyper-parameter choices and convergence to local optima for the remaining cases. We derive a quantitative measure for the quality of a given multiplex core-periphery structure that allows the determination of the optimal core size. Numerical experiments on synthetic and real-world networks illustrate that our approach is robust against noisy layers and outperforms baseline methods with respect to a variety of core-periphery quality measures. In particular, all methods based on layer aggregation are improved when used in combination with the novel optimized layer coreness vector weights. As the runtime of our method depends linearly on the number of edges of the network it is scalable to large-scale multiplex networks. ",
    "url": "https://arxiv.org/abs/2310.19697",
    "authors": [
      "Kai Bergermann",
      "Martin Stoll",
      "Francesco Tudisco"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2310.19704",
    "title": "A Survey on Knowledge Editing of Neural Networks",
    "abstract": "Deep neural networks are becoming increasingly pervasive in academia and industry, matching and surpassing human performance on a wide variety of fields and related tasks. However, just as humans, even the largest artificial neural networks make mistakes, and once-correct predictions can become invalid as the world progresses in time. Augmenting datasets with samples that account for mistakes or up-to-date information has become a common workaround in practical applications. However, the well-known phenomenon of catastrophic forgetting poses a challenge in achieving precise changes in the implicitly memorized knowledge of neural network parameters, often requiring a full model re-training to achieve desired behaviors. That is expensive, unreliable, and incompatible with the current trend of large self-supervised pre-training, making it necessary to find more efficient and effective methods for adapting neural network models to changing data. To address this need, knowledge editing is emerging as a novel area of research that aims to enable reliable, data-efficient, and fast changes to a pre-trained target model, without affecting model behaviors on previously learned tasks. In this survey, we provide a brief review of this recent artificial intelligence field of research. We first introduce the problem of editing neural networks, formalize it in a common framework and differentiate it from more notorious branches of research such as continuous learning. Next, we provide a review of the most relevant knowledge editing approaches and datasets proposed so far, grouping works under four different families: regularization techniques, meta-learning, direct model editing, and architectural strategies. Finally, we outline some intersections with other fields of research and potential directions for future works. ",
    "url": "https://arxiv.org/abs/2310.19704",
    "authors": [
      "Vittorio Mazzia",
      "Alessandro Pedrani",
      "Andrea Caciolai",
      "Kay Rottmann",
      "Davide Bernardi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.19731",
    "title": "ViR: Vision Retention Networks",
    "abstract": "Vision Transformers (ViTs) have attracted a lot of popularity in recent years, due to their exceptional capabilities in modeling long-range spatial dependencies and scalability for large scale training. Although the training parallelism of self-attention mechanism plays an important role in retaining great performance, its quadratic complexity baffles the application of ViTs in many scenarios which demand fast inference. This effect is even more pronounced in applications in which autoregressive modeling of input features is required. In Natural Language Processing (NLP), a new stream of efforts have proposed parallelizable models with recurrent formulation that allows for efficient inference in generative applications. Inspired by this trend, we propose a new class of computer vision models, dubbed Vision Retention Networks (ViR), with dual parallel and recurrent formulations, which strike an optimal balance between fast inference and parallel training with competitive performance. In particular, ViR scales favorably for image throughput and memory consumption in tasks that require higher-resolution images due to its flexible formulation in processing large sequence lengths. The ViR is the first attempt to realize dual parallel and recurrent equivalency in a general vision backbone for recognition tasks. We have validated the effectiveness of ViR through extensive experiments with different dataset sizes and various image resolutions and achieved competitive performance. Our code and pretrained models will be made publicly available. ",
    "url": "https://arxiv.org/abs/2310.19731",
    "authors": [
      "Ali Hatamizadeh",
      "Michael Ranzinger",
      "Jan Kautz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19737",
    "title": "Adversarial Attacks and Defenses in Large Language Models: Old and New  Threats",
    "abstract": "Over the past decade, there has been extensive research aimed at enhancing the robustness of neural networks, yet this problem remains vastly unsolved. Here, one major impediment has been the overestimation of the robustness of new defense approaches due to faulty defense evaluations. Flawed robustness evaluations necessitate rectifications in subsequent works, dangerously slowing down the research and providing a false sense of security. In this context, we will face substantial challenges associated with an impending adversarial arms race in natural language processing, specifically with closed-source Large Language Models (LLMs), such as ChatGPT, Google Bard, or Anthropic's Claude. We provide a first set of prerequisites to improve the robustness assessment of new approaches and reduce the amount of faulty evaluations. Additionally, we identify embedding space attacks on LLMs as another viable threat model for the purposes of generating malicious content in open-sourced models. Finally, we demonstrate on a recently proposed defense that, without LLM-specific best practices in place, it is easy to overestimate the robustness of a new approach. ",
    "url": "https://arxiv.org/abs/2310.19737",
    "authors": [
      "Leo Schwinn",
      "David Dobre",
      "Stephan G\u00fcnnemann",
      "Gauthier Gidel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.19750",
    "title": "Chain-of-Thought Embeddings for Stance Detection on Social Media",
    "abstract": "Stance detection on social media is challenging for Large Language Models (LLMs), as emerging slang and colloquial language in online conversations often contain deeply implicit stance labels. Chain-of-Thought (COT) prompting has recently been shown to improve performance on stance detection tasks -- alleviating some of these issues. However, COT prompting still struggles with implicit stance identification. This challenge arises because many samples are initially challenging to comprehend before a model becomes familiar with the slang and evolving knowledge related to different topics, all of which need to be acquired through the training data. In this study, we address this problem by introducing COT Embeddings which improve COT performance on stance detection tasks by embedding COT reasonings and integrating them into a traditional RoBERTa-based stance detection pipeline. Our analysis demonstrates that 1) text encoders can leverage COT reasonings with minor errors or hallucinations that would otherwise distort the COT output label. 2) Text encoders can overlook misleading COT reasoning when a sample's prediction heavily depends on domain-specific patterns. Our model achieves SOTA performance on multiple stance detection datasets collected from social media. ",
    "url": "https://arxiv.org/abs/2310.19750",
    "authors": [
      "Joseph Gatto",
      "Omar Sharif",
      "Sarah Masud Preum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.19760",
    "title": "Epidemic outbreak prediction using machine learning models",
    "abstract": "In today's world,the risk of emerging and re-emerging epidemics have increased.The recent advancement in healthcare technology has made it possible to predict an epidemic outbreak in a region.Early prediction of an epidemic outbreak greatly helps the authorities to be prepared with the necessary medications and logistics required to keep things in control. In this article, we try to predict the epidemic outbreak (influenza, hepatitis and malaria) for the state of New York, USA using machine and deep learning algorithms, and a portal has been created for the same which can alert the authorities and health care organizations of the region in case of an outbreak. The algorithm takes historical data to predict the possible number of cases for 5 weeks into the future. Non-clinical factors like google search trends,social media data and weather data have also been used to predict the probability of an outbreak. ",
    "url": "https://arxiv.org/abs/2310.19760",
    "authors": [
      "Akshara Pramod",
      "JS Abhishek",
      "Dr. Suganthi K"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2310.19763",
    "title": "Autoregressive Renaissance in Neural PDE Solvers",
    "abstract": "Recent developments in the field of neural partial differential equation (PDE) solvers have placed a strong emphasis on neural operators. However, the paper \"Message Passing Neural PDE Solver\" by Brandstetter et al. published in ICLR 2022 revisits autoregressive models and designs a message passing graph neural network that is comparable with or outperforms both the state-of-the-art Fourier Neural Operator and traditional classical PDE solvers in its generalization capabilities and performance. This blog post delves into the key contributions of this work, exploring the strategies used to address the common problem of instability in autoregressive models and the design choices of the message passing graph neural network architecture. ",
    "url": "https://arxiv.org/abs/2310.19763",
    "authors": [
      "Yolanne Yi Ran Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.19791",
    "title": "LILO: Learning Interpretable Libraries by Compressing and Documenting  Code",
    "abstract": "While large language models (LLMs) now excel at code generation, a key aspect of software development is the art of refactoring: consolidating code into libraries of reusable and readable programs. In this paper, we introduce LILO, a neurosymbolic framework that iteratively synthesizes, compresses, and documents code to build libraries tailored to particular problem domains. LILO combines LLM-guided program synthesis with recent algorithmic advances in automated refactoring from Stitch: a symbolic compression system that efficiently identifies optimal lambda abstractions across large code corpora. To make these abstractions interpretable, we introduce an auto-documentation (AutoDoc) procedure that infers natural language names and docstrings based on contextual examples of usage. In addition to improving human readability, we find that AutoDoc boosts performance by helping LILO's synthesizer to interpret and deploy learned abstractions. We evaluate LILO on three inductive program synthesis benchmarks for string editing, scene reasoning, and graphics composition. Compared to existing neural and symbolic methods - including the state-of-the-art library learning algorithm DreamCoder - LILO solves more complex tasks and learns richer libraries that are grounded in linguistic knowledge. ",
    "url": "https://arxiv.org/abs/2310.19791",
    "authors": [
      "Gabriel Grand",
      "Lionel Wong",
      "Matthew Bowers",
      "Theo X. Olausson",
      "Muxin Liu",
      "Joshua B. Tenenbaum",
      "Jacob Andreas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2310.18346",
    "title": "Data-Free Distillation Improves Efficiency and Privacy in Federated  Thorax Disease Analysis",
    "abstract": "Thorax disease analysis in large-scale, multi-centre, and multi-scanner settings is often limited by strict privacy policies. Federated learning (FL) offers a potential solution, while traditional parameter-based FL can be limited by issues such as high communication costs, data leakage, and heterogeneity. Distillation-based FL can improve efficiency, but it relies on a proxy dataset, which is often impractical in clinical practice. To address these challenges, we introduce a data-free distillation-based FL approach FedKDF. In FedKDF, the server employs a lightweight generator to aggregate knowledge from different clients without requiring access to their private data or a proxy dataset. FedKDF combines the predictors from clients into a single, unified predictor, which is further optimized using the learned knowledge in the lightweight generator. Our empirical experiments demonstrate that FedKDF offers a robust solution for efficient, privacy-preserving federated thorax disease analysis. ",
    "url": "https://arxiv.org/abs/2310.18346",
    "authors": [
      "Ming Li",
      "Guang Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18565",
    "title": "Linearly Embedding Sparse Vectors from $\\ell_2$ to $\\ell_1$ via  Deterministic Dimension-Reducing Maps",
    "abstract": "This note is concerned with deterministic constructions of $m \\times N$ matrices satisfying a restricted isometry property from $\\ell_2$ to $\\ell_1$ on $s$-sparse vectors. Similarly to the standard ($\\ell_2$ to $\\ell_2$) restricted isometry property, such constructions can be found in the regime $m \\asymp s^2$, at least in theory. With effectiveness of implementation in mind, two simple constructions are presented in the less pleasing but still relevant regime $m \\asymp s^4$. The first one, executing a Las Vegas strategy, is quasideterministic and applies in the real setting. The second one, exploiting Golomb rulers, is explicit and applies to the complex setting. As a stepping stone, an explicit isometric embedding from $\\ell_2^n(\\mathbb{C})$ to $\\ell_4^{cn^2}(\\mathbb{C})$ is presented. Finally, the extension of the problem from sparse vectors to low-rank matrices is raised as an open question. ",
    "url": "https://arxiv.org/abs/2310.18565",
    "authors": [
      "Simon Foucart"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.18654",
    "title": "Causal discovery in a complex industrial system: A time series benchmark",
    "abstract": "Causal discovery outputs a causal structure, represented by a graph, from observed data. For time series data, there is a variety of methods, however, it is difficult to evaluate these on real data as realistic use cases very rarely come with a known causal graph to which output can be compared. In this paper, we present a dataset from an industrial subsystem at the European Spallation Source along with its causal graph which has been constructed from expert knowledge. This provides a testbed for causal discovery from time series observations of complex systems, and we believe this can help inform the development of causal discovery methodology. ",
    "url": "https://arxiv.org/abs/2310.18654",
    "authors": [
      "S\u00f8ren Wengel Mogensen",
      "Karin Rathsman",
      "Per Nilsson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18814",
    "title": "Stability of Random Forests and Coverage of Random-Forest Prediction  Intervals",
    "abstract": "We establish stability of random forests under the mild condition that the squared response ($Y^2$) does not have a heavy tail. In particular, our analysis holds for the practical version of random forests that is implemented in popular packages like \\texttt{randomForest} in \\texttt{R}. Empirical results show that stability may persist even beyond our assumption and hold for heavy-tailed $Y^2$. Using the stability property, we prove a non-asymptotic lower bound for the coverage probability of prediction intervals constructed from the out-of-bag error of random forests. With another mild condition that is typically satisfied when $Y$ is continuous, we also establish a complementary upper bound, which can be similarly established for the jackknife prediction interval constructed from an arbitrary stable algorithm. We also discuss the asymptotic coverage probability under assumptions weaker than those considered in previous literature. Our work implies that random forests, with its stability property, is an effective machine learning method that can provide not only satisfactory point prediction but also justified interval prediction at almost no extra computational cost. ",
    "url": "https://arxiv.org/abs/2310.18814",
    "authors": [
      "Yan Wang",
      "Huaiqing Wu",
      "Dan Nettleton"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18897",
    "title": "Learning Subgrid-Scale Models in Discontinuous Galerkin Methods with  Neural Ordinary Differential Equations for Compressible Navier--Stokes  Equations",
    "abstract": "The growing computing power over the years has enabled simulations to become more complex and accurate. However, high-fidelity simulations, while immensely valuable for scientific discovery and problem solving, come with significant computational demands. As a result, it is common to run a low-fidelity model with a subgrid-scale model to reduce the computational cost, but selecting the appropriate subgrid-scale models and tuning them are challenging. We propose a novel method for learning the subgrid-scale model effects when simulating partial differential equations using neural ordinary differential equations in the context of discontinuous Galerkin (DG) spatial discretization. Our approach learns the missing scales of the low-order DG solver at a continuous level and hence improves the accuracy of the low-order DG approximations as well as accelerates the filtered high-order DG simulations with a certain degree of precision. We demonstrate the performance of our approach through multidimensional Taylor--Green vortex examples at different Reynolds numbers and times, which cover laminar, transitional, and turbulent regimes. The proposed method not only reconstructs the subgrid-scale from the low-order (1st-order) approximation but also speeds up the filtered high-order DG (6th-order) simulation by two orders of magnitude. ",
    "url": "https://arxiv.org/abs/2310.18897",
    "authors": [
      "Shinhoo Kang",
      "Emil M. Constantinescu"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.18907",
    "title": "Topological, or Non-topological? A Deep Learning Based Prediction",
    "abstract": "Prediction and discovery of new materials with desired properties are at the forefront of quantum science and technology research. A major bottleneck in this field is the computational resources and time complexity related to finding new materials from ab initio calculations. In this work, an effective and robust deep learning-based model is proposed by incorporating persistent homology and graph neural network which offers an accuracy of 91.4% and an F1 score of 88.5% in classifying topological vs. non-topological materials, outperforming the other state-of-the-art classifier models. The incorporation of the graph neural network encodes the underlying relation between the atoms into the model based on their own crystalline structures and thus proved to be an effective method to represent and process non-euclidean data like molecules with a relatively shallow network. The persistent homology pipeline in the suggested neural network is capable of integrating the atom-specific topological information into the deep learning model, increasing robustness, and gain in performance. It is believed that the presented work will be an efficacious tool for predicting the topological class and therefore enable the high-throughput search for novel materials in this field. ",
    "url": "https://arxiv.org/abs/2310.18907",
    "authors": [
      "Ashiqur Rasul",
      "Md Shafayat Hossain",
      "Ankan Ghosh Dastider",
      "Himaddri Roy",
      "M. Zahid Hasan",
      "Quazi D. M. Khosru"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19041",
    "title": "On Linear Separation Capacity of Self-Supervised Representation Learning",
    "abstract": "Recent advances in self-supervised learning have highlighted the efficacy of data augmentation in learning data representation from unlabeled data. Training a linear model atop these enhanced representations can yield an adept classifier. Despite the remarkable empirical performance, the underlying mechanisms that enable data augmentation to unravel nonlinear data structures into linearly separable representations remain elusive. This paper seeks to bridge this gap by investigating under what conditions learned representations can linearly separate manifolds when data is drawn from a multi-manifold model. Our investigation reveals that data augmentation offers additional information beyond observed data and can thus improve the information-theoretic optimal rate of linear separation capacity. In particular, we show that self-supervised learning can linearly separate manifolds with a smaller distance than unsupervised learning, underscoring the additional benefits of data augmentation. Our theoretical analysis further underscores that the performance of downstream linear classifiers primarily hinges on the linear separability of data representations rather than the size of the labeled data set, reaffirming the viability of constructing efficient classifiers with limited labeled data amid an expansive unlabeled data set. ",
    "url": "https://arxiv.org/abs/2310.19041",
    "authors": [
      "Shulei Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2310.19192",
    "title": "Conformal Normalization in Recurrent Neural Network of Grid Cells",
    "abstract": "Grid cells in the entorhinal cortex of the mammalian brain exhibit striking hexagon firing patterns in their response maps as the animal (e.g., a rat) navigates in a 2D open environment. The responses of the population of grid cells collectively form a vector in a high-dimensional neural activity space, and this vector represents the self-position of the agent in the 2D physical space. As the agent moves, the vector is transformed by a recurrent neural network that takes the velocity of the agent as input. In this paper, we propose a simple and general conformal normalization of the input velocity for the recurrent neural network, so that the local displacement of the position vector in the high-dimensional neural space is proportional to the local displacement of the agent in the 2D physical space, regardless of the direction of the input velocity. Our numerical experiments on the minimally simple linear and non-linear recurrent networks show that conformal normalization leads to the emergence of the hexagon grid patterns. Furthermore, we derive a new theoretical understanding that connects conformal normalization to the emergence of hexagon grid patterns in navigation tasks. ",
    "url": "https://arxiv.org/abs/2310.19192",
    "authors": [
      "Dehong Xu",
      "Ruiqi Gao",
      "Wen-Hao Zhang",
      "Xue-Xin Wei",
      "Ying Nian Wu"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.19385",
    "title": "Gradient-free online learning of subgrid-scale dynamics with neural  emulators",
    "abstract": "In this paper, we propose a generic algorithm to train machine learning-based subgrid parametrizations online, i.e., with $\\textit{a posteriori}$ loss functions for non-differentiable numerical solvers. The proposed approach leverage neural emulators to train an approximation of the reduced state-space solver, which is then used to allows gradient propagation through temporal integration steps. The algorithm is able to recover most of the benefit of online strategies without having to compute the gradient of the original solver. It is demonstrated that training the neural emulator and parametrization components separately with respective loss quantities is necessary in order to minimize the propagation of some approximation bias. ",
    "url": "https://arxiv.org/abs/2310.19385",
    "authors": [
      "Hugo Frezat",
      "Guillaume Balarac",
      "Julien Le Sommer",
      "Ronan Fablet"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2310.19445",
    "title": "A Federated Learning Framework for Stenosis Detection",
    "abstract": "This study explores the use of Federated Learning (FL) for stenosis detection in coronary angiography images (CA). Two heterogeneous datasets from two institutions were considered: Dataset 1 includes 1219 images from 200 patients, which we acquired at the Ospedale Riuniti of Ancona (Italy); Dataset 2 includes 7492 sequential images from 90 patients from a previous study available in the literature. Stenosis detection was performed by using a Faster R-CNN model. In our FL framework, only the weights of the model backbone were shared among the two client institutions, using Federated Averaging (FedAvg) for weight aggregation. We assessed the performance of stenosis detection using Precision (P rec), Recall (Rec), and F1 score (F1). Our results showed that the FL framework does not substantially affects clients 2 performance, which already achieved good performance with local training; for client 1, instead, FL framework increases the performance with respect to local model of +3.76%, +17.21% and +10.80%, respectively, reaching P rec = 73.56, Rec = 67.01 and F1 = 70.13. With such results, we showed that FL may enable multicentric studies relevant to automatic stenosis detection in CA by addressing data heterogeneity from various institutions, while preserving patient privacy. ",
    "url": "https://arxiv.org/abs/2310.19445",
    "authors": [
      "Mariachiara Di Cosmo",
      "Giovanna Migliorelli",
      "Matteo Francioni",
      "Andi Mucaj",
      "Alessandro Maolo",
      "Alessandro Aprile",
      "Emanuele Frontoni",
      "Maria Chiara Fiorentino",
      "Sara Moccia"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19711",
    "title": "Flip Graph Connectivity for Arrangements of Pseudolines and  Pseudocircles",
    "abstract": "Flip graphs of combinatorial and geometric objects are at the heart of many deep structural insights and connections between different branches of discrete mathematics and computer science. They also provide a natural framework for the study of reconfiguration problems. We study flip graphs of arrangements of pseudolines and of arrangements of pseudocircles, which are combinatorial generalizations of lines and circles, respectively. In both cases we consider triangle flips as local transformation and prove conjectures regarding their connectivity. In the case of $n$ pseudolines we show that the connectivity of the flip graph equals its minimum degree, which is exactly $n-2$. For the proof we introduce the class of shellable line arrangements, which serve as reference objects for the construction of disjoint paths. In fact, shellable arrangements are elements of a flip graph of line arrangements which are vertices of a polytope (Felsner and Ziegler; DM 241 (2001), 301--312). This polytope forms a cluster of good connectivity in the flip graph of pseudolines. In the case of pseudocircles we show that triangle flips induce a connected flip graph on \\emph{intersecting} arrangements and also on cylindrical intersecting arrangements. The result for cylindrical arrangements is used in the proof for intersecting arrangements. We also show that in both settings the diameter of the flip graph is in $\\Theta(n^3)$. Our constructions make essential use of variants of the sweeping lemma for pseudocircle arrangements (Snoeyink and Hershberger; Proc.\\ SoCG 1989: 354--363). We finally study cylindrical arrangements in their own right and provide new combinatorial characterizations of this class. ",
    "url": "https://arxiv.org/abs/2310.19711",
    "authors": [
      "Yan Alves Radtke",
      "Stefan Felsner",
      "Johannes Obenaus",
      "Sandro Roch",
      "Manfred Scheucher",
      "Birgit Vogtenhuber"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2310.19767",
    "title": "Autoregressive Attention Neural Networks for Non-Line-of-Sight User  Tracking with Dynamic Metasurface Antennas",
    "abstract": "User localization and tracking in the upcoming generation of wireless networks have the potential to be revolutionized by technologies such as the Dynamic Metasurface Antennas (DMAs). Commonly proposed algorithmic approaches rely on assumptions about relatively dominant Line-of-Sight (LoS) paths, or require pilot transmission sequences whose length is comparable to the number of DMA elements, thus, leading to limited effectiveness and considerable measurement overheads in blocked LoS and dynamic multipath environments. In this paper, we present a two-stage machine-learning-based approach for user tracking, specifically designed for non-LoS multipath settings. A newly proposed attention-based Neural Network (NN) is first trained to map noisy channel responses to potential user positions, regardless of user mobility patterns. This architecture constitutes a modification of the prominent vision transformer, specifically modified for extracting information from high-dimensional frequency response signals. As a second stage, the NN's predictions for the past user positions are passed through a learnable autoregressive model to exploit the time-correlated channel information and obtain the final position predictions. The channel estimation procedure leverages a DMA receive architecture with partially-connected radio frequency chains, which results to reduced numbers of pilots. The numerical evaluation over an outdoor ray-tracing scenario illustrates that despite LoS blockage, this methodology is capable of achieving high position accuracy across various multipath settings. ",
    "url": "https://arxiv.org/abs/2310.19767",
    "authors": [
      "Kyriakos Stylianopoulos",
      "Murat Bayraktar",
      "Nuria Gonz\u00e1lez Prelcic",
      "George C. Alexandropoulos"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19777",
    "title": "Conditional gradients for total variation regularization with PDE  constraints: a graph cuts approach",
    "abstract": "Total variation regularization has proven to be a valuable tool in the context of optimal control of differential equations. This is particularly attributed to the observation that TV-penalties often favor piecewise constant minimizers with well-behaved jumpsets. On the downside, their intricate properties significantly complicate every aspect of their analysis, from the derivation of first-order optimality conditions to their discrete approximation and the choice of a suitable solution algorithm. In this paper, we investigate a general class of minimization problems with TV-regularization, comprising both continuous and discretized control spaces, from a convex geometry perspective. This leads to a variety of novel theoretical insights on minimization problems with total variation regularization as well as tools for their practical realization. First, by studying the extremal points of the respective total variation unit balls, we enable their efficient solution by geometry exploiting algorithms, e.g. fully-corrective generalized conditional gradient methods. We give a detailed account on the practical realization of such a method for piecewise constant finite element approximations of the control on triangulations of the spatial domain. Second, in the same setting and for suitable sequences of uniformly refined meshes, it is shown that minimizers to discretized PDE-constrained optimal control problems approximate solutions to a continuous limit problem involving an anisotropic total variation reflecting the fine-scale geometry of the mesh. ",
    "url": "https://arxiv.org/abs/2310.19777",
    "authors": [
      "Giacomo Cristinelli",
      "Jos\u00e9 A. Iglesias",
      "Daniel Walter"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.19794",
    "title": "Robust Causal Bandits for Linear Models",
    "abstract": "Sequential design of experiments for optimizing a reward function in causal systems can be effectively modeled by the sequential design of interventions in causal bandits (CBs). In the existing literature on CBs, a critical assumption is that the causal models remain constant over time. However, this assumption does not necessarily hold in complex systems, which constantly undergo temporal model fluctuations. This paper addresses the robustness of CBs to such model fluctuations. The focus is on causal systems with linear structural equation models (SEMs). The SEMs and the time-varying pre- and post-interventional statistical models are all unknown. Cumulative regret is adopted as the design criteria, based on which the objective is to design a sequence of interventions that incur the smallest cumulative regret with respect to an oracle aware of the entire causal model and its fluctuations. First, it is established that the existing approaches fail to maintain regret sub-linearity with even a few instances of model deviation. Specifically, when the number of instances with model deviation is as few as $T^\\frac{1}{2L}$, where $T$ is the time horizon and $L$ is the longest causal path in the graph, the existing algorithms will have linear regret in $T$. Next, a robust CB algorithm is designed, and its regret is analyzed, where upper and information-theoretic lower bounds on the regret are established. Specifically, in a graph with $N$ nodes and maximum degree $d$, under a general measure of model deviation $C$, the cumulative regret is upper bounded by $\\tilde{\\mathcal{O}}(d^{L-\\frac{1}{2}}(\\sqrt{NT} + NC))$ and lower bounded by $\\Omega(d^{\\frac{L}{2}-2}\\max\\{\\sqrt{T},d^2C\\})$. Comparing these bounds establishes that the proposed algorithm achieves nearly optimal $\\tilde{\\mathcal{O}}(\\sqrt{T})$ regret when $C$ is $o(\\sqrt{T})$ and maintains sub-linear regret for a broader range of $C$. ",
    "url": "https://arxiv.org/abs/2310.19794",
    "authors": [
      "Zirui Yan",
      "Arpan Mukherjee",
      "Burak Var\u0131c\u0131",
      "Ali Tajer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1906.03829",
    "title": "Transfer Learning for Hate Speech Detection in Social Media",
    "abstract": " Title: Transfer Learning for Hate Speech Detection in Social Media ",
    "url": "https://arxiv.org/abs/1906.03829",
    "authors": [
      "Lanqin Yuan",
      "Tianyu Wang",
      "Gabriela Ferraro",
      "Hanna Suominen",
      "Marian-Andrei Rizoiu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:1908.08016",
    "title": "Testing Robustness Against Unforeseen Adversaries",
    "abstract": " Comments: Datasets available at this https URL ",
    "url": "https://arxiv.org/abs/1908.08016",
    "authors": [
      "Max Kaufmann",
      "Daniel Kang",
      "Yi Sun",
      "Steven Basart",
      "Xuwang Yin",
      "Mantas Mazeika",
      "Akul Arora",
      "Adam Dziedzic",
      "Franziska Boenisch",
      "Tom Brown",
      "Jacob Steinhardt",
      "Dan Hendrycks"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1909.09485",
    "title": "BSDAR: Beam Search Decoding with Attention Reward in Neural Keyphrase  Generation",
    "abstract": " Comments: arxiv preprint. a preliminary study ",
    "url": "https://arxiv.org/abs/1909.09485",
    "authors": [
      "Iftitahu Ni'mah",
      "Vlado Menkovski",
      "Mykola Pechenizkiy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2011.00446",
    "title": "Efficient Learning of Control Policies for Robust Quadruped Bounding  using Pretrained Neural Networks",
    "abstract": " Comments: 12 pages ",
    "url": "https://arxiv.org/abs/2011.00446",
    "authors": [
      "Zhicheng Wang",
      "Anqiao Li",
      "Yixiao Zheng",
      "Anhuan Xie",
      "Zhibin Li",
      "Jun Wu",
      "Qiuguo Zhu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.02835",
    "title": "On the Role of Entropy-based Loss for Learning Causal Structures with  Continuous Optimization",
    "abstract": " Title: On the Role of Entropy-based Loss for Learning Causal Structures with  Continuous Optimization ",
    "url": "https://arxiv.org/abs/2106.02835",
    "authors": [
      "Weilin Chen",
      "Jie Qiao",
      "Ruichu Cai",
      "Zhifeng Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2106.14186",
    "title": "An XAI Approach to Deep Learning Models in the Detection of DCIS",
    "abstract": " Comments: 12 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2106.14186",
    "authors": [
      "Michele La Ferla",
      "Matthew Montebello",
      "Dylan Seychell"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.11438",
    "title": "A special case of Vu's conjecture: Coloring nearly disjoint graphs of  bounded maximum degree",
    "abstract": " Comments: 16 pages with one-page appendix; final version, to appear in Combinatorics, Probability, and Computing ",
    "url": "https://arxiv.org/abs/2109.11438",
    "authors": [
      "Tom Kelly",
      "Daniela K\u00fchn",
      "Deryk Osthus"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2110.03894",
    "title": "Neural Model Reprogramming with Similarity Based Mapping for  Low-Resource Spoken Command Recognition",
    "abstract": " Comments: Accepted to Interspeech 2023. Code is available at: this https URL Selected as Best Student Paper Candidate ",
    "url": "https://arxiv.org/abs/2110.03894",
    "authors": [
      "Hao Yen",
      "Pin-Jui Ku",
      "Chao-Han Huck Yang",
      "Hu Hu",
      "Sabato Marco Siniscalchi",
      "Pin-Yu Chen",
      "Yu Tsao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2202.06208",
    "title": "Improving Molecular Representation Learning with Metric  Learning-enhanced Optimal Transport",
    "abstract": " Title: Improving Molecular Representation Learning with Metric  Learning-enhanced Optimal Transport ",
    "url": "https://arxiv.org/abs/2202.06208",
    "authors": [
      "Fang Wu",
      "Nicolas Courty",
      "Shuting Jin",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2203.02128",
    "title": "Distributionally Robust Bayesian Optimization with $\\varphi$-divergences",
    "abstract": " Comments: NeurIPS 2023 camera ready paper ",
    "url": "https://arxiv.org/abs/2203.02128",
    "authors": [
      "Hisham Husain",
      "Vu Nguyen",
      "Anton van den Hengel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.03897",
    "title": "Geodesic Multi-Modal Mixup for Robust Fine-Tuning",
    "abstract": " Comments: To appear at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2203.03897",
    "authors": [
      "Changdae Oh",
      "Junhyuk So",
      "Hoyoon Byun",
      "YongTaek Lim",
      "Minchul Shin",
      "Jong-June Jeon",
      "Kyungwoo Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.05145",
    "title": "Cascaded Sparse Feature Propagation Network for Interactive Segmentation",
    "abstract": " Comments: The first two authors contribute equally. Accepted by BMVC 2023 ",
    "url": "https://arxiv.org/abs/2203.05145",
    "authors": [
      "Chuyu Zhang",
      "Chuanyang Hu",
      "Hui Ren",
      "Yongfei Liu",
      "Xuming He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.15529",
    "title": "Treatment Learning Causal Transformer for Noisy Image Classification",
    "abstract": " Comments: Accepted to IEEE WACV 2023. The first version was finished in May 2018 ",
    "url": "https://arxiv.org/abs/2203.15529",
    "authors": [
      "Chao-Han Huck Yang",
      "I-Te Danny Hung",
      "Yi-Chieh Liu",
      "Pin-Yu Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.02341",
    "title": "Complex Locomotion Skill Learning via Differentiable Physics",
    "abstract": " Title: Complex Locomotion Skill Learning via Differentiable Physics ",
    "url": "https://arxiv.org/abs/2206.02341",
    "authors": [
      "Yu Fang",
      "Jiancheng Liu",
      "Mingrui Zhang",
      "Jiasheng Zhang",
      "Yidong Ma",
      "Minchen Li",
      "Yuanming Hu",
      "Chenfanfu Jiang",
      "Tiantian Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07303",
    "title": "Energetic Variational Neural Network Discretizations of Gradient Flows",
    "abstract": " Comments: 27 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2206.07303",
    "authors": [
      "Ziqing Hu",
      "Chun Liu",
      "Yiwei Wang",
      "Zhiliang Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2207.03576",
    "title": "Robustness Evaluation of Deep Unsupervised Learning Algorithms for  Intrusion Detection Systems",
    "abstract": " Comments: Machine Learning for Cybersecurity Workshop at the International Conference on Machine Learning(ICLR-ML4CY) ",
    "url": "https://arxiv.org/abs/2207.03576",
    "authors": [
      "D'Jeff Kanda Nkashama",
      "Arian Soltani",
      "Jean-Charles Verdier",
      "Marc Frappier",
      "Pierre-Martin Tardif",
      "Froduald Kabanza"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.13842",
    "title": "Dive into Machine Learning Algorithms for Influenza Virus Host  Prediction with Hemagglutinin Sequences",
    "abstract": " Comments: Published at BioSystems; V1: minor typo correction ",
    "url": "https://arxiv.org/abs/2207.13842",
    "authors": [
      "Yanhua Xu",
      "Dominik Wojtczak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.04048",
    "title": "Studying Drowsiness Detection Performance while Driving through Scalable  Machine Learning Models using Electroencephalography",
    "abstract": " Title: Studying Drowsiness Detection Performance while Driving through Scalable  Machine Learning Models using Electroencephalography ",
    "url": "https://arxiv.org/abs/2209.04048",
    "authors": [
      "Jos\u00e9 Manuel Hidalgo Rogel",
      "Enrique Tom\u00e1s Mart\u00ednez Beltr\u00e1n",
      "Mario Quiles P\u00e9rez",
      "Sergio L\u00f3pez Bernal",
      "Gregorio Mart\u00ednez P\u00e9rez",
      "Alberto Huertas Celdr\u00e1n"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04074",
    "title": "Are All Steps Equally Important? Benchmarking Essentiality Detection of  Events",
    "abstract": " Comments: EMNLP 2023 ",
    "url": "https://arxiv.org/abs/2210.04074",
    "authors": [
      "Haoyu Wang",
      "Hongming Zhang",
      "Yueguan Wang",
      "Yuqian Deng",
      "Muhao Chen",
      "Dan Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04802",
    "title": "SimSCOOD: Systematic Analysis of Out-of-Distribution Generalization in  Fine-tuned Source Code Models",
    "abstract": " Comments: 19 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2210.04802",
    "authors": [
      "Hossein Hajipour",
      "Ning Yu",
      "Cristian-Alexandru Staicu",
      "Mario Fritz"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2210.12974",
    "title": "Investigating Neuron Disturbing in Fusing Heterogeneous Neural Networks",
    "abstract": " Comments: 16 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2210.12974",
    "authors": [
      "Biao Zhang",
      "Shuqin Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.17122",
    "title": "Mining Word Boundaries in Speech as Naturally Annotated Word  Segmentation Data",
    "abstract": " Comments: latest version ",
    "url": "https://arxiv.org/abs/2210.17122",
    "authors": [
      "Lei Zhang",
      "Zhenghua Li",
      "Shilin Zhou",
      "Chen Gong",
      "Zhefeng Wang",
      "Baoxing Huai",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.09565",
    "title": "Towards Good Practices in Evaluating Transfer Adversarial Attacks",
    "abstract": " Comments: An extended version can be found at arXiv:2310.11850. Code and a list of categorized attacks are available at this https URL ",
    "url": "https://arxiv.org/abs/2211.09565",
    "authors": [
      "Zhengyu Zhao",
      "Hanwei Zhang",
      "Renjue Li",
      "Ronan Sicre",
      "Laurent Amsaleg",
      "Michael Backes"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14646",
    "title": "Towards Improved Input Masking for Convolutional Neural Networks",
    "abstract": " Comments: 29 pages, 19 figures. Accepted at ICCV 2023 ",
    "url": "https://arxiv.org/abs/2211.14646",
    "authors": [
      "Sriram Balasubramanian",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.03447",
    "title": "Integration of Pre-trained Protein Language Models into Geometric Deep  Learning Networks",
    "abstract": " Title: Integration of Pre-trained Protein Language Models into Geometric Deep  Learning Networks ",
    "url": "https://arxiv.org/abs/2212.03447",
    "authors": [
      "Fang Wu",
      "Lirong Wu",
      "Dragomir Radev",
      "Jinbo Xu",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2212.09508",
    "title": "A note on the smallest eigenvalue of the empirical covariance of causal  Gaussian processes",
    "abstract": " Title: A note on the smallest eigenvalue of the empirical covariance of causal  Gaussian processes ",
    "url": "https://arxiv.org/abs/2212.09508",
    "authors": [
      "Ingvar Ziemann"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2212.14424",
    "title": "Normalizing flow neural networks by JKO scheme",
    "abstract": " Comments: NeurIPS 2023 spotlight ",
    "url": "https://arxiv.org/abs/2212.14424",
    "authors": [
      "Chen Xu",
      "Xiuyuan Cheng",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.00278",
    "title": "Isometric path complexity of graphs",
    "abstract": " Comments: A preliminary version appeared in the proceedings of the MFCS 2023 conference ",
    "url": "https://arxiv.org/abs/2301.00278",
    "authors": [
      "Dibyayan Chakraborty",
      "J\u00e9r\u00e9mie Chalopin",
      "Florent Foucaud",
      "Yann Vax\u00e8s"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2301.01597",
    "title": "Problem-Dependent Power of Quantum Neural Networks on Multi-Class  Classification",
    "abstract": " Comments: Updated version. Published on PRL ",
    "url": "https://arxiv.org/abs/2301.01597",
    "authors": [
      "Yuxuan Du",
      "Yibo Yang",
      "Dacheng Tao",
      "Min-Hsiu Hsieh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.05798",
    "title": "Regulating For-Hire Autonomous Vehicles for An Equitable Multimodal  Transportation Network",
    "abstract": " Title: Regulating For-Hire Autonomous Vehicles for An Equitable Multimodal  Transportation Network ",
    "url": "https://arxiv.org/abs/2301.05798",
    "authors": [
      "Jing Gao",
      "Sen Li"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "General Economics (econ.GN)"
    ]
  },
  {
    "id": "arXiv:2301.09028",
    "title": "Characterization and Learning of Causal Graphs with Small Conditioning  Sets",
    "abstract": " Comments: Published in NeurIPS'23. 41 pages ",
    "url": "https://arxiv.org/abs/2301.09028",
    "authors": [
      "Murat Kocaoglu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.11990",
    "title": "Alignment with human representations supports robust few-shot learning",
    "abstract": " Comments: Spotlight at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2301.11990",
    "authors": [
      "Ilia Sucholutsky",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.12321",
    "title": "Neural Relation Graph: A Unified Framework for Identifying Label Noise  and Outlier Data",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2301.12321",
    "authors": [
      "Jang-Hyun Kim",
      "Sangdoo Yun",
      "Hyun Oh Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12549",
    "title": "Unlocking Deterministic Robustness Certification on ImageNet",
    "abstract": " Title: Unlocking Deterministic Robustness Certification on ImageNet ",
    "url": "https://arxiv.org/abs/2301.12549",
    "authors": [
      "Kai Hu",
      "Andy Zou",
      "Zifan Wang",
      "Klas Leino",
      "Matt Fredrikson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.00878",
    "title": "The Contextual Lasso: Sparse Linear Models via Deep Neural Networks",
    "abstract": " Comments: To appear in Advances in Neural Information Processing Systems ",
    "url": "https://arxiv.org/abs/2302.00878",
    "authors": [
      "Ryan Thompson",
      "Amir Dezfouli",
      "Robert Kohn"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2302.01381",
    "title": "Effective Robustness against Natural Distribution Shifts for Models with  Different Training Data",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2302.01381",
    "authors": [
      "Zhouxing Shi",
      "Nicholas Carlini",
      "Ananth Balashankar",
      "Ludwig Schmidt",
      "Cho-Jui Hsieh",
      "Alex Beutel",
      "Yao Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.02560",
    "title": "Causal Estimation of Exposure Shifts with Neural Networks: Evaluating  the Health Benefits of Stricter Air Quality Standards in the US",
    "abstract": " Title: Causal Estimation of Exposure Shifts with Neural Networks: Evaluating  the Health Benefits of Stricter Air Quality Standards in the US ",
    "url": "https://arxiv.org/abs/2302.02560",
    "authors": [
      "Mauricio Tec",
      "Oladimeji Mudele",
      "Kevin Josey",
      "Francesca Dominici"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.04610",
    "title": "Outlier-Robust Gromov-Wasserstein for Graph Data",
    "abstract": " Title: Outlier-Robust Gromov-Wasserstein for Graph Data ",
    "url": "https://arxiv.org/abs/2302.04610",
    "authors": [
      "Lemin Kong",
      "Jiajin Li",
      "Jianheng Tang",
      "Anthony Man-Cho So"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.08643",
    "title": "Fast Temporal Wavelet Graph Neural Networks",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2111.01940 ",
    "url": "https://arxiv.org/abs/2302.08643",
    "authors": [
      "Duc Thien Nguyen",
      "Manh Duc Tuan Nguyen",
      "Truong Son Hy",
      "Risi Kondor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.09267",
    "title": "Stochastic Approximation Approaches to Group Distributionally Robust  Optimization",
    "abstract": " Title: Stochastic Approximation Approaches to Group Distributionally Robust  Optimization ",
    "url": "https://arxiv.org/abs/2302.09267",
    "authors": [
      "Lijun Zhang",
      "Peng Zhao",
      "Zhen-Hua Zhuang",
      "Tianbao Yang",
      "Zhi-Hua Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.14655",
    "title": "A Multifidelity Approach to Robust Orbit Determination",
    "abstract": " Comments: accepted for publication in Acta Astronautica ",
    "url": "https://arxiv.org/abs/2302.14655",
    "authors": [
      "Alberto Foss\u00e0",
      "Roberto Armellin",
      "Emmanuel Delande",
      "Matteo Losacco",
      "Francesco Sanfedino"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2303.01870",
    "title": "Revisiting Adversarial Training for ImageNet: Architectures, Training  and Generalization across Threat Models",
    "abstract": " Comments: Accepted at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2303.01870",
    "authors": [
      "Naman D Singh",
      "Francesco Croce",
      "Matthias Hein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.02014",
    "title": "Summary Statistic Privacy in Data Sharing",
    "abstract": " Title: Summary Statistic Privacy in Data Sharing ",
    "url": "https://arxiv.org/abs/2303.02014",
    "authors": [
      "Zinan Lin",
      "Shuaiqi Wang",
      "Vyas Sekar",
      "Giulia Fanti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06999",
    "title": "Identifying Label Errors in Object Detection Datasets by Loss Inspection",
    "abstract": " Title: Identifying Label Errors in Object Detection Datasets by Loss Inspection ",
    "url": "https://arxiv.org/abs/2303.06999",
    "authors": [
      "Marius Schubert",
      "Tobias Riedlinger",
      "Karsten Kahl",
      "Daniel Kr\u00f6ll",
      "Sebastian Schoenen",
      "Sini\u0161a \u0160egvi\u0107",
      "Matthias Rottmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12175",
    "title": "Black-box Backdoor Defense via Zero-shot Image Purification",
    "abstract": " Comments: Accepted by NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2303.12175",
    "authors": [
      "Yucheng Shi",
      "Mengnan Du",
      "Xuansheng Wu",
      "Zihan Guan",
      "Jin Sun",
      "Ninghao Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.13506",
    "title": "The Quantization Model of Neural Scaling",
    "abstract": " Comments: 24 pages, 18 figures, NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2303.13506",
    "authors": [
      "Eric J. Michaud",
      "Ziming Liu",
      "Uzay Girit",
      "Max Tegmark"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)"
    ]
  },
  {
    "id": "arXiv:2303.16813",
    "title": "Optimal approximation using complex-valued neural networks",
    "abstract": " Comments: accepted at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2303.16813",
    "authors": [
      "Paul Geuchen",
      "Felix Voigtlaender"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.07363",
    "title": "An Integrated Cyber-Physical Risk Assessment Framework for Worst-Case  Attacks in Industrial Control Systems",
    "abstract": " Title: An Integrated Cyber-Physical Risk Assessment Framework for Worst-Case  Attacks in Industrial Control Systems ",
    "url": "https://arxiv.org/abs/2304.07363",
    "authors": [
      "Navid Aftabi",
      "Dan Li",
      "Ph.D.",
      "Thomas Sharkey",
      "Ph.D"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.07441",
    "title": "Fully Scalable Massively Parallel Algorithms for Embedded Planar Graphs",
    "abstract": " Comments: To appear in SODA24. 55 pages, 9 figures, 1 table. Added section on weighted edit distance and shortened abstract ",
    "url": "https://arxiv.org/abs/2304.07441",
    "authors": [
      "Yi-Jun Chang",
      "Da Wei Zheng"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2304.10127",
    "title": "Learning Sample Difficulty from Pre-trained Models for Reliable  Prediction",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2304.10127",
    "authors": [
      "Peng Cui",
      "Dan Zhang",
      "Zhijie Deng",
      "Yinpeng Dong",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.10921",
    "title": "Gradient-Based Distributed Controller Design Over Directed Networks",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2304.10921",
    "authors": [
      "Yuto Watanabe",
      "Kazunori Sakurama",
      "Hyo-Sung Ahn"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.10932",
    "title": "Learning Dictionaries from Physical-Based Interpolation for Water  Network Leak Localization",
    "abstract": " Title: Learning Dictionaries from Physical-Based Interpolation for Water  Network Leak Localization ",
    "url": "https://arxiv.org/abs/2304.10932",
    "authors": [
      "Paul Irofti",
      "Luis Romero-Ben",
      "Florin Stoican",
      "Vicen\u00e7 Puig"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2304.13949",
    "title": "UCF: Uncovering Common Features for Generalizable Deepfake Detection",
    "abstract": " Title: UCF: Uncovering Common Features for Generalizable Deepfake Detection ",
    "url": "https://arxiv.org/abs/2304.13949",
    "authors": [
      "Zhiyuan Yan",
      "Yong Zhang",
      "Yanbo Fan",
      "Baoyuan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.00478",
    "title": "Domain Agnostic Fourier Neural Operators",
    "abstract": " Title: Domain Agnostic Fourier Neural Operators ",
    "url": "https://arxiv.org/abs/2305.00478",
    "authors": [
      "Ning Liu",
      "Siavash Jafarzadeh",
      "Yue Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.06156",
    "title": "The Vault: A Comprehensive Multilingual Dataset for Advancing Code  Understanding and Generation",
    "abstract": " Comments: Accepted at EMNLP 2023, Long Findings ",
    "url": "https://arxiv.org/abs/2305.06156",
    "authors": [
      "Dung Nguyen Manh",
      "Nam Le Hai",
      "Anh T. V. Dau",
      "Anh Minh Nguyen",
      "Khanh Nghiem",
      "Jin Guo",
      "Nghi D. Q. Bui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.06773",
    "title": "Towards a Better Understanding of the Computer Vision Research Community  in Africa",
    "abstract": " Comments: Published in EAAMO'23 under ACM License. This work is part of our African computer vision grassroots research in Ro'ya - CV4Africa, this https URL ",
    "url": "https://arxiv.org/abs/2305.06773",
    "authors": [
      "Abdul-Hakeem Omotayo",
      "Mai Gamal",
      "Eman Ehab",
      "Gbetondji Dovonon",
      "Zainab Akinjobi",
      "Ismaila Lukman",
      "Houcemeddine Turki",
      "Mahmod Abdien",
      "Idriss Tondji",
      "Abigail Oppong",
      "Yvan Pimi",
      "Karim Gamal",
      "Ro'ya-CV4Africa",
      "Mennatullah Siam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08528",
    "title": "NICOL: A Neuro-inspired Collaborative Semi-humanoid Robot that Bridges  Social Interaction and Reliable Manipulation",
    "abstract": " Title: NICOL: A Neuro-inspired Collaborative Semi-humanoid Robot that Bridges  Social Interaction and Reliable Manipulation ",
    "url": "https://arxiv.org/abs/2305.08528",
    "authors": [
      "Matthias Kerzel",
      "Philipp Allgeuer",
      "Erik Strahl",
      "Nicolas Frick",
      "Jan-Gerrit Habekost",
      "Manfred Eppe",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.09821",
    "title": "Single-Photon Counting Receivers for Optical Wireless Communications in  Future 6G Networks",
    "abstract": " Title: Single-Photon Counting Receivers for Optical Wireless Communications in  Future 6G Networks ",
    "url": "https://arxiv.org/abs/2305.09821",
    "authors": [
      "Shenjie Huang",
      "Danial Chitnis",
      "Cheng Chen",
      "Harald Haas",
      "Mohammad-Ali Khalighi",
      "Robert K. Henderson",
      "Majid Safari"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.09956",
    "title": "The Adversarial Consistency of Surrogate Risks for Binary Classification",
    "abstract": " Comments: 17 pages, published in NeurIps 2023. version 2: reorganized Section 4 and added proofs of the approximate complimentary slackness theorems. arXiv admin note: text overlap with arXiv:2206.09099 ",
    "url": "https://arxiv.org/abs/2305.09956",
    "authors": [
      "Natalie Frank",
      "Jonathan Niles-Weed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2305.10037",
    "title": "Can Language Models Solve Graph Problems in Natural Language?",
    "abstract": " Comments: NeurIPS 2023 Spotlight ",
    "url": "https://arxiv.org/abs/2305.10037",
    "authors": [
      "Heng Wang",
      "Shangbin Feng",
      "Tianxing He",
      "Zhaoxuan Tan",
      "Xiaochuang Han",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.11132",
    "title": "Attacks on Online Learners: a Teacher-Student Analysis",
    "abstract": " Comments: 19 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2305.11132",
    "authors": [
      "Riccardo Giuseppe Margiotta",
      "Sebastian Goldt",
      "Guido Sanguinetti"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12467",
    "title": "Understanding Multi-phase Optimization Dynamics and Rich Nonlinear  Behaviors of ReLU Networks",
    "abstract": " Comments: 94 pages, NeurIPS 2023 Spotlight ",
    "url": "https://arxiv.org/abs/2305.12467",
    "authors": [
      "Mingze Wang",
      "Chao Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2305.14286",
    "title": "Equivariant Neural Simulators for Stochastic Spatiotemporal Dynamics",
    "abstract": " Comments: Accepted to NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2305.14286",
    "authors": [
      "Koen Minartz",
      "Yoeri Poels",
      "Simon Koop",
      "Vlado Menkovski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15121",
    "title": "Beyond Individual Input for Deep Anomaly Detection on Tabular Data",
    "abstract": " Title: Beyond Individual Input for Deep Anomaly Detection on Tabular Data ",
    "url": "https://arxiv.org/abs/2305.15121",
    "authors": [
      "Hugo Thimonier",
      "Fabrice Popineau",
      "Arpad Rimmel",
      "Bich-Li\u00ean Doan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15383",
    "title": "On the Minimax Regret for Online Learning with Feedback Graphs",
    "abstract": " Title: On the Minimax Regret for Online Learning with Feedback Graphs ",
    "url": "https://arxiv.org/abs/2305.15383",
    "authors": [
      "Khaled Eldowa",
      "Emmanuel Esposito",
      "Tommaso Cesari",
      "Nicol\u00f2 Cesa-Bianchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15944",
    "title": "How to Turn Your Knowledge Graph Embeddings into Generative Models",
    "abstract": " Title: How to Turn Your Knowledge Graph Embeddings into Generative Models ",
    "url": "https://arxiv.org/abs/2305.15944",
    "authors": [
      "Lorenzo Loconte",
      "Nicola Di Mauro",
      "Robert Peharz",
      "Antonio Vergari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16289",
    "title": "Diversify Your Vision Datasets with Automatic Diffusion-Based  Augmentation",
    "abstract": " Comments: Update: replaced Planes dataset with Waterbirds & updated results after bug fix ",
    "url": "https://arxiv.org/abs/2305.16289",
    "authors": [
      "Lisa Dunlap",
      "Alyssa Umino",
      "Han Zhang",
      "Jiezhi Yang",
      "Joseph E. Gonzalez",
      "Trevor Darrell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16934",
    "title": "On Evaluating Adversarial Robustness of Large Vision-Language Models",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2305.16934",
    "authors": [
      "Yunqing Zhao",
      "Tianyu Pang",
      "Chao Du",
      "Xiao Yang",
      "Chongxuan Li",
      "Ngai-Man Cheung",
      "Min Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2305.16960",
    "title": "Training Socially Aligned Language Models on Simulated Social  Interactions",
    "abstract": " Comments: Code, data, and models can be downloaded via this https URL ",
    "url": "https://arxiv.org/abs/2305.16960",
    "authors": [
      "Ruibo Liu",
      "Ruixin Yang",
      "Chenyan Jia",
      "Ge Zhang",
      "Denny Zhou",
      "Andrew M. Dai",
      "Diyi Yang",
      "Soroush Vosoughi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2305.17225",
    "title": "Causal Component Analysis",
    "abstract": " Comments: NeurIPS 2023 camera-ready version ",
    "url": "https://arxiv.org/abs/2305.17225",
    "authors": [
      "Liang Wendong",
      "Armin Keki\u0107",
      "Julius von K\u00fcgelgen",
      "Simon Buchholz",
      "Michel Besserve",
      "Luigi Gresele",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.18402",
    "title": "Neural Sculpting: Uncovering hierarchically modular task structure in  neural networks through pruning and network analysis",
    "abstract": " Title: Neural Sculpting: Uncovering hierarchically modular task structure in  neural networks through pruning and network analysis ",
    "url": "https://arxiv.org/abs/2305.18402",
    "authors": [
      "Shreyas Malakarjun Patil",
      "Loizos Michael",
      "Constantine Dovrolis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19185",
    "title": "Compression with Bayesian Implicit Neural Representations",
    "abstract": " Comments: Accepted as a Spotlight paper in NeurIPS 2023. Updated camera-ready version ",
    "url": "https://arxiv.org/abs/2305.19185",
    "authors": [
      "Zongyu Guo",
      "Gergely Flamich",
      "Jiajun He",
      "Zhibo Chen",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.19366",
    "title": "Joint Bayesian Inference of Graphical Structure and Parameters with a  Single Generative Flow Network",
    "abstract": " Title: Joint Bayesian Inference of Graphical Structure and Parameters with a  Single Generative Flow Network ",
    "url": "https://arxiv.org/abs/2305.19366",
    "authors": [
      "Tristan Deleu",
      "Mizu Nishikawa-Toomey",
      "Jithendaraa Subramanian",
      "Nikolay Malkin",
      "Laurent Charlin",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.19753",
    "title": "The Tunnel Effect: Building Data Representations in Deep Neural Networks",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2305.19753",
    "authors": [
      "Wojciech Masarczyk",
      "Mateusz Ostaszewski",
      "Ehsan Imani",
      "Razvan Pascanu",
      "Piotr Mi\u0142o\u015b",
      "Tomasz Trzci\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.19818",
    "title": "Spectal Harmonics: Bridging Spectral Embedding and Matrix Completion in  Self-Supervised Learning",
    "abstract": " Comments: 12 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2305.19818",
    "authors": [
      "Marina Munkhoeva",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.20054",
    "title": "UNSSOR: Unsupervised Neural Speech Separation by Leveraging  Over-determined Training Mixtures",
    "abstract": " Comments: in Conference on Neural Information Processing Systems (NeurIPS), 2023 ",
    "url": "https://arxiv.org/abs/2305.20054",
    "authors": [
      "Zhong-Qiu Wang",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.00169",
    "title": "Inconsistency, Instability, and Generalization Gap of Deep Neural  Network Training",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.00169",
    "authors": [
      "Rie Johnson",
      "Tong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.00412",
    "title": "Beamforming Design for IRS-and-UAV-Aided Two-Way Amplify-and-Forward  Relay Networks in Maritime IoT",
    "abstract": " Title: Beamforming Design for IRS-and-UAV-Aided Two-Way Amplify-and-Forward  Relay Networks in Maritime IoT ",
    "url": "https://arxiv.org/abs/2306.00412",
    "authors": [
      "Xuehui Wang",
      "Feng Shu",
      "Yuanyuan Wu",
      "Weiping Shi",
      "Shihao Yan",
      "Yifan Zhao",
      "Qiankun Cheng",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.00542",
    "title": "Nonparametric Identifiability of Causal Representations from Unknown  Interventions",
    "abstract": " Comments: NeurIPS 2023 camera-ready version; 36 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2306.00542",
    "authors": [
      "Julius von K\u00fcgelgen",
      "Michel Besserve",
      "Liang Wendong",
      "Luigi Gresele",
      "Armin Keki\u0107",
      "Elias Bareinboim",
      "David M. Blei",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02014",
    "title": "Uncovering the Hidden Dynamics of Video Self-supervised Learning under  Distribution Shifts",
    "abstract": " Comments: NeurIPS 2023 Spotlight ",
    "url": "https://arxiv.org/abs/2306.02014",
    "authors": [
      "Pritam Sarkar",
      "Ahmad Beirami",
      "Ali Etemad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02049",
    "title": "LambdaBeam: Neural Program Search with Higher-Order Functions and  Lambdas",
    "abstract": " Title: LambdaBeam: Neural Program Search with Higher-Order Functions and  Lambdas ",
    "url": "https://arxiv.org/abs/2306.02049",
    "authors": [
      "Kensen Shi",
      "Hanjun Dai",
      "Wen-Ding Li",
      "Kevin Ellis",
      "Charles Sutton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2306.04949",
    "title": "Robust Learning with Progressive Data Expansion Against Spurious  Correlation",
    "abstract": " Comments: 22 pages, 7 figures, 11 tables. In NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.04949",
    "authors": [
      "Yihe Deng",
      "Yu Yang",
      "Baharan Mirzasoleiman",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.05304",
    "title": "Bayesian Optimisation of Functions on Graphs",
    "abstract": " Comments: NeurIPS 2023. 11 pages, 11 figures, 1 table (29 pages, 31 figures, 1 table including references and appendices) ",
    "url": "https://arxiv.org/abs/2306.05304",
    "authors": [
      "Xingchen Wan",
      "Pierre Osselin",
      "Henry Kenlay",
      "Binxin Ru",
      "Michael A. Osborne",
      "Xiaowen Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.05587",
    "title": "MC-NN: An End-to-End Multi-Channel Neural Network Approach for  Predicting Influenza A Virus Hosts and Antigenic Types",
    "abstract": " Comments: Accepted version submitted to the SN Computer Science; Published in the SN Computer Science 2023; V1: minor updates were made to the Results section ",
    "url": "https://arxiv.org/abs/2306.05587",
    "authors": [
      "Yanhua Xu",
      "Dominik Wojtczak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2306.06155",
    "title": "Intensity Profile Projection: A Framework for Continuous-Time  Representation Learning for Dynamic Networks",
    "abstract": " Comments: 37 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2306.06155",
    "authors": [
      "Alexander Modell",
      "Ian Gallagher",
      "Emma Ceccherini",
      "Nick Whiteley",
      "Patrick Rubin-Delanchy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.06203",
    "title": "FLSL: Feature-level Self-supervised Learning",
    "abstract": " Title: FLSL: Feature-level Self-supervised Learning ",
    "url": "https://arxiv.org/abs/2306.06203",
    "authors": [
      "Qing Su",
      "Anton Netchaev",
      "Hai Li",
      "Shihao Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.06230",
    "title": "Design Frameworks for Hyper-Connected Social XRI Immersive Metaverse  Environments",
    "abstract": " Title: Design Frameworks for Hyper-Connected Social XRI Immersive Metaverse  Environments ",
    "url": "https://arxiv.org/abs/2306.06230",
    "authors": [
      "Jie Guan",
      "Alexis Morris"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2306.06529",
    "title": "Neural Injective Functions for Multisets, Measures and Graphs via a  Finite Witness Theorem",
    "abstract": " Comments: NeurIPS 2023 camera-ready ",
    "url": "https://arxiv.org/abs/2306.06529",
    "authors": [
      "Tal Amir",
      "Steven J. Gortler",
      "Ilai Avni",
      "Ravina Ravina",
      "Nadav Dym"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06805",
    "title": "Unlocking Feature Visualization for Deeper Networks with MAgnitude  Constrained Optimization",
    "abstract": " Title: Unlocking Feature Visualization for Deeper Networks with MAgnitude  Constrained Optimization ",
    "url": "https://arxiv.org/abs/2306.06805",
    "authors": [
      "Thomas Fel",
      "Thibaut Boissin",
      "Victor Boutin",
      "Agustin Picard",
      "Paul Novello",
      "Julien Colin",
      "Drew Linsley",
      "Tom Rousseau",
      "R\u00e9mi Cad\u00e8ne",
      "Laurent Gardes",
      "Thomas Serre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.08943",
    "title": "Neural Fields with Hard Constraints of Arbitrary Differential Order",
    "abstract": " Comments: 37th Conference on Neural Information Processing Systems (NeurIPS 2023) ",
    "url": "https://arxiv.org/abs/2306.08943",
    "authors": [
      "Fangcheng Zhong",
      "Kyle Fogarty",
      "Param Hanji",
      "Tianhao Wu",
      "Alejandro Sztrajman",
      "Andrew Spielberg",
      "Andrea Tagliasacchi",
      "Petra Bosilj",
      "Cengiz Oztireli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.09335",
    "title": "Class-Conditional Conformal Prediction with Many Classes",
    "abstract": " Title: Class-Conditional Conformal Prediction with Many Classes ",
    "url": "https://arxiv.org/abs/2306.09335",
    "authors": [
      "Tiffany Ding",
      "Anastasios N. Angelopoulos",
      "Stephen Bates",
      "Michael I. Jordan",
      "Ryan J. Tibshirani"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2306.09818",
    "title": "HiNeRV: Video Compression with Hierarchical Encoding-based Neural  Representation",
    "abstract": " Title: HiNeRV: Video Compression with Hierarchical Encoding-based Neural  Representation ",
    "url": "https://arxiv.org/abs/2306.09818",
    "authors": [
      "Ho Man Kwan",
      "Ge Gao",
      "Fan Zhang",
      "Andrew Gower",
      "David Bull"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.10168",
    "title": "Beyond Geometry: Comparing the Temporal Structure of Computation in  Neural Circuits with Dynamical Similarity Analysis",
    "abstract": " Comments: 22 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2306.10168",
    "authors": [
      "Mitchell Ostrow",
      "Adam Eisen",
      "Leo Kozachkov",
      "Ila Fiete"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2306.10608",
    "title": "STHG: Spatial-Temporal Heterogeneous Graph Learning for Advanced  Audio-Visual Diarization",
    "abstract": " Comments: Validation report for the Ego4D challenge at CVPR 2023 ",
    "url": "https://arxiv.org/abs/2306.10608",
    "authors": [
      "Kyle Min"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.10890",
    "title": "QoS-Aware Downlink Beamforming for Joint Transmission in Multi-Cell  Networks",
    "abstract": " Title: QoS-Aware Downlink Beamforming for Joint Transmission in Multi-Cell  Networks ",
    "url": "https://arxiv.org/abs/2306.10890",
    "authors": [
      "Chen-Yen Lin",
      "Kuang-Hao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2306.11839",
    "title": "Should I Stop or Should I Go: Early Stopping with Heterogeneous  Populations",
    "abstract": " Comments: NeurIPS 2023 (spotlight) ",
    "url": "https://arxiv.org/abs/2306.11839",
    "authors": [
      "Hammaad Adam",
      "Fan Yin",
      "Huibin",
      "Neil Tenenholtz",
      "Lorin Crawford",
      "Lester Mackey",
      "Allison Koenecke"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.14818",
    "title": "Accelerating Molecular Graph Neural Networks via Knowledge Distillation",
    "abstract": " Comments: Accepted as a conference paper at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.14818",
    "authors": [
      "Filip Ekstr\u00f6m Kelvinius",
      "Dimitar Georgiev",
      "Artur Petrov Toshev",
      "Johannes Gasteiger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2306.17283",
    "title": "A Neural Separation Algorithm for the Rounded Capacity Inequalities",
    "abstract": " Title: A Neural Separation Algorithm for the Rounded Capacity Inequalities ",
    "url": "https://arxiv.org/abs/2306.17283",
    "authors": [
      "Hyeonah Kim",
      "Jinkyoo Park",
      "Changhyun Kwon"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2307.00134",
    "title": "Generalization Limits of Graph Neural Networks in Identity Effects  Learning",
    "abstract": " Comments: 13 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2307.00134",
    "authors": [
      "Giuseppe Alessio D'Inverno",
      "Simone Brugiapaglia",
      "Mirco Ravanelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.01426",
    "title": "DeepfakeBench: A Comprehensive Benchmark of Deepfake Detection",
    "abstract": " Title: DeepfakeBench: A Comprehensive Benchmark of Deepfake Detection ",
    "url": "https://arxiv.org/abs/2307.01426",
    "authors": [
      "Zhiyuan Yan",
      "Yong Zhang",
      "Xinhang Yuan",
      "Siwei Lyu",
      "Baoyuan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.04284",
    "title": "Effects of Network Connectivity and Functional Diversity Distribution on  Human Collective Ideation",
    "abstract": " Comments: 44 pages, 19 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2307.04284",
    "authors": [
      "Yiding Cao",
      "Yingjun Dong",
      "Minjun Kim",
      "Neil G. MacLaren",
      "Sriniwas Pandey",
      "Shelley D. Dionne",
      "Francis J. Yammarino",
      "Hiroki Sayama"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2307.04333",
    "title": "Enhancing Adversarial Robustness via Score-Based Optimization",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2307.04333",
    "authors": [
      "Boya Zhang",
      "Weijian Luo",
      "Zhihua Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.05397",
    "title": "On the Vulnerability of DeepFake Detectors to Attacks Generated by  Denoising Diffusion Models",
    "abstract": " Comments: Submitted for review ",
    "url": "https://arxiv.org/abs/2307.05397",
    "authors": [
      "Marija Ivanovska",
      "Vitomir \u0160truc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.06290",
    "title": "Instruction Mining: When Data Mining Meets Large Language Model  Finetuning",
    "abstract": " Comments: 22 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2307.06290",
    "authors": [
      "Yihan Cao",
      "Yanbin Kang",
      "Chi Wang",
      "Lichao Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.06775",
    "title": "A Novel Site-Agnostic Multimodal Deep Learning Model to Identify  Pro-Eating Disorder Content on Social Media",
    "abstract": " Title: A Novel Site-Agnostic Multimodal Deep Learning Model to Identify  Pro-Eating Disorder Content on Social Media ",
    "url": "https://arxiv.org/abs/2307.06775",
    "authors": [
      "Jonathan Feldman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2307.07288",
    "title": "Implicit Neural Feature Fusion Function for Multispectral and  Hyperspectral Image Fusion",
    "abstract": " Title: Implicit Neural Feature Fusion Function for Multispectral and  Hyperspectral Image Fusion ",
    "url": "https://arxiv.org/abs/2307.07288",
    "authors": [
      "ShangQi Deng",
      "RuoCheng Wu",
      "Liang-Jian Deng",
      "Ran Ran",
      "Gemine Vivone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.08452",
    "title": "SBMLtoODEjax: Efficient Simulation and Optimization of Biological  Network Models in JAX",
    "abstract": " Title: SBMLtoODEjax: Efficient Simulation and Optimization of Biological  Network Models in JAX ",
    "url": "https://arxiv.org/abs/2307.08452",
    "authors": [
      "Mayalen Etcheverry",
      "Michael Levin",
      "Cl\u00e9ment Moulin-Frier",
      "Pierre-Yves Oudeyer"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2307.08657",
    "title": "Neural Image Compression: Generalization, Robustness, and Spectral  Biases",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2307.08657",
    "authors": [
      "Kelsey Lieberman",
      "James Diffenderfer",
      "Charles Godfrey",
      "Bhavya Kailkhura"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08763",
    "title": "Video-Mined Task Graphs for Keystep Recognition in Instructional Videos",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2307.08763",
    "authors": [
      "Kumar Ashutosh",
      "Santhosh Kumar Ramakrishnan",
      "Triantafyllos Afouras",
      "Kristen Grauman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.00186",
    "title": "Learning Complex Motion Plans using Neural ODEs with Safety and  Stability Guarantees",
    "abstract": " Title: Learning Complex Motion Plans using Neural ODEs with Safety and  Stability Guarantees ",
    "url": "https://arxiv.org/abs/2308.00186",
    "authors": [
      "Farhad Nawaz",
      "Tianyu Li",
      "Nikolai Matni",
      "Nadia Figueroa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.05309",
    "title": "Homophily-enhanced Structure Learning for Graph Clustering",
    "abstract": " Comments: 11 pages with 7 figures. Accepted by CIKM'23 ",
    "url": "https://arxiv.org/abs/2308.05309",
    "authors": [
      "Ming Gu",
      "Gaoming Yang",
      "Sheng Zhou",
      "Ning Ma",
      "Jiawei Chen",
      "Qiaoyu Tan",
      "Meihan Liu",
      "Jiajun Bu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.06483",
    "title": "BigWavGAN: A Wave-To-Wave Generative Adversarial Network for Music  Super-Resolution",
    "abstract": " Comments: Accepted by IEEE GCCE 2023 ",
    "url": "https://arxiv.org/abs/2308.06483",
    "authors": [
      "Yenan Zhang",
      "Hiroshi Watanabe"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.14113",
    "title": "Semantic-aware Consistency Network for Cloth-changing Person  Re-Identification",
    "abstract": " Comments: Accepted by ACM MM 2023 ",
    "url": "https://arxiv.org/abs/2308.14113",
    "authors": [
      "Peini Guo",
      "Hong Liu",
      "Jianbing Wu",
      "Guoquan Wang",
      "Tao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14847",
    "title": "NSF: Neural Surface Fields for Human Modeling from Monocular Depth",
    "abstract": " Comments: Accpted to ICCV 2023; Homepage at: this https URL ",
    "url": "https://arxiv.org/abs/2308.14847",
    "authors": [
      "Yuxuan Xue",
      "Bharat Lal Bhatnagar",
      "Riccardo Marin",
      "Nikolaos Sarafianos",
      "Yuanlu Xu",
      "Gerard Pons-Moll",
      "Tony Tung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.14864",
    "title": "NAS-X: Neural Adaptive Smoothing via Twisting",
    "abstract": " Comments: Updating for clarity and adding new baselines ",
    "url": "https://arxiv.org/abs/2308.14864",
    "authors": [
      "Dieterich Lawson",
      "Michael Li",
      "Scott Linderman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.16573",
    "title": "Dual-Decoder Consistency via Pseudo-Labels Guided Data Augmentation for  Semi-Supervised Medical Image Segmentation",
    "abstract": " Title: Dual-Decoder Consistency via Pseudo-Labels Guided Data Augmentation for  Semi-Supervised Medical Image Segmentation ",
    "url": "https://arxiv.org/abs/2308.16573",
    "authors": [
      "Yuanbin Chen",
      "Tao Wang",
      "Hui Tang",
      "Longxuan Zhao",
      "Ruige Zong",
      "Shun Chen",
      "Tao Tan",
      "Xinlin Zhang",
      "Tong Tong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.00073",
    "title": "Diffusion Variational Autoencoder for Tackling Stochasticity in  Multi-Step Regression Stock Price Prediction",
    "abstract": " Comments: CIKM 2023 ",
    "url": "https://arxiv.org/abs/2309.00073",
    "authors": [
      "Kelvin J.L. Koa",
      "Yunshan Ma",
      "Ritchie Ng",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)"
    ]
  },
  {
    "id": "arXiv:2309.01903",
    "title": "Towards Robust Plant Disease Diagnosis with Hard-sample Re-mining  Strategy",
    "abstract": " Title: Towards Robust Plant Disease Diagnosis with Hard-sample Re-mining  Strategy ",
    "url": "https://arxiv.org/abs/2309.01903",
    "authors": [
      "Quan Huu Cap",
      "Atsushi Fukuda",
      "Satoshi Kagiwada",
      "Hiroyuki Uga",
      "Nobusuke Iwasaki",
      "Hitoshi Iyatomi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.02460",
    "title": "Effective Multi-Graph Neural Networks for Illicit Account Detection on  Cryptocurrency Transaction Networks",
    "abstract": " Title: Effective Multi-Graph Neural Networks for Illicit Account Detection on  Cryptocurrency Transaction Networks ",
    "url": "https://arxiv.org/abs/2309.02460",
    "authors": [
      "Zhihao Ding",
      "Jieming Shi",
      "Qing Li",
      "Jiannong Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.03329",
    "title": "MEGANet: Multi-Scale Edge-Guided Attention Network for Weak Boundary  Polyp Segmentation",
    "abstract": " Comments: Accepted at the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2024) ",
    "url": "https://arxiv.org/abs/2309.03329",
    "authors": [
      "Nhat-Tan Bui",
      "Dinh-Hieu Hoang",
      "Quang-Thuc Nguyen",
      "Minh-Triet Tran",
      "Ngan Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.03800",
    "title": "Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and  Luck",
    "abstract": " Comments: v2: NeurIPS 2023 camera-ready updates ",
    "url": "https://arxiv.org/abs/2309.03800",
    "authors": [
      "Benjamin L. Edelman",
      "Surbhi Goel",
      "Sham Kakade",
      "Eran Malach",
      "Cyril Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.03875",
    "title": "Network Sampling Methods for Estimating Social Networks, Population  Percentages, and Totals of People Experiencing Unsheltered Homelessness",
    "abstract": " Title: Network Sampling Methods for Estimating Social Networks, Population  Percentages, and Totals of People Experiencing Unsheltered Homelessness ",
    "url": "https://arxiv.org/abs/2309.03875",
    "authors": [
      "Zack W. Almquist",
      "Ashley Hazel",
      "Owen Kajfasz",
      "Janelle Rothfolk",
      "Claire Guilmette",
      "Mary-Catherine Anderson",
      "Larisa Ozeryansky",
      "Amy Hagopian"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2309.05994",
    "title": "ATTA: Anomaly-aware Test-Time Adaptation for Out-of-Distribution  Detection in Segmentation",
    "abstract": " Comments: Published in NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2309.05994",
    "authors": [
      "Zhitong Gao",
      "Shipeng Yan",
      "Xuming He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.08036",
    "title": "BEA: Revisiting anchor-based object detection DNN using Budding Ensemble  Architecture",
    "abstract": " Comments: 14 pages, 5 pages supplementary material. Accepted at BMVC-2023 ",
    "url": "https://arxiv.org/abs/2309.08036",
    "authors": [
      "Syed Sha Qutub",
      "Neslihan Kose",
      "Rafael Rosales",
      "Michael Paulitsch",
      "Korbinian Hagn",
      "Florian Geissler",
      "Yang Peng",
      "Gereon Hinz",
      "Alois Knoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.10987",
    "title": "SpikingNeRF: Making Bio-inspired Neural Networks See through the Real  World",
    "abstract": " Title: SpikingNeRF: Making Bio-inspired Neural Networks See through the Real  World ",
    "url": "https://arxiv.org/abs/2309.10987",
    "authors": [
      "Xingting Yao",
      "Qinghao Hu",
      "Tielong Liu",
      "Zitao Mo",
      "Zeyu Zhu",
      "Zhengyang Zhuge",
      "Jian Cheng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.11523",
    "title": "RMT: Retentive Networks Meet Vision Transformers",
    "abstract": " Comments: Code will be released at this https URL ",
    "url": "https://arxiv.org/abs/2309.11523",
    "authors": [
      "Qihang Fan",
      "Huaibo Huang",
      "Mingrui Chen",
      "Hongmin Liu",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13591",
    "title": "Robust Distributed Learning: Tight Error Bounds and Breakdown Point  under Data Heterogeneity",
    "abstract": " Comments: Accepted to NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2309.13591",
    "authors": [
      "Youssef Allouah",
      "Rachid Guerraoui",
      "Nirupam Gupta",
      "Rafa\u00ebl Pinot",
      "Geovani Rizk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2309.13944",
    "title": "Provable Training for Graph Contrastive Learning",
    "abstract": " Comments: NeurIPS 2023 spotlight. Camera-ready version ",
    "url": "https://arxiv.org/abs/2309.13944",
    "authors": [
      "Yue Yu",
      "Xiao Wang",
      "Mengmei Zhang",
      "Nian Liu",
      "Chuan Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.15376",
    "title": "ADGym: Design Choices for Deep Anomaly Detection",
    "abstract": " Comments: NeurIPS 2023. The first three authors contribute equally. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2309.15376",
    "authors": [
      "Minqi Jiang",
      "Chaochuan Hou",
      "Ao Zheng",
      "Songqiao Han",
      "Hailiang Huang",
      "Qingsong Wen",
      "Xiyang Hu",
      "Yue Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00402",
    "title": "DiskANN++: Efficient Page-based Search over Isomorphic Mapped Graph  Index using Query-sensitivity Entry Vertex",
    "abstract": " Comments: 14 pages including references, 9 figures ",
    "url": "https://arxiv.org/abs/2310.00402",
    "authors": [
      "Jiongkang Ni",
      "Xiaoliang Xu",
      "Yuxiang Wang",
      "Can Li",
      "Jiajie Yao",
      "Shihai Xiao",
      "Xuecang Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2310.00431",
    "title": "ResolvNet: A Graph Convolutional Network with multi-scale Consistency",
    "abstract": " Title: ResolvNet: A Graph Convolutional Network with multi-scale Consistency ",
    "url": "https://arxiv.org/abs/2310.00431",
    "authors": [
      "Christian Koke",
      "Abhishek Saroha",
      "Yuesong Shen",
      "Marvin Eisenberger",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.03274",
    "title": "Fragment-based Pretraining and Finetuning on Molecular Graphs",
    "abstract": " Comments: 18 pages, 4 figures, published in NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2310.03274",
    "authors": [
      "Kha-Dinh Luong",
      "Ambuj Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05378",
    "title": "Transcending the Attention Paradigm: Representation Learning from  Geospatial Social Media Data",
    "abstract": " Title: Transcending the Attention Paradigm: Representation Learning from  Geospatial Social Media Data ",
    "url": "https://arxiv.org/abs/2310.05378",
    "authors": [
      "Nick DiSanto",
      "Anthony Corso",
      "Benjamin Sanders",
      "Gavin Harding"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.06182",
    "title": "PAC-Bayesian Spectrally-Normalized Bounds for Adversarially Robust  Generalization",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2310.06182",
    "authors": [
      "Jiancong Xiao",
      "Ruoyu Sun",
      "Zhi- Quan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.08800",
    "title": "DDMT: Denoising Diffusion Mask Transformer Models for Multivariate Time  Series Anomaly Detection",
    "abstract": " Comments: 16 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2310.08800",
    "authors": [
      "Chaocheng Yang",
      "Tingyin Wang",
      "Xuanhui Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.10121",
    "title": "From Continuous Dynamics to Graph Neural Networks: Neural Diffusion and  Beyond",
    "abstract": " Title: From Continuous Dynamics to Graph Neural Networks: Neural Diffusion and  Beyond ",
    "url": "https://arxiv.org/abs/2310.10121",
    "authors": [
      "Andi Han",
      "Dai Shi",
      "Lequan Lin",
      "Junbin Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.10893",
    "title": "Active Learning Framework for Cost-Effective TCR-Epitope Binding  Affinity Prediction",
    "abstract": " Comments: 10 pages, 7 figures, this paper has been accepted for publication in the proceedings of the IEEE International Conference on Bioinformatics and Biomedicine (BIBM) 2023 ",
    "url": "https://arxiv.org/abs/2310.10893",
    "authors": [
      "Pengfei Zhang",
      "Seojin Bang",
      "Heewook Lee"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.11166",
    "title": "ViSoBERT: A Pre-Trained Language Model for Vietnamese Social Media Text  Processing",
    "abstract": " Comments: Accepted at EMNLP'2023 Main Conference ",
    "url": "https://arxiv.org/abs/2310.11166",
    "authors": [
      "Quoc-Nam Nguyen",
      "Thang Chau Phan",
      "Duc-Vu Nguyen",
      "Kiet Van Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.12671",
    "title": "Neural networks for insurance pricing with frequency and severity data:  a benchmark study from data preprocessing to technical tariff",
    "abstract": " Title: Neural networks for insurance pricing with frequency and severity data:  a benchmark study from data preprocessing to technical tariff ",
    "url": "https://arxiv.org/abs/2310.12671",
    "authors": [
      "Freek Holvoet",
      "Katrien Antonio",
      "Roel Henckaerts"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Risk Management (q-fin.RM)"
    ]
  },
  {
    "id": "arXiv:2310.13019",
    "title": "Tailoring Adversarial Attacks on Deep Neural Networks for Targeted Class  Manipulation Using DeepFool Algorithm",
    "abstract": " Comments: 8 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2310.13019",
    "authors": [
      "S. M. Fazle Rabby Labib",
      "Joyanta Jyoti Mondal",
      "Meem Arafat Manab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.13388",
    "title": "Music Augmentation and Denoising For Peak-Based Audio Fingerprinting",
    "abstract": " Title: Music Augmentation and Denoising For Peak-Based Audio Fingerprinting ",
    "url": "https://arxiv.org/abs/2310.13388",
    "authors": [
      "Kamil Akesbi",
      "Dorian Desblancs",
      "Benjamin Martin"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.13981",
    "title": "Filling the Missing: Exploring Generative AI for Enhanced Federated  Learning over Heterogeneous Mobile Edge Devices",
    "abstract": " Comments: 13 pages, 5 figures. Submitted to IEEE for possible publication ",
    "url": "https://arxiv.org/abs/2310.13981",
    "authors": [
      "Peichun Li",
      "Hanwen Zhang",
      "Yuan Wu",
      "Liping Qian",
      "Rong Yu",
      "Dusit Niyato",
      "Xuemin Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.14009",
    "title": "One is More: Diverse Perspectives within a Single Network for Efficient  DRL",
    "abstract": " Comments: Preprint ",
    "url": "https://arxiv.org/abs/2310.14009",
    "authors": [
      "Yiqin Tan",
      "Ling Pan",
      "Longbo Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.14736",
    "title": "SAMCLR: Contrastive pre-training on complex scenes using SAM for view  sampling",
    "abstract": " Comments: Accepted at NeurIPS 2023 Workshop on SSL ",
    "url": "https://arxiv.org/abs/2310.14736",
    "authors": [
      "Benjamin Missaoui",
      "Chongbin Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.15342",
    "title": "Towards Hybrid-grained Feature Interaction Selection for Deep Sparse  Network",
    "abstract": " Comments: NeurIPS 2023 poster ",
    "url": "https://arxiv.org/abs/2310.15342",
    "authors": [
      "Fuyuan Lyu",
      "Xing Tang",
      "Dugang Liu",
      "Chen Ma",
      "Weihong Luo",
      "Liang Chen",
      "Xiuqiang He",
      "Xue Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.15478",
    "title": "How to Train Your Neural Control Barrier Function: Learning Safety  Filters for Complex Input-Constrained Systems",
    "abstract": " Comments: Submitted to ICRA 2024. Project page can be found at this https URL ",
    "url": "https://arxiv.org/abs/2310.15478",
    "authors": [
      "Oswin So",
      "Zachary Serlin",
      "Makai Mann",
      "Jake Gonzales",
      "Kwesi Rutledge",
      "Nicholas Roy",
      "Chuchu Fan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.16105",
    "title": "Locally Differentially Private Gradient Tracking for Distributed Online  Learning over Directed Graphs",
    "abstract": " Comments: 21 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2310.16105",
    "authors": [
      "Ziqin Chen",
      "Yongqiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16401",
    "title": "Graph Neural Networks with a Distribution of Parametrized Graphs",
    "abstract": " Title: Graph Neural Networks with a Distribution of Parametrized Graphs ",
    "url": "https://arxiv.org/abs/2310.16401",
    "authors": [
      "See Hian Lee",
      "Feng Ji",
      "Kelin Xia",
      "Wee Peng Tay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16831",
    "title": "PERF: Panoramic Neural Radiance Field from a Single Panorama",
    "abstract": " Comments: Project Page: this https URL , Code: this https URL ",
    "url": "https://arxiv.org/abs/2310.16831",
    "authors": [
      "Guangcong Wang",
      "Peng Wang",
      "Zhaoxi Chen",
      "Wenping Wang",
      "Chen Change Loy",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16999",
    "title": "Trust, but Verify: Robust Image Segmentation using Deep Learning",
    "abstract": " Comments: 5 Pages, 8 Figures, conference ",
    "url": "https://arxiv.org/abs/2310.16999",
    "authors": [
      "Fahim Ahmed Zaman",
      "Xiaodong Wu",
      "Weiyu Xu",
      "Milan Sonka",
      "Raghuraman Mudumbai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.17015",
    "title": "Data Augmentation for Emotion Detection in Small Imbalanced Text Data",
    "abstract": " Comments: To be published in the Proceedings of the 22nd IEEE International Conference on Machine Learning Applications (ICMLA 2023) ",
    "url": "https://arxiv.org/abs/2310.17015",
    "authors": [
      "Anna Koufakou",
      "Diego Grisales",
      "Ragy Costa de jesus",
      "Oscar Fox"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.17493",
    "title": "A Hybrid Graph Network for Complex Activity Detection in Video",
    "abstract": " Comments: This paper is Accepted at WACV 2024 ",
    "url": "https://arxiv.org/abs/2310.17493",
    "authors": [
      "Salman Khan",
      "Izzeddin Teeti",
      "Andrew Bradley",
      "Mohamed Elhoseiny",
      "Fabio Cuzzolin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.17796",
    "title": "ControlLLM: Augment Language Models with Tools by Searching on Graphs",
    "abstract": " Comments: 22 pages, 9 figures, 10 tables ",
    "url": "https://arxiv.org/abs/2310.17796",
    "authors": [
      "Zhaoyang Liu",
      "Zeqiang Lai",
      "Zhangwei Gao",
      "Erfei Cui",
      "Zhiheng Li",
      "Xizhou Zhu",
      "Lewei Lu",
      "Qifeng Chen",
      "Yu Qiao",
      "Jifeng Dai",
      "Wenhai Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2310.17952",
    "title": "Shape-centered Representation Learning for Visible-Infrared Person  Re-identification",
    "abstract": " Title: Shape-centered Representation Learning for Visible-Infrared Person  Re-identification ",
    "url": "https://arxiv.org/abs/2310.17952",
    "authors": [
      "Shuang Li",
      "Jiaxu Leng",
      "Ji Gan",
      "Mengjingcheng Mo",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18237",
    "title": "Generative AI Model for Artistic Style Transfer Using Convolutional  Neural Networks",
    "abstract": " Comments: Incorrectly Input ",
    "url": "https://arxiv.org/abs/2310.18237",
    "authors": [
      "Jonayet Miah",
      "Duc M Cao",
      "Md Abu Sayed",
      "Md. Sabbirul Haque"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  }
]