[
  {
    "id": "arXiv:2310.15195",
    "title": "Neural Multi-Objective Combinatorial Optimization with Diversity  Enhancement",
    "abstract": "Most of existing neural methods for multi-objective combinatorial optimization (MOCO) problems solely rely on decomposition, which often leads to repetitive solutions for the respective subproblems, thus a limited Pareto set. Beyond decomposition, we propose a novel neural heuristic with diversity enhancement (NHDE) to produce more Pareto solutions from two perspectives. On the one hand, to hinder duplicated solutions for different subproblems, we propose an indicator-enhanced deep reinforcement learning method to guide the model, and design a heterogeneous graph attention mechanism to capture the relations between the instance graph and the Pareto front graph. On the other hand, to excavate more solutions in the neighborhood of each subproblem, we present a multiple Pareto optima strategy to sample and preserve desirable solutions. Experimental results on classic MOCO problems show that our NHDE is able to generate a Pareto front with higher diversity, thereby achieving superior overall performance. Moreover, our NHDE is generic and can be applied to different neural methods for MOCO. ",
    "url": "https://arxiv.org/abs/2310.15195",
    "authors": [
      "Jinbiao Chen",
      "Zizhen Zhang",
      "Zhiguang Cao",
      "Yaoxin Wu",
      "Yining Ma",
      "Te Ye",
      "Jiahai Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.15196",
    "title": "Efficient Meta Neural Heuristic for Multi-Objective Combinatorial  Optimization",
    "abstract": "Recently, neural heuristics based on deep reinforcement learning have exhibited promise in solving multi-objective combinatorial optimization problems (MOCOPs). However, they are still struggling to achieve high learning efficiency and solution quality. To tackle this issue, we propose an efficient meta neural heuristic (EMNH), in which a meta-model is first trained and then fine-tuned with a few steps to solve corresponding single-objective subproblems. Specifically, for the training process, a (partial) architecture-shared multi-task model is leveraged to achieve parallel learning for the meta-model, so as to speed up the training; meanwhile, a scaled symmetric sampling method with respect to the weight vectors is designed to stabilize the training. For the fine-tuning process, an efficient hierarchical method is proposed to systematically tackle all the subproblems. Experimental results on the multi-objective traveling salesman problem (MOTSP), multi-objective capacitated vehicle routing problem (MOCVRP), and multi-objective knapsack problem (MOKP) show that, EMNH is able to outperform the state-of-the-art neural heuristics in terms of solution quality and learning efficiency, and yield competitive solutions to the strong traditional heuristics while consuming much shorter time. ",
    "url": "https://arxiv.org/abs/2310.15196",
    "authors": [
      "Jinbiao Chen",
      "Jiahai Wang",
      "Zizhen Zhang",
      "Zhiguang Cao",
      "Te Ye",
      "Siyuan Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.15204",
    "title": "Mid-Long Term Daily Electricity Consumption Forecasting Based on  Piecewise Linear Regression and Dilated Causal CNN",
    "abstract": "Daily electricity consumption forecasting is a classical problem. Existing forecasting algorithms tend to have decreased accuracy on special dates like holidays. This study decomposes the daily electricity consumption series into three components: trend, seasonal, and residual, and constructs a two-stage prediction method using piecewise linear regression as a filter and Dilated Causal CNN as a predictor. The specific steps involve setting breakpoints on the time axis and fitting the piecewise linear regression model with one-hot encoded information such as month, weekday, and holidays. For the challenging prediction of the Spring Festival, distance is introduced as a variable using a third-degree polynomial form in the model. The residual sequence obtained in the previous step is modeled using Dilated Causal CNN, and the final prediction of daily electricity consumption is the sum of the two-stage predictions. Experimental results demonstrate that this method achieves higher accuracy compared to existing approaches. ",
    "url": "https://arxiv.org/abs/2310.15204",
    "authors": [
      "Zhou Lan",
      "Ben Liu",
      "Yi Feng",
      "Danhuang Dong",
      "Peng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15261",
    "title": "Modality Dropout for Multimodal Device Directed Speech Detection using  Verbal and Non-Verbal Features",
    "abstract": "Device-directed speech detection (DDSD) is the binary classification task of distinguishing between queries directed at a voice assistant versus side conversation or background speech. State-of-the-art DDSD systems use verbal cues, e.g acoustic, text and/or automatic speech recognition system (ASR) features, to classify speech as device-directed or otherwise, and often have to contend with one or more of these modalities being unavailable when deployed in real-world settings. In this paper, we investigate fusion schemes for DDSD systems that can be made more robust to missing modalities. Concurrently, we study the use of non-verbal cues, specifically prosody features, in addition to verbal cues for DDSD. We present different approaches to combine scores and embeddings from prosody with the corresponding verbal cues, finding that prosody improves DDSD performance by upto 8.5% in terms of false acceptance rate (FA) at a given fixed operating point via non-linear intermediate fusion, while our use of modality dropout techniques improves the performance of these models by 7.4% in terms of FA when evaluated with missing modalities during inference time. ",
    "url": "https://arxiv.org/abs/2310.15261",
    "authors": [
      "Gautam Krishna",
      "Sameer Dharur",
      "Oggi Rudovic",
      "Pranay Dighe",
      "Saurabh Adya",
      "Ahmed Hussen Abdelaziz",
      "Ahmed H Tewfik"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.15262",
    "title": "Data Augmentation Techniques for Machine Translation of Code-Switched  Texts: A Comparative Study",
    "abstract": "Code-switching (CSW) text generation has been receiving increasing attention as a solution to address data scarcity. In light of this growing interest, we need more comprehensive studies comparing different augmentation approaches. In this work, we compare three popular approaches: lexical replacements, linguistic theories, and back-translation (BT), in the context of Egyptian Arabic-English CSW. We assess the effectiveness of the approaches on machine translation and the quality of augmentations through human evaluation. We show that BT and CSW predictive-based lexical replacement, being trained on CSW parallel data, perform best on both tasks. Linguistic theories and random lexical replacement prove to be effective in the lack of CSW parallel data, where both approaches achieve similar results. ",
    "url": "https://arxiv.org/abs/2310.15262",
    "authors": [
      "Injy Hamed",
      "Nizar Habash",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.15299",
    "title": "Neural Network with Local Converging Input (NNLCI) for Supersonic Flow  Problems with Unstructured Grids",
    "abstract": "In recent years, surrogate models based on deep neural networks (DNN) have been widely used to solve partial differential equations, which were traditionally handled by means of numerical simulations. This kind of surrogate models, however, focuses on global interpolation of the training dataset, and thus requires a large network structure. The process is both time consuming and computationally costly, thereby restricting their use for high-fidelity prediction of complex physical problems. In the present study, we develop a neural network with local converging input (NNLCI) for high-fidelity prediction using unstructured data. The framework utilizes the local domain of dependence with converging coarse solutions as input, which greatly reduces computational resource and training time. As a validation case, the NNLCI method is applied to study inviscid supersonic flows in channels with bumps. Different bump geometries and locations are considered to benchmark the effectiveness and versability of the proposed approach. Detailed flow structures, including shock-wave interactions, are examined systematically. ",
    "url": "https://arxiv.org/abs/2310.15299",
    "authors": [
      "Weiming Ding",
      "Haoxiang Huang",
      "Tzu Jung Lee",
      "Yingjie Liu",
      "Vigor Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2310.15318",
    "title": "HetGPT: Harnessing the Power of Prompt Tuning in Pre-Trained  Heterogeneous Graph Neural Networks",
    "abstract": "Graphs have emerged as a natural choice to represent and analyze the intricate patterns and rich information of the Web, enabling applications such as online page classification and social recommendation. The prevailing \"pre-train, fine-tune\" paradigm has been widely adopted in graph machine learning tasks, particularly in scenarios with limited labeled nodes. However, this approach often exhibits a misalignment between the training objectives of pretext tasks and those of downstream tasks. This gap can result in the \"negative transfer\" problem, wherein the knowledge gained from pre-training adversely affects performance in the downstream tasks. The surge in prompt-based learning within Natural Language Processing (NLP) suggests the potential of adapting a \"pre-train, prompt\" paradigm to graphs as an alternative. However, existing graph prompting techniques are tailored to homogeneous graphs, neglecting the inherent heterogeneity of Web graphs. To bridge this gap, we propose HetGPT, a general post-training prompting framework to improve the predictive performance of pre-trained heterogeneous graph neural networks (HGNNs). The key is the design of a novel prompting function that integrates a virtual class prompt and a heterogeneous feature prompt, with the aim to reformulate downstream tasks to mirror pretext tasks. Moreover, HetGPT introduces a multi-view neighborhood aggregation mechanism, capturing the complex neighborhood structure in heterogeneous graphs. Extensive experiments on three benchmark datasets demonstrate HetGPT's capability to enhance the performance of state-of-the-art HGNNs on semi-supervised node classification. ",
    "url": "https://arxiv.org/abs/2310.15318",
    "authors": [
      "Yihong Ma",
      "Ning Yan",
      "Jiayu Li",
      "Masood Mortazavi",
      "Nitesh V. Chawla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.15319",
    "title": "Hallucination Detection for Grounded Instruction Generation",
    "abstract": "We investigate the problem of generating instructions to guide humans to navigate in simulated residential environments. A major issue with current models is hallucination: they generate references to actions or objects that are inconsistent with what a human follower would perform or encounter along the described path. We develop a model that detects these hallucinated references by adopting a model pre-trained on a large corpus of image-text pairs, and fine-tuning it with a contrastive loss that separates correct instructions from instructions containing synthesized hallucinations. Our final model outperforms several baselines, including using word probability estimated by the instruction-generation model, and supervised models based on LSTM and Transformer. ",
    "url": "https://arxiv.org/abs/2310.15319",
    "authors": [
      "Lingjun Zhao",
      "Khanh Nguyen",
      "Hal Daum\u00e9 III"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15342",
    "title": "Towards Hybrid-grained Feature Interaction Selection for Deep Sparse  Network",
    "abstract": "Deep sparse networks are widely investigated as a neural network architecture for prediction tasks with high-dimensional sparse features, with which feature interaction selection is a critical component. While previous methods primarily focus on how to search feature interaction in a coarse-grained space, less attention has been given to a finer granularity. In this work, we introduce a hybrid-grained feature interaction selection approach that targets both feature field and feature value for deep sparse networks. To explore such expansive space, we propose a decomposed space which is calculated on the fly. We then develop a selection algorithm called OptFeature, which efficiently selects the feature interaction from both the feature field and the feature value simultaneously. Results from experiments on three large real-world benchmark datasets demonstrate that OptFeature performs well in terms of accuracy and efficiency. Additional studies support the feasibility of our method. ",
    "url": "https://arxiv.org/abs/2310.15342",
    "authors": [
      "Fuyuan Lyu",
      "Xing Tang",
      "Dugang Liu",
      "Chen Ma",
      "Weihong Luo",
      "Liang Chen",
      "Xiuqiang He",
      "Xue Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.15388",
    "title": "Remote Heart Rate Monitoring in Smart Environments from Videos with  Self-supervised Pre-training",
    "abstract": "Recent advances in deep learning have made it increasingly feasible to estimate heart rate remotely in smart environments by analyzing videos. However, a notable limitation of deep learning methods is their heavy reliance on extensive sets of labeled data for effective training. To address this issue, self-supervised learning has emerged as a promising avenue. Building on this, we introduce a solution that utilizes self-supervised contrastive learning for the estimation of remote photoplethysmography (PPG) and heart rate monitoring, thereby reducing the dependence on labeled data and enhancing performance. We propose the use of 3 spatial and 3 temporal augmentations for training an encoder through a contrastive framework, followed by utilizing the late-intermediate embeddings of the encoder for remote PPG and heart rate estimation. Our experiments on two publicly available datasets showcase the improvement of our proposed approach over several related works as well as supervised learning baselines, as our results approach the state-of-the-art. We also perform thorough experiments to showcase the effects of using different design choices such as the video representation learning method, the augmentations used in the pre-training stage, and others. We also demonstrate the robustness of our proposed method over the supervised learning approaches on reduced amounts of labeled data. ",
    "url": "https://arxiv.org/abs/2310.15388",
    "authors": [
      "Divij Gupta",
      "Ali Etemad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15413",
    "title": "Sensor Attacks and Resilient Defense on HVAC Systems for Energy Market  Signal Tracking",
    "abstract": "The power flexibility from smart buildings makes them suitable candidates for providing grid services. The building automation system (BAS) that employs model predictive control (MPC) for grid services relies heavily on sensor data gathered from IoT-based HVAC systems through communication networks. However, cyber-attacks that tamper sensor values can compromise the accuracy and flexibility of HVAC system power adjustment. Existing studies on grid-interactive buildings mainly focus on the efficiency and flexibility of buildings' participation in grid operations, while the security aspect is lacking. In this paper, we investigate the effects of cyber-attacks on HVAC systems in grid-interactive buildings, specifically their power-tracking performance. We design a stochastic optimization-based stealthy sensor attack and a corresponding defense strategy using a resilient control framework. The attack and its defense are tested in a physical model of a test building with a single-chiller HVAC system. Simulation results demonstrate that minor falsifications caused by a stealthy sensor attack can significantly alter the power profile, leading to large power tracking errors. However, the resilient control framework can reduce the power tracking error by over 70% under such attacks without filtering out compromised data. ",
    "url": "https://arxiv.org/abs/2310.15413",
    "authors": [
      "Guanyu Tian",
      "Qun Zhou Sun",
      "Yiyuan Qiao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.15416",
    "title": "Nominality Score Conditioned Time Series Anomaly Detection by  Point/Sequential Reconstruction",
    "abstract": "Time series anomaly detection is challenging due to the complexity and variety of patterns that can occur. One major difficulty arises from modeling time-dependent relationships to find contextual anomalies while maintaining detection accuracy for point anomalies. In this paper, we propose a framework for unsupervised time series anomaly detection that utilizes point-based and sequence-based reconstruction models. The point-based model attempts to quantify point anomalies, and the sequence-based model attempts to quantify both point and contextual anomalies. Under the formulation that the observed time point is a two-stage deviated value from a nominal time point, we introduce a nominality score calculated from the ratio of a combined value of the reconstruction errors. We derive an induced anomaly score by further integrating the nominality score and anomaly score, then theoretically prove the superiority of the induced anomaly score over the original anomaly score under certain conditions. Extensive studies conducted on several public datasets show that the proposed framework outperforms most state-of-the-art baselines for time series anomaly detection. ",
    "url": "https://arxiv.org/abs/2310.15416",
    "authors": [
      "Chih-Yu Lai",
      "Fan-Keng Sun",
      "Zhengqi Gao",
      "Jeffrey H. Lang",
      "Duane S. Boning"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.15431",
    "title": "What Makes it Ok to Set a Fire? Iterative Self-distillation of Contexts  and Rationales for Disambiguating Defeasible Social and Moral Situations",
    "abstract": "Moral or ethical judgments rely heavily on the specific contexts in which they occur. Understanding varying shades of defeasible contextualizations (i.e., additional information that strengthens or attenuates the moral acceptability of an action) is critical to accurately represent the subtlety and intricacy of grounded human moral judgment in real-life scenarios. We introduce defeasible moral reasoning: a task to provide grounded contexts that make an action more or less morally acceptable, along with commonsense rationales that justify the reasoning. To elicit high-quality task data, we take an iterative self-distillation approach that starts from a small amount of unstructured seed knowledge from GPT-3 and then alternates between (1) self-distillation from student models; (2) targeted filtering with a critic model trained by human judgment (to boost validity) and NLI (to boost diversity); (3) self-imitation learning (to amplify the desired data quality). This process yields a student model that produces defeasible contexts with improved validity, diversity, and defeasibility. From this model we distill a high-quality dataset, \\delta-Rules-of-Thumb, of 1.2M entries of contextualizations and rationales for 115K defeasible moral actions rated highly by human annotators 85.9% to 99.8% of the time. Using \\delta-RoT we obtain a final student model that wins over all intermediate student models by a notable margin. ",
    "url": "https://arxiv.org/abs/2310.15431",
    "authors": [
      "Kavel Rao",
      "Liwei Jiang",
      "Valentina Pyatkin",
      "Yuling Gu",
      "Niket Tandon",
      "Nouha Dziri",
      "Faeze Brahman",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.15436",
    "title": "VGX: Large-Scale Sample Generation for Boosting Learning-Based Software  Vulnerability Analyses",
    "abstract": "Accompanying the successes of learning-based defensive software vulnerability analyses is the lack of large and quality sets of labeled vulnerable program samples, which impedes further advancement of those defenses. Existing automated sample generation approaches have shown potentials yet still fall short of practical expectations due to the high noise in the generated samples. This paper proposes VGX, a new technique aimed for large-scale generation of high-quality vulnerability datasets. Given a normal program, VGX identifies the code contexts in which vulnerabilities can be injected, using a customized Transformer featured with a new value-flowbased position encoding and pre-trained against new objectives particularly for learning code structure and context. Then, VGX materializes vulnerability-injection code editing in the identified contexts using patterns of such edits obtained from both historical fixes and human knowledge about real-world vulnerabilities. Compared to four state-of-the-art (SOTA) baselines (pattern-, Transformer-, GNN-, and pattern+Transformer-based), VGX achieved 99.09-890.06% higher F1 and 22.45%-328.47% higher label accuracy. For in-the-wild sample production, VGX generated 150,392 vulnerable samples, from which we randomly chose 10% to assess how much these samples help vulnerability detection, localization, and repair. Our results show SOTA techniques for these three application tasks achieved 19.15-330.80% higher F1, 12.86-19.31% higher top-10 accuracy, and 85.02-99.30% higher top-50 accuracy, respectively, by adding those samples to their original training data. These samples also helped a SOTA vulnerability detector discover 13 more real-world vulnerabilities (CVEs) in critical systems (e.g., Linux kernel) that would be missed by the original model. ",
    "url": "https://arxiv.org/abs/2310.15436",
    "authors": [
      "Yu Nong",
      "Richard Fang",
      "Guangbei Yi",
      "Kunsong Zhao",
      "Xiapu Luo",
      "Feng Chen",
      "Haipeng Cai"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.15439",
    "title": "K-HATERS: A Hate Speech Detection Corpus in Korean with Target-Specific  Ratings",
    "abstract": "Numerous datasets have been proposed to combat the spread of online hate. Despite these efforts, a majority of these resources are English-centric, primarily focusing on overt forms of hate. This research gap calls for developing high-quality corpora in diverse languages that also encapsulate more subtle hate expressions. This study introduces K-HATERS, a new corpus for hate speech detection in Korean, comprising approximately 192K news comments with target-specific offensiveness ratings. This resource is the largest offensive language corpus in Korean and is the first to offer target-specific ratings on a three-point Likert scale, enabling the detection of hate expressions in Korean across varying degrees of offensiveness. We conduct experiments showing the effectiveness of the proposed corpus, including a comparison with existing datasets. Additionally, to address potential noise and bias in human annotations, we explore a novel idea of adopting the Cognitive Reflection Test, which is widely used in social science for assessing an individual's cognitive ability, as a proxy of labeling quality. Findings indicate that annotations from individuals with the lowest test scores tend to yield detection models that make biased predictions toward specific target groups and are less accurate. This study contributes to the NLP research on hate speech detection and resource construction. The code and dataset can be accessed at https://github.com/ssu-humane/K-HATERS. ",
    "url": "https://arxiv.org/abs/2310.15439",
    "authors": [
      "Chaewon Park",
      "Soohwan Kim",
      "Kyubyong Park",
      "Kunwoo Park"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.15444",
    "title": "Fast Propagation is Better: Accelerating Single-Step Adversarial  Training via Sampling Subnetworks",
    "abstract": "Adversarial training has shown promise in building robust models against adversarial examples. A major drawback of adversarial training is the computational overhead introduced by the generation of adversarial examples. To overcome this limitation, adversarial training based on single-step attacks has been explored. Previous work improves the single-step adversarial training from different perspectives, e.g., sample initialization, loss regularization, and training strategy. Almost all of them treat the underlying model as a black box. In this work, we propose to exploit the interior building blocks of the model to improve efficiency. Specifically, we propose to dynamically sample lightweight subnetworks as a surrogate model during training. By doing this, both the forward and backward passes can be accelerated for efficient adversarial training. Besides, we provide theoretical analysis to show the model robustness can be improved by the single-step adversarial training with sampled subnetworks. Furthermore, we propose a novel sampling strategy where the sampling varies from layer to layer and from iteration to iteration. Compared with previous methods, our method not only reduces the training cost but also achieves better model robustness. Evaluations on a series of popular datasets demonstrate the effectiveness of the proposed FB-Better. Our code has been released at https://github.com/jiaxiaojunQAQ/FP-Better. ",
    "url": "https://arxiv.org/abs/2310.15444",
    "authors": [
      "Xiaojun Jia",
      "Jianshu Li",
      "Jindong Gu",
      "Yang Bai",
      "Xiaochun Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.15450",
    "title": "General Identifiability and Achievability for Causal Representation  Learning",
    "abstract": "This paper focuses on causal representation learning (CRL) under a general nonparametric causal latent model and a general transformation model that maps the latent data to the observational data. It establishes \\textbf{identifiability} and \\textbf{achievability} results using two hard \\textbf{uncoupled} interventions per node in the latent causal graph. Notably, one does not know which pair of intervention environments have the same node intervened (hence, uncoupled environments). For identifiability, the paper establishes that perfect recovery of the latent causal model and variables is guaranteed under uncoupled interventions. For achievability, an algorithm is designed that uses observational and interventional data and recovers the latent causal model and variables with provable guarantees for the algorithm. This algorithm leverages score variations across different environments to estimate the inverse of the transformer and, subsequently, the latent variables. The analysis, additionally, recovers the existing identifiability result for two hard \\textbf{coupled} interventions, that is when metadata about the pair of environments that have the same node intervened is known. It is noteworthy that the existing results on non-parametric identifiability require assumptions on interventions and additional faithfulness assumptions. This paper shows that when observational data is available, additional faithfulness assumptions are unnecessary. ",
    "url": "https://arxiv.org/abs/2310.15450",
    "authors": [
      "Burak Var\u0131c\u0131",
      "Emre Acart\u00fcrk",
      "Karthikeyan Shanmugam",
      "Ali Tajer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.15460",
    "title": "HL-DPoS: An Enhanced Anti-Long-Range Attack DPoS Algorithm",
    "abstract": "The consensus algorithm is crucial in blockchain for ensuring the validity and security of transactions across the decentralized network. However, achieving consensus among nodes and packaging blocks in blockchain networks is a complex task that requires efficient and secure consensus algorithms. The DPoS consensus algorithm has emerged as a popular choice due to its fast transaction processing and high throughput. Despite these advantages, the algorithm still suffers from weaknesses such as centralization and vulnerability to long-range attacks, which can compromise the integrity of the blockchain network. To combat these problems, we developed an Enhanced Anti-Long-Range Attack DPoS algorithm (HL-DPoS). First, we split nodes into pieces to reduce centralization issues while giving witness nodes the power to report and benefit from malicious node's reports, maintaining high efficiency and high security. Second, we propose a validation method in HL-DPoS that compares consensuses transactions with the longest chain to detect long-range attacks. Algorithm analysis and simulation experiment results demonstrate that our HL-DPoS consensus algorithm improves security while achieving better consensus performance. ",
    "url": "https://arxiv.org/abs/2310.15460",
    "authors": [
      "Yang Li",
      "Chunhe Xia",
      "Chunyan Li",
      "Yuan Zhao",
      "Chen Chen",
      "Tianbo Wang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.15466",
    "title": "EKGNet: A 10.96\u03bcW Fully Analog Neural Network for Intra-Patient  Arrhythmia Classification",
    "abstract": "We present an integrated approach by combining analog computing and deep learning for electrocardiogram (ECG) arrhythmia classification. We propose EKGNet, a hardware-efficient and fully analog arrhythmia classification architecture that archives high accuracy with low power consumption. The proposed architecture leverages the energy efficiency of transistors operating in the subthreshold region, eliminating the need for analog-to-digital converters (ADC) and static random access memory (SRAM). The system design includes a novel analog sequential Multiply-Accumulate (MAC) circuit that mitigates process, supply voltage, and temperature variations. Experimental evaluations on PhysioNet's MIT-BIH and PTB Diagnostics datasets demonstrate the effectiveness of the proposed method, achieving average balanced accuracy of 95% and 94.25% for intra-patient arrhythmia classification and myocardial infarction (MI) classification, respectively. This innovative approach presents a promising avenue for developing low-power arrhythmia classification systems with enhanced accuracy and transferability in biomedical applications. ",
    "url": "https://arxiv.org/abs/2310.15466",
    "authors": [
      "Benyamin Haghi",
      "Lin Ma",
      "Sahin Lale",
      "Anima Anandkumar",
      "Azita Emami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15469",
    "title": "The Janus Interface: How Fine-Tuning in Large Language Models Amplifies  the Privacy Risks",
    "abstract": "The era post-2018 marked the advent of Large Language Models (LLMs), with innovations such as OpenAI's ChatGPT showcasing prodigious linguistic prowess. As the industry galloped toward augmenting model parameters and capitalizing on vast swaths of human language data, security and privacy challenges also emerged. Foremost among these is the potential inadvertent accrual of Personal Identifiable Information (PII) during web-based data acquisition, posing risks of unintended PII disclosure. While strategies like RLHF during training and Catastrophic Forgetting have been marshaled to control the risk of privacy infringements, recent advancements in LLMs, epitomized by OpenAI's fine-tuning interface for GPT-3.5, have reignited concerns. One may ask: can the fine-tuning of LLMs precipitate the leakage of personal information embedded within training datasets? This paper reports the first endeavor to seek the answer to the question, particularly our discovery of a new LLM exploitation avenue, called the Janus attack. In the attack, one can construct a PII association task, whereby an LLM is fine-tuned using a minuscule PII dataset, to potentially reinstate and reveal concealed PIIs. Our findings indicate that, with a trivial fine-tuning outlay, LLMs such as GPT-3.5 can transition from being impermeable to PII extraction to a state where they divulge a substantial proportion of concealed PII. This research, through its deep dive into the Janus attack vector, underscores the imperative of navigating the intricate interplay between LLM utility and privacy preservation. ",
    "url": "https://arxiv.org/abs/2310.15469",
    "authors": [
      "Xiaoyi Chen",
      "Siyuan Tang",
      "Rui Zhu",
      "Shijun Yan",
      "Lei Jin",
      "Zihao Wang",
      "Liya Su",
      "XiaoFeng Wang",
      "Haixu Tang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.15472",
    "title": "Interpretable Survival Analysis for Heart Failure Risk Prediction",
    "abstract": "Survival analysis, or time-to-event analysis, is an important and widespread problem in healthcare research. Medical research has traditionally relied on Cox models for survival analysis, due to their simplicity and interpretability. Cox models assume a log-linear hazard function as well as proportional hazards over time, and can perform poorly when these assumptions fail. Newer survival models based on machine learning avoid these assumptions and offer improved accuracy, yet sometimes at the expense of model interpretability, which is vital for clinical use. We propose a novel survival analysis pipeline that is both interpretable and competitive with state-of-the-art survival models. Specifically, we use an improved version of survival stacking to transform a survival analysis problem to a classification problem, ControlBurn to perform feature selection, and Explainable Boosting Machines to generate interpretable predictions. To evaluate our pipeline, we predict risk of heart failure using a large-scale EHR database. Our pipeline achieves state-of-the-art performance and provides interesting and novel insights about risk factors for heart failure. ",
    "url": "https://arxiv.org/abs/2310.15472",
    "authors": [
      "Mike Van Ness",
      "Tomas Bosschieter",
      "Natasha Din",
      "Andrew Ambrosy",
      "Alexander Sandhu",
      "Madeleine Udell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.15482",
    "title": "Salient Object Detection in RGB-D Videos",
    "abstract": "Given the widespread adoption of depth-sensing acquisition devices, RGB-D videos and related data/media have gained considerable traction in various aspects of daily life. Consequently, conducting salient object detection (SOD) in RGB-D videos presents a highly promising and evolving avenue. Despite the potential of this area, SOD in RGB-D videos remains somewhat under-explored, with RGB-D SOD and video SOD (VSOD) traditionally studied in isolation. To explore this emerging field, this paper makes two primary contributions: the dataset and the model. On one front, we construct the RDVS dataset, a new RGB-D VSOD dataset with realistic depth and characterized by its diversity of scenes and rigorous frame-by-frame annotations. We validate the dataset through comprehensive attribute and object-oriented analyses, and provide training and testing splits. Moreover, we introduce DCTNet+, a three-stream network tailored for RGB-D VSOD, with an emphasis on RGB modality and treats depth and optical flow as auxiliary modalities. In pursuit of effective feature enhancement, refinement, and fusion for precise final prediction, we propose two modules: the multi-modal attention module (MAM) and the refinement fusion module (RFM). To enhance interaction and fusion within RFM, we design a universal interaction module (UIM) and then integrate holistic multi-modal attentive paths (HMAPs) for refining multi-modal low-level features before reaching RFMs. Comprehensive experiments, conducted on pseudo RGB-D video datasets alongside our RDVS, highlight the superiority of DCTNet+ over 17 VSOD models and 14 RGB-D SOD models. Ablation experiments were performed on both pseudo and realistic RGB-D video datasets to demonstrate the advantages of individual modules as well as the necessity of introducing realistic depth. Our code together with RDVS dataset will be available at https://github.com/kerenfu/RDVS/. ",
    "url": "https://arxiv.org/abs/2310.15482",
    "authors": [
      "Ao Mou",
      "Yukang Lu",
      "Jiahao He",
      "Dingyao Min",
      "Keren Fu",
      "Qijun Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.15484",
    "title": "NuTrea: Neural Tree Search for Context-guided Multi-hop KGQA",
    "abstract": "Multi-hop Knowledge Graph Question Answering (KGQA) is a task that involves retrieving nodes from a knowledge graph (KG) to answer natural language questions. Recent GNN-based approaches formulate this task as a KG path searching problem, where messages are sequentially propagated from the seed node towards the answer nodes. However, these messages are past-oriented, and they do not consider the full KG context. To make matters worse, KG nodes often represent proper noun entities and are sometimes encrypted, being uninformative in selecting between paths. To address these problems, we propose Neural Tree Search (NuTrea), a tree search-based GNN model that incorporates the broader KG context. Our model adopts a message-passing scheme that probes the unreached subtree regions to boost the past-oriented embeddings. In addition, we introduce the Relation Frequency-Inverse Entity Frequency (RF-IEF) node embedding that considers the global KG context to better characterize ambiguous KG nodes. The general effectiveness of our approach is demonstrated through experiments on three major multi-hop KGQA benchmark datasets, and our extensive analyses further validate its expressiveness and robustness. Overall, NuTrea provides a powerful means to query the KG with complex natural language questions. Code is available at https://github.com/mlvlab/NuTrea. ",
    "url": "https://arxiv.org/abs/2310.15484",
    "authors": [
      "Hyeong Kyu Choi",
      "Seunghun Lee",
      "Jaewon Chu",
      "Hyunwoo J. Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.15492",
    "title": "Robust Representation Learning for Unified Online Top-K Recommendation",
    "abstract": "In large-scale industrial e-commerce, the efficiency of an online recommendation system is crucial in delivering highly relevant item/content advertising that caters to diverse business scenarios. However, most existing studies focus solely on item advertising, neglecting the significance of content advertising. This oversight results in inconsistencies within the multi-entity structure and unfair retrieval. Furthermore, the challenge of retrieving top-k advertisements from multi-entity advertisements across different domains adds to the complexity. Recent research proves that user-entity behaviors within different domains exhibit characteristics of differentiation and homogeneity. Therefore, the multi-domain matching models typically rely on the hybrid-experts framework with domain-invariant and domain-specific representations. Unfortunately, most approaches primarily focus on optimizing the combination mode of different experts, failing to address the inherent difficulty in optimizing the expert modules themselves. The existence of redundant information across different domains introduces interference and competition among experts, while the distinct learning objectives of each domain lead to varying optimization challenges among experts. To tackle these issues, we propose robust representation learning for the unified online top-k recommendation. Our approach constructs unified modeling in entity space to ensure data fairness. The robust representation learning employs domain adversarial learning and multi-view wasserstein distribution learning to learn robust representations. Moreover, the proposed method balances conflicting objectives through the homoscedastic uncertainty weights and orthogonality constraints. Various experiments validate the effectiveness and rationality of our proposed method, which has been successfully deployed online to serve real business scenarios. ",
    "url": "https://arxiv.org/abs/2310.15492",
    "authors": [
      "Minfang Lu",
      "Yuchen Jiang",
      "Huihui Dong",
      "Qi Li",
      "Ziru Xu",
      "Yuanlin Liu",
      "Lixia Wu",
      "Haoyuan Hu",
      "Han Zhu",
      "Yuning Jiang",
      "Jian Xu",
      "Bo Zheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.15516",
    "title": "Graph Attention-based Deep Reinforcement Learning for solving the  Chinese Postman Problem with Load-dependent costs",
    "abstract": "Recently, Deep reinforcement learning (DRL) models have shown promising results in solving routing problems. However, most DRL solvers are commonly proposed to solve node routing problems, such as the Traveling Salesman Problem (TSP). Meanwhile, there has been limited research on applying neural methods to arc routing problems, such as the Chinese Postman Problem (CPP), since they often feature irregular and complex solution spaces compared to TSP. To fill these gaps, this paper proposes a novel DRL framework to address the CPP with load-dependent costs (CPP-LC) (Corberan et al., 2018), which is a complex arc routing problem with load constraints. The novelty of our method is two-fold. First, we formulate the CPP-LC as a Markov Decision Process (MDP) sequential model. Subsequently, we introduce an autoregressive model based on DRL, namely Arc-DRL, consisting of an encoder and decoder to address the CPP-LC challenge effectively. Such a framework allows the DRL model to work efficiently and scalably to arc routing problems. Furthermore, we propose a new bio-inspired meta-heuristic solution based on Evolutionary Algorithm (EA) for CPP-LC. Extensive experiments show that Arc-DRL outperforms existing meta-heuristic methods such as Iterative Local Search (ILS) and Variable Neighborhood Search (VNS) proposed by (Corberan et al., 2018) on large benchmark datasets for CPP-LC regarding both solution quality and running time; while the EA gives the best solution quality with much more running time. We release our C++ implementations for metaheuristics such as EA, ILS and VNS along with the code for data generation and our generated data at https://github.com/HySonLab/Chinese_Postman_Problem ",
    "url": "https://arxiv.org/abs/2310.15516",
    "authors": [
      "Cong Dao Tran",
      "Truong Son Hy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15523",
    "title": "Generative and Contrastive Paradigms Are Complementary for Graph  Self-Supervised Learning",
    "abstract": "For graph self-supervised learning (GSSL), masked autoencoder (MAE) follows the generative paradigm and learns to reconstruct masked graph edges or node features. Contrastive Learning (CL) maximizes the similarity between augmented views of the same graph and is widely used for GSSL. However, MAE and CL are considered separately in existing works for GSSL. We observe that the MAE and CL paradigms are complementary and propose the graph contrastive masked autoencoder (GCMAE) framework to unify them. Specifically, by focusing on local edges or node features, MAE cannot capture global information of the graph and is sensitive to particular edges and features. On the contrary, CL excels in extracting global information because it considers the relation between graphs. As such, we equip GCMAE with an MAE branch and a CL branch, and the two branches share a common encoder, which allows the MAE branch to exploit the global information extracted by the CL branch. To force GCMAE to capture global graph structures, we train it to reconstruct the entire adjacency matrix instead of only the masked edges as in existing works. Moreover, a discrimination loss is proposed for feature reconstruction, which improves the disparity between node embeddings rather than reducing the reconstruction error to tackle the feature smoothing problem of MAE. We evaluate GCMAE on four popular graph tasks (i.e., node classification, node clustering, link prediction, and graph classification) and compare with 14 state-of-the-art baselines. The results show that GCMAE consistently provides good accuracy across these tasks, and the maximum accuracy improvement is up to 3.2% compared with the best-performing baseline. ",
    "url": "https://arxiv.org/abs/2310.15523",
    "authors": [
      "Yuxiang Wang",
      "Xiao Yan",
      "Chuang Hu",
      "Fangcheng Fu",
      "Wentao Zhang",
      "Hao Wang",
      "Shuo Shang",
      "Jiawei Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.15524",
    "title": "On the Inherent Privacy Properties of Discrete Denoising Diffusion  Models",
    "abstract": "Privacy concerns have led to a surge in the creation of synthetic datasets, with diffusion models emerging as a promising avenue. Although prior studies have performed empirical evaluations on these models, there has been a gap in providing a mathematical characterization of their privacy-preserving capabilities. To address this, we present the pioneering theoretical exploration of the privacy preservation inherent in discrete diffusion models (DDMs) for discrete dataset generation. Focusing on per-instance differential privacy (pDP), our framework elucidates the potential privacy leakage for each data point in a given training dataset, offering insights into data preprocessing to reduce privacy risks of the synthetic dataset generation via DDMs. Our bounds also show that training with $s$-sized data points leads to a surge in privacy leakage from $(\\epsilon, \\mathcal{O}(\\frac{1}{s^2\\epsilon}))$-pDP to $(\\epsilon, \\mathcal{O}(\\frac{1}{s\\epsilon}))$-pDP during the transition from the pure noise to the synthetic clean data phase, and a faster decay in diffusion coefficients amplifies the privacy guarantee. Finally, we empirically verify our theoretical findings on both synthetic and real-world datasets. ",
    "url": "https://arxiv.org/abs/2310.15524",
    "authors": [
      "Rongzhe Wei",
      "Eleonora Krea\u010di\u0107",
      "Haoyu Wang",
      "Haoteng Yin",
      "Eli Chien",
      "Vamsi K. Potluru",
      "Pan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15526",
    "title": "Privacy Amplification for Matrix Mechanisms",
    "abstract": "Privacy amplification exploits randomness in data selection to provide tighter differential privacy (DP) guarantees. This analysis is key to DP-SGD's success in machine learning, but, is not readily applicable to the newer state-of-the-art algorithms. This is because these algorithms, known as DP-FTRL, use the matrix mechanism to add correlated noise instead of independent noise as in DP-SGD. In this paper, we propose \"MMCC\", the first algorithm to analyze privacy amplification via sampling for any generic matrix mechanism. MMCC is nearly tight in that it approaches a lower bound as $\\epsilon\\to0$. To analyze correlated outputs in MMCC, we prove that they can be analyzed as if they were independent, by conditioning them on prior outputs. Our \"conditional composition theorem\" has broad utility: we use it to show that the noise added to binary-tree-DP-FTRL can asymptotically match the noise added to DP-SGD with amplification. Our amplification algorithm also has practical empirical utility: we show it leads to significant improvement in the privacy-utility trade-offs for DP-FTRL algorithms on standard benchmarks. ",
    "url": "https://arxiv.org/abs/2310.15526",
    "authors": [
      "Christopher A. Choquette-Choo",
      "Arun Ganesh",
      "Thomas Steinke",
      "Abhradeep Thakurta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.15529",
    "title": "Symmetric Strategies for Multi-Access IoT Network Optimization: A Common  Information Approach",
    "abstract": "In the context of IoT deployments, a multitude of devices concurrently require network access to transmit data over a shared communication channel. Employing symmetric strategies can effectively facilitate the collaborative use of the communication medium among these devices. By adopting such strategies, devices collectively optimize their transmission parameters, resulting in minimized collisions and enhanced overall network throughput. Our primary focus centers on the formulation of symmetric (i.e., identical) strategies for the sensors, aiming to optimize a finite horizon team objective. The imposition of symmetric strategies introduces novel facets and complexities into the team problem. To address this, we embrace the common information approach and adapt it to accommodate the use of symmetric strategies. This adaptation yields a dynamic programming framework grounded in common information, wherein each step entails the minimization of a single function mapping from an agent's private information space to the space of probability distributions over possible actions. Our proposed policy/method incurs a reduced cumulative cost compared to other methods employing symmetric strategies, a point substantiated by our simulation results. ",
    "url": "https://arxiv.org/abs/2310.15529",
    "authors": [
      "Sagar Sudhakara"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2310.15539",
    "title": "SteloCoder: a Decoder-Only LLM for Multi-Language to Python Code  Translation",
    "abstract": "With the recent focus on Large Language Models (LLMs), both StarCoder (Li et al., 2023) and Code Llama (Rozi\\`ere et al., 2023) have demonstrated remarkable performance in code generation. However, there is still a need for improvement in code translation functionality with efficient training techniques. In response to this, we introduce SteloCoder, a decoder-only StarCoder-based LLM designed specifically for multi-programming language-to-Python code translation. In particular, SteloCoder achieves C++, C#, JavaScript, Java, or PHP-to-Python code translation without specifying the input programming language. We modified StarCoder model architecture by incorporating a Mixture-of-Experts (MoE) technique featuring five experts and a gating network for multi-task handling. Experts are obtained by StarCoder fine-tuning. Specifically, we use a Low-Rank Adaptive Method (LoRA) technique, limiting each expert size as only 0.06% of number of StarCoder's parameters. At the same time, to enhance training efficiency in terms of time, we adopt curriculum learning strategy and use self-instruct data for efficient fine-tuning. As a result, each expert takes only 6 hours to train on one single 80Gb A100 HBM. With experiments on XLCoST datasets, SteloCoder achieves an average of 73.76 CodeBLEU score in multi-programming language-to-Python translation, surpassing the top performance from the leaderboard by at least 3.5. This accomplishment is attributed to only 45M extra parameters with StarCoder as the backbone and 32 hours of valid training on one 80GB A100 HBM. The source code is release here: https://github.com/sade-adrien/SteloCoder. ",
    "url": "https://arxiv.org/abs/2310.15539",
    "authors": [
      "Jialing Pan",
      "Adrien Sad\u00e9",
      "Jin Kim",
      "Eric Soriano",
      "Guillem Sole",
      "Sylvain Flamant"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.15543",
    "title": "Symmetry-preserving graph attention network to solve routing problems at  multiple resolutions",
    "abstract": "Travelling Salesperson Problems (TSPs) and Vehicle Routing Problems (VRPs) have achieved reasonable improvement in accuracy and computation time with the adaptation of Machine Learning (ML) methods. However, none of the previous works completely respects the symmetries arising from TSPs and VRPs including rotation, translation, permutation, and scaling. In this work, we introduce the first-ever completely equivariant model and training to solve combinatorial problems. Furthermore, it is essential to capture the multiscale structure (i.e. from local to global information) of the input graph, especially for the cases of large and long-range graphs, while previous methods are limited to extracting only local information that can lead to a local or sub-optimal solution. To tackle the above limitation, we propose a Multiresolution scheme in combination with Equivariant Graph Attention network (mEGAT) architecture, which can learn the optimal route based on low-level and high-level graph resolutions in an efficient way. In particular, our approach constructs a hierarchy of coarse-graining graphs from the input graph, in which we try to solve the routing problems on simple low-level graphs first, then utilize that knowledge for the more complex high-level graphs. Experimentally, we have shown that our model outperforms existing baselines and proved that symmetry preservation and multiresolution are important recipes for solving combinatorial problems in a data-driven manner. Our source code is publicly available at https://github.com/HySonLab/Multires-NP-hard ",
    "url": "https://arxiv.org/abs/2310.15543",
    "authors": [
      "Cong Dao Tran",
      "Thong Bach",
      "Truong Son Hy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15552",
    "title": "Unveiling Multilinguality in Transformer Models: Exploring Language  Specificity in Feed-Forward Networks",
    "abstract": "Recent research suggests that the feed-forward module within Transformers can be viewed as a collection of key-value memories, where the keys learn to capture specific patterns from the input based on the training examples. The values then combine the output from the 'memories' of the keys to generate predictions about the next token. This leads to an incremental process of prediction that gradually converges towards the final token choice near the output layers. This interesting perspective raises questions about how multilingual models might leverage this mechanism. Specifically, for autoregressive models trained on two or more languages, do all neurons (across layers) respond equally to all languages? No! Our hypothesis centers around the notion that during pretraining, certain model parameters learn strong language-specific features, while others learn more language-agnostic (shared across languages) features. To validate this, we conduct experiments utilizing parallel corpora of two languages that the model was initially pretrained on. Our findings reveal that the layers closest to the network's input or output tend to exhibit more language-specific behaviour compared to the layers in the middle. ",
    "url": "https://arxiv.org/abs/2310.15552",
    "authors": [
      "Sunit Bhattacharya",
      "Ondrej Bojar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.15568",
    "title": "I$^2$MD: 3D Action Representation Learning with Inter- and Intra-modal  Mutual Distillation",
    "abstract": "Recent progresses on self-supervised 3D human action representation learning are largely attributed to contrastive learning. However, in conventional contrastive frameworks, the rich complementarity between different skeleton modalities remains under-explored. Moreover, optimized with distinguishing self-augmented samples, models struggle with numerous similar positive instances in the case of limited action categories. In this work, we tackle the aforementioned problems by introducing a general Inter- and Intra-modal Mutual Distillation (I$^2$MD) framework. In I$^2$MD, we first re-formulate the cross-modal interaction as a Cross-modal Mutual Distillation (CMD) process. Different from existing distillation solutions that transfer the knowledge of a pre-trained and fixed teacher to the student, in CMD, the knowledge is continuously updated and bidirectionally distilled between modalities during pre-training. To alleviate the interference of similar samples and exploit their underlying contexts, we further design the Intra-modal Mutual Distillation (IMD) strategy, In IMD, the Dynamic Neighbors Aggregation (DNA) mechanism is first introduced, where an additional cluster-level discrimination branch is instantiated in each modality. It adaptively aggregates highly-correlated neighboring features, forming local cluster-level contrasting. Mutual distillation is then performed between the two branches for cross-level knowledge exchange. Extensive experiments on three datasets show that our approach sets a series of new records. ",
    "url": "https://arxiv.org/abs/2310.15568",
    "authors": [
      "Yunyao Mao",
      "Jiajun Deng",
      "Wengang Zhou",
      "Zhenbo Lu",
      "Wanli Ouyang",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.15580",
    "title": "Identifiable Latent Polynomial Causal Models Through the Lens of Change",
    "abstract": "Causal representation learning aims to unveil latent high-level causal representations from observed low-level data. One of its primary tasks is to provide reliable assurance of identifying these latent causal models, known as identifiability. A recent breakthrough explores identifiability by leveraging the change of causal influences among latent causal variables across multiple environments \\citep{liu2022identifying}. However, this progress rests on the assumption that the causal relationships among latent causal variables adhere strictly to linear Gaussian models. In this paper, we extend the scope of latent causal models to involve nonlinear causal relationships, represented by polynomial models, and general noise distributions conforming to the exponential family. Additionally, we investigate the necessity of imposing changes on all causal parameters and present partial identifiability results when part of them remains unchanged. Further, we propose a novel empirical estimation method, grounded in our theoretical finding, that enables learning consistent latent causal representations. Our experimental results, obtained from both synthetic and real-world data, validate our theoretical contributions concerning identifiability and consistency. ",
    "url": "https://arxiv.org/abs/2310.15580",
    "authors": [
      "Yuhang Liu",
      "Zhen Zhang",
      "Dong Gong",
      "Mingming Gong",
      "Biwei Huang",
      "Anton van den Hengel",
      "Kun Zhang",
      "Javen Qinfeng Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15581",
    "title": "Deep ReLU neural networks overcome the curse of dimensionality in the  numerical approximation of semilinear partial integro-differential equations",
    "abstract": "We prove that deep neural networks with ReLU activation function are capable of approximating solutions of semilinear partial integro-differential equations in the case of gradient-independent and Lipschitz-continuous nonlinearities, while the required number of parameters in the neural networks grows at most polynomially in both the dimension $ d\\in\\mathbb{N} $ and the reciprocal of the prescribed accuracy $ \\epsilon $. ",
    "url": "https://arxiv.org/abs/2310.15581",
    "authors": [
      "Ariel Neufeld",
      "Tuan Anh Nguyen",
      "Sizhou Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2310.15582",
    "title": "SecV: Secure Code Partitioning via Multi-Language Secure Values",
    "abstract": "Trusted execution environments like Intel SGX provide \\emph{enclaves}, which offer strong security guarantees for applications. Running entire applications inside enclaves is possible, but this approach leads to a large trusted computing base (TCB). As such, various tools have been developed to partition programs written in languages such as C or Java into \\emph{trusted} and \\emph{untrusted} parts, which are run in and out of enclaves respectively. However, those tools depend on language-specific taint-analysis and partitioning techniques. They cannot be reused for other languages and there is thus a need for tools that transcend this language barrier. We address this challenge by proposing a multi-language technique to specify sensitive code or data, as well as a multi-language tool to analyse and partition the resulting programs for trusted execution environments like Intel SGX. We leverage GraalVM's Truffle framework, which provides a language-agnostic abstract syntax tree (AST) representation for programs, to provide special AST nodes called \\emph{secure nodes} that encapsulate sensitive program information. Secure nodes can easily be embedded into the ASTs of a wide range of languages via Truffle's \\emph{polyglot API}. Our technique includes a multi-language dynamic taint tracking tool to analyse and partition applications based on our generic secure nodes. Our extensive evaluation with micro- and macro-benchmarks shows that we can use our technique for two languages (Javascript and \\python), and that partitioned programs can obtain up to $14.5\\%$ performance improvement as compared to unpartitioned versions. ",
    "url": "https://arxiv.org/abs/2310.15582",
    "authors": [
      "Peterson Yuhala",
      "Pascal Felber",
      "Hugo Guiroux",
      "Jean-Pierre Lozi",
      "Alain Tchana",
      "Valerio Schiavoni",
      "Ga\u00ebl Thomas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2310.15584",
    "title": "Accelerating Split Federated Learning over Wireless Communication  Networks",
    "abstract": "The development of artificial intelligence (AI) provides opportunities for the promotion of deep neural network (DNN)-based applications. However, the large amount of parameters and computational complexity of DNN makes it difficult to deploy it on edge devices which are resource-constrained. An efficient method to address this challenge is model partition/splitting, in which DNN is divided into two parts which are deployed on device and server respectively for co-training or co-inference. In this paper, we consider a split federated learning (SFL) framework that combines the parallel model training mechanism of federated learning (FL) and the model splitting structure of split learning (SL). We consider a practical scenario of heterogeneous devices with individual split points of DNN. We formulate a joint problem of split point selection and bandwidth allocation to minimize the system latency. By using alternating optimization, we decompose the problem into two sub-problems and solve them optimally. Experiment results demonstrate the superiority of our work in latency reduction and accuracy improvement. ",
    "url": "https://arxiv.org/abs/2310.15584",
    "authors": [
      "Ce Xu",
      "Jinxuan Li",
      "Yuan Liu",
      "Yushi Ling",
      "Miaowen Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.15586",
    "title": "Detecting Intentional AIS Shutdown in Open Sea Maritime Surveillance  Using Self-Supervised Deep Learning",
    "abstract": "In maritime traffic surveillance, detecting illegal activities, such as illegal fishing or transshipment of illicit products is a crucial task of the coastal administration. In the open sea, one has to rely on Automatic Identification System (AIS) message transmitted by on-board transponders, which are captured by surveillance satellites. However, insincere vessels often intentionally shut down their AIS transponders to hide illegal activities. In the open sea, it is very challenging to differentiate intentional AIS shutdowns from missing reception due to protocol limitations, bad weather conditions or restricting satellite positions. This paper presents a novel approach for the detection of abnormal AIS missing reception based on self-supervised deep learning techniques and transformer models. Using historical data, the trained model predicts if a message should be received in the upcoming minute or not. Afterwards, the model reports on detected anomalies by comparing the prediction with what actually happens. Our method can process AIS messages in real-time, in particular, more than 500 Millions AIS messages per month, corresponding to the trajectories of more than 60 000 ships. The method is evaluated on 1-year of real-world data coming from four Norwegian surveillance satellites. Using related research results, we validated our method by rediscovering already detected intentional AIS shutdowns. ",
    "url": "https://arxiv.org/abs/2310.15586",
    "authors": [
      "Pierre Bernab\u00e9",
      "Arnaud Gotlieb",
      "Bruno Legeard",
      "Dusica Marijan",
      "Frank Olaf Sem-Jacobsen",
      "Helge Spieker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.15590",
    "title": "Facial Data Minimization: Shallow Model as Your Privacy Filter",
    "abstract": "Face recognition service has been used in many fields and brings much convenience to people. However, once the user's facial data is transmitted to a service provider, the user will lose control of his/her private data. In recent years, there exist various security and privacy issues due to the leakage of facial data. Although many privacy-preserving methods have been proposed, they usually fail when they are not accessible to adversaries' strategies or auxiliary data. Hence, in this paper, by fully considering two cases of uploading facial images and facial features, which are very typical in face recognition service systems, we proposed a data privacy minimization transformation (PMT) method. This method can process the original facial data based on the shallow model of authorized services to obtain the obfuscated data. The obfuscated data can not only maintain satisfactory performance on authorized models and restrict the performance on other unauthorized models but also prevent original privacy data from leaking by AI methods and human visual theft. Additionally, since a service provider may execute preprocessing operations on the received data, we also propose an enhanced perturbation method to improve the robustness of PMT. Besides, to authorize one facial image to multiple service models simultaneously, a multiple restriction mechanism is proposed to improve the scalability of PMT. Finally, we conduct extensive experiments and evaluate the effectiveness of the proposed PMT in defending against face reconstruction, data abuse, and face attribute estimation attacks. These experimental results demonstrate that PMT performs well in preventing facial data abuse and privacy leakage while maintaining face recognition accuracy. ",
    "url": "https://arxiv.org/abs/2310.15590",
    "authors": [
      "Yuwen Pu",
      "Jiahao Chen",
      "Jiayu Pan",
      "Hao li",
      "Diqun Yan",
      "Xuhong Zhang",
      "Shouling Ji"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.15593",
    "title": "RecipeMeta: Metapath-enhanced Recipe Recommendation on Heterogeneous  Recipe Network",
    "abstract": "Recipe is a set of instructions that describes how to make food. It can help people from the preparation of ingredients, food cooking process, etc. to prepare the food, and increasingly in demand on the Web. To help users find the vast amount of recipes on the Web, we address the task of recipe recommendation. Due to multiple data types and relationships in a recipe, we can treat it as a heterogeneous network to describe its information more accurately. To effectively utilize the heterogeneous network, metapath was proposed to describe the higher-level semantic information between two entities by defining a compound path from peer entities. Therefore, we propose a metapath-enhanced recipe recommendation framework, RecipeMeta, that combines GNN (Graph Neural Network)-based representation learning and specific metapath-based information in a recipe to predict User-Recipe pairs for recommendation. Through extensive experiments, we demonstrate that the proposed model, RecipeMeta, outperforms state-of-the-art methods for recipe recommendation. ",
    "url": "https://arxiv.org/abs/2310.15593",
    "authors": [
      "Jialiang Shi",
      "Takahiro Komamizu",
      "Keisuke Doman",
      "Haruya Kyutoku",
      "Ichiro Ide"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2310.15614",
    "title": "Sparse Bayesian neural networks for regression: Tackling overfitting and  computational challenges in uncertainty quantification",
    "abstract": "Neural networks (NNs) are primarily developed within the frequentist statistical framework. Nevertheless, frequentist NNs lack the capability to provide uncertainties in the predictions, and hence their robustness can not be adequately assessed. Conversely, the Bayesian neural networks (BNNs) naturally offer predictive uncertainty by applying Bayes' theorem. However, their computational requirements pose significant challenges. Moreover, both frequentist NNs and BNNs suffer from overfitting issues when dealing with noisy and sparse data, which render their predictions unwieldy away from the available data space. To address both these problems simultaneously, we leverage insights from a hierarchical setting in which the parameter priors are conditional on hyperparameters to construct a BNN by applying a semi-analytical framework known as nonlinear sparse Bayesian learning (NSBL). We call our network sparse Bayesian neural network (SBNN) which aims to address the practical and computational issues associated with BNNs. Simultaneously, imposing a sparsity-inducing prior encourages the automatic pruning of redundant parameters based on the automatic relevance determination (ARD) concept. This process involves removing redundant parameters by optimally selecting the precision of the parameters prior probability density functions (pdfs), resulting in a tractable treatment for overfitting. To demonstrate the benefits of the SBNN algorithm, the study presents an illustrative regression problem and compares the results of a BNN using standard Bayesian inference, hierarchical Bayesian inference, and a BNN equipped with the proposed algorithm. Subsequently, we demonstrate the importance of considering the full parameter posterior by comparing the results with those obtained using the Laplace approximation with and without NSBL. ",
    "url": "https://arxiv.org/abs/2310.15614",
    "authors": [
      "Nastaran Dabiran",
      "Brandon Robinson",
      "Rimple Sandhu",
      "Mohammad Khalil",
      "Dominique Poirel",
      "Abhijit Sarkar"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2310.15624",
    "title": "GUPNet++: Geometry Uncertainty Propagation Network for Monocular 3D  Object Detection",
    "abstract": "Geometry plays a significant role in monocular 3D object detection. It can be used to estimate object depth by using the perspective projection between object's physical size and 2D projection in the image plane, which can introduce mathematical priors into deep models. However, this projection process also introduces error amplification, where the error of the estimated height is amplified and reflected into the projected depth. It leads to unreliable depth inferences and also impairs training stability. To tackle this problem, we propose a novel Geometry Uncertainty Propagation Network (GUPNet++) by modeling geometry projection in a probabilistic manner. This ensures depth predictions are well-bounded and associated with a reasonable uncertainty. The significance of introducing such geometric uncertainty is two-fold: (1). It models the uncertainty propagation relationship of the geometry projection during training, improving the stability and efficiency of the end-to-end model learning. (2). It can be derived to a highly reliable confidence to indicate the quality of the 3D detection result, enabling more reliable detection inference. Experiments show that the proposed approach not only obtains (state-of-the-art) SOTA performance in image-based monocular 3D detection but also demonstrates superiority in efficacy with a simplified framework. ",
    "url": "https://arxiv.org/abs/2310.15624",
    "authors": [
      "Yan Lu",
      "Xinzhu Ma",
      "Lei Yang",
      "Tianzhu Zhang",
      "Yating Liu",
      "Qi Chu",
      "Tong He",
      "Yonghui Li",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15636",
    "title": "Career Path Prediction using Resume Representation Learning and  Skill-based Matching",
    "abstract": "The impact of person-job fit on job satisfaction and performance is widely acknowledged, which highlights the importance of providing workers with next steps at the right time in their career. This task of predicting the next step in a career is known as career path prediction, and has diverse applications such as turnover prevention and internal job mobility. Existing methods to career path prediction rely on large amounts of private career history data to model the interactions between job titles and companies. We propose leveraging the unexplored textual descriptions that are part of work experience sections in resumes. We introduce a structured dataset of 2,164 anonymized career histories, annotated with ESCO occupation labels. Based on this dataset, we present a novel representation learning approach, CareerBERT, specifically designed for work history data. We develop a skill-based model and a text-based model for career path prediction, which achieve 35.24% and 39.61% recall@10 respectively on our dataset. Finally, we show that both approaches are complementary as a hybrid approach achieves the strongest result with 43.01% recall@10. ",
    "url": "https://arxiv.org/abs/2310.15636",
    "authors": [
      "Jens-Joris Decorte",
      "Jeroen Van Hautte",
      "Johannes Deleu",
      "Chris Develder",
      "Thomas Demeester"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.15641",
    "title": "Guaranteed Coverage Prediction Intervals with Gaussian Process  Regression",
    "abstract": "Gaussian Process Regression (GPR) is a popular regression method, which unlike most Machine Learning techniques, provides estimates of uncertainty for its predictions. These uncertainty estimates however, are based on the assumption that the model is well-specified, an assumption that is violated in most practical applications, since the required knowledge is rarely available. As a result, the produced uncertainty estimates can become very misleading; for example the prediction intervals (PIs) produced for the 95\\% confidence level may cover much less than 95\\% of the true labels. To address this issue, this paper introduces an extension of GPR based on a Machine Learning framework called, Conformal Prediction (CP). This extension guarantees the production of PIs with the required coverage even when the model is completely misspecified. The proposed approach combines the advantages of GPR with the valid coverage guarantee of CP, while the performed experimental results demonstrate its superiority over existing methods. ",
    "url": "https://arxiv.org/abs/2310.15641",
    "authors": [
      "Harris Papadopoulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15645",
    "title": "Light up that Droid! On the Effectiveness of Static Analysis Features  against App Obfuscation for Android Malware Detection",
    "abstract": "Malware authors have seen obfuscation as the mean to bypass malware detectors based on static analysis features. For Android, several studies have confirmed that many anti-malware products are easily evaded with simple program transformations. As opposed to these works, ML detection proposals for Android leveraging static analysis features have also been proposed as obfuscation-resilient. Therefore, it needs to be determined to what extent the use of a specific obfuscation strategy or tool poses a risk for the validity of ML malware detectors for Android based on static analysis features. To shed some light in this regard, in this article we assess the impact of specific obfuscation techniques on common features extracted using static analysis and determine whether the changes are significant enough to undermine the effectiveness of ML malware detectors that rely on these features. The experimental results suggest that obfuscation techniques affect all static analysis features to varying degrees across different tools. However, certain features retain their validity for ML malware detection even in the presence of obfuscation. Based on these findings, we propose a ML malware detector for Android that is robust against obfuscation and outperforms current state-of-the-art detectors. ",
    "url": "https://arxiv.org/abs/2310.15645",
    "authors": [
      "Borja Molina-Coronado",
      "Antonio Ruggia",
      "Usue Mori",
      "Alessio Merlo",
      "Alexander Mendiburu",
      "Jose Miguel-Alonso"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.15646",
    "title": "Mean Teacher DETR with Masked Feature Alignment: A Robust Domain  Adaptive Detection Transformer Framework",
    "abstract": "Unsupervised domain adaptation object detection(UDAOD) research on Detection Transformer(DETR) mainly focuses on feature alignment and existing methods can be divided into two kinds, each of which has its unresolved issues. One-stage feature alignment methods can easily lead to performance fluctuation and training stagnation. Two-stage feature alignment method based on mean teacher comprises a pretraining stage followed by a self-training stage, each facing problems in obtaining reliable pretrained model and achieving consistent performance gains. Methods mentioned above have not yet explore how to utilize the third related domain such as target-like domain to assist adaptation. To address these issues, we propose a two-stage framework named MTM, i.e. Mean Teacher-DETR with Masked Feature Alignment. In the pretraining stage, we utilize labeled target-like images produced by image style transfer to avoid performance fluctuation. In the self-training stage, we leverage unlabeled target images by pseudo labels based on mean teacher and propose a module called Object Queries Knowledge Transfer(OQKT) to ensure consistent performance gains of the student model. Most importantly, we propose masked feature alignment methods including Masked Domain Query-based Feature Alignment(MDQFA) and Masked Token-wise Feature Alignment(MTWFA) to alleviate domain shift in a more robust way, which not only prevent training stagnation and lead to a robust pretrained model in the pretraining stage, but also enhance the model's target performance in the self-training stage. Experiments on three challenging scenarios and a theoretical analysis verify the effectiveness of MTM. ",
    "url": "https://arxiv.org/abs/2310.15646",
    "authors": [
      "Weixi Weng",
      "Chun Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.15648",
    "title": "Dynamic Convolutional Neural Networks as Efficient Pre-trained Audio  Models",
    "abstract": "The introduction of large-scale audio datasets, such as AudioSet, paved the way for Transformers to conquer the audio domain and replace CNNs as the state-of-the-art neural network architecture for many tasks. Audio Spectrogram Transformers are excellent at exploiting large datasets, creating powerful pre-trained models that surpass CNNs when fine-tuned on downstream tasks. However, current popular Audio Spectrogram Transformers are demanding in terms of computational complexity compared to CNNs. Recently, we have shown that, by employing Transformer-to-CNN Knowledge Distillation, efficient CNNs can catch up with and even outperform Transformers on large datasets. In this work, we extend this line of research and increase the capacity of efficient CNNs by introducing dynamic CNN blocks, constructed of dynamic non-linearities, dynamic convolutions and attention mechanisms. We show that these dynamic CNNs outperform traditional efficient CNNs, in terms of the performance-complexity trade-off and parameter efficiency, at the task of audio tagging on the large-scale AudioSet. Our experiments further indicate that the introduced dynamic CNNs achieve better performance on downstream tasks and scale up well, attaining Transformer performance and even outperforming them on AudioSet and several downstream tasks. ",
    "url": "https://arxiv.org/abs/2310.15648",
    "authors": [
      "Florian Schmid",
      "Khaled Koutini",
      "Gerhard Widmer"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.15653",
    "title": "Deceptive Fairness Attacks on Graphs via Meta Learning",
    "abstract": "We study deceptive fairness attacks on graphs to answer the following question: How can we achieve poisoning attacks on a graph learning model to exacerbate the bias deceptively? We answer this question via a bi-level optimization problem and propose a meta learning-based framework named FATE. FATE is broadly applicable with respect to various fairness definitions and graph learning models, as well as arbitrary choices of manipulation operations. We further instantiate FATE to attack statistical parity and individual fairness on graph neural networks. We conduct extensive experimental evaluations on real-world datasets in the task of semi-supervised node classification. The experimental results demonstrate that FATE could amplify the bias of graph neural networks with or without fairness consideration while maintaining the utility on the downstream task. We hope this paper provides insights into the adversarial robustness of fair graph learning and can shed light on designing robust and fair graph learning in future studies. ",
    "url": "https://arxiv.org/abs/2310.15653",
    "authors": [
      "Jian Kang",
      "Yinglong Xia",
      "Ross Maciejewski",
      "Jiebo Luo",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.15654",
    "title": "A Survey on Detection of LLMs-Generated Content",
    "abstract": "The burgeoning capabilities of advanced large language models (LLMs) such as ChatGPT have led to an increase in synthetic content generation with implications across a variety of sectors, including media, cybersecurity, public discourse, and education. As such, the ability to detect LLMs-generated content has become of paramount importance. We aim to provide a detailed overview of existing detection strategies and benchmarks, scrutinizing their differences and identifying key challenges and prospects in the field, advocating for more adaptable and robust models to enhance detection accuracy. We also posit the necessity for a multi-faceted approach to defend against various attacks to counter the rapidly advancing capabilities of LLMs. To the best of our knowledge, this work is the first comprehensive survey on the detection in the era of LLMs. We hope it will provide a broad understanding of the current landscape of LLMs-generated content detection, offering a guiding reference for researchers and practitioners striving to uphold the integrity of digital information in an era increasingly dominated by synthetic content. The relevant papers are summarized and will be consistently updated at https://github.com/Xianjun-Yang/Awesome_papers_on_LLMs_detection.git. ",
    "url": "https://arxiv.org/abs/2310.15654",
    "authors": [
      "Xianjun Yang",
      "Liangming Pan",
      "Xuandong Zhao",
      "Haifeng Chen",
      "Linda Petzold",
      "William Yang Wang",
      "Wei Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15655",
    "title": "Breaking of brightness consistency in optical flow with a lightweight  CNN network",
    "abstract": "Sparse optical flow is widely used in various computer vision tasks, however assuming brightness consistency limits its performance in High Dynamic Range (HDR) environments. In this work, a lightweight network is used to extract illumination robust convolutional features and corners with strong invariance. Modifying the typical brightness consistency of the optical flow method to the convolutional feature consistency yields the light-robust hybrid optical flow method. The proposed network runs at 190 FPS on a commercial CPU because it uses only four convolutional layers to extract feature maps and score maps simultaneously. Since the shallow network is difficult to train directly, a deep network is designed to compute the reliability map that helps it. An end-to-end unsupervised training mode is used for both networks. To validate the proposed method, we compare corner repeatability and matching performance with origin optical flow under dynamic illumination. In addition, a more accurate visual inertial system is constructed by replacing the optical flow method in VINS-Mono. In a public HDR dataset, it reduces translation errors by 93\\%. The code is publicly available at https://github.com/linyicheng1/LET-NET. ",
    "url": "https://arxiv.org/abs/2310.15655",
    "authors": [
      "Yicheng Lin",
      "Shuo Wang",
      "Yunlong Jiang",
      "Bin Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.15656",
    "title": "Momentum Gradient-based Untargeted Attack on Hypergraph Neural Networks",
    "abstract": "Hypergraph Neural Networks (HGNNs) have been successfully applied in various hypergraph-related tasks due to their excellent higher-order representation capabilities. Recent works have shown that deep learning models are vulnerable to adversarial attacks. Most studies on graph adversarial attacks have focused on Graph Neural Networks (GNNs), and the study of adversarial attacks on HGNNs remains largely unexplored. In this paper, we try to reduce this gap. We design a new HGNNs attack model for the untargeted attack, namely MGHGA, which focuses on modifying node features. We consider the process of HGNNs training and use a surrogate model to implement the attack before hypergraph modeling. Specifically, MGHGA consists of two parts: feature selection and feature modification. We use a momentum gradient mechanism to choose the attack node features in the feature selection module. In the feature modification module, we use two feature generation approaches (direct modification and sign gradient) to enable MGHGA to be employed on discrete and continuous datasets. We conduct extensive experiments on five benchmark datasets to validate the attack performance of MGHGA in the node and the visual object classification tasks. The results show that MGHGA improves performance by an average of 2% compared to the than the baselines. ",
    "url": "https://arxiv.org/abs/2310.15656",
    "authors": [
      "Yang Chen",
      "Stjepan Picek",
      "Zhonglin Ye",
      "Zhaoyang Wang",
      "Haixing Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15657",
    "title": "Testing the Limits: Unusual Text Inputs Generation for Mobile App Crash  Detection with Large Language Model",
    "abstract": "Mobile applications have become a ubiquitous part of our daily life, providing users with access to various services and utilities. Text input, as an important interaction channel between users and applications, plays an important role in core functionality such as search queries, authentication, messaging, etc. However, certain special text (e.g., -18 for Font Size) can cause the app to crash, and generating diversified unusual inputs for fully testing the app is highly demanded. Nevertheless, this is also challenging due to the combination of explosion dilemma, high context sensitivity, and complex constraint relations. This paper proposes InputBlaster which leverages the LLM to automatically generate unusual text inputs for mobile app crash detection. It formulates the unusual inputs generation problem as a task of producing a set of test generators, each of which can yield a batch of unusual text inputs under the same mutation rule. In detail, InputBlaster leverages LLM to produce the test generators together with the mutation rules serving as the reasoning chain, and utilizes the in-context learning schema to demonstrate the LLM with examples for boosting the performance. InputBlaster is evaluated on 36 text input widgets with cash bugs involving 31 popular Android apps, and results show that it achieves 78% bug detection rate, with 136% higher than the best baseline. Besides, we integrate it with the automated GUI testing tool and detect 37 unseen crashes in real-world apps from Google Play. ",
    "url": "https://arxiv.org/abs/2310.15657",
    "authors": [
      "Zhe Liu",
      "Chunyang Chen",
      "Junjie Wang",
      "Mengzhuo Chen",
      "Boyu Wu",
      "Xing Che",
      "Dandan Wang",
      "Qing Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.15669",
    "title": "Robust Methods for Multiscale Coarse Approximations of Diffusion Models  in Perforated Domains",
    "abstract": "For the Poisson equation posed in a domain containing a large number of polygonal perforations, we propose a low-dimensional coarse approximation space based on a coarse polygonal partitioning of the domain. Similarly to other multiscale numerical methods, this coarse space is spanned by locally discrete harmonic basis functions. Along the subdomain boundaries, the basis functions are piecewise polynomial. The main contribution of this article is an error estimate regarding the H1-projection over the coarse space which depends only on the regularity of the solution over the edges of the coarse partitioning. For a specific edge refinement procedure, the error analysis establishes superconvergence of the method even if the true solution has a low general regularity. Combined with domain decomposition (DD) methods, the coarse space leads to an efficient two-level iterative linear solver which reaches the fine-scale finite element error in few iterations. It also bodes well as a preconditioner for Krylov methods and provides scalability with respect to the number of subdomains. Numerical experiments showcase the increased precision of the coarse approximation as well as the efficiency and scalability of the coarse space as a component of a DD algorithm. ",
    "url": "https://arxiv.org/abs/2310.15669",
    "authors": [
      "Miranda Boutilier",
      "Konstantin Brenner",
      "Victorita Dolean"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.15670",
    "title": "Leveraging Vision-Centric Multi-Modal Expertise for 3D Object Detection",
    "abstract": "Current research is primarily dedicated to advancing the accuracy of camera-only 3D object detectors (apprentice) through the knowledge transferred from LiDAR- or multi-modal-based counterparts (expert). However, the presence of the domain gap between LiDAR and camera features, coupled with the inherent incompatibility in temporal fusion, significantly hinders the effectiveness of distillation-based enhancements for apprentices. Motivated by the success of uni-modal distillation, an apprentice-friendly expert model would predominantly rely on camera features, while still achieving comparable performance to multi-modal models. To this end, we introduce VCD, a framework to improve the camera-only apprentice model, including an apprentice-friendly multi-modal expert and temporal-fusion-friendly distillation supervision. The multi-modal expert VCD-E adopts an identical structure as that of the camera-only apprentice in order to alleviate the feature disparity, and leverages LiDAR input as a depth prior to reconstruct the 3D scene, achieving the performance on par with other heterogeneous multi-modal experts. Additionally, a fine-grained trajectory-based distillation module is introduced with the purpose of individually rectifying the motion misalignment for each object in the scene. With those improvements, our camera-only apprentice VCD-A sets new state-of-the-art on nuScenes with a score of 63.1% NDS. ",
    "url": "https://arxiv.org/abs/2310.15670",
    "authors": [
      "Linyan Huang",
      "Zhiqi Li",
      "Chonghao Sima",
      "Wenhai Wang",
      "Jingdong Wang",
      "Yu Qiao",
      "Hongyang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.15677",
    "title": "Robot-Relay : Building-Wide, Calibration-Less Visual Servoing with  Learned Sensor Handover Network",
    "abstract": "We present a system which grows and manages a network of remote viewpoints during the natural installation cycle for a newly installed camera network or a newly deployed robot fleet. No explicit notion of camera position or orientation is required, neither global - i.e. relative to a building plan - nor local - i.e. relative to an interesting point in a room. Furthermore, no metric relationship between viewpoints is required. Instead, we leverage our prior work in effective remote control without extrinsic or intrinsic calibration and extend it to the multi-camera setting. In this, we memorise, from simultaneous robot detections in the tracker thread, soft pixel-wise topological connections between viewpoints. We demonstrate our system with repeated autonomous traversals of workspaces connected by a network of six cameras across a productive office environment. ",
    "url": "https://arxiv.org/abs/2310.15677",
    "authors": [
      "Luke Robinson",
      "Matthew Gadd",
      "Paul Newman",
      "Daniele De Martini"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.15690",
    "title": "Physics-Informed with Power-Enhanced Residual Network for Interpolation  and Inverse Problems",
    "abstract": "This paper introduces a novel neural network structure called the Power-Enhancing residual network, designed to improve interpolation capabilities for both smooth and non-smooth functions in 2D and 3D settings. By adding power terms to residual elements, the architecture boosts the network's expressive power. The study explores network depth, width, and optimization methods, showing the architecture's adaptability and performance advantages. Consistently, the results emphasize the exceptional accuracy of the proposed Power-Enhancing residual network, particularly for non-smooth functions. Real-world examples also confirm its superiority over plain neural network in terms of accuracy, convergence, and efficiency. The study also looks at the impact of deeper network. Moreover, the proposed architecture is also applied to solving the inverse Burgers' equation, demonstrating superior performance. In conclusion, the Power-Enhancing residual network offers a versatile solution that significantly enhances neural network capabilities. The codes implemented are available at: \\url{https://github.com/CMMAi/ResNet_for_PINN}. ",
    "url": "https://arxiv.org/abs/2310.15690",
    "authors": [
      "Amir Noorizadegan",
      "D.L. Young",
      "Y.C. Hon",
      "C.S. Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2310.15692",
    "title": "Graph-based Trajectory Prediction with Cooperative Information",
    "abstract": "For automated driving, predicting the future trajectories of other road users in complex traffic situations is a hard problem. Modern neural networks use the past trajectories of traffic participants as well as map data to gather hints about the possible driver intention and likely maneuvers. With increasing connectivity between cars and other traffic actors, cooperative information is another source of data that can be used as inputs for trajectory prediction algorithms. Connected actors might transmit their intended path or even complete planned trajectories to other actors, which simplifies the prediction problem due to the imposed constraints. In this work, we outline the benefits of using this source of data for trajectory prediction and propose a graph-based neural network architecture that can leverage this additional data. We show that the network performance increases substantially if cooperative data is present. Also, our proposed training scheme improves the network's performance even for cases where no cooperative information is available. We also show that the network can deal with inaccurate cooperative data, which allows it to be used in real automated driving environments. ",
    "url": "https://arxiv.org/abs/2310.15692",
    "authors": [
      "Jan Strohbeck",
      "Sebastian Maschke",
      "Max Mertens",
      "Michael Buchholz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.15702",
    "title": "Enhancing Biomedical Lay Summarisation with External Knowledge Graphs",
    "abstract": "Previous approaches for automatic lay summarisation are exclusively reliant on the source article that, given it is written for a technical audience (e.g., researchers), is unlikely to explicitly define all technical concepts or state all of the background information that is relevant for a lay audience. We address this issue by augmenting eLife, an existing biomedical lay summarisation dataset, with article-specific knowledge graphs, each containing detailed information on relevant biomedical concepts. Using both automatic and human evaluations, we systematically investigate the effectiveness of three different approaches for incorporating knowledge graphs within lay summarisation models, with each method targeting a distinct area of the encoder-decoder model architecture. Our results confirm that integrating graph-based domain knowledge can significantly benefit lay summarisation by substantially increasing the readability of generated text and improving the explanation of technical concepts. ",
    "url": "https://arxiv.org/abs/2310.15702",
    "authors": [
      "Tomas Goldsack",
      "Zhihao Zhang",
      "Chen Tang",
      "Carolina Scarton",
      "Chenghua Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.15705",
    "title": "Learning-based Scheduling for Information Accuracy and Freshness in  Wireless Networks",
    "abstract": "We consider a system of multiple sources, a single communication channel, and a single monitoring station. Each source measures a time-varying quantity with varying levels of accuracy and one of them sends its update to the monitoring station via the channel. The probability of success of each attempted communication is a function of the source scheduled for transmitting its update. Both the probability of correct measurement and the probability of successful transmission of all the sources are unknown to the scheduler. The metric of interest is the reward received by the system which depends on the accuracy of the last update received by the destination and the Age-of-Information (AoI) of the system. We model our scheduling problem as a variant of the multi-arm bandit problem with sources as different arms. We compare the performance of all $4$ standard bandit policies, namely, ETC, $\\epsilon$-greedy, UCB, and TS suitably adjusted to our system model via simulations. In addition, we provide analytical guarantees of $2$ of these policies, ETC, and $\\epsilon$-greedy. Finally, we characterize the lower bound on the cumulative regret achievable by any policy. ",
    "url": "https://arxiv.org/abs/2310.15705",
    "authors": [
      "Hitesh Gudwani"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.15712",
    "title": "GNeSF: Generalizable Neural Semantic Fields",
    "abstract": "3D scene segmentation based on neural implicit representation has emerged recently with the advantage of training only on 2D supervision. However, existing approaches still requires expensive per-scene optimization that prohibits generalization to novel scenes during inference. To circumvent this problem, we introduce a generalizable 3D segmentation framework based on implicit representation. Specifically, our framework takes in multi-view image features and semantic maps as the inputs instead of only spatial information to avoid overfitting to scene-specific geometric and semantic information. We propose a novel soft voting mechanism to aggregate the 2D semantic information from different views for each 3D point. In addition to the image features, view difference information is also encoded in our framework to predict the voting scores. Intuitively, this allows the semantic information from nearby views to contribute more compared to distant ones. Furthermore, a visibility module is also designed to detect and filter out detrimental information from occluded views. Due to the generalizability of our proposed method, we can synthesize semantic maps or conduct 3D semantic segmentation for novel scenes with solely 2D semantic supervision. Experimental results show that our approach achieves comparable performance with scene-specific approaches. More importantly, our approach can even outperform existing strong supervision-based approaches with only 2D annotations. Our source code is available at: https://github.com/HLinChen/GNeSF. ",
    "url": "https://arxiv.org/abs/2310.15712",
    "authors": [
      "Hanlin Chen",
      "Chen Li",
      "Mengqi Guo",
      "Zhiwen Yan",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.15722",
    "title": "Re-Temp: Relation-Aware Temporal Representation Learning for Temporal  Knowledge Graph Completion",
    "abstract": "Temporal Knowledge Graph Completion (TKGC) under the extrapolation setting aims to predict the missing entity from a fact in the future, posing a challenge that aligns more closely with real-world prediction problems. Existing research mostly encodes entities and relations using sequential graph neural networks applied to recent snapshots. However, these approaches tend to overlook the ability to skip irrelevant snapshots according to entity-related relations in the query and disregard the importance of explicit temporal information. To address this, we propose our model, Re-Temp (Relation-Aware Temporal Representation Learning), which leverages explicit temporal embedding as input and incorporates skip information flow after each timestamp to skip unnecessary information for prediction. Additionally, we introduce a two-phase forward propagation method to prevent information leakage. Through the evaluation on six TKGC (extrapolation) datasets, we demonstrate that our model outperforms all eight recent state-of-the-art models by a significant margin. ",
    "url": "https://arxiv.org/abs/2310.15722",
    "authors": [
      "Kunze Wang",
      "Soyeon Caren Han",
      "Josiah Poon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.15725",
    "title": "Query-adaptive DETR for Crowded Pedestrian Detection",
    "abstract": "DEtection TRansformer (DETR) and its variants (DETRs) have been successfully applied to crowded pedestrian detection, which achieved promising performance. However, we find that, in different degrees of crowded scenes, the number of DETRs' queries must be adjusted manually, otherwise, the performance would degrade to varying degrees. In this paper, we first analyze the two current query generation methods and summarize four guidelines for designing the adaptive query generation method. Then, we propose Rank-based Adaptive Query Generation (RAQG) to alleviate the problem. Specifically, we design a rank prediction head that can predict the rank of the lowest confidence positive training sample produced by the encoder. Based on the predicted rank, we design an adaptive selection method that can adaptively select coarse detection results produced by the encoder to generate queries. Moreover, to train the rank prediction head better, we propose Soft Gradient L1 Loss. The gradient of Soft Gradient L1 Loss is continuous, which can describe the relationship between the loss value and the updated value of model parameters granularly. Our method is simple and effective, which can be plugged into any DETRs to make it query-adaptive in theory. The experimental results on Crowdhuman dataset and Citypersons dataset show that our method can adaptively generate queries for DETRs and achieve competitive results. Especially, our method achieves state-of-the-art 39.4% MR on Crowdhuman dataset. ",
    "url": "https://arxiv.org/abs/2310.15725",
    "authors": [
      "Feng Gao",
      "Jiaxu Leng",
      "Ji Gan",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.15745",
    "title": "Integrating Battery-Less Energy Harvesting Devices in Multi-hop  Industrial Wireless Sensor Networks",
    "abstract": "Industrial wireless sensor networks enable real-time data collection, analysis, and control by interconnecting diverse industrial devices. In these industrial settings, power outlets are not always available, and reliance on battery power can be impractical due to the need for frequent battery replacement or stringent safety regulations. Battery-less energy harvesters present a suitable alternative for powering these devices. However, these energy harvesters, equipped with supercapacitors instead of batteries, suffer from intermittent on-off behavior due to their limited energy storage capacity. As a result, they struggle with extended or frequent energy-consuming phases of multi-hop network formation, such as network joining and synchronization. To address these challenges, our work proposes three strategies for integrating battery-less energy harvesting devices into industrial multi-hop wireless sensor networks. In contrast to other works, our work prioritizes the mitigation of intermittency-related issues, rather than focusing solely on average energy consumption, as is typically the case with battery-powered devices. For each of the proposed strategies, we provide an in-depth discussion of their suitability based on several critical factors, including the type of energy source, storage capacity, device mobility, latency, and reliability. ",
    "url": "https://arxiv.org/abs/2310.15745",
    "authors": [
      "Dries Van Leemput",
      "Jeroen Hoebeke",
      "Eli De Poorter"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.15747",
    "title": "Large Language Models are Temporal and Causal Reasoners for Video  Question Answering",
    "abstract": "Large Language Models (LLMs) have shown remarkable performances on a wide range of natural language understanding and generation tasks. We observe that the LLMs provide effective priors in exploiting $\\textit{linguistic shortcuts}$ for temporal and causal reasoning in Video Question Answering (VideoQA). However, such priors often cause suboptimal results on VideoQA by leading the model to over-rely on questions, $\\textit{i.e.}$, $\\textit{linguistic bias}$, while ignoring visual content. This is also known as `ungrounded guesses' or `hallucinations'. To address this problem while leveraging LLMs' prior on VideoQA, we propose a novel framework, Flipped-VQA, encouraging the model to predict all the combinations of $\\langle$V, Q, A$\\rangle$ triplet by flipping the source pair and the target label to understand their complex relationships, $\\textit{i.e.}$, predict A, Q, and V given a VQ, VA, and QA pairs, respectively. In this paper, we develop LLaMA-VQA by applying Flipped-VQA to LLaMA, and it outperforms both LLMs-based and non-LLMs-based models on five challenging VideoQA benchmarks. Furthermore, our Flipped-VQA is a general framework that is applicable to various LLMs (OPT and GPT-J) and consistently improves their performances. We empirically demonstrate that Flipped-VQA not only enhances the exploitation of linguistic shortcuts but also mitigates the linguistic bias, which causes incorrect answers over-relying on the question. Code is available at https://github.com/mlvlab/Flipped-VQA. ",
    "url": "https://arxiv.org/abs/2310.15747",
    "authors": [
      "Dohwan Ko",
      "Ji Soo Lee",
      "Wooyoung Kang",
      "Byungseok Roh",
      "Hyunwoo J. Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.15761",
    "title": "Agent-based models of social behaviour and communication in evacuations:  A systematic review",
    "abstract": "Most modern agent-based evacuation models involve interactions between evacuees. However, the assumed reasons for interactions and portrayal of them may be overly simple. Research from social psychology suggests that people interact and communicate with one another when evacuating and evacuee response is impacted by the way information is communicated. Thus, we conducted a systematic review of agent-based evacuation models to identify 1) how social interactions and communication approaches between agents are simulated, and 2) what key variables related to evacuation are addressed in these models. We searched Web of Science and ScienceDirect to identify articles that simulated information exchange between agents during evacuations, and social behaviour during evacuations. From the final 70 included articles, we categorised eight types of social interaction that increased in social complexity from collision avoidance to social influence based on strength of social connections with other agents. In the 17 models which simulated communication, we categorised four ways that agents communicate information: spatially through information trails or radii around agents, via social networks and via external communication. Finally, the variables either manipulated or measured in the models were categorised into the following groups: environmental condition, personal attributes of the agents, procedure, and source of information. We discuss promising directions for agent-based evacuation models to capture the effects of communication and group dynamics on evacuee behaviour. Moreover, we demonstrate how communication and group dynamics may impact the variables commonly used in agent-based evacuation models. ",
    "url": "https://arxiv.org/abs/2310.15761",
    "authors": [
      "Anne Templeton",
      "Hui Xie",
      "Steve Gwynne",
      "Aoife Hunt",
      "Pete Thompson",
      "Gerta K\u00f6ster"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2310.15762",
    "title": "SharkGraph: A Time Series Distributed Graph System",
    "abstract": "Current graph systems can easily process billions of data, however when increased to exceed hundred billions, the performance decreases dramatically, time series data always be very huge, consequently computation on time series graphs still remains challenging nowadays. In current piece of work, we introduces SharkGraph, a (distributed file system) DFS-based time series graph system, used a novel storage structure (Time Series Graph Data File) TGF, By reading file stream to iterate graph computation, SharkGraph is able to execute batch graph query, simulation, data mining, or clustering algorithm on exceed hundred billions edge size industry graph. Through well defined experiments that shows SharkGraph performs well on large-scale graph processing, also can support time traversal for graphs, and recover state at any position in the timeline. By repeating experiments reported for existing distributed systems like GraphX, we demonstrate that SharkGraph can easily handle hundreds billions of data, rather than GraphX which met many problems such as memory issues and skewed distribution on graph traversal. Compared with other graph systems SharkGraph uses less memory and more efficiently to process the same graph. ",
    "url": "https://arxiv.org/abs/2310.15762",
    "authors": [
      "Derong Tang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2310.15766",
    "title": "Robust Learning via Conditional Prevalence Adjustment",
    "abstract": "Healthcare data often come from multiple sites in which the correlations between confounding variables can vary widely. If deep learning models exploit these unstable correlations, they might fail catastrophically in unseen sites. Although many methods have been proposed to tackle unstable correlations, each has its limitations. For example, adversarial training forces models to completely ignore unstable correlations, but doing so may lead to poor predictive performance. Other methods (e.g. Invariant risk minimization [4]) try to learn domain-invariant representations that rely only on stable associations by assuming a causal data-generating process (input X causes class label Y ). Thus, they may be ineffective for anti-causal tasks (Y causes X), which are common in computer vision. We propose a method called CoPA (Conditional Prevalence-Adjustment) for anti-causal tasks. CoPA assumes that (1) generation mechanism is stable, i.e. label Y and confounding variable(s) Z generate X, and (2) the unstable conditional prevalence in each site E fully accounts for the unstable correlations between X and Y . Our crucial observation is that confounding variables are routinely recorded in healthcare settings and the prevalence can be readily estimated, for example, from a set of (Y, Z) samples (no need for corresponding samples of X). CoPA can work even if there is a single training site, a scenario which is often overlooked by existing methods. Our experiments on synthetic and real data show CoPA beating competitive baselines. ",
    "url": "https://arxiv.org/abs/2310.15766",
    "authors": [
      "Minh Nguyen",
      "Alan Q. Wang",
      "Heejong Kim",
      "Mert R. Sabuncu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15772",
    "title": "Causal Understanding of Why Users Share Hate Speech on Social Media",
    "abstract": "Hate speech on social media threatens the mental and physical well-being of individuals and is further responsible for real-world violence. An important driver behind the spread of hate speech and thus why hateful posts can go viral are reshares, yet little is known about why users reshare hate speech. In this paper, we present a comprehensive, causal analysis of the user attributes that make users reshare hate speech. However, causal inference from observational social media data is challenging, because such data likely suffer from selection bias, and there is further confounding due to differences in the vulnerability of users to hate speech. We develop a novel, three-step causal framework: (1) We debias the observational social media data by applying inverse propensity scoring. (2) We use the debiased propensity scores to model the latent vulnerability of users to hate speech as a latent embedding. (3) We model the causal effects of user attributes on users' probability of sharing hate speech, while controlling for the latent vulnerability of users to hate speech. Compared to existing baselines, a particular strength of our framework is that it models causal effects that are non-linear, yet still explainable. We find that users with fewer followers, fewer friends, and fewer posts share more hate speech. Younger accounts, in return, share less hate speech. Overall, understanding the factors that drive users to share hate speech is crucial for detecting individuals at risk of engaging in harmful behavior and for designing effective mitigation strategies. ",
    "url": "https://arxiv.org/abs/2310.15772",
    "authors": [
      "Dominique Geissler",
      "Abdurahman Maarouf",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.15778",
    "title": "3D Masked Autoencoders for Enhanced Privacy in MRI Scans",
    "abstract": "MRI scans provide valuable medical information, however they also contain sensitive and personally identifiable information (PII) that needs to be protected. Whereas MRI metadata is easily sanitized, MRI image data is a privacy risk because it contains information to render highly-realistic 3D visualizations of a patient's head, enabling malicious actors to possibly identify the subject by cross-referencing a database. Data anonymization and de-identification is concerned with ensuring the privacy and confidentiality of individuals' personal information. Traditional MRI de-identification methods remove privacy-sensitive parts (e.g. eyes, nose etc.) from a given scan. This comes at the expense of introducing a domain shift that can throw off downstream analyses. Recently, a GAN-based approach was proposed to de-identify a patient's scan by remodeling it (e.g. changing the face) rather than by removing parts. In this work, we propose CP-MAE, a model that de-identifies the face using masked autoencoders and that outperforms all previous approaches in terms of downstream task performance as well as de-identification. With our method we are able to synthesize scans of resolution up to $256^3$ (previously 128 cubic) which constitutes an eight-fold increase in the number of voxels. Using our construction we were able to design a system that exhibits a highly robust training stage, making it easy to fit the network on novel data. ",
    "url": "https://arxiv.org/abs/2310.15778",
    "authors": [
      "Lennart Alexander Van der Goten",
      "Kevin Smith"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.15797",
    "title": "Random Entity Quantization for Parameter-Efficient Compositional  Knowledge Graph Representation",
    "abstract": "Representation Learning on Knowledge Graphs (KGs) is essential for downstream tasks. The dominant approach, KG Embedding (KGE), represents entities with independent vectors and faces the scalability challenge. Recent studies propose an alternative way for parameter efficiency, which represents entities by composing entity-corresponding codewords matched from predefined small-scale codebooks. We refer to the process of obtaining corresponding codewords of each entity as entity quantization, for which previous works have designed complicated strategies. Surprisingly, this paper shows that simple random entity quantization can achieve similar results to current strategies. We analyze this phenomenon and reveal that entity codes, the quantization outcomes for expressing entities, have higher entropy at the code level and Jaccard distance at the codeword level under random entity quantization. Therefore, different entities become more easily distinguished, facilitating effective KG representation. The above results show that current quantization strategies are not critical for KG representation, and there is still room for improvement in entity distinguishability beyond current strategies. The code to reproduce our results is available at https://github.com/JiaangL/RandomQuantization. ",
    "url": "https://arxiv.org/abs/2310.15797",
    "authors": [
      "Jiaang Li",
      "Quan Wang",
      "Yi Liu",
      "Licheng Zhang",
      "Zhendong Mao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15799",
    "title": "DALE: Generative Data Augmentation for Low-Resource Legal NLP",
    "abstract": "We present DALE, a novel and effective generative Data Augmentation framework for low-resource LEgal NLP. DALE addresses the challenges existing frameworks pose in generating effective data augmentations of legal documents - legal language, with its specialized vocabulary and complex semantics, morphology, and syntax, does not benefit from data augmentations that merely rephrase the source sentence. To address this, DALE, built on an Encoder-Decoder Language Model, is pre-trained on a novel unsupervised text denoising objective based on selective masking - our masking strategy exploits the domain-specific language characteristics of templatized legal documents to mask collocated spans of text. Denoising these spans helps DALE acquire knowledge about legal concepts, principles, and language usage. Consequently, it develops the ability to generate coherent and diverse augmentations with novel contexts. Finally, DALE performs conditional generation to generate synthetic augmentations for low-resource Legal NLP tasks. We demonstrate the effectiveness of DALE on 13 datasets spanning 6 tasks and 4 low-resource settings. DALE outperforms all our baselines, including LLMs, qualitatively and quantitatively, with improvements of 1%-50%. ",
    "url": "https://arxiv.org/abs/2310.15799",
    "authors": [
      "Sreyan Ghosh",
      "Chandra Kiran Evuru",
      "Sonal Kumar",
      "S Ramaneswaran",
      "S Sakshi",
      "Utkarsh Tyagi",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.15808",
    "title": "Dissecting the Performance of Satellite Network Operators",
    "abstract": "The rapid growth of satellite network operators (SNOs) has revolutionized broadband communications, enabling global connectivity and bridging the digital divide. As these networks expand, it is important to evaluate their performance and efficiency. This paper presents the first comprehensive study of SNOs. We take an opportunistic approach and devise a methodology which allows to identify public network measurements performed via SNOs. We apply this methodology to both M-Lab and RIPE public datasets which allowed us to characterize low level performance and footprint of up to 18 SNOs operating in different orbits. Finally, we identify and recruit paid testers on three popular SNOs (Starlink, HughesNet, and ViaSat) to evaluate the performance of popular applications like web browsing and video streaming. ",
    "url": "https://arxiv.org/abs/2310.15808",
    "authors": [
      "Aravindh Raman",
      "Matteo Varvello",
      "Hyunseok Chang",
      "Nishanth Sastry",
      "Yasir Zaki"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.15819",
    "title": "Generative Language Models Exhibit Social Identity Biases",
    "abstract": "The surge in popularity of large language models has given rise to concerns about biases that these models could learn from humans. In this study, we investigate whether ingroup solidarity and outgroup hostility, fundamental social biases known from social science, are present in 51 large language models. We find that almost all foundational language models and some instruction fine-tuned models exhibit clear ingroup-positive and outgroup-negative biases when prompted to complete sentences (e.g., \"We are...\"). A comparison of LLM-generated sentences with human-written sentences on the internet reveals that these models exhibit similar level, if not greater, levels of bias than human text. To investigate where these biases stem from, we experimentally varied the amount of ingroup-positive or outgroup-negative sentences the model was exposed to during fine-tuning in the context of the United States Democrat-Republican divide. Doing so resulted in the models exhibiting a marked increase in ingroup solidarity and an even greater increase in outgroup hostility. Furthermore, removing either ingroup-positive or outgroup-negative sentences (or both) from the fine-tuning data leads to a significant reduction in both ingroup solidarity and outgroup hostility, suggesting that biases can be reduced by removing biased training data. Our findings suggest that modern language models exhibit fundamental social identity biases and that such biases can be mitigated by curating training data. Our results have practical implications for creating less biased large-language models and further underscore the need for more research into user interactions with LLMs to prevent potential bias reinforcement in humans. ",
    "url": "https://arxiv.org/abs/2310.15819",
    "authors": [
      "Tiancheng Hu",
      "Yara Kyrychenko",
      "Steve Rathje",
      "Nigel Collier",
      "Sander van der Linden",
      "Jon Roozenbeek"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.15830",
    "title": "Localization of Small Leakages in Water Distribution Networks using  Concept Drift Explanation Methods",
    "abstract": "Facing climate change the already limited availability of drinking water will decrease in the future rendering drinking water an increasingly scarce resource. Considerable amounts of it are lost through leakages in water transportation and distribution networks. Leakage detection and localization are challenging problems due to the complex interactions and changing demands in water distribution networks. Especially small leakages are hard to pinpoint yet their localization is vital to avoid water loss over long periods of time. While there exist different approaches to solving the tasks of leakage detection and localization, they are relying on various information about the system, e.g. real-time demand measurements and the precise network topology, which is an unrealistic assumption in many real-world scenarios. In contrast, this work attempts leakage localization using pressure measurements only. For this purpose, first, leakages in the water distribution network are modeled employing Bayesian networks, and the system dynamics are analyzed. We then show how the problem is connected to and can be considered through the lens of concept drift. In particular, we argue that model-based explanations of concept drift are a promising tool for localizing leakages given limited information about the network. The methodology is experimentally evaluated using realistic benchmark scenarios. ",
    "url": "https://arxiv.org/abs/2310.15830",
    "authors": [
      "Valerie Vaquet",
      "Fabian Hinder",
      "Kathrin Lammers",
      "Jonas Vaquet",
      "Barbara Hammer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15836",
    "title": "A Diffusion Weighted Graph Framework for New Intent Discovery",
    "abstract": "New Intent Discovery (NID) aims to recognize both new and known intents from unlabeled data with the aid of limited labeled data containing only known intents. Without considering structure relationships between samples, previous methods generate noisy supervisory signals which cannot strike a balance between quantity and quality, hindering the formation of new intent clusters and effective transfer of the pre-training knowledge. To mitigate this limitation, we propose a novel Diffusion Weighted Graph Framework (DWGF) to capture both semantic similarities and structure relationships inherent in data, enabling more sufficient and reliable supervisory signals. Specifically, for each sample, we diffuse neighborhood relationships along semantic paths guided by the nearest neighbors for multiple hops to characterize its local structure discriminately. Then, we sample its positive keys and weigh them based on semantic similarities and local structures for contrastive learning. During inference, we further propose Graph Smoothing Filter (GSF) to explicitly utilize the structure relationships to filter high-frequency noise embodied in semantically ambiguous samples on the cluster boundary. Extensive experiments show that our method outperforms state-of-the-art models on all evaluation metrics across multiple benchmark datasets. Code and data are available at https://github.com/yibai-shi/DWGF. ",
    "url": "https://arxiv.org/abs/2310.15836",
    "authors": [
      "Wenkai Shi",
      "Wenbin An",
      "Feng Tian",
      "Qinghua Zheng",
      "QianYing Wang",
      "Ping Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15858",
    "title": "Topology-aware Debiased Self-supervised Graph Learning for  Recommendation",
    "abstract": "In recommendation, graph-based Collaborative Filtering (CF) methods mitigate the data sparsity by introducing Graph Contrastive Learning (GCL). However, the random negative sampling strategy in these GCL-based CF models neglects the semantic structure of users (items), which not only introduces false negatives (negatives that are similar to anchor user (item)) but also ignores the potential positive samples. To tackle the above issues, we propose Topology-aware Debiased Self-supervised Graph Learning (TDSGL) for recommendation, which constructs contrastive pairs according to the semantic similarity between users (items). Specifically, since the original user-item interaction data commendably reflects the purchasing intent of users and certain characteristics of items, we calculate the semantic similarity between users (items) on interaction data. Then, given a user (item), we construct its negative pairs by selecting users (items) which embed different semantic structures to ensure the semantic difference between the given user (item) and its negatives. Moreover, for a user (item), we design a feature extraction module that converts other semantically similar users (items) into an auxiliary positive sample to acquire a more informative representation. Experimental results show that the proposed model outperforms the state-of-the-art models significantly on three public datasets. Our model implementation codes are available at https://github.com/malajikuai/TDSGL. ",
    "url": "https://arxiv.org/abs/2310.15858",
    "authors": [
      "Lei Han",
      "Hui Yan",
      "Zhicheng Qiao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.15865",
    "title": "Using Causality-Aware Graph Neural Networks to Predict Temporal  Centralities in Dynamic Graphs",
    "abstract": "Node centralities play a pivotal role in network science, social network analysis, and recommender systems. In temporal data, static path-based centralities like closeness or betweenness can give misleading results about the true importance of nodes in a temporal graph. To address this issue, temporal generalizations of betweenness and closeness have been defined that are based on the shortest time-respecting paths between pairs of nodes. However, a major issue of those generalizations is that the calculation of such paths is computationally expensive. Addressing this issue, we study the application of De Bruijn Graph Neural Networks (DBGNN), a causality-aware graph neural network architecture, to predict temporal path-based centralities in time series data. We experimentally evaluate our approach in 13 temporal graphs from biological and social systems and show that it considerably improves the prediction of both betweenness and closeness centrality compared to a static Graph Convolutional Neural Network. ",
    "url": "https://arxiv.org/abs/2310.15865",
    "authors": [
      "Franziska Heeg",
      "Ingo Scholtes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.15888",
    "title": "State Sequences Prediction via Fourier Transform for Representation  Learning",
    "abstract": "While deep reinforcement learning (RL) has been demonstrated effective in solving complex control tasks, sample efficiency remains a key challenge due to the large amounts of data required for remarkable performance. Existing research explores the application of representation learning for data-efficient RL, e.g., learning predictive representations by predicting long-term future states. However, many existing methods do not fully exploit the structural information inherent in sequential state signals, which can potentially improve the quality of long-term decision-making but is difficult to discern in the time domain. To tackle this problem, we propose State Sequences Prediction via Fourier Transform (SPF), a novel method that exploits the frequency domain of state sequences to extract the underlying patterns in time series data for learning expressive representations efficiently. Specifically, we theoretically analyze the existence of structural information in state sequences, which is closely related to policy performance and signal regularity, and then propose to predict the Fourier transform of infinite-step future state sequences to extract such information. One of the appealing features of SPF is that it is simple to implement while not requiring storage of infinite-step future states as prediction targets. Experiments demonstrate that the proposed method outperforms several state-of-the-art algorithms in terms of both sample efficiency and performance. ",
    "url": "https://arxiv.org/abs/2310.15888",
    "authors": [
      "Mingxuan Ye",
      "Yufei Kuang",
      "Jie Wang",
      "Rui Yang",
      "Wengang Zhou",
      "Houqiang Li",
      "Feng Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15890",
    "title": "Cross-feature Contrastive Loss for Decentralized Deep Learning on  Heterogeneous Data",
    "abstract": "The current state-of-the-art decentralized learning algorithms mostly assume the data distribution to be Independent and Identically Distributed (IID). However, in practical scenarios, the distributed datasets can have significantly heterogeneous data distributions across the agents. In this work, we present a novel approach for decentralized learning on heterogeneous data, where data-free knowledge distillation through contrastive loss on cross-features is utilized to improve performance. Cross-features for a pair of neighboring agents are the features (i.e., last hidden layer activations) obtained from the data of an agent with respect to the model parameters of the other agent. We demonstrate the effectiveness of the proposed technique through an exhaustive set of experiments on various Computer Vision datasets (CIFAR-10, CIFAR-100, Fashion MNIST, and ImageNet), model architectures, and network topologies. Our experiments show that the proposed method achieves superior performance (0.2-4% improvement in test accuracy) compared to other existing techniques for decentralized learning on heterogeneous data. ",
    "url": "https://arxiv.org/abs/2310.15890",
    "authors": [
      "Sai Aparna Aketi",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15903",
    "title": "Neural Collapse in Multi-label Learning with Pick-all-label Loss",
    "abstract": "We study deep neural networks for the multi-label classification (MLab) task through the lens of neural collapse (NC). Previous works have been restricted to the multi-class classification setting and discovered a prevalent NC phenomenon comprising of the following properties for the last-layer features: (i) the variability of features within every class collapses to zero, (ii) the set of feature means form an equi-angular tight frame (ETF), and (iii) the last layer classifiers collapse to the feature mean upon some scaling. We generalize the study to multi-label learning, and prove for the first time that a generalized NC phenomenon holds with the \"pick-all-label'' formulation. Under the natural analog of the unconstrained feature model (UFM), we establish that the only global classifier of the pick-all-label cross entropy loss display the same ETF geometry which further collapse to multiplicity-1 feature class means. Besides, we discover a combinatorial property in generalized NC which is unique for multi-label learning that we call ``tag-wise average'' property, where the feature class-means of samples with multiple labels are scaled average of the feature class-means of single label tags. Theoretically, we establish global optimality result for the pick-all-label cross-entropy risk for the UFM. Additionally, We also provide empirical evidence to support our investigation into training deep neural networks on multi-label datasets, resulting in improved training efficiency. ",
    "url": "https://arxiv.org/abs/2310.15903",
    "authors": [
      "Pengyu Li",
      "Yutong Wang",
      "Xiao Li",
      "Qing Qu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15904",
    "title": "Do Stochastic Parrots have Feelings Too? Improving Neural Detection of  Synthetic Text via Emotion Recognition",
    "abstract": "Recent developments in generative AI have shone a spotlight on high-performance synthetic text generation technologies. The now wide availability and ease of use of such models highlights the urgent need to provide equally powerful technologies capable of identifying synthetic text. With this in mind, we draw inspiration from psychological studies which suggest that people can be driven by emotion and encode emotion in the text they compose. We hypothesize that pretrained language models (PLMs) have an affective deficit because they lack such an emotional driver when generating text and consequently may generate synthetic text which has affective incoherence i.e. lacking the kind of emotional coherence present in human-authored text. We subsequently develop an emotionally aware detector by fine-tuning a PLM on emotion. Experiment results indicate that our emotionally-aware detector achieves improvements across a range of synthetic text generators, various sized models, datasets, and domains. Finally, we compare our emotionally-aware synthetic text detector to ChatGPT in the task of identification of its own output and show substantial gains, reinforcing the potential of emotion as a signal to identify synthetic text. Code, models, and datasets are available at https: //github.com/alanagiasi/emoPLMsynth ",
    "url": "https://arxiv.org/abs/2310.15904",
    "authors": [
      "Alan Cowap",
      "Yvette Graham",
      "Jennifer Foster"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15905",
    "title": "Is Probing All You Need? Indicator Tasks as an Alternative to Probing  Embedding Spaces",
    "abstract": "The ability to identify and control different kinds of linguistic information encoded in vector representations of words has many use cases, especially for explainability and bias removal. This is usually done via a set of simple classification tasks, termed probes, to evaluate the information encoded in the embedding space. However, the involvement of a trainable classifier leads to entanglement between the probe's results and the classifier's nature. As a result, contemporary works on probing include tasks that do not involve training of auxiliary models. In this work we introduce the term indicator tasks for non-trainable tasks which are used to query embedding spaces for the existence of certain properties, and claim that this kind of tasks may point to a direction opposite to probes, and that this contradiction complicates the decision on whether a property exists in an embedding space. We demonstrate our claims with two test cases, one dealing with gender debiasing and another with the erasure of morphological information from embedding spaces. We show that the application of a suitable indicator provides a more accurate picture of the information captured and removed compared to probes. We thus conclude that indicator tasks should be implemented and taken into consideration when eliciting information from embedded representations. ",
    "url": "https://arxiv.org/abs/2310.15905",
    "authors": [
      "Tal Levy",
      "Omer Goldman",
      "Reut Tsarfaty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15907",
    "title": "LiCROM: Linear-Subspace Continuous Reduced Order Modeling with Neural  Fields",
    "abstract": "Linear reduced-order modeling (ROM) simplifies complex simulations by approximating the behavior of a system using a simplified kinematic representation. Typically, ROM is trained on input simulations created with a specific spatial discretization, and then serves to accelerate simulations with the same discretization. This discretization-dependence is restrictive. Becoming independent of a specific discretization would provide flexibility to mix and match mesh resolutions, connectivity, and type (tetrahedral, hexahedral) in training data; to accelerate simulations with novel discretizations unseen during training; and to accelerate adaptive simulations that temporally or parametrically change the discretization. We present a flexible, discretization-independent approach to reduced-order modeling. Like traditional ROM, we represent the configuration as a linear combination of displacement fields. Unlike traditional ROM, our displacement fields are continuous maps from every point on the reference domain to a corresponding displacement vector; these maps are represented as implicit neural fields. With linear continuous ROM (LiCROM), our training set can include multiple geometries undergoing multiple loading conditions, independent of their discretization. This opens the door to novel applications of reduced order modeling. We can now accelerate simulations that modify the geometry at runtime, for instance via cutting, hole punching, and even swapping the entire mesh. We can also accelerate simulations of geometries unseen during training. We demonstrate one-shot generalization, training on a single geometry and subsequently simulating various unseen geometries. ",
    "url": "https://arxiv.org/abs/2310.15907",
    "authors": [
      "Yue Chang",
      "Peter Yichen Chen",
      "Zhecheng Wang",
      "Maurizio M. Chiaramonte",
      "Kevin Carlberg",
      "Eitan Grinspun"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2310.15932",
    "title": "Online Robust Mean Estimation",
    "abstract": "We study the problem of high-dimensional robust mean estimation in an online setting. Specifically, we consider a scenario where $n$ sensors are measuring some common, ongoing phenomenon. At each time step $t=1,2,\\ldots,T$, the $i^{th}$ sensor reports its readings $x^{(i)}_t$ for that time step. The algorithm must then commit to its estimate $\\mu_t$ for the true mean value of the process at time $t$. We assume that most of the sensors observe independent samples from some common distribution $X$, but an $\\epsilon$-fraction of them may instead behave maliciously. The algorithm wishes to compute a good approximation $\\mu$ to the true mean $\\mu^\\ast := \\mathbf{E}[X]$. We note that if the algorithm is allowed to wait until time $T$ to report its estimate, this reduces to the well-studied problem of robust mean estimation. However, the requirement that our algorithm produces partial estimates as the data is coming in substantially complicates the situation. We prove two main results about online robust mean estimation in this model. First, if the uncorrupted samples satisfy the standard condition of $(\\epsilon,\\delta)$-stability, we give an efficient online algorithm that outputs estimates $\\mu_t$, $t \\in [T],$ such that with high probability it holds that $\\|\\mu-\\mu^\\ast\\|_2 = O(\\delta \\log(T))$, where $\\mu = (\\mu_t)_{t \\in [T]}$. We note that this error bound is nearly competitive with the best offline algorithms, which would achieve $\\ell_2$-error of $O(\\delta)$. Our second main result shows that with additional assumptions on the input (most notably that $X$ is a product distribution) there are inefficient algorithms whose error does not depend on $T$ at all. ",
    "url": "https://arxiv.org/abs/2310.15932",
    "authors": [
      "Daniel M. Kane",
      "Ilias Diakonikolas",
      "Hanshen Xiao",
      "Sihan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.15937",
    "title": "A Behavioral Perspective on Models of Linear Dynamical Networks with  Manifest Variables",
    "abstract": "Networks of dynamical systems play an important role in various domains and have motivated many studies on control and analysis of linear dynamical networks. For linear network models considered in these studies, it is typically pre-determined what signal channels are inputs and what are outputs. These models do not capture the practical need to incorporate different experimental situations, where different selections of input and output channels are applied to the same network. Moreover, a unified view on different network models is lacking. This work makes an initial step towards addressing the above issues by taking a behavioral perspective, where input and output channels are not pre-determined. The focus of this work is on behavioral network models with only external variables. Novel dual graphical representations, called system graphs and signal graphs, are introduced for behavioral networks. Moreover, connections between behavioral network models and structural vector autoregressive models are established. Besides their connection in graphical representations, it is shown that the regularity of interconnections is an essential assumption when choosing a structural vector autoregressive model. ",
    "url": "https://arxiv.org/abs/2310.15937",
    "authors": [
      "Shengling Shi",
      "Zhiyong Sun",
      "Bart De Schutter"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.15938",
    "title": "ABKD: Graph Neural Network Compression with Attention-Based Knowledge  Distillation",
    "abstract": "Graph Neural Networks (GNNs) have proven to be quite versatile for a variety of applications, including recommendation systems, fake news detection, drug discovery, and even computer vision. Due to the expanding size of graph-structured data, GNN models have also increased in complexity, leading to substantial latency issues. This is primarily attributed to the irregular structure of graph data and its access pattern into memory. The natural solution to reduce latency is to compress large GNNs into small GNNs. One way to do this is via knowledge distillation (KD). However, most KD approaches for GNNs only consider the outputs of the last layers and do not consider the outputs of the intermediate layers of the GNNs; these layers may contain important inductive biases indicated by the graph structure. To address this shortcoming, we propose a novel KD approach to GNN compression that we call Attention-Based Knowledge Distillation (ABKD). ABKD is a KD approach that uses attention to identify important intermediate teacher-student layer pairs and focuses on aligning their outputs. ABKD enables higher compression of GNNs with a smaller accuracy dropoff compared to existing KD approaches. On average, we achieve a 1.79% increase in accuracy with a 32.3x compression ratio on OGBN-Mag, a large graph dataset, compared to state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2310.15938",
    "authors": [
      "Anshul Ahluwalia",
      "Rohit Das",
      "Payman Behnam",
      "Alind Khare",
      "Pan Li",
      "Alexey Tumanov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15950",
    "title": "Representation Learning with Large Language Models for Recommendation",
    "abstract": "Recommender systems have seen significant advancements with the influence of deep learning and graph neural networks, particularly in capturing complex user-item relationships. However, these graph-based recommenders heavily depend on ID-based data, potentially disregarding valuable textual information associated with users and items, resulting in less informative learned representations. Moreover, the utilization of implicit feedback data introduces potential noise and bias, posing challenges for the effectiveness of user preference learning. While the integration of large language models (LLMs) into traditional ID-based recommenders has gained attention, challenges such as scalability issues, limitations in text-only reliance, and prompt input constraints need to be addressed for effective implementation in practical recommender systems. To address these challenges, we propose a model-agnostic framework RLMRec that aims to enhance existing recommenders with LLM-empowered representation learning. It proposes a recommendation paradigm that integrates representation learning with LLMs to capture intricate semantic aspects of user behaviors and preferences. RLMRec incorporates auxiliary textual signals, develops a user/item profiling paradigm empowered by LLMs, and aligns the semantic space of LLMs with the representation space of collaborative relational signals through a cross-view alignment framework. This work further establish a theoretical foundation demonstrating that incorporating textual signals through mutual information maximization enhances the quality of representations. In our evaluation, we integrate RLMRec with state-of-the-art recommender models, while also analyzing its efficiency and robustness to noise data. Our implementation codes are available at https://github.com/HKUDS/RLMRec. ",
    "url": "https://arxiv.org/abs/2310.15950",
    "authors": [
      "Xubin Ren",
      "Wei Wei",
      "Lianghao Xia",
      "Lixin Su",
      "Suqi Cheng",
      "Junfeng Wang",
      "Dawei Yin",
      "Chao Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.15952",
    "title": "Improving Robustness and Reliability in Medical Image Classification  with Latent-Guided Diffusion and Nested-Ensembles",
    "abstract": "While deep learning models have achieved remarkable success across a range of medical image analysis tasks, deployment of these models in real clinical contexts requires that they be robust to variability in the acquired images. While many methods apply predefined transformations to augment the training data to enhance test-time robustness, these transformations may not ensure the model's robustness to the diverse variability seen in patient images. In this paper, we introduce a novel three-stage approach based on transformers coupled with conditional diffusion models, with the goal of improving model robustness to the kinds of imaging variability commonly encountered in practice without the need for pre-determined data augmentation strategies. To this end, multiple image encoders first learn hierarchical feature representations to build discriminative latent spaces. Next, a reverse diffusion process, guided by the latent code, acts on an informative prior and proposes prediction candidates in a generative manner. Finally, several prediction candidates are aggregated in a bi-level aggregation protocol to produce the final output. Through extensive experiments on medical imaging benchmark datasets, we show that our method improves upon state-of-the-art methods in terms of robustness and confidence calibration. Additionally, we introduce a strategy to quantify the prediction uncertainty at the instance level, increasing their trustworthiness to clinicians using them in clinical practice. ",
    "url": "https://arxiv.org/abs/2310.15952",
    "authors": [
      "Xing Shen",
      "Hengguan Huang",
      "Brennan Nichyporuk",
      "Tal Arbel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.15955",
    "title": "Decoupled DETR: Spatially Disentangling Localization and Classification  for Improved End-to-End Object Detection",
    "abstract": "The introduction of DETR represents a new paradigm for object detection. However, its decoder conducts classification and box localization using shared queries and cross-attention layers, leading to suboptimal results. We observe that different regions of interest in the visual feature map are suitable for performing query classification and box localization tasks, even for the same object. Salient regions provide vital information for classification, while the boundaries around them are more favorable for box regression. Unfortunately, such spatial misalignment between these two tasks greatly hinders DETR's training. Therefore, in this work, we focus on decoupling localization and classification tasks in DETR. To achieve this, we introduce a new design scheme called spatially decoupled DETR (SD-DETR), which includes a task-aware query generation module and a disentangled feature learning process. We elaborately design the task-aware query initialization process and divide the cross-attention block in the decoder to allow the task-aware queries to match different visual regions. Meanwhile, we also observe that the prediction misalignment problem for high classification confidence and precise localization exists, so we propose an alignment loss to further guide the spatially decoupled DETR training. Through extensive experiments, we demonstrate that our approach achieves a significant improvement in MSCOCO datasets compared to previous work. For instance, we improve the performance of Conditional DETR by 4.5 AP. By spatially disentangling the two tasks, our method overcomes the misalignment problem and greatly improves the performance of DETR for object detection. ",
    "url": "https://arxiv.org/abs/2310.15955",
    "authors": [
      "Manyuan Zhang",
      "Guanglu Song",
      "Yu Liu",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.15978",
    "title": "Graph Deep Learning for Time Series Forecasting",
    "abstract": "Graph-based deep learning methods have become popular tools to process collections of correlated time series. Differently from traditional multivariate forecasting methods, neural graph-based predictors take advantage of pairwise relationships by conditioning forecasts on a (possibly dynamic) graph spanning the time series collection. The conditioning can take the form of an architectural inductive bias on the neural forecasting architecture, resulting in a family of deep learning models called spatiotemporal graph neural networks. Such relational inductive biases enable the training of global forecasting models on large time-series collections, while at the same time localizing predictions w.r.t. each element in the set (i.e., graph nodes) by accounting for local correlations among them (i.e., graph edges). Indeed, recent theoretical and practical advances in graph neural networks and deep learning for time series forecasting make the adoption of such processing frameworks appealing and timely. However, most of the studies in the literature focus on proposing variations of existing neural architectures by taking advantage of modern deep learning practices, while foundational and methodological aspects have not been subject to systematic investigation. To fill the gap, this paper aims to introduce a comprehensive methodological framework that formalizes the forecasting problem and provides design principles for graph-based predictive models and methods to assess their performance. At the same time, together with an overview of the field, we provide design guidelines, recommendations, and best practices, as well as an in-depth discussion of open challenges and future research directions. ",
    "url": "https://arxiv.org/abs/2310.15978",
    "authors": [
      "Andrea Cini",
      "Ivan Marisca",
      "Daniele Zambon",
      "Cesare Alippi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.15990",
    "title": "An Iterative Approach to Data-Driven Inference for Decoding Oscillator  Network Structures",
    "abstract": "In complex networks, interactions between multiple agents give rise to an array of intricate global dynamics, ranging from synchronization to cluster formations. Decoding the connectivity structure as well as the types of interactions from measurement data is the first step toward understanding these intriguing behaviors. In this paper, we present a bilinear optimization framework to infer both the connectivity and interaction functions of oscillator networks with the identical class of coupling functions. We then propose an iterative algorithm to solve the resulting bilinear problem and illustrate its convergence. We validate our approach on both simulated and noisy experimental datasets, where we demonstrate its effectiveness compared with existing approaches. ",
    "url": "https://arxiv.org/abs/2310.15990",
    "authors": [
      "Shicheng Li",
      "Bharat Singhal",
      "Jr-Shin Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2310.15999",
    "title": "Transitivity Recovering Decompositions: Interpretable and Robust  Fine-Grained Relationships",
    "abstract": "Recent advances in fine-grained representation learning leverage local-to-global (emergent) relationships for achieving state-of-the-art results. The relational representations relied upon by such methods, however, are abstract. We aim to deconstruct this abstraction by expressing them as interpretable graphs over image views. We begin by theoretically showing that abstract relational representations are nothing but a way of recovering transitive relationships among local views. Based on this, we design Transitivity Recovering Decompositions (TRD), a graph-space search algorithm that identifies interpretable equivalents of abstract emergent relationships at both instance and class levels, and with no post-hoc computations. We additionally show that TRD is provably robust to noisy views, with empirical evidence also supporting this finding. The latter allows TRD to perform at par or even better than the state-of-the-art, while being fully interpretable. Implementation is available at https://github.com/abhrac/trd. ",
    "url": "https://arxiv.org/abs/2310.15999",
    "authors": [
      "Abhra Chaudhuri",
      "Massimiliano Mancini",
      "Zeynep Akata",
      "Anjan Dutta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16020",
    "title": "ConvBKI: Real-Time Probabilistic Semantic Mapping Network with  Quantifiable Uncertainty",
    "abstract": "In this paper, we develop a modular neural network for real-time semantic mapping in uncertain environments, which explicitly updates per-voxel probabilistic distributions within a neural network layer. Our approach combines the reliability of classical probabilistic algorithms with the performance and efficiency of modern neural networks. Although robotic perception is often divided between modern differentiable methods and classical explicit methods, a union of both is necessary for real-time and trustworthy performance. We introduce a novel Convolutional Bayesian Kernel Inference (ConvBKI) layer which incorporates semantic segmentation predictions online into a 3D map through a depthwise convolution layer by leveraging conjugate priors. We compare ConvBKI against state-of-the-art deep learning approaches and probabilistic algorithms for mapping to evaluate reliability and performance. We also create a Robot Operating System (ROS) package of ConvBKI and test it on real-world perceptually challenging off-road driving data. ",
    "url": "https://arxiv.org/abs/2310.16020",
    "authors": [
      "Joey Wilson",
      "Yuewei Fu",
      "Joshua Friesen",
      "Parker Ewen",
      "Andrew Capodieci",
      "Paramsothy Jayakumar",
      "Kira Barton",
      "Maani Ghaffari"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16022",
    "title": "A Colorful and Robust Measure for FDFAs",
    "abstract": "We define a measure on families of DFAs (FDFAs) that we show to be robust in the sense that two FDFAs for the same language are guaranteed to agree on this measure. This measure tightly relates to the Wagner-Hierarchy (that defines the complexity of omega regular languages). Inspired by the recently introduced natural colors of infinite words, we define natural colors for finite words (prefixes of periods of infinite words). From this semantic definition we derive the Colorful FDFA a novel canonical model for $\\omega$-regular languages that also assigns correct colors for finite and infinite words. From the colorful FDFA, for languages that can be recognized by deterministic B\\\"uchi or coB\\\"uchi automata, we generate a canonical DBA or DCA termed the Black $\\&$ White Automaton, thus complementing the recent result on canonical good for games coB\\\"uchi automata for coB\\\"uchi languages. ",
    "url": "https://arxiv.org/abs/2310.16022",
    "authors": [
      "Dana Fisman",
      "Emmanuel Goldberg",
      "Oded Zimerman"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2310.16027",
    "title": "TimewarpVAE: Simultaneous Time-Warping and Representation Learning of  Trajectories",
    "abstract": "Human demonstrations of trajectories are an important source of training data for many machine learning problems. However, the difficulty of collecting human demonstration data for complex tasks makes learning efficient representations of those trajectories challenging. For many problems, such as for handwriting or for quasistatic dexterous manipulation, the exact timings of the trajectories should be factored from their spatial path characteristics. In this work, we propose TimewarpVAE, a fully differentiable manifold-learning algorithm that incorporates Dynamic Time Warping (DTW) to simultaneously learn both timing variations and latent factors of spatial variation. We show how the TimewarpVAE algorithm learns appropriate time alignments and meaningful representations of spatial variations in small handwriting and fork manipulation datasets. Our results have lower spatial reconstruction test error than baseline approaches and the learned low-dimensional representations can be used to efficiently generate semantically meaningful novel trajectories. ",
    "url": "https://arxiv.org/abs/2310.16027",
    "authors": [
      "Travers Rhodes",
      "Daniel D. Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.16046",
    "title": "A Unified, Scalable Framework for Neural Population Decoding",
    "abstract": "Our ability to use deep learning approaches to decipher neural activity would likely benefit from greater scale, in terms of both model size and datasets. However, the integration of many neural recordings into one unified model is challenging, as each recording contains the activity of different neurons from different individual animals. In this paper, we introduce a training framework and architecture designed to model the population dynamics of neural activity across diverse, large-scale neural recordings. Our method first tokenizes individual spikes within the dataset to build an efficient representation of neural events that captures the fine temporal structure of neural activity. We then employ cross-attention and a PerceiverIO backbone to further construct a latent tokenization of neural population activities. Utilizing this architecture and training framework, we construct a large-scale multi-session model trained on large datasets from seven nonhuman primates, spanning over 158 different sessions of recording from over 27,373 neural units and over 100 hours of recordings. In a number of different tasks, we demonstrate that our pretrained model can be rapidly adapted to new, unseen sessions with unspecified neuron correspondence, enabling few-shot performance with minimal labels. This work presents a powerful new approach for building deep learning tools to analyze neural data and stakes out a clear path to training at scale. ",
    "url": "https://arxiv.org/abs/2310.16046",
    "authors": [
      "Mehdi Azabou",
      "Vinam Arora",
      "Venkataramana Ganesh",
      "Ximeng Mao",
      "Santosh Nachimuthu",
      "Michael J. Mendelson",
      "Blake Richards",
      "Matthew G. Perich",
      "Guillaume Lajoie",
      "Eva L. Dyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2310.16048",
    "title": "AI Alignment and Social Choice: Fundamental Limitations and Policy  Implications",
    "abstract": "Aligning AI agents to human intentions and values is a key bottleneck in building safe and deployable AI applications. But whose values should AI agents be aligned with? Reinforcement learning with human feedback (RLHF) has emerged as the key framework for AI alignment. RLHF uses feedback from human reinforcers to fine-tune outputs; all widely deployed large language models (LLMs) use RLHF to align their outputs to human values. It is critical to understand the limitations of RLHF and consider policy challenges arising from these limitations. In this paper, we investigate a specific challenge in building RLHF systems that respect democratic norms. Building on impossibility results in social choice theory, we show that, under fairly broad assumptions, there is no unique voting protocol to universally align AI systems using RLHF through democratic processes. Further, we show that aligning AI agents with the values of all individuals will always violate certain private ethical preferences of an individual user i.e., universal AI alignment using RLHF is impossible. We discuss policy implications for the governance of AI systems built using RLHF: first, the need for mandating transparent voting rules to hold model builders accountable. Second, the need for model builders to focus on developing AI agents that are narrowly aligned to specific user groups. ",
    "url": "https://arxiv.org/abs/2310.16048",
    "authors": [
      "Abhilash Mishra"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15202",
    "title": "Predicting Transcription Factor Binding Sites using Transformer based  Capsule Network",
    "abstract": "Prediction of binding sites for transcription factors is important to understand how they regulate gene expression and how this regulation can be modulated for therapeutic purposes. Although in the past few years there are significant works addressing this issue, there is still space for improvement. In this regard, a transformer based capsule network viz. DNABERT-Cap is proposed in this work to predict transcription factor binding sites mining ChIP-seq datasets. DNABERT-Cap is a bidirectional encoder pre-trained with large number of genomic DNA sequences, empowered with a capsule layer responsible for the final prediction. The proposed model builds a predictor for transcription factor binding sites using the joint optimisation of features encompassing both bidirectional encoder and capsule layer, along with convolutional and bidirectional long-short term memory layers. To evaluate the efficiency of the proposed approach, we use a benchmark ChIP-seq datasets of five cell lines viz. A549, GM12878, Hep-G2, H1-hESC and Hela, available in the ENCODE repository. The results show that the average area under the receiver operating characteristic curve score exceeds 0.91 for all such five cell lines. DNABERT-Cap is also compared with existing state-of-the-art deep learning based predictors viz. DeepARC, DeepTF, CNN-Zeng and DeepBind, and is seen to outperform them. ",
    "url": "https://arxiv.org/abs/2310.15202",
    "authors": [
      "Nimisha Ghosh",
      "Daniele Santoni",
      "Indrajit Saha",
      "Giovanni Felici"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15286",
    "title": "A Doubly Robust Approach to Sparse Reinforcement Learning",
    "abstract": "We propose a new regret minimization algorithm for episodic sparse linear Markov decision process (SMDP) where the state-transition distribution is a linear function of observed features. The only previously known algorithm for SMDP requires the knowledge of the sparsity parameter and oracle access to an unknown policy. We overcome these limitations by combining the doubly robust method that allows one to use feature vectors of \\emph{all} actions with a novel analysis technique that enables the algorithm to use data from all periods in all episodes. The regret of the proposed algorithm is $\\tilde{O}(\\sigma^{-1}_{\\min} s_{\\star} H \\sqrt{N})$, where $\\sigma_{\\min}$ denotes the restrictive the minimum eigenvalue of the average Gram matrix of feature vectors, $s_\\star$ is the sparsity parameter, $H$ is the length of an episode, and $N$ is the number of rounds. We provide a lower regret bound that matches the upper bound up to logarithmic factors on a newly identified subclass of SMDPs. Our numerical experiments support our theoretical results and demonstrate the superior performance of our algorithm. ",
    "url": "https://arxiv.org/abs/2310.15286",
    "authors": [
      "Wonyoung Kim",
      "Garud Iyengar",
      "Assaf Zeevi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15328",
    "title": "DeepVox and SAVE-CT: a contrast- and dose-independent 3D deep learning  approach for thoracic aorta segmentation and aneurysm prediction using  computed tomography scans",
    "abstract": "Thoracic aortic aneurysm (TAA) is a fatal disease which potentially leads to dissection or rupture through progressive enlargement of the aorta. It is usually asymptomatic and screening recommendation are limited. The gold-standard evaluation is performed by computed tomography angiography (CTA) and radiologists time-consuming assessment. Scans for other indications could help on this screening, however if acquired without contrast enhancement or with low dose protocol, it can make the clinical evaluation difficult, besides increasing the scans quantity for the radiologists. In this study, it was selected 587 unique CT scans including control and TAA patients, acquired with low and standard dose protocols, with or without contrast enhancement. A novel segmentation model, DeepVox, exhibited dice score coefficients of 0.932 and 0.897 for development and test sets, respectively, with faster training speed in comparison to models reported in the literature. The novel TAA classification model, SAVE-CT, presented accuracies of 0.930 and 0.922 for development and test sets, respectively, using only the binary segmentation mask from DeepVox as input, without hand-engineered features. These two models together are a potential approach for TAA screening, as they can handle variable number of slices as input, handling thoracic and thoracoabdominal sequences, in a fully automated contrast- and dose-independent evaluation. This may assist to decrease TAA mortality and prioritize the evaluation queue of patients for radiologists. ",
    "url": "https://arxiv.org/abs/2310.15328",
    "authors": [
      "Matheus del-Valle",
      "Lariza Laura de Oliveira",
      "Henrique Cursino Vieira",
      "Henrique Min Ho Lee",
      "Lucas Lembran\u00e7a Pinheiro",
      "Maria Fernanda Portugal",
      "Newton Shydeo Brand\u00e3o Miyoshi",
      "Nelson Wolosker"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15330",
    "title": "Unsupervised Federated Learning: A Federated Gradient EM Algorithm for  Heterogeneous Mixture Models with Robustness against Adversarial Attacks",
    "abstract": "While supervised federated learning approaches have enjoyed significant success, the domain of unsupervised federated learning remains relatively underexplored. In this paper, we introduce a novel federated gradient EM algorithm designed for the unsupervised learning of mixture models with heterogeneous mixture proportions across tasks. We begin with a comprehensive finite-sample theory that holds for general mixture models, then apply this general theory on Gaussian Mixture Models (GMMs) and Mixture of Regressions (MoRs) to characterize the explicit estimation error of model parameters and mixture proportions. Our proposed federated gradient EM algorithm demonstrates several key advantages: adaptability to unknown task similarity, resilience against adversarial attacks on a small fraction of data sources, protection of local data privacy, and computational and communication efficiency. ",
    "url": "https://arxiv.org/abs/2310.15330",
    "authors": [
      "Ye Tian",
      "Haolei Weng",
      "Yang Feng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15371",
    "title": "Vicinal Feature Statistics Augmentation for Federated 3D Medical Volume  Segmentation",
    "abstract": "Federated learning (FL) enables multiple client medical institutes collaboratively train a deep learning (DL) model with privacy protection. However, the performance of FL can be constrained by the limited availability of labeled data in small institutes and the heterogeneous (i.e., non-i.i.d.) data distribution across institutes. Though data augmentation has been a proven technique to boost the generalization capabilities of conventional centralized DL as a \"free lunch\", its application in FL is largely underexplored. Notably, constrained by costly labeling, 3D medical segmentation generally relies on data augmentation. In this work, we aim to develop a vicinal feature-level data augmentation (VFDA) scheme to efficiently alleviate the local feature shift and facilitate collaborative training for privacy-aware FL segmentation. We take both the inner- and inter-institute divergence into consideration, without the need for cross-institute transfer of raw data or their mixup. Specifically, we exploit the batch-wise feature statistics (e.g., mean and standard deviation) in each institute to abstractly represent the discrepancy of data, and model each feature statistic probabilistically via a Gaussian prototype, with the mean corresponding to the original statistic and the variance quantifying the augmentation scope. From the vicinal risk minimization perspective, novel feature statistics can be drawn from the Gaussian distribution to fulfill augmentation. The variance is explicitly derived by the data bias in each individual institute and the underlying feature statistics characterized by all participating institutes. The added-on VFDA consistently yielded marked improvements over six advanced FL methods on both 3D brain tumor and cardiac segmentation. ",
    "url": "https://arxiv.org/abs/2310.15371",
    "authors": [
      "Yongsong Huang",
      "Wanqing Xie",
      "Mingzhen Li",
      "Mingmei Cheng",
      "Jinzhou Wu",
      "Weixiao Wang",
      "Jane You",
      "Xiaofeng Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2310.15375",
    "title": "Optimal Structured Matrix Approximation for Robustness to Incomplete  Biosequence Data",
    "abstract": "We propose a general method for optimally approximating an arbitrary matrix $\\mathbf{M}$ by a structured matrix $\\mathbf{T}$ (circulant, Toeplitz/Hankel, etc.) and examine its use for estimating the spectra of genomic linkage disequilibrium matrices. This application is prototypical of a variety of genomic and proteomic problems that demand robustness to incomplete biosequence information. We perform a simulation study and corroborative test of our method using real genomic data from the Mouse Genome Database. The results confirm the predicted utility of the method and provide strong evidence of its potential value to a wide range of bioinformatics applications. Our optimal general matrix approximation method is expected to be of independent interest to an even broader range of applications in applied mathematics and engineering. ",
    "url": "https://arxiv.org/abs/2310.15375",
    "authors": [
      "Chris Salahub",
      "Jeffrey Uhlmann"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2310.15387",
    "title": "Error analysis of generative adversarial network",
    "abstract": "The generative adversarial network (GAN) is an important model developed for high-dimensional distribution learning in recent years. However, there is a pressing need for a comprehensive method to understand its error convergence rate. In this research, we focus on studying the error convergence rate of the GAN model that is based on a class of functions encompassing the discriminator and generator neural networks. These functions are VC type with bounded envelope function under our assumptions, enabling the application of the Talagrand inequality. By employing the Talagrand inequality and Borel-Cantelli lemma, we establish a tight convergence rate for the error of GAN. This method can also be applied on existing error estimations of GAN and yields improved convergence rates. In particular, the error defined with the neural network distance is a special case error in our definition. ",
    "url": "https://arxiv.org/abs/2310.15387",
    "authors": [
      "Mahmud Hasan",
      "Hailin Sang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15401",
    "title": "Graph decomposition via edge edits into a union of regular graphs",
    "abstract": "Suppose a finite, unweighted, combinatorial graph $G = (V,E)$ is the union of several (degree-)regular graphs which are then additionally connected with a few additional edges. $G$ will then have only a small number of vertices $v \\in V$ with the property that one of their neighbors $(v,w) \\in E$ has a higher degree $\\mbox{deg}(w) > \\mbox{deg}(v)$. We prove the converse statement: if a graph has few vertices having a neighbor with higher degree and satisfies a mild regularity condition, then, via adding and removing a few edges, the graph can be turned into a disjoint union of (distance-)regular graphs. The number of edge operations depends on the maximum degree and number of vertices with a higher degree neighbor but is independent of the size of $|V|$. ",
    "url": "https://arxiv.org/abs/2310.15401",
    "authors": [
      "Tony Zeng"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2310.15425",
    "title": "The Mason-Alberta Phonetic Segmenter: A forced alignment system based on  deep neural networks and interpolation",
    "abstract": "Forced alignment systems automatically determine boundaries between segments in speech data, given an orthographic transcription. These tools are commonplace in phonetics to facilitate the use of speech data that would be infeasible to manually transcribe and segment. In the present paper, we describe a new neural network-based forced alignment system, the Mason-Alberta Phonetic Segmenter (MAPS). The MAPS aligner serves as a testbed for two possible improvements we pursue for forced alignment systems. The first is treating the acoustic model in a forced aligner as a tagging task, rather than a classification task, motivated by the common understanding that segments in speech are not truly discrete and commonly overlap. The second is an interpolation technique to allow boundaries more precise than the common 10 ms limit in modern forced alignment systems. We compare configurations of our system to a state-of-the-art system, the Montreal Forced Aligner. The tagging approach did not generally yield improved results over the Montreal Forced Aligner. However, a system with the interpolation technique had a 27.92% increase relative to the Montreal Forced Aligner in the amount of boundaries within 10 ms of the target on the test set. We also reflect on the task and training process for acoustic modeling in forced alignment, highlighting how the output targets for these models do not match phoneticians' conception of similarity between phones and that reconciliation of this tension may require rethinking the task and output targets or how speech itself should be segmented. ",
    "url": "https://arxiv.org/abs/2310.15425",
    "authors": [
      "Matthew C. Kelley",
      "Scott James Perry",
      "Benjamin V. Tucker"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2310.15478",
    "title": "How to Train Your Neural Control Barrier Function: Learning Safety  Filters for Complex Input-Constrained Systems",
    "abstract": "Control barrier functions (CBFs) have become popular as a safety filter to guarantee the safety of nonlinear dynamical systems for arbitrary inputs. However, it is difficult to construct functions that satisfy the CBF constraints for high relative degree systems with input constraints. To address these challenges, recent work has explored learning CBFs using neural networks via neural CBFs (NCBFs). However, such methods face difficulties when scaling to higher dimensional systems under input constraints. In this work, we first identify challenges that NCBFs face during training. Next, to address these challenges, we propose policy neural CBFs (PNCBFs), a method of constructing CBFs by learning the value function of a nominal policy, and show that the value function of the maximum-over-time cost is a CBF. We demonstrate the effectiveness of our method in simulation on a variety of systems ranging from toy linear systems to an F-16 jet with a 16-dimensional state space. Finally, we validate our approach on a two-agent quadcopter system on hardware under tight input constraints. ",
    "url": "https://arxiv.org/abs/2310.15478",
    "authors": [
      "Oswin So",
      "Zachary Serlin",
      "Makai Mann",
      "Jake Gonzales",
      "Kwesi Rutledge",
      "Nicholas Roy",
      "Chuchu Fan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.15550",
    "title": "PET Synthesis via Self-supervised Adaptive Residual Estimation  Generative Adversarial Network",
    "abstract": "Positron emission tomography (PET) is a widely used, highly sensitive molecular imaging in clinical diagnosis. There is interest in reducing the radiation exposure from PET but also maintaining adequate image quality. Recent methods using convolutional neural networks (CNNs) to generate synthesized high-quality PET images from low-dose counterparts have been reported to be state-of-the-art for low-to-high image recovery methods. However, these methods are prone to exhibiting discrepancies in texture and structure between synthesized and real images. Furthermore, the distribution shift between low-dose PET and standard PET has not been fully investigated. To address these issues, we developed a self-supervised adaptive residual estimation generative adversarial network (SS-AEGAN). We introduce (1) An adaptive residual estimation mapping mechanism, AE-Net, designed to dynamically rectify the preliminary synthesized PET images by taking the residual map between the low-dose PET and synthesized output as the input, and (2) A self-supervised pre-training strategy to enhance the feature representation of the coarse generator. Our experiments with a public benchmark dataset of total-body PET images show that SS-AEGAN consistently outperformed the state-of-the-art synthesis methods with various dose reduction factors. ",
    "url": "https://arxiv.org/abs/2310.15550",
    "authors": [
      "Yuxin Xue",
      "Lei Bi",
      "Yige Peng",
      "Michael Fulham",
      "David Dagan Feng",
      "Jinman Kim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15627",
    "title": "Contextual directed acyclic graphs",
    "abstract": "Estimating the structure of directed acyclic graphs (DAGs) from observational data remains a significant challenge in machine learning. Most research in this area concentrates on learning a single DAG for the entire population. This paper considers an alternative setting where the graph structure varies across individuals based on available \"contextual\" features. We tackle this contextual DAG problem via a neural network that maps the contextual features to a DAG, represented as a weighted adjacency matrix. The neural network is equipped with a novel projection layer that ensures the output matrices are sparse and satisfy a recently developed characterization of acyclicity. We devise a scalable computational framework for learning contextual DAGs and provide a convergence guarantee and an analytical gradient for backpropagating through the projection layer. Our experiments suggest that the new approach can recover the true context-specific graph where existing approaches fail. ",
    "url": "https://arxiv.org/abs/2310.15627",
    "authors": [
      "Ryan Thompson",
      "Edwin V. Bonilla",
      "Robert Kohn"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15709",
    "title": "Causal Representation Learning Made Identifiable by Grouping of  Observational Variables",
    "abstract": "A topic of great current interest is Causal Representation Learning (CRL), whose goal is to learn a causal model for hidden features in a data-driven manner. Unfortunately, CRL is severely ill-posed since it is a combination of the two notoriously ill-posed problems of representation learning and causal discovery. Yet, finding practical identifiability conditions that guarantee a unique solution is crucial for its practical applicability. Most approaches so far have been based on assumptions on the latent causal mechanisms, such as temporal causality, or existence of supervision or interventions; these can be too restrictive in actual applications. Here, we show identifiability based on novel, weak constraints, which requires no temporal structure, intervention, nor weak supervision. The approach is based assuming the observational mixing exhibits a suitable grouping of the observational variables. We also propose a novel self-supervised estimation framework consistent with the model, prove its statistical consistency, and experimentally show its superior CRL performances compared to the state-of-the-art baselines. We further demonstrate its robustness against latent confounders and causal cycles. ",
    "url": "https://arxiv.org/abs/2310.15709",
    "authors": [
      "Hiroshi Morioka",
      "Aapo Hyv\u00e4rinen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15767",
    "title": "Unpaired MRI Super Resolution with Self-Supervised Contrastive Learning",
    "abstract": "High-resolution (HR) magnetic resonance imaging (MRI) is crucial for enhancing diagnostic accuracy in clinical settings. Nonetheless, the inherent limitation of MRI resolution restricts its widespread applicability. Deep learning-based image super-resolution (SR) methods exhibit promise in improving MRI resolution without additional cost. However, these methods frequently require a substantial number of HR MRI images for training, which can be challenging to acquire. In this paper, we propose an unpaired MRI SR approach that employs self-supervised contrastive learning to enhance SR performance with limited training data. Our approach leverages both authentic HR images and synthetically generated SR images to construct positive and negative sample pairs, thus facilitating the learning of discriminative features. Empirical results presented in this study underscore significant enhancements in the peak signal-to-noise ratio and structural similarity index, even when a paucity of HR images is available. These findings accentuate the potential of our approach in addressing the challenge of limited training data, thereby contributing to the advancement of high-resolution MRI in clinical applications. ",
    "url": "https://arxiv.org/abs/2310.15767",
    "authors": [
      "Hao Li",
      "Quanwei Liu",
      "Jianan Liu",
      "Xiling Liu",
      "Yanni Dong",
      "Tao Huang",
      "Zhihan Lv"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15786",
    "title": "Amortised Inference in Neural Networks for Small-Scale Probabilistic  Meta-Learning",
    "abstract": "The global inducing point variational approximation for BNNs is based on using a set of inducing inputs to construct a series of conditional distributions that accurately approximate the conditionals of the true posterior distribution. Our key insight is that these inducing inputs can be replaced by the actual data, such that the variational distribution consists of a set of approximate likelihoods for each datapoint. This structure lends itself to amortised inference, in which the parameters of each approximate likelihood are obtained by passing each datapoint through a meta-model known as the inference network. By training this inference network across related datasets, we can meta-learn Bayesian inference over task-specific BNNs. ",
    "url": "https://arxiv.org/abs/2310.15786",
    "authors": [
      "Matthew Ashman",
      "Tommy Rochussen",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15853",
    "title": "Improving Event Time Prediction by Learning to Partition the Event Time  Space",
    "abstract": "Recently developed survival analysis methods improve upon existing approaches by predicting the probability of event occurrence in each of a number pre-specified (discrete) time intervals. By avoiding placing strong parametric assumptions on the event density, this approach tends to improve prediction performance, particularly when data are plentiful. However, in clinical settings with limited available data, it is often preferable to judiciously partition the event time space into a limited number of intervals well suited to the prediction task at hand. In this work, we develop a method to learn from data a set of cut points defining such a partition. We show that in two simulated datasets, we are able to recover intervals that match the underlying generative model. We then demonstrate improved prediction performance on three real-world observational datasets, including a large, newly harmonized stroke risk prediction dataset. Finally, we argue that our approach facilitates clinical decision-making by suggesting time intervals that are most appropriate for each task, in the sense that they facilitate more accurate risk prediction. ",
    "url": "https://arxiv.org/abs/2310.15853",
    "authors": [
      "Jimmy Hickey",
      "Ricardo Henao",
      "Daniel Wojdyla",
      "Michael Pencina",
      "Matthew M. Engelhard"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1904.07381",
    "title": "Approximation Algorithms for Distributionally Robust Stochastic  Optimization with Black-Box Distributions",
    "abstract": " Title: Approximation Algorithms for Distributionally Robust Stochastic  Optimization with Black-Box Distributions ",
    "url": "https://arxiv.org/abs/1904.07381",
    "authors": [
      "Andre Linhares",
      "Chaitanya Swamy"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2106.03412",
    "title": "Resolution learning in deep convolutional networks using scale-space  theory",
    "abstract": " Comments: Preprint accepted by IEEE Transactions on Image Processing, 2021 (TIP). Link to final published article: this https URL ",
    "url": "https://arxiv.org/abs/2106.03412",
    "authors": [
      "Silvia L.Pintea",
      "Nergis Tomen",
      "Stanley F. Goes",
      "Marco Loog",
      "Jan C. van Gemert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2201.08022",
    "title": "HEAM: High-Efficiency Approximate Multiplier Optimization for Deep  Neural Networks",
    "abstract": " Comments: 5 pages, 2022 IEEE International Symposium on Circuits and Systems (ISCAS) ",
    "url": "https://arxiv.org/abs/2201.08022",
    "authors": [
      "Su Zheng",
      "Zhen Li",
      "Yao Lu",
      "Jingbo Gao",
      "Jide Zhang",
      "Lingli Wang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.11808",
    "title": "LAP: An Attention-Based Module for Concept Based Self-Interpretation and  Knowledge Injection in Convolutional Neural Networks",
    "abstract": " Title: LAP: An Attention-Based Module for Concept Based Self-Interpretation and  Knowledge Injection in Convolutional Neural Networks ",
    "url": "https://arxiv.org/abs/2201.11808",
    "authors": [
      "Rassa Ghavami Modegh",
      "Ahmad Salimi",
      "Alireza Dizaji",
      "Hamid R. Rabiee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.10739",
    "title": "JAMES: Normalizing Job Titles with Multi-Aspect Graph Embeddings and  Reasoning",
    "abstract": " Comments: Accepted at IEEE DSAA 2023 ",
    "url": "https://arxiv.org/abs/2202.10739",
    "authors": [
      "Michiharu Yamashita",
      "Jia Tracy Shen",
      "Thanh Tran",
      "Hamoon Ekhtiari",
      "Dongwon Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.05481",
    "title": "Fully Adaptive Composition in Differential Privacy",
    "abstract": " Comments: 23 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2203.05481",
    "authors": [
      "Justin Whitehouse",
      "Aaditya Ramdas",
      "Ryan Rogers",
      "Zhiwei Steven Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.15316",
    "title": "Anomaly Detection in Echocardiograms with Dynamic Variational Trajectory  Models",
    "abstract": " Title: Anomaly Detection in Echocardiograms with Dynamic Variational Trajectory  Models ",
    "url": "https://arxiv.org/abs/2206.15316",
    "authors": [
      "Alain Ryser",
      "Laura Manduchi",
      "Fabian Laumer",
      "Holger Michel",
      "Sven Wellmann",
      "Julia E. Vogt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.12653",
    "title": "Incremental Measurement of Structural Entropy for Dynamic Graphs",
    "abstract": " Title: Incremental Measurement of Structural Entropy for Dynamic Graphs ",
    "url": "https://arxiv.org/abs/2207.12653",
    "authors": [
      "Runze Yang",
      "Hao Peng",
      "Angsheng Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2209.00232",
    "title": "Hybrid Gromov-Wasserstein Embedding for Capsule Learning",
    "abstract": " Title: Hybrid Gromov-Wasserstein Embedding for Capsule Learning ",
    "url": "https://arxiv.org/abs/2209.00232",
    "authors": [
      "Pourya Shamsolmoali",
      "Masoumeh Zareapoor",
      "Swagatam Das",
      "Eric Granger",
      "Salvador Garcia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.11740",
    "title": "On the Shift Invariance of Max Pooling Feature Maps in Convolutional  Neural Networks",
    "abstract": " Title: On the Shift Invariance of Max Pooling Feature Maps in Convolutional  Neural Networks ",
    "url": "https://arxiv.org/abs/2209.11740",
    "authors": [
      "Hubert Leterme",
      "K\u00e9vin Polisano",
      "Val\u00e9rie Perrier",
      "Karteek Alahari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2212.06808",
    "title": "Incentive-Aware Models of Financial Networks",
    "abstract": " Title: Incentive-Aware Models of Financial Networks ",
    "url": "https://arxiv.org/abs/2212.06808",
    "authors": [
      "Akhil Jalan",
      "Deepayan Chakrabarti",
      "Purnamrita Sarkar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2212.10465",
    "title": "SODA: Million-scale Dialogue Distillation with Social Commonsense  Contextualization",
    "abstract": " Comments: EMNLP 2023. Dataset, model, and code can be found at this https URL ",
    "url": "https://arxiv.org/abs/2212.10465",
    "authors": [
      "Hyunwoo Kim",
      "Jack Hessel",
      "Liwei Jiang",
      "Peter West",
      "Ximing Lu",
      "Youngjae Yu",
      "Pei Zhou",
      "Ronan Le Bras",
      "Malihe Alikhani",
      "Gunhee Kim",
      "Maarten Sap",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.10956",
    "title": "Graph Neural Networks can Recover the Hidden Features Solely from the  Graph Structure",
    "abstract": " Comments: ICML 2023 ",
    "url": "https://arxiv.org/abs/2301.10956",
    "authors": [
      "Ryoma Sato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.13060",
    "title": "Zero-One Laws of Graph Neural Networks",
    "abstract": " Comments: NeurIPS '23 camera-ready version; 10 pages + references + 10 pages appendices, 7 figures ",
    "url": "https://arxiv.org/abs/2301.13060",
    "authors": [
      "Sam Adam-Day",
      "Theodor Mihai Iliant",
      "\u0130smail \u0130lkan Ceylan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00617",
    "title": "Learning Large-scale Neural Fields via Context Pruned Meta-Learning",
    "abstract": " Comments: Published as a conference proceeding for NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2302.00617",
    "authors": [
      "Jihoon Tack",
      "Subin Kim",
      "Sihyun Yu",
      "Jaeho Lee",
      "Jinwoo Shin",
      "Jonathan Richard Schwarz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.02854",
    "title": "NA-SODINN: a deep learning algorithm for exoplanet image detection based  on residual noise regimes",
    "abstract": " Comments: A&A in press ",
    "url": "https://arxiv.org/abs/2302.02854",
    "authors": [
      "Carles Cantero",
      "Olivier Absil",
      "Carl-Henrik Dahlqvist",
      "Marc Van Droogenbroeck"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.04451",
    "title": "Generalization in Graph Neural Networks: Improved PAC-Bayesian Bounds on  Graph Diffusion",
    "abstract": " Comments: 36 pages. Appeared in AISTATS 2023 ",
    "url": "https://arxiv.org/abs/2302.04451",
    "authors": [
      "Haotian Ju",
      "Dongyue Li",
      "Aneesh Sharma",
      "Hongyang R. Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.06434",
    "title": "Efficient Graph Laplacian Estimation by Proximal Newton",
    "abstract": " Title: Efficient Graph Laplacian Estimation by Proximal Newton ",
    "url": "https://arxiv.org/abs/2302.06434",
    "authors": [
      "Yakov Medvedovsky",
      "Eran Treister",
      "Tirza Routtenberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2302.07294",
    "title": "Derandomized Novelty Detection with FDR Control via Conformal E-values",
    "abstract": " Comments: 35 pages, 24 figures ",
    "url": "https://arxiv.org/abs/2302.07294",
    "authors": [
      "Meshi Bashari",
      "Amir Epstein",
      "Yaniv Romano",
      "Matteo Sesia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2302.12250",
    "title": "Phase diagram of early training dynamics in deep neural networks: effect  of the learning rate, depth, and width",
    "abstract": " Comments: Accepted at NeurIPS 2023 (camera-ready version): Additional results added for cross-entropy loss and effect on network output at initialization; 10+32 pages, 8+35 figures ",
    "url": "https://arxiv.org/abs/2302.12250",
    "authors": [
      "Dayal Singh Kalra",
      "Maissam Barkeshli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)"
    ]
  },
  {
    "id": "arXiv:2303.03387",
    "title": "CoSyn: Detecting Implicit Hate Speech in Online Conversations Using a  Context Synergized Hyperbolic Network",
    "abstract": " Comments: Accepted to EMNLP 2023 Main Conference. Code: this https URL ",
    "url": "https://arxiv.org/abs/2303.03387",
    "authors": [
      "Sreyan Ghosh",
      "Manan Suri",
      "Purva Chiniya",
      "Utkarsh Tyagi",
      "Sonal Kumar",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.15206",
    "title": "Perceptual Quality Assessment of NeRF and Neural View Synthesis Methods  for Front-Facing Views",
    "abstract": " Title: Perceptual Quality Assessment of NeRF and Neural View Synthesis Methods  for Front-Facing Views ",
    "url": "https://arxiv.org/abs/2303.15206",
    "authors": [
      "Hanxue Liang",
      "Tianhao Wu",
      "Param Hanji",
      "Francesco Banterle",
      "Hongyun Gao",
      "Rafal Mantiuk",
      "Cengiz Oztireli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2304.12668",
    "title": "Social media in the Global South: A Network Dataset of the Malian  Twittersphere",
    "abstract": " Comments: 12 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2304.12668",
    "authors": [
      "Daniel Thilo Schroeder",
      "Mirjam de Bruijn",
      "Luca Bruls",
      "Mulatu Alemayehu Moges",
      "Samba Dialimpa Badji",
      "No\u00ebmie Fritz",
      "Modibo Galy Cisse",
      "Johannes Langguth",
      "Bruce Mutsvairo",
      "Kristin Skare Orgeret"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.13658",
    "title": "Understanding Compositional Data Augmentation in Typologically Diverse  Morphological Inflection",
    "abstract": " Comments: EMNLP 2023 camera-ready ",
    "url": "https://arxiv.org/abs/2305.13658",
    "authors": [
      "Farhan Samir",
      "Miikka Silfverberg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13751",
    "title": "Challenges in Context-Aware Neural Machine Translation",
    "abstract": " Comments: Accepted to EMNLP 2023 ",
    "url": "https://arxiv.org/abs/2305.13751",
    "authors": [
      "Linghao Jin",
      "Jacqueline He",
      "Jonathan May",
      "Xuezhe Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13981",
    "title": "Preserving Knowledge Invariance: Rethinking Robustness Evaluation of  Open Information Extraction",
    "abstract": " Comments: Accepted by EMNLP 2023 Main Conference ",
    "url": "https://arxiv.org/abs/2305.13981",
    "authors": [
      "Ji Qi",
      "Chuchun Zhang",
      "Xiaozhi Wang",
      "Kaisheng Zeng",
      "Jifan Yu",
      "Jinxin Liu",
      "Jiuding Sun",
      "Yuxiang Chen",
      "Lei Hou",
      "Juanzi Li",
      "Bin Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.13999",
    "title": "Towards A Unified View of Sparse Feed-Forward Network in Pretraining  Large Language Model",
    "abstract": " Comments: Accepted to EMNLP 2023 ",
    "url": "https://arxiv.org/abs/2305.13999",
    "authors": [
      "Zeyu Leo Liu",
      "Tim Dettmers",
      "Xi Victoria Lin",
      "Veselin Stoyanov",
      "Xian Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15110",
    "title": "Intersection of Longest Cycle and Largest Bond in 3-Connected Graphs",
    "abstract": " Comments: 16 pages, 19 figures. Paper presented at the 54th Southeastern International Conference on Combinatorics, Graph Theory and Computing (March 6-10, 2023); submitted on May 9, 2023 to the conference proceedings book series publication titled \"Springer Proceedings in Mathematics and Statistics\" (PROMS). Paper abstract also on this https URL ",
    "url": "https://arxiv.org/abs/2305.15110",
    "authors": [
      "Emily Ren"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2305.17297",
    "title": "Denoising Low-Rank Data Under Distribution Shift: Double Descent and  Data Augmentation",
    "abstract": " Comments: Complete overhaul of presentation, many new results ",
    "url": "https://arxiv.org/abs/2305.17297",
    "authors": [
      "Chinmaya Kausik",
      "Kashvi Srivastava",
      "Rishi Sonthalia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.02602",
    "title": "ReContrast: Domain-Specific Anomaly Detection via Contrastive  Reconstruction",
    "abstract": " Comments: NeurIPS 2023 Poster ",
    "url": "https://arxiv.org/abs/2306.02602",
    "authors": [
      "Jia Guo",
      "Shuai Lu",
      "Lize Jia",
      "Weihang Zhang",
      "Huiqi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.05131",
    "title": "Conformal Prediction for Federated Uncertainty Quantification Under  Label Shift",
    "abstract": " Comments: ICML 2023 ",
    "url": "https://arxiv.org/abs/2306.05131",
    "authors": [
      "Vincent Plassier",
      "Mehdi Makni",
      "Aleksandr Rubashevskii",
      "Eric Moulines",
      "Maxim Panov"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.10912",
    "title": "Jamming Detection in Low-BER Mobile Indoor Scenarios via Deep Learning",
    "abstract": " Comments: 14 pages, 14 figures; Submitted and under review ",
    "url": "https://arxiv.org/abs/2306.10912",
    "authors": [
      "Savio Sciancalepore",
      "Fabrice Kusters",
      "Nada Khaled Abdelhadi",
      "Gabriele Oligeri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.10933",
    "title": "Towards Open-World Recommendation with Knowledge Augmentation from Large  Language Models",
    "abstract": " Title: Towards Open-World Recommendation with Knowledge Augmentation from Large  Language Models ",
    "url": "https://arxiv.org/abs/2306.10933",
    "authors": [
      "Yunjia Xi",
      "Weiwen Liu",
      "Jianghao Lin",
      "Jieming Zhu",
      "Bo Chen",
      "Ruiming Tang",
      "Weinan Zhang",
      "Rui Zhang",
      "Yong Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2306.15359",
    "title": "Matrix equation representation of the convolution equation and its  unique solvability",
    "abstract": " Title: Matrix equation representation of the convolution equation and its  unique solvability ",
    "url": "https://arxiv.org/abs/2306.15359",
    "authors": [
      "Yuki Satake",
      "Tomohiro Sogabe",
      "Tomoya Kemmochi",
      "Shao-Liang Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2306.16635",
    "title": "Improving Fairness in Deepfake Detection",
    "abstract": " Title: Improving Fairness in Deepfake Detection ",
    "url": "https://arxiv.org/abs/2306.16635",
    "authors": [
      "Yan Ju",
      "Shu Hu",
      "Shan Jia",
      "George H. Chen",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.03217",
    "title": "Quantification of Uncertainty with Adversarial Models",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2307.03217",
    "authors": [
      "Kajetan Schweighofer",
      "Lukas Aichberger",
      "Mykyta Ielanskyi",
      "G\u00fcnter Klambauer",
      "Sepp Hochreiter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.03838",
    "title": "RADAR: Robust AI-Text Detection via Adversarial Learning",
    "abstract": " Comments: Accepted by NeurIPS 2023. Project page and demos: this https URL ",
    "url": "https://arxiv.org/abs/2307.03838",
    "authors": [
      "Xiaomeng Hu",
      "Pin-Yu Chen",
      "Tsung-Yi Ho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.09302",
    "title": "Conformal prediction under ambiguous ground truth",
    "abstract": " Title: Conformal prediction under ambiguous ground truth ",
    "url": "https://arxiv.org/abs/2307.09302",
    "authors": [
      "David Stutz",
      "Abhijit Guha Roy",
      "Tatiana Matejovicova",
      "Patricia Strachan",
      "Ali Taylan Cemgil",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.13885",
    "title": "Efficient Estimation of Average-Case Robustness for Multi-Class  Classification",
    "abstract": " Title: Efficient Estimation of Average-Case Robustness for Multi-Class  Classification ",
    "url": "https://arxiv.org/abs/2307.13885",
    "authors": [
      "Tessa Han",
      "Suraj Srinivas",
      "Himabindu Lakkaraju"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.14387",
    "title": "Coupled-Space Attacks against Random-Walk-based Anomaly Detection",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2307.14387",
    "authors": [
      "Yuni Lai",
      "Marcin Waniek",
      "Liying Li",
      "Jingwen Wu",
      "Yulin Zhu",
      "Tomasz P. Michalak",
      "Talal Rahwan",
      "Kai Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.14491",
    "title": "A Unified Framework for Modality-Agnostic Deepfakes Detection",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2307.14491",
    "authors": [
      "Cai Yu",
      "Peng Chen",
      "Jiahe Tian",
      "Jin Liu",
      "Jiao Dai",
      "Xi Wang",
      "Yesheng Chai",
      "Shan Jia",
      "Siwei Lyu",
      "Jizhong Han"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2308.05379",
    "title": "Beyond Semantics: Learning a Behavior Augmented Relevance Model with  Self-supervised Learning",
    "abstract": " Comments: Accepted by CIKM2023 ",
    "url": "https://arxiv.org/abs/2308.05379",
    "authors": [
      "Zeyuan Chen",
      "Wei Chen",
      "Jia Xu",
      "Zhongyi Liu",
      "Wei Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.10637",
    "title": "Metro Access Network with Convergence of Coherent and Analog RoF Data  Services",
    "abstract": " Title: Metro Access Network with Convergence of Coherent and Analog RoF Data  Services ",
    "url": "https://arxiv.org/abs/2308.10637",
    "authors": [
      "Amol Delmade",
      "Frank Slyne",
      "Colm Browning",
      "Daniel Kilper Liam Barry",
      "Marco Ruffini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.12947",
    "title": "Counting Distinct Elements Under Person-Level Differential Privacy",
    "abstract": " Title: Counting Distinct Elements Under Person-Level Differential Privacy ",
    "url": "https://arxiv.org/abs/2308.12947",
    "authors": [
      "Alexander Knop",
      "Thomas Steinke"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.06067",
    "title": "Batch Implicit Neural Representation for MRI Parallel Reconstruction",
    "abstract": " Title: Batch Implicit Neural Representation for MRI Parallel Reconstruction ",
    "url": "https://arxiv.org/abs/2309.06067",
    "authors": [
      "Hao Li",
      "Yusheng Zhou",
      "Jianan Liu",
      "Xiling Liu",
      "Tao Huang",
      "Zhihan Lv"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2309.06132",
    "title": "Measuring vagueness and subjectivity in texts: from symbolic to neural  VAGO",
    "abstract": " Comments: Paper to appear in the Proceedings of the 2023 IEEE International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT) ",
    "url": "https://arxiv.org/abs/2309.06132",
    "authors": [
      "Benjamin Icard",
      "Vincent Claveau",
      "Ghislain Atemezing",
      "Paul \u00c9gr\u00e9"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.06782",
    "title": "Scalable neural network models and terascale datasets for particle-flow  reconstruction",
    "abstract": " Comments: 20 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2309.06782",
    "authors": [
      "Joosep Pata",
      "Eric Wulff",
      "Farouk Mokhtar",
      "David Southwick",
      "Mengke Zhang",
      "Maria Girone",
      "Javier Duarte"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Instrumentation and Detectors (physics.ins-det)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.08030",
    "title": "AV2Wav: Diffusion-Based Re-synthesis from Continuous Self-supervised  Features for Audio-Visual Speech Enhancement",
    "abstract": " Comments: Submitted to ICASSP 2024 ",
    "url": "https://arxiv.org/abs/2309.08030",
    "authors": [
      "Ju-Chieh Chou",
      "Chung-Ming Chien",
      "Karen Livescu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.13837",
    "title": "Backorder Prediction in Inventory Management: Classification Techniques  and Cost Considerations",
    "abstract": " Title: Backorder Prediction in Inventory Management: Classification Techniques  and Cost Considerations ",
    "url": "https://arxiv.org/abs/2309.13837",
    "authors": [
      "Sarit Maitra",
      "Sukanya Kundu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2309.14057",
    "title": "Weakly Supervised Semantic Segmentation by Knowledge Graph Inference",
    "abstract": " Comments: Our description in Chapter 3, Section 3.2 of the paper is too repetitive with the paper \"Object detection meets knowledge graphs\". There is an error in the description of formula (5) in Section 3.3. And a detailed reasoning process is required for formula (5). Therefore, we wish to request a retraction of the paper ",
    "url": "https://arxiv.org/abs/2309.14057",
    "authors": [
      "Jia Zhang",
      "Bo Peng",
      "Xi Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.14518",
    "title": "Detach-ROCKET: Sequential feature selection for time series  classification with random convolutional kernels",
    "abstract": " Comments: 14 pages, 4 figures, 1 table ",
    "url": "https://arxiv.org/abs/2309.14518",
    "authors": [
      "Gonzalo Uribarri",
      "Federico Barone",
      "Alessio Ansuini",
      "Erik Frans\u00e9n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.14538",
    "title": "Dynamic Scene Graph Representation for Surgical Video",
    "abstract": " Title: Dynamic Scene Graph Representation for Surgical Video ",
    "url": "https://arxiv.org/abs/2309.14538",
    "authors": [
      "Felix Holm",
      "Ghazal Ghazaei",
      "Tobias Czempiel",
      "Ege \u00d6zsoy",
      "Stefan Saur",
      "Nassir Navab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16730",
    "title": "Explainable machine learning-based prediction model for diabetic  nephropathy",
    "abstract": " Title: Explainable machine learning-based prediction model for diabetic  nephropathy ",
    "url": "https://arxiv.org/abs/2309.16730",
    "authors": [
      "Jing-Mei Yin",
      "Yang Li",
      "Jun-Tang Xue",
      "Guo-Wei Zong",
      "Zhong-Ze Fang",
      "Lang Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.02971",
    "title": "Prompting and Adapter Tuning for Self-supervised Encoder-Decoder Speech  Model",
    "abstract": " Comments: Accepted to IEEE ASRU 2023 ",
    "url": "https://arxiv.org/abs/2310.02971",
    "authors": [
      "Kai-Wei Chang",
      "Ming-Hsin Chen",
      "Yun-Ping Lin",
      "Jing Neng Hsu",
      "Paul Kuo-Ming Huang",
      "Chien-yu Huang",
      "Shang-Wen Li",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.03388",
    "title": "OpenPatch: a 3D patchwork for Out-Of-Distribution detection",
    "abstract": " Title: OpenPatch: a 3D patchwork for Out-Of-Distribution detection ",
    "url": "https://arxiv.org/abs/2310.03388",
    "authors": [
      "Paolo Rabino",
      "Antonio Alliegro",
      "Francesco Cappio Borlino",
      "Tatiana Tommasi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05030",
    "title": "Counter Turing Test CT^2: AI-Generated Text Detection is Not as Easy as  You May Think -- Introducing AI Detectability Index",
    "abstract": " Comments: EMNLP 2023 Main ",
    "url": "https://arxiv.org/abs/2310.05030",
    "authors": [
      "Megha Chakraborty",
      "S.M Towhidul Islam Tonmoy",
      "S M Mehedi Zaman",
      "Krish Sharma",
      "Niyar R Barman",
      "Chandan Gupta",
      "Shreya Gautam",
      "Tanay Kumar",
      "Vinija Jain",
      "Aman Chadha",
      "Amit P. Sheth",
      "Amitava Das"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05388",
    "title": "GROVE: A Retrieval-augmented Complex Story Generation Framework with A  Forest of Evidence",
    "abstract": " Comments: Findings of EMNLP 2023 ",
    "url": "https://arxiv.org/abs/2310.05388",
    "authors": [
      "Zhihua Wen",
      "Zhiliang Tian",
      "Wei Wu",
      "Yuxin Yang",
      "Yanqi Shi",
      "Zhen Huang",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.06484",
    "title": "Memory efficient location recommendation through proximity-aware  representation",
    "abstract": " Title: Memory efficient location recommendation through proximity-aware  representation ",
    "url": "https://arxiv.org/abs/2310.06484",
    "authors": [
      "Xuan Luo",
      "Mingqing Huang",
      "Rui Lv",
      "Hui Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.06498",
    "title": "A New Benchmark and Reverse Validation Method for Passage-level  Hallucination Detection",
    "abstract": " Comments: EMNLP2023 Findings ",
    "url": "https://arxiv.org/abs/2310.06498",
    "authors": [
      "Shiping Yang",
      "Renliang Sun",
      "Xiaojun Wan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.09706",
    "title": "AdaptSSR: Pre-training User Model with Augmentation-Adaptive  Self-Supervised Ranking",
    "abstract": " Comments: Accepted by NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2310.09706",
    "authors": [
      "Yang Yu",
      "Qi Liu",
      "Kai Zhang",
      "Yuren Zhang",
      "Chao Song",
      "Min Hou",
      "Yuqing Yuan",
      "Zhihao Ye",
      "Zaixi Zhang",
      "Sanshi Lei Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.11368",
    "title": "VECHR: A Dataset for Explainable and Robust Classification of  Vulnerability Type in the European Court of Human Rights",
    "abstract": " Comments: Accepted to EMNLP 2023 ",
    "url": "https://arxiv.org/abs/2310.11368",
    "authors": [
      "Shanshan Xu",
      "Leon Staufer",
      "T.Y.S.S Santosh",
      "Oana Ichim",
      "Corina Heri",
      "Matthias Grabmair"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.11398",
    "title": "Neural Attention: Enhancing QKV Calculation in Self-Attention Mechanism  with Neural Networks",
    "abstract": " Comments: Updated the formulas in Section 3.2 \"Detailed Methodology\" and revised Section 2 \"Background\" for clarity and accuracy ",
    "url": "https://arxiv.org/abs/2310.11398",
    "authors": [
      "Muhan Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.11479",
    "title": "On the Temperature of Bayesian Graph Neural Networks for Conformal  Prediction",
    "abstract": " Title: On the Temperature of Bayesian Graph Neural Networks for Conformal  Prediction ",
    "url": "https://arxiv.org/abs/2310.11479",
    "authors": [
      "Seohyeon Cha",
      "Honggu Kang",
      "Joonhyuk Kang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.11978",
    "title": "Can bin-wise scaling improve consistency and adaptivity of prediction  uncertainty for machine learning regression ?",
    "abstract": " Comments: This version corrects an error in the estimation of the Sx scores for the test set, affecting Fig. 2 and Tables I-III of the initial version. The main points of the discussion and the conclusions are unchanged ",
    "url": "https://arxiv.org/abs/2310.11978",
    "authors": [
      "Pascal Pernot"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2310.12172",
    "title": "Overview of ImageArg-2023: The First Shared Task in Multimodal Argument  Mining",
    "abstract": " Comments: In The 10th Argument Mining Workshop, held in conjunction with The Conference on Empirical Methods in Natural Language Processing (EMNLP), December 2023 ",
    "url": "https://arxiv.org/abs/2310.12172",
    "authors": [
      "Zhexiong Liu",
      "Mohamed Elaraby",
      "Yang Zhong",
      "Diane Litman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.13123",
    "title": "Fuel Consumption Prediction for a Passenger Ferry using Machine Learning  and In-service Data: A Comparative Study",
    "abstract": " Comments: 20 pages, 11 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2310.13123",
    "authors": [
      "Pedram Agand",
      "Allison Kennedy",
      "Trevor Harris",
      "Chanwoo Bae",
      "Mo Chen",
      "Edward J Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.13573",
    "title": "Boosting Generalization with Adaptive Style Techniques for Fingerprint  Liveness Detection",
    "abstract": " Comments: 1st Place in LivDet2023 Fingerprint Representation Challenge ",
    "url": "https://arxiv.org/abs/2310.13573",
    "authors": [
      "Kexin Zhu",
      "Bo Lin",
      "Yang Qiu",
      "Adam Yule",
      "Yao Tang",
      "Jiajun Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.14270",
    "title": "Diffusion-Based Adversarial Purification for Speaker Verification",
    "abstract": " Title: Diffusion-Based Adversarial Purification for Speaker Verification ",
    "url": "https://arxiv.org/abs/2310.14270",
    "authors": [
      "Yibo Bai",
      "Xiao-Lei Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2310.14925",
    "title": "Efficient Causal Discovery for Robotics Applications",
    "abstract": " Comments: Published at 5th Italian Conference on Robotics and Intelligent Machines (I-RIM 3D 2023) ",
    "url": "https://arxiv.org/abs/2310.14925",
    "authors": [
      "Luca Castri",
      "Sariah Mghames",
      "Nicola Bellotto"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.14948",
    "title": "Physics-Informed Graph Convolutional Networks: Towards a generalized  framework for complex geometries",
    "abstract": " Title: Physics-Informed Graph Convolutional Networks: Towards a generalized  framework for complex geometries ",
    "url": "https://arxiv.org/abs/2310.14948",
    "authors": [
      "Marien Chenaud",
      "Jos\u00e9 Alves",
      "Fr\u00e9d\u00e9ric Magoul\u00e8s"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2310.15047",
    "title": "Meta- (out-of-context) learning in neural networks",
    "abstract": " Title: Meta- (out-of-context) learning in neural networks ",
    "url": "https://arxiv.org/abs/2310.15047",
    "authors": [
      "Dmitrii Krasheninnikov",
      "Egor Krasheninnikov",
      "Bruno Mlodozeniec",
      "David Krueger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.15168",
    "title": "Ghost on the Shell: An Expressive Representation of General 3D Shapes",
    "abstract": " Comments: Technical Report (26 pages, 16 figures, Project Page: this https URL) ",
    "url": "https://arxiv.org/abs/2310.15168",
    "authors": [
      "Zhen Liu",
      "Yao Feng",
      "Yuliang Xiu",
      "Weiyang Liu",
      "Liam Paull",
      "Michael J. Black",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  }
]