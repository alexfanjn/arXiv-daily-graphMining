[
  {
    "id": "arXiv:2310.16061",
    "title": "Segue: Side-information Guided Generative Unlearnable Examples for  Facial Privacy Protection in Real World",
    "abstract": "The widespread use of face recognition technology has given rise to privacy concerns, as many individuals are worried about the collection and utilization of their facial data. To address these concerns, researchers are actively exploring the concept of ``unlearnable examples\", by adding imperceptible perturbation to data in the model training stage, which aims to prevent the model from learning discriminate features of the target face. However, current methods are inefficient and cannot guarantee transferability and robustness at the same time, causing impracticality in the real world. To remedy it, we propose a novel method called Segue: Side-information guided generative unlearnable examples. Specifically, we leverage a once-trained multiple-used model to generate the desired perturbation rather than the time-consuming gradient-based method. To improve transferability, we introduce side information such as true labels and pseudo labels, which are inherently consistent across different scenarios. For robustness enhancement, a distortion layer is integrated into the training pipeline. Extensive experiments demonstrate that the proposed Segue is much faster than previous methods (1000$\\times$) and achieves transferable effectiveness across different datasets and model architectures. Furthermore, it can resist JPEG compression, adversarial training, and some standard data augmentations. ",
    "url": "https://arxiv.org/abs/2310.16061",
    "authors": [
      "Zhiling Zhang",
      "Jie Zhang",
      "Kui Zhang",
      "Wenbo Zhou",
      "Weiming Zhang",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16062",
    "title": "Confounder Balancing in Adversarial Domain Adaptation for Pre-Trained  Large Models Fine-Tuning",
    "abstract": "The excellent generalization, contextual learning, and emergence abilities in the pre-trained large models (PLMs) handle specific tasks without direct training data, making them the better foundation models in the adversarial domain adaptation (ADA) methods to transfer knowledge learned from the source domain to target domains. However, existing ADA methods fail to account for the confounder properly, which is the root cause of the source data distribution that differs from the target domains. This study proposes an adversarial domain adaptation with confounder balancing for PLMs fine-tuning (ADA-CBF). The ADA-CBF includes a PLM as the foundation model for a feature extractor, a domain classifier and a confounder classifier, and they are jointly trained with an adversarial loss. This loss is designed to improve the domain-invariant representation learning by diluting the discrimination in the domain classifier. At the same time, the adversarial loss also balances the confounder distribution among source and unmeasured domains in training. Compared to existing ADA methods, ADA-CBF can correctly identify confounders in domain-invariant features, thereby eliminating the confounder biases in the extracted features from PLMs. The confounder classifier in ADA-CBF is designed as a plug-and-play and can be applied in the confounder measurable, unmeasurable, or partially measurable environments. Empirical results on natural language processing and computer vision downstream tasks show that ADA-CBF outperforms the newest GPT-4, LLaMA2, ViT and ADA methods. ",
    "url": "https://arxiv.org/abs/2310.16062",
    "authors": [
      "Shuoran Jiang",
      "Qingcai Chen",
      "Yang Xiang",
      "Youcheng Pan",
      "Xiangping Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16063",
    "title": "Enhancing Traffic Prediction with Learnable Filter Module",
    "abstract": "Modeling future traffic conditions often relies heavily on complex spatial-temporal neural networks to capture spatial and temporal correlations, which can overlook the inherent noise in the data. This noise, often manifesting as unexpected short-term peaks or drops in traffic observation, is typically caused by traffic accidents or inherent sensor vibration. In practice, such noise can be challenging to model due to its stochastic nature and can lead to overfitting risks if a neural network is designed to learn this behavior. To address this issue, we propose a learnable filter module to filter out noise in traffic data adaptively. This module leverages the Fourier transform to convert the data to the frequency domain, where noise is filtered based on its pattern. The denoised data is then recovered to the time domain using the inverse Fourier transform. Our approach focuses on enhancing the quality of the input data for traffic prediction models, which is a critical yet often overlooked aspect in the field. We demonstrate that the proposed module is lightweight, easy to integrate with existing models, and can significantly improve traffic prediction performance. Furthermore, we validate our approach with extensive experimental results on real-world datasets, showing that it effectively mitigates noise and enhances prediction accuracy. ",
    "url": "https://arxiv.org/abs/2310.16063",
    "authors": [
      "Yuanshao Zhu",
      "Yongchao Ye",
      "Xiangyu Zhao",
      "James J.Q. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16065",
    "title": "The Hyperdimensional Transform: a Holographic Representation of  Functions",
    "abstract": "Integral transforms are invaluable mathematical tools to map functions into spaces where they are easier to characterize. We introduce the hyperdimensional transform as a new kind of integral transform. It converts square-integrable functions into noise-robust, holographic, high-dimensional representations called hyperdimensional vectors. The central idea is to approximate a function by a linear combination of random functions. We formally introduce a set of stochastic, orthogonal basis functions and define the hyperdimensional transform and its inverse. We discuss general transform-related properties such as its uniqueness, approximation properties of the inverse transform, and the representation of integrals and derivatives. The hyperdimensional transform offers a powerful, flexible framework that connects closely with other integral transforms, such as the Fourier, Laplace, and fuzzy transforms. Moreover, it provides theoretical foundations and new insights for the field of hyperdimensional computing, a computing paradigm that is rapidly gaining attention for efficient and explainable machine learning algorithms, with potential applications in statistical modelling and machine learning. In addition, we provide straightforward and easily understandable code, which can function as a tutorial and allows for the reproduction of the demonstrated examples, from computing the transform to solving differential equations. ",
    "url": "https://arxiv.org/abs/2310.16065",
    "authors": [
      "Pieter Dewulf",
      "Michiel Stock",
      "Bernard De Baets"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.16070",
    "title": "Spatial-Temporal Hypergraph Neural Network for Traffic Forecasting",
    "abstract": "Traffic forecasting, which benefits from mobile Internet development and position technologies, plays a critical role in Intelligent Transportation Systems. It helps to implement rich and varied transportation applications and bring convenient transportation services to people based on collected traffic data. Most existing methods usually leverage graph-based deep learning networks to model the complex road network for traffic forecasting shallowly. Despite their effectiveness, these methods are generally limited in fully capturing high-order spatial dependencies caused by road network topology and high-order temporal dependencies caused by traffic dynamics. To tackle the above issues, we focus on the essence of traffic system and propose STHODE: Spatio-Temporal Hypergraph Neural Ordinary Differential Equation Network, which combines road network topology and traffic dynamics to capture high-order spatio-temporal dependencies in traffic data. Technically, STHODE consists of a spatial module and a temporal module. On the one hand, we construct a spatial hypergraph and leverage an adaptive MixHop hypergraph ODE network to capture high-order spatial dependencies. On the other hand, we utilize a temporal hypergraph and employ a hyperedge evolving ODE network to capture high-order temporal dependencies. Finally, we aggregate the outputs of stacked STHODE layers to mutually enhance the prediction performance. Extensive experiments conducted on four real-world traffic datasets demonstrate the superior performance of our proposed model compared to various baselines. ",
    "url": "https://arxiv.org/abs/2310.16070",
    "authors": [
      "Chengzhi Yao",
      "Zhi Li",
      "Junbo Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16071",
    "title": "Grid Frequency Forecasting in University Campuses using Convolutional  LSTM",
    "abstract": "The modern power grid is facing increasing complexities, primarily stemming from the integration of renewable energy sources and evolving consumption patterns. This paper introduces an innovative methodology that harnesses Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks to establish robust time series forecasting models for grid frequency. These models effectively capture the spatiotemporal intricacies inherent in grid frequency data, significantly enhancing prediction accuracy and bolstering power grid reliability. The research explores the potential and development of individualized Convolutional LSTM (ConvLSTM) models for buildings within a university campus, enabling them to be independently trained and evaluated for each building. Individual ConvLSTM models are trained on power consumption data for each campus building and forecast the grid frequency based on historical trends. The results convincingly demonstrate the superiority of the proposed models over traditional forecasting techniques, as evidenced by performance metrics such as Mean Square Error (MSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE). Additionally, an Ensemble Model is formulated to aggregate insights from the building-specific models, delivering comprehensive forecasts for the entire campus. This approach ensures the privacy and security of power consumption data specific to each building. ",
    "url": "https://arxiv.org/abs/2310.16071",
    "authors": [
      "Aneesh Sathe",
      "Wen Ren Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.16073",
    "title": "Correlation Debiasing for Unbiased Scene Graph Generation in Videos",
    "abstract": "Dynamic scene graph generation (SGG) from videos requires not only comprehensive understanding of objects across the scenes that are prone to temporal fluctuations but also a model the temporal motions and interactions with different objects. Moreover, the long-tailed distribution of visual relationships is the crucial bottleneck of most dynamic SGG methods, since most of them focus on capturing spatio-temporal context using complex architectures, which leads to the generation of biased scene graphs. To address these challenges, we propose FloCoDe: Flow-aware temporal consistency and Correlation Debiasing with uncertainty attenuation for unbiased dynamic scene graphs. FloCoDe employs feature warping using flow to detect temporally consistent objects across the frames. In addition, it uses correlation debiasing to learn the unbiased relation representation for long-tailed classes. Moreover, to attenuate the predictive uncertainties, it uses a mixture of sigmoidal cross-entropy loss and contrastive loss to incorporate label correlations to identify the commonly co-occurring relations and help debias the long-tailed ones. Extensive experimental evaluation shows a performance gain as high as 4.1% showing the superiority of generating more unbiased scene graphs. ",
    "url": "https://arxiv.org/abs/2310.16073",
    "authors": [
      "Anant Khandelwal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16095",
    "title": "CR-COPEC: Causal Rationale of Corporate Performance Changes to Learn  from Financial Reports",
    "abstract": "In this paper, we introduce CR-COPEC called Causal Rationale of Corporate Performance Changes from financial reports. This is a comprehensive large-scale domain-adaptation causal sentence dataset to detect financial performance changes of corporate. CR-COPEC contributes to two major achievements. First, it detects causal rationale from 10-K annual reports of the U.S. companies, which contain experts' causal analysis following accounting standards in a formal manner. This dataset can be widely used by both individual investors and analysts as material information resources for investing and decision making without tremendous effort to read through all the documents. Second, it carefully considers different characteristics which affect the financial performance of companies in twelve industries. As a result, CR-COPEC can distinguish causal sentences in various industries by taking unique narratives in each industry into consideration. We also provide an extensive analysis of how well CR-COPEC dataset is constructed and suited for classifying target sentences as causal ones with respect to industry characteristics. Our dataset and experimental codes are publicly available. ",
    "url": "https://arxiv.org/abs/2310.16095",
    "authors": [
      "Ye Eun Chun",
      "Sunjae Kwon",
      "Kyunghwan Sohn",
      "Nakwon Sung",
      "Junyoup Lee",
      "Byungki Seo",
      "Kevin Compher",
      "Seung-won Hwang",
      "Jaesik Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2310.16105",
    "title": "Locally Differentially Private Gradient Tracking for Distributed Online  Learning over Directed Graphs",
    "abstract": "Distributed online learning has been proven extremely effective in solving large-scale machine learning problems involving streaming data. However, information sharing between learners in distributed learning also raises concerns about the potential leakage of individual learners' sensitive data. To mitigate this risk, differential privacy, which is widely regarded as the \"gold standard\" for privacy protection, has been widely employed in many existing results on distributed online learning. However, these results often face a fundamental tradeoff between learning accuracy and privacy. In this paper, we propose a locally differentially private gradient tracking based distributed online learning algorithm that successfully circumvents this tradeoff. Our analysis shows that the proposed algorithm converges in mean square to the exact optimal solution while ensuring rigorous local differential privacy, with the cumulative privacy budget guaranteed to be finite even when the number of iterations tends to infinity. The algorithm is applicable even when the communication graph among learners is directed. To the best of our knowledge, this is the first result that simultaneously ensures learning accuracy and rigorous local differential privacy in distributed online learning over directed graphs. We evaluate our algorithm's performance by using multiple benchmark machine-learning applications, including logistic regression on the \"Mushrooms\" dataset and CNN-based image classification on the \"MNIST\" and \"CIFAR-10\" datasets, respectively. The experimental results confirm that the proposed algorithm outperforms existing counterparts in both training and testing accuracies. ",
    "url": "https://arxiv.org/abs/2310.16105",
    "authors": [
      "Ziqin Chen",
      "Yongqiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16106",
    "title": "Decentralized Learning over Wireless Networks with Broadcast-Based  Subgraph Sampling",
    "abstract": "This work centers on the communication aspects of decentralized learning over wireless networks, using consensus-based decentralized stochastic gradient descent (D-SGD). Considering the actual communication cost or delay caused by in-network information exchange in an iterative process, our goal is to achieve fast convergence of the algorithm measured by improvement per transmission slot. We propose BASS, an efficient communication framework for D-SGD over wireless networks with broadcast transmission and probabilistic subgraph sampling. In each iteration, we activate multiple subsets of non-interfering nodes to broadcast model updates to their neighbors. These subsets are randomly activated over time, with probabilities reflecting their importance in network connectivity and subject to a communication cost constraint (e.g., the average number of transmission slots per iteration). During the consensus update step, only bi-directional links are effectively preserved to maintain communication symmetry. In comparison to existing link-based scheduling methods, the inherent broadcasting nature of wireless channels offers intrinsic advantages in speeding up convergence of decentralized learning by creating more communicated links with the same number of transmission slots. ",
    "url": "https://arxiv.org/abs/2310.16106",
    "authors": [
      "Daniel P\u00e9rez Herrera",
      "Zheng Chen",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.16109",
    "title": "Complex Image Generation SwinTransformer Network for Audio Denoising",
    "abstract": "Achieving high-performance audio denoising is still a challenging task in real-world applications. Existing time-frequency methods often ignore the quality of generated frequency domain images. This paper converts the audio denoising problem into an image generation task. We first develop a complex image generation SwinTransformer network to capture more information from the complex Fourier domain. We then impose structure similarity and detailed loss functions to generate high-quality images and develop an SDR loss to minimize the difference between denoised and clean audios. Extensive experiments on two benchmark datasets demonstrate that our proposed model is better than state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2310.16109",
    "authors": [
      "Youshan Zhang",
      "Jialu Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.16113",
    "title": "Compressed representation of brain genetic transcription",
    "abstract": "The architecture of the brain is too complex to be intuitively surveyable without the use of compressed representations that project its variation into a compact, navigable space. The task is especially challenging with high-dimensional data, such as gene expression, where the joint complexity of anatomical and transcriptional patterns demands maximum compression. Established practice is to use standard principal component analysis (PCA), whose computational felicity is offset by limited expressivity, especially at great compression ratios. Employing whole-brain, voxel-wise Allen Brain Atlas transcription data, here we systematically compare compressed representations based on the most widely supported linear and non-linear methods-PCA, kernel PCA, non-negative matrix factorization (NMF), t-stochastic neighbour embedding (t-SNE), uniform manifold approximation and projection (UMAP), and deep auto-encoding-quantifying reconstruction fidelity, anatomical coherence, and predictive utility with respect to signalling, microstructural, and metabolic targets. We show that deep auto-encoders yield superior representations across all metrics of performance and target domains, supporting their use as the reference standard for representing transcription patterns in the human brain. ",
    "url": "https://arxiv.org/abs/2310.16113",
    "authors": [
      "James K Ruffle",
      "Henry Watkins",
      "Robert J Gray",
      "Harpreet Hyare",
      "Michel Thiebaut de Schotten",
      "Parashkev Nachev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2310.16125",
    "title": "Online Thermal Field Prediction for Metal Additive Manufacturing of Thin  Walls",
    "abstract": "This paper aims to study a practical issue in metal AM, i.e., how to predict the thermal field of yet-to-print parts online when only a few sensors are available. This work proposes an online thermal field prediction method using mapping and reconstruction, which could be integrated into a metal AM process for online performance control. Based on the similarity of temperature curves (curve segments of a temperature profile of one point), the thermal field mapping applies an artificial neural network to estimate the temperature curves of points on the yet-to-print layer from measured temperatures of certain points on the previously printed layer. With measured/predicted temperature profiles of several points on the same layer, the thermal field reconstruction proposes a reduced order model (ROM) to construct the temperature profiles of all points on the same layer, which could be used to build the temperature field of the entire layer. The training of ROM is performed with an extreme learning machine (ELM) for computational efficiency. Fifteen wire arc AM experiments and nine simulations are designed for thin walls with a fixed length and unidirectional printing of each layer. The test results indicate that the proposed prediction method could construct the thermal field of a yet-to-print layer within 0.1 seconds on a low-cost desktop. Meanwhile, the method has acceptable generalization capability in most cases from lower layers to higher layers in the same simulation and from one simulation to a new simulation on different AM process parameters. More importantly, after fine-tuning the proposed method with limited experimental data, the relative errors of all predicted temperature profiles on a new experiment are sufficiently small, demonstrating the applicability and generalization of the proposed thermal field prediction method in online applications for metal AM. ",
    "url": "https://arxiv.org/abs/2310.16125",
    "authors": [
      "Yifan Tang",
      "M. Rahmani Dehaghani",
      "Pouyan Sajadi",
      "Shahriar Bakrani Balani",
      "Akshay Dhalpe",
      "Suraj Panicker",
      "Di Wu",
      "Eric Coatanea",
      "G. Gary Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16131",
    "title": "GenKIE: Robust Generative Multimodal Document Key Information Extraction",
    "abstract": "Key information extraction (KIE) from scanned documents has gained increasing attention because of its applications in various domains. Although promising results have been achieved by some recent KIE approaches, they are usually built based on discriminative models, which lack the ability to handle optical character recognition (OCR) errors and require laborious token-level labelling. In this paper, we propose a novel generative end-to-end model, named GenKIE, to address the KIE task. GenKIE is a sequence-to-sequence multimodal generative model that utilizes multimodal encoders to embed visual, layout and textual features and a decoder to generate the desired output. Well-designed prompts are leveraged to incorporate the label semantics as the weakly supervised signals and entice the generation of the key information. One notable advantage of the generative model is that it enables automatic correction of OCR errors. Besides, token-level granular annotation is not required. Extensive experiments on multiple public real-world datasets show that GenKIE effectively generalizes over different types of documents and achieves state-of-the-art results. Our experiments also validate the model's robustness against OCR errors, making GenKIE highly applicable in real-world scenarios. ",
    "url": "https://arxiv.org/abs/2310.16131",
    "authors": [
      "Panfeng Cao",
      "Ye Wang",
      "Qiang Zhang",
      "Zaiqiao Meng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.16138",
    "title": "Subtle Signals: Video-based Detection of Infant Non-nutritive Sucking as  a Neurodevelopmental Cue",
    "abstract": "Non-nutritive sucking (NNS), which refers to the act of sucking on a pacifier, finger, or similar object without nutrient intake, plays a crucial role in assessing healthy early development. In the case of preterm infants, NNS behavior is a key component in determining their readiness for feeding. In older infants, the characteristics of NNS behavior offer valuable insights into neural and motor development. Additionally, NNS activity has been proposed as a potential safeguard against sudden infant death syndrome (SIDS). However, the clinical application of NNS assessment is currently hindered by labor-intensive and subjective finger-in-mouth evaluations. Consequently, researchers often resort to expensive pressure transducers for objective NNS signal measurement. To enhance the accessibility and reliability of NNS signal monitoring for both clinicians and researchers, we introduce a vision-based algorithm designed for non-contact detection of NNS activity using baby monitor footage in natural settings. Our approach involves a comprehensive exploration of optical flow and temporal convolutional networks, enabling the detection and amplification of subtle infant-sucking signals. We successfully classify short video clips of uniform length into NNS and non-NNS periods. Furthermore, we investigate manual and learning-based techniques to piece together local classification results, facilitating the segmentation of longer mixed-activity videos into NNS and non-NNS segments of varying duration. Our research introduces two novel datasets of annotated infant videos, including one sourced from our clinical study featuring 19 infant subjects and 183 hours of overnight baby monitor footage. ",
    "url": "https://arxiv.org/abs/2310.16138",
    "authors": [
      "Shaotong Zhu",
      "Michael Wan",
      "Sai Kumar Reddy Manne",
      "Emily Zimmerman",
      "Sarah Ostadabbas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.16141",
    "title": "Context-aware explainable recommendations over knowledge graphs",
    "abstract": "Knowledge graphs contain rich semantic relationships related to items and incorporating such semantic relationships into recommender systems helps to explore the latent connections of items, thus improving the accuracy of prediction and enhancing the explainability of recommendations. However, such explainability is not adapted to users' contexts, which can significantly influence their preferences. In this work, we propose CA-KGCN (Context-Aware Knowledge Graph Convolutional Network), an end-to-end framework that can model users' preferences adapted to their contexts and can incorporate rich semantic relationships in the knowledge graph related to items. This framework captures users' attention to different factors: contexts and features of items. More specifically, the framework can model users' preferences adapted to their contexts and provide explanations adapted to the given context. Experiments on three real-world datasets show the effectiveness of our framework: modeling users' preferences adapted to their contexts and explaining the recommendations generated. ",
    "url": "https://arxiv.org/abs/2310.16141",
    "authors": [
      "Jinfeng Zhong",
      "Elsa Negre"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.16148",
    "title": "Yin Yang Convolutional Nets: Image Manifold Extraction by the Analysis  of Opposites",
    "abstract": "Computer vision in general presented several advances such as training optimizations, new architectures (pure attention, efficient block, vision language models, generative models, among others). This have improved performance in several tasks such as classification, and others. However, the majority of these models focus on modifications that are taking distance from realistic neuroscientific approaches related to the brain. In this work, we adopt a more bio-inspired approach and present the Yin Yang Convolutional Network, an architecture that extracts visual manifold, its blocks are intended to separate analysis of colors and forms at its initial layers, simulating occipital lobe's operations. Our results shows that our architecture provides State-of-the-Art efficiency among low parameter architectures in the dataset CIFAR-10. Our first model reached 93.32\\% test accuracy, 0.8\\% more than the older SOTA in this category, while having 150k less parameters (726k in total). Our second model uses 52k parameters, losing only 3.86\\% test accuracy. We also performed an analysis on ImageNet, where we reached 66.49\\% validation accuracy with 1.6M parameters. We make the code publicly available at: https://github.com/NoSavedDATA/YinYang_CNN. ",
    "url": "https://arxiv.org/abs/2310.16148",
    "authors": [
      "Augusto Seben da Rosa",
      "Frederico Santos de Oliveira",
      "Anderson da Silva Soares",
      "Arnaldo Candido Junior"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.16152",
    "title": "FLTrojan: Privacy Leakage Attacks against Federated Language Models  Through Selective Weight Tampering",
    "abstract": "Federated learning (FL) is becoming a key component in many technology-based applications including language modeling -- where individual FL participants often have privacy-sensitive text data in their local datasets. However, realizing the extent of privacy leakage in federated language models is not straightforward and the existing attacks only intend to extract data regardless of how sensitive or naive it is. To fill this gap, in this paper, we introduce two novel findings with regard to leaking privacy-sensitive user data from federated language models. Firstly, we make a key observation that model snapshots from the intermediate rounds in FL can cause greater privacy leakage than the final trained model. Secondly, we identify that privacy leakage can be aggravated by tampering with a model's selective weights that are specifically responsible for memorizing the sensitive training data. We show how a malicious client can leak the privacy-sensitive data of some other user in FL even without any cooperation from the server. Our best-performing method improves the membership inference recall by 29% and achieves up to 70% private data reconstruction, evidently outperforming existing attacks with stronger assumptions of adversary capabilities. ",
    "url": "https://arxiv.org/abs/2310.16152",
    "authors": [
      "Md Rafi Ur Rashid",
      "Vishnu Asutosh Dasu",
      "Kang Gu",
      "Najrin Sultana",
      "Shagufta Mehnaz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16154",
    "title": "Breaking the Curse of Dimensionality in Deep Neural Networks by Learning  Invariant Representations",
    "abstract": "Artificial intelligence, particularly the subfield of machine learning, has seen a paradigm shift towards data-driven models that learn from and adapt to data. This has resulted in unprecedented advancements in various domains such as natural language processing and computer vision, largely attributed to deep learning, a special class of machine learning models. Deep learning arguably surpasses traditional approaches by learning the relevant features from raw data through a series of computational layers. This thesis explores the theoretical foundations of deep learning by studying the relationship between the architecture of these models and the inherent structures found within the data they process. In particular, we ask What drives the efficacy of deep learning algorithms and allows them to beat the so-called curse of dimensionality-i.e. the difficulty of generally learning functions in high dimensions due to the exponentially increasing need for data points with increased dimensionality? Is it their ability to learn relevant representations of the data by exploiting their structure? How do different architectures exploit different data structures? In order to address these questions, we push forward the idea that the structure of the data can be effectively characterized by its invariances-i.e. aspects that are irrelevant for the task at hand. Our methodology takes an empirical approach to deep learning, combining experimental studies with physics-inspired toy models. These simplified models allow us to investigate and interpret the complex behaviors we observe in deep learning systems, offering insights into their inner workings, with the far-reaching goal of bridging the gap between theory and practice. ",
    "url": "https://arxiv.org/abs/2310.16154",
    "authors": [
      "Leonardo Petrini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16190",
    "title": "Multilayer Environment and Toolchain for Holistic NetwOrk Design and  Analysis",
    "abstract": "The recent developments and research in distributed ledger technologies and blockchain have contributed to the increasing adoption of distributed systems. To collect relevant insights into systems' behavior, we observe many evaluation frameworks focusing mainly on the system under test throughput. However, these frameworks often need more comprehensiveness and generality, particularly in adopting a distributed applications' cross-layer approach. This work analyses in detail the requirements for distributed systems assessment. We summarize these findings into a structured methodology and experimentation framework called METHODA. Our approach emphasizes setting up and assessing a broader spectrum of distributed systems and addresses a notable research gap. We showcase the effectiveness of the framework by evaluating four distinct systems and their interaction, leveraging a diverse set of eight carefully selected metrics and 12 essential parameters. Through experimentation and analysis we demonstrate the framework's capabilities to provide valuable insights across various use cases. For instance, we identify that a combination of Trusted Execution Environments with threshold signature scheme FROST introduces minimal overhead on the performance with average latency around \\SI{40}{\\ms}. We showcase an emulation of realistic systems behavior, e.g., Maximal Extractable Value is possible and could be used to further model such dynamics. The METHODA framework enables a deeper understanding of distributed systems and is a powerful tool for researchers and practitioners navigating the complex landscape of modern computing infrastructures. ",
    "url": "https://arxiv.org/abs/2310.16190",
    "authors": [
      "Filip Rezabek",
      "Kilian Glas",
      "Richard von Seck",
      "Achraf Aroua",
      "Tizian Leonhardt",
      "Georg Carle"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2310.16212",
    "title": "ShadowSense: Unsupervised Domain Adaptation and Feature Fusion for  Shadow-Agnostic Tree Crown Detection from RGB-Thermal Drone Imagery",
    "abstract": "Accurate detection of individual tree crowns from remote sensing data poses a significant challenge due to the dense nature of forest canopy and the presence of diverse environmental variations, e.g., overlapping canopies, occlusions, and varying lighting conditions. Additionally, the lack of data for training robust models adds another limitation in effectively studying complex forest conditions. This paper presents a novel method for detecting shadowed tree crowns and provides a challenging dataset comprising roughly 50k paired RGB-thermal images to facilitate future research for illumination-invariant detection. The proposed method (ShadowSense) is entirely self-supervised, leveraging domain adversarial training without source domain annotations for feature extraction and foreground feature alignment for feature pyramid networks to adapt domain-invariant representations by focusing on visible foreground regions, respectively. It then fuses complementary information of both modalities to effectively improve upon the predictions of an RGB-trained detector and boost the overall accuracy. Extensive experiments demonstrate the superiority of the proposed method over both the baseline RGB-trained detector and state-of-the-art techniques that rely on unsupervised domain adaptation or early image fusion. Our code and data are available: https://github.com/rudrakshkapil/ShadowSense ",
    "url": "https://arxiv.org/abs/2310.16212",
    "authors": [
      "Rudraksh Kapil",
      "Seyed Mojtaba Marvasti-Zadeh",
      "Nadir Erbilgin",
      "Nilanjan Ray"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16224",
    "title": "Poison is Not Traceless: Fully-Agnostic Detection of Poisoning Attacks",
    "abstract": "The performance of machine learning models depends on the quality of the underlying data. Malicious actors can attack the model by poisoning the training data. Current detectors are tied to either specific data types, models, or attacks, and therefore have limited applicability in real-world scenarios. This paper presents a novel fully-agnostic framework, DIVA (Detecting InVisible Attacks), that detects attacks solely relying on analyzing the potentially poisoned data set. DIVA is based on the idea that poisoning attacks can be detected by comparing the classifier's accuracy on poisoned and clean data and pre-trains a meta-learner using Complexity Measures to estimate the otherwise unknown accuracy on a hypothetical clean dataset. The framework applies to generic poisoning attacks. For evaluation purposes, in this paper, we test DIVA on label-flipping attacks. ",
    "url": "https://arxiv.org/abs/2310.16224",
    "authors": [
      "Xinglong Chang",
      "Katharina Dost",
      "Gillian Dobbie",
      "J\u00f6rg Wicker"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16234",
    "title": "Pixel-Level Clustering Network for Unsupervised Image Segmentation",
    "abstract": "While image segmentation is crucial in various computer vision applications, such as autonomous driving, grasping, and robot navigation, annotating all objects at the pixel-level for training is nearly impossible. Therefore, the study of unsupervised image segmentation methods is essential. In this paper, we present a pixel-level clustering framework for segmenting images into regions without using ground truth annotations. The proposed framework includes feature embedding modules with an attention mechanism, a feature statistics computing module, image reconstruction, and superpixel segmentation to achieve accurate unsupervised segmentation. Additionally, we propose a training strategy that utilizes intra-consistency within each superpixel, inter-similarity/dissimilarity between neighboring superpixels, and structural similarity between images. To avoid potential over-segmentation caused by superpixel-based losses, we also propose a post-processing method. Furthermore, we present an extension of the proposed method for unsupervised semantic segmentation. We conducted experiments on three publicly available datasets (Berkeley segmentation dataset, PASCAL VOC 2012 dataset, and COCO-Stuff dataset) to demonstrate the effectiveness of the proposed framework. The experimental results show that the proposed framework outperforms previous state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2310.16234",
    "authors": [
      "Cuong Manh Hoang",
      "Byeongkeun Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.16241",
    "title": "Task Grouping for Automated Multi-Task Machine Learning via Task  Affinity Prediction",
    "abstract": "When a number of similar tasks have to be learned simultaneously, multi-task learning (MTL) models can attain significantly higher accuracy than single-task learning (STL) models. However, the advantage of MTL depends on various factors, such as the similarity of the tasks, the sizes of the datasets, and so on; in fact, some tasks might not benefit from MTL and may even incur a loss of accuracy compared to STL. Hence, the question arises: which tasks should be learned together? Domain experts can attempt to group tasks together following intuition, experience, and best practices, but manual grouping can be labor-intensive and far from optimal. In this paper, we propose a novel automated approach for task grouping. First, we study the affinity of tasks for MTL using four benchmark datasets that have been used extensively in the MTL literature, focusing on neural network-based MTL models. We identify inherent task features and STL characteristics that can help us to predict whether a group of tasks should be learned together using MTL or if they should be learned independently using STL. Building on this predictor, we introduce a randomized search algorithm, which employs the predictor to minimize the number of MTL trainings performed during the search for task groups. We demonstrate on the four benchmark datasets that our predictor-driven search approach can find better task groupings than existing baseline approaches. ",
    "url": "https://arxiv.org/abs/2310.16241",
    "authors": [
      "Afiya Ayman",
      "Ayan Mukhopadhyay",
      "Aron Laszka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16249",
    "title": "A clustering tool for interrogating finite element models based on  eigenvectors of graph adjacency",
    "abstract": "This note introduces an unsupervised learning algorithm to debug errors in finite element (FE) simulation models and details how it was productionised. The algorithm clusters degrees of freedom in the FE model using numerical properties of the adjacency of its stiffness matrix. The algorithm has been deployed as a tool called `Model Stability Analysis' tool within the commercial structural FE suite Oasys GSA (www.oasys-software.com/gsa). It has been used successfully by end-users for debugging real world FE models and we present examples of the tool in action. ",
    "url": "https://arxiv.org/abs/2310.16249",
    "authors": [
      "Ramaseshan Kannan"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.16256",
    "title": "A Causal Disentangled Multi-Granularity Graph Classification Method",
    "abstract": "Graph data widely exists in real life, with large amounts of data and complex structures. It is necessary to map graph data to low-dimensional embedding. Graph classification, a critical graph task, mainly relies on identifying the important substructures within the graph. At present, some graph classification methods do not combine the multi-granularity characteristics of graph data. This lack of granularity distinction in modeling leads to a conflation of key information and false correlations within the model. So, achieving the desired goal of a credible and interpretable model becomes challenging. This paper proposes a causal disentangled multi-granularity graph representation learning method (CDM-GNN) to solve this challenge. The CDM-GNN model disentangles the important substructures and bias parts within the graph from a multi-granularity perspective. The disentanglement of the CDM-GNN model reveals important and bias parts, forming the foundation for its classification task, specifically, model interpretations. The CDM-GNN model exhibits strong classification performance and generates explanatory outcomes aligning with human cognitive patterns. In order to verify the effectiveness of the model, this paper compares the three real-world datasets MUTAG, PTC, and IMDM-M. Six state-of-the-art models, namely GCN, GAT, Top-k, ASAPool, SUGAR, and SAT are employed for comparison purposes. Additionally, a qualitative analysis of the interpretation results is conducted. ",
    "url": "https://arxiv.org/abs/2310.16256",
    "authors": [
      "Yuan Li",
      "Li Liu",
      "Penggang Chen",
      "Youmin Zhang",
      "Guoyin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2310.16263",
    "title": "Enhancing Large Language Models for Secure Code Generation: A  Dataset-driven Study on Vulnerability Mitigation",
    "abstract": "Large language models (LLMs) have brought significant advancements to code generation, benefiting both novice and experienced developers. However, their training using unsanitized data from open-source repositories, like GitHub, introduces the risk of inadvertently propagating security vulnerabilities. To effectively mitigate this concern, this paper presents a comprehensive study focused on evaluating and enhancing code LLMs from a software security perspective. We introduce SecuCoGen\\footnote{SecuCoGen has been uploaded as supplemental material and will be made publicly available after publication.}, a meticulously curated dataset targeting 21 critical vulnerability types. SecuCoGen comprises 180 samples and serves as the foundation for conducting experiments on three crucial code-related tasks: code generation, code repair and vulnerability classification, with a strong emphasis on security. Our experimental results reveal that existing models often overlook security concerns during code generation, leading to the generation of vulnerable code. To address this, we propose effective approaches to mitigate the security vulnerabilities and enhance the overall robustness of code generated by LLMs. Moreover, our study identifies weaknesses in existing models' ability to repair vulnerable code, even when provided with vulnerability information. Additionally, certain vulnerability types pose challenges for the models, hindering their performance in vulnerability classification. Based on these findings, we believe our study will have a positive impact on the software engineering community, inspiring the development of improved methods for training and utilizing LLMs, thereby leading to safer and more trustworthy model deployment. ",
    "url": "https://arxiv.org/abs/2310.16263",
    "authors": [
      "Jiexin Wang",
      "Liuwen Cao",
      "Xitong Luo",
      "Zhiping Zhou",
      "Jiayuan Xie",
      "Adam Jatowt",
      "Yi Cai"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.16283",
    "title": "Modeling and Analysis of the Lead-Lag Network of Economic Indicators",
    "abstract": "We propose a method of analyzing multivariate time series data that investigates lead-lag relationships among economic indicators during the COVID-19 era with a weighted directed network of lagged variables. The analysis includes a stock index, average unemployment, and several variables that are used to calculate inflation. Three complex networks are created, with these variables and several lags of each as the network nodes. Network edges are weighted based on three relationship metrics: correlation, mutual information, and transfer entropy. In each network, nodes are merged, and edges are aggregated to simplify the weighted directed graph. Pagerank is used to determine the most influential and the most influenced node over the time period. Results were reasonably robust within each network, but they were heavily dependent on the choice of metric. ",
    "url": "https://arxiv.org/abs/2310.16283",
    "authors": [
      "Amanda Goodrick",
      "Hiroki Sayama"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2310.16288",
    "title": "MotionAGFormer: Enhancing 3D Human Pose Estimation with a  Transformer-GCNFormer Network",
    "abstract": "Recent transformer-based approaches have demonstrated excellent performance in 3D human pose estimation. However, they have a holistic view and by encoding global relationships between all the joints, they do not capture the local dependencies precisely. In this paper, we present a novel Attention-GCNFormer (AGFormer) block that divides the number of channels by using two parallel transformer and GCNFormer streams. Our proposed GCNFormer module exploits the local relationship between adjacent joints, outputting a new representation that is complementary to the transformer output. By fusing these two representation in an adaptive way, AGFormer exhibits the ability to better learn the underlying 3D structure. By stacking multiple AGFormer blocks, we propose MotionAGFormer in four different variants, which can be chosen based on the speed-accuracy trade-off. We evaluate our model on two popular benchmark datasets: Human3.6M and MPI-INF-3DHP. MotionAGFormer-B achieves state-of-the-art results, with P1 errors of 38.4mm and 16.2mm, respectively. Remarkably, it uses a quarter of the parameters and is three times more computationally efficient than the previous leading model on Human3.6M dataset. Code and models are available at https://github.com/TaatiTeam/MotionAGFormer. ",
    "url": "https://arxiv.org/abs/2310.16288",
    "authors": [
      "Soroush Mehraban",
      "Vida Adeli",
      "Babak Taati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16295",
    "title": "Instance-wise Linearization of Neural Network for Model Interpretation",
    "abstract": "Neural network have achieved remarkable successes in many scientific fields. However, the interpretability of the neural network model is still a major bottlenecks to deploy such technique into our daily life. The challenge can dive into the non-linear behavior of the neural network, which rises a critical question that how a model use input feature to make a decision. The classical approach to address this challenge is feature attribution, which assigns an important score to each input feature and reveal its importance of current prediction. However, current feature attribution approaches often indicate the importance of each input feature without detail of how they are actually processed by a model internally. These attribution approaches often raise a concern that whether they highlight correct features for a model prediction. For a neural network model, the non-linear behavior is often caused by non-linear activation units of a model. However, the computation behavior of a prediction from a neural network model is locally linear, because one prediction has only one activation pattern. Base on the observation, we propose an instance-wise linearization approach to reformulates the forward computation process of a neural network prediction. This approach reformulates different layers of convolution neural networks into linear matrix multiplication. Aggregating all layers' computation, a prediction complex convolution neural network operations can be described as a linear matrix multiplication $F(x) = W \\cdot x + b$. This equation can not only provides a feature attribution map that highlights the important of the input features but also tells how each input feature contributes to a prediction exactly. Furthermore, we discuss the application of this technique in both supervise classification and unsupervised neural network learning parametric t-SNE dimension reduction. ",
    "url": "https://arxiv.org/abs/2310.16295",
    "authors": [
      "Zhimin Li",
      "Shusen Liu",
      "Kailkhura Bhavya",
      "Timo Bremer",
      "Valerio Pascucci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16302",
    "title": "Imperfect Digital Twin Assisted Low Cost Reinforcement Training for  Multi-UAV Networks",
    "abstract": "Deep Reinforcement Learning (DRL) is widely used to optimize the performance of multi-UAV networks. However, the training of DRL relies on the frequent interactions between the UAVs and the environment, which consumes lots of energy due to the flying and communication of UAVs in practical experiments. Inspired by the growing digital twin (DT) technology, which can simulate the performance of algorithms in the digital space constructed by coping features of the physical space, the DT is introduced to reduce the costs of practical training, e.g., energy and hardware purchases. Different from previous DT-assisted works with an assumption of perfect reflecting real physics by virtual digital, we consider an imperfect DT model with deviations for assisting the training of multi-UAV networks. Remarkably, to trade off the training cost, DT construction cost, and the impact of deviations of DT on training, the natural and virtually generated UAV mixing deployment method is proposed. Two cascade neural networks (NN) are used to optimize the joint number of virtually generated UAVs, the DT construction cost, and the performance of multi-UAV networks. These two NNs are trained by unsupervised and reinforcement learning, both low-cost label-free training methods. Simulation results show the training cost can significantly decrease while guaranteeing the training performance. This implies that an efficient decision can be made with imperfect DTs in multi-UAV networks. ",
    "url": "https://arxiv.org/abs/2310.16302",
    "authors": [
      "Xiucheng Wang",
      "Nan Cheng",
      "Longfei Ma",
      "Zhisheng Yin",
      "Tom. Luan",
      "Ning Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.16303",
    "title": "URL-BERT: Training Webpage Representations via Social Media Engagements",
    "abstract": "Understanding and representing webpages is crucial to online social networks where users may share and engage with URLs. Common language model (LM) encoders such as BERT can be used to understand and represent the textual content of webpages. However, these representations may not model thematic information of web domains and URLs or accurately capture their appeal to social media users. In this work, we introduce a new pre-training objective that can be used to adapt LMs to understand URLs and webpages. Our proposed framework consists of two steps: (1) scalable graph embeddings to learn shallow representations of URLs based on user engagement on social media and (2) a contrastive objective that aligns LM representations with the aforementioned graph-based representation. We apply our framework to the multilingual version of BERT to obtain the model URL-BERT. We experimentally demonstrate that our continued pre-training approach improves webpage understanding on a variety of tasks and Twitter internal and external benchmarks. ",
    "url": "https://arxiv.org/abs/2310.16303",
    "authors": [
      "Ayesha Qamar",
      "Chetan Verma",
      "Ahmed El-Kishky",
      "Sumit Binnani",
      "Sneha Mehta",
      "Taylor Berg-Kirkpatrick"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.16310",
    "title": "Score Matching-based Pseudolikelihood Estimation of Neural Marked  Spatio-Temporal Point Process with Uncertainty Quantification",
    "abstract": "Spatio-temporal point processes (STPPs) are potent mathematical tools for modeling and predicting events with both temporal and spatial features. Despite their versatility, most existing methods for learning STPPs either assume a restricted form of the spatio-temporal distribution, or suffer from inaccurate approximations of the intractable integral in the likelihood training objective. These issues typically arise from the normalization term of the probability density function. Moreover, current techniques fail to provide uncertainty quantification for model predictions, such as confidence intervals for the predicted event's arrival time and confidence regions for the event's location, which is crucial given the considerable randomness of the data. To tackle these challenges, we introduce SMASH: a Score MAtching-based pSeudolikeliHood estimator for learning marked STPPs with uncertainty quantification. Specifically, our framework adopts a normalization-free objective by estimating the pseudolikelihood of marked STPPs through score-matching and offers uncertainty quantification for the predicted event time, location and mark by computing confidence regions over the generated samples. The superior performance of our proposed framework is demonstrated through extensive experiments in both event prediction and uncertainty quantification. ",
    "url": "https://arxiv.org/abs/2310.16310",
    "authors": [
      "Zichong Li",
      "Qunzhi Xu",
      "Zhenghao Xu",
      "Yajun Mei",
      "Tuo Zhao",
      "Hongyuan Zha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16314",
    "title": "Understanding Code Semantics: An Evaluation of Transformer Models in  Summarization",
    "abstract": "This paper delves into the intricacies of code summarization using advanced transformer-based language models. Through empirical studies, we evaluate the efficacy of code summarization by altering function and variable names to explore whether models truly understand code semantics or merely rely on textual cues. We have also introduced adversaries like dead code and commented code across three programming languages (Python, Javascript, and Java) to further scrutinize the model's understanding. Ultimately, our research aims to offer valuable insights into the inner workings of transformer-based LMs, enhancing their ability to understand code and contributing to more efficient software development practices and maintenance workflows. ",
    "url": "https://arxiv.org/abs/2310.16314",
    "authors": [
      "Debanjan Mondal",
      "Abhilasha Lodha",
      "Ankita Sahoo",
      "Beena Kumari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16318",
    "title": "Modality-Agnostic Self-Supervised Learning with Meta-Learned Masked  Auto-Encoder",
    "abstract": "Despite its practical importance across a wide range of modalities, recent advances in self-supervised learning (SSL) have been primarily focused on a few well-curated domains, e.g., vision and language, often relying on their domain-specific knowledge. For example, Masked Auto-Encoder (MAE) has become one of the popular architectures in these domains, but less has explored its potential in other modalities. In this paper, we develop MAE as a unified, modality-agnostic SSL framework. In turn, we argue meta-learning as a key to interpreting MAE as a modality-agnostic learner, and propose enhancements to MAE from the motivation to jointly improve its SSL across diverse modalities, coined MetaMAE as a result. Our key idea is to view the mask reconstruction of MAE as a meta-learning task: masked tokens are predicted by adapting the Transformer meta-learner through the amortization of unmasked tokens. Based on this novel interpretation, we propose to integrate two advanced meta-learning techniques. First, we adapt the amortized latent of the Transformer encoder using gradient-based meta-learning to enhance the reconstruction. Then, we maximize the alignment between amortized and adapted latents through task contrastive learning which guides the Transformer encoder to better encode the task-specific knowledge. Our experiment demonstrates the superiority of MetaMAE in the modality-agnostic SSL benchmark (called DABS), significantly outperforming prior baselines. Code is available at https://github.com/alinlab/MetaMAE. ",
    "url": "https://arxiv.org/abs/2310.16318",
    "authors": [
      "Huiwon Jang",
      "Jihoon Tack",
      "Daewon Choi",
      "Jongheon Jeong",
      "Jinwoo Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.16335",
    "title": "Defense Against Model Extraction Attacks on Recommender Systems",
    "abstract": "The robustness of recommender systems has become a prominent topic within the research community. Numerous adversarial attacks have been proposed, but most of them rely on extensive prior knowledge, such as all the white-box attacks or most of the black-box attacks which assume that certain external knowledge is available. Among these attacks, the model extraction attack stands out as a promising and practical method, involving training a surrogate model by repeatedly querying the target model. However, there is a significant gap in the existing literature when it comes to defending against model extraction attacks on recommender systems. In this paper, we introduce Gradient-based Ranking Optimization (GRO), which is the first defense strategy designed to counter such attacks. We formalize the defense as an optimization problem, aiming to minimize the loss of the protected target model while maximizing the loss of the attacker's surrogate model. Since top-k ranking lists are non-differentiable, we transform them into swap matrices which are instead differentiable. These swap matrices serve as input to a student model that emulates the surrogate model's behavior. By back-propagating the loss of the student model, we obtain gradients for the swap matrices. These gradients are used to compute a swap loss, which maximizes the loss of the student model. We conducted experiments on three benchmark datasets to evaluate the performance of GRO, and the results demonstrate its superior effectiveness in defending against model extraction attacks. ",
    "url": "https://arxiv.org/abs/2310.16335",
    "authors": [
      "Sixiao Zhang",
      "Hongzhi Yin",
      "Hongxu Chen",
      "Cheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16349",
    "title": "DiffRef3D: A Diffusion-based Proposal Refinement Framework for 3D Object  Detection",
    "abstract": "Denoising diffusion models show remarkable performances in generative tasks, and their potential applications in perception tasks are gaining interest. In this paper, we introduce a novel framework named DiffRef3D which adopts the diffusion process on 3D object detection with point clouds for the first time. Specifically, we formulate the proposal refinement stage of two-stage 3D object detectors as a conditional diffusion process. During training, DiffRef3D gradually adds noise to the residuals between proposals and target objects, then applies the noisy residuals to proposals to generate hypotheses. The refinement module utilizes these hypotheses to denoise the noisy residuals and generate accurate box predictions. In the inference phase, DiffRef3D generates initial hypotheses by sampling noise from a Gaussian distribution as residuals and refines the hypotheses through iterative steps. DiffRef3D is a versatile proposal refinement framework that consistently improves the performance of existing 3D object detection models. We demonstrate the significance of DiffRef3D through extensive experiments on the KITTI benchmark. Code will be available. ",
    "url": "https://arxiv.org/abs/2310.16349",
    "authors": [
      "Se-Ho Kim",
      "Inyong Koo",
      "Inyoung Lee",
      "Byeongjun Park",
      "Changick Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16350",
    "title": "Unraveling Feature Extraction Mechanisms in Neural Networks",
    "abstract": "The underlying mechanism of neural networks in capturing precise knowledge has been the subject of consistent research efforts. In this work, we propose a theoretical approach based on Neural Tangent Kernels (NTKs) to investigate such mechanisms. Specifically, considering the infinite network width, we hypothesize the learning dynamics of target models may intuitively unravel the features they acquire from training data, deepening our insights into their internal mechanisms. We apply our approach to several fundamental models and reveal how these models leverage statistical features during gradient descent and how they are integrated into final decisions. We also discovered that the choice of activation function can affect feature extraction. For instance, the use of the \\textit{ReLU} activation function could potentially introduce a bias in features, providing a plausible explanation for its replacement with alternative functions in recent pre-trained language models. Additionally, we find that while self-attention and CNN models may exhibit limitations in learning n-grams, multiplication-based models seem to excel in this area. We verify these theoretical findings through experiments and find that they can be applied to analyze language modeling tasks, which can be regarded as a special variant of classification. Our contributions offer insights into the roles and capacities of fundamental components within large language models, thereby aiding the broader understanding of these complex systems. ",
    "url": "https://arxiv.org/abs/2310.16350",
    "authors": [
      "Xiaobing Sun",
      "Jiaxi Li",
      "Wei Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.16362",
    "title": "Neural Potential Field for Obstacle-Aware Local Motion Planning",
    "abstract": "Model predictive control (MPC) may provide local motion planning for mobile robotic platforms. The challenging aspect is the analytic representation of collision cost for the case when both the obstacle map and robot footprint are arbitrary. We propose a Neural Potential Field: a neural network model that returns a differentiable collision cost based on robot pose, obstacle map, and robot footprint. The differentiability of our model allows its usage within the MPC solver. It is computationally hard to solve problems with a very high number of parameters. Therefore, our architecture includes neural image encoders, which transform obstacle maps and robot footprints into embeddings, which reduce problem dimensionality by two orders of magnitude. The reference data for network training are generated based on algorithmic calculation of a signed distance function. Comparative experiments showed that the proposed approach is comparable with existing local planners: it provides trajectories with outperforming smoothness, comparable path length, and safe distance from obstacles. Experiment on Husky UGV mobile robot showed that our approach allows real-time and safe local planning. The code for our approach is presented at https://github.com/cog-isa/NPField together with demo video. ",
    "url": "https://arxiv.org/abs/2310.16362",
    "authors": [
      "Muhammad Alhaddad",
      "Konstantin Mironov",
      "Aleksey Staroverov",
      "Aleksandr Panov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16371",
    "title": "Synergizing Airborne Non-Terrestrial Networks and Reconfigurable  Intelligent Surfaces-Aided 6G IoT",
    "abstract": "On the one hand, Reconfigurable Intelligent Surfaces (RISs) emerge as a promising solution to meet the demand for higher data rates, improved coverage, and efficient spectrum utilization. On the other hand, Non-Terrestrial Networks (NTNs) offer unprecedented possibilities for global connectivity. Moreover, the NTN can also support the upsurge in the number of Internet of Things (IoT) devices by providing reliable and ubiquitous connectivity. Although NTNs have shown promising results, there are several challenges associated with their usage, such as signal propagation delays, interference, security, etc. In this article, we have discussed the possibilities of integrating RIS with an NTN platform to overcome the issues associated with NTN. Furthermore, through experimental validation, we have demonstrated that the RIS-assisted NTN can play a pivotal role in improving the performance of the entire communication system. ",
    "url": "https://arxiv.org/abs/2310.16371",
    "authors": [
      "Muhammad Ali Jamshed",
      "Aryan Kaushik",
      "Mesut Toka",
      "Wonjae Shin",
      "Muhammad Zeeshan Shakir",
      "Soumya P. Dash",
      "Davide Dardari"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.16375",
    "title": "DyExplainer: Explainable Dynamic Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) resurge as a trending research subject owing to their impressive ability to capture representations from graph-structured data. However, the black-box nature of GNNs presents a significant challenge in terms of comprehending and trusting these models, thereby limiting their practical applications in mission-critical scenarios. Although there has been substantial progress in the field of explaining GNNs in recent years, the majority of these studies are centered on static graphs, leaving the explanation of dynamic GNNs largely unexplored. Dynamic GNNs, with their ever-evolving graph structures, pose a unique challenge and require additional efforts to effectively capture temporal dependencies and structural relationships. To address this challenge, we present DyExplainer, a novel approach to explaining dynamic GNNs on the fly. DyExplainer trains a dynamic GNN backbone to extract representations of the graph at each snapshot, while simultaneously exploring structural relationships and temporal dependencies through a sparse attention technique. To preserve the desired properties of the explanation, such as structural consistency and temporal continuity, we augment our approach with contrastive learning techniques to provide priori-guided regularization. To model longer-term temporal dependencies, we develop a buffer-based live-updating scheme for training. The results of our extensive experiments on various datasets demonstrate the superiority of DyExplainer, not only providing faithful explainability of the model predictions but also significantly improving the model prediction accuracy, as evidenced in the link prediction task. ",
    "url": "https://arxiv.org/abs/2310.16375",
    "authors": [
      "Tianchun Wang",
      "Dongsheng Luo",
      "Wei Cheng",
      "Haifeng Chen",
      "Xiang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16376",
    "title": "GADY: Unsupervised Anomaly Detection on Dynamic Graphs",
    "abstract": "Anomaly detection on dynamic graphs refers to detecting entities whose behaviors obviously deviate from the norms observed within graphs and their temporal information. This field has drawn increasing attention due to its application in finance, network security, social networks, and more. However, existing methods face two challenges: dynamic structure constructing challenge - difficulties in capturing graph structure with complex time information and negative sampling challenge - unable to construct excellent negative samples for unsupervised learning. To address these challenges, we propose Unsupervised Generative Anomaly Detection on Dynamic Graphs (GADY). To tackle the first challenge, we propose a continuous dynamic graph model to capture the fine-grained information, which breaks the limit of existing discrete methods. Specifically, we employ a message-passing framework combined with positional features to get edge embeddings, which are decoded to identify anomalies. For the second challenge, we pioneer the use of Generative Adversarial Networks to generate negative interactions. Moreover, we design a loss function to alter the training goal of the generator while ensuring the diversity and quality of generated samples. Extensive experiments demonstrate that our proposed GADY significantly outperforms the previous state-of-the-art method on three real-world datasets. Supplementary experiments further validate the effectiveness of our model design and the necessity of each module. ",
    "url": "https://arxiv.org/abs/2310.16376",
    "authors": [
      "Shiqi Lou",
      "Qingyue Zhang",
      "Shujie Yang",
      "Yuyang Tian",
      "Zhaoxuan Tan",
      "Minnan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.16380",
    "title": "A model for multi-attack classification to improve intrusion detection  performance using deep learning approaches",
    "abstract": "This proposed model introduces novel deep learning methodologies. The objective here is to create a reliable intrusion detection mechanism to help identify malicious attacks. Deep learning based solution framework is developed consisting of three approaches. The first approach is Long-Short Term Memory Recurrent Neural Network (LSTM-RNN) with seven optimizer functions such as adamax, SGD, adagrad, adam, RMSprop, nadam and adadelta. The model is evaluated on NSL-KDD dataset and classified multi attack classification. The model has outperformed with adamax optimizer in terms of accuracy, detection rate and low false alarm rate. The results of LSTM-RNN with adamax optimizer is compared with existing shallow machine and deep learning models in terms of accuracy, detection rate and low false alarm rate. The multi model methodology consisting of Recurrent Neural Network (RNN), Long-Short Term Memory Recurrent Neural Network (LSTM-RNN), and Deep Neural Network (DNN). The multi models are evaluated on bench mark datasets such as KDD99, NSL-KDD, and UNSWNB15 datasets. The models self-learnt the features and classifies the attack classes as multi-attack classification. The models RNN, and LSTM-RNN provide considerable performance compared to other existing methods on KDD99 and NSL-KDD dataset ",
    "url": "https://arxiv.org/abs/2310.16380",
    "authors": [
      "Arun Kumar Silivery",
      "Ram Mohan Rao Kovvur"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16389",
    "title": "MVFAN: Multi-View Feature Assisted Network for 4D Radar Object Detection",
    "abstract": "4D radar is recognized for its resilience and cost-effectiveness under adverse weather conditions, thus playing a pivotal role in autonomous driving. While cameras and LiDAR are typically the primary sensors used in perception modules for autonomous vehicles, radar serves as a valuable supplementary sensor. Unlike LiDAR and cameras, radar remains unimpaired by harsh weather conditions, thereby offering a dependable alternative in challenging environments. Developing radar-based 3D object detection not only augments the competency of autonomous vehicles but also provides economic benefits. In response, we propose the Multi-View Feature Assisted Network (\\textit{MVFAN}), an end-to-end, anchor-free, and single-stage framework for 4D-radar-based 3D object detection for autonomous vehicles. We tackle the issue of insufficient feature utilization by introducing a novel Position Map Generation module to enhance feature learning by reweighing foreground and background points, and their features, considering the irregular distribution of radar point clouds. Additionally, we propose a pioneering backbone, the Radar Feature Assisted backbone, explicitly crafted to fully exploit the valuable Doppler velocity and reflectivity data provided by the 4D radar sensor. Comprehensive experiments and ablation studies carried out on Astyx and VoD datasets attest to the efficacy of our framework. The incorporation of Doppler velocity and RCS reflectivity dramatically improves the detection performance for small moving objects such as pedestrians and cyclists. Consequently, our approach culminates in a highly optimized 4D-radar-based 3D object detection capability for autonomous driving systems, setting a new standard in the field. ",
    "url": "https://arxiv.org/abs/2310.16389",
    "authors": [
      "Qiao Yan",
      "Yihan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16397",
    "title": "Learning Efficient Surrogate Dynamic Models with Graph Spline Networks",
    "abstract": "While complex simulations of physical systems have been widely used in engineering and scientific computing, lowering their often prohibitive computational requirements has only recently been tackled by deep learning approaches. In this paper, we present GraphSplineNets, a novel deep-learning method to speed up the forecasting of physical systems by reducing the grid size and number of iteration steps of deep surrogate models. Our method uses two differentiable orthogonal spline collocation methods to efficiently predict response at any location in time and space. Additionally, we introduce an adaptive collocation strategy in space to prioritize sampling from the most important regions. GraphSplineNets improve the accuracy-speedup tradeoff in forecasting various dynamical systems with increasing complexity, including the heat equation, damped wave propagation, Navier-Stokes equations, and real-world ocean currents in both regular and irregular domains. ",
    "url": "https://arxiv.org/abs/2310.16397",
    "authors": [
      "Chuanbo Hua",
      "Federico Berto",
      "Michael Poli",
      "Stefano Massaroli",
      "Jinkyoo Park"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16401",
    "title": "Graph Neural Networks with a Distribution of Parametrized Graphs",
    "abstract": "Traditionally, graph neural networks have been trained using a single observed graph. However, the observed graph represents only one possible realization. In many applications, the graph may encounter uncertainties, such as having erroneous or missing edges, as well as edge weights that provide little informative value. To address these challenges and capture additional information previously absent in the observed graph, we introduce latent variables to parameterize and generate multiple graphs. We obtain the maximum likelihood estimate of the network parameters in an Expectation-Maximization (EM) framework based on the multiple graphs. Specifically, we iteratively determine the distribution of the graphs using a Markov Chain Monte Carlo (MCMC) method, incorporating the principles of PAC-Bayesian theory. Numerical experiments demonstrate improvements in performance against baseline models on node classification for heterogeneous graphs and graph regression on chemistry datasets. ",
    "url": "https://arxiv.org/abs/2310.16401",
    "authors": [
      "See Hian Lee",
      "Feng Ji",
      "Kelin Xia",
      "Wee Peng Tay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16407",
    "title": "Information-Theoretic Generalization Analysis for Topology-aware  Heterogeneous Federated Edge Learning over Noisy Channels",
    "abstract": "With the rapid growth of edge intelligence, the deployment of federated learning (FL) over wireless networks has garnered increasing attention, which is called Federated Edge Learning (FEEL). In FEEL, both mobile devices transmitting model parameters over noisy channels and collecting data in diverse environments pose challenges to the generalization of trained models. Moreover, devices can engage in decentralized FL via Device-to-Device communication while the communication topology of connected devices also impacts the generalization of models. Most recent theoretical studies overlook the incorporation of all these effects into FEEL when developing generalization analyses. In contrast, our work presents an information-theoretic generalization analysis for topology-aware FEEL in the presence of data heterogeneity and noisy channels. Additionally, we propose a novel regularization method called Federated Global Mutual Information Reduction (FedGMIR) to enhance the performance of models based on our analysis. Numerical results validate our theoretical findings and provide evidence for the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2310.16407",
    "authors": [
      "Zheshun Wu",
      "Zenglin Xu",
      "Hongfang Yu",
      "Jie Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16421",
    "title": "Graph Agent: Explicit Reasoning Agent for Graphs",
    "abstract": "Graph embedding methods such as Graph Neural Networks (GNNs) and Graph Transformers have contributed to the development of graph reasoning algorithms for various tasks on knowledge graphs. However, the lack of interpretability and explainability of graph embedding methods has limited their applicability in scenarios requiring explicit reasoning. In this paper, we introduce the Graph Agent (GA), an intelligent agent methodology of leveraging large language models (LLMs), inductive-deductive reasoning modules, and long-term memory for knowledge graph reasoning tasks. GA integrates aspects of symbolic reasoning and existing graph embedding methods to provide an innovative approach for complex graph reasoning tasks. By converting graph structures into textual data, GA enables LLMs to process, reason, and provide predictions alongside human-interpretable explanations. The effectiveness of the GA was evaluated on node classification and link prediction tasks. Results showed that GA reached state-of-the-art performance, demonstrating accuracy of 90.65%, 95.48%, and 89.32% on Cora, PubMed, and PrimeKG datasets, respectively. Compared to existing GNN and transformer models, GA offered advantages of explicit reasoning ability, free-of-training, easy adaption to various graph reasoning tasks ",
    "url": "https://arxiv.org/abs/2310.16421",
    "authors": [
      "Qinyong Wang",
      "Zhenxiang Gao",
      "Rong Xu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.16435",
    "title": "On Pixel-level Performance Assessment in Anomaly Detection",
    "abstract": "Anomaly detection methods have demonstrated remarkable success across various applications. However, assessing their performance, particularly at the pixel-level, presents a complex challenge due to the severe imbalance that is most commonly present between normal and abnormal samples. Commonly adopted evaluation metrics designed for pixel-level detection may not effectively capture the nuanced performance variations arising from this class imbalance. In this paper, we dissect the intricacies of this challenge, underscored by visual evidence and statistical analysis, leading to delve into the need for evaluation metrics that account for the imbalance. We offer insights into more accurate metrics, using eleven leading contemporary anomaly detection methods on twenty-one anomaly detection problems. Overall, from this extensive experimental evaluation, we can conclude that Precision-Recall-based metrics can better capture relative method performance, making them more suitable for the task. ",
    "url": "https://arxiv.org/abs/2310.16435",
    "authors": [
      "Mehdi Rafiei",
      "Toby P. Breckon",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16452",
    "title": "Faithful Path Language Modelling for Explainable Recommendation over  Knowledge Graph",
    "abstract": "Path reasoning methods over knowledge graphs have gained popularity for their potential to improve transparency in recommender systems. However, the resulting models still rely on pre-trained knowledge graph embeddings, fail to fully exploit the interdependence between entities and relations in the KG for recommendation, and may generate inaccurate explanations. In this paper, we introduce PEARLM, a novel approach that efficiently captures user behaviour and product-side knowledge through language modelling. With our approach, knowledge graph embeddings are directly learned from paths over the KG by the language model, which also unifies entities and relations in the same optimisation space. Constraints on the sequence decoding additionally guarantee path faithfulness with respect to the KG. Experiments on two datasets show the effectiveness of our approach compared to state-of-the-art baselines. Source code and datasets: AVAILABLE AFTER GETTING ACCEPTED. ",
    "url": "https://arxiv.org/abs/2310.16452",
    "authors": [
      "Giacomo Balloccu",
      "Ludovico Boratto",
      "Christian Cancedda",
      "Gianni Fenu",
      "Mirko Marras"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16453",
    "title": "ClearMark: Intuitive and Robust Model Watermarking via Transposed Model  Training",
    "abstract": "Due to costly efforts during data acquisition and model training, Deep Neural Networks (DNNs) belong to the intellectual property of the model creator. Hence, unauthorized use, theft, or modification may lead to legal repercussions. Existing DNN watermarking methods for ownership proof are often non-intuitive, embed human-invisible marks, require trust in algorithmic assessment that lacks human-understandable attributes, and rely on rigid thresholds, making it susceptible to failure in cases of partial watermark erasure. This paper introduces ClearMark, the first DNN watermarking method designed for intuitive human assessment. ClearMark embeds visible watermarks, enabling human decision-making without rigid value thresholds while allowing technology-assisted evaluations. ClearMark defines a transposed model architecture allowing to use of the model in a backward fashion to interwove the watermark with the main task within all model parameters. Compared to existing watermarking methods, ClearMark produces visual watermarks that are easy for humans to understand without requiring complex verification algorithms or strict thresholds. The watermark is embedded within all model parameters and entangled with the main task, exhibiting superior robustness. It shows an 8,544-bit watermark capacity comparable to the strongest existing work. Crucially, ClearMark's effectiveness is model and dataset-agnostic, and resilient against adversarial model manipulations, as demonstrated in a comprehensive study performed with four datasets and seven architectures. ",
    "url": "https://arxiv.org/abs/2310.16453",
    "authors": [
      "Torsten Krau\u00df",
      "Jasper Stang",
      "Alexandra Dmitrienko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16459",
    "title": "DualMatch: Robust Semi-Supervised Learning with Dual-Level Interaction",
    "abstract": "Semi-supervised learning provides an expressive framework for exploiting unlabeled data when labels are insufficient. Previous semi-supervised learning methods typically match model predictions of different data-augmented views in a single-level interaction manner, which highly relies on the quality of pseudo-labels and results in semi-supervised learning not robust. In this paper, we propose a novel SSL method called DualMatch, in which the class prediction jointly invokes feature embedding in a dual-level interaction manner. DualMatch requires consistent regularizations for data augmentation, specifically, 1) ensuring that different augmented views are regulated with consistent class predictions, and 2) ensuring that different data of one class are regulated with similar feature embeddings. Extensive experiments demonstrate the effectiveness of DualMatch. In the standard SSL setting, the proposal achieves 9% error reduction compared with SOTA methods, even in a more challenging class-imbalanced setting, the proposal can still achieve 6% error reduction. Code is available at https://github.com/CWangAI/DualMatch ",
    "url": "https://arxiv.org/abs/2310.16459",
    "authors": [
      "Cong Wang",
      "Xiaofeng Cao",
      "Lanzhe Guo2",
      "Zenglin Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16466",
    "title": "Learning Continuous Network Emerging Dynamics from Scarce Observations  via Data-Adaptive Stochastic Processes",
    "abstract": "Learning network dynamics from the empirical structure and spatio-temporal observation data is crucial to revealing the interaction mechanisms of complex networks in a wide range of domains. However, most existing methods only aim at learning network dynamic behaviors generated by a specific ordinary differential equation instance, resulting in ineffectiveness for new ones, and generally require dense observations. The observed data, especially from network emerging dynamics, are usually difficult to obtain, which brings trouble to model learning. Therefore, how to learn accurate network dynamics with sparse, irregularly-sampled, partial, and noisy observations remains a fundamental challenge. We introduce Neural ODE Processes for Network Dynamics (NDP4ND), a new class of stochastic processes governed by stochastic data-adaptive network dynamics, to overcome the challenge and learn continuous network dynamics from scarce observations. Intensive experiments conducted on various network dynamics in ecological population evolution, phototaxis movement, brain activity, epidemic spreading, and real-world empirical systems, demonstrate that the proposed method has excellent data adaptability and computational efficiency, and can adapt to unseen network emerging dynamics, producing accurate interpolation and extrapolation with reducing the ratio of required observation data to only about 6\\% and improving the learning speed for new dynamics by three orders of magnitude. ",
    "url": "https://arxiv.org/abs/2310.16466",
    "authors": [
      "Jiaxu Cui",
      "Bingyi Sun",
      "Jiming Liu",
      "Bo Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2310.16468",
    "title": "Formal Runtime Error Detection During Development in the Automotive  Industry",
    "abstract": "Modern automotive software is highly complex and consists of millions lines of code. For safety-relevant automotive software, it is recommended to use sound static program analysis to prove the absence of runtime errors. However, the analysis is often perceived as burdensome by developers because it runs for a long time and produces many false alarms. If the analysis is performed on the integrated software system, there is a scalability problem, and the analysis is only possible at a late stage of development. If the analysis is performed on individual modules instead, this is possible at an early stage of development, but the usage context of modules is missing, which leads to too many false alarms. In this case study, we present how automatically inferred contracts add context to module-level analysis. Leveraging these contracts with an off-the-shelf tool for abstract interpretation makes module-level analysis more precise and more scalable. We evaluate this framework quantitatively on industrial case studies from different automotive domains. Additionally, we report on our qualitative experience for the verification of large-scale embedded software projects. ",
    "url": "https://arxiv.org/abs/2310.16468",
    "authors": [
      "Jesko Hecking-Harbusch",
      "Jochen Quante",
      "Maximilian Schlund"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.16473",
    "title": "Symphony of experts: orchestration with adversarial insights in  reinforcement learning",
    "abstract": "Structured reinforcement learning leverages policies with advantageous properties to reach better performance, particularly in scenarios where exploration poses challenges. We explore this field through the concept of orchestration, where a (small) set of expert policies guides decision-making; the modeling thereof constitutes our first contribution. We then establish value-functions regret bounds for orchestration in the tabular setting by transferring regret-bound results from adversarial settings. We generalize and extend the analysis of natural policy gradient in Agarwal et al. [2021, Section 5.3] to arbitrary adversarial aggregation strategies. We also extend it to the case of estimated advantage functions, providing insights into sample complexity both in expectation and high probability. A key point of our approach lies in its arguably more transparent proofs compared to existing methods. Finally, we present simulations for a stochastic matching toy model. ",
    "url": "https://arxiv.org/abs/2310.16473",
    "authors": [
      "Matthieu Jonckheere",
      "Chiara Mignacco",
      "Gilles Stoltz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.16475",
    "title": "Efficient Serverless Function Scheduling at the Network Edge",
    "abstract": "Serverless computing is a promising approach for edge computing since its inherent features, e.g., lightweight virtualization, rapid scalability, and economic efficiency. However, previous studies have not studied well the issues of significant cold start latency and highly dynamic workloads in serverless function scheduling, which are exacerbated at the resource-limited network edge. In this paper, we formulate the Serverless Function Scheduling (SFS) problem for resource-limited edge computing, aiming to minimize the average response time. To efficiently solve this intractable scheduling problem, we first consider a simplified offline form of the problem and design a polynomial-time optimal scheduling algorithm based on each function's weight. Furthermore, we propose an Enhanced Shortest Function First (ESFF) algorithm, in which the function weight represents the scheduling urgency. To avoid frequent cold starts, ESFF selectively decides the initialization of new function instances when receiving requests. To deal with dynamic workloads, ESFF judiciously replaces serverless functions based on the function weight at the completion time of requests. Extensive simulations based on real-world serverless request traces are conducted, and the results show that ESFF consistently and substantially outperforms existing baselines under different settings. ",
    "url": "https://arxiv.org/abs/2310.16475",
    "authors": [
      "Lou Jiong",
      "Tang Zhiqing",
      "Yuan Shijing",
      "Li Jie",
      "Chengtao Wu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.16485",
    "title": "A Comprehensive Python Library for Deep Learning-Based Event Detection  in Multivariate Time Series Data and Information Retrieval in NLP",
    "abstract": "Event detection in time series data is crucial in various domains, including finance, healthcare, cybersecurity, and science. Accurately identifying events in time series data is vital for making informed decisions, detecting anomalies, and predicting future trends. Despite extensive research exploring diverse methods for event detection in time series, with deep learning approaches being among the most advanced, there is still room for improvement and innovation in this field. In this paper, we present a new deep learning supervised method for detecting events in multivariate time series data. Our method combines four distinct novelties compared to existing deep-learning supervised methods. Firstly, it is based on regression instead of binary classification. Secondly, it does not require labeled datasets where each point is labeled; instead, it only requires reference events defined as time points or intervals of time. Thirdly, it is designed to be robust by using a stacked ensemble learning meta-model that combines deep learning models, ranging from classic feed-forward neural networks (FFNs) to state-of-the-art architectures like transformers. This ensemble approach can mitigate individual model weaknesses and biases, resulting in more robust predictions. Finally, to facilitate practical implementation, we have developed a Python package to accompany our proposed method. The package, called eventdetector-ts, can be installed through the Python Package Index (PyPI). In this paper, we present our method and provide a comprehensive guide on the usage of the package. We showcase its versatility and effectiveness through different real-world use cases from natural language processing (NLP) to financial security domains. ",
    "url": "https://arxiv.org/abs/2310.16485",
    "authors": [
      "Menouar Azib",
      "Benjamin Renard",
      "Philippe Garnier",
      "Vincent G\u00e9not",
      "Nicolas Andr\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16491",
    "title": "TSONN: Time-stepping-oriented neural network for solving partial  differential equations",
    "abstract": "Deep neural networks (DNNs), especially physics-informed neural networks (PINNs), have recently become a new popular method for solving forward and inverse problems governed by partial differential equations (PDEs). However, these methods still face challenges in achieving stable training and obtaining correct results in many problems, since minimizing PDE residuals with PDE-based soft constraint make the problem ill-conditioned. Different from all existing methods that directly minimize PDE residuals, this work integrates time-stepping method with deep learning, and transforms the original ill-conditioned optimization problem into a series of well-conditioned sub-problems over given pseudo time intervals. The convergence of model training is significantly improved by following the trajectory of the pseudo time-stepping process, yielding a robust optimization-based PDE solver. Our results show that the proposed method achieves stable training and correct results in many problems that standard PINNs fail to solve, requiring only a simple modification on the loss function. In addition, we demonstrate several novel properties and advantages of time-stepping methods within the framework of neural network-based optimization approach, in comparison to traditional grid-based numerical method. Specifically, explicit scheme allows significantly larger time step, while implicit scheme can be implemented as straightforwardly as explicit scheme. ",
    "url": "https://arxiv.org/abs/2310.16491",
    "authors": [
      "Wenbo Cao",
      "Weiwei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2310.16492",
    "title": "On the Powerfulness of Textual Outlier Exposure for Visual OoD Detection",
    "abstract": "Successful detection of Out-of-Distribution (OoD) data is becoming increasingly important to ensure safe deployment of neural networks. One of the main challenges in OoD detection is that neural networks output overconfident predictions on OoD data, make it difficult to determine OoD-ness of data solely based on their predictions. Outlier exposure addresses this issue by introducing an additional loss that encourages low-confidence predictions on OoD data during training. While outlier exposure has shown promising potential in improving OoD detection performance, all previous studies on outlier exposure have been limited to utilizing visual outliers. Drawing inspiration from the recent advancements in vision-language pre-training, this paper venture out to the uncharted territory of textual outlier exposure. First, we uncover the benefits of using textual outliers by replacing real or virtual outliers in the image-domain with textual equivalents. Then, we propose various ways of generating preferable textual outliers. Our extensive experiments demonstrate that generated textual outliers achieve competitive performance on large-scale OoD and hard OoD benchmarks. Furthermore, we conduct empirical analyses of textual outliers to provide primary criteria for designing advantageous textual outliers: near-distribution, descriptiveness, and inclusion of visual semantics. ",
    "url": "https://arxiv.org/abs/2310.16492",
    "authors": [
      "Sangha Park",
      "Jisoo Mok",
      "Dahuin Jung",
      "Saehyung Lee",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16494",
    "title": "Lang3DSG: Language-based contrastive pre-training for 3D Scene Graph  prediction",
    "abstract": "D scene graphs are an emerging 3D scene representation, that models both the objects present in the scene as well as their relationships. However, learning 3D scene graphs is a challenging task because it requires not only object labels but also relationship annotations, which are very scarce in datasets. While it is widely accepted that pre-training is an effective approach to improve model performance in low data regimes, in this paper, we find that existing pre-training methods are ill-suited for 3D scene graphs. To solve this issue, we present the first language-based pre-training approach for 3D scene graphs, whereby we exploit the strong relationship between scene graphs and language. To this end, we leverage the language encoder of CLIP, a popular vision-language model, to distill its knowledge into our graph-based network. We formulate a contrastive pre-training, which aligns text embeddings of relationships (subject-predicate-object triplets) and predicted 3D graph features. Our method achieves state-of-the-art results on the main semantic 3D scene graph benchmark by showing improved effectiveness over pre-training baselines and outperforming all the existing fully supervised scene graph prediction methods by a significant margin. Furthermore, since our scene graph features are language-aligned, it allows us to query the language space of the features in a zero-shot manner. In this paper, we show an example of utilizing this property of the features to predict the room type of a scene without further training. ",
    "url": "https://arxiv.org/abs/2310.16494",
    "authors": [
      "Sebastian Koch",
      "Pedro Hermosilla",
      "Narunas Vaskevicius",
      "Mirco Colosi",
      "Timo Ropinski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16520",
    "title": "Towards Self-Interpretable Graph-Level Anomaly Detection",
    "abstract": "Graph-level anomaly detection (GLAD) aims to identify graphs that exhibit notable dissimilarity compared to the majority in a collection. However, current works primarily focus on evaluating graph-level abnormality while failing to provide meaningful explanations for the predictions, which largely limits their reliability and application scope. In this paper, we investigate a new challenging problem, explainable GLAD, where the learning objective is to predict the abnormality of each graph sample with corresponding explanations, i.e., the vital subgraph that leads to the predictions. To address this challenging problem, we propose a Self-Interpretable Graph aNomaly dETection model (SIGNET for short) that detects anomalous graphs as well as generates informative explanations simultaneously. Specifically, we first introduce the multi-view subgraph information bottleneck (MSIB) framework, serving as the design basis of our self-interpretable GLAD approach. This way SIGNET is able to not only measure the abnormality of each graph based on cross-view mutual information but also provide informative graph rationales by extracting bottleneck subgraphs from the input graph and its dual hypergraph in a self-supervised way. Extensive experiments on 16 datasets demonstrate the anomaly detection capability and self-interpretability of SIGNET. ",
    "url": "https://arxiv.org/abs/2310.16520",
    "authors": [
      "Yixin Liu",
      "Kaize Ding",
      "Qinghua Lu",
      "Fuyi Li",
      "Leo Yu Zhang",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16523",
    "title": "Improving Diversity of Demographic Representation in Large Language  Models via Collective-Critiques and Self-Voting",
    "abstract": "A crucial challenge for generative large language models (LLMs) is diversity: when a user's prompt is under-specified, models may follow implicit assumptions while generating a response, which may result in homogenization of the responses, as well as certain demographic groups being under-represented or even erased from the generated responses. In this paper, we formalize diversity of representation in generative LLMs. We present evaluation datasets and propose metrics to measure diversity in generated responses along people and culture axes. We find that LLMs understand the notion of diversity, and that they can reason and critique their own responses for that goal. This finding motivated a new prompting technique called collective-critique and self-voting (CCSV) to self-improve people diversity of LLMs by tapping into its diversity reasoning capabilities, without relying on handcrafted examples or prompt tuning. Extensive empirical experiments with both human and automated evaluations show that our proposed approach is effective at improving people and culture diversity, and outperforms all baseline methods by a large margin. ",
    "url": "https://arxiv.org/abs/2310.16523",
    "authors": [
      "Preethi Lahoti",
      "Nicholas Blumm",
      "Xiao Ma",
      "Raghavendra Kotikalapudi",
      "Sahitya Potluri",
      "Qijun Tan",
      "Hansa Srinivasan",
      "Ben Packer",
      "Ahmad Beirami",
      "Alex Beutel",
      "Jilin Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.16527",
    "title": "Enhancing Document Information Analysis with Multi-Task Pre-training: A  Robust Approach for Information Extraction in Visually-Rich Documents",
    "abstract": "This paper introduces a deep learning model tailored for document information analysis, emphasizing document classification, entity relation extraction, and document visual question answering. The proposed model leverages transformer-based models to encode all the information present in a document image, including textual, visual, and layout information. The model is pre-trained and subsequently fine-tuned for various document image analysis tasks. The proposed model incorporates three additional tasks during the pre-training phase, including reading order identification of different layout segments in a document image, layout segments categorization as per PubLayNet, and generation of the text sequence within a given layout segment (text block). The model also incorporates a collective pre-training scheme where losses of all the tasks under consideration, including pre-training and fine-tuning tasks with all datasets, are considered. Additional encoder and decoder blocks are added to the RoBERTa network to generate results for all tasks. The proposed model achieved impressive results across all tasks, with an accuracy of 95.87% on the RVL-CDIP dataset for document classification, F1 scores of 0.9306, 0.9804, 0.9794, and 0.8742 on the FUNSD, CORD, SROIE, and Kleister-NDA datasets respectively for entity relation extraction, and an ANLS score of 0.8468 on the DocVQA dataset for visual question answering. The results highlight the effectiveness of the proposed model in understanding and interpreting complex document layouts and content, making it a promising tool for document analysis tasks. ",
    "url": "https://arxiv.org/abs/2310.16527",
    "authors": [
      "Tofik Ali",
      "Partha Pratim Roy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16530",
    "title": "Toward Practical Privacy-Preserving Convolutional Neural Networks  Exploiting Fully Homomorphic Encryption",
    "abstract": "Incorporating fully homomorphic encryption (FHE) into the inference process of a convolutional neural network (CNN) draws enormous attention as a viable approach for achieving private inference (PI). FHE allows delegating the entire computation process to the server while ensuring the confidentiality of sensitive client-side data. However, practical FHE implementation of a CNN faces significant hurdles, primarily due to FHE's substantial computational and memory overhead. To address these challenges, we propose a set of optimizations, which includes GPU/ASIC acceleration, an efficient activation function, and an optimized packing scheme. We evaluate our method using the ResNet models on the CIFAR-10 and ImageNet datasets, achieving several orders of magnitude improvement compared to prior work and reducing the latency of the encrypted CNN inference to 1.4 seconds on an NVIDIA A100 GPU. We also show that the latency drops to a mere 0.03 seconds with a custom hardware design. ",
    "url": "https://arxiv.org/abs/2310.16530",
    "authors": [
      "Jaiyoung Park",
      "Donghwan Kim",
      "Jongmin Kim",
      "Sangpyo Kim",
      "Wonkyung Jung",
      "Jung Hee Cheon",
      "Jung Ho Ahn"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2310.16532",
    "title": "Learning Robust Deep Visual Representations from EEG Brain Recordings",
    "abstract": "Decoding the human brain has been a hallmark of neuroscientists and Artificial Intelligence researchers alike. Reconstruction of visual images from brain Electroencephalography (EEG) signals has garnered a lot of interest due to its applications in brain-computer interfacing. This study proposes a two-stage method where the first step is to obtain EEG-derived features for robust learning of deep representations and subsequently utilize the learned representation for image generation and classification. We demonstrate the generalizability of our feature extraction pipeline across three different datasets using deep-learning architectures with supervised and contrastive learning methods. We have performed the zero-shot EEG classification task to support the generalizability claim further. We observed that a subject invariant linearly separable visual representation was learned using EEG data alone in an unimodal setting that gives better k-means accuracy as compared to a joint representation learning between EEG and images. Finally, we propose a novel framework to transform unseen images into the EEG space and reconstruct them with approximation, showcasing the potential for image reconstruction from EEG signals. Our proposed image synthesis method from EEG shows 62.9% and 36.13% inception score improvement on the EEGCVPR40 and the Thoughtviz datasets, which is better than state-of-the-art performance in GAN. ",
    "url": "https://arxiv.org/abs/2310.16532",
    "authors": [
      "Prajwal Singh",
      "Dwip Dalal",
      "Gautam Vashishtha",
      "Krishna Miyapuram",
      "Shanmuganathan Raman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16540",
    "title": "Dual Defense: Adversarial, Traceable, and Invisible Robust Watermarking  against Face Swapping",
    "abstract": "The malicious applications of deep forgery, represented by face swapping, have introduced security threats such as misinformation dissemination and identity fraud. While some research has proposed the use of robust watermarking methods to trace the copyright of facial images for post-event traceability, these methods cannot effectively prevent the generation of forgeries at the source and curb their dissemination. To address this problem, we propose a novel comprehensive active defense mechanism that combines traceability and adversariality, called Dual Defense. Dual Defense invisibly embeds a single robust watermark within the target face to actively respond to sudden cases of malicious face swapping. It disrupts the output of the face swapping model while maintaining the integrity of watermark information throughout the entire dissemination process. This allows for watermark extraction at any stage of image tracking for traceability. Specifically, we introduce a watermark embedding network based on original-domain feature impersonation attack. This network learns robust adversarial features of target facial images and embeds watermarks, seeking a well-balanced trade-off between watermark invisibility, adversariality, and traceability through perceptual adversarial encoding strategies. Extensive experiments demonstrate that Dual Defense achieves optimal overall defense success rates and exhibits promising universality in anti-face swapping tasks and dataset generalization ability. It maintains impressive adversariality and traceability in both original and robust settings, surpassing current forgery defense methods that possess only one of these capabilities, including CMUA-Watermark, Anti-Forgery, FakeTagger, or PGD methods. ",
    "url": "https://arxiv.org/abs/2310.16540",
    "authors": [
      "Yunming Zhang",
      "Dengpan Ye",
      "Caiyun Xie",
      "Long Tang",
      "Chuanxi Chen",
      "Ziyi Liu",
      "Jiacheng Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16550",
    "title": "Dynamic Processing Neural Network Architecture For Hearing Loss  Compensation",
    "abstract": "This paper proposes neural networks for compensating sensorineural hearing loss. The aim of the hearing loss compensation task is to transform a speech signal to increase speech intelligibility after further processing by a person with a hearing impairment, which is modeled by a hearing loss model. We propose an interpretable model called dynamic processing network, which has a structure similar to band-wise dynamic compressor. The network is differentiable, and therefore allows to learn its parameters to maximize speech intelligibility. More generic models based on convolutional layers were tested as well. The performance of the tested architectures was assessed using spectro-temporal objective index (STOI) with hearing-threshold noise and hearing aid speech intelligibility (HASPI) metrics. The dynamic processing network gave a significant improvement of STOI and HASPI in comparison to popular compressive gain prescription rule Camfit. A large enough convolutional network could outperform the interpretable model with the cost of larger computational load. Finally, a combination of the dynamic processing network with convolutional neural network gave the best results in terms of STOI and HASPI. ",
    "url": "https://arxiv.org/abs/2310.16550",
    "authors": [
      "Szymon Drgas",
      "Lars Bramsl\u00f8w",
      "Archontis Politis",
      "Gaurav Naithani",
      "Tuomas Virtanen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.16560",
    "title": "Label Propagation for Graph Label Noise",
    "abstract": "Label noise is a common challenge in large datasets, as it can significantly degrade the generalization ability of deep neural networks. Most existing studies focus on noisy labels in computer vision; however, graph models encompass both node features and graph topology as input, and become more susceptible to label noise through message-passing mechanisms. Recently, only a few works have been proposed to tackle the label noise on graphs. One major limitation is that they assume the graph is homophilous and the labels are smoothly distributed. Nevertheless, real-world graphs may contain varying degrees of heterophily or even be heterophily-dominated, leading to the inadequacy of current methods. In this paper, we study graph label noise in the context of arbitrary heterophily, with the aim of rectifying noisy labels and assigning labels to previously unlabeled nodes. We begin by conducting two empirical analyses to explore the impact of graph homophily on graph label noise. Following observations, we propose a simple yet efficient algorithm, denoted as LP4GLN. Specifically, LP4GLN is an iterative algorithm with three steps: (1) reconstruct the graph to recover the homophily property, (2) utilize label propagation to rectify the noisy labels, (3) select high-confidence labels to retain for the next iteration. By iterating these steps, we obtain a set of correct labels, ultimately achieving high accuracy in the node classification task. The theoretical analysis is also provided to demonstrate its remarkable denoising \"effect\". Finally, we conduct experiments on 10 benchmark datasets under varying graph heterophily levels and noise types, comparing the performance of LP4GLN with 7 typical baselines. Our results illustrate the superior performance of the proposed LP4GLN. ",
    "url": "https://arxiv.org/abs/2310.16560",
    "authors": [
      "Yao Cheng",
      "Caihua Shan",
      "Yifei Shen",
      "Xiang Li",
      "Siqiang Luo",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.16569",
    "title": "Flow-Attention-based Spatio-Temporal Aggregation Network for 3D Mask  Detection",
    "abstract": "Anti-spoofing detection has become a necessity for face recognition systems due to the security threat posed by spoofing attacks. Despite great success in traditional attacks, most deep-learning-based methods perform poorly in 3D masks, which can highly simulate real faces in appearance and structure, suffering generalizability insufficiency while focusing only on the spatial domain with single frame input. This has been mitigated by the recent introduction of a biomedical technology called rPPG (remote photoplethysmography). However, rPPG-based methods are sensitive to noisy interference and require at least one second (> 25 frames) of observation time, which induces high computational overhead. To address these challenges, we propose a novel 3D mask detection framework, called FASTEN (Flow-Attention-based Spatio-Temporal aggrEgation Network). We tailor the network for focusing more on fine-grained details in large movements, which can eliminate redundant spatio-temporal feature interference and quickly capture splicing traces of 3D masks in fewer frames. Our proposed network contains three key modules: 1) a facial optical flow network to obtain non-RGB inter-frame flow information; 2) flow attention to assign different significance to each frame; 3) spatio-temporal aggregation to aggregate high-level spatial features and temporal transition features. Through extensive experiments, FASTEN only requires five frames of input and outperforms eight competitors for both intra-dataset and cross-dataset evaluations in terms of multiple detection metrics. Moreover, FASTEN has been deployed in real-world mobile devices for practical 3D mask detection. ",
    "url": "https://arxiv.org/abs/2310.16569",
    "authors": [
      "Yuxin Cao",
      "Yian Li",
      "Yumeng Zhu",
      "Derui Wang",
      "Minhui Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.16579",
    "title": "WSDMS: Debunk Fake News via Weakly Supervised Detection of Misinforming  Sentences with Contextualized Social Wisdom",
    "abstract": "In recent years, we witness the explosion of false and unconfirmed information (i.e., rumors) that went viral on social media and shocked the public. Rumors can trigger versatile, mostly controversial stance expressions among social media users. Rumor verification and stance detection are different yet relevant tasks. Fake news debunking primarily focuses on determining the truthfulness of news articles, which oversimplifies the issue as fake news often combines elements of both truth and falsehood. Thus, it becomes crucial to identify specific instances of misinformation within the articles. In this research, we investigate a novel task in the field of fake news debunking, which involves detecting sentence-level misinformation. One of the major challenges in this task is the absence of a training dataset with sentence-level annotations regarding veracity. Inspired by the Multiple Instance Learning (MIL) approach, we propose a model called Weakly Supervised Detection of Misinforming Sentences (WSDMS). This model only requires bag-level labels for training but is capable of inferring both sentence-level misinformation and article-level veracity, aided by relevant social media conversations that are attentively contextualized with news sentences. We evaluate WSDMS on three real-world benchmarks and demonstrate that it outperforms existing state-of-the-art baselines in debunking fake news at both the sentence and article levels. ",
    "url": "https://arxiv.org/abs/2310.16579",
    "authors": [
      "Ruichao Yang",
      "Wei Gao",
      "Jing Ma",
      "Hongzhan Lin",
      "Zhiwei Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.16602",
    "title": "Parcel loss prediction in last-mile delivery: deep and non-deep  approaches with insights from Explainable AI",
    "abstract": "Within the domain of e-commerce retail, an important objective is the reduction of parcel loss during the last-mile delivery phase. The ever-increasing availability of data, including product, customer, and order information, has made it possible for the application of machine learning in parcel loss prediction. However, a significant challenge arises from the inherent imbalance in the data, i.e., only a very low percentage of parcels are lost. In this paper, we propose two machine learning approaches, namely, Data Balance with Supervised Learning (DBSL) and Deep Hybrid Ensemble Learning (DHEL), to accurately predict parcel loss. The practical implication of such predictions is their value in aiding e-commerce retailers in optimizing insurance-related decision-making policies. We conduct a comprehensive evaluation of the proposed machine learning models using one year data from Belgian shipments. The findings show that the DHEL model, which combines a feed-forward autoencoder with a random forest, achieves the highest classification performance. Furthermore, we use the techniques from Explainable AI (XAI) to illustrate how prediction models can be used in enhancing business processes and augmenting the overall value proposition for e-commerce retailers in the last mile delivery. ",
    "url": "https://arxiv.org/abs/2310.16602",
    "authors": [
      "Jan de Leeuw",
      "Zaharah Bukhsh",
      "Yingqian Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16605",
    "title": "Distributionally Robust Unsupervised Dense Retrieval Training on Web  Graphs",
    "abstract": "This paper introduces Web-DRO, an unsupervised dense retrieval model, which clusters documents based on web structures and reweights the groups during contrastive training. Specifically, we first leverage web graph links and contrastively train an embedding model for clustering anchor-document pairs. Then we use Group Distributional Robust Optimization to reweight different clusters of anchor-document pairs, which guides the model to assign more weights to the group with higher contrastive loss and pay more attention to the worst case during training. Our experiments on MS MARCO and BEIR show that our model, Web-DRO, significantly improves the retrieval effectiveness in unsupervised scenarios. A comparison of clustering techniques shows that training on the web graph combining URL information reaches optimal performance on clustering. Further analysis confirms that group weights are stable and valid, indicating consistent model preferences as well as effective up-weighting of valuable groups and down-weighting of uninformative ones. The code of this paper can be obtained from https://github.com/OpenMatch/Web-DRO. ",
    "url": "https://arxiv.org/abs/2310.16605",
    "authors": [
      "Peixuan Han",
      "Zhenghao Liu",
      "Zhiyuan Liu",
      "Chenyan Xiong"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.16609",
    "title": "Back Transcription as a Method for Evaluating Robustness of Natural  Language Understanding Models to Speech Recognition Errors",
    "abstract": "In a spoken dialogue system, an NLU model is preceded by a speech recognition system that can deteriorate the performance of natural language understanding. This paper proposes a method for investigating the impact of speech recognition errors on the performance of natural language understanding models. The proposed method combines the back transcription procedure with a fine-grained technique for categorizing the errors that affect the performance of NLU models. The method relies on the usage of synthesized speech for NLU evaluation. We show that the use of synthesized speech in place of audio recording does not change the outcomes of the presented technique in a significant way. ",
    "url": "https://arxiv.org/abs/2310.16609",
    "authors": [
      "Marek Kubis",
      "Pawe\u0142 Sk\u00f3rzewski",
      "Marcin Sowa\u0144ski",
      "Tomasz Zi\u0119tkiewicz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.16616",
    "title": "Context Does Matter: End-to-end Panoptic Narrative Grounding with  Deformable Attention Refined Matching Network",
    "abstract": "Panoramic Narrative Grounding (PNG) is an emerging visual grounding task that aims to segment visual objects in images based on dense narrative captions. The current state-of-the-art methods first refine the representation of phrase by aggregating the most similar $k$ image pixels, and then match the refined text representations with the pixels of the image feature map to generate segmentation results. However, simply aggregating sampled image features ignores the contextual information, which can lead to phrase-to-pixel mis-match. In this paper, we propose a novel learning framework called Deformable Attention Refined Matching Network (DRMN), whose main idea is to bring deformable attention in the iterative process of feature learning to incorporate essential context information of different scales of pixels. DRMN iteratively re-encodes pixels with the deformable attention network after updating the feature representation of the top-$k$ most similar pixels. As such, DRMN can lead to accurate yet discriminative pixel representations, purify the top-$k$ most similar pixels, and consequently alleviate the phrase-to-pixel mis-match substantially.Experimental results show that our novel design significantly improves the matching results between text phrases and image pixels. Concretely, DRMN achieves new state-of-the-art performance on the PNG benchmark with an average recall improvement 3.5%. The codes are available in: https://github.com/JaMesLiMers/DRMN. ",
    "url": "https://arxiv.org/abs/2310.16616",
    "authors": [
      "Yiming Lin",
      "Xiao-Bo Jin",
      "Qiufeng Wang",
      "Kaizhu Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.16647",
    "title": "Achieving Constraints in Neural Networks: A Stochastic Augmented  Lagrangian Approach",
    "abstract": "Regularizing Deep Neural Networks (DNNs) is essential for improving generalizability and preventing overfitting. Fixed penalty methods, though common, lack adaptability and suffer from hyperparameter sensitivity. In this paper, we propose a novel approach to DNN regularization by framing the training process as a constrained optimization problem. Where the data fidelity term is the minimization objective and the regularization terms serve as constraints. Then, we employ the Stochastic Augmented Lagrangian (SAL) method to achieve a more flexible and efficient regularization mechanism. Our approach extends beyond black-box regularization, demonstrating significant improvements in white-box models, where weights are often subject to hard constraints to ensure interpretability. Experimental results on image-based classification on MNIST, CIFAR10, and CIFAR100 datasets validate the effectiveness of our approach. SAL consistently achieves higher Accuracy while also achieving better constraint satisfaction, thus showcasing its potential for optimizing DNNs under constrained settings. ",
    "url": "https://arxiv.org/abs/2310.16647",
    "authors": [
      "Diogo Lavado",
      "Cl\u00e1udia Soares",
      "Alessandra Micheletti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2310.16652",
    "title": "How Robust is Federated Learning to Communication Error? A Comparison  Study Between Uplink and Downlink Channels",
    "abstract": "Because of its privacy-preserving capability, federated learning (FL) has attracted significant attention from both academia and industry. However, when being implemented over wireless networks, it is not clear how much communication error can be tolerated by FL. This paper investigates the robustness of FL to the uplink and downlink communication error. Our theoretical analysis reveals that the robustness depends on two critical parameters, namely the number of clients and the numerical range of model parameters. It is also shown that the uplink communication in FL can tolerate a higher bit error rate (BER) than downlink communication, and this difference is quantified by a proposed formula. The findings and theoretical analyses are further validated by extensive experiments. ",
    "url": "https://arxiv.org/abs/2310.16652",
    "authors": [
      "Linping Qu",
      "Shenghui Song",
      "Chi-Ying Tsui",
      "Yuyi Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16665",
    "title": "Robust Source-Free Domain Adaptation for Fundus Image Segmentation",
    "abstract": "Unsupervised Domain Adaptation (UDA) is a learning technique that transfers knowledge learned in the source domain from labelled training data to the target domain with only unlabelled data. It is of significant importance to medical image segmentation because of the usual lack of labelled training data. Although extensive efforts have been made to optimize UDA techniques to improve the accuracy of segmentation models in the target domain, few studies have addressed the robustness of these models under UDA. In this study, we propose a two-stage training strategy for robust domain adaptation. In the source training stage, we utilize adversarial sample augmentation to enhance the robustness and generalization capability of the source model. And in the target training stage, we propose a novel robust pseudo-label and pseudo-boundary (PLPB) method, which effectively utilizes unlabeled target data to generate pseudo labels and pseudo boundaries that enable model self-adaptation without requiring source data. Extensive experimental results on cross-domain fundus image segmentation confirm the effectiveness and versatility of our method. Source code of this study is openly accessible at https://github.com/LinGrayy/PLPB. ",
    "url": "https://arxiv.org/abs/2310.16665",
    "authors": [
      "Lingrui Li",
      "Yanfeng Zhou",
      "Ge Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16667",
    "title": "CoDet: Co-Occurrence Guided Region-Word Alignment for Open-Vocabulary  Object Detection",
    "abstract": "Deriving reliable region-word alignment from image-text pairs is critical to learn object-level vision-language representations for open-vocabulary object detection. Existing methods typically rely on pre-trained or self-trained vision-language models for alignment, which are prone to limitations in localization accuracy or generalization capabilities. In this paper, we propose CoDet, a novel approach that overcomes the reliance on pre-aligned vision-language space by reformulating region-word alignment as a co-occurring object discovery problem. Intuitively, by grouping images that mention a shared concept in their captions, objects corresponding to the shared concept shall exhibit high co-occurrence among the group. CoDet then leverages visual similarities to discover the co-occurring objects and align them with the shared concept. Extensive experiments demonstrate that CoDet has superior performances and compelling scalability in open-vocabulary detection, e.g., by scaling up the visual backbone, CoDet achieves 37.0 $\\text{AP}^m_{novel}$ and 44.7 $\\text{AP}^m_{all}$ on OV-LVIS, surpassing the previous SoTA by 4.2 $\\text{AP}^m_{novel}$ and 9.8 $\\text{AP}^m_{all}$. Code is available at https://github.com/CVMI-Lab/CoDet. ",
    "url": "https://arxiv.org/abs/2310.16667",
    "authors": [
      "Chuofan Ma",
      "Yi Jiang",
      "Xin Wen",
      "Zehuan Yuan",
      "Xiaojuan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16673",
    "title": "Exploring Large Language Models for Code Explanation",
    "abstract": "Automating code documentation through explanatory text can prove highly beneficial in code understanding. Large Language Models (LLMs) have made remarkable strides in Natural Language Processing, especially within software engineering tasks such as code generation and code summarization. This study specifically delves into the task of generating natural-language summaries for code snippets, using various LLMs. The findings indicate that Code LLMs outperform their generic counterparts, and zero-shot methods yield superior results when dealing with datasets with dissimilar distributions between training and testing sets. ",
    "url": "https://arxiv.org/abs/2310.16673",
    "authors": [
      "Paheli Bhattacharya",
      "Manojit Chakraborty",
      "Kartheek N S N Palepu",
      "Vikas Pandey",
      "Ishan Dindorkar",
      "Rakesh Rajpurohit",
      "Rishabh Gupta"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.16675",
    "title": "Agreeing to Stop: Reliable Latency-Adaptive Decision Making via  Ensembles of Spiking Neural Networks",
    "abstract": "Spiking neural networks (SNNs) are recurrent models that can leverage sparsity in input time series to efficiently carry out tasks such as classification. Additional efficiency gains can be obtained if decisions are taken as early as possible as a function of the complexity of the input time series. The decision on when to stop inference and produce a decision must rely on an estimate of the current accuracy of the decision. Prior work demonstrated the use of conformal prediction (CP) as a principled way to quantify uncertainty and support adaptive-latency decisions in SNNs. In this paper, we propose to enhance the uncertainty quantification capabilities of SNNs by implementing ensemble models for the purpose of improving the reliability of stopping decisions. Intuitively, an ensemble of multiple models can decide when to stop more reliably by selecting times at which most models agree that the current accuracy level is sufficient. The proposed method relies on different forms of information pooling from ensemble models, and offers theoretical reliability guarantees. We specifically show that variational inference-based ensembles with p-variable pooling significantly reduce the average latency of state-of-the-art methods, while maintaining reliability guarantees. ",
    "url": "https://arxiv.org/abs/2310.16675",
    "authors": [
      "Jiechen Chen",
      "Sangwoo Park",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.16678",
    "title": "Robust and Actively Secure Serverless Collaborative Learning",
    "abstract": "Collaborative machine learning (ML) is widely used to enable institutions to learn better models from distributed data. While collaborative approaches to learning intuitively protect user data, they remain vulnerable to either the server, the clients, or both, deviating from the protocol. Indeed, because the protocol is asymmetric, a malicious server can abuse its power to reconstruct client data points. Conversely, malicious clients can corrupt learning with malicious updates. Thus, both clients and servers require a guarantee when the other cannot be trusted to fully cooperate. In this work, we propose a peer-to-peer (P2P) learning scheme that is secure against malicious servers and robust to malicious clients. Our core contribution is a generic framework that transforms any (compatible) algorithm for robust aggregation of model updates to the setting where servers and clients can act maliciously. Finally, we demonstrate the computational efficiency of our approach even with 1-million parameter models trained by 100s of peers on standard datasets. ",
    "url": "https://arxiv.org/abs/2310.16678",
    "authors": [
      "Olive Franzese",
      "Adam Dziedzic",
      "Christopher A. Choquette-Choo",
      "Mark R. Thomas",
      "Muhammad Ahmad Kaleem",
      "Stephan Rabanser",
      "Congyu Fang",
      "Somesh Jha",
      "Nicolas Papernot",
      "Xiao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.16684",
    "title": "Local Statistics for Generative Image Detection",
    "abstract": "Diffusion models (DMs) are generative models that learn to synthesize images from Gaussian noise. DMs can be trained to do a variety of tasks such as image generation and image super-resolution. Researchers have made significant improvement in the capability of synthesizing photorealistic images in the past few years. These successes also hasten the need to address the potential misuse of synthesized images. In this paper, we highlight the effectiveness of computing local statistics, as opposed to global statistics, in distinguishing digital camera images from DM-generated images. We hypothesized that local statistics should be used to address the spatial non-stationarity problem in images. We show that our approach produced promising results and it is also robust to various perturbations such as image resizing and JPEG compression. ",
    "url": "https://arxiv.org/abs/2310.16684",
    "authors": [
      "Yung Jer Wong",
      "Teck Khim Ng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16685",
    "title": "Detection of news written by the ChatGPT through authorship attribution  performed by a Bidirectional LSTM model",
    "abstract": "The large language based-model chatbot ChatGPT gained a lot of popularity since its launch and has been used in a wide range of situations. This research centers around a particular situation, when the ChatGPT is used to produce news that will be consumed by the population, causing the facilitation in the production of fake news, spread of misinformation and lack of trust in news sources. Aware of these problems, this research aims to build an artificial intelligence model capable of performing authorship attribution on news articles, identifying the ones written by the ChatGPT. To achieve this goal, a dataset containing equal amounts of human and ChatGPT written news was assembled and different natural processing language techniques were used to extract features from it that were used to train, validate and test three models built with different techniques. The best performance was produced by the Bidirectional Long Short Term Memory (LSTM) Neural Network model, achiving 91.57\\% accuracy when tested against the data from the testing set. ",
    "url": "https://arxiv.org/abs/2310.16685",
    "authors": [
      "Amanda Ferrari Iaquinta",
      "Gustavo Voltani von Atzingen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.16694",
    "title": "DSAM-GN:Graph Network based on Dynamic Similarity Adjacency Matrices for  Vehicle Re-identification",
    "abstract": "In recent years, vehicle re-identification (Re-ID) has gained increasing importance in various applications such as assisted driving systems, traffic flow management, and vehicle tracking, due to the growth of intelligent transportation systems. However, the presence of extraneous background information and occlusions can interfere with the learning of discriminative features, leading to significant variations in the same vehicle image across different scenarios. This paper proposes a method, named graph network based on dynamic similarity adjacency matrices (DSAM-GN), which incorporates a novel approach for constructing adjacency matrices to capture spatial relationships of local features and reduce background noise. Specifically, the proposed method divides the extracted vehicle features into different patches as nodes within the graph network. A spatial attention-based similarity adjacency matrix generation (SASAMG) module is employed to compute similarity matrices of nodes, and a dynamic erasure operation is applied to disconnect nodes with low similarity, resulting in similarity adjacency matrices. Finally, the nodes and similarity adjacency matrices are fed into graph networks to extract more discriminative features for vehicle Re-ID. Experimental results on public datasets VeRi-776 and VehicleID demonstrate the effectiveness of the proposed method compared with recent works. ",
    "url": "https://arxiv.org/abs/2310.16694",
    "authors": [
      "Yuejun Jiao",
      "Song Qiu",
      "Mingsong Chen",
      "Dingding Han",
      "Qingli Li",
      "Yue Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16695",
    "title": "From Pointwise to Powerhouse: Initialising Neural Networks with  Generative Models",
    "abstract": "Traditional initialisation methods, e.g. He and Xavier, have been effective in avoiding the problem of vanishing or exploding gradients in neural networks. However, they only use simple pointwise distributions, which model one-dimensional variables. Moreover, they ignore most information about the architecture and disregard past training experiences. These limitations can be overcome by employing generative models for initialisation. In this paper, we introduce two groups of new initialisation methods. First, we locally initialise weight groups by employing variational autoencoders. Secondly, we globally initialise full weight sets by employing graph hypernetworks. We thoroughly evaluate the impact of the employed generative models on state-of-the-art neural networks in terms of accuracy, convergence speed and ensembling. Our results show that global initialisations result in higher accuracy and faster initial convergence speed. However, the implementation through graph hypernetworks leads to diminished ensemble performance on out of distribution data. To counteract, we propose a modification called noise graph hypernetwork, which encourages diversity in the produced ensemble members. Furthermore, our approach might be able to transfer learned knowledge to different image distributions. Our work provides insights into the potential, the trade-offs and possible modifications of these new initialisation methods. ",
    "url": "https://arxiv.org/abs/2310.16695",
    "authors": [
      "Christian Harder",
      "Moritz Fuchs",
      "Yuri Tolkach",
      "Anirban Mukhopadhyay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16696",
    "title": "Interpretable time series neural representation for classification  purposes",
    "abstract": "Deep learning has made significant advances in creating efficient representations of time series data by automatically identifying complex patterns. However, these approaches lack interpretability, as the time series is transformed into a latent vector that is not easily interpretable. On the other hand, Symbolic Aggregate approximation (SAX) methods allow the creation of symbolic representations that can be interpreted but do not capture complex patterns effectively. In this work, we propose a set of requirements for a neural representation of univariate time series to be interpretable. We propose a new unsupervised neural architecture that meets these requirements. The proposed model produces consistent, discrete, interpretable, and visualizable representations. The model is learned independently of any downstream tasks in an unsupervised setting to ensure robustness. As a demonstration of the effectiveness of the proposed model, we propose experiments on classification tasks using UCR archive datasets. The obtained results are extensively compared to other interpretable models and state-of-the-art neural representation learning models. The experiments show that the proposed model yields, on average better results than other interpretable approaches on multiple datasets. We also present qualitative experiments to asses the interpretability of the approach. ",
    "url": "https://arxiv.org/abs/2310.16696",
    "authors": [
      "Etienne Le Naour",
      "Ghislain Agoua",
      "Nicolas Baskiotis",
      "Vincent Guigue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16700",
    "title": "Streamlining Knowledge Graph Construction with a fa\u00e7ade: The SPARQL  Anything project",
    "abstract": "What should a data integration framework for knowledge engineers look like? Recent research on Knowledge Graph construction proposes the design of a fa\\c{c}ade, a notion borrowed from object-oriented software engineering. This idea is applied to SPARQL Anything, a system that allows querying heterogeneous resources as-if they were in RDF, in plain SPARQL 1.1, by overloading the SERVICE clause. SPARQL Anything supports a wide variety of file formats, from popular ones (CSV, JSON, XML, Spreadsheets) to others that are not supported by alternative solutions (Markdown, YAML, DOCx, Bibtex). Features include querying Web APIs with high flexibility, parametrised queries, and chaining multiple transformations into complex pipelines. In this paper, we describe the design rationale and software architecture of the SPARQL Anything system. We provide references to an extensive set of reusable, real-world scenarios from various application domains. We report on the value-to-users of the founding assumptions of its design, compared to alternative solutions through a community survey and a field report from the industry. ",
    "url": "https://arxiv.org/abs/2310.16700",
    "authors": [
      "Luigi Asprino",
      "Enrico Daga",
      "Justin Dowdy",
      "Paul Mulholland",
      "Aldo Gangemi",
      "Marco Ratta"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2310.16706",
    "title": "Nighttime Driver Behavior Prediction Using Taillight Signal Recognition  via CNN-SVM Classifier",
    "abstract": "This paper aims to enhance the ability to predict nighttime driving behavior by identifying taillights of both human-driven and autonomous vehicles. The proposed model incorporates a customized detector designed to accurately detect front-vehicle taillights on the road. At the beginning of the detector, a learnable pre-processing block is implemented, which extracts deep features from input images and calculates the data rarity for each feature. In the next step, drawing inspiration from soft attention, a weighted binary mask is designed that guides the model to focus more on predetermined regions. This research utilizes Convolutional Neural Networks (CNNs) to extract distinguishing characteristics from these areas, then reduces dimensions using Principal Component Analysis (PCA). Finally, the Support Vector Machine (SVM) is used to predict the behavior of the vehicles. To train and evaluate the model, a large-scale dataset is collected from two types of dash-cams and Insta360 cameras from the rear view of Ford Motor Company vehicles. This dataset includes over 12k frames captured during both daytime and nighttime hours. To address the limited nighttime data, a unique pixel-wise image processing technique is implemented to convert daytime images into realistic night images. The findings from the experiments demonstrate that the proposed methodology can accurately categorize vehicle behavior with 92.14% accuracy, 97.38% specificity, 92.09% sensitivity, 92.10% F1-measure, and 0.895 Cohen's Kappa Statistic. Further details are available at https://github.com/DeepCar/Taillight_Recognition. ",
    "url": "https://arxiv.org/abs/2310.16706",
    "authors": [
      "Amir Hossein Barshooi",
      "Elmira Bagheri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16737",
    "title": "Translating Universal Scene Descriptions into Knowledge Graphs for  Robotic Environment",
    "abstract": "Robots performing human-scale manipulation tasks require an extensive amount of knowledge about their surroundings in order to perform their actions competently and human-like. In this work, we investigate the use of virtual reality technology as an implementation for robot environment modeling, and present a technique for translating scene graphs into knowledge bases. To this end, we take advantage of the Universal Scene Description (USD) format which is an emerging standard for the authoring, visualization and simulation of complex environments. We investigate the conversion of USD-based environment models into Knowledge Graph (KG) representations that facilitate semantic querying and integration with additional knowledge sources. ",
    "url": "https://arxiv.org/abs/2310.16737",
    "authors": [
      "Giang Hoang Nguyen",
      "Daniel Bessler",
      "Simon Stelter",
      "Mihai Pomarlan",
      "Michael Beetz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2310.16738",
    "title": "Improving Conversational Recommendation Systems via Bias Analysis and  Language-Model-Enhanced Data Augmentation",
    "abstract": "Conversational Recommendation System (CRS) is a rapidly growing research area that has gained significant attention alongside advancements in language modelling techniques. However, the current state of conversational recommendation faces numerous challenges due to its relative novelty and limited existing contributions. In this study, we delve into benchmark datasets for developing CRS models and address potential biases arising from the feedback loop inherent in multi-turn interactions, including selection bias and multiple popularity bias variants. Drawing inspiration from the success of generative data via using language models and data augmentation techniques, we present two novel strategies, 'Once-Aug' and 'PopNudge', to enhance model performance while mitigating biases. Through extensive experiments on ReDial and TG-ReDial benchmark datasets, we show a consistent improvement of CRS techniques with our data augmentation approaches and offer additional insights on addressing multiple newly formulated biases. ",
    "url": "https://arxiv.org/abs/2310.16738",
    "authors": [
      "Xi Wang",
      "Hossein A. Rahmani",
      "Jiqun Liu",
      "Emine Yilmaz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.16745",
    "title": "Design Space Exploration of Sparsity-Aware Application-Specific Spiking  Neural Network Accelerators",
    "abstract": "Spiking Neural Networks (SNNs) offer a promising alternative to Artificial Neural Networks (ANNs) for deep learning applications, particularly in resource-constrained systems. This is largely due to their inherent sparsity, influenced by factors such as the input dataset, the length of the spike train, and the network topology. While a few prior works have demonstrated the advantages of incorporating sparsity into the hardware design, especially in terms of reducing energy consumption, the impact on hardware resources has not yet been explored. This is where design space exploration (DSE) becomes crucial, as it allows for the optimization of hardware performance by tailoring both the hardware and model parameters to suit specific application needs. However, DSE can be extremely challenging given the potentially large design space and the interplay of hardware architecture design choices and application-specific model parameters. In this paper, we propose a flexible hardware design that leverages the sparsity of SNNs to identify highly efficient, application-specific accelerator designs. We develop a high-level, cycle-accurate simulation framework for this hardware and demonstrate the framework's benefits in enabling detailed and fine-grained exploration of SNN design choices, such as the layer-wise logical-to-hardware ratio (LHR). Our experimental results show that our design can (i) achieve up to $76\\%$ reduction in hardware resources and (ii) deliver a speed increase of up to $31.25\\times$, while requiring $27\\%$ fewer hardware resources compared to sparsity-oblivious designs. We further showcase the robustness of our framework by varying spike train lengths with different neuron population sizes to find the optimal trade-off points between accuracy and hardware latency. ",
    "url": "https://arxiv.org/abs/2310.16745",
    "authors": [
      "Ilkin Aliyev. Kama Svoboda",
      "Tosiron Adegbija"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2310.16753",
    "title": "PROMINET: Prototype-based Multi-View Network for Interpretable Email  Response Prediction",
    "abstract": "Email is a widely used tool for business communication, and email marketing has emerged as a cost-effective strategy for enterprises. While previous studies have examined factors affecting email marketing performance, limited research has focused on understanding email response behavior by considering email content and metadata. This study proposes a Prototype-based Multi-view Network (PROMINET) that incorporates semantic and structural information from email data. By utilizing prototype learning, the PROMINET model generates latent exemplars, enabling interpretable email response prediction. The model maps learned semantic and structural exemplars to observed samples in the training data at different levels of granularity, such as document, sentence, or phrase. The approach is evaluated on two real-world email datasets: the Enron corpus and an in-house Email Marketing corpus. Experimental results demonstrate that the PROMINET model outperforms baseline models, achieving a ~3% improvement in F1 score on both datasets. Additionally, the model provides interpretability through prototypes at different granularity levels while maintaining comparable performance to non-interpretable models. The learned prototypes also show potential for generating suggestions to enhance email text editing and improve the likelihood of effective email responses. This research contributes to enhancing sender-receiver communication and customer engagement in email interactions. ",
    "url": "https://arxiv.org/abs/2310.16753",
    "authors": [
      "Yuqing Wang",
      "Prashanth Vijayaraghavan",
      "Ehsan Degan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16761",
    "title": "IntenDD: A Unified Contrastive Learning Approach for Intent Detection  and Discovery",
    "abstract": "Identifying intents from dialogue utterances forms an integral component of task-oriented dialogue systems. Intent-related tasks are typically formulated either as a classification task, where the utterances are classified into predefined categories or as a clustering task when new and previously unknown intent categories need to be discovered from these utterances. Further, the intent classification may be modeled in a multiclass (MC) or multilabel (ML) setup. While typically these tasks are modeled as separate tasks, we propose IntenDD, a unified approach leveraging a shared utterance encoding backbone. IntenDD uses an entirely unsupervised contrastive learning strategy for representation learning, where pseudo-labels for the unlabeled utterances are generated based on their lexical features. Additionally, we introduce a two-step post-processing setup for the classification tasks using modified adsorption. Here, first, the residuals in the training data are propagated followed by smoothing the labels both modeled in a transductive setting. Through extensive evaluations on various benchmark datasets, we find that our approach consistently outperforms competitive baselines across all three tasks. On average, IntenDD reports percentage improvements of 2.32%, 1.26%, and 1.52% in their respective metrics for few-shot MC, few-shot ML, and the intent discovery tasks respectively. ",
    "url": "https://arxiv.org/abs/2310.16761",
    "authors": [
      "Bhavuk Singhal",
      "Ashim Gupta",
      "Shivasankaran V P",
      "Amrith Krishna"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.16783",
    "title": "S$^3$-TTA: Scale-Style Selection for Test-Time Augmentation in  Biomedical Image Segmentation",
    "abstract": "Deep-learning models have been successful in biomedical image segmentation. To generalize for real-world deployment, test-time augmentation (TTA) methods are often used to transform the test image into different versions that are hopefully closer to the training domain. Unfortunately, due to the vast diversity of instance scale and image styles, many augmented test images produce undesirable results, thus lowering the overall performance. This work proposes a new TTA framework, S$^3$-TTA, which selects the suitable image scale and style for each test image based on a transformation consistency metric. In addition, S$^3$-TTA constructs an end-to-end augmentation-segmentation joint-training pipeline to ensure a task-oriented augmentation. On public benchmarks for cell and lung segmentation, S$^3$-TTA demonstrates improvements over the prior art by 3.4% and 1.3%, respectively, by simply augmenting the input data in testing phase. ",
    "url": "https://arxiv.org/abs/2310.16783",
    "authors": [
      "Kangxian Xie",
      "Siyu Huang",
      "Sebastian Cajas Ordone",
      "Hanspeter Pfister",
      "Donglai Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16802",
    "title": "From Molecules to Materials: Pre-training Large Generalizable Models for  Atomic Property Prediction",
    "abstract": "Foundation models have been transformational in machine learning fields such as natural language processing and computer vision. Similar success in atomic property prediction has been limited due to the challenges of training effective models across multiple chemical domains. To address this, we introduce Joint Multi-domain Pre-training (JMP), a supervised pre-training strategy that simultaneously trains on multiple datasets from different chemical domains, treating each dataset as a unique pre-training task within a multi-task framework. Our combined training dataset consists of $\\sim$120M systems from OC20, OC22, ANI-1x, and Transition-1x. We evaluate performance and generalization by fine-tuning over a diverse set of downstream tasks and datasets including: QM9, rMD17, MatBench, QMOF, SPICE, and MD22. JMP demonstrates an average improvement of 59% over training from scratch, and matches or sets state-of-the-art on 34 out of 40 tasks. Our work highlights the potential of pre-training strategies that utilize diverse data to advance property prediction across chemical domains, especially for low-data tasks. ",
    "url": "https://arxiv.org/abs/2310.16802",
    "authors": [
      "Nima Shoghi",
      "Adeesh Kolluru",
      "John R. Kitchin",
      "Zachary W. Ulissi",
      "C. Lawrence Zitnick",
      "Brandon M. Wood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16803",
    "title": "Language Agnostic Code Embeddings",
    "abstract": "Recently, code language models have achieved notable advancements in addressing a diverse array of essential code comprehension and generation tasks. Yet, the field lacks a comprehensive deep dive and understanding of the code embeddings of multilingual code models. In this paper, we present a comprehensive study on multilingual code embeddings, focusing on the cross-lingual capabilities of these embeddings across different programming languages. Through probing experiments, we demonstrate that code embeddings comprise two distinct components: one deeply tied to the nuances and syntax of a specific language, and the other remaining agnostic to these details, primarily focusing on semantics. Further, we show that when we isolate and eliminate this language-specific component, we witness significant improvements in downstream code retrieval tasks, leading to an absolute increase of up to +17 in the Mean Reciprocal Rank (MRR). ",
    "url": "https://arxiv.org/abs/2310.16803",
    "authors": [
      "Saiteja Utpala",
      "Alex Gu",
      "Pin Yu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16808",
    "title": "Fingervein Verification using Convolutional Multi-Head Attention Network",
    "abstract": "Biometric verification systems are deployed in various security-based access-control applications that require user-friendly and reliable person verification. Among the different biometric characteristics, fingervein biometrics have been extensively studied owing to their reliable verification performance. Furthermore, fingervein patterns reside inside the skin and are not visible outside; therefore, they possess inherent resistance to presentation attacks and degradation due to external factors. In this paper, we introduce a novel fingervein verification technique using a convolutional multihead attention network called VeinAtnNet. The proposed VeinAtnNet is designed to achieve light weight with a smaller number of learnable parameters while extracting discriminant information from both normal and enhanced fingervein images. The proposed VeinAtnNet was trained on the newly constructed fingervein dataset with 300 unique fingervein patterns that were captured in multiple sessions to obtain 92 samples per unique fingervein. Extensive experiments were performed on the newly collected dataset FV-300 and the publicly available FV-USM and FV-PolyU fingervein dataset. The performance of the proposed method was compared with five state-of-the-art fingervein verification systems, indicating the efficacy of the proposed VeinAtnNet. ",
    "url": "https://arxiv.org/abs/2310.16808",
    "authors": [
      "Raghavendra Ramachandra",
      "Sushma Venkatesh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16827",
    "title": "Robust Sparsification for Matroid Intersection with Applications",
    "abstract": "Matroid intersection is a classical optimization problem where, given two matroids over the same ground set, the goal is to find the largest common independent set. In this paper, we show that there exists a certain \"sparsifer\": a subset of elements, of size $O(|S^{opt}| \\cdot 1/\\varepsilon)$, where $S^{opt}$ denotes the optimal solution, that is guaranteed to contain a $3/2 + \\varepsilon$ approximation, while guaranteeing certain robustness properties. We call such a small subset a Density Constrained Subset (DCS), which is inspired by the Edge-Degree Constrained Subgraph (EDCS) [Bernstein and Stein, 2015], originally designed for the maximum cardinality matching problem in a graph. Our proof is constructive and hinges on a greedy decomposition of matroids, which we call the density-based decomposition. We show that this sparsifier has certain robustness properties that can be used in one-way communication and random-order streaming models. ",
    "url": "https://arxiv.org/abs/2310.16827",
    "authors": [
      "Chien-Chung Huang",
      "Fran\u00e7ois Sellier"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2310.16828",
    "title": "TD-MPC2: Scalable, Robust World Models for Continuous Control",
    "abstract": "TD-MPC is a model-based reinforcement learning (RL) algorithm that performs local trajectory optimization in the latent space of a learned implicit (decoder-free) world model. In this work, we present TD-MPC2: a series of improvements upon the TD-MPC algorithm. We demonstrate that TD-MPC2 improves significantly over baselines across 104 online RL tasks spanning 4 diverse task domains, achieving consistently strong results with a single set of hyperparameters. We further show that agent capabilities increase with model and data size, and successfully train a single 317M parameter agent to perform 80 tasks across multiple task domains, embodiments, and action spaces. We conclude with an account of lessons, opportunities, and risks associated with large TD-MPC2 agents. Explore videos, models, data, code, and more at https://nicklashansen.github.io/td-mpc2 ",
    "url": "https://arxiv.org/abs/2310.16828",
    "authors": [
      "Nicklas Hansen",
      "Hao Su",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.16831",
    "title": "PERF: Panoramic Neural Radiance Field from a Single Panorama",
    "abstract": "Neural Radiance Field (NeRF) has achieved substantial progress in novel view synthesis given multi-view images. Recently, some works have attempted to train a NeRF from a single image with 3D priors. They mainly focus on a limited field of view and there are few invisible occlusions, which greatly limits their scalability to real-world 360-degree panoramic scenarios with large-size occlusions. In this paper, we present PERF, a 360-degree novel view synthesis framework that trains a panoramic neural radiance field from a single panorama. Notably, PERF allows 3D roaming in a complex scene without expensive and tedious image collection. To achieve this goal, we propose a novel collaborative RGBD inpainting method and a progressive inpainting-and-erasing method to lift up a 360-degree 2D scene to a 3D scene. Specifically, we first predict a panoramic depth map as initialization given a single panorama, and reconstruct visible 3D regions with volume rendering. Then we introduce a collaborative RGBD inpainting approach into a NeRF for completing RGB images and depth maps from random views, which is derived from an RGB Stable Diffusion model and a monocular depth estimator. Finally, we introduce an inpainting-and-erasing strategy to avoid inconsistent geometry between a newly-sampled view and reference views. The two components are integrated into the learning of NeRFs in a unified optimization framework and achieve promising results. Extensive experiments on Replica and a new dataset PERF-in-the-wild demonstrate the superiority of our PERF over state-of-the-art methods. Our PERF can be widely used for real-world applications, such as panorama-to-3D, text-to-3D, and 3D scene stylization applications. Project page and code are available at https://perf-project.github.io/. ",
    "url": "https://arxiv.org/abs/2310.16831",
    "authors": [
      "Guangcong Wang",
      "Peng Wang",
      "Zhaoxi Chen",
      "Wenping Wang",
      "Chen Change Loy",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16832",
    "title": "LightSpeed: Light and Fast Neural Light Fields on Mobile Devices",
    "abstract": "Real-time novel-view image synthesis on mobile devices is prohibitive due to the limited computational power and storage. Using volumetric rendering methods, such as NeRF and its derivatives, on mobile devices is not suitable due to the high computational cost of volumetric rendering. On the other hand, recent advances in neural light field representations have shown promising real-time view synthesis results on mobile devices. Neural light field methods learn a direct mapping from a ray representation to the pixel color. The current choice of ray representation is either stratified ray sampling or Pl\\\"{u}cker coordinates, overlooking the classic light slab (two-plane) representation, the preferred representation to interpolate between light field views. In this work, we find that using the light slab representation is an efficient representation for learning a neural light field. More importantly, it is a lower-dimensional ray representation enabling us to learn the 4D ray space using feature grids which are significantly faster to train and render. Although mostly designed for frontal views, we show that the light-slab representation can be further extended to non-frontal scenes using a divide-and-conquer strategy. Our method offers superior rendering quality compared to previous light field methods and achieves a significantly improved trade-off between rendering quality and speed. ",
    "url": "https://arxiv.org/abs/2310.16832",
    "authors": [
      "Aarush Gupta",
      "Junli Cao",
      "Chaoyang Wang",
      "Ju Hu",
      "Sergey Tulyakov",
      "Jian Ren",
      "L\u00e1szl\u00f3 A Jeni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.16835",
    "title": "Proposal-Contrastive Pretraining for Object Detection from Fewer Data",
    "abstract": "The use of pretrained deep neural networks represents an attractive way to achieve strong results with few data available. When specialized in dense problems such as object detection, learning local rather than global information in images has proven to be more efficient. However, for unsupervised pretraining, the popular contrastive learning requires a large batch size and, therefore, a lot of resources. To address this problem, we are interested in transformer-based object detectors that have recently gained traction in the community with good performance and with the particularity of generating many diverse object proposals. In this work, we present Proposal Selection Contrast (ProSeCo), a novel unsupervised overall pretraining approach that leverages this property. ProSeCo uses the large number of object proposals generated by the detector for contrastive learning, which allows the use of a smaller batch size, combined with object-level features to learn local information in the images. To improve the effectiveness of the contrastive loss, we introduce the object location information in the selection of positive examples to take into account multiple overlapping object proposals. When reusing pretrained backbone, we advocate for consistency in learning local information between the backbone and the detection head. We show that our method outperforms state of the art in unsupervised pretraining for object detection on standard and novel benchmarks in learning with fewer data. ",
    "url": "https://arxiv.org/abs/2310.16835",
    "authors": [
      "Quentin Bouniot",
      "Romaric Audigier",
      "Ang\u00e9lique Loesch",
      "Amaury Habrard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16121",
    "title": "19 Parameters Is All You Need: Tiny Neural Networks for Particle Physics",
    "abstract": "As particle accelerators increase their collision rates, and deep learning solutions prove their viability, there is a growing need for lightweight and fast neural network architectures for low-latency tasks such as triggering. We examine the potential of one recent Lorentz- and permutation-symmetric architecture, PELICAN, and present its instances with as few as 19 trainable parameters that outperform generic architectures with tens of thousands of parameters when compared on the binary classification task of top quark jet tagging. ",
    "url": "https://arxiv.org/abs/2310.16121",
    "authors": [
      "Alexander Bogatskiy",
      "Timothy Hoffman",
      "Jan T. Offermann"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2310.16175",
    "title": "G-CASCADE: Efficient Cascaded Graph Convolutional Decoding for 2D  Medical Image Segmentation",
    "abstract": "In recent years, medical image segmentation has become an important application in the field of computer-aided diagnosis. In this paper, we are the first to propose a new graph convolution-based decoder namely, Cascaded Graph Convolutional Attention Decoder (G-CASCADE), for 2D medical image segmentation. G-CASCADE progressively refines multi-stage feature maps generated by hierarchical transformer encoders with an efficient graph convolution block. The encoder utilizes the self-attention mechanism to capture long-range dependencies, while the decoder refines the feature maps preserving long-range information due to the global receptive fields of the graph convolution block. Rigorous evaluations of our decoder with multiple transformer encoders on five medical image segmentation tasks (i.e., Abdomen organs, Cardiac organs, Polyp lesions, Skin lesions, and Retinal vessels) show that our model outperforms other state-of-the-art (SOTA) methods. We also demonstrate that our decoder achieves better DICE scores than the SOTA CASCADE decoder with 80.8% fewer parameters and 82.3% fewer FLOPs. Our decoder can easily be used with other hierarchical encoders for general-purpose semantic and medical image segmentation tasks. ",
    "url": "https://arxiv.org/abs/2310.16175",
    "authors": [
      "Md Mostafijur Rahman",
      "Radu Marculescu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16463",
    "title": "Constructing disjoint Steiner trees in Sierpi\u0144ski graphs",
    "abstract": "Let $G$ be a graph and $S\\subseteq V(G)$ with $|S|\\geq 2$. Then the trees $T_1, T_2, \\cdots, T_\\ell$ in $G$ are \\emph{internally disjoint Steiner trees} connecting $S$ (or $S$-Steiner trees) if $E(T_i) \\cap E(T_j )=\\emptyset$ and $V(T_i)\\cap V(T_j)=S$ for every pair of distinct integers $i,j$, $1 \\leq i, j \\leq \\ell$. Similarly, if we only have the condition $E(T_i) \\cap E(T_j )=\\emptyset$ but without the condition $V(T_i)\\cap V(T_j)=S$, then they are \\emph{edge-disjoint Steiner trees}. The \\emph{generalized $k$-connectivity}, denoted by $\\kappa_k(G)$, of a graph $G$, is defined as $\\kappa_k(G)=\\min\\{\\kappa_G(S)|S \\subseteq V(G) \\ \\textrm{and} \\ |S|=k \\}$, where $\\kappa_G(S)$ is the maximum number of internally disjoint $S$-Steiner trees. The \\emph{generalized local edge-connectivity} $\\lambda_{G}(S)$ is the maximum number of edge-disjoint Steiner trees connecting $S$ in $G$. The {\\it generalized $k$-edge-connectivity} $\\lambda_k(G)$ of $G$ is defined as $\\lambda_k(G)=\\min\\{\\lambda_{G}(S)\\,|\\,S\\subseteq V(G) \\ and \\ |S|=k\\}$. These measures are generalizations of the concepts of connectivity and edge-connectivity, and they and can be used as measures of vulnerability of networks. It is, in general, difficult to compute these generalized connectivities. However, there are precise results for some special classes of graphs. In this paper, we obtain the exact value of $\\lambda_{k}(S(n,\\ell))$ for $3\\leq k\\leq \\ell^n$, and the exact value of $\\kappa_{k}(S(n,\\ell))$ for $3\\leq k\\leq \\ell$, where $S(n, \\ell)$ is the Sierpi\\'{n}ski graphs with order $\\ell^n$. As a direct consequence, these graphs provide additional interesting examples when $\\lambda_{k}(S(n,\\ell))=\\kappa_{k}(S(n,\\ell))$. We also study the some network properties of Sierpi\\'{n}ski graphs. ",
    "url": "https://arxiv.org/abs/2310.16463",
    "authors": [
      "Chenxu Yang",
      "Ping Li",
      "Yaping Mao",
      "Eddie Cheng",
      "Ralf Klasing"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2310.16597",
    "title": "Beyond IID weights: sparse and low-rank deep Neural Networks are also  Gaussian Processes",
    "abstract": "The infinitely wide neural network has been proven a useful and manageable mathematical model that enables the understanding of many phenomena appearing in deep learning. One example is the convergence of random deep networks to Gaussian processes that allows a rigorous analysis of the way the choice of activation function and network weights impacts the training dynamics. In this paper, we extend the seminal proof of Matthews et al. (2018) to a larger class of initial weight distributions (which we call PSEUDO-IID), including the established cases of IID and orthogonal weights, as well as the emerging low-rank and structured sparse settings celebrated for their computational speed-up benefits. We show that fully-connected and convolutional networks initialized with PSEUDO-IID distributions are all effectively equivalent up to their variance. Using our results, one can identify the Edge-of-Chaos for a broader class of neural networks and tune them at criticality in order to enhance their training. ",
    "url": "https://arxiv.org/abs/2310.16597",
    "authors": [
      "Thiziri Nait-Saada",
      "Alireza Naderi",
      "Jared Tanner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16638",
    "title": "Robust Covariate Shift Adaptation for Density-Ratio Estimation",
    "abstract": "Consider a scenario where we have access to train data with both covariates and outcomes while test data only contains covariates. In this scenario, our primary aim is to predict the missing outcomes of the test data. With this objective in mind, we train parametric regression models under a covariate shift, where covariate distributions are different between the train and test data. For this problem, existing studies have proposed covariate shift adaptation via importance weighting using the density ratio. This approach averages the train data losses, each weighted by an estimated ratio of the covariate densities between the train and test data, to approximate the test-data risk. Although it allows us to obtain a test-data risk minimizer, its performance heavily relies on the accuracy of the density ratio estimation. Moreover, even if the density ratio can be consistently estimated, the estimation errors of the density ratio also yield bias in the estimators of the regression model's parameters of interest. To mitigate these challenges, we introduce a doubly robust estimator for covariate shift adaptation via importance weighting, which incorporates an additional estimator for the regression function. Leveraging double machine learning techniques, our estimator reduces the bias arising from the density ratio estimation errors. We demonstrate the asymptotic distribution of the regression parameter estimator. Notably, our estimator remains consistent if either the density ratio estimator or the regression function is consistent, showcasing its robustness against potential errors in density ratio estimation. Finally, we confirm the soundness of our proposed method via simulation studies. ",
    "url": "https://arxiv.org/abs/2310.16638",
    "authors": [
      "Masahiro Kato"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.16742",
    "title": "Interferometric Neural Networks",
    "abstract": "On the one hand, artificial neural networks have many successful applications in the field of machine learning and optimization. On the other hand, interferometers are integral parts of any field that deals with waves such as optics, astronomy, and quantum physics. Here, we introduce neural networks composed of interferometers and then build generative adversarial networks from them. Our networks do not have any classical layer and can be realized on quantum computers or photonic chips. We demonstrate their applicability for combinatorial optimization, image classification, and image generation. For combinatorial optimization, our network consistently converges to the global optimum or remains within a narrow range of it. In multi-class image classification tasks, our networks achieve accuracies of 93% and 83%. Lastly, we show their capability to generate images of digits from 0 to 9 as well as human faces. ",
    "url": "https://arxiv.org/abs/2310.16742",
    "authors": [
      "Arun Sehrawat"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1703.10146",
    "title": "Community Detection and Stochastic Block Models",
    "abstract": " Title: Community Detection and Stochastic Block Models ",
    "url": "https://arxiv.org/abs/1703.10146",
    "authors": [
      "Emmanuel Abbe"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Computational Complexity (cs.CC)",
      "Information Theory (cs.IT)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1903.02758",
    "title": "A face cover perspective to $\\ell_1$ embeddings of planar graphs",
    "abstract": " Title: A face cover perspective to $\\ell_1$ embeddings of planar graphs ",
    "url": "https://arxiv.org/abs/1903.02758",
    "authors": [
      "Arnold Filtser"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:1912.13490",
    "title": "A Neurocomputational Account of Consciousness: The Goal-Aligning  Representation Internal Manipulation Theory (GARIM)",
    "abstract": " Title: A Neurocomputational Account of Consciousness: The Goal-Aligning  Representation Internal Manipulation Theory (GARIM) ",
    "url": "https://arxiv.org/abs/1912.13490",
    "authors": [
      "Gianluca Baldassarre",
      "Giovanni Granato"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2006.16785",
    "title": "Lipschitzness Is All You Need To Tame Off-policy Generative Adversarial  Imitation Learning",
    "abstract": " Comments: Accepted for publication in Machine Learning 2022 ",
    "url": "https://arxiv.org/abs/2006.16785",
    "authors": [
      "Lionel Blond\u00e9",
      "Pablo Strasser",
      "Alexandros Kalousis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2102.06134",
    "title": "Sweeps, polytopes, oriented matroids, and allowable graphs of  permutations",
    "abstract": " Comments: 48 pages, 14 figures, published version ",
    "url": "https://arxiv.org/abs/2102.06134",
    "authors": [
      "Arnau Padrol",
      "Eva Philippe"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2106.03232",
    "title": "A Targeted Assessment of Incremental Processing in Neural LanguageModels  and Humans",
    "abstract": " Comments: Published in the proceedings of ACL 2021 ",
    "url": "https://arxiv.org/abs/2106.03232",
    "authors": [
      "Ethan Gotlieb Wilcox",
      "Pranali Vani",
      "Roger P. Levy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2112.02814",
    "title": "A Survey of Deep Learning for Low-Shot Object Detection",
    "abstract": " Title: A Survey of Deep Learning for Low-Shot Object Detection ",
    "url": "https://arxiv.org/abs/2112.02814",
    "authors": [
      "Qihan Huang",
      "Haofei Zhang",
      "Mengqi Xue",
      "Jie Song",
      "Mingli Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.12717",
    "title": "Forward Composition Propagation for Explainable Neural Reasoning",
    "abstract": " Title: Forward Composition Propagation for Explainable Neural Reasoning ",
    "url": "https://arxiv.org/abs/2112.12717",
    "authors": [
      "Isel Grau",
      "Gonzalo N\u00e1poles",
      "Marilyn Bello",
      "Yamisleydi Salgueiro",
      "Agnieszka Jastrzebska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.08022",
    "title": "HEAM: High-Efficiency Approximate Multiplier Optimization for Deep  Neural Networks",
    "abstract": " Comments: 5 pages, 2022 IEEE International Symposium on Circuits and Systems (ISCAS) ",
    "url": "https://arxiv.org/abs/2201.08022",
    "authors": [
      "Su Zheng",
      "Zhen Li",
      "Yao Lu",
      "Jingbo Gao",
      "Jide Zhang",
      "Lingli Wang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.07918",
    "title": "\"Understanding Robustness Lottery\": A Geometric Visual Comparative  Analysis of Neural Network Pruning Approaches",
    "abstract": " Title: \"Understanding Robustness Lottery\": A Geometric Visual Comparative  Analysis of Neural Network Pruning Approaches ",
    "url": "https://arxiv.org/abs/2206.07918",
    "authors": [
      "Zhimin Li",
      "Shusen Liu",
      "Xin Yu",
      "Kailkhura Bhavya",
      "Jie Cao",
      "Diffenderfer James Daniel",
      "Peer-Timo Bremer",
      "Valerio Pascucci"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.09785",
    "title": "Unsupervised energy disaggregation via convolutional sparse coding",
    "abstract": " Comments: 9 pages, 2 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2207.09785",
    "authors": [
      "Christian Aarset",
      "Andreas Habring",
      "Martin Holler",
      "Mario Mitter"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2208.09140",
    "title": "Energy Efficient Obfuscation of Side-Channel Leakage for Preventing  Side-Channel Attacks",
    "abstract": " Title: Energy Efficient Obfuscation of Side-Channel Leakage for Preventing  Side-Channel Attacks ",
    "url": "https://arxiv.org/abs/2208.09140",
    "authors": [
      "Shan Jin",
      "Minghua Xu",
      "Yiwei Cai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2209.15543",
    "title": "Bayesian Neural Networks for Geothermal Resource Assessment: Prediction  with Uncertainty",
    "abstract": " Comments: 27 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2209.15543",
    "authors": [
      "Stephen Brown",
      "William L. Rodi",
      "Marco Seracini",
      "Chen Gu",
      "Michael Fehler",
      "James Faulds",
      "Connor M. Smith",
      "Sven Treitel"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04979",
    "title": "Label-free segmentation from cardiac ultrasound using self-supervised  learning",
    "abstract": " Comments: 37 pages, 3 Tables, 7 Figures ",
    "url": "https://arxiv.org/abs/2210.04979",
    "authors": [
      "Danielle L. Ferreira",
      "Zaynaf Salaymang",
      "Rima Arnaout"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12089",
    "title": "A Survey on Graph Counterfactual Explanations: Definitions, Methods,  Evaluation",
    "abstract": " Title: A Survey on Graph Counterfactual Explanations: Definitions, Methods,  Evaluation ",
    "url": "https://arxiv.org/abs/2210.12089",
    "authors": [
      "Mario Alfonso Prado-Romero",
      "Bardh Prenkaj",
      "Giovanni Stilo",
      "Fosca Giannotti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.09717",
    "title": "UPTON: Preventing Authorship Leakage from Public Text Release via Data  Poisoning",
    "abstract": " Title: UPTON: Preventing Authorship Leakage from Public Text Release via Data  Poisoning ",
    "url": "https://arxiv.org/abs/2211.09717",
    "authors": [
      "Ziyao Wang",
      "Thai Le",
      "Dongwon Lee"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.12421",
    "title": "Data-Driven Network Neuroscience: On Data Collection and Benchmark",
    "abstract": " Title: Data-Driven Network Neuroscience: On Data Collection and Benchmark ",
    "url": "https://arxiv.org/abs/2211.12421",
    "authors": [
      "Jiaxing Xu",
      "Yunhan Yang",
      "David Tse Jung Huang",
      "Sophi Shilpa Gururajapathy",
      "Yiping Ke",
      "Miao Qiao",
      "Alan Wang",
      "Haribalan Kumar",
      "Josh McGeown",
      "Eryn Kwon"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2212.05946",
    "title": "Evaluation and Improvement of Interpretability for Self-Explainable  Part-Prototype Networks",
    "abstract": " Title: Evaluation and Improvement of Interpretability for Self-Explainable  Part-Prototype Networks ",
    "url": "https://arxiv.org/abs/2212.05946",
    "authors": [
      "Qihan Huang",
      "Mengqi Xue",
      "Wenqi Huang",
      "Haofei Zhang",
      "Jie Song",
      "Yongcheng Jing",
      "Mingli Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.00288",
    "title": "CoderEval: A Benchmark of Pragmatic Code Generation with Generative  Pre-trained Models",
    "abstract": " Title: CoderEval: A Benchmark of Pragmatic Code Generation with Generative  Pre-trained Models ",
    "url": "https://arxiv.org/abs/2302.00288",
    "authors": [
      "Hao Yu",
      "Bo Shen",
      "Dezhi Ran",
      "Jiaxin Zhang",
      "Qi Zhang",
      "Yuchi Ma",
      "Guangtai Liang",
      "Ying Li",
      "Qianxiang Wang",
      "Tao Xie"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2302.13875",
    "title": "Evaluating Robustness and Uncertainty of Graph Models Under Structural  Distributional Shifts",
    "abstract": " Title: Evaluating Robustness and Uncertainty of Graph Models Under Structural  Distributional Shifts ",
    "url": "https://arxiv.org/abs/2302.13875",
    "authors": [
      "Gleb Bazhenov",
      "Denis Kuznedelev",
      "Andrey Malinin",
      "Artem Babenko",
      "Liudmila Prokhorenkova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.07972",
    "title": "GoNet: An Approach-Constrained Generative Grasp Sampling Network",
    "abstract": " Comments: IEEE-RAS International Conference on Humanoid Robots (Humanoids 2023) ",
    "url": "https://arxiv.org/abs/2303.07972",
    "authors": [
      "Zehang Weng",
      "Haofei Lu",
      "Jens Lundell",
      "Danica Kragic"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.09863",
    "title": "Deep Nonparametric Estimation of Intrinsic Data Structures by Chart  Autoencoders: Generalization Error and Robustness",
    "abstract": " Title: Deep Nonparametric Estimation of Intrinsic Data Structures by Chart  Autoencoders: Generalization Error and Robustness ",
    "url": "https://arxiv.org/abs/2303.09863",
    "authors": [
      "Hao Liu",
      "Alex Havrilla",
      "Rongjie Lai",
      "Wenjing Liao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15556",
    "title": "Complexity of Reconfiguration in Surface Chemical Reaction Networks",
    "abstract": " Title: Complexity of Reconfiguration in Surface Chemical Reaction Networks ",
    "url": "https://arxiv.org/abs/2303.15556",
    "authors": [
      "Robert M. Alaniz",
      "Josh Brunner",
      "Michael Coulombe",
      "Erik D. Demaine",
      "Jenny Diomidov",
      "Ryan Knobel",
      "Timothy Gomez",
      "Elise Grizzell",
      "Jayson Lynch",
      "Andrew Rodriguez",
      "Robert Schweller",
      "Tim Wylie"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2303.16774",
    "title": "Polarization and multiscale structural balance in signed networks",
    "abstract": " Comments: 35 pages; 10 figures ",
    "url": "https://arxiv.org/abs/2303.16774",
    "authors": [
      "Szymon Talaga",
      "Massimo Stella",
      "Trevor James Swanson",
      "Andreia Sofia Teixeira"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2304.00170",
    "title": "Fixation probability in evolutionary dynamics on switching temporal  networks",
    "abstract": " Title: Fixation probability in evolutionary dynamics on switching temporal  networks ",
    "url": "https://arxiv.org/abs/2304.00170",
    "authors": [
      "Jnanajyoti Bhaumik",
      "Naoki Masuda"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2304.00488",
    "title": "Saddle-to-Saddle Dynamics in Diagonal Linear Networks",
    "abstract": " Title: Saddle-to-Saddle Dynamics in Diagonal Linear Networks ",
    "url": "https://arxiv.org/abs/2304.00488",
    "authors": [
      "Scott Pesme",
      "Nicolas Flammarion"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2304.03510",
    "title": "Multispectral Imaging for Differential Face Morphing Attack Detection: A  Preliminary Study",
    "abstract": " Comments: Accepted in IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2024 ",
    "url": "https://arxiv.org/abs/2304.03510",
    "authors": [
      "Raghavendra Ramachandra",
      "Sushma Venkatesh",
      "Naser Damer",
      "Narayan Vetrekar",
      "Rajendra Gad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.07485",
    "title": "Critical Sampling for Robust Evolution Operator Learning of Unknown  Dynamical Systems",
    "abstract": " Comments: Accepted by IEEE Transactions on Artificial Intelligence (IEEE TAI) ",
    "url": "https://arxiv.org/abs/2304.07485",
    "authors": [
      "Ce Zhang",
      "Kailiang Wu",
      "Zhihai He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2304.09097",
    "title": "Sheaf Neural Networks for Graph-based Recommender Systems",
    "abstract": " Comments: 9 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2304.09097",
    "authors": [
      "Antonio Purificato",
      "Giulia Cassar\u00e0",
      "Pietro Li\u00f2",
      "Fabrizio Silvestri"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.09576",
    "title": "Leveraging the two timescale regime to demonstrate convergence of neural  networks",
    "abstract": " Comments: NeurIPS 2023. 34 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2304.09576",
    "authors": [
      "Pierre Marion",
      "Rapha\u00ebl Berthier"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.00467",
    "title": "The iteration time and the general position number in graph convexities",
    "abstract": " Title: The iteration time and the general position number in graph convexities ",
    "url": "https://arxiv.org/abs/2305.00467",
    "authors": [
      "Julio Araujo",
      "Mitre C. Dourado",
      "F\u00e1bio Protti",
      "Rudini Sampaio"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2305.01094",
    "title": "Performative Prediction with Bandit Feedback: Learning through  Reparameterization",
    "abstract": " Title: Performative Prediction with Bandit Feedback: Learning through  Reparameterization ",
    "url": "https://arxiv.org/abs/2305.01094",
    "authors": [
      "Yatong Chen",
      "Wei Tang",
      "Chien-Ju Ho",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.04423",
    "title": "Robust Power Allocation for UAV-aided ISAC Systems with Uncertain  Location Sensing Errors",
    "abstract": " Title: Robust Power Allocation for UAV-aided ISAC Systems with Uncertain  Location Sensing Errors ",
    "url": "https://arxiv.org/abs/2305.04423",
    "authors": [
      "Junchang Sun",
      "Shuai Ma",
      "Ruixin Yang",
      "Yang Tingting",
      "Shiyin Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.04574",
    "title": "TAPS: Connecting Certified and Adversarial Training",
    "abstract": " Comments: NeuIPS'23 ",
    "url": "https://arxiv.org/abs/2305.04574",
    "authors": [
      "Yuhao Mao",
      "Mark Niklas M\u00fcller",
      "Marc Fischer",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.06343",
    "title": "Incorporating Structured Representations into Pretrained Vision &  Language Models Using Scene Graphs",
    "abstract": " Comments: EMNLP 2023 ",
    "url": "https://arxiv.org/abs/2305.06343",
    "authors": [
      "Roei Herzig",
      "Alon Mendelson",
      "Leonid Karlinsky",
      "Assaf Arbelle",
      "Rogerio Feris",
      "Trevor Darrell",
      "Amir Globerson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.11430",
    "title": "TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks",
    "abstract": " Comments: Accepted to EMNLP 2023 ",
    "url": "https://arxiv.org/abs/2305.11430",
    "authors": [
      "Shubhra Kanti Karmaker Santu",
      "Dongji Feng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.11772",
    "title": "Neural Foundations of Mental Simulation: Future Prediction of Latent  Representations on Dynamic Scenes",
    "abstract": " Comments: 20 pages, 10 figures, NeurIPS 2023 Camera Ready Version (spotlight) ",
    "url": "https://arxiv.org/abs/2305.11772",
    "authors": [
      "Aran Nayebi",
      "Rishi Rajalingham",
      "Mehrdad Jazayeri",
      "Guangyu Robert Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2305.12786",
    "title": "Mitigating Data Imbalance and Representation Degeneration in  Multilingual Machine Translation",
    "abstract": " Comments: Accepted to Findings of EMNLP 2023, add statistical significance tests. code available at this https URL ",
    "url": "https://arxiv.org/abs/2305.12786",
    "authors": [
      "Wen Lai",
      "Alexandra Chronopoulou",
      "Alexander Fraser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.15141",
    "title": "From Tempered to Benign Overfitting in ReLU Neural Networks",
    "abstract": " Comments: NeurIPS 2023 camera ready version ",
    "url": "https://arxiv.org/abs/2305.15141",
    "authors": [
      "Guy Kornowski",
      "Gilad Yehudai",
      "Ohad Shamir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.16475",
    "title": "Initialization-Dependent Sample Complexity of Linear Predictors and  Neural Networks",
    "abstract": " Comments: 30 pages ",
    "url": "https://arxiv.org/abs/2305.16475",
    "authors": [
      "Roey Magen",
      "Ohad Shamir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.16508",
    "title": "Most Neural Networks Are Almost Learnable",
    "abstract": " Comments: Small fixes after review ",
    "url": "https://arxiv.org/abs/2305.16508",
    "authors": [
      "Amit Daniely",
      "Nathan Srebro",
      "Gal Vardi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.18097",
    "title": "Performance Analysis of Discrete-Phase-Shifter IRS-aided  Amplify-and-Forward Relay Network",
    "abstract": " Title: Performance Analysis of Discrete-Phase-Shifter IRS-aided  Amplify-and-Forward Relay Network ",
    "url": "https://arxiv.org/abs/2305.18097",
    "authors": [
      "Rongen Dong",
      "Zhongyi Xie",
      "Feng Shu",
      "Mengxing Huang",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2306.01293",
    "title": "LoCoOp: Few-Shot Out-of-Distribution Detection via Prompt Learning",
    "abstract": " Comments: Accepted at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.01293",
    "authors": [
      "Atsuyuki Miyai",
      "Qing Yu",
      "Go Irie",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.02109",
    "title": "Encoding Time-Series Explanations through Self-Supervised Model Behavior  Consistency",
    "abstract": " Comments: Accepted to NeurIPS 2023 (spotlight) ",
    "url": "https://arxiv.org/abs/2306.02109",
    "authors": [
      "Owen Queen",
      "Thomas Hartvigsen",
      "Teddy Koker",
      "Huan He",
      "Theodoros Tsiligkaridis",
      "Marinka Zitnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.05501",
    "title": "Robust Framework for Explanation Evaluation in Time Series  Classification",
    "abstract": " Comments: Pre-print ",
    "url": "https://arxiv.org/abs/2306.05501",
    "authors": [
      "Thu Trang Nguyen",
      "Thach Le Nguyen",
      "Georgiana Ifrim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.09065",
    "title": "Node Cardinality Estimation in a Heterogeneous Wireless Network Deployed  Over a Large Region Using a Mobile Base Station",
    "abstract": " Comments: Accepted for publication at the 'Journal of Network and Computer Applications' (this https URL). It is an expanded version of the paper, which was presented at the IEEE SPCOM 2020 conference. DOI: 10.1109/SPCOM50965.2020.9179541 ",
    "url": "https://arxiv.org/abs/2306.09065",
    "authors": [
      "Sachin Kadam",
      "Kaustubh S. Bhargao",
      "Gaurav S. Kasbekar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.11974",
    "title": "Universal adversarial perturbations for multiple classification tasks  with quantum classifiers",
    "abstract": " Title: Universal adversarial perturbations for multiple classification tasks  with quantum classifiers ",
    "url": "https://arxiv.org/abs/2306.11974",
    "authors": [
      "Yun-Zhong Qiu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.15217",
    "title": "Unsupervised Episode Generation for Graph Meta-learning",
    "abstract": " Comments: 12 pages, 12 figures, Preprint version ",
    "url": "https://arxiv.org/abs/2306.15217",
    "authors": [
      "Jihyeong Jung",
      "Sangwoo Seo",
      "Sungwon Kim",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.15969",
    "title": "Separable Physics-Informed Neural Networks",
    "abstract": " Comments: To appear in NeurIPS 2023 (28 pages, 13 figures). arXiv admin note: text overlap with arXiv:2211.08761 ",
    "url": "https://arxiv.org/abs/2306.15969",
    "authors": [
      "Junwoo Cho",
      "Seungtae Nam",
      "Hyunmo Yang",
      "Seok-Bae Yun",
      "Youngjoon Hong",
      "Eunbyung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.01180",
    "title": "PlanE: Representation Learning over Planar Graphs",
    "abstract": " Comments: Proceedings of the Thirty-Seventh Annual Conference on Advances in Neural Information Processing Systems (NeurIPS 2023). Code and data available at: this https URL ",
    "url": "https://arxiv.org/abs/2307.01180",
    "authors": [
      "Radoslav Dimitrov",
      "Zeyang Zhao",
      "Ralph Abboud",
      "\u0130smail \u0130lkan Ceylan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.03305",
    "title": "A Vulnerability of Attribution Methods Using Pre-Softmax Scores",
    "abstract": " Comments: 7 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2307.03305",
    "authors": [
      "Miguel Lerma",
      "Mirtha Lucas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.11694",
    "title": "SynerGPT: In-Context Learning for Personalized Drug Synergy Prediction  and Drug Design",
    "abstract": " Title: SynerGPT: In-Context Learning for Personalized Drug Synergy Prediction  and Drug Design ",
    "url": "https://arxiv.org/abs/2307.11694",
    "authors": [
      "Carl Edwards",
      "Aakanksha Naik",
      "Tushar Khot",
      "Martin Burke",
      "Heng Ji",
      "Tom Hope"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Molecular Networks (q-bio.MN)"
    ]
  },
  {
    "id": "arXiv:2307.13885",
    "title": "Efficient Estimation of Average-Case Robustness for Multi-Class  Classification",
    "abstract": " Title: Efficient Estimation of Average-Case Robustness for Multi-Class  Classification ",
    "url": "https://arxiv.org/abs/2307.13885",
    "authors": [
      "Tessa Han",
      "Suraj Srinivas",
      "Himabindu Lakkaraju"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.15776",
    "title": "Select and Augment: Enhanced Dense Retrieval Knowledge Graph  Augmentation",
    "abstract": " Comments: Article has already been puclished to Journal of Artificial Intelligence Research (JAIR) ",
    "url": "https://arxiv.org/abs/2307.15776",
    "authors": [
      "Micheal Abaho",
      "Yousef H. Alfaifi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.06399",
    "title": "Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via  Mixed-Effect Models and Hierarchical Clustering",
    "abstract": " Comments: 34 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2308.06399",
    "authors": [
      "Lorenzo Valleggi",
      "Marco Scutari",
      "Federico Mattia Stefanini"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2308.06975",
    "title": "Can Knowledge Graphs Simplify Text?",
    "abstract": " Comments: Accepted as a Main Conference Long Paper at CIKM 2023 ",
    "url": "https://arxiv.org/abs/2308.06975",
    "authors": [
      "Anthony Colas",
      "Haodi Ma",
      "Xuanli He",
      "Yang Bai",
      "Daisy Zhe Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.04579",
    "title": "EGOFALLS: A visual-audio dataset and benchmark for fall detection using  egocentric cameras",
    "abstract": " Title: EGOFALLS: A visual-audio dataset and benchmark for fall detection using  egocentric cameras ",
    "url": "https://arxiv.org/abs/2309.04579",
    "authors": [
      "Xueyi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.06578",
    "title": "Can Large Language Models Discern Evidence for Scientific Hypotheses?  Case Studies in the Social Sciences",
    "abstract": " Title: Can Large Language Models Discern Evidence for Scientific Hypotheses?  Case Studies in the Social Sciences ",
    "url": "https://arxiv.org/abs/2309.06578",
    "authors": [
      "Sai Koneru",
      "Jian Wu",
      "Sarah Rajtmajer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.09725",
    "title": "Neural Collapse for Unconstrained Feature Model under Cross-entropy Loss  with Imbalanced Data",
    "abstract": " Comments: 38 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2309.09725",
    "authors": [
      "Wanli Hong",
      "Shuyang Ling"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2309.16928",
    "title": "Learning to Receive Help: Intervention-Aware Concept Embedding Models",
    "abstract": " Comments: Accepted as a spotlight at the Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023) ",
    "url": "https://arxiv.org/abs/2309.16928",
    "authors": [
      "Mateo Espinosa Zarlenga",
      "Katherine M. Collins",
      "Krishnamurthy Dvijotham",
      "Adrian Weller",
      "Zohreh Shams",
      "Mateja Jamnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01037",
    "title": "Seismogram Transformer: A generic deep learning backbone network for  multiple earthquake monitoring tasks",
    "abstract": " Title: Seismogram Transformer: A generic deep learning backbone network for  multiple earthquake monitoring tasks ",
    "url": "https://arxiv.org/abs/2310.01037",
    "authors": [
      "Sen Li",
      "Xu Yang",
      "Anye Cao",
      "Changbin Wang",
      "Yaoqi Liu",
      "Yapeng Liu",
      "Qiang Niu"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.02674",
    "title": "Land-cover change detection using paired OpenStreetMap data and optical  high-resolution imagery via object-guided Transformer",
    "abstract": " Title: Land-cover change detection using paired OpenStreetMap data and optical  high-resolution imagery via object-guided Transformer ",
    "url": "https://arxiv.org/abs/2310.02674",
    "authors": [
      "Hongruixuan Chen",
      "Cuiling Lan",
      "Jian Song",
      "Clifford Broni-Bediako",
      "Junshi Xia",
      "Naoto Yokoya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2310.04951",
    "title": "CodeTransOcean: A Comprehensive Multilingual Benchmark for Code  Translation",
    "abstract": " Comments: Accepted by Findings of EMNLP 2023 ",
    "url": "https://arxiv.org/abs/2310.04951",
    "authors": [
      "Weixiang Yan",
      "Yuchen Tian",
      "Yunzhe Li",
      "Qian Chen",
      "Wen Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2310.06754",
    "title": "Performance Analysis of RIS-assisted MIMO-OFDM Cellular Networks Based  on Matern Cluster Processes",
    "abstract": " Title: Performance Analysis of RIS-assisted MIMO-OFDM Cellular Networks Based  on Matern Cluster Processes ",
    "url": "https://arxiv.org/abs/2310.06754",
    "authors": [
      "Guodong Sun",
      "Francois Baccelli",
      "Ke Feng",
      "Luis Uzeda Garcia",
      "Stefano Paris"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2310.07440",
    "title": "Distance Weighted Trans Network for Image Completion",
    "abstract": " Title: Distance Weighted Trans Network for Image Completion ",
    "url": "https://arxiv.org/abs/2310.07440",
    "authors": [
      "Pourya Shamsolmoali",
      "Masoumeh Zareapoor",
      "Huiyu Zhou",
      "Xuelong Li",
      "Yue Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.08176",
    "title": "Infinite Width Graph Neural Networks for Node Regression/ Classification",
    "abstract": " Comments: 49 Pages, 2 Figures (with subfigures), multiple tables, made table of contents fit to one page and added Derivatives on GAT*NTK and GAT*GP in A.4 ",
    "url": "https://arxiv.org/abs/2310.08176",
    "authors": [
      "Yunus Cobanoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10316",
    "title": "Spectral representation of two-sided signals from $\\ell_\\infty$ and  applications to signal processing",
    "abstract": " Title: Spectral representation of two-sided signals from $\\ell_\\infty$ and  applications to signal processing ",
    "url": "https://arxiv.org/abs/2310.10316",
    "authors": [
      "Nikolai Dokuchaev"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Functional Analysis (math.FA)"
    ]
  },
  {
    "id": "arXiv:2310.11069",
    "title": "VoxArabica: A Robust Dialect-Aware Arabic Speech Recognition System",
    "abstract": " Comments: Accepted at ArabicNLP conference co-located with EMNLP'23. First three authors contributed equally ",
    "url": "https://arxiv.org/abs/2310.11069",
    "authors": [
      "Abdul Waheed",
      "Bashar Talafha",
      "Peter Suvellin",
      "AbdelRahim Elmadany",
      "Muhammad Abdul-Mageed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.12541",
    "title": "Large Language Model for Multi-objective Evolutionary Optimization",
    "abstract": " Title: Large Language Model for Multi-objective Evolutionary Optimization ",
    "url": "https://arxiv.org/abs/2310.12541",
    "authors": [
      "Fei Liu",
      "Xi Lin",
      "Zhenkun Wang",
      "Shunyu Yao",
      "Xialiang Tong",
      "Mingxuan Yuan",
      "Qingfu Zhang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2310.13276",
    "title": "InvGC: Robust Cross-Modal Retrieval by Inverse Graph Convolution",
    "abstract": " Comments: Findings of EMNLP 2023 ",
    "url": "https://arxiv.org/abs/2310.13276",
    "authors": [
      "Xiangru Jian",
      "Yimu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2310.13447",
    "title": "Multiscale Superpixel Structured Difference Graph Convolutional Network  for VL Representation",
    "abstract": " Title: Multiscale Superpixel Structured Difference Graph Convolutional Network  for VL Representation ",
    "url": "https://arxiv.org/abs/2310.13447",
    "authors": [
      "Siyu Zhang",
      "Yeming Chen",
      "Sirui Cheng",
      "Yaoru Sun",
      "Jun Yang",
      "Lizhi Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.14480",
    "title": "Attention-Enhancing Backdoor Attacks Against BERT-based Models",
    "abstract": " Comments: Findings of EMNLP 2023 ",
    "url": "https://arxiv.org/abs/2310.14480",
    "authors": [
      "Weimin Lyu",
      "Songzhu Zheng",
      "Lu Pang",
      "Haibin Ling",
      "Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.14563",
    "title": "NormDial: A Comparable Bilingual Synthetic Dialog Dataset for Modeling  Social Norm Adherence and Violation",
    "abstract": " Comments: EMNLP 2023 Main Conference, Short Paper; Data at this https URL ",
    "url": "https://arxiv.org/abs/2310.14563",
    "authors": [
      "Oliver Li",
      "Mallika Subramanian",
      "Arkadiy Saakyan",
      "Sky CH-Wang",
      "Smaranda Muresan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.15074",
    "title": "MGAS: Multi-Granularity Architecture Search for Effective and Efficient  Neural Networks",
    "abstract": " Title: MGAS: Multi-Granularity Architecture Search for Effective and Efficient  Neural Networks ",
    "url": "https://arxiv.org/abs/2310.15074",
    "authors": [
      "Xiaoyun Liu",
      "Divya Saxena",
      "Jiannong Cao",
      "Yuqing Zhao",
      "Penghui Ruan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.15614",
    "title": "Sparse Bayesian neural networks for regression: Tackling overfitting and  computational challenges in uncertainty quantification",
    "abstract": " Title: Sparse Bayesian neural networks for regression: Tackling overfitting and  computational challenges in uncertainty quantification ",
    "url": "https://arxiv.org/abs/2310.15614",
    "authors": [
      "Nastaran Dabiran",
      "Brandon Robinson",
      "Rimple Sandhu",
      "Mohammad Khalil",
      "Dominique Poirel",
      "Abhijit Sarkar"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2310.15669",
    "title": "Robust Methods for Multiscale Coarse Approximations of Diffusion Models  in Perforated Domains",
    "abstract": " Comments: 32 pages, 14 figures, submitted to Journal of Computational Physics ",
    "url": "https://arxiv.org/abs/2310.15669",
    "authors": [
      "Miranda Boutilier",
      "Konstantin Brenner",
      "Victorita Dolean"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.15952",
    "title": "Improving Robustness and Reliability in Medical Image Classification  with Latent-Guided Diffusion and Nested-Ensembles",
    "abstract": " Comments: 13 pages, 6 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2310.15952",
    "authors": [
      "Xing Shen",
      "Hengguan Huang",
      "Brennan Nichyporuk",
      "Tal Arbel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]