[
  {
    "id": "arXiv:2310.01418",
    "title": "Cordyceps@LT-EDI: Depression Detection with Reddit and Self-training",
    "abstract": "Depression is debilitating, and not uncommon. Indeed, studies of excessive social media users show correlations with depression, ADHD, and other mental health concerns. Given that there is a large number of people with excessive social media usage, then there is a significant population of potentially undiagnosed users and posts that they create. In this paper, we propose a depression severity detection system using a semi-supervised learning technique to predict if a post is from a user who is experiencing severe, moderate, or low (non-diagnostic) levels of depression. Namely, we use a trained model to classify a large number of unlabelled social media posts from Reddit, then use these generated labels to train a more powerful classifier. We demonstrate our framework on Detecting Signs of Depression from Social Media Text - LT-EDI@RANLP 2023 shared task, where our framework ranks 3rd overall. ",
    "url": "https://arxiv.org/abs/2310.01418",
    "authors": [
      "Dean Ninalga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01419",
    "title": "Design Principles of Robust Multi-Armed Bandit Framework in Video  Recommendations",
    "abstract": "Current multi-armed bandit approaches in recommender systems (RS) have focused more on devising effective exploration techniques, while not adequately addressing common exploitation challenges related to distributional changes and item cannibalization. Little work exists to guide the design of robust bandit frameworks that can address these frequent challenges in RS. In this paper, we propose a new design principles to (i) make bandit models robust to time-variant metadata signals, (ii) less prone to item cannibalization, and (iii) prevent their weights fluctuating due to data sparsity. Through a series of experiments, we systematically examine the influence of several important bandit design choices. We demonstrate the advantage of our proposed design principles at making bandit models robust to dynamic behavioral changes through in-depth analyses. Noticeably, we show improved relative gain compared to a baseline bandit model not incorporating our design choices of up to $11.88\\%$ and $44.85\\%$, respectively in ROC-AUC and PR-AUC. Case studies about fairness in recommending specific popular and unpopular titles are presented, to demonstrate the robustness of our proposed design at addressing popularity biases. ",
    "url": "https://arxiv.org/abs/2310.01419",
    "authors": [
      "Belhassen Bayar",
      "Phanideep Gampa",
      "Ainur Yessenalina",
      "Zhen Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01423",
    "title": "An Empirical Study of AI Generated Text Detection Tools",
    "abstract": "Since ChatGPT has emerged as a major AIGC model, providing high-quality responses across a wide range of applications (including software development and maintenance), it has attracted much interest from many individuals. ChatGPT has great promise, but there are serious problems that might arise from its misuse, especially in the realms of education and public safety. Several AIGC detectors are available, and they have all been tested on genuine text. However, more study is needed to see how effective they are for multi-domain ChatGPT material. This study aims to fill this need by creating a multi-domain dataset for testing the state-of-the-art APIs and tools for detecting artificially generated information used by universities and other research institutions. A large dataset consisting of articles, abstracts, stories, news, and product reviews was created for this study. The second step is to use the newly created dataset to put six tools through their paces. Six different artificial intelligence (AI) text identification systems, including \"GPTkit,\" \"GPTZero,\" \"Originality,\" \"Sapling,\" \"Writer,\" and \"Zylalab,\" have accuracy rates between 55.29 and 97.0%. Although all the tools fared well in the evaluations, originality was particularly effective across the board. ",
    "url": "https://arxiv.org/abs/2310.01423",
    "authors": [
      "Arslan Akram"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01424",
    "title": "Identifying and Mitigating Privacy Risks Stemming from Language Models:  A Survey",
    "abstract": "Rapid advancements in language models (LMs) have led to their adoption across many sectors. Alongside the potential benefits, such models present a range of risks, including around privacy. In particular, as LMs have grown in size, the potential to memorise aspects of their training data has increased, resulting in the risk of leaking private information. As LMs become increasingly widespread, it is vital that we understand such privacy risks and how they might be mitigated. To help researchers and policymakers understand the state of knowledge around privacy attacks and mitigations, including where more work is needed, we present the first technical survey on LM privacy. We (i) identify a taxonomy of salient dimensions where attacks differ on LMs, (ii) survey existing attacks and use our taxonomy of dimensions to highlight key trends, (iii) discuss existing mitigation strategies, highlighting their strengths and limitations, identifying key gaps and demonstrating open problems and areas for concern. ",
    "url": "https://arxiv.org/abs/2310.01424",
    "authors": [
      "Victoria Smith",
      "Ali Shahin Shamsabadi",
      "Carolyn Ashurst",
      "Adrian Weller"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01430",
    "title": "Sarcasm in Sight and Sound: Benchmarking and Expansion to Improve  Multimodal Sarcasm Detection",
    "abstract": "The introduction of the MUStARD dataset, and its emotion recognition extension MUStARD++, have identified sarcasm to be a multi-modal phenomenon -- expressed not only in natural language text, but also through manners of speech (like tonality and intonation) and visual cues (facial expression). With this work, we aim to perform a rigorous benchmarking of the MUStARD++ dataset by considering state-of-the-art language, speech, and visual encoders, for fully utilizing the totality of the multi-modal richness that it has to offer, achieving a 2\\% improvement in macro-F1 over the existing benchmark. Additionally, to cure the imbalance in the `sarcasm type' category in MUStARD++, we propose an extension, which we call \\emph{MUStARD++ Balanced}, benchmarking the same with instances from the extension split across both train and test sets, achieving a further 2.4\\% macro-F1 boost. The new clips were taken from a novel source -- the TV show, House MD, which adds to the diversity of the dataset, and were manually annotated by multiple annotators with substantial inter-annotator agreement in terms of Cohen's kappa and Krippendorf's alpha. Our code, extended data, and SOTA benchmark models are made public. ",
    "url": "https://arxiv.org/abs/2310.01430",
    "authors": [
      "Swapnil Bhosale",
      "Abhra Chaudhuri",
      "Alex Lee Robert Williams",
      "Divyank Tiwari",
      "Anjan Dutta",
      "Xiatian Zhu",
      "Pushpak Bhattacharyya",
      "Diptesh Kanojia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01436",
    "title": "Graph Neural Architecture Search with GPT-4",
    "abstract": "Graph Neural Architecture Search (GNAS) has shown promising results in automatically designing graph neural networks. However, GNAS still requires intensive human labor with rich domain knowledge to design the search space and search strategy. In this paper, we integrate GPT-4 into GNAS and propose a new GPT-4 based Graph Neural Architecture Search method (GPT4GNAS for short). The basic idea of our method is to design a new class of prompts for GPT-4 to guide GPT-4 toward the generative task of graph neural architectures. The prompts consist of descriptions of the search space, search strategy, and search feedback of GNAS. By iteratively running GPT-4 with the prompts, GPT4GNAS generates more accurate graph neural networks with fast convergence. Experimental results show that embedding GPT-4 into GNAS outperforms the state-of-the-art GNAS methods. ",
    "url": "https://arxiv.org/abs/2310.01436",
    "authors": [
      "Haishuai Wang",
      "Yang Gao",
      "Xin Zheng",
      "Peng Zhang",
      "Hongyang Chen",
      "Jiajun Bu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01443",
    "title": "Quantum-Based Feature Selection for Multi-classification Problem in  Complex Systems with Edge Computing",
    "abstract": "The complex systems with edge computing require a huge amount of multi-feature data to extract appropriate insights for their decision making, so it is important to find a feasible feature selection method to improve the computational efficiency and save the resource consumption. In this paper, a quantum-based feature selection algorithm for the multi-classification problem, namely, QReliefF, is proposed, which can effectively reduce the complexity of algorithm and improve its computational efficiency. First, all features of each sample are encoded into a quantum state by performing operations CMP and R_y, and then the amplitude estimation is applied to calculate the similarity between any two quantum states (i.e., two samples). According to the similarities, the Grover-Long method is utilized to find the nearest k neighbor samples, and then the weight vector is updated. After a certain number of iterations through the above process, the desired features can be selected with regards to the final weight vector and the threshold {\\tau}. Compared with the classical ReliefF algorithm, our algorithm reduces the complexity of similarity calculation from O(MN) to O(M), the complexity of finding the nearest neighbor from O(M) to O(sqrt(M)), and resource consumption from O(MN) to O(MlogN). Meanwhile, compared with the quantum Relief algorithm, our algorithm is superior in finding the nearest neighbor, reducing the complexity from O(M) to O(sqrt(M)). Finally, in order to verify the feasibility of our algorithm, a simulation experiment based on Rigetti with a simple example is performed. ",
    "url": "https://arxiv.org/abs/2310.01443",
    "authors": [
      "Wenjie Liu",
      "Junxiu Chen",
      "Yuxiang Wang",
      "Peipei Gao",
      "Zhibin Lei",
      "Xu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2310.01469",
    "title": "LLM Lies: Hallucinations are not Bugs, but Features as Adversarial  Examples",
    "abstract": "Large Language Models (LLMs), including GPT-3.5, LLaMA, and PaLM, seem to be knowledgeable and able to adapt to many tasks. However, we still can not completely trust their answer, since LLMs suffer from hallucination--fabricating non-existent facts to cheat users without perception. And the reasons for their existence and pervasiveness remain unclear. In this paper, we demonstrate that non-sense prompts composed of random tokens can also elicit the LLMs to respond with hallucinations. This phenomenon forces us to revisit that hallucination may be another view of adversarial examples, and it shares similar features with conventional adversarial examples as the basic feature of LLMs. Therefore, we formalize an automatic hallucination triggering method as the hallucination attack in an adversarial way. Finally, we explore basic feature of attacked adversarial prompts and propose a simple yet effective defense strategy. Our code is released on GitHub. ",
    "url": "https://arxiv.org/abs/2310.01469",
    "authors": [
      "Jia-Yu Yao",
      "Kun-Peng Ning",
      "Zhen-Hui Liu",
      "Mu-Nan Ning",
      "Li Yuan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01506",
    "title": "Direct Inversion: Boosting Diffusion-based Editing with 3 Lines of Code",
    "abstract": "Text-guided diffusion models have revolutionized image generation and editing, offering exceptional realism and diversity. Specifically, in the context of diffusion-based editing, where a source image is edited according to a target prompt, the process commences by acquiring a noisy latent vector corresponding to the source image via the diffusion model. This vector is subsequently fed into separate source and target diffusion branches for editing. The accuracy of this inversion process significantly impacts the final editing outcome, influencing both essential content preservation of the source image and edit fidelity according to the target prompt. Prior inversion techniques aimed at finding a unified solution in both the source and target diffusion branches. However, our theoretical and empirical analyses reveal that disentangling these branches leads to a distinct separation of responsibilities for preserving essential content and ensuring edit fidelity. Building on this insight, we introduce \"Direct Inversion,\" a novel technique achieving optimal performance of both branches with just three lines of code. To assess image editing performance, we present PIE-Bench, an editing benchmark with 700 images showcasing diverse scenes and editing types, accompanied by versatile annotations and comprehensive evaluation metrics. Compared to state-of-the-art optimization-based inversion techniques, our solution not only yields superior performance across 8 editing methods but also achieves nearly an order of speed-up. ",
    "url": "https://arxiv.org/abs/2310.01506",
    "authors": [
      "Xuan Ju",
      "Ailing Zeng",
      "Yuxuan Bian",
      "Shaoteng Liu",
      "Qiang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.01519",
    "title": "Decision-Oriented Intervention Cost Prediction for Multi-robot  Persistent Monitoring",
    "abstract": "In this paper, we present a differentiable, decision-oriented learning technique for a class of vehicle routing problems. Specifically, we consider a scenario where a team of Unmanned Aerial Vehicles (UAVs) and Unmanned Ground Vehicles (UGVs) are persistently monitoring an environment. The UGVs are occasionally taken over by humans to take detours to recharge the depleted UAVs. The goal is to select routes for the UGVs so that they can efficiently monitor the environment while reducing the cost of interventions. The former is modeled as a monotone, submodular function whereas the latter is a linear function of the routes of the UGVs. We consider a scenario where the former is known but the latter depends on the context (e.g., wind and terrain conditions) that must be learned. Typically, we first learn to predict the cost function and then solve the optimization problem. However, the loss function used in prediction may be misaligned with our final goal of finding good routes. We propose a \\emph{decision-oriented learning} framework that incorporates task optimization as a differentiable layer in the prediction phase. To make the task optimization (which is a non-monotone submodular function) differentiable, we propose the Differentiable Cost Scaled Greedy algorithm. We demonstrate the efficacy of the proposed framework through numerical simulations. The results show that the proposed framework can result in better performance than the traditional approach. ",
    "url": "https://arxiv.org/abs/2310.01519",
    "authors": [
      "Guangyao Shi",
      "Chak Lam Shek",
      "Nare Karapetyan",
      "Pratap Tokekar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.01526",
    "title": "Modern code reviews -- Preliminary results of a systematic mapping study",
    "abstract": "Reviewing source code is a common practice in a modern and collaborative coding environment. In the past few years, the research on modern code reviews has gained interest among practitioners and researchers. The objective of our investigation is to observe the evolution of research related to modern code reviews, identify research gaps and serve as a basis for future research. We use a systematic mapping approach to identify and classify 177 research papers. As preliminary result of our investigation, we present in this paper a classification scheme of the main contributions of modern code review research between 2005 and 2018. ",
    "url": "https://arxiv.org/abs/2310.01526",
    "authors": [
      "Deepika Badampudi",
      "Ricardo Britto",
      "Michael Unterkalmsteiner"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.01537",
    "title": "Adversarial Client Detection via Non-parametric Subspace Monitoring in  the Internet of Federated Things",
    "abstract": "The Internet of Federated Things (IoFT) represents a network of interconnected systems with federated learning as the backbone, facilitating collaborative knowledge acquisition while ensuring data privacy for individual systems. The wide adoption of IoFT, however, is hindered by security concerns, particularly the susceptibility of federated learning networks to adversarial attacks. In this paper, we propose an effective non-parametric approach FedRR, which leverages the low-rank features of the transmitted parameter updates generated by federated learning to address the adversarial attack problem. Besides, our proposed method is capable of accurately detecting adversarial clients and controlling the false alarm rate under the scenario with no attack occurring. Experiments based on digit recognition using the MNIST datasets validated the advantages of our approach. ",
    "url": "https://arxiv.org/abs/2310.01537",
    "authors": [
      "Xianjian Xie",
      "Xiaochen Xian",
      "Dan Li",
      "Andi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01546",
    "title": "Decentralization Cheapens Corruptive Majority Attacks",
    "abstract": "Corruptive majority attacks, in which mining power is distributed among miners and an attacker attempts to bribe a majority of miners into participation in a majority attack, pose a threat to blockchains. Budish bounded the cost of bribing miners to participate in an attack by their expected loss as a result of attack success. We show that this bound is loose. In particular, an attack may be structured so that under equilibrium play by most miners, a miner's choice to participate only slightly affects the attack success chance. Combined with the fact that most of the cost of attack success is externalized by any given small miner, this implies that if most mining power is controlled by small miners, bribing miners to participate in such an attack is much cheaper than the Budish bound. We provide a scheme for a cheap corruptive majority attack and discuss practical concerns and consequences. ",
    "url": "https://arxiv.org/abs/2310.01546",
    "authors": [
      "Stephen H. Newman"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2310.01558",
    "title": "Making Retrieval-Augmented Language Models Robust to Irrelevant Context",
    "abstract": "Retrieval-augmented language models (RALMs) hold promise to produce language understanding systems that are are factual, efficient, and up-to-date. An important desideratum of RALMs, is that retrieved information helps model performance when it is relevant, and does not harm performance when it is not. This is particularly important in multi-hop reasoning scenarios, where misuse of irrelevant evidence can lead to cascading errors. However, recent work has shown that retrieval augmentation can sometimes have a negative effect on performance. In this work, we present a thorough analysis on five open-domain question answering benchmarks, characterizing cases when retrieval reduces accuracy. We then propose two methods to mitigate this issue. First, a simple baseline that filters out retrieved passages that do not entail question-answer pairs according to a natural language inference (NLI) model. This is effective in preventing performance reduction, but at a cost of also discarding relevant passages. Thus, we propose a method for automatically generating data to fine-tune the language model to properly leverage retrieved passages, using a mix of relevant and irrelevant contexts at training time. We empirically show that even 1,000 examples suffice to train the model to be robust to irrelevant contexts while maintaining high performance on examples with relevant ones. ",
    "url": "https://arxiv.org/abs/2310.01558",
    "authors": [
      "Ori Yoran",
      "Tomer Wolfson",
      "Ori Ram",
      "Jonathan Berant"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01565",
    "title": "Causality-informed Rapid Post-hurricane Building Damage Detection in  Large Scale from InSAR Imagery",
    "abstract": "Timely and accurate assessment of hurricane-induced building damage is crucial for effective post-hurricane response and recovery efforts. Recently, remote sensing technologies provide large-scale optical or Interferometric Synthetic Aperture Radar (InSAR) imagery data immediately after a disastrous event, which can be readily used to conduct rapid building damage assessment. Compared to optical satellite imageries, the Synthetic Aperture Radar can penetrate cloud cover and provide more complete spatial coverage of damaged zones in various weather conditions. However, these InSAR imageries often contain highly noisy and mixed signals induced by co-occurring or co-located building damage, flood, flood/wind-induced vegetation changes, as well as anthropogenic activities, making it challenging to extract accurate building damage information. In this paper, we introduced an approach for rapid post-hurricane building damage detection from InSAR imagery. This approach encoded complex causal dependencies among wind, flood, building damage, and InSAR imagery using a holistic causal Bayesian network. Based on the causal Bayesian network, we further jointly inferred the large-scale unobserved building damage by fusing the information from InSAR imagery with prior physical models of flood and wind, without the need for ground truth labels. Furthermore, we validated our estimation results in a real-world devastating hurricane -- the 2022 Hurricane Ian. We gathered and annotated building damage ground truth data in Lee County, Florida, and compared the introduced method's estimation results with the ground truth and benchmarked it against state-of-the-art models to assess the effectiveness of our proposed method. Results show that our method achieves rapid and accurate detection of building damage, with significantly reduced processing time compared to traditional manual inspection methods. ",
    "url": "https://arxiv.org/abs/2310.01565",
    "authors": [
      "Chenguang Wang",
      "Yepeng Liu",
      "Xiaojian Zhang",
      "Xuechun Li",
      "Vladimir Paramygin",
      "Arthriya Subgranon",
      "Peter Sheng",
      "Xilei Zhao",
      "Susu Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.01568",
    "title": "Defending Against Authorship Identification Attacks",
    "abstract": "Authorship identification has proven unsettlingly effective in inferring the identity of the author of an unsigned document, even when sensitive personal information has been carefully omitted. In the digital era, individuals leave a lasting digital footprint through their written content, whether it is posted on social media, stored on their employer's computers, or located elsewhere. When individuals need to communicate publicly yet wish to remain anonymous, there is little available to protect them from unwanted authorship identification. This unprecedented threat to privacy is evident in scenarios such as whistle-blowing. Proposed defenses against authorship identification attacks primarily aim to obfuscate one's writing style, thereby making it unlinkable to their pre-existing writing, while concurrently preserving the original meaning and grammatical integrity. The presented work offers a comprehensive review of the advancements in this research area spanning over the past two decades and beyond. It emphasizes the methodological frameworks of modification and generation-based strategies devised to evade authorship identification attacks, highlighting joint efforts from the differential privacy community. Limitations of current research are discussed, with a spotlight on open challenges and potential research avenues. ",
    "url": "https://arxiv.org/abs/2310.01568",
    "authors": [
      "Haining Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.01580",
    "title": "Active Learning on Neural Networks through Interactive Generation of  Digit Patterns and Visual Representation",
    "abstract": "Artificial neural networks (ANNs) have been broadly utilized to analyze various data and solve different domain problems. However, neural networks (NNs) have been considered a black box operation for years because their underlying computation and meaning are hidden. Due to this nature, users often face difficulties in interpreting the underlying mechanism of the NNs and the benefits of using them. In this paper, to improve users' learning and understanding of NNs, an interactive learning system is designed to create digit patterns and recognize them in real time. To help users clearly understand the visual differences of digit patterns (i.e., 0 ~ 9) and their results with an NN, integrating visualization is considered to present all digit patterns in a two-dimensional display space with supporting multiple user interactions. An evaluation with multiple datasets is conducted to determine its usability for active learning. In addition, informal user testing is managed during a summer workshop by asking the workshop participants to use the system. ",
    "url": "https://arxiv.org/abs/2310.01580",
    "authors": [
      "Dong H. Jeong",
      "Jin-Hee Cho",
      "Feng Chen",
      "Audun Josang",
      "Soo-Yeon Ji"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01595",
    "title": "Memory-efficient particle filter recurrent neural network for object  localization",
    "abstract": "This study proposes a novel memory-efficient recurrent neural network (RNN) architecture specified to solve the object localization problem. This problem is to recover the object states along with its movement in a noisy environment. We take the idea of the classical particle filter and combine it with GRU RNN architecture. The key feature of the resulting memory-efficient particle filter RNN model (mePFRNN) is that it requires the same number of parameters to process environments of different sizes. Thus, the proposed mePFRNN architecture consumes less memory to store parameters compared to the previously proposed PFRNN model. To demonstrate the performance of our model, we test it on symmetric and noisy environments that are incredibly challenging for filtering algorithms. In our experiments, the mePFRNN model provides more precise localization than the considered competitors and requires fewer trained parameters. ",
    "url": "https://arxiv.org/abs/2310.01595",
    "authors": [
      "Roman Korkin",
      "Ivan Oseledets",
      "Aleksandr Katrutsa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01602",
    "title": "CAT-LM: Training Language Models on Aligned Code And Tests",
    "abstract": "Testing is an integral part of the software development process. Yet, writing tests is time-consuming and therefore often neglected. Classical test generation tools such as EvoSuite generate behavioral test suites by optimizing for coverage, but tend to produce tests that are hard to understand. Language models trained on code can generate code that is highly similar to that written by humans, but current models are trained to generate each file separately, as is standard practice in natural language processing, and thus fail to consider the code-under-test context when producing a test file. In this work, we propose the Aligned Code And Tests Language Model (CAT-LM), a GPT-style language model with 2.7 Billion parameters, trained on a corpus of Python and Java projects. We utilize a novel pretraining signal that explicitly considers the mapping between code and test files when available. We also drastically increase the maximum sequence length of inputs to 8,192 tokens, 4x more than typical code generation models, to ensure that the code context is available to the model when generating test code. We analyze its usefulness for realistic applications, showing that sampling with filtering (e.g., by compilability, coverage) allows it to efficiently produce tests that achieve coverage similar to ones written by developers while resembling their writing style. By utilizing the code context, CAT-LM generates more valid tests than even much larger language models trained with more data (CodeGen 16B and StarCoder) and substantially outperforms a recent test-specific model (TeCo) at test completion. Overall, our work highlights the importance of incorporating software-specific insights when training language models for code and paves the way to more powerful automated test generation. ",
    "url": "https://arxiv.org/abs/2310.01602",
    "authors": [
      "Nikitha Rao",
      "Kush Jain",
      "Uri Alon",
      "Claire Le Goues",
      "Vincent J. Hellendoorn"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01618",
    "title": "Operator Learning Meets Numerical Analysis: Improving Neural Networks  through Iterative Methods",
    "abstract": "Deep neural networks, despite their success in numerous applications, often function without established theoretical foundations. In this paper, we bridge this gap by drawing parallels between deep learning and classical numerical analysis. By framing neural networks as operators with fixed points representing desired solutions, we develop a theoretical framework grounded in iterative methods for operator equations. Under defined conditions, we present convergence proofs based on fixed point theory. We demonstrate that popular architectures, such as diffusion models and AlphaFold, inherently employ iterative operator learning. Empirical assessments highlight that performing iterations through network operators improves performance. We also introduce an iterative graph neural network, PIGN, that further demonstrates benefits of iterations. Our work aims to enhance the understanding of deep learning by merging insights from numerical analysis, potentially guiding the design of future networks with clearer theoretical underpinnings and improved performance. ",
    "url": "https://arxiv.org/abs/2310.01618",
    "authors": [
      "Emanuele Zappala",
      "Daniel Levine",
      "Sizhuang He",
      "Syed Rizvi",
      "Sacha Levy",
      "David van Dijk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.01626",
    "title": "Model Explanation via Support Graphs",
    "abstract": "In this note, we introduce the notion of support graph to define explanations for any model of a logic program. An explanation is an acyclic support graph that, for each true atom in the model, induces a proof in terms of program rules represented by labels. A classical model may have zero, one or several explanations: when it has at least one, it is called a justified model. We prove that all stable models are justified whereas, in general, the opposite does not hold, at least for disjunctive programs. We also provide a meta-programming encoding in Answer Set Programming that generates the explanations for a given stable model of some program. We prove that the encoding is sound and complete, that is, there is a one-to-one correspondence between each answer set of the encoding and each explanation for the original stable model. ",
    "url": "https://arxiv.org/abs/2310.01626",
    "authors": [
      "Pedro Cabalar",
      "Brais Mu\u00f1iz"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2310.01633",
    "title": "Distributionally Robust Path Integral Control",
    "abstract": "We consider a continuous-time continuous-space stochastic optimal control problem, where the controller lacks exact knowledge of the underlying diffusion process, relying instead on a finite set of historical disturbance trajectories. In situations where data collection is limited, the controller synthesized from empirical data may exhibit poor performance. To address this issue, we introduce a novel approach named Distributionally Robust Path Integral (DRPI). The proposed method employs distributionally robust optimization (DRO) to robustify the resulting policy against the unknown diffusion process. Notably, the DRPI scheme shows similarities with risk-sensitive control, which enables us to utilize the path integral control (PIC) framework as an efficient solution scheme. We derive theoretical performance guarantees for the DRPI scheme, which closely aligns with selecting a risk parameter in risk-sensitive control. We validate the efficacy of our scheme and showcase its superiority when compared to risk-neutral PIC policies in the absence of the true diffusion process. ",
    "url": "https://arxiv.org/abs/2310.01633",
    "authors": [
      "Hyuk Park",
      "Duo Zhou",
      "Grani A. Hanasusanto",
      "Takashi Tanaka"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.01634",
    "title": "Deep Insights into Noisy Pseudo Labeling on Graph Data",
    "abstract": "Pseudo labeling (PL) is a wide-applied strategy to enlarge the labeled dataset by self-annotating the potential samples during the training process. Several works have shown that it can improve the graph learning model performance in general. However, we notice that the incorrect labels can be fatal to the graph training process. Inappropriate PL may result in the performance degrading, especially on graph data where the noise can propagate. Surprisingly, the corresponding error is seldom theoretically analyzed in the literature. In this paper, we aim to give deep insights of PL on graph learning models. We first present the error analysis of PL strategy by showing that the error is bounded by the confidence of PL threshold and consistency of multi-view prediction. Then, we theoretically illustrate the effect of PL on convergence property. Based on the analysis, we propose a cautious pseudo labeling methodology in which we pseudo label the samples with highest confidence and multi-view consistency. Finally, extensive experiments demonstrate that the proposed strategy improves graph learning process and outperforms other PL strategies on link prediction and node classification tasks. ",
    "url": "https://arxiv.org/abs/2310.01634",
    "authors": [
      "Botao Wang",
      "Jia Li",
      "Yang Liu",
      "Jiashun Cheng",
      "Yu Rong",
      "Wenjia Wang",
      "Fugee Tsung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01636",
    "title": "Adaptive Visual Scene Understanding: Incremental Scene Graph Generation",
    "abstract": "Scene graph generation (SGG) involves analyzing images to extract meaningful information about objects and their relationships. Given the dynamic nature of the visual world, it becomes crucial for AI systems to detect new objects and establish their new relationships with existing objects. To address the lack of continual learning methodologies in SGG, we introduce the comprehensive Continual ScenE Graph Generation (CSEGG) dataset along with 3 learning scenarios and 8 evaluation metrics. Our research investigates the continual learning performances of existing SGG methods on the retention of previous object entities and relationships as they learn new ones. Moreover, we also explore how continual object detection enhances generalization in classifying known relationships on unknown objects. We conduct extensive experiments benchmarking and analyzing the classical two-stage SGG methods and the most recent transformer-based SGG methods in continual learning settings, and gain valuable insights into the CSEGG problem. We invite the research community to explore this emerging field of study. ",
    "url": "https://arxiv.org/abs/2310.01636",
    "authors": [
      "Naitik Khandelwal",
      "Xiao Liu",
      "Mengmi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.01646",
    "title": "Strategic Information Attacks on Incentive-Compatible Navigational  Recommendations in Intelligent Transportation Systems",
    "abstract": "Intelligent transportation systems (ITS) have gained significant attention from various communities, driven by rapid advancements in informational technology. Within the realm of ITS, navigational recommendation systems (RS) play a pivotal role, as users often face diverse path (route) options in such complex urban environments. However, RS is not immune to vulnerabilities, especially when confronted with potential information-based attacks. This study aims to explore the impacts of these cyber threats on RS, explicitly focusing on local targeted information attacks in which the attacker favors certain groups or businesses. We study human behaviors and propose the coordinated incentive-compatible RS that guides users toward a mixed Nash equilibrium, under which each user has no incentive to deviate from the recommendation. Then, we delve into the vulnerabilities within the recommendation process, focusing on scenarios involving misinformed demands. In such cases, the attacker can fabricate fake users to mislead the RS's recommendations. Using the Stackelberg game approach, the analytical results and the numerical case study reveal that RS is susceptible to informational attacks. This study highlights the need to consider informational attacks for a more resilient and effective navigational recommendation. ",
    "url": "https://arxiv.org/abs/2310.01646",
    "authors": [
      "Ya-Ting Yang",
      "Haozhe Lei",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.01649",
    "title": "On Training Derivative-Constrained Neural Networks",
    "abstract": "We refer to the setting where the (partial) derivatives of a neural network's (NN's) predictions with respect to its inputs are used as additional training signal as a derivative-constrained (DC) NN. This situation is common in physics-informed settings in the natural sciences. We propose an integrated RELU (IReLU) activation function to improve training of DC NNs. We also investigate denormalization and label rescaling to help stabilize DC training. We evaluate our methods on physics-informed settings including quantum chemistry and Scientific Machine Learning (SciML) tasks. We demonstrate that existing architectures with IReLU activations combined with denormalization and label rescaling better incorporate training signal provided by derivative constraints. ",
    "url": "https://arxiv.org/abs/2310.01649",
    "authors": [
      "KaiChieh Lo",
      "Daniel Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01663",
    "title": "Task-guided Domain Gap Reduction for Monocular Depth Prediction in  Endoscopy",
    "abstract": "Colorectal cancer remains one of the deadliest cancers in the world. In recent years computer-aided methods have aimed to enhance cancer screening and improve the quality and availability of colonoscopies by automatizing sub-tasks. One such task is predicting depth from monocular video frames, which can assist endoscopic navigation. As ground truth depth from standard in-vivo colonoscopy remains unobtainable due to hardware constraints, two approaches have aimed to circumvent the need for real training data: supervised methods trained on labeled synthetic data and self-supervised models trained on unlabeled real data. However, self-supervised methods depend on unreliable loss functions that struggle with edges, self-occlusion, and lighting inconsistency. Methods trained on synthetic data can provide accurate depth for synthetic geometries but do not use any geometric supervisory signal from real data and overfit to synthetic anatomies and properties. This work proposes a novel approach to leverage labeled synthetic and unlabeled real data. While previous domain adaptation methods indiscriminately enforce the distributions of both input data modalities to coincide, we focus on the end task, depth prediction, and translate only essential information between the input domains. Our approach results in more resilient and accurate depth maps of real colonoscopy sequences. ",
    "url": "https://arxiv.org/abs/2310.01663",
    "authors": [
      "Anita Rau",
      "Binod Bhattarai",
      "Lourdes Agapito",
      "Danail Stoyanov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.01675",
    "title": "Decision-Dominant Strategic Defense Against Lateral Movement for 5G  Zero-Trust Multi-Domain Networks",
    "abstract": "Multi-domain warfare is a military doctrine that leverages capabilities from different domains, including air, land, sea, space, and cyberspace, to create a highly interconnected battle network that is difficult for adversaries to disrupt or defeat. However, the adoption of 5G technologies on battlefields presents new vulnerabilities due to the complexity of interconnections and the diversity of software, hardware, and devices from different supply chains. Therefore, establishing a zero-trust architecture for 5G-enabled networks is crucial for continuous monitoring and fast data analytics to protect against targeted attacks. To address these challenges, we propose a proactive end-to-end security scheme that utilizes a 5G satellite-guided air-ground network. Our approach incorporates a decision-dominant learning-based method that can thwart the lateral movement of adversaries targeting critical assets on the battlefield before they can conduct reconnaissance or gain necessary access or credentials. We demonstrate the effectiveness of our game-theoretic design, which uses a meta-learning framework to enable zero-trust monitoring and decision-dominant defense against attackers in emerging multi-domain battlefield networks. ",
    "url": "https://arxiv.org/abs/2310.01675",
    "authors": [
      "Tao Li",
      "Yunian Pan",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.01680",
    "title": "Keypoint-Augmented Self-Supervised Learning for Medical Image  Segmentation with Limited Annotation",
    "abstract": "Pretraining CNN models (i.e., UNet) through self-supervision has become a powerful approach to facilitate medical image segmentation under low annotation regimes. Recent contrastive learning methods encourage similar global representations when the same image undergoes different transformations, or enforce invariance across different image/patch features that are intrinsically correlated. However, CNN-extracted global and local features are limited in capturing long-range spatial dependencies that are essential in biological anatomy. To this end, we present a keypoint-augmented fusion layer that extracts representations preserving both short- and long-range self-attention. In particular, we augment the CNN feature map at multiple scales by incorporating an additional input that learns long-range spatial self-attention among localized keypoint features. Further, we introduce both global and local self-supervised pretraining for the framework. At the global scale, we obtain global representations from both the bottleneck of the UNet, and by aggregating multiscale keypoint features. These global features are subsequently regularized through image-level contrastive objectives. At the local scale, we define a distance-based criterion to first establish correspondences among keypoints and encourage similarity between their features. Through extensive experiments on both MRI and CT segmentation tasks, we demonstrate the architectural advantages of our proposed method in comparison to both CNN and Transformer-based UNets, when all architectures are trained with randomly initialized weights. With our proposed pretraining strategy, our method further outperforms existing SSL methods by producing more robust self-attention and achieving state-of-the-art segmentation results. The code is available at https://github.com/zshyang/kaf.git. ",
    "url": "https://arxiv.org/abs/2310.01680",
    "authors": [
      "Zhangsihao Yang",
      "Mengwei Ren",
      "Kaize Ding",
      "Guido Gerig",
      "Yalin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01686",
    "title": "OFDM-RSMA: Robust Transmission under Inter-Carrier Interference",
    "abstract": "Rate-splitting multiple access (RSMA) is a multiple access scheme to mitigate the effects of the multi-user interference (MUI) in multi-antenna systems. In this study, we leverage the interference management capabilities of RSMA to tackle the issue of inter-carrier interference (ICI) in orthogonal frequency division multiplexing (OFDM) waveform. We formulate a sum-rate maximization problem to find the optimal subcarrier and power allocation for downlink transmission in a two-user system using RSMA and OFDM. A weighted minimum mean-square error (WMMSE)-based algorithm is proposed to obtain a solution for the formulated non-convex problem. We show that the marriage of rate-splitting (RS) with OFDM provides complementary strengths to cope with peculiar characteristic of wireless medium and its performance-limiting challenges including inter-symbol interference (ISI), MUI, ICI, and inter-numerology interference (INI). The sum-rate performance of the proposed OFDM-RSMA scheme is numerically compared with that of conventional orthogonal frequency division multiple access (OFDMA) and OFDM-non-orthogonal multiple access (NOMA). It is shown that the proposed OFDM-RSMA outperforms OFDM-NOMA and OFDMA in diverse propagation channel conditions owing to its flexible structure and robust interference management capabilities. ",
    "url": "https://arxiv.org/abs/2310.01686",
    "authors": [
      "Mehmet Mert Sahin",
      "Onur Dizdar",
      "Bruno Clerckx",
      "Huseyin Arslan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.01689",
    "title": "Threat Modelling in Internet of Things (IoT) Environment Using Dynamic  Attack Graphs",
    "abstract": "We present a threat modelling approach to represent changes to the attack paths through an Internet of Things (IoT) environment when the environment changes dynamically, i.e., when new devices are added or removed from the system or when whole sub-systems join or leave. The proposed approach investigates the propagation of threats using attack graphs. However, traditional attack graph approaches have been applied in static environments that do not continuously change such as the Enterprise networks, leading to static and usually very large attack graphs. In contrast, IoT environments are often characterised by dynamic change and interconnections; different topologies for different systems may interconnect with each other dynamically and outside the operator control. Such new interconnections lead to changes in the reachability amongst devices according to which their corresponding attack graphs change. This requires dynamic topology and attack graphs for threat and risk analysis. In this paper, we develop a threat modelling approach that cope with dynamic system changes that may occur in IoT environments and enables identifying attack paths whilst allowing for system dynamics. We develop dynamic topology and attack graphs that are able to cope with the changes in the IoT environment rapidly by maintaining their associated graphs. To motivate the work and illustrate our approach we introduce an example scenario based on healthcare systems. Our approach is implemented using a Graph Database Management Tool (GDBM) -- Neo4j -- which is a popular tool for mapping, visualising and querying the graphs of highly connected data, and is efficient in providing a rapid threat modelling mechanism, which makes it suitable for capturing security changes in the dynamic IoT environment. ",
    "url": "https://arxiv.org/abs/2310.01689",
    "authors": [
      "Marwa Salayma",
      "Emil C Lupu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.01693",
    "title": "Closing the Curious Case of Neural Text Degeneration",
    "abstract": "Despite their ubiquity in language generation, it remains unknown why truncation sampling heuristics like nucleus sampling are so effective. We provide a theoretical explanation for the effectiveness of the truncation sampling by proving that truncation methods that discard tokens below some probability threshold (the most common type of truncation) can guarantee that all sampled tokens have nonzero true probability. However, thresholds are a coarse heuristic, and necessarily discard some tokens with nonzero true probability as well. In pursuit of a more precise sampling strategy, we show that we can leverage a known source of model errors, the softmax bottleneck, to prove that certain tokens have nonzero true probability, without relying on a threshold. Based on our findings, we develop an experimental truncation strategy and the present pilot studies demonstrating the promise of this type of algorithm. Our evaluations show that our method outperforms its threshold-based counterparts under automatic and human evaluation metrics for low-entropy (i.e., close to greedy) open-ended text generation. Our theoretical findings and pilot experiments provide both insight into why truncation sampling works, and make progress toward more expressive sampling algorithms that better surface the generative capabilities of large language models. ",
    "url": "https://arxiv.org/abs/2310.01693",
    "authors": [
      "Matthew Finlayson",
      "John Hewitt",
      "Alexander Koller",
      "Swabha Swayamdipta",
      "Ashish Sabharwal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.01696",
    "title": "DANI: Fast Diffusion Aware Network Inference with Preserving Topological  Structure Property",
    "abstract": "The fast growth of social networks and their data access limitations in recent years has led to increasing difficulty in obtaining the complete topology of these networks. However, diffusion information over these networks is available, and many algorithms have been proposed to infer the underlying networks using this information. The previously proposed algorithms only focus on inferring more links and ignore preserving the critical topological characteristics of the underlying social networks. In this paper, we propose a novel method called DANI to infer the underlying network while preserving its structural properties. It is based on the Markov transition matrix derived from time series cascades, as well as the node-node similarity that can be observed in the cascade behavior from a structural point of view. In addition, the presented method has linear time complexity (increases linearly with the number of nodes, number of cascades, and square of the average length of cascades), and its distributed version in the MapReduce framework is also scalable. We applied the proposed approach to both real and synthetic networks. The experimental results showed that DANI has higher accuracy and lower run time while maintaining structural properties, including modular structure, degree distribution, connected components, density, and clustering coefficients, than well-known network inference methods. ",
    "url": "https://arxiv.org/abs/2310.01696",
    "authors": [
      "Maryam Ramezani",
      "Aryan Ahadinia",
      "Erfan Farhadi",
      "Hamid R. Rabiee"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01704",
    "title": "Transformers are efficient hierarchical chemical graph learners",
    "abstract": "Transformers, adapted from natural language processing, are emerging as a leading approach for graph representation learning. Contemporary graph transformers often treat nodes or edges as separate tokens. This approach leads to computational challenges for even moderately-sized graphs due to the quadratic scaling of self-attention complexity with token count. In this paper, we introduce SubFormer, a graph transformer that operates on subgraphs that aggregate information by a message-passing mechanism. This approach reduces the number of tokens and enhances learning long-range interactions. We demonstrate SubFormer on benchmarks for predicting molecular properties from chemical structures and show that it is competitive with state-of-the-art graph transformers at a fraction of the computational cost, with training times on the order of minutes on a consumer-grade graphics card. We interpret the attention weights in terms of chemical structures. We show that SubFormer exhibits limited over-smoothing and avoids over-squashing, which is prevalent in traditional graph neural networks. ",
    "url": "https://arxiv.org/abs/2310.01704",
    "authors": [
      "Zihan Pengmei",
      "Zimu Li",
      "Chih-chan Tien",
      "Risi Kondor",
      "Aaron R. Dinner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01706",
    "title": "On Representation Complexity of Model-based and Model-free Reinforcement  Learning",
    "abstract": "We study the representation complexity of model-based and model-free reinforcement learning (RL) in the context of circuit complexity. We prove theoretically that there exists a broad class of MDPs such that their underlying transition and reward functions can be represented by constant depth circuits with polynomial size, while the optimal $Q$-function suffers an exponential circuit complexity in constant-depth circuits. By drawing attention to the approximation errors and building connections to complexity theory, our theory provides unique insights into why model-based algorithms usually enjoy better sample complexity than model-free algorithms from a novel representation complexity perspective: in some cases, the ground-truth rule (model) of the environment is simple to represent, while other quantities, such as $Q$-function, appear complex. We empirically corroborate our theory by comparing the approximation error of the transition kernel, reward function, and optimal $Q$-function in various Mujoco environments, which demonstrates that the approximation errors of the transition kernel and reward function are consistently lower than those of the optimal $Q$-function. To the best of our knowledge, this work is the first to study the circuit complexity of RL, which also provides a rigorous framework for future research. ",
    "url": "https://arxiv.org/abs/2310.01706",
    "authors": [
      "Hanlin Zhu",
      "Baihe Huang",
      "Stuart Russell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01711",
    "title": "Learning Class-Specific Spectral Patterns to Improve Deep Learning Based  Scene-Level Fire Smoke Detection from Multi-Spectral Satellite Imagery",
    "abstract": "Detecting fire smoke is crucial for the timely identification of early wildfires using satellite imagery. However, the spatial and spectral similarity of fire smoke to other confounding aerosols, such as clouds and haze, often confuse even the most advanced deep-learning (DL) models. Nonetheless, these aerosols also present distinct spectral characteristics in some specific bands, and such spectral patterns are useful for distinguishing the aerosols more accurately. Early research tried to derive various threshold values from the reflectance and brightness temperature in specific spectral bands to differentiate smoke and cloud pixels. However, such threshold values were determined based on domain knowledge and are hard to generalise. In addition, such threshold values were manually derived from specific combinations of bands to infer spectral patterns, making them difficult to employ in deep-learning models. In this paper, we introduce a DL module called input amplification (InAmp) which is designed to enable DL models to learn class-specific spectral patterns automatically from multi-spectral satellite imagery and improve the fire smoke detection accuracy. InAmp can be conveniently integrated with different DL architectures. We evaluate the effectiveness of the InAmp module on different Convolutional neural network (CNN) architectures using two satellite imagery datasets: USTC_SmokeRS, derived from Moderate Resolution Imaging Spectroradiometer (MODIS) with three spectral bands; and Landsat_Smk, derived from Landsat 5/8 with six spectral bands. Our experimental results demonstrate that the InAmp module improves the fire smoke detection accuracy of the CNN models. Additionally, we visualise the spectral patterns extracted by the InAmp module using test imagery and demonstrate that the InAmp module can effectively extract class-specific spectral patterns. ",
    "url": "https://arxiv.org/abs/2310.01711",
    "authors": [
      "Liang Zhao",
      "Jixue Liu",
      "Stefan Peters",
      "Jiuyong Li",
      "Norman Mueller",
      "Simon Oliver"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.01719",
    "title": "Software Testing and Code Refactoring: A Survey with Practitioners",
    "abstract": "Nowadays, software testing professionals are commonly required to develop coding skills to work on test automation. One essential skill required from those who code is the ability to implement code refactoring, a valued quality aspect of software development; however, software developers usually encounter obstacles in successfully applying this practice. In this scenario, the present study aims to explore how software testing professionals (e.g., software testers, test engineers, test analysts, and software QAs) deal with code refactoring to understand the benefits and limitations of this practice in the context of software testing. We followed the guidelines to conduct surveys in software engineering and applied three sampling techniques, namely convenience sampling, purposive sampling, and snowballing sampling, to collect data from testing professionals. We received answers from 80 individuals reporting their experience refactoring the code of automated tests. We concluded that in the context of software testing, refactoring offers several benefits, such as supporting the maintenance of automated tests and improving the performance of the testing team. However, practitioners might encounter barriers in effectively implementing this practice, in particular, the lack of interest from managers and leaders. Our study raises discussions on the importance of having testing professionals implement refactoring in the code of automated tests, allowing them to improve their coding abilities. ",
    "url": "https://arxiv.org/abs/2310.01719",
    "authors": [
      "Danilo Leandro Lima",
      "Ronnie de Souza Santos",
      "Guilherme Pires Garcia",
      "Sildemir S. da Silva",
      "Cesar Franca",
      "Luiz Fernando Capretz"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.01732",
    "title": "Nugget: Neural Agglomerative Embeddings of Text",
    "abstract": "Embedding text sequences is a widespread requirement in modern language understanding. Existing approaches focus largely on constant-size representations. This is problematic, as the amount of information contained in text often varies with the length of the input. We propose a solution called Nugget, which encodes language into a representation based on a dynamically selected subset of input tokens. These nuggets are learned through tasks like autoencoding and machine translation, and intuitively segment language into meaningful units. We demonstrate Nugget outperforms related approaches in tasks involving semantic comparison. Finally, we illustrate these compact units allow for expanding the contextual window of a language model (LM), suggesting new future LMs that can condition on significantly larger amounts of content. ",
    "url": "https://arxiv.org/abs/2310.01732",
    "authors": [
      "Guanghui Qin",
      "Benjamin Van Durme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01737",
    "title": "Blending Imitation and Reinforcement Learning for Robust Policy  Improvement",
    "abstract": "While reinforcement learning (RL) has shown promising performance, its sample complexity continues to be a substantial hurdle, restricting its broader application across a variety of domains. Imitation learning (IL) utilizes oracles to improve sample efficiency, yet it is often constrained by the quality of the oracles deployed. which actively interleaves between IL and RL based on an online estimate of their performance. RPI draws on the strengths of IL, using oracle queries to facilitate exploration, an aspect that is notably challenging in sparse-reward RL, particularly during the early stages of learning. As learning unfolds, RPI gradually transitions to RL, effectively treating the learned policy as an improved oracle. This algorithm is capable of learning from and improving upon a diverse set of black-box oracles. Integral to RPI are Robust Active Policy Selection (RAPS) and Robust Policy Gradient (RPG), both of which reason over whether to perform state-wise imitation from the oracles or learn from its own value function when the learner's performance surpasses that of the oracles in a specific state. Empirical evaluations and theoretical analysis validate that RPI excels in comparison to existing state-of-the-art methodologies, demonstrating superior performance across various benchmark domains. ",
    "url": "https://arxiv.org/abs/2310.01737",
    "authors": [
      "Xuefeng Liu",
      "Takuma Yoneda",
      "Rick L. Stevens",
      "Matthew R. Walter",
      "Yuxin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.01747",
    "title": "5G Network Slicing: Analysis of Multiple Machine Learning Classifiers",
    "abstract": "The division of one physical 5G communications infrastructure into several virtual network slices with distinct characteristics such as bandwidth, latency, reliability, security, and service quality is known as 5G network slicing. Each slice is a separate logical network that meets the requirements of specific services or use cases, such as virtual reality, gaming, autonomous vehicles, or industrial automation. The network slice can be adjusted dynamically to meet the changing demands of the service, resulting in a more cost-effective and efficient approach to delivering diverse services and applications over a shared infrastructure. This paper assesses various machine learning techniques, including the logistic regression model, linear discriminant model, k-nearest neighbor's model, decision tree model, random forest model, SVC BernoulliNB model, and GaussianNB model, to investigate the accuracy and precision of each model on detecting network slices. The report also gives an overview of 5G network slicing. ",
    "url": "https://arxiv.org/abs/2310.01747",
    "authors": [
      "Mirsad Malkoc",
      "Hisham A. Kholidy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01753",
    "title": "CausalTime: Realistically Generated Time-series for Benchmarking of  Causal Discovery",
    "abstract": "Time-series causal discovery (TSCD) is a fundamental problem of machine learning. However, existing synthetic datasets cannot properly evaluate or predict the algorithms' performance on real data. This study introduces the CausalTime pipeline to generate time-series that highly resemble the real data and with ground truth causal graphs for quantitative performance evaluation. The pipeline starts from real observations in a specific scenario and produces a matching benchmark dataset. Firstly, we harness deep neural networks along with normalizing flow to accurately capture realistic dynamics. Secondly, we extract hypothesized causal graphs by performing importance analysis on the neural network or leveraging prior knowledge. Thirdly, we derive the ground truth causal graphs by splitting the causal model into causal term, residual term, and noise term. Lastly, using the fitted network and the derived causal graph, we generate corresponding versatile time-series proper for algorithm assessment. In the experiments, we validate the fidelity of the generated data through qualitative and quantitative experiments, followed by a benchmarking of existing TSCD algorithms using these generated datasets. CausalTime offers a feasible solution to evaluating TSCD algorithms in real applications and can be generalized to a wide range of fields. For easy use of the proposed approach, we also provide a user-friendly website, hosted on www.causaltime.cc. ",
    "url": "https://arxiv.org/abs/2310.01753",
    "authors": [
      "Yuxiao Cheng",
      "Ziqian Wang",
      "Tingxiong Xiao",
      "Qin Zhong",
      "Jinli Suo",
      "Kunlun He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.01755",
    "title": "ImageNet-OOD: Deciphering Modern Out-of-Distribution Detection  Algorithms",
    "abstract": "The task of out-of-distribution (OOD) detection is notoriously ill-defined. Earlier works focused on new-class detection, aiming to identify label-altering data distribution shifts, also known as \"semantic shift.\" However, recent works argue for a focus on failure detection, expanding the OOD evaluation framework to account for label-preserving data distribution shifts, also known as \"covariate shift.\" Intriguingly, under this new framework, complex OOD detectors that were previously considered state-of-the-art now perform similarly to, or even worse than the simple maximum softmax probability baseline. This raises the question: what are the latest OOD detectors actually detecting? Deciphering the behavior of OOD detection algorithms requires evaluation datasets that decouples semantic shift and covariate shift. To aid our investigations, we present ImageNet-OOD, a clean semantic shift dataset that minimizes the interference of covariate shift. Through comprehensive experiments, we show that OOD detectors are more sensitive to covariate shift than to semantic shift, and the benefits of recent OOD detection algorithms on semantic shift detection is minimal. Our dataset and analyses provide important insights for guiding the design of future OOD detectors. ",
    "url": "https://arxiv.org/abs/2310.01755",
    "authors": [
      "William Yang",
      "Byron Zhang",
      "Olga Russakovsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.01758",
    "title": "Linearization of ReLU Activation Function for Neural Network-Embedded  Optimization:Optimal Day-Ahead Energy Scheduling",
    "abstract": "Neural networks have been widely applied in the power system area. They can be used for better predicting input information and modeling system performance with increased accuracy. In some applications such as battery degradation neural network-based microgrid day-ahead energy scheduling, the input features of the trained learning model are variables to be solved in optimization models that enforce limits on the output of the same learning model. This will create a neural network-embedded optimization problem; the use of nonlinear activation functions in the neural network will make such problems extremely hard to solve if not unsolvable. To address this emerging challenge, this paper investigated different methods for linearizing the nonlinear activation functions with a particular focus on the widely used rectified linear unit (ReLU) function. Four linearization methods tailored for the ReLU activation function are developed, analyzed and compared in this paper. Each method employs a set of linear constraints to replace the ReLU function, effectively linearizing the optimization problem, which can overcome the computational challenges associated with the nonlinearity of the neural network model. These proposed linearization methods provide valuable tools for effectively solving optimization problems that integrate neural network models with ReLU activation functions. ",
    "url": "https://arxiv.org/abs/2310.01758",
    "authors": [
      "Cunzhi Zhao",
      "Xingpeng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.01770",
    "title": "A simple connection from loss flatness to compressed representations in  neural networks",
    "abstract": "Deep neural networks' generalization capacity has been studied in a variety of ways, including at least two distinct categories of approach: one based on the shape of the loss landscape in parameter space, and the other based on the structure of the representation manifold in feature space (that is, in the space of unit activities). These two approaches are related, but they are rarely studied together and explicitly connected. Here, we present a simple analysis that makes such a connection. We show that, in the last phase of learning of deep neural networks, compression of the volume of the manifold of neural representations correlates with the flatness of the loss around the minima explored by ongoing parameter optimization. We show that this is predicted by a relatively simple mathematical relationship: loss flatness implies compression of neural representations. Our results build closely on prior work of \\citet{ma_linear_2021}, which shows how flatness (i.e., small eigenvalues of the loss Hessian) develops in late phases of learning and lead to robustness to perturbations in network inputs. Moreover, we show there is no similarly direct connection between local dimensionality and sharpness, suggesting that this property may be controlled by different mechanisms than volume and hence may play a complementary role in neural representations. Overall, we advance a dual perspective on generalization in neural networks in both parameter and feature space. ",
    "url": "https://arxiv.org/abs/2310.01770",
    "authors": [
      "Shirui Chen",
      "Stefano Recanatesi",
      "Eric Shea-Brown"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01780",
    "title": "Social Optimal Freshness in Multi-Source, Multi-Channel Systems via MDP",
    "abstract": "Many systems necessitate frequent and consistent updates of a specific information. Often this information is updated regularly, where an old packet becomes completely obsolete in the presence of a new packet. In this context, we consider a system with multiple sources, each equipped with a storage buffer of size one, communicating to a common destination via d orthogonal channels. In each slot, the packets arrive at each source with certain probability and occupy the buffer (by discarding the old packet if any), and each transfer (to the destination) is successful with certain other probability. Thus in any slot, there are two (Age of Information) AoI-measures for each source: one corresponding to the information at the source itself and the other corresponding to the information of the same source available at the destination; some sources may not even have the packet to transmit. The aim of the controller at the destination is to maintain the freshness of information of all the sources, to the best extent possible -- it aims to design an optimal scheduling policy that assigns in each slot, a subset of sources with packets (at maximum d) for transmission. This is achieved using an appropriate Markov Decision Process (MDP) framework, where the objective function is the sum of Average AoIs (AAoI) of all the sources. We derive a very simple stationary policy that is epsilon-optimal -- in any slot, order the sources with packets in the decreasing order of the differences in AoI at the destination and the source and choose the top sources for transmission. With moderate number of sources (less than 30), the AAoI reduces in the range of 30-90%. ",
    "url": "https://arxiv.org/abs/2310.01780",
    "authors": [
      "Shiksha Singhal",
      "Veeraruna Kavitha",
      "Vidya Shankar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2310.01794",
    "title": "GNNX-BENCH: Unravelling the Utility of Perturbation-based GNN Explainers  through In-depth Benchmarking",
    "abstract": "Numerous explainability methods have been proposed to shed light on the inner workings of GNNs. Despite the inclusion of empirical evaluations in all the proposed algorithms, the interrogative aspects of these evaluations lack diversity. As a result, various facets of explainability pertaining to GNNs, such as a comparative analysis of counterfactual reasoners, their stability to variational factors such as different GNN architectures, noise, stochasticity in non-convex loss surfaces, feasibility amidst domain constraints, and so forth, have yet to be formally investigated. Motivated by this need, we present a benchmarking study on perturbation-based explainability methods for GNNs, aiming to systematically evaluate and compare a wide range of explainability techniques. Among the key findings of our study, we identify the Pareto-optimal methods that exhibit superior efficacy and stability in the presence of noise. Nonetheless, our study reveals that all algorithms are affected by stability issues when faced with noisy data. Furthermore, we have established that the current generation of counterfactual explainers often fails to provide feasible recourses due to violations of topological constraints encoded by domain-specific considerations. Overall, this benchmarking study empowers stakeholders in the field of GNNs with a comprehensive understanding of the state-of-the-art explainability methods, potential research problems for further enhancement, and the implications of their application in real-world scenarios. ",
    "url": "https://arxiv.org/abs/2310.01794",
    "authors": [
      "Mert Kosan",
      "Samidha Verma",
      "Burouj Armgaan",
      "Khushbu Pahwa",
      "Ambuj Singh",
      "Sourav Medya",
      "Sayan Ranu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01795",
    "title": "TempoNet: Empowering long-term Knee Joint Angle Prediction with Dynamic  Temporal Attention in Exoskeleton Control",
    "abstract": "In the realm of exoskeleton control, achieving precise control poses challenges due to the mechanical delay of exoskeletons. To address this, incorporating future gait trajectories as feed-forward input has been proposed. However, existing deep learning models for gait prediction mainly focus on short-term predictions, leaving the long-term performance of these models relatively unexplored. In this study, we present TempoNet, a novel model specifically designed for precise knee joint angle prediction. By harnessing dynamic temporal attention within the Transformer-based architecture, TempoNet surpasses existing models in forecasting knee joint angles over extended time horizons. Notably, our model achieves a remarkable reduction of 10\\% to 185\\% in Mean Absolute Error (MAE) for 100 ms ahead forecasting compared to other transformer-based models, demonstrating its effectiveness. Furthermore, TempoNet exhibits further reliability and superiority over the baseline Transformer model, outperforming it by 14\\% in MAE for the 200 ms prediction horizon. These findings highlight the efficacy of TempoNet in accurately predicting knee joint angles and emphasize the importance of incorporating dynamic temporal attention. TempoNet's capability to enhance knee joint angle prediction accuracy opens up possibilities for precise control, improved rehabilitation outcomes, advanced sports performance analysis, and deeper insights into biomechanical research. Code implementation for the TempoNet model can be found in the GitHub repository: https://github.com/LyesSaadSaoud/TempoNet. ",
    "url": "https://arxiv.org/abs/2310.01795",
    "authors": [
      "Lyes Saad Saoud",
      "Irfan Hussain"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2310.01818",
    "title": "AutoLoRa: A Parameter-Free Automated Robust Fine-Tuning Framework",
    "abstract": "Robust Fine-Tuning (RFT) is a low-cost strategy to obtain adversarial robustness in downstream applications, without requiring a lot of computational resources and collecting significant amounts of data. This paper uncovers an issue with the existing RFT, where optimizing both adversarial and natural objectives through the feature extractor (FE) yields significantly divergent gradient directions. This divergence introduces instability in the optimization process, thereby hindering the attainment of adversarial robustness and rendering RFT highly sensitive to hyperparameters. To mitigate this issue, we propose a low-rank (LoRa) branch that disentangles RFT into two distinct components: optimizing natural objectives via the LoRa branch and adversarial objectives via the FE. Besides, we introduce heuristic strategies for automating the scheduling of the learning rate and the scalars of loss terms. Extensive empirical evaluations demonstrate that our proposed automated RFT disentangled via the LoRa branch (AutoLoRa) achieves new state-of-the-art results across a range of downstream tasks. AutoLoRa holds significant practical utility, as it automatically converts a pre-trained FE into an adversarially robust model for downstream tasks without the need for searching hyperparameters. ",
    "url": "https://arxiv.org/abs/2310.01818",
    "authors": [
      "Xilie Xu",
      "Jingfeng Zhang",
      "Mohan Kankanhalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.01820",
    "title": "Towards Robust Fidelity for Evaluating Explainability of Graph Neural  Networks",
    "abstract": "Graph Neural Networks (GNNs) are neural models that leverage the dependency structure in graphical data via message passing among the graph nodes. GNNs have emerged as pivotal architectures in analyzing graph-structured data, and their expansive application in sensitive domains requires a comprehensive understanding of their decision-making processes -- necessitating a framework for GNN explainability. An explanation function for GNNs takes a pre-trained GNN along with a graph as input, to produce a `sufficient statistic' subgraph with respect to the graph label. A main challenge in studying GNN explainability is to provide fidelity measures that evaluate the performance of these explanation functions. This paper studies this foundational challenge, spotlighting the inherent limitations of prevailing fidelity metrics, including $Fid_+$, $Fid_-$, and $Fid_\\Delta$. Specifically, a formal, information-theoretic definition of explainability is introduced and it is shown that existing metrics often fail to align with this definition across various statistical scenarios. The reason is due to potential distribution shifts when subgraphs are removed in computing these fidelity measures. Subsequently, a robust class of fidelity measures are introduced, and it is shown analytically that they are resilient to distribution shift issues and are applicable in a wide range of scenarios. Extensive empirical analysis on both synthetic and real datasets are provided to illustrate that the proposed metrics are more coherent with gold standard metrics. ",
    "url": "https://arxiv.org/abs/2310.01820",
    "authors": [
      "Xu Zheng",
      "Farhad Shirani",
      "Tianchun Wang",
      "Wei Cheng",
      "Zhuomin Chen",
      "Haifeng Chen",
      "Hua Wei",
      "Dongsheng Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01821",
    "title": "MIMO-NeRF: Fast Neural Rendering with Multi-input Multi-output Neural  Radiance Fields",
    "abstract": "Neural radiance fields (NeRFs) have shown impressive results for novel view synthesis. However, they depend on the repetitive use of a single-input single-output multilayer perceptron (SISO MLP) that maps 3D coordinates and view direction to the color and volume density in a sample-wise manner, which slows the rendering. We propose a multi-input multi-output NeRF (MIMO-NeRF) that reduces the number of MLPs running by replacing the SISO MLP with a MIMO MLP and conducting mappings in a group-wise manner. One notable challenge with this approach is that the color and volume density of each point can differ according to a choice of input coordinates in a group, which can lead to some notable ambiguity. We also propose a self-supervised learning method that regularizes the MIMO MLP with multiple fast reformulated MLPs to alleviate this ambiguity without using pretrained models. The results of a comprehensive experimental evaluation including comparative and ablation studies are presented to show that MIMO-NeRF obtains a good trade-off between speed and quality with a reasonable training time. We then demonstrate that MIMO-NeRF is compatible with and complementary to previous advancements in NeRFs by applying it to two representative fast NeRFs, i.e., a NeRF with sample reduction (DONeRF) and a NeRF with alternative representations (TensoRF). ",
    "url": "https://arxiv.org/abs/2310.01821",
    "authors": [
      "Takuhiro Kaneko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.01840",
    "title": "Self-Supervised High Dynamic Range Imaging with Multi-Exposure Images in  Dynamic Scenes",
    "abstract": "Merging multi-exposure images is a common approach for obtaining high dynamic range (HDR) images, with the primary challenge being the avoidance of ghosting artifacts in dynamic scenes. Recent methods have proposed using deep neural networks for deghosting. However, the methods typically rely on sufficient data with HDR ground-truths, which are difficult and costly to collect. In this work, to eliminate the need for labeled data, we propose SelfHDR, a self-supervised HDR reconstruction method that only requires dynamic multi-exposure images during training. Specifically, SelfHDR learns a reconstruction network under the supervision of two complementary components, which can be constructed from multi-exposure images and focus on HDR color as well as structure, respectively. The color component is estimated from aligned multi-exposure images, while the structure one is generated through a structure-focused network that is supervised by the color component and an input reference (\\eg, medium-exposure) image. During testing, the learned reconstruction network is directly deployed to predict an HDR image. Experiments on real-world images demonstrate our SelfHDR achieves superior results against the state-of-the-art self-supervised methods, and comparable performance to supervised ones. Codes are available at https://github.com/cszhilu1998/SelfHDR ",
    "url": "https://arxiv.org/abs/2310.01840",
    "authors": [
      "Zhilu Zhang",
      "Haoyu Wang",
      "Shuai Liu",
      "Xiaotao Wang",
      "Lei Lei",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.01842",
    "title": "SelfGraphVQA: A Self-Supervised Graph Neural Network for Scene-based  Question Answering",
    "abstract": "The intersection of vision and language is of major interest due to the increased focus on seamless integration between recognition and reasoning. Scene graphs (SGs) have emerged as a useful tool for multimodal image analysis, showing impressive performance in tasks such as Visual Question Answering (VQA). In this work, we demonstrate that despite the effectiveness of scene graphs in VQA tasks, current methods that utilize idealized annotated scene graphs struggle to generalize when using predicted scene graphs extracted from images. To address this issue, we introduce the SelfGraphVQA framework. Our approach extracts a scene graph from an input image using a pre-trained scene graph generator and employs semantically-preserving augmentation with self-supervised techniques. This method improves the utilization of graph representations in VQA tasks by circumventing the need for costly and potentially biased annotated data. By creating alternative views of the extracted graphs through image augmentations, we can learn joint embeddings by optimizing the informational content in their representations using an un-normalized contrastive approach. As we work with SGs, we experiment with three distinct maximization strategies: node-wise, graph-wise, and permutation-equivariant regularization. We empirically showcase the effectiveness of the extracted scene graph for VQA and demonstrate that these approaches enhance overall performance by highlighting the significance of visual information. This offers a more practical solution for VQA tasks that rely on SGs for complex reasoning questions. ",
    "url": "https://arxiv.org/abs/2310.01842",
    "authors": [
      "Bruno Souza",
      "Marius Aasan",
      "Helio Pedrini",
      "Ad\u00edn Ram\u00edrez Rivera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.01850",
    "title": "Multi-class Network Intrusion Detection with Class Imbalance via LSTM &  SMOTE",
    "abstract": "Monitoring network traffic to maintain the quality of service (QoS) and to detect network intrusions in a timely and efficient manner is essential. As network traffic is sequential, recurrent neural networks (RNNs) such as long short-term memory (LSTM) are suitable for building network intrusion detection systems. However, in the case of a few dataset examples of the rare attack types, even these networks perform poorly. This paper proposes to use oversampling techniques along with appropriate loss functions to handle class imbalance for the detection of various types of network intrusions. Our deep learning model employs LSTM with fully connected layers to perform multi-class classification of network attacks. We enhance the representation of minority classes: i) through the application of the Synthetic Minority Over-sampling Technique (SMOTE), and ii) by employing categorical focal cross-entropy loss to apply a focal factor to down-weight examples of the majority classes and focus more on hard examples of the minority classes. Extensive experiments on KDD99 and CICIDS2017 datasets show promising results in detecting network intrusions (with many rare attack types, e.g., Probe, R2L, DDoS, PortScan, etc.). ",
    "url": "https://arxiv.org/abs/2310.01850",
    "authors": [
      "Muhammad Wasim Nawaz",
      "Rashid Munawar",
      "Ahsan Mehmood",
      "Muhammad Mahboob Ur Rahman",
      "Qammer H. Abbasi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.01865",
    "title": "Conditional Instrumental Variable Regression with Representation  Learning for Causal Inference",
    "abstract": "This paper studies the challenging problem of estimating causal effects from observational data, in the presence of unobserved confounders. The two-stage least square (TSLS) method and its variants with a standard instrumental variable (IV) are commonly used to eliminate confounding bias, including the bias caused by unobserved confounders, but they rely on the linearity assumption. Besides, the strict condition of unconfounded instruments posed on a standard IV is too strong to be practical. To address these challenging and practical problems of the standard IV method (linearity assumption and the strict condition), in this paper, we use a conditional IV (CIV) to relax the unconfounded instrument condition of standard IV and propose a non-linear CIV regression with Confounding Balancing Representation Learning, CBRL.CIV, for jointly eliminating the confounding bias from unobserved confounders and balancing the observed confounders, without the linearity assumption. We theoretically demonstrate the soundness of CBRL.CIV. Extensive experiments on synthetic and two real-world datasets show the competitive performance of CBRL.CIV against state-of-the-art IV-based estimators and superiority in dealing with the non-linear situation. ",
    "url": "https://arxiv.org/abs/2310.01865",
    "authors": [
      "Debo Cheng",
      "Ziqi Xu",
      "Jiuyong Li",
      "Lin Liu",
      "Jixue Liu",
      "Thuc Duy Le"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01866",
    "title": "Route Design in Sheepdog System--Traveling Salesman Problem Formulation  and Evolutionary Computation Solution--",
    "abstract": "In this study, we consider the guidance control problem of the sheepdog system, which involves the guidance of the flock using the characteristics of the sheepdog and sheep. Sheepdog systems require a strategy to guide sheep agents to a target value using a small number of sheepdog agents, and various methods have been proposed. Previous studies have proposed a guidance control law to guide a herd of sheep reliably, but the movement distance of a sheepdog required for guidance has not been considered. Therefore, in this study, we propose a novel guidance algorithm in which a supposedly efficient route for guiding a flock of sheep is designed via Traveling Salesman Problem and evolutionary computation. Numerical simulations were performed to confirm whether sheep flocks could be guided and controlled using the obtained guidance routes. We specifically revealed that the proposed method reduces both the guidance failure rate and the guidance distance. ",
    "url": "https://arxiv.org/abs/2310.01866",
    "authors": [
      "Wataru. Imahayashi",
      "Yusuke. Tsunoda",
      "Masaki. Ogura"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2310.01875",
    "title": "Towards Stable Backdoor Purification through Feature Shift Tuning",
    "abstract": "It has been widely observed that deep neural networks (DNN) are vulnerable to backdoor attacks where attackers could manipulate the model behavior maliciously by tampering with a small set of training samples. Although a line of defense methods is proposed to mitigate this threat, they either require complicated modifications to the training process or heavily rely on the specific model architecture, which makes them hard to deploy into real-world applications. Therefore, in this paper, we instead start with fine-tuning, one of the most common and easy-to-deploy backdoor defenses, through comprehensive evaluations against diverse attack scenarios. Observations made through initial experiments show that in contrast to the promising defensive results on high poisoning rates, vanilla tuning methods completely fail at low poisoning rate scenarios. Our analysis shows that with the low poisoning rate, the entanglement between backdoor and clean features undermines the effect of tuning-based defenses. Therefore, it is necessary to disentangle the backdoor and clean features in order to improve backdoor purification. To address this, we introduce Feature Shift Tuning (FST), a method for tuning-based backdoor purification. Specifically, FST encourages feature shifts by actively deviating the classifier weights from the originally compromised weights. Extensive experiments demonstrate that our FST provides consistently stable performance under different attack settings. Additionally, it is also convenient to deploy in real-world scenarios with significantly reduced computation costs. Our codes are available at \\url{https://github.com/AISafety-HKUST/stable_backdoor_purification}. ",
    "url": "https://arxiv.org/abs/2310.01875",
    "authors": [
      "Rui Min",
      "Zeyu Qin",
      "Li Shen",
      "Minhao Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.01876",
    "title": "A Dual Attentive Generative Adversarial Network for Remote Sensing Image  Change Detection",
    "abstract": "Remote sensing change detection between bi-temporal images receives growing concentration from researchers. However, comparing two bi-temporal images for detecting changes is challenging, as they demonstrate different appearances. In this paper, we propose a dual attentive generative adversarial network for achieving very high-resolution remote sensing image change detection tasks, which regards the detection model as a generator and attains the optimal weights of the detection model without increasing the parameters of the detection model through generative-adversarial strategy, boosting the spatial contiguity of predictions. Moreover, We design a multi-level feature extractor for effectively fusing multi-level features, which adopts the pre-trained model to extract multi-level features from bi-temporal images and introduces aggregate connections to fuse them. To strengthen the identification of multi-scale objects, we propose a multi-scale adaptive fusion module to adaptively fuse multi-scale features through various receptive fields and design a context refinement module to explore contextual dependencies. Moreover, the DAGAN framework utilizes the 4-layer convolution network as a discriminator to identify whether the synthetic image is fake or real. Extensive experiments represent that the DAGAN framework has better performance with 85.01% mean IoU and 91.48% mean F1 score than advanced methods on the LEVIR dataset. ",
    "url": "https://arxiv.org/abs/2310.01876",
    "authors": [
      "Luyi Qiu",
      "Xiaofeng Zhang",
      "ChaoChen Gu",
      "and ShanYing Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.01878",
    "title": "Enhancing Workflow Security in Multi-Cloud Environments through  Monitoring and Adaptation upon Cloud Service and Network Security Violations",
    "abstract": "Cloud computing has emerged as a crucial solution for handling data- and compute-intensive workflows, offering scalability to address dynamic demands. However, ensuring the secure execution of workflows in the untrusted multi-cloud environment poses significant challenges, given the sensitive nature of the involved data and tasks. The lack of comprehensive approaches for detecting attacks during workflow execution, coupled with inadequate measures for reacting to security and privacy breaches has been identified in the literature. To close this gap, in this work, we propose an approach that focuses on monitoring cloud services and networks to detect security violations during workflow executions. Upon detection, our approach selects the optimal adaptation action to minimize the impact on the workflow. To mitigate the uncertain cost associated with such adaptations and their potential impact on other tasks in the workflow, we employ adaptive learning to determine the most suitable adaptation action. Our approach is evaluated based on the performance of the detection procedure and the impact of the selected adaptations on the workflows. ",
    "url": "https://arxiv.org/abs/2310.01878",
    "authors": [
      "Nafiseh Soveizi",
      "Dimka Karastoyanova"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.01880",
    "title": "AutoCast++: Enhancing World Event Prediction with Zero-shot  Ranking-based Context Retrieval",
    "abstract": "Machine-based prediction of real-world events is garnering attention due to its potential for informed decision-making. Whereas traditional forecasting predominantly hinges on structured data like time-series, recent breakthroughs in language models enable predictions using unstructured text. In particular, (Zou et al., 2022) unveils AutoCast, a new benchmark that employs news articles for answering forecasting queries. Nevertheless, existing methods still trail behind human performance. The cornerstone of accurate forecasting, we argue, lies in identifying a concise, yet rich subset of news snippets from a vast corpus. With this motivation, we introduce AutoCast++, a zero-shot ranking-based context retrieval system, tailored to sift through expansive news document collections for event forecasting. Our approach first re-ranks articles based on zero-shot question-passage relevance, honing in on semantically pertinent news. Following this, the chosen articles are subjected to zero-shot summarization to attain succinct context. Leveraging a pre-trained language model, we conduct both the relevance evaluation and article summarization without needing domain-specific training. Notably, recent articles can sometimes be at odds with preceding ones due to new facts or unanticipated incidents, leading to fluctuating temporal dynamics. To tackle this, our re-ranking mechanism gives preference to more recent articles, and we further regularize the multi-passage representation learning to align with human forecaster responses made on different dates. Empirical results underscore marked improvements across multiple metrics, improving the performance for multiple-choice questions (MCQ) by 48% and true/false (TF) questions by up to 8%. ",
    "url": "https://arxiv.org/abs/2310.01880",
    "authors": [
      "Qi Yan",
      "Raihan Seraj",
      "Jiawei He",
      "Lili Meng",
      "Tristan Sylvain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01881",
    "title": "Adaptive Multi-NeRF: Exploit Efficient Parallelism in Adaptive Multiple  Scale Neural Radiance Field Rendering",
    "abstract": "Recent advances in Neural Radiance Fields (NeRF) have demonstrated significant potential for representing 3D scene appearances as implicit neural networks, enabling the synthesis of high-fidelity novel views. However, the lengthy training and rendering process hinders the widespread adoption of this promising technique for real-time rendering applications. To address this issue, we present an effective adaptive multi-NeRF method designed to accelerate the neural rendering process for large scenes with unbalanced workloads due to varying scene complexities. Our method adaptively subdivides scenes into axis-aligned bounding boxes using a tree hierarchy approach, assigning smaller NeRFs to different-sized subspaces based on the complexity of each scene portion. This ensures the underlying neural representation is specific to a particular part of the scene. We optimize scene subdivision by employing a guidance density grid, which balances representation capability for each Multilayer Perceptron (MLP). Consequently, samples generated by each ray can be sorted and collected for parallel inference, achieving a balanced workload suitable for small MLPs with consistent dimensions for regular and GPU-friendly computations. We aosl demonstrated an efficient NeRF sampling strategy that intrinsically adapts to increase parallelism, utilization, and reduce kernel calls, thereby achieving much higher GPU utilization and accelerating the rendering process. ",
    "url": "https://arxiv.org/abs/2310.01881",
    "authors": [
      "Tong Wang",
      "Shuichi Kurabayashi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.01894",
    "title": "Waveform Manipulation Against DNN-based Modulation Classification  Attacks",
    "abstract": "In this paper we propose a method for defending against an eavesdropper that uses a Deep Neural Network (DNN) for learning the modulation of wireless communication signals. Our method is based on manipulating the emitted waveform with the aid of a continuous time frequency-modulated (FM) obfuscating signal that is mixed with the modulated data. The resulting waveform allows a legitimate receiver (LRx) to demodulate the data but it increases the test error of a pre-trained or adversarially-trained DNN classifier at the eavesdropper. The scheme works for analog modulation and digital single carrier and multi carrier orthogonal frequency division multiplexing (OFDM) waveforms, while it can implemented in frame-based wireless protocols. The results indicate that careful selection of the parameters of the obfuscating waveform can drop classification performance at the eavesdropper to less than 10% in AWGN and fading channels with no performance loss at the LRx. ",
    "url": "https://arxiv.org/abs/2310.01894",
    "authors": [
      "Dimitrios Varkatzas",
      "Antonios Argyriou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.01931",
    "title": "MarineDet: Towards Open-Marine Object Detection",
    "abstract": "Marine object detection has gained prominence in marine research, driven by the pressing need to unravel oceanic mysteries and enhance our understanding of invaluable marine ecosystems. There is a profound requirement to efficiently and accurately identify and localize diverse and unseen marine entities within underwater imagery. The open-marine object detection (OMOD for short) is required to detect diverse and unseen marine objects, performing categorization and localization simultaneously. To achieve OMOD, we present \\textbf{MarineDet}. We formulate a joint visual-text semantic space through pre-training and then perform marine-specific training to achieve in-air-to-marine knowledge transfer. Considering there is no specific dataset designed for OMOD, we construct a \\textbf{MarineDet dataset} consisting of 821 marine-relative object categories to promote and measure OMOD performance. The experimental results demonstrate the superior performance of MarineDet over existing generalist and specialist object detection algorithms. To the best of our knowledge, we are the first to present OMOD, which holds a more valuable and practical setting for marine ecosystem monitoring and management. Our research not only pushes the boundaries of marine understanding but also offers a standard pipeline for OMOD. ",
    "url": "https://arxiv.org/abs/2310.01931",
    "authors": [
      "Liang Haixin",
      "Zheng Ziqiang",
      "Ma Zeyu",
      "Sai-Kit Yeung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.01937",
    "title": "Causal Inference with Conditional Front-Door Adjustment and Identifiable  Variational Autoencoder",
    "abstract": "An essential and challenging problem in causal inference is causal effect estimation from observational data. The problem becomes more difficult with the presence of unobserved confounding variables. The front-door adjustment is a practical approach for dealing with unobserved confounding variables. However, the restriction for the standard front-door adjustment is difficult to satisfy in practice. In this paper, we relax some of the restrictions by proposing the concept of conditional front-door (CFD) adjustment and develop the theorem that guarantees the causal effect identifiability of CFD adjustment. Furthermore, as it is often impossible for a CFD variable to be given in practice, it is desirable to learn it from data. By leveraging the ability of deep generative models, we propose CFDiVAE to learn the representation of the CFD adjustment variable directly from data with the identifiable Variational AutoEncoder and formally prove the model identifiability. Extensive experiments on synthetic datasets validate the effectiveness of CFDiVAE and its superiority over existing methods. The experiments also show that the performance of CFDiVAE is less sensitive to the causal strength of unobserved confounding variables. We further apply CFDiVAE to a real-world dataset to demonstrate its potential application. ",
    "url": "https://arxiv.org/abs/2310.01937",
    "authors": [
      "Ziqi Xu",
      "Debo Cheng",
      "Jiuyong Li",
      "Jixue Liu",
      "Lin Liu",
      "Kui Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01951",
    "title": "Probabilistic Reach-Avoid for Bayesian Neural Networks",
    "abstract": "Model-based reinforcement learning seeks to simultaneously learn the dynamics of an unknown stochastic environment and synthesise an optimal policy for acting in it. Ensuring the safety and robustness of sequential decisions made through a policy in such an environment is a key challenge for policies intended for safety-critical scenarios. In this work, we investigate two complementary problems: first, computing reach-avoid probabilities for iterative predictions made with dynamical models, with dynamics described by Bayesian neural network (BNN); second, synthesising control policies that are optimal with respect to a given reach-avoid specification (reaching a \"target\" state, while avoiding a set of \"unsafe\" states) and a learned BNN model. Our solution leverages interval propagation and backward recursion techniques to compute lower bounds for the probability that a policy's sequence of actions leads to satisfying the reach-avoid specification. Such computed lower bounds provide safety certification for the given policy and BNN model. We then introduce control synthesis algorithms to derive policies maximizing said lower bounds on the safety probability. We demonstrate the effectiveness of our method on a series of control benchmarks characterized by learned BNN dynamics models. On our most challenging benchmark, compared to purely data-driven policies the optimal synthesis algorithm is able to provide more than a four-fold increase in the number of certifiable states and more than a three-fold increase in the average guaranteed reach-avoid probability. ",
    "url": "https://arxiv.org/abs/2310.01951",
    "authors": [
      "Matthew Wicker",
      "Luca Laurenti",
      "Andrea Patane",
      "Nicola Paoletti",
      "Alessandro Abate",
      "Marta Kwiatkowska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01966",
    "title": "Throughput Maximization for Instantly Decodable Network Coded NOMA in  Broadcast Communication Systems",
    "abstract": "Non-orthogonal multiple access (NOMA) is a promising transmission scheme employed at the physical layer to improve the spectral efficiency. In this paper, we develop a novel cross-layer approach by employing NOMA at the physical layer and instantly decodable network coding (IDNC) at the network layer in downlink cellular networks. Following this approach, two IDNC packets are selected for each transmission, with one designed for all receivers and the other designed only for the strong receivers which can employ successive interference cancellation (SIC). The IDNC packets selection, transmission rates adaption for the two IDNC packets, and NOMA power allocation are jointly considered to improve the throughput of the network. Given the intractability of the problem, we decouple it into two separate subproblems, the IDNC scheduling which jointly selects the IDNC packets and the transmission rates with the given NOMA power allocation, and the NOMA power allocation with the given IDNC scheduling. The IDNC scheduling can be reduced to a maximum weight clique problem, and two heuristic algorithms named as maximum weight vertex (MWV) search and maximum weight path based maximum weight vertex (MWP-MWV) search are developed to solve the first subproblem. An iterative function evaluation (IFE) approach is proposed to solve the second subproblem. Simulation results are presented to demonstrates the throughput gain of the proposed approach over the existing solutions. ",
    "url": "https://arxiv.org/abs/2310.01966",
    "authors": [
      "Zhonghui Mei"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2310.01968",
    "title": "PyHexTop: a compact Python code for topology optimization using  hexagonal elements",
    "abstract": "Python serves as an open-source and cost-effective alternative to the MATLAB programming language. This paper introduces a concise topology optimization Python code, named ``PyHexTop,\" primarily intended for educational purposes. Code employs hexagonal elements to parameterize design domains as such elements provide checkerboard-free optimized design naturally. PyHexTop is developed based on the ``HoneyTop90\" MATLAB code~\\cite{kumar2023honeytop90} and uses the NumPy and SciPy libraries. Code is straightforward and easily comprehensible, proving a helpful tool that can help people new in the topology optimization field to learn and explore. PyHexTop is specifically tailored to address compliance minimization with specified volume constraints. The paper provides a detailed explanation of the code for solving the MBB design and extensions to solve problems with varying boundary and force conditions. The code is publicly shared at: \\url{https://github.com/PrabhatIn/PyHexTop.} ",
    "url": "https://arxiv.org/abs/2310.01968",
    "authors": [
      "Aditi Agarwal",
      "Anupam Saxena",
      "Prabhat Kumar"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2310.01969",
    "title": "Steganalysis of AI Models LSB Attacks",
    "abstract": "Artificial intelligence has made significant progress in the last decade, leading to a rise in the popularity of model sharing. The model zoo ecosystem, a repository of pre-trained AI models, has advanced the AI open-source community and opened new avenues for cyber risks. Malicious attackers can exploit shared models to launch cyber-attacks. This work focuses on the steganalysis of injected malicious Least Significant Bit (LSB) steganography into AI models, and it is the first work focusing on AI model attacks. In response to this threat, this paper presents a steganalysis method specifically tailored to detect and mitigate malicious LSB steganography attacks based on supervised and unsupervised AI detection steganalysis methods. Our proposed technique aims to preserve the integrity of shared models, protect user trust, and maintain the momentum of open collaboration within the AI community. In this work, we propose 3 steganalysis methods and open source our code. We found that the success of the steganalysis depends on the LSB attack location. If the attacker decides to exploit the least significant bits in the LSB, the ability to detect the attacks is low. However, if the attack is in the most significant LSB bits, the attack can be detected with almost perfect accuracy. ",
    "url": "https://arxiv.org/abs/2310.01969",
    "authors": [
      "Daniel Gilkarov",
      "Ran Dubin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.01975",
    "title": "Benign Overfitting in Two-Layer ReLU Convolutional Neural Networks for  XOR Data",
    "abstract": "Modern deep learning models are usually highly over-parameterized so that they can overfit the training data. Surprisingly, such overfitting neural networks can usually still achieve high prediction accuracy. To study this \"benign overfitting\" phenomenon, a line of recent works has theoretically studied the learning of linear models and two-layer neural networks. However, most of these analyses are still limited to the very simple learning problems where the Bayes-optimal classifier is linear. In this work, we investigate a class of XOR-type classification tasks with label-flipping noises. We show that, under a certain condition on the sample complexity and signal-to-noise ratio, an over-parameterized ReLU CNN trained by gradient descent can achieve near Bayes-optimal accuracy. Moreover, we also establish a matching lower bound result showing that when the previous condition is not satisfied, the prediction accuracy of the obtained CNN is an absolute constant away from the Bayes-optimal rate. Our result demonstrates that CNNs have a remarkable capacity to efficiently learn XOR problems, even in the presence of highly correlated features. ",
    "url": "https://arxiv.org/abs/2310.01975",
    "authors": [
      "Xuran Meng",
      "Difan Zou",
      "Yuan Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01986",
    "title": "A Vision-Based Tactile Sensing System for Multimodal Contact Information  Perception via Neural Network",
    "abstract": "In general, robotic dexterous hands are equipped with various sensors for acquiring multimodal contact information such as position, force, and pose of the grasped object. This multi-sensor-based design adds complexity to the robotic system. In contrast, vision-based tactile sensors employ specialized optical designs to enable the extraction of tactile information across different modalities within a single system. Nonetheless, the decoupling design for different modalities in common systems is often independent. Therefore, as the dimensionality of tactile modalities increases, it poses more complex challenges in data processing and decoupling, thereby limiting its application to some extent. Here, we developed a multimodal sensing system based on a vision-based tactile sensor, which utilizes visual representations of tactile information to perceive the multimodal contact information of the grasped object. The visual representations contain extensive content that can be decoupled by a deep neural network to obtain multimodal contact information such as classification, position, posture, and force of the grasped object. The results show that the tactile sensing system can perceive multimodal tactile information using only one single sensor and without different data decoupling designs for different modal tactile information, which reduces the complexity of the tactile system and demonstrates the potential for multimodal tactile integration in various fields such as biomedicine, biology, and robotics. ",
    "url": "https://arxiv.org/abs/2310.01986",
    "authors": [
      "Weiliang Xu",
      "Guoyuan Zhou",
      "Yuanzhi Zhou",
      "Zhibin Zou",
      "Jiali Wang",
      "Wenfeng Wu",
      "Xinming Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.02000",
    "title": "MUSCLE: Multi-task Self-supervised Continual Learning to Pre-train Deep  Models for X-ray Images of Multiple Body Parts",
    "abstract": "While self-supervised learning (SSL) algorithms have been widely used to pre-train deep models, few efforts [11] have been done to improve representation learning of X-ray image analysis with SSL pre-trained models. In this work, we study a novel self-supervised pre-training pipeline, namely Multi-task Self-super-vised Continual Learning (MUSCLE), for multiple medical imaging tasks, such as classification and segmentation, using X-ray images collected from multiple body parts, including heads, lungs, and bones. Specifically, MUSCLE aggregates X-rays collected from multiple body parts for MoCo-based representation learning, and adopts a well-designed continual learning (CL) procedure to further pre-train the backbone subject various X-ray analysis tasks jointly. Certain strategies for image pre-processing, learning schedules, and regularization have been used to solve data heterogeneity, overfitting, and catastrophic forgetting problems for multi-task/dataset learning in MUSCLE.We evaluate MUSCLE using 9 real-world X-ray datasets with various tasks, including pneumonia classification, skeletal abnormality classification, lung segmentation, and tuberculosis (TB) detection. Comparisons against other pre-trained models [7] confirm the proof-of-concept that self-supervised multi-task/dataset continual pre-training could boost the performance of X-ray image analysis. ",
    "url": "https://arxiv.org/abs/2310.02000",
    "authors": [
      "Weibin Liao",
      "Haoyi Xiong",
      "Qingzhong Wang",
      "Yan Mo",
      "Xuhong Li",
      "Yi Liu",
      "Zeyu Chen",
      "Siyu Huang",
      "Dejing Dou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.02003",
    "title": "L2MAC: Large Language Model Automatic Computer for Unbounded Code  Generation",
    "abstract": "Transformer-based large language models (LLMs) are constrained by the fixed context window of the underlying transformer architecture, hindering their ability to produce long and logically consistent code. Memory-augmented LLMs are a promising solution, but current approaches cannot handle long code generation tasks since they (1) only focus on reading memory and reduce its evolution to the concatenation of new memories or (2) use very specialized memories that cannot adapt to other domains. This paper presents L2MAC, the first practical LLM-based stored-program automatic computer for long and consistent code generation. Its memory has two components: the instruction registry, which is populated with a prompt program to solve the user-given task, and a file store, which will contain the final and intermediate outputs. Each instruction is executed by a separate LLM instance, whose context is managed by a control unit capable of precise memory reading and writing to ensure effective interaction with the file store. These components enable L2MAC to generate virtually unbounded code structures, bypassing the constraints of the finite context window while producing code that fulfills complex user-specified requirements. We empirically show that L2MAC succeeds in generating large code bases for system design tasks where other coding methods fall short in implementing user requirements and provide insight into the reasons for this performance gap. ",
    "url": "https://arxiv.org/abs/2310.02003",
    "authors": [
      "Samuel Holt",
      "Max Ruiz Luyten",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2310.02016",
    "title": "Ranking a Set of Objects using Heterogeneous Workers: QUITE an Easy  Problem",
    "abstract": "We focus on the problem of ranking $N$ objects starting from a set of noisy pairwise comparisons provided by a crowd of unequal workers, each worker being characterized by a specific degree of reliability, which reflects her ability to rank pairs of objects. More specifically, we assume that objects are endowed with intrinsic qualities and that the probability with which an object is preferred to another depends both on the difference between the qualities of the two competitors and on the reliability of the worker. We propose QUITE, a non-adaptive ranking algorithm that jointly estimates workers' reliabilities and qualities of objects. Performance of QUITE is compared in different scenarios against previously proposed algorithms. Finally, we show how QUITE can be naturally made adaptive. ",
    "url": "https://arxiv.org/abs/2310.02016",
    "authors": [
      "Alessandro Nordio",
      "Alberto tarable",
      "Emilio Leonardi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Performance (cs.PF)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.02027",
    "title": "DeepHGCN: Toward Deeper Hyperbolic Graph Convolutional Networks",
    "abstract": "Hyperbolic graph convolutional networks (HGCN) have demonstrated significant potential in extracting information from hierarchical graphs. However, existing HGCNs are limited to shallow architectures, due to the expensive hyperbolic operations and the over-smoothing issue as depth increases. Although in GCNs, treatments have been applied to alleviate over-smoothing, developing a hyperbolic therapy presents distinct challenges since operations should be carefully designed to fit the hyperbolic nature. Addressing the above challenges, in this work, we propose DeepHGCN, the first deep multi-layer HGCN architecture with dramatically improved computational efficiency and substantially alleviated over-smoothing effect. DeepHGCN presents two key enablers of deep HGCNs: (1) a novel hyperbolic feature transformation layer that enables fast and accurate linear maps; and (2) Techniques such as hyperbolic residual connections and regularization for both weights and features facilitated by an efficient hyperbolic midpoint method. Extensive experiments demonstrate that DeepHGCN obtains significant improvements in link prediction and node classification tasks compared to both Euclidean and shallow hyperbolic GCN variants. ",
    "url": "https://arxiv.org/abs/2310.02027",
    "authors": [
      "Jiaxu Liu",
      "Xinping Yi",
      "Xiaowei Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.02029",
    "title": "Between accurate prediction and poor decision making: the AI/ML gap",
    "abstract": "Intelligent agents rely on AI/ML functionalities to predict the consequence of possible actions and optimise the policy. However, the effort of the research community in addressing prediction accuracy has been so intense (and successful) that it created the illusion that the more accurate the learner prediction (or classification) the better would have been the final decision. Now, such an assumption is valid only if the (human or artificial) decision maker has complete knowledge of the utility of the possible actions. This paper argues that AI/ML community has taken so far a too unbalanced approach by devoting excessive attention to the estimation of the state (or target) probability to the detriment of accurate and reliable estimations of the utility. In particular, few evidence exists about the impact of a wrong utility assessment on the resulting expected utility of the decision strategy. This situation is creating a substantial gap between the expectations and the effective impact of AI solutions, as witnessed by recent criticisms and emphasised by the regulatory legislative efforts. This paper aims to study this gap by quantifying the sensitivity of the expected utility to the utility uncertainty and comparing it to the one due to probability estimation. Theoretical and simulated results show that an inaccurate utility assessment may as (and sometimes) more harmful than a poor probability estimation. The final recommendation to the community is then to undertake a focus shift from a pure accuracy-driven (or obsessed) approach to a more utility-aware methodology. ",
    "url": "https://arxiv.org/abs/2310.02029",
    "authors": [
      "Gianluca Bontempi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.02048",
    "title": "Exploring Generalisability of Self-Distillation with No Labels for  SAR-Based Vegetation Prediction",
    "abstract": "In this work we pre-train a DINO-ViT based model using two Synthetic Aperture Radar datasets (S1GRD or GSSIC) across three regions (China, Conus, Europe). We fine-tune the models on smaller labeled datasets to predict vegetation percentage, and empirically study the connection between the embedding space of the models and their ability to generalize across diverse geographic regions and to unseen data. For S1GRD, embedding spaces of different regions are clearly separated, while GSSIC's overlaps. Positional patterns remain during fine-tuning, and greater distances in embeddings often result in higher errors for unfamiliar regions. With this, our work increases our understanding of generalizability for self-supervised models applied to remote sensing. ",
    "url": "https://arxiv.org/abs/2310.02048",
    "authors": [
      "Laura Mart\u00ednez-Ferrer",
      "Anna Jungbluth",
      "Joseph A. Gallego-Mejia",
      "Matt Allen",
      "Francisco Dorr",
      "Freddie Kalaitzis",
      "Ra\u00fal Ramos-Poll\u00e1n"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.02053",
    "title": "Controlling Topic-Focus Articulation in Meaning-to-Text Generation using  Graph Neural Networks",
    "abstract": "A bare meaning representation can be expressed in various ways using natural language, depending on how the information is structured on the surface level. We are interested in finding ways to control topic-focus articulation when generating text from meaning. We focus on distinguishing active and passive voice for sentences with transitive verbs. The idea is to add pragmatic information such as topic to the meaning representation, thereby forcing either active or passive voice when given to a natural language generation system. We use graph neural models because there is no explicit information about word order in a meaning represented by a graph. We try three different methods for topic-focus articulation (TFA) employing graph neural models for a meaning-to-text generation task. We propose a novel encoding strategy about node aggregation in graph neural models, which instead of traditional encoding by aggregating adjacent node information, learns node representations by using depth-first search. The results show our approach can get competitive performance with state-of-art graph models on general text generation, and lead to significant improvements on the task of active-passive conversion compared to traditional adjacency-based aggregation strategies. Different types of TFA can have a huge impact on the performance of the graph models. ",
    "url": "https://arxiv.org/abs/2310.02053",
    "authors": [
      "Chunliu Wang",
      "Rik van Noord",
      "Johan Bos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.02059",
    "title": "Security Weaknesses of Copilot Generated Code in GitHub",
    "abstract": "Modern code generation tools use AI models, particularly Large Language Models (LLMs), to generate functional and complete code. While such tools are becoming popular and widely available for developers, using these tools is often accompanied by security challenges. Therefore, it is important to assess the quality of the generated code, especially in terms of its security. Researchers have recently explored various aspects of code generation tools, including security. However, many open questions about the security of the generated code require further investigation, especially the security issues of automatically generated code in the wild. To this end, we conducted an empirical study by analyzing the security weaknesses in code snippets generated by GitHub Copilot that are found as part of publicly available projects hosted on GitHub. The goal is to investigate the types of security issues and their scale in real-world scenarios (rather than crafted scenarios). To this end, we identified 435 code snippets generated by Copilot from publicly available projects. We then conducted extensive security analysis to identify Common Weakness Enumeration (CWE) instances in these code snippets. The results show that (1) 35.8% of Copilot generated code snippets contain CWEs, and those issues are spread across multiple languages, (2) the security weaknesses are diverse and related to 42 different CWEs, in which CWE-78: OS Command Injection, CWE-330: Use of Insufficiently Random Values, and CWE-703: Improper Check or Handling of Exceptional Conditions occurred the most frequently, and (3) among the 42 CWEs identified, 11 of those belong to the currently recognized 2022 CWE Top-25. Our findings confirm that developers should be careful when adding code generated by Copilot (and similar AI code generation tools) and should also run appropriate security checks as they accept the suggested code. ",
    "url": "https://arxiv.org/abs/2310.02059",
    "authors": [
      "Yujia Fu",
      "Peng Liang",
      "Amjed Tahir",
      "Zengyang Li",
      "Mojtaba Shahin",
      "Jiaxin Yu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.02069",
    "title": "TOaCNN: Adaptive Convolutional Neural Network for Multidisciplinary  Topology Optimization",
    "abstract": "This paper presents an adaptive convolutional neural network (CNN) architecture that can automate diverse topology optimization (TO) problems having different underlying physics. The architecture uses the encoder-decoder networks with dense layers in the middle which includes an additional adaptive layer to capture complex geometrical features. The network is trained using the dataset obtained from the three open-source TO codes involving different physics. The robustness and success of the presented adaptive CNN are demonstrated on compliance minimization problems with constant and design-dependent loads and material bulk modulus optimization. The architecture takes the user's input of the volume fraction. It instantly generates optimized designs resembling their counterparts obtained via open-source TO codes with negligible performance and volume fraction error. ",
    "url": "https://arxiv.org/abs/2310.02069",
    "authors": [
      "Khaish Singh Chadha",
      "Prabhat Kumar"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2310.02094",
    "title": "CoNO: Complex Neural Operator for Continuous Dynamical Systems",
    "abstract": "Neural operators extend data-driven models to map between infinite-dimensional functional spaces. These models have successfully solved continuous dynamical systems represented by differential equations, viz weather forecasting, fluid flow, or solid mechanics. However, the existing operators still rely on real space, thereby losing rich representations potentially captured in the complex space by functional transforms. In this paper, we introduce a Complex Neural Operator (CoNO), that parameterizes the integral kernel in the complex fractional Fourier domain. Additionally, the model employing a complex-valued neural network along with aliasing-free activation functions preserves the complex values and complex algebraic properties, thereby enabling improved representation, robustness to noise, and generalization. We show that the model effectively captures the underlying partial differential equation with a single complex fractional Fourier transform. We perform an extensive empirical evaluation of CoNO on several datasets and additional tasks such as zero-shot super-resolution, evaluation of out-of-distribution data, data efficiency, and robustness to noise. CoNO exhibits comparable or superior performance to all the state-of-the-art models in these tasks. Altogether, CoNO presents a robust and superior model for modeling continuous dynamical systems, providing a fillip to scientific machine learning. ",
    "url": "https://arxiv.org/abs/2310.02094",
    "authors": [
      "Karn Tiwari",
      "N M Anoop Krishnan",
      "Prathosh A P"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.02104",
    "title": "An empirical study of ChatGPT-3.5 on question answering and code  maintenance",
    "abstract": "Ever since the launch of ChatGPT in 2022, a rising concern is whether ChatGPT will replace programmers and kill jobs. Motivated by this widespread concern, we conducted an empirical study to systematically compare ChatGPT against programmers in question-answering and software-maintaining. We reused a dataset introduced by prior work, which includes 130 StackOverflow (SO) discussion threads referred to by the Java developers of 357 GitHub projects. We mainly investigated three research questions (RQs). First, how does ChatGPT compare with programmers when answering technical questions? Second, how do developers perceive the differences between ChatGPT's answers and SO answers? Third, how does ChatGPT compare with humans when revising code for maintenance requests? For RQ1, we provided the 130 SO questions to ChatGPT, and manually compared ChatGPT answers with the accepted/most popular SO answers in terms of relevance, readability, informativeness, comprehensiveness, and reusability. For RQ2, we conducted a user study with 30 developers, asking each developer to assess and compare 10 pairs of answers, without knowing the information source (i.e., ChatGPT or SO). For RQ3, we distilled 48 software maintenance tasks from 48 GitHub projects citing the studied SO threads. We queried ChatGPT to revise a given Java file, and to incorporate the code implementation for any prescribed maintenance requirement. Our study reveals interesting phenomena: For the majority of SO questions (97/130), ChatGPT provided better answers; in 203 of 300 ratings, developers preferred ChatGPT answers to SO answers; ChatGPT revised code correctly for 22 of the 48 tasks. Our research will expand people's knowledge of ChatGPT capabilities, and shed light on future adoption of ChatGPT by the software industry. ",
    "url": "https://arxiv.org/abs/2310.02104",
    "authors": [
      "Md Mahir Asef Kabir",
      "Sk Adnan Hassan",
      "Xiaoyin Wang",
      "Ying Wang",
      "Hai Yu",
      "Na Meng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.02113",
    "title": "FLEDGE: Ledger-based Federated Learning Resilient to Inference and  Backdoor Attacks",
    "abstract": "Federated learning (FL) is a distributed learning process that uses a trusted aggregation server to allow multiple parties (or clients) to collaboratively train a machine learning model without having them share their private data. Recent research, however, has demonstrated the effectiveness of inference and poisoning attacks on FL. Mitigating both attacks simultaneously is very challenging. State-of-the-art solutions have proposed the use of poisoning defenses with Secure Multi-Party Computation (SMPC) and/or Differential Privacy (DP). However, these techniques are not efficient and fail to address the malicious intent behind the attacks, i.e., adversaries (curious servers and/or compromised clients) seek to exploit a system for monetization purposes. To overcome these limitations, we present a ledger-based FL framework known as FLEDGE that allows making parties accountable for their behavior and achieve reasonable efficiency for mitigating inference and poisoning attacks. Our solution leverages crypto-currency to increase party accountability by penalizing malicious behavior and rewarding benign conduct. We conduct an extensive evaluation on four public datasets: Reddit, MNIST, Fashion-MNIST, and CIFAR-10. Our experimental results demonstrate that (1) FLEDGE provides strong privacy guarantees for model updates without sacrificing model utility; (2) FLEDGE can successfully mitigate different poisoning attacks without degrading the performance of the global model; and (3) FLEDGE offers unique reward mechanisms to promote benign behavior during model training and/or model aggregation. ",
    "url": "https://arxiv.org/abs/2310.02113",
    "authors": [
      "Jorge Castillo",
      "Phillip Rieger",
      "Hossein Fereidooni",
      "Qian Chen",
      "Ahmad Sadeghi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.02124",
    "title": "Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology  View",
    "abstract": "As Natural Language Processing (NLP) systems are increasingly employed in intricate social environments, a pressing query emerges: Can these NLP systems mirror human-esque collaborative intelligence, in a multi-agent society consisting of multiple large language models (LLMs)? This paper probes the collaboration mechanisms among contemporary NLP systems by melding practical experiments with theoretical insights. We fabricate four unique `societies' comprised of LLM agents, where each agent is characterized by a specific `trait' (easy-going or overconfident) and engages in collaboration with a distinct `thinking pattern' (debate or reflection). Evaluating these multi-agent societies on three benchmark datasets, we discern that LLM agents navigate tasks by leveraging diverse social behaviors, from active debates to introspective reflections. Notably, certain collaborative strategies only optimize efficiency (using fewer API tokens), but also outshine previous top-tier approaches. Moreover, our results further illustrate that LLM agents manifest human-like social behaviors, such as conformity or majority rule, mirroring foundational Social Psychology theories. In conclusion, we integrate insights from Social Psychology to contextualize the collaboration of LLM agents, inspiring further investigations into the collaboration mechanism for LLMs. We commit to sharing our code and datasets (already submitted in supplementary materials), hoping to catalyze further research in this promising avenue (All code and data are available at \\url{https://github.com/zjunlp/MachineSoM}.). ",
    "url": "https://arxiv.org/abs/2310.02124",
    "authors": [
      "Jintian Zhang",
      "Xin Xu",
      "Shumin Deng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2310.02128",
    "title": "Semantic Code Graph -- an information model to facilitate software  comprehension",
    "abstract": "Software comprehension can be extremely time-consuming due to the ever-growing size of codebases. Consequently, there is an increasing need to accelerate the code comprehension process to facilitate maintenance and reduce associated costs. A crucial aspect of this process is understanding and preserving the high quality of the code dependency structure. While a variety of code structure models already exist, there is a surprising lack of models that closely represent the source code and focus on software comprehension. As a result, there are no readily available and easy-to-use tools to assist with dependency comprehension, refactoring, and quality monitoring of code. To address this gap, we propose the Semantic Code Graph (SCG), an information model that offers a detailed abstract representation of code dependencies with a close relationship to the source code. To validate the SCG model's usefulness in software comprehension, we compare it to nine other source code representation models. Additionally, we select 11 well-known and widely-used open-source projects developed in Java and Scala and perform a range of software comprehension activities on them using three different code representation models: the proposed SCG, the Call Graph (CG), and the Class Collaboration Network (CCN). We then qualitatively analyze the results to compare the performance of these models in terms of software comprehension capabilities. These activities encompass project structure comprehension, identifying critical project entities, interactive visualization of code dependencies, and uncovering code similarities through software mining. Our findings demonstrate that the SCG enhances software comprehension capabilities compared to the prevailing CCN and CG models. We believe that the work described is a step towards the next generation of tools that streamline code dependency comprehension and management. ",
    "url": "https://arxiv.org/abs/2310.02128",
    "authors": [
      "Krzysztof Borowski",
      "Bartosz Bali\u015b",
      "Tomasz Orzechowski"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.02130",
    "title": "Clustering Graphs of Bounded Treewidth to Minimize the Sum of  Radius-Dependent Costs",
    "abstract": "We consider the following natural problem that generalizes min-sum-radii clustering: Given is $k\\in\\mathbb{N}$ as well as some metric space $(V,d)$ where $V=F\\cup C$ for facilities $F$ and clients $C$. The goal is to find a clustering given by $k$ facility-radius pairs $(f_1,r_1),\\dots,(f_k,r_k)\\in F\\times\\mathbb{R}_{\\geq 0}$ such that $C\\subseteq B(f_1,r_1)\\cup\\dots\\cup B(f_k,r_k)$ and $\\sum_{i=1,\\dots,k} g(r_i)$ is minimized for some increasing function $g:\\mathbb{R}_{\\geq 0}\\rightarrow\\mathbb{R}_{\\geq 0}$. Here, $B(x,r)$ is the radius-$r$ ball centered at $x$. For the case that $(V,d)$ is the shortest-path metric of some edge-weighted graph of bounded treewidth, we present a dynamic program that is tailored to this class of problems and achieves a polynomial running time, establishing that the problem is in $\\mathsf{XP}$ with parameter treewidth. ",
    "url": "https://arxiv.org/abs/2310.02130",
    "authors": [
      "Lukas Drexler",
      "Jan H\u00f6ckendorff",
      "Joshua K\u00f6nen",
      "Kevin Schewior"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2310.02134",
    "title": "A discrete approximation scheme for fully nonlinear partial  integro-differential equations with the convergence rate of robust  $\u03b1$-stable central limit theorem",
    "abstract": "In this work, we develop a numerical method to study the error estimates of the $\\alpha$-stable central limit theorem under sublinear expectation with $\\alpha \\in(0,2)$, whose limit distribution can be characterized by a fully nonlinear integro-differential equation (PIDE). Based on the sequence of independent random variables, we propose a discrete approximation scheme for the fully nonlinear PIDE. With the help of the nonlinear stochastic analysis techniques and numerical analysis tools, we establish the error bounds for the discrete approximation scheme, which in turn provides a general error bound for the robust $\\alpha$-stable central limit theorem, including the integrable case $\\alpha \\in(1,2)$ as well as the non-integrable case $\\alpha \\in(0,1]$. Finally, we provide some concrete examples to illustrate our main results and derive the precise convergence rates. ",
    "url": "https://arxiv.org/abs/2310.02134",
    "authors": [
      "Lianzi Jiang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.02140",
    "title": "PAD-Phys: Exploiting Physiology for Presentation Attack Detection in  Face Biometrics",
    "abstract": "Presentation Attack Detection (PAD) is a crucial stage in facial recognition systems to avoid leakage of personal information or spoofing of identity to entities. Recently, pulse detection based on remote photoplethysmography (rPPG) has been shown to be effective in face presentation attack detection. This work presents three different approaches to the presentation attack detection based on rPPG: (i) The physiological domain, a domain using rPPG-based models, (ii) the Deepfakes domain, a domain where models were retrained from the physiological domain to specific Deepfakes detection tasks; and (iii) a new Presentation Attack domain was trained by applying transfer learning from the two previous domains to improve the capability to differentiate between bona-fides and attacks. The results show the efficiency of the rPPG-based models for presentation attack detection, evidencing a 21.70% decrease in average classification error rate (ACER) (from 41.03% to 19.32%) when the presentation attack domain is compared to the physiological and Deepfakes domains. Our experiments highlight the efficiency of transfer learning in rPPG-based models and perform well in presentation attack detection in instruments that do not allow copying of this physiological feature. ",
    "url": "https://arxiv.org/abs/2310.02140",
    "authors": [
      "Luis F. Gomez",
      "Julian Fierrez",
      "Aythami Morales",
      "Mahdi Ghafourian",
      "Ruben Tolosana",
      "Imanol Solano",
      "Alejandro Garcia",
      "Francisco Zamora-Martinez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.02143",
    "title": "CORec-Cri: How collaborative and social technologies can help to  contextualize crises?",
    "abstract": "Crisis situations can present complex and multifaceted challenges, often requiring the involvement of multiple organizations and stakeholders with varying areas of expertise, responsibilities, and resources. Acquiring accurate and timely information about impacted areas is crucial to effectively respond to these crises. In this paper, we investigate how collaborative and social technologies help to contextualize crises, including identifying impacted areas and real-time needs. To this end, we define CORec-Cri (Contextulized Ontology-based Recommender system for crisis management) based on existing work. Our motivation for this approach is two-fold: first, effective collaboration among stakeholders is essential for efficient and coordinated crisis response; second, social computing facilitates interaction, information flow, and collaboration among stakeholders. We detail the key components of our system design, highlighting its potential to support decision-making, resource allocation, and communication among stakeholders. Finally, we provide examples of how our system can be applied to contextualize crises to improve crisis management. ",
    "url": "https://arxiv.org/abs/2310.02143",
    "authors": [
      "Ngoc Luyen Le",
      "Jinfeng Zhong",
      "Elsa Negre",
      "Marie-H\u00e9l\u00e8ne Abel"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.02147",
    "title": "Finite-Time Analysis of Whittle Index based Q-Learning for Restless  Multi-Armed Bandits with Neural Network Function Approximation",
    "abstract": "Whittle index policy is a heuristic to the intractable restless multi-armed bandits (RMAB) problem. Although it is provably asymptotically optimal, finding Whittle indices remains difficult. In this paper, we present Neural-Q-Whittle, a Whittle index based Q-learning algorithm for RMAB with neural network function approximation, which is an example of nonlinear two-timescale stochastic approximation with Q-function values updated on a faster timescale and Whittle indices on a slower timescale. Despite the empirical success of deep Q-learning, the non-asymptotic convergence rate of Neural-Q-Whittle, which couples neural networks with two-timescale Q-learning largely remains unclear. This paper provides a finite-time analysis of Neural-Q-Whittle, where data are generated from a Markov chain, and Q-function is approximated by a ReLU neural network. Our analysis leverages a Lyapunov drift approach to capture the evolution of two coupled parameters, and the nonlinearity in value function approximation further requires us to characterize the approximation error. Combing these provide Neural-Q-Whittle with $\\mathcal{O}(1/k^{2/3})$ convergence rate, where $k$ is the number of iterations. ",
    "url": "https://arxiv.org/abs/2310.02147",
    "authors": [
      "Guojun Xiong",
      "Jian Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.02156",
    "title": "Probabilistically Rewired Message-Passing Neural Networks",
    "abstract": "Message-passing graph neural networks (MPNNs) emerged as powerful tools for processing graph-structured input. However, they operate on a fixed input graph structure, ignoring potential noise and missing information. Furthermore, their local aggregation mechanism can lead to problems such as over-squashing and limited expressive power in capturing relevant graph structures. Existing solutions to these challenges have primarily relied on heuristic methods, often disregarding the underlying data distribution. Hence, devising principled approaches for learning to infer graph structures relevant to the given prediction task remains an open challenge. In this work, leveraging recent progress in exact and differentiable $k$-subset sampling, we devise probabilistically rewired MPNNs (PR-MPNNs), which learn to add relevant edges while omitting less beneficial ones. For the first time, our theoretical analysis explores how PR-MPNNs enhance expressive power, and we identify precise conditions under which they outperform purely randomized approaches. Empirically, we demonstrate that our approach effectively mitigates issues like over-squashing and under-reaching. In addition, on established real-world datasets, our method exhibits competitive or superior predictive performance compared to traditional MPNN models and recent graph transformer architectures. ",
    "url": "https://arxiv.org/abs/2310.02156",
    "authors": [
      "Chendi Qian",
      "Andrei Manolache",
      "Kareem Ahmed",
      "Zhe Zeng",
      "Guy Van den Broeck",
      "Mathias Niepert",
      "Christopher Morris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.02164",
    "title": "Graph Unlearning: A Review",
    "abstract": "Graph unlearning emerges as a crucial advancement in the pursuit of responsible AI, providing the means to remove sensitive data traces from trained models, thereby upholding the right to be forgotten. It is evident that graph machine learning exhibits sensitivity to data privacy and adversarial attacks, necessitating the application of graph unlearning techniques to address these concerns effectively. In this comprehensive survey paper, we present the first systematic review of graph unlearning approaches, encompassing a diverse array of methodologies and offering a detailed taxonomy and up-to-date literature overview to facilitate the understanding of researchers new to this field. Additionally, we establish the vital connections between graph unlearning and differential privacy, augmenting our understanding of the relevance of privacy-preserving techniques in this context. To ensure clarity, we provide lucid explanations of the fundamental concepts and evaluation measures used in graph unlearning, catering to a broader audience with varying levels of expertise. Delving into potential applications, we explore the versatility of graph unlearning across various domains, including but not limited to social networks, adversarial settings, and resource-constrained environments like the Internet of Things (IoT), illustrating its potential impact in safeguarding data privacy and enhancing AI systems' robustness. Finally, we shed light on promising research directions, encouraging further progress and innovation within the domain of graph unlearning. By laying a solid foundation and fostering continued progress, this survey seeks to inspire researchers to further advance the field of graph unlearning, thereby instilling confidence in the ethical growth of AI systems and reinforcing the responsible application of machine learning techniques in various domains. ",
    "url": "https://arxiv.org/abs/2310.02164",
    "authors": [
      "Anwar Said",
      "Tyler Derr",
      "Mudassir Shabbir",
      "Waseem Abbas",
      "Xenofon Koutsoukos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.02166",
    "title": "Large Language Models Meet Knowledge Graphs to Answer Factoid Questions",
    "abstract": "Recently, it has been shown that the incorporation of structured knowledge into Large Language Models significantly improves the results for a variety of NLP tasks. In this paper, we propose a method for exploring pre-trained Text-to-Text Language Models enriched with additional information from Knowledge Graphs for answering factoid questions. More specifically, we propose an algorithm for subgraphs extraction from a Knowledge Graph based on question entities and answer candidates. Then, we procure easily interpreted information with Transformer-based models through the linearization of the extracted subgraphs. Final re-ranking of the answer candidates with the extracted information boosts Hits@1 scores of the pre-trained text-to-text language models by 4-6%. ",
    "url": "https://arxiv.org/abs/2310.02166",
    "authors": [
      "Mikhail Salnikov",
      "Hai Le",
      "Prateek Rajput",
      "Irina Nikishina",
      "Pavel Braslavski",
      "Valentin Malykh",
      "Alexander Panchenko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.02172",
    "title": "Lyfe Agents: Generative agents for low-cost real-time social  interactions",
    "abstract": "Highly autonomous generative agents powered by large language models promise to simulate intricate social behaviors in virtual societies. However, achieving real-time interactions with humans at a low computational cost remains challenging. Here, we introduce Lyfe Agents. They combine low-cost with real-time responsiveness, all while remaining intelligent and goal-oriented. Key innovations include: (1) an option-action framework, reducing the cost of high-level decisions; (2) asynchronous self-monitoring for better self-consistency; and (3) a Summarize-and-Forget memory mechanism, prioritizing critical memory items at a low cost. We evaluate Lyfe Agents' self-motivation and sociability across several multi-agent scenarios in our custom LyfeGame 3D virtual environment platform. When equipped with our brain-inspired techniques, Lyfe Agents can exhibit human-like self-motivated social reasoning. For example, the agents can solve a crime (a murder mystery) through autonomous collaboration and information exchange. Meanwhile, our techniques enabled Lyfe Agents to operate at a computational cost 10-100 times lower than existing alternatives. Our findings underscore the transformative potential of autonomous generative agents to enrich human social experiences in virtual worlds. ",
    "url": "https://arxiv.org/abs/2310.02172",
    "authors": [
      "Zhao Kaiya",
      "Michelangelo Naim",
      "Jovana Kondic",
      "Manuel Cortes",
      "Jiaxin Ge",
      "Shuying Luo",
      "Guangyu Robert Yang",
      "Andrew Ahn"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.02201",
    "title": "Learnable Data Augmentation for One-Shot Unsupervised Domain Adaptation",
    "abstract": "This paper presents a classification framework based on learnable data augmentation to tackle the One-Shot Unsupervised Domain Adaptation (OS-UDA) problem. OS-UDA is the most challenging setting in Domain Adaptation, as only one single unlabeled target sample is assumed to be available for model adaptation. Driven by such single sample, our method LearnAug-UDA learns how to augment source data, making it perceptually similar to the target. As a result, a classifier trained on such augmented data will generalize well for the target domain. To achieve this, we designed an encoder-decoder architecture that exploits a perceptual loss and style transfer strategies to augment the source data. Our method achieves state-of-the-art performance on two well-known Domain Adaptation benchmarks, DomainNet and VisDA. The project code is available at https://github.com/IIT-PAVIS/LearnAug-UDA ",
    "url": "https://arxiv.org/abs/2310.02201",
    "authors": [
      "Julio Ivan Davila Carrazco",
      "Pietro Morerio",
      "Alessio Del Bue",
      "Vittorio Murino"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.02211",
    "title": "Fast Localization and Tracking in City-Scale UWB Networks",
    "abstract": "Localization of networked nodes is an essential problem in emerging applications, including first-responder navigation, automated manufacturing lines, vehicular and drone navigation, asset navigation and tracking, Internet of Things and 5G communication networks. In this paper, we present Locate3D, a novel system for peer-to-peer node localization and orientation estimation in large networks. Unlike traditional range-only methods, Locate3D introduces angle-of-arrival (AoA) data as an added network topology constraint. The system solves three key challenges: it uses angles to reduce the number of measurements required by 4x and jointly use range and angle data for location estimation. We develop a spanning-tree approach for fast location updates, and to ensure the output graphs are rigid and uniquely realizable, even in occluded or weakly connected areas. Locate3D cuts down latency by up to 75% without compromising accuracy, surpassing standard range-only solutions. It has a 10.2 meters median localization error for large-scale networks (30,000 nodes, 15 anchors spread across 14km square) and 0.5 meters for small-scale networks (10 nodes). ",
    "url": "https://arxiv.org/abs/2310.02211",
    "authors": [
      "Nakul Garg",
      "Irtaza Shahid",
      "Ramanujan K Sheshadri",
      "Karthikeyan Sundaresan",
      "Nirupam Roy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.02223",
    "title": "Optimum Monitoring of Heterogeneous Continuous Time Markov Chains",
    "abstract": "We study a remote monitoring system in which a collection of ergodic, aperiodic, mutually independent, and heterogeneous continuous time Markov chain (CTMC) based information sources is considered. In this system, a common remote monitor samples the states of the individual CTMCs according to a Poisson process with possibly different per-source sampling rates, in order to maintain remote estimates of the states of each of the sources. Three information freshness models are considered to quantify the accuracy of the remote estimates: fresh when equal (FWE), fresh when sampled (FWS) and fresh when close (FWC). For each of these freshness models, closed-form expressions are derived for mean information freshness for a given source. Using these expressions, optimum sampling rates for all sources are obtained so as to maximize the weighted sum freshness of the monitoring system under an overall sampling rate constraint. This optimization problem possesses a water-filling solution with quadratic worst case computational complexity in the number of information sources. Numerical examples are provided to validate the effectiveness of the optimum sampler in comparison to several baseline sampling policies. ",
    "url": "https://arxiv.org/abs/2310.02223",
    "authors": [
      "Nail Akar",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2310.02232",
    "title": "HoloNets: Spectral Convolutions do extend to Directed Graphs",
    "abstract": "Within the graph learning community, conventional wisdom dictates that spectral convolutional networks may only be deployed on undirected graphs: Only there could the existence of a well-defined graph Fourier transform be guaranteed, so that information may be translated between spatial- and spectral domains. Here we show this traditional reliance on the graph Fourier transform to be superfluous and -- making use of certain advanced tools from complex analysis and spectral theory -- extend spectral convolutions to directed graphs. We provide a frequency-response interpretation of newly developed filters, investigate the influence of the basis used to express filters and discuss the interplay with characteristic operators on which networks are based. In order to thoroughly test the developed theory, we conduct experiments in real world settings, showcasing that directed spectral convolutional networks provide new state of the art results for heterophilic node classification on many datasets and -- as opposed to baselines -- may be rendered stable to resolution-scale varying topological perturbations. ",
    "url": "https://arxiv.org/abs/2310.02232",
    "authors": [
      "Christian Koke",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.02234",
    "title": "MIS-AVioDD: Modality Invariant and Specific Representation for  Audio-Visual Deepfake Detection",
    "abstract": "Deepfakes are synthetic media generated using deep generative algorithms and have posed a severe societal and political threat. Apart from facial manipulation and synthetic voice, recently, a novel kind of deepfakes has emerged with either audio or visual modalities manipulated. In this regard, a new generation of multimodal audio-visual deepfake detectors is being investigated to collectively focus on audio and visual data for multimodal manipulation detection. Existing multimodal (audio-visual) deepfake detectors are often based on the fusion of the audio and visual streams from the video. Existing studies suggest that these multimodal detectors often obtain equivalent performances with unimodal audio and visual deepfake detectors. We conjecture that the heterogeneous nature of the audio and visual signals creates distributional modality gaps and poses a significant challenge to effective fusion and efficient performance. In this paper, we tackle the problem at the representation level to aid the fusion of audio and visual streams for multimodal deepfake detection. Specifically, we propose the joint use of modality (audio and visual) invariant and specific representations. This ensures that the common patterns and patterns specific to each modality representing pristine or fake content are preserved and fused for multimodal deepfake manipulation detection. Our experimental results on FakeAVCeleb and KoDF audio-visual deepfake datasets suggest the enhanced accuracy of our proposed method over SOTA unimodal and multimodal audio-visual deepfake detectors by $17.8$% and $18.4$%, respectively. Thus, obtaining state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2310.02234",
    "authors": [
      "Vinaya Sree Katamneni",
      "Ajita Rattani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.02237",
    "title": "Exploring Model Learning Heterogeneity for Boosting Ensemble Robustness",
    "abstract": "Deep neural network ensembles hold the potential of improving generalization performance for complex learning tasks. This paper presents formal analysis and empirical evaluation to show that heterogeneous deep ensembles with high ensemble diversity can effectively leverage model learning heterogeneity to boost ensemble robustness. We first show that heterogeneous DNN models trained for solving the same learning problem, e.g., object detection, can significantly strengthen the mean average precision (mAP) through our weighted bounding box ensemble consensus method. Second, we further compose ensembles of heterogeneous models for solving different learning problems, e.g., object detection and semantic segmentation, by introducing the connected component labeling (CCL) based alignment. We show that this two-tier heterogeneity driven ensemble construction method can compose an ensemble team that promotes high ensemble diversity and low negative correlation among member models of the ensemble, strengthening ensemble robustness against both negative examples and adversarial attacks. Third, we provide a formal analysis of the ensemble robustness in terms of negative correlation. Extensive experiments validate the enhanced robustness of heterogeneous ensembles in both benign and adversarial settings. The source codes are available on GitHub at https://github.com/git-disl/HeteRobust. ",
    "url": "https://arxiv.org/abs/2310.02237",
    "authors": [
      "Yanzhao Wu",
      "Ka-Ho Chow",
      "Wenqi Wei",
      "Ling Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.02244",
    "title": "Tensor Programs VI: Feature Learning in Infinite-Depth Neural Networks",
    "abstract": "By classifying infinite-width neural networks and identifying the *optimal* limit, Tensor Programs IV and V demonstrated a universal way, called $\\mu$P, for *widthwise hyperparameter transfer*, i.e., predicting optimal hyperparameters of wide neural networks from narrow ones. Here we investigate the analogous classification for *depthwise parametrizations* of deep residual networks (resnets). We classify depthwise parametrizations of block multiplier and learning rate by their infinite-width-then-depth limits. In resnets where each block has only one layer, we identify a unique optimal parametrization, called Depth-$\\mu$P that extends $\\mu$P and show empirically it admits depthwise hyperparameter transfer. We identify *feature diversity* as a crucial factor in deep networks, and Depth-$\\mu$P can be characterized as maximizing both feature learning and feature diversity. Exploiting this, we find that absolute value, among all homogeneous nonlinearities, maximizes feature diversity and indeed empirically leads to significant better performance. However, if each block is deeper (such as modern transformers), then we find fundamental limitations in all possible infinite-depth limits of such parametrizations, which we illustrate both theoretically and empirically on simple networks as well as Megatron transformer trained on Common Crawl. ",
    "url": "https://arxiv.org/abs/2310.02244",
    "authors": [
      "Greg Yang",
      "Dingli Yu",
      "Chen Zhu",
      "Soufiane Hayou"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2310.02247",
    "title": "Efficient Enumeration of Drawings and Combinatorial Structures for  Maximal Planar Graphs",
    "abstract": "We propose efficient algorithms for enumerating the notorious combinatorial structures of maximal planar graphs, called canonical orderings and Schnyder woods, and the related classical graph drawings by de Fraysseix, Pach, and Pollack [Combinatorica, 1990] and by Schnyder [SODA, 1990], called canonical drawings and Schnyder drawings, respectively. To this aim (i) we devise an algorithm for enumerating special $e$-bipolar orientations of maximal planar graphs, called canonical orientations; (ii) we establish bijections between canonical orientations and canonical drawings, and between canonical orientations and Schnyder drawings; and (iii) we exploit the known correspondence between canonical orientations and canonical orderings, and the known bijection between canonical orientations and Schnyder woods. All our enumeration algorithms have $O(n)$ setup time, space usage, and delay between any two consecutively listed outputs, for an $n$-vertex maximal planar graph. ",
    "url": "https://arxiv.org/abs/2310.02247",
    "authors": [
      "Giordano Da Lozzo",
      "Giuseppe Di Battista",
      "Fabrizio Frati",
      "Fabrizio Grosso",
      "Maurizio Patrignani"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2310.02249",
    "title": "Harnessing Pre-Trained Sentence Transformers for Offensive Language  Detection in Indian Languages",
    "abstract": "In our increasingly interconnected digital world, social media platforms have emerged as powerful channels for the dissemination of hate speech and offensive content. This work delves into the domain of hate speech detection, placing specific emphasis on three low-resource Indian languages: Bengali, Assamese, and Gujarati. The challenge is framed as a text classification task, aimed at discerning whether a tweet contains offensive or non-offensive content. Leveraging the HASOC 2023 datasets, we fine-tuned pre-trained BERT and SBERT models to evaluate their effectiveness in identifying hate speech. Our findings underscore the superiority of monolingual sentence-BERT models, particularly in the Bengali language, where we achieved the highest ranking. However, the performance in Assamese and Gujarati languages signifies ongoing opportunities for enhancement. Our goal is to foster inclusive online spaces by countering hate speech proliferation. ",
    "url": "https://arxiv.org/abs/2310.02249",
    "authors": [
      "Ananya Joshi",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.02258",
    "title": "A Neural Scaling Law from Lottery Ticket Ensembling",
    "abstract": "Neural scaling laws (NSL) refer to the phenomenon where model performance improves with scale. Sharma & Kaplan analyzed NSL using approximation theory and predict that MSE losses decay as $N^{-\\alpha}$, $\\alpha=4/d$, where $N$ is the number of model parameters, and $d$ is the intrinsic input dimension. Although their theory works well for some cases (e.g., ReLU networks), we surprisingly find that a simple 1D problem $y=x^2$ manifests a different scaling law ($\\alpha=1$) from their predictions ($\\alpha=4$). We opened the neural networks and found that the new scaling law originates from lottery ticket ensembling: a wider network on average has more \"lottery tickets\", which are ensembled to reduce the variance of outputs. We support the ensembling mechanism by mechanistically interpreting single neural networks, as well as studying them statistically. We attribute the $N^{-1}$ scaling law to the \"central limit theorem\" of lottery tickets. Finally, we discuss its potential implications for large language models and statistical physics-type theories of learning. ",
    "url": "https://arxiv.org/abs/2310.02258",
    "authors": [
      "Ziming Liu",
      "Max Tegmark"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.01515",
    "title": "Tensor Ring Optimized Quantum-Enhanced Tensor Neural Networks",
    "abstract": "Quantum machine learning researchers often rely on incorporating Tensor Networks (TN) into Deep Neural Networks (DNN) and variational optimization. However, the standard optimization techniques used for training the contracted trainable weights of each model layer suffer from the correlations and entanglement structure between the model parameters on classical implementations. To address this issue, a multi-layer design of a Tensor Ring optimized variational Quantum learning classifier (Quan-TR) comprising cascading entangling gates replacing the fully connected (dense) layers of a TN is proposed, and it is referred to as Tensor Ring optimized Quantum-enhanced tensor neural Networks (TR-QNet). TR-QNet parameters are optimized through the stochastic gradient descent algorithm on qubit measurements. The proposed TR-QNet is assessed on three distinct datasets, namely Iris, MNIST, and CIFAR-10, to demonstrate the enhanced precision achieved for binary classification. On quantum simulations, the proposed TR-QNet achieves promising accuracy of $94.5\\%$, $86.16\\%$, and $83.54\\%$ on the Iris, MNIST, and CIFAR-10 datasets, respectively. Benchmark studies have been conducted on state-of-the-art quantum and classical implementations of TN models to show the efficacy of the proposed TR-QNet. Moreover, the scalability of TR-QNet highlights its potential for exhibiting in deep learning applications on a large scale. The PyTorch implementation of TR-QNet is available on Github:https://github.com/konar1987/TR-QNet/ ",
    "url": "https://arxiv.org/abs/2310.01515",
    "authors": [
      "Debanjan Konar",
      "Dheeraj Peddireddy",
      "Vaneet Aggarwal",
      "Bijaya K. Panigrahi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01583",
    "title": "An Investigation of Representation and Allocation Harms in Contrastive  Learning",
    "abstract": "The effect of underrepresentation on the performance of minority groups is known to be a serious problem in supervised learning settings; however, it has been underexplored so far in the context of self-supervised learning (SSL). In this paper, we demonstrate that contrastive learning (CL), a popular variant of SSL, tends to collapse representations of minority groups with certain majority groups. We refer to this phenomenon as representation harm and demonstrate it on image and text datasets using the corresponding popular CL methods. Furthermore, our causal mediation analysis of allocation harm on a downstream classification task reveals that representation harm is partly responsible for it, thus emphasizing the importance of studying and mitigating representation harm. Finally, we provide a theoretical explanation for representation harm using a stochastic block model that leads to a representational neural collapse in a contrastive learning setting. ",
    "url": "https://arxiv.org/abs/2310.01583",
    "authors": [
      "Subha Maity",
      "Mayank Agarwal",
      "Mikhail Yurochkin",
      "Yuekai Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01609",
    "title": "Adversarial Contextual Bandits Go Kernelized",
    "abstract": "We study a generalization of the problem of online learning in adversarial linear contextual bandits by incorporating loss functions that belong to a reproducing kernel Hilbert space, which allows for a more flexible modeling of complex decision-making scenarios. We propose a computationally efficient algorithm that makes use of a new optimistically biased estimator for the loss functions and achieves near-optimal regret guarantees under a variety of eigenvalue decay assumptions made on the underlying kernel. Specifically, under the assumption of polynomial eigendecay with exponent $c>1$, the regret is $\\widetilde{O}(KT^{\\frac{1}{2}(1+\\frac{1}{c})})$, where $T$ denotes the number of rounds and $K$ the number of actions. Furthermore, when the eigendecay follows an exponential pattern, we achieve an even tighter regret bound of $\\widetilde{O}(\\sqrt{T})$. These rates match the lower bounds in all special cases where lower bounds are known at all, and match the best known upper bounds available for the more well-studied stochastic counterpart of our problem. ",
    "url": "https://arxiv.org/abs/2310.01609",
    "authors": [
      "Gergely Neu",
      "Julia Olkhovskaya",
      "Sattar Vakili"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01683",
    "title": "Commutative Width and Depth Scaling in Deep Neural Networks",
    "abstract": "This paper is the second in the series Commutative Scaling of Width and Depth (WD) about commutativity of infinite width and depth limits in deep neural networks. Our aim is to understand the behaviour of neural functions (functions that depend on a neural network model) as width and depth go to infinity (in some sense), and eventually identify settings under which commutativity holds, i.e. the neural function tends to the same limit no matter how width and depth limits are taken. In this paper, we formally introduce and define the commutativity framework, and discuss its implications on neural network design and scaling. We study commutativity for the neural covariance kernel which reflects how network layers separate data. Our findings extend previous results established in [55] by showing that taking the width and depth to infinity in a deep neural network with skip connections, when branches are suitably scaled to avoid exploding behaviour, result in the same covariance structure no matter how that limit is taken. This has a number of theoretical and practical implications that we discuss in the paper. The proof techniques in this paper are novel and rely on tools that are more accessible to readers who are not familiar with stochastic calculus (used in the proofs of WD(I))). ",
    "url": "https://arxiv.org/abs/2310.01683",
    "authors": [
      "Soufiane Hayou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01756",
    "title": "Improved Algorithms for Adversarial Bandits with Unbounded Losses",
    "abstract": "We consider the Adversarial Multi-Armed Bandits (MAB) problem with unbounded losses, where the algorithms have no prior knowledge on the sizes of the losses. We present UMAB-NN and UMAB-G, two algorithms for non-negative and general unbounded loss respectively. For non-negative unbounded loss, UMAB-NN achieves the first adaptive and scale free regret bound without uniform exploration. Built up on that, we further develop UMAB-G that can learn from arbitrary unbounded loss. Our analysis reveals the asymmetry between positive and negative losses in the MAB problem and provide additional insights. We also accompany our theoretical findings with extensive empirical evaluations, showing that our algorithms consistently out-performs all existing algorithms that handles unbounded losses. ",
    "url": "https://arxiv.org/abs/2310.01756",
    "authors": [
      "Mingyu Chen",
      "Xuezhou Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01799",
    "title": "SMRD: SURE-based Robust MRI Reconstruction with Diffusion Models",
    "abstract": "Diffusion models have recently gained popularity for accelerated MRI reconstruction due to their high sample quality. They can effectively serve as rich data priors while incorporating the forward model flexibly at inference time, and they have been shown to be more robust than unrolled methods under distribution shifts. However, diffusion models require careful tuning of inference hyperparameters on a validation set and are still sensitive to distribution shifts during testing. To address these challenges, we introduce SURE-based MRI Reconstruction with Diffusion models (SMRD), a method that performs test-time hyperparameter tuning to enhance robustness during testing. SMRD uses Stein's Unbiased Risk Estimator (SURE) to estimate the mean squared error of the reconstruction during testing. SURE is then used to automatically tune the inference hyperparameters and to set an early stopping criterion without the need for validation tuning. To the best of our knowledge, SMRD is the first to incorporate SURE into the sampling stage of diffusion models for automatic hyperparameter selection. SMRD outperforms diffusion model baselines on various measurement noise levels, acceleration factors, and anatomies, achieving a PSNR improvement of up to 6 dB under measurement noise. The code is publicly available at https://github.com/batuozt/SMRD . ",
    "url": "https://arxiv.org/abs/2310.01799",
    "authors": [
      "Batu Ozturkler",
      "Chao Liu",
      "Benjamin Eckart",
      "Morteza Mardani",
      "Jiaming Song",
      "Jan Kautz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.01885",
    "title": "Synthetic CT Generation via Variant Invertible Network for All-digital  Brain PET Attenuation Correction",
    "abstract": "Attenuation correction (AC) is essential for the generation of artifact-free and quantitatively accurate positron emission tomography (PET) images. However, AC of PET faces challenges including inter-scan motion and erroneous transformation of structural voxel-intensities to PET attenuation-correction factors. Nowadays, the problem of AC for quantitative PET have been solved to a large extent after the commercial availability of devices combining PET with computed tomography (CT). Meanwhile, considering the feasibility of a deep learning approach for PET AC without anatomical imaging, this paper develops a PET AC method, which uses deep learning to generate continuously valued CT images from non-attenuation corrected PET images for AC on brain PET imaging. Specifically, an invertible network combined with the variable augmentation strategy that can achieve the bidirectional inference processes is proposed for synthetic CT generation (IVNAC). To evaluate the performance of the proposed algorithm, we conducted a comprehensive study on a total of 1440 data from 37 clinical patients using comparative algorithms (such as Cycle-GAN and Pix2pix). Perceptual analysis and quantitative evaluations illustrate that the invertible network for PET AC outperforms other existing AC models, which demonstrates the potential of the proposed method and the feasibility of achieving brain PET AC without CT. ",
    "url": "https://arxiv.org/abs/2310.01885",
    "authors": [
      "Yu Guan",
      "Bohui Shen",
      "Xinchong Shi",
      "Xiangsong Zhang",
      "Bingxuan Li",
      "Qiegen Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2310.01934",
    "title": "Robust deformable image registration using cycle-consistent implicit  representations",
    "abstract": "Recent works in medical image registration have proposed the use of Implicit Neural Representations, demonstrating performance that rivals state-of-the-art learning-based methods. However, these implicit representations need to be optimized for each new image pair, which is a stochastic process that may fail to converge to a global minimum. To improve robustness, we propose a deformable registration method using pairs of cycle-consistent Implicit Neural Representations: each implicit representation is linked to a second implicit representation that estimates the opposite transformation, causing each network to act as a regularizer for its paired opposite. During inference, we generate multiple deformation estimates by numerically inverting the paired backward transformation and evaluating the consensus of the optimized pair. This consensus improves registration accuracy over using a single representation and results in a robust uncertainty metric that can be used for automatic quality control. We evaluate our method with a 4D lung CT dataset. The proposed cycle-consistent optimization method reduces the optimization failure rate from 2.4% to 0.0% compared to the current state-of-the-art. The proposed inference method improves landmark accuracy by 4.5% and the proposed uncertainty metric detects all instances where the registration method fails to converge to a correct solution. We verify the generalizability of these results to other data using a centerline propagation task in abdominal 4D MRI, where our method achieves a 46% improvement in propagation consistency compared with single-INR registration and demonstrates a strong correlation between the proposed uncertainty metric and registration accuracy. ",
    "url": "https://arxiv.org/abs/2310.01934",
    "authors": [
      "Louis D. van Harten",
      "Jaap Stoker",
      "Ivana I\u0161gum"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.02068",
    "title": "Well-posedness and numerical analysis of an elapsed time model with  strongly coupled neural networks",
    "abstract": "The elapsed time equation is an age-structured model that describes dynamics of interconnected spiking neurons through the elapsed time since the last discharge, leading to many interesting questions on the evolution of the system from a mathematical and biological point of view. In this work, we first deal with the case when transmission after a spike is instantaneous and the case when there exists a distributed delay that depends on previous history of the system, which is a more realistic assumption. Then we study the well-posedness and the numerical analysis of the elapsed time models. For existence and uniqueness we improve the previous works by relaxing some hypothesis on the nonlinearity, including the strongly excitatory case, while for the numerical analysis we prove that the approximation given by the explicit upwind scheme converges to the solution of the non-linear problem. We also show some numerical simulations to compare the behavior of the system in the case of instantaneous transmission with the case of distributed delay under different parameters, leading to solutions with different asymptotic profiles. ",
    "url": "https://arxiv.org/abs/2310.02068",
    "authors": [
      "Mauricio Sepulveda",
      "Nicolas Torres",
      "Luis Miguel Villada"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.02074",
    "title": "ACE: A fast, skillful learned global atmospheric model for climate  prediction",
    "abstract": "Existing ML-based atmospheric models are not suitable for climate prediction, which requires long-term stability and physical consistency. We present ACE (AI2 Climate Emulator), a 200M-parameter, autoregressive machine learning emulator of an existing comprehensive 100-km resolution global atmospheric model. The formulation of ACE allows evaluation of physical laws such as the conservation of mass and moisture. The emulator is stable for 10 years, nearly conserves column moisture without explicit constraints and faithfully reproduces the reference model's climate, outperforming a challenging baseline on over 80% of tracked variables. ACE requires nearly 100x less wall clock time and is 100x more energy efficient than the reference model using typically available resources. ",
    "url": "https://arxiv.org/abs/2310.02074",
    "authors": [
      "Oliver Watt-Meyer",
      "Gideon Dresdner",
      "Jeremy McGibbon",
      "Spencer K. Clark",
      "Brian Henn",
      "James Duncan",
      "Noah D. Brenowitz",
      "Karthik Kashinath",
      "Michael S. Pritchard",
      "Boris Bonev",
      "Matthew E. Peters",
      "Christopher S. Bretherton"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.02152",
    "title": "Graph Neural Network-based EEG Classification: A Survey",
    "abstract": "Graph neural networks (GNN) are increasingly used to classify EEG for tasks such as emotion recognition, motor imagery and neurological diseases and disorders. A wide range of methods have been proposed to design GNN-based classifiers. Therefore, there is a need for a systematic review and categorisation of these approaches. We exhaustively search the published literature on this topic and derive several categories for comparison. These categories highlight the similarities and differences among the methods. The results suggest a prevalence of spectral graph convolutional layers over spatial. Additionally, we identify standard forms of node features, with the most popular being the raw EEG signal and differential entropy. Our results summarise the emerging trends in GNN-based approaches for EEG classification. Finally, we discuss several promising research directions, such as exploring the potential of transfer learning methods and appropriate modelling of cross-frequency interactions. ",
    "url": "https://arxiv.org/abs/2310.02152",
    "authors": [
      "Dominik Klepl",
      "Min Wu",
      "Fei He"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2310.02215",
    "title": "An experimental system for detection and localization of hemorrhage  using ultra-wideband microwaves with deep learning",
    "abstract": "Stroke is a leading cause of mortality and disability. Emergent diagnosis and intervention are critical, and predicated upon initial brain imaging; however, existing clinical imaging modalities are generally costly, immobile, and demand highly specialized operation and interpretation. Low-energy microwaves have been explored as low-cost, small form factor, fast, and safe probes of tissue dielectric properties, with both imaging and diagnostic potential. Nevertheless, challenges inherent to microwave reconstruction have impeded progress, hence microwave imaging (MWI) remains an elusive scientific aim. Herein, we introduce a dedicated experimental framework comprising a robotic navigation system to translate blood-mimicking phantoms within an anatomically realistic human head model. An 8-element ultra-wideband (UWB) array of modified antipodal Vivaldi antennas was developed and driven by a two-port vector network analyzer spanning 0.6-9.0 GHz at an operating power of 1 mw. Complex scattering parameters were measured, and dielectric signatures of hemorrhage were learned using a dedicated deep neural network for prediction of hemorrhage classes and localization. An overall sensitivity and specificity for detection >0.99 was observed, with Rayliegh mean localization error of 1.65 mm. The study establishes the feasibility of a robust experimental model and deep learning solution for UWB microwave stroke detection. ",
    "url": "https://arxiv.org/abs/2310.02215",
    "authors": [
      "Eisa Hedayati",
      "Fatemeh Safari",
      "George Verghese",
      "Vito R. Ciancia",
      "Daniel K. Sodickson",
      "Seena Dehkharghani",
      "Leeor Alon"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2008.05825",
    "title": "Unifying supervised learning and VAEs -- coverage, systematics and  goodness-of-fit in normalizing-flow based neural network models for  astro-particle reconstructions",
    "abstract": " Title: Unifying supervised learning and VAEs -- coverage, systematics and  goodness-of-fit in normalizing-flow based neural network models for  astro-particle reconstructions ",
    "url": "https://arxiv.org/abs/2008.05825",
    "authors": [
      "Thorsten Gl\u00fcsenkamp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2010.08019",
    "title": "Error estimates of residual minimization using neural networks for  linear PDEs",
    "abstract": " Title: Error estimates of residual minimization using neural networks for  linear PDEs ",
    "url": "https://arxiv.org/abs/2010.08019",
    "authors": [
      "Yeonjong Shin",
      "Zhongqiang Zhang",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2106.02626",
    "title": "Dynamics of specialization in neural modules under resource constraints",
    "abstract": " Title: Dynamics of specialization in neural modules under resource constraints ",
    "url": "https://arxiv.org/abs/2106.02626",
    "authors": [
      "Gabriel B\u00e9na",
      "Dan F. M. Goodman"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2108.11299",
    "title": "Certifiers Make Neural Networks Vulnerable to Availability Attacks",
    "abstract": " Comments: Published at 16th ACM Workshop on Artificial Intelligence and Security (AISec '23) ",
    "url": "https://arxiv.org/abs/2108.11299",
    "authors": [
      "Tobias Lorenz",
      "Marta Kwiatkowska",
      "Mario Fritz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01446",
    "title": "RoLoMa: Robust Loco-Manipulation for Quadruped Robots with Arms",
    "abstract": " Comments: 16 pages, accepted to Autonomous Robots. For associated videos, see this https URL ",
    "url": "https://arxiv.org/abs/2203.01446",
    "authors": [
      "Henrique Ferrolho",
      "Vladimir Ivan",
      "Wolfgang Merkt",
      "Ioannis Havoutis",
      "Sethu Vijayakumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2203.03958",
    "title": "Betweenness Approximation for Edge Computing with Hypergraph Neural  Network",
    "abstract": " Title: Betweenness Approximation for Edge Computing with Hypergraph Neural  Network ",
    "url": "https://arxiv.org/abs/2203.03958",
    "authors": [
      "Yaguang Guo",
      "Wenxin Xie",
      "Qingren Wang",
      "Dengcheng Yan",
      "Yiwen Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.06318",
    "title": "Limited-Trust in Diffusion of Competing Alternatives over Social  Networks",
    "abstract": " Title: Limited-Trust in Diffusion of Competing Alternatives over Social  Networks ",
    "url": "https://arxiv.org/abs/2206.06318",
    "authors": [
      "Vincent Leon",
      "S. Rasoul Etesami",
      "Rakesh Nagi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2208.08723",
    "title": "Disentangled Contrastive Learning for Social Recommendation",
    "abstract": " Comments: CIKM2022 ",
    "url": "https://arxiv.org/abs/2208.08723",
    "authors": [
      "Jiahao Wu",
      "Wenqi Fan",
      "Jingfan Chen",
      "Shengcai Liu",
      "Qing Li",
      "Ke Tang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.09404",
    "title": "A Machine Learning Approach to Solving Large Bilevel and Stochastic  Programs: Application to Cycling Network Design",
    "abstract": " Title: A Machine Learning Approach to Solving Large Bilevel and Stochastic  Programs: Application to Cycling Network Design ",
    "url": "https://arxiv.org/abs/2209.09404",
    "authors": [
      "Timothy C. Y. Chan",
      "Bo Lin",
      "Shoshanna Saxe"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00383",
    "title": "On minimally tough chordal graphs",
    "abstract": " Title: On minimally tough chordal graphs ",
    "url": "https://arxiv.org/abs/2210.00383",
    "authors": [
      "Cl\u00e9ment Dallard",
      "Blas Fern\u00e1ndez",
      "Gyula Y. Katona",
      "Martin Milani\u010d",
      "Kitti Varga"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2210.02166",
    "title": "Robust Bayesian Inference for Moving Horizon Estimation",
    "abstract": " Comments: 17 pages ",
    "url": "https://arxiv.org/abs/2210.02166",
    "authors": [
      "Wenhan Cao",
      "Chang Liu",
      "Zhiqian Lan",
      "Shengbo Eben Li",
      "Wei Pan",
      "Angelo Alessandri"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.02808",
    "title": "Effective Self-supervised Pre-training on Low-compute Networks without  Distillation",
    "abstract": " Comments: ICLR 2023 Camera Ready. Code is publicly available at this https URL ",
    "url": "https://arxiv.org/abs/2210.02808",
    "authors": [
      "Fuwen Tan",
      "Fatemeh Saleh",
      "Brais Martinez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.06282",
    "title": "DialoGen: Generalized Long-Range Context Representation for Dialogue  Systems",
    "abstract": " Comments: Accepted at PACLIC 2023 ",
    "url": "https://arxiv.org/abs/2210.06282",
    "authors": [
      "Suvodip Dey",
      "Maunendra Sankar Desarkar",
      "Asif Ekbal",
      "P.K. Srijith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.12921",
    "title": "Learning k-Level Sparse Neural Networks Using a New Generalized Weighted  Group Sparse Envelope Regularization",
    "abstract": " Title: Learning k-Level Sparse Neural Networks Using a New Generalized Weighted  Group Sparse Envelope Regularization ",
    "url": "https://arxiv.org/abs/2212.12921",
    "authors": [
      "Yehonathan Refael",
      "Iftach Arbel",
      "Wasim Huleihel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.00492",
    "title": "Lumos: Heterogeneity-aware Federated Graph Learning over Decentralized  Devices",
    "abstract": " Comments: 13 pages, 7 figures, published in the Proceedings of the 39th IEEE International Conference on Data Engineering (ICDE 2023) ",
    "url": "https://arxiv.org/abs/2303.00492",
    "authors": [
      "Qiying Pan",
      "Yifei Zhu",
      "Lingyang Chu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.09590",
    "title": "Visual Analytics of Multivariate Networks with Representation Learning  and Composite Variable Construction",
    "abstract": " Comments: The previous version of this manuscript was accepted for publication by a journal. We decided to withdraw the version because the journal made an unacceptable requirement for us: change of the authors' affiliations ",
    "url": "https://arxiv.org/abs/2303.09590",
    "authors": [
      "Hsiao-Ying Lu",
      "Takanori Fujiwara",
      "Ming-Yi Chang",
      "Yang-chih Fu",
      "Anders Ynnerman",
      "Kwan-Liu Ma"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.13372",
    "title": "DRSM: De-Randomized Smoothing on Malware Classifier Providing Certified  Robustness",
    "abstract": " Title: DRSM: De-Randomized Smoothing on Malware Classifier Providing Certified  Robustness ",
    "url": "https://arxiv.org/abs/2303.13372",
    "authors": [
      "Shoumik Saha",
      "Wenxiao Wang",
      "Yigitcan Kaya",
      "Soheil Feizi",
      "Tudor Dumitras"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04736",
    "title": "On the Possibilities of AI-Generated Text Detection",
    "abstract": " Title: On the Possibilities of AI-Generated Text Detection ",
    "url": "https://arxiv.org/abs/2304.04736",
    "authors": [
      "Souradip Chakraborty",
      "Amrit Singh Bedi",
      "Sicheng Zhu",
      "Bang An",
      "Dinesh Manocha",
      "Furong Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.06656",
    "title": "Improved Approximations for Relative Survivable Network Design",
    "abstract": " Comments: 34 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2304.06656",
    "authors": [
      "Michael Dinitz",
      "Ama Koranteng",
      "Guy Kortsarz",
      "Zeev Nutov"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2304.12541",
    "title": "Efficient Bayesian inference using physics-informed invertible neural  networks for inverse problems",
    "abstract": " Title: Efficient Bayesian inference using physics-informed invertible neural  networks for inverse problems ",
    "url": "https://arxiv.org/abs/2304.12541",
    "authors": [
      "Xiaofei Guan",
      "Xintong Wang",
      "Hao Wu",
      "Zihao Yang",
      "Peng Yu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.02154",
    "title": "Spectral bound for random Schreier graphs of the general linear group",
    "abstract": " Comments: 32 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2305.02154",
    "authors": [
      "Geoffroy Caillat-Grenier"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2305.13269",
    "title": "Chain-of-Knowledge: Grounding Large Language Models via Dynamic  Knowledge Adapting over Heterogeneous Sources",
    "abstract": " Title: Chain-of-Knowledge: Grounding Large Language Models via Dynamic  Knowledge Adapting over Heterogeneous Sources ",
    "url": "https://arxiv.org/abs/2305.13269",
    "authors": [
      "Xingxuan Li",
      "Ruochen Zhao",
      "Yew Ken Chia",
      "Bosheng Ding",
      "Shafiq Joty",
      "Soujanya Poria",
      "Lidong Bing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14122",
    "title": "Transferring Learning Trajectories of Neural Networks",
    "abstract": " Comments: v2: updates include theoretical analysis and additional experiments ",
    "url": "https://arxiv.org/abs/2305.14122",
    "authors": [
      "Daiki Chijiwa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.16446",
    "title": "The Representation Jensen-Shannon Divergence",
    "abstract": " Title: The Representation Jensen-Shannon Divergence ",
    "url": "https://arxiv.org/abs/2305.16446",
    "authors": [
      "Jhoan K. Hoyos-Osorio",
      "Santiago Posso-Murillo",
      "Luis G. Sanchez-Giraldo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.18030",
    "title": "Automated Search-Space Generation Neural Architecture Search",
    "abstract": " Comments: Graph visualization for DARTS, SuperResNet are omitted for arXiv version due to exceeding page dimension limit. Please refer to the open-review version for taking the visualizations ",
    "url": "https://arxiv.org/abs/2305.18030",
    "authors": [
      "Tianyi Chen",
      "Luming Liang",
      "Tianyu Ding",
      "Ilya Zharkov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18593",
    "title": "On Diffusion Modeling for Anomaly Detection",
    "abstract": " Title: On Diffusion Modeling for Anomaly Detection ",
    "url": "https://arxiv.org/abs/2305.18593",
    "authors": [
      "Victor Livernoche",
      "Vineet Jain",
      "Yashar Hezaveh",
      "Siamak Ravanbakhsh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19337",
    "title": "HiGen: Hierarchical Graph Generative Networks",
    "abstract": " Comments: 9 pages ",
    "url": "https://arxiv.org/abs/2305.19337",
    "authors": [
      "Mahdi Karami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.00814",
    "title": "Vocos: Closing the gap between time-domain and Fourier-based neural  vocoders for high-quality audio synthesis",
    "abstract": " Title: Vocos: Closing the gap between time-domain and Fourier-based neural  vocoders for high-quality audio synthesis ",
    "url": "https://arxiv.org/abs/2306.00814",
    "authors": [
      "Hubert Siuzdak"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.01102",
    "title": "LLMatic: Neural Architecture Search via Large Language Models and  Quality Diversity Optimization",
    "abstract": " Title: LLMatic: Neural Architecture Search via Large Language Models and  Quality Diversity Optimization ",
    "url": "https://arxiv.org/abs/2306.01102",
    "authors": [
      "Muhammad U. Nasir",
      "Sam Earle",
      "Julian Togelius",
      "Steven James",
      "Christopher Cleghorn"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.06900",
    "title": "Improving Knee Joint Angle Prediction through Dynamic Contextual Focus  and Gated Linear Units",
    "abstract": " Comments: Under consideration at Pattern Recognition Letters ",
    "url": "https://arxiv.org/abs/2306.06900",
    "authors": [
      "Lyes Saad Saoud",
      "Humaid Ibrahim",
      "Ahmad Aljarah",
      "Irfan Hussain"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2306.07888",
    "title": "CAMEO: A Causal Transfer Learning Approach for Performance Optimization  of Configurable Computer Systems",
    "abstract": " Title: CAMEO: A Causal Transfer Learning Approach for Performance Optimization  of Configurable Computer Systems ",
    "url": "https://arxiv.org/abs/2306.07888",
    "authors": [
      "Md Shahriar Iqbal",
      "Ziyuan Zhong",
      "Iftakhar Ahmad",
      "Baishakhi Ray",
      "Pooyan Jamshidi"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.11238",
    "title": "CAMP-Net: Consistency-Aware Multi-Prior Network for Accelerated MRI  Reconstruction",
    "abstract": " Title: CAMP-Net: Consistency-Aware Multi-Prior Network for Accelerated MRI  Reconstruction ",
    "url": "https://arxiv.org/abs/2306.11238",
    "authors": [
      "Liping Zhang",
      "Xiaobo Li",
      "Weitian Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.00481",
    "title": "Seeing is not Believing: An Identity Hider for Human Vision Privacy  Protection",
    "abstract": " Title: Seeing is not Believing: An Identity Hider for Human Vision Privacy  Protection ",
    "url": "https://arxiv.org/abs/2307.00481",
    "authors": [
      "Tao Wang",
      "Yushu Zhang",
      "Zixuan Yang",
      "Hua Zhang",
      "Zhongyun Hua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.00724",
    "title": "LXL: LiDAR Excluded Lean 3D Object Detection with 4D Imaging Radar and  Camera Fusion",
    "abstract": " Comments: Accepted by IEEE Transactions on Intelligent Vehicles ",
    "url": "https://arxiv.org/abs/2307.00724",
    "authors": [
      "Weiyi Xiong",
      "Jianan Liu",
      "Tao Huang",
      "Qing-Long Han",
      "Yuxuan Xia",
      "Bing Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.09520",
    "title": "Adversarial Bayesian Augmentation for Single-Source Domain  Generalization",
    "abstract": " Comments: Accepted to ICCV 2023 ",
    "url": "https://arxiv.org/abs/2307.09520",
    "authors": [
      "Sheng Cheng",
      "Tejas Gokhale",
      "Yezhou Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12360",
    "title": "Unravelling the Mechanics of Knitted Fabrics Through Hierarchical  Geometric Representation",
    "abstract": " Title: Unravelling the Mechanics of Knitted Fabrics Through Hierarchical  Geometric Representation ",
    "url": "https://arxiv.org/abs/2307.12360",
    "authors": [
      "Xiaoxiao Ding",
      "Vanessa Sanchez",
      "Katia Bertoldi",
      "Chris H. Rycroft"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2307.15514",
    "title": "Revisiting Fully Convolutional Geometric Features for Object 6D Pose  Estimation",
    "abstract": " Comments: Camera ready version, 18 pages and 13 figures. Published at the 8th International Workshop on Recovering 6D Object Pose ",
    "url": "https://arxiv.org/abs/2307.15514",
    "authors": [
      "Jaime Corsetti",
      "Davide Boscaini",
      "Fabio Poiesi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.16412",
    "title": "RCS-YOLO: A Fast and High-Accuracy Object Detector for Brain Tumor  Detection",
    "abstract": " Title: RCS-YOLO: A Fast and High-Accuracy Object Detector for Brain Tumor  Detection ",
    "url": "https://arxiv.org/abs/2307.16412",
    "authors": [
      "Ming Kang",
      "Chee-Ming Ting",
      "Fung Fung Ting",
      "Rapha\u00ebl C.-W. Phan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.07505",
    "title": "Data Race Detection Using Large Language Models",
    "abstract": " Title: Data Race Detection Using Large Language Models ",
    "url": "https://arxiv.org/abs/2308.07505",
    "authors": [
      "Le Chen",
      "Xianzhong Ding",
      "Murali Emani",
      "Tristan Vanderbruggen",
      "Pei-hung Lin",
      "Chuanhua Liao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.12899",
    "title": "Unified Data Management and Comprehensive Performance Evaluation for  Urban Spatial-Temporal Prediction [Experiment, Analysis & Benchmark]",
    "abstract": " Comments: 14 pages, 3 figures, VLDB under review ",
    "url": "https://arxiv.org/abs/2308.12899",
    "authors": [
      "Jiawei Jiang",
      "Chengkai Han",
      "Wayne Xin Zhao",
      "Jingyuan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.14847",
    "title": "NSF: Neural Surface Fields for Human Modeling from Monocular Depth",
    "abstract": " Comments: Accpted to ICCV 2023; Homepage at: this https URL ",
    "url": "https://arxiv.org/abs/2308.14847",
    "authors": [
      "Yuxuan Xue",
      "Bharat Lal Bhatnagar",
      "Riccardo Marin",
      "Nikolaos Sarafianos",
      "Yuanlu Xu",
      "Gerard Pons-Moll",
      "Tony Tung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.04644",
    "title": "Towards Understanding Neural Collapse: The Effects of Batch  Normalization and Weight Decay",
    "abstract": " Title: Towards Understanding Neural Collapse: The Effects of Batch  Normalization and Weight Decay ",
    "url": "https://arxiv.org/abs/2309.04644",
    "authors": [
      "Leyan Pan",
      "Xinyuan Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.04747",
    "title": "When to Learn What: Model-Adaptive Data Augmentation Curriculum",
    "abstract": " Comments: Our paper is accpeted by ICCV 2023 ",
    "url": "https://arxiv.org/abs/2309.04747",
    "authors": [
      "Chengkai Hou",
      "Jieyu Zhang",
      "Tianyi Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.05379",
    "title": "On Truthful Constrained Heterogeneous Facility Location with Max-Variant  Cost",
    "abstract": " Title: On Truthful Constrained Heterogeneous Facility Location with Max-Variant  Cost ",
    "url": "https://arxiv.org/abs/2309.05379",
    "authors": [
      "Mohammad Lotfi",
      "Alexandros A. Voudouris"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2309.08835",
    "title": "Intelligent machines work in unstructured environments by differential  neural computing",
    "abstract": " Comments: 17 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2309.08835",
    "authors": [
      "Shengbo Wang",
      "Shuo Gao",
      "Chenyu Tang",
      "Cong Li",
      "Shurui Wang",
      "Jiaqi Wang",
      "Hubin Zhao",
      "Guohua Hu",
      "Arokia Nathan",
      "Ravinder Dahiya",
      "Luigi Occhipinti"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.09075",
    "title": "Music Generation based on Generative Adversarial Networks with  Transformer",
    "abstract": " Comments: The results exist serious factual error ",
    "url": "https://arxiv.org/abs/2309.09075",
    "authors": [
      "Ziyi Jiang",
      "Ruoxue Wu",
      "Zhenghan Chen",
      "Xiaoxuan Liang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.11500",
    "title": "A Large-scale Dataset for Audio-Language Representation Learning",
    "abstract": " Title: A Large-scale Dataset for Audio-Language Representation Learning ",
    "url": "https://arxiv.org/abs/2309.11500",
    "authors": [
      "Luoyi Sun",
      "Xuenan Xu",
      "Mengyue Wu",
      "Weidi Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.12449",
    "title": "Dynamic Prediction of Delays in Software Projects using Delay Patterns  and Bayesian Modeling",
    "abstract": " Title: Dynamic Prediction of Delays in Software Projects using Delay Patterns  and Bayesian Modeling ",
    "url": "https://arxiv.org/abs/2309.12449",
    "authors": [
      "Elvan Kula",
      "Eric Greuter",
      "Arie van Deursen",
      "Georgios Gousios"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.12955",
    "title": "On Data Fabrication in Collaborative Vehicular Perception: Attacks and  Countermeasures",
    "abstract": " Comments: 18 pages, 24 figures, accepted by Usenix Security 2024 ",
    "url": "https://arxiv.org/abs/2309.12955",
    "authors": [
      "Qingzhao Zhang",
      "Shuowei Jin",
      "Ruiyang Zhu",
      "Jiachen Sun",
      "Xumiao Zhang",
      "Qi Alfred Chen",
      "Z. Morley Mao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.14006",
    "title": "Multiple evolutionary pressures shape identical consonant avoidance in  the world's languages",
    "abstract": " Comments: 33 pp ",
    "url": "https://arxiv.org/abs/2309.14006",
    "authors": [
      "Chundra A. Cathcart"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.14610",
    "title": "Unsupervised Graph Deep Learning Reveals Emergent Flood Risk Profile of  Urban Areas",
    "abstract": " Comments: 24 pages ",
    "url": "https://arxiv.org/abs/2309.14610",
    "authors": [
      "Kai Yin",
      "Ali Mostafavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2309.14846",
    "title": "Supersonic: Learning to Generate Source Code Optimizations in C/C++",
    "abstract": " Title: Supersonic: Learning to Generate Source Code Optimizations in C/C++ ",
    "url": "https://arxiv.org/abs/2309.14846",
    "authors": [
      "Zimin Chen",
      "Sen Fang",
      "Martin Monperrus"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.15289",
    "title": "SEPT: Towards Efficient Scene Representation Learning for Motion  Prediction",
    "abstract": " Title: SEPT: Towards Efficient Scene Representation Learning for Motion  Prediction ",
    "url": "https://arxiv.org/abs/2309.15289",
    "authors": [
      "Zhiqian Lan",
      "Yuxuan Jiang",
      "Yao Mu",
      "Chen Chen",
      "Shengbo Eben Li",
      "Hang Zhao",
      "Keqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16499",
    "title": "Cross-City Matters: A Multimodal Remote Sensing Benchmark Dataset for  Cross-City Semantic Segmentation using High-Resolution Domain Adaptation  Networks",
    "abstract": " Title: Cross-City Matters: A Multimodal Remote Sensing Benchmark Dataset for  Cross-City Semantic Segmentation using High-Resolution Domain Adaptation  Networks ",
    "url": "https://arxiv.org/abs/2309.16499",
    "authors": [
      "Danfeng Hong",
      "Bing Zhang",
      "Hao Li",
      "Yuxuan Li",
      "Jing Yao",
      "Chenyu Li",
      "Martin Werner",
      "Jocelyn Chanussot",
      "Alexander Zipf",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2309.16631",
    "title": "Robust Offline Reinforcement Learning -- Certify the Confidence Interval",
    "abstract": " Comments: the theoretical and experimental were only partial and incomplete ",
    "url": "https://arxiv.org/abs/2309.16631",
    "authors": [
      "Jiarui Yao",
      "Simon Shaolei Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16742",
    "title": "Supervised Learning Models for Early Detection of Albuminuria Risk in  Type-2 Diabetes Mellitus Patients",
    "abstract": " Comments: Accepted in the 10th International Conference on Advanced Informatics: Concepts, Theory and Applications (ICAICTA 2023) ",
    "url": "https://arxiv.org/abs/2309.16742",
    "authors": [
      "Arief Purnama Muharram",
      "Dicky Levenus Tahapary",
      "Yeni Dwi Lestari",
      "Randy Sarayar",
      "Valerie Josephine Dirjayanto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2309.16783",
    "title": "Photonic Accelerators for Image Segmentation in Autonomous Driving and  Defect Detection",
    "abstract": " Title: Photonic Accelerators for Image Segmentation in Autonomous Driving and  Defect Detection ",
    "url": "https://arxiv.org/abs/2309.16783",
    "authors": [
      "Lakshmi Nair",
      "David Widemann",
      "Brad Turcott",
      "Nick Moore",
      "Alexandra Wleklinski",
      "Darius Bunandar",
      "Ioannis Papavasileiou",
      "Shihu Wang",
      "Eric Logan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.16916",
    "title": "ONNXExplainer: an ONNX Based Generic Framework to Explain Neural  Networks Using Shapley Values",
    "abstract": " Comments: 11 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2309.16916",
    "authors": [
      "Yong Zhao",
      "Runxin He",
      "Nicholas Kersting",
      "Can Liu",
      "Shubham Agrawal",
      "Chiranjeet Chetia",
      "Yu Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16971",
    "title": "Multi-Resolution Active Learning of Fourier Neural Operators",
    "abstract": " Title: Multi-Resolution Active Learning of Fourier Neural Operators ",
    "url": "https://arxiv.org/abs/2309.16971",
    "authors": [
      "Shibo Li",
      "Xin Yu",
      "Wei Xing",
      "Mike Kirby",
      "Akil Narayan",
      "Shandian Zhe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.17415",
    "title": "Intuitive or Dependent? Investigating LLMs' Robustness to Conflicting  Prompts",
    "abstract": " Title: Intuitive or Dependent? Investigating LLMs' Robustness to Conflicting  Prompts ",
    "url": "https://arxiv.org/abs/2309.17415",
    "authors": [
      "Jiahao Ying",
      "Yixin Cao",
      "Kai Xiong",
      "Yidong He",
      "Long Cui",
      "Yongbin Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.00233",
    "title": "CausalImages: An R Package for Causal Inference with Earth Observation,  Bio-medical, and Social Science Images",
    "abstract": " Comments: For accompanying software, see this https URL ",
    "url": "https://arxiv.org/abs/2310.00233",
    "authors": [
      "Connor T. Jerzak",
      "Adel Daoud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2310.00238",
    "title": "Feasibility-Guaranteed Safety Critical Control with Applications to  Heterogeneous Platoons",
    "abstract": " Comments: 8 pages, 3 figures. arXiv admin note: text overlap with arXiv:2304.00372 ",
    "url": "https://arxiv.org/abs/2310.00238",
    "authors": [
      "Shuo Liu",
      "Wei Xiao",
      "Calin A. Belta"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.00527",
    "title": "Self-supervised Learning of Contextualized Local Visual Embeddings",
    "abstract": " Comments: Pre-print. 4th Visual Inductive Priors for Data-Efficient Deep Learning Workshop ICCV 2023. Code at $\\href{this https URL}{\\text{this link}}$ ",
    "url": "https://arxiv.org/abs/2310.00527",
    "authors": [
      "Thalles Santos Silva",
      "Helio Pedrini",
      "Ad\u00edn Ram\u00edrez Rivera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.01181",
    "title": "Graph Isomorphic Networks for Assessing Reliability of the  Medium-Voltage Grid",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2310.01181",
    "authors": [
      "Charlotte Cambier van Nooten",
      "Tom van de Poll",
      "Sonja F\u00fcllhase",
      "Jacco Heres",
      "Tom Heskes",
      "Yuliya Shapovalova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01259",
    "title": "Faster and Accurate Neural Networks with Semantic Inference",
    "abstract": " Comments: 14 pages, 6 figures, conference format ",
    "url": "https://arxiv.org/abs/2310.01259",
    "authors": [
      "Sazzad Sayyed",
      "Jonathan Ashdown",
      "Francesco Restuccia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01272",
    "title": "A Unified View on Neural Message Passing with Opinion Dynamics for  Social Networks",
    "abstract": " Title: A Unified View on Neural Message Passing with Opinion Dynamics for  Social Networks ",
    "url": "https://arxiv.org/abs/2310.01272",
    "authors": [
      "Outongyi Lv",
      "Bingxin Zhou",
      "Jing Wang",
      "Xiang Xiao",
      "Weishu Zhao",
      "Lirong Zheng"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2310.01307",
    "title": "On the Generalization of Training-based ChatGPT Detection Methods",
    "abstract": " Title: On the Generalization of Training-based ChatGPT Detection Methods ",
    "url": "https://arxiv.org/abs/2310.01307",
    "authors": [
      "Han Xu",
      "Jie Ren",
      "Pengfei He",
      "Shenglai Zeng",
      "Yingqian Cui",
      "Amy Liu",
      "Hui Liu",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01405",
    "title": "Representation Engineering: A Top-Down Approach to AI Transparency",
    "abstract": " Comments: Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2310.01405",
    "authors": [
      "Andy Zou",
      "Long Phan",
      "Sarah Chen",
      "James Campbell",
      "Phillip Guo",
      "Richard Ren",
      "Alexander Pan",
      "Xuwang Yin",
      "Mantas Mazeika",
      "Ann-Kathrin Dombrowski",
      "Shashwat Goel",
      "Nathaniel Li",
      "Michael J. Byun",
      "Zifan Wang",
      "Alex Mallen",
      "Steven Basart",
      "Sanmi Koyejo",
      "Dawn Song",
      "Matt Fredrikson",
      "J. Zico Kolter",
      "Dan Hendrycks"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  }
]