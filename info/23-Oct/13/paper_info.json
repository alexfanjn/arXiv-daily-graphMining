[
  {
    "id": "arXiv:2310.07724",
    "title": "Visual Forecasting as a Mid-level Representation for Avoidance",
    "abstract": "The challenge of navigation in environments with dynamic objects continues to be a central issue in the study of autonomous agents. While predictive methods hold promise, their reliance on precise state information makes them less practical for real-world implementation. This study presents visual forecasting as an innovative alternative. By introducing intuitive visual cues, this approach projects the future trajectories of dynamic objects to improve agent perception and enable anticipatory actions. Our research explores two distinct strategies for conveying predictive information through visual forecasting: (1) sequences of bounding boxes, and (2) augmented paths. To validate the proposed visual forecasting strategies, we initiate evaluations in simulated environments using the Unity engine and then extend these evaluations to real-world scenarios to assess both practicality and effectiveness. The results confirm the viability of visual forecasting as a promising solution for navigation and obstacle avoidance in dynamic environments. ",
    "url": "https://arxiv.org/abs/2310.07724",
    "authors": [
      "Hsuan-Kung Yang",
      "Tsung-Chih Chiang",
      "Ting-Ru Liu",
      "Chun-Wei Huang",
      "Jou-Min Liu",
      "Chun-Yi Lee"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07725",
    "title": "Extreme Image Transformations Facilitate Robust Latent Object  Representations",
    "abstract": "Adversarial attacks can affect the object recognition capabilities of machines in wild. These can often result from spurious correlations between input and class labels, and are prone to memorization in large networks. While networks are expected to do automated feature selection, it is not effective at the scale of the object. Humans, however, are able to select the minimum set of features required to form a robust representation of an object. In this work, we show that finetuning any pretrained off-the-shelf network with Extreme Image Transformations (EIT) not only helps in learning a robust latent representation, it also improves the performance of these networks against common adversarial attacks of various intensities. Our EIT trained networks show strong activations in the object regions even when tested with more intense noise, showing promising generalizations across different kinds of adversarial attacks. ",
    "url": "https://arxiv.org/abs/2310.07725",
    "authors": [
      "Girik Malik",
      "Dakarai Crowder",
      "Ennio Mingolla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.07726",
    "title": "Towards the Vulnerability of Watermarking Artificial Intelligence  Generated Content",
    "abstract": "Artificial Intelligence Generated Content (AIGC) is gaining great popularity in social media, with many commercial services available. These services leverage advanced generative models, such as latent diffusion models and large language models, to generate creative content (e.g., realistic images, fluent sentences) for users. The usage of such generated content needs to be highly regulated, as the service providers need to ensure the users do not violate the usage policies (e.g., abuse for commercialization, generating and distributing unsafe content). Numerous watermarking approaches have been proposed recently. However, in this paper, we show that an adversary can easily break these watermarking mechanisms. Specifically, we consider two possible attacks. (1) Watermark removal: the adversary can easily erase the embedded watermark from the generated content and then use it freely without the regulation of the service provider. (2) Watermark forge: the adversary can create illegal content with forged watermarks from another user, causing the service provider to make wrong attributions. We propose WMaGi, a unified framework to achieve both attacks in a holistic way. The key idea is to leverage a pre-trained diffusion model for content processing, and a generative adversarial network for watermark removing or forging. We evaluate WMaGi on different datasets and embedding setups. The results prove that it can achieve high success rates while maintaining the quality of the generated content. Compared with existing diffusion model-based attacks, WMaGi is 5,050$\\sim$11,000$\\times$ faster. ",
    "url": "https://arxiv.org/abs/2310.07726",
    "authors": [
      "Guanlin Li",
      "Yifei Chen",
      "Jie Zhang",
      "Jiwei Li",
      "Shangwei Guo",
      "Tianwei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07739",
    "title": "Identity Collapse? Realignment of Taiwanese Voters in the 2024  Presidential Elections on Social Media",
    "abstract": "The 2024 Taiwanese Presidential Election is not just a critical geopolitical event, it also engages with long-standing debate in politics regarding the factors that lead to the rise of new political parties and candidates. In 2021, the Economist called Taiwan \"the most dangerous place on earth\" due to its critical role in a fragile supply chain. Additionally, a four-candidate race has emerged in a traditionally bipartisan election which begs the question: how will voters realign given the choice of four candidates? Leveraging more than a million posts on social media, we analyze user (predominantly Taiwanese) discourse and engagement along the axes of national identity, issue topic, and partisan alignment. Results reveal alternative candidates (Ko and Gou) draw attention from the fringes rather than the center relative to national identity, and traditional candidates derive more engagement from the traditional media and salience to geopolitical issues. Crucially, in-group references generate more engagement than out-group references, contrary to Western-based studies. We discuss how the dissolution of Taiwan's single-issue society may not just lead to more viable candidates and multi-issue discourse, but the misalignment of national and partisan identity may heal deep-seated partisan cleavages. ",
    "url": "https://arxiv.org/abs/2310.07739",
    "authors": [
      "Ho-Chun Herbert Chang",
      "Sunny Fang"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2310.07756",
    "title": "Self-supervised Representation Learning From Random Data Projectors",
    "abstract": "Self-supervised representation learning~(SSRL) has advanced considerably by exploiting the transformation invariance assumption under artificially designed data augmentations. While augmentation-based SSRL algorithms push the boundaries of performance in computer vision and natural language processing, they are often not directly applicable to other data modalities, and can conflict with application-specific data augmentation constraints. This paper presents an SSRL approach that can be applied to any data modality and network architecture because it does not rely on augmentations or masking. Specifically, we show that high-quality data representations can be learned by reconstructing random data projections. We evaluate the proposed approach on a wide range of representation learning tasks that span diverse modalities and real-world applications. We show that it outperforms multiple state-of-the-art SSRL baselines. Due to its wide applicability and strong empirical results, we argue that learning from randomness is a fruitful research direction worthy of attention and further study. ",
    "url": "https://arxiv.org/abs/2310.07756",
    "authors": [
      "Yi Sui",
      "Tongzi Wu",
      "Jesse C. Cresswell",
      "Ga Wu",
      "George Stein",
      "Xiaoshi Huang",
      "Xiaochen Zhang",
      "Maksims Volkovs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07765",
    "title": "Feature Learning and Generalization in Deep Networks with Orthogonal  Weights",
    "abstract": "Fully-connected deep neural networks with weights initialized from independent Gaussian distributions can be tuned to criticality, which prevents the exponential growth or decay of signals propagating through the network. However, such networks still exhibit fluctuations that grow linearly with the depth of the network, which may impair the training of networks with width comparable to depth. We show analytically that rectangular networks with tanh activations and weights initialized from the ensemble of orthogonal matrices have corresponding preactivation fluctuations which are independent of depth, to leading order in inverse width. Moreover, we demonstrate numerically that, at initialization, all correlators involving the neural tangent kernel (NTK) and its descendants at leading order in inverse width -- which govern the evolution of observables during training -- saturate at a depth of $\\sim 20$, rather than growing without bound as in the case of Gaussian initializations. We speculate that this structure preserves finite-width feature learning while reducing overall noise, thus improving both generalization and training speed. We provide some experimental justification by relating empirical measurements of the NTK to the superior performance of deep nonlinear orthogonal networks trained under full-batch gradient descent on the MNIST and CIFAR-10 classification tasks. ",
    "url": "https://arxiv.org/abs/2310.07765",
    "authors": [
      "Hannah Day",
      "Yonatan Kahn",
      "Daniel A. Roberts"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "High Energy Physics - Theory (hep-th)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.07779",
    "title": "Social Approval and Network Homophily as Motivators of Online Toxicity",
    "abstract": "Online hate messaging is a pervasive issue plaguing the well-being of social media users. This research empirically investigates a novel theory positing that online hate may be driven primarily by the pursuit of social approval rather than a direct desire to harm the targets. Results show that toxicity is homophilous in users' social networks and that a user's propensity for hostility can be predicted by their social networks. We also illustrate how receiving greater or fewer social engagements in the form of likes, retweets, quotes, and replies affects a user's subsequent toxicity. We establish a clear connection between receiving social approval signals and increases in subsequent toxicity. Being retweeted plays a particularly prominent role in escalating toxicity. Results also show that not receiving expected levels of social approval leads to decreased toxicity. We discuss the important implications of our research and opportunities to combat online hate. ",
    "url": "https://arxiv.org/abs/2310.07779",
    "authors": [
      "Julie Jiang",
      "Luca Luceri",
      "Joseph B. Walther",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.07780",
    "title": "Promoting Robustness of Randomized Smoothing: Two Cost-Effective  Approaches",
    "abstract": "Randomized smoothing has recently attracted attentions in the field of adversarial robustness to provide provable robustness guarantees on smoothed neural network classifiers. However, existing works show that vanilla randomized smoothing usually does not provide good robustness performance and often requires (re)training techniques on the base classifier in order to boost the robustness of the resulting smoothed classifier. In this work, we propose two cost-effective approaches to boost the robustness of randomized smoothing while preserving its clean performance. The first approach introduces a new robust training method AdvMacerwhich combines adversarial training and robustness certification maximization for randomized smoothing. We show that AdvMacer can improve the robustness performance of randomized smoothing classifiers compared to SOTA baselines, while being 3x faster to train than MACER baseline. The second approach introduces a post-processing method EsbRS which greatly improves the robustness certificate based on building model ensembles. We explore different aspects of model ensembles that has not been studied by prior works and propose a novel design methodology to further improve robustness of the ensemble based on our theoretical analysis. ",
    "url": "https://arxiv.org/abs/2310.07780",
    "authors": [
      "Linbo Liu",
      "Trong Nghia Hoang",
      "Lam M. Nguyen",
      "Tsui-Wei Weng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07786",
    "title": "Non-Stationary Contextual Bandit Learning via Neural Predictive Ensemble  Sampling",
    "abstract": "Real-world applications of contextual bandits often exhibit non-stationarity due to seasonality, serendipity, and evolving social trends. While a number of non-stationary contextual bandit learning algorithms have been proposed in the literature, they excessively explore due to a lack of prioritization for information of enduring value, or are designed in ways that do not scale in modern applications with high-dimensional user-specific features and large action set, or both. In this paper, we introduce a novel non-stationary contextual bandit algorithm that addresses these concerns. It combines a scalable, deep-neural-network-based architecture with a carefully designed exploration mechanism that strategically prioritizes collecting information with the most lasting value in a non-stationary environment. Through empirical evaluations on two real-world recommendation datasets, which exhibit pronounced non-stationarity, we demonstrate that our approach significantly outperforms the state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2310.07786",
    "authors": [
      "Zheqing Zhu",
      "Yueyang Liu",
      "Xu Kuang",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.07793",
    "title": "GenTKG: Generative Forecasting on Temporal Knowledge Graph",
    "abstract": "The rapid advancements in large language models (LLMs) have ignited interest in the temporal knowledge graph (tKG) domain, where conventional carefully designed embedding-based and rule-based models dominate. The question remains open of whether pre-trained LLMs can understand structured temporal relational data and replace them as the foundation model for temporal relational forecasting. Therefore, we bring temporal knowledge forecasting into the generative setting. However, challenges occur in the huge chasms between complex temporal graph data structure and sequential natural expressions LLMs can handle, and between the enormous data sizes of tKGs and heavy computation costs of finetuning LLMs. To address these challenges, we propose a novel retrieval augmented generation framework that performs generative forecasting on tKGs named GenTKG, which combines a temporal logical rule-based retrieval strategy and lightweight parameter-efficient instruction tuning. Extensive experiments have shown that GenTKG outperforms conventional methods of temporal relational forecasting under low computation resources. GenTKG also highlights remarkable transferability with exceeding performance on unseen datasets without re-training. Our work reveals the huge potential of LLMs in the tKG domain and opens a new frontier for generative forecasting on tKGs. ",
    "url": "https://arxiv.org/abs/2310.07793",
    "authors": [
      "Ruotong Liao",
      "Xu Jia",
      "Yunpu Ma",
      "Volker Tresp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07794",
    "title": "CRITERIA: a New Benchmarking Paradigm for Evaluating Trajectory  Prediction Models for Autonomous Driving",
    "abstract": "Benchmarking is a common method for evaluating trajectory prediction models for autonomous driving. Existing benchmarks rely on datasets, which are biased towards more common scenarios, such as cruising, and distance-based metrics that are computed by averaging over all scenarios. Following such a regiment provides a little insight into the properties of the models both in terms of how well they can handle different scenarios and how admissible and diverse their outputs are. There exist a number of complementary metrics designed to measure the admissibility and diversity of trajectories, however, they suffer from biases, such as length of trajectories. In this paper, we propose a new benChmarking paRadIgm for evaluaTing trajEctoRy predIction Approaches (CRITERIA). Particularly, we propose 1) a method for extracting driving scenarios at varying levels of specificity according to the structure of the roads, models' performance, and data properties for fine-grained ranking of prediction models; 2) A set of new bias-free metrics for measuring diversity, by incorporating the characteristics of a given scenario, and admissibility, by considering the structure of roads and kinematic compliancy, motivated by real-world driving constraints. 3) Using the proposed benchmark, we conduct extensive experimentation on a representative set of the prediction models using the large scale Argoverse dataset. We show that the proposed benchmark can produce a more accurate ranking of the models and serve as a means of characterizing their behavior. We further present ablation studies to highlight contributions of different elements that are used to compute the proposed metrics. ",
    "url": "https://arxiv.org/abs/2310.07794",
    "authors": [
      "Changhe Chen",
      "Mozhgan Pourkeshavarz",
      "Amir Rasouli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.07799",
    "title": "A Transfer-Learning-Based Prognosis Prediction Paradigm that Bridges  Data Distribution Shift across EMR Datasets",
    "abstract": "Due to the limited information about emerging diseases, symptoms are hard to be noticed and recognized, so that the window for clinical intervention could be ignored. An effective prognostic model is expected to assist doctors in making right diagnosis and designing personalized treatment plan, so to promptly prevent unfavorable outcomes. However, in the early stage of a disease, limited data collection and clinical experiences, plus the concern out of privacy and ethics, may result in restricted data availability for reference, to the extent that even data labels are difficult to mark correctly. In addition, Electronic Medical Record (EMR) data of different diseases or of different sources of the same disease can prove to be having serious cross-dataset feature misalignment problems, greatly mutilating the efficiency of deep learning models. This article introduces a transfer learning method to build a transition model from source dataset to target dataset. By way of constraining the distribution shift of features generated in disparate domains, domain-invariant features that are exclusively relative to downstream tasks are captured, so to cultivate a unified domain-invariant encoder across various task domains to achieve better feature representation. Experimental results of several target tasks demonstrate that our proposed model outperforms competing baseline methods and has higher rate of training convergence, especially in dealing with limited data amount. A multitude of experiences have proven the efficacy of our method to provide more accurate predictions concerning newly emergent pandemics and other diseases. ",
    "url": "https://arxiv.org/abs/2310.07799",
    "authors": [
      "Zhongji Zhang",
      "Yuhang Wang",
      "Yinghao Zhu",
      "Xinyu Ma",
      "Tianlong Wang",
      "Chaohe Zhang",
      "Yasha Wang",
      "Liantao Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07801",
    "title": "Trajectory-aware Principal Manifold Framework for Data Augmentation and  Image Generation",
    "abstract": "Data augmentation for deep learning benefits model training, image transformation, medical imaging analysis and many other fields. Many existing methods generate new samples from a parametric distribution, like the Gaussian, with little attention to generate samples along the data manifold in either the input or feature space. In this paper, we verify that there are theoretical and practical advantages of using the principal manifold hidden in the feature space than the Gaussian distribution. We then propose a novel trajectory-aware principal manifold framework to restore the manifold backbone and generate samples along a specific trajectory. On top of the autoencoder architecture, we further introduce an intrinsic dimension regularization term to make the manifold more compact and enable few-shot image generation. Experimental results show that the novel framework is able to extract more compact manifold representation, improve classification accuracy and generate smooth transformation among few samples. ",
    "url": "https://arxiv.org/abs/2310.07801",
    "authors": [
      "Elvis Han Cui",
      "Bingbin Li",
      "Yanan Li",
      "Weng Kee Wong",
      "Donghui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2310.07809",
    "title": "On the Robustness of Mechanism Design under Total Variation Distance",
    "abstract": "We study the problem of designing mechanisms when agents' valuation functions are drawn from unknown and correlated prior distributions. In particular, we are given a prior distribution $\\D$, and we are interested in designing a (truthful) mechanism that has good performance for all ``true distributions'' that are close to $\\D$ in Total Variation (TV) distance. We show that DSIC and BIC mechanisms in this setting are strongly robust with respect to TV distance, for any bounded objective function $\\Ocal$, extending a recent result of Brustle et al. (\\cite{Brustle2020}, EC 2020). At the heart of our result is a fundamental duality property of total variation distance. As direct applications of our result, we (i) demonstrate how to find approximately revenue-optimal and approximately BIC mechanisms for weakly dependent prior distributions; (ii) show how to find correlation-robust mechanisms when only ``noisy'' versions of marginals are accessible, extending recent results of Bei et. al. (\\cite{bei2019correlation}, SODA 2019); (iii) prove that prophet-inequality type guarantees are preserved for correlated priors, recovering a variant of a result of D{\\\"u}tting and Kesselheim (\\cite{Dutting19}, EC 2019); (iv) give a new necessary condition for a correlated distribution to witness an infinite separation in revenue between simple and optimal mechanisms, complementing recent results of Psomas et al. (\\cite{psomas2022infinite}, NeurIPS 2022); (v) give a new condition for simple mechanisms to approximate revenue-optimal mechanisms for the case of a single agent whose type is drawn from a correlated distribution that can be captured by a Markov Random Field, complementing recent results of Cai and Oikonomou (\\cite{Cai21}, EC 2021). ",
    "url": "https://arxiv.org/abs/2310.07809",
    "authors": [
      "Anuran Makur",
      "Marios Mertzanidis",
      "Alexandros Psomas",
      "Athina Terzoglou"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2310.07824",
    "title": "An On-Chip Trainable Neuron Circuit for SFQ-Based Spiking Neural  Networks",
    "abstract": "We present an on-chip trainable neuron circuit. Our proposed circuit suits bio-inspired spike-based time-dependent data computation for training spiking neural networks (SNN). The thresholds of neurons can be increased or decreased depending on the desired application-specific spike generation rate. This mechanism provides us with a flexible design and scalable circuit structure. We demonstrate the trainable neuron structure under different operating scenarios. The circuits are designed and optimized for the MIT LL SFQ5ee fabrication process. Margin values for all parameters are above 25\\% with a 3GHz throughput for a 16-input neuron. ",
    "url": "https://arxiv.org/abs/2310.07824",
    "authors": [
      "Beyza Zeynep Ucpinar",
      "Mustafa Altay Karamuftuoglu",
      "Sasan Razmkhah",
      "Massoud Pedram"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Superconductivity (cond-mat.supr-con)"
    ]
  },
  {
    "id": "arXiv:2310.07844",
    "title": "Saturation-Aware Angular Velocity Estimation: Extending the Robustness  of SLAM to Aggressive Motions",
    "abstract": "We propose a novel angular velocity estimation method to increase the robustness of Simultaneous Localization And Mapping (SLAM) algorithms against gyroscope saturations induced by aggressive motions. Field robotics expose robots to various hazards, including steep terrains, landslides, and staircases, where substantial accelerations and angular velocities can occur if the robot loses stability and tumbles. These extreme motions can saturate sensor measurements, especially gyroscopes, which are the first sensors to become inoperative. While the structural integrity of the robot is at risk, the resilience of the SLAM framework is oftentimes given little consideration. Consequently, even if the robot is physically capable of continuing the mission, its operation will be compromised due to a corrupted representation of the world. Regarding this problem, we propose a way to estimate the angular velocity using accelerometers during extreme rotations caused by tumbling. We show that our method reduces the median localization error by 71.5 % in translation and 65.5 % in rotation and reduces the number of SLAM failures by 73.3 % on the collected data. We also propose the Tumbling-Induced Gyroscope Saturation (TIGS) dataset, which consists of outdoor experiments recording the motion of a lidar subject to angular velocities four times higher than other available datasets. The dataset is available online at https://github.com/norlab-ulaval/Norlab_wiki/wiki/TIGS-Dataset. ",
    "url": "https://arxiv.org/abs/2310.07844",
    "authors": [
      "Simon-Pierre Desch\u00eanes",
      "Dominic Baril",
      "Mat\u011bj Boxan",
      "Johann Laconte",
      "Philippe Gigu\u00e8re",
      "Fran\u00e7ois Pomerleau"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.07847",
    "title": "Dependency Practices for Vulnerability Mitigation",
    "abstract": "Relying on dependency packages accelerates software development, but it also increases the exposure to security vulnerabilities that may be present in dependencies. While developers have full control over which dependency packages (and which version) they use, they have no control over the dependencies of their dependencies. Such transitive dependencies, which often amount to a greater number than direct dependencies, can become infected with vulnerabilities and put software projects at risk. To mitigate this risk, Practitioners need to select dependencies that respond quickly to vulnerabilities to prevent the propagation of vulnerable code to their project. To identify such dependencies, we analyze more than 450 vulnerabilities in the npm ecosystem to understand why dependent packages remain vulnerable. We identify over 200,000 npm packages that are infected through their dependencies and use 9 features to build a prediction model that identifies packages that quickly adopt the vulnerability fix and prevent further propagation of vulnerabilities. We also study the relationship between these features and the response speed of vulnerable packages. We complement our work with a practitioner survey to understand the applicability of our findings. Developers can incorporate our findings into their dependency management practices to mitigate the impact of vulnerabilities from their dependency supply chain. ",
    "url": "https://arxiv.org/abs/2310.07847",
    "authors": [
      "Abbas Javan Jafari",
      "Diego Elias Costa",
      "Ahmad Abdellatif",
      "Emad Shihab"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.07848",
    "title": "Framework for Question-Answering in Sanskrit through Automated  Construction of Knowledge Graphs",
    "abstract": "Sanskrit (sa\\d{m}sk\\d{r}ta) enjoys one of the largest and most varied literature in the whole world. Extracting the knowledge from it, however, is a challenging task due to multiple reasons including complexity of the language and paucity of standard natural language processing tools. In this paper, we target the problem of building knowledge graphs for particular types of relationships from sa\\d{m}sk\\d{r}ta texts. We build a natural language question-answering system in sa\\d{m}sk\\d{r}ta that uses the knowledge graph to answer factoid questions. We design a framework for the overall system and implement two separate instances of the system on human relationships from mah\\=abh\\=arata and r\\=am\\=aya\\d{n}a, and one instance on synonymous relationships from bh\\=avaprak\\=a\\'sa nigha\\d{n}\\d{t}u, a technical text from \\=ayurveda. We show that about 50% of the factoid questions can be answered correctly by the system. More importantly, we analyse the shortcomings of the system in detail for each step, and discuss the possible ways forward. ",
    "url": "https://arxiv.org/abs/2310.07848",
    "authors": [
      "Hrishikesh Terdalkar",
      "Arnab Bhattacharya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.07855",
    "title": "CrIBo: Self-Supervised Learning via Cross-Image Object-Level  Bootstrapping",
    "abstract": "Leveraging nearest neighbor retrieval for self-supervised representation learning has proven beneficial with object-centric images. However, this approach faces limitations when applied to scene-centric datasets, where multiple objects within an image are only implicitly captured in the global representation. Such global bootstrapping can lead to undesirable entanglement of object representations. Furthermore, even object-centric datasets stand to benefit from a finer-grained bootstrapping approach. In response to these challenges, we introduce a novel Cross-Image Object-Level Bootstrapping method tailored to enhance dense visual representation learning. By employing object-level nearest neighbor bootstrapping throughout the training, CrIBo emerges as a notably strong and adequate candidate for in-context learning, leveraging nearest neighbor retrieval at test time. CrIBo shows state-of-the-art performance on the latter task while being highly competitive in more standard downstream segmentation tasks. Our code and pretrained models will be publicly available upon acceptance. ",
    "url": "https://arxiv.org/abs/2310.07855",
    "authors": [
      "Tim Lebailly",
      "Thomas Stegm\u00fcller",
      "Behzad Bozorgtabar",
      "Jean-Philippe Thiran",
      "Tinne Tuytelaars"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07856",
    "title": "Assessing Evaluation Metrics for Neural Test Oracle Generation",
    "abstract": "In this work, we revisit existing oracle generation studies plus ChatGPT to empirically investigate the current standing of their performance in both NLG-based and test adequacy metrics. Specifically, we train and run four state-of-the-art test oracle generation models on five NLG-based and two test adequacy metrics for our analysis. We apply two different correlation analyses between these two different sets of metrics. Surprisingly, we found no significant correlation between the NLG-based metrics and test adequacy metrics. For instance, oracles generated from ChatGPT on the project activemq-artemis had the highest performance on all the NLG-based metrics among the studied NOGs, however, it had the most number of projects with a decrease in test adequacy metrics compared to all the studied NOGs. We further conduct a qualitative analysis to explore the reasons behind our observations, we found that oracles with high NLG-based metrics but low test adequacy metrics tend to have complex or multiple chained method invocations within the oracle's parameters, making it hard for the model to generate completely, affecting the test adequacy metrics. On the other hand, oracles with low NLG-based metrics but high test adequacy metrics tend to have to call different assertion types or a different method that functions similarly to the ones in the ground truth. Overall, this work complements prior studies on test oracle generation with an extensive performance evaluation with both NLG and test adequacy metrics and provides guidelines for better assessment of deep learning applications in software test generation in the future. ",
    "url": "https://arxiv.org/abs/2310.07856",
    "authors": [
      "Jiho Shin",
      "Hadi Hemmati",
      "Moshi Wei",
      "Song Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.07879",
    "title": "Deepfakes, Phrenology, Surveillance, and More! A Taxonomy of AI Privacy  Risks",
    "abstract": "Privacy is a key principle for developing ethical AI technologies, but how does including AI technologies in products and services change privacy risks? We constructed a taxonomy of AI privacy risks by analyzing 321 documented AI privacy incidents. We codified how the unique capabilities and requirements of AI technologies described in those incidents generated new privacy risks, exacerbated known ones, or otherwise did not meaningfully alter the risk. We present 12 high-level privacy risks that AI technologies either newly created (e.g., exposure risks from deepfake pornography) or exacerbated (e.g., surveillance risks from collecting training data). One upshot of our work is that incorporating AI technologies into a product can alter the privacy risks it entails. Yet, current privacy-preserving AI/ML methods (e.g., federated learning, differential privacy) only address a subset of the privacy risks arising from the capabilities and data requirements of AI. ",
    "url": "https://arxiv.org/abs/2310.07879",
    "authors": [
      "Hao-Ping Lee",
      "Yu-Ju Yang",
      "Thomas Serban von Davier",
      "Jodi Forlizzi",
      "Sauvik Das"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2310.07881",
    "title": "DeePref: Deep Reinforcement Learning For Video Prefetching In Content  Delivery Networks",
    "abstract": "Content Delivery Networks carry the majority of Internet traffic, and the increasing demand for video content as a major IP traffic across the Internet highlights the importance of caching and prefetching optimization algorithms. Prefetching aims to make data available in the cache before the requester places its request to reduce access time and improve the Quality of Experience on the user side. Prefetching is well investigated in operating systems, compiler instructions, in-memory cache, local storage systems, high-speed networks, and cloud systems. Traditional prefetching techniques are well adapted to a particular access pattern, but fail to adapt to sudden variations or randomization in workloads. This paper explores the use of reinforcement learning to tackle the changes in user access patterns and automatically adapt over time. To this end, we propose, DeePref, a Deep Reinforcement Learning agent for online video content prefetching in Content Delivery Networks. DeePref is a prefetcher implemented on edge networks and is agnostic to hardware design, operating systems, and applications. Our results show that DeePref DRQN, using a real-world dataset, achieves a 17% increase in prefetching accuracy and a 28% increase in prefetching coverage on average compared to baseline approaches that use video content popularity as a building block to statically or dynamically make prefetching decisions. We also study the possibility of transfer learning of statistical models from one edge network into another, where unseen user requests from unknown distribution are observed. In terms of transfer learning, the increase in prefetching accuracy and prefetching coverage are [$30%$, $10%$], respectively. Our source code will be available on Github. ",
    "url": "https://arxiv.org/abs/2310.07881",
    "authors": [
      "Nawras Alkassab",
      "Chin-Tser Huang",
      "Tania Lorido Botran"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07885",
    "title": "Leader-Follower Neural Networks with Local Error Signals Inspired by  Complex Collectives",
    "abstract": "The collective behavior of a network with heterogeneous, resource-limited information processing units (e.g., group of fish, flock of birds, or network of neurons) demonstrates high self-organization and complexity. These emergent properties arise from simple interaction rules where certain individuals can exhibit leadership-like behavior and influence the collective activity of the group. Motivated by the intricacy of these collectives, we propose a neural network (NN) architecture inspired by the rules observed in nature's collective ensembles. This NN structure contains workers that encompass one or more information processing units (e.g., neurons, filters, layers, or blocks of layers). Workers are either leaders or followers, and we train a leader-follower neural network (LFNN) by leveraging local error signals and optionally incorporating backpropagation (BP) and global loss. We investigate worker behavior and evaluate LFNNs through extensive experimentation. Our LFNNs trained with local error signals achieve significantly lower error rates than previous BP-free algorithms on MNIST and CIFAR-10 and even surpass BP-enabled baselines. In the case of ImageNet, our LFNN-l demonstrates superior scalability and outperforms previous BP-free algorithms by a significant margin. ",
    "url": "https://arxiv.org/abs/2310.07885",
    "authors": [
      "Chenzhong Yin",
      "Mingxi Cheng",
      "Xiongye Xiao",
      "Xinghe Chen",
      "Shahin Nazarian",
      "Andrei Irimia",
      "Paul Bogdan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07886",
    "title": "A Survey of Feature Types and Their Contributions for Camera Tampering  Detection",
    "abstract": "Camera tamper detection is the ability to detect unauthorized and unintentional alterations in surveillance cameras by analyzing the video. Camera tampering can occur due to natural events or it can be caused intentionally to disrupt surveillance. We cast tampering detection as a change detection problem, and perform a review of the existing literature with emphasis on feature types. We formulate tampering detection as a time series analysis problem, and design experiments to study the robustness and capability of various feature types. We compute ten features on real-world surveillance video and apply time series analysis to ascertain their predictability, and their capability to detect tampering. Finally, we quantify the performance of various time series models using each feature type to detect tampering. ",
    "url": "https://arxiv.org/abs/2310.07886",
    "authors": [
      "Pranav Mantini",
      "Shishir K. Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07889",
    "title": "LangNav: Language as a Perceptual Representation for Navigation",
    "abstract": "We explore the use of language as a perceptual representation for vision-and-language navigation. Our approach uses off-the-shelf vision systems (for image captioning and object detection) to convert an agent's egocentric panoramic view at each time step into natural language descriptions. We then finetune a pretrained language model to select an action, based on the current view and the trajectory history, that would best fulfill the navigation instructions. In contrast to the standard setup which adapts a pretrained language model to work directly with continuous visual features from pretrained vision models, our approach instead uses (discrete) language as the perceptual representation. We explore two use cases of our language-based navigation (LangNav) approach on the R2R vision-and-language navigation benchmark: generating synthetic trajectories from a prompted large language model (GPT-4) with which to finetune a smaller language model; and sim-to-real transfer where we transfer a policy learned on a simulated environment (ALFRED) to a real-world environment (R2R). Our approach is found to improve upon strong baselines that rely on visual features in settings where only a few gold trajectories (10-100) are available, demonstrating the potential of using language as a perceptual representation for navigation tasks. ",
    "url": "https://arxiv.org/abs/2310.07889",
    "authors": [
      "Bowen Pan",
      "Rameswar Panda",
      "SouYoung Jin",
      "Rogerio Feris",
      "Aude Oliva",
      "Phillip Isola",
      "Yoon Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.07892",
    "title": "ASV Station Keeping under Wind Disturbances using Neural Network  Simulation Error Minimization Model Predictive Control",
    "abstract": "Station keeping is an essential maneuver for Autonomous Surface Vehicles (ASVs), mainly when used in confined spaces, to carry out surveys that require the ASV to keep its position or in collaboration with other vehicles where the relative position has an impact over the mission. However, this maneuver can become challenging for classic feedback controllers due to the need for an accurate model of the ASV dynamics and the environmental disturbances. This work proposes a Model Predictive Controller using Neural Network Simulation Error Minimization (NNSEM-MPC) to accurately predict the dynamics of the ASV under wind disturbances. The performance of the proposed scheme under wind disturbances is tested and compared against other controllers in simulation, using the Robotics Operating System (ROS) and the multipurpose simulation environment Gazebo. A set of six tests were conducted by combining two wind speeds (3 m/s and 6 m/s) and three wind directions (0$^\\circ$, 90$^\\circ$, and 180$^\\circ$). The simulation results clearly show the advantage of the NNSEM-MPC over the following methods: backstepping controller, sliding mode controller, simplified dynamics MPC (SD-MPC), neural ordinary differential equation MPC (NODE-MPC), and knowledge-based NODE MPC (KNODE-MPC). The proposed NNSEM-MPC approach performs better than the rest in 4 out of the 6 test conditions, and it is the second best in the 2 remaining test cases, reducing the mean position and heading error by at least 31\\% and 46\\% respectively across all the test cases. In terms of execution speed, the proposed NNSEM-MPC is at least 36\\% faster than the rest of the MPC controllers. The field experiments on two different ASV platforms showed that ASVs can effectively keep the station utilizing the proposed method, with a position error as low as $1.68$ m and a heading error as low as $6.14^{\\circ}$ within time windows of at least $150$s. ",
    "url": "https://arxiv.org/abs/2310.07892",
    "authors": [
      "Jalil Chavez-Galaviz",
      "Jianwen Li",
      "Ajinkya Chaudhary",
      "Nina Mahmoudian"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07906",
    "title": "Power Tracking Control of Heterogeneous Populations of TCLs with  Partially Measured States",
    "abstract": "This paper presents a new aggregate power tracking control scheme for populations of thermostatically controlled loads (TCLs). The control design is performed in the framework of partial differential equations (PDEs) based on a late-lumping procedure without truncating the infinite-dimensional model describing the dynamics of the TCL population. An input-output linearization control scheme, which is independent of system parameters and uses only partial state measurement, is derived, and a sliding model-like control is applied to achieve finite-time input-to-state stability for tracking error dynamics. Such a control strategy can ensure robust performance in the presence of modeling uncertainties, while considerably reducing the communication burden in large scale distributed systems similar to that considered in the present work. A rigorous analysis of the closed-loop stability of the underlying PDE system was conducted, which guaranteed the validity of the developed control scheme. Simulation studies were performed while considering two TCL populations with a significant difference in their size, and the results show that the developed control scheme performs well in both cases, thereby confirming the effectiveness of the proposed solution. ",
    "url": "https://arxiv.org/abs/2310.07906",
    "authors": [
      "Zhenhe Zhang",
      "Jun Zheng",
      "Guchuan Zhu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Analysis of PDEs (math.AP)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2310.07915",
    "title": "Tag Your Fish in the Broken Net: A Responsible Web Framework for  Protecting Online Privacy and Copyright",
    "abstract": "The World Wide Web, a ubiquitous source of information, serves as a primary resource for countless individuals, amassing a vast amount of data from global internet users. However, this online data, when scraped, indexed, and utilized for activities like web crawling, search engine indexing, and, notably, AI model training, often diverges from the original intent of its contributors. The ascent of Generative AI has accentuated concerns surrounding data privacy and copyright infringement. Regrettably, the web's current framework falls short in facilitating pivotal actions like consent withdrawal or data copyright claims. While some companies offer voluntary measures, such as crawler access restrictions, these often remain inaccessible to individual users. To empower online users to exercise their rights and enable companies to adhere to regulations, this paper introduces a user-controlled consent tagging framework for online data. It leverages the extensibility of HTTP and HTML in conjunction with the decentralized nature of distributed ledger technology. With this framework, users have the ability to tag their online data at the time of transmission, and subsequently, they can track and request the withdrawal of consent for their data from the data holders. A proof-of-concept system is implemented, demonstrating the feasibility of the framework. This work holds significant potential for contributing to the reinforcement of user consent, privacy, and copyright on the modern internet and lays the groundwork for future insights into creating a more responsible and user-centric web ecosystem. ",
    "url": "https://arxiv.org/abs/2310.07915",
    "authors": [
      "Dawen Zhang",
      "Boming Xia",
      "Yue Liu",
      "Xiwei Xu",
      "Thong Hoang",
      "Zhenchang Xing",
      "Mark Staples",
      "Qinghua Lu",
      "Liming Zhu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.07916",
    "title": "Dynamic Appearance Particle Neural Radiance Field",
    "abstract": "Neural Radiance Fields (NeRFs) have shown great potential in modelling 3D scenes. Dynamic NeRFs extend this model by capturing time-varying elements, typically using deformation fields. The existing dynamic NeRFs employ a similar Eulerian representation for both light radiance and deformation fields. This leads to a close coupling of appearance and motion and lacks a physical interpretation. In this work, we propose Dynamic Appearance Particle Neural Radiance Field (DAP-NeRF), which introduces particle-based representation to model the motions of visual elements in a dynamic 3D scene. DAP-NeRF consists of superposition of a static field and a dynamic field. The dynamic field is quantised as a collection of {\\em appearance particles}, which carries the visual information of a small dynamic element in the scene and is equipped with a motion model. All components, including the static field, the visual features and motion models of the particles, are learned from monocular videos without any prior geometric knowledge of the scene. We develop an efficient computational framework for the particle-based model. We also construct a new dataset to evaluate motion modelling. Experimental results show that DAP-NeRF is an effective technique to capture not only the appearance but also the physically meaningful motions in a 3D dynamic scene. ",
    "url": "https://arxiv.org/abs/2310.07916",
    "authors": [
      "Ancheng Lin",
      "Jun Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07932",
    "title": "What Matters to You? Towards Visual Representation Alignment for Robot  Learning",
    "abstract": "When operating in service of people, robots need to optimize rewards aligned with end-user preferences. Since robots will rely on raw perceptual inputs like RGB images, their rewards will inevitably use visual representations. Recently there has been excitement in using representations from pre-trained visual models, but key to making these work in robotics is fine-tuning, which is typically done via proxy tasks like dynamics prediction or enforcing temporal cycle-consistency. However, all these proxy tasks bypass the human's input on what matters to them, exacerbating spurious correlations and ultimately leading to robot behaviors that are misaligned with user preferences. In this work, we propose that robots should leverage human feedback to align their visual representations with the end-user and disentangle what matters for the task. We propose Representation-Aligned Preference-based Learning (RAPL), a method for solving the visual representation alignment problem and visual reward learning problem through the lens of preference-based learning and optimal transport. Across experiments in X-MAGICAL and in robotic manipulation, we find that RAPL's reward consistently generates preferred robot behaviors with high sample efficiency, and shows strong zero-shot generalization when the visual representation is learned from a different embodiment than the robot's. ",
    "url": "https://arxiv.org/abs/2310.07932",
    "authors": [
      "Ran Tian",
      "Chenfeng Xu",
      "Masayoshi Tomizuka",
      "Jitendra Malik",
      "Andrea Bajcsy"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07941",
    "title": "A Convolutional Network Adaptation for Cortical Classification During  Mobile Brain Imaging",
    "abstract": "Deep neural networks (DNN) have become increasingly utilized in brain-computer interface (BCI) technologies with the outset goal of classifying human physiological signals in computer-readable format. While our present understanding of DNN usage for BCI is promising, we have little experience in deciphering neural events from dynamic freely-mobile situations. Using an improved version of EEGNet, our goal was to classify cognitive events from electroencephalography (EEG) signals while subjects simultaneously walked on a treadmill, sometimes while carrying a rucksack equivalent to 40% of their body weight. Walking subjects simultaneously performed a visual oddball target detection task, eliciting the P300 event-related potential (ERP), which then served as the DNN classification target. We found the base EEGNet to reach classification levels well above chance, with similar performance to previously reported P300 results. We found performance to be robust to noise, with classification similar for walking and loaded walking, with respect to standard seated condition with minimal movement. With additional architectural search and tuning to the EEGNet model (termed Cog-Neuro, herein; CN-EEGNet), we reached classification accuracy of greater than 95%, similar to previously reported state of the art levels in seated P300 tasks. To our knowledge, these results are the first documented implementation of a DNN for the classification of cognitive neural state during dual-task walking. The classification of one's ongoing cognitive state during a demanding physical task establishes the utility for BCI in complex environments. ",
    "url": "https://arxiv.org/abs/2310.07941",
    "authors": [
      "Benjamin Cichy",
      "Jamie Lukos",
      "Mohammad Alam",
      "J. Cortney Bradford",
      "Nicholas Wymbs"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.07958",
    "title": "Towards Causal Deep Learning for Vulnerability Detection",
    "abstract": "Deep learning vulnerability detection has shown promising results in recent years. However, an important challenge that still blocks it from being very useful in practice is that the model is not robust under perturbation and it cannot generalize well over the out-of-distribution (OOD) data, e.g., applying a trained model to unseen projects in real world. We hypothesize that this is because the model learned non-robust features, e.g., variable names, that have spurious correlations with labels. When the perturbed and OOD datasets no longer have the same spurious features, the model prediction fails. To address the challenge, in this paper, we introduced causality into deep learning vulnerability detection. Our approach CausalVul consists of two phases. First, we designed novel perturbations to discover spurious features that the model may use to make predictions. Second, we applied the causal learning algorithms, specifically, do-calculus, on top of existing deep learning models to systematically remove the use of spurious features and thus promote causal based prediction. Our results show that CausalVul consistently improved the model accuracy, robustness and OOD performance for all the state-of-the-art models and datasets we experimented. To the best of our knowledge, this is the first work that introduces do calculus based causal learning to software engineering models and shows it's indeed useful for improving the model accuracy, robustness and generalization. Our replication package is located at https://figshare.com/s/0ffda320dcb96c249ef2. ",
    "url": "https://arxiv.org/abs/2310.07958",
    "authors": [
      "Md Mahbubur Rahman",
      "Ira Ceka",
      "Chengzhi Mao",
      "Saikat Chakraborty",
      "Baishakhi Ray",
      "Wei Le"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2310.07969",
    "title": "CleftGAN: Adapting A Style-Based Generative Adversarial Network To  Create Images Depicting Cleft Lip Deformity",
    "abstract": "A major obstacle when attempting to train a machine learning system to evaluate facial clefts is the scarcity of large datasets of high-quality, ethics board-approved patient images. In response, we have built a deep learning-based cleft lip generator designed to produce an almost unlimited number of artificial images exhibiting high-fidelity facsimiles of cleft lip with wide variation. We undertook a transfer learning protocol testing different versions of StyleGAN-ADA (a generative adversarial network image generator incorporating adaptive data augmentation (ADA)) as the base model. Training images depicting a variety of cleft deformities were pre-processed to adjust for rotation, scaling, color adjustment and background blurring. The ADA modification of the primary algorithm permitted construction of our new generative model while requiring input of a relatively small number of training images. Adversarial training was carried out using 514 unique frontal photographs of cleft-affected faces to adapt a pre-trained model based on 70,000 normal faces. The Frechet Inception Distance (FID) was used to measure the similarity of the newly generated facial images to the cleft training dataset, while Perceptual Path Length (PPL) and the novel Divergence Index of Severity Histograms (DISH) measures were also used to assess the performance of the image generator that we dub CleftGAN. We found that StyleGAN3 with translation invariance (StyleGAN3-t) performed optimally as a base model. Generated images achieved a low FID reflecting a close similarity to our training input dataset of genuine cleft images. Low PPL and DISH measures reflected a smooth and semantically valid interpolation of images through the transfer learning process and a similar distribution of severity in the training and generated images, respectively. ",
    "url": "https://arxiv.org/abs/2310.07969",
    "authors": [
      "Abdullah Hayajneh",
      "Erchin Serpedin",
      "Mohammad Shaqfeh",
      "Graeme Glass",
      "Mitchell A. Stotland"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07975",
    "title": "Self-supervised visual learning for analyzing firearms trafficking  activities on the Web",
    "abstract": "Automated visual firearms classification from RGB images is an important real-world task with applications in public space security, intelligence gathering and law enforcement investigations. When applied to images massively crawled from the World Wide Web (including social media and dark Web sites), it can serve as an important component of systems that attempt to identify criminal firearms trafficking networks, by analyzing Big Data from open-source intelligence. Deep Neural Networks (DNN) are the state-of-the-art methodology for achieving this, with Convolutional Neural Networks (CNN) being typically employed. The common transfer learning approach consists of pretraining on a large-scale, generic annotated dataset for whole-image classification, such as ImageNet-1k, and then finetuning the DNN on a smaller, annotated, task-specific, downstream dataset for visual firearms classification. Neither Visual Transformer (ViT) neural architectures nor Self-Supervised Learning (SSL) approaches have been so far evaluated on this critical task. SSL essentially consists of replacing the traditional supervised pretraining objective with an unsupervised pretext task that does not require ground-truth labels.. ",
    "url": "https://arxiv.org/abs/2310.07975",
    "authors": [
      "Sotirios Konstantakos",
      "Despina Ioanna Chalkiadaki",
      "Ioannis Mademlis",
      "Adamantia Anna Rebolledo Chrysochoou",
      "Georgios Th. Papadopoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07979",
    "title": "Graph-SCP: Accelerating Set Cover Problems with Graph Neural Networks",
    "abstract": "Machine learning (ML) approaches are increasingly being used to accelerate combinatorial optimization (CO) problems. We look specifically at the Set Cover Problem (SCP) and propose Graph-SCP, a graph neural network method that can augment existing optimization solvers by learning to identify a much smaller sub-problem that contains the solution space. We evaluate the performance of Graph-SCP on synthetic weighted and unweighted SCP instances with diverse problem characteristics and complexities, and on instances from the OR Library, a canonical benchmark for SCP. We show that Graph-SCP reduces the problem size by 30-70% and achieves run time speedups up to~25x when compared to commercial solvers (Gurobi). Given a desired optimality threshold, Graph-SCP will improve upon it or even achieve 100% optimality. This is in contrast to fast greedy solutions that significantly compromise solution quality to achieve guaranteed polynomial run time. Graph-SCP can generalize to larger problem sizes and can be used with other conventional or ML-augmented CO solvers to lead to potential additional run time improvement. ",
    "url": "https://arxiv.org/abs/2310.07979",
    "authors": [
      "Zohair Shafi",
      "Benjamin A. Miller",
      "Tina Eliassi-Rad",
      "Rajmonda S. Caceres"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2310.07980",
    "title": "GRASP: Accelerating Shortest Path Attacks via Graph Attention",
    "abstract": "Recent advances in machine learning (ML) have shown promise in aiding and accelerating classical combinatorial optimization algorithms. ML-based speed ups that aim to learn in an end to end manner (i.e., directly output the solution) tend to trade off run time with solution quality. Therefore, solutions that are able to accelerate existing solvers while maintaining their performance guarantees, are of great interest. We consider an APX-hard problem, where an adversary aims to attack shortest paths in a graph by removing the minimum number of edges. We propose the GRASP algorithm: Graph Attention Accelerated Shortest Path Attack, an ML aided optimization algorithm that achieves run times up to 10x faster, while maintaining the quality of solution generated. GRASP uses a graph attention network to identify a smaller subgraph containing the combinatorial solution, thus effectively reducing the input problem size. Additionally, we demonstrate how careful representation of the input graph, including node features that correlate well with the optimization task, can highlight important structure in the optimization solution. ",
    "url": "https://arxiv.org/abs/2310.07980",
    "authors": [
      "Zohair Shafi. Benjamin A. Miller",
      "Ayan Chatterjee",
      "Tina Eliassi-Rad",
      "Rajmonda S. Caceres"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07985",
    "title": "Neural Combinatorial Optimization with Heavy Decoder: Toward Large Scale  Generalization",
    "abstract": "Neural combinatorial optimization (NCO) is a promising learning-based approach for solving challenging combinatorial optimization problems without specialized algorithm design by experts. However, most constructive NCO methods cannot solve problems with large-scale instance sizes, which significantly diminishes their usefulness for real-world applications. In this work, we propose a novel Light Encoder and Heavy Decoder (LEHD) model with a strong generalization ability to address this critical issue. The LEHD model can learn to dynamically capture the relationships between all available nodes of varying sizes, which is beneficial for model generalization to problems of various scales. Moreover, we develop a data-efficient training scheme and a flexible solution construction mechanism for the proposed LEHD model. By training on small-scale problem instances, the LEHD model can generate nearly optimal solutions for the Travelling Salesman Problem (TSP) and the Capacitated Vehicle Routing Problem (CVRP) with up to 1000 nodes, and also generalizes well to solve real-world TSPLib and CVRPLib problems. These results confirm our proposed LEHD model can significantly improve the state-of-the-art performance for constructive NCO. The code is available at https://github.com/CIAM-Group/NCO_code/tree/main/single_objective/LEHD. ",
    "url": "https://arxiv.org/abs/2310.07985",
    "authors": [
      "Fu Luo",
      "Xi Lin",
      "Fei Liu",
      "Qingfu Zhang",
      "Zhenkun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2310.07995",
    "title": "HeightFormer: A Multilevel Interaction and Image-adaptive  Classification-regression Network for Monocular Height Estimation with Aerial  Images",
    "abstract": "Height estimation has long been a pivotal topic within measurement and remote sensing disciplines, proving critical for endeavours such as 3D urban modelling, MR and autonomous driving. Traditional methods utilise stereo matching or multisensor fusion, both well-established techniques that typically necessitate multiple images from varying perspectives and adjunct sensors like SAR, leading to substantial deployment costs. Single image height estimation has emerged as an attractive alternative, boasting a larger data source variety and simpler deployment. However, current methods suffer from limitations such as fixed receptive fields, a lack of global information interaction, leading to noticeable instance-level height deviations. The inherent complexity of height prediction can result in a blurry estimation of object edge depth when using mainstream regression methods based on fixed height division. This paper presents a comprehensive solution for monocular height estimation in remote sensing, termed HeightFormer, combining multilevel interactions and image-adaptive classification-regression. It features the Multilevel Interaction Backbone (MIB) and Image-adaptive Classification-regression Height Generator (ICG). MIB supplements the fixed sample grid in CNN of the conventional backbone network with tokens of different interaction ranges. It is complemented by a pixel-, patch-, and feature map-level hierarchical interaction mechanism, designed to relay spatial geometry information across different scales and introducing a global receptive field to enhance the quality of instance-level height estimation. The ICG dynamically generates height partition for each image and reframes the traditional regression task, using a refinement from coarse to fine classification-regression that significantly mitigates the innate ill-posedness issue and drastically improves edge sharpness. ",
    "url": "https://arxiv.org/abs/2310.07995",
    "authors": [
      "Zhan Chen",
      "Yidan Zhang",
      "Xiyu Qi",
      "Yongqiang Mao",
      "Xin Zhou",
      "Lulu Niu",
      "Hui Wu",
      "Lei Wang",
      "Yunping Ge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07997",
    "title": "Point-NeuS: Point-Guided Neural Implicit Surface Reconstruction by  Volume Rendering",
    "abstract": "Recently, learning neural implicit surface by volume rendering has been a promising way for multi-view reconstruction. However, limited accuracy and excessive time complexity remain bottlenecks that current methods urgently need to overcome. To address these challenges, we propose a new method called Point-NeuS, utilizing point-guided mechanisms to achieve accurate and efficient reconstruction. Point modeling is organically embedded into the volume rendering to enhance and regularize the representation of implicit surface. Specifically, to achieve precise point guidance and noise robustness, aleatoric uncertainty of the point cloud is modeled to capture the distribution of noise and estimate the reliability of points. Additionally, a Neural Projection module connecting points and images is introduced to add geometric constraints to the Signed Distance Function (SDF). To better compensate for geometric bias between volume rendering and point modeling, high-fidelity points are filtered into an Implicit Displacement Network to improve the representation of SDF. Benefiting from our effective point guidance, lightweight networks are employed to achieve an impressive 11x speedup compared to NeuS. Extensive experiments show that our method yields high-quality surfaces, especially for fine-grained details and smooth regions. Moreover, it exhibits strong robustness to both noisy and sparse data. ",
    "url": "https://arxiv.org/abs/2310.07997",
    "authors": [
      "Chen Zhang",
      "Wanjuan Su",
      "Wenbing Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07998",
    "title": "A Novel Statistical Measure for Out-of-Distribution Detection in Data  Quality Assurance",
    "abstract": "Data outside the problem domain poses significant threats to the security of AI-based intelligent systems. Aiming to investigate the data domain and out-of-distribution (OOD) data in AI quality management (AIQM) study, this paper proposes to use deep learning techniques for feature representation and develop a novel statistical measure for OOD detection. First, to extract low-dimensional representative features distinguishing normal and OOD data, the proposed research combines the deep auto-encoder (AE) architecture and neuron activation status for feature engineering. Then, using local conditional probability (LCP) in data reconstruction, a novel and superior statistical measure is developed to calculate the score of OOD detection. Experiments and evaluations are conducted on image benchmark datasets and an industrial dataset. Through comparative analysis with other common statistical measures in OOD detection, the proposed research is validated as feasible and effective in OOD and AIQM studies. ",
    "url": "https://arxiv.org/abs/2310.07998",
    "authors": [
      "Tinghui Ouyang",
      "Isao Echizen",
      "Yoshiki Seo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.08008",
    "title": "Effects of Human Adversarial and Affable Samples on BERT  Generalizability",
    "abstract": "BERT-based models have had strong performance on leaderboards, yet have been demonstrably worse in real-world settings requiring generalization. Limited quantities of training data is considered a key impediment to achieving generalizability in machine learning. In this paper, we examine the impact of training \\textit{data quality}, not quantity, on a model's generalizability. We consider two characteristics of training data: the portion of human-adversarial (h-adversarial), i.e., sample pairs with seemingly minor differences but different ground-truth labels, and human-affable (h-affable) training samples, i.e., sample pairs with minor differences but the same ground-truth label. We find that for a fixed size of training samples, as a rule of thumb, having 10-30\\% h-adversarial instances improves the precision, and therefore F1, by up to 20 points in the tasks of text classification and relation extraction. Increasing h-adversarials beyond this range can result in performance plateaus or even degradation.In contrast, h-affables may not contribute to a model's generalizability and may even degrade generalization performance. ",
    "url": "https://arxiv.org/abs/2310.08008",
    "authors": [
      "Aparna Elangovan",
      "Jiayuan He",
      "Yuan Li",
      "Karin Verspoor"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.08019",
    "title": "Robust 1-bit Compressed Sensing with Iterative Hard Thresholding",
    "abstract": "In 1-bit compressed sensing, the aim is to estimate a $k$-sparse unit vector $x\\in S^{n-1}$ within an $\\epsilon$ error (in $\\ell_2$) from minimal number of linear measurements that are quantized to just their signs, i.e., from measurements of the form $y = \\mathrm{Sign}(\\langle a, x\\rangle).$ In this paper, we study a noisy version where a fraction of the measurements can be flipped, potentially by an adversary. In particular, we analyze the Binary Iterative Hard Thresholding (BIHT) algorithm, a proximal gradient descent on a properly defined loss function used for 1-bit compressed sensing, in this noisy setting. It is known from recent results that, with $\\tilde{O}(\\frac{k}{\\epsilon})$ noiseless measurements, BIHT provides an estimate within $\\epsilon$ error. This result is optimal and universal, meaning one set of measurements work for all sparse vectors. In this paper, we show that BIHT also provides better results than all known methods for the noisy setting. We show that when up to $\\tau$-fraction of the sign measurements are incorrect (adversarial error), with the same number of measurements as before, BIHT agnostically provides an estimate of $x$ within an $\\tilde{O}(\\epsilon+\\tau)$ error, maintaining the universality of measurements. This establishes stability of iterative hard thresholding in the presence of measurement error. To obtain the result, we use the restricted approximate invertibility of Gaussian matrices, as well as a tight analysis of the high-dimensional geometry of the adversarially corrupted measurements. ",
    "url": "https://arxiv.org/abs/2310.08019",
    "authors": [
      "Namiko Matsumoto",
      "Arya Mazumdar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.08026",
    "title": "Beyond Sharing Weights in Decoupling Feature Learning Network for UAV  RGB-Infrared Vehicle Re-Identification",
    "abstract": "Owing to the capacity of performing full-time target search, cross-modality vehicle re-identification (Re-ID) based on unmanned aerial vehicle (UAV) is gaining more attention in both video surveillance and public security. However, this promising and innovative research has not been studied sufficiently due to the data inadequacy issue. Meanwhile, the cross-modality discrepancy and orientation discrepancy challenges further aggravate the difficulty of this task. To this end, we pioneer a cross-modality vehicle Re-ID benchmark named UAV Cross-Modality Vehicle Re-ID (UCM-VeID), containing 753 identities with 16015 RGB and 13913 infrared images. Moreover, to meet cross-modality discrepancy and orientation discrepancy challenges, we present a hybrid weights decoupling network (HWDNet) to learn the shared discriminative orientation-invariant features. For the first challenge, we proposed a hybrid weights siamese network with a well-designed weight restrainer and its corresponding objective function to learn both modality-specific and modality shared information. In terms of the second challenge, three effective decoupling structures with two pretext tasks are investigated to learn orientation-invariant feature. Comprehensive experiments are carried out to validate the effectiveness of the proposed method. The dataset and codes will be released at https://github.com/moonstarL/UAV-CM-VeID. ",
    "url": "https://arxiv.org/abs/2310.08026",
    "authors": [
      "Xingyue Liu",
      "Jiahao Qi",
      "Chen Chen",
      "Kangcheng Bin",
      "Ping Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.08027",
    "title": "Exploring Large Language Models for Multi-Modal Out-of-Distribution  Detection",
    "abstract": "Out-of-distribution (OOD) detection is essential for reliable and trustworthy machine learning. Recent multi-modal OOD detection leverages textual information from in-distribution (ID) class names for visual OOD detection, yet it currently neglects the rich contextual information of ID classes. Large language models (LLMs) encode a wealth of world knowledge and can be prompted to generate descriptive features for each class. Indiscriminately using such knowledge causes catastrophic damage to OOD detection due to LLMs' hallucinations, as is observed by our analysis. In this paper, we propose to apply world knowledge to enhance OOD detection performance through selective generation from LLMs. Specifically, we introduce a consistency-based uncertainty calibration method to estimate the confidence score of each generation. We further extract visual objects from each image to fully capitalize on the aforementioned world knowledge. Extensive experiments demonstrate that our method consistently outperforms the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2310.08027",
    "authors": [
      "Yi Dai",
      "Hao Lang",
      "Kaisheng Zeng",
      "Fei Huang",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.08031",
    "title": "Local Graph Clustering with Noisy Labels",
    "abstract": "The growing interest in machine learning problems over graphs with additional node information such as texts, images, or labels has popularized methods that require the costly operation of processing the entire graph. Yet, little effort has been made to the development of fast local methods (i.e. without accessing the entire graph) that extract useful information from such data. To that end, we propose a study of local graph clustering using noisy node labels as a proxy for additional node information. In this setting, nodes receive initial binary labels based on cluster affiliation: 1 if they belong to the target cluster and 0 otherwise. Subsequently, a fraction of these labels is flipped. We investigate the benefits of incorporating noisy labels for local graph clustering. By constructing a weighted graph with such labels, we study the performance of graph diffusion-based local clustering method on both the original and the weighted graphs. From a theoretical perspective, we consider recovering an unknown target cluster with a single seed node in a random graph with independent noisy node labels. We provide sufficient conditions on the label noise under which, with high probability, using diffusion in the weighted graph yields a more accurate recovery of the target cluster. This approach proves more effective than using the given labels alone or using diffusion in the label-free original graph. Empirically, we show that reliable node labels can be obtained with just a few samples from an attributed graph. Moreover, utilizing these labels via diffusion in the weighted graph leads to significantly better local clustering performance across several real-world datasets, improving F1 scores by up to 13%. ",
    "url": "https://arxiv.org/abs/2310.08031",
    "authors": [
      "Artur Back de Luca",
      "Kimon Fountoulakis",
      "Shenghao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.08032",
    "title": "Incorporating Domain Knowledge Graph into Multimodal Movie Genre  Classification with Self-Supervised Attention and Contrastive Learning",
    "abstract": "Multimodal movie genre classification has always been regarded as a demanding multi-label classification task due to the diversity of multimodal data such as posters, plot summaries, trailers and metadata. Although existing works have made great progress in modeling and combining each modality, they still face three issues: 1) unutilized group relations in metadata, 2) unreliable attention allocation, and 3) indiscriminative fused features. Given that the knowledge graph has been proven to contain rich information, we present a novel framework that exploits the knowledge graph from various perspectives to address the above problems. As a preparation, the metadata is processed into a domain knowledge graph. A translate model for knowledge graph embedding is adopted to capture the relations between entities. Firstly we retrieve the relevant embedding from the knowledge graph by utilizing group relations in metadata and then integrate it with other modalities. Next, we introduce an Attention Teacher module for reliable attention allocation based on self-supervised learning. It learns the distribution of the knowledge graph and produces rational attention weights. Finally, a Genre-Centroid Anchored Contrastive Learning module is proposed to strengthen the discriminative ability of fused features. The embedding space of anchors is initialized from the genre entities in the knowledge graph. To verify the effectiveness of our framework, we collect a larger and more challenging dataset named MM-IMDb 2.0 compared with the MM-IMDb dataset. The experimental results on two datasets demonstrate that our model is superior to the state-of-the-art methods. We will release the code in the near future. ",
    "url": "https://arxiv.org/abs/2310.08032",
    "authors": [
      "Jiaqi Li",
      "Guilin Qi",
      "Chuanyi Zhang",
      "Yongrui Chen",
      "Yiming Tan",
      "Chenlong Xia",
      "Ye Tian"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.08040",
    "title": "SEE-OoD: Supervised Exploration For Enhanced Out-of-Distribution  Detection",
    "abstract": "Current techniques for Out-of-Distribution (OoD) detection predominantly rely on quantifying predictive uncertainty and incorporating model regularization during the training phase, using either real or synthetic OoD samples. However, methods that utilize real OoD samples lack exploration and are prone to overfit the OoD samples at hand. Whereas synthetic samples are often generated based on features extracted from training data, rendering them less effective when the training and OoD data are highly overlapped in the feature space. In this work, we propose a Wasserstein-score-based generative adversarial training scheme to enhance OoD detection accuracy, which, for the first time, performs data augmentation and exploration simultaneously under the supervision of limited OoD samples. Specifically, the generator explores OoD spaces and generates synthetic OoD samples using feedback from the discriminator, while the discriminator exploits both the observed and synthesized samples for OoD detection using a predefined Wasserstein score. We provide theoretical guarantees that the optimal solutions of our generative scheme are statistically achievable through adversarial training in empirical settings. We then demonstrate that the proposed method outperforms state-of-the-art techniques on various computer vision datasets and exhibits superior generalizability to unseen OoD data. ",
    "url": "https://arxiv.org/abs/2310.08040",
    "authors": [
      "Xiaoyang Song",
      "Wenbo Sun",
      "Maher Nouiehed",
      "Raed Al Kontar",
      "Judy Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.08043",
    "title": "Understanding and Controlling a Maze-Solving Policy Network",
    "abstract": "To understand the goals and goal representations of AI systems, we carefully study a pretrained reinforcement learning policy that solves mazes by navigating to a range of target squares. We find this network pursues multiple context-dependent goals, and we further identify circuits within the network that correspond to one of these goals. In particular, we identified eleven channels that track the location of the goal. By modifying these channels, either with hand-designed interventions or by combining forward passes, we can partially control the policy. We show that this network contains redundant, distributed, and retargetable goal representations, shedding light on the nature of goal-direction in trained policy networks. ",
    "url": "https://arxiv.org/abs/2310.08043",
    "authors": [
      "Ulisse Mini",
      "Peli Grietzer",
      "Mrinank Sharma",
      "Austin Meek",
      "Monte MacDiarmid",
      "Alexander Matt Turner"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.08044",
    "title": "EC-Depth: Exploring the consistency of self-supervised monocular depth  estimation under challenging scenes",
    "abstract": "Self-supervised monocular depth estimation holds significant importance in the fields of autonomous driving and robotics. However, existing methods are typically designed to train and test on clear and pristine datasets, overlooking the impact of various adverse conditions prevalent in real-world scenarios. As a result, it is commonly observed that most self-supervised monocular depth estimation methods struggle to perform adequately under challenging conditions. To address this issue, we present EC-Depth, a novel self-supervised two-stage training framework to achieve a robust depth estimation, starting from the foundation of depth prediction consistency under different perturbations. Leveraging the proposed perturbation-invariant depth consistency constraint module and the consistency-based pseudo-label selection module, our model attains accurate and consistent depth predictions in both standard and challenging scenarios. Extensive experiments substantiate the effectiveness of the proposed method. Moreover, our method surpasses existing state-of-the-art methods on KITTI, KITTI-C and DrivingStereo benchmarks, demonstrating its potential for enhancing the reliability of self-supervised monocular depth estimation models in real-world applications. ",
    "url": "https://arxiv.org/abs/2310.08044",
    "authors": [
      "Ruijie Zhu",
      "Ziyang Song",
      "Chuxin Wang",
      "Jianfeng He",
      "Tianzhu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.08045",
    "title": "Model Predictive Inferential Control of Neural State-Space Models for  Autonomous Vehicle Motion Planning",
    "abstract": "Model predictive control (MPC) has proven useful in enabling safe and optimal motion planning for autonomous vehicles. In this paper, we investigate how to achieve MPC-based motion planning when a neural state-space model represents the vehicle dynamics. As the neural state-space model will lead to highly complex, nonlinear and nonconvex optimization landscapes, mainstream gradient-based MPC methods will be computationally too heavy to be a viable solution. In a departure, we propose the idea of model predictive inferential control (MPIC), which seeks to infer the best control decisions from the control objectives and constraints. Following the idea, we convert the MPC problem for motion planning into a Bayesian state estimation problem. Then, we develop a new particle filtering/smoothing approach to perform the estimation. This approach is implemented as banks of unscented Kalman filters/smoothers and offers high sampling efficiency, fast computation, and estimation accuracy. We evaluate the MPIC approach through a simulation study of autonomous driving in different scenarios, along with an exhaustive comparison with gradient-based MPC. The results show that the MPIC approach has considerable computational efficiency, regardless of complex neural network architectures, and shows the capability to solve large-scale MPC problems for neural state-space models. ",
    "url": "https://arxiv.org/abs/2310.08045",
    "authors": [
      "Iman Askari",
      "Xumein Tu",
      "Shen Zeng",
      "Huazhen Fang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.08064",
    "title": "Age Estimation Based on Graph Convolutional Networks and Multi-head  Attention Mechanisms",
    "abstract": "Age estimation technology is a part of facial recognition and has been applied to identity authentication. This technology achieves the development and application of a juvenile anti-addiction system by authenticating users in the game. Convolutional Neural Network (CNN) and Transformer algorithms are widely used in this application scenario. However, these two models cannot flexibly extract and model features of faces with irregular shapes, and they are ineffective in capturing key information. Furthermore, the above methods will contain a lot of background information while extracting features, which will interfere with the model. In consequence, it is easy to extract redundant information from images. In this paper, a new modeling idea is proposed to solve this problem, which can flexibly model irregular objects. The Graph Convolutional Network (GCN) is used to extract features from irregular face images effectively, and multi-head attention mechanisms are added to avoid redundant features and capture key region information in the image. This model can effectively improve the accuracy of age estimation and reduce the MAE error value to about 3.64, which is better than the effect of today's age estimation model, to improve the accuracy of face recognition and identity authentication. ",
    "url": "https://arxiv.org/abs/2310.08064",
    "authors": [
      "Miaomiao Yang",
      "Changwei Yao",
      "Shijin Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.08069",
    "title": "Rethinking Negative Pairs in Code Search",
    "abstract": "Recently, contrastive learning has become a key component in fine-tuning code search models for software development efficiency and effectiveness. It pulls together positive code snippets while pushing negative samples away given search queries. Among contrastive learning, InfoNCE is the most widely used loss function due to its better performance. However, the following problems in negative samples of InfoNCE may deteriorate its representation learning: 1) The existence of false negative samples in large code corpora due to duplications. 2). The failure to explicitly differentiate between the potential relevance of negative samples. As an example, a bubble sorting algorithm example is less ``negative'' than a file saving function for the quick sorting algorithm query. In this paper, we tackle the above problems by proposing a simple yet effective Soft-InfoNCE loss that inserts weight terms into InfoNCE. In our proposed loss function, we apply three methods to estimate the weights of negative pairs and show that the vanilla InfoNCE loss is a special case of Soft-InfoNCE. Theoretically, we analyze the effects of Soft-InfoNCE on controlling the distribution of learnt code representations and on deducing a more precise mutual information estimation. We furthermore discuss the superiority of proposed loss functions with other design alternatives. Extensive experiments demonstrate the effectiveness of Soft-InfoNCE and weights estimation methods under state-of-the-art code search models on a large-scale public dataset consisting of six programming languages. Source code is available at \\url{https://github.com/Alex-HaochenLi/Soft-InfoNCE}. ",
    "url": "https://arxiv.org/abs/2310.08069",
    "authors": [
      "Haochen Li",
      "Xin Zhou",
      "Luu Anh Tuan",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.08073",
    "title": "Samples on Thin Ice: Re-Evaluating Adversarial Pruning of Neural  Networks",
    "abstract": "Neural network pruning has shown to be an effective technique for reducing the network size, trading desirable properties like generalization and robustness to adversarial attacks for higher sparsity. Recent work has claimed that adversarial pruning methods can produce sparse networks while also preserving robustness to adversarial examples. In this work, we first re-evaluate three state-of-the-art adversarial pruning methods, showing that their robustness was indeed overestimated. We then compare pruned and dense versions of the same models, discovering that samples on thin ice, i.e., closer to the unpruned model's decision boundary, are typically misclassified after pruning. We conclude by discussing how this intuition may lead to designing more effective adversarial pruning methods in future work. ",
    "url": "https://arxiv.org/abs/2310.08073",
    "authors": [
      "Giorgio Piras",
      "Maura Pintor",
      "Ambra Demontis",
      "Battista Biggio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.08133",
    "title": "Multi Level Dense Layer Neural Network Model for Housing Price  Prediction",
    "abstract": "Predicting the price of a house remains a challenging issue that needs to be addressed. Research has attempted to establish a model with different methods and algorithms to predict the housing price, from the traditional hedonic model to a neural network algorithm. However, many existing algorithms in the literature are proposed without any finetuning and customization in the model. In this paper, the author attempted to propose a novel neural network-based model to improve the performance of housing price prediction. Inspired by the modular neural network, the proposed model consists of a three-level neural network that is capable to process information in parallel. The author compared several state-of-the-art algorithms available in the literature on the Boston housing dataset to evaluate the effectiveness of the proposed model. The results show that the proposed model provides better accuracy and outperforms existing algorithms in different evaluation metrics. The code for the implementation is available https://github.com/wijayarobert/MultiLevelDenseLayerNN ",
    "url": "https://arxiv.org/abs/2310.08133",
    "authors": [
      "Robert Wijaya"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.08138",
    "title": "Multi-Scale Spatial-Temporal Recurrent Networks for Traffic Flow  Prediction",
    "abstract": "Traffic flow prediction is one of the most fundamental tasks of intelligent transportation systems. The complex and dynamic spatial-temporal dependencies make the traffic flow prediction quite challenging. Although existing spatial-temporal graph neural networks hold prominent, they often encounter challenges such as (1) ignoring the fixed graph that limits the predictive performance of the model, (2) insufficiently capturing complex spatial-temporal dependencies simultaneously, and (3) lacking attention to spatial-temporal information at different time lengths. In this paper, we propose a Multi-Scale Spatial-Temporal Recurrent Network for traffic flow prediction, namely MSSTRN, which consists of two different recurrent neural networks: the single-step gate recurrent unit and the multi-step gate recurrent unit to fully capture the complex spatial-temporal information in the traffic data under different time windows. Moreover, we propose a spatial-temporal synchronous attention mechanism that integrates adaptive position graph convolutions into the self-attention mechanism to achieve synchronous capture of spatial-temporal dependencies. We conducted extensive experiments on four real traffic datasets and demonstrated that our model achieves the best prediction accuracy with non-trivial margins compared to all the twenty baseline methods. ",
    "url": "https://arxiv.org/abs/2310.08138",
    "authors": [
      "Haiyang Liu",
      "Chunjiang Zhu",
      "Detian Zhang",
      "Qing Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.08139",
    "title": "DualAug: Exploiting Additional Heavy Augmentation with OOD Data  Rejection",
    "abstract": "Data augmentation is a dominant method for reducing model overfitting and improving generalization. Most existing data augmentation methods tend to find a compromise in augmenting the data, \\textit{i.e.}, increasing the amplitude of augmentation carefully to avoid degrading some data too much and doing harm to the model performance. We delve into the relationship between data augmentation and model performance, revealing that the performance drop with heavy augmentation comes from the presence of out-of-distribution (OOD) data. Nonetheless, as the same data transformation has different effects for different training samples, even for heavy augmentation, there remains part of in-distribution data which is beneficial to model training. Based on the observation, we propose a novel data augmentation method, named \\textbf{DualAug}, to keep the augmentation in distribution as much as possible at a reasonable time and computational cost. We design a data mixing strategy to fuse augmented data from both the basic- and the heavy-augmentation branches. Extensive experiments on supervised image classification benchmarks show that DualAug improve various automated data augmentation method. Moreover, the experiments on semi-supervised learning and contrastive self-supervised learning demonstrate that our DualAug can also improve related method. Code is available at \\href{https://github.com/shuguang99/DualAug}{https://github.com/shuguang99/DualAug}. ",
    "url": "https://arxiv.org/abs/2310.08139",
    "authors": [
      "Zehao Wang",
      "Yiwen Guo",
      "Qizhang Li",
      "Guanglei Yang",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.08140",
    "title": "CODY: A graph-based framework for the analysis of COnversation DYnamics  in online social networks",
    "abstract": "Conversations are an integral part of online social media, and gaining insights into these conversations is of significant value for many commercial as well as academic use cases. From a computational perspective, however, analyzing conversation data is complex, and numerous aspects must be considered. Next to the structure of conversations, the discussed content - as well as their dynamics - have to be taken into account. Still, most existing modelling and analysis approaches focus only on one of these aspects and, in particular, lack the capability to investigate the temporal evolution of a conversation. To address these shortcomings, in this work, we present CODY, a content-aware, graph-based framework to study the dynamics of online conversations along multiple dimensions. Its capabilities are extensively demonstrated by conducting three experiments based on a large conversation dataset from the German political Twittersphere. First, the posting activity across the lifetime of conversations is examined. We find that posting activity follows an exponential saturation pattern. Based on this activity model, we develop a volume-based sampling method to study conversation dynamics using temporal network snapshots. In a second experiment, we focus on the evolution of a conversation's structure and leverage a novel metric, the temporal Wiener index, for that. Results indicate that as conversations progress, a conversation's structure tends to be less sprawling and more centered around the original seed post. Furthermore, focusing on the dynamics of content in conversations, the evolution of hashtag usage within conversations is studied. Initially used hashtags do not necessarily keep their dominant prevalence throughout the lifetime of a conversation. Instead, various \"hashtag hijacking\" scenarios are found. ",
    "url": "https://arxiv.org/abs/2310.08140",
    "authors": [
      "John Ziegler",
      "Fabian Kneissl",
      "Michael Gertz"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.08153",
    "title": "A Systematic Evaluation of Automated Tools for Side-Channel  Vulnerabilities Detection in Cryptographic Libraries",
    "abstract": "To protect cryptographic implementations from side-channel vulnerabilities, developers must adopt constant-time programming practices. As these can be error-prone, many side-channel detection tools have been proposed. Despite this, such vulnerabilities are still manually found in cryptographic libraries. While a recent paper by Jancar et al. shows that developers rarely perform side-channel detection, it is unclear if existing detection tools could have found these vulnerabilities in the first place. To answer this question, we surveyed the literature to build a classification of 34 side-channel detection frameworks. The classification we offer compares multiple criteria, including the methods used, the scalability of the analysis or the threat model considered. We then built a unified common benchmark of representative cryptographic operations on a selection of 5 promising detection tools. This benchmark allows us to better compare the capabilities of each tool, and the scalability of their analysis. Additionally, we offer a classification of recently published side-channel vulnerabilities. We then test each of the selected tools on benchmarks reproducing a subset of these vulnerabilities as well as the context in which they appear. We find that existing tools can struggle to find vulnerabilities for a variety of reasons, mainly the lack of support for SIMD instructions, implicit flows, and internal secret generation. Based on our findings, we develop a set of recommendations for the research community and cryptographic library developers, with the goal to improve the effectiveness of side-channel detection tools. ",
    "url": "https://arxiv.org/abs/2310.08153",
    "authors": [
      "Antoine Geimer",
      "Math\u00e9o Vergnolle",
      "Fr\u00e9d\u00e9ric Recoules",
      "Lesly-Ann Daniel",
      "S\u00e9bastien Bardin",
      "Cl\u00e9mentine Maurice"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.08163",
    "title": "Combining Decentralized IDentifiers with Proof of Membership to Enable  Trust in IoT Networks",
    "abstract": "The Self-Sovereign Identity (SSI) is a decentralized paradigm enabling full control over the data used to build and prove the identity. In Internet of Things networks with security requirements, the Self-Sovereign Identity can play a key role and bring benefits with respect to centralized identity solutions. The challenge is to make the SSI compatible with resource-constraint IoT networks. In line with this objective, the paper proposes and discusses an alternative (mutual) authentication process for IoT nodes under the same administration domain. The main idea is to combine the Decentralized IDentifier (DID)-based verification of private key ownership with the verification of a proof that the DID belongs to an evolving trusted set. The solution is built around the proof of membership notion. The paper analyzes two membership solutions, a novel solution designed by the Authors based on Merkle trees and a second one based on the adaptation of Boneh, Boyen and Shacham (BBS) group signature scheme. The paper concludes with a performance estimation and a comparative analysis. ",
    "url": "https://arxiv.org/abs/2310.08163",
    "authors": [
      "Alessandro Pino",
      "Davide Margaria",
      "Andrea Vesco"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.08176",
    "title": "Infinite Width Graph Neural Networks for Node Regression/ Classification",
    "abstract": "This work analyzes Graph Neural Networks, a generalization of Fully-Connected Deep Neural Nets on Graph structured data, when their width, that is the number of nodes in each fullyconnected layer is increasing to infinity. Infinite Width Neural Networks are connecting Deep Learning to Gaussian Processes and Kernels, both Machine Learning Frameworks with long traditions and extensive theoretical foundations. Gaussian Processes and Kernels have much less hyperparameters then Neural Networks and can be used for uncertainty estimation, making them more user friendly for applications. This works extends the increasing amount of research connecting Gaussian Processes and Kernels to Neural Networks. The Kernel and Gaussian Process closed forms are derived for a variety of architectures, namely the standard Graph Neural Network, the Graph Neural Network with Skip-Concatenate Connections and the Graph Attention Neural Network. All architectures are evaluated on a variety of datasets on the task of transductive Node Regression and Classification. Additionally, a Spectral Sparsification method known as Effective Resistance is used to improve runtime and memory requirements. Extending the setting to inductive graph learning tasks (Graph Regression/ Classification) is straightforward and is briefly discussed in 3.5. ",
    "url": "https://arxiv.org/abs/2310.08176",
    "authors": [
      "Yunus Cobanoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.08177",
    "title": "Improving Fast Minimum-Norm Attacks with Hyperparameter Optimization",
    "abstract": "Evaluating the adversarial robustness of machine learning models using gradient-based attacks is challenging. In this work, we show that hyperparameter optimization can improve fast minimum-norm attacks by automating the selection of the loss function, the optimizer and the step-size scheduler, along with the corresponding hyperparameters. Our extensive evaluation involving several robust models demonstrates the improved efficacy of fast minimum-norm attacks when hyper-up with hyperparameter optimization. We release our open-source code at https://github.com/pralab/HO-FMN. ",
    "url": "https://arxiv.org/abs/2310.08177",
    "authors": [
      "Giuseppe Floris",
      "Raffaele Mura",
      "Luca Scionis",
      "Giorgio Piras",
      "Maura Pintor",
      "Ambra Demontis",
      "Battista Biggio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.08182",
    "title": "XIMAGENET-12: An Explainable AI Benchmark Dataset for Model Robustness  Evaluation",
    "abstract": "The lack of standardized robustness metrics and the widespread reliance on numerous unrelated benchmark datasets for testing have created a gap between academically validated robust models and their often problematic practical adoption. To address this, we introduce XIMAGENET-12, an explainable benchmark dataset with over 200K images and 15,600 manual semantic annotations. Covering 12 categories from ImageNet to represent objects commonly encountered in practical life and simulating six diverse scenarios, including overexposure, blurring, color changing, etc., we further propose a novel robustness criterion that extends beyond model generation ability assessment. This benchmark dataset, along with related code, is available at https://sites.google.com/view/ximagenet-12/home. Researchers and practitioners can leverage this resource to evaluate the robustness of their visual models under challenging conditions and ultimately benefit from the demands of practical computer vision systems. ",
    "url": "https://arxiv.org/abs/2310.08182",
    "authors": [
      "Qiang Li",
      "Dan Zhang",
      "Shengzhao Lei",
      "Xun Zhao",
      "Shuyan Li",
      "Porawit Kamnoedboon",
      "WeiWei Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.08192",
    "title": "Slip Detection and Surface Prediction Through Bio-Inspired Tactile  Feedback",
    "abstract": "High resolution tactile sensing has great potential in autonomous mobile robotics, particularly for legged robots. One particular area where it has significant promise is the traversal of challenging, varied terrain. Depending on whether an environment is slippery, soft, hard or dry, a robot must adapt its method of locomotion accordingly. Currently many multi-legged robots, such as Boston Dynamic's Spot robot, have preset gaits for different surface types, but struggle over terrains where the surface type changes frequently. Being able to automatically detect changes within an environment would allow a robot to autonomously adjust its method of locomotion to better suit conditions, without requiring a human user to manually set the change in surface type. In this paper we report on the first detailed investigation of the properties of a particular bio-inspired tactile sensor, the TacTip, to test its suitability for this kind of automatic detection of surface conditions. We explored different processing techniques and a regression model, using a custom made rig for data collection to determine how a robot could sense directional and general force on the sensor in a variety of conditions. This allowed us to successfully demonstrate how the sensor can be used to distinguish between soft, hard, dry and (wet) slippery surfaces. We further explored a neural model to classify specific surface textures. Pin movement (the movement of optical markers within the sensor) was key to sensing this information, and all models relied on some form of temporal information. Our final trained models could successfully determine the direction the sensor is heading in, the amount of force acting on it, and determine differences in the surface texture such as Lego vs smooth hard surface, or concrete vs smooth hard surface. ",
    "url": "https://arxiv.org/abs/2310.08192",
    "authors": [
      "Dexter R. Shepherd",
      "Phil Husbands",
      "Andy Philippides",
      "Chris Johnson"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.08224",
    "title": "Emergence of Latent Binary Encoding in Deep Neural Network Classifiers",
    "abstract": "We observe the emergence of binary encoding within the latent space of deep-neural-network classifiers. Such binary encoding is induced by introducing a linear penultimate layer, which is equipped during training with a loss function that grows as $\\exp(\\vec{x}^2)$, where $\\vec{x}$ are the coordinates in the latent space. The phenomenon we describe represents a specific instance of a well-documented occurrence known as \\textit{neural collapse}, which arises in the terminal phase of training and entails the collapse of latent class means to the vertices of a simplex equiangular tight frame (ETF). We show that binary encoding accelerates convergence toward the simplex ETF and enhances classification accuracy. ",
    "url": "https://arxiv.org/abs/2310.08224",
    "authors": [
      "Luigi Sbail\u00f2",
      "Luca Ghiringhelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.08240",
    "title": "Who Said That? Benchmarking Social Media AI Detection",
    "abstract": "AI-generated text has proliferated across various online platforms, offering both transformative prospects and posing significant risks related to misinformation and manipulation. Addressing these challenges, this paper introduces SAID (Social media AI Detection), a novel benchmark developed to assess AI-text detection models' capabilities in real social media platforms. It incorporates real AI-generate text from popular social media platforms like Zhihu and Quora. Unlike existing benchmarks, SAID deals with content that reflects the sophisticated strategies employed by real AI users on the Internet which may evade detection or gain visibility, providing a more realistic and challenging evaluation landscape. A notable finding of our study, based on the Zhihu dataset, reveals that annotators can distinguish between AI-generated and human-generated texts with an average accuracy rate of 96.5%. This finding necessitates a re-evaluation of human capability in recognizing AI-generated text in today's widely AI-influenced environment. Furthermore, we present a new user-oriented AI-text detection challenge focusing on the practicality and effectiveness of identifying AI-generated text based on user information and multiple responses. The experimental results demonstrate that conducting detection tasks on actual social media platforms proves to be more challenging compared to traditional simulated AI-text detection, resulting in a decreased accuracy. On the other hand, user-oriented AI-generated text detection significantly improve the accuracy of detection. ",
    "url": "https://arxiv.org/abs/2310.08240",
    "authors": [
      "Wanyun Cui",
      "Linqiu Zhang",
      "Qianle Wang",
      "Shuyang Cai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.08259",
    "title": "Invisible Threats: Backdoor Attack in OCR Systems",
    "abstract": "Optical Character Recognition (OCR) is a widely used tool to extract text from scanned documents. Today, the state-of-the-art is achieved by exploiting deep neural networks. However, the cost of this performance is paid at the price of system vulnerability. For instance, in backdoor attacks, attackers compromise the training phase by inserting a backdoor in the victim's model that will be activated at testing time by specific patterns while leaving the overall model performance intact. This work proposes a backdoor attack for OCR resulting in the injection of non-readable characters from malicious input images. This simple but effective attack exposes the state-of-the-art OCR weakness, making the extracted text correct to human eyes but simultaneously unusable for the NLP application that uses OCR as a preprocessing step. Experimental results show that the attacked models successfully output non-readable characters for around 90% of the poisoned instances without harming their performance for the remaining instances. ",
    "url": "https://arxiv.org/abs/2310.08259",
    "authors": [
      "Mauro Conti",
      "Nicola Farronato",
      "Stefanos Koffas",
      "Luca Pajola",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.08261",
    "title": "GraphAlign: Enhancing Accurate Feature Alignment by Graph matching for  Multi-Modal 3D Object Detection",
    "abstract": "LiDAR and cameras are complementary sensors for 3D object detection in autonomous driving. However, it is challenging to explore the unnatural interaction between point clouds and images, and the critical factor is how to conduct feature alignment of heterogeneous modalities. Currently, many methods achieve feature alignment by projection calibration only, without considering the problem of coordinate conversion accuracy errors between sensors, leading to sub-optimal performance. In this paper, we present GraphAlign, a more accurate feature alignment strategy for 3D object detection by graph matching. Specifically, we fuse image features from a semantic segmentation encoder in the image branch and point cloud features from a 3D Sparse CNN in the LiDAR branch. To save computation, we construct the nearest neighbor relationship by calculating Euclidean distance within the subspaces that are divided into the point cloud features. Through the projection calibration between the image and point cloud, we project the nearest neighbors of point cloud features onto the image features. Then by matching the nearest neighbors with a single point cloud to multiple images, we search for a more appropriate feature alignment. In addition, we provide a self-attention module to enhance the weights of significant relations to fine-tune the feature alignment between heterogeneous modalities. Extensive experiments on nuScenes benchmark demonstrate the effectiveness and efficiency of our GraphAlign. ",
    "url": "https://arxiv.org/abs/2310.08261",
    "authors": [
      "Ziying Song",
      "Haiyue Wei",
      "Lin Bai",
      "Lei Yang",
      "Caiyan Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.08270",
    "title": "Hilbert Space Embedding-based Trajectory Optimization for Multi-Modal  Uncertain Obstacle Trajectory Prediction",
    "abstract": "Safe autonomous driving critically depends on how well the ego-vehicle can predict the trajectories of neighboring vehicles. To this end, several trajectory prediction algorithms have been presented in the existing literature. Many of these approaches output a multi-modal distribution of obstacle trajectories instead of a single deterministic prediction to account for the underlying uncertainty. However, existing planners cannot handle the multi-modality based on just sample-level information of the predictions. With this motivation, this paper proposes a trajectory optimizer that can leverage the distributional aspects of the prediction in a computationally tractable and sample-efficient manner. Our optimizer can work with arbitrarily complex distributions and thus can be used with output distribution represented as a deep neural network. The core of our approach is built on embedding distribution in Reproducing Kernel Hilbert Space (RKHS), which we leverage in two ways. First, we propose an RKHS embedding approach to select probable samples from the obstacle trajectory distribution. Second, we rephrase chance-constrained optimization as distribution matching in RKHS and propose a novel sampling-based optimizer for its solution. We validate our approach with hand-crafted and neural network-based predictors trained on real-world datasets and show improvement over the existing stochastic optimization approaches in safety metrics. ",
    "url": "https://arxiv.org/abs/2310.08270",
    "authors": [
      "Basant Sharma",
      "Aditya Sharma",
      "K.Madhava Krishna",
      "Arun Kumar Singh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.08276",
    "title": "Direction-Oriented Visual-semantic Embedding Model for Remote Sensing  Image-text Retrieval",
    "abstract": "Image-text retrieval has developed rapidly in recent years. However, it is still a challenge in remote sensing due to visual-semantic imbalance, which leads to incorrect matching of non-semantic visual and textual features. To solve this problem, we propose a novel Direction-Oriented Visual-semantic Embedding Model (DOVE) to mine the relationship between vision and language. Concretely, a Regional-Oriented Attention Module (ROAM) adaptively adjusts the distance between the final visual and textual embeddings in the latent semantic space, oriented by regional visual features. Meanwhile, a lightweight Digging Text Genome Assistant (DTGA) is designed to expand the range of tractable textual representation and enhance global word-level semantic connections using less attention operations. Ultimately, we exploit a global visual-semantic constraint to reduce single visual dependency and serve as an external constraint for the final visual and textual representations. The effectiveness and superiority of our method are verified by extensive experiments including parameter evaluation, quantitative comparison, ablation studies and visual analysis, on two benchmark datasets, RSICD and RSITMD. ",
    "url": "https://arxiv.org/abs/2310.08276",
    "authors": [
      "Qing Ma",
      "Jiancheng Pan",
      "Cong Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.08279",
    "title": "CP-KGC: Constrained-Prompt Knowledge Graph Completion with Large  Language Models",
    "abstract": "Knowledge graph completion (KGC) aims to utilize existing knowledge to deduce and infer missing connections within knowledge graphs. Text-based approaches, like SimKGC, have outperformed graph embedding methods, showcasing the promise of inductive KGC. However, the efficacy of text-based methods hinges on the quality of entity textual descriptions. In this paper, we identify the key issue of whether large language models (LLMs) can generate effective text. To mitigate hallucination in LLM-generated text in this paper, we introduce a constraint-based prompt that utilizes the entity and its textual description as contextual constraints to enhance data quality. Our Constrained-Prompt Knowledge Graph Completion (CP-KGC) method demonstrates effective inference under low resource computing conditions and surpasses prior results on the WN18RR and FB15K237 datasets. This showcases the integration of LLMs in KGC tasks and provides new directions for future research. ",
    "url": "https://arxiv.org/abs/2310.08279",
    "authors": [
      "Rui Yang",
      "Li Fang",
      "Yi Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.08298",
    "title": "MProto: Multi-Prototype Network with Denoised Optimal Transport for  Distantly Supervised Named Entity Recognition",
    "abstract": "Distantly supervised named entity recognition (DS-NER) aims to locate entity mentions and classify their types with only knowledge bases or gazetteers and unlabeled corpus. However, distant annotations are noisy and degrade the performance of NER models. In this paper, we propose a noise-robust prototype network named MProto for the DS-NER task. Different from previous prototype-based NER methods, MProto represents each entity type with multiple prototypes to characterize the intra-class variance among entity representations. To optimize the classifier, each token should be assigned an appropriate ground-truth prototype and we consider such token-prototype assignment as an optimal transport (OT) problem. Furthermore, to mitigate the noise from incomplete labeling, we propose a novel denoised optimal transport (DOT) algorithm. Specifically, we utilize the assignment result between Other class tokens and all prototypes to distinguish unlabeled entity tokens from true negatives. Experiments on several DS-NER benchmarks demonstrate that our MProto achieves state-of-the-art performance. The source code is now available on Github. ",
    "url": "https://arxiv.org/abs/2310.08298",
    "authors": [
      "Shuhui Wu",
      "Yongliang Shen",
      "Zeqi Tan",
      "Wenqi Ren",
      "Jietian Guo",
      "Shiliang Pu",
      "Weiming Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.08320",
    "title": "Defending Our Privacy With Backdoors",
    "abstract": "The proliferation of large AI models trained on uncurated, often sensitive web-scraped data has raised significant privacy concerns. One of the concerns is that adversaries can extract information about the training data using privacy attacks. Unfortunately, the task of removing specific information from the models without sacrificing performance is not straightforward and has proven to be challenging. We propose a rather easy yet effective defense based on backdoor attacks to remove private information such as names of individuals from models, and focus in this work on text encoders. Specifically, through strategic insertion of backdoors, we align the embeddings of sensitive phrases with those of neutral terms-\"a person\" instead of the person's name. Our empirical results demonstrate the effectiveness of our backdoor-based defense on CLIP by assessing its performance using a specialized privacy attack for zero-shot classifiers. Our approach provides not only a new \"dual-use\" perspective on backdoor attacks, but also presents a promising avenue to enhance the privacy of individuals within models trained on uncurated web-scraped data. ",
    "url": "https://arxiv.org/abs/2310.08320",
    "authors": [
      "Dominik Hintersdorf",
      "Lukas Struppek",
      "Daniel Neider",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.08326",
    "title": "NSM4D: Neural Scene Model Based Online 4D Point Cloud Sequence  Understanding",
    "abstract": "Understanding 4D point cloud sequences online is of significant practical value in various scenarios such as VR/AR, robotics, and autonomous driving. The key goal is to continuously analyze the geometry and dynamics of a 3D scene as unstructured and redundant point cloud sequences arrive. And the main challenge is to effectively model the long-term history while keeping computational costs manageable. To tackle these challenges, we introduce a generic online 4D perception paradigm called NSM4D. NSM4D serves as a plug-and-play strategy that can be adapted to existing 4D backbones, significantly enhancing their online perception capabilities for both indoor and outdoor scenarios. To efficiently capture the redundant 4D history, we propose a neural scene model that factorizes geometry and motion information by constructing geometry tokens separately storing geometry and motion features. Exploiting the history becomes as straightforward as querying the neural scene model. As the sequence progresses, the neural scene model dynamically deforms to align with new observations, effectively providing the historical context and updating itself with the new observations. By employing token representation, NSM4D also exhibits robustness to low-level sensor noise and maintains a compact size through a geometric sampling scheme. We integrate NSM4D with state-of-the-art 4D perception backbones, demonstrating significant improvements on various online perception benchmarks in indoor and outdoor settings. Notably, we achieve a 9.6% accuracy improvement for HOI4D online action segmentation and a 3.4% mIoU improvement for SemanticKITTI online semantic segmentation. Furthermore, we show that NSM4D inherently offers excellent scalability to longer sequences beyond the training set, which is crucial for real-world applications. ",
    "url": "https://arxiv.org/abs/2310.08326",
    "authors": [
      "Yuhao Dong",
      "Zhuoyang Zhang",
      "Yunze Liu",
      "Li Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.08328",
    "title": "Transport-Hub-Aware Spatial-Temporal Adaptive Graph Transformer for  Traffic Flow Prediction",
    "abstract": "As a core technology of Intelligent Transportation System (ITS), traffic flow prediction has a wide range of applications. Traffic flow data are spatial-temporal, which are not only correlated to spatial locations in road networks, but also vary with temporal time indices. Existing methods have solved the challenges in traffic flow prediction partly, focusing on modeling spatial-temporal dependencies effectively, while not all intrinsic properties of traffic flow data are utilized fully. Besides, there are very few attempts at incremental learning of spatial-temporal data mining, and few previous works can be easily transferred to the traffic flow prediction task. Motivated by the challenge of incremental learning methods for traffic flow prediction and the underutilization of intrinsic properties of road networks, we propose a Transport-Hub-aware Spatial-Temporal adaptive graph transFormer (H-STFormer) for traffic flow prediction. Specifically, we first design a novel spatial self-attention module to capture the dynamic spatial dependencies. Three graph masking matrices are integrated into spatial self-attentions to highlight both short- and long-term dependences. Additionally, we employ a temporal self-attention module to detect dynamic temporal patterns in the traffic flow data. Finally, we design an extra spatial-temporal knowledge distillation module for incremental learning of traffic flow prediction tasks. Through extensive experiments, we show the effectiveness of H-STFormer in normal and incremental traffic flow prediction tasks. The code is available at https://github.com/Fantasy-Shaw/H-STFormer. ",
    "url": "https://arxiv.org/abs/2310.08328",
    "authors": [
      "Xiao Xu",
      "Lei Zhang",
      "Bailong Liu",
      "Zhizhen Liang",
      "Xuefei Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.08332",
    "title": "Real-Time Neural BRDF with Spherically Distributed Primitives",
    "abstract": "We propose a novel compact and efficient neural BRDF offering highly versatile material representation, yet with very-light memory and neural computation consumption towards achieving real-time rendering. The results in Figure 1, rendered at full HD resolution on a current desktop machine, show that our system achieves real-time rendering with a wide variety of appearances, which is approached by the following two designs. On the one hand, noting that bidirectional reflectance is distributed in a very sparse high-dimensional subspace, we propose to project the BRDF into two low-dimensional components, i.e., two hemisphere feature-grids for incoming and outgoing directions, respectively. On the other hand, learnable neural reflectance primitives are distributed on our highly-tailored spherical surface grid, which offer informative features for each component and alleviate the conventional heavy feature learning network to a much smaller one, leading to very fast evaluation. These primitives are centrally stored in a codebook and can be shared across multiple grids and even across materials, based on the low-cost indices stored in material-specific spherical surface grids. Our neural BRDF, which is agnostic to the material, provides a unified framework that can represent a variety of materials in consistent manner. Comprehensive experimental results on measured BRDF compression, Monte Carlo simulated BRDF acceleration, and extension to spatially varying effect demonstrate the superior quality and generalizability achieved by the proposed scheme. ",
    "url": "https://arxiv.org/abs/2310.08332",
    "authors": [
      "Yishun Dou",
      "Zhong Zheng",
      "Qiaoqiao Jin",
      "Bingbing Ni",
      "Yugang Chen",
      "Junxiang Ke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.08335",
    "title": "2SFGL: A Simple And Robust Protocol For Graph-Based Fraud Detection",
    "abstract": "Financial crime detection using graph learning improves financial safety and efficiency. However, criminals may commit financial crimes across different institutions to avoid detection, which increases the difficulty of detection for financial institutions which use local data for graph learning. As most financial institutions are subject to strict regulations in regards to data privacy protection, the training data is often isolated and conventional learning technology cannot handle the problem. Federated learning (FL) allows multiple institutions to train a model without revealing their datasets to each other, hence ensuring data privacy protection. In this paper, we proposes a novel two-stage approach to federated graph learning (2SFGL): The first stage of 2SFGL involves the virtual fusion of multiparty graphs, and the second involves model training and inference on the virtual graph. We evaluate our framework on a conventional fraud detection task based on the FraudAmazonDataset and FraudYelpDataset. Experimental results show that integrating and applying a GCN (Graph Convolutional Network) with our 2SFGL framework to the same task results in a 17.6\\%-30.2\\% increase in performance on several typical metrics compared to the case only using FedAvg, while integrating GraphSAGE with 2SFGL results in a 6\\%-16.2\\% increase in performance compared to the case only using FedAvg. We conclude that our proposed framework is a robust and simple protocol which can be simply integrated to pre-existing graph-based fraud detection methods. ",
    "url": "https://arxiv.org/abs/2310.08335",
    "authors": [
      "Zhirui Pan",
      "Guangzhong Wang",
      "Zhaoning Li",
      "Lifeng Chen",
      "Yang Bian",
      "Zhongyuan Lai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.08337",
    "title": "Neural Diffusion Models",
    "abstract": "Diffusion models have shown remarkable performance on many generative tasks. Despite recent success, most diffusion models are restricted in that they only allow linear transformation of the data distribution. In contrast, broader family of transformations can potentially help train generative distributions more efficiently, simplifying the reverse process and closing the gap between the true negative log-likelihood and the variational approximation. In this paper, we present Neural Diffusion Models (NDMs), a generalization of conventional diffusion models that enables defining and learning time-dependent non-linear transformations of data. We show how to optimise NDMs using a variational bound in a simulation-free setting. Moreover, we derive a time-continuous formulation of NDMs, which allows fast and reliable inference using off-the-shelf numerical ODE and SDE solvers. Finally, we demonstrate the utility of NDMs with learnable transformations through experiments on standard image generation benchmarks, including CIFAR-10, downsampled versions of ImageNet and CelebA-HQ. NDMs outperform conventional diffusion models in terms of likelihood and produce high-quality samples. ",
    "url": "https://arxiv.org/abs/2310.08337",
    "authors": [
      "Grigory Bartosh",
      "Dmitry Vetrov",
      "Christian A. Naesseth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.08358",
    "title": "Towards Demystifying the Generalization Behaviors When Neural Collapse  Emerges",
    "abstract": "Neural Collapse (NC) is a well-known phenomenon of deep neural networks in the terminal phase of training (TPT). It is characterized by the collapse of features and classifier into a symmetrical structure, known as simplex equiangular tight frame (ETF). While there have been extensive studies on optimization characteristics showing the global optimality of neural collapse, little research has been done on the generalization behaviors during the occurrence of NC. Particularly, the important phenomenon of generalization improvement during TPT has been remaining in an empirical observation and lacking rigorous theoretical explanation. In this paper, we establish the connection between the minimization of CE and a multi-class SVM during TPT, and then derive a multi-class margin generalization bound, which provides a theoretical explanation for why continuing training can still lead to accuracy improvement on test set, even after the train accuracy has reached 100%. Additionally, our further theoretical results indicate that different alignment between labels and features in a simplex ETF can result in varying degrees of generalization improvement, despite all models reaching NC and demonstrating similar optimization performance on train set. We refer to this newly discovered property as \"non-conservative generalization\". In experiments, we also provide empirical observations to verify the indications suggested by our theoretical results. ",
    "url": "https://arxiv.org/abs/2310.08358",
    "authors": [
      "Peifeng Gao",
      "Qianqian Xu",
      "Yibo Yang",
      "Peisong Wen",
      "Huiyang Shao",
      "Zhiyong Yang",
      "Bernard Ghanem",
      "Qingming Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.08362",
    "title": "Multi-Value Alignment in Normative Multi-Agent System: An Evolutionary  Optimisation Approach",
    "abstract": "Value-alignment in normative multi-agent systems is used to promote a certain value and to ensure the consistent behaviour of agents in autonomous intelligent systems with human values. However, the current literature is limited to the incorporation of effective norms for single-value alignment with no consideration of agents' heterogeneity and the requirement of simultaneous promotion and alignment of multiple values. This research proposes a multi-value promotion model that uses multi-objective evolutionary algorithms and decentralised reasoning to produce the optimum parametric set of norms that is aligned with multiple simultaneous values of heterogeneous agents and the system. To understand various aspects of this complex problem, several evolutionary algorithms were used to find a set of optimised norm parameters considering two toy tax scenarios with two and five values are considered. The results are analysed from different perspectives to show the impact of a selected evolutionary algorithm on the solution, and the importance of understanding the relation between values when prioritising them. ",
    "url": "https://arxiv.org/abs/2310.08362",
    "authors": [
      "Maha Riad",
      "Vinicius de Carvalho",
      "Fatemeh Golpayegani"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2310.08364",
    "title": "Map2Schedule: An End-to-End Link Scheduling Method for Urban V2V  Communications",
    "abstract": "Urban vehicle-to-vehicle (V2V) link scheduling with shared spectrum is a challenging problem. Its main goal is to find the scheduling policy that can maximize system performance (usually the sum capacity of each link or their energy efficiency). Given that each link can experience interference from all other active links, the scheduling becomes a combinatorial integer programming problem and generally does not scale well with the number of V2V pairs. Moreover, link scheduling requires accurate channel state information (CSI), which is very difficult to estimate with good accuracy under high vehicle mobility. In this paper, we propose an end-to-end urban V2V link scheduling method called Map2Schedule, which can directly generate V2V scheduling policy from the city map and vehicle locations. Map2Schedule delivers comparable performance to the physical-model-based methods in urban settings while maintaining low computation complexity. This enhanced performance is achieved by machine learning (ML) technologies. Specifically, we first deploy the convolutional neural network (CNN) model to estimate the CSI from street layout and vehicle locations and then apply the graph embedding model for optimal scheduling policy. The results show that the proposed method can achieve high accuracy with much lower overhead and latency. ",
    "url": "https://arxiv.org/abs/2310.08364",
    "authors": [
      "Lihao Zhang",
      "Haijian Sun",
      "Jin Sun",
      "Ramviyas Parasuraman",
      "Yinghui Ye",
      "Rose Qingyang Hu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.08365",
    "title": "From Large Language Models to Knowledge Graphs for Biomarker Discovery  in Cancer",
    "abstract": "Domain experts often rely on up-to-date knowledge for apprehending and disseminating specific biological processes that help them design strategies to develop prevention and therapeutic decision-making. A challenging scenario for artificial intelligence (AI) is using biomedical data (e.g., texts, imaging, omics, and clinical) to provide diagnosis and treatment recommendations for cancerous conditions. Data and knowledge about cancer, drugs, genes, proteins, and their mechanism is spread across structured (knowledge bases (KBs)) and unstructured (e.g., scientific articles) sources. A large-scale knowledge graph (KG) can be constructed by integrating these data, followed by extracting facts about semantically interrelated entities and relations. Such KGs not only allow exploration and question answering (QA) but also allow domain experts to deduce new knowledge. However, exploring and querying large-scale KGs is tedious for non-domain users due to a lack of understanding of the underlying data assets and semantic technologies. In this paper, we develop a domain KG to leverage cancer-specific biomarker discovery and interactive QA. For this, a domain ontology called OncoNet Ontology (ONO) is developed to enable semantic reasoning for validating gene-disease relations. The KG is then enriched by harmonizing the ONO, controlled vocabularies, and additional biomedical concepts from scientific articles by employing BioBERT- and SciBERT-based information extraction (IE) methods. Further, since the biomedical domain is evolving, where new findings often replace old ones, without employing up-to-date findings, there is a high chance an AI system exhibits concept drift while providing diagnosis and treatment. Therefore, we finetuned the KG using large language models (LLMs) based on more recent articles and KBs that might not have been seen by the named entity recognition models. ",
    "url": "https://arxiv.org/abs/2310.08365",
    "authors": [
      "Md. Rezaul Karim",
      "Lina Molinas Comet",
      "Md Shajalal",
      "Oya Beyan",
      "Dietrich Rebholz-Schuhmann",
      "Stefan Decker"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.08373",
    "title": "Chrono: A Peer-to-Peer Network with Verifiable Causality",
    "abstract": "Logical clocks are a fundamental tool to establish causal ordering of events in a distributed system. They have been used as the building block in weakly consistent storage systems, causally ordered broadcast, distributed snapshots, deadlock detection, and distributed system debugging. However, prior logical clock constructs fail to work in a permissionless setting with Byzantine participants. In this work, we introduce Chrono, a novel logical clock system that targets an open and decentralized network. Chrono introduces a new logical clock construct, the Decaying Onion Bloom Clock (DOBC), that scales independently to the size of the network. To tolerate Byzantine behaviors, Chrono leverages non-uniform incrementally verifiable computation (IVC) to efficiently prove and verify the construction of DOBC clocks. We have applied Chrono to build two decentralized applications, a weakly consistent key-value store and an anti-censorship social network, demonstrating the power of scalable, verifiable causality in a decentralized network. ",
    "url": "https://arxiv.org/abs/2310.08373",
    "authors": [
      "Michael Hu Yiqing",
      "Guangda Sun",
      "Arun Fu",
      "Akasha Zhu",
      "Jialin Li"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.08384",
    "title": "Towards Running Time Analysis of Interactive Multi-objective  Evolutionary Algorithms",
    "abstract": "Evolutionary algorithms (EAs) are widely used for multi-objective optimization due to their population-based nature. Traditional multi-objective EAs (MOEAs) generate a large set of solutions to approximate the Pareto front, leaving a decision maker (DM) with the task of selecting a preferred solution. However, this process can be inefficient and time-consuming, especially when there are many objectives or the subjective preferences of DM is known. To address this issue, interactive MOEAs (iMOEAs) combine decision making into the optimization process, i.e., update the population with the help of the DM. In contrast to their wide applications, there has existed only two pieces of theoretical works on iMOEAs, which only considered interactive variants of the two simple single-objective algorithms, RLS and (1+1)-EA. This paper provides the first running time analysis (the essential theoretical aspect of EAs) for practical iMOEAs. Specifically, we prove that the expected running time of the well-developed interactive NSGA-II (called R-NSGA-II) for solving the OneMinMax and OneJumpZeroJump problems is $O(n \\log n)$ and $O(n^k)$, respectively, which are all asymptotically faster than the traditional NSGA-II. Meanwhile, we present a variant of OneMinMax, and prove that R-NSGA-II can be exponentially slower than NSGA-II. These results provide theoretical justification for the effectiveness of iMOEAs while identifying situations where they may fail. Experiments are also conducted to validate the theoretical results. ",
    "url": "https://arxiv.org/abs/2310.08384",
    "authors": [
      "Tianhao Lu",
      "Chao Bian",
      "Chao Qian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.08387",
    "title": "MeanAP-Guided Reinforced Active Learning for Object Detection",
    "abstract": "Active learning presents a promising avenue for training high-performance models with minimal labeled data, achieved by judiciously selecting the most informative instances to label and incorporating them into the task learner. Despite notable advancements in active learning for image recognition, metrics devised or learned to gauge the information gain of data, crucial for query strategy design, do not consistently align with task model performance metrics, such as Mean Average Precision (MeanAP) in object detection tasks. This paper introduces MeanAP-Guided Reinforced Active Learning for Object Detection (MAGRAL), a novel approach that directly utilizes the MeanAP metric of the task model to devise a sampling strategy employing a reinforcement learning-based sampling agent. Built upon LSTM architecture, the agent efficiently explores and selects subsequent training instances, and optimizes the process through policy gradient with MeanAP serving as reward. Recognizing the time-intensive nature of MeanAP computation at each step, we propose fast look-up tables to expedite agent training. We assess MAGRAL's efficacy across popular benchmarks, PASCAL VOC and MS COCO, utilizing different backbone architectures. Empirical findings substantiate MAGRAL's superiority over recent state-of-the-art methods, showcasing substantial performance gains. MAGRAL establishes a robust baseline for reinforced active object detection, signifying its potential in advancing the field. ",
    "url": "https://arxiv.org/abs/2310.08387",
    "authors": [
      "Zhixuan Liang",
      "Xingyu Zeng",
      "Rui Zhao",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.08392",
    "title": "Introducing a Deep Neural Network-based Model Predictive Control  Framework for Rapid Controller Implementation",
    "abstract": "Model Predictive Control (MPC) provides an optimal control solution based on a cost function while allowing for the implementation of process constraints. As a model-based optimal control technique, the performance of MPC strongly depends on the model used where a trade-off between model computation time and prediction performance exists. One solution is the integration of MPC with a machine learning (ML) based process model which are quick to evaluate online. This work presents the experimental implementation of a deep neural network (DNN) based nonlinear MPC for Homogeneous Charge Compression Ignition (HCCI) combustion control. The DNN model consists of a Long Short-Term Memory (LSTM) network surrounded by fully connected layers which was trained using experimental engine data and showed acceptable prediction performance with under 5% error for all outputs. Using this model, the MPC is designed to track the Indicated Mean Effective Pressure (IMEP) and combustion phasing trajectories, while minimizing several parameters. Using the acados software package to enable the real-time implementation of the MPC on an ARM Cortex A72, the optimization calculations are completed within 1.4 ms. The external A72 processor is integrated with the prototyping engine controller using a UDP connection allowing for rapid experimental deployment of the NMPC. The IMEP trajectory following of the developed controller was excellent, with a root-mean-square error of 0.133 bar, in addition to observing process constraints. ",
    "url": "https://arxiv.org/abs/2310.08392",
    "authors": [
      "David C. Gordon",
      "Alexander Winkler",
      "Julian Bedei",
      "Patrick Schaber",
      "Jakob Andert",
      "Charles R. Koch"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.08396",
    "title": "Uncertainty-Aware Planning for Heterogeneous Robot Teams using Dynamic  Topological Graphs and Mixed-Integer Programming",
    "abstract": "Planning under uncertainty is a fundamental challenge in robotics. For multi-robot teams, the challenge is further exacerbated, since the planning problem can quickly become computationally intractable as the number of robots increase. In this paper, we propose a novel approach for planning under uncertainty using heterogeneous multi-robot teams. In particular, we leverage the notion of a dynamic topological graph and mixed-integer programming to generate multi-robot plans that deploy fast scout team members to reduce uncertainty about the environment. We test our approach in a number of representative scenarios where the robot team must move through an environment while minimizing detection in the presence of uncertain observer positions. We demonstrate that our approach is sufficiently computationally tractable for real-time re-planning in changing environments, can improve performance in the presence of imperfect information, and can be adjusted to accommodate different risk profiles. ",
    "url": "https://arxiv.org/abs/2310.08396",
    "authors": [
      "Cora A. Dimmig",
      "Kevin C. Wolfe",
      "Marin Kobilarov",
      "Joseph Moore"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.08413",
    "title": "Control-Based Planning over Probability Mass Function Measurements via  Robust Linear Programming",
    "abstract": "We propose an approach to synthesize linear feedback controllers for linear systems in polygonal environments. Our method focuses on designing a robust controller that can account for uncertainty in measurements. Its inputs are provided by a perception module that generates probability mass functions (PMFs) for predefined landmarks in the environment, such as distinguishable geometric features. We formulate an optimization problem with Control Lyapunov Function (CLF) and Control Barrier Function (CBF) constraints to derive a stable and safe controller. Using the strong duality of linear programs (LPs) and robust optimization, we convert the optimization problem to a linear program that can be efficiently solved offline. At a high level, our approach partially combines perception, planning, and real-time control into a single design problem. An additional advantage of our method is the ability to produce controllers capable of exhibiting nonlinear behavior while relying solely on an offline LP for control synthesis. ",
    "url": "https://arxiv.org/abs/2310.08413",
    "authors": [
      "Mehdi Kermanshah",
      "Calin Belta",
      "Roberto Tron"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.08420",
    "title": "Visual Attention-Prompted Prediction and Learning",
    "abstract": "Explanation(attention)-guided learning is a method that enhances a model's predictive power by incorporating human understanding during the training phase. While attention-guided learning has shown promising results, it often involves time-consuming and computationally expensive model retraining. To address this issue, we introduce the attention-prompted prediction technique, which enables direct prediction guided by the attention prompt without the need for model retraining. However, this approach presents several challenges, including: 1) How to incorporate the visual attention prompt into the model's decision-making process and leverage it for future predictions even in the absence of a prompt? and 2) How to handle the incomplete information from the visual attention prompt? To tackle these challenges, we propose a novel framework called Visual Attention-Prompted Prediction and Learning, which seamlessly integrates visual attention prompts into the model's decision-making process and adapts to images both with and without attention prompts for prediction. To address the incomplete information of the visual attention prompt, we introduce a perturbation-based attention map modification method. Additionally, we propose an optimization-based mask aggregation method with a new weight learning function for adaptive perturbed annotation aggregation in the attention map modification process. Our overall framework is designed to learn in an attention-prompt guided multi-task manner to enhance future predictions even for samples without attention prompts and trained in an alternating manner for better convergence. Extensive experiments conducted on two datasets demonstrate the effectiveness of our proposed framework in enhancing predictions for samples, both with and without provided prompts. ",
    "url": "https://arxiv.org/abs/2310.08420",
    "authors": [
      "Yifei Zhang",
      "Siyi Gu",
      "Bo Pan",
      "Guangji Bai",
      "Xiaofeng Yang",
      "Liang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.08421",
    "title": "\"SegLoc\": Study on Novel Visual Self-supervised Learning Scheme (Segment  Localization) Tailored for Dense Prediction Tasks of Security Inspection  X-ray Images",
    "abstract": "Lately, remarkable advancements of artificial intelligence have been attributed to the integration of self-supervised learning scheme. Despite impressive achievements within NLP, yet SSL in computer vision has not been able to stay on track comparatively. Recently, integration of contrastive learning on top of existing SSL models has established considerable progress in computer vision through which visual SSL models have outperformed their supervised counterparts. Nevertheless, most of these improvements were limited to classification tasks, and also, few works have been dedicated to evaluation of SSL models in real-world scenarios of computer vision, while the majority of works are centered around datasets containing class-wise portrait images, most notably, ImageNet. Consequently, in this work, we have considered dense prediction task of semantic segmentation in security inspection x-ray images to evaluate our proposed model Segmentation Localization. Based upon the model Instance Localization, our model SegLoc has managed to address one of the most challenging downsides of contrastive learning, i.e., false negative pairs of query embeddings. In order to do so, in contrast to baseline model InsLoc, our pretraining dataset is synthesized by cropping, transforming, then pasting already labeled segments from an available labeled dataset, foregrounds, onto instances of an unlabeled dataset, backgrounds. In our case, PIDray and SIXray datasets are considered as labeled and unlabeled datasets, respectively. Moreover, we fully harness labels by avoiding false negative pairs through implementing the idea, one queue per class, in MoCo-v2 whereby negative pairs corresponding to each query are extracted from its corresponding queue within the memory bank. Our approach has outperformed random initialization by 3% to 6%, while having underperformed supervised initialization. ",
    "url": "https://arxiv.org/abs/2310.08421",
    "authors": [
      "Shervin Halat",
      "Mohammad Rahmati",
      "Ehsan Nazerfard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.08425",
    "title": "Differentially Private Non-convex Learning for Multi-layer Neural  Networks",
    "abstract": "This paper focuses on the problem of Differentially Private Stochastic Optimization for (multi-layer) fully connected neural networks with a single output node. In the first part, we examine cases with no hidden nodes, specifically focusing on Generalized Linear Models (GLMs). We investigate the well-specific model where the random noise possesses a zero mean, and the link function is both bounded and Lipschitz continuous. We propose several algorithms and our analysis demonstrates the feasibility of achieving an excess population risk that remains invariant to the data dimension. We also delve into the scenario involving the ReLU link function, and our findings mirror those of the bounded link function. We conclude this section by contrasting well-specified and misspecified models, using ReLU regression as a representative example. In the second part of the paper, we extend our ideas to two-layer neural networks with sigmoid or ReLU activation functions in the well-specified model. In the third part, we study the theoretical guarantees of DP-SGD in Abadi et al. (2016) for fully connected multi-layer neural networks. By utilizing recent advances in Neural Tangent Kernel theory, we provide the first excess population risk when both the sample size and the width of the network are sufficiently large. Additionally, we discuss the role of some parameters in DP-SGD regarding their utility, both theoretically and empirically. ",
    "url": "https://arxiv.org/abs/2310.08425",
    "authors": [
      "Hanpu Shen",
      "Cheng-Long Wang",
      "Zihang Xiang",
      "Yiming Ying",
      "Di Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.08429",
    "title": "Revisiting Data Augmentation for Rotational Invariance in Convolutional  Neural Networks",
    "abstract": "Convolutional Neural Networks (CNN) offer state of the art performance in various computer vision tasks. Many of those tasks require different subtypes of affine invariances (scale, rotational, translational) to image transformations. Convolutional layers are translation equivariant by design, but in their basic form lack invariances. In this work we investigate how best to include rotational invariance in a CNN for image classification. Our experiments show that networks trained with data augmentation alone can classify rotated images nearly as well as in the normal unrotated case; this increase in representational power comes only at the cost of training time. We also compare data augmentation versus two modified CNN models for achieving rotational invariance or equivariance, Spatial Transformer Networks and Group Equivariant CNNs, finding no significant accuracy increase with these specialized methods. In the case of data augmented networks, we also analyze which layers help the network to encode the rotational invariance, which is important for understanding its limitations and how to best retrain a network with data augmentation to achieve invariance to rotation. ",
    "url": "https://arxiv.org/abs/2310.08429",
    "authors": [
      "Facundo Manuel Quiroga",
      "Franco Ronchetti",
      "Laura Lanzarini",
      "Aurelio Fernandez-Bariviera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.08431",
    "title": "Neural Sampling in Hierarchical Exponential-family Energy-based Models",
    "abstract": "Bayesian brain theory suggests that the brain employs generative models to understand the external world. The sampling-based perspective posits that the brain infers the posterior distribution through samples of stochastic neuronal responses. Additionally, the brain continually updates its generative model to approach the true distribution of the external world. In this study, we introduce the Hierarchical Exponential-family Energy-based (HEE) model, which captures the dynamics of inference and learning. In the HEE model, we decompose the partition function into individual layers and leverage a group of neurons with shorter time constants to sample the gradient of the decomposed normalization term. This allows our model to estimate the partition function and perform inference simultaneously, circumventing the negative phase encountered in conventional energy-based models (EBMs). As a result, the learning process is localized both in time and space, and the model is easy to converge. To match the brain's rapid computation, we demonstrate that neural adaptation can serve as a momentum term, significantly accelerating the inference process. On natural image datasets, our model exhibits representations akin to those observed in the biological visual system. Furthermore, for the machine learning community, our model can generate observations through joint or marginal generation. We show that marginal generation outperforms joint generation and achieves performance on par with other EBMs. ",
    "url": "https://arxiv.org/abs/2310.08431",
    "authors": [
      "Xingsi Dong",
      "Si Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2310.08446",
    "title": "Towards Robust Multi-Modal Reasoning via Model Selection",
    "abstract": "The reasoning capabilities of LLM (Large Language Model) are widely acknowledged in recent research, inspiring studies on tool learning and autonomous agents. LLM serves as the \"brain\" of agent, orchestrating multiple tools for collaborative multi-step task solving. Unlike methods invoking tools like calculators or weather APIs for straightforward tasks, multi-modal agents excel by integrating diverse AI models for complex challenges. However, current multi-modal agents neglect the significance of model selection: they primarily focus on the planning and execution phases, and will only invoke predefined task-specific models for each subtask, making the execution fragile. Meanwhile, other traditional model selection methods are either incompatible with or suboptimal for the multi-modal agent scenarios, due to ignorance of dependencies among subtasks arising by multi-step reasoning. To this end, we identify the key challenges therein and propose the $\\textit{M}^3$ framework as a plug-in with negligible runtime overhead at test-time. This framework improves model selection and bolsters the robustness of multi-modal agents in multi-step reasoning. In the absence of suitable benchmarks, we create MS-GQA, a new dataset specifically designed to investigate the model selection challenge in multi-modal agents. Our experiments reveal that our framework enables dynamic model selection, considering both user inputs and subtask dependencies, thereby robustifying the overall reasoning process. Our code and benchmark: https://github.com/LINs-lab/M3. ",
    "url": "https://arxiv.org/abs/2310.08446",
    "authors": [
      "Xiangyan Liu",
      "Rongxue Li",
      "Wei Ji",
      "Tao Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.08459",
    "title": "A Survey on Heterogeneous Transfer Learning",
    "abstract": "The application of transfer learning, an approach utilizing knowledge from a source domain to enhance model performance in a target domain, has seen a tremendous rise in recent years, underpinning many real-world scenarios. The key to its success lies in the shared common knowledge between the domains, a prerequisite in most transfer learning methodologies. These methods typically presuppose identical feature spaces and label spaces in both domains, known as homogeneous transfer learning, which, however, is not always a practical assumption. Oftentimes, the source and target domains vary in feature spaces, data distributions, and label spaces, making it challenging or costly to secure source domain data with identical feature and label spaces as the target domain. Arbitrary elimination of these differences is not always feasible or optimal. Thus, heterogeneous transfer learning, acknowledging and dealing with such disparities, has emerged as a promising approach for a variety of tasks. Despite the existence of a survey in 2017 on this topic, the fast-paced advances post-2017 necessitate an updated, in-depth review. We therefore present a comprehensive survey of recent developments in heterogeneous transfer learning methods, offering a systematic guide for future research. Our paper reviews methodologies for diverse learning scenarios, discusses the limitations of current studies, and covers various application contexts, including Natural Language Processing, Computer Vision, Multimodality, and Biomedicine, to foster a deeper understanding and spur future research. ",
    "url": "https://arxiv.org/abs/2310.08459",
    "authors": [
      "Runxue Bao",
      "Yiming Sun",
      "Yuhe Gao",
      "Jindong Wang",
      "Qiang Yang",
      "Haifeng Chen",
      "Zhi-Hong Mao",
      "Xing Xie",
      "Ye Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.08488",
    "title": "Community Consensus: Converging Locally despite Adversaries and  Heterogeneous Connectivity",
    "abstract": "We introduce the concept of community consensus in the presence of malicious agents using a well-known median-based consensus algorithm. We consider networks that have multiple well-connected regions that we term communities, characterized by specific robustness and minimum degree properties. Prior work derives conditions on properties that are necessary and sufficient for achieving global consensus in a network. This however, requires the minimum degree of the network graph to be proportional to the number of malicious agents in the network, which is not very practical in large networks. In this work we present a natural generalization of this previous result. We characterize cases when although global consensus is not reached, some subsets of agents $V_i$ will still converge to the same values $\\mathcal{M}_i$ among themselves. We define more relaxed requirements for this new type of consensus to be reached in terms of the number $k$ of edges connecting an agent in a community to agents external to the community, and the number of malicious agents in each community. ",
    "url": "https://arxiv.org/abs/2310.08488",
    "authors": [
      "Cristina Gava",
      "Aron Vekassy",
      "Matthew Cavorsi",
      "Stephanie Gil",
      "Frederik Mallmann-Trenn"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2310.08513",
    "title": "How connectivity structure shapes rich and lazy learning in neural  circuits",
    "abstract": "In theoretical neuroscience, recent work leverages deep learning tools to explore how some network attributes critically influence its learning dynamics. Notably, initial weight distributions with small (resp. large) variance may yield a rich (resp. lazy) regime, where significant (resp. minor) changes to network states and representation are observed over the course of learning. However, in biology, neural circuit connectivity generally has a low-rank structure and therefore differs markedly from the random initializations generally used for these studies. As such, here we investigate how the structure of the initial weights, in particular their effective rank, influences the network learning regime. Through both empirical and theoretical analyses, we discover that high-rank initializations typically yield smaller network changes indicative of lazier learning, a finding we also confirm with experimentally-driven initial connectivity in recurrent neural networks. Conversely, low-rank initialization biases learning towards richer learning. Importantly, however, as an exception to this rule, we find lazier learning can still occur with a low-rank initialization that aligns with task and data statistics. Our research highlights the pivotal role of initial weight structures in shaping learning regimes, with implications for metabolic costs of plasticity and risks of catastrophic forgetting. ",
    "url": "https://arxiv.org/abs/2310.08513",
    "authors": [
      "Yuhan Helena Liu",
      "Aristide Baratin",
      "Jonathan Cornford",
      "Stefan Mihalas",
      "Eric Shea-Brown",
      "Guillaume Lajoie"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2310.08543",
    "title": "NetDiffusion: Network Data Augmentation Through Protocol-Constrained  Traffic Generation",
    "abstract": "Datasets of labeled network traces are essential for a multitude of machine learning (ML) tasks in networking, yet their availability is hindered by privacy and maintenance concerns, such as data staleness. To overcome this limitation, synthetic network traces can often augment existing datasets. Unfortunately, current synthetic trace generation methods, which typically produce only aggregated flow statistics or a few selected packet attributes, do not always suffice, especially when model training relies on having features that are only available from packet traces. This shortfall manifests in both insufficient statistical resemblance to real traces and suboptimal performance on ML tasks when employed for data augmentation. In this paper, we apply diffusion models to generate high-resolution synthetic network traffic traces. We present NetDiffusion, a tool that uses a finely-tuned, controlled variant of a Stable Diffusion model to generate synthetic network traffic that is high fidelity and conforms to protocol specifications. Our evaluation demonstrates that packet captures generated from NetDiffusion can achieve higher statistical similarity to real data and improved ML model performance than current state-of-the-art approaches (e.g., GAN-based approaches). Furthermore, our synthetic traces are compatible with common network analysis tools and support a myriad of network tasks, suggesting that NetDiffusion can serve a broader spectrum of network analysis and testing tasks, extending beyond ML-centric applications. ",
    "url": "https://arxiv.org/abs/2310.08543",
    "authors": [
      "Xi Jiang",
      "Shinan Liu",
      "Aaron Gember-Jacobson",
      "Arjun Nitin Bhagoji",
      "Paul Schmitt",
      "Francesco Bronzino",
      "Nick Feamster"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.06960",
    "title": "Jaynes Machine: The universal microstructure of deep neural networks",
    "abstract": "We present a novel theory of the microstructure of deep neural networks. Using a theoretical framework called statistical teleodynamics, which is a conceptual synthesis of statistical thermodynamics and potential game theory, we predict that all highly connected layers of deep neural networks have a universal microstructure of connection strengths that is distributed lognormally ($LN({\\mu}, {\\sigma})$). Furthermore, under ideal conditions, the theory predicts that ${\\mu}$ and ${\\sigma}$ are the same for all layers in all networks. This is shown to be the result of an arbitrage equilibrium where all connections compete and contribute the same effective utility towards the minimization of the overall loss function. These surprising predictions are shown to be supported by empirical data from six large-scale deep neural networks in real life. We also discuss how these results can be exploited to reduce the amount of data, time, and computational resources needed to train large deep neural networks. ",
    "url": "https://arxiv.org/abs/2310.06960",
    "authors": [
      "Venkat Venkatasubramanian",
      "N. Sanjeevrajan",
      "Manasi Khandekar"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.07891",
    "title": "A Theory of Non-Linear Feature Learning with One Gradient Step in  Two-Layer Neural Networks",
    "abstract": "Feature learning is thought to be one of the fundamental reasons for the success of deep neural networks. It is rigorously known that in two-layer fully-connected neural networks under certain conditions, one step of gradient descent on the first layer followed by ridge regression on the second layer can lead to feature learning; characterized by the appearance of a separated rank-one component -- spike -- in the spectrum of the feature matrix. However, with a constant gradient descent step size, this spike only carries information from the linear component of the target function and therefore learning non-linear components is impossible. We show that with a learning rate that grows with the sample size, such training in fact introduces multiple rank-one components, each corresponding to a specific polynomial feature. We further prove that the limiting large-dimensional and large sample training and test errors of the updated neural networks are fully characterized by these spikes. By precisely analyzing the improvement in the loss, we demonstrate that these non-linear features can enhance learning. ",
    "url": "https://arxiv.org/abs/2310.07891",
    "authors": [
      "Behrad Moniri",
      "Donghwan Lee",
      "Hamed Hassani",
      "Edgar Dobriban"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07908",
    "title": "Recurrent networks recognize patterns with low-dimensional oscillations",
    "abstract": "This study proposes a novel dynamical mechanism for pattern recognition discovered by interpreting a recurrent neural network (RNN) trained on a simple task inspired by the SET card game. We interpreted the trained RNN as recognizing patterns via phase shifts in a low-dimensional limit cycle in a manner analogous to transitions in a finite state automaton (FSA). We further validated this interpretation by handcrafting a simple oscillatory model that reproduces the dynamics of the trained RNN. Our findings not only suggest of a potential dynamical mechanism capable of pattern recognition, but also suggest of a potential neural implementation of FSA. Above all, this work contributes to the growing discourse on deep learning model interpretability. ",
    "url": "https://arxiv.org/abs/2310.07908",
    "authors": [
      "Keith T. Murray"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.07927",
    "title": "Enhanced sampling of Crystal Nucleation with Graph Representation Learnt  Variables",
    "abstract": "In this study, we present a graph neural network-based learning approach using an autoencoder setup to derive low-dimensional variables from features observed in experimental crystal structures. These variables are then biased in enhanced sampling to observe state-to-state transitions and reliable thermodynamic weights. Our approach uses simple convolution and pooling methods. To verify the effectiveness of our protocol, we examined the nucleation of various allotropes and polymorphs of iron and glycine from their molten states. Our graph latent variables when biased in well-tempered metadynamics consistently show transitions between states and achieve accurate free energy calculations in agreement with experiments, both of which are indicators of dependable sampling. This underscores the strength and promise of our graph neural net variables for improved sampling. The protocol shown here should be applicable for other systems and with other sampling methods. ",
    "url": "https://arxiv.org/abs/2310.07927",
    "authors": [
      "Ziyue Zou",
      "Pratyush Tiwary"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.08150",
    "title": "On Extreme Value Asymptotics of Projected Sample Covariances in High  Dimensions with Applications in Finance and Convolutional Networks",
    "abstract": "Maximum-type statistics of certain functions of the sample covariance matrix of high-dimensional vector time series are studied to statistically confirm or reject the null hypothesis that a data set has been collected under normal conditions. The approach generalizes the case of the maximal deviation of the sample autocovariances function from its assumed values. Within a linear time series framework it is shown that Gumbel-type extreme value asymptotics holds true. As applications we discuss long-only mimimal-variance portfolio optimization and subportfolio analysis with respect to idiosyncratic risks, ETF index tracking by sparse tracking portfolios, convolutional deep learners for image analysis and the analysis of array-of-sensors data. ",
    "url": "https://arxiv.org/abs/2310.08150",
    "authors": [
      "Ansgar Steland"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.08165",
    "title": "COVID-19 Detection Using Swin Transformer Approach from Computed  Tomography Images",
    "abstract": "The accurate and efficient diagnosis of COVID-19 is of paramount importance, particularly in the context of large-scale medical imaging datasets. In this preprint paper, we propose a novel approach for COVID-19 diagnosis using CT images that leverages the power of Swin Transformer models, state-of-the-art solutions in computer vision tasks. Our method includes a systematic approach for patient-level predictions, where individual CT slices are classified as COVID-19 or non-COVID, and the patient's overall diagnosis is determined through majority voting. The application of the Swin Transformer in this context results in patient-level predictions that demonstrate exceptional diagnostic accuracy. In terms of evaluation metrics, our approach consistently outperforms the baseline, as well as numerous competing methods, showcasing its effectiveness in COVID-19 diagnosis. The macro F1 score achieved by our model exceeds the baseline and offers a robust solution for accurate diagnosis. ",
    "url": "https://arxiv.org/abs/2310.08165",
    "authors": [
      "Kenan Morani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.08225",
    "title": "Fast Word Error Rate Estimation Using Self-Supervised Representations  For Speech And Text",
    "abstract": "The quality of automatic speech recognition (ASR) is typically measured by word error rate (WER). WER estimation is a task aiming to predict the WER of an ASR system, given a speech utterance and a transcription. This task has gained increasing attention while advanced ASR systems are trained on large amounts of data. In this case, WER estimation becomes necessary in many scenarios, for example, selecting training data with unknown transcription quality or estimating the testing performance of an ASR system without ground truth transcriptions. Facing large amounts of data, the computation efficiency of a WER estimator becomes essential in practical applications. However, previous works usually did not consider it as a priority. In this paper, a Fast WER estimator (Fe-WER) using self-supervised learning representation (SSLR) is introduced. The estimator is built upon SSLR aggregated by average pooling. The results show that Fe-WER outperformed the e-WER3 baseline relatively by 19.69% and 7.16% on Ted-Lium3 in both evaluation metrics of root mean square error and Pearson correlation coefficient, respectively. Moreover, the estimation weighted by duration was 10.43% when the target was 10.88%. Lastly, the inference speed was about 4x in terms of a real-time factor. ",
    "url": "https://arxiv.org/abs/2310.08225",
    "authors": [
      "Chanho Park",
      "Chengsong Lu",
      "Mingjie Chen",
      "Thomas Hain"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2310.08287",
    "title": "A Symmetry-Aware Exploration of Bayesian Neural Network Posteriors",
    "abstract": "The distribution of the weights of modern deep neural networks (DNNs) - crucial for uncertainty quantification and robustness - is an eminently complex object due to its extremely high dimensionality. This paper proposes one of the first large-scale explorations of the posterior distribution of deep Bayesian Neural Networks (BNNs), expanding its study to real-world vision tasks and architectures. Specifically, we investigate the optimal approach for approximating the posterior, analyze the connection between posterior quality and uncertainty quantification, delve into the impact of modes on the posterior, and explore methods for visualizing the posterior. Moreover, we uncover weight-space symmetries as a critical aspect for understanding the posterior. To this extent, we develop an in-depth assessment of the impact of both permutation and scaling symmetries that tend to obfuscate the Bayesian posterior. While the first type of transformation is known for duplicating modes, we explore the relationship between the latter and L2 regularization, challenging previous misconceptions. Finally, to help the community improve our understanding of the Bayesian posterior, we will shortly release the first large-scale checkpoint dataset, including thousands of real-world models and our codes. ",
    "url": "https://arxiv.org/abs/2310.08287",
    "authors": [
      "Olivier Laurent",
      "Emanuel Aldea",
      "Gianni Franchi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.08292",
    "title": "Concealed Electronic Countermeasures of Radar Signal with Adversarial  Examples",
    "abstract": "Electronic countermeasures involving radar signals are an important aspect of modern warfare. Traditional electronic countermeasures techniques typically add large-scale interference signals to ensure interference effects, which can lead to attacks being too obvious. In recent years, AI-based attack methods have emerged that can effectively solve this problem, but the attack scenarios are currently limited to time domain radar signal classification. In this paper, we focus on the time-frequency images classification scenario of radar signals. We first propose an attack pipeline under the time-frequency images scenario and DITIMI-FGSM attack algorithm with high transferability. Then, we propose STFT-based time domain signal attack(STDS) algorithm to solve the problem of non-invertibility in time-frequency analysis, thus obtaining the time-domain representation of the interference signal. A large number of experiments show that our attack pipeline is feasible and the proposed attack method has a high success rate. ",
    "url": "https://arxiv.org/abs/2310.08292",
    "authors": [
      "Ruinan Ma",
      "Canjie Zhu",
      "Mingfeng Lu",
      "Yunjie Li",
      "Yu-an Tan",
      "Ruibin Zhang",
      "Ran Tao"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.08338",
    "title": "A cry for help: Early detection of brain injury in newborns",
    "abstract": "Since the 1960s, neonatal clinicians have known that newborns suffering from certain neurological conditions exhibit altered crying patterns such as the high-pitched cry in birth asphyxia. Despite an annual burden of over 1.5 million infant deaths and disabilities, early detection of neonatal brain injuries due to asphyxia remains a challenge, particularly in developing countries where the majority of births are not attended by a trained physician. Here we report on the first inter-continental clinical study to demonstrate that neonatal brain injury can be reliably determined from recorded infant cries using an AI algorithm we call Roseline. Previous and recent work has been limited by the lack of a large, high-quality clinical database of cry recordings, constraining the application of state-of-the-art machine learning. We develop a new training methodology for audio-based pathology detection models and evaluate this system on a large database of newborn cry sounds acquired from geographically diverse settings -- 5 hospitals across 3 continents. Our system extracts interpretable acoustic biomarkers that support clinical decisions and is able to accurately detect neurological injury from newborns' cries with an AUC of 92.5% (88.7% sensitivity at 80% specificity). Cry-based neurological monitoring opens the door for low-cost, easy-to-use, non-invasive and contact-free screening of at-risk babies, especially when integrated into simple devices like smartphones or neonatal ICU monitors. This would provide a reliable tool where there are no alternatives, but also curtail the need to regularly exert newborns to physically-exhausting or radiation-exposing assessments such as brain CT scans. This work sets the stage for embracing the infant cry as a vital sign and indicates the potential of AI-driven sound monitoring for the future of affordable healthcare. ",
    "url": "https://arxiv.org/abs/2310.08338",
    "authors": [
      "Charles C. Onu",
      "Samantha Latremouille",
      "Arsenii Gorin",
      "Junhao Wang",
      "Uchenna Ekwochi",
      "Peter O. Ubuane",
      "Omolara A. Kehinde",
      "Muhammad A. Salisu",
      "Datonye Briggs",
      "Yoshua Bengio",
      "Doina Precup"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2310.08439",
    "title": "TensorMD: Scalable Tensor-Diagram based Machine Learning Interatomic  Potential on Heterogeneous Many-Core Processors",
    "abstract": "Molecular dynamics simulations have emerged as a potent tool for investigating the physical properties and kinetic behaviors of materials at the atomic scale, particularly in extreme conditions. Ab initio accuracy is now achievable with machine learning based interatomic potentials. With recent advancements in high-performance computing, highly accurate and large-scale simulations become feasible. This study introduces TensorMD, a new machine learning interatomic potential (MLIP) model that integrates physical principles and tensor diagrams. The tensor formalism provides a more efficient computation and greater flexibility for use with other scientific codes. Additionally, we proposed several portable optimization strategies and developed a highly optimized version for the new Sunway supercomputer. Our optimized TensorMD can achieve unprecedented performance on the new Sunway, enabling simulations of up to 52 billion atoms with a time-to-solution of 31 ps/step/atom, setting new records for HPC + AI + MD. ",
    "url": "https://arxiv.org/abs/2310.08439",
    "authors": [
      "Xin Chen",
      "Yucheng Ouyang",
      "Xin Chen",
      "Zhenchuan Chen",
      "Rongfen Lin",
      "Xingyu Gao",
      "Lifang Wang",
      "Fang Li",
      "Yin Liu",
      "Honghui Shang",
      "Haifeng Song"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.08495",
    "title": "Characterizing climate pathways using feature importance on echo state  networks",
    "abstract": "The 2022 National Defense Strategy of the United States listed climate change as a serious threat to national security. Climate intervention methods, such as stratospheric aerosol injection, have been proposed as mitigation strategies, but the downstream effects of such actions on a complex climate system are not well understood. The development of algorithmic techniques for quantifying relationships between source and impact variables related to a climate event (i.e., a climate pathway) would help inform policy decisions. Data-driven deep learning models have become powerful tools for modeling highly nonlinear relationships and may provide a route to characterize climate variable relationships. In this paper, we explore the use of an echo state network (ESN) for characterizing climate pathways. ESNs are a computationally efficient neural network variation designed for temporal data, and recent work proposes ESNs as a useful tool for forecasting spatio-temporal climate data. Like other neural networks, ESNs are non-interpretable black-box models, which poses a hurdle for understanding variable relationships. We address this issue by developing feature importance methods for ESNs in the context of spatio-temporal data to quantify variable relationships captured by the model. We conduct a simulation study to assess and compare the feature importance techniques, and we demonstrate the approach on reanalysis climate data. In the climate application, we select a time period that includes the 1991 volcanic eruption of Mount Pinatubo. This event was a significant stratospheric aerosol injection, which we use as a proxy for an artificial stratospheric aerosol injection. Using the proposed approach, we are able to characterize relationships between pathway variables associated with this event. ",
    "url": "https://arxiv.org/abs/2310.08495",
    "authors": [
      "Katherine Goode",
      "Daniel Ries",
      "Kellie McClernon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2107.14432",
    "title": "Adaptive Optimizers with Sparse Group Lasso for Neural Networks in CTR  Prediction",
    "abstract": " Comments: 24 pages. Published as a conference paper at ECML PKDD 2021. This version includes Appendix which was not included in the published version because of page limit ",
    "url": "https://arxiv.org/abs/2107.14432",
    "authors": [
      "Yun Yue",
      "Yongchao Liu",
      "Suo Tong",
      "Minghao Li",
      "Zhen Zhang",
      "Chunyang Wen",
      "Huanjun Bao",
      "Lihong Gu",
      "Jinjie Gu",
      "Yixiang Mu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.09339",
    "title": "Vision Transformers: From Semantic Segmentation to Dense Prediction",
    "abstract": " Comments: Extended version of CVPR 2021 paper arXiv:2012.15840 ",
    "url": "https://arxiv.org/abs/2207.09339",
    "authors": [
      "Li Zhang",
      "Jiachen Lu",
      "Sixiao Zheng",
      "Xinxuan Zhao",
      "Xiatian Zhu",
      "Yanwei Fu",
      "Tao Xiang",
      "Jianfeng Feng",
      "Philip H.S. Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.02809",
    "title": "The Role of Morphological Variation in Evolutionary Robotics: Maximizing  Performance and Robustness",
    "abstract": " Comments: submitted to MIT Evolutionary Computation Journal ",
    "url": "https://arxiv.org/abs/2208.02809",
    "authors": [
      "Jonata Tyska Carvalho",
      "Stefano Nolfi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.09222",
    "title": "MMTSA: Multimodal Temporal Segment Attention Network for Efficient Human  Activity Recognition",
    "abstract": " Title: MMTSA: Multimodal Temporal Segment Attention Network for Efficient Human  Activity Recognition ",
    "url": "https://arxiv.org/abs/2210.09222",
    "authors": [
      "Ziqi Gao",
      "Yuntao Wang",
      "Jianguo Chen",
      "Junliang Xing",
      "Shwetak Patel",
      "Xin Liu",
      "Yuanchun Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.11355",
    "title": "Network Synthetic Interventions: A Causal Framework for Panel Data Under  Network Interference",
    "abstract": " Comments: 49 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2210.11355",
    "authors": [
      "Anish Agarwal",
      "Sarah H. Cen",
      "Devavrat Shah",
      "Christina Lee Yu"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2210.13660",
    "title": "Multi-SpacePhish: Extending the Evasion-space of Adversarial Attacks  against Phishing Website Detectors using Machine Learning",
    "abstract": " Title: Multi-SpacePhish: Extending the Evasion-space of Adversarial Attacks  against Phishing Website Detectors using Machine Learning ",
    "url": "https://arxiv.org/abs/2210.13660",
    "authors": [
      "Ying Yuan",
      "Giovanni Apruzzese",
      "Mauro Conti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2211.12345",
    "title": "Understanding Sparse Feature Updates in Deep Networks using Iterative  Linearisation",
    "abstract": " Title: Understanding Sparse Feature Updates in Deep Networks using Iterative  Linearisation ",
    "url": "https://arxiv.org/abs/2211.12345",
    "authors": [
      "Adrian Goldwaser",
      "Hong Ge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2212.00613",
    "title": "NeuWigs: A Neural Dynamic Model for Volumetric Hair Capture and  Animation",
    "abstract": " Title: NeuWigs: A Neural Dynamic Model for Volumetric Hair Capture and  Animation ",
    "url": "https://arxiv.org/abs/2212.00613",
    "authors": [
      "Ziyan Wang",
      "Giljoo Nam",
      "Tuur Stuyck",
      "Stephen Lombardi",
      "Chen Cao",
      "Jason Saragih",
      "Michael Zollhoefer",
      "Jessica Hodgins",
      "Christoph Lassner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2212.06068",
    "title": "Solving the Wide-band Inverse Scattering Problem via Equivariant Neural  Networks",
    "abstract": " Comments: 21 pages, 9 figures, and 4 tables ",
    "url": "https://arxiv.org/abs/2212.06068",
    "authors": [
      "Borong Zhang",
      "Leonardo Zepeda-N\u00fa\u00f1ez",
      "Qin Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2212.09408",
    "title": "Universal Object Detection with Large Vision Model",
    "abstract": " Comments: Accepted by International Journal of Computer Vision (IJCV). The 2nd place in the object detection track of the Robust Vision Challenge (RVC 2022) ",
    "url": "https://arxiv.org/abs/2212.09408",
    "authors": [
      "Feng Lin",
      "Wenze Hu",
      "Yaowei Wang",
      "Yonghong Tian",
      "Guangming Lu",
      "Fanglin Chen",
      "Yong Xu",
      "Xiaoyu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.03900",
    "title": "Strong SDP based bounds on the cutwidth of a graph",
    "abstract": " Title: Strong SDP based bounds on the cutwidth of a graph ",
    "url": "https://arxiv.org/abs/2301.03900",
    "authors": [
      "Elisabeth Gaar",
      "Diane Puges",
      "Angelika Wiegele"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2301.07995",
    "title": "Sequential learning and control: Targeted exploration for robust  performance",
    "abstract": " Comments: submitted to IEEE Transactions on Automatic Control (TAC) ",
    "url": "https://arxiv.org/abs/2301.07995",
    "authors": [
      "Janani Venkatasubramanian",
      "Johannes K\u00f6hler",
      "Julian Berberich",
      "Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2301.12082",
    "title": "Pushing the Limits of Fewshot Anomaly Detection in Industry Vision:  Graphcore",
    "abstract": " Title: Pushing the Limits of Fewshot Anomaly Detection in Industry Vision:  Graphcore ",
    "url": "https://arxiv.org/abs/2301.12082",
    "authors": [
      "Guoyang Xie",
      "Jinbao Wang",
      "Jiaqi Liu",
      "Feng Zheng",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.13359",
    "title": "IM-IAD: Industrial Image Anomaly Detection Benchmark in Manufacturing",
    "abstract": " Title: IM-IAD: Industrial Image Anomaly Detection Benchmark in Manufacturing ",
    "url": "https://arxiv.org/abs/2301.13359",
    "authors": [
      "Guoyang Xie",
      "Jinbao Wang",
      "Jiaqi Liu",
      "Jiayi Lyu",
      "Yong Liu",
      "Chengjie Wang",
      "Feng Zheng",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.13613",
    "title": "Geometry-based approximation of waves in complex domains",
    "abstract": " Title: Geometry-based approximation of waves in complex domains ",
    "url": "https://arxiv.org/abs/2301.13613",
    "authors": [
      "Davide Pradovera",
      "Monica Nonino",
      "Ilaria Perugia"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2302.02931",
    "title": "Bitrate-Constrained DRO: Beyond Worst Case Robustness To Unknown Group  Shifts",
    "abstract": " Title: Bitrate-Constrained DRO: Beyond Worst Case Robustness To Unknown Group  Shifts ",
    "url": "https://arxiv.org/abs/2302.02931",
    "authors": [
      "Amrith Setlur",
      "Don Dennis",
      "Benjamin Eysenbach",
      "Aditi Raghunathan",
      "Chelsea Finn",
      "Virginia Smith",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07189",
    "title": "Optimizing Convolutional Neural Networks for Chronic Obstructive  Pulmonary Disease Detection in Clinical Computed Tomography Imaging",
    "abstract": " Title: Optimizing Convolutional Neural Networks for Chronic Obstructive  Pulmonary Disease Detection in Clinical Computed Tomography Imaging ",
    "url": "https://arxiv.org/abs/2303.07189",
    "authors": [
      "Tina Dorosti",
      "Manuel Schultheiss",
      "Felix Hofmann",
      "Johannes Thalhammer",
      "Luisa Kirchner",
      "Theresa Urban",
      "Franz Pfeiffer",
      "Florian Schaff",
      "Tobias Lasser",
      "Daniela Pfeiffer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07312",
    "title": "Enhancing LiDAR performance: Robust De-skewing Exclusively Relying on  Range Measurements",
    "abstract": " Comments: 6 pages , 5 figures ",
    "url": "https://arxiv.org/abs/2303.07312",
    "authors": [
      "Omar Salem",
      "Emanuele Giacomini",
      "Leonardo Brizi",
      "Luca Di Giammarino",
      "Giorgio Grisetti"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.10108",
    "title": "Data-Centric Learning from Unlabeled Graphs with Diffusion Model",
    "abstract": " Comments: Accepted by NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2303.10108",
    "authors": [
      "Gang Liu",
      "Eric Inae",
      "Tong Zhao",
      "Jiaxin Xu",
      "Tengfei Luo",
      "Meng Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.17823",
    "title": "An interpretable neural network-based non-proportional odds model for  ordinal regression",
    "abstract": " Comments: 38 pages, 18 figures ",
    "url": "https://arxiv.org/abs/2303.17823",
    "authors": [
      "Akifumi Okuno",
      "Kazuharu Harada"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.03198",
    "title": "RFAConv: Innovating Spatial Attention and Standard Convolutional  Operation",
    "abstract": " Comments: 12 pages, 11figures ",
    "url": "https://arxiv.org/abs/2304.03198",
    "authors": [
      "Xin Zhang",
      "Chen Liu",
      "Degang Yang",
      "Tingting Song",
      "Yichen Ye",
      "Ke Li",
      "Yingze Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.04234",
    "title": "Variational operator learning: A unified paradigm marrying training  neural operators and solving partial differential equations",
    "abstract": " Comments: 35 pages, 6 figures with 5 extended figures ",
    "url": "https://arxiv.org/abs/2304.04234",
    "authors": [
      "Tengfei Xu",
      "Dachuan Liu",
      "Peng Hao",
      "Bo Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2304.12233",
    "title": "Diffusion-based Generative AI for Exploring Transition States from 2D  Molecular Graphs",
    "abstract": " Title: Diffusion-based Generative AI for Exploring Transition States from 2D  Molecular Graphs ",
    "url": "https://arxiv.org/abs/2304.12233",
    "authors": [
      "Seonghwan Kim",
      "Jeheon Woo",
      "Woo Youn Kim"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.13819",
    "title": "MAPConNet: Self-supervised 3D Pose Transfer with Mesh and Point  Contrastive Learning",
    "abstract": " Comments: Accepted by ICCV 2023 ",
    "url": "https://arxiv.org/abs/2304.13819",
    "authors": [
      "Jiaze Sun",
      "Zhixiang Chen",
      "Tae-Kyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.06118",
    "title": "NeRF2: Neural Radio-Frequency Radiance Fields",
    "abstract": " Title: NeRF2: Neural Radio-Frequency Radiance Fields ",
    "url": "https://arxiv.org/abs/2305.06118",
    "authors": [
      "Xiaopeng Zhao",
      "Zhenlin An",
      "Qingrui Pan",
      "Lei Yang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.06648",
    "title": "Generalization bounds for neural ordinary differential equations and  deep residual networks",
    "abstract": " Comments: NeurIPS 2023, 21 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2305.06648",
    "authors": [
      "Pierre Marion"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.07375",
    "title": "Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation",
    "abstract": " Comments: Accepted to Findings of EMNLP 2023 ",
    "url": "https://arxiv.org/abs/2305.07375",
    "authors": [
      "Jinglong Gao",
      "Xiao Ding",
      "Bing Qin",
      "Ting Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.09548",
    "title": "Measuring Social Dimensions of Self-Presentation in Social Media  Biographies with an Identity-based Approach",
    "abstract": " Title: Measuring Social Dimensions of Self-Presentation in Social Media  Biographies with an Identity-based Approach ",
    "url": "https://arxiv.org/abs/2305.09548",
    "authors": [
      "Navid Madani",
      "Rabiraj Bandyopadhyay",
      "Briony Swire-Thompson",
      "Michael Miller Yoder",
      "Kenneth Joseph"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.15394",
    "title": "Differentially-Private Decision Trees and Provable Robustness to Data  Poisoning",
    "abstract": " Title: Differentially-Private Decision Trees and Provable Robustness to Data  Poisoning ",
    "url": "https://arxiv.org/abs/2305.15394",
    "authors": [
      "Dani\u00ebl Vos",
      "Jelle Vos",
      "Tianyu Li",
      "Zekeriya Erkin",
      "Sicco Verwer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.17536",
    "title": "On Locally Identifying Coloring of Cartesian Product and Tensor Product  of Graphs",
    "abstract": " Title: On Locally Identifying Coloring of Cartesian Product and Tensor Product  of Graphs ",
    "url": "https://arxiv.org/abs/2305.17536",
    "authors": [
      "Sriram Bhyravarapu",
      "Swati Kumari",
      "I. Vinod Reddy"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2306.14041",
    "title": "Smoothed $f$-Divergence Distributionally Robust Optimization",
    "abstract": " Title: Smoothed $f$-Divergence Distributionally Robust Optimization ",
    "url": "https://arxiv.org/abs/2306.14041",
    "authors": [
      "Zhenyuan Liu",
      "Bart P. G. Van Parys",
      "Henry Lam"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.16335",
    "title": "Emulating the dynamics of complex systems using autoregressive models on  manifolds (mNARX)",
    "abstract": " Title: Emulating the dynamics of complex systems using autoregressive models on  manifolds (mNARX) ",
    "url": "https://arxiv.org/abs/2306.16335",
    "authors": [
      "Styfen Sch\u00e4r",
      "Stefano Marelli",
      "Bruno Sudret"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2307.09855",
    "title": "Cross-thread critical sections and efficient dynamic race prediction  methods",
    "abstract": " Comments: Revised POPL'24 submission. 1. WCP is sound and show that WCP soundness proof can be adapted. 2. Cross-thread critical sections arise in practice, though the impact is not drastic. This in line with other works (like WCP) that advance the state of the art ",
    "url": "https://arxiv.org/abs/2307.09855",
    "authors": [
      "Martin Sulzmann",
      "Peter Thiemann"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2308.03998",
    "title": "Real-time Strawberry Detection Based on Improved YOLOv5s Architecture  for Robotic Harvesting in open-field environment",
    "abstract": " Comments: 20 pages; 15 figures ",
    "url": "https://arxiv.org/abs/2308.03998",
    "authors": [
      "Zixuan He",
      "Salik Ram Khanal",
      "Xin Zhang",
      "Manoj Karkee",
      "Qin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.04102",
    "title": "Asynchronous Evolution of Deep Neural Network Architectures",
    "abstract": " Title: Asynchronous Evolution of Deep Neural Network Architectures ",
    "url": "https://arxiv.org/abs/2308.04102",
    "authors": [
      "Jason Liang",
      "Hormoz Shahrzad",
      "Risto Miikkulainen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.05035",
    "title": "Expert load matters: operating networks at high accuracy and low manual  effort",
    "abstract": " Comments: Accepted to the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) ",
    "url": "https://arxiv.org/abs/2308.05035",
    "authors": [
      "Sara Sangalli",
      "Ertunc Erdil",
      "Ender Konukoglu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2308.05636",
    "title": "A Homomorphic Encryption Framework for Privacy-Preserving Spiking Neural  Networks",
    "abstract": " Title: A Homomorphic Encryption Framework for Privacy-Preserving Spiking Neural  Networks ",
    "url": "https://arxiv.org/abs/2308.05636",
    "authors": [
      "Farzad Nikfam",
      "Raffaele Casaburi",
      "Alberto Marchisio",
      "Maurizio Martina",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2308.12243",
    "title": "Multi-Objective Optimization for Sparse Deep Neural Network Training",
    "abstract": " Comments: 13 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2308.12243",
    "authors": [
      "S. S. Hotegni",
      "S. Peitz",
      "M. Berkemeier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2308.12435",
    "title": "Characterising representation dynamics in recurrent neural networks for  object recognition",
    "abstract": " Comments: 8 pages, 7 figures; revision of our Conference on Cognitive Computational Neuroscience (CCN) 2023 paper ",
    "url": "https://arxiv.org/abs/2308.12435",
    "authors": [
      "Sushrut Thorat",
      "Adrien Doerig",
      "Tim C. Kietzmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2308.13422",
    "title": "QKSAN: A Quantum Kernel Self-Attention Network",
    "abstract": " Title: QKSAN: A Quantum Kernel Self-Attention Network ",
    "url": "https://arxiv.org/abs/2308.13422",
    "authors": [
      "Ren-Xin Zhao",
      "Jinjing Shi",
      "Xuelong Li"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.14311",
    "title": "Spread Control Method on Unknown Networks Based on Hierarchical  Reinforcement Learning",
    "abstract": " Title: Spread Control Method on Unknown Networks Based on Hierarchical  Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2308.14311",
    "authors": [
      "Wenxiang Dong",
      "Zhanjiang Chen",
      "H.Vicky Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.00480",
    "title": "Learning-based NLOS Detection and Uncertainty Prediction of GNSS  Observations with Transformer-Enhanced LSTM Network",
    "abstract": " Comments: Accepted for the IEEE ITSC2023 ",
    "url": "https://arxiv.org/abs/2309.00480",
    "authors": [
      "Haoming Zhang",
      "Zhanxin Wang",
      "Heike Vallery"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.03004",
    "title": "A Theoretical Explanation of Activation Sparsity through Flat Minima and  Adversarial Robustness",
    "abstract": " Title: A Theoretical Explanation of Activation Sparsity through Flat Minima and  Adversarial Robustness ",
    "url": "https://arxiv.org/abs/2309.03004",
    "authors": [
      "Ze Peng",
      "Lei Qi",
      "Yinghuan Shi",
      "Yang Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11523",
    "title": "RMT: Retentive Networks Meet Vision Transformers",
    "abstract": " Comments: The work is still in progress ",
    "url": "https://arxiv.org/abs/2309.11523",
    "authors": [
      "Qihang Fan",
      "Huaibo Huang",
      "Mingrui Chen",
      "Hongmin Liu",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00327",
    "title": "Memorization with neural nets: going beyond the worst case",
    "abstract": " Title: Memorization with neural nets: going beyond the worst case ",
    "url": "https://arxiv.org/abs/2310.00327",
    "authors": [
      "Sjoerd Dirksen",
      "Patrick Finke",
      "Martin Genzel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2310.00656",
    "title": "LEGO-Prover: Neural Theorem Proving with Growing Libraries",
    "abstract": " Title: LEGO-Prover: Neural Theorem Proving with Growing Libraries ",
    "url": "https://arxiv.org/abs/2310.00656",
    "authors": [
      "Huajian Xin",
      "Haiming Wang",
      "Chuanyang Zheng",
      "Lin Li",
      "Zhengying Liu",
      "Qingxing Cao",
      "Yinya Huang",
      "Jing Xiong",
      "Han Shi",
      "Enze Xie",
      "Jian Yin",
      "Zhenguo Li",
      "Xiaodan Liang",
      "Heng Liao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.00847",
    "title": "Can Pre-trained Networks Detect Familiar Out-of-Distribution Data?",
    "abstract": " Title: Can Pre-trained Networks Detect Familiar Out-of-Distribution Data? ",
    "url": "https://arxiv.org/abs/2310.00847",
    "authors": [
      "Atsuyuki Miyai",
      "Qing Yu",
      "Go Irie",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.01649",
    "title": "On Training Derivative-Constrained Neural Networks",
    "abstract": " Title: On Training Derivative-Constrained Neural Networks ",
    "url": "https://arxiv.org/abs/2310.01649",
    "authors": [
      "KaiChieh Lo",
      "Daniel Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.02244",
    "title": "Tensor Programs VI: Feature Learning in Infinite-Depth Neural Networks",
    "abstract": " Title: Tensor Programs VI: Feature Learning in Infinite-Depth Neural Networks ",
    "url": "https://arxiv.org/abs/2310.02244",
    "authors": [
      "Greg Yang",
      "Dingli Yu",
      "Chen Zhu",
      "Soufiane Hayou"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2310.02772",
    "title": "Spike Accumulation Forwarding for Effective Training of Spiking Neural  Networks",
    "abstract": " Comments: 11 pages, 5 figures, Appendix:8 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2310.02772",
    "authors": [
      "Ryuji Saiin",
      "Tomoya Shirakawa",
      "Sota Yoshihara",
      "Yoshihide Sawada",
      "Hiroyuki Kusumoto"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05354",
    "title": "An Initial Investigation of Neural Replay Simulator for Over-the-Air  Adversarial Perturbations to Automatic Speaker Verification",
    "abstract": " Title: An Initial Investigation of Neural Replay Simulator for Over-the-Air  Adversarial Perturbations to Automatic Speaker Verification ",
    "url": "https://arxiv.org/abs/2310.05354",
    "authors": [
      "Jiaqi Li",
      "Li Wang",
      "Liumeng Xue",
      "Lei Wang",
      "Zhizheng Wu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.05624",
    "title": "Locality-Aware Generalizable Implicit Neural Representation",
    "abstract": " Comments: 19 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2310.05624",
    "authors": [
      "Doyup Lee",
      "Chiheon Kim",
      "Minsu Cho",
      "Wook-Shin Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.06488",
    "title": "SpikeCLIP: A Contrastive Language-Image Pretrained Spiking Neural  Network",
    "abstract": " Title: SpikeCLIP: A Contrastive Language-Image Pretrained Spiking Neural  Network ",
    "url": "https://arxiv.org/abs/2310.06488",
    "authors": [
      "Tianlong Li",
      "Wenhao Liu",
      "Changze Lv",
      "Jianhan Xu",
      "Cenyuan Zhang",
      "Muling Wu",
      "Xiaoqing Zheng",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.06823",
    "title": "NECO: NEural Collapse Based Out-of-distribution detection",
    "abstract": " Comments: 28 pages ",
    "url": "https://arxiv.org/abs/2310.06823",
    "authors": [
      "Mou\u00efn Ben Ammar",
      "Nacim Belkhir",
      "Sebastian Popescu",
      "Antoine Manzanera",
      "Gianni Franchi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07246",
    "title": "Vec-Tok Speech: speech vectorization and tokenization for neural speech  generation",
    "abstract": " Comments: 15 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2310.07246",
    "authors": [
      "Xinfa Zhu",
      "Yuanjun Lv",
      "Yi Lei",
      "Tao Li",
      "Wendi He",
      "Hongbin Zhou",
      "Heng Lu",
      "Lei Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.07352",
    "title": "Adaptive Distributionally Robust Planning for Renewable-Powered Fast  Charging Stations Under Decision-Dependent EV Diffusion Uncertainty",
    "abstract": " Title: Adaptive Distributionally Robust Planning for Renewable-Powered Fast  Charging Stations Under Decision-Dependent EV Diffusion Uncertainty ",
    "url": "https://arxiv.org/abs/2310.07352",
    "authors": [
      "Yujia Li",
      "Feng Qiu",
      "Yixuan Chen",
      "Yunhe Hou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2310.07365",
    "title": "GraphControl: Adding Conditional Control to Universal Graph Pre-trained  Models for Graph Domain Transfer Learning",
    "abstract": " Comments: Under Review ",
    "url": "https://arxiv.org/abs/2310.07365",
    "authors": [
      "Yun Zhu",
      "Yaoke Wang",
      "Haizhou Shi",
      "Zhenshuo Zhang",
      "Siliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07402",
    "title": "NuTime: Numerically Multi-Scaled Embedding for Large-Scale Time Series  Pretraining",
    "abstract": " Title: NuTime: Numerically Multi-Scaled Embedding for Large-Scale Time Series  Pretraining ",
    "url": "https://arxiv.org/abs/2310.07402",
    "authors": [
      "Chenguo Lin",
      "Xumeng Wen",
      "Wei Cao",
      "Congrui Huang",
      "Jiang Bian",
      "Stephen Lin",
      "Zhirong Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07449",
    "title": "PoRF: Pose Residual Field for Accurate Neural Surface Reconstruction",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2310.07449",
    "authors": [
      "Jia-Wang Bian",
      "Wenjing Bian",
      "Victor Adrian Prisacariu",
      "Philip Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07478",
    "title": "Multimodal Graph Learning for Generative Tasks",
    "abstract": " Title: Multimodal Graph Learning for Generative Tasks ",
    "url": "https://arxiv.org/abs/2310.07478",
    "authors": [
      "Minji Yoon",
      "Jing Yu Koh",
      "Bryan Hooi",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07522",
    "title": "S4C: Self-Supervised Semantic Scene Completion with Neural Fields",
    "abstract": " Title: S4C: Self-Supervised Semantic Scene Completion with Neural Fields ",
    "url": "https://arxiv.org/abs/2310.07522",
    "authors": [
      "Adrian Hayler",
      "Felix Wimbauer",
      "Dominik Muhle",
      "Christian Rupprecht",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]