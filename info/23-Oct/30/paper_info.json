[
  {
    "id": "arXiv:2310.17664",
    "title": "Cascaded Multi-task Adaptive Learning Based on Neural Architecture  Search",
    "abstract": "Cascading multiple pre-trained models is an effective way to compose an end-to-end system. However, fine-tuning the full cascaded model is parameter and memory inefficient and our observations reveal that only applying adapter modules on cascaded model can not achieve considerable performance as fine-tuning. We propose an automatic and effective adaptive learning method to optimize end-to-end cascaded multi-task models based on Neural Architecture Search (NAS) framework. The candidate adaptive operations on each specific module consist of frozen, inserting an adapter and fine-tuning. We further add a penalty item on the loss to limit the learned structure which takes the amount of trainable parameters into account. The penalty item successfully restrict the searched architecture and the proposed approach is able to search similar tuning scheme with hand-craft, compressing the optimizing parameters to 8.7% corresponding to full fine-tuning on SLURP with an even better performance. ",
    "url": "https://arxiv.org/abs/2310.17664",
    "authors": [
      "Yingying Gao",
      "Shilei Zhang",
      "Zihao Cui",
      "Chao Deng",
      "Junlan Feng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.17668",
    "title": "Fine tuning Pre trained Models for Robustness Under Noisy Labels",
    "abstract": "The presence of noisy labels in a training dataset can significantly impact the performance of machine learning models. To tackle this issue, researchers have explored methods for Learning with Noisy Labels to identify clean samples and reduce the influence of noisy labels. However, constraining the influence of a certain portion of the training dataset can result in a reduction in overall generalization performance. To alleviate this, recent studies have considered the careful utilization of noisy labels by leveraging huge computational resources. Therefore, the increasing training cost necessitates a reevaluation of efficiency. In other areas of research, there has been a focus on developing fine-tuning techniques for large pre-trained models that aim to achieve both high generalization performance and efficiency. However, these methods have mainly concentrated on clean datasets, and there has been limited exploration of the noisy label scenario. In this research, our aim is to find an appropriate way to fine-tune pre-trained models for noisy labeled datasets. To achieve this goal, we investigate the characteristics of pre-trained models when they encounter noisy datasets. Through empirical analysis, we introduce a novel algorithm called TURN, which robustly and efficiently transfers the prior knowledge of pre-trained models. The algorithm consists of two main steps: (1) independently tuning the linear classifier to protect the feature extractor from being distorted by noisy labels, and (2) reducing the noisy label ratio and fine-tuning the entire model based on the noise-reduced dataset to adapt it to the target dataset. The proposed algorithm has been extensively tested and demonstrates efficient yet improved denoising performance on various benchmarks compared to previous methods. ",
    "url": "https://arxiv.org/abs/2310.17668",
    "authors": [
      "Sumyeong Ahn",
      "Sihyeon Kim",
      "Jongwoo Ko",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.17669",
    "title": "An Approach for Efficient Neural Architecture Search Space Definition",
    "abstract": "As we advance in the fast-growing era of Machine Learning, various new and more complex neural architectures are arising to tackle problem more efficiently. On the one hand their efficient usage requires advanced knowledge and expertise, which is most of the time difficult to find on the labor market. On the other hand, searching for an optimized neural architecture is a time-consuming task when it is performed manually using a trial and error approach. Hence, a method and a tool support is needed to assist users of neural architectures, leading to an eagerness in the field of Automatic Machine Learning (AutoML). When it comes to Deep Learning, an important part of AutoML is the Neural Architecture Search (NAS). In this paper, we propose a novel cell-based hierarchical search space, easy to comprehend and manipulate. The objectives of the proposed approach are to optimize the search-time and to be general enough to handle most of state of the art Convolutional Neural Networks (CNN) architectures. ",
    "url": "https://arxiv.org/abs/2310.17669",
    "authors": [
      "L\u00e9o Pouy",
      "Fouad Khenfri",
      "Patrick Leserf",
      "Chokri Mraidha",
      "Cherif Larouci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.17670",
    "title": "Unknown Health States Recognition With Collective Decision Based Deep  Learning Networks In Predictive Maintenance Applications",
    "abstract": "At present, decision making solutions developed based on deep learning (DL) models have received extensive attention in predictive maintenance (PM) applications along with the rapid improvement of computing power. Relying on the superior properties of shared weights and spatial pooling, Convolutional Neural Network (CNN) can learn effective representations of health states from industrial data. Many developed CNN-based schemes, such as advanced CNNs that introduce residual learning and multi-scale learning, have shown good performance in health state recognition tasks under the assumption that all the classes are known. However, these schemes have no ability to deal with new abnormal samples that belong to state classes not part of the training set. In this paper, a collective decision framework for different CNNs is proposed. It is based on a One-vs-Rest network (OVRN) to simultaneously achieve classification of known and unknown health states. OVRN learn state-specific discriminative features and enhance the ability to reject new abnormal samples incorporated to different CNNs. According to the validation results on the public dataset of Tennessee Eastman Process (TEP), the proposed CNN-based decision schemes incorporating OVRN have outstanding recognition ability for samples of unknown heath states, while maintaining satisfactory accuracy on known states. The results show that the new DL framework outperforms conventional CNNs, and the one based on residual and multi-scale learning has the best overall performance. ",
    "url": "https://arxiv.org/abs/2310.17670",
    "authors": [
      "Chuyue Lou",
      "M. Amine Atoui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.17680",
    "title": "CodeFusion: A Pre-trained Diffusion Model for Code Generation",
    "abstract": "Imagine a developer who can only change their last line of code, how often would they have to start writing a function from scratch before it is correct? Auto-regressive models for code generation from natural language have a similar limitation: they do not easily allow reconsidering earlier tokens generated. We introduce CodeFusion, a pre-trained diffusion code generation model that addresses this limitation by iteratively denoising a complete program conditioned on the encoded natural language. We evaluate CodeFusion on the task of natural language to code generation for Bash, Python, and Microsoft Excel conditional formatting (CF) rules. Experiments show that CodeFusion (75M parameters) performs on par with state-of-the-art auto-regressive systems (350M-175B parameters) in top-1 accuracy and outperforms them in top-3 and top-5 accuracy due to its better balance in diversity versus quality. ",
    "url": "https://arxiv.org/abs/2310.17680",
    "authors": [
      "Mukul Singh",
      "Jos\u00e9 Cambronero",
      "Sumit Gulwani",
      "Vu Le",
      "Carina Negreanu",
      "Gust Verbruggen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2310.17687",
    "title": "Counterfactual Fairness for Predictions using Generative Adversarial  Networks",
    "abstract": "Fairness in predictions is of direct importance in practice due to legal, ethical, and societal reasons. It is often achieved through counterfactual fairness, which ensures that the prediction for an individual is the same as that in a counterfactual world under a different sensitive attribute. However, achieving counterfactual fairness is challenging as counterfactuals are unobservable. In this paper, we develop a novel deep neural network called Generative Counterfactual Fairness Network (GCFN) for making predictions under counterfactual fairness. Specifically, we leverage a tailored generative adversarial network to directly learn the counterfactual distribution of the descendants of the sensitive attribute, which we then use to enforce fair predictions through a novel counterfactual mediator regularization. If the counterfactual distribution is learned sufficiently well, our method is mathematically guaranteed to ensure the notion of counterfactual fairness. Thereby, our GCFN addresses key shortcomings of existing baselines that are based on inferring latent variables, yet which (a) are potentially correlated with the sensitive attributes and thus lead to bias, and (b) have weak capability in constructing latent representations and thus low prediction performance. Across various experiments, our method achieves state-of-the-art performance. Using a real-world case study from recidivism prediction, we further demonstrate that our method makes meaningful predictions in practice. ",
    "url": "https://arxiv.org/abs/2310.17687",
    "authors": [
      "Yuchen Ma",
      "Dennis Frauen",
      "Valentyn Melnychuk",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.17723",
    "title": "ZeroQuant-HERO: Hardware-Enhanced Robust Optimized Post-Training  Quantization Framework for W8A8 Transformers",
    "abstract": "Quantization techniques are pivotal in reducing the memory and computational demands of deep neural network inference. Existing solutions, such as ZeroQuant, offer dynamic quantization for models like BERT and GPT but overlook crucial memory-bounded operators and the complexities of per-token quantization. Addressing these gaps, we present a novel, fully hardware-enhanced robust optimized post-training W8A8 quantization framework, ZeroQuant-HERO. This framework uniquely integrates both memory bandwidth and compute-intensive operators, aiming for optimal hardware performance. Additionally, it offers flexibility by allowing specific INT8 modules to switch to FP16/BF16 mode, enhancing accuracy. ",
    "url": "https://arxiv.org/abs/2310.17723",
    "authors": [
      "Zhewei Yao",
      "Reza Yazdani Aminabadi",
      "Stephen Youn",
      "Xiaoxia Wu",
      "Elton Zheng",
      "Yuxiong He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.17729",
    "title": "Improving Traffic Density Forecasting in Intelligent Transportation  Systems Using Gated Graph Neural Networks",
    "abstract": "This study delves into the application of graph neural networks in the realm of traffic forecasting, a crucial facet of intelligent transportation systems. Accurate traffic predictions are vital for functions like trip planning, traffic control, and vehicle routing in such systems. Three prominent GNN architectures Graph Convolutional Networks (Graph Sample and Aggregation) and Gated Graph Neural Networks are explored within the context of traffic prediction. Each architecture's methodology is thoroughly examined, including layer configurations, activation functions,and hyperparameters. The primary goal is to minimize prediction errors, with GGNNs emerging as the most effective choice among the three models. The research outlines outcomes for each architecture, elucidating their predictive performance through root mean squared error and mean absolute error (MAE). Hypothetical results reveal intriguing insights: GCNs display an RMSE of 9.10 and an MAE of 8.00, while GraphSAGE shows improvement with an RMSE of 8.3 and an MAE of 7.5. Gated Graph Neural Networks (GGNNs) exhibit the lowest RMSE at 9.15 and an impressive MAE of 7.1, positioning them as the frontrunner. ",
    "url": "https://arxiv.org/abs/2310.17729",
    "authors": [
      "Razib Hayat Khan",
      "Jonayet Miah",
      "S M Yasir Arafat",
      "M M Mahbubul Syeed",
      "Duc M Ca"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.17732",
    "title": "GNN-GMVO: Graph Neural Networks for Optimizing Gross Merchandise Value  in Similar Item Recommendation",
    "abstract": "Similar item recommendation is a critical task in the e-Commerce industry, which helps customers explore similar and relevant alternatives based on their interested products. Despite the traditional machine learning models, Graph Neural Networks (GNNs), by design, can understand complex relations like similarity between products. However, in contrast to their wide usage in retrieval tasks and their focus on optimizing the relevance, the current GNN architectures are not tailored toward maximizing revenue-related objectives such as Gross Merchandise Value (GMV), which is one of the major business metrics for e-Commerce companies. In addition, defining accurate edge relations in GNNs is non-trivial in large-scale e-Commerce systems, due to the heterogeneity nature of the item-item relationships. This work aims to address these issues by designing a new GNN architecture called GNN-GMVO (Graph Neural Network - Gross Merchandise Value Optimizer). This model directly optimizes GMV while considering the complex relations between items. In addition, we propose a customized edge construction method to tailor the model toward similar item recommendation task and alleviate the noisy and complex item-item relations. In our comprehensive experiments on three real-world datasets, we show higher prediction performance and expected GMV for top ranked items recommended by our model when compared with selected state-of-the-art benchmark models. ",
    "url": "https://arxiv.org/abs/2310.17732",
    "authors": [
      "Ramin Giahi",
      "Reza Yousefi Maragheh",
      "Nima Farrokhsiar",
      "Jianpeng Xu",
      "Jason Cho",
      "Evren Korpeoglu",
      "Sushant Kumar",
      "Kannan Achan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.17737",
    "title": "ArchBERT: Bi-Modal Understanding of Neural Architectures and Natural  Languages",
    "abstract": "Building multi-modal language models has been a trend in the recent years, where additional modalities such as image, video, speech, etc. are jointly learned along with natural languages (i.e., textual information). Despite the success of these multi-modal language models with different modalities, there is no existing solution for neural network architectures and natural languages. Providing neural architectural information as a new modality allows us to provide fast architecture-2-text and text-2-architecture retrieval/generation services on the cloud with a single inference. Such solution is valuable in terms of helping beginner and intermediate ML users to come up with better neural architectures or AutoML approaches with a simple text query. In this paper, we propose ArchBERT, a bi-modal model for joint learning and understanding of neural architectures and natural languages, which opens up new avenues for research in this area. We also introduce a pre-training strategy named Masked Architecture Modeling (MAM) for a more generalized joint learning. Moreover, we introduce and publicly release two new bi-modal datasets for training and validating our methods. The ArchBERT's performance is verified through a set of numerical experiments on different downstream tasks such as architecture-oriented reasoning, question answering, and captioning (summarization). Datasets, codes, and demos are available supplementary materials. ",
    "url": "https://arxiv.org/abs/2310.17737",
    "authors": [
      "Mohammad Akbari",
      "Saeed Ranjbar Alvar",
      "Behnam Kamranian",
      "Amin Banitalebi-Dehkordi",
      "Yong Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.17748",
    "title": "Making the End-User a Priority in Benchmarking: OrionBench for  Unsupervised Time Series Anomaly Detection",
    "abstract": "Time series anomaly detection is a prevalent problem in many application domains such as patient monitoring in healthcare, forecasting in finance, or predictive maintenance in energy. This has led to the emergence of a plethora of anomaly detection methods, including more recently, deep learning based methods. Although several benchmarks have been proposed to compare newly developed models, they usually rely on one-time execution over a limited set of datasets and the comparison is restricted to a few models. We propose OrionBench -- a user centric continuously maintained benchmark for unsupervised time series anomaly detection. The framework provides universal abstractions to represent models, extensibility to add new pipelines and datasets, hyperparameter standardization, pipeline verification, and frequent releases with published benchmarks. We demonstrate the usage of OrionBench, and the progression of pipelines across 15 releases published over the course of three years. Moreover, we walk through two real scenarios we experienced with OrionBench that highlight the importance of continuous benchmarks in unsupervised time series anomaly detection. ",
    "url": "https://arxiv.org/abs/2310.17748",
    "authors": [
      "Sarah Alnegheimish",
      "Laure Berti-Equille",
      "Kalyan Veeramachaneni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.17769",
    "title": "Social Contract AI: Aligning AI Assistants with Implicit Group Norms",
    "abstract": "We explore the idea of aligning an AI assistant by inverting a model of users' (unknown) preferences from observed interactions. To validate our proposal, we run proof-of-concept simulations in the economic ultimatum game, formalizing user preferences as policies that guide the actions of simulated players. We find that the AI assistant accurately aligns its behavior to match standard policies from the economic literature (e.g., selfish, altruistic). However, the assistant's learned policies lack robustness and exhibit limited generalization in an out-of-distribution setting when confronted with a currency (e.g., grams of medicine) that was not included in the assistant's training distribution. Additionally, we find that when there is inconsistency in the relationship between language use and an unknown policy (e.g., an altruistic policy combined with rude language), the assistant's learning of the policy is slowed. Overall, our preliminary results suggest that developing simulation frameworks in which AI assistants need to infer preferences from diverse users can provide a valuable approach for studying practical alignment questions. ",
    "url": "https://arxiv.org/abs/2310.17769",
    "authors": [
      "Jan-Philipp Fr\u00e4nken",
      "Sam Kwok",
      "Peixuan Ye",
      "Kanishk Gandhi",
      "Dilip Arumugam",
      "Jared Moore",
      "Alex Tamkin",
      "Tobias Gerstenberg",
      "Noah D. Goodman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.17772",
    "title": "Learning Optimal Classification Trees Robust to Distribution Shifts",
    "abstract": "We consider the problem of learning classification trees that are robust to distribution shifts between training and testing/deployment data. This problem arises frequently in high stakes settings such as public health and social work where data is often collected using self-reported surveys which are highly sensitive to e.g., the framing of the questions, the time when and place where the survey is conducted, and the level of comfort the interviewee has in sharing information with the interviewer. We propose a method for learning optimal robust classification trees based on mixed-integer robust optimization technology. In particular, we demonstrate that the problem of learning an optimal robust tree can be cast as a single-stage mixed-integer robust optimization problem with a highly nonlinear and discontinuous objective. We reformulate this problem equivalently as a two-stage linear robust optimization problem for which we devise a tailored solution procedure based on constraint generation. We evaluate the performance of our approach on numerous publicly available datasets, and compare the performance to a regularized, non-robust optimal tree. We show an increase of up to 12.48% in worst-case accuracy and of up to 4.85% in average-case accuracy across several datasets and distribution shifts from using our robust solution in comparison to the non-robust one. ",
    "url": "https://arxiv.org/abs/2310.17772",
    "authors": [
      "Nathan Justin",
      "Sina Aghaei",
      "Andr\u00e9s G\u00f3mez",
      "Phebe Vayanos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.17773",
    "title": "Graph Convolutional Networks for Complex Traffic Scenario Classification",
    "abstract": "A scenario-based testing approach can reduce the time required to obtain statistically significant evidence of the safety of Automated Driving Systems (ADS). Identifying these scenarios in an automated manner is a challenging task. Most methods on scenario classification do not work for complex scenarios with diverse environments (highways, urban) and interaction with other traffic agents. This is mirrored in their approaches which model an individual vehicle in relation to its environment, but neglect the interaction between multiple vehicles (e.g. cut-ins, stationary lead vehicle). Furthermore, existing datasets lack diversity and do not have per-frame annotations to accurately learn the start and end time of a scenario. We propose a method for complex traffic scenario classification that is able to model the interaction of a vehicle with the environment, as well as other agents. We use Graph Convolutional Networks to model spatial and temporal aspects of these scenarios. Expanding the nuScenes and Argoverse 2 driving datasets, we introduce a scenario-labeled dataset, which covers different driving environments and is annotated per frame. Training our method on this dataset, we present a promising baseline for future research on per-frame complex scenario classification. ",
    "url": "https://arxiv.org/abs/2310.17773",
    "authors": [
      "Tobias Hoek",
      "Holger Caesar",
      "Andreas Falkov\u00e9n",
      "Tommy Johansson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2310.17790",
    "title": "Neural Stress Fields for Reduced-order Elastoplasticity and Fracture",
    "abstract": "We propose a hybrid neural network and physics framework for reduced-order modeling of elastoplasticity and fracture. State-of-the-art scientific computing models like the Material Point Method (MPM) faithfully simulate large-deformation elastoplasticity and fracture mechanics. However, their long runtime and large memory consumption render them unsuitable for applications constrained by computation time and memory usage, e.g., virtual reality. To overcome these barriers, we propose a reduced-order framework. Our key innovation is training a low-dimensional manifold for the Kirchhoff stress field via an implicit neural representation. This low-dimensional neural stress field (NSF) enables efficient evaluations of stress values and, correspondingly, internal forces at arbitrary spatial locations. In addition, we also train neural deformation and affine fields to build low-dimensional manifolds for the deformation and affine momentum fields. These neural stress, deformation, and affine fields share the same low-dimensional latent space, which uniquely embeds the high-dimensional simulation state. After training, we run new simulations by evolving in this single latent space, which drastically reduces the computation time and memory consumption. Our general continuum-mechanics-based reduced-order framework is applicable to any phenomena governed by the elastodynamics equation. To showcase the versatility of our framework, we simulate a wide range of material behaviors, including elastica, sand, metal, non-Newtonian fluids, fracture, contact, and collision. We demonstrate dimension reduction by up to 100,000X and time savings by up to 10X. ",
    "url": "https://arxiv.org/abs/2310.17790",
    "authors": [
      "Zeshun Zong",
      "Xuan Li",
      "Minchen Li",
      "Maurizio M. Chiaramonte",
      "Wojciech Matusik",
      "Eitan Grinspun",
      "Kevin Carlberg",
      "Chenfanfu Jiang",
      "Peter Yichen Chen"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.17793",
    "title": "\"You Are An Expert Linguistic Annotator\": Limits of LLMs as Analyzers of  Abstract Meaning Representation",
    "abstract": "Large language models (LLMs) show amazing proficiency and fluency in the use of language. Does this mean that they have also acquired insightful linguistic knowledge about the language, to an extent that they can serve as an \"expert linguistic annotator\"? In this paper, we examine the successes and limitations of the GPT-3, ChatGPT, and GPT-4 models in analysis of sentence meaning structure, focusing on the Abstract Meaning Representation (AMR; Banarescu et al. 2013) parsing formalism, which provides rich graphical representations of sentence meaning structure while abstracting away from surface forms. We compare models' analysis of this semantic structure across two settings: 1) direct production of AMR parses based on zero- and few-shot prompts, and 2) indirect partial reconstruction of AMR via metalinguistic natural language queries (e.g., \"Identify the primary event of this sentence, and the predicate corresponding to that event.\"). Across these settings, we find that models can reliably reproduce the basic format of AMR, and can often capture core event, argument, and modifier structure -- however, model outputs are prone to frequent and major errors, and holistic analysis of parse acceptability shows that even with few-shot demonstrations, models have virtually 0% success in producing fully accurate parses. Eliciting natural language responses produces similar patterns of errors. Overall, our findings indicate that these models out-of-the-box can capture aspects of semantic structure, but there remain key limitations in their ability to support fully accurate semantic analyses or parses. ",
    "url": "https://arxiv.org/abs/2310.17793",
    "authors": [
      "Allyson Ettinger",
      "Jena D. Hwang",
      "Valentina Pyatkin",
      "Chandra Bhagavatula",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.17796",
    "title": "ControlLLM: Augment Language Models with Tools by Searching on Graphs",
    "abstract": "We present ControlLLM, a novel framework that enables large language models (LLMs) to utilize multi-modal tools for solving complex real-world tasks. Despite the remarkable performance of LLMs, they still struggle with tool invocation due to ambiguous user prompts, inaccurate tool selection and parameterization, and inefficient tool scheduling. To overcome these challenges, our framework comprises three key components: (1) a \\textit{task decomposer} that breaks down a complex task into clear subtasks with well-defined inputs and outputs; (2) a \\textit{Thoughts-on-Graph (ToG) paradigm} that searches the optimal solution path on a pre-built tool graph, which specifies the parameter and dependency relations among different tools; and (3) an \\textit{execution engine with a rich toolbox} that interprets the solution path and runs the tools efficiently on different computational devices. We evaluate our framework on diverse tasks involving image, audio, and video processing, demonstrating its superior accuracy, efficiency, and versatility compared to existing methods. ",
    "url": "https://arxiv.org/abs/2310.17796",
    "authors": [
      "Zhaoyang Liu",
      "Zeqiang Lai",
      "Zhangwei Gao",
      "Erfei Cui",
      "Xizhou Zhu",
      "Lewei Lu",
      "Qifeng Chen",
      "Yu Qiao",
      "Jifeng Dai",
      "Wenhai Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2310.17801",
    "title": "Image Prior and Posterior Conditional Probability Representation for  Efficient Damage Assessment",
    "abstract": "It is important to quantify Damage Assessment (DA) for Human Assistance and Disaster Response (HADR) applications. In this paper, to achieve efficient and scalable DA in HADR, an image prior and posterior conditional probability (IP2CP) is developed as an effective computational imaging representation. Equipped with the IP2CP representation, the matching pre- and post-disaster images are effectively encoded into one image that is then processed using deep learning approaches to determine the damage levels. Two scenarios of crucial importance for the practical use of DA in HADR applications are examined: pixel-wise semantic segmentation and patch-based contrastive learning-based global damage classification. Results achieved by IP2CP in both scenarios demonstrate promising performances, showing that our IP2CP-based methods within the deep learning framework can effectively achieve data and computational efficiency, which is of utmost importance for the DA in HADR applications. ",
    "url": "https://arxiv.org/abs/2310.17801",
    "authors": [
      "Jie Wei",
      "Weicong Feng",
      "Erik Blasch",
      "Erika Ardiles-Cruz",
      "Haibin Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.17805",
    "title": "Reward Scale Robustness for Proximal Policy Optimization via DreamerV3  Tricks",
    "abstract": "Most reinforcement learning methods rely heavily on dense, well-normalized environment rewards. DreamerV3 recently introduced a model-based method with a number of tricks that mitigate these limitations, achieving state-of-the-art on a wide range of benchmarks with a single set of hyperparameters. This result sparked discussion about the generality of the tricks, since they appear to be applicable to other reinforcement learning algorithms. Our work applies DreamerV3's tricks to PPO and is the first such empirical study outside of the original work. Surprisingly, we find that the tricks presented do not transfer as general improvements to PPO. We use a high quality PPO reference implementation and present extensive ablation studies totaling over 10,000 A100 hours on the Arcade Learning Environment and the DeepMind Control Suite. Though our experiments demonstrate that these tricks do not generally outperform PPO, we identify cases where they succeed and offer insight into the relationship between the implementation tricks. In particular, PPO with these tricks performs comparably to PPO on Atari games with reward clipping and significantly outperforms PPO without reward clipping. ",
    "url": "https://arxiv.org/abs/2310.17805",
    "authors": [
      "Ryan Sullivan",
      "Akarsh Kumar",
      "Shengyi Huang",
      "John P. Dickerson",
      "Joseph Suarez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.17807",
    "title": "Clover: Closed-Loop Verifiable Code Generation",
    "abstract": "The use of large language models for code generation is a rapidly growing trend in software development. However, without effective methods for ensuring the correctness of generated code, this trend could lead to any number of undesirable outcomes. In this paper, we lay out a vision for addressing this challenge: the Clover paradigm, short for Closed-Loop Verifiable Code Generation, which reduces correctness checking to the more accessible problem of consistency checking. At the core of Clover lies a checker that performs consistency checks among code, docstrings, and formal annotations. The checker is implemented using a novel integration of formal verification tools and large language models. We provide a theoretical analysis to support our thesis that Clover should be effective at consistency checking. We also empirically investigate its feasibility on a hand-designed dataset (CloverBench) featuring annotated Dafny programs at a textbook level of difficulty. Experimental results show that for this dataset, (i) LLMs are reasonably successful at automatically generating formal specifications; and (ii) our consistency checker achieves a promising acceptance rate (up to 87%) for correct instances while maintaining zero tolerance for incorrect ones (no false positives). ",
    "url": "https://arxiv.org/abs/2310.17807",
    "authors": [
      "Chuyue Sun",
      "Ying Sheng",
      "Oded Padon",
      "Clark Barrett"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.17842",
    "title": "What You See Is What You Detect: Towards better Object Densification in  3D detection",
    "abstract": "Recent works have demonstrated the importance of object completion in 3D Perception from Lidar signal. Several methods have been proposed in which modules were used to densify the point clouds produced by laser scanners, leading to better recall and more accurate results. Pursuing in that direction, we present, in this work, a counter-intuitive perspective: the widely-used full-shape completion approach actually leads to a higher error-upper bound especially for far away objects and small objects like pedestrians. Based on this observation, we introduce a visible part completion method that requires only 11.3\\% of the prediction points that previous methods generate. To recover the dense representation, we propose a mesh-deformation-based method to augment the point set associated with visible foreground objects. Considering that our approach focuses only on the visible part of the foreground objects to achieve accurate 3D detection, we named our method What You See Is What You Detect (WYSIWYD). Our proposed method is thus a detector-independent model that consists of 2 parts: an Intra-Frustum Segmentation Transformer (IFST) and a Mesh Depth Completion Network(MDCNet) that predicts the foreground depth from mesh deformation. This way, our model does not require the time-consuming full-depth completion task used by most pseudo-lidar-based methods. Our experimental evaluation shows that our approach can provide up to 12.2\\% performance improvements over most of the public baseline models on the KITTI and NuScenes dataset bringing the state-of-the-art to a new level. The codes will be available at \\textcolor[RGB]{0,0,255}{\\url{{https://github.com/Orbis36/WYSIWYD}} ",
    "url": "https://arxiv.org/abs/2310.17842",
    "authors": [
      "Tianran Liu",
      "Zeping Zhang Morteza Mousa Pasandi",
      "Robert Laganiere"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.17852",
    "title": "Function Space Bayesian Pseudocoreset for Bayesian Neural Networks",
    "abstract": "A Bayesian pseudocoreset is a compact synthetic dataset summarizing essential information of a large-scale dataset and thus can be used as a proxy dataset for scalable Bayesian inference. Typically, a Bayesian pseudocoreset is constructed by minimizing a divergence measure between the posterior conditioning on the pseudocoreset and the posterior conditioning on the full dataset. However, evaluating the divergence can be challenging, particularly for the models like deep neural networks having high-dimensional parameters. In this paper, we propose a novel Bayesian pseudocoreset construction method that operates on a function space. Unlike previous methods, which construct and match the coreset and full data posteriors in the space of model parameters (weights), our method constructs variational approximations to the coreset posterior on a function space and matches it to the full data posterior in the function space. By working directly on the function space, our method could bypass several challenges that may arise when working on a weight space, including limited scalability and multi-modality issue. Through various experiments, we demonstrate that the Bayesian pseudocoresets constructed from our method enjoys enhanced uncertainty quantification and better robustness across various model architectures. ",
    "url": "https://arxiv.org/abs/2310.17852",
    "authors": [
      "Balhae Kim",
      "Hyungi Lee",
      "Juho Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.17869",
    "title": "Grid Jigsaw Representation with CLIP: A New Perspective on Image  Clustering",
    "abstract": "Unsupervised representation learning for image clustering is essential in computer vision. Although the advancement of visual models has improved image clustering with efficient visual representations, challenges still remain. Firstly, these features often lack the ability to represent the internal structure of images, hindering the accurate clustering of visually similar images. Secondly, the existing features tend to lack finer-grained semantic labels, limiting the ability to capture nuanced differences and similarities between images. In this paper, we first introduce Jigsaw based strategy method for image clustering called Grid Jigsaw Representation (GJR) with systematic exposition from pixel to feature in discrepancy against human and computer. We emphasize that this algorithm, which mimics human jigsaw puzzle, can effectively improve the model to distinguish the spatial feature between different samples and enhance the clustering ability. GJR modules are appended to a variety of deep convolutional networks and tested with significant improvements on a wide range of benchmark datasets including CIFAR-10, CIFAR-100/20, STL-10, ImageNet-10 and ImageNetDog-15. On the other hand, convergence efficiency is always an important challenge for unsupervised image clustering. Recently, pretrained representation learning has made great progress and released models can extract mature visual representations. It is obvious that use the pretrained model as feature extractor can speed up the convergence of clustering where our aim is to provide new perspective in image clustering with reasonable resource application and provide new baseline. Further, we innovate pretrain-based Grid Jigsaw Representation (pGJR) with improvement by GJR. The experiment results show the effectiveness on the clustering task with respect to the ACC, NMI and ARI three metrics and super fast convergence speed. ",
    "url": "https://arxiv.org/abs/2310.17869",
    "authors": [
      "Zijie Song",
      "Zhenzhen Hu",
      "Richang Hong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.17880",
    "title": "Reconstructive Latent-Space Neural Radiance Fields for Efficient 3D  Scene Representations",
    "abstract": "Neural Radiance Fields (NeRFs) have proven to be powerful 3D representations, capable of high quality novel view synthesis of complex scenes. While NeRFs have been applied to graphics, vision, and robotics, problems with slow rendering speed and characteristic visual artifacts prevent adoption in many use cases. In this work, we investigate combining an autoencoder (AE) with a NeRF, in which latent features (instead of colours) are rendered and then convolutionally decoded. The resulting latent-space NeRF can produce novel views with higher quality than standard colour-space NeRFs, as the AE can correct certain visual artifacts, while rendering over three times faster. Our work is orthogonal to other techniques for improving NeRF efficiency. Further, we can control the tradeoff between efficiency and image quality by shrinking the AE architecture, achieving over 13 times faster rendering with only a small drop in performance. We hope that our approach can form the basis of an efficient, yet high-fidelity, 3D scene representation for downstream tasks, especially when retaining differentiability is useful, as in many robotics scenarios requiring continual learning. ",
    "url": "https://arxiv.org/abs/2310.17880",
    "authors": [
      "Tristan Aumentado-Armstrong",
      "Ashkan Mirzaei",
      "Marcus A. Brubaker",
      "Jonathan Kelly",
      "Alex Levinshtein",
      "Konstantinos G. Derpanis",
      "Igor Gilitschenski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.17884",
    "title": "Can LLMs Keep a Secret? Testing Privacy Implications of Language Models  via Contextual Integrity Theory",
    "abstract": "The interactive use of large language models (LLMs) in AI assistants (at work, home, etc.) introduces a new set of inference-time privacy risks: LLMs are fed different types of information from multiple sources in their inputs and are expected to reason about what to share in their outputs, for what purpose and with whom, within a given context. In this work, we draw attention to the highly critical yet overlooked notion of contextual privacy by proposing ConfAIde, a benchmark designed to identify critical weaknesses in the privacy reasoning capabilities of instruction-tuned LLMs. Our experiments show that even the most capable models such as GPT-4 and ChatGPT reveal private information in contexts that humans would not, 39% and 57% of the time, respectively. This leakage persists even when we employ privacy-inducing prompts or chain-of-thought reasoning. Our work underscores the immediate need to explore novel inference-time privacy-preserving approaches, based on reasoning and theory of mind. ",
    "url": "https://arxiv.org/abs/2310.17884",
    "authors": [
      "Niloofar Mireshghallah",
      "Hyunwoo Kim",
      "Xuhui Zhou",
      "Yulia Tsvetkov",
      "Maarten Sap",
      "Reza Shokri",
      "Yejin Choi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.17903",
    "title": "Pitfalls in Language Models for Code Intelligence: A Taxonomy and Survey",
    "abstract": "Modern language models (LMs) have been successfully employed in source code generation and understanding, leading to a significant increase in research focused on learning-based code intelligence, such as automated bug repair, and test case generation. Despite their great potential, language models for code intelligence (LM4Code) are susceptible to potential pitfalls, which hinder realistic performance and further impact their reliability and applicability in real-world deployment. Such challenges drive the need for a comprehensive understanding - not just identifying these issues but delving into their possible implications and existing solutions to build more reliable language models tailored to code intelligence. Based on a well-defined systematic research approach, we conducted an extensive literature review to uncover the pitfalls inherent in LM4Code. Finally, 67 primary studies from top-tier venues have been identified. After carefully examining these studies, we designed a taxonomy of pitfalls in LM4Code research and conducted a systematic study to summarize the issues, implications, current solutions, and challenges of different pitfalls for LM4Code systems. We developed a comprehensive classification scheme that dissects pitfalls across four crucial aspects: data collection and labeling, system design and learning, performance evaluation, and deployment and maintenance. Through this study, we aim to provide a roadmap for researchers and practitioners, facilitating their understanding and utilization of LM4Code in reliable and trustworthy ways. ",
    "url": "https://arxiv.org/abs/2310.17903",
    "authors": [
      "Xinyu She",
      "Yue Liu",
      "Yanjie Zhao",
      "Yiling He",
      "Li Li",
      "Chakkrit Tantithamthavorn",
      "Zhan Qin",
      "Haoyu Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.17931",
    "title": "Coded Caching Scheme for Partially Connected Linear Networks Via  Multi-antenna Placement Delivery Array",
    "abstract": "In this paper, we study the coded caching scheme for the $(K,L,M_{\\text{T}},M_{\\text{U}},N)$ partially connected linear network, where there are $N$ files each of which has an equal size, $K+L-1$ transmitters and $K$ users; each user and transmitter caches at most $M_{\\text{U}}$ and $M_{\\text{T}}$ files respectively; each user cyclically communicates with $L$ transmitters. The goal is to design caching and delivery schemes to reduce the transmission latency measured by the metric normalized delivery time (NDT). By delicately designing the data placement of the transmitters and users according to the topology, we show that a combinatorial structure called multiple-antenna placement delivery array (MAPDA), which was originally proposed for the multiple-input single-output broadcast channels, can be also used to design schemes for the partially connected linear network. Then, based on existing MAPDAs and our constructing approach, we propose new schemes that achieve the optimal NDT when $ {M_\\text{T}}+ {M_\\text{U}}\\geq N$ and smaller NDT than that of the existing schemes when (${M_\\text{T}}+ {M_\\text{U}}\\leq N$, $\\frac{M_\\text{U}}{N}+\\frac{M_\\text{T}}{N} \\frac{L}{K}\\left\\lceil \\frac{K}{L} \\right\\rceil \\geq 1$) or ($ {M_\\text{U}}+ {M_\\text{T}}< N, \\frac{K}{L}\\notin\\mathbb{Z}^+$). Moreover, our schemes operate in one-shot linear delivery and significantly reduce the subpacketizations compared to the existing scheme, which implies that our schemes have a wider range of applications and lower complexity of implementation. ",
    "url": "https://arxiv.org/abs/2310.17931",
    "authors": [
      "Minquan Cheng",
      "Yun Xie",
      "Zhenhao Huang",
      "Mingming Zhang",
      "Youlong Wu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2310.17949",
    "title": "Instance Segmentation under Occlusions via Location-aware Copy-Paste  Data Augmentation",
    "abstract": "Occlusion is a long-standing problem in computer vision, particularly in instance segmentation. ACM MMSports 2023 DeepSportRadar has introduced a dataset that focuses on segmenting human subjects within a basketball context and a specialized evaluation metric for occlusion scenarios. Given the modest size of the dataset and the highly deformable nature of the objects to be segmented, this challenge demands the application of robust data augmentation techniques and wisely-chosen deep learning architectures. Our work (ranked 1st in the competition) first proposes a novel data augmentation technique, capable of generating more training samples with wider distribution. Then, we adopt a new architecture - Hybrid Task Cascade (HTC) framework with CBNetV2 as backbone and MaskIoU head to improve segmentation performance. Furthermore, we employ a Stochastic Weight Averaging (SWA) training strategy to improve the model's generalization. As a result, we achieve a remarkable occlusion score (OM) of 0.533 on the challenge dataset, securing the top-1 position on the leaderboard. Source code is available at this https://github.com/nguyendinhson-kaist/MMSports23-Seg-AutoID. ",
    "url": "https://arxiv.org/abs/2310.17949",
    "authors": [
      "Son Nguyen",
      "Mikel Lainsa",
      "Hung Dao",
      "Daeyoung Kim",
      "Giang Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.17952",
    "title": "Shape-centered Representation Learning for Visible-Infrared Person  Re-identification",
    "abstract": "Current Visible-Infrared Person Re-Identification (VI-ReID) methods prioritize extracting distinguishing appearance features, ignoring the natural resistance of body shape against modality changes. Initially, we gauged the discriminative potential of shapes by a straightforward concatenation of shape and appearance features. However, two unresolved issues persist in the utilization of shape features. One pertains to the dependence on auxiliary models for shape feature extraction in the inference phase, along with the errors in generated infrared shapes due to the intrinsic modality disparity. The other issue involves the inadequately explored correlation between shape and appearance features. To tackle the aforementioned challenges, we propose the Shape-centered Representation Learning framework (ScRL), which focuses on learning shape features and appearance features associated with shapes. Specifically, we devise the Shape Feature Propagation (SFP), facilitating direct extraction of shape features from original images with minimal complexity costs during inference. To restitute inaccuracies in infrared body shapes at the feature level, we present the Infrared Shape Restitution (ISR). Furthermore, to acquire appearance features related to shape, we design the Appearance Feature Enhancement (AFE), which accentuates identity-related features while suppressing identity-unrelated features guided by shape features. Extensive experiments are conducted to validate the effectiveness of the proposed ScRL. Achieving remarkable results, the Rank-1 (mAP) accuracy attains 76.1%, 71.2%, 92.4% (72.6%, 52.9%, 86.7%) on the SYSU-MM01, HITSZ-VCM, RegDB datasets respectively, outperforming existing state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2310.17952",
    "authors": [
      "Shuang Li",
      "Jiaxu Leng",
      "Ji Gan",
      "Mengjingcheng Mo",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.17974",
    "title": "FaultSeg Swin-UNETR: Transformer-Based Self-Supervised Pretraining Model  for Fault Recognition",
    "abstract": "This paper introduces an approach to enhance seismic fault recognition through self-supervised pretraining. Seismic fault interpretation holds great significance in the fields of geophysics and geology. However, conventional methods for seismic fault recognition encounter various issues, including dependence on data quality and quantity, as well as susceptibility to interpreter subjectivity. Currently, automated fault recognition methods proposed based on small synthetic datasets experience performance degradation when applied to actual seismic data. To address these challenges, we have introduced the concept of self-supervised learning, utilizing a substantial amount of relatively easily obtainable unlabeled seismic data for pretraining. Specifically, we have employed the Swin Transformer model as the core network and employed the SimMIM pretraining task to capture unique features related to discontinuities in seismic data. During the fine-tuning phase, inspired by edge detection techniques, we have also refined the structure of the Swin-UNETR model, enabling multiscale decoding and fusion for more effective fault detection. Experimental results demonstrate that our proposed method attains state-of-the-art performance on the Thebe dataset, as measured by the OIS and ODS metrics. ",
    "url": "https://arxiv.org/abs/2310.17974",
    "authors": [
      "Zeren Zhang",
      "Ran Chen",
      "Jinwen Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.18068",
    "title": "Simple and Robust Dynamic Two-Dimensional Convex Hull",
    "abstract": "The convex hull of a data set $P$ is the smallest convex set that contains $P$. In this work, we present a new data structure for convex hull, that allows for efficient dynamic updates. In a dynamic convex hull implementation, the following traits are desirable: (1) algorithms for efficiently answering queries as to whether a specified point is inside or outside the hull, (2) adhering to geometric robustness, and (3) algorithmic simplicity.Furthermore, a specific but well-motivated type of two-dimensional data is rank-based data. Here, the input is a set of real-valued numbers $Y$ where for any number $y\\in Y$ its rank is its index in $Y$'s sorted order. Each value in $Y$ can be mapped to a point $(rank, value)$ to obtain a two-dimensional point set. In this work, we give an efficient, geometrically robust, dynamic convex hull algorithm, that facilitates queries to whether a point is internal. Furthermore, our construction can be used to efficiently update the convex hull of rank-ordered data, when the real-valued point set is subject to insertions and deletions. Our improved solution is based on an algorithmic simplification of the classical convex hull data structure by Overmars and van Leeuwen~[STOC'80], combined with new algorithmic insights. Our theoretical guarantees on the update time match those of Overmars and van Leeuwen, namely $O(\\log^2 |P|)$, while we allow a wider range of functionalities (including rank-based data). Our algorithmic simplification includes simplifying an 11-case check down to a 3-case check that can be written in 20 lines of easily readable C-code. We extend our solution to provide a trade-off between theoretical guarantees and the practical performance of our algorithm. We test and compare our solutions extensively on inputs that were generated randomly or adversarially, including benchmarking datasets from the literature. ",
    "url": "https://arxiv.org/abs/2310.18068",
    "authors": [
      "Emil Toftegaard G\u00e6de",
      "Inge Li G\u00f8rtz",
      "Ivor van der Hoog",
      "Christoffer Krogh",
      "Eva Rotenberg"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2310.18073",
    "title": "A Scalable Framework for Table of Contents Extraction from Complex ESG  Annual Reports",
    "abstract": "Table of contents (ToC) extraction centres on structuring documents in a hierarchical manner. In this paper, we propose a new dataset, ESGDoc, comprising 1,093 ESG annual reports from 563 companies spanning from 2001 to 2022. These reports pose significant challenges due to their diverse structures and extensive length. To address these challenges, we propose a new framework for Toc extraction, consisting of three steps: (1) Constructing an initial tree of text blocks based on reading order and font sizes; (2) Modelling each tree node (or text block) independently by considering its contextual information captured in node-centric subtree; (3) Modifying the original tree by taking appropriate action on each tree node (Keep, Delete, or Move). This construction-modelling-modification (CMM) process offers several benefits. It eliminates the need for pairwise modelling of section headings as in previous approaches, making document segmentation practically feasible. By incorporating structured information, each section heading can leverage both local and long-distance context relevant to itself. Experimental results show that our approach outperforms the previous state-of-the-art baseline with a fraction of running time. Our framework proves its scalability by effectively handling documents of any length. ",
    "url": "https://arxiv.org/abs/2310.18073",
    "authors": [
      "Xinyu Wang",
      "Lin Gui",
      "Yulan He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.18080",
    "title": "Unveiling the Potential of Probabilistic Embeddings in Self-Supervised  Learning",
    "abstract": "In recent years, self-supervised learning has played a pivotal role in advancing machine learning by allowing models to acquire meaningful representations from unlabeled data. An intriguing research avenue involves developing self-supervised models within an information-theoretic framework, but many studies often deviate from the stochasticity assumptions made when deriving their objectives. To gain deeper insights into this issue, we propose to explicitly model the representation with stochastic embeddings and assess their effects on performance, information compression and potential for out-of-distribution detection. From an information-theoretic perspective, we seek to investigate the impact of probabilistic modeling on the information bottleneck, shedding light on a trade-off between compression and preservation of information in both representation and loss space. Emphasizing the importance of distinguishing between these two spaces, we demonstrate how constraining one can affect the other, potentially leading to performance degradation. Moreover, our findings suggest that introducing an additional bottleneck in the loss space can significantly enhance the ability to detect out-of-distribution examples, only leveraging either representation features or the variance of their underlying distribution. ",
    "url": "https://arxiv.org/abs/2310.18080",
    "authors": [
      "Denis Janiak",
      "Jakub Binkowski",
      "Piotr Bielak",
      "Tomasz Kajdanowicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18091",
    "title": "Adversarial Anomaly Detection using Gaussian Priors and Nonlinear  Anomaly Scores",
    "abstract": "Anomaly detection in imbalanced datasets is a frequent and crucial problem, especially in the medical domain where retrieving and labeling irregularities is often expensive. By combining the generative stability of a $\\beta$-variational autoencoder (VAE) with the discriminative strengths of generative adversarial networks (GANs), we propose a novel model, $\\beta$-VAEGAN. We investigate methods for composing anomaly scores based on the discriminative and reconstructive capabilities of our model. Existing work focuses on linear combinations of these components to determine if data is anomalous. We advance existing work by training a kernelized support vector machine (SVM) on the respective error components to also consider nonlinear relationships. This improves anomaly detection performance, while allowing faster optimization. Lastly, we use the deviations from the Gaussian prior of $\\beta$-VAEGAN to form a novel anomaly score component. In comparison to state-of-the-art work, we improve the $F_1$ score during anomaly detection from 0.85 to 0.92 on the widely used MITBIH Arrhythmia Database. ",
    "url": "https://arxiv.org/abs/2310.18091",
    "authors": [
      "Fiete L\u00fcer",
      "Tobias Weber",
      "Maxim Dolgich",
      "Christian B\u00f6hm"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.18098",
    "title": "Mind the Gap: Automated Corpus Creation for Enthymeme Detection and  Reconstruction in Learner Arguments",
    "abstract": "Writing strong arguments can be challenging for learners. It requires to select and arrange multiple argumentative discourse units (ADUs) in a logical and coherent way as well as to decide which ADUs to leave implicit, so called enthymemes. However, when important ADUs are missing, readers might not be able to follow the reasoning or understand the argument's main point. This paper introduces two new tasks for learner arguments: to identify gaps in arguments (enthymeme detection) and to fill such gaps (enthymeme reconstruction). Approaches to both tasks may help learners improve their argument quality. We study how corpora for these tasks can be created automatically by deleting ADUs from an argumentative text that are central to the argument and its quality, while maintaining the text's naturalness. Based on the ICLEv3 corpus of argumentative learner essays, we create 40,089 argument instances for enthymeme detection and reconstruction. Through manual studies, we provide evidence that the proposed corpus creation process leads to the desired quality reduction, and results in arguments that are similarly natural to those written by learners. Finally, first baseline approaches to enthymeme detection and reconstruction demonstrate the corpus' usefulness. ",
    "url": "https://arxiv.org/abs/2310.18098",
    "authors": [
      "Maja Stahl",
      "Nick D\u00fcsterhus",
      "Mei-Hua Chen",
      "Henning Wachsmuth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.18104",
    "title": "Classifier-head Informed Feature Masking and Prototype-based Logit  Smoothing for Out-of-Distribution Detection",
    "abstract": "Out-of-distribution (OOD) detection is essential when deploying neural networks in the real world. One main challenge is that neural networks often make overconfident predictions on OOD data. In this study, we propose an effective post-hoc OOD detection method based on a new feature masking strategy and a novel logit smoothing strategy. Feature masking determines the important features at the penultimate layer for each in-distribution (ID) class based on the weights of the ID class in the classifier head and masks the rest features. Logit smoothing computes the cosine similarity between the feature vector of the test sample and the prototype of the predicted ID class at the penultimate layer and uses the similarity as an adaptive temperature factor on the logit to alleviate the network's overconfidence prediction for OOD data. With these strategies, we can reduce feature activation of OOD data and enlarge the gap in OOD score between ID and OOD data. Extensive experiments on multiple standard OOD detection benchmarks demonstrate the effectiveness of our method and its compatibility with existing methods, with new state-of-the-art performance achieved from our method. The source code will be released publicly. ",
    "url": "https://arxiv.org/abs/2310.18104",
    "authors": [
      "Zhuohao Sun",
      "Yiqiao Qiu",
      "Zhijun Tan",
      "Weishi Zheng",
      "Ruixuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18123",
    "title": "Sample Complexity Bounds for Score-Matching: Causal Discovery and  Generative Modeling",
    "abstract": "This paper provides statistical sample complexity bounds for score-matching and its applications in causal discovery. We demonstrate that accurate estimation of the score function is achievable by training a standard deep ReLU neural network using stochastic gradient descent. We establish bounds on the error rate of recovering causal relationships using the score-matching-based causal discovery method of Rolland et al. [2022], assuming a sufficiently good estimation of the score function. Finally, we analyze the upper bound of score-matching estimation within the score-based generative modeling, which has been applied for causal discovery but is also of independent interest within the domain of generative models. ",
    "url": "https://arxiv.org/abs/2310.18123",
    "authors": [
      "Zhenyu Zhu",
      "Francesco Locatello",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.18141",
    "title": "Unsupervised Representation Learning for Diverse Deformable Shape  Collections",
    "abstract": "We introduce a novel learning-based method for encoding and manipulating 3D surface meshes. Our method is specifically designed to create an interpretable embedding space for deformable shape collections. Unlike previous 3D mesh autoencoders that require meshes to be in a 1-to-1 correspondence, our approach is trained on diverse meshes in an unsupervised manner. Central to our method is a spectral pooling technique that establishes a universal latent space, breaking free from traditional constraints of mesh connectivity and shape categories. The entire process consists of two stages. In the first stage, we employ the functional map paradigm to extract point-to-point (p2p) maps between a collection of shapes in an unsupervised manner. These p2p maps are then utilized to construct a common latent space, which ensures straightforward interpretation and independence from mesh connectivity and shape category. Through extensive experiments, we demonstrate that our method achieves excellent reconstructions and produces more realistic and smoother interpolations than baseline approaches. ",
    "url": "https://arxiv.org/abs/2310.18141",
    "authors": [
      "Sara Hahner",
      "Souhaib Attaiki",
      "Jochen Garcke",
      "Maks Ovsjanikov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18149",
    "title": "Game of arrivals at a two queue network with heterogeneous customer  routes",
    "abstract": "We consider a queuing network that opens at a specified time, where customers are non-atomic and belong to different classes. Each class has its own route, and as is typical in the literature, the costs are a linear function of waiting and service completion time. We restrict ourselves to a two class, two queue network: this simplification is well motivated as the diversity in solution structure as a function of problem parameters is substantial even in this simple setting (e.g., a specific routing structure involves eight different regimes), suggesting a combinatorial blow up as the number of queues, routes and customer classes increase. We identify the unique Nash equilibrium customer arrival profile when the customer linear cost preferences are different. This profile is a function of problem parameters including the size of each class, service rates at each queue, and customer cost preferences. When customer cost preferences match, under certain parametric settings, the equilibrium arrival profiles may not be unique and may lie in a convex set. We further make a surprising observation that in some parametric settings, customers in one class may arrive in disjoint intervals. Further, the two classes may arrive in contiguous intervals or in overlapping intervals, and at varying rates within an interval, depending upon the problem parameters. ",
    "url": "https://arxiv.org/abs/2310.18149",
    "authors": [
      "Agniv Bandyopadhyay",
      "Sandeep Juneja"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2310.18152",
    "title": "Disentangled Representation Learning with Large Language Models for  Text-Attributed Graphs",
    "abstract": "Text-attributed graphs (TAGs) are prevalent on the web and research over TAGs such as citation networks, e-commerce networks and social networks has attracted considerable attention in the web community. Recently, large language models (LLMs) have demonstrated exceptional capabilities across a wide range of tasks. However, the existing works focus on harnessing the potential of LLMs solely relying on prompts to convey graph structure information to LLMs, thus suffering from insufficient understanding of the complex structural relationships within TAGs. To address this problem, in this paper we present the Disentangled Graph-Text Learner (DGTL) model, which is able to enhance the reasoning and predicting capabilities of LLMs for TAGs. Our proposed DGTL model incorporates graph structure information through tailored disentangled graph neural network (GNN) layers, enabling LLMs to capture the intricate relationships hidden in text-attributed graphs from multiple structural factors. Furthermore, DGTL operates with frozen pre-trained LLMs, reducing computational costs and allowing much more flexibility in combining with different LLM models. Experimental evaluations demonstrate the effectiveness of the proposed DGTL model on achieving superior or comparable performance over state-of-the-art baselines. Additionally, we also demonstrate that our DGTL model can offer natural language explanations for predictions, thereby significantly enhancing model interpretability. ",
    "url": "https://arxiv.org/abs/2310.18152",
    "authors": [
      "Yijian Qin",
      "Xin Wang",
      "Ziwei Zhang",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18159",
    "title": "DESiRED -- Dynamic, Enhanced, and Smart iRED: A P4-AQM with Deep  Reinforcement Learning and In-band Network Telemetry",
    "abstract": "Active Queue Management (AQM) is a mechanism employed to alleviate transient congestion in network device buffers, such as routers and switches. Traditional AQM algorithms use fixed thresholds, like target delay or queue occupancy, to compute random packet drop probabilities. A very small target delay can increase packet losses and reduce link utilization, while a large target delay may increase queueing delays while lowering drop probability. Due to dynamic network traffic characteristics, where traffic fluctuations can lead to significant queue variations, maintaining a fixed threshold AQM may not suit all applications. Consequently, we explore the question: \\textit{What is the ideal threshold (target delay) for AQMs?} In this work, we introduce DESiRED (Dynamic, Enhanced, and Smart iRED), a P4-based AQM that leverages precise network feedback from In-band Network Telemetry (INT) to feed a Deep Reinforcement Learning (DRL) model. This model dynamically adjusts the target delay based on rewards that maximize application Quality of Service (QoS). We evaluate DESiRED in a realistic P4-based test environment running an MPEG-DASH service. Our findings demonstrate up to a 90x reduction in video stall and a 42x increase in high-resolution video playback quality when the target delay is adjusted dynamically by DESiRED. ",
    "url": "https://arxiv.org/abs/2310.18159",
    "authors": [
      "Leandro C. de Almeida",
      "Washington Rodrigo Dias da Silva",
      "Thiago C. Tavares",
      "Rafael Pasquini",
      "Chrysa Papagianni",
      "F\u00e1bio L. Verdi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.18162",
    "title": "Proportional Fairness in Clustering: A Social Choice Perspective",
    "abstract": "We study the proportional clustering problem of Chen et al. [ICML'19] and relate it to the area of multiwinner voting in computational social choice. We show that any clustering satisfying a weak proportionality notion of Brill and Peters [EC'23] simultaneously obtains the best known approximations to the proportional fairness notion of Chen et al. [ICML'19], but also to individual fairness [Jung et al., FORC'20] and the \"core\" [Li et al. ICML'21]. In fact, we show that any approximation to proportional fairness is also an approximation to individual fairness and vice versa. Finally, we also study stronger notions of proportional representation, in which deviations do not only happen to single, but multiple candidate centers, and show that stronger proportionality notions of Brill and Peters [EC'23] imply approximations to these stronger guarantees. ",
    "url": "https://arxiv.org/abs/2310.18162",
    "authors": [
      "Leon Kellerhals",
      "Jannik Peters"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2310.18165",
    "title": "Enhancing Enterprise Network Security: Comparing Machine-Level and  Process-Level Analysis for Dynamic Malware Detection",
    "abstract": "Analysing malware is important to understand how malicious software works and to develop appropriate detection and prevention methods. Dynamic analysis can overcome evasion techniques commonly used to bypass static analysis and provide insights into malware runtime activities. Much research on dynamic analysis focused on investigating machine-level information (e.g., CPU, memory, network usage) to identify whether a machine is running malicious activities. A malicious machine does not necessarily mean all running processes on the machine are also malicious. If we can isolate the malicious process instead of isolating the whole machine, we could kill the malicious process, and the machine can keep doing its job. Another challenge dynamic malware detection research faces is that the samples are executed in one machine without any background applications running. It is unrealistic as a computer typically runs many benign (background) applications when a malware incident happens. Our experiment with machine-level data shows that the existence of background applications decreases previous state-of-the-art accuracy by about 20.12% on average. We also proposed a process-level Recurrent Neural Network (RNN)-based detection model. Our proposed model performs better than the machine-level detection model; 0.049 increase in detection rate and a false-positive rate below 0.1. ",
    "url": "https://arxiv.org/abs/2310.18165",
    "authors": [
      "Baskoro Adi Pratomo",
      "Toby Jackson",
      "Pete Burnap",
      "Andrew Hood",
      "Eirini Anthi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18205",
    "title": "Lost in Translation, Found in Spans: Identifying Claims in Multilingual  Social Media",
    "abstract": "Claim span identification (CSI) is an important step in fact-checking pipelines, aiming to identify text segments that contain a checkworthy claim or assertion in a social media post. Despite its importance to journalists and human fact-checkers, it remains a severely understudied problem, and the scarce research on this topic so far has only focused on English. Here we aim to bridge this gap by creating a novel dataset, X-CLAIM, consisting of 7K real-world claims collected from numerous social media platforms in five Indian languages and English. We report strong baselines with state-of-the-art encoder-only language models (e.g., XLM-R) and we demonstrate the benefits of training on multiple languages over alternative cross-lingual transfer methods such as zero-shot transfer, or training on translated data, from a high-resource language such as English. We evaluate generative large language models from the GPT series using prompting methods on the X-CLAIM dataset and we find that they underperform the smaller encoder-only language models for low-resource languages. ",
    "url": "https://arxiv.org/abs/2310.18205",
    "authors": [
      "Shubham Mittal",
      "Megha Sundriyal",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.18209",
    "title": "Alignment and Outer Shell Isotropy for Hyperbolic Graph Contrastive  Learning",
    "abstract": "Learning good self-supervised graph representations that are beneficial to downstream tasks is challenging. Among a variety of methods, contrastive learning enjoys competitive performance. The embeddings of contrastive learning are arranged on a hypersphere that enables the Cosine distance measurement in the Euclidean space. However, the underlying structure of many domains such as graphs exhibits highly non-Euclidean latent geometry. To this end, we propose a novel contrastive learning framework to learn high-quality graph embedding. Specifically, we design the alignment metric that effectively captures the hierarchical data-invariant information, as well as we propose a substitute of uniformity metric to prevent the so-called dimensional collapse. We show that in the hyperbolic space one has to address the leaf- and height-level uniformity which are related to properties of trees, whereas in the ambient space of the hyperbolic manifold, these notions translate into imposing an isotropic ring density towards boundaries of Poincar\\'e ball. This ring density can be easily imposed by promoting the isotropic feature distribution on the tangent space of manifold. In the experiments, we demonstrate the efficacy of our proposed method across different hyperbolic graph embedding techniques in both supervised and self-supervised learning settings. ",
    "url": "https://arxiv.org/abs/2310.18209",
    "authors": [
      "Yifei Zhang",
      "Hao Zhu",
      "Jiahong Liu",
      "Piotr Koniusz",
      "Irwin King"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.18212",
    "title": "Robustness of Algorithms for Causal Structure Learning to Hyperparameter  Choice",
    "abstract": "Hyperparameters play a critical role in machine learning. Hyperparameter tuning can make the difference between state-of-the-art and poor prediction performance for any algorithm, but it is particularly challenging for structure learning due to its unsupervised nature. As a result, hyperparameter tuning is often neglected in favour of using the default values provided by a particular implementation of an algorithm. While there have been numerous studies on performance evaluation of causal discovery algorithms, how hyperparameters affect individual algorithms, as well as the choice of the best algorithm for a specific problem, has not been studied in depth before. This work addresses this gap by investigating the influence of hyperparameters on causal structure learning tasks. Specifically, we perform an empirical evaluation of hyperparameter selection for some seminal learning algorithms on datasets of varying levels of complexity. We find that, while the choice of algorithm remains crucial to obtaining state-of-the-art performance, hyperparameter selection in ensemble settings strongly influences the choice of algorithm, in that a poor choice of hyperparameters can lead to analysts using algorithms which do not give state-of-the-art performance for their data. ",
    "url": "https://arxiv.org/abs/2310.18212",
    "authors": [
      "Damian Machlanski",
      "Spyridon Samothrakis",
      "Paul Clarke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2310.18237",
    "title": "Generative AI Model for Artistic Style Transfer Using Convolutional  Neural Networks",
    "abstract": "Artistic style transfer, a captivating application of generative artificial intelligence, involves fusing the content of one image with the artistic style of another to create unique visual compositions. This paper presents a comprehensive overview of a novel technique for style transfer using Convolutional Neural Networks (CNNs). By leveraging deep image representations learned by CNNs, we demonstrate how to separate and manipulate image content and style, enabling the synthesis of high-quality images that combine content and style in a harmonious manner. We describe the methodology, including content and style representations, loss computation, and optimization, and showcase experimental results highlighting the effectiveness and versatility of the approach across different styles and content ",
    "url": "https://arxiv.org/abs/2310.18237",
    "authors": [
      "Jonayet Miah",
      "Duc M Cao",
      "Md Abu Sayed",
      "Md. Sabbirul Haque"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2310.18241",
    "title": "$\u03b1$-Mutual Information: A Tunable Privacy Measure for Privacy  Protection in Data Sharing",
    "abstract": "This paper adopts Arimoto's $\\alpha$-Mutual Information as a tunable privacy measure, in a privacy-preserving data release setting that aims to prevent disclosing private data to adversaries. By fine-tuning the privacy metric, we demonstrate that our approach yields superior models that effectively thwart attackers across various performance dimensions. We formulate a general distortion-based mechanism that manipulates the original data to offer privacy protection. The distortion metrics are determined according to the data structure of a specific experiment. We confront the problem expressed in the formulation by employing a general adversarial deep learning framework that consists of a releaser and an adversary, trained with opposite goals. This study conducts empirical experiments on images and time-series data to verify the functionality of $\\alpha$-Mutual Information. We evaluate the privacy-utility trade-off of customized models and compare them to mutual information as the baseline measure. Finally, we analyze the consequence of an attacker's access to side information about private data and witness that adapting the privacy measure results in a more refined model than the state-of-the-art in terms of resiliency against side information. ",
    "url": "https://arxiv.org/abs/2310.18241",
    "authors": [
      "MirHamed Jafarzadeh Asl",
      "Mohammadhadi Shateri",
      "Fabrice Labeau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.18247",
    "title": "Guided Data Augmentation for Offline Reinforcement Learning and  Imitation Learning",
    "abstract": "Learning from demonstration (LfD) is a popular technique that uses expert demonstrations to learn robot control policies. However, the difficulty in acquiring expert-quality demonstrations limits the applicability of LfD methods: real-world data collection is often costly, and the quality of the demonstrations depends greatly on the demonstrator's abilities and safety concerns. A number of works have leveraged data augmentation (DA) to inexpensively generate additional demonstration data, but most DA works generate augmented data in a random fashion and ultimately produce highly suboptimal data. In this work, we propose Guided Data Augmentation (GuDA), a human-guided DA framework that generates expert-quality augmented data. The key insight of GuDA is that while it may be difficult to demonstrate the sequence of actions required to produce expert data, a user can often easily identify when an augmented trajectory segment represents task progress. Thus, the user can impose a series of simple rules on the DA process to automatically generate augmented samples that approximate expert behavior. To extract a policy from GuDA, we use off-the-shelf offline reinforcement learning and behavior cloning algorithms. We evaluate GuDA on a physical robot soccer task as well as simulated D4RL navigation tasks, a simulated autonomous driving task, and a simulated soccer task. Empirically, we find that GuDA enables learning from a small set of potentially suboptimal demonstrations and substantially outperforms a DA strategy that samples augmented data randomly. ",
    "url": "https://arxiv.org/abs/2310.18247",
    "authors": [
      "Nicholas E. Corrado",
      "Yuxiao Qu",
      "John U. Balis",
      "Adam Labiosa",
      "Josiah P. Hanna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.18251",
    "title": "A Self-Supervised Approach to Land Cover Segmentation",
    "abstract": "Land use/land cover change (LULC) maps are integral resources in earth science and agricultural research. Due to the nature of such maps, the creation of LULC maps is often constrained by the time and human resources necessary to accurately annotate satellite imagery and remote sensing data. While computer vision models that perform semantic segmentation to create detailed labels from such data are not uncommon, litle research has been done on self-supervised and unsupervised approaches to labelling LULC maps without the use of ground-truth masks. Here, we demonstrate a self-supervised method of land cover segmentation that has no need for high-quality ground truth labels. The proposed deep learning employs a frozen pre-trained ViT backbone transferred from DINO in a STEGO architecture and is fine-tuned using a custom dataset consisting of very high resolution (VHR) sattelite imagery. After only 10 epochs of fine-tuning, an accuracy of roughly 52% was observed across 5 samples, signifying the feasibility of self-supervised models for the automated labelling of VHR LULC maps. ",
    "url": "https://arxiv.org/abs/2310.18251",
    "authors": [
      "Charles Moore",
      "Dakota Hester"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18257",
    "title": "MIM-GAN-based Anomaly Detection for Multivariate Time Series Data",
    "abstract": "The loss function of Generative adversarial network(GAN) is an important factor that affects the quality and diversity of the generated samples for anomaly detection. In this paper, we propose an unsupervised multiple time series anomaly detection algorithm based on the GAN with message importance measure(MIM-GAN). In particular, the time series data is divided into subsequences using a sliding window. Then a generator and a discriminator designed based on the Long Short-Term Memory (LSTM) are employed to capture the temporal correlations of the time series data. To avoid the local optimal solution of loss function and the model collapse, we introduce an exponential information measure into the loss function of GAN. Additionally, a discriminant reconstruction score consisting on discrimination and reconstruction loss is taken into account. The global optimal solution for the loss function is derived and the model collapse is proved to be avoided in our proposed MIM-GAN-based anomaly detection algorithm. Experimental results show that the proposed MIM-GAN-based anomaly detection algorithm has superior performance in terms of precision, recall, and F1 score. ",
    "url": "https://arxiv.org/abs/2310.18257",
    "authors": [
      "Shan Lu",
      "Zhicheng Dong",
      "Donghong Cai",
      "Fang Fang",
      "Dongcai Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18263",
    "title": "MalFake: A Multimodal Fake News Identification for Malayalam using  Recurrent Neural Networks and VGG-16",
    "abstract": "The amount of news being consumed online has substantially expanded in recent years. Fake news has become increasingly common, especially in regional languages like Malayalam, due to the rapid publication and lack of editorial standards on some online sites. Fake news may have a terrible effect on society, causing people to make bad judgments, lose faith in authorities, and even engage in violent behavior. When we take into the context of India, there are many regional languages, and fake news is spreading in every language. Therefore, providing efficient techniques for identifying false information in regional tongues is crucial. Until now, little to no work has been done in Malayalam, extracting features from multiple modalities to classify fake news. Multimodal approaches are more accurate in detecting fake news, as features from multiple modalities are extracted to build the deep learning classification model. As far as we know, this is the first piece of work in Malayalam that uses multimodal deep learning to tackle false information. Models trained with more than one modality typically outperform models taught with only one modality. Our study in the Malayalam language utilizing multimodal deep learning is a significant step toward more effective misinformation detection and mitigation. ",
    "url": "https://arxiv.org/abs/2310.18263",
    "authors": [
      "Adhish S. Sujan",
      "Ajitha. V",
      "Aleena Benny",
      "Amiya M. P.",
      "V. S. Anoop"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.18264",
    "title": "Learning to Search Feasible and Infeasible Regions of Routing Problems  with Flexible Neural k-Opt",
    "abstract": "In this paper, we present Neural k-Opt (NeuOpt), a novel learning-to-search (L2S) solver for routing problems. It learns to perform flexible k-opt exchanges based on a tailored action factorization method and a customized recurrent dual-stream decoder. As a pioneering work to circumvent the pure feasibility masking scheme and enable the autonomous exploration of both feasible and infeasible regions, we then propose the Guided Infeasible Region Exploration (GIRE) scheme, which supplements the NeuOpt policy network with feasibility-related features and leverages reward shaping to steer reinforcement learning more effectively. Additionally, we equip NeuOpt with Dynamic Data Augmentation (D2A) for more diverse searches during inference. Extensive experiments on the Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP) demonstrate that our NeuOpt not only significantly outstrips existing (masking-based) L2S solvers, but also showcases superiority over the learning-to-construct (L2C) and learning-to-predict (L2P) solvers. Notably, we offer fresh perspectives on how neural solvers can handle VRP constraints. Our code is available: https://github.com/yining043/NeuOpt. ",
    "url": "https://arxiv.org/abs/2310.18264",
    "authors": [
      "Yining Ma",
      "Zhiguang Cao",
      "Yeow Meng Chee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.18268",
    "title": "PlantPlotGAN: A Physics-Informed Generative Adversarial Network for  Plant Disease Prediction",
    "abstract": "Monitoring plantations is crucial for crop management and producing healthy harvests. Unmanned Aerial Vehicles (UAVs) have been used to collect multispectral images that aid in this monitoring. However, given the number of hectares to be monitored and the limitations of flight, plant disease signals become visually clear only in the later stages of plant growth and only if the disease has spread throughout a significant portion of the plantation. This limited amount of relevant data hampers the prediction models, as the algorithms struggle to generalize patterns with unbalanced or unrealistic augmented datasets effectively. To address this issue, we propose PlantPlotGAN, a physics-informed generative model capable of creating synthetic multispectral plot images with realistic vegetation indices. These indices served as a proxy for disease detection and were used to evaluate if our model could help increase the accuracy of prediction models. The results demonstrate that the synthetic imagery generated from PlantPlotGAN outperforms state-of-the-art methods regarding the Fr\\'echet inception distance. Moreover, prediction models achieve higher accuracy metrics when trained with synthetic and original imagery for earlier plant disease detection compared to the training processes based solely on real imagery. ",
    "url": "https://arxiv.org/abs/2310.18268",
    "authors": [
      "Felipe A. Lopes",
      "Vasit Sagan",
      "Flavio Esposito"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.18274",
    "title": "LipSim: A Provably Robust Perceptual Similarity Metric",
    "abstract": "Recent years have seen growing interest in developing and applying perceptual similarity metrics. Research has shown the superiority of perceptual metrics over pixel-wise metrics in aligning with human perception and serving as a proxy for the human visual system. On the other hand, as perceptual metrics rely on neural networks, there is a growing concern regarding their resilience, given the established vulnerability of neural networks to adversarial attacks. It is indeed logical to infer that perceptual metrics may inherit both the strengths and shortcomings of neural networks. In this work, we demonstrate the vulnerability of state-of-the-art perceptual similarity metrics based on an ensemble of ViT-based feature extractors to adversarial attacks. We then propose a framework to train a robust perceptual similarity metric called LipSim (Lipschitz Similarity Metric) with provable guarantees. By leveraging 1-Lipschitz neural networks as the backbone, LipSim provides guarded areas around each data point and certificates for all perturbations within an $\\ell_2$ ball. Finally, a comprehensive set of experiments shows the performance of LipSim in terms of natural and certified scores and on the image retrieval application. The code is available at https://github.com/SaraGhazanfari/LipSim. ",
    "url": "https://arxiv.org/abs/2310.18274",
    "authors": [
      "Sara Ghazanfari",
      "Alexandre Araujo",
      "Prashanth Krishnamurthy",
      "Farshad Khorrami",
      "Siddharth Garg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18285",
    "title": "Heterogeneous Federated Learning with Group-Aware Prompt Tuning",
    "abstract": "Transformers have achieved remarkable success in various machine-learning tasks, prompting their widespread adoption. In this paper, we explore their application in the context of federated learning (FL), with a particular focus on heterogeneous scenarios where individual clients possess diverse local datasets. To meet the computational and communication demands of FL, we leverage pre-trained Transformers and use an efficient prompt-tuning strategy. Our strategy introduces the concept of learning both shared and group prompts, enabling the acquisition of universal knowledge and group-specific knowledge simultaneously. Additionally, a prompt selection module assigns personalized group prompts to each input, aligning the global model with the data distribution of each client. This approach allows us to train a single global model that can automatically adapt to various local client data distributions without requiring local fine-tuning. In this way, our proposed method effectively bridges the gap between global and personalized local models in Federated Learning and surpasses alternative approaches that lack the capability to adapt to previously unseen clients. The effectiveness of our approach is rigorously validated through extensive experimentation and ablation studies. ",
    "url": "https://arxiv.org/abs/2310.18285",
    "authors": [
      "Wenlong Deng",
      "Christos Thrampoulidis",
      "Xiaoxiao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.17659",
    "title": "RTNH+: Enhanced 4D Radar Object Detection Network using Combined  CFAR-based Two-level Preprocessing and Vertical Encoding",
    "abstract": "Four-dimensional (4D) Radar is a useful sensor for 3D object detection and the relative radial speed estimation of surrounding objects under various weather conditions. However, since Radar measurements are corrupted with invalid components such as noise, interference, and clutter, it is necessary to employ a preprocessing algorithm before the 3D object detection with neural networks. In this paper, we propose RTNH+ that is an enhanced version of RTNH, a 4D Radar object detection network, by two novel algorithms. The first algorithm is the combined constant false alarm rate (CFAR)-based two-level preprocessing (CCTP) algorithm that generates two filtered measurements of different characteristics using the same 4D Radar measurements, which can enrich the information of the input to the 4D Radar object detection network. The second is the vertical encoding (VE) algorithm that effectively encodes vertical features of the road objects from the CCTP outputs. We provide details of the RTNH+, and demonstrate that RTNH+ achieves significant performance improvement of 10.14\\% in ${{AP}_{3D}^{IoU=0.3}}$ and 16.12\\% in ${{AP}_{3D}^{IoU=0.5}}$ over RTNH. ",
    "url": "https://arxiv.org/abs/2310.17659",
    "authors": [
      "Seung-Hyun Kong",
      "Dong-Hee Paek",
      "Sangjae Cho"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.17675",
    "title": "Early Detection of Tuberculosis with Machine Learning Cough Audio  Analysis: Towards More Accessible Global Triaging Usage",
    "abstract": "Tuberculosis (TB), a bacterial disease mainly affecting the lungs, is one of the leading infectious causes of mortality worldwide. To prevent TB from spreading within the body, which causes life-threatening complications, timely and effective anti-TB treatment is crucial. Cough, an objective biomarker for TB, is a triage tool that monitors treatment response and regresses with successful therapy. Current gold standards for TB diagnosis are slow or inaccessible, especially in rural areas where TB is most prevalent. In addition, current machine learning (ML) diagnosis research, like utilizing chest radiographs, is ineffective and does not monitor treatment progression. To enable effective diagnosis, an ensemble model was developed that analyzes, using a novel ML architecture, coughs' acoustic epidemiologies from smartphones' microphones to detect TB. The architecture includes a 2D-CNN and XGBoost that was trained on 724,964 cough audio samples and demographics from 7 countries. After feature extraction (Mel-spectrograms) and data augmentation (IR-convolution), the model achieved AUROC (area under the receiving operator characteristic) of 88%, surpassing WHO's requirements for screening tests. The results are available within 15 seconds and can easily be accessible via a mobile app. This research helps to improve TB diagnosis through a promising accurate, quick, and accessible triaging tool. ",
    "url": "https://arxiv.org/abs/2310.17675",
    "authors": [
      "Chandra Suda"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2310.17712",
    "title": "Community Detection and Classification Guarantees Using Embeddings  Learned by Node2Vec",
    "abstract": "Embedding the nodes of a large network into an Euclidean space is a common objective in modern machine learning, with a variety of tools available. These embeddings can then be used as features for tasks such as community detection/node clustering or link prediction, where they achieve state of the art performance. With the exception of spectral clustering methods, there is little theoretical understanding for other commonly used approaches to learning embeddings. In this work we examine the theoretical properties of the embeddings learned by node2vec. Our main result shows that the use of k-means clustering on the embedding vectors produced by node2vec gives weakly consistent community recovery for the nodes in (degree corrected) stochastic block models. We also discuss the use of these embeddings for node and link prediction tasks. We demonstrate this result empirically, and examine how this relates to other embedding tools for network data. ",
    "url": "https://arxiv.org/abs/2310.17712",
    "authors": [
      "Andrew Davison",
      "S. Carlyle Morgan",
      "Owen G. Ward"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2310.17816",
    "title": "Local Discovery by Partitioning: Polynomial-Time Causal Discovery Around  Exposure-Outcome Pairs",
    "abstract": "This work addresses the problem of automated covariate selection under limited prior knowledge. Given an exposure-outcome pair {X,Y} and a variable set Z of unknown causal structure, the Local Discovery by Partitioning (LDP) algorithm partitions Z into subsets defined by their relation to {X,Y}. We enumerate eight exhaustive and mutually exclusive partitions of any arbitrary Z and leverage this taxonomy to differentiate confounders from other variable types. LDP is motivated by valid adjustment set identification, but avoids the pretreatment assumption commonly made by automated covariate selection methods. We provide theoretical guarantees that LDP returns a valid adjustment set for any Z that meets sufficient graphical conditions. Under stronger conditions, we prove that partition labels are asymptotically correct. Total independence tests is worst-case quadratic in |Z|, with sub-quadratic runtimes observed empirically. We numerically validate our theoretical guarantees on synthetic and semi-synthetic graphs. Adjustment sets from LDP yield less biased and more precise average treatment effect estimates than baselines, with LDP outperforming on confounder recall, test count, and runtime for valid adjustment set discovery. ",
    "url": "https://arxiv.org/abs/2310.17816",
    "authors": [
      "Jacqueline Maasch",
      "Weishen Pan",
      "Shantanu Gupta",
      "Volodymyr Kuleshov",
      "Kyra Gan",
      "Fei Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2310.17864",
    "title": "TorchAudio 2.1: Advancing speech recognition, self-supervised learning,  and audio processing components for PyTorch",
    "abstract": "TorchAudio is an open-source audio and speech processing library built for PyTorch. It aims to accelerate the research and development of audio and speech technologies by providing well-designed, easy-to-use, and performant PyTorch components. Its contributors routinely engage with users to understand their needs and fulfill them by developing impactful features. Here, we survey TorchAudio's development principles and contents and highlight key features we include in its latest version (2.1): self-supervised learning pre-trained pipelines and training recipes, high-performance CTC decoders, speech recognition models and training recipes, advanced media I/O capabilities, and tools for performing forced alignment, multi-channel speech enhancement, and reference-less speech assessment. For a selection of these features, through empirical studies, we demonstrate their efficacy and show that they achieve competitive or state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2310.17864",
    "authors": [
      "Jeff Hwang",
      "Moto Hira",
      "Caroline Chen",
      "Xiaohui Zhang",
      "Zhaoheng Ni",
      "Guangzhi Sun",
      "Pingchuan Ma",
      "Ruizhe Huang",
      "Vineel Pratap",
      "Yuekai Zhang",
      "Anurag Kumar",
      "Chin-Yun Yu",
      "Chuang Zhu",
      "Chunxi Liu",
      "Jacob Kahn",
      "Mirco Ravanelli",
      "Peng Sun",
      "Shinji Watanabe",
      "Yangyang Shi",
      "Yumeng Tao",
      "Robin Scheibler",
      "Samuele Cornell",
      "Sean Kim",
      "Stavros Petridis"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2310.18222",
    "title": "TBDLNet: a network for classifying multidrug-resistant and  drug-sensitive tuberculosis",
    "abstract": "This paper proposes applying a novel deep-learning model, TBDLNet, to recognize CT images to classify multidrug-resistant and drug-sensitive tuberculosis automatically. The pre-trained ResNet50 is selected to extract features. Three randomized neural networks are used to alleviate the overfitting problem. The ensemble of three RNNs is applied to boost the robustness via majority voting. The proposed model is evaluated by five-fold cross-validation. Five indexes are selected in this paper, which are accuracy, sensitivity, precision, F1-score, and specificity. The TBDLNet achieves 0.9822 accuracy, 0.9815 specificity, 0.9823 precision, 0.9829 sensitivity, and 0.9826 F1-score, respectively. The TBDLNet is suitable for classifying multidrug-resistant tuberculosis and drug-sensitive tuberculosis. It can detect multidrug-resistant pulmonary tuberculosis as early as possible, which helps to adjust the treatment plan in time and improve the treatment effect. ",
    "url": "https://arxiv.org/abs/2310.18222",
    "authors": [
      "Ziquan Zhu",
      "Jing Tao",
      "Shuihua Wang",
      "Xin Zhang",
      "Yudong Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18309",
    "title": "Social media battle for attention: opinion dynamics on competing  networks",
    "abstract": "In the age of information abundance, attention is a coveted resource. Social media platforms vigorously compete for users' engagement, influencing the evolution of their opinions on a variety of topics. With recommendation algorithms often accused of creating \"filter bubbles\", where like-minded individuals interact predominantly with one another, it's crucial to understand the consequences of this unregulated attention market. To address this, we present a model of opinion dynamics on a multiplex network. Each layer of the network represents a distinct social media platform, each with its unique characteristics. Users, as nodes in this network, share their opinions across platforms and decide how much time to allocate in each platform depending on its perceived quality. Our model reveals two key findings. i) When examining two platforms - one with a neutral recommendation algorithm and another with a homophily-based algorithm - we uncover that even if users spend the majority of their time on the neutral platform, opinion polarization can persist. ii) By allowing users to dynamically allocate their social energy across platforms in accordance to their homophilic preferences, a further segregation of individuals emerges. While network fragmentation is usually associated with \"echo chambers\", the emergent multi-platform segregation leads to an increase in users' satisfaction without the undesired increase in polarization. These results underscore the significance of acknowledging how individuals gather information from a multitude of sources. Furthermore, they emphasize that policy interventions on a single social media platform may yield limited impact. ",
    "url": "https://arxiv.org/abs/2310.18309",
    "authors": [
      "Andrea Somazzi",
      "Giuseppe Maria Ferro",
      "Diego Garlaschelli",
      "Simon Asher Levin"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:1912.13490",
    "title": "A Neurocomputational Account of Flexible Goal-directed Cognition and  Consciousness: The Goal-Aligning Representation Internal Manipulation Theory  (GARIM)",
    "abstract": " Title: A Neurocomputational Account of Flexible Goal-directed Cognition and  Consciousness: The Goal-Aligning Representation Internal Manipulation Theory  (GARIM) ",
    "url": "https://arxiv.org/abs/1912.13490",
    "authors": [
      "Giovanni Granato",
      "Gianluca Baldassarre"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2110.14053",
    "title": "NeuroBack: Improving CDCL SAT Solving using Graph Neural Networks",
    "abstract": " Title: NeuroBack: Improving CDCL SAT Solving using Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2110.14053",
    "authors": [
      "Wenxi Wang",
      "Yang Hu",
      "Mohit Tiwari",
      "Sarfraz Khurshid",
      "Kenneth McMillan",
      "Risto Miikkulainen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08189",
    "title": "Supplementing Recurrent Neural Networks with Annealing to Solve  Combinatorial Optimization Problems",
    "abstract": " Comments: 14 pages, 3 figures, 4 tables. Github code: this https URL Published version ",
    "url": "https://arxiv.org/abs/2207.08189",
    "authors": [
      "Shoummo Ahsan Khandoker",
      "Jawaril Munshad Abedin",
      "Mohamed Hibat-Allah"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2208.04627",
    "title": "Causal Effect Identification in Uncertain Causal Networks",
    "abstract": " Comments: 27 pages, 9 figures, NeurIPS 2023 conference, causal identification, causal discovery, probabilistic models ",
    "url": "https://arxiv.org/abs/2208.04627",
    "authors": [
      "Sina Akbari",
      "Fateme Jamshidi",
      "Ehsan Mokhtarian",
      "Matthew J. Vowels",
      "Jalal Etesami",
      "Negar Kiyavash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2212.06096",
    "title": "Implicit Convolutional Kernels for Steerable CNNs",
    "abstract": " Comments: Accepted to 37th Conference on Neural Information Processing Systems (NeurIPS 2023) ",
    "url": "https://arxiv.org/abs/2212.06096",
    "authors": [
      "Maksim Zhdanov",
      "Nico Hoffmann",
      "Gabriele Cesa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.07056",
    "title": "On the Probability of Necessity and Sufficiency of Explaining Graph  Neural Networks: A Lower Bound Optimization Approach",
    "abstract": " Comments: 36 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2212.07056",
    "authors": [
      "Ruichu Cai",
      "Yuxuan Zhu",
      "Xuexin Chen",
      "Yuan Fang",
      "Min Wu",
      "Jie Qiao",
      "Zhifeng Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.02428",
    "title": "Sensitivity analysis using Physics-informed neural networks",
    "abstract": " Comments: 22 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2301.02428",
    "authors": [
      "John M. Hanna",
      "Jos\u00e9 V. Aguado",
      "Sebastien Comas-Cardona",
      "Ramzi Askri",
      "Domenico Borzacchiello"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2302.00993",
    "title": "Unpaired Multi-Domain Causal Representation Learning",
    "abstract": " Title: Unpaired Multi-Domain Causal Representation Learning ",
    "url": "https://arxiv.org/abs/2302.00993",
    "authors": [
      "Nils Sturma",
      "Chandler Squires",
      "Mathias Drton",
      "Caroline Uhler"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2302.08478",
    "title": "Kernelized Back-Projection Networks for Blind Super Resolution",
    "abstract": " Comments: The first two authors contributed equally to this work ",
    "url": "https://arxiv.org/abs/2302.08478",
    "authors": [
      "Tomoki Yoshida",
      "Yuki Kondo",
      "Takahiro Maeda",
      "Kazutoshi Akita",
      "Norimichi Ukita"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.08631",
    "title": "Practical Contextual Bandits with Feedback Graphs",
    "abstract": " Title: Practical Contextual Bandits with Feedback Graphs ",
    "url": "https://arxiv.org/abs/2302.08631",
    "authors": [
      "Mengxiao Zhang",
      "Yuheng Zhang",
      "Olga Vrousgou",
      "Haipeng Luo",
      "Paul Mineiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.13934",
    "title": "Statistical Learning under Heterogeneous Distribution Shift",
    "abstract": " Title: Statistical Learning under Heterogeneous Distribution Shift ",
    "url": "https://arxiv.org/abs/2302.13934",
    "authors": [
      "Max Simchowitz",
      "Anurag Ajay",
      "Pulkit Agrawal",
      "Akshay Krishnamurthy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.03169",
    "title": "A Unified Algebraic Perspective on Lipschitz Neural Networks",
    "abstract": " Comments: ICLR 2023. Spotlight paper ",
    "url": "https://arxiv.org/abs/2303.03169",
    "authors": [
      "Alexandre Araujo",
      "Aaron Havens",
      "Blaise Delattre",
      "Alexandre Allauzen",
      "Bin Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07230",
    "title": "Systematic Evaluation of Deep Learning Models for Failure Prediction",
    "abstract": " Title: Systematic Evaluation of Deep Learning Models for Failure Prediction ",
    "url": "https://arxiv.org/abs/2303.07230",
    "authors": [
      "Fatemeh Hadadi",
      "Joshua H. Dawes",
      "Donghwan Shin",
      "Domenico Bianculli",
      "Lionel Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.11205",
    "title": "Entropy-dissipation Informed Neural Network for McKean-Vlasov Type PDEs",
    "abstract": " Comments: Accepted to NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2303.11205",
    "authors": [
      "Zebang Shen",
      "Zhenfu Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2303.11403",
    "title": "eP-ALM: Efficient Perceptual Augmentation of Language Models",
    "abstract": " Comments: Accepted at ICCV 2023. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2303.11403",
    "authors": [
      "Mustafa Shukor",
      "Corentin Dancette",
      "Matthieu Cord"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.02247",
    "title": "Disentangling Structure and Style: Political Bias Detection in News by  Inducing Document Hierarchy",
    "abstract": " Comments: Findings of EMNLP 2023 ",
    "url": "https://arxiv.org/abs/2304.02247",
    "authors": [
      "Jiwoo Hong",
      "Yejin Cho",
      "Jaemin Jung",
      "Jiyoung Han",
      "James Thorne"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.06706",
    "title": "Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2304.06706",
    "authors": [
      "Jonathan T. Barron",
      "Ben Mildenhall",
      "Dor Verbin",
      "Pratul P. Srinivasan",
      "Peter Hedman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14218",
    "title": "DUBLIN -- Document Understanding By Language-Image Network",
    "abstract": " Title: DUBLIN -- Document Understanding By Language-Image Network ",
    "url": "https://arxiv.org/abs/2305.14218",
    "authors": [
      "Kriti Aggarwal",
      "Aditi Khandelwal",
      "Kumar Tanmay",
      "Owais Mohammed Khan",
      "Qiang Liu",
      "Monojit Choudhury",
      "Hardik Hansrajbhai Chauhan",
      "Subhojit Som",
      "Vishrav Chaudhary",
      "Saurabh Tiwary"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14695",
    "title": "A Causal View of Entity Bias in (Large) Language Models",
    "abstract": " Comments: Findings of EMNLP 2023 ",
    "url": "https://arxiv.org/abs/2305.14695",
    "authors": [
      "Fei Wang",
      "Wenjie Mo",
      "Yiwei Wang",
      "Wenxuan Zhou",
      "Muhao Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16379",
    "title": "Learning Better with Less: Effective Augmentation for Sample-Efficient  Visual Reinforcement Learning",
    "abstract": " Comments: NeurIPS 2023 poster ",
    "url": "https://arxiv.org/abs/2305.16379",
    "authors": [
      "Guozheng Ma",
      "Linrui Zhang",
      "Haoyu Wang",
      "Lu Li",
      "Zilin Wang",
      "Zhen Wang",
      "Li Shen",
      "Xueqian Wang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18370",
    "title": "Explainable Brain Age Prediction using coVariance Neural Networks",
    "abstract": " Comments: Camera ready version for NeurIPS 2023. arXiv admin note: substantial text overlap with arXiv:2305.01807 ",
    "url": "https://arxiv.org/abs/2305.18370",
    "authors": [
      "Saurabh Sihag",
      "Gonzalo Mateos",
      "Corey McMillan",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2305.19068",
    "title": "Complex Query Answering on Eventuality Knowledge Graph with Implicit  Logical Constraints",
    "abstract": " Title: Complex Query Answering on Eventuality Knowledge Graph with Implicit  Logical Constraints ",
    "url": "https://arxiv.org/abs/2305.19068",
    "authors": [
      "Jiaxin Bai",
      "Xin Liu",
      "Weiqi Wang",
      "Chen Luo",
      "Yangqiu Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2305.19079",
    "title": "Analyzing the Sample Complexity of Self-Supervised Image Reconstruction  Methods",
    "abstract": " Title: Analyzing the Sample Complexity of Self-Supervised Image Reconstruction  Methods ",
    "url": "https://arxiv.org/abs/2305.19079",
    "authors": [
      "Tobit Klug",
      "Dogukan Atik",
      "Reinhard Heckel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.19181",
    "title": "Table Detection for Visually Rich Document Images",
    "abstract": " Comments: Accepted by Knowledge-Based Systems ",
    "url": "https://arxiv.org/abs/2305.19181",
    "authors": [
      "Bin Xiao",
      "Murat Simsek",
      "Burak Kantarci",
      "Ala Abu Alkheir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2306.00006",
    "title": "Truncated Affinity Maximization: One-class Homophily Modeling for Graph  Anomaly Detection",
    "abstract": " Comments: 19 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2306.00006",
    "authors": [
      "Hezhe Qiao",
      "Guansong Pang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.01859",
    "title": "Spatially Resolved Gene Expression Prediction from H&E Histology Images  via Bi-modal Contrastive Learning",
    "abstract": " Title: Spatially Resolved Gene Expression Prediction from H&E Histology Images  via Bi-modal Contrastive Learning ",
    "url": "https://arxiv.org/abs/2306.01859",
    "authors": [
      "Ronald Xie",
      "Kuan Pang",
      "Sai W. Chung",
      "Catia T. Perciani",
      "Sonya A. MacParland",
      "Bo Wang",
      "Gary D. Bader"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.03266",
    "title": "Extending the Design Space of Graph Neural Networks by Rethinking  Folklore Weisfeiler-Lehman",
    "abstract": " Comments: Accepted to NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.03266",
    "authors": [
      "Jiarui Feng",
      "Lecheng Kong",
      "Hao Liu",
      "Dacheng Tao",
      "Fuhai Li",
      "Muhan Zhang",
      "Yixin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.11641",
    "title": "SALSA VERDE: a machine learning attack on Learning With Errors with  sparse small secrets",
    "abstract": " Comments: 18 pages, accepted to NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.11641",
    "authors": [
      "Cathy Yuanchen Li",
      "Emily Wenger",
      "Zeyuan Allen-Zhu",
      "Francois Charton",
      "Kristin Lauter"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2307.02318",
    "title": "Deep Contract Design via Discontinuous Networks",
    "abstract": " Title: Deep Contract Design via Discontinuous Networks ",
    "url": "https://arxiv.org/abs/2307.02318",
    "authors": [
      "Tonghan Wang",
      "Paul D\u00fctting",
      "Dmitry Ivanov",
      "Inbal Talgam-Cohen",
      "David C. Parkes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.04090",
    "title": "DebateKG: Automatic Policy Debate Case Creation with Semantic Knowledge  Graphs",
    "abstract": " Comments: 8 pages, Accepted to The 4th New Frontiers in Summarization Workshop (EMNLP 2023), System Demonstration paper ",
    "url": "https://arxiv.org/abs/2307.04090",
    "authors": [
      "Allen Roush",
      "David Mezzetti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.08623",
    "title": "HYTREL: Hypergraph-enhanced Tabular Data Representation Learning",
    "abstract": " Comments: NeurIPS 2023 (spotlight) ",
    "url": "https://arxiv.org/abs/2307.08623",
    "authors": [
      "Pei Chen",
      "Soumajyoti Sarkar",
      "Leonard Lausen",
      "Balasubramaniam Srinivasan",
      "Sheng Zha",
      "Ruihong Huang",
      "George Karypis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.12233",
    "title": "Adaptive Consensus-based Reference Generation for the Regulation of  Open-Channel Networks",
    "abstract": " Comments: 14 pages, 7 figures, submitted to IEEE Access (version 2) ",
    "url": "https://arxiv.org/abs/2307.12233",
    "authors": [
      "Marco Fabris",
      "Marco D. Bellinazzi",
      "Andrea Furlanetto",
      "Angelo Cenedese"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.13755",
    "title": "Training-based Model Refinement and Representation Disagreement for  Semi-Supervised Object Detection",
    "abstract": " Comments: Accepted in IEEE/CVF Winter Applications of Computer Vision (WACV) 2024 ",
    "url": "https://arxiv.org/abs/2307.13755",
    "authors": [
      "Seyed Mojtaba Marvasti-Zadeh",
      "Nilanjan Ray",
      "Nadir Erbilgin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.15662",
    "title": "Robust data-driven learning and control of nonlinear systems. A Sontag's  formula approach",
    "abstract": " Comments: Preprint submitted to journal (under review). 25 pages, 6 figures, font 12pt ",
    "url": "https://arxiv.org/abs/2307.15662",
    "authors": [
      "Yeyson A. Becerra-Mora",
      "Jos\u00e9 \u00c1ngel Acosta"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2308.04808",
    "title": "Joint-Relation Transformer for Multi-Person Motion Prediction",
    "abstract": " Title: Joint-Relation Transformer for Multi-Person Motion Prediction ",
    "url": "https://arxiv.org/abs/2308.04808",
    "authors": [
      "Qingyao Xu",
      "Weibo Mao",
      "Jingze Gong",
      "Chenxin Xu",
      "Siheng Chen",
      "Weidi Xie",
      "Ya Zhang",
      "Yanfeng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.08643",
    "title": "Towards Personalized Federated Learning via Heterogeneous Model  Reassembly",
    "abstract": " Comments: This paper has been accepted by NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2308.08643",
    "authors": [
      "Jiaqi Wang",
      "Xingyi Yang",
      "Suhan Cui",
      "Liwei Che",
      "Lingjuan Lyu",
      "Dongkuan Xu",
      "Fenglong Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2308.12947",
    "title": "Counting Distinct Elements Under Person-Level Differential Privacy",
    "abstract": " Title: Counting Distinct Elements Under Person-Level Differential Privacy ",
    "url": "https://arxiv.org/abs/2308.12947",
    "authors": [
      "Alexander Knop",
      "Thomas Steinke"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.00184",
    "title": "A Survey of Network Requirements for Enabling Effective Cyber Deception",
    "abstract": " Title: A Survey of Network Requirements for Enabling Effective Cyber Deception ",
    "url": "https://arxiv.org/abs/2309.00184",
    "authors": [
      "Md Abu Sayed",
      "Moqsadur Rahman",
      "Mohammad Ariful Islam Khan",
      "Deepak Tosh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.04679",
    "title": "Embedding structure matters: Comparing methods to adapt multilingual  vocabularies to new languages",
    "abstract": " Comments: Camera-ready for Proceedings of the 3rd Workshop on Multilingual Representation Learning ",
    "url": "https://arxiv.org/abs/2309.04679",
    "authors": [
      "C.M. Downey",
      "Terra Blevins",
      "Nora Goldfine",
      "Shane Steinert-Threlkeld"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.04810",
    "title": "Neural Latent Geometry Search: Product Manifold Inference via  Gromov-Hausdorff-Informed Bayesian Optimization",
    "abstract": " Title: Neural Latent Geometry Search: Product Manifold Inference via  Gromov-Hausdorff-Informed Bayesian Optimization ",
    "url": "https://arxiv.org/abs/2309.04810",
    "authors": [
      "Haitz Saez de Ocariz Borde",
      "Alvaro Arroyo",
      "Ismael Morales",
      "Ingmar Posner",
      "Xiaowen Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.11139",
    "title": "More complex encoder is not all you need",
    "abstract": " Title: More complex encoder is not all you need ",
    "url": "https://arxiv.org/abs/2309.11139",
    "authors": [
      "Weibin Yang",
      "Longwei Xu",
      "Pengwei Wang",
      "Dehua Geng",
      "Yusong Li",
      "Mingyuan Xu",
      "Zhiqi Dong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.12095",
    "title": "Bayesian sparsification for deep neural networks with Bayesian model  reduction",
    "abstract": " Title: Bayesian sparsification for deep neural networks with Bayesian model  reduction ",
    "url": "https://arxiv.org/abs/2309.12095",
    "authors": [
      "Dimitrije Markovi\u0107",
      "Karl J. Friston",
      "Stefan J. Kiebel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.14208",
    "title": "Framework based on complex networks to model and mine patient pathways",
    "abstract": " Comments: 35 pages, 11 figures, 2 appendices ",
    "url": "https://arxiv.org/abs/2309.14208",
    "authors": [
      "Caroline de Oliveira Costa Souza Rosa",
      "M\u00e1rcia Ito",
      "Alex Borges Vieira",
      "Klaus Wehmuth",
      "Ant\u00f4nio Tadeu Azevedo Gomes"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16318",
    "title": "DeepPCR: Parallelizing Sequential Operations in Neural Networks",
    "abstract": " Title: DeepPCR: Parallelizing Sequential Operations in Neural Networks ",
    "url": "https://arxiv.org/abs/2309.16318",
    "authors": [
      "Federico Danieli",
      "Miguel Sarabia",
      "Xavier Suau",
      "Pau Rodr\u00edguez",
      "Luca Zappella"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00656",
    "title": "LEGO-Prover: Neural Theorem Proving with Growing Libraries",
    "abstract": " Title: LEGO-Prover: Neural Theorem Proving with Growing Libraries ",
    "url": "https://arxiv.org/abs/2310.00656",
    "authors": [
      "Haiming Wang",
      "Huajian Xin",
      "Chuanyang Zheng",
      "Lin Li",
      "Zhengying Liu",
      "Qingxing Cao",
      "Yinya Huang",
      "Jing Xiong",
      "Han Shi",
      "Enze Xie",
      "Jian Yin",
      "Zhenguo Li",
      "Heng Liao",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05351",
    "title": "Generalized Neural Collapse for a Large Number of Classes",
    "abstract": " Comments: 32 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2310.05351",
    "authors": [
      "Jiachen Jiang",
      "Jinxin Zhou",
      "Peng Wang",
      "Qing Qu",
      "Dustin Mixon",
      "Chong You",
      "Zhihui Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2310.06822",
    "title": "Neural Bounding",
    "abstract": " Title: Neural Bounding ",
    "url": "https://arxiv.org/abs/2310.06822",
    "authors": [
      "Wenxin Liu",
      "Michael Fischer",
      "Paul D. Yoo",
      "Tobias Ritschel"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.08670",
    "title": "Every Parameter Matters: Ensuring the Convergence of Federated Learning  with Dynamic Heterogeneous Models Reduction",
    "abstract": " Comments: Accepted at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2310.08670",
    "authors": [
      "Hanhan Zhou",
      "Tian Lan",
      "Guru Venkataramani",
      "Wenbo Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.11069",
    "title": "VoxArabica: A Robust Dialect-Aware Arabic Speech Recognition System",
    "abstract": " Comments: Accepted at ArabicNLP conference co-located with EMNLP'23. First three authors contributed equally ",
    "url": "https://arxiv.org/abs/2310.11069",
    "authors": [
      "Abdul Waheed",
      "Bashar Talafha",
      "Peter Sullivan",
      "AbdelRahim Elmadany",
      "Muhammad Abdul-Mageed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.12305",
    "title": "Building Random, Fair, and Verifiable Games on Blockchain. Raffle smart  contract designs on Sui Network",
    "abstract": " Title: Building Random, Fair, and Verifiable Games on Blockchain. Raffle smart  contract designs on Sui Network ",
    "url": "https://arxiv.org/abs/2310.12305",
    "authors": [
      "Eason Chen",
      "Justa Liang",
      "Ray Huang",
      "Pierce Hung",
      "Damien Chen",
      "Ashley Hsu",
      "Konstantinos Chalkias",
      "Stefanos Pleros"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.12692",
    "title": "Representation Learning via Consistent Assignment of Views over Random  Partitions",
    "abstract": " Comments: To appear in NeurIPS 2023. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2310.12692",
    "authors": [
      "Thalles Silva",
      "Ad\u00edn Ram\u00edrez Rivera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.13167",
    "title": "Visualizing Causality in Mixed Reality for Manual Task Learning: An  Exploratory Study",
    "abstract": " Title: Visualizing Causality in Mixed Reality for Manual Task Learning: An  Exploratory Study ",
    "url": "https://arxiv.org/abs/2310.13167",
    "authors": [
      "Rahul Jain",
      "Jingyu Shi",
      "Andrew Benton",
      "Moiz Rasheed",
      "Hyungjun Doh",
      "Subramanian Chidambaram",
      "Karthik Ramani"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2310.13786",
    "title": "Fundamental Limits of Membership Inference Attacks on Machine Learning  Models",
    "abstract": " Title: Fundamental Limits of Membership Inference Attacks on Machine Learning  Models ",
    "url": "https://arxiv.org/abs/2310.13786",
    "authors": [
      "Eric Aubinais",
      "Elisabeth Gassiat",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.14586",
    "title": "GNNEvaluator: Evaluating GNN Performance On Unseen Graphs Without Labels",
    "abstract": " Comments: Accepted by NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2310.14586",
    "authors": [
      "Xin Zheng",
      "Miao Zhang",
      "Chunyang Chen",
      "Soheila Molaei",
      "Chuan Zhou",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16314",
    "title": "Understanding Code Semantics: An Evaluation of Transformer Models in  Summarization",
    "abstract": " Comments: Accepted at GenBench, EMNLP 2023. All authors are co-first authors and have equal contributions ",
    "url": "https://arxiv.org/abs/2310.16314",
    "authors": [
      "Debanjan Mondal",
      "Abhilasha Lodha",
      "Ankita Sahoo",
      "Beena Kumari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16737",
    "title": "Translating Universal Scene Descriptions into Knowledge Graphs for  Robotic Environment",
    "abstract": " Comments: 6 pages, 3 figures, ICRA 2024 ",
    "url": "https://arxiv.org/abs/2310.16737",
    "authors": [
      "Giang Hoang Nguyen",
      "Daniel Bessler",
      "Simon Stelter",
      "Mihai Pomarlan",
      "Michael Beetz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2310.16832",
    "title": "LightSpeed: Light and Fast Neural Light Fields on Mobile Devices",
    "abstract": " Comments: Project Page: this http URL . Add camera ready version ",
    "url": "https://arxiv.org/abs/2310.16832",
    "authors": [
      "Aarush Gupta",
      "Junli Cao",
      "Chaoyang Wang",
      "Ju Hu",
      "Sergey Tulyakov",
      "Jian Ren",
      "L\u00e1szl\u00f3 A Jeni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.17015",
    "title": "Data Augmentation for Emotion Detection in Small Imbalanced Text Data",
    "abstract": " Comments: To be published in the Proceedings of IEEE International Conference on Machine Learning Applications IEEE (ICMLA 2023) ",
    "url": "https://arxiv.org/abs/2310.17015",
    "authors": [
      "Anna Koufakou",
      "Diego Grisales",
      "Ragy Costa de jesus",
      "Oscar Fox"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.17097",
    "title": "Navigating Data Heterogeneity in Federated Learning A Semi-Supervised  Approach for Object Detection",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2310.17097",
    "authors": [
      "Taehyeon Kim",
      "Eric Lin",
      "Junu Lee",
      "Christian Lau",
      "Vaikkunth Mugunthan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.17136",
    "title": "Core Challenge 2023: Solver and Graph Descriptions",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2208.02495, arXiv:2207.13959 ",
    "url": "https://arxiv.org/abs/2310.17136",
    "authors": [
      "Takehide Soh",
      "Tomoya Tanjo",
      "Yoshio Okamoto",
      "Takehiro Ito"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2310.17341",
    "title": "De-novo Chemical Reaction Generation by Means of Temporarily  Convolutional Neural Networks",
    "abstract": " Title: De-novo Chemical Reaction Generation by Means of Temporarily  Convolutional Neural Networks ",
    "url": "https://arxiv.org/abs/2310.17341",
    "authors": [
      "Andrei Buin",
      "Hung Yi Chiang",
      "S. Andrew Gadsden",
      "Faraz A. Alderson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.17523",
    "title": "Adaptive Resource Management for Edge Network Slicing using Incremental  Multi-Agent Deep Reinforcement Learning",
    "abstract": " Title: Adaptive Resource Management for Edge Network Slicing using Incremental  Multi-Agent Deep Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2310.17523",
    "authors": [
      "Haiyuan Li",
      "Yuelin Liu",
      "Xueqing Zhou",
      "Xenofon Vasilakos",
      "Reza Nejabati",
      "Shuangyi Yan",
      "Dimitra Simeonidou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.17594",
    "title": "SPA: A Graph Spectral Alignment Perspective for Domain Adaptation",
    "abstract": " Comments: NeurIPS 2023 camera ready ",
    "url": "https://arxiv.org/abs/2310.17594",
    "authors": [
      "Zhiqing Xiao",
      "Haobo Wang",
      "Ying Jin",
      "Lei Feng",
      "Gang Chen",
      "Fei Huang",
      "Junbo Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.17651",
    "title": "High-Dimensional Prediction for Sequential Decision Making",
    "abstract": " Comments: Added references, Arxiv abstract edited ",
    "url": "https://arxiv.org/abs/2310.17651",
    "authors": [
      "Georgy Noarov",
      "Ramya Ramalingam",
      "Aaron Roth",
      "Stephan Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  }
]