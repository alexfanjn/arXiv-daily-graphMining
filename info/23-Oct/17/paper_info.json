[
  {
    "id": "arXiv:2310.09297",
    "title": "Understanding AI Cognition: A Neural Module for Inference Inspired by  Human Memory Mechanisms",
    "abstract": "How humans and machines make sense of current inputs for relation reasoning and question-answering while putting the perceived information into context of our past memories, has been a challenging conundrum in cognitive science and artificial intelligence. Inspired by human brain's memory system and cognitive architectures, we propose a PMI framework that consists of perception, memory and inference components. Notably, the memory module comprises working and long-term memory, with the latter endowed with a higher-order structure to retain more accumulated knowledge and experiences. Through a differentiable competitive write access, current perceptions update working memory, which is later merged with long-term memory via outer product associations, averting memory overflow and minimizing information conflicts. In the inference module, relevant information is retrieved from two separate memory origins and associatively integrated to attain a more comprehensive and precise interpretation of current perceptions. We exploratively apply our PMI to improve prevailing Transformers and CNN models on question-answering tasks like bAbI-20k and Sort-of-CLEVR datasets, as well as relation calculation and image classification tasks, and in each case, our PMI enhancements consistently outshine their original counterparts significantly. Visualization analyses reveal that memory consolidation, along with the interaction and integration of information from diverse memory sources, substantially contributes to the model effectiveness on inference tasks. ",
    "url": "https://arxiv.org/abs/2310.09297",
    "authors": [
      "Xiangyu Zeng",
      "Jie Lin",
      "Piao Hu",
      "Ruizheng Huang",
      "Zhicheng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.09298",
    "title": "ByteStack-ID: Integrated Stacked Model Leveraging Payload Byte Frequency  for Grayscale Image-based Network Intrusion Detection",
    "abstract": "In the ever-evolving realm of network security, the swift and accurate identification of diverse attack classes within network traffic is of paramount importance. This paper introduces \"ByteStack-ID,\" a pioneering approach tailored for packet-level intrusion detection. At its core, ByteStack-ID leverages grayscale images generated from the frequency distributions of payload data, a groundbreaking technique that greatly enhances the model's ability to discern intricate data patterns. Notably, our approach is exclusively grounded in packet-level information, a departure from conventional Network Intrusion Detection Systems (NIDS) that predominantly rely on flow-based data. While building upon the fundamental concept of stacking methodology, ByteStack-ID diverges from traditional stacking approaches. It seamlessly integrates additional meta learner layers into the concatenated base learners, creating a highly optimized, unified model. Empirical results unequivocally confirm the outstanding effectiveness of the ByteStack-ID framework, consistently outperforming baseline models and state-of-the-art approaches across pivotal performance metrics, including precision, recall, and F1-score. Impressively, our proposed approach achieves an exceptional 81\\% macro F1-score in multiclass classification tasks. In a landscape marked by the continuous evolution of network threats, ByteStack-ID emerges as a robust and versatile security solution, relying solely on packet-level information extracted from network traffic data. ",
    "url": "https://arxiv.org/abs/2310.09298",
    "authors": [
      "Irfan Khan",
      "Yasir Ali Farrukh",
      "Syed Wali"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09299",
    "title": "Digital Twin Assisted Deep Reinforcement Learning for Online  Optimization of Network Slicing Admission Control",
    "abstract": "The proliferation of diverse network services in 5G and beyond networks has led to the emergence of network slicing technologies. Among these, admission control plays a crucial role in achieving specific optimization goals through the selective acceptance of service requests. Although Deep Reinforcement Learning (DRL) forms the foundation in many admission control approaches for its effectiveness and flexibility, the initial instability of DRL models hinders their practical deployment in real-world networks. In this work, we propose a digital twin (DT) assisted DRL solution to address this issue. Specifically, we first formulate the admission decision-making process as a semi-Markov decision process, which is subsequently simplified into an equivalent discrete-time Markov decision process to facilitate the implementation of DRL methods. The DT is established through supervised learning and employed to assist the training phase of the DRL model. Extensive simulations show that the DT-assisted DRL model increased resource utilization by over 40\\% compared to the directly trained state-of-the-art Dueling-DQN and over 20\\% compared to our directly trained DRL model during initial training. This improvement is achieved while preserving the model's capacity to optimize the long-term rewards. ",
    "url": "https://arxiv.org/abs/2310.09299",
    "authors": [
      "Zhenyu Tao",
      "Wei Xu",
      "Xiaohu You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.09340",
    "title": "Geo-knowledge-guided GPT models improve the extraction of location  descriptions from disaster-related social media messages",
    "abstract": "Social media messages posted by people during natural disasters often contain important location descriptions, such as the locations of victims. Recent research has shown that many of these location descriptions go beyond simple place names, such as city names and street names, and are difficult to extract using typical named entity recognition (NER) tools. While advanced machine learning models could be trained, they require large labeled training datasets that can be time-consuming and labor-intensive to create. In this work, we propose a method that fuses geo-knowledge of location descriptions and a Generative Pre-trained Transformer (GPT) model, such as ChatGPT and GPT-4. The result is a geo-knowledge-guided GPT model that can accurately extract location descriptions from disaster-related social media messages. Also, only 22 training examples encoding geo-knowledge are used in our method. We conduct experiments to compare this method with nine alternative approaches on a dataset of tweets from Hurricane Harvey. Our method demonstrates an over 40% improvement over typically used NER approaches. The experiment results also show that geo-knowledge is indispensable for guiding the behavior of GPT models. The extracted location descriptions can help disaster responders reach victims more quickly and may even save lives. ",
    "url": "https://arxiv.org/abs/2310.09340",
    "authors": [
      "Yingjie Hu",
      "Gengchen Mai",
      "Chris Cundy",
      "Kristy Choi",
      "Ni Lao",
      "Wei Liu",
      "Gaurish Lakhanpal",
      "Ryan Zhenqi Zhou",
      "Kenneth Joseph"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.09341",
    "title": "Addressing the cold start problem in privacy preserving content-based  recommender systems using hypercube graphs",
    "abstract": "The initial interaction of a user with a recommender system is problematic because, in such a so-called cold start situation, the recommender system has very little information about the user, if any. Moreover, in collaborative filtering, users need to share their preferences with the service provider by rating items while in content-based filtering there is no need for such information sharing. We have recently shown that a content-based model that uses hypercube graphs can determine user preferences with a very limited number of ratings while better preserving user privacy. In this paper, we confirm these findings on the basis of experiments with more than 1,000 users in the restaurant and movie domains. We show that the proposed method outperforms standard machine learning algorithms when the number of available ratings is at most 10, which often happens, and is competitive with larger training sets. In addition, training is simple and does not require large computational efforts. ",
    "url": "https://arxiv.org/abs/2310.09341",
    "authors": [
      "Noa Tuval",
      "Alain Hertz",
      "Tsvi Kuflik"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2310.09347",
    "title": "Efficient Apple Maturity and Damage Assessment: A Lightweight Detection  Model with GAN and Attention Mechanism",
    "abstract": "This study proposes a method based on lightweight convolutional neural networks (CNN) and generative adversarial networks (GAN) for apple ripeness and damage level detection tasks. Initially, a lightweight CNN model is designed by optimizing the model's depth and width, as well as employing advanced model compression techniques, successfully reducing the model's parameter and computational requirements, thus enhancing real-time performance in practical applications. Simultaneously, attention mechanisms are introduced, dynamically adjusting the importance of different feature layers to improve the performance in object detection tasks. To address the issues of sample imbalance and insufficient sample size, GANs are used to generate realistic apple images, expanding the training dataset and enhancing the model's recognition capability when faced with apples of varying ripeness and damage levels. Furthermore, by applying the object detection network for damage location annotation on damaged apples, the accuracy of damage level detection is improved, providing a more precise basis for decision-making. Experimental results show that in apple ripeness grading detection, the proposed model achieves 95.6\\%, 93.8\\%, 95.0\\%, and 56.5 in precision, recall, accuracy, and FPS, respectively. In apple damage level detection, the proposed model reaches 95.3\\%, 93.7\\%, and 94.5\\% in precision, recall, and mAP, respectively. In both tasks, the proposed method outperforms other mainstream models, demonstrating the excellent performance and high practical value of the proposed method in apple ripeness and damage level detection tasks. ",
    "url": "https://arxiv.org/abs/2310.09347",
    "authors": [
      "Yufei Liu",
      "Manzhou Li",
      "Qin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.09350",
    "title": "Unsupervised Domain Adaption for Neural Information Retrieval",
    "abstract": "Neural information retrieval requires costly annotated data for each target domain to be competitive. Synthetic annotation by query generation using Large Language Models or rule-based string manipulation has been proposed as an alternative, but their relative merits have not been analysed. In this paper, we compare both methods head-to-head using the same neural IR architecture. We focus on the BEIR benchmark, which includes test datasets from several domains with no training data, and explore two scenarios: zero-shot, where the supervised system is trained in a large out-of-domain dataset (MS-MARCO); and unsupervised domain adaptation, where, in addition to MS-MARCO, the system is fine-tuned in synthetic data from the target domain. Our results indicate that Large Language Models outperform rule-based methods in all scenarios by a large margin, and, more importantly, that unsupervised domain adaptation is effective compared to applying a supervised IR system in a zero-shot fashion. In addition we explore several sizes of open Large Language Models to generate synthetic data and find that a medium-sized model suffices. Code and models are publicly available for reproducibility. ",
    "url": "https://arxiv.org/abs/2310.09350",
    "authors": [
      "Carlos Dominguez",
      "Jon Ander Campos",
      "Eneko Agirre",
      "Gorka Azkune"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.09358",
    "title": "When are Bandits Robust to Misspecification?",
    "abstract": "Parametric feature-based reward models are widely employed by algorithms for decision making settings such as bandits and contextual bandits. The typical assumption under which they are analysed is realizability, i.e., that the true rewards of actions are perfectly explained by some parametric model in the class. We are, however, interested in the situation where the true rewards are (potentially significantly) misspecified with respect to the model class. For parameterized bandits and contextual bandits, we identify sufficient conditions, depending on the problem instance and model class, under which classic algorithms such as $\\epsilon$-greedy and LinUCB enjoy sublinear (in the time horizon) regret guarantees under even grossly misspecified rewards. This is in contrast to existing worst-case results for misspecified bandits which show regret bounds that scale linearly with time, and shows that there can be a nontrivially large set of bandit instances that are robust to misspecification. ",
    "url": "https://arxiv.org/abs/2310.09358",
    "authors": [
      "Debangshu Banerjee",
      "Aditya Gopalan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.09360",
    "title": "Exact Verification of ReLU Neural Control Barrier Functions",
    "abstract": "Control Barrier Functions (CBFs) are a popular approach for safe control of nonlinear systems. In CBF-based control, the desired safety properties of the system are mapped to nonnegativity of a CBF, and the control input is chosen to ensure that the CBF remains nonnegative for all time. Recently, machine learning methods that represent CBFs as neural networks (neural control barrier functions, or NCBFs) have shown great promise due to the universal representability of neural networks. However, verifying that a learned CBF guarantees safety remains a challenging research problem. This paper presents novel exact conditions and algorithms for verifying safety of feedforward NCBFs with ReLU activation functions. The key challenge in doing so is that, due to the piecewise linearity of the ReLU function, the NCBF will be nondifferentiable at certain points, thus invalidating traditional safety verification methods that assume a smooth barrier function. We resolve this issue by leveraging a generalization of Nagumo's theorem for proving invariance of sets with nonsmooth boundaries to derive necessary and sufficient conditions for safety. Based on this condition, we propose an algorithm for safety verification of NCBFs that first decomposes the NCBF into piecewise linear segments and then solves a nonlinear program to verify safety of each segment as well as the intersections of the linear segments. We mitigate the complexity by only considering the boundary of the safe region and by pruning the segments with Interval Bound Propagation (IBP) and linear relaxation. We evaluate our approach through numerical studies with comparison to state-of-the-art SMT-based methods. Our code is available at https://github.com/HongchaoZhang-HZ/exactverif-reluncbf-nips23. ",
    "url": "https://arxiv.org/abs/2310.09360",
    "authors": [
      "Hongchao Zhang",
      "Junlin Wu",
      "Yevgeniy Vorobeychik",
      "Andrew Clark"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09361",
    "title": "Is Certifying $\\ell_p$ Robustness Still Worthwhile?",
    "abstract": "Over the years, researchers have developed myriad attacks that exploit the ubiquity of adversarial examples, as well as defenses that aim to guard against the security vulnerabilities posed by such attacks. Of particular interest to this paper are defenses that provide provable guarantees against the class of $\\ell_p$-bounded attacks. Certified defenses have made significant progress, taking robustness certification from toy models and datasets to large-scale problems like ImageNet classification. While this is undoubtedly an interesting academic problem, as the field has matured, its impact in practice remains unclear, thus we find it useful to revisit the motivation for continuing this line of research. There are three layers to this inquiry, which we address in this paper: (1) why do we care about robustness research? (2) why do we care about the $\\ell_p$-bounded threat model? And (3) why do we care about certification as opposed to empirical defenses? In brief, we take the position that local robustness certification indeed confers practical value to the field of machine learning. We focus especially on the latter two questions from above. With respect to the first of the two, we argue that the $\\ell_p$-bounded threat model acts as a minimal requirement for safe application of models in security-critical domains, while at the same time, evidence has mounted suggesting that local robustness may lead to downstream external benefits not immediately related to robustness. As for the second, we argue that (i) certification provides a resolution to the cat-and-mouse game of adversarial attacks; and furthermore, that (ii) perhaps contrary to popular belief, there may not exist a fundamental trade-off between accuracy, robustness, and certifiability, while moreover, certified training techniques constitute a particularly promising way for learning robust models. ",
    "url": "https://arxiv.org/abs/2310.09361",
    "authors": [
      "Ravi Mangal",
      "Klas Leino",
      "Zifan Wang",
      "Kai Hu",
      "Weicheng Yu",
      "Corina Pasareanu",
      "Anupam Datta",
      "Matt Fredrikson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09383",
    "title": "Integrating Symbolic Reasoning into Neural Generative Models for Design  Generation",
    "abstract": "Design generation requires tight integration of neural and symbolic reasoning, as good design must meet explicit user needs and honor implicit rules for aesthetics, utility, and convenience. Current automated design tools driven by neural networks produce appealing designs, but cannot satisfy user specifications and utility requirements. Symbolic reasoning tools, such as constraint programming, cannot perceive low-level visual information in images or capture subtle aspects such as aesthetics. We introduce the Spatial Reasoning Integrated Generator (SPRING) for design generation. SPRING embeds a neural and symbolic integrated spatial reasoning module inside the deep generative network. The spatial reasoning module decides the locations of objects to be generated in the form of bounding boxes, which are predicted by a recurrent neural network and filtered by symbolic constraint satisfaction. Embedding symbolic reasoning into neural generation guarantees that the output of SPRING satisfies user requirements. Furthermore, SPRING offers interpretability, allowing users to visualize and diagnose the generation process through the bounding boxes. SPRING is also adept at managing novel user specifications not encountered during its training, thanks to its proficiency in zero-shot constraint transfer. Quantitative evaluations and a human study reveal that SPRING outperforms baseline generative models, excelling in delivering high design quality and better meeting user specifications. ",
    "url": "https://arxiv.org/abs/2310.09383",
    "authors": [
      "Maxwell Joseph Jacobson",
      "Yexiang Xue"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.09395",
    "title": "Medial Skeletal Diagram: A Generalized Medial Axis Approach for Compact  3D Shape Representation",
    "abstract": "We propose the Medial Skeletal Diagram, a novel skeletal representation that tackles the prevailing issues around compactness and reconstruction accuracy in existing skeletal representations. Our approach augments the continuous elements in the medial axis representation to effectively shift the complexity away from discrete elements. To that end, we introduce generalized enveloping primitives, an enhancement of the standard primitives in medial axis, which ensures efficient coverage of intricate local features of the input shape and substantially reduces the number of discrete elements required. Moreover, we present a computational framework that constructs a medial skeletal diagram from an arbitrary closed manifold mesh. Our optimization pipeline ensures that the resulting medial skeletal diagram comprehensively covers the input shape with the fewest primitives. Additionally, each optimized primitive undergoes a post-refinement process to guarantee an accurate match with the source mesh in both geometry and tessellation. We validate our approach on a comprehensive benchmark of 100 shapes, demonstrating its compactness of the discrete elements and superior reconstruction accuracy across a variety of cases. Furthermore, we exemplify the versatility of our representation in downstream applications such as shape optimization, shape generation, mesh decomposition, mesh alignment, mesh compression, and user-interactive design. ",
    "url": "https://arxiv.org/abs/2310.09395",
    "authors": [
      "Minghao Guo",
      "Bohan Wang",
      "Wojciech Matusik"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2310.09412",
    "title": "Hybrid Reinforcement Learning for Optimizing Pump Sustainability in  Real-World Water Distribution Networks",
    "abstract": "This article addresses the pump-scheduling optimization problem to enhance real-time control of real-world water distribution networks (WDNs). Our primary objectives are to adhere to physical operational constraints while reducing energy consumption and operational costs. Traditional optimization techniques, such as evolution-based and genetic algorithms, often fall short due to their lack of convergence guarantees. Conversely, reinforcement learning (RL) stands out for its adaptability to uncertainties and reduced inference time, enabling real-time responsiveness. However, the effective implementation of RL is contingent on building accurate simulation models for WDNs, and prior applications have been limited by errors in simulation training data. These errors can potentially cause the RL agent to learn misleading patterns and actions and recommend suboptimal operational strategies. To overcome these challenges, we present an improved \"hybrid RL\" methodology. This method integrates the benefits of RL while anchoring it in historical data, which serves as a baseline to incrementally introduce optimal control recommendations. By leveraging operational data as a foundation for the agent's actions, we enhance the explainability of the agent's actions, foster more robust recommendations, and minimize error. Our findings demonstrate that the hybrid RL agent can significantly improve sustainability, operational efficiency, and dynamically adapt to emerging scenarios in real-world WDNs. ",
    "url": "https://arxiv.org/abs/2310.09412",
    "authors": [
      "Harsh Patel",
      "Yuan Zhou",
      "Alexander P Lamb",
      "Shu Wang",
      "Jieliang Luo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09434",
    "title": "Learning nonlinear integral operators via Recurrent Neural Networks and  its application in solving Integro-Differential Equations",
    "abstract": "In this paper, we propose using LSTM-RNNs (Long Short-Term Memory-Recurrent Neural Networks) to learn and represent nonlinear integral operators that appear in nonlinear integro-differential equations (IDEs). The LSTM-RNN representation of the nonlinear integral operator allows us to turn a system of nonlinear integro-differential equations into a system of ordinary differential equations for which many efficient solvers are available. Furthermore, because the use of LSTM-RNN representation of the nonlinear integral operator in an IDE eliminates the need to perform a numerical integration in each numerical time evolution step, the overall temporal cost of the LSTM-RNN-based IDE solver can be reduced to $O(n_T)$ from $O(n_T^2)$ if a $n_T$-step trajectory is to be computed. We illustrate the efficiency and robustness of this LSTM-RNN-based numerical IDE solver with a model problem. Additionally, we highlight the generalizability of the learned integral operator by applying it to IDEs driven by different external forces. As a practical application, we show how this methodology can effectively solve the Dyson's equation for quantum many-body systems. ",
    "url": "https://arxiv.org/abs/2310.09434",
    "authors": [
      "Hardeep Bassi",
      "Yuanran Zhu",
      "Senwei Liang",
      "Jia Yin",
      "Cian C. Reeves",
      "Vojtech Vlcek",
      "Chao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2310.09461",
    "title": "MAC: ModAlity Calibration for Object Detection",
    "abstract": "The flourishing success of Deep Neural Networks(DNNs) on RGB-input perception tasks has opened unbounded possibilities for non-RGB-input perception tasks, such as object detection from wireless signals, lidar scans, and infrared images. Compared to the matured development pipeline of RGB-input (source modality) models, developing non-RGB-input (target-modality) models from scratch poses excessive challenges in the modality-specific network design/training tricks and labor in the target-modality annotation. In this paper, we propose ModAlity Calibration (MAC), an efficient pipeline for calibrating target-modality inputs to the DNN object detection models developed on the RGB (source) modality. We compose a target-modality-input model by adding a small calibrator module ahead of a source-modality model and introduce MAC training techniques to impose dense supervision on the calibrator. By leveraging (1) prior knowledge synthesized from the source-modality model and (2) paired {target, source} data with zero manual annotations, our target-modality models reach comparable or better metrics than baseline models that require 100% manual annotations. We demonstrate the effectiveness of MAC by composing the WiFi-input, Lidar-input, and Thermal-Infrared-input models upon the pre-trained RGB-input models respectively. ",
    "url": "https://arxiv.org/abs/2310.09461",
    "authors": [
      "Yutian Lei",
      "Jun Liu",
      "Dong Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.09462",
    "title": "A Framework for Empowering Reinforcement Learning Agents with Causal  Analysis: Enhancing Automated Cryptocurrency Trading",
    "abstract": "Despite advances in artificial intelligence-enhanced trading methods, developing a profitable automated trading system remains challenging in the rapidly evolving cryptocurrency market. This study aims to address these challenges by developing a reinforcement learning-based automated trading system for five popular altcoins~(cryptocurrencies other than Bitcoin): Binance Coin, Ethereum, Litecoin, Ripple, and Tether. To this end, we present CausalReinforceNet, a framework framed as a decision support system. Designed as the foundational architecture of the trading system, the CausalReinforceNet framework enhances the capabilities of the reinforcement learning agent through causal analysis. Within this framework, we use Bayesian networks in the feature engineering process to identify the most relevant features with causal relationships that influence cryptocurrency price movements. Additionally, we incorporate probabilistic price direction signals from dynamic Bayesian networks to enhance our reinforcement learning agent's decision-making. Due to the high volatility of the cryptocurrency market, we design our framework to adopt a conservative approach that limits sell and buy position sizes to manage risk. We develop two agents using the CausalReinforceNet framework, each based on distinct reinforcement learning algorithms. The results indicate that our framework substantially surpasses the Buy-and-Hold benchmark strategy in profitability. Additionally, both agents generated notable returns on investment for Binance Coin and Ethereum. ",
    "url": "https://arxiv.org/abs/2310.09462",
    "authors": [
      "Rasoul Amirzadeh",
      "Dhananjay Thiruvady",
      "Asef Nazari",
      "Mong Shan Ee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09466",
    "title": "Robust Anti-jamming Communications with DMA-Based Reconfigurable  Heterogeneous Array",
    "abstract": "In the future commercial and military communication systems, anti-jamming remains a critical issue. Existing homogeneous or heterogeneous arrays with a limited degrees of freedom (DoF) and high consumption are unable to meet the requirements of communication in rapidly changing and intense jamming environments. To address these challenges, we propose a reconfigurable heterogeneous array (RHA) architecture based on dynamic metasurface antenna (DMA), which will increase the DoF and further improve anti-jamming capabilities. We propose a two-step anti-jamming scheme based on RHA, where the multipaths are estimated by an atomic norm minimization (ANM) based scheme, and then the received signal-to-interference-plus-noise ratio (SINR) is maximized by jointly designing the phase shift of each DMA element and the weights of the array elements. To solve the challenging non-convex discrete fractional problem along with the estimation error in the direction of arrival (DoA) and channel state information (CSI), we propose a robust alternative algorithm based on the S-procedure to solve the lower-bound SINR maximization problem. Simulation results demonstrate that the proposed RHA architecture and corresponding schemes have superior performance in terms of jamming immunity and robustness. ",
    "url": "https://arxiv.org/abs/2310.09466",
    "authors": [
      "Kaizhi Huang",
      "Wenyu Jiang",
      "Yajun Chen",
      "Liang Jin",
      "Qingqing Wu",
      "Xiaoling Hu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.09483",
    "title": "Sorting and Selection in Rounds with Adversarial Comparisons",
    "abstract": "We continue the study of selection and sorting of $n$ numbers under the adversarial comparator model, where comparisons can be adversarially tampered with if the arguments are sufficiently close. We derive a randomized sorting algorithm that does $O(n \\log^2 n)$ comparisons and gives a correct answer with high probability, addressing an open problem of Ajtai, Feldman, Hassadim, and Nelson [AFHN15]. Our algorithm also implies a selection algorithm that does $O(n \\log n)$ comparisons and gives a correct answer with high probability. Both of these results are a $\\log$ factor away from the naive lower bound. [AFHN15] shows an $\\Omega(n^{1+\\varepsilon})$ lower bound for both sorting and selection in the deterministic case, so our results also prove a discrepancy between what is possible with deterministic and randomized algorithms in this setting. We also consider both sorting and selection in rounds, exploring the tradeoff between accuracy, number of comparisons, and number of rounds. Using results from sorting networks, we give general algorithms for sorting in $d$ rounds where the number of comparisons increases with $d$ and the accuracy decreases with $d$. Using these algorithms, we derive selection algorithms in $d+O(\\log d)$ rounds that use the same number of comparisons as the corresponding sorting algorithm, but have a constant accuracy. Notably, this gives selection algorithms in $d$ rounds that use $n^{1 + o(1)}$ comparisons and have constant accuracy for all $d = \\omega(1)$, which still beats the deterministic lower bound of $\\Omega(n^{1+\\varepsilon})$. ",
    "url": "https://arxiv.org/abs/2310.09483",
    "authors": [
      "Christopher Trevisan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2310.09485",
    "title": "Applying Bayesian Ridge Regression AI Modeling in Virus Severity  Prediction",
    "abstract": "Artificial intelligence (AI) is a powerful tool for reshaping healthcare systems. In healthcare, AI is invaluable for its capacity to manage vast amounts of data, which can lead to more accurate and speedy diagnoses, ultimately easing the workload on healthcare professionals. As a result, AI has proven itself to be a power tool across various industries, simplifying complex tasks and pattern recognition that would otherwise be overwhelming for humans or traditional computer algorithms. In this paper, we review the strengths and weaknesses of Bayesian Ridge Regression, an AI model that can be used to bring cutting edge virus analysis to healthcare professionals around the world. The model's accuracy assessment revealed promising results, with room for improvement primarily related to data organization. In addition, the severity index serves as a valuable tool to gain a broad overview of patient care needs, aligning with healthcare professionals' preference for broader categorizations. ",
    "url": "https://arxiv.org/abs/2310.09485",
    "authors": [
      "Jai Pal",
      "Bryan Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09486",
    "title": "Mirage: Model-Agnostic Graph Distillation for Graph Classification",
    "abstract": "GNNs, like other deep learning models, are data and computation hungry. There is a pressing need to scale training of GNNs on large datasets to enable their usage on low-resource environments. Graph distillation is an effort in that direction with the aim to construct a smaller synthetic training set from the original training data without significantly compromising model performance. While initial efforts are promising, this work is motivated by two key observations: (1) Existing graph distillation algorithms themselves rely on training with the full dataset, which undermines the very premise of graph distillation. (2) The distillation process is specific to the target GNN architecture and hyper-parameters and thus not robust to changes in the modeling pipeline. We circumvent these limitations by designing a distillation algorithm called Mirage for graph classification. Mirage is built on the insight that a message-passing GNN decomposes the input graph into a multiset of computation trees. Furthermore, the frequency distribution of computation trees is often skewed in nature, enabling us to condense this data into a concise distilled summary. By compressing the computation data itself, as opposed to emulating gradient flows on the original training set-a prevalent approach to date-Mirage transforms into an unsupervised and architecture-agnostic distillation algorithm. Extensive benchmarking on real-world datasets underscores Mirage's superiority, showcasing enhanced generalization accuracy, data compression, and distillation efficiency when compared to state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2310.09486",
    "authors": [
      "Mridul Gupta",
      "Sahil Manchanda",
      "Sayan Ranu",
      "Hariprasad Kodamana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.09492",
    "title": "Perception Reinforcement Using Auxiliary Learning Feature Fusion: A  Modified Yolov8 for Head Detection",
    "abstract": "Head detection provides distribution information of pedestrian, which is crucial for scene statistical analysis, traffic management, and risk assessment and early warning. However, scene complexity and large-scale variation in the real world make accurate detection more difficult. Therefore, we present a modified Yolov8 which improves head detection performance through reinforcing target perception. An Auxiliary Learning Feature Fusion (ALFF) module comprised of LSTM and convolutional blocks is used as the auxiliary task to help the model perceive targets. In addition, we introduce Noise Calibration into Distribution Focal Loss to facilitate model fitting and improve the accuracy of detection. Considering the requirements of high accuracy and speed for the head detection task, our method is adapted with two kinds of backbone, namely Yolov8n and Yolov8m. The results demonstrate the superior performance of our approach in improving detection accuracy and robustness. ",
    "url": "https://arxiv.org/abs/2310.09492",
    "authors": [
      "Jiezhou Chen",
      "Guankun Wang",
      "Weixiang Liu",
      "Xiaopin Zhong",
      "Yibin Tian",
      "ZongZe Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.09503",
    "title": "JM3D & JM3D-LLM: Elevating 3D Representation with Joint Multi-modal Cues",
    "abstract": "The rising importance of 3D representation learning, pivotal in computer vision, autonomous driving, and robotics, is evident. However, a prevailing trend, which straightforwardly resorted to transferring 2D alignment strategies to the 3D domain, encounters three distinct challenges: (1) Information Degradation: This arises from the alignment of 3D data with mere single-view 2D images and generic texts, neglecting the need for multi-view images and detailed subcategory texts. (2) Insufficient Synergy: These strategies align 3D representations to image and text features individually, hampering the overall optimization for 3D models. (3) Underutilization: The fine-grained information inherent in the learned representations is often not fully exploited, indicating a potential loss in detail. To address these issues, we introduce JM3D, a comprehensive approach integrating point cloud, text, and image. Key contributions include the Structured Multimodal Organizer (SMO), enriching vision-language representation with multiple views and hierarchical text, and the Joint Multi-modal Alignment (JMA), combining language understanding with visual representation. Our advanced model, JM3D-LLM, marries 3D representation with large language models via efficient fine-tuning. Evaluations on ModelNet40 and ScanObjectNN establish JM3D's superiority. The superior performance of JM3D-LLM further underscores the effectiveness of our representation transfer approach. Our code and models are available at https://github.com/Mr-Neko/JM3D. ",
    "url": "https://arxiv.org/abs/2310.09503",
    "authors": [
      "Jiayi Ji",
      "Haowei Wang",
      "Changli Wu",
      "Yiwei Ma",
      "Xiaoshuai Sun",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.09504",
    "title": "Node Dissimilarity Index for Complex Network Analysis",
    "abstract": "We propose a principal component analysis (PCA)-based approach to quantify (the node dissimilarity index, NDI) the extent of dissimilarity among nodes in a network with respect to values incurred for a suite of node-level metrics (like centrality metrics). We subject the dataset (n nodes and their values incurred for four commonly studied centrality metrics: degree, eigenvector, betweenness and closeness) to PCA and retain the m ( <= 4) principal components (with variance >= 1.0). We construct an n-node dissimilarity matrix whose entries are the absolute difference (if m = 1) or Euclidean distance (if M > 1) of the principal component coordinates of the corresponding nodes. We compute NDI (>= 1.0) to be the ratio of the principal Eigenvalue of the node dissimilarity matrix and average of entries in the node dissimilarity matrix. The larger the NDI, the greater the dissimilarity among the node-level metrics (centrality metrics) values considered for analysis. ",
    "url": "https://arxiv.org/abs/2310.09504",
    "authors": [
      "Natarajan Meghanathan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.09507",
    "title": "Foundation Ark: Accruing and Reusing Knowledge for Superior and Robust  Performance",
    "abstract": "Deep learning nowadays offers expert-level and sometimes even super-expert-level performance, but achieving such performance demands massive annotated data for training (e.g., Google's proprietary CXR Foundation Model (CXR-FM) was trained on 821,544 labeled and mostly private chest X-rays (CXRs)). Numerous datasets are publicly available in medical imaging but individually small and heterogeneous in expert labels. We envision a powerful and robust foundation model that can be trained by aggregating numerous small public datasets. To realize this vision, we have developed Ark, a framework that accrues and reuses knowledge from heterogeneous expert annotations in various datasets. As a proof of concept, we have trained two Ark models on 335,484 and 704,363 CXRs, respectively, by merging several datasets including ChestX-ray14, CheXpert, MIMIC-II, and VinDr-CXR, evaluated them on a wide range of imaging tasks covering both classification and segmentation via fine-tuning, linear-probing, and gender-bias analysis, and demonstrated our Ark's superior and robust performance over the SOTA fully/self-supervised baselines and Google's proprietary CXR-FM. This enhanced performance is attributed to our simple yet powerful observation that aggregating numerous public datasets diversifies patient populations and accrues knowledge from diverse experts, yielding unprecedented performance yet saving annotation cost. With all codes and pretrained models released at GitHub.com/JLiangLab/Ark, we hope that Ark exerts an important impact on open science, as accruing and reusing knowledge from expert annotations in public datasets can potentially surpass the performance of proprietary models trained on unusually large data, inspiring many more researchers worldwide to share codes and datasets to build open foundation models, accelerate open science, and democratize deep learning for medical imaging. ",
    "url": "https://arxiv.org/abs/2310.09507",
    "authors": [
      "DongAo Ma",
      "Jiaxuan Pang",
      "Michael B. Gotway",
      "Jianming Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.09510",
    "title": "Survey on Security Attacks in Connected and Autonomous Vehicular Systems",
    "abstract": "Connected and autonomous vehicles, also known as CAVs, are a general trend in the evolution of the automotive industry that can be utilized to make transportation safer, improve the number of mobility options available, user costs will go down and new jobs will be created. However, as our society grows more automated and networked, criminal actors will have additional opportunities to conduct a variety of attacks, putting CAV security in danger. By providing a brief review of the state of cyber security in the CAVs environment, this study aims to draw attention to the issues and concerns associated with security. The first thing it does is categorize the multiple cybersecurity threats and weaknesses in the context of CAVs into three groups: attacks on the vehicles network, attacks on the Internet at large, and other attacks. This is done in accordance with the various communication networks and targets under attack. Next, it considers the possibility of cyber attacks to be an additional form of threat posed by the environment of CAVs. After that, it details the most uptodate defense tactics for securing CAVs and analyzes how effective they are. In addition, it draws some conclusions about the various cyber security and safety requirements of CAVs that are now available, which is beneficial for the use of CAVs in the real world. At the end, we discussed some implications on Adversary Attacks on Autonomous Vehicles. In conclusion, a number of difficulties and unsolved issues for future research are analyzed and explored. ",
    "url": "https://arxiv.org/abs/2310.09510",
    "authors": [
      "S M Mostaq Hossain",
      "Shampa Banik",
      "Trapa Banik",
      "Ashfak Md Shibli"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.09516",
    "title": "Efficient Link Prediction via GNN Layers Induced by Negative Sampling",
    "abstract": "Graph neural networks (GNNs) for link prediction can loosely be divided into two broad categories. First, \\emph{node-wise} architectures pre-compute individual embeddings for each node that are later combined by a simple decoder to make predictions. While extremely efficient at inference time (since node embeddings are only computed once and repeatedly reused), model expressiveness is limited such that isomorphic nodes contributing to candidate edges may not be distinguishable, compromising accuracy. In contrast, \\emph{edge-wise} methods rely on the formation of edge-specific subgraph embeddings to enrich the representation of pair-wise relationships, disambiguating isomorphic nodes to improve accuracy, but with the cost of increased model complexity. To better navigate this trade-off, we propose a novel GNN architecture whereby the \\emph{forward pass} explicitly depends on \\emph{both} positive (as is typical) and negative (unique to our approach) edges to inform more flexible, yet still cheap node-wise embeddings. This is achieved by recasting the embeddings themselves as minimizers of a forward-pass-specific energy function (distinct from the actual training loss) that favors separation of positive and negative samples. As demonstrated by extensive empirical evaluations, the resulting architecture retains the inference speed of node-wise models, while producing competitive accuracy with edge-wise alternatives. ",
    "url": "https://arxiv.org/abs/2310.09516",
    "authors": [
      "Yuxin Wang",
      "Xiannian Hu",
      "Quan Gan",
      "Xuanjing Huang",
      "Xipeng Qiu",
      "David Wipf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.09522",
    "title": "Dynamic Prediction of Full-Ocean Depth SSP by Hierarchical LSTM: An  Experimental Result",
    "abstract": "SSP distribution is an important parameter for underwater positioning, navigation and timing (PNT) because it affects the propagation mode of underwater acoustic signals. To accurate predict future sound speed distribution, we propose a hierarchical long short--term memory (H--LSTM) neural network for future sound speed prediction, which explore the distribution pattern of sound velocity in the time dimension. To verify the feasibility and effectiveness, we conducted both simulations and real experiments. The ocean experiment was held in the South China Sea in April, 2023. Results show that the accuracy of the proposed method outperforms the state--of--the--art methods. ",
    "url": "https://arxiv.org/abs/2310.09522",
    "authors": [
      "Jiajun Lu",
      "Wei Huang",
      "Hao Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.09525",
    "title": "TS-ENAS:Two-Stage Evolution for Cell-based Network Architecture Search",
    "abstract": "Neural network architecture search provides a solution to the automatic design of network structures. However, it is difficult to search the whole network architecture directly. Although using stacked cells to search neural network architectures is an effective way to reduce the complexity of searching, these methods do not able find the global optimal neural network structure since the number of layers, cells and connection methods is fixed. In this paper, we propose a Two-Stage Evolution for cell-based Network Architecture Search(TS-ENAS), including one-stage searching based on stacked cells and second-stage adjusting these cells. In our algorithm, a new cell-based search space and an effective two-stage encoding method are designed to represent cells and neural network structures. In addition, a cell-based weight inheritance strategy is designed to initialize the weight of the network, which significantly reduces the running time of the algorithm. The proposed methods are extensively tested and compared on four image classification dataset, Fashion-MNIST, CIFAR10, CIFAR100 and ImageNet and compared with 22 state-of-the-art algorithms including hand-designed networks and NAS networks. The experimental results show that TS-ENAS can more effectively find the neural network architecture with comparative performance. ",
    "url": "https://arxiv.org/abs/2310.09525",
    "authors": [
      "Juan Zou",
      "Shenghong Wu",
      "Yizhang Xia",
      "Weiwei Jiang",
      "Zeping Wu",
      "Jinhua Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.09527",
    "title": "A discontinuous plane wave neural network method for Helmholtz equation  and time-harmonic Maxwell's equations",
    "abstract": "In this paper we propose a {\\it discontinuous} plane wave neural network (DPWNN) method with $hp-$refinement for approximately solving Helmholtz equation and time-harmonic Maxwell equations. In this method, we define a quadratic functional as in the plane wave least square (PWLS) method with $h-$refinement and introduce new discretization sets spanned by element-wise neural network functions with a single hidden layer, where the activation function on each element is chosen as a complex-valued exponential function like the plane wave function. The desired approximate solution is recursively generated by iteratively solving the minimization problem associated with the functional and the sets described above, which is defined by a sequence of approximate minimizers of the underlying residual functionals, where plane wave direction angles and activation coefficients are alternatively computed by iterative algorithms. For the proposed DPWNN method, the plane wave directions are adaptively determined in the iterative process, which is different from that in the standard PWLS method (where the plane wave directions are preliminarily given). Numerical experiments will confirm that this DPWNN method can generate approximate solutions with higher accuracy than the PWLS method. ",
    "url": "https://arxiv.org/abs/2310.09527",
    "authors": [
      "Long Yuan",
      "Qiya Hu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.09528",
    "title": "Hypernetwork-based Meta-Learning for Low-Rank Physics-Informed Neural  Networks",
    "abstract": "In various engineering and applied science applications, repetitive numerical simulations of partial differential equations (PDEs) for varying input parameters are often required (e.g., aircraft shape optimization over many design parameters) and solvers are required to perform rapid execution. In this study, we suggest a path that potentially opens up a possibility for physics-informed neural networks (PINNs), emerging deep-learning-based solvers, to be considered as one such solver. Although PINNs have pioneered a proper integration of deep-learning and scientific computing, they require repetitive time-consuming training of neural networks, which is not suitable for many-query scenarios. To address this issue, we propose a lightweight low-rank PINNs containing only hundreds of model parameters and an associated hypernetwork-based meta-learning algorithm, which allows efficient approximation of solutions of PDEs for varying ranges of PDE input parameters. Moreover, we show that the proposed method is effective in overcoming a challenging issue, known as \"failure modes\" of PINNs. ",
    "url": "https://arxiv.org/abs/2310.09528",
    "authors": [
      "Woojin Cho",
      "Kookjin Lee",
      "Donsub Rim",
      "Noseong Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2310.09533",
    "title": "Towards End-to-End Unsupervised Saliency Detection with Self-Supervised  Top-Down Context",
    "abstract": "Unsupervised salient object detection aims to detect salient objects without using supervision signals eliminating the tedious task of manually labeling salient objects. To improve training efficiency, end-to-end methods for USOD have been proposed as a promising alternative. However, current solutions rely heavily on noisy handcraft labels and fail to mine rich semantic information from deep features. In this paper, we propose a self-supervised end-to-end salient object detection framework via top-down context. Specifically, motivated by contrastive learning, we exploit the self-localization from the deepest feature to construct the location maps which are then leveraged to learn the most instructive segmentation guidance. Further considering the lack of detailed information in deepest features, we exploit the detail-boosting refiner module to enrich the location labels with details. Moreover, we observe that due to lack of supervision, current unsupervised saliency models tend to detect non-salient objects that are salient in some other samples of corresponding scenarios. To address this widespread issue, we design a novel Unsupervised Non-Salient Suppression (UNSS) method developing the ability to ignore non-salient objects. Extensive experiments on benchmark datasets demonstrate that our method achieves leading performance among the recent end-to-end methods and most of the multi-stage solutions. The code is available. ",
    "url": "https://arxiv.org/abs/2310.09533",
    "authors": [
      "Yicheng Song",
      "Shuyong Gao",
      "Haozhe Xing",
      "Yiting Cheng",
      "Yan Wang",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.09554",
    "title": "Neural network scoring for efficient computing",
    "abstract": "Much work has been dedicated to estimating and optimizing workloads in high-performance computing (HPC) and deep learning. However, researchers have typically relied on few metrics to assess the efficiency of those techniques. Most notably, the accuracy, the loss of the prediction, and the computational time with regard to GPUs or/and CPUs characteristics. It is rare to see figures for power consumption, partly due to the difficulty of obtaining accurate power readings. In this paper, we introduce a composite score that aims to characterize the trade-off between accuracy and power consumption measured during the inference of neural networks. For this purpose, we present a new open-source tool allowing researchers to consider more metrics: granular power consumption, but also RAM/CPU/GPU utilization, as well as storage, and network input/output (I/O). To our best knowledge, it is the first fit test for neural architectures on hardware architectures. This is made possible thanks to reproducible power efficiency measurements. We applied this procedure to state-of-the-art neural network architectures on miscellaneous hardware. One of the main applications and novelties is the measurement of algorithmic power efficiency. The objective is to allow researchers to grasp their algorithms' efficiencies better. This methodology was developed to explore trade-offs between energy usage and accuracy in neural networks. It is also useful when fitting hardware for a specific task or to compare two architectures more accurately, with architecture exploration in mind. ",
    "url": "https://arxiv.org/abs/2310.09554",
    "authors": [
      "Hugo Waltsburger",
      "Erwan Libessart",
      "Chengfang Ren",
      "Anthony Kolar",
      "Regis Guinvarc'h"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09561",
    "title": "Graph Neural Network approaches for single-cell data: A recent overview",
    "abstract": "Graph Neural Networks (GNN) are reshaping our understanding of biomedicine and diseases by revealing the deep connections among genes and cells. As both algorithmic and biomedical technologies have advanced significantly, we're entering a transformative phase of personalized medicine. While pioneering tools like Graph Attention Networks (GAT) and Graph Convolutional Neural Networks (Graph CNN) are advancing graph-based learning, the rise of single-cell sequencing techniques is reshaping our insights on cellular diversity and function. Numerous studies have combined GNNs with single-cell data, showing promising results. In this work, we highlight the GNN methodologies tailored for single-cell data over the recent years. We outline the diverse range of graph deep learning architectures that center on GAT methodologies. Furthermore, we underscore the several objectives of GNN strategies in single-cell data contexts, ranging from cell-type annotation, data integration and imputation, gene regulatory network reconstruction, clustering and many others. This review anticipates a future where GNNs become central to single-cell analysis efforts, particularly as vast omics datasets are continuously generated and the interconnectedness of cells and genes enhances our depth of knowledge in biomedicine. ",
    "url": "https://arxiv.org/abs/2310.09561",
    "authors": [
      "Konstantinos Lazaros",
      "Dimitris E. Koumadorakis",
      "Panagiotis Vlamos",
      "Aristidis G. Vrahatis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Genomics (q-bio.GN)"
    ]
  },
  {
    "id": "arXiv:2310.09571",
    "title": "On the Feasibility of Cross-Language Detection of Malicious Packages in  npm and PyPI",
    "abstract": "Current software supply chains heavily rely on open-source packages hosted in public repositories. Given the popularity of ecosystems like npm and PyPI, malicious users started to spread malware by publishing open-source packages containing malicious code. Recent works apply machine learning techniques to detect malicious packages in the npm ecosystem. However, the scarcity of samples poses a challenge to the application of machine learning techniques in other ecosystems. Despite the differences between JavaScript and Python, the open-source software supply chain attacks targeting such languages show noticeable similarities (e.g., use of installation scripts, obfuscated strings, URLs). In this paper, we present a novel approach that involves a set of language-independent features and the training of models capable of detecting malicious packages in npm and PyPI by capturing their commonalities. This methodology allows us to train models on a diverse dataset encompassing multiple languages, thereby overcoming the challenge of limited sample availability. We evaluate the models both in a controlled experiment (where labels of data are known) and in the wild by scanning newly uploaded packages for both npm and PyPI for 10 days. We find that our approach successfully detects malicious packages for both npm and PyPI. Over an analysis of 31,292 packages, we reported 58 previously unknown malicious packages (38 for npm and 20 for PyPI), which were consequently removed from the respective repositories. ",
    "url": "https://arxiv.org/abs/2310.09571",
    "authors": [
      "Piergiorgio Ladisa",
      "Serena Elisa Ponta",
      "Nicola Ronzoni",
      "Matias Martinez",
      "Olivier Barais"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.09583",
    "title": "Two Sides of The Same Coin: Bridging Deep Equilibrium Models and Neural  ODEs via Homotopy Continuation",
    "abstract": "Deep Equilibrium Models (DEQs) and Neural Ordinary Differential Equations (Neural ODEs) are two branches of implicit models that have achieved remarkable success owing to their superior performance and low memory consumption. While both are implicit models, DEQs and Neural ODEs are derived from different mathematical formulations. Inspired by homotopy continuation, we establish a connection between these two models and illustrate that they are actually two sides of the same coin. Homotopy continuation is a classical method of solving nonlinear equations based on a corresponding ODE. Given this connection, we proposed a new implicit model called HomoODE that inherits the property of high accuracy from DEQs and the property of stability from Neural ODEs. Unlike DEQs, which explicitly solve an equilibrium-point-finding problem via Newton's methods in the forward pass, HomoODE solves the equilibrium-point-finding problem implicitly using a modified Neural ODE via homotopy continuation. Further, we developed an acceleration method for HomoODE with a shared learnable initial point. It is worth noting that our model also provides a better understanding of why Augmented Neural ODEs work as long as the augmented part is regarded as the equilibrium point to find. Comprehensive experiments with several image classification tasks demonstrate that HomoODE surpasses existing implicit models in terms of both accuracy and memory consumption. ",
    "url": "https://arxiv.org/abs/2310.09583",
    "authors": [
      "Shutong Ding",
      "Tianyu Cui",
      "Jingya Wang",
      "Ye Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.09586",
    "title": "Causality and Independence Enhancement for Biased Node Classification",
    "abstract": "Most existing methods that address out-of-distribution (OOD) generalization for node classification on graphs primarily focus on a specific type of data biases, such as label selection bias or structural bias. However, anticipating the type of bias in advance is extremely challenging, and designing models solely for one specific type may not necessarily improve overall generalization performance. Moreover, limited research has focused on the impact of mixed biases, which are more prevalent and demanding in real-world scenarios. To address these limitations, we propose a novel Causality and Independence Enhancement (CIE) framework, applicable to various graph neural networks (GNNs). Our approach estimates causal and spurious features at the node representation level and mitigates the influence of spurious correlations through the backdoor adjustment. Meanwhile, independence constraint is introduced to improve the discriminability and stability of causal and spurious features in complex biased environments. Essentially, CIE eliminates different types of data biases from a unified perspective, without the need to design separate methods for each bias as before. To evaluate the performance under specific types of data biases, mixed biases, and low-resource scenarios, we conducted comprehensive experiments on five publicly available datasets. Experimental results demonstrate that our approach CIE not only significantly enhances the performance of GNNs but outperforms state-of-the-art debiased node classification methods. ",
    "url": "https://arxiv.org/abs/2310.09586",
    "authors": [
      "Guoxin Chen",
      "Yongqing Wang",
      "Fangda Guo",
      "Qinglang Guo",
      "Jiangli Shao",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09593",
    "title": "Context-aware Session-based Recommendation with Graph Neural Networks",
    "abstract": "Session-based recommendation (SBR) is a task that aims to predict items based on anonymous sequences of user behaviors in a session. While there are methods that leverage rich context information in sessions for SBR, most of them have the following limitations: 1) they fail to distinguish the item-item edge types when constructing the global graph for exploiting cross-session contexts; 2) they learn a fixed embedding vector for each item, which lacks the flexibility to reflect the variation of user interests across sessions; 3) they generally use the one-hot encoded vector of the target item as the hard label to predict, thus failing to capture the true user preference. To solve these issues, we propose CARES, a novel context-aware session-based recommendation model with graph neural networks, which utilizes different types of contexts in sessions to capture user interests. Specifically, we first construct a multi-relation cross-session graph to connect items according to intra- and cross-session item-level contexts. Further, to encode the variation of user interests, we design personalized item representations. Finally, we employ a label collaboration strategy for generating soft user preference distribution as labels. Experiments on three benchmark datasets demonstrate that CARES consistently outperforms state-of-the-art models in terms of P@20 and MRR@20. Our data and codes are publicly available at https://github.com/brilliantZhang/CARES. ",
    "url": "https://arxiv.org/abs/2310.09593",
    "authors": [
      "Zhihui Zhang",
      "JianXiang Yu",
      "Xiang Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.09609",
    "title": "Towards Intelligent Network Management: Leveraging AI for Network  Service Detection",
    "abstract": "As the complexity and scale of modern computer networks continue to increase, there has emerged an urgent need for precise traffic analysis, which plays a pivotal role in cutting-edge wireless connectivity technologies. This study focuses on leveraging Machine Learning methodologies to create an advanced network traffic classification system. We introduce a novel data-driven approach that excels in identifying various network service types in real-time, by analyzing patterns within the network traffic. Our method organizes similar kinds of network traffic into distinct categories, referred to as network services, based on latency requirement. Furthermore, it decomposes the network traffic stream into multiple, smaller traffic flows, with each flow uniquely carrying a specific service. Our ML models are trained on a dataset comprised of labeled examples representing different network service types collected on various Wi-Fi network conditions. Upon evaluation, our system demonstrates a remarkable accuracy in distinguishing the network services. These results emphasize the substantial promise of integrating Artificial Intelligence in wireless technologies. Such an approach encourages more efficient energy consumption, enhances Quality of Service assurance, and optimizes the allocation of network resources, thus laying a solid groundwork for the development of advanced intelligent networks. ",
    "url": "https://arxiv.org/abs/2310.09609",
    "authors": [
      "Khuong N. Nguyen",
      "Abhishek Sehgal",
      "Yuming Zhu",
      "Junsu Choi",
      "Guanbo Chen",
      "Hao Chen",
      "Boon Loong Ng",
      "Charlie Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.09612",
    "title": "Deep Neural Networks Can Learn Generalizable Same-Different Visual  Relations",
    "abstract": "Although deep neural networks can achieve human-level performance on many object recognition benchmarks, prior work suggests that these same models fail to learn simple abstract relations, such as determining whether two objects are the same or different. Much of this prior work focuses on training convolutional neural networks to classify images of two same or two different abstract shapes, testing generalization on within-distribution stimuli. In this article, we comprehensively study whether deep neural networks can acquire and generalize same-different relations both within and out-of-distribution using a variety of architectures, forms of pretraining, and fine-tuning datasets. We find that certain pretrained transformers can learn a same-different relation that generalizes with near perfect accuracy to out-of-distribution stimuli. Furthermore, we find that fine-tuning on abstract shapes that lack texture or color provides the strongest out-of-distribution generalization. Our results suggest that, with the right approach, deep neural networks can learn generalizable same-different visual relations. ",
    "url": "https://arxiv.org/abs/2310.09612",
    "authors": [
      "Alexa R. Tartaglini",
      "Sheridan Feucht",
      "Michael A. Lepori",
      "Wai Keen Vong",
      "Charles Lovering",
      "Brenden M. Lake",
      "Ellie Pavlick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.09624",
    "title": "ASSERT: Automated Safety Scenario Red Teaming for Evaluating the  Robustness of Large Language Models",
    "abstract": "As large language models are integrated into society, robustness toward a suite of prompts is increasingly important to maintain reliability in a high-variance environment.Robustness evaluations must comprehensively encapsulate the various settings in which a user may invoke an intelligent system. This paper proposes ASSERT, Automated Safety Scenario Red Teaming, consisting of three methods -- semantically aligned augmentation, target bootstrapping, and adversarial knowledge injection. For robust safety evaluation, we apply these methods in the critical domain of AI safety to algorithmically generate a test suite of prompts covering diverse robustness settings -- semantic equivalence, related scenarios, and adversarial. We partition our prompts into four safety domains for a fine-grained analysis of how the domain affects model performance. Despite dedicated safeguards in existing state-of-the-art models, we find statistically significant performance differences of up to 11% in absolute classification accuracy among semantically related scenarios and error rates of up to 19% absolute error in zero-shot adversarial settings, raising concerns for users' physical safety. ",
    "url": "https://arxiv.org/abs/2310.09624",
    "authors": [
      "Alex Mei",
      "Sharon Levy",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09634",
    "title": "An End-to-End System for Reproducibility Assessment of Source Code  Repositories via Their Readmes",
    "abstract": "Increased reproducibility of machine learning research has been a driving force for dramatic improvements in learning performances. The scientific community further fosters this effort by including reproducibility ratings in reviewer forms and considering them as a crucial factor for the overall evaluation of papers. Accompanying source code is not sufficient to make a work reproducible. The shared codes should meet the ML reproducibility checklist as well. This work aims to support reproducibility evaluations of papers with source codes. We propose an end-to-end system that operates on the Readme file of the source code repositories. The system checks the compliance of a given Readme to a template proposed by a widely used platform for sharing source codes of research. Our system generates scores based on a custom function to combine section scores. We also train a hierarchical transformer model to assign a class label to a given Readme. The experimental results show that the section similarity-based system performs better than the hierarchical transformer. Moreover, it has an advantage regarding explainability since one can directly relate the score to the sections of Readme files. ",
    "url": "https://arxiv.org/abs/2310.09634",
    "authors": [
      "Ey\u00fcp Kaan Akdeniz",
      "Selma Tekir",
      "Malik Nizar Asad Al Hinnawi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.09636",
    "title": "Generative Adversarial Training for Text-to-Speech Synthesis Based on  Raw Phonetic Input and Explicit Prosody Modelling",
    "abstract": "We describe an end-to-end speech synthesis system that uses generative adversarial training. We train our Vocoder for raw phoneme-to-audio conversion, using explicit phonetic, pitch and duration modeling. We experiment with several pre-trained models for contextualized and decontextualized word embeddings and we introduce a new method for highly expressive character voice matching, based on discreet style tokens. ",
    "url": "https://arxiv.org/abs/2310.09636",
    "authors": [
      "Tiberiu Boros",
      "Stefan Daniel Dumitrescu",
      "Ionut Mironica",
      "Radu Chivereanu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09652",
    "title": "BufferSearch: Generating Black-Box Adversarial Texts With Lower Queries",
    "abstract": "Machine learning security has recently become a prominent topic in the natural language processing (NLP) area. The existing black-box adversarial attack suffers prohibitively from the high model querying complexity, resulting in easily being captured by anti-attack monitors. Meanwhile, how to eliminate redundant model queries is rarely explored. In this paper, we propose a query-efficient approach BufferSearch to effectively attack general intelligent NLP systems with the minimal number of querying requests. In general, BufferSearch makes use of historical information and conducts statistical test to avoid incurring model queries frequently. Numerically, we demonstrate the effectiveness of BufferSearch on various benchmark text-classification experiments by achieving the competitive attacking performance but with a significant reduction of query quantity. Furthermore, BufferSearch performs multiple times better than competitors within restricted query budget. Our work establishes a strong benchmark for the future study of query-efficiency in NLP adversarial attacks. ",
    "url": "https://arxiv.org/abs/2310.09652",
    "authors": [
      "Wenjie Lv",
      "Zhen Wang",
      "Yitao Zheng",
      "Zhehua Zhong",
      "Qi Xuan",
      "Tianyi Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.09657",
    "title": "Topology-guided Hypergraph Transformer Network: Unveiling Structural  Insights for Improved Representation",
    "abstract": "Hypergraphs, with their capacity to depict high-order relationships, have emerged as a significant extension of traditional graphs. Although Graph Neural Networks (GNNs) have remarkable performance in graph representation learning, their extension to hypergraphs encounters challenges due to their intricate structures. Furthermore, current hypergraph transformers, a special variant of GNN, utilize semantic feature-based self-attention, ignoring topological attributes of nodes and hyperedges. To address these challenges, we propose a Topology-guided Hypergraph Transformer Network (THTN). In this model, we first formulate a hypergraph from a graph while retaining its structural essence to learn higher-order relations within the graph. Then, we design a simple yet effective structural and spatial encoding module to incorporate the topological and spatial information of the nodes into their representation. Further, we present a structure-aware self-attention mechanism that discovers the important nodes and hyperedges from both semantic and structural viewpoints. By leveraging these two modules, THTN crafts an improved node representation, capturing both local and global topological expressions. Extensive experiments conducted on node classification tasks demonstrate that the performance of the proposed model consistently exceeds that of the existing approaches. ",
    "url": "https://arxiv.org/abs/2310.09657",
    "authors": [
      "Khaled Mohammed Saifuddin",
      "Mehmet Emin Aktas",
      "Esra Akbas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09659",
    "title": "HAPS in the Non-Terrestrial Network Nexus: Prospective Architectures and  Performance Insights",
    "abstract": "High altitude platform stations (HAPS) have recently emerged as a new key stratospheric player in non-terrestrial networks (NTN) alongside satellites and low-altitude platforms. In this paper, we present the main communication links between HAPS and other NTN platforms, their advantages, and their challenges. Then, prospective network architectures in which HAPS plays an indispensable role in the future NTNs are presented such as ad-hoc, cell-free, and integrated access and backhaul. To showcase the importance of HAPS in the NTN, we provide comprehensive performance insights when using HAPS in the prospective architectures with the most suitable communication link. The insights show the HAPS' ability to interconnect the NTN nexus as well as their versatility by incorporating different metrics into the analysis such as routing latency, energy efficiency, coverage probability, and channel capacity. Depending on the architecture, HAPS will play different roles in NTN, such as a UAV network center, satellite relay, and ground network extension. Finally, the performance gain provided by HAPS usage in NTN is further highlighted by comparing the results when no HAPS are used. ",
    "url": "https://arxiv.org/abs/2310.09659",
    "authors": [
      "Zhengying Lou",
      "Baha Eddine Youcef Belmekki",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.09661",
    "title": "Legend at ArAIEval Shared Task: Persuasion Technique Detection using a  Language-Agnostic Text Representation Model",
    "abstract": "In this paper, we share our best performing submission to the Arabic AI Tasks Evaluation Challenge (ArAIEval) at ArabicNLP 2023. Our focus was on Task 1, which involves identifying persuasion techniques in excerpts from tweets and news articles. The persuasion technique in Arabic texts was detected using a training loop with XLM-RoBERTa, a language-agnostic text representation model. This approach proved to be potent, leveraging fine-tuning of a multilingual language model. In our evaluation of the test set, we achieved a micro F1 score of 0.64 for subtask A of the competition. ",
    "url": "https://arxiv.org/abs/2310.09661",
    "authors": [
      "Olumide E. Ojo",
      "Olaronke O. Adebanji",
      "Hiram Calvo",
      "Damian O. Dieke",
      "Olumuyiwa E. Ojo",
      "Seye E. Akinsanya",
      "Tolulope O. Abiola",
      "Anna Feldman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.09675",
    "title": "Efficient Model-Agnostic Multi-Group Equivariant Networks",
    "abstract": "Constructing model-agnostic group equivariant networks, such as equitune (Basu et al., 2023b) and its generalizations (Kim et al., 2023), can be computationally expensive for large product groups. We address this by providing efficient model-agnostic equivariant designs for two related problems: one where the network has multiple inputs each with potentially different groups acting on them, and another where there is a single input but the group acting on it is a large product group. For the first design, we initially consider a linear model and characterize the entire equivariant space that satisfies this constraint. This characterization gives rise to a novel fusion layer between different channels that satisfies an invariance-symmetry (IS) constraint, which we call an IS layer. We then extend this design beyond linear models, similar to equitune, consisting of equivariant and IS layers. We also show that the IS layer is a universal approximator of invariant-symmetric functions. Inspired by the first design, we use the notion of the IS property to design a second efficient model-agnostic equivariant design for large product groups acting on a single input. For the first design, we provide experiments on multi-image classification where each view is transformed independently with transformations such as rotations. We find equivariant models are robust to such transformations and perform competitively otherwise. For the second design, we consider three applications: language compositionality on the SCAN dataset to product groups; fairness in natural language generation from GPT-2 to address intersectionality; and robust zero-shot image classification with CLIP. Overall, our methods are simple and general, competitive with equitune and its variants, while also being computationally more efficient. ",
    "url": "https://arxiv.org/abs/2310.09675",
    "authors": [
      "Razan Baltaji",
      "Sourya Basu",
      "Lav R. Varshney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.09699",
    "title": "Solving Max-Min Fair Resource Allocations Quickly on Large Graphs",
    "abstract": "We consider the max-min fair resource allocation problem. The best-known solutions use either a sequence of optimizations or waterfilling, which only applies to a narrow set of cases. These solutions have become a practical bottleneck in WAN traffic engineering and cluster scheduling, especially at larger problem sizes. We improve both approaches: (1) we show how to convert the optimization sequence into a single fast optimization, and (2) we generalize waterfilling to the multi-path case. We empirically show our new algorithms Pareto-dominate prior techniques: they produce faster, fairer, and more efficient allocations. Some of our allocators also have theoretical guarantees: they trade off a bounded amount of unfairness for faster allocation. We have deployed our allocators in Azure's WAN traffic engineering pipeline, where we preserve solution quality and achieve a roughly $3\\times$ speedup. ",
    "url": "https://arxiv.org/abs/2310.09699",
    "authors": [
      "Pooria Namyar",
      "Behnaz Arzani",
      "Srikanth Kandula",
      "Santiago Segarra",
      "Daniel Crankshaw",
      "Umesh Krishnaswamy",
      "Ramesh Govindan",
      "Himanshu Raj"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.09705",
    "title": "SGA: A Graph Augmentation Method for Signed Graph Neural Networks",
    "abstract": "Signed Graph Neural Networks (SGNNs) are vital for analyzing complex patterns in real-world signed graphs containing positive and negative links. However, three key challenges hinder current SGNN-based signed graph representation learning: sparsity in signed graphs leaves latent structures undiscovered, unbalanced triangles pose representation difficulties for SGNN models, and real-world signed graph datasets often lack supplementary information like node labels and features. These constraints limit the potential of SGNN-based representation learning. We address these issues with data augmentation techniques. Despite many graph data augmentation methods existing for unsigned graphs, none are tailored for signed graphs. Our paper introduces the novel Signed Graph Augmentation framework (SGA), comprising three main components. First, we employ the SGNN model to encode the signed graph, extracting latent structural information for candidate augmentation structures. Second, we evaluate these candidate samples (edges) and select the most beneficial ones for modifying the original training set. Third, we propose a novel augmentation perspective that assigns varying training difficulty to training samples, enabling the design of a new training strategy. Extensive experiments on six real-world datasets (Bitcoin-alpha, Bitcoin-otc, Epinions, Slashdot, Wiki-elec, and Wiki-RfA) demonstrate that SGA significantly improves performance across multiple benchmarks. Our method outperforms baselines by up to 22.2% in AUC for SGCN on Wiki-RfA, 33.3% in F1-binary, 48.8% in F1-micro, and 36.3% in F1-macro for GAT on Bitcoin-alpha in link sign prediction. ",
    "url": "https://arxiv.org/abs/2310.09705",
    "authors": [
      "Zeyu Zhang",
      "Shuyan Wan",
      "Sijie Wang",
      "Xianda Zheng",
      "Xinrui Zhang",
      "Kaiqi Zhao",
      "Jiamou Liu",
      "Dong Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.09706",
    "title": "AdaptSSR: Pre-training User Model with Augmentation-Adaptive  Self-Supervised Ranking",
    "abstract": "User modeling, which aims to capture users' characteristics or interests, heavily relies on task-specific labeled data and suffers from the data sparsity issue. Several recent studies tackled this problem by pre-training the user model on massive user behavior sequences with a contrastive learning task. Generally, these methods assume different views of the same behavior sequence constructed via data augmentation are semantically consistent, i.e., reflecting similar characteristics or interests of the user, and thus maximizing their agreement in the feature space. However, due to the diverse interests and heavy noise in user behaviors, existing augmentation methods tend to lose certain characteristics of the user or introduce noisy interests. Thus, forcing the user model to directly maximize the similarity between the augmented views may result in a negative transfer. To this end, we propose to replace the contrastive learning task with a new pretext task: Augmentation-Adaptive Self-Supervised Ranking (AdaptSSR), which alleviates the requirement of semantic consistency between the augmented views while pre-training a discriminative user model. Specifically, we adopt a multiple pairwise ranking loss which trains the user model to capture the similarity orders between the implicitly augmented view, the explicitly augmented view, and views from other users. We further employ an in-batch hard negative sampling strategy to facilitate model training. Moreover, considering the distinct impacts of data augmentation on different behavior sequences, we design an augmentation-adaptive fusion mechanism to automatically adjust the similarity order constraint applied to each sample based on the estimated similarity between the augmented views. Extensive experiments on both public and industrial datasets with six downstream tasks verify the effectiveness of AdaptSSR. ",
    "url": "https://arxiv.org/abs/2310.09706",
    "authors": [
      "Yang Yu",
      "Qi Liu",
      "Kai Zhang",
      "Yuren Zhang",
      "Chao Song",
      "Min Hou",
      "Yuqing Yuan",
      "Zhihao Ye",
      "Zaixi Zhang",
      "Sanshi Lei Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.09735",
    "title": "Assessing Smart Algorithms for Gait Phases Detection in Lower Limb  Prosthesis: A Comprehensive Review",
    "abstract": "Over the past few years, the division of gait phases has emerged as a complex area of research that carries significant importance for various applications in the field of gait technologies. The accurate partitioning of gait phases plays a crucial role in advancing these applications. Researchers have been exploring a range of sensors that can be employed to provide data for algorithms involved in gait phase partitioning. These sensors can be broadly categorized into two types: wearable and non-wearable, each offering unique advantages and capabilities. In our study aimed at examining the current approaches to gait analysis and detection specifically designed for implementation in ambulatory rehabilitation systems, we conducted a comprehensive meta-analysis of existing research studies. Our analysis revealed a diverse range of sensors and sensor combinations that demonstrate the ability to analyze gait patterns in ambulatory settings. These sensor options vary from basic force-based binary switches to more intricate setups incorporating multiple inertial sensors and sophisticated algorithms. The findings highlight the wide spectrum of available technologies and methodologies used in gait analysis for ambulatory applications. To conduct an extensive review, we systematically examined two prominent databases, IEEE and Scopus, with the aim of identifying relevant studies pertaining to gait analysis. The search criteria were limited to 189 papers published between 1999 and 2023. From this pool, we identified and included five papers that specifically focused on various techniques including Thresholding, Quasi-static method, adaptive classifier, and SVM-based approaches. These selected papers provided valuable insights for our review. ",
    "url": "https://arxiv.org/abs/2310.09735",
    "authors": [
      "Barath Kumar JK",
      "Aswadh Khumar G S"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.09744",
    "title": "Explore the Effect of Data Selection on Poison Efficiency in Backdoor  Attacks",
    "abstract": "As the number of parameters in Deep Neural Networks (DNNs) scales, the thirst for training data also increases. To save costs, it has become common for users and enterprises to delegate time-consuming data collection to third parties. Unfortunately, recent research has shown that this practice raises the risk of DNNs being exposed to backdoor attacks. Specifically, an attacker can maliciously control the behavior of a trained model by poisoning a small portion of the training data. In this study, we focus on improving the poisoning efficiency of backdoor attacks from the sample selection perspective. The existing attack methods construct such poisoned samples by randomly selecting some clean data from the benign set and then embedding a trigger into them. However, this random selection strategy ignores that each sample may contribute differently to the backdoor injection, thereby reducing the poisoning efficiency. To address the above problem, a new selection strategy named Improved Filtering and Updating Strategy (FUS++) is proposed. Specifically, we adopt the forgetting events of the samples to indicate the contribution of different poisoned samples and use the curvature of the loss surface to analyses the effectiveness of this phenomenon. Accordingly, we combine forgetting events and curvature of different samples to conduct a simple yet efficient sample selection strategy. The experimental results on image classification (CIFAR-10, CIFAR-100, ImageNet-10), text classification (AG News), audio classification (ESC-50), and age regression (Facial Age) consistently demonstrate the effectiveness of the proposed strategy: the attack performance using FUS++ is significantly higher than that using random selection for the same poisoning ratio. ",
    "url": "https://arxiv.org/abs/2310.09744",
    "authors": [
      "Ziqiang Li",
      "Pengfei Xia",
      "Hong Sun",
      "Yueqi Zeng",
      "Wei Zhang",
      "Bin Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.09748",
    "title": "Large Language Model-Aware In-Context Learning for Code Generation",
    "abstract": "Large language models (LLMs) have shown impressive in-context learning (ICL) ability in code generation. LLMs take a prompt consisting of requirement-code examples and a new requirement as input, and output new programs. Existing studies have found that ICL is highly dominated by the examples and thus arises research on example selection. However, existing approaches randomly select examples or only consider the textual similarity of requirements to retrieve, leading to sub-optimal performance. In this paper, we propose a novel learning-based selection approach named LAIL (LLM-Aware In-context Learning) for code generation. Given a candidate example, we exploit LLMs themselves to estimate it by considering the generation probabilities of ground-truth programs given a requirement and the example. We then label candidate examples as positive or negative through the probability feedback. Based on the labeled data, we import a contrastive learning objective to train an effective retriever that acquires the preference of LLMs in code generation. We apply LAIL to three LLMs and evaluate it on three representative datasets (e.g., MBJP, MBPP, and MBCPP). LATA outperforms the state-of-the-art baselines by 11.58%, 6.89%, and 5.07% on CodeGen, and 4.38%, 2.85%, and 2.74% on GPT-3.5 in terms of Pass@1, respectively. ",
    "url": "https://arxiv.org/abs/2310.09748",
    "authors": [
      "Jia Li",
      "Ge Li",
      "Chongyang Tao",
      "Jia Li",
      "Huangzhao Zhang",
      "Fang Liu",
      "Zhi Jin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.09755",
    "title": "Beyond Segmentation: Road Network Generation with Multi-Modal LLMs",
    "abstract": "This paper introduces an innovative approach to road network generation through the utilization of a multi-modal Large Language Model (LLM). Our model is specifically designed to process aerial images of road layouts and produce detailed, navigable road networks within the input images. The core innovation of our system lies in the unique training methodology employed for the large language model to generate road networks as its output. This approach draws inspiration from the BLIP-2 architecture arXiv:2301.12597, leveraging pre-trained frozen image encoders and large language models to create a versatile multi-modal LLM. Our work also offers an alternative to the reasoning segmentation method proposed in the LISA paper arXiv:2308.00692. By training the large language model with our approach, the necessity for generating binary segmentation masks, as suggested in the LISA paper arXiv:2308.00692, is effectively eliminated. Experimental results underscore the efficacy of our multi-modal LLM in providing precise and valuable navigational guidance. This research represents a significant stride in bolstering autonomous navigation systems, especially in road network scenarios, where accurate guidance is of paramount importance. ",
    "url": "https://arxiv.org/abs/2310.09755",
    "authors": [
      "Sumedh Rasal",
      "Sanjay Kumar Boddhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.09757",
    "title": "MoEmo Vision Transformer: Integrating Cross-Attention and Movement  Vectors in 3D Pose Estimation for HRI Emotion Detection",
    "abstract": "Emotion detection presents challenges to intelligent human-robot interaction (HRI). Foundational deep learning techniques used in emotion detection are limited by information-constrained datasets or models that lack the necessary complexity to learn interactions between input data elements, such as the the variance of human emotions across different contexts. In the current effort, we introduce 1) MoEmo (Motion to Emotion), a cross-attention vision transformer (ViT) for human emotion detection within robotics systems based on 3D human pose estimations across various contexts, and 2) a data set that offers full-body videos of human movement and corresponding emotion labels based on human gestures and environmental contexts. Compared to existing approaches, our method effectively leverages the subtle connections between movement vectors of gestures and environmental contexts through the use of cross-attention on the extracted movement vectors of full-body human gestures/poses and feature maps of environmental contexts. We implement a cross-attention fusion model to combine movement vectors and environment contexts into a joint representation to derive emotion estimation. Leveraging our Naturalistic Motion Database, we train the MoEmo system to jointly analyze motion and context, yielding emotion detection that outperforms the current state-of-the-art. ",
    "url": "https://arxiv.org/abs/2310.09757",
    "authors": [
      "David C. Jeong",
      "Tianma Shen",
      "Hongji Liu",
      "Raghav Kapoor",
      "Casey Nguyen",
      "Song Liu",
      "Christopher A. Kitts"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.09759",
    "title": "Prototype-oriented Unsupervised Change Detection for Disaster Management",
    "abstract": "Climate change has led to an increased frequency of natural disasters such as floods and cyclones. This emphasizes the importance of effective disaster monitoring. In response, the remote sensing community has explored change detection methods. These methods are primarily categorized into supervised techniques, which yield precise results but come with high labeling costs, and unsupervised techniques, which eliminate the need for labeling but involve intricate hyperparameter tuning. To address these challenges, we propose a novel unsupervised change detection method named Prototype-oriented Unsupervised Change Detection for Disaster Management (PUCD). PUCD captures changes by comparing features from pre-event, post-event, and prototype-oriented change synthesis images via a foundational model, and refines results using the Segment Anything Model (SAM). Although PUCD is an unsupervised change detection, it does not require complex hyperparameter tuning. We evaluate PUCD framework on the LEVIR-Extension dataset and the disaster dataset and it achieves state-of-the-art performance compared to other methods on the LEVIR-Extension dataset. ",
    "url": "https://arxiv.org/abs/2310.09759",
    "authors": [
      "Youngtack Oh",
      "Minseok Seo",
      "Doyi Ki",
      "Junghoon Seo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.09760",
    "title": "Image Augmentation with Controlled Diffusion for Weakly-Supervised  Semantic Segmentation",
    "abstract": "Weakly-supervised semantic segmentation (WSSS), which aims to train segmentation models solely using image-level labels, has achieved significant attention. Existing methods primarily focus on generating high-quality pseudo labels using available images and their image-level labels. However, the quality of pseudo labels degrades significantly when the size of available dataset is limited. Thus, in this paper, we tackle this problem from a different view by introducing a novel approach called Image Augmentation with Controlled Diffusion (IACD). This framework effectively augments existing labeled datasets by generating diverse images through controlled diffusion, where the available images and image-level labels are served as the controlling information. Moreover, we also propose a high-quality image selection strategy to mitigate the potential noise introduced by the randomness of diffusion models. In the experiments, our proposed IACD approach clearly surpasses existing state-of-the-art methods. This effect is more obvious when the amount of available data is small, demonstrating the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2310.09760",
    "authors": [
      "Wangyu Wu",
      "Tianhong Dai",
      "Xiaowei Huang",
      "Fei Ma",
      "Jimin Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.09762",
    "title": "Diversifying the Mixture-of-Experts Representation for Language Models  with Orthogonal Optimizer",
    "abstract": "The Mixture of Experts (MoE) has emerged as a highly successful technique in deep learning, based on the principle of divide-and-conquer to maximize model capacity without significant additional computational cost. Even in the era of large-scale language models (LLMs), MoE continues to play a crucial role, as some researchers have indicated that GPT-4 adopts the MoE structure to ensure diverse inference results. However, MoE is susceptible to performance degeneracy, particularly evident in the issues of imbalance and homogeneous representation among experts. While previous studies have extensively addressed the problem of imbalance, the challenge of homogeneous representation remains unresolved. In this study, we shed light on the homogeneous representation problem, wherein experts in the MoE fail to specialize and lack diversity, leading to frustratingly high similarities in their representations (up to 99% in a well-performed MoE model). This problem restricts the expressive power of the MoE and, we argue, contradicts its original intention. To tackle this issue, we propose a straightforward yet highly effective solution: OMoE, an orthogonal expert optimizer. Additionally, we introduce an alternating training strategy that encourages each expert to update in a direction orthogonal to the subspace spanned by other experts. Our algorithm facilitates MoE training in two key ways: firstly, it explicitly enhances representation diversity, and secondly, it implicitly fosters interaction between experts during orthogonal weights computation. Through extensive experiments, we demonstrate that our proposed optimization algorithm significantly improves the performance of fine-tuning the MoE model on the GLUE benchmark, SuperGLUE benchmark, question-answering task, and name entity recognition tasks. ",
    "url": "https://arxiv.org/abs/2310.09762",
    "authors": [
      "Boan Liu",
      "Liang Ding",
      "Li Shen",
      "Keqin Peng",
      "Yu Cao",
      "Dazhao Cheng",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.09764",
    "title": "DropMix: Better Graph Contrastive Learning with Harder Negative Samples",
    "abstract": "While generating better negative samples for contrastive learning has been widely studied in the areas of CV and NLP, very few work has focused on graph-structured data. Recently, Mixup has been introduced to synthesize hard negative samples in graph contrastive learning (GCL). However, due to the unsupervised learning nature of GCL, without the help of soft labels, directly mixing representations of samples could inadvertently lead to the information loss of the original hard negative and further adversely affect the quality of the newly generated harder negative. To address the problem, in this paper, we propose a novel method DropMix to synthesize harder negative samples, which consists of two main steps. Specifically, we first select some hard negative samples by measuring their hardness from both local and global views in the graph simultaneously. After that, we mix hard negatives only on partial representation dimensions to generate harder ones and decrease the information loss caused by Mixup. We conduct extensive experiments to verify the effectiveness of DropMix on six benchmark datasets. Our results show that our method can lead to better GCL performance. Our data and codes are publicly available at https://github.com/Mayueq/DropMix-Code. ",
    "url": "https://arxiv.org/abs/2310.09764",
    "authors": [
      "Yueqi Ma",
      "Minjie Chen",
      "Xiang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.09772",
    "title": "Revisiting Graph Meaning Representations through Decoupling Contextual  Representation Learning and Structural Information Propagation",
    "abstract": "In the field of natural language understanding, the intersection of neural models and graph meaning representations (GMRs) remains a compelling area of research. Despite the growing interest, a critical gap persists in understanding the exact influence of GMRs, particularly concerning relation extraction tasks. Addressing this, we introduce DAGNN-plus, a simple and parameter-efficient neural architecture designed to decouple contextual representation learning from structural information propagation. Coupled with various sequence encoders and GMRs, this architecture provides a foundation for systematic experimentation on two English and two Chinese datasets. Our empirical analysis utilizes four different graph formalisms and nine parsers. The results yield a nuanced understanding of GMRs, showing improvements in three out of the four datasets, particularly favoring English over Chinese due to highly accurate parsers. Interestingly, GMRs appear less effective in literary-domain datasets compared to general-domain datasets. These findings lay the groundwork for better-informed design of GMRs and parsers to improve relation classification, which is expected to tangibly impact the future trajectory of natural language understanding research. ",
    "url": "https://arxiv.org/abs/2310.09772",
    "authors": [
      "Li Zhou",
      "Wenyu Chen",
      "Dingyi Zeng",
      "Hong Qu",
      "Daniel Hershcovich"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.09773",
    "title": "RSVP: Customer Intent Detection via Agent Response Contrastive and  Generative Pre-Training",
    "abstract": "The dialogue systems in customer services have been developed with neural models to provide users with precise answers and round-the-clock support in task-oriented conversations by detecting customer intents based on their utterances. Existing intent detection approaches have highly relied on adaptively pre-training language models with large-scale datasets, yet the predominant cost of data collection may hinder their superiority. In addition, they neglect the information within the conversational responses of the agents, which have a lower collection cost, but are significant to customer intent as agents must tailor their replies based on the customers' intent. In this paper, we propose RSVP, a self-supervised framework dedicated to task-oriented dialogues, which utilizes agent responses for pre-training in a two-stage manner. Specifically, we introduce two pre-training tasks to incorporate the relations of utterance-response pairs: 1) Response Retrieval by selecting a correct response from a batch of candidates, and 2) Response Generation by mimicking agents to generate the response to a given utterance. Our benchmark results for two real-world customer service datasets show that RSVP significantly outperforms the state-of-the-art baselines by 4.95% for accuracy, 3.4% for MRR@3, and 2.75% for MRR@5 on average. Extensive case studies are investigated to show the validity of incorporating agent responses into the pre-training stage. ",
    "url": "https://arxiv.org/abs/2310.09773",
    "authors": [
      "Yu-Chien Tang",
      "Wei-Yao Wang",
      "An-Zi Yen",
      "Wen-Chih Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.09776",
    "title": "CBARF: Cascaded Bundle-Adjusting Neural Radiance Fields from Imperfect  Camera Poses",
    "abstract": "Existing volumetric neural rendering techniques, such as Neural Radiance Fields (NeRF), face limitations in synthesizing high-quality novel views when the camera poses of input images are imperfect. To address this issue, we propose a novel 3D reconstruction framework that enables simultaneous optimization of camera poses, dubbed CBARF (Cascaded Bundle-Adjusting NeRF).In a nutshell, our framework optimizes camera poses in a coarse-to-fine manner and then reconstructs scenes based on the rectified poses. It is observed that the initialization of camera poses has a significant impact on the performance of bundle-adjustment (BA). Therefore, we cascade multiple BA modules at different scales to progressively improve the camera poses. Meanwhile, we develop a neighbor-replacement strategy to further optimize the results of BA in each stage. In this step, we introduce a novel criterion to effectively identify poorly estimated camera poses. Then we replace them with the poses of neighboring cameras, thus further eliminating the impact of inaccurate camera poses. Once camera poses have been optimized, we employ a density voxel grid to generate high-quality 3D reconstructed scenes and images in novel views. Experimental results demonstrate that our CBARF model achieves state-of-the-art performance in both pose optimization and novel view synthesis, especially in the existence of large camera pose noise. ",
    "url": "https://arxiv.org/abs/2310.09776",
    "authors": [
      "Hongyu Fu",
      "Xin Yu",
      "Lincheng Li",
      "Li Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.09781",
    "title": "Negative Sampling with Adaptive Denoising Mixup for Knowledge Graph  Embedding",
    "abstract": "Knowledge graph embedding (KGE) aims to map entities and relations of a knowledge graph (KG) into a low-dimensional and dense vector space via contrasting the positive and negative triples. In the training process of KGEs, negative sampling is essential to find high-quality negative triples since KGs only contain positive triples. Most existing negative sampling methods assume that non-existent triples with high scores are high-quality negative triples. However, negative triples sampled by these methods are likely to contain noise. Specifically, they ignore that non-existent triples with high scores might also be true facts due to the incompleteness of KGs, which are usually called false negative triples. To alleviate the above issue, we propose an easily pluggable denoising mixup method called DeMix, which generates high-quality triples by refining sampled negative triples in a self-supervised manner. Given a sampled unlabeled triple, DeMix firstly classifies it into a marginal pseudo-negative triple or a negative triple based on the judgment of the KGE model itself. Secondly, it selects an appropriate mixup partner for the current triple to synthesize a partially positive or a harder negative triple. Experimental results on the knowledge graph completion task show that the proposed DeMix is superior to other negative sampling techniques, ensuring corresponding KGEs a faster convergence and better link prediction results. ",
    "url": "https://arxiv.org/abs/2310.09781",
    "authors": [
      "Xiangnan Chen",
      "Wen Zhang",
      "Zhen Yao",
      "Mingyang Chen",
      "Siliang Tang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.09787",
    "title": "Dynamic Link Prediction for New Nodes in Temporal Graph Networks",
    "abstract": "Modelling temporal networks for dynamic link prediction of new nodes has many real-world applications, such as providing relevant item recommendations to new customers in recommender systems and suggesting appropriate posts to new users on social platforms. Unlike old nodes, new nodes have few historical links, which poses a challenge for the dynamic link prediction task. Most existing dynamic models treat all nodes equally and are not specialized for new nodes, resulting in suboptimal performances. In this paper, we consider dynamic link prediction of new nodes as a few-shot problem and propose a novel model based on the meta-learning principle to effectively mitigate this problem. Specifically, we develop a temporal encoder with a node-level span memory to obtain a new node embedding, and then we use a predictor to determine whether the new node generates a link. To overcome the few-shot challenge, we incorporate the encoder-predictor into the meta-learning paradigm, which can learn two types of implicit information during the formation of the temporal network through span adaptation and node adaptation. The acquired implicit information can serve as model initialisation and facilitate rapid adaptation to new nodes through a fine-tuning process on just a few links. Experiments on three publicly available datasets demonstrate the superior performance of our model compared to existing state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2310.09787",
    "authors": [
      "Xiaobo Zhu",
      "Yan Wu",
      "Qinhu Zhang",
      "Zhanheng Chen",
      "Ying He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09792",
    "title": "SCME: A Self-Contrastive Method for Data-free and Query-Limited Model  Extraction Attack",
    "abstract": "Previous studies have revealed that artificial intelligence (AI) systems are vulnerable to adversarial attacks. Among them, model extraction attacks fool the target model by generating adversarial examples on a substitute model. The core of such an attack is training a substitute model as similar to the target model as possible, where the simulation process can be categorized in a data-dependent and data-free manner. Compared with the data-dependent method, the data-free one has been proven to be more practical in the real world since it trains the substitute model with synthesized data. However, the distribution of these fake data lacks diversity and cannot detect the decision boundary of the target model well, resulting in the dissatisfactory simulation effect. Besides, these data-free techniques need a vast number of queries to train the substitute model, increasing the time and computing consumption and the risk of exposure. To solve the aforementioned problems, in this paper, we propose a novel data-free model extraction method named SCME (Self-Contrastive Model Extraction), which considers both the inter- and intra-class diversity in synthesizing fake data. In addition, SCME introduces the Mixup operation to augment the fake data, which can explore the target model's decision boundary effectively and improve the simulating capacity. Extensive experiments show that the proposed method can yield diversified fake data. Moreover, our method has shown superiority in many different attack settings under the query-limited scenario, especially for untargeted attacks, the SCME outperforms SOTA methods by 11.43\\% on average for five baseline datasets. ",
    "url": "https://arxiv.org/abs/2310.09792",
    "authors": [
      "Renyang Liu",
      "Jinhong Zhang",
      "Kwok-Yan Lam",
      "Jun Zhao",
      "Wei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.09793",
    "title": "Automated Detection of Cat Facial Landmarks",
    "abstract": "The field of animal affective computing is rapidly emerging, and analysis of facial expressions is a crucial aspect. One of the most significant challenges that researchers in the field currently face is the scarcity of high-quality, comprehensive datasets that allow the development of models for facial expressions analysis. One of the possible approaches is the utilisation of facial landmarks, which has been shown for humans and animals. In this paper we present a novel dataset of cat facial images annotated with bounding boxes and 48 facial landmarks grounded in cat facial anatomy. We also introduce a landmark detection convolution neural network-based model which uses a magnifying ensembe method. Our model shows excellent performance on cat faces and is generalizable to human facial landmark detection. ",
    "url": "https://arxiv.org/abs/2310.09793",
    "authors": [
      "George Martvel",
      "Ilan Shimshoni",
      "Anna Zamansky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.09795",
    "title": "AFLOW: Developing Adversarial Examples under Extremely Noise-limited  Settings",
    "abstract": "Extensive studies have demonstrated that deep neural networks (DNNs) are vulnerable to adversarial attacks. Despite the significant progress in the attack success rate that has been made recently, the adversarial noise generated by most of the existing attack methods is still too conspicuous to the human eyes and proved to be easily detected by defense mechanisms. Resulting that these malicious examples cannot contribute to exploring the vulnerabilities of existing DNNs sufficiently. Thus, to better reveal the defects of DNNs and further help enhance their robustness under noise-limited situations, a new inconspicuous adversarial examples generation method is exactly needed to be proposed. To bridge this gap, we propose a novel Normalize Flow-based end-to-end attack framework, called AFLOW, to synthesize imperceptible adversarial examples under strict constraints. Specifically, rather than the noise-adding manner, AFLOW directly perturbs the hidden representation of the corresponding image to craft the desired adversarial examples. Compared with existing methods, extensive experiments on three benchmark datasets show that the adversarial examples built by AFLOW exhibit superiority in imperceptibility, image quality and attack capability. Even on robust models, AFLOW can still achieve higher attack results than previous methods. ",
    "url": "https://arxiv.org/abs/2310.09795",
    "authors": [
      "Renyang Liu",
      "Jinhong Zhang",
      "Haoran Li",
      "Jin Zhang",
      "Yuanyu Wang",
      "Wei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.09797",
    "title": "A Number Representation Systems Library Supporting New Representations  Based on Morris Tapered Floating-point with Hidden Exponent Bit",
    "abstract": "The introduction of posit reopened the debate about the utility of IEEE754 in specific domains. In this context, we propose a high-level language (Scala) library that aims to reduce the effort of designing and testing new number representation systems (NRSs). The library's efficiency is tested with three new NRSs derived from Morris Tapered Floating-Point by adding a hidden exponent bit. We call these NRSs MorrisHEB, MorrisBiasHEB, and MorrisUnaryHEB, respectively. We show that they offer a better dynamic range, better decimal accuracy for unary operations, more exact results for addition (37.61% in the case of MorrisUnaryHEB), and better average decimal accuracy for inexact results on binary operations than posit and IEEE754. Going through existing benchmarks in the literature, and favorable/unfavorable examples for IEEE754/posit, we show that these new NRSs produce similar (less than one decimal accuracy difference) or even better results than IEEE754 and posit. Given the entire spectrum of results, there are arguments for MorrisBiasHEB to be used as a replacement for IEEE754 in general computations. MorrisUnaryHEB has a more populated ``golden zone'' (+13.6%) and a better dynamic range (149X) than posit, making it a candidate for machine learning computations. ",
    "url": "https://arxiv.org/abs/2310.09797",
    "authors": [
      "Stefan-Dan Ciocirlan",
      "Dumitrel Loghin"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2310.09800",
    "title": "Model Inversion Attacks on Homogeneous and Heterogeneous Graph Neural  Networks",
    "abstract": "Recently, Graph Neural Networks (GNNs), including Homogeneous Graph Neural Networks (HomoGNNs) and Heterogeneous Graph Neural Networks (HeteGNNs), have made remarkable progress in many physical scenarios, especially in communication applications. Despite achieving great success, the privacy issue of such models has also received considerable attention. Previous studies have shown that given a well-fitted target GNN, the attacker can reconstruct the sensitive training graph of this model via model inversion attacks, leading to significant privacy worries for the AI service provider. We advocate that the vulnerability comes from the target GNN itself and the prior knowledge about the shared properties in real-world graphs. Inspired by this, we propose a novel model inversion attack method on HomoGNNs and HeteGNNs, namely HomoGMI and HeteGMI. Specifically, HomoGMI and HeteGMI are gradient-descent-based optimization methods that aim to maximize the cross-entropy loss on the target GNN and the $1^{st}$ and $2^{nd}$-order proximities on the reconstructed graph. Notably, to the best of our knowledge, HeteGMI is the first attempt to perform model inversion attacks on HeteGNNs. Extensive experiments on multiple benchmarks demonstrate that the proposed method can achieve better performance than the competitors. ",
    "url": "https://arxiv.org/abs/2310.09800",
    "authors": [
      "Renyang Liu",
      "Wei Zhou",
      "Jinhong Zhang",
      "Xiaoyuan Liu",
      "Peiyuan Si",
      "Haoran Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.09806",
    "title": "Can LSH (Locality-Sensitive Hashing) Be Replaced by Neural Network?",
    "abstract": "With the rapid development of GPU (Graphics Processing Unit) technologies and neural networks, we can explore more appropriate data structures and algorithms. Recent progress shows that neural networks can partly replace traditional data structures. In this paper, we proposed a novel DNN (Deep Neural Network)-based learned locality-sensitive hashing, called LLSH, to efficiently and flexibly map high-dimensional data to low-dimensional space. LLSH replaces the traditional LSH (Locality-sensitive Hashing) function families with parallel multi-layer neural networks, which reduces the time and memory consumption and guarantees query accuracy simultaneously. The proposed LLSH demonstrate the feasibility of replacing the hash index with learning-based neural networks and open a new door for developers to design and configure data organization more accurately to improve information-searching performance. Extensive experiments on different types of datasets show the superiority of the proposed method in query accuracy, time consumption, and memory usage. ",
    "url": "https://arxiv.org/abs/2310.09806",
    "authors": [
      "Renyang Liu",
      "Jun Zhao",
      "Xing Chu",
      "Yu Liang",
      "Wei Zhou",
      "Jing He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.09810",
    "title": "ChatGPT for Vulnerability Detection, Classification, and Repair: How Far  Are We?",
    "abstract": "Large language models (LLMs) like ChatGPT (i.e., gpt-3.5-turbo and gpt-4) exhibited remarkable advancement in a range of software engineering tasks associated with source code such as code review and code generation. In this paper, we undertake a comprehensive study by instructing ChatGPT for four prevalent vulnerability tasks: function and line-level vulnerability prediction, vulnerability classification, severity estimation, and vulnerability repair. We compare ChatGPT with state-of-the-art language models designed for software vulnerability purposes. Through an empirical assessment employing extensive real-world datasets featuring over 190,000 C/C++ functions, we found that ChatGPT achieves limited performance, trailing behind other language models in vulnerability contexts by a significant margin. The experimental outcomes highlight the challenging nature of vulnerability prediction tasks, requiring domain-specific expertise. Despite ChatGPT's substantial model scale, exceeding that of source code-pre-trained language models (e.g., CodeBERT) by a factor of 14,000, the process of fine-tuning remains imperative for ChatGPT to generalize for vulnerability prediction tasks. We publish the studied dataset, experimental prompts for ChatGPT, and experimental results at https://github.com/awsm-research/ChatGPT4Vul. ",
    "url": "https://arxiv.org/abs/2310.09810",
    "authors": [
      "Michael Fu",
      "Chakkrit Tantithamthavorn",
      "Van Nguyen",
      "Trung Le"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.09817",
    "title": "OAAFormer: Robust and Efficient Point Cloud Registration Through  Overlapping-Aware Attention in Transformer",
    "abstract": "In the domain of point cloud registration, the coarse-to-fine feature matching paradigm has received substantial attention owing to its impressive performance. This paradigm involves a two-step process: first, the extraction of multi-level features, and subsequently, the propagation of correspondences from coarse to fine levels. Nonetheless, this paradigm exhibits two notable limitations.Firstly, the utilization of the Dual Softmax operation has the potential to promote one-to-one correspondences between superpoints, inadvertently excluding valuable correspondences. This propensity arises from the fact that a source superpoint typically maintains associations with multiple target superpoints. Secondly, it is imperative to closely examine the overlapping areas between point clouds, as only correspondences within these regions decisively determine the actual transformation. Based on these considerations, we propose {\\em OAAFormer} to enhance correspondence quality. On one hand, we introduce a soft matching mechanism, facilitating the propagation of potentially valuable correspondences from coarse to fine levels. Additionally, we integrate an overlapping region detection module to minimize mismatches to the greatest extent possible. Furthermore, we introduce a region-wise attention module with linear complexity during the fine-level matching phase, designed to enhance the discriminative capabilities of the extracted features. Tests on the challenging 3DLoMatch benchmark demonstrate that our approach leads to a substantial increase of about 7\\% in the inlier ratio, as well as an enhancement of 2-4\\% in registration recall. = ",
    "url": "https://arxiv.org/abs/2310.09817",
    "authors": [
      "Junjie Gao",
      "Qiujie Dong",
      "Ruian Wang",
      "Shuangmin Chen",
      "Shiqing Xin",
      "Changhe Tu",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.09831",
    "title": "MAGIC: Detecting Advanced Persistent Threats via Masked Graph  Representation Learning",
    "abstract": "Advance Persistent Threats (APTs), adopted by most delicate attackers, are becoming increasing common and pose great threat to various enterprises and institutions. Data provenance analysis on provenance graphs has emerged as a common approach in APT detection. However, previous works have exhibited several shortcomings: (1) requiring attack-containing data and a priori knowledge of APTs, (2) failing in extracting the rich contextual information buried within provenance graphs and (3) becoming impracticable due to their prohibitive computation overhead and memory consumption. In this paper, we introduce MAGIC, a novel and flexible self-supervised APT detection approach capable of performing multi-granularity detection under different level of supervision. MAGIC leverages masked graph representation learning to model benign system entities and behaviors, performing efficient deep feature extraction and structure abstraction on provenance graphs. By ferreting out anomalous system behaviors via outlier detection methods, MAGIC is able to perform both system entity level and batched log level APT detection. MAGIC is specially designed to handle concept drift with a model adaption mechanism and successfully applies to universal conditions and detection scenarios. We evaluate MAGIC on three widely-used datasets, including both real-world and simulated attacks. Evaluation results indicate that MAGIC achieves promising detection results in all scenarios and shows enormous advantage over state-of-the-art APT detection approaches in performance overhead. ",
    "url": "https://arxiv.org/abs/2310.09831",
    "authors": [
      "Zian Jia",
      "Yun Xiong",
      "Yuhong Nan",
      "Yao Zhang",
      "Jinjing Zhao",
      "Mi Wen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09833",
    "title": "MIR2: Towards Provably Robust Multi-Agent Reinforcement Learning by  Mutual Information Regularization",
    "abstract": "Robust multi-agent reinforcement learning (MARL) necessitates resilience to uncertain or worst-case actions by unknown allies. Existing max-min optimization techniques in robust MARL seek to enhance resilience by training agents against worst-case adversaries, but this becomes intractable as the number of agents grows, leading to exponentially increasing worst-case scenarios. Attempts to simplify this complexity often yield overly pessimistic policies, inadequate robustness across scenarios and high computational demands. Unlike these approaches, humans naturally learn adaptive and resilient behaviors without the necessity of preparing for every conceivable worst-case scenario. Motivated by this, we propose MIR2, which trains policy in routine scenarios and minimize Mutual Information as Robust Regularization. Theoretically, we frame robustness as an inference problem and prove that minimizing mutual information between histories and actions implicitly maximizes a lower bound on robustness under certain assumptions. Further analysis reveals that our proposed approach prevents agents from overreacting to others through an information bottleneck and aligns the policy with a robust action prior. Empirically, our MIR2 displays even greater resilience against worst-case adversaries than max-min optimization in StarCraft II, Multi-agent Mujoco and rendezvous. Our superiority is consistent when deployed in challenging real-world robot swarm control scenario. See code and demo videos in Supplementary Materials. ",
    "url": "https://arxiv.org/abs/2310.09833",
    "authors": [
      "Simin Li",
      "Ruixiao Xu",
      "Jun Guo",
      "Pu Feng",
      "Jiakai Wang",
      "Aishan Liu",
      "Yaodong Yang",
      "Xianglong Liu",
      "Weifeng Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.09835",
    "title": "Secure and Robust Communications for Cislunar Space Networks",
    "abstract": "There is no doubt that the Moon has become the center of interest for commercial and international actors. Over the past decade, the number of planned long-term missions has increased dramatically. This makes the establishment of cislunar space networks (CSNs) crucial to orchestrate uninterrupted communications between the Moon and Earth. However, there are numerous challenges, unknowns, and uncertainties associated with cislunar communications that may pose various risks to lunar missions. In this study, we aim to address these challenges for cislunar communications by proposing a machine learning-based cislunar space domain awareness (SDA) capability that enables robust and secure communications. To this end, we first propose a detailed channel model for selected cislunar scenarios. Secondly, we propose two types of interference that could model anomalies that occur in cislunar space and are so far known only to a limited extent. Finally, we discuss our cislunar SDA to work in conjunction with the spacecraft communication system. Our proposed cislunar SDA, involving heuristic learning capabilities with machine learning algorithms, detects interference models with over 96% accuracy. The results demonstrate the promising performance of our cislunar SDA approach for secure and robust cislunar communication. ",
    "url": "https://arxiv.org/abs/2310.09835",
    "authors": [
      "Selen Gecgel Cetin",
      "Gunes Karabulut Kurt",
      "Angeles Vazquez-Castro"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09838",
    "title": "Explaining How a Neural Network Play the Go Game and Let People Learn",
    "abstract": "The AI model has surpassed human players in the game of Go, and it is widely believed that the AI model has encoded new knowledge about the Go game beyond human players. In this way, explaining the knowledge encoded by the AI model and using it to teach human players represent a promising-yet-challenging issue in explainable AI. To this end, mathematical supports are required to ensure that human players can learn accurate and verifiable knowledge, rather than specious intuitive analysis. Thus, in this paper, we extract interaction primitives between stones encoded by the value network for the Go game, so as to enable people to learn from the value network. Experiments show the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2310.09838",
    "authors": [
      "Huilin Zhou",
      "Huijie Tang",
      "Mingjie Li",
      "Hao Zhang",
      "Zhenyu Liu",
      "Quanshi Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09853",
    "title": "MERTech: Instrument Playing Technique Detection Using Self-Supervised  Pretrained Model With Multi-Task Finetuning",
    "abstract": "Instrument playing techniques (IPTs) constitute a pivotal component of musical expression. However, the development of automatic IPT detection methods suffers from limited labeled data and inherent class imbalance issues. In this paper, we propose to apply a self-supervised learning model pre-trained on large-scale unlabeled music data and finetune it on IPT detection tasks. This approach addresses data scarcity and class imbalance challenges. Recognizing the significance of pitch in capturing the nuances of IPTs and the importance of onset in locating IPT events, we investigate multi-task finetuning with pitch and onset detection as auxiliary tasks. Additionally, we apply a post-processing approach for event-level prediction, where an IPT activation initiates an event only if the onset output confirms an onset in that frame. Our method outperforms prior approaches in both frame-level and event-level metrics across multiple IPT benchmark datasets. Further experiments demonstrate the efficacy of multi-task finetuning on each IPT class. ",
    "url": "https://arxiv.org/abs/2310.09853",
    "authors": [
      "Dichucheng Li",
      "Yinghao Ma",
      "Weixing Wei",
      "Qiuqiang Kong",
      "Yulun Wu",
      "Mingjin Che",
      "Fan Xia",
      "Emmanouil Benetos",
      "Wei Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.09856",
    "title": "Pseudo-differential integral autoencoder network for inverse PDE  operators",
    "abstract": "Partial differential equations (PDEs) play a foundational role in modeling physical phenomena. This study addresses the challenging task of determining variable coefficients within PDEs from measurement data. We introduce a novel neural network, \"pseudo-differential IAEnet\" (pd-IAEnet), which draws inspiration from pseudo-differential operators. pd-IAEnet achieves significantly enhanced computational speed and accuracy with fewer parameters compared to conventional models. Extensive benchmark evaluations are conducted across a range of inverse problems, including Electrical Impedance Tomography (EIT), optical tomography, and seismic imaging, consistently demonstrating pd-IAEnet's superior accuracy. Notably, pd-IAEnet exhibits robustness in the presence of measurement noise, a critical characteristic for real-world applications. An exceptional feature is its discretization invariance, enabling effective training on data from diverse discretization schemes while maintaining accuracy on different meshes. In summary, pd-IAEnet offers a potent and efficient solution for addressing inverse PDE problems, contributing to improved computational efficiency, robustness, and adaptability to a wide array of data sources. ",
    "url": "https://arxiv.org/abs/2310.09856",
    "authors": [
      "Ke Chen",
      "Jasen Lai",
      "Chunmei Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.09858",
    "title": "Federated Reinforcement Learning for Resource Allocation in V2X Networks",
    "abstract": "Resource allocation significantly impacts the performance of vehicle-to-everything (V2X) networks. Most existing algorithms for resource allocation are based on optimization or machine learning (e.g., reinforcement learning). In this paper, we explore resource allocation in a V2X network under the framework of federated reinforcement learning (FRL). On one hand, the usage of RL overcomes many challenges from the model-based optimization schemes. On the other hand, federated learning (FL) enables agents to deal with a number of practical issues, such as privacy, communication overhead, and exploration efficiency. The framework of FRL is then implemented by the inexact alternative direction method of multipliers (ADMM), where subproblems are solved approximately using policy gradients and accelerated by an adaptive step size calculated from their second moments. The developed algorithm, PASM, is proven to be convergent under mild conditions and has a nice numerical performance compared with some baseline methods for solving the resource allocation problem in a V2X network. ",
    "url": "https://arxiv.org/abs/2310.09858",
    "authors": [
      "Kaidi Xu",
      "Shenglong Zhou",
      "Geoffrey Ye Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.09872",
    "title": "Empower Text-Attributed Graphs Learning with Large Language Models  (LLMs)",
    "abstract": "Text-attributed graphs have recently garnered significant attention due to their wide range of applications in web domains. Existing methodologies employ word embedding models for acquiring text representations as node features, which are subsequently fed into Graph Neural Networks (GNNs) for training. Recently, the advent of Large Language Models (LLMs) has introduced their powerful capabilities in information retrieval and text generation, which can greatly enhance the text attributes of graph data. Furthermore, the acquisition and labeling of extensive datasets are both costly and time-consuming endeavors. Consequently, few-shot learning has emerged as a crucial problem in the context of graph learning tasks. In order to tackle this challenge, we propose a lightweight paradigm called ENG, which adopts a plug-and-play approach to empower text-attributed graphs through node generation using LLMs. Specifically, we utilize LLMs to extract semantic information from the labels and generate samples that belong to these categories as exemplars. Subsequently, we employ an edge predictor to capture the structural information inherent in the raw dataset and integrate the newly generated samples into the original graph. This approach harnesses LLMs for enhancing class-level information and seamlessly introduces labeled nodes and edges without modifying the raw dataset, thereby facilitating the node classification task in few-shot scenarios. Extensive experiments demonstrate the outstanding performance of our proposed paradigm, particularly in low-shot scenarios. For instance, in the 1-shot setting of the ogbn-arxiv dataset, ENG achieves a 76% improvement over the baseline model. ",
    "url": "https://arxiv.org/abs/2310.09872",
    "authors": [
      "Jianxiang Yu",
      "Yuxiang Ren",
      "Chenghua Gong",
      "Jiaqi Tan",
      "Xiang Li",
      "Xuecang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09883",
    "title": "Zero-Shot Object Goal Visual Navigation With Class-Independent  Relationship Network",
    "abstract": "This paper investigates the zero-shot object goal visual navigation problem. In the object goal visual navigation task, the agent needs to locate navigation targets from its egocentric visual input. \"Zero-shot\" means that the target the agent needs to find is not trained during the training phase. To address the issue of coupling navigation ability with target features during training, we propose the Class-Independent Relationship Network (CIRN). This method combines target detection information with the relative semantic similarity between the target and the navigation target, and constructs a brand new state representation based on similarity ranking, this state representation does not include target feature or environment feature, effectively decoupling the agent's navigation ability from target features. And a Graph Convolutional Network (GCN) is employed to learn the relationships between different objects based on their similarities. During testing, our approach demonstrates strong generalization capabilities, including zero-shot navigation tasks with different targets and environments. Through extensive experiments in the AI2-THOR virtual environment, our method outperforms the current state-of-the-art approaches in the zero-shot object goal visual navigation task. Furthermore, we conducted experiments in more challenging cross-target and cross-scene settings, which further validate the robustness and generalization ability of our method. Our code is available at: https://github.com/SmartAndCleverRobot/ICRA-CIRN. ",
    "url": "https://arxiv.org/abs/2310.09883",
    "authors": [
      "Xinting Li",
      "Shizhou Zhang",
      "Yue LU",
      "Kerry Dan",
      "Lingyan Ran",
      "Peng Wang",
      "Yanning Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.09891",
    "title": "Towards Deep Learning Models Resistant to Transfer-based Adversarial  Attacks via Data-centric Robust Learning",
    "abstract": "Transfer-based adversarial attacks raise a severe threat to real-world deep learning systems since they do not require access to target models. Adversarial training (AT), which is recognized as the strongest defense against white-box attacks, has also guaranteed high robustness to (black-box) transfer-based attacks. However, AT suffers from heavy computational overhead since it optimizes the adversarial examples during the whole training process. In this paper, we demonstrate that such heavy optimization is not necessary for AT against transfer-based attacks. Instead, a one-shot adversarial augmentation prior to training is sufficient, and we name this new defense paradigm Data-centric Robust Learning (DRL). Our experimental results show that DRL outperforms widely-used AT techniques (e.g., PGD-AT, TRADES, EAT, and FAT) in terms of black-box robustness and even surpasses the top-1 defense on RobustBench when combined with diverse data augmentations and loss regularizations. We also identify other benefits of DRL, for instance, the model generalization capability and robust fairness. ",
    "url": "https://arxiv.org/abs/2310.09891",
    "authors": [
      "Yulong Yang",
      "Chenhao Lin",
      "Xiang Ji",
      "Qiwei Tian",
      "Qian Li",
      "Hongshan Yang",
      "Zhibo Wang",
      "Chao Shen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09892",
    "title": "Active Perception using Neural Radiance Fields",
    "abstract": "We study active perception from first principles to argue that an autonomous agent performing active perception should maximize the mutual information that past observations posses about future ones. Doing so requires (a) a representation of the scene that summarizes past observations and the ability to update this representation to incorporate new observations (state estimation and mapping), (b) the ability to synthesize new observations of the scene (a generative model), and (c) the ability to select control trajectories that maximize predictive information (planning). This motivates a neural radiance field (NeRF)-like representation which captures photometric, geometric and semantic properties of the scene grounded. This representation is well-suited to synthesizing new observations from different viewpoints. And thereby, a sampling-based planner can be used to calculate the predictive information from synthetic observations along dynamically-feasible trajectories. We use active perception for exploring cluttered indoor environments and employ a notion of semantic uncertainty to check for the successful completion of an exploration task. We demonstrate these ideas via simulation in realistic 3D indoor environments. ",
    "url": "https://arxiv.org/abs/2310.09892",
    "authors": [
      "Siming He",
      "Christopher D. Hsu",
      "Dexter Ong",
      "Yifei Simon Shao",
      "Pratik Chaudhari"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.09924",
    "title": "Deep Reinforcement Learning with Explicit Context Representation",
    "abstract": "Reinforcement learning (RL) has shown an outstanding capability for solving complex computational problems. However, most RL algorithms lack an explicit method that would allow learning from contextual information. Humans use context to identify patterns and relations among elements in the environment, along with how to avoid making wrong actions. On the other hand, what may seem like an obviously wrong decision from a human perspective could take hundreds of steps for an RL agent to learn to avoid. This paper proposes a framework for discrete environments called Iota explicit context representation (IECR). The framework involves representing each state using contextual key frames (CKFs), which can then be used to extract a function that represents the affordances of the state; in addition, two loss functions are introduced with respect to the affordances of the state. The novelty of the IECR framework lies in its capacity to extract contextual information from the environment and learn from the CKFs' representation. We validate the framework by developing four new algorithms that learn using context: Iota deep Q-network (IDQN), Iota double deep Q-network (IDDQN), Iota dueling deep Q-network (IDuDQN), and Iota dueling double deep Q-network (IDDDQN). Furthermore, we evaluate the framework and the new algorithms in five discrete environments. We show that all the algorithms, which use contextual information, converge in around 40,000 training steps of the neural networks, significantly outperforming their state-of-the-art equivalents. ",
    "url": "https://arxiv.org/abs/2310.09924",
    "authors": [
      "Francisco Munguia-Galeano",
      "Ah-Hwee Tan",
      "Ze Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09932",
    "title": "\"Reading Between the Heat\": Co-Teaching Body Thermal Signatures for  Non-intrusive Stress Detection",
    "abstract": "Stress impacts our physical and mental health as well as our social life. A passive and contactless indoor stress monitoring system can unlock numerous important applications such as workplace productivity assessment, smart homes, and personalized mental health monitoring. While the thermal signatures from a user's body captured by a thermal camera can provide important information about the \"fight-flight\" response of the sympathetic and parasympathetic nervous system, relying solely on thermal imaging for training a stress prediction model often lead to overfitting and consequently a suboptimal performance. This paper addresses this challenge by introducing ThermaStrain, a novel co-teaching framework that achieves high-stress prediction performance by transferring knowledge from the wearable modality to the contactless thermal modality. During training, ThermaStrain incorporates a wearable electrodermal activity (EDA) sensor to generate stress-indicative representations from thermal videos, emulating stress-indicative representations from a wearable EDA sensor. During testing, only thermal sensing is used, and stress-indicative patterns from thermal data and emulated EDA representations are extracted to improve stress assessment. The study collected a comprehensive dataset with thermal video and EDA data under various stress conditions and distances. ThermaStrain achieves an F1 score of 0.8293 in binary stress classification, outperforming the thermal-only baseline approach by over 9%. Extensive evaluations highlight ThermaStrain's effectiveness in recognizing stress-indicative attributes, its adaptability across distances and stress scenarios, real-time executability on edge platforms, its applicability to multi-individual sensing, ability to function on limited visibility and unfamiliar conditions, and the advantages of its co-teaching approach. ",
    "url": "https://arxiv.org/abs/2310.09932",
    "authors": [
      "Yi Xiao",
      "Harshit Sharma",
      "Zhongyang Zhang",
      "Dessa Bergen-Cico",
      "Tauhidur Rahman",
      "Asif Salekin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.09933",
    "title": "Quantitative Stability Conditions for Grid-Forming Converters With  Complex Droop Control",
    "abstract": "In this paper, we study analytically the transient stability of grid-connected distributed generation systems with grid-forming (GFM) complex droop control, also known as dispatchable virtual oscillator control (dVOC). We prove theoretically that complex droop control, as a state-of-the-art GFM control, always possesses steady-state equilibria whereas classical p/f and q/v droop control does not. We provide quantitative conditions for complex droop control maintaining transient stability (global asymptotic stability) under grid disturbances, which is beyond the well-established local (non-global) stability for classical droop control. For the transient instability of complex droop control, we reveal that the unstable trajectories are bounded, manifesting as limit cycle oscillations. Moreover, we extend our stability results from second-order GFM control dynamics to full-order system dynamics that additionally encompass both circuit electromagnetic transients and inner-loop dynamics. Our theoretical results contribute an insightful understanding of the transient stability and instability of complex droop control and offer practical guidelines for parameter tuning and stability guarantees. ",
    "url": "https://arxiv.org/abs/2310.09933",
    "authors": [
      "Xiuqiang He",
      "Linbin Huang",
      "Irina Suboti\u0107",
      "Verena H\u00e4berle",
      "Florian D\u00f6rfler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.09943",
    "title": "Evaluating Robustness of Visual Representations for Object Assembly Task  Requiring Spatio-Geometrical Reasoning",
    "abstract": "This paper primarily focuses on evaluating and benchmarking the robustness of visual representations in the context of object assembly tasks. Specifically, it investigates the alignment and insertion of objects with geometrical extrusions and intrusions, commonly referred to as a peg-in-hole task. The accuracy required to detect and orient the peg and the hole geometry in SE(3) space for successful assembly poses significant challenges. Addressing this, we employ a general framework in visuomotor policy learning that utilizes visual pretraining models as vision encoders. Our study investigates the robustness of this framework when applied to a dual-arm manipulation setup, specifically to the grasp variations. Our quantitative analysis shows that existing pretrained models fail to capture the essential visual features necessary for this task. However, a visual encoder trained from scratch consistently outperforms the frozen pretrained models. Moreover, we discuss rotation representations and associated loss functions that substantially improve policy learning. We present a novel task scenario designed to evaluate the progress in visuomotor policy learning, with a specific focus on improving the robustness of intricate assembly tasks that require both geometrical and spatial reasoning. Videos, additional experiments, dataset, and code are available at https://bit.ly/geometric-peg-in-hole . ",
    "url": "https://arxiv.org/abs/2310.09943",
    "authors": [
      "Chahyon Ku",
      "Carl Winge",
      "Ryan Diaz",
      "Wentao Yuan",
      "Karthik Desingh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.09949",
    "title": "Chameleon: a Heterogeneous and Disaggregated Accelerator System for  Retrieval-Augmented Language Models",
    "abstract": "A Retrieval-Augmented Language Model (RALM) augments a generative language model by retrieving context-specific knowledge from an external database. This strategy facilitates impressive text generation quality even with smaller models, thus reducing orders of magnitude of computational demands. However, RALMs introduce unique system design challenges due to (a) the diverse workload characteristics between LM inference and retrieval and (b) the various system requirements and bottlenecks for different RALM configurations such as model sizes, database sizes, and retrieval frequencies. We propose Chameleon, a heterogeneous accelerator system that integrates both LM and retrieval accelerators in a disaggregated architecture. The heterogeneity ensures efficient acceleration of both LM inference and retrieval, while the accelerator disaggregation enables the system to independently scale both types of accelerators to fulfill diverse RALM requirements. Our Chameleon prototype implements retrieval accelerators on FPGAs and assigns LM inference to GPUs, with a CPU server orchestrating these accelerators over the network. Compared to CPU-based and CPU-GPU vector search systems, Chameleon achieves up to 23.72x speedup and 26.2x energy efficiency. Evaluated on various RALMs, Chameleon exhibits up to 2.16x reduction in latency and 3.18x speedup in throughput compared to the hybrid CPU-GPU architecture. These promising results pave the way for bringing accelerator heterogeneity and disaggregation into future RALM systems. ",
    "url": "https://arxiv.org/abs/2310.09949",
    "authors": [
      "Wenqi Jiang",
      "Marco Zeller",
      "Roger Waleffe",
      "Torsten Hoefler",
      "Gustavo Alonso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.09952",
    "title": "Seeking Next Layer Neurons' Attention for Error-Backpropagation-Like  Training in a Multi-Agent Network Framework",
    "abstract": "Despite considerable theoretical progress in the training of neural networks viewed as a multi-agent system of neurons, particularly concerning biological plausibility and decentralized training, their applicability to real-world problems remains limited due to scalability issues. In contrast, error-backpropagation has demonstrated its effectiveness for training deep networks in practice. In this study, we propose a local objective for neurons that, when pursued by neurons individually, align them to exhibit similarities to error-backpropagation in terms of efficiency and scalability during training. For this purpose, we examine a neural network comprising decentralized, self-interested neurons seeking to maximize their local objective -- attention from subsequent layer neurons -- and identify the optimal strategy for neurons. We also analyze the relationship between this strategy and backpropagation, establishing conditions under which the derived strategy is equivalent to error-backpropagation. Lastly, we demonstrate the learning capacity of these multi-agent neural networks through experiments on three datasets and showcase their superior performance relative to error-backpropagation in a catastrophic forgetting benchmark. ",
    "url": "https://arxiv.org/abs/2310.09952",
    "authors": [
      "Arshia Soltani Moakhar",
      "Mohammad Azizmalayeri",
      "Hossein Mirzaei",
      "Mohammad Taghi Manzuri",
      "Mohammad Hossein Rohban"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2310.09987",
    "title": "Network Disruption via Continuous Batch Removal: The Case of Sicilian  Mafia",
    "abstract": "Network disruption is pivotal in understanding the robustness and vulnerability of complex networks, which is instrumental in devising strategies for infrastructure protection, epidemic control, cybersecurity, and combating crime. In this paper, with a particular focus on disrupting criminal networks, we proposed to impose a within-the-largest-connected-component constraint in a continuous batch removal disruption process. Through a series of experiments on a recently released Sicilian Mafia network, we revealed that the constraint would enhance degree-based methods while weakening betweenness-based approaches. Moreover, based on the findings from the experiments using various disruption strategies, we propose a structurally-filtered greedy disruption strategy that integrates the effectiveness of greedy-like methods with the efficiency of structural-metric-based approaches. The proposed strategy significantly outperforms the longstanding state-of-the-art method of betweenness centrality while maintaining the same time complexity. ",
    "url": "https://arxiv.org/abs/2310.09987",
    "authors": [
      "Mingshan Jia",
      "Pasquale De Meo",
      "Bogdan Gabrys",
      "Katarzyna Musial"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.09994",
    "title": "A Survey of Graph and Attention Based Hyperspectral Image Classification  Methods for Remote Sensing Data",
    "abstract": "The use of Deep Learning techniques for classification in Hyperspectral Imaging (HSI) is rapidly growing and achieving improved performances. Due to the nature of the data captured by sensors that produce HSI images, a common issue is the dimensionality of the bands that may or may not contribute to the label class distinction. Due to the widespread nature of class labels, Principal Component Analysis is a common method used for reducing the dimensionality. However,there may exist methods that incorporate all bands of the Hyperspectral image with the help of the Attention mechanism. Furthermore, to yield better spectral spatial feature extraction, recent methods have also explored the usage of Graph Convolution Networks and their unique ability to use node features in prediction, which is akin to the pixel spectral makeup. In this survey we present a comprehensive summary of Graph based and Attention based methods to perform Hyperspectral Image Classification for remote sensing and aerial HSI images. We also summarize relevant datasets on which these techniques have been evaluated and benchmark the processing techniques. ",
    "url": "https://arxiv.org/abs/2310.09994",
    "authors": [
      "Aryan Vats",
      "Manan Suri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.10001",
    "title": "Auditing Targeted Political Advertising on Social Media During the 2021  German Election",
    "abstract": "Political advertising on social media has become a central element in election campaigns. However, granular information about political advertising on social media was previously unavailable, thus raising concerns regarding fairness, accountability, and transparency in electoral processes. In this paper, we analyze targeted political advertising on social media using a unique, large-scale dataset of over 80000 political ads from Meta during the 2021 German federal election, with more than 1.1 billion impressions. For each political ad, our dataset records granular information about targeting strategies, spending, and actual impressions. We then study (i) the prevalence of targeted ads across the political spectrum; (ii) the discrepancies between targeted and actual audiences due to algorithmic distribution; and (iii) what makes an efficient targeting strategy on social media. We find that targeted ads are prevalent across the entire political spectrum, with considerable differences in strategies and efficiency between the political left and right. Furthermore, there are significant discrepancies between the targeted and actual audience, which vary across parties. Notably, the efficiency of political ads (as measured by impressions per EUR) is particularly high when ads are targeted at a broad audience, or published by far-right parties - which raises important fairness concerns. Overall, our work contributes to a better understanding of targeted political advertising on social media and informs policymakers about the design of effective regulatory frameworks to promote fairness, accountability, and transparency. ",
    "url": "https://arxiv.org/abs/2310.10001",
    "authors": [
      "Dominik B\u00e4r",
      "Francesco Pierri",
      "Gianmarco De Francisci Morales",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.10010",
    "title": "Black-box Targeted Adversarial Attack on Segment Anything (SAM)",
    "abstract": "Deep recognition models are widely vulnerable to adversarial examples, which change the model output by adding quasi-imperceptible perturbation to the image input. Recently, Segment Anything Model (SAM) has emerged to become a popular foundation model in computer vision due to its impressive generalization to unseen data and tasks. Realizing flexible attacks on SAM is beneficial for understanding the robustness of SAM in the adversarial context. To this end, this work aims to achieve a targeted adversarial attack (TAA) on SAM. Specifically, under a certain prompt, the goal is to make the predicted mask of an adversarial example resemble that of a given target image. The task of TAA on SAM has been realized in a recent arXiv work in the white-box setup by assuming access to prompt and model, which is thus less practical. To address the issue of prompt dependence, we propose a simple yet effective approach by only attacking the image encoder. Moreover, we propose a novel regularization loss to enhance the cross-model transferability by increasing the feature dominance of adversarial images over random natural images. Extensive experiments verify the effectiveness of our proposed simple techniques to conduct a successful black-box TAA on SAM. ",
    "url": "https://arxiv.org/abs/2310.10010",
    "authors": [
      "Sheng Zheng",
      "Chaoning Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.10033",
    "title": "Deep Unfolding Network for Image Compressed Sensing by Content-adaptive  Gradient Updating and Deformation-invariant Non-local Modeling",
    "abstract": "Inspired by certain optimization solvers, the deep unfolding network (DUN) has attracted much attention in recent years for image compressed sensing (CS). However, there still exist the following two issues: 1) In existing DUNs, most hyperparameters are usually content independent, which greatly limits their adaptability for different input contents. 2) In each iteration, a plain convolutional neural network is usually adopted, which weakens the perception of wider context prior and therefore depresses the expressive ability. In this paper, inspired by the traditional Proximal Gradient Descent (PGD) algorithm, a novel DUN for image compressed sensing (dubbed DUN-CSNet) is proposed to solve the above two issues. Specifically, for the first issue, a novel content adaptive gradient descent network is proposed, in which a well-designed step size generation sub-network is developed to dynamically allocate the corresponding step sizes for different textures of input image by generating a content-aware step size map, realizing a content-adaptive gradient updating. For the second issue, considering the fact that many similar patches exist in an image but have undergone a deformation, a novel deformation-invariant non-local proximal mapping network is developed, which can adaptively build the long-range dependencies between the nonlocal patches by deformation-invariant non-local modeling, leading to a wider perception on context priors. Extensive experiments manifest that the proposed DUN-CSNet outperforms existing state-of-the-art CS methods by large margins. ",
    "url": "https://arxiv.org/abs/2310.10033",
    "authors": [
      "Wenxue Cui",
      "Xiaopeng Fan",
      "Jian Zhang",
      "Debin Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2310.10036",
    "title": "Evading Detection Actively: Toward Anti-Forensics against Forgery  Localization",
    "abstract": "Anti-forensics seeks to eliminate or conceal traces of tampering artifacts. Typically, anti-forensic methods are designed to deceive binary detectors and persuade them to misjudge the authenticity of an image. However, to the best of our knowledge, no attempts have been made to deceive forgery detectors at the pixel level and mis-locate forged regions. Traditional adversarial attack methods cannot be directly used against forgery localization due to the following defects: 1) they tend to just naively induce the target forensic models to flip their pixel-level pristine or forged decisions; 2) their anti-forensics performance tends to be severely degraded when faced with the unseen forensic models; 3) they lose validity once the target forensic models are retrained with the anti-forensics images generated by them. To tackle the three defects, we propose SEAR (Self-supErvised Anti-foRensics), a novel self-supervised and adversarial training algorithm that effectively trains deep-learning anti-forensic models against forgery localization. SEAR sets a pretext task to reconstruct perturbation for self-supervised learning. In adversarial training, SEAR employs a forgery localization model as a supervisor to explore tampering features and constructs a deep-learning concealer to erase corresponding traces. We have conducted largescale experiments across diverse datasets. The experimental results demonstrate that, through the combination of self-supervised learning and adversarial learning, SEAR successfully deceives the state-of-the-art forgery localization methods, as well as tackle the three defects regarding traditional adversarial attack methods mentioned above. ",
    "url": "https://arxiv.org/abs/2310.10036",
    "authors": [
      "Long Zhuo",
      "Shenghai Luo",
      "Shunquan Tan",
      "Han Chen",
      "Bin Li",
      "Jiwu Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2310.10038",
    "title": "Smart City Transportation: Deep Learning Ensemble Approach for Traffic  Accident Detection",
    "abstract": "The dynamic and unpredictable nature of road traffic necessitates effective accident detection methods for enhancing safety and streamlining traffic management in smart cities. This paper offers a comprehensive exploration study of prevailing accident detection techniques, shedding light on the nuances of other state-of-the-art methodologies while providing a detailed overview of distinct traffic accident types like rear-end collisions, T-bone collisions, and frontal impact accidents. Our novel approach introduces the I3D-CONVLSTM2D model architecture, a lightweight solution tailored explicitly for accident detection in smart city traffic surveillance systems by integrating RGB frames with optical flow information. Our experimental study's empirical analysis underscores our approach's efficacy, with the I3D-CONVLSTM2D RGB + Optical-Flow (Trainable) model outperforming its counterparts, achieving an impressive 87\\% Mean Average Precision (MAP). Our findings further elaborate on the challenges posed by data imbalances, particularly when working with a limited number of datasets, road structures, and traffic scenarios. Ultimately, our research illuminates the path towards a sophisticated vision-based accident detection system primed for real-time integration into edge IoT devices within smart urban infrastructures. ",
    "url": "https://arxiv.org/abs/2310.10038",
    "authors": [
      "Victor Adewopo",
      "Nelly Elsayed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.10056",
    "title": "Latent Conservative Objective Models for Data-Driven Crystal Structure  Prediction",
    "abstract": "In computational chemistry, crystal structure prediction (CSP) is an optimization problem that involves discovering the lowest energy stable crystal structure for a given chemical formula. This problem is challenging as it requires discovering globally optimal designs with the lowest energies on complex manifolds. One approach to tackle this problem involves building simulators based on density functional theory (DFT) followed by running search in simulation, but these simulators are painfully slow. In this paper, we study present and study an alternate, data-driven approach to crystal structure prediction: instead of directly searching for the most stable structures in simulation, we train a surrogate model of the crystal formation energy from a database of existing crystal structures, and then optimize this model with respect to the parameters of the crystal structure. This surrogate model is trained to be conservative so as to prevent exploitation of its errors by the optimizer. To handle optimization in the non-Euclidean space of crystal structures, we first utilize a state-of-the-art graph diffusion auto-encoder (CD-VAE) to convert a crystal structure into a vector-based search space and then optimize a conservative surrogate model of the crystal energy, trained on top of this vector representation. We show that our approach, dubbed LCOMs (latent conservative objective models), performs comparably to the best current approaches in terms of success rate of structure prediction, while also drastically reducing computational cost. ",
    "url": "https://arxiv.org/abs/2310.10056",
    "authors": [
      "Han Qi",
      "Xinyang Geng",
      "Stefano Rando",
      "Iku Ohama",
      "Aviral Kumar",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10060",
    "title": "Data Augmentation for Time-Series Classification: a Comprehensive Survey",
    "abstract": "Data Augmentation (DA) for Time Series Classification (TSC) is a common technique in machine learning to increase the number of training samples, which enhances model performance, enriches the dataset variety, and helps mitigate overfitting. Nonetheless, this technique is currently faced with challenges characterized by incomplete reviews, ambiguous taxonomies, insufficient evaluations, and user-unfriendly tools. This study undertakes a detailed exploration of DA for TSC. We first conducted a thorough review of the developments in the field of DA for TSC over the past 10 years since existing surveys on DA for TSC are not comprehensive enough. Our efforts encompassed gathering more than 60 distinct DA techniques from a pool over 100 research papers. This endeavor culminated in the creation of an innovative taxonomy exclusively tailored to DA within the TSC domain. The taxonomy organizes methods into five main categories: Transformation-Based, Pattern-Based, Generative, Decomposition-Based, and Automated Data Augmentation. This classification serves as a sturdy reference for researchers when choosing methods. In addition, since there is a lack of comprehensive and detailed evaluations of popular data augmentation methods, we conduct a comprehensive assessment. More than 15 DA methods were tested on 8 UCR time-series datasets using the ResNet and deploying a multi-metric evaluation strategy that includes Accuracy, Method Ranking, and Residual Analysis, the outcome was a baseline accuracy of 88.94 +- 11.83%. Findings highlighted the variable effectiveness of DA methods, for instance, methods like Permutation enhanced performance while Rotation decreased accuracy. Dataset properties also profoundly influence DA efficacy, we give users accurate and practical advice based on our experimental results to guide them in choosing the most appropriate DA methods for different data characteristics. ",
    "url": "https://arxiv.org/abs/2310.10060",
    "authors": [
      "Zijun Gao",
      "Lingbo Li",
      "Tianhua Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10064",
    "title": "Learning Graph Filters for Spectral GNNs via Newton Interpolation",
    "abstract": "Spectral Graph Neural Networks (GNNs) are gaining attention because they can surpass the limitations of message-passing GNNs by learning spectral filters that capture essential frequency information in graph data through task supervision. However, previous research suggests that the choice of filter frequency is tied to the graph's homophily level, a connection that hasn't been thoroughly explored in existing spectral GNNs. To address this gap, the study conducts both theoretical and empirical analyses, revealing that low-frequency filters have a positive correlation with homophily, while high-frequency filters have a negative correlation. This leads to the introduction of a shape-aware regularization technique applied to a Newton Interpolation-based spectral filter, enabling the customization of polynomial spectral filters that align with desired homophily levels. Extensive experiments demonstrate that NewtonNet successfully achieves the desired filter shapes and exhibits superior performance on both homophilous and heterophilous datasets. ",
    "url": "https://arxiv.org/abs/2310.10064",
    "authors": [
      "Junjie Xu",
      "Enyan Dai",
      "Dongsheng Luo",
      "Xiang Zhang",
      "Suhang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.10073",
    "title": "Expression Domain Translation Network for Cross-domain Head Reenactment",
    "abstract": "Despite the remarkable advancements in head reenactment, the existing methods face challenges in cross-domain head reenactment, which aims to transfer human motions to domains outside the human, including cartoon characters. It is still difficult to extract motion from out-of-domain images due to the distinct appearances, such as large eyes. Recently, previous work introduced a large-scale anime dataset called AnimeCeleb and a cross-domain head reenactment model, including an optimization-based mapping function to translate the human domain's expressions to the anime domain. However, we found that the mapping function, which relies on a subset of expressions, imposes limitations on the mapping of various expressions. To solve this challenge, we introduce a novel expression domain translation network that transforms human expressions into anime expressions. Specifically, to maintain the geometric consistency of expressions between the input and output of the expression domain translation network, we employ a 3D geometric-aware loss function that reduces the distances between the vertices in the 3D mesh of the human and anime. By doing so, it forces high-fidelity and one-to-one mapping with respect to two cross-expression domains. Our method outperforms existing methods in both qualitative and quantitative analysis, marking a significant advancement in the field of cross-domain head reenactment. ",
    "url": "https://arxiv.org/abs/2310.10073",
    "authors": [
      "Taewoong Kang",
      "Jeongsik Oh",
      "Jaeseong Lee",
      "Sunghyun Park",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.10074",
    "title": "SoTTA: Robust Test-Time Adaptation on Noisy Data Streams",
    "abstract": "Test-time adaptation (TTA) aims to address distributional shifts between training and testing data using only unlabeled test data streams for continual model adaptation. However, most TTA methods assume benign test streams, while test samples could be unexpectedly diverse in the wild. For instance, an unseen object or noise could appear in autonomous driving. This leads to a new threat to existing TTA algorithms; we found that prior TTA algorithms suffer from those noisy test samples as they blindly adapt to incoming samples. To address this problem, we present Screening-out Test-Time Adaptation (SoTTA), a novel TTA algorithm that is robust to noisy samples. The key enabler of SoTTA is two-fold: (i) input-wise robustness via high-confidence uniform-class sampling that effectively filters out the impact of noisy samples and (ii) parameter-wise robustness via entropy-sharpness minimization that improves the robustness of model parameters against large gradients from noisy samples. Our evaluation with standard TTA benchmarks with various noisy scenarios shows that our method outperforms state-of-the-art TTA methods under the presence of noisy samples and achieves comparable accuracy to those methods without noisy samples. The source code is available at https://github.com/taeckyung/SoTTA . ",
    "url": "https://arxiv.org/abs/2310.10074",
    "authors": [
      "Taesik Gong",
      "Yewon Kim",
      "Taeckyung Lee",
      "Sorn Chottananurak",
      "Sung-Ju Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10077",
    "title": "Prompt Packer: Deceiving LLMs through Compositional Instruction with  Hidden Attacks",
    "abstract": "Recently, Large language models (LLMs) with powerful general capabilities have been increasingly integrated into various Web applications, while undergoing alignment training to ensure that the generated content aligns with user intent and ethics. Unfortunately, they remain the risk of generating harmful content like hate speech and criminal activities in practical applications. Current approaches primarily rely on detecting, collecting, and training against harmful prompts to prevent such risks. However, they typically focused on the \"superficial\" harmful prompts with a solitary intent, ignoring composite attack instructions with multiple intentions that can easily elicit harmful content in real-world scenarios. In this paper, we introduce an innovative technique for obfuscating harmful instructions: Compositional Instruction Attacks (CIA), which refers to attacking by combination and encapsulation of multiple instructions. CIA hides harmful prompts within instructions of harmless intentions, making it impossible for the model to identify underlying malicious intentions. Furthermore, we implement two transformation methods, known as T-CIA and W-CIA, to automatically disguise harmful instructions as talking or writing tasks, making them appear harmless to LLMs. We evaluated CIA on GPT-4, ChatGPT, and ChatGLM2 with two safety assessment datasets and two harmful prompt datasets. It achieves an attack success rate of 95%+ on safety assessment datasets, and 83%+ for GPT-4, 91%+ for ChatGPT (gpt-3.5-turbo backed) and ChatGLM2-6B on harmful prompt datasets. Our approach reveals the vulnerability of LLMs to such compositional instruction attacks that harbor underlying harmful intentions, contributing significantly to LLM security development. Warning: this paper may contain offensive or upsetting content! ",
    "url": "https://arxiv.org/abs/2310.10077",
    "authors": [
      "Shuyu Jiang",
      "Xingshu Chen",
      "Rui Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.10090",
    "title": "Orthogonal Uncertainty Representation of Data Manifold for Robust  Long-Tailed Learning",
    "abstract": "In scenarios with long-tailed distributions, the model's ability to identify tail classes is limited due to the under-representation of tail samples. Class rebalancing, information augmentation, and other techniques have been proposed to facilitate models to learn the potential distribution of tail classes. The disadvantage is that these methods generally pursue models with balanced class accuracy on the data manifold, while ignoring the ability of the model to resist interference. By constructing noisy data manifold, we found that the robustness of models trained on unbalanced data has a long-tail phenomenon. That is, even if the class accuracy is balanced on the data domain, it still has bias on the noisy data manifold. However, existing methods cannot effectively mitigate the above phenomenon, which makes the model vulnerable in long-tailed scenarios. In this work, we propose an Orthogonal Uncertainty Representation (OUR) of feature embedding and an end-to-end training strategy to improve the long-tail phenomenon of model robustness. As a general enhancement tool, OUR has excellent compatibility with other methods and does not require additional data generation, ensuring fast and efficient training. Comprehensive evaluations on long-tailed datasets show that our method significantly improves the long-tail phenomenon of robustness, bringing consistent performance gains to other long-tailed learning methods. ",
    "url": "https://arxiv.org/abs/2310.10090",
    "authors": [
      "Yanbiao Ma",
      "Licheng Jiao",
      "Fang Liu",
      "Shuyuan Yang",
      "Xu Liu",
      "Lingling Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.10092",
    "title": "Label Differential Privacy via Aggregation",
    "abstract": "In many real-world applications, in particular due to recent developments in the privacy landscape, training data may be aggregated to preserve the privacy of sensitive training labels. In the learning from label proportions (LLP) framework, the dataset is partitioned into bags of feature-vectors which are available only with the sum of the labels per bag. A further restriction, which we call learning from bag aggregates (LBA) is where instead of individual feature-vectors, only the (possibly weighted) sum of the feature-vectors per bag is available. We study whether such aggregation techniques can provide privacy guarantees under the notion of label differential privacy (label-DP) previously studied in for e.g. [Chaudhuri-Hsu'11, Ghazi et al.'21, Esfandiari et al.'22]. It is easily seen that naive LBA and LLP do not provide label-DP. Our main result however, shows that weighted LBA using iid Gaussian weights with $m$ randomly sampled disjoint $k$-sized bags is in fact $(\\varepsilon, \\delta)$-label-DP for any $\\varepsilon > 0$ with $\\delta \\approx \\exp(-\\Omega(\\sqrt{k}))$ assuming a lower bound on the linear-mse regression loss. Further, this preserves the optimum over linear mse-regressors of bounded norm to within $(1 \\pm o(1))$-factor w.p. $\\approx 1 - \\exp(-\\Omega(m))$. We emphasize that no additive label noise is required. The analogous weighted-LLP does not however admit label-DP. Nevertheless, we show that if additive $N(0, 1)$ noise can be added to any constant fraction of the instance labels, then the noisy weighted-LLP admits similar label-DP guarantees without assumptions on the dataset, while preserving the utility of Lipschitz-bounded neural mse-regression tasks. Our work is the first to demonstrate that label-DP can be achieved by randomly weighted aggregation for regression tasks, using no or little additive noise. ",
    "url": "https://arxiv.org/abs/2310.10092",
    "authors": [
      "Anand Brahmbhatt",
      "Rishi Saket",
      "Shreyas Havaldar",
      "Anshul Nasery",
      "Aravindan Raghuveer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.10102",
    "title": "KAKURENBO: Adaptively Hiding Samples in Deep Neural Network Training",
    "abstract": "This paper proposes a method for hiding the least-important samples during the training of deep neural networks to increase efficiency, i.e., to reduce the cost of training. Using information about the loss and prediction confidence during training, we adaptively find samples to exclude in a given epoch based on their contribution to the overall learning process, without significantly degrading accuracy. We explore the converge properties when accounting for the reduction in the number of SGD updates. Empirical results on various large-scale datasets and models used directly in image classification and segmentation show that while the with-replacement importance sampling algorithm performs poorly on large datasets, our method can reduce total training time by up to 22% impacting accuracy only by 0.4% compared to the baseline. Code available at https://github.com/TruongThaoNguyen/kakurenbo ",
    "url": "https://arxiv.org/abs/2310.10102",
    "authors": [
      "Truong Thao Nguyen",
      "Balazs Gerofi",
      "Edgar Josafat Martinez-Noriega",
      "Fran\u00e7ois Trahay",
      "Mohamed Wahib"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10114",
    "title": "Node classification in networks via simplicial interactions",
    "abstract": "In the node classification task, it is intuitively understood that densely connected nodes tend to exhibit similar attributes. However, it is crucial to first define what constitutes a dense connection and to develop a reliable mathematical tool for assessing node cohesiveness. In this paper, we propose a probability-based objective function for semi-supervised node classification that takes advantage of higher-order networks' capabilities. The proposed function embodies the philosophy most aligned with the intuition behind classifying within higher-order networks, as it is designed to reduce the likelihood of nodes interconnected through higher-order networks bearing different labels. We evaluate the function using both balanced and imbalanced datasets generated by the Planted Partition Model (PPM), as well as a real-world political book dataset. According to the results, in challenging classification contexts characterized by low homo-connection probability, high hetero-connection probability, and limited prior information of nodes, higher-order networks outperform pairwise interactions in terms of objective function performance. Notably, the objective function exhibits elevated Recall and F1-score relative to Precision in the imbalanced dataset, indicating its potential applicability in many domains where detecting false negatives is critical, even at the expense of some false positives. ",
    "url": "https://arxiv.org/abs/2310.10114",
    "authors": [
      "Eunho Koo",
      "Tongseok Lim"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2310.10121",
    "title": "From Continuous Dynamics to Graph Neural Networks: Neural Diffusion and  Beyond",
    "abstract": "Graph neural networks (GNNs) have demonstrated significant promise in modelling relational data and have been widely applied in various fields of interest. The key mechanism behind GNNs is the so-called message passing where information is being iteratively aggregated to central nodes from their neighbourhood. Such a scheme has been found to be intrinsically linked to a physical process known as heat diffusion, where the propagation of GNNs naturally corresponds to the evolution of heat density. Analogizing the process of message passing to the heat dynamics allows to fundamentally understand the power and pitfalls of GNNs and consequently informs better model design. Recently, there emerges a plethora of works that proposes GNNs inspired from the continuous dynamics formulation, in an attempt to mitigate the known limitations of GNNs, such as oversmoothing and oversquashing. In this survey, we provide the first systematic and comprehensive review of studies that leverage the continuous perspective of GNNs. To this end, we introduce foundational ingredients for adapting continuous dynamics to GNNs, along with a general framework for the design of graph neural dynamics. We then review and categorize existing works based on their driven mechanisms and underlying dynamics. We also summarize how the limitations of classic GNNs can be addressed under the continuous framework. We conclude by identifying multiple open research directions. ",
    "url": "https://arxiv.org/abs/2310.10121",
    "authors": [
      "Andi Han",
      "Dai Shi",
      "Lequan Lin",
      "Junbin Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.10124",
    "title": "A Comprehensive Study of Privacy Risks in Curriculum Learning",
    "abstract": "Training a machine learning model with data following a meaningful order, i.e., from easy to hard, has been proven to be effective in accelerating the training process and achieving better model performance. The key enabling technique is curriculum learning (CL), which has seen great success and has been deployed in areas like image and text classification. Yet, how CL affects the privacy of machine learning is unclear. Given that CL changes the way a model memorizes the training data, its influence on data privacy needs to be thoroughly evaluated. To fill this knowledge gap, we perform the first study and leverage membership inference attack (MIA) and attribute inference attack (AIA) as two vectors to quantify the privacy leakage caused by CL. Our evaluation of nine real-world datasets with attack methods (NN-based, metric-based, label-only MIA, and NN-based AIA) revealed new insights about CL. First, MIA becomes slightly more effective when CL is applied, but the impact is much more prominent to a subset of training samples ranked as difficult. Second, a model trained under CL is less vulnerable under AIA, compared to MIA. Third, the existing defense techniques like DP-SGD, MemGuard, and MixupMMD are still effective under CL, though DP-SGD has a significant impact on target model accuracy. Finally, based on our insights into CL, we propose a new MIA, termed Diff-Cali, which exploits the difficulty scores for result calibration and is demonstrated to be effective against all CL methods and the normal training method. With this study, we hope to draw the community's attention to the unintended privacy risks of emerging machine-learning techniques and develop new attack benchmarks and defense solutions. ",
    "url": "https://arxiv.org/abs/2310.10124",
    "authors": [
      "Joann Qiongna Chen",
      "Xinlei He",
      "Zheng Li",
      "Yang Zhang",
      "Zhou Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10133",
    "title": "Empowering SMPC: Bridging the Gap Between Scalability, Memory Efficiency  and Privacy in Neural Network Inference",
    "abstract": "This paper aims to develop an efficient open-source Secure Multi-Party Computation (SMPC) repository, that addresses the issue of practical and scalable implementation of SMPC protocol on machines with moderate computational resources, while aiming to reduce the execution time. We implement the ABY2.0 protocol for SMPC, providing developers with effective tools for building applications on the ABY 2.0 protocol. This article addresses the limitations of the C++ based MOTION2NX framework for secure neural network inference, including memory constraints and operation compatibility issues. Our enhancements include optimizing the memory usage, reducing execution time using a third-party Helper node, and enhancing efficiency while still preserving data privacy. These optimizations enable MNIST dataset inference in just 32 seconds with only 0.2 GB of RAM for a 5-layer neural network. In contrast, the previous baseline implementation required 8.03 GB of RAM and 200 seconds of execution time. ",
    "url": "https://arxiv.org/abs/2310.10133",
    "authors": [
      "Ramya Burra",
      "Anshoo Tandon",
      "Srishti Mittal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.10138",
    "title": "Node-based Knowledge Graph Contrastive Learning for Medical Relationship  Prediction",
    "abstract": "The embedding of Biomedical Knowledge Graphs (BKGs) generates robust representations, valuable for a variety of artificial intelligence applications, including predicting drug combinations and reasoning disease-drug relationships. Meanwhile, contrastive learning (CL) is widely employed to enhance the distinctiveness of these representations. However, constructing suitable contrastive pairs for CL, especially within Knowledge Graphs (KGs), has been challenging. In this paper, we proposed a novel node-based contrastive learning method for knowledge graph embedding, NC-KGE. NC-KGE enhances knowledge extraction in embeddings and speeds up training convergence by constructing appropriate contrastive node pairs on KGs. This scheme can be easily integrated with other knowledge graph embedding (KGE) methods. For downstream task such as biochemical relationship prediction, we have incorporated a relation-aware attention mechanism into NC-KGE, focusing on the semantic relationships and node interactions. Extensive experiments show that NC-KGE performs competitively with state-of-the-art models on public datasets like FB15k-237 and WN18RR. Particularly in biomedical relationship prediction tasks, NC-KGE outperforms all baselines on datasets such as PharmKG8k-28, DRKG17k-21, and BioKG72k-14, especially in predicting drug combination relationships. We release our code at https://github.com/zhi520/NC-KGE. ",
    "url": "https://arxiv.org/abs/2310.10138",
    "authors": [
      "Zhiguang Fan",
      "Yuedong Yang",
      "Mingyuan Xu",
      "Hongming Chen"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Computation and Language (cs.CL)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2310.10166",
    "title": "The Road to On-board Change Detection: A Lightweight Patch-Level Change  Detection Network via Exploring the Potential of Pruning and Pooling",
    "abstract": "Existing satellite remote sensing change detection (CD) methods often crop original large-scale bi-temporal image pairs into small patch pairs and then use pixel-level CD methods to fairly process all the patch pairs. However, due to the sparsity of change in large-scale satellite remote sensing images, existing pixel-level CD methods suffer from a waste of computational cost and memory resources on lots of unchanged areas, which reduces the processing efficiency of on-board platform with extremely limited computation and memory resources. To address this issue, we propose a lightweight patch-level CD network (LPCDNet) to rapidly remove lots of unchanged patch pairs in large-scale bi-temporal image pairs. This is helpful to accelerate the subsequent pixel-level CD processing stage and reduce its memory costs. In our LPCDNet, a sensitivity-guided channel pruning method is proposed to remove unimportant channels and construct the lightweight backbone network on basis of ResNet18 network. Then, the multi-layer feature compression (MLFC) module is designed to compress and fuse the multi-level feature information of bi-temporal image patch. The output of MLFC module is fed into the fully-connected decision network to generate the predicted binary label. Finally, a weighted cross-entropy loss is utilized in the training process of network to tackle the change/unchange class imbalance problem. Experiments on two CD datasets demonstrate that our LPCDNet achieves more than 1000 frames per second on an edge computation platform, i.e., NVIDIA Jetson AGX Orin, which is more than 3 times that of the existing methods without noticeable CD performance loss. In addition, our method reduces more than 60% memory costs of the subsequent pixel-level CD processing stage. ",
    "url": "https://arxiv.org/abs/2310.10166",
    "authors": [
      "Lihui Xue",
      "Zhihao Wang",
      "Xueqian Wang",
      "Gang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10177",
    "title": "Hypergraph Echo State Network",
    "abstract": "A hypergraph as a generalization of graphs records higher-order interactions among nodes, yields a more flexible network model, and allows non-linear features for a group of nodes. In this article, we propose a hypergraph echo state network (HypergraphESN) as a generalization of graph echo state network (GraphESN) designed for efficient processing of hypergraph-structured data, derive convergence conditions for the algorithm, and discuss its versatility in comparison to GraphESN. The numerical experiments on the binary classification tasks demonstrate that HypergraphESN exhibits comparable or superior accuracy performance to GraphESN for hypergraph-structured data, and accuracy increases if more higher-order interactions in a network are identified. ",
    "url": "https://arxiv.org/abs/2310.10177",
    "authors": [
      "Justin Lien"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10211",
    "title": "GEVO-ML: Optimizing Machine Learning Code with Evolutionary Computation",
    "abstract": "Parallel accelerators, such as GPUs, are key enablers for large-scale Machine Learning (ML) applications. However, ML model developers often lack detailed knowledge of the underlying system architectures, while system programmers usually do not have a high-level understanding of the ML model that runs on the specific system. To mitigate this gap between two relevant aspects of domain knowledge, this paper proposes GEVO-ML, a tool for automatically discovering optimization opportunities and tuning the performance of ML kernels, where the model and training/prediction processes are uniformly represented in a single intermediate language, the Multiple-Layer Intermediate Representation (MLIR). GEVO-ML uses multi-objective evolutionary search to find edits (mutations) to MLIR code that ultimately runs on GPUs, improving performance on desired criteria while retaining required functionality. We demonstrate GEVO-ML on two different ML workloads for both model training and prediction. GEVO-ML finds significant Pareto improvements for these models, achieving 90.43% performance improvement when model accuracy is relaxed by 2%, from 91.2% to 89.3%. For the training workloads, GEVO-ML finds a 4.88% improvement in model accuracy, from 91% to 96%, without sacrificing training or testing speed. Our analysis of key GEVO-ML mutations reveals diverse code modifications, while might be foreign to human developers, achieving similar effects with how human developers improve model design, for example, by changing learning rates or pruning non-essential layer parameters. ",
    "url": "https://arxiv.org/abs/2310.10211",
    "authors": [
      "Jhe-Yu Liou",
      "Stephanie Forrest",
      "Carole-Jean Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10226",
    "title": "Repetition In Repetition Out: Towards Understanding Neural Text  Degeneration from the Data Perspective",
    "abstract": "There are a number of diverging hypotheses about the neural text degeneration problem, i.e., generating repetitive and dull loops, which makes this problem both interesting and confusing. In this work, we aim to advance our understanding by presenting a straightforward and fundamental explanation from the data perspective. Our preliminary investigation reveals a strong correlation between the degeneration issue and the presence of repetitions in training data. Subsequent experiments also demonstrate that by selectively dropping out the attention to repetitive words in training data, degeneration can be significantly minimized. Furthermore, our empirical analysis illustrates that prior works addressing the degeneration issue from various standpoints, such as the high-inflow words, the likelihood objective, and the self-reinforcement phenomenon, can be interpreted by one simple explanation. That is, penalizing the repetitions in training data is a common and fundamental factor for their effectiveness. Moreover, our experiments reveal that penalizing the repetitions in training data remains critical even when considering larger model sizes and instruction tuning. ",
    "url": "https://arxiv.org/abs/2310.10226",
    "authors": [
      "Huayang Li",
      "Tian Lan",
      "Zihao Fu",
      "Deng Cai",
      "Lemao Liu",
      "Nigel Collier",
      "Taro Watanabe",
      "Yixuan Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.10237",
    "title": "SGOOD: Substructure-enhanced Graph-Level Out-of-Distribution Detection",
    "abstract": "Graph-level representation learning is important in a wide range of applications. However, existing graph-level models are generally built on i.i.d. assumption for both training and testing graphs, which is not realistic in an open world, where models can encounter out-of-distribution (OOD) testing graphs that are from different distributions unknown during training. A trustworthy model should not only produce accurate predictions for in-distribution (ID) data, but also detect OOD graphs to avoid unreliable prediction. In this paper, we present SGOOD, a novel graph-level OOD detection framework. We find that substructure differences commonly exist between ID and OOD graphs. Hence, SGOOD explicitly utilizes substructures to learn powerful representations to achieve superior performance. Specifically, we build a super graph of substructures for every graph, and design a two-level graph encoding pipeline that works on both original graphs and super graphs to obtain substructure-enhanced graph representations. To further distinguish ID and OOD graphs, we develop three graph augmentation techniques that preserve substructures and increase expressiveness. Extensive experiments against 10 competitors on numerous graph datasets demonstrate the superiority of SGOOD, often surpassing existing methods by a significant margin. The code is available at https://anonymous.4open.science/r/SGOOD-0958. ",
    "url": "https://arxiv.org/abs/2310.10237",
    "authors": [
      "Zhihao Ding",
      "Jieming Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.10245",
    "title": "Mask wearing object detection algorithm based on improved YOLOv5",
    "abstract": "Wearing a mask is one of the important measures to prevent infectious diseases. However, it is difficult to detect people's mask-wearing situation in public places with high traffic flow. To address the above problem, this paper proposes a mask-wearing face detection model based on YOLOv5l. Firstly, Multi-Head Attentional Self-Convolution not only improves the convergence speed of the model but also enhances the accuracy of the model detection. Secondly, the introduction of Swin Transformer Block is able to extract more useful feature information, enhance the detection ability of small targets, and improve the overall accuracy of the model. Our designed I-CBAM module can improve target detection accuracy. In addition, using enhanced feature fusion enables the model to better adapt to object detection tasks of different scales. In the experimentation on the MASK dataset, the results show that the model proposed in this paper achieved a 1.1% improvement in mAP(0.5) and a 1.3% improvement in mAP(0.5:0.95) compared to the YOLOv5l model. Our proposed method significantly enhances the detection capability of mask-wearing. ",
    "url": "https://arxiv.org/abs/2310.10245",
    "authors": [
      "Peng Wen",
      "Junhu Zhang",
      "Haitao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.10259",
    "title": "Leveraging heterogeneous spillover effects in maximizing contextual  bandit rewards",
    "abstract": "Recommender systems relying on contextual multi-armed bandits continuously improve relevant item recommendations by taking into account the contextual information. The objective of these bandit algorithms is to learn the best arm (i.e., best item to recommend) for each user and thus maximize the cumulative rewards from user engagement with the recommendations. However, current approaches ignore potential spillover between interacting users, where the action of one user can impact the actions and rewards of other users. Moreover, spillover may vary for different people based on their preferences and the closeness of ties to other users. This leads to heterogeneity in the spillover effects, i.e., the extent to which the action of one user can impact the action of another. Here, we propose a framework that allows contextual multi-armed bandits to account for such heterogeneous spillovers when choosing the best arm for each user. By experimenting on several real-world datasets using prominent linear and non-linear contextual bandit algorithms, we observe that our proposed method leads to significantly higher rewards than existing solutions that ignore spillover. ",
    "url": "https://arxiv.org/abs/2310.10259",
    "authors": [
      "Ahmed Sayeed Faruk",
      "Elena Zheleva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.10260",
    "title": "Prediction of Arabic Legal Rulings using Large Language Models",
    "abstract": "In the intricate field of legal studies, the analysis of court decisions is a cornerstone for the effective functioning of the judicial system. The ability to predict court outcomes helps judges during the decision-making process and equips lawyers with invaluable insights, enhancing their strategic approaches to cases. Despite its significance, the domain of Arabic court analysis remains under-explored. This paper pioneers a comprehensive predictive analysis of Arabic court decisions on a dataset of 10,813 commercial court real cases, leveraging the advanced capabilities of the current state-of-the-art large language models. Through a systematic exploration, we evaluate three prevalent foundational models (LLaMA-7b, JAIS-13b, and GPT3.5-turbo) and three training paradigms: zero-shot, one-shot, and tailored fine-tuning. Besides, we assess the benefit of summarizing and/or translating the original Arabic input texts. This leads to a spectrum of 14 model variants, for which we offer a granular performance assessment with a series of different metrics (human assessment, GPT evaluation, ROUGE, and BLEU scores). We show that all variants of LLaMA models yield limited performance, whereas GPT-3.5-based models outperform all other models by a wide margin, surpassing the average score of the dedicated Arabic-centric JAIS model by 50%. Furthermore, we show that all scores except human evaluation are inconsistent and unreliable for assessing the performance of large language models on court decision predictions. This study paves the way for future research, bridging the gap between computational linguistics and Arabic legal analytics. ",
    "url": "https://arxiv.org/abs/2310.10260",
    "authors": [
      "Adel Ammar",
      "Anis Koubaa",
      "Bilel Benjdira",
      "Omar Najar",
      "Serry Sibaee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10264",
    "title": "Towards Open-World Co-Salient Object Detection with Generative  Uncertainty-aware Group Selective Exchange-Masking",
    "abstract": "The traditional definition of co-salient object detection (CoSOD) task is to segment the common salient objects in a group of relevant images. This definition is based on an assumption of group consensus consistency that is not always reasonable in the open-world setting, which results in robustness issue in the model when dealing with irrelevant images in the inputting image group under the open-word scenarios. To tackle this problem, we introduce a group selective exchange-masking (GSEM) approach for enhancing the robustness of the CoSOD model. GSEM takes two groups of images as input, each containing different types of salient objects. Based on the mixed metric we designed, GSEM selects a subset of images from each group using a novel learning-based strategy, then the selected images are exchanged. To simultaneously consider the uncertainty introduced by irrelevant images and the consensus features of the remaining relevant images in the group, we designed a latent variable generator branch and CoSOD transformer branch. The former is composed of a vector quantised-variational autoencoder to generate stochastic global variables that model uncertainty. The latter is designed to capture correlation-based local features that include group consensus. Finally, the outputs of the two branches are merged and passed to a transformer-based decoder to generate robust predictions. Taking into account that there are currently no benchmark datasets specifically designed for open-world scenarios, we constructed three open-world benchmark datasets, namely OWCoSal, OWCoSOD, and OWCoCA, based on existing datasets. By breaking the group-consistency assumption, these datasets provide effective simulations of real-world scenarios and can better evaluate the robustness and practicality of models. ",
    "url": "https://arxiv.org/abs/2310.10264",
    "authors": [
      "Yang Wu",
      "Shenglong Hu",
      "Huihui Song",
      "Kaihua Zhang",
      "Bo Liu",
      "Dong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.10275",
    "title": "A ML-LLM pairing for better code comment classification",
    "abstract": "The \"Information Retrieval in Software Engineering (IRSE)\" at FIRE 2023 shared task introduces code comment classification, a challenging task that pairs a code snippet with a comment that should be evaluated as either useful or not useful to the understanding of the relevant code. We answer the code comment classification shared task challenge by providing a two-fold evaluation: from an algorithmic perspective, we compare the performance of classical machine learning systems and complement our evaluations from a data-driven perspective by generating additional data with the help of large language model (LLM) prompting to measure the potential increase in performance. Our best model, which took second place in the shared task, is a Neural Network with a Macro-F1 score of 88.401% on the provided seed data and a 1.5% overall increase in performance on the data generated by the LLM. ",
    "url": "https://arxiv.org/abs/2310.10275",
    "authors": [
      "Hanna Abi Akl"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.10299",
    "title": "Forking Uncertainties: Reliable Prediction and Model Predictive Control  with Sequence Models via Conformal Risk Control",
    "abstract": "In many real-world problems, predictions are leveraged to monitor and control cyber-physical systems, demanding guarantees on the satisfaction of reliability and safety requirements. However, predictions are inherently uncertain, and managing prediction uncertainty presents significant challenges in environments characterized by complex dynamics and forking trajectories. In this work, we assume access to a pre-designed probabilistic implicit or explicit sequence model, which may have been obtained using model-based or model-free methods. We introduce probabilistic time series-conformal risk prediction (PTS-CRC), a novel post-hoc calibration procedure that operates on the predictions produced by any pre-designed probabilistic forecaster to yield reliable error bars. In contrast to existing art, PTS-CRC produces predictive sets based on an ensemble of multiple prototype trajectories sampled from the sequence model, supporting the efficient representation of forking uncertainties. Furthermore, unlike the state of the art, PTS-CRC can satisfy reliability definitions beyond coverage. This property is leveraged to devise a novel model predictive control (MPC) framework that addresses open-loop and closed-loop control problems under general average constraints on the quality or safety of the control policy. We experimentally validate the performance of PTS-CRC prediction and control by studying a number of use cases in the context of wireless networking. Across all the considered tasks, PTS-CRC predictors are shown to provide more informative predictive sets, as well as safe control policies with larger returns. ",
    "url": "https://arxiv.org/abs/2310.10299",
    "authors": [
      "Matteo Zecchin",
      "Sangwoo Park",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10301",
    "title": "Multi-Body Neural Scene Flow",
    "abstract": "The test-time optimization of scene flow - using a coordinate network as a neural prior - has gained popularity due to its simplicity, lack of dataset bias, and state-of-the-art performance. We observe, however, that although coordinate networks capture general motions by implicitly regularizing the scene flow predictions to be spatially smooth, the neural prior by itself is unable to identify the underlying multi-body rigid motions present in real-world data. To address this, we show that multi-body rigidity can be achieved without the cumbersome and brittle strategy of constraining the $SE(3)$ parameters of each rigid body as done in previous works. This is achieved by regularizing the scene flow optimization to encourage isometry in flow predictions for rigid bodies. This strategy enables multi-body rigidity in scene flow while maintaining a continuous flow field, hence allowing dense long-term scene flow integration across a sequence of point clouds. We conduct extensive experiments on real-world datasets and demonstrate that our approach outperforms the state-of-the-art in 3D scene flow and long-term point-wise 4D trajectory prediction. The code is available at: \\href{https://github.com/kavisha725/MBNSF}{https://github.com/kavisha725/MBNSF}. ",
    "url": "https://arxiv.org/abs/2310.10301",
    "authors": [
      "Kavisha Vidanapathirana",
      "Shin-Fang Chng",
      "Xueqian Li",
      "Simon Lucey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.10307",
    "title": "Learning visual-based deformable object rearrangement with local graph  neural networks",
    "abstract": "Goal-conditioned rearrangement of deformable objects (e.g. straightening a rope and folding a cloth) is one of the most common deformable manipulation tasks, where the robot needs to rearrange a deformable object into a prescribed goal configuration with only visual observations. These tasks are typically confronted with two main challenges: the high dimensionality of deformable configuration space and the underlying complexity, nonlinearity and uncertainty inherent in deformable dynamics. To address these challenges, we propose a novel representation strategy that can efficiently model the deformable object states with a set of keypoints and their interactions. We further propose local-graph neural network (GNN), a light local GNN learning to jointly model the deformable rearrangement dynamics and infer the optimal manipulation actions (e.g. pick and place) by constructing and updating two dynamic graphs. Both simulated and real experiments have been conducted to demonstrate that the proposed dynamic graph representation shows superior expressiveness in modeling deformable rearrangement dynamics. Our method reaches much higher success rates on a variety of deformable rearrangement tasks (96.3% on average) than state-of-the-art method in simulation experiments. Besides, our method is much more lighter and has a 60% shorter inference time than state-of-the-art methods. We also demonstrate that our method performs well in the multi-task learning scenario and can be transferred to real-world applications with an average success rate of 95% by solely fine tuning a keypoint detector. ",
    "url": "https://arxiv.org/abs/2310.10307",
    "authors": [
      "Yuhong Deng",
      "Xueqian Wang",
      "Lipeng chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.10308",
    "title": "Time integration schemes based on neural networks for solving partial  differential equations on coarse grids",
    "abstract": "The accuracy of solving partial differential equations (PDEs) on coarse grids is greatly affected by the choice of discretization schemes. In this work, we propose to learn time integration schemes based on neural networks which satisfy three distinct sets of mathematical constraints, i.e., unconstrained, semi-constrained with the root condition, and fully-constrained with both root and consistency conditions. We focus on the learning of 3-step linear multistep methods, which we subsequently applied to solve three model PDEs, i.e., the one-dimensional heat equation, the one-dimensional wave equation, and the one-dimensional Burgers' equation. The results show that the prediction error of the learned fully-constrained scheme is close to that of the Runge-Kutta method and Adams-Bashforth method. Compared to the traditional methods, the learned unconstrained and semi-constrained schemes significantly reduce the prediction error on coarse grids. On a grid that is 4 times coarser than the reference grid, the mean square error shows a reduction of up to an order of magnitude for some of the heat equation cases, and a substantial improvement in phase prediction for the wave equation. On a 32 times coarser grid, the mean square error for the Burgers' equation can be reduced by up to 35% to 40%. ",
    "url": "https://arxiv.org/abs/2310.10308",
    "authors": [
      "Xinxin Yan",
      "Zhideng Zhou",
      "Xiaohan Cheng",
      "Xiaolei Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10316",
    "title": "Spectral representation of two-sided signals from $\\ell_\\infty$ and  applications to signal processing",
    "abstract": "The paper presents a spectral representation for general type two-sided discrete time signals from $\\ell_\\infty$, i.e for all bounded discrete time signals, including signals that do not vanish at $\\pm\\infty$. This representation allows to extend on the general type signals from $\\ell_\\infty$ the notions of transfer functions, spectrum gaps, and filters, and to obtain some frequency conditions of predictability and data recoverability. ",
    "url": "https://arxiv.org/abs/2310.10316",
    "authors": [
      "Nikolai Dokuchaev"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Functional Analysis (math.FA)"
    ]
  },
  {
    "id": "arXiv:2310.10320",
    "title": "Adaptive Particle Swarm Optimization for through-foliage target  detection with drone swarms",
    "abstract": "This work contributes to efforts on autonomously detecting a vegetation-occluded target by airborne observers. It investigates and enhances previous work on a Particle Swarm Optimization (PSO) strategy for Airborne Optical Sectioning (AOS) drone swarms. First, it identifies two issues with that method and proposes to resolve them by a leader stabilization for its scattering and projection-based line positions for its default scanning pattern. Second, it connects this method to other PSO variants and presents a new adaptive PSO strategy for AOS drone swarms that draws on the ideas of Adaptive PSO (APSO). ",
    "url": "https://arxiv.org/abs/2310.10320",
    "authors": [
      "Julia P\u00f6schl"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.10321",
    "title": "Hamming Encoder: Mining Discriminative k-mers for Discrete Sequence  Classification",
    "abstract": "Sequence classification has numerous applications in various fields. Despite extensive studies in the last decades, many challenges still exist, particularly in pattern-based methods. Existing pattern-based methods measure the discriminative power of each feature individually during the mining process, leading to the result of missing some combinations of features with discriminative power. Furthermore, it is difficult to ensure the overall discriminative performance after converting sequences into feature vectors. To address these challenges, we propose a novel approach called Hamming Encoder, which utilizes a binarized 1D-convolutional neural network (1DCNN) architecture to mine discriminative k-mer sets. In particular, we adopt a Hamming distance-based similarity measure to ensure consistency in the feature mining and classification procedure. Our method involves training an interpretable CNN encoder for sequential data and performing a gradient-based search for discriminative k-mer combinations. Experiments show that the Hamming Encoder method proposed in this paper outperforms existing state-of-the-art methods in terms of classification accuracy. ",
    "url": "https://arxiv.org/abs/2310.10321",
    "authors": [
      "Junjie Dong",
      "Mudi Jiang",
      "Lianyu Hu",
      "Zengyou He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10338",
    "title": "Scene Graph Conditioning in Latent Diffusion",
    "abstract": "Diffusion models excel in image generation but lack detailed semantic control using text prompts. Additional techniques have been developed to address this limitation. However, conditioning diffusion models solely on text-based descriptions is challenging due to ambiguity and lack of structure. In contrast, scene graphs offer a more precise representation of image content, making them superior for fine-grained control and accurate synthesis in image generation models. The amount of image and scene-graph data is sparse, which makes fine-tuning large diffusion models challenging. We propose multiple approaches to tackle this problem using ControlNet and Gated Self-Attention. We were able to show that using out proposed methods it is possible to generate images from scene graphs with much higher quality, outperforming previous methods. Our source code is publicly available on https://github.com/FrankFundel/SGCond ",
    "url": "https://arxiv.org/abs/2310.10338",
    "authors": [
      "Frank Fundel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.10353",
    "title": "Multimodal Object Query Initialization for 3D Object Detection",
    "abstract": "3D object detection models that exploit both LiDAR and camera sensor features are top performers in large-scale autonomous driving benchmarks. A transformer is a popular network architecture used for this task, in which so-called object queries act as candidate objects. Initializing these object queries based on current sensor inputs is a common practice. For this, existing methods strongly rely on LiDAR data however, and do not fully exploit image features. Besides, they introduce significant latency. To overcome these limitations we propose EfficientQ3M, an efficient, modular, and multimodal solution for object query initialization for transformer-based 3D object detection models. The proposed initialization method is combined with a \"modality-balanced\" transformer decoder where the queries can access all sensor modalities throughout the decoder. In experiments, we outperform the state of the art in transformer-based LiDAR object detection on the competitive nuScenes benchmark and showcase the benefits of input-dependent multimodal query initialization, while being more efficient than the available alternatives for LiDAR-camera initialization. The proposed method can be applied with any combination of sensor modalities as input, demonstrating its modularity. ",
    "url": "https://arxiv.org/abs/2310.10353",
    "authors": [
      "Mathijs R. van Geerenstein",
      "Felicia Ruppel",
      "Klaus Dietmayer",
      "Dariu M. Gavrila"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10362",
    "title": "Prompt Tuning for Multi-View Graph Contrastive Learning",
    "abstract": "In recent years, \"pre-training and fine-tuning\" has emerged as a promising approach in addressing the issues of label dependency and poor generalization performance in traditional GNNs. To reduce labeling requirement, the \"pre-train, fine-tune\" and \"pre-train, prompt\" paradigms have become increasingly common. In particular, prompt tuning is a popular alternative to \"pre-training and fine-tuning\" in natural language processing, which is designed to narrow the gap between pre-training and downstream objectives. However, existing study of prompting on graphs is still limited, lacking a framework that can accommodate commonly used graph pre-training methods and downstream tasks. In this paper, we propose a multi-view graph contrastive learning method as pretext and design a prompting tuning for it. Specifically, we first reformulate graph pre-training and downstream tasks into a common format. Second, we construct multi-view contrasts to capture relevant information of graphs by GNN. Third, we design a prompting tuning method for our multi-view graph contrastive learning method to bridge the gap between pretexts and downsteam tasks. Finally, we conduct extensive experiments on benchmark datasets to evaluate and analyze our proposed method. ",
    "url": "https://arxiv.org/abs/2310.10362",
    "authors": [
      "Chenghua Gong",
      "Xiang Li",
      "Jianxiang Yu",
      "Cheng Yao",
      "Jiaqi Tan",
      "Chengcheng Yu",
      "Dawei Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.10374",
    "title": "Multi-Factor Spatio-Temporal Prediction based on Graph Decomposition  Learning",
    "abstract": "Spatio-temporal (ST) prediction is an important and widely used technique in data mining and analytics, especially for ST data in urban systems such as transportation data. In practice, the ST data generation is usually influenced by various latent factors tied to natural phenomena or human socioeconomic activities, impacting specific spatial areas selectively. However, existing ST prediction methods usually do not refine the impacts of different factors, but directly model the entangled impacts of multiple factors. This amplifies the modeling complexity of ST data and compromises model interpretability. To this end, we propose a multi-factor ST prediction task that predicts partial ST data evolution under different factors, and combines them for a final prediction. We make two contributions to this task: an effective theoretical solution and a portable instantiation framework. Specifically, we first propose a theoretical solution called decomposed prediction strategy and prove its effectiveness from the perspective of information entropy theory. On top of that, we instantiate a novel model-agnostic framework, named spatio-temporal graph decomposition learning (STGDL), for multi-factor ST prediction. The framework consists of two main components: an automatic graph decomposition module that decomposes the original graph structure inherent in ST data into subgraphs corresponding to different factors, and a decomposed learning network that learns the partial ST data on each subgraph separately and integrates them for the final prediction. We conduct extensive experiments on four real-world ST datasets of two types of graphs, i.e., grid graph and network graph. Results show that our framework significantly reduces prediction errors of various ST models by 9.41% on average (35.36% at most). Furthermore, a case study reveals the interpretability potential of our framework. ",
    "url": "https://arxiv.org/abs/2310.10374",
    "authors": [
      "Jiahao Ji",
      "Jingyuan Wang",
      "Yu Mou",
      "Cheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10380",
    "title": "Contextual Data Augmentation for Task-Oriented Dialog Systems",
    "abstract": "Collection of annotated dialogs for training task-oriented dialog systems have been one of the key bottlenecks in improving current models. While dialog response generation has been widely studied on the agent side, it is not evident if similar generative models can be used to generate a large variety of, and often unexpected, user inputs that real dialog systems encounter in practice. Existing data augmentation techniques such as paraphrase generation do not take the dialog context into consideration. In this paper, we develop a novel dialog augmentation model that generates a user turn, conditioning on full dialog context. Additionally, with a new prompt design for language model, and output re-ranking, the dialogs generated from our model can be directly used to train downstream dialog systems. On common benchmark datasets MultiWoZ and SGD, we show that our dialog augmentation model generates high quality dialogs and improves dialog success rate by as much as $8\\%$ over baseline. ",
    "url": "https://arxiv.org/abs/2310.10380",
    "authors": [
      "Dustin Axman",
      "Avik Ray",
      "Shubham Garg",
      "Jing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.10383",
    "title": "Privacy in Large Language Models: Attacks, Defenses and Future  Directions",
    "abstract": "The advancement of large language models (LLMs) has significantly enhanced the ability to effectively tackle various downstream NLP tasks and unify these tasks into generative pipelines. On the one hand, powerful language models, trained on massive textual data, have brought unparalleled accessibility and usability for both models and users. On the other hand, unrestricted access to these models can also introduce potential malicious and unintentional privacy risks. Despite ongoing efforts to address the safety and privacy concerns associated with LLMs, the problem remains unresolved. In this paper, we provide a comprehensive analysis of the current privacy attacks targeting LLMs and categorize them according to the adversary's assumed capabilities to shed light on the potential vulnerabilities present in LLMs. Then, we present a detailed overview of prominent defense strategies that have been developed to counter these privacy attacks. Beyond existing works, we identify upcoming privacy concerns as LLMs evolve. Lastly, we point out several potential avenues for future exploration. ",
    "url": "https://arxiv.org/abs/2310.10383",
    "authors": [
      "Haoran Li",
      "Yulin Chen",
      "Jinglong Luo",
      "Yan Kang",
      "Xiaojin Zhang",
      "Qi Hu",
      "Chunkit Chan",
      "Yangqiu Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.10385",
    "title": "Towards a Better Understanding of Variations in Zero-Shot Neural Machine  Translation Performance",
    "abstract": "Multilingual Neural Machine Translation (MNMT) facilitates knowledge sharing but often suffers from poor zero-shot (ZS) translation qualities. While prior work has explored the causes of overall low ZS performance, our work introduces a fresh perspective: the presence of high variations in ZS performance. This suggests that MNMT does not uniformly exhibit poor ZS capability; instead, certain translation directions yield reasonable results. Through systematic experimentation involving 1,560 language directions spanning 40 languages, we identify three key factors contributing to high variations in ZS NMT performance: 1) target side translation capability 2) vocabulary overlap 3) linguistic properties. Our findings highlight that the target side translation quality is the most influential factor, with vocabulary overlap consistently impacting ZS performance. Additionally, linguistic properties, such as language family and writing system, play a role, particularly with smaller models. Furthermore, we suggest that the off-target issue is a symptom of inadequate ZS performance, emphasizing that zero-shot translation challenges extend beyond addressing the off-target problem. We release the data and models serving as a benchmark to study zero-shot for future research at https://github.com/Smu-Tan/ZS-NMT-Variations ",
    "url": "https://arxiv.org/abs/2310.10385",
    "authors": [
      "Shaomu Tan",
      "Christof Monz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10391",
    "title": "Towards Open World Active Learning for 3D Object Detection",
    "abstract": "Significant strides have been made in closed world 3D object detection, testing systems in environments with known classes. However, the challenge arises in open world scenarios where new object classes appear. Existing efforts sequentially learn novel classes from streams of labeled data at a significant annotation cost, impeding efficient deployment to the wild. To seek effective solutions, we investigate a more practical yet challenging research task: Open World Active Learning for 3D Object Detection (OWAL-3D), aiming at selecting a small number of 3D boxes to annotate while maximizing detection performance on both known and unknown classes. The core difficulty centers on striking a balance between mining more unknown instances and minimizing the labeling expenses of point clouds. Empirically, our study finds the harmonious and inverse relationship between box quantities and their confidences can help alleviate the dilemma, avoiding the repeated selection of common known instances and focusing on uncertain objects that are potentially unknown. We unify both relational constraints into a simple and effective AL strategy namely OpenCRB, which guides to acquisition of informative point clouds with the least amount of boxes to label. Furthermore, we develop a comprehensive codebase for easy reproducing and future research, supporting 15 baseline methods (i.e., active learning, out-of-distribution detection and open world detection), 2 types of modern 3D detectors (i.e., one-stage SECOND and two-stage PV-RCNN) and 3 benchmark 3D datasets (i.e., KITTI, nuScenes and Waymo). Extensive experiments evidence that the proposed Open-CRB demonstrates superiority and flexibility in recognizing both novel and shared categories with very limited labeling costs, compared to state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2310.10391",
    "authors": [
      "Zhuoxiao Chen",
      "Yadan Luo",
      "Zixin Wang",
      "Zijian Wang",
      "Xin Yu",
      "Zi Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10404",
    "title": "Weakly Supervised Fine-grained Scene Graph Generation via Large Language  Model",
    "abstract": "Weakly-Supervised Scene Graph Generation (WSSGG) research has recently emerged as an alternative to the fully-supervised approach that heavily relies on costly annotations. In this regard, studies on WSSGG have utilized image captions to obtain unlocalized triplets while primarily focusing on grounding the unlocalized triplets over image regions. However, they have overlooked the two issues involved in the triplet formation process from the captions: 1) Semantic over-simplification issue arises when extracting triplets from captions, where fine-grained predicates in captions are undesirably converted into coarse-grained predicates, resulting in a long-tailed predicate distribution, and 2) Low-density scene graph issue arises when aligning the triplets in the caption with entity/predicate classes of interest, where many triplets are discarded and not used in training, leading to insufficient supervision. To tackle the two issues, we propose a new approach, i.e., Large Language Model for weakly-supervised SGG (LLM4SGG), where we mitigate the two issues by leveraging the LLM's in-depth understanding of language and reasoning ability during the extraction of triplets from captions and alignment of entity/predicate classes with target data. To further engage the LLM in these processes, we adopt the idea of Chain-of-Thought and the in-context few-shot learning strategy. To validate the effectiveness of LLM4SGG, we conduct extensive experiments on Visual Genome and GQA datasets, showing significant improvements in both Recall@K and mean Recall@K compared to the state-of-the-art WSSGG methods. A further appeal is that LLM4SGG is data-efficient, enabling effective model training with a small amount of training images. ",
    "url": "https://arxiv.org/abs/2310.10404",
    "authors": [
      "Kibum Kim",
      "Kanghoon Yoon",
      "Jaeyeong Jeon",
      "Yeonjun In",
      "Jinyoung Moon",
      "Donghyun Kim",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.10423",
    "title": "YOLOv7 for Mosquito Breeding Grounds Detection and Tracking",
    "abstract": "With the looming threat of climate change, neglected tropical diseases such as dengue, zika, and chikungunya have the potential to become an even greater global concern. Remote sensing technologies can aid in controlling the spread of Aedes Aegypti, the transmission vector of such diseases, by automating the detection and mapping of mosquito breeding sites, such that local entities can properly intervene. In this work, we leverage YOLOv7, a state-of-the-art and computationally efficient detection approach, to localize and track mosquito foci in videos captured by unmanned aerial vehicles. We experiment on a dataset released to the public as part of the ICIP 2023 grand challenge entitled Automatic Detection of Mosquito Breeding Grounds. We show that YOLOv7 can be directly applied to detect larger foci categories such as pools, tires, and water tanks and that a cheap and straightforward aggregation of frame-by-frame detection can incorporate time consistency into the tracking process. ",
    "url": "https://arxiv.org/abs/2310.10423",
    "authors": [
      "Camila Laranjeira",
      "Daniel Andrade",
      "Jefersson A. dos Santos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.10424",
    "title": "A Novel Benchmarking Paradigm and a Scale- and Motion-Aware Model for  Egocentric Pedestrian Trajectory Prediction",
    "abstract": "Predicting pedestrian behavior is one of the main challenges for intelligent driving systems. In this paper, we present a new paradigm for evaluating egocentric pedestrian trajectory prediction algorithms. Based on various contextual information, we extract driving scenarios for a meaningful and systematic approach to identifying challenges for prediction models. In this regard, we also propose a new metric for more effective ranking within the scenario-based evaluation. We conduct extensive empirical studies of existing models on these scenarios to expose shortcomings and strengths of different approaches. The scenario-based analysis highlights the importance of using multimodal sources of information and challenges caused by inadequate modeling of ego-motion and scale of pedestrians. To this end, we propose a novel egocentric trajectory prediction model that benefits from multimodal sources of data fused in an effective and efficient step-wise hierarchical fashion and two auxiliary tasks designed to learn more robust representation of scene dynamics. We show that our approach achieves significant improvement by up to 40% in challenging scenarios compared to the past arts via empirical evaluation on common benchmark datasets. ",
    "url": "https://arxiv.org/abs/2310.10424",
    "authors": [
      "Amir Rasouli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.10427",
    "title": "DANAA: Towards transferable attacks with double adversarial neuron  attribution",
    "abstract": "While deep neural networks have excellent results in many fields, they are susceptible to interference from attacking samples resulting in erroneous judgments. Feature-level attacks are one of the effective attack types, which targets the learnt features in the hidden layers to improve its transferability across different models. Yet it is observed that the transferability has been largely impacted by the neuron importance estimation results. In this paper, a double adversarial neuron attribution attack method, termed `DANAA', is proposed to obtain more accurate feature importance estimation. In our method, the model outputs are attributed to the middle layer based on an adversarial non-linear path. The goal is to measure the weight of individual neurons and retain the features that are more important towards transferability. We have conducted extensive experiments on the benchmark datasets to demonstrate the state-of-the-art performance of our method. Our code is available at: https://github.com/Davidjinzb/DANAA ",
    "url": "https://arxiv.org/abs/2310.10427",
    "authors": [
      "Zhibo Jin",
      "Zhiyu Zhu",
      "Xinyi Wang",
      "Jiayu Zhang",
      "Jun Shen",
      "Huaming Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.10429",
    "title": "Exploiting User Comments for Early Detection of Fake News Prior to  Users' Commenting",
    "abstract": "Both accuracy and timeliness are key factors in detecting fake news on social media. However, most existing methods encounter an accuracy-timeliness dilemma: Content-only methods guarantee timeliness but perform moderately because of limited available information, while social context-based ones generally perform better but inevitably lead to latency because of social context accumulation needs. To break such a dilemma, a feasible but not well-studied solution is to leverage social contexts (e.g., comments) from historical news for training a detection model and apply it to newly emerging news without social contexts. This requires the model to (1) sufficiently learn helpful knowledge from social contexts, and (2) be well compatible with situations that social contexts are available or not. To achieve this goal, we propose to absorb and parameterize useful knowledge from comments in historical news and then inject it into a content-only detection model. Specifically, we design the Comments Assisted Fake News Detection method (CAS-FEND), which transfers useful knowledge from a comments-aware teacher model to a content-only student model during training. The student model is further used to detect newly emerging fake news. Experiments show that the CAS-FEND student model outperforms all content-only methods and even those with 1/4 comments as inputs, demonstrating its superiority for early detection. ",
    "url": "https://arxiv.org/abs/2310.10429",
    "authors": [
      "Qiong Nan",
      "Qiang Sheng",
      "Juan Cao",
      "Yongchun Zhu",
      "Danding Wang",
      "Guang Yang",
      "Jintao Li",
      "Kai Shu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.10431",
    "title": "Longitudinal Self-supervised Learning Using Neural Ordinary Differential  Equation",
    "abstract": "Longitudinal analysis in medical imaging is crucial to investigate the progressive changes in anatomical structures or disease progression over time. In recent years, a novel class of algorithms has emerged with the goal of learning disease progression in a self-supervised manner, using either pairs of consecutive images or time series of images. By capturing temporal patterns without external labels or supervision, longitudinal self-supervised learning (LSSL) has become a promising avenue. To better understand this core method, we explore in this paper the LSSL algorithm under different scenarios. The original LSSL is embedded in an auto-encoder (AE) structure. However, conventional self-supervised strategies are usually implemented in a Siamese-like manner. Therefore, (as a first novelty) in this study, we explore the use of Siamese-like LSSL. Another new core framework named neural ordinary differential equation (NODE). NODE is a neural network architecture that learns the dynamics of ordinary differential equations (ODE) through the use of neural networks. Many temporal systems can be described by ODE, including modeling disease progression. We believe that there is an interesting connection to make between LSSL and NODE. This paper aims at providing a better understanding of those core algorithms for learning the disease progression with the mentioned change. In our different experiments, we employ a longitudinal dataset, named OPHDIAT, targeting diabetic retinopathy (DR) follow-up. Our results demonstrate the application of LSSL without including a reconstruction term, as well as the potential of incorporating NODE in conjunction with LSSL. ",
    "url": "https://arxiv.org/abs/2310.10431",
    "authors": [
      "Rachid Zeghlache",
      "Pierre-Henri Conze",
      "Mostafa El Habib Daho",
      "Yihao Li",
      "Hugo Le Boit\u00e9",
      "Ramin Tadayoni",
      "Pascal Massin",
      "B\u00e9atrice Cochener",
      "Ikram Brahim",
      "Gwenol\u00e9 Quellec",
      "Mathieu Lamard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.10433",
    "title": "Object Detection in Aerial Images in Scarce Data Regimes",
    "abstract": "Most contributions on Few-Shot Object Detection (FSOD) evaluate their methods on natural images only, yet the transferability of the announced performance is not guaranteed for applications on other kinds of images. We demonstrate this with an in-depth analysis of existing FSOD methods on aerial images and observed a large performance gap compared to natural images. Small objects, more numerous in aerial images, are the cause for the apparent performance gap between natural and aerial images. As a consequence, we improve FSOD performance on small objects with a carefully designed attention mechanism. In addition, we also propose a scale-adaptive box similarity criterion, that improves the training and evaluation of FSOD methods, particularly for small objects. We also contribute to generic FSOD with two distinct approaches based on metric learning and fine-tuning. Impressive results are achieved with the fine-tuning method, which encourages tackling more complex scenarios such as Cross-Domain FSOD. We conduct preliminary experiments in this direction and obtain promising results. Finally, we address the deployment of the detection models inside COSE's systems. Detection must be done in real-time in extremely large images (more than 100 megapixels), with limited computation power. Leveraging existing optimization tools such as TensorRT, we successfully tackle this engineering challenge. ",
    "url": "https://arxiv.org/abs/2310.10433",
    "authors": [
      "Pierre Le Jeune"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10441",
    "title": "Efficiently matching random inhomogeneous graphs via degree profiles",
    "abstract": "In this paper, we study the problem of recovering the latent vertex correspondence between two correlated random graphs with vastly inhomogeneous and unknown edge probabilities between different pairs of vertices. Inspired by and extending the matching algorithm via degree profiles by Ding, Ma, Wu and Xu (2021), we obtain an efficient matching algorithm as long as the minimal average degree is at least $\\Omega(\\log^{2} n)$ and the minimal correlation is at least $1 - O(\\log^{-2} n)$. ",
    "url": "https://arxiv.org/abs/2310.10441",
    "authors": [
      "Jian Ding",
      "Yumou Fei",
      "Yuanzheng Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.10462",
    "title": "Adaptive Neural Ranking Framework: Toward Maximized Business Goal for  Cascade Ranking Systems",
    "abstract": "Cascade ranking is widely used for large-scale top-k selection problems in online advertising and recommendation systems, and learning-to-rank is an important way to optimize the models in cascade ranking systems. Previous works on learning-to-rank usually focus on letting the model learn the complete order or pay more attention to the order of top materials, and adopt the corresponding rank metrics as optimization targets. However, these optimization targets can not adapt to various cascade ranking scenarios with varying data complexities and model capabilities; and the existing metric-driven methods such as the Lambda framework can only optimize a rough upper bound of the metric, potentially resulting in performance misalignment. To address these issues, we first propose a novel perspective on optimizing cascade ranking systems by highlighting the adaptability of optimization targets to data complexities and model capabilities. Concretely, we employ multi-task learning framework to adaptively combine the optimization of relaxed and full targets, which refers to metrics Recall@m@k and OAP respectively. Then we introduce a permutation matrix to represent the rank metrics and employ differentiable sorting techniques to obtain a relaxed permutation matrix with controllable approximate error bound. This enables us to optimize both the relaxed and full targets directly and more appropriately using the proposed surrogate losses within the deep learning framework. We named this method as Adaptive Neural Ranking Framework. We use the NeuralSort method to obtain the relaxed permutation matrix and draw on the uncertainty weight method in multi-task learning to optimize the proposed losses jointly. Experiments on a total of 4 public and industrial benchmarks show the effectiveness and generalization of our method, and online experiment shows that our method has significant application value. ",
    "url": "https://arxiv.org/abs/2310.10462",
    "authors": [
      "Yunli Wang",
      "Zhiqiang Wang",
      "Jian Yang",
      "Shiyang Wen",
      "Dongying Kong",
      "Han Li",
      "Kun Gai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10467",
    "title": "Stance Detection with Collaborative Role-Infused LLM-Based Agents",
    "abstract": "Stance detection automatically detects the stance in a text towards a target, vital for content analysis in web and social media research. Despite their promising capabilities, LLMs encounter challenges when directly applied to stance detection. First, stance detection demands multi-aspect knowledge, from deciphering event-related terminologies to understanding the expression styles in social media platforms. Second, stance detection requires advanced reasoning to infer authors' implicit viewpoints, as stance are often subtly embedded rather than overtly stated in the text. To address these challenges, we design a three-stage framework COLA (short for Collaborative rOle-infused LLM-based Agents) in which LLMs are designated distinct roles, creating a collaborative system where each role contributes uniquely. Initially, in the multidimensional text analysis stage, we configure the LLMs to act as a linguistic expert, a domain specialist, and a social media veteran to get a multifaceted analysis of texts, thus overcoming the first challenge. Next, in the reasoning-enhanced debating stage, for each potential stance, we designate a specific LLM-based agent to advocate for it, guiding the LLM to detect logical connections between text features and stance, tackling the second challenge. Finally, in the stance conclusion stage, a final decision maker agent consolidates prior insights to determine the stance. Our approach avoids extra annotated data and model training and is highly usable. We achieve state-of-the-art performance across multiple datasets. Ablation studies validate the effectiveness of each design role in handling stance detection. Further experiments have demonstrated the explainability and the versatility of our approach. Our approach excels in usability, accuracy, effectiveness, explainability and versatility, highlighting its value. ",
    "url": "https://arxiv.org/abs/2310.10467",
    "authors": [
      "Xiaochong Lan",
      "Chen Gao",
      "Depeng Jin",
      "Yong Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.10482",
    "title": "xCOMET: Transparent Machine Translation Evaluation through Fine-grained  Error Detection",
    "abstract": "Widely used learned metrics for machine translation evaluation, such as COMET and BLEURT, estimate the quality of a translation hypothesis by providing a single sentence-level score. As such, they offer little insight into translation errors (e.g., what are the errors and what is their severity). On the other hand, generative large language models (LLMs) are amplifying the adoption of more granular strategies to evaluation, attempting to detail and categorize translation errors. In this work, we introduce xCOMET, an open-source learned metric designed to bridge the gap between these approaches. xCOMET integrates both sentence-level evaluation and error span detection capabilities, exhibiting state-of-the-art performance across all types of evaluation (sentence-level, system-level, and error span detection). Moreover, it does so while highlighting and categorizing error spans, thus enriching the quality assessment. We also provide a robustness analysis with stress tests, and show that xCOMET is largely capable of identifying localized critical errors and hallucinations. ",
    "url": "https://arxiv.org/abs/2310.10482",
    "authors": [
      "Nuno M. Guerreiro",
      "Ricardo Rei",
      "Daan van Stigt",
      "Luisa Coheur",
      "Pierre Colombo",
      "Andr\u00e9 F.T. Martins"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.10483",
    "title": "Passive Inference Attacks on Split Learning via Adversarial  Regularization",
    "abstract": "Split Learning (SL) has emerged as a practical and efficient alternative to traditional federated learning. While previous attempts to attack SL have often relied on overly strong assumptions or targeted easily exploitable models, we seek to develop more practical attacks. We introduce SDAR, a novel attack framework against SL with an honest-but-curious server. SDAR leverages auxiliary data and adversarial regularization to learn a decodable simulator of the client's private model, which can effectively infer the client's private features under the vanilla SL, and both features and labels under the U-shaped SL. We perform extensive experiments in both configurations to validate the effectiveness of our proposed attacks. Notably, in challenging but practical scenarios where existing passive attacks struggle to reconstruct the client's private data effectively, SDAR consistently achieves attack performance comparable to active attacks. On CIFAR-10, at the deep split level of 7, SDAR achieves private feature reconstruction with less than 0.025 mean squared error in both the vanilla and the U-shaped SL, and attains a label inference accuracy of over 98% in the U-shaped setting, while existing attacks fail to produce non-trivial results. ",
    "url": "https://arxiv.org/abs/2310.10483",
    "authors": [
      "Xiaochen Zhu",
      "Xinjian Luo",
      "Yuncheng Wu",
      "Yangfan Jiang",
      "Xiaokui Xiao",
      "Beng Chin Ooi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10495",
    "title": "Metric Ensembles For Hallucination Detection",
    "abstract": "Abstractive text summarization has garnered increased interest as of late, in part due to the proliferation of large language models (LLMs). One of the most pressing problems related to generation of abstractive summaries is the need to reduce \"hallucinations,\" information that was not included in the document being summarized, and which may be wholly incorrect. Due to this need, a wide array of metrics estimating consistency with the text being summarized have been proposed. We examine in particular a suite of unsupervised metrics for summary consistency, and measure their correlations with each other and with human evaluation scores in the wiki_bio_gpt3_hallucination dataset. We then compare these evaluations to models made from a simple linear ensemble of these metrics. We find that LLM-based methods outperform other unsupervised metrics for hallucination detection. We also find that ensemble methods can improve these scores even further, provided that the metrics in the ensemble have sufficiently similar and uncorrelated error rates. Finally, we present an ensemble method for LLM-based evaluations that we show improves over this previous SOTA. ",
    "url": "https://arxiv.org/abs/2310.10495",
    "authors": [
      "Grant C. Forbes",
      "Parth Katlana",
      "Zeydy Ortiz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.10517",
    "title": "Distribution prediction for image compression: An experimental  re-compressor for JPEG images",
    "abstract": "We propose a new scheme to re-compress JPEG images in a lossless way. Using a JPEG image as an input the algorithm partially decodes the signal to obtain quantized DCT coefficients and then re-compress them in a more effective way. ",
    "url": "https://arxiv.org/abs/2310.10517",
    "authors": [
      "Maxim Koroteev",
      "Yaroslav Borisov",
      "Pavel Frolov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.10547",
    "title": "InfoGCN++: Learning Representation by Predicting the Future for Online  Human Skeleton-based Action Recognition",
    "abstract": "Skeleton-based action recognition has made significant advancements recently, with models like InfoGCN showcasing remarkable accuracy. However, these models exhibit a key limitation: they necessitate complete action observation prior to classification, which constrains their applicability in real-time situations such as surveillance and robotic systems. To overcome this barrier, we introduce InfoGCN++, an innovative extension of InfoGCN, explicitly developed for online skeleton-based action recognition. InfoGCN++ augments the abilities of the original InfoGCN model by allowing real-time categorization of action types, independent of the observation sequence's length. It transcends conventional approaches by learning from current and anticipated future movements, thereby creating a more thorough representation of the entire sequence. Our approach to prediction is managed as an extrapolation issue, grounded on observed actions. To enable this, InfoGCN++ incorporates Neural Ordinary Differential Equations, a concept that lets it effectively model the continuous evolution of hidden states. Following rigorous evaluations on three skeleton-based action recognition benchmarks, InfoGCN++ demonstrates exceptional performance in online action recognition. It consistently equals or exceeds existing techniques, highlighting its significant potential to reshape the landscape of real-time action recognition applications. Consequently, this work represents a major leap forward from InfoGCN, pushing the limits of what's possible in online, skeleton-based action recognition. The code for InfoGCN++ is publicly available at https://github.com/stnoah1/infogcn2 for further exploration and validation. ",
    "url": "https://arxiv.org/abs/2310.10547",
    "authors": [
      "Seunggeun Chi",
      "Hyung-gun Chi",
      "Qixing Huang",
      "Karthik Ramani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.10556",
    "title": "Sample Complexity of Preference-Based Nonparametric Off-Policy  Evaluation with Deep Networks",
    "abstract": "A recently popular approach to solving reinforcement learning is with data from human preferences. In fact, human preference data are now used with classic reinforcement learning algorithms such as actor-critic methods, which involve evaluating an intermediate policy over a reward learned from human preference data with distribution shift, known as off-policy evaluation (OPE). Such algorithm includes (i) learning reward function from human preference dataset, and (ii) learning expected cumulative reward of a target policy. Despite the huge empirical success, existing OPE methods with preference data often lack theoretical understanding and rely heavily on heuristics. In this paper, we study the sample efficiency of OPE with human preference and establish a statistical guarantee for it. Specifically, we approach OPE by learning the value function by fitted-Q-evaluation with a deep neural network. By appropriately selecting the size of a ReLU network, we show that one can leverage any low-dimensional manifold structure in the Markov decision process and obtain a sample-efficient estimator without suffering from the curse of high data ambient dimensionality. Under the assumption of high reward smoothness, our results \\textit{almost align with the classical OPE results with observable reward data}. To the best of our knowledge, this is the first result that establishes a \\textit{provably efficient} guarantee for off-policy evaluation with RLHF. ",
    "url": "https://arxiv.org/abs/2310.10556",
    "authors": [
      "Zihao Li",
      "Xiang Ji",
      "Minshuo Chen",
      "Mengdi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.10575",
    "title": "Matching the Neuronal Representations of V1 is Necessary to Improve  Robustness in CNNs with V1-like Front-ends",
    "abstract": "While some convolutional neural networks (CNNs) have achieved great success in object recognition, they struggle to identify objects in images corrupted with different types of common noise patterns. Recently, it was shown that simulating computations in early visual areas at the front of CNNs leads to improvements in robustness to image corruptions. Here, we further explore this result and show that the neuronal representations that emerge from precisely matching the distribution of RF properties found in primate V1 is key for this improvement in robustness. We built two variants of a model with a front-end modeling the primate primary visual cortex (V1): one sampling RF properties uniformly and the other sampling from empirical biological distributions. The model with the biological sampling has a considerably higher robustness to image corruptions that the uniform variant (relative difference of 8.72%). While similar neuronal sub-populations across the two variants have similar response properties and learn similar downstream weights, the impact on downstream processing is strikingly different. This result sheds light on the origin of the improvements in robustness observed in some biologically-inspired models, pointing to the need of precisely mimicking the neuronal representations found in the primate brain. ",
    "url": "https://arxiv.org/abs/2310.10575",
    "authors": [
      "Ruxandra Barbulescu",
      "Tiago Marques",
      "Arlindo L. Oliveira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2310.10585",
    "title": "Temporally Robust Multi-Agent STL Motion Planning in Continuous Time",
    "abstract": "Signal Temporal Logic (STL) is a formal language over continuous-time signals (such as trajectories of a multi-agent system) that allows for the specification of complex spatial and temporal system requirements (such as staying sufficiently close to each other within certain time intervals). To promote robustness in multi-agent motion planning with such complex requirements, we consider motion planning with the goal of maximizing the temporal robustness of their joint STL specification, i.e. maximizing the permissible time shifts of each agent's trajectory while still satisfying the STL specification. Previous methods presented temporally robust motion planning and control in a discrete-time Mixed Integer Linear Programming (MILP) optimization scheme. In contrast, we parameterize the trajectory by continuous B\\'ezier curves, where the curvature and the time-traversal of the trajectory are parameterized individually. We show an algorithm generating continuous-time temporally robust trajectories and prove soundness of our approach. Moreover, we empirically show that our parametrization realizes this with a considerable speed-up compared to state-of-the-art methods based on constant interval time discretization. ",
    "url": "https://arxiv.org/abs/2310.10585",
    "authors": [
      "Joris Verhagen",
      "Lars Lindemann",
      "Jana Tumova"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.10587",
    "title": "A Tri-Level Optimization Model for Interdependent Infrastructure Network  Resilience Against Compound Hazard Events",
    "abstract": "Resilient operation of interdependent infrastructures against compound hazard events is essential for maintaining societal well-being. To address consequence assessment challenges in this problem space, we propose a novel tri-level optimization model applied to a proof-of-concept case study with fuel distribution and transportation networks -- encompassing one realistic network; one fictitious, yet realistic network; as well as networks drawn from three synthetic distributions. Mathematically, our approach takes the form of a defender-attacker-defender (DAD) model -- a multi-agent tri-level optimization, comprised of a defender, attacker, and an operator acting in sequence. Here, our notional operator may choose proxy actions to operate an interdependent system comprised of fuel terminals and gas stations (functioning as supplies) and a transportation network with traffic flow (functioning as demand) to minimize unmet demand at gas stations. A notional attacker aims to hypothetically disrupt normal operations by reducing supply at the supply terminals, and the notional defender aims to identify best proxy defense policy options which include hardening supply terminals or allowing alternative distribution methods such as trucking reserve supplies. We solve our DAD formulation at a metropolitan scale and present practical defense policy insights against hypothetical compound hazards. We demonstrate the generalizability of our framework by presenting results for a realistic network; a fictitious, yet realistic network; as well as for three networks drawn from synthetic distributions. Additionally, we demonstrate the scalability of the framework by investigating runtime performance as a function of the network size. Steps for future research are also discussed. ",
    "url": "https://arxiv.org/abs/2310.10587",
    "authors": [
      "Matthew R. Oster",
      "Ilya Amburg",
      "Samrat Chatterjee",
      "Daniel A. Eisenberg",
      "Dennis G. Thomas",
      "Feng Pan",
      "Auroop R. Ganguly"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.10603",
    "title": "Exploring the Power of Graph Neural Networks in Solving Linear  Optimization Problems",
    "abstract": "Recently, machine learning, particularly message-passing graph neural networks (MPNNs), has gained traction in enhancing exact optimization algorithms. For example, MPNNs speed up solving mixed-integer optimization problems by imitating computational intensive heuristics like strong branching, which entails solving multiple linear optimization problems (LPs). Despite the empirical success, the reasons behind MPNNs' effectiveness in emulating linear optimization remain largely unclear. Here, we show that MPNNs can simulate standard interior-point methods for LPs, explaining their practical success. Furthermore, we highlight how MPNNs can serve as a lightweight proxy for solving LPs, adapting to a given problem instance distribution. Empirically, we show that MPNNs solve LP relaxations of standard combinatorial optimization problems close to optimality, often surpassing conventional solvers and competing approaches in solving time. ",
    "url": "https://arxiv.org/abs/2310.10603",
    "authors": [
      "Chendi Qian",
      "Didier Ch\u00e9telat",
      "Christopher Morris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.10608",
    "title": "Quality control using convolutional neural networks applied to samples  of very small size",
    "abstract": "Although there is extensive literature on the application of artificial neural networks (NNs) in quality control (QC), to monitor the conformity of a process to quality specifications, at least five QC measurements are required, increasing the related cost. To explore the application of neural networks to samples of QC measurements of very small size, four one-dimensional (1-D) convolutional neural networks (CNNs) were designed, trained, and tested with datasets of $ n $-tuples of simulated standardized normally distributed QC measurements, for $ 1 \\leq n \\leq 4$. The designed neural networks were compared to statistical QC functions with equal probabilities for false rejection, applied to samples of the same size. When the $ n $-tuples included at least two QC measurements distributed as $ \\mathcal{N}(\\mu, \\sigma^2) $, where $ 0.2 < |\\mu| \\leq 6.0 $, and $ 1.0 < \\sigma \\leq 7.0 $, the designed neural networks outperformed the respective statistical QC functions. Therefore, 1-D CNNs applied to samples of 2-4 quality control measurements can be used to increase the probability of detection of the nonconformity of a process to the quality specifications, with lower cost. ",
    "url": "https://arxiv.org/abs/2310.10608",
    "authors": [
      "Rallou A. Chatzimichail",
      "Aristides T. Hatjimihail"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.10610",
    "title": "Quantifying Assistive Robustness Via the Natural-Adversarial Frontier",
    "abstract": "Our ultimate goal is to build robust policies for robots that assist people. What makes this hard is that people can behave unexpectedly at test time, potentially interacting with the robot outside its training distribution and leading to failures. Even just measuring robustness is a challenge. Adversarial perturbations are the default, but they can paint the wrong picture: they can correspond to human motions that are unlikely to occur during natural interactions with people. A robot policy might fail under small adversarial perturbations but work under large natural perturbations. We propose that capturing robustness in these interactive settings requires constructing and analyzing the entire natural-adversarial frontier: the Pareto-frontier of human policies that are the best trade-offs between naturalness and low robot performance. We introduce RIGID, a method for constructing this frontier by training adversarial human policies that trade off between minimizing robot reward and acting human-like (as measured by a discriminator). On an Assistive Gym task, we use RIGID to analyze the performance of standard collaborative Reinforcement Learning, as well as the performance of existing methods meant to increase robustness. We also compare the frontier RIGID identifies with the failures identified in expert adversarial interaction, and with naturally-occurring failures during user interaction. Overall, we find evidence that RIGID can provide a meaningful measure of robustness predictive of deployment performance, and uncover failure cases in human-robot interaction that are difficult to find manually. https://ood-human.github.io. ",
    "url": "https://arxiv.org/abs/2310.10610",
    "authors": [
      "Jerry Zhi-Yang He",
      "Zackory Erickson",
      "Daniel S. Brown",
      "Anca D. Dragan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.10640",
    "title": "LLM Blueprint: Enabling Text-to-Image Generation with Complex and  Detailed Prompts",
    "abstract": "Diffusion-based generative models have significantly advanced text-to-image generation but encounter challenges when processing lengthy and intricate text prompts describing complex scenes with multiple objects. While excelling in generating images from short, single-object descriptions, these models often struggle to faithfully capture all the nuanced details within longer and more elaborate textual inputs. In response, we present a novel approach leveraging Large Language Models (LLMs) to extract critical components from text prompts, including bounding box coordinates for foreground objects, detailed textual descriptions for individual objects, and a succinct background context. These components form the foundation of our layout-to-image generation model, which operates in two phases. The initial Global Scene Generation utilizes object layouts and background context to create an initial scene but often falls short in faithfully representing object characteristics as specified in the prompts. To address this limitation, we introduce an Iterative Refinement Scheme that iteratively evaluates and refines box-level content to align them with their textual descriptions, recomposing objects as needed to ensure consistency. Our evaluation on complex prompts featuring multiple objects demonstrates a substantial improvement in recall compared to baseline diffusion models. This is further validated by a user study, underscoring the efficacy of our approach in generating coherent and detailed scenes from intricate textual inputs. ",
    "url": "https://arxiv.org/abs/2310.10640",
    "authors": [
      "Hanan Gani",
      "Shariq Farooq Bhat",
      "Muzammal Naseer",
      "Salman Khan",
      "Peter Wonka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.10642",
    "title": "Real-time Photorealistic Dynamic Scene Representation and Rendering with  4D Gaussian Splatting",
    "abstract": "Reconstructing dynamic 3D scenes from 2D images and generating diverse views over time is challenging due to scene complexity and temporal dynamics. Despite advancements in neural implicit models, limitations persist: (i) Inadequate Scene Structure: Existing methods struggle to reveal the spatial and temporal structure of dynamic scenes from directly learning the complex 6D plenoptic function. (ii) Scaling Deformation Modeling: Explicitly modeling scene element deformation becomes impractical for complex dynamics. To address these issues, we consider the spacetime as an entirety and propose to approximate the underlying spatio-temporal 4D volume of a dynamic scene by optimizing a collection of 4D primitives, with explicit geometry and appearance modeling. Learning to optimize the 4D primitives enables us to synthesize novel views at any desired time with our tailored rendering routine. Our model is conceptually simple, consisting of a 4D Gaussian parameterized by anisotropic ellipses that can rotate arbitrarily in space and time, as well as view-dependent and time-evolved appearance represented by the coefficient of 4D spherindrical harmonics. This approach offers simplicity, flexibility for variable-length video and end-to-end training, and efficient real-time rendering, making it suitable for capturing complex dynamic scene motions. Experiments across various benchmarks, including monocular and multi-view scenarios, demonstrate our 4DGS model's superior visual quality and efficiency. ",
    "url": "https://arxiv.org/abs/2310.10642",
    "authors": [
      "Zeyu Yang",
      "Hongye Yang",
      "Zijie Pan",
      "Xiatian Zhu",
      "Li Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.10650",
    "title": "TraM-NeRF: Tracing Mirror and Near-Perfect Specular Reflections through  Neural Radiance Fields",
    "abstract": "Implicit representations like Neural Radiance Fields (NeRF) showed impressive results for photorealistic rendering of complex scenes with fine details. However, ideal or near-perfectly specular reflecting objects such as mirrors, which are often encountered in various indoor scenes, impose ambiguities and inconsistencies in the representation of the reconstructed scene leading to severe artifacts in the synthesized renderings. In this paper, we present a novel reflection tracing method tailored for the involved volume rendering within NeRF that takes these mirror-like objects into account while avoiding the cost of straightforward but expensive extensions through standard path tracing. By explicitly modeling the reflection behavior using physically plausible materials and estimating the reflected radiance with Monte-Carlo methods within the volume rendering formulation, we derive efficient strategies for importance sampling and the transmittance computation along rays from only few samples. We show that our novel method enables the training of consistent representations of such challenging scenes and achieves superior results in comparison to previous state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2310.10650",
    "authors": [
      "Leif Van Holland",
      "Ruben Bliersbach",
      "Jan U. M\u00fcller",
      "Patrick Stotko",
      "Reinhard Klein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2308.14714",
    "title": "A Stochastic Surveillance Stackelberg Game: Co-Optimizing Defense  Placement and Patrol Strategy",
    "abstract": "Stochastic patrol routing is known to be advantageous in adversarial settings; however, the optimal choice of stochastic routing strategy is dependent on a model of the adversary. Duan et al. formulated a Stackelberg game for the worst-case scenario, i.e., a surveillance agent confronted with an omniscient attacker [IEEE TCNS, 8(2), 769-80, 2021]. In this article, we extend their formulation to accommodate heterogeneous defenses at the various nodes of the graph. We derive an upper bound on the value of the game. We identify methods for computing effective patrol strategies for certain classes of graphs. Finally, we leverage the heterogeneous defense formulation to develop novel defense placement algorithms that complement the patrol strategies. ",
    "url": "https://arxiv.org/abs/2308.14714",
    "authors": [
      "Yohan John",
      "Gilberto Diaz-Garcia",
      "Xiaoming Duan",
      "Jason R. Marden",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2310.09294",
    "title": "Unlocking the Potential of Synthetic Fuel Production: Coupled  Optimization of Heat Exchanger Network and Operating Parameters of a 1 MW  Power-to-Liquid Plant",
    "abstract": "The use of synthetic fuels is a promising way to reduce emissions significantly. To accelerate cost-effective large-scale synthetic fuel deployment, we optimize a novel 1 MW PtL-plant in terms of PtL-efficiency and fuel production costs. For numerous plants, the available waste heat and temperature level depend on the operating point. Thus, to optimize efficiency and costs, the choice of the operating point is included in the heat exchanger network synthesis. All nonlinearities are approximated using piecewise linear models and transferred to MILP. Adapting the epsilon constraint method allows us to solve the multi-criteria problem with uniformly distributed solutions on the Pareto front. The results show that compared to the conventional design process, the production cost can be reduced to 1.83 EUR/kg and the PtL-efficiency can be increased to 61.30 %. By applying the presented method, climate-neutral synthetic fuels can be promoted and emissions can be reduced in the long term. ",
    "url": "https://arxiv.org/abs/2310.09294",
    "authors": [
      "David Huber",
      "Felix Birkelbach",
      "Ren\u00e9 Hofmann"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.09597",
    "title": "Adaptive maximization of social welfare",
    "abstract": "We consider the problem of repeatedly choosing policies to maximize social welfare. Welfare is a weighted sum of private utility and public revenue. Earlier outcomes inform later policies. Utility is not observed, but indirectly inferred. Response functions are learned through experimentation. We derive a lower bound on regret, and a matching adversarial upper bound for a variant of the Exp3 algorithm. Cumulative regret grows at a rate of $T^{2/3}$. This implies that (i) welfare maximization is harder than the multi-armed bandit problem (with a rate of $T^{1/2}$ for finite policy sets), and (ii) our algorithm achieves the optimal rate. For the stochastic setting, if social welfare is concave, we can achieve a rate of $T^{1/2}$ (for continuous policy sets), using a dyadic search algorithm. We analyze an extension to nonlinear income taxation, and sketch an extension to commodity taxation. We compare our setting to monopoly pricing (which is easier), and price setting for bilateral trade (which is harder). ",
    "url": "https://arxiv.org/abs/2310.09597",
    "authors": [
      "Nicolo Cesa-Bianchi",
      "Roberto Colomboni",
      "Maximilian Kasy"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09603",
    "title": "B-Spine: Learning B-Spline Curve Representation for Robust and  Interpretable Spinal Curvature Estimation",
    "abstract": "Spinal curvature estimation is important to the diagnosis and treatment of the scoliosis. Existing methods face several issues such as the need of expensive annotations on the vertebral landmarks and being sensitive to the image quality. It is challenging to achieve robust estimation and obtain interpretable results, especially for low-quality images which are blurry and hazy. In this paper, we propose B-Spine, a novel deep learning pipeline to learn B-spline curve representation of the spine and estimate the Cobb angles for spinal curvature estimation from low-quality X-ray images. Given a low-quality input, a novel SegRefine network which employs the unpaired image-to-image translation is proposed to generate a high quality spine mask from the initial segmentation result. Next, a novel mask-based B-spline prediction model is proposed to predict the B-spline curve for the spine centerline. Finally, the Cobb angles are estimated by a hybrid approach which combines the curve slope analysis and a curve-based regression model. We conduct quantitative and qualitative comparisons with the representative and SOTA learning-based methods on the public AASCE2019 dataset and our new proposed CJUH-JLU dataset which contains more challenging low-quality images. The superior performance on both datasets shows our method can achieve both robustness and interpretability for spinal curvature estimation. ",
    "url": "https://arxiv.org/abs/2310.09603",
    "authors": [
      "Hao Wang",
      "Qiang Song",
      "Ruofeng Yin",
      "Rui Ma",
      "Yizhou Yu",
      "Yi Chang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.09804",
    "title": "Communication Compression for Byzantine Robust Learning: New Efficient  Algorithms and Improved Rates",
    "abstract": "Byzantine robustness is an essential feature of algorithms for certain distributed optimization problems, typically encountered in collaborative/federated learning. These problems are usually huge-scale, implying that communication compression is also imperative for their resolution. These factors have spurred recent algorithmic and theoretical developments in the literature of Byzantine-robust learning with compression. In this paper, we contribute to this research area in two main directions. First, we propose a new Byzantine-robust method with compression -- Byz-DASHA-PAGE -- and prove that the new method has better convergence rate (for non-convex and Polyak-Lojasiewicz smooth optimization problems), smaller neighborhood size in the heterogeneous case, and tolerates more Byzantine workers under over-parametrization than the previous method with SOTA theoretical convergence guarantees (Byz-VR-MARINA). Secondly, we develop the first Byzantine-robust method with communication compression and error feedback -- Byz-EF21 -- along with its bidirectional compression version -- Byz-EF21-BC -- and derive the convergence rates for these methods for non-convex and Polyak-Lojasiewicz smooth case. We test the proposed methods and illustrate our theoretical findings in the numerical experiments. ",
    "url": "https://arxiv.org/abs/2310.09804",
    "authors": [
      "Ahmad Rammal",
      "Kaja Gruntkowska",
      "Nikita Fedin",
      "Eduard Gorbunov",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09903",
    "title": "Evaluation of feature selection performance for identification of best  effective technical indicators on stock market price prediction",
    "abstract": "Due to the influence of many factors, including technical indicators on stock market prediction, feature selection is important to choose the best indicators. One of the feature selection methods that consider the performance of models during feature selection is the wrapper feature selection method. The aim of this research is to identify a combination of the best stock market indicators through feature selection to predict the stock market price with the least error. In order to evaluate the impact of wrapper feature selection techniques on stock market prediction, in this paper SFS and SBS with 10 estimators and 123 technical indicators have been examined on the last 10 years of Apple Company. Also, by the proposed method, the data created by the 3-day time window were converted to the appropriate input for regression methods. Based on the results observed: (1) Each wrapper feature selection method has different results with different machine learning methods, and each method is more correlated with a specific set of technical indicators of the stock market. (2) Ridge and LR estimates alone, and with two methods of the wrapper feature selection, namely SFS and SBS; They had the best results with all assessment criteria for market forecast. (3)The Ridge and LR method with all the R2, MSE, RMSE, MAE and MAPE have the best stock market prediction results. Also, the MLP Regression Method, along with the Sequential Forwards Selection and the MSE, had the best performance. SVR regression, along with the SFS and the MSE, has improved greatly compared to the SVR regression with all indicators. (4) It was also observed that different features are selected by different ML methods with different evaluation parameters. (5) Most ML methods have used the Squeeze_pro, Percentage Price Oscillator, Thermo, Decay, Archer On-Balance Volume, Bollinger Bands, Squeeze and Ichimoku indicator. ",
    "url": "https://arxiv.org/abs/2310.09903",
    "authors": [
      "Fatemeh Moodi",
      "Amir Jahangard-Rafsanjani"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09999",
    "title": "Outlier Detection Using Generative Models with Theoretical Performance  Guarantees",
    "abstract": "This paper considers the problem of recovering signals modeled by generative models from linear measurements contaminated with sparse outliers. We propose an outlier detection approach for reconstructing the ground-truth signals modeled by generative models under sparse outliers. We establish theoretical recovery guarantees for reconstruction of signals using generative models in the presence of outliers, giving lower bounds on the number of correctable outliers. Our results are applicable to both linear generator neural networks and the nonlinear generator neural networks with an arbitrary number of layers. We propose an iterative alternating direction method of multipliers (ADMM) algorithm for solving the outlier detection problem via $\\ell_1$ norm minimization, and a gradient descent algorithm for solving the outlier detection problem via squared $\\ell_1$ norm minimization. We conduct extensive experiments using variational auto-encoder and deep convolutional generative adversarial networks, and the experimental results show that the signals can be successfully reconstructed under outliers using our approach. Our approach outperforms the traditional Lasso and $\\ell_2$ minimization approach. ",
    "url": "https://arxiv.org/abs/2310.09999",
    "authors": [
      "Jirong Yi",
      "Jingchao Gao",
      "Tianming Wang",
      "Xiaodong Wu",
      "Weiyu Xu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.10002",
    "title": "Assessing Encoder-Decoder Architectures for Robust Coronary Artery  Segmentation",
    "abstract": "Coronary artery diseases are among the leading causes of mortality worldwide. Timely and accurate diagnosis, facilitated by precise coronary artery segmentation, is pivotal in changing patient outcomes. In the realm of biomedical imaging, convolutional neural networks, especially the U-Net architecture, have revolutionised segmentation processes. However, one of the primary challenges remains the lack of benchmarking datasets specific to coronary arteries. However through the use of the recently published public dataset ASOCA, the potential of deep learning for accurate coronary segmentation can be improved. This paper delves deep into examining the performance of 25 distinct encoder-decoder combinations. Through analysis of the 40 cases provided to ASOCA participants, it is revealed that the EfficientNet-LinkNet combination, serving as encoder and decoder, stands out. It achieves a Dice coefficient of 0.882 and a 95th percentile Hausdorff distance of 4.753. These findings not only underscore the superiority of our model in comparison to those presented at the MICCAI 2020 challenge but also set the stage for future advancements in coronary artery segmentation, opening doors to enhanced diagnostic and treatment strategies. ",
    "url": "https://arxiv.org/abs/2310.10002",
    "authors": [
      "Shisheng Zhang",
      "Ramtin Gharleghi",
      "Sonit Singh",
      "Arcot Sowmya",
      "Susann Beier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.10003",
    "title": "Conformal Contextual Robust Optimization",
    "abstract": "Data-driven approaches to predict-then-optimize decision-making problems seek to mitigate the risk of uncertainty region misspecification in safety-critical settings. Current approaches, however, suffer from considering overly conservative uncertainty regions, often resulting in suboptimal decisionmaking. To this end, we propose Conformal-Predict-Then-Optimize (CPO), a framework for leveraging highly informative, nonconvex conformal prediction regions over high-dimensional spaces based on conditional generative models, which have the desired distribution-free coverage guarantees. Despite guaranteeing robustness, such black-box optimization procedures alone inspire little confidence owing to the lack of explanation of why a particular decision was found to be optimal. We, therefore, augment CPO to additionally provide semantically meaningful visual summaries of the uncertainty regions to give qualitative intuition for the optimal decision. We highlight the CPO framework by demonstrating results on a suite of simulation-based inference benchmark tasks and a vehicle routing task based on probabilistic weather prediction. ",
    "url": "https://arxiv.org/abs/2310.10003",
    "authors": [
      "Yash Patel",
      "Sahana Rayan",
      "Ambuj Tewari"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.10013",
    "title": "Riemannian Residual Neural Networks",
    "abstract": "Recent methods in geometric deep learning have introduced various neural networks to operate over data that lie on Riemannian manifolds. Such networks are often necessary to learn well over graphs with a hierarchical structure or to learn over manifold-valued data encountered in the natural sciences. These networks are often inspired by and directly generalize standard Euclidean neural networks. However, extending Euclidean networks is difficult and has only been done for a select few manifolds. In this work, we examine the residual neural network (ResNet) and show how to extend this construction to general Riemannian manifolds in a geometrically principled manner. Originally introduced to help solve the vanishing gradient problem, ResNets have become ubiquitous in machine learning due to their beneficial learning properties, excellent empirical results, and easy-to-incorporate nature when building varied neural networks. We find that our Riemannian ResNets mirror these desirable properties: when compared to existing manifold neural networks designed to learn over hyperbolic space and the manifold of symmetric positive definite matrices, we outperform both kinds of networks in terms of relevant testing metrics and training dynamics. ",
    "url": "https://arxiv.org/abs/2310.10013",
    "authors": [
      "Isay Katsman",
      "Eric Ming Chen",
      "Sidhanth Holalkere",
      "Anna Asch",
      "Aaron Lou",
      "Ser-Nam Lim",
      "Christopher De Sa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10026",
    "title": "Real-time Speech Enhancement and Separation with a Unified Deep Neural  Network for Single/Dual Talker Scenarios",
    "abstract": "This paper introduces a practical approach for leveraging a real-time deep learning model to alternate between speech enhancement and joint speech enhancement and separation depending on whether the input mixture contains one or two active speakers. Scale-invariant signal-to-distortion ratio (SI-SDR) has shown to be a highly effective training measure in time-domain speech separation. However, the SI-SDR metric is ill-defined for zero-energy target signals, which is a problem when training a speech separation model using utterances with varying numbers of talkers. Unlike existing solutions that focus on modifying the loss function to accommodate zero-energy target signals, the proposed approach circumvents this problem by training the model to extract speech on both its output channels regardless if the input is a single or dual-talker mixture. A lightweight speaker overlap detection (SOD) module is also introduced to differentiate between single and dual-talker segments in real-time. The proposed module takes advantage of the new formulation by operating directly on the separated masks, given by the separation model, instead of the original mixture, thus effectively simplifying the detection task. Experimental results show that the proposed training approach outperforms existing solutions, and the SOD module exhibits high accuracy. ",
    "url": "https://arxiv.org/abs/2310.10026",
    "authors": [
      "Kashyap Patel",
      "Anton Kovalyov",
      "Issa Panahi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2310.10088",
    "title": "PUCA: Patch-Unshuffle and Channel Attention for Enhanced Self-Supervised  Image Denoising",
    "abstract": "Although supervised image denoising networks have shown remarkable performance on synthesized noisy images, they often fail in practice due to the difference between real and synthesized noise. Since clean-noisy image pairs from the real world are extremely costly to gather, self-supervised learning, which utilizes noisy input itself as a target, has been studied. To prevent a self-supervised denoising model from learning identical mapping, each output pixel should not be influenced by its corresponding input pixel; This requirement is known as J-invariance. Blind-spot networks (BSNs) have been a prevalent choice to ensure J-invariance in self-supervised image denoising. However, constructing variations of BSNs by injecting additional operations such as downsampling can expose blinded information, thereby violating J-invariance. Consequently, convolutions designed specifically for BSNs have been allowed only, limiting architectural flexibility. To overcome this limitation, we propose PUCA, a novel J-invariant U-Net architecture, for self-supervised denoising. PUCA leverages patch-unshuffle/shuffle to dramatically expand receptive fields while maintaining J-invariance and dilated attention blocks (DABs) for global context incorporation. Experimental results demonstrate that PUCA achieves state-of-the-art performance, outperforming existing methods in self-supervised image denoising. ",
    "url": "https://arxiv.org/abs/2310.10088",
    "authors": [
      "Hyemi Jang",
      "Junsung Park",
      "Dahuin Jung",
      "Jaihyun Lew",
      "Ho Bae",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10143",
    "title": "An Empirical Study of Simplicial Representation Learning with  Wasserstein Distance",
    "abstract": "In this paper, we delve into the problem of simplicial representation learning utilizing the 1-Wasserstein distance on a tree structure (a.k.a., Tree-Wasserstein distance (TWD)), where TWD is defined as the L1 distance between two tree-embedded vectors. Specifically, we consider a framework for simplicial representation estimation employing a self-supervised learning approach based on SimCLR with a negative TWD as a similarity measure. In SimCLR, the cosine similarity with real-vector embeddings is often utilized; however, it has not been well studied utilizing L1-based measures with simplicial embeddings. A key challenge is that training the L1 distance is numerically challenging and often yields unsatisfactory outcomes, and there are numerous choices for probability models. Thus, this study empirically investigates a strategy for optimizing self-supervised learning with TWD and find a stable training procedure. More specifically, we evaluate the combination of two types of TWD (total variation and ClusterTree) and several simplicial models including the softmax function, the ArcFace probability model, and simplicial embedding. Moreover, we propose a simple yet effective Jeffrey divergence-based regularization method to stabilize the optimization. Through empirical experiments on STL10, CIFAR10, CIFAR100, and SVHN, we first found that the simple combination of softmax function and TWD can obtain significantly lower results than the standard SimCLR (non-simplicial model and cosine similarity). We found that the model performance depends on the combination of TWD and the simplicial model, and the Jeffrey divergence regularization usually helps model training. Finally, we inferred that the appropriate choice of combination of TWD and simplicial models outperformed cosine similarity based representation learning. ",
    "url": "https://arxiv.org/abs/2310.10143",
    "authors": [
      "Makoto Yamada",
      "Yuki Takezawa",
      "Guillaume Houry",
      "Kira Michaela Dusterwald",
      "Deborah Sulem",
      "Han Zhao",
      "Yao-Hung Hubert Tsai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10171",
    "title": "On permutation symmetries in Bayesian neural network posteriors: a  variational perspective",
    "abstract": "The elusive nature of gradient-based optimization in neural networks is tied to their loss landscape geometry, which is poorly understood. However recent work has brought solid evidence that there is essentially no loss barrier between the local solutions of gradient descent, once accounting for weight-permutations that leave the network's computation unchanged. This raises questions for approximate inference in Bayesian neural networks (BNNs), where we are interested in marginalizing over multiple points in the loss landscape. In this work, we first extend the formalism of marginalized loss barrier and solution interpolation to BNNs, before proposing a matching algorithm to search for linearly connected solutions. This is achieved by aligning the distributions of two independent approximate Bayesian solutions with respect to permutation matrices. We build on the results of Ainsworth et al. (2023), reframing the problem as a combinatorial optimization one, using an approximation to the sum of bilinear assignment problem. We then experiment on a variety of architectures and datasets, finding nearly zero marginalized loss barriers for linearly connected solutions. ",
    "url": "https://arxiv.org/abs/2310.10171",
    "authors": [
      "Simone Rossi",
      "Ankit Singh",
      "Thomas Hannagan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10209",
    "title": "Self-supervised Fetal MRI 3D Reconstruction Based on Radiation Diffusion  Generation Model",
    "abstract": "Although the use of multiple stacks can handle slice-to-volume motion correction and artifact removal problems, there are still several problems: 1) The slice-to-volume method usually uses slices as input, which cannot solve the problem of uniform intensity distribution and complementarity in regions of different fetal MRI stacks; 2) The integrity of 3D space is not considered, which adversely affects the discrimination and generation of globally consistent information in fetal MRI; 3) Fetal MRI with severe motion artifacts in the real-world cannot achieve high-quality super-resolution reconstruction. To address these issues, we propose a novel fetal brain MRI high-quality volume reconstruction method, called the Radiation Diffusion Generation Model (RDGM). It is a self-supervised generation method, which incorporates the idea of Neural Radiation Field (NeRF) based on the coordinate generation and diffusion model based on super-resolution generation. To solve regional intensity heterogeneity in different directions, we use a pre-trained transformer model for slice registration, and then, a new regionally Consistent Implicit Neural Representation (CINR) network sub-module is proposed. CINR can generate the initial volume by combining a coordinate association map of two different coordinate mapping spaces. To enhance volume global consistency and discrimination, we introduce the Volume Diffusion Super-resolution Generation (VDSG) mechanism. The global intensity discriminant generation from volume-to-volume is carried out using the idea of diffusion generation, and CINR becomes the deviation intensity generation network of the volume-to-volume diffusion model. Finally, the experimental results on real-world fetal brain MRI stacks demonstrate the state-of-the-art performance of our method. ",
    "url": "https://arxiv.org/abs/2310.10209",
    "authors": [
      "Junpeng Tan",
      "Xin Zhang",
      "Yao Lv",
      "Xiangmin Xu",
      "Gang Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10224",
    "title": "Generalizing Medical Image Representations via Quaternion Wavelet  Networks",
    "abstract": "Neural network generalizability is becoming a broad research field due to the increasing availability of datasets from different sources and for various tasks. This issue is even wider when processing medical data, where a lack of methodological standards causes large variations being provided by different imaging centers or acquired with various devices and cofactors. To overcome these limitations, we introduce a novel, generalizable, data- and task-agnostic framework able to extract salient features from medical images. The proposed quaternion wavelet network (QUAVE) can be easily integrated with any pre-existing medical image analysis or synthesis task, and it can be involved with real, quaternion, or hypercomplex-valued models, generalizing their adoption to single-channel data. QUAVE first extracts different sub-bands through the quaternion wavelet transform, resulting in both low-frequency/approximation bands and high-frequency/fine-grained features. Then, it weighs the most representative set of sub-bands to be involved as input to any other neural model for image processing, replacing standard data samples. We conduct an extensive experimental evaluation comprising different datasets, diverse image analysis, and synthesis tasks including reconstruction, segmentation, and modality translation. We also evaluate QUAVE in combination with both real and quaternion-valued models. Results demonstrate the effectiveness and the generalizability of the proposed framework that improves network performance while being flexible to be adopted in manifold scenarios. ",
    "url": "https://arxiv.org/abs/2310.10224",
    "authors": [
      "Luigi Sigillo",
      "Eleonora Grassucci",
      "Aurelio Uncini",
      "Danilo Comminiello"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10240",
    "title": "The Mixtures and the Neural Critics: On the Pointwise Mutual Information  Profiles of Fine Distributions",
    "abstract": "Mutual information quantifies the dependence between two random variables and remains invariant under diffeomorphisms. In this paper, we explore the pointwise mutual information profile, an extension of mutual information that maintains this invariance. We analytically describe the profiles of multivariate normal distributions and introduce the family of fine distributions, for which the profile can be accurately approximated using Monte Carlo methods. We then show how fine distributions can be used to study the limitations of existing mutual information estimators, investigate the behavior of neural critics used in variational estimators, and understand the effect of experimental outliers on mutual information estimation. Finally, we show how fine distributions can be used to obtain model-based Bayesian estimates of mutual information, suitable for problems with available domain expertise in which uncertainty quantification is necessary. ",
    "url": "https://arxiv.org/abs/2310.10240",
    "authors": [
      "Pawe\u0142 Czy\u017c",
      "Frederic Grabowski",
      "Julia E. Vogt",
      "Niko Beerenwinkel",
      "Alexander Marx"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10413",
    "title": "Image super-resolution via dynamic network",
    "abstract": "Convolutional neural networks (CNNs) depend on deep network architectures to extract accurate information for image super-resolution. However, obtained information of these CNNs cannot completely express predicted high-quality images for complex scenes. In this paper, we present a dynamic network for image super-resolution (DSRNet), which contains a residual enhancement block, wide enhancement block, feature refinement block and construction block. The residual enhancement block is composed of a residual enhanced architecture to facilitate hierarchical features for image super-resolution. To enhance robustness of obtained super-resolution model for complex scenes, a wide enhancement block achieves a dynamic architecture to learn more robust information to enhance applicability of an obtained super-resolution model for varying scenes. To prevent interference of components in a wide enhancement block, a refinement block utilizes a stacked architecture to accurately learn obtained features. Also, a residual learning operation is embedded in the refinement block to prevent long-term dependency problem. Finally, a construction block is responsible for reconstructing high-quality images. Designed heterogeneous architecture can not only facilitate richer structural information, but also be lightweight, which is suitable for mobile digital devices. Experimental results shows that our method is more competitive in terms of performance and recovering time of image super-resolution and complexity. The code of DSRNet can be obtained at https://github.com/hellloxiaotian/DSRNet. ",
    "url": "https://arxiv.org/abs/2310.10413",
    "authors": [
      "Chunwei Tian",
      "Xuanyu Zhang",
      "Qi Zhang",
      "Mingming Yang",
      "Zhaojie Ju"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.10414",
    "title": "Style transfer between Microscopy and Magnetic Resonance Imaging via  Generative Adversarial Network in small sample size settings",
    "abstract": "Cross-modal augmentation of Magnetic Resonance Imaging (MRI) and microscopic imaging based on the same tissue samples is promising because it can allow histopathological analysis in the absence of an underlying invasive biopsy procedure. Here, we tested a method for generating microscopic histological images from MRI scans of the corpus callosum using conditional generative adversarial network (cGAN) architecture. To our knowledge, this is the first multimodal translation of the brain MRI to histological volumetric representation of the same sample. The technique was assessed by training paired image translation models taking sets of images from MRI scans and microscopy. The use of cGAN for this purpose is challenging because microscopy images are large in size and typically have low sample availability. The current work demonstrates that the framework reliably synthesizes histology images from MRI scans of corpus callosum, emphasizing the network's ability to train on high resolution histologies paired with relatively lower-resolution MRI scans. With the ultimate goal of avoiding biopsies, the proposed tool can be used for educational purposes. ",
    "url": "https://arxiv.org/abs/2310.10414",
    "authors": [
      "Monika Pytlarz",
      "Adrian Onicas",
      "Alessandro Crimi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.10434",
    "title": "Equivariant Matrix Function Neural Networks",
    "abstract": "Graph Neural Networks (GNNs), especially message-passing neural networks (MPNNs), have emerged as powerful architectures for learning on graphs in diverse applications. However, MPNNs face challenges when modeling non-local interactions in systems such as large conjugated molecules, metals, or amorphous materials. Although Spectral GNNs and traditional neural networks such as recurrent neural networks and transformers mitigate these challenges, they often lack extensivity, adaptability, generalizability, computational efficiency, or fail to capture detailed structural relationships or symmetries in the data. To address these concerns, we introduce Matrix Function Neural Networks (MFNs), a novel architecture that parameterizes non-local interactions through analytic matrix equivariant functions. Employing resolvent expansions offers a straightforward implementation and the potential for linear scaling with system size. The MFN architecture achieves state-of-the-art performance in standard graph benchmarks, such as the ZINC and TU datasets, and is able to capture intricate non-local interactions in quantum systems, paving the way to new state-of-the-art force fields. ",
    "url": "https://arxiv.org/abs/2310.10434",
    "authors": [
      "Ilyes Batatia",
      "Lars L. Schaaf",
      "Huajie Chen",
      "G\u00e1bor Cs\u00e1nyi",
      "Christoph Ortner",
      "Felix A. Faber"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2310.10448",
    "title": "A Geometric Insight into Equivariant Message Passing Neural Networks on  Riemannian Manifolds",
    "abstract": "This work proposes a geometric insight into equivariant message passing on Riemannian manifolds. As previously proposed, numerical features on Riemannian manifolds are represented as coordinate-independent feature fields on the manifold. To any coordinate-independent feature field on a manifold comes attached an equivariant embedding of the principal bundle to the space of numerical features. We argue that the metric this embedding induces on the numerical feature space should optimally preserve the principal bundle's original metric. This optimality criterion leads to the minimization of a twisted form of the Polyakov action with respect to the graph of this embedding, yielding an equivariant diffusion process on the associated vector bundle. We obtain a message passing scheme on the manifold by discretizing the diffusion equation flow for a fixed time step. We propose a higher-order equivariant diffusion process equivalent to diffusion on the cartesian product of the base manifold. The discretization of the higher-order diffusion process on a graph yields a new general class of equivariant GNN, generalizing the ACE and MACE formalism to data on Riemannian manifolds. ",
    "url": "https://arxiv.org/abs/2310.10448",
    "authors": [
      "Ilyes Batatia"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10451",
    "title": "Distributed search on graphs using discrete time quantum walk",
    "abstract": "Searching with coined quantum walk is a problem that has interested the community since a long time. While most results consider spatial searches on regular lattices, some work have introduced several models of coined quantum walks on graphs. This work introduces a distributed searching quantum walk on graphs. Our contribution is in two parts: (i) we introduce a new mathematical model of a coined quantum walk on graphs designed to search both nodes or edges; (ii) we provide an anonymous distributed scheme to implement such a model. ",
    "url": "https://arxiv.org/abs/2310.10451",
    "authors": [
      "Mathieu Roget",
      "Giuseppe Di Molfetta"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.10559",
    "title": "Causal Dynamic Variational Autoencoder for Counterfactual Regression in  Longitudinal Data",
    "abstract": "Estimating treatment effects over time is relevant in many real-world applications, such as precision medicine, epidemiology, economy, and marketing. Many state-of-the-art methods either assume the observations of all confounders or seek to infer the unobserved ones. We take a different perspective by assuming unobserved risk factors, i.e., adjustment variables that affect only the sequence of outcomes. Under unconfoundedness, we target the Individual Treatment Effect (ITE) estimation with unobserved heterogeneity in the treatment response due to missing risk factors. We address the challenges posed by time-varying effects and unobserved adjustment variables. Led by theoretical results over the validity of the learned adjustment variables and generalization bounds over the treatment effect, we devise Causal DVAE (CDVAE). This model combines a Dynamic Variational Autoencoder (DVAE) framework with a weighting strategy using propensity scores to estimate counterfactual responses. The CDVAE model allows for accurate estimation of ITE and captures the underlying heterogeneity in longitudinal data. Evaluations of our model show superior performance over state-of-the-art models. ",
    "url": "https://arxiv.org/abs/2310.10559",
    "authors": [
      "Mouad El Bouchattaoui",
      "Myriam Tami",
      "Benoit Lepetit",
      "Paul-Henry Courn\u00e8de"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.10602",
    "title": "Physics-informed neural wavefields with Gabor basis functions",
    "abstract": "Recently, Physics-Informed Neural Networks (PINNs) have gained significant attention for their versatile interpolation capabilities in solving partial differential equations (PDEs). Despite their potential, the training can be computationally demanding, especially for intricate functions like wavefields. This is primarily due to the neural-based (learned) basis functions, biased toward low frequencies, as they are dominated by polynomial calculations, which are not inherently wavefield-friendly. In response, we propose an approach to enhance the efficiency and accuracy of neural network wavefield solutions by modeling them as linear combinations of Gabor basis functions that satisfy the wave equation. Specifically, for the Helmholtz equation, we augment the fully connected neural network model with an adaptable Gabor layer constituting the final hidden layer, employing a weighted summation of these Gabor neurons to compute the predictions (output). These weights/coefficients of the Gabor functions are learned from the previous hidden layers that include nonlinear activation functions. To ensure the Gabor layer's utilization across the model space, we incorporate a smaller auxiliary network to forecast the center of each Gabor function based on input coordinates. Realistic assessments showcase the efficacy of this novel implementation compared to the vanilla PINN, particularly in scenarios involving high-frequencies and realistic models that are often challenging for PINNs. ",
    "url": "https://arxiv.org/abs/2310.10602",
    "authors": [
      "Tariq Alkhalifah",
      "Xinquan Huang"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Artificial Intelligence (cs.AI)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2002.12530",
    "title": "Temporal Convolutional Attention-based Network For Sequence Modeling",
    "abstract": " Comments: 7 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2002.12530",
    "authors": [
      "Hongyan Hao",
      "Yan Wang",
      "Siqiao Xue",
      "Yudi Xia",
      "Jian Zhao",
      "Furao Shen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2010.10274",
    "title": "Graph Fairing Convolutional Networks for Anomaly Detection",
    "abstract": " Title: Graph Fairing Convolutional Networks for Anomaly Detection ",
    "url": "https://arxiv.org/abs/2010.10274",
    "authors": [
      "Mahsa Mesgaran",
      "A. Ben Hamza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2010.12611",
    "title": "Information access representations and social capital in networks",
    "abstract": " Title: Information access representations and social capital in networks ",
    "url": "https://arxiv.org/abs/2010.12611",
    "authors": [
      "Ashkan Bashardoust",
      "Hannah C. Beilinson",
      "Sorelle A. Friedler",
      "Jiajie Ma",
      "Jade Rousseau",
      "Carlos E. Scheidegger",
      "Blair D. Sullivan",
      "Nasanbayar Ulzii-Orshikh",
      "Suresh Venkatasubramanian"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2106.00042",
    "title": "A study on the plasticity of neural networks",
    "abstract": " Title: A study on the plasticity of neural networks ",
    "url": "https://arxiv.org/abs/2106.00042",
    "authors": [
      "Tudor Berariu",
      "Wojciech Czarnecki",
      "Soham De",
      "Jorg Bornschein",
      "Samuel Smith",
      "Razvan Pascanu",
      "Claudia Clopath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.02331",
    "title": "Manifold-Aware Deep Clustering: Maximizing Angles between Embedding  Vectors Based on Regular Simplex",
    "abstract": " Comments: Accepted by Interspeech 2021 ",
    "url": "https://arxiv.org/abs/2106.02331",
    "authors": [
      "Keitaro Tanaka",
      "Ryosuke Sawata",
      "Shusuke Takahashi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.07002",
    "title": "Change is Everywhere: Single-Temporal Supervised Object Change Detection  in Remote Sensing Imagery",
    "abstract": " Comments: ICCV 2021 ",
    "url": "https://arxiv.org/abs/2108.07002",
    "authors": [
      "Zhuo Zheng",
      "Ailong Ma",
      "Liangpei Zhang",
      "Yanfei Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.03135",
    "title": "Label Noise in Adversarial Training: A Novel Perspective to Study Robust  Overfitting",
    "abstract": " Comments: Neurips 2022 (Oral); A previous version of this paper (v1) used the title `Double Descent in Adversarial Training: An Implicit Label Noise Perspective` ",
    "url": "https://arxiv.org/abs/2110.03135",
    "authors": [
      "Chengyu Dong",
      "Liyuan Liu",
      "Jingbo Shang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.12938",
    "title": "Counterfactual Memorization in Neural Language Models",
    "abstract": " Comments: NeurIPS 2023; 42 pages, 33 figures ",
    "url": "https://arxiv.org/abs/2112.12938",
    "authors": [
      "Chiyuan Zhang",
      "Daphne Ippolito",
      "Katherine Lee",
      "Matthew Jagielski",
      "Florian Tram\u00e8r",
      "Nicholas Carlini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.06070",
    "title": "ALA: Naturalness-aware Adversarial Lightness Attack",
    "abstract": " Comments: 9 pages ",
    "url": "https://arxiv.org/abs/2201.06070",
    "authors": [
      "Yihao Huang",
      "Liangru Sun",
      "Qing Guo",
      "Felix Juefei-Xu",
      "Jiayi Zhu",
      "Jincao Feng",
      "Yang Liu",
      "Geguang Pu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.03583",
    "title": "Multi-Label Classification of Thoracic Diseases using Dense  Convolutional Network on Chest Radiographs",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2202.03583",
    "authors": [
      "Dipkamal Bhusal",
      "Sanjeeb Prasad Panday"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.13424",
    "title": "Dealing with Sparse Rewards Using Graph Neural Networks",
    "abstract": " Title: Dealing with Sparse Rewards Using Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2203.13424",
    "authors": [
      "Matvey Gerasyov",
      "Ilya Makarov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2205.14307",
    "title": "TFLEX: Temporal Feature-Logic Embedding Framework for Complex Reasoning  over Temporal Knowledge Graph",
    "abstract": " Comments: Accepted to NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2205.14307",
    "authors": [
      "Xueyuan Lin",
      "Chengjin Xu",
      "Haihong E",
      "Fenglong Su",
      "Gengxian Zhou",
      "Tianyi Hu",
      "Ningyuan Li",
      "Mingzhi Sun",
      "Haoran Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.07173",
    "title": "Deep Image Clustering with Contrastive Learning and Multi-scale Graph  Convolutional Networks",
    "abstract": " Comments: To appear in the Pattern Recognition journal ",
    "url": "https://arxiv.org/abs/2207.07173",
    "authors": [
      "Yuankun Xu",
      "Dong Huang",
      "Chang-Dong Wang",
      "Jian-Huang Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.07870",
    "title": "Scene Graph for Embodied Exploration in Cluttered Scenario",
    "abstract": " Title: Scene Graph for Embodied Exploration in Cluttered Scenario ",
    "url": "https://arxiv.org/abs/2207.07870",
    "authors": [
      "Yuhong Deng",
      "Qie Sima",
      "Di Guo",
      "Huaping Liu",
      "Yi Wang",
      "Fuchun Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.09324",
    "title": "Signed Network Embedding with Application to Simultaneous Detection of  Communities and Anomalies",
    "abstract": " Comments: 24 pages, 4 figures. The appendix containing technical proof is not included, and will be uploaded in the future ",
    "url": "https://arxiv.org/abs/2207.09324",
    "authors": [
      "Haoran Zhang",
      "Junhui Wang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2208.00175",
    "title": "Global, Unified Representation of Heterogenous Robot Dynamics Using  Composition Operators: A Koopman Direct Encoding Method",
    "abstract": " Comments: 12 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2208.00175",
    "authors": [
      "Harry Asada"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.01430",
    "title": "A Model for Multi-Agent Heterogeneous Interaction Problems",
    "abstract": " Comments: 8 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2208.01430",
    "authors": [
      "Christopher D. Hsu",
      "Mulugeta A. Haile",
      "Pratik Chaudhari"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2208.10051",
    "title": "Observer-based Leader-following Consensus for Positive Multi-agent  Systems Over Time-varying Graphs",
    "abstract": " Title: Observer-based Leader-following Consensus for Positive Multi-agent  Systems Over Time-varying Graphs ",
    "url": "https://arxiv.org/abs/2208.10051",
    "authors": [
      "Ruonan Li",
      "Yichen Zhang",
      "Yutao Tang",
      "Shurong Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2208.12227",
    "title": "Community Detection in the Hypergraph SBM: Exact Recovery Given the  Similarity Matrix",
    "abstract": " Comments: To appear at the Conference on Learning Theory (COLT) 2023. Error in footnote page 3 ",
    "url": "https://arxiv.org/abs/2208.12227",
    "authors": [
      "Julia Gaudio",
      "Nirmit Joshi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.12909",
    "title": "Pipeline-Invariant Representation Learning for Neuroimaging",
    "abstract": " Comments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 17 pages ",
    "url": "https://arxiv.org/abs/2208.12909",
    "authors": [
      "Xinhui Li",
      "Alex Fedorov",
      "Mrinal Mathur",
      "Anees Abrol",
      "Gregory Kiar",
      "Sergey Plis",
      "Vince Calhoun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2209.02167",
    "title": "Red Teaming with Mind Reading: White-Box Adversarial Policies Against RL  Agents",
    "abstract": " Comments: Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2209.02167",
    "authors": [
      "Stephen Casper",
      "Taylor Killian",
      "Gabriel Kreiman",
      "Dylan Hadfield-Menell"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.03358",
    "title": "Attacking the Spike: On the Transferability and Security of Spiking  Neural Networks to Adversarial Examples",
    "abstract": " Title: Attacking the Spike: On the Transferability and Security of Spiking  Neural Networks to Adversarial Examples ",
    "url": "https://arxiv.org/abs/2209.03358",
    "authors": [
      "Nuo Xu",
      "Kaleel Mahmood",
      "Haowen Fang",
      "Ethan Rathbun",
      "Caiwen Ding",
      "Wujie Wen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.07881",
    "title": "Model Predictive Robustness of Signal Temporal Logic Predicates",
    "abstract": " Comments: @2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works ",
    "url": "https://arxiv.org/abs/2209.07881",
    "authors": [
      "Yuanfei Lin",
      "Haoxuan Li",
      "Matthias Althoff"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2209.15240",
    "title": "Universal Prompt Tuning for Graph Neural Networks",
    "abstract": " Title: Universal Prompt Tuning for Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2209.15240",
    "authors": [
      "Taoran Fang",
      "Yunchao Zhang",
      "Yang Yang",
      "Chunping Wang",
      "Lei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04193",
    "title": "Predicting fluid-structure interaction with graph neural networks",
    "abstract": " Title: Predicting fluid-structure interaction with graph neural networks ",
    "url": "https://arxiv.org/abs/2210.04193",
    "authors": [
      "Rui Gao",
      "Rajeev K. Jaiman"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05521",
    "title": "Hybrid Inverted Index Is a Robust Accelerator for Dense Retrieval",
    "abstract": " Title: Hybrid Inverted Index Is a Robust Accelerator for Dense Retrieval ",
    "url": "https://arxiv.org/abs/2210.05521",
    "authors": [
      "Peitian Zhang",
      "Zheng Liu",
      "Shitao Xiao",
      "Zhicheng Dou",
      "Jing Yao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.07373",
    "title": "Mind the Labels: Describing Relations in Knowledge Graphs With  Pretrained Models",
    "abstract": " Comments: Long paper at EACL '23. Code and data: this https URL ",
    "url": "https://arxiv.org/abs/2210.07373",
    "authors": [
      "Zden\u011bk Kasner",
      "Ioannis Konstas",
      "Ond\u0159ej Du\u0161ek"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.08577",
    "title": "Stochastic Occupancy Grid Map Prediction in Dynamic Scenes",
    "abstract": " Comments: Accepted by 7th Annual Conference on Robot Learning (CoRL), 2023 ",
    "url": "https://arxiv.org/abs/2210.08577",
    "authors": [
      "Zhanteng Xie",
      "Philip Dames"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.09017",
    "title": "Robust Data-Driven Moving Horizon Estimation for Linear Discrete-Time  Systems",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2210.09017",
    "authors": [
      "Tobias M. Wolff",
      "Victor G. Lopez",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.13179",
    "title": "A simple probabilistic neural network for machine understanding",
    "abstract": " Comments: 34 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2210.13179",
    "authors": [
      "Rongrong Xie",
      "Matteo Marsili"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.03536",
    "title": "Knowledge Graph Embedding: A Survey from the Perspective of  Representation Spaces",
    "abstract": " Comments: 42 pages, 6 figures, 9 tables ",
    "url": "https://arxiv.org/abs/2211.03536",
    "authors": [
      "Jiahang Cao",
      "Jinyuan Fang",
      "Zaiqiao Meng",
      "Shangsong Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2211.07866",
    "title": "Efficient Estimation for Longitudinal Network via Adaptive Merging",
    "abstract": " Comments: 26 pages and 2 figures; appendix including technical proof will be uploaded later ",
    "url": "https://arxiv.org/abs/2211.07866",
    "authors": [
      "Haoran Zhang",
      "Junhui Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10960",
    "title": "CoCoNet: Coupled Contrastive Learning Network with Multi-level Feature  Ensemble for Multi-modality Image Fusion",
    "abstract": " Title: CoCoNet: Coupled Contrastive Learning Network with Multi-level Feature  Ensemble for Multi-modality Image Fusion ",
    "url": "https://arxiv.org/abs/2211.10960",
    "authors": [
      "Jinyuan Liu",
      "Runjia Lin",
      "Guanyao Wu",
      "Risheng Liu",
      "Zhongxuan Luo",
      "Xin Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12421",
    "title": "Data-Driven Network Neuroscience: On Data Collection and Benchmark",
    "abstract": " Title: Data-Driven Network Neuroscience: On Data Collection and Benchmark ",
    "url": "https://arxiv.org/abs/2211.12421",
    "authors": [
      "Jiaxing Xu",
      "Yunhan Yang",
      "David Tse Jung Huang",
      "Sophi Shilpa Gururajapathy",
      "Yiping Ke",
      "Miao Qiao",
      "Alan Wang",
      "Haribalan Kumar",
      "Josh McGeown",
      "Eryn Kwon"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2212.02042",
    "title": "Refiner: Data Refining against Gradient Leakage Attacks in Federated  Learning",
    "abstract": " Comments: under review ",
    "url": "https://arxiv.org/abs/2212.02042",
    "authors": [
      "Mingyuan Fan",
      "Cen Chen",
      "Chengyu Wang",
      "Xiaodan Li",
      "Wenmeng Zhou",
      "Jun Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.09771",
    "title": "Automation and AI Technology in Surface Mining With a Brief Introduction  to Open-Pit Operations in the Pilbara",
    "abstract": " Comments: Accepted manuscript. Paper provides insights on state-of-the-art technologies and future trends. Keywords: Mining automation, robotics, intelligent systems, machine learning, remote sensing, geostatistics, planning, scheduling, optimization, modelling, geology, complex systems. Document: 20 pages, 5 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2301.09771",
    "authors": [
      "Raymond Leung",
      "Andrew J Hill",
      "Arman Melkumyan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "General Literature (cs.GL)"
    ]
  },
  {
    "id": "arXiv:2301.11375",
    "title": "Neural networks learn to magnify areas near decision boundaries",
    "abstract": " Comments: 93 pages, 48 figures ",
    "url": "https://arxiv.org/abs/2301.11375",
    "authors": [
      "Jacob A. Zavatone-Veth",
      "Sheng Yang",
      "Julian A. Rubinfien",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.13629",
    "title": "DiffSTG: Probabilistic Spatio-Temporal Graph Forecasting with Denoising  Diffusion Models",
    "abstract": " Comments: Accepted to the 31st ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems ",
    "url": "https://arxiv.org/abs/2301.13629",
    "authors": [
      "Haomin Wen",
      "Youfang Lin",
      "Yutong Xia",
      "Huaiyu Wan",
      "Qingsong Wen",
      "Roger Zimmermann",
      "Yuxuan Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.01474",
    "title": "Defensive ML: Defending Architectural Side-channels with Adversarial  Obfuscation",
    "abstract": " Comments: Preprint. Under review ",
    "url": "https://arxiv.org/abs/2302.01474",
    "authors": [
      "Hyoungwook Nam",
      "Raghavendra Pradyumna Pothukuchi",
      "Bo Li",
      "Nam Sung Kim",
      "Josep Torrellas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02088",
    "title": "AV-NeRF: Learning Neural Fields for Real-World Audio-Visual Scene  Synthesis",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2302.02088",
    "authors": [
      "Susan Liang",
      "Chao Huang",
      "Yapeng Tian",
      "Anurag Kumar",
      "Chenliang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2302.09127",
    "title": "Robust Pseudo-Markets for Reusable Public Resources",
    "abstract": " Title: Robust Pseudo-Markets for Reusable Public Resources ",
    "url": "https://arxiv.org/abs/2302.09127",
    "authors": [
      "Siddhartha Banerjee",
      "Giannis Fikioris",
      "\u00c9va Tardos"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2302.09422",
    "title": "Neural Attention Memory",
    "abstract": " Comments: Preprint. Under review ",
    "url": "https://arxiv.org/abs/2302.09422",
    "authors": [
      "Hyoungwook Nam",
      "Seung Byum Seo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.11668",
    "title": "Graphs with minimum fractional domatic number",
    "abstract": " Title: Graphs with minimum fractional domatic number ",
    "url": "https://arxiv.org/abs/2302.11668",
    "authors": [
      "Maximilien Gadouleau",
      "Nathaniel Harms",
      "George B. Mertzios",
      "Viktor Zamaraev"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2303.01310",
    "title": "Learning Language-Conditioned Deformable Object Manipulation with Graph  Dynamics",
    "abstract": " Comments: submitted to ICRA 2024 ",
    "url": "https://arxiv.org/abs/2303.01310",
    "authors": [
      "Kai Mo",
      "Yuhong Deng",
      "Chongkun Xia",
      "Xueqian Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.04038",
    "title": "Root Cause Identification for Collective Anomalies in Time Series given  an Acyclic Summary Causal Graph with Loops",
    "abstract": " Comments: Proceedings of the 26th International Conference on Artificial Intelligence and Statistics (AISTATS) 2023, Valencia, Spain ",
    "url": "https://arxiv.org/abs/2303.04038",
    "authors": [
      "Charles K. Assaad",
      "Imad Ez-zejjari",
      "Lei Zan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.07312",
    "title": "Enhancing LiDAR performance: Robust De-skewing Exclusively Relying on  Range Measurements",
    "abstract": " Comments: 6 pages , 5 figures ",
    "url": "https://arxiv.org/abs/2303.07312",
    "authors": [
      "Omar Salem",
      "Emanuele Giacomini",
      "Leonardo Brizi",
      "Luca Di Giammarino",
      "Giorgio Grisetti"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.09639",
    "title": "Neural Architecture Search for Effective Teacher-Student Knowledge  Transfer in Language Models",
    "abstract": " Comments: 11 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2303.09639",
    "authors": [
      "Aashka Trivedi",
      "Takuma Udagawa",
      "Michele Merler",
      "Rameswar Panda",
      "Yousef El-Kurdi",
      "Bishwaranjan Bhattacharjee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.18201",
    "title": "TPMCF: Temporal QoS Prediction using Multi-Source Collaborative Features",
    "abstract": " Comments: 10 Pages, 7 figures ",
    "url": "https://arxiv.org/abs/2303.18201",
    "authors": [
      "Suraj Kumar",
      "Soumi Chattopadhyay",
      "Chandranath Adak"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.00485",
    "title": "Graph Mining for Cybersecurity: A Survey",
    "abstract": " Title: Graph Mining for Cybersecurity: A Survey ",
    "url": "https://arxiv.org/abs/2304.00485",
    "authors": [
      "Bo Yan",
      "Cheng Yang",
      "Chuan Shi",
      "Yong Fang",
      "Qi Li",
      "Yanfang Ye",
      "Junping Du"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2304.01492",
    "title": "A Unified Contrastive Transfer Framework with Propagation Structure for  Boosting Low-Resource Rumor Detection",
    "abstract": " Comments: An extension of the first contrastive approach for low-resource rumor detection (arXiv:2204.08143) ",
    "url": "https://arxiv.org/abs/2304.01492",
    "authors": [
      "Hongzhan Lin",
      "Jing Ma",
      "Ruichao Yang",
      "Zhiwei Yang",
      "Mingfei Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2304.04403",
    "title": "H2RBox-v2: Incorporating Symmetry for Boosting Horizontal Box Supervised  Oriented Object Detection",
    "abstract": " Comments: 15 pages, 4 figures, 11 tables, accepted by NeurIPS'23, the source code is available at this https URL ",
    "url": "https://arxiv.org/abs/2304.04403",
    "authors": [
      "Yi Yu",
      "Xue Yang",
      "Qingyun Li",
      "Yue Zhou",
      "Gefan Zhang",
      "Feipeng Da",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.08799",
    "title": "Self-Supervised 3D Action Representation Learning with Skeleton Cloud  Colorization",
    "abstract": " Comments: Accepted by TPAMI. This work is an extension of our ICCV 2021 paper [arXiv:2108.01959] this https URL ",
    "url": "https://arxiv.org/abs/2304.08799",
    "authors": [
      "Siyuan Yang",
      "Jun Liu",
      "Shijian Lu",
      "Er Meng Hwa",
      "Yongjian Hu",
      "Alex C. Kot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.01074",
    "title": "Physical Adversarial Attacks for Surveillance: A Survey",
    "abstract": " Comments: This paper has been accepted for publication in T-NNLS ",
    "url": "https://arxiv.org/abs/2305.01074",
    "authors": [
      "Kien Nguyen",
      "Tharindu Fernando",
      "Clinton Fookes",
      "Sridha Sridharan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.01572",
    "title": "H2CGL: Modeling Dynamics of Citation Network for Impact Prediction",
    "abstract": " Comments: Accepted by IP&M ",
    "url": "https://arxiv.org/abs/2305.01572",
    "authors": [
      "Guoxiu He",
      "Zhikai Xue",
      "Zhuoren Jiang",
      "Yangyang Kang",
      "Star Zhao",
      "Wei Lu"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.06331",
    "title": "Prior Global Search Stability on Finite Graphs with Uncertainty. May  Greedy Search Win?",
    "abstract": " Title: Prior Global Search Stability on Finite Graphs with Uncertainty. May  Greedy Search Win? ",
    "url": "https://arxiv.org/abs/2305.06331",
    "authors": [
      "Andrey Ananev",
      "Aleksey Khlyupin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2305.10563",
    "title": "HaSa: Hardness and Structure-Aware Contrastive Knowledge Graph Embedding",
    "abstract": " Title: HaSa: Hardness and Structure-Aware Contrastive Knowledge Graph Embedding ",
    "url": "https://arxiv.org/abs/2305.10563",
    "authors": [
      "Honggen Zhang",
      "June Zhang",
      "Igor Molybog"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12074",
    "title": "DisCo: Distilled Student Models Co-training for Semi-supervised Text  Mining",
    "abstract": " Title: DisCo: Distilled Student Models Co-training for Semi-supervised Text  Mining ",
    "url": "https://arxiv.org/abs/2305.12074",
    "authors": [
      "Weifeng Jiang",
      "Qianren Mao",
      "Jianxin Li",
      "Ting Deng",
      "Weiyi Yang",
      "Zheng Wang",
      "Chenghua Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12351",
    "title": "Are Your Explanations Reliable? Investigating the Stability of LIME in  Explaining Text Classifiers by Marrying XAI and Adversarial Attack",
    "abstract": " Comments: 14 pages, 6 figures. Replacement by the updated version to be published in EMNLP 2023 ",
    "url": "https://arxiv.org/abs/2305.12351",
    "authors": [
      "Christopher Burger",
      "Lingwei Chen",
      "Thai Le"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12599",
    "title": "Enhancing Logical Reasoning of Large Language Models through  Logic-Driven Data Augmentation",
    "abstract": " Comments: Accepted for oral presentation at the LLM@IJCAI 2023 non-archival symposium ",
    "url": "https://arxiv.org/abs/2305.12599",
    "authors": [
      "Qiming Bao",
      "Alex Yuxuan Peng",
      "Zhenyun Deng",
      "Wanjun Zhong",
      "Gael Gendron",
      "Timothy Pistotti",
      "Neset Tan",
      "Nathan Young",
      "Yang Chen",
      "Yonghua Zhu",
      "Paul Denny",
      "Michael Witbrock",
      "Jiamou Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12809",
    "title": "Relabeling Minimal Training Subset to Flip a Prediction",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2305.12809",
    "authors": [
      "Jinghan Yang",
      "Linjie Xu",
      "Lequan Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.12870",
    "title": "Lion: Adversarial Distillation of Proprietary Large Language Models",
    "abstract": " Comments: 21 pages, 5 figures, EMNLP 2023 main conference ",
    "url": "https://arxiv.org/abs/2305.12870",
    "authors": [
      "Yuxin Jiang",
      "Chunkit Chan",
      "Mingyang Chen",
      "Wei Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12872",
    "title": "Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a  Bayesian Game",
    "abstract": " Title: Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a  Bayesian Game ",
    "url": "https://arxiv.org/abs/2305.12872",
    "authors": [
      "Simin Li",
      "Jun Guo",
      "Jingqiao Xiu",
      "Ruixiao Xu",
      "Xin Yu",
      "Jiakai Wang",
      "Aishan Liu",
      "Yaodong Yang",
      "Xianglong Liu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2305.12883",
    "title": "Prediction Risk and Estimation Risk of the Ridgeless Least Squares  Estimator under General Assumptions on Regression Errors",
    "abstract": " Comments: 17 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2305.12883",
    "authors": [
      "Sungyoon Lee",
      "Sokbae Lee"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.13954",
    "title": "Robust Prompt Optimization for Large Language Models Against  Distribution Shifts",
    "abstract": " Title: Robust Prompt Optimization for Large Language Models Against  Distribution Shifts ",
    "url": "https://arxiv.org/abs/2305.13954",
    "authors": [
      "Moxin Li",
      "Wenjie Wang",
      "Fuli Feng",
      "Yixin Cao",
      "Jizhi Zhang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14950",
    "title": "Adversarial Demonstration Attacks on Large Language Models",
    "abstract": " Title: Adversarial Demonstration Attacks on Large Language Models ",
    "url": "https://arxiv.org/abs/2305.14950",
    "authors": [
      "Jiongxiao Wang",
      "Zichen Liu",
      "Keun Hee Park",
      "Zhuojun Jiang",
      "Zhaoheng Zheng",
      "Zhuofeng Wu",
      "Muhao Chen",
      "Chaowei Xiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16988",
    "title": "Sharp Bounds for Generalized Causal Sensitivity Analysis",
    "abstract": " Comments: Accepted at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2305.16988",
    "authors": [
      "Dennis Frauen",
      "Valentyn Melnychuk",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17220",
    "title": "VoxDet: Voxel Learning for Novel Instance Detection",
    "abstract": " Comments: 18 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2305.17220",
    "authors": [
      "Bowen Li",
      "Jiashun Wang",
      "Yaoyu Hu",
      "Chen Wang",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.19428",
    "title": "Evaluating geospatial context information for travel mode detection",
    "abstract": " Comments: updated Method and Discussion; accepted by Journal of Transport Geography ",
    "url": "https://arxiv.org/abs/2305.19428",
    "authors": [
      "Ye Hong",
      "Emanuel St\u00fcdeli",
      "Martin Raubal"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.00038",
    "title": "FedCSD: A Federated Learning Based Approach for Code-Smell Detection",
    "abstract": " Comments: 17 pages, 7 figures, Journal paper ",
    "url": "https://arxiv.org/abs/2306.00038",
    "authors": [
      "Sadi Alawadi",
      "Khalid Alkharabsheh",
      "Fahed Alkhabbas",
      "Victor Kebande",
      "Feras M. Awaysheh",
      "Fabio Palomba",
      "Mohammed Awad"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.00893",
    "title": "Efficient Temporal Butterfly Counting and Enumeration on Temporal  Bipartite Graphs",
    "abstract": " Title: Efficient Temporal Butterfly Counting and Enumeration on Temporal  Bipartite Graphs ",
    "url": "https://arxiv.org/abs/2306.00893",
    "authors": [
      "Xinwei Cai",
      "Xiangyu Ke",
      "Kai Wang",
      "Lu Chen",
      "Tianming Zhang",
      "Qing Liu",
      "Yunjun Gao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2306.01323",
    "title": "Demystifying Structural Disparity in Graph Neural Networks: Can One Size  Fit All?",
    "abstract": " Comments: 55 pages, 24 figures. arXiv admin note: text overlap with arXiv:2106.15535 by other authors ",
    "url": "https://arxiv.org/abs/2306.01323",
    "authors": [
      "Haitao Mao",
      "Zhikai Chen",
      "Wei Jin",
      "Haoyu Han",
      "Yao Ma",
      "Tong Zhao",
      "Neil Shah",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02558",
    "title": "Multi-View Representation is What You Need for Point-Cloud Pre-Training",
    "abstract": " Comments: 14 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2306.02558",
    "authors": [
      "Siming Yan",
      "Chen Song",
      "Youkang Kong",
      "Qixing Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.04324",
    "title": "GCT-TTE: Graph Convolutional Transformer for Travel Time Estimation",
    "abstract": " Comments: 17 pages, 7 figures, 4 tables; supplementary included; accepted in Journal of Big Data ",
    "url": "https://arxiv.org/abs/2306.04324",
    "authors": [
      "Vladimir Mashurov",
      "Vaagn Chopurian",
      "Vadim Porvatov",
      "Arseny Ivanov",
      "Natalia Semenova"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.06335",
    "title": "How to Learn and Generalize From Three Minutes of Data:  Physics-Constrained and Uncertainty-Aware Neural Stochastic Differential  Equations",
    "abstract": " Comments: Final submission to CoRL 2023 ",
    "url": "https://arxiv.org/abs/2306.06335",
    "authors": [
      "Franck Djeumou",
      "Cyrus Neary",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2306.09112",
    "title": "On Certified Generalization in Structured Prediction",
    "abstract": " Title: On Certified Generalization in Structured Prediction ",
    "url": "https://arxiv.org/abs/2306.09112",
    "authors": [
      "Bastian Boll",
      "Christoph Schn\u00f6rr"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.09124",
    "title": "DIFFender: Diffusion-Based Adversarial Defense against Patch Attacks",
    "abstract": " Title: DIFFender: Diffusion-Based Adversarial Defense against Patch Attacks ",
    "url": "https://arxiv.org/abs/2306.09124",
    "authors": [
      "Caixin Kang",
      "Yinpeng Dong",
      "Zhengyi Wang",
      "Shouwei Ruan",
      "Yubo Chen",
      "Hang Su",
      "Xingxing Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.09597",
    "title": "Clickbait Detection via Large Language Models",
    "abstract": " Title: Clickbait Detection via Large Language Models ",
    "url": "https://arxiv.org/abs/2306.09597",
    "authors": [
      "Han Wang",
      "Yi Zhu",
      "Ye Wang",
      "Yun Li",
      "Yunhao Yuan",
      "Jipeng Qiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.10792",
    "title": "NAR-Former V2: Rethinking Transformer for Universal Neural Network  Representation Learning",
    "abstract": " Comments: 9 pages, 2 figures, 6 tables. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2306.10792",
    "authors": [
      "Yun Yi",
      "Haokui Zhang",
      "Rong Xiao",
      "Nannan Wang",
      "Xiaoyu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.11626",
    "title": "Regularized Robust MDPs and Risk-Sensitive MDPs: Equivalence, Policy  Gradient, and Sample Complexity",
    "abstract": " Title: Regularized Robust MDPs and Risk-Sensitive MDPs: Equivalence, Policy  Gradient, and Sample Complexity ",
    "url": "https://arxiv.org/abs/2306.11626",
    "authors": [
      "Runyu Zhang",
      "Yang Hu",
      "Na Li"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.00743",
    "title": "Joint Power Allocation and Beamforming for Active IRS-aided Directional  Modulation Network",
    "abstract": " Title: Joint Power Allocation and Beamforming for Active IRS-aided Directional  Modulation Network ",
    "url": "https://arxiv.org/abs/2307.00743",
    "authors": [
      "Rongen Dong",
      "Feng Shu",
      "Yongzhao Li",
      "Jun Li",
      "Yongpeng Wu",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2307.06422",
    "title": "Differentially Private Decoupled Graph Convolutions for Multigranular  Topology Protection",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2307.06422",
    "authors": [
      "Eli Chien",
      "Wei-Ning Chen",
      "Chao Pan",
      "Pan Li",
      "Ayfer \u00d6zg\u00fcr",
      "Olgica Milenkovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.06527",
    "title": "Free-Form Composition Networks for Egocentric Action Recognition",
    "abstract": " Title: Free-Form Composition Networks for Egocentric Action Recognition ",
    "url": "https://arxiv.org/abs/2307.06527",
    "authors": [
      "Haoran Wang",
      "Qinghua Cheng",
      "Baosheng Yu",
      "Yibing Zhan",
      "Dapeng Tao",
      "Liang Ding",
      "Haibin Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12510",
    "title": "An Empirical Evaluation of Temporal Graph Benchmark",
    "abstract": " Comments: in progress, more results are added ",
    "url": "https://arxiv.org/abs/2307.12510",
    "authors": [
      "Le Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12750",
    "title": "DawnIK: Decentralized Collision-Aware Inverse Kinematics Solver for  Heterogeneous Multi-Arm Systems",
    "abstract": " Comments: Salih Marangoz and Rohit Menon have equal authorship ",
    "url": "https://arxiv.org/abs/2307.12750",
    "authors": [
      "Salih Marangoz",
      "Rohit Menon",
      "Nils Dengler",
      "Maren Bennewitz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.12906",
    "title": "QAmplifyNet: Pushing the Boundaries of Supply Chain Backorder Prediction  Using Interpretable Hybrid Quantum-Classical Neural Network",
    "abstract": " Title: QAmplifyNet: Pushing the Boundaries of Supply Chain Backorder Prediction  Using Interpretable Hybrid Quantum-Classical Neural Network ",
    "url": "https://arxiv.org/abs/2307.12906",
    "authors": [
      "Md Abrar Jahin",
      "Md Sakib Hossain Shovon",
      "Md. Saiful Islam",
      "Jungpil Shin",
      "M. F. Mridha",
      "Yuichi Okuyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2307.13345",
    "title": "Do humans and Convolutional Neural Networks attend to similar areas  during scene classification: Effects of task and image type",
    "abstract": " Title: Do humans and Convolutional Neural Networks attend to similar areas  during scene classification: Effects of task and image type ",
    "url": "https://arxiv.org/abs/2307.13345",
    "authors": [
      "Romy M\u00fcller",
      "Marcel D\u00fcrschmidt",
      "Julian Ullrich",
      "Carsten Knoll",
      "Sascha Weber",
      "Steffen Seitz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2307.14070",
    "title": "PNT-Edge: Towards Robust Edge Detection with Noisy Labels by Learning  Pixel-level Noise Transitions",
    "abstract": " Comments: Accepted by ACM-MM 2023 ",
    "url": "https://arxiv.org/abs/2307.14070",
    "authors": [
      "Wenjie Xuan",
      "Shanshan Zhao",
      "Yu Yao",
      "Juhua Liu",
      "Tongliang Liu",
      "Yixin Chen",
      "Bo Du",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.14442",
    "title": "Neural Schr\u00f6dinger Bridge with Sinkhorn Losses: Application to  Data-driven Minimum Effort Control of Colloidal Self-assembly",
    "abstract": " Title: Neural Schr\u00f6dinger Bridge with Sinkhorn Losses: Application to  Data-driven Minimum Effort Control of Colloidal Self-assembly ",
    "url": "https://arxiv.org/abs/2307.14442",
    "authors": [
      "Iman Nodozi",
      "Charlie Yan",
      "Mira Khare",
      "Abhishek Halder",
      "Ali Mesbah"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.01362",
    "title": "Explainable Deep Learning for Tumor Dynamic Modeling and Overall  Survival Prediction using Neural-ODE",
    "abstract": " Comments: 33 pages, 4 Figures and 2 Tables. Includes Supplementary Materials ",
    "url": "https://arxiv.org/abs/2308.01362",
    "authors": [
      "Mark Laurie",
      "James Lu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.03467",
    "title": "RoadScan: A Novel and Robust Transfer Learning Framework for Autonomous  Pothole Detection in Roads",
    "abstract": " Comments: 6 pages, 5 figures, Accepted at the IEEE 7th Conference on Communication and Information Technology 2023 ",
    "url": "https://arxiv.org/abs/2308.03467",
    "authors": [
      "Guruprasad Parasnis",
      "Anmol Chokshi",
      "Vansh Jain",
      "Kailas Devadkar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.07774",
    "title": "A Graph Encoder-Decoder Network for Unsupervised Anomaly Detection",
    "abstract": " Title: A Graph Encoder-Decoder Network for Unsupervised Anomaly Detection ",
    "url": "https://arxiv.org/abs/2308.07774",
    "authors": [
      "Mahsa Mesgaran",
      "A. Ben Hamza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.08925",
    "title": "A White-Box False Positive Adversarial Attack Method on Contrastive  Loss-Based Offline Handwritten Signature Verification Models",
    "abstract": " Comments: 8 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2308.08925",
    "authors": [
      "Zhongliang Guo",
      "Weiye Li",
      "Yifei Qian",
      "Ognjen Arandjelovi\u0107",
      "Lei Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.09487",
    "title": "Poison Dart Frog: A Clean-Label Attack with Low Poisoning Rate and High  Attack Success Rate in the Absence of Training Data",
    "abstract": " Title: Poison Dart Frog: A Clean-Label Attack with Low Poisoning Rate and High  Attack Success Rate in the Absence of Training Data ",
    "url": "https://arxiv.org/abs/2308.09487",
    "authors": [
      "Binhao Ma",
      "Jiahui Wang",
      "Dejun Wang",
      "Bo Meng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.09678",
    "title": "PoSynDA: Multi-Hypothesis Pose Synthesis Domain Adaptation for Robust 3D  Human Pose Estimation",
    "abstract": " Comments: Accepted to ACM Multimedia 2023; 10 pages, 4 figures, 8 tables; the code is at this https URL ",
    "url": "https://arxiv.org/abs/2308.09678",
    "authors": [
      "Hanbing Liu",
      "Jun-Yan He",
      "Zhi-Qi Cheng",
      "Wangmeng Xiang",
      "Qize Yang",
      "Wenhao Chai",
      "Gaoang Wang",
      "Xu Bao",
      "Bin Luo",
      "Yifeng Geng",
      "Xuansong Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2308.10335",
    "title": "A Study on Robustness and Reliability of Large Language Model Code  Generation",
    "abstract": " Title: A Study on Robustness and Reliability of Large Language Model Code  Generation ",
    "url": "https://arxiv.org/abs/2308.10335",
    "authors": [
      "Li Zhong",
      "Zilong Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2308.16422",
    "title": "DECODE: DilatEd COnvolutional neural network for Detecting  Extreme-mass-ratio inspirals",
    "abstract": " Comments: 13 pages, 5 figures, and 2 tables ",
    "url": "https://arxiv.org/abs/2308.16422",
    "authors": [
      "Tianyu Zhao",
      "Yue Zhou",
      "Ruijun Shi",
      "Zhoujian Cao",
      "Zhixiang Ren"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ]
  },
  {
    "id": "arXiv:2308.16518",
    "title": "MS23D: A 3D Object Detection Method Using Multi-Scale Semantic Feature  Points to Construct 3D Feature Layer",
    "abstract": " Title: MS23D: A 3D Object Detection Method Using Multi-Scale Semantic Feature  Points to Construct 3D Feature Layer ",
    "url": "https://arxiv.org/abs/2308.16518",
    "authors": [
      "Yongxin Shao",
      "Aihong Tan",
      "Tianhong Yan",
      "Zhetao Sun",
      "Yiyang Zhang",
      "Jiaxin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.01429",
    "title": "Adapting Segment Anything Model for Change Detection in HR Remote  Sensing Images",
    "abstract": " Title: Adapting Segment Anything Model for Change Detection in HR Remote  Sensing Images ",
    "url": "https://arxiv.org/abs/2309.01429",
    "authors": [
      "Lei Ding",
      "Kun Zhu",
      "Daifeng Peng",
      "Hao Tang",
      "Kuiwu Yang",
      "Lorenzo Bruzzone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.02772",
    "title": "Improving Code Generation by Dynamic Temperature Sampling",
    "abstract": " Title: Improving Code Generation by Dynamic Temperature Sampling ",
    "url": "https://arxiv.org/abs/2309.02772",
    "authors": [
      "Yuqi Zhu",
      "Jia Li",
      "Ge Li",
      "YunFei Zhao",
      "Jia Li",
      "Zhi Jin",
      "Hong Mei"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.03038",
    "title": "Cellular Wireless Networks in the Upper Mid-Band",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2309.03038",
    "authors": [
      "Seongjoon Kang",
      "Marco Mezzavilla",
      "Sundeep Rangan",
      "Arjuna Madanayake",
      "Satheesh Bojja Venkatakrishnan",
      "Gregory Hellbourg",
      "Monisha Ghosh",
      "Hamed Rahmani",
      "Aditya Dhananjay"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.04761",
    "title": "A Comprehensive Survey on Deep Learning Techniques in Educational Data  Mining",
    "abstract": " Comments: 21 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2309.04761",
    "authors": [
      "Yuanguo Lin",
      "Hong Chen",
      "Wei Xia",
      "Fan Lin",
      "Pengcheng Wu",
      "Zongyue Wang",
      "Yong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2309.09378",
    "title": "Dynamics of Fisheries in the Azores Islands: A Network Analysis Approach",
    "abstract": " Title: Dynamics of Fisheries in the Azores Islands: A Network Analysis Approach ",
    "url": "https://arxiv.org/abs/2309.09378",
    "authors": [
      "Brenda Nogueira",
      "Ana Torres",
      "Nuno Moniz",
      "Gui M. Menezes"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2309.09733",
    "title": "Replication: Contrastive Learning and Data Augmentation in Traffic  Classification Using a Flowpic Input Representation",
    "abstract": " Comments: to appear at ACM Internet Traffic Measurement (IMC) 2023, replication track ",
    "url": "https://arxiv.org/abs/2309.09733",
    "authors": [
      "Alessandro Finamore",
      "Chao Wang",
      "Jonatan Krolikowski",
      "Jose M. Navarro",
      "Fuxing Chen",
      "Dario Rossi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2309.10462",
    "title": "Computing the Weight Distribution of the Binary Reed-Muller Code  ${\\mathcal R} (4,9)$",
    "abstract": " Title: Computing the Weight Distribution of the Binary Reed-Muller Code  ${\\mathcal R} (4,9)$ ",
    "url": "https://arxiv.org/abs/2309.10462",
    "authors": [
      "Miroslav Markov",
      "Yuri Borissov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2309.11751",
    "title": "How Robust is Google's Bard to Adversarial Image Attacks?",
    "abstract": " Comments: Technical report ",
    "url": "https://arxiv.org/abs/2309.11751",
    "authors": [
      "Yinpeng Dong",
      "Huanran Chen",
      "Jiawei Chen",
      "Zhengwei Fang",
      "Xiao Yang",
      "Yichi Zhang",
      "Yu Tian",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.12819",
    "title": "Doubly Robust Proximal Causal Learning for Continuous Treatments",
    "abstract": " Comments: Preprint, under review ",
    "url": "https://arxiv.org/abs/2309.12819",
    "authors": [
      "Yong Wu",
      "Yanwei Fu",
      "Shouyan Wang",
      "Xinwei Sun"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13567",
    "title": "MentaLLaMA: Interpretable Mental Health Analysis on Social Media with  Large Language Models",
    "abstract": " Comments: Work in progress ",
    "url": "https://arxiv.org/abs/2309.13567",
    "authors": [
      "Kailai Yang",
      "Tianlin Zhang",
      "Ziyan Kuang",
      "Qianqian Xie",
      "Sophia Ananiadou",
      "Jimin Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.15642",
    "title": "Efficient tensor network simulation of IBM's largest quantum processors",
    "abstract": " Comments: 6 pages, 6 figures, plus Supplementary Material of 1 page with 1 table. Revised version ",
    "url": "https://arxiv.org/abs/2309.15642",
    "authors": [
      "Siddhartha Patra",
      "Saeed S. Jahromi",
      "Sukhbinder Singh",
      "Roman Orus"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.15757",
    "title": "Latent Graphs for Semi-Supervised Learning on Biomedical Tabular Data",
    "abstract": " Comments: Accepted at IJCLR 2023 ",
    "url": "https://arxiv.org/abs/2309.15757",
    "authors": [
      "Boshko Koloski",
      "Nada Lavra\u010d",
      "Senja Pollak",
      "Bla\u017e \u0160krlj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.17281",
    "title": "Information Flow in Self-Supervised Learning",
    "abstract": " Title: Information Flow in Self-Supervised Learning ",
    "url": "https://arxiv.org/abs/2309.17281",
    "authors": [
      "Zhiquan Tan",
      "Jingqin Yang",
      "Weiran Huang",
      "Yang Yuan",
      "Yifan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00029",
    "title": "Adversarial Driving Behavior Generation Incorporating Human Risk  Cognition for Autonomous Vehicle Evaluation",
    "abstract": " Comments: We find there is expression error in III.A. A correction edition will be offered ",
    "url": "https://arxiv.org/abs/2310.00029",
    "authors": [
      "Zhen Liu",
      "Hang Gao",
      "Hao Ma",
      "Shuo Cai",
      "Yunfeng Hu",
      "Ting Qu",
      "Hong Chen",
      "Xun Gong"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.02156",
    "title": "Probabilistically Rewired Message-Passing Neural Networks",
    "abstract": " Title: Probabilistically Rewired Message-Passing Neural Networks ",
    "url": "https://arxiv.org/abs/2310.02156",
    "authors": [
      "Chendi Qian",
      "Andrei Manolache",
      "Kareem Ahmed",
      "Zhe Zeng",
      "Guy Van den Broeck",
      "Mathias Niepert",
      "Christopher Morris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.02234",
    "title": "MIS-AVoiDD: Modality Invariant and Specific Representation for  Audio-Visual Deepfake Detection",
    "abstract": " Comments: 8 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2310.02234",
    "authors": [
      "Vinaya Sree Katamneni",
      "Ajita Rattani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.02772",
    "title": "Spike Accumulation Forwarding for Effective Training of Spiking Neural  Networks",
    "abstract": " Comments: 10 pages, 5 figures, Appendix:8 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2310.02772",
    "authors": [
      "Ryuji Saiin",
      "Tomoya Shirakawa",
      "Sota Yoshihara",
      "Yoshihide Sawada",
      "Hiroyuki Kusumoto"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.02956",
    "title": "Credit card score prediction using machine learning models: A new  dataset",
    "abstract": " Title: Credit card score prediction using machine learning models: A new  dataset ",
    "url": "https://arxiv.org/abs/2310.02956",
    "authors": [
      "Anas Arram",
      "Masri Ayob",
      "Musatafa Abbas Abbood Albadr",
      "Alaa Sulaiman",
      "Dheeb Albashish"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.03166",
    "title": "Raze to the Ground: Query-Efficient Adversarial HTML Attacks on  Machine-Learning Phishing Webpage Detectors",
    "abstract": " Comments: Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security (AISec '23), November 30, 2023, Copenhagen, Denmark ",
    "url": "https://arxiv.org/abs/2310.03166",
    "authors": [
      "Biagio Montaruli",
      "Luca Demetrio",
      "Maura Pintor",
      "Luca Compagna",
      "Davide Balzarotti",
      "Battista Biggio"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.03365",
    "title": "Swin-Tempo: Temporal-Aware Lung Nodule Detection in CT Scans as Video  Sequences Using Swin Transformer-Enhanced UNet",
    "abstract": " Title: Swin-Tempo: Temporal-Aware Lung Nodule Detection in CT Scans as Video  Sequences Using Swin Transformer-Enhanced UNet ",
    "url": "https://arxiv.org/abs/2310.03365",
    "authors": [
      "Hossein Jafari",
      "Karim Faez",
      "Hamidreza Amindavar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.03431",
    "title": "Robust Zero Level-Set Extraction from Unsigned Distance Fields Based on  Double Covering",
    "abstract": " Comments: accepted to ACM Transactions on Graphics (SIGGRAPH Asia 2023) ",
    "url": "https://arxiv.org/abs/2310.03431",
    "authors": [
      "Fei Hou",
      "Xuhui Chen",
      "Wencheng Wang",
      "Hong Qin",
      "Ying He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.04364",
    "title": "Enhanced Backpressure Routing Using Wireless Link Features",
    "abstract": " Comments: 5 pages, 5 figures, accepted to IEEE CAMSAP 2023. arXiv admin note: text overlap with arXiv:2211.10748 ",
    "url": "https://arxiv.org/abs/2310.04364",
    "authors": [
      "Zhongyuan Zhao",
      "Gunjan Verma",
      "Ananthram Swami",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.04482",
    "title": "EMOFM: Ensemble MLP mOdel with Feature-based Mixers for Click-Through  Rate Prediction",
    "abstract": " Title: EMOFM: Ensemble MLP mOdel with Feature-based Mixers for Click-Through  Rate Prediction ",
    "url": "https://arxiv.org/abs/2310.04482",
    "authors": [
      "Yujian Betterest Li",
      "Kai Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05318",
    "title": "Resolving the Imbalance Issue in Hierarchical Disciplinary Topic  Inference via LLM-based Data Augmentation",
    "abstract": " Comments: 6 pages, accepted by ICDM 2023 ",
    "url": "https://arxiv.org/abs/2310.05318",
    "authors": [
      "Xunxin Cai",
      "Meng Xiao",
      "Zhiyuan Ning",
      "Yuanchun Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.05351",
    "title": "Generalized Neural Collapse for a Large Number of Classes",
    "abstract": " Comments: 32 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2310.05351",
    "authors": [
      "Jiachen Jiang",
      "Jinxin Zhou",
      "Peng Wang",
      "Qing Qu",
      "Dustin Mixon",
      "Chong You",
      "Zhihui Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2310.05446",
    "title": "RetSeg: Retention-based Colorectal Polyps Segmentation Network",
    "abstract": " Comments: Updated version with a PDF ",
    "url": "https://arxiv.org/abs/2310.05446",
    "authors": [
      "Khaled ELKarazle",
      "Valliappan Raman",
      "Caslon Chua",
      "Patrick Then"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05483",
    "title": "Geometry-Guided Ray Augmentation for Neural Surface Reconstruction with  Sparse Views",
    "abstract": " Title: Geometry-Guided Ray Augmentation for Neural Surface Reconstruction with  Sparse Views ",
    "url": "https://arxiv.org/abs/2310.05483",
    "authors": [
      "Jiawei Yao",
      "Tong Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.06446",
    "title": "Rule Mining for Correcting Classification Models",
    "abstract": " Title: Rule Mining for Correcting Classification Models ",
    "url": "https://arxiv.org/abs/2310.06446",
    "authors": [
      "Hirofumi Suzuki",
      "Hiroaki Iwashita",
      "Takuya Takagi",
      "Yuta Fujishige",
      "Satoshi Hara"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.06511",
    "title": "Self-Supervised Dataset Distillation for Transfer Learning",
    "abstract": " Title: Self-Supervised Dataset Distillation for Transfer Learning ",
    "url": "https://arxiv.org/abs/2310.06511",
    "authors": [
      "Dong Bok Lee",
      "Seanie Lee",
      "Joonho Ko",
      "Kenji Kawaguchi",
      "Juho Lee",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07248",
    "title": "IBoxCLA: Towards Robust Box-supervised Segmentation of Polyp via  Improved Box-dice and Contrastive Latent-anchors",
    "abstract": " Title: IBoxCLA: Towards Robust Box-supervised Segmentation of Polyp via  Improved Box-dice and Contrastive Latent-anchors ",
    "url": "https://arxiv.org/abs/2310.07248",
    "authors": [
      "Zhiwei Wang",
      "Qiang Hu",
      "Hongkuan Shi",
      "Li He",
      "Man He",
      "Wenxuan Dai",
      "Ting Li",
      "Yitong Zhang",
      "Dun Li",
      "Mei Liu",
      "Qiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07250",
    "title": "Synthesizing Missing MRI Sequences from Available Modalities using  Generative Adversarial Networks in BraTS Dataset",
    "abstract": " Comments: It will be edited and later uploaded ",
    "url": "https://arxiv.org/abs/2310.07250",
    "authors": [
      "Ibrahim Ethem Hamamci"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.07325",
    "title": "An Adversarial Example for Direct Logit Attribution: Memory Management  in gelu-4l",
    "abstract": " Title: An Adversarial Example for Direct Logit Attribution: Memory Management  in gelu-4l ",
    "url": "https://arxiv.org/abs/2310.07325",
    "authors": [
      "James Dao",
      "Yeu-Tong Lau",
      "Can Rager",
      "Jett Janiak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07437",
    "title": "A Branched Deep Convolutional Network for Forecasting the Occurrence of  Hazes in Paris using Meteorological Maps with Different Characteristic  Spatial Scales",
    "abstract": " Title: A Branched Deep Convolutional Network for Forecasting the Occurrence of  Hazes in Paris using Meteorological Maps with Different Characteristic  Spatial Scales ",
    "url": "https://arxiv.org/abs/2310.07437",
    "authors": [
      "Chien Wang"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07678",
    "title": "Explainable Image Similarity: Integrating Siamese Networks and Grad-CAM",
    "abstract": " Comments: The manuscript has been accepted for publication in \"Journal of Imaging\" ",
    "url": "https://arxiv.org/abs/2310.07678",
    "authors": [
      "Ioannis E. Livieris",
      "Emmanuel Pintelas",
      "Niki Kiriakidou",
      "Panagiotis Pintelas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07786",
    "title": "Non-Stationary Contextual Bandit Learning via Neural Predictive Ensemble  Sampling",
    "abstract": " Title: Non-Stationary Contextual Bandit Learning via Neural Predictive Ensemble  Sampling ",
    "url": "https://arxiv.org/abs/2310.07786",
    "authors": [
      "Zheqing Zhu",
      "Yueyang Liu",
      "Xu Kuang",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.08139",
    "title": "DualAug: Exploiting Additional Heavy Augmentation with OOD Data  Rejection",
    "abstract": " Comments: 14 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2310.08139",
    "authors": [
      "Zehao Wang",
      "Yiwen Guo",
      "Qizhang Li",
      "Guanglei Yang",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.08328",
    "title": "Transport-Hub-Aware Spatial-Temporal Adaptive Graph Transformer for  Traffic Flow Prediction",
    "abstract": " Comments: 11 pages, 4 figures. Spatial self-attention of this work extends AAAI23 - PDFormer(arXiv:2301.07945) by other authors, cited as Ref. [17]. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2310.08328",
    "authors": [
      "Xiao Xu",
      "Lei Zhang",
      "Bailong Liu",
      "Zhizhen Liang",
      "Xuefei Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.08384",
    "title": "Towards Running Time Analysis of Interactive Multi-objective  Evolutionary Algorithms",
    "abstract": " Title: Towards Running Time Analysis of Interactive Multi-objective  Evolutionary Algorithms ",
    "url": "https://arxiv.org/abs/2310.08384",
    "authors": [
      "Tianhao Lu",
      "Chao Bian",
      "Chao Qian"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.08421",
    "title": "SegLoc: Novel Visual Self-supervised Learning Scheme for Dense  Prediction Tasks of Security Inspection X-ray Images",
    "abstract": " Title: SegLoc: Novel Visual Self-supervised Learning Scheme for Dense  Prediction Tasks of Security Inspection X-ray Images ",
    "url": "https://arxiv.org/abs/2310.08421",
    "authors": [
      "Shervin Halat",
      "Mohammad Rahmati",
      "Ehsan Nazerfard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.08459",
    "title": "A Survey of Heterogeneous Transfer Learning",
    "abstract": " Title: A Survey of Heterogeneous Transfer Learning ",
    "url": "https://arxiv.org/abs/2310.08459",
    "authors": [
      "Runxue Bao",
      "Yiming Sun",
      "Yuhe Gao",
      "Jindong Wang",
      "Qiang Yang",
      "Haifeng Chen",
      "Zhi-Hong Mao",
      "Ye Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.09254",
    "title": "Generative Entropic Neural Optimal Transport To Map Within and Across  Spaces",
    "abstract": " Title: Generative Entropic Neural Optimal Transport To Map Within and Across  Spaces ",
    "url": "https://arxiv.org/abs/2310.09254",
    "authors": [
      "Dominik Klein",
      "Th\u00e9o Uscidda",
      "Fabian Theis",
      "Marco Cuturi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  }
]