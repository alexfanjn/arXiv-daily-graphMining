[
  {
    "id": "arXiv:2310.04424",
    "title": "Stability Analysis of Non-Linear Classifiers using Gene Regulatory  Neural Network for Biological AI",
    "abstract": "The Gene Regulatory Network (GRN) of biological cells governs a number of key functionalities that enables them to adapt and survive through different environmental conditions. Close observation of the GRN shows that the structure and operational principles resembles an Artificial Neural Network (ANN), which can pave the way for the development of Biological Artificial Intelligence. In particular, a gene's transcription and translation process resembles a sigmoidal-like property based on transcription factor inputs. In this paper, we develop a mathematical model of gene-perceptron using a dual-layered transcription-translation chemical reaction model, enabling us to transform a GRN into a Gene Regulatory Neural Network (GRNN). We perform stability analysis for each gene-perceptron within the fully-connected GRNN sub network to determine temporal as well as stable concentration outputs that will result in reliable computing performance. We focus on a non-linear classifier application for the GRNN, where we analyzed generic multi-layer GRNNs as well as E.Coli GRNN that is derived from trans-omic experimental data. Our analysis found that varying the parameters of the chemical reactions can allow us shift the boundaries of the classification region, laying the platform for programmable GRNNs that suit diverse application requirements. ",
    "url": "https://arxiv.org/abs/2310.04424",
    "authors": [
      "Adrian Ratwatte",
      "Samitha Somathilaka",
      "Sasitharan Balasubramaniam",
      "Assaf A. Gilad"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Molecular Networks (q-bio.MN)"
    ]
  },
  {
    "id": "arXiv:2310.04429",
    "title": "NetDiffus: Network Traffic Generation by Diffusion Models through  Time-Series Imaging",
    "abstract": "Network data analytics are now at the core of almost every networking solution. Nonetheless, limited access to networking data has been an enduring challenge due to many reasons including complexity of modern networks, commercial sensitivity, privacy and regulatory constraints. In this work, we explore how to leverage recent advancements in Diffusion Models (DM) to generate synthetic network traffic data. We develop an end-to-end framework - NetDiffus that first converts one-dimensional time-series network traffic into two-dimensional images, and then synthesizes representative images for the original data. We demonstrate that NetDiffus outperforms the state-of-the-art traffic generation methods based on Generative Adversarial Networks (GANs) by providing 66.4% increase in fidelity of the generated data and 18.1% increase in downstream machine learning tasks. We evaluate NetDiffus on seven diverse traffic traces and show that utilizing synthetic data significantly improves traffic fingerprinting, anomaly detection and traffic classification. ",
    "url": "https://arxiv.org/abs/2310.04429",
    "authors": [
      "Nirhoshan Sivaroopan",
      "Dumindu Bandara",
      "Chamara Madarasingha",
      "Guilluame Jourjon",
      "Anura Jayasumana",
      "Kanchana Thilakarathna"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04431",
    "title": "Can neural networks count digit frequency?",
    "abstract": "In this research, we aim to compare the performance of different classical machine learning models and neural networks in identifying the frequency of occurrence of each digit in a given number. It has various applications in machine learning and computer vision, e.g. for obtaining the frequency of a target object in a visual scene. We considered this problem as a hybrid of classification and regression tasks. We carefully create our own datasets to observe systematic differences between different methods. We evaluate each of the methods using different metrics across multiple datasets.The metrics of performance used were the root mean squared error and mean absolute error for regression evaluation, and accuracy for classification performance evaluation. We observe that decision trees and random forests overfit to the dataset, due to their inherent bias, and are not able to generalize well. We also observe that the neural networks significantly outperform the classical machine learning models in terms of both the regression and classification metrics for both the 6-digit and 10-digit number datasets. Dataset and code are available on github. ",
    "url": "https://arxiv.org/abs/2310.04431",
    "authors": [
      "Padmaksh Khandelwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.04440",
    "title": "Facilitating Battery Swapping Services for Freight Trucks with  Spatial-Temporal Demand Prediction",
    "abstract": "Electrifying heavy-duty trucks offers a substantial opportunity to curtail carbon emissions, advancing toward a carbon-neutral future. However, the inherent challenges of limited battery energy and the sheer weight of heavy-duty trucks lead to reduced mileage and prolonged charging durations. Consequently, battery-swapping services emerge as an attractive solution for these trucks. This paper employs a two-fold approach to investigate the potential and enhance the efficacy of such services. Firstly, spatial-temporal demand prediction models are adopted to predict the traffic patterns for the upcoming hours. Subsequently, the prediction guides an optimization module for efficient battery allocation and deployment. Analyzing the heavy-duty truck data on a highway network spanning over 2,500 miles, our model and analysis underscore the value of prediction/machine learning in facilitating future decision-makings. In particular, we find that the initial phase of implementing battery-swapping services favors mobile battery-swapping stations, but as the system matures, fixed-location stations are preferred. ",
    "url": "https://arxiv.org/abs/2310.04440",
    "authors": [
      "Linyu Liu",
      "Zhen Dai",
      "Shiji Song",
      "Xiaocheng Li",
      "Guanting Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.04445",
    "title": "LoFT: Local Proxy Fine-tuning For Improving Transferability Of  Adversarial Attacks Against Large Language Model",
    "abstract": "It has been shown that Large Language Model (LLM) alignments can be circumvented by appending specially crafted attack suffixes with harmful queries to elicit harmful responses. To conduct attacks against private target models whose characterization is unknown, public models can be used as proxies to fashion the attack, with successful attacks being transferred from public proxies to private target models. The success rate of attack depends on how closely the proxy model approximates the private model. We hypothesize that for attacks to be transferrable, it is sufficient if the proxy can approximate the target model in the neighborhood of the harmful query. Therefore, in this paper, we propose \\emph{Local Fine-Tuning (LoFT)}, \\textit{i.e.}, fine-tuning proxy models on similar queries that lie in the lexico-semantic neighborhood of harmful queries to decrease the divergence between the proxy and target models. First, we demonstrate three approaches to prompt private target models to obtain similar queries given harmful queries. Next, we obtain data for local fine-tuning by eliciting responses from target models for the generated similar queries. Then, we optimize attack suffixes to generate attack prompts and evaluate the impact of our local fine-tuning on the attack's success rate. Experiments show that local fine-tuning of proxy models improves attack transferability and increases attack success rate by $39\\%$, $7\\%$, and $0.5\\%$ (absolute) on target models ChatGPT, GPT-4, and Claude respectively. ",
    "url": "https://arxiv.org/abs/2310.04445",
    "authors": [
      "Muhammad Ahmed Shah",
      "Roshan Sharma",
      "Hira Dhamyal",
      "Raphael Olivier",
      "Ankit Shah",
      "Dareen Alharthi",
      "Hazim T Bukhari",
      "Massa Baali",
      "Soham Deshmukh",
      "Michael Kuhlmann",
      "Bhiksha Raj",
      "Rita Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04447",
    "title": "A Survey on Conflict Detection in IoT-based Smart Homes",
    "abstract": "As the adoption of IoT-based smart homes continues to grow, the importance of addressing potential conflicts becomes increasingly vital for ensuring seamless functionality and user satisfaction. In this survey, we introduce a novel conflict taxonomy, complete with formal definitions of each conflict type that may arise within the smart home environment. We design an advanced conflict model to effectively categorize these conflicts, setting the stage for our in-depth review of recent research in the field. By employing our proposed model, we systematically classify conflicts and present a comprehensive overview of cutting-edge conflict detection approaches. This extensive analysis allows us to highlight similarities, clarify significant differences, and uncover prevailing trends in conflict detection techniques. In conclusion, we shed light on open issues and suggest promising avenues for future research to foster accelerated development and deployment of IoT-based smart homes, ultimately enhancing their overall performance and user experience. ",
    "url": "https://arxiv.org/abs/2310.04447",
    "authors": [
      "Bing Huang",
      "Dipankar Chaki",
      "Athman Bouguettaya",
      "Kwok-Yan Lam"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2310.04452",
    "title": "Short text classification with machine learning in the social sciences:  The case of climate change on Twitter",
    "abstract": "To analyse large numbers of texts, social science researchers are increasingly confronting the challenge of text classification. When manual labeling is not possible and researchers have to find automatized ways to classify texts, computer science provides a useful toolbox of machine-learning methods whose performance remains understudied in the social sciences. In this article, we compare the performance of the most widely used text classifiers by applying them to a typical research scenario in social science research: a relatively small labeled dataset with infrequent occurrence of categories of interest, which is a part of a large unlabeled dataset. As an example case, we look at Twitter communication regarding climate change, a topic of increasing scholarly interest in interdisciplinary social science research. Using a novel dataset including 5,750 tweets from various international organizations regarding the highly ambiguous concept of climate change, we evaluate the performance of methods in automatically classifying tweets based on whether they are about climate change or not. In this context, we highlight two main findings. First, supervised machine-learning methods perform better than state-of-the-art lexicons, in particular as class balance increases. Second, traditional machine-learning methods, such as logistic regression and random forest, perform similarly to sophisticated deep-learning methods, whilst requiring much less training time and computational resources. The results have important implications for the analysis of short texts in social science research. ",
    "url": "https://arxiv.org/abs/2310.04452",
    "authors": [
      "Karina Shyrokykh",
      "Maksym Girnyk",
      "Lisa Dellmuth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2310.04455",
    "title": "Inclusive Data Representation in Federated Learning: A Novel Approach  Integrating Textual and Visual Prompt",
    "abstract": "Federated Learning (FL) is often impeded by communication overhead issues. Prompt tuning, as a potential solution, has been introduced to only adjust a few trainable parameters rather than the whole model. However, current single-modality prompt tuning approaches fail to comprehensively portray local clients' data. To overcome this limitation, we present Twin Prompt Federated learning (TPFL), a pioneering solution that integrates both visual and textual modalities, ensuring a more holistic representation of local clients' data characteristics. Furthermore, in order to tackle the data heterogeneity issues, we introduce the Augmented TPFL (ATPFL) employing the contrastive learning to TPFL, which not only enhances the global knowledge acquisition of client models but also fosters the development of robust, compact models. The effectiveness of TPFL and ATPFL is substantiated by our extensive evaluations, consistently showing superior performance compared to all baselines. ",
    "url": "https://arxiv.org/abs/2310.04455",
    "authors": [
      "Zihao Zhao",
      "Zhenpeng Shi",
      "Yang Liu",
      "Wenbo Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.04460",
    "title": "Tuning In to Neural Encoding: Linking Human Brain and Artificial  Supervised Representations of Language",
    "abstract": "To understand the algorithm that supports the human brain's language representation, previous research has attempted to predict neural responses to linguistic stimuli using embeddings generated by artificial neural networks (ANNs), a process known as neural encoding. However, most of these studies have focused on probing neural representations of Germanic languages, such as English, with unsupervised ANNs. In this paper, we propose to bridge the gap between human brain and supervised ANN representations of the Chinese language. Specifically, we investigate how task tuning influences a pretained Transformer for neural encoding and which tasks lead to the best encoding performances. We generate supervised representations on eight Natural Language Understanding (NLU) tasks using prompt-tuning, a technique that is seldom explored in neural encoding for language. We demonstrate that prompt-tuning yields representations that better predict neural responses to Chinese stimuli than traditional fine-tuning on four tasks. Furthermore, we discover that tasks that require a fine-grained processing of concepts and entities lead to representations that are most predictive of brain activation patterns. Additionally, we reveal that the proportion of tuned parameters highly influences the neural encoding performance of fine-tuned models. Overall, our experimental findings could help us better understand the relationship between supervised artificial and brain language representations. ",
    "url": "https://arxiv.org/abs/2310.04460",
    "authors": [
      "Jingyuan Sun",
      "Xiaohan Zhang",
      "Marie-Francine Moens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.04469",
    "title": "Taming Binarized Neural Networks and Mixed-Integer Programs",
    "abstract": "There has been a great deal of recent interest in binarized neural networks, especially because of their explainability. At the same time, automatic differentiation algorithms such as backpropagation fail for binarized neural networks, which limits their applicability. By reformulating the problem of training binarized neural networks as a subadditive dual of a mixed-integer program, we show that binarized neural networks admit a tame representation. This, in turn, makes it possible to use the framework of Bolte et al. for implicit differentiation, which offers the possibility for practical implementation of backpropagation in the context of binarized neural networks. This approach could also be used for a broader class of mixed-integer programs, beyond the training of binarized neural networks, as encountered in symbolic approaches to AI and beyond. ",
    "url": "https://arxiv.org/abs/2310.04469",
    "authors": [
      "Johannes Aspman",
      "Georgios Korpas",
      "Jakub Marecek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2310.04470",
    "title": "Hierarchical Multi-Marginal Optimal Transport for Network Alignment",
    "abstract": "Finding node correspondence across networks, namely multi-network alignment, is an essential prerequisite for joint learning on multiple networks. Despite great success in aligning networks in pairs, the literature on multi-network alignment is sparse due to the exponentially growing solution space and lack of high-order discrepancy measures. To fill this gap, we propose a hierarchical multi-marginal optimal transport framework named HOT for multi-network alignment. To handle the large solution space, multiple networks are decomposed into smaller aligned clusters via the fused Gromov-Wasserstein (FGW) barycenter. To depict high-order relationships across multiple networks, the FGW distance is generalized to the multi-marginal setting, based on which networks can be aligned jointly. A fast proximal point method is further developed with guaranteed convergence to a local optimum. Extensive experiments and analysis show that our proposed HOT achieves significant improvements over the state-of-the-art in both effectiveness and scalability. ",
    "url": "https://arxiv.org/abs/2310.04470",
    "authors": [
      "Zhichen Zeng",
      "Boxin Du",
      "Si Zhang",
      "Yinglong Xia",
      "Zhining Liu",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.04475",
    "title": "Demystifying Embedding Spaces using Large Language Models",
    "abstract": "Embeddings have become a pivotal means to represent complex, multi-faceted information about entities, concepts, and relationships in a condensed and useful format. Nevertheless, they often preclude direct interpretation. While downstream tasks make use of these compressed representations, meaningful interpretation usually requires visualization using dimensionality reduction or specialized machine learning interpretability methods. This paper addresses the challenge of making such embeddings more interpretable and broadly useful, by employing Large Language Models (LLMs) to directly interact with embeddings -- transforming abstract vectors into understandable narratives. By injecting embeddings into LLMs, we enable querying and exploration of complex embedding data. We demonstrate our approach on a variety of diverse tasks, including: enhancing concept activation vectors (CAVs), communicating novel embedded entities, and decoding user preferences in recommender systems. Our work couples the immense information potential of embeddings with the interpretative power of LLMs. ",
    "url": "https://arxiv.org/abs/2310.04475",
    "authors": [
      "Guy Tennenholtz",
      "Yinlam Chow",
      "Chih-Wei Hsu",
      "Jihwan Jeong",
      "Lior Shani",
      "Azamat Tulepbergenov",
      "Deepak Ramachandran",
      "Martin Mladenov",
      "Craig Boutilier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04482",
    "title": "EMOFM: Ensemble MLP mOdel with Feature-based Mixers for Click-Through  Rate Prediction",
    "abstract": "Track one of CTI competition is on click-through rate (CTR) prediction. The dataset contains millions of records and each field-wise feature in a record consists of hashed integers for privacy. For this task, the keys of network-based methods might be type-wise feature extraction and information fusion across different fields. Multi-layer perceptrons (MLPs) are able to extract field feature, but could not efficiently fuse features. Motivated by the natural fusion characteristic of cross attention and the efficiency of transformer-based structures, we propose simple plug-in mixers for field/type-wise feature fusion, and thus construct an field&type-wise ensemble model, namely EMOFM (Ensemble MLP mOdel with Feature-based Mixers). In the experiments, the proposed model is evaluated on the dataset, the optimization process is visualized and ablation studies are explored. It is shown that EMOFM outperforms compared baselines. In the end, we discuss on future work. WARNING: The comparison might not be fair enough since the proposed method is designed for this data in particular while compared methods are not. For example, EMOFM especially takes different types of interactions into consideration while others do not. Anyway, we do hope that the ideas inside our method could help other developers/learners/researchers/thinkers and so on. ",
    "url": "https://arxiv.org/abs/2310.04482",
    "authors": [
      "Yujian Betterest Li",
      "Kai Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.04484",
    "title": "Ada-Instruct: Adapting Instruction Generators for Complex Reasoning",
    "abstract": "Generating diverse and sophisticated instructions for downstream tasks by Large Language Models (LLMs) is pivotal for advancing the effect. Current approaches leverage closed-source LLMs, employing in-context prompting for instruction generation. However, in this paper, we found that in-context prompting cannot generate complex instructions with length $\\ge 100$ for tasks like code completion. To solve this problem, we introduce Ada-Instruct, an adaptive instruction generator developed by fine-tuning open-source LLMs. Our pivotal finding illustrates that fine-tuning open-source LLMs with a mere ten samples generates long instructions that maintain distributional consistency for complex reasoning tasks. We empirically validated Ada-Instruct's efficacy across different applications, including code completion, mathematical reasoning, and commonsense reasoning. The results underscore Ada-Instruct's superiority, evidencing its improvements over its base models, current self-instruct methods, and other state-of-the-art models. ",
    "url": "https://arxiv.org/abs/2310.04484",
    "authors": [
      "Wanyun Cui",
      "Qianle Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.04486",
    "title": "T-Rep: Representation Learning for Time Series using Time-Embeddings",
    "abstract": "Multivariate time series present challenges to standard machine learning techniques, as they are often unlabeled, high dimensional, noisy, and contain missing data. To address this, we propose T-Rep, a self-supervised method to learn time series representations at a timestep granularity. T-Rep learns vector embeddings of time alongside its feature extractor, to extract temporal features such as trend, periodicity, or distribution shifts from the signal. These time-embeddings are leveraged in pretext tasks, to incorporate smooth and fine-grained temporal dependencies in the representations, as well as reinforce robustness to missing data. We evaluate T-Rep on downstream classification, forecasting, and anomaly detection tasks. It is compared to existing self-supervised algorithms for time series, which it outperforms in all three tasks. We test T-Rep in missing data regimes, where it proves more resilient than its counterparts. Finally, we provide latent space visualisation experiments, highlighting the interpretability of the learned representations. ",
    "url": "https://arxiv.org/abs/2310.04486",
    "authors": [
      "Archibald Fraikin",
      "Adrien Bennetot",
      "St\u00e9phanie Allassonni\u00e8re"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.04496",
    "title": "URLOST: Unsupervised Representation Learning without Stationarity or  Topology",
    "abstract": "Unsupervised representation learning has seen tremendous progress but is constrained by its reliance on data modality-specific stationarity and topology, a limitation not found in biological intelligence systems. For instance, human vision processes visual signals derived from irregular and non-stationary sampling lattices yet accurately perceives the geometry of the world. We introduce a novel framework that learns from high-dimensional data lacking stationarity and topology. Our model combines a learnable self-organizing layer, density adjusted spectral clustering, and masked autoencoders. We evaluate its effectiveness on simulated biological vision data, neural recordings from the primary visual cortex, and gene expression datasets. Compared to state-of-the-art unsupervised learning methods like SimCLR and MAE, our model excels at learning meaningful representations across diverse modalities without depending on stationarity or topology. It also outperforms other methods not dependent on these factors, setting a new benchmark in the field. This work represents a step toward unsupervised learning methods that can generalize across diverse high-dimensional data modalities. ",
    "url": "https://arxiv.org/abs/2310.04496",
    "authors": [
      "Zeyu Yun",
      "Juexiao Zhang",
      "Bruno Olshausen",
      "Yann LeCun",
      "Yubei Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04516",
    "title": "Vulnerability Analysis of Nonlinear Control Systems to Stealthy False  Data Injection Attacks",
    "abstract": "In this work, we focus on analyzing vulnerability of nonlinear dynamical control systems to stealthy false data injection attacks on sensors. We start by defining the stealthiness notion in the most general form where an attack is considered stealthy if it would be undetected by any intrusion detector, i.e., any intrusion detector could not do better than a random guess. Depending on the level of attacker's knowledge about the plant model, controller, and the system states, two different attack models are considered. For each attack model, we derive the conditions for which the system will be vulnerable to stealthy impactful attacks, in addition to finding a methodology for designing such sequence of false data injection attacks. When the attacker has complete knowledge about the system, we show that if the closed loop system is incrementally exponentially stable while the open loop plant is incrementally unstable, then the system is vulnerable to stealthy yet impactful attacks on sensors. However, in the second attack model, with less knowledge about the system, additional conditions need to be satisfied and the level of stealthiness depends on the accuracy of attacker's knowledge about the system. We also consider the impact of stealthy attacks on state estimation, and show that if the closed loop control system including the estimator is incrementally stable, then the state estimation in the presence of attack converges to the attack free estimates. Finally, we illustrate our results on numerical case studies. ",
    "url": "https://arxiv.org/abs/2310.04516",
    "authors": [
      "Amir Khazraei",
      "Miroslav Pajic"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.04519",
    "title": "SPADE: Sparsity-Guided Debugging for Deep Neural Networks",
    "abstract": "Interpretability, broadly defined as mechanisms for understanding why and how machine learning models reach their decisions, is one of the key open goals at the intersection of deep learning theory and practice. Towards this goal, multiple tools have been proposed to aid a human examiner in reasoning about a network's behavior in general or on a set of instances. However, the outputs of these tools-such as input saliency maps or neuron visualizations-are frequently difficult for a human to interpret, or even misleading, due, in particular, to the fact that neurons can be multifaceted, i.e., a single neuron can be associated with multiple distinct feature combinations. In this paper, we present a new general approach to address this problem, called SPADE, which, given a trained model and a target sample, uses sample-targeted pruning to provide a \"trace\" of the network's execution on the sample, reducing the network to the connections that are most relevant to the specific prediction. We demonstrate that preprocessing with SPADE significantly increases both the accuracy of image saliency maps across several interpretability methods and the usefulness of neuron visualizations, aiding humans in reasoning about network behavior. Our findings show that sample-specific pruning of connections can disentangle multifaceted neurons, leading to consistently improved interpretability. ",
    "url": "https://arxiv.org/abs/2310.04519",
    "authors": [
      "Arshia Soltani Moakhar",
      "Eugenia Iofinova",
      "Dan Alistarh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04521",
    "title": "Lie Neurons: Adjoint-Equivariant Neural Networks for Semisimple Lie  Algebras",
    "abstract": "This paper proposes an adjoint-equivariant neural network that takes Lie algebra data as input. Various types of equivariant neural networks have been proposed in the literature, which treat the input data as elements in a vector space carrying certain types of transformations. In comparison, we aim to process inputs that are transformations between vector spaces. The change of basis on transformation is described by conjugations, inducing the adjoint-equivariance relationship that our model is designed to capture. Leveraging the invariance property of the Killing form, the proposed network is a general framework that works for arbitrary semisimple Lie algebras. Our network possesses a simple structure that can be viewed as a Lie algebraic generalization of a multi-layer perceptron (MLP). This work extends the application of equivariant feature learning. As an example, we showcase its value in homography modeling using sl(3) Lie algebra. ",
    "url": "https://arxiv.org/abs/2310.04521",
    "authors": [
      "Tzu-Yuan Lin",
      "Minghan Zhu",
      "Maani Ghaffari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.04539",
    "title": "Generating Less Certain Adversarial Examples Improves Robust  Generalization",
    "abstract": "Recent studies have shown that deep neural networks are vulnerable to adversarial examples. Numerous defenses have been proposed to improve model robustness, among which adversarial training is most successful. In this work, we revisit the robust overfitting phenomenon. In particular, we argue that overconfident models produced during adversarial training could be a potential cause, supported by the empirical observation that the predicted labels of adversarial examples generated by models with better robust generalization ability tend to have significantly more even distributions. Based on the proposed definition of adversarial certainty, we incorporate an extragradient step in the adversarial training framework to search for models that can generate adversarially perturbed inputs with lower certainty, further improving robust generalization. Our approach is general and can be easily combined with other variants of adversarial training methods. Extensive experiments on image benchmarks demonstrate that our method effectively alleviates robust overfitting and is able to produce models with consistently improved robustness. ",
    "url": "https://arxiv.org/abs/2310.04539",
    "authors": [
      "Minxing Zhang",
      "Michael Backes",
      "Xiao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04540",
    "title": "Multi-decadal Sea Level Prediction using Neural Networks and Spectral  Clustering on Climate Model Large Ensembles and Satellite Altimeter Data",
    "abstract": "Sea surface height observations provided by satellite altimetry since 1993 show a rising rate (3.4 mm/year) for global mean sea level. While on average, sea level has risen 10 cm over the last 30 years, there is considerable regional variation in the sea level change. Through this work, we predict sea level trends 30 years into the future at a 2-degree spatial resolution and investigate the future patterns of the sea level change. We show the potential of machine learning (ML) in this challenging application of long-term sea level forecasting over the global ocean. Our approach incorporates sea level data from both altimeter observations and climate model simulations. We develop a supervised learning framework using fully connected neural networks (FCNNs) that can predict the sea level trend based on climate model projections. Alongside this, our method provides uncertainty estimates associated with the ML prediction. We also show the effectiveness of partitioning our spatial dataset and learning a dedicated ML model for each segmented region. We compare two partitioning strategies: one achieved using domain knowledge, and the other employing spectral clustering. Our results demonstrate that segmenting the spatial dataset with spectral clustering improves the ML predictions. ",
    "url": "https://arxiv.org/abs/2310.04540",
    "authors": [
      "Saumya Sinha",
      "John Fasullo",
      "R. Steven Nerem",
      "Claire Monteleoni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04541",
    "title": "Iris Liveness Detection Competition (LivDet-Iris) -- The 2023 Edition",
    "abstract": "This paper describes the results of the 2023 edition of the ''LivDet'' series of iris presentation attack detection (PAD) competitions. New elements in this fifth competition include (1) GAN-generated iris images as a category of presentation attack instruments (PAI), and (2) an evaluation of human accuracy at detecting PAI as a reference benchmark. Clarkson University and the University of Notre Dame contributed image datasets for the competition, composed of samples representing seven different PAI categories, as well as baseline PAD algorithms. Fraunhofer IGD, Beijing University of Civil Engineering and Architecture, and Hochschule Darmstadt contributed results for a total of eight PAD algorithms to the competition. Accuracy results are analyzed by different PAI types, and compared to human accuracy. Overall, the Fraunhofer IGD algorithm, using an attention-based pixel-wise binary supervision network, showed the best-weighted accuracy results (average classification error rate of 37.31%), while the Beijing University of Civil Engineering and Architecture's algorithm won when equal weights for each PAI were given (average classification rate of 22.15%). These results suggest that iris PAD is still a challenging problem. ",
    "url": "https://arxiv.org/abs/2310.04541",
    "authors": [
      "Patrick Tinsley",
      "Sandip Purnapatra",
      "Mahsa Mitcheff",
      "Aidan Boyd",
      "Colton Crum",
      "Kevin Bowyer",
      "Patrick Flynn",
      "Stephanie Schuckers",
      "Adam Czajka",
      "Meiling Fang",
      "Naser Damer",
      "Xingyu Liu",
      "Caiyong Wang",
      "Xianyun Sun",
      "Zhaohua Chang",
      "Xinyue Li",
      "Guangzhe Zhao",
      "Juan Tapia",
      "Christoph Busch",
      "Carlos Aravena",
      "Daniel Schulz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.04546",
    "title": "Privacy-Preserving Financial Anomaly Detection via Federated Learning &  Multi-Party Computation",
    "abstract": "One of the main goals of financial institutions (FIs) today is combating fraud and financial crime. To this end, FIs use sophisticated machine-learning models trained using data collected from their customers. The output of machine learning models may be manually reviewed for critical use cases, e.g., determining the likelihood of a transaction being anomalous and the subsequent course of action. While advanced machine learning models greatly aid an FI in anomaly detection, model performance could be significantly improved using additional customer data from other FIs. In practice, however, an FI may not have appropriate consent from customers to share their data with other FIs. Additionally, data privacy regulations may prohibit FIs from sharing clients' sensitive data in certain geographies. Combining customer data to jointly train highly accurate anomaly detection models is therefore challenging for FIs in operational settings. In this paper, we describe a privacy-preserving framework that allows FIs to jointly train highly accurate anomaly detection models. The framework combines the concept of federated learning with efficient multi-party computation and noisy aggregates inspired by differential privacy. The presented framework was submitted as a winning entry to the financial crime detection track of the US/UK PETs Challenge. The challenge considered an architecture where banks hold customer data and execute transactions through a central network. We show that our solution enables the network to train a highly accurate anomaly detection model while preserving privacy of customer data. Experimental results demonstrate that use of additional customer data using the proposed approach results in improvement of our anomaly detection model's AUPRC from 0.6 to 0.7. We discuss how our framework, can be generalized to other similar scenarios. ",
    "url": "https://arxiv.org/abs/2310.04546",
    "authors": [
      "Sunpreet Arora",
      "Andrew Beams",
      "Panagiotis Chatzigiannis",
      "Sebastian Meiser",
      "Karan Patel",
      "Srinivasan Raghuraman",
      "Peter Rindal",
      "Harshal Shah",
      "Yizhen Wang",
      "Yuhang Wu",
      "Hao Yang",
      "Mahdi Zamani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.04560",
    "title": "Talk like a Graph: Encoding Graphs for Large Language Models",
    "abstract": "Graphs are a powerful tool for representing and analyzing complex relationships in real-world applications such as social networks, recommender systems, and computational finance. Reasoning on graphs is essential for drawing inferences about the relationships between entities in a complex system, and to identify hidden patterns and trends. Despite the remarkable progress in automated reasoning with natural text, reasoning on graphs with large language models (LLMs) remains an understudied problem. In this work, we perform the first comprehensive study of encoding graph-structured data as text for consumption by LLMs. We show that LLM performance on graph reasoning tasks varies on three fundamental levels: (1) the graph encoding method, (2) the nature of the graph task itself, and (3) interestingly, the very structure of the graph considered. These novel results provide valuable insight on strategies for encoding graphs as text. Using these insights we illustrate how the correct choice of encoders can boost performance on graph reasoning tasks inside LLMs by 4.8% to 61.8%, depending on the task. ",
    "url": "https://arxiv.org/abs/2310.04560",
    "authors": [
      "Bahare Fatemi",
      "Jonathan Halcrow",
      "Bryan Perozzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04562",
    "title": "Towards Foundation Models for Knowledge Graph Reasoning",
    "abstract": "Foundation models in language and vision have the ability to run inference on any textual and visual inputs thanks to the transferable representations such as a vocabulary of tokens in language. Knowledge graphs (KGs) have different entity and relation vocabularies that generally do not overlap. The key challenge of designing foundation models on KGs is to learn such transferable representations that enable inference on any graph with arbitrary entity and relation vocabularies. In this work, we make a step towards such foundation models and present ULTRA, an approach for learning universal and transferable graph representations. ULTRA builds relational representations as a function conditioned on their interactions. Such a conditioning strategy allows a pre-trained ULTRA model to inductively generalize to any unseen KG with any relation vocabulary and to be fine-tuned on any graph. Conducting link prediction experiments on 57 different KGs, we find that the zero-shot inductive inference performance of a single pre-trained ULTRA model on unseen graphs of various sizes is often on par or better than strong baselines trained on specific graphs. Fine-tuning further boosts the performance. ",
    "url": "https://arxiv.org/abs/2310.04562",
    "authors": [
      "Mikhail Galkin",
      "Xinyu Yuan",
      "Hesham Mostafa",
      "Jian Tang",
      "Zhaocheng Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.04570",
    "title": "Transformer-Based Neural Surrogate for Link-Level Path Loss Prediction  from Variable-Sized Maps",
    "abstract": "Estimating path loss for a transmitter-receiver location is key to many use-cases including network planning and handover. Machine learning has become a popular tool to predict wireless channel properties based on map data. In this work, we present a transformer-based neural network architecture that enables predicting link-level properties from maps of various dimensions and from sparse measurements. The map contains information about buildings and foliage. The transformer model attends to the regions that are relevant for path loss prediction and, therefore, scales efficiently to maps of different size. Further, our approach works with continuous transmitter and receiver coordinates without relying on discretization. In experiments, we show that the proposed model is able to efficiently learn dominant path losses from sparse training data and generalizes well when tested on novel maps. ",
    "url": "https://arxiv.org/abs/2310.04570",
    "authors": [
      "Thomas M. Hehn",
      "Tribhuvanesh Orekondy",
      "Ori Shental",
      "Arash Behboodi",
      "Juan Bucheli",
      "Akash Doshi",
      "June Namgoong",
      "Taesang Yoo",
      "Ashwin Sampath",
      "Joseph B. Soriaga"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04575",
    "title": "Real-time Optical Network Sensing Control Plane Enabled by a Novel Sub  us Response Time Fibre Sensing Control Device",
    "abstract": "We propose and implement a novel fibre sensing control device and associated sensing control plane that effectively controls backscatter and polarization-based fibre sensing. We experimentally demonstrate in a fibre network that this device and associated control plane can achieve sub-us response time. ",
    "url": "https://arxiv.org/abs/2310.04575",
    "authors": [
      "Mijail Szczerban",
      "Mikael Mazur",
      "Lauren Dallachiesa",
      "Ha\u00efk Mardoyan",
      "Sarvesh Bidkar",
      "Roland Ryf",
      "Jesse Simsarian"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2310.04580",
    "title": "An Operational Data-Driven Malfunction Detection Framework for Enhanced  Power Distribution System Monitoring -- The DeMaDs Approach",
    "abstract": "The changes in the electric energy system toward a sustainable future are inevitable and already on the way today. This often entails a change of paradigm for the electric energy grid, for example, the switch from central to decentralized power generation which also has to provide grid-supporting functionalities. However, due to the scarcity of distributed sensors, new solutions for grid operators for monitoring these functionalities are needed. The framework presented in this work allows to apply and assess data-driven detection methods in order to implement such monitoring capabilities. Furthermore, an approach to a multi-stage detection of misconfigurations is introduced. Details on implementations of the single stages as well as their requirements are also presented. Furthermore, testing and validation results are discussed. Due to its feature of being seamlessly integrable into system operators' current metering infrastructure, clear benefits of the proposed solution are pointed out. ",
    "url": "https://arxiv.org/abs/2310.04580",
    "authors": [
      "David Fellner",
      "Thomas I. Strasser",
      "Wolfgang Kastner",
      "Feizifar Behnam",
      "Ibrahim F. Abdulhadi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.04584",
    "title": "An Algorithm to Train Unrestricted Sequential Discrete Morphological  Neural Networks",
    "abstract": "With the advent of deep learning, there have been attempts to insert mathematical morphology (MM) operators into convolutional neural networks (CNN), and the most successful endeavor to date has been the morphological neural networks (MNN). Although MNN have performed better than CNN in solving some problems, they inherit their black-box nature. Furthermore, in the case of binary images, they are approximations, which loose the Boolean lattice structure of MM operators and, thus, it is not possible to represent a specific class of W-operators with desired properties. In a recent work, we proposed the Discrete Morphological Neural Networks (DMNN) for binary image transformation to represent specific classes of W-operators and estimate them via machine learning. We also proposed a stochastic lattice gradient descent algorithm (SLGDA) to learn the parameters of Canonical Discrete Morphological Neural Networks (CDMNN), whose architecture is composed only of operators that can be decomposed as the supremum, infimum, and complement of erosions and dilations. In this paper, we propose an algorithm to learn unrestricted sequential DMNN (USDMNN), whose architecture is given by the composition of general W-operators. We consider the representation of a W-operator by its characteristic Boolean function, and then learn it via a SLGDA in the Boolean lattice of functions. Although both the CDMNN and USDMNN have the Boolean lattice structure, USDMNN are not as dependent on prior information about the problem at hand, and may be more suitable in instances in which the practitioner does not have strong domain knowledge. We illustrate the algorithm in a practical example. ",
    "url": "https://arxiv.org/abs/2310.04584",
    "authors": [
      "Diego Marcondes",
      "Mariana Feldman",
      "Junior Barrera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.04605",
    "title": "Learning Optimal Power Flow Value Functions with Input-Convex Neural  Networks",
    "abstract": "The Optimal Power Flow (OPF) problem is integral to the functioning of power systems, aiming to optimize generation dispatch while adhering to technical and operational constraints. These constraints are far from straightforward; they involve intricate, non-convex considerations related to Alternating Current (AC) power flow, which are essential for the safety and practicality of electrical grids. However, solving the OPF problem for varying conditions within stringent time frames poses practical challenges. To address this, operators resort to model simplifications of varying accuracy. Unfortunately, better approximations (tight convex relaxations) are often computationally intractable. This research explores machine learning (ML) to learn convex approximate solutions for faster analysis in the online setting while still allowing for coupling into other convex dependent decision problems. By trading off a small amount of accuracy for substantial gains in speed, they enable the efficient exploration of vast solution spaces in these complex problems. ",
    "url": "https://arxiv.org/abs/2310.04605",
    "authors": [
      "Andrew Rosemberg",
      "Mathieu Tanneau",
      "Bruno Fanzeres",
      "Joaquim Garcia",
      "Pascal Van Hentenryck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2310.04612",
    "title": "A Topological Perspective on Demystifying GNN-Based Link Prediction  Performance",
    "abstract": "Graph Neural Networks (GNNs) have shown great promise in learning node embeddings for link prediction (LP). While numerous studies aim to improve the overall LP performance of GNNs, none have explored its varying performance across different nodes and its underlying reasons. To this end, we aim to demystify which nodes will perform better from the perspective of their local topology. Despite the widespread belief that low-degree nodes exhibit poorer LP performance, our empirical findings provide nuances to this viewpoint and prompt us to propose a better metric, Topological Concentration (TC), based on the intersection of the local subgraph of each node with the ones of its neighbors. We empirically demonstrate that TC has a higher correlation with LP performance than other node-level topological metrics like degree and subgraph density, offering a better way to identify low-performing nodes than using cold-start. With TC, we discover a novel topological distribution shift issue in which newly joined neighbors of a node tend to become less interactive with that node's existing neighbors, compromising the generalizability of node embeddings for LP at testing time. To make the computation of TC scalable, We further propose Approximated Topological Concentration (ATC) and theoretically/empirically justify its efficacy in approximating TC and reducing the computation complexity. Given the positive correlation between node TC and its LP performance, we explore the potential of boosting LP performance via enhancing TC by re-weighting edges in the message-passing and discuss its effectiveness with limitations. Our code is publicly available at https://github.com/YuWVandy/Topo_LP_GNN. ",
    "url": "https://arxiv.org/abs/2310.04612",
    "authors": [
      "Yu Wang",
      "Tong Zhao",
      "Yuying Zhao",
      "Yunchao Liu",
      "Xueqi Cheng",
      "Neil Shah",
      "Tyler Derr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.04627",
    "title": "Profit: Benchmarking Personalization and Robustness Trade-off in  Federated Prompt Tuning",
    "abstract": "In many applications of federated learning (FL), clients desire models that are personalized using their local data, yet are also robust in the sense that they retain general global knowledge. However, the presence of data heterogeneity across clients induces a fundamental trade-off between personalization (i.e., adaptation to a local distribution) and robustness (i.e., not forgetting previously learned general knowledge). It is critical to understand how to navigate this personalization vs robustness trade-off when designing federated systems, which are increasingly moving towards a paradigm of fine-tuning large foundation models. Due to limited computational and communication capabilities in most federated settings, this foundation model fine-tuning must be done using parameter-efficient fine-tuning (PEFT) approaches. While some recent work has studied federated approaches to PEFT, the personalization vs robustness trade-off of federated PEFT has been largely unexplored. In this work, we take a step towards bridging this gap by benchmarking fundamental FL algorithms -- FedAvg and FedSGD plus personalization (via client local fine-tuning) -- applied to one of the most ubiquitous PEFT approaches to large language models (LLMs) -- prompt tuning -- in a multitude of hyperparameter settings under varying levels of data heterogeneity. Our results show that federated-trained prompts can be surprisingly robust when using a small learning rate with many local epochs for personalization, especially when using an adaptive optimizer as the client optimizer during federated training. We also demonstrate that simple approaches such as adding regularization and interpolating two prompts are effective in improving the personalization vs robustness trade-off in computation-limited settings with few local updates allowed for personalization. ",
    "url": "https://arxiv.org/abs/2310.04627",
    "authors": [
      "Liam Collins",
      "Shanshan Wu",
      "Sewoong Oh",
      "Khe Chai Sim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04633",
    "title": "Unbiased and Robust: External Attention-enhanced Graph Contrastive  Learning for Cross-domain Sequential Recommendation",
    "abstract": "Cross-domain sequential recommenders (CSRs) are gaining considerable research attention as they can capture user sequential preference by leveraging side information from multiple domains. However, these works typically follow an ideal setup, i.e., different domains obey similar data distribution, which ignores the bias brought by asymmetric interaction densities (a.k.a. the inter-domain density bias). Besides, the frequently adopted mechanism (e.g., the self-attention network) in sequence encoder only focuses on the interactions within a local view, which overlooks the global correlations between different training batches. To this end, we propose an External Attention-enhanced Graph Contrastive Learning framework, namely EA-GCL. Specifically, to remove the impact of the inter-domain density bias, an auxiliary Self-Supervised Learning (SSL) task is attached to the traditional graph encoder under a multi-task learning manner. To robustly capture users' behavioral patterns, we develop an external attention-based sequence encoder that contains an MLP-based memory-sharing structure. Unlike the self-attention mechanism, such a structure can effectively alleviate the bias interference from the batch-based training scheme. Extensive experiments on two real-world datasets demonstrate that EA-GCL outperforms several state-of-the-art baselines on CSR tasks. The source codes and relevant datasets are available at https://github.com/HoupingY/EA-GCL. ",
    "url": "https://arxiv.org/abs/2310.04633",
    "authors": [
      "Xinhua Wang",
      "Houping Yue",
      "Zizheng Wang",
      "Liancheng Xu",
      "Jinyu Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.04639",
    "title": "X-Transfer: A Transfer Learning-Based Framework for Robust GAN-Generated  Fake Image Detection",
    "abstract": "Generative adversarial networks (GANs) have remarkably advanced in diverse domains, especially image generation and editing. However, the misuse of GANs for generating deceptive images raises significant security concerns, including face replacement and fake accounts, which have gained widespread attention. Consequently, there is an urgent need for effective detection methods to distinguish between real and fake images. Some of the current research centers around the application of transfer learning. Nevertheless, it encounters challenges such as knowledge forgetting from the original dataset and inadequate performance when dealing with imbalanced data during training. To alleviate the above issues, this paper introduces a novel GAN-generated image detection algorithm called X-Transfer. This model enhances transfer learning by utilizing two sibling neural networks that employ interleaved parallel gradient transmission. This approach also effectively mitigates the problem of excessive knowledge forgetting. In addition, we combine AUC loss term and cross-entropy loss to enhance the model's performance comprehensively. The AUC loss approximates the AUC metric using WMW statistics, ensuring differentiability and improving the performance of traditional AUC evaluation. We carry out comprehensive experiments on multiple facial image datasets. The results show that our model outperforms the general transferring approach, and the best accuracy achieves 99.04%, which is increased by approximately 10%. Furthermore, we demonstrate excellent performance on non-face datasets, validating its generality and broader application prospects. ",
    "url": "https://arxiv.org/abs/2310.04639",
    "authors": [
      "Lei Zhang",
      "Hao Chen",
      "Shu Hu",
      "Bin Zhu",
      "Xi Wu",
      "Jinrong Hu",
      "Xin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.04655",
    "title": "VLAttack: Multimodal Adversarial Attacks on Vision-Language Tasks via  Pre-trained Models",
    "abstract": "Vision-Language (VL) pre-trained models have shown their superiority on many multimodal tasks. However, the adversarial robustness of such models has not been fully explored. Existing approaches mainly focus on exploring the adversarial robustness under the white-box setting, which is unrealistic. In this paper, we aim to investigate a new yet practical task to craft image and text perturbations using pre-trained VL models to attack black-box fine-tuned models on different downstream tasks. Towards this end, we propose VLAttack to generate adversarial samples by fusing perturbations of images and texts from both single-modal and multimodal levels. At the single-modal level, we propose a new block-wise similarity attack (BSA) strategy to learn image perturbations for disrupting universal representations. Besides, we adopt an existing text attack strategy to generate text perturbations independent of the image-modal attack. At the multimodal level, we design a novel iterative cross-search attack (ICSA) method to update adversarial image-text pairs periodically, starting with the outputs from the single-modal level. We conduct extensive experiments to attack three widely-used VL pretrained models for six tasks on eight datasets. Experimental results show that the proposed VLAttack framework achieves the highest attack success rates on all tasks compared with state-of-the-art baselines, which reveals a significant blind spot in the deployment of pre-trained VL models. Codes will be released soon. ",
    "url": "https://arxiv.org/abs/2310.04655",
    "authors": [
      "Ziyi Yin",
      "Muchao Ye",
      "Tianrong Zhang",
      "Tianyu Du",
      "Jinguo Zhu",
      "Han Liu",
      "Jinghui Chen",
      "Ting Wang",
      "Fenglong Ma"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.04662",
    "title": "HalluciDet: Hallucinating RGB Modality for Person Detection Through  Privileged Information",
    "abstract": "A powerful way to adapt a visual recognition model to a new domain is through image translation. However, common image translation approaches only focus on generating data from the same distribution of the target domain. In visual recognition tasks with complex images, such as pedestrian detection on aerial images with a large cross-modal shift in data distribution from Infrared (IR) to RGB images, a translation focused on generation might lead to poor performance as the loss focuses on irrelevant details for the task. In this paper, we propose HalluciDet, an IR-RGB image translation model for object detection that, instead of focusing on reconstructing the original image on the IR modality, is guided directly on reducing the detection loss of an RGB detector, and therefore avoids the need to access RGB data. This model produces a new image representation that enhances the object of interest in the scene and greatly improves detection performance. We empirically compare our approach against state-of-the-art image translation methods as well as with the commonly used fine-tuning on IR, and show that our method improves detection accuracy in most cases, by exploiting the privileged information encoded in a pre-trained RGB detector. ",
    "url": "https://arxiv.org/abs/2310.04662",
    "authors": [
      "Heitor Rapela Medeiros",
      "Fidel A. Guerrero Pena",
      "Masih Aminbeidokhti",
      "Thomas Dubail",
      "Eric Granger",
      "Marco Pedersoli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.04668",
    "title": "Label-free Node Classification on Graphs with Large Language Models  (LLMS)",
    "abstract": "In recent years, there have been remarkable advancements in node classification achieved by Graph Neural Networks (GNNs). However, they necessitate abundant high-quality labels to ensure promising performance. In contrast, Large Language Models (LLMs) exhibit impressive zero-shot proficiency on text-attributed graphs. Yet, they face challenges in efficiently processing structural data and suffer from high inference costs. In light of these observations, this work introduces a label-free node classification on graphs with LLMs pipeline, LLM-GNN. It amalgamates the strengths of both GNNs and LLMs while mitigating their limitations. Specifically, LLMs are leveraged to annotate a small portion of nodes and then GNNs are trained on LLMs' annotations to make predictions for the remaining large portion of nodes. The implementation of LLM-GNN faces a unique challenge: how can we actively select nodes for LLMs to annotate and consequently enhance the GNN training? How can we leverage LLMs to obtain annotations of high quality, representativeness, and diversity, thereby enhancing GNN performance with less cost? To tackle this challenge, we develop an annotation quality heuristic and leverage the confidence scores derived from LLMs to advanced node selection. Comprehensive experimental results validate the effectiveness of LLM-GNN. In particular, LLM-GNN can achieve an accuracy of 74.9% on a vast-scale dataset \\products with a cost less than 1 dollar. ",
    "url": "https://arxiv.org/abs/2310.04668",
    "authors": [
      "Zhikai Chen",
      "Haitao Mao",
      "Hongzhi Wen",
      "Haoyu Han",
      "Wei Jin",
      "Haiyang Zhang",
      "Hui Liu",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.04674",
    "title": "Modeling non-uniform uncertainty in Reaction Prediction via Boosting and  Dropout",
    "abstract": "Reaction prediction has been recognized as a critical task in synthetic chemistry, where the goal is to predict the outcome of a reaction based on the given reactants. With the widespread adoption of generative models, the Variational Autoencoder(VAE) framework has typically been employed to tackle challenges in reaction prediction, where the reactants are encoded as a condition for the decoder, which then generates the product. Despite effectiveness, these conditional VAE (CVAE) models still fail to adequately account for the inherent uncertainty in reaction prediction, which primarily stems from the stochastic reaction process. The principal limitations are twofold. Firstly, in these CVAE models, the prior is independent of the reactants, leading to a default wide and assumed uniform distribution variance of the generated product. Secondly, reactants with analogous molecular representations are presumed to undergo similar electronic transition processes, thereby producing similar products. This hinders the ability to model diverse reaction mechanisms effectively. Since the variance in outcomes is inherently non-uniform, we are thus motivated to develop a framework that generates reaction products with non-uniform uncertainty. Firstly, we eliminate the latent variable in previous CVAE models to mitigate uncontrol-label noise. Instead, we introduce randomness into product generation via boosting to ensemble diverse models and cover the range of potential outcomes, and through dropout to secure models with minor variations. Additionally, we design a ranking method to union the predictions from boosting and dropout, prioritizing the most plausible products. Experimental results on the largest reaction prediction benchmark USPTO-MIT show the superior performance of our proposed method in modeling the non-uniform uncertainty compared to baselines. ",
    "url": "https://arxiv.org/abs/2310.04674",
    "authors": [
      "Taicheng Guo",
      "Changsheng Ma",
      "Xiuying Chen",
      "Bozhao Nan",
      "Kehan Guo",
      "Shichao Pei",
      "Nitesh V. Chawla",
      "Olaf Wiest",
      "Xiangliang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2310.04685",
    "title": "Automatic and Efficient Customization of Neural Networks for ML  Applications",
    "abstract": "ML APIs have greatly relieved application developers of the burden to design and train their own neural network models -- classifying objects in an image can now be as simple as one line of Python code to call an API. However, these APIs offer the same pre-trained models regardless of how their output is used by different applications. This can be suboptimal as not all ML inference errors can cause application failures, and the distinction between inference errors that can or cannot cause failures varies greatly across applications. To tackle this problem, we first study 77 real-world applications, which collectively use six ML APIs from two providers, to reveal common patterns of how ML API output affects applications' decision processes. Inspired by the findings, we propose ChameleonAPI, an optimization framework for ML APIs, which takes effect without changing the application source code. ChameleonAPI provides application developers with a parser that automatically analyzes the application to produce an abstract of its decision process, which is then used to devise an application-specific loss function that only penalizes API output errors critical to the application. ChameleonAPI uses the loss function to efficiently train a neural network model customized for each application and deploys it to serve API invocations from the respective application via existing interface. Compared to a baseline that selects the best-of-all commercial ML API, we show that ChameleonAPI reduces incorrect application decisions by 43%. ",
    "url": "https://arxiv.org/abs/2310.04685",
    "authors": [
      "Yuhan Liu",
      "Chengcheng Wan",
      "Kuntai Du",
      "Henry Hoffmann",
      "Junchen Jiang",
      "Shan Lu",
      "Michael Maire"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.04687",
    "title": "Understanding and Improving Adversarial Attacks on Latent Diffusion  Model",
    "abstract": "Latent Diffusion Model (LDM) has emerged as a leading tool in image generation, particularly with its capability in few-shot generation. This capability also presents risks, notably in unauthorized artwork replication and misinformation generation. In response, adversarial attacks have been designed to safeguard personal images from being used as reference data. However, existing adversarial attacks are predominantly empirical, lacking a solid theoretical foundation. In this paper, we introduce a comprehensive theoretical framework for understanding adversarial attacks on LDM. Based on the framework, we propose a novel adversarial attack that exploits a unified target to guide the adversarial attack both in the forward and the reverse process of LDM. We provide empirical evidences that our method overcomes the offset problem of the optimization of adversarial attacks in existing methods. Through rigorous experiments, our findings demonstrate that our method outperforms current attacks and is able to generalize over different state-of-the-art few-shot generation pipelines based on LDM. Our method can serve as a stronger and efficient tool for people exposed to the risk of data privacy and security to protect themselves in the new era of powerful generative models. The code is available on GitHub: https://github.com/CaradryanLiang/ImprovedAdvDM.git. ",
    "url": "https://arxiv.org/abs/2310.04687",
    "authors": [
      "Boyang Zheng",
      "Chumeng Liang",
      "Xiaoyu Wu",
      "Yan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.04688",
    "title": "PatchProto Networks for Few-shot Visual Anomaly Classification",
    "abstract": "The visual anomaly diagnosis can automatically analyze the defective products, which has been widely applied in industrial quality inspection. The anomaly classification can classify the defective products into different categories. However, the anomaly samples are hard to access in practice, which impedes the training of canonical machine learning models. This paper studies a practical issue that anomaly samples for training are extremely scarce, i.e., few-shot learning (FSL). Utilizing the sufficient normal samples, we propose PatchProto networks for few-shot anomaly classification. Different from classical FSL methods, PatchProto networks only extract CNN features of defective regions of interest, which serves as the prototypes for few-shot learning. Compared with basic few-shot classifier, the experiment results on MVTec-AD dataset show PatchProto networks significantly improve the few-shot anomaly classification accuracy. ",
    "url": "https://arxiv.org/abs/2310.04688",
    "authors": [
      "Jian Wang",
      "Yue Zhuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.04689",
    "title": "SeeDS: Semantic Separable Diffusion Synthesizer for Zero-shot Food  Detection",
    "abstract": "Food detection is becoming a fundamental task in food computing that supports various multimedia applications, including food recommendation and dietary monitoring. To deal with real-world scenarios, food detection needs to localize and recognize novel food objects that are not seen during training, demanding Zero-Shot Detection (ZSD). However, the complexity of semantic attributes and intra-class feature diversity poses challenges for ZSD methods in distinguishing fine-grained food classes. To tackle this, we propose the Semantic Separable Diffusion Synthesizer (SeeDS) framework for Zero-Shot Food Detection (ZSFD). SeeDS consists of two modules: a Semantic Separable Synthesizing Module (S$^3$M) and a Region Feature Denoising Diffusion Model (RFDDM). The S$^3$M learns the disentangled semantic representation for complex food attributes from ingredients and cuisines, and synthesizes discriminative food features via enhanced semantic information. The RFDDM utilizes a novel diffusion model to generate diversified region features and enhances ZSFD via fine-grained synthesized features. Extensive experiments show the state-of-the-art ZSFD performance of our proposed method on two food datasets, ZSFooD and UECFOOD-256. Moreover, SeeDS also maintains effectiveness on general ZSD datasets, PASCAL VOC and MS COCO. The code and dataset can be found at https://github.com/LanceZPF/SeeDS. ",
    "url": "https://arxiv.org/abs/2310.04689",
    "authors": [
      "Pengfei Zhou",
      "Weiqing Min",
      "Yang Zhang",
      "Jiajun Song",
      "Ying Jin",
      "Shuqiang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.04690",
    "title": "A dimension-reduced variational approach for solving physics-based  inverse problems using generative adversarial network priors and normalizing  flows",
    "abstract": "We propose a novel modular inference approach combining two different generative models -- generative adversarial networks (GAN) and normalizing flows -- to approximate the posterior distribution of physics-based Bayesian inverse problems framed in high-dimensional ambient spaces. We dub the proposed framework GAN-Flow. The proposed method leverages the intrinsic dimension reduction and superior sample generation capabilities of GANs to define a low-dimensional data-driven prior distribution. Once a trained GAN-prior is available, the inverse problem is solved entirely in the latent space of the GAN using variational Bayesian inference with normalizing flow-based variational distribution, which approximates low-dimensional posterior distribution by transforming realizations from the low-dimensional latent prior (Gaussian) to corresponding realizations of a low-dimensional variational posterior distribution. The trained GAN generator then maps realizations from this approximate posterior distribution in the latent space back to the high-dimensional ambient space. We also propose a two-stage training strategy for GAN-Flow wherein we train the two generative models sequentially. Thereafter, GAN-Flow can estimate the statistics of posterior-predictive quantities of interest at virtually no additional computational cost. The synergy between the two types of generative models allows us to overcome many challenges associated with the application of Bayesian inference to large-scale inverse problems, chief among which are describing an informative prior and sampling from the high-dimensional posterior. We demonstrate the efficacy and flexibility of GAN-Flow on various physics-based inverse problems of varying ambient dimensionality and prior knowledge using different types of GANs and normalizing flows. ",
    "url": "https://arxiv.org/abs/2310.04690",
    "authors": [
      "Agnimitra Dasgupta",
      "Dhruv V Patel",
      "Deep Ray",
      "Erik A Johnson",
      "Assad A Oberai"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2310.04693",
    "title": "Robustness-enhanced Uplift Modeling with Adversarial Feature  Desensitization",
    "abstract": "Uplift modeling has shown very promising results in online marketing. However, most existing works are prone to the robustness challenge in some practical applications. In this paper, we first present a possible explanation for the above phenomenon. We verify that there is a feature sensitivity problem in online marketing using different real-world datasets, where the perturbation of some key features will seriously affect the performance of the uplift model and even cause the opposite trend. To solve the above problem, we propose a novel robustness-enhanced uplift modeling framework with adversarial feature desensitization (RUAD). Specifically, our RUAD can more effectively alleviate the feature sensitivity of the uplift model through two customized modules, including a feature selection module with joint multi-label modeling to identify a key subset from the input features and an adversarial feature desensitization module using adversarial training and soft interpolation operations to enhance the robustness of the model against this selected subset of features. Finally, we conduct extensive experiments on a public dataset and a real product dataset to verify the effectiveness of our RUAD in online marketing. In addition, we also demonstrate the robustness of our RUAD to the feature sensitivity, as well as the compatibility with different uplift models. ",
    "url": "https://arxiv.org/abs/2310.04693",
    "authors": [
      "Zexu Sun",
      "Bowei He",
      "Ming Ma",
      "Jiakai Tang",
      "Yuchen Wang",
      "Chen Ma",
      "Dugang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.04694",
    "title": "DNA-Based Data Storage Systems: A Review of Implementations and Code  Constructions",
    "abstract": "In this review paper, we delve into the nascent field of molecular data storage, focusing on system implementations and code constructions. We start by providing an overview of basic concepts in synthetic and computational biology. Afterwards, we proceed with a review of the diverse approaches followed to implement such systems. In the process, we identify new problems in communication and coding theory, and discuss some relevant results pertaining to DNA sequence profiles, coded trace reconstruction, coding for DNA punchcard systems and coding for unique reconstruction. ",
    "url": "https://arxiv.org/abs/2310.04694",
    "authors": [
      "Olgica Milenkovic",
      "Chao Pan"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2310.04701",
    "title": "Twin Graph-based Anomaly Detection via Attentive Multi-Modal Learning  for Microservice System",
    "abstract": "Microservice architecture has sprung up over recent years for managing enterprise applications, due to its ability to independently deploy and scale services. Despite its benefits, ensuring the reliability and safety of a microservice system remains highly challenging. Existing anomaly detection algorithms based on a single data modality (i.e., metrics, logs, or traces) fail to fully account for the complex correlations and interactions between different modalities, leading to false negatives and false alarms, whereas incorporating more data modalities can offer opportunities for further performance gain. As a fresh attempt, we propose in this paper a semi-supervised graph-based anomaly detection method, MSTGAD, which seamlessly integrates all available data modalities via attentive multi-modal learning. First, we extract and normalize features from the three modalities, and further integrate them using a graph, namely MST (microservice system twin) graph, where each node represents a service instance and the edge indicates the scheduling relationship between different service instances. The MST graph provides a virtual representation of the status and scheduling relationships among service instances of a real-world microservice system. Second, we construct a transformer-based neural network with both spatial and temporal attention mechanisms to model the inter-correlations between different modalities and temporal dependencies between the data points. This enables us to detect anomalies automatically and accurately in real-time. The source code of MSTGAD is publicly available at https://github.com/alipay/microservice_system_twin_graph_based_anomaly_detection. ",
    "url": "https://arxiv.org/abs/2310.04701",
    "authors": [
      "Jun Huang",
      "Yang Yang",
      "Hang Yu",
      "Jianguo Li",
      "Xiao Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.04714",
    "title": "Generalized Robust Test-Time Adaptation in Continuous Dynamic Scenarios",
    "abstract": "Test-time adaptation (TTA) adapts the pre-trained models to test distributions during the inference phase exclusively employing unlabeled test data streams, which holds great value for the deployment of models in real-world applications. Numerous studies have achieved promising performance on simplistic test streams, characterized by independently and uniformly sampled test data originating from a fixed target data distribution. However, these methods frequently prove ineffective in practical scenarios, where both continual covariate shift and continual label shift occur simultaneously, i.e., data and label distributions change concurrently and continually over time. In this study, a more challenging Practical Test-Time Adaptation (PTTA) setup is introduced, which takes into account the concurrent presence of continual covariate shift and continual label shift, and we propose a Generalized Robust Test-Time Adaptation (GRoTTA) method to effectively address the difficult problem. We start by steadily adapting the model through Robust Parameter Adaptation to make balanced predictions for test samples. To be specific, firstly, the effects of continual label shift are eliminated by enforcing the model to learn from a uniform label distribution and introducing recalibration of batch normalization to ensure stability. Secondly, the continual covariate shift is alleviated by employing a source knowledge regularization with the teacher-student model to update parameters. Considering the potential information in the test stream, we further refine the balanced predictions by Bias-Guided Output Adaptation, which exploits latent structure in the feature space and is adaptive to the imbalanced label distribution. Extensive experiments demonstrate GRoTTA outperforms the existing competitors by a large margin under PTTA setting, rendering it highly conducive for adoption in real-world applications. ",
    "url": "https://arxiv.org/abs/2310.04714",
    "authors": [
      "Shuang Li",
      "Longhui Yuan",
      "Binhui Xie",
      "Tao Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.04719",
    "title": "A Comprehensive Survey on Deep Neural Image Deblurring",
    "abstract": "Image deblurring tries to eliminate degradation elements of an image causing blurriness and improve the quality of an image for better texture and object visualization. Traditionally, prior-based optimization approaches predominated in image deblurring, but deep neural networks recently brought a major breakthrough in the field. In this paper, we comprehensively review the recent progress of the deep neural architectures in both blind and non-blind image deblurring. We outline the most popular deep neural network structures used in deblurring applications, describe their strengths and novelties, summarize performance metrics, and introduce broadly used datasets. In addition, we discuss the current challenges and research gaps in this domain and suggest potential research directions for future works. ",
    "url": "https://arxiv.org/abs/2310.04719",
    "authors": [
      "Sajjad Amrollahi Biyouki",
      "Hoon Hwangbo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.04727",
    "title": "Task Aware Modulation using Representation Learning: An Approach for Few  Shot Learning in Heterogeneous Systems",
    "abstract": "We present a Task-aware modulation using Representation Learning (TAM-RL) framework that enhances personalized predictions in few-shot settings for heterogeneous systems when individual task characteristics are not known. TAM-RL extracts embeddings representing the actual inherent characteristics of these entities and uses these characteristics to personalize the predictions for each entity/task. Using real-world hydrological and flux tower benchmark data sets, we show that TAM-RL can significantly outperform existing baseline approaches such as MAML and multi-modal MAML (MMAML) while being much faster and simpler to train due to less complexity. Specifically, TAM-RL eliminates the need for sensitive hyper-parameters like inner loop steps and inner loop learning rate, which are crucial for model convergence in MAML, MMAML. We further present an empirical evaluation via synthetic data to explore the impact of heterogeneity amongst the entities on the relative performance of MAML, MMAML, and TAM-RL. We show that TAM-RL significantly improves predictive performance for cases where it is possible to learn distinct representations for different tasks. ",
    "url": "https://arxiv.org/abs/2310.04727",
    "authors": [
      "Arvind Renganathan",
      "Rahul Ghosh",
      "Ankush Khandelwal",
      "Vipin Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.04749",
    "title": "ConvNeXtv2 Fusion with Mask R-CNN for Automatic Region Based Coronary  Artery Stenosis Detection for Disease Diagnosis",
    "abstract": "Coronary Artery Diseases although preventable are one of the leading cause of mortality worldwide. Due to the onerous nature of diagnosis, tackling CADs has proved challenging. This study addresses the automation of resource-intensive and time-consuming process of manually detecting stenotic lesions in coronary arteries in X-ray coronary angiography images. To overcome this challenge, we employ a specialized Convnext-V2 backbone based Mask RCNN model pre-trained for instance segmentation tasks. Our empirical findings affirm that the proposed model exhibits commendable performance in identifying stenotic lesions. Notably, our approach achieves a substantial F1 score of 0.5353 in this demanding task, underscoring its effectiveness in streamlining this intensive process. ",
    "url": "https://arxiv.org/abs/2310.04749",
    "authors": [
      "Sandesh Pokhrel",
      "Sanjay Bhandari",
      "Eduard Vazquez",
      "Yash Raj Shrestha",
      "Binod Bhattarai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.04764",
    "title": "Characterizations of Definable Context-Free Graphs",
    "abstract": "We give a characterization of those sets of graphs that are both definable in Counting Monadic Second Order Logic (CMS) and context-free, i.e., least solutions of Hyperedge-Replacement (HR)-grammars introduced by Courcelle and Engelfriet. We give the following equivalent characterizations: (a) a set of graphs is recognizable (in the algebra that consists of all graphs and HR-operations) and has bounded tree-width; further, we refine this condition and show equivalence with recognizability in a finite-sort subalgebra of the graph algebra; (b) the set is parsable, i.e., there is an MS-definable transduction from graphs to a set of derivation trees labelled by HR-operations, such that the set of graphs is the image of this set of trees under the evaluation of the HR-operations; (c) the set of graphs is the image of unranked recognizable set of trees under an MS-definable transduction whose inverse is also MS-definable. The main goal of this paper is to present the above characterization, of which several directions are already known, in an accessible and unified way. We rely on a novel connection between two seminal results, a logical characterization of context-free graph languages in terms of tree to graph MS-definable transductions, by Courcelle and Engelfriet~, and a proof that an optimal-width tree decomposition of a graph can be built by an MS-definable transduction, by Bojanczyk and Pilipczuk. ",
    "url": "https://arxiv.org/abs/2310.04764",
    "authors": [
      "Radu Iosif",
      "Florian Zuleger"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2310.04768",
    "title": "Online Corrupted User Detection and Regret Minimization",
    "abstract": "In real-world online web systems, multiple users usually arrive sequentially into the system. For applications like click fraud and fake reviews, some users can maliciously perform corrupted (disrupted) behaviors to trick the system. Therefore, it is crucial to design efficient online learning algorithms to robustly learn from potentially corrupted user behaviors and accurately identify the corrupted users in an online manner. Existing works propose bandit algorithms robust to adversarial corruption. However, these algorithms are designed for a single user, and cannot leverage the implicit social relations among multiple users for more efficient learning. Moreover, none of them consider how to detect corrupted users online in the multiple-user scenario. In this paper, we present an important online learning problem named LOCUD to learn and utilize unknown user relations from disrupted behaviors to speed up learning, and identify the corrupted users in an online setting. To robustly learn and utilize the unknown relations among potentially corrupted users, we propose a novel bandit algorithm RCLUB-WCU. To detect the corrupted users, we devise a novel online detection algorithm OCCUD based on RCLUB-WCU's inferred user relations. We prove a regret upper bound for RCLUB-WCU, which asymptotically matches the lower bound with respect to $T$ up to logarithmic factors, and matches the state-of-the-art results in degenerate cases. We also give a theoretical guarantee for the detection accuracy of OCCUD. With extensive experiments, our methods achieve superior performance over previous bandit algorithms and high corrupted user detection accuracy. ",
    "url": "https://arxiv.org/abs/2310.04768",
    "authors": [
      "Zhiyong Wang",
      "Jize Xie",
      "Tong Yu",
      "Shuai Li",
      "John C.S. Lui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04780",
    "title": "IPMix: Label-Preserving Data Augmentation Method for Training Robust  Classifiers",
    "abstract": "Data augmentation has been proven effective for training high-accuracy convolutional neural network classifiers by preventing overfitting. However, building deep neural networks in real-world scenarios requires not only high accuracy on clean data but also robustness when data distributions shift. While prior methods have proposed that there is a trade-off between accuracy and robustness, we propose IPMix, a simple data augmentation approach to improve robustness without hurting clean accuracy. IPMix integrates three levels of data augmentation (image-level, patch-level, and pixel-level) into a coherent and label-preserving technique to increase the diversity of training data with limited computational overhead. To further improve the robustness, IPMix introduces structural complexity at different levels to generate more diverse images and adopts the random mixing method for multi-scale information fusion. Experiments demonstrate that IPMix outperforms state-of-the-art corruption robustness on CIFAR-C and ImageNet-C. In addition, we show that IPMix also significantly improves the other safety measures, including robustness to adversarial perturbations, calibration, prediction consistency, and anomaly detection, achieving state-of-the-art or comparable results on several benchmarks, including ImageNet-R, ImageNet-A, and ImageNet-O. ",
    "url": "https://arxiv.org/abs/2310.04780",
    "authors": [
      "Zhenglin Huang",
      "Xianan Bao",
      "Na Zhang",
      "Qingqi Zhang",
      "Xiaomei Tu",
      "Biao Wu",
      "Xi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.04788",
    "title": "PMNN:Physical Model-driven Neural Network for solving time-fractional  differential equations",
    "abstract": "In this paper, an innovative Physical Model-driven Neural Network (PMNN) method is proposed to solve time-fractional differential equations. It establishes a temporal iteration scheme based on physical model-driven neural networks which effectively combines deep neural networks (DNNs) with interpolation approximation of fractional derivatives. Specifically, once the fractional differential operator is discretized, DNNs are employed as a bridge to integrate interpolation approximation techniques with differential equations. On the basis of this integration, we construct a neural-based iteration scheme. Subsequently, by training DNNs to learn this temporal iteration scheme, approximate solutions to the differential equations can be obtained. The proposed method aims to preserve the intrinsic physical information within the equations as far as possible. It fully utilizes the powerful fitting capability of neural networks while maintaining the efficiency of the difference schemes for fractional differential equations. Moreover, we validate the efficiency and accuracy of PMNN through several numerical experiments. ",
    "url": "https://arxiv.org/abs/2310.04788",
    "authors": [
      "Zhiying Ma",
      "Jie Hou",
      "Wenhao Zhu",
      "Yaxin Peng",
      "Ying Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.04789",
    "title": "HNS: An Efficient Hermite Neural Solver for Solving Time-Fractional  Partial Differential Equations",
    "abstract": "Neural network solvers represent an innovative and promising approach for tackling time-fractional partial differential equations by utilizing deep learning techniques. L1 interpolation approximation serves as the standard method for addressing time-fractional derivatives within neural network solvers. However, we have discovered that neural network solvers based on L1 interpolation approximation are unable to fully exploit the benefits of neural networks, and the accuracy of these models is constrained to interpolation errors. In this paper, we present the high-precision Hermite Neural Solver (HNS) for solving time-fractional partial differential equations. Specifically, we first construct a high-order explicit approximation scheme for fractional derivatives using Hermite interpolation techniques, and rigorously analyze its approximation accuracy. Afterward, taking into account the infinitely differentiable properties of deep neural networks, we integrate the high-order Hermite interpolation explicit approximation scheme with deep neural networks to propose the HNS. The experimental results show that HNS achieves higher accuracy than methods based on the L1 scheme for both forward and inverse problems, as well as in high-dimensional scenarios. This indicates that HNS has significantly improved accuracy and flexibility compared to existing L1-based methods, and has overcome the limitations of explicit finite difference approximation methods that are often constrained to function value interpolation. As a result, the HNS is not a simple combination of numerical computing methods and neural networks, but rather achieves a complementary and mutually reinforcing advantages of both approaches. The data and code can be found at \\url{https://github.com/hsbhc/HNS}. ",
    "url": "https://arxiv.org/abs/2310.04789",
    "authors": [
      "Jie Hou",
      "Zhiying Ma",
      "Shihui Ying",
      "Ying Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.04800",
    "title": "Fully Sparse Long Range 3D Object Detection Using Range Experts and  Multimodal Virtual Points",
    "abstract": "3D object detection at long-range is crucial for ensuring the safety and efficiency of self-driving cars, allowing them to accurately perceive and react to objects, obstacles, and potential hazards from a distance. But most current state-of-the-art LiDAR based methods are limited by the sparsity of range sensors, which generates a form of domain gap between points closer to and farther away from the ego vehicle. Another related problem is the label imbalance for faraway objects, which inhibits the performance of Deep Neural Networks at long-range. Although image features could be beneficial for long-range detections, and some recently proposed multimodal methods incorporate image features, they do not scale well computationally at long ranges or are limited by depth estimation accuracy. To address the above limitations, we propose to combine two LiDAR based 3D detection networks, one specializing at near to mid-range objects, and one at long-range 3D detection. To train a detector at long range under a scarce label regime, we further propose to weigh the loss according to the labelled objects' distance from ego vehicle. To mitigate the LiDAR sparsity issue, we leverage Multimodal Virtual Points (MVP), an image based depth completion algorithm, to enrich our data with virtual points. Our method, combining two range experts trained with MVP, which we refer to as RangeFSD, achieves state-of-the-art performance on the Argoverse2 (AV2) dataset, with improvements at long range. The code will be released soon. ",
    "url": "https://arxiv.org/abs/2310.04800",
    "authors": [
      "Ajinkya Khoche",
      "Laura Pereira S\u00e1nchez",
      "Nazre Batool",
      "Sina Sharif Mansouri",
      "Patric Jensfelt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.04816",
    "title": "Hacking Generative Models with Differentiable Network Bending",
    "abstract": "In this work, we propose a method to 'hack' generative models, pushing their outputs away from the original training distribution towards a new objective. We inject a small-scale trainable module between the intermediate layers of the model and train it for a low number of iterations, keeping the rest of the network frozen. The resulting output images display an uncanny quality, given by the tension between the original and new objectives that can be exploited for artistic purposes. ",
    "url": "https://arxiv.org/abs/2310.04816",
    "authors": [
      "Giacomo Aldegheri",
      "Alina Rogalska",
      "Ahmed Youssef",
      "Eugenia Iofinova"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04820",
    "title": "The BCH Family of Storage Codes on Triangle-Free Graphs is of Unit Rate",
    "abstract": "Let $\\Gamma$ be a simple connected graph on $n$ vertices, and let $C$ be a code of length $n$ whose coordinates are indexed by the vertices of $\\Gamma$. We say that $C$ is a \\textit{storage code} on $\\Gamma$ if for any codeword $c \\in C$, one can recover the information on each coordinate of $c$ by accessing its neighbors in $\\Gamma$. The main problem here is to construct high-rate storage codes on triangle-free graphs. In this paper, we solve an open problem posed by Barg and Z\\'emor in 2022, showing that the BCH family of storage codes is of unit rate. Furthermore, we generalize the construction of the BCH family and obtain more storage codes of unit rate on triangle-free graphs. ",
    "url": "https://arxiv.org/abs/2310.04820",
    "authors": [
      "Haihua Deng",
      "Hexiang Huang",
      "Guobiao Weng",
      "Qing Xiang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2310.04837",
    "title": "Federated Self-Supervised Learning of Monocular Depth Estimators for  Autonomous Vehicles",
    "abstract": "Image-based depth estimation has gained significant attention in recent research on computer vision for autonomous vehicles in intelligent transportation systems. This focus stems from its cost-effectiveness and wide range of potential applications. Unlike binocular depth estimation methods that require two fixed cameras, monocular depth estimation methods only rely on a single camera, making them highly versatile. While state-of-the-art approaches for this task leverage self-supervised learning of deep neural networks in conjunction with tasks like pose estimation and semantic segmentation, none of them have explored the combination of federated learning and self-supervision to train models using unlabeled and private data captured by autonomous vehicles. The utilization of federated learning offers notable benefits, including enhanced privacy protection, reduced network consumption, and improved resilience to connectivity issues. To address this gap, we propose FedSCDepth, a novel method that combines federated learning and deep self-supervision to enable the learning of monocular depth estimators with comparable effectiveness and superior efficiency compared to the current state-of-the-art methods. Our evaluation experiments conducted on Eigen's Split of the KITTI dataset demonstrate that our proposed method achieves near state-of-the-art performance, with a test loss below 0.13 and requiring, on average, only 1.5k training steps and up to 0.415 GB of weight data transfer per autonomous vehicle on each round. ",
    "url": "https://arxiv.org/abs/2310.04837",
    "authors": [
      "Elton F. de S. Soares",
      "Carlos Alberto V. Campos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.04845",
    "title": "Exploiting Facial Relationships and Feature Aggregation for Multi-Face  Forgery Detection",
    "abstract": "Face forgery techniques have emerged as a forefront concern, and numerous detection approaches have been proposed to address this challenge. However, existing methods predominantly concentrate on single-face manipulation detection, leaving the more intricate and realistic realm of multi-face forgeries relatively unexplored. This paper proposes a novel framework explicitly tailored for multi-face forgery detection,filling a critical gap in the current research. The framework mainly involves two modules:(i) a facial relationships learning module, which generates distinguishable local features for each face within images,(ii) a global feature aggregation module that leverages the mutual constraints between global and local information to enhance forgery detection accuracy.Our experimental results on two publicly available multi-face forgery datasets demonstrate that the proposed approach achieves state-of-the-art performance in multi-face forgery detection scenarios. ",
    "url": "https://arxiv.org/abs/2310.04845",
    "authors": [
      "Chenhao Lin",
      "Fangbin Yi",
      "Hang Wang",
      "Qian Li",
      "Deng Jingyi",
      "Chao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.04852",
    "title": "Balancing utility and cognitive cost in social representation",
    "abstract": "To successfully navigate its environment, an agent must construct and maintain representations of the other agents that it encounters. Such representations are useful for many tasks, but they are not without cost. As a result, agents must make decisions regarding how much information they choose to represent about the agents in their environment. Using selective imitation as an example task, we motivate the problem of finding agent representations that optimally trade off between downstream utility and information cost, and illustrate two example approaches to resource-constrained social representation. ",
    "url": "https://arxiv.org/abs/2310.04852",
    "authors": [
      "Max Taylor-Davies",
      "Christopher G. Lucas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.04865",
    "title": "ForeSeer: Product Aspect Forecasting Using Temporal Graph Embedding",
    "abstract": "Developing text mining approaches to mine aspects from customer reviews has been well-studied due to its importance in understanding customer needs and product attributes. In contrast, it remains unclear how to predict the future emerging aspects of a new product that currently has little review information. This task, which we named product aspect forecasting, is critical for recommending new products, but also challenging because of the missing reviews. Here, we propose ForeSeer, a novel textual mining and product embedding approach progressively trained on temporal product graphs for this novel product aspect forecasting task. ForeSeer transfers reviews from similar products on a large product graph and exploits these reviews to predict aspects that might emerge in future reviews. A key novelty of our method is to jointly provide review, product, and aspect embeddings that are both time-sensitive and less affected by extremely imbalanced aspect frequencies. We evaluated ForeSeer on a real-world product review system containing 11,536,382 reviews and 11,000 products over 3 years. We observe that ForeSeer substantially outperformed existing approaches with at least 49.1\\% AUPRC improvement under the real setting where aspect associations are not given. ForeSeer further improves future link prediction on the product graph and the review aspect association prediction. Collectively, Foreseer offers a novel framework for review forecasting by effectively integrating review text, product network, and temporal information, opening up new avenues for online shopping recommendation and e-commerce applications. ",
    "url": "https://arxiv.org/abs/2310.04865",
    "authors": [
      "Zixuan Liu",
      "Gaurush Hiranandani",
      "Kun Qian",
      "Eddie W. Huang",
      "Yi Xu",
      "Belinda Zeng",
      "Karthik Subbian",
      "Sheng Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04867",
    "title": "Randomized Sparse Neural Galerkin Schemes for Solving Evolution  Equations with Deep Networks",
    "abstract": "Training neural networks sequentially in time to approximate solution fields of time-dependent partial differential equations can be beneficial for preserving causality and other physics properties; however, the sequential-in-time training is numerically challenging because training errors quickly accumulate and amplify over time. This work introduces Neural Galerkin schemes that update randomized sparse subsets of network parameters at each time step. The randomization avoids overfitting locally in time and so helps prevent the error from accumulating quickly over the sequential-in-time training, which is motivated by dropout that addresses a similar issue of overfitting due to neuron co-adaptation. The sparsity of the update reduces the computational costs of training without losing expressiveness because many of the network parameters are redundant locally at each time step. In numerical experiments with a wide range of evolution equations, the proposed scheme with randomized sparse updates is up to two orders of magnitude more accurate at a fixed computational budget and up to two orders of magnitude faster at a fixed accuracy than schemes with dense updates. ",
    "url": "https://arxiv.org/abs/2310.04867",
    "authors": [
      "Jules Berman",
      "Benjamin Peherstorfer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.04878",
    "title": "Hybrid Recommendation System using Graph Neural Network and BERT  Embeddings",
    "abstract": "Recommender systems have emerged as a crucial component of the modern web ecosystem. The effectiveness and accuracy of such systems are critical for providing users with personalized recommendations that meet their specific interests and needs. In this paper, we introduce a novel model that utilizes a Graph Neural Network (GNN) in conjunction with sentence transformer embeddings to predict anime recommendations for different users. Our model employs the task of link prediction to create a recommendation system that considers both the features of anime and user interactions with different anime. The hybridization of the GNN and transformer embeddings enables us to capture both inter-level and intra-level features of anime data.Our model not only recommends anime to users but also predicts the rating a specific user would give to an anime. We utilize the GraphSAGE network for model building and weighted root mean square error (RMSE) to evaluate the performance of the model. Our approach has the potential to significantly enhance the accuracy and effectiveness of anime recommendation systems and can be extended to other domains that require personalized recommendations. ",
    "url": "https://arxiv.org/abs/2310.04878",
    "authors": [
      "Shashidhar Reddy Javaji",
      "Krutika Sarode"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04889",
    "title": "GradXKG: A Universal Explain-per-use Temporal Knowledge Graph Explainer",
    "abstract": "Temporal knowledge graphs (TKGs) have shown promise for reasoning tasks by incorporating a temporal dimension to represent how facts evolve over time. However, existing TKG reasoning (TKGR) models lack explainability due to their black-box nature. Recent work has attempted to address this through customized model architectures that generate reasoning paths, but these recent approaches have limited generalizability and provide sparse explanatory output. To enable interpretability for most TKGR models, we propose GradXKG, a novel two-stage gradient-based approach for explaining Relational Graph Convolution Network (RGCN)-based TKGR models. First, a Grad-CAM-inspired RGCN explainer tracks gradients to quantify each node's contribution across timesteps in an efficient \"explain-per-use\" fashion. Second, an integrated gradients explainer consolidates importance scores for RGCN outputs, extending compatibility across diverse TKGR architectures based on RGCN. Together, the two explainers highlight the most critical nodes at each timestep for a given prediction. Our extensive experiments demonstrated that, by leveraging gradient information, GradXKG provides insightful explanations grounded in the model's logic in a timely manner for most RGCN-based TKGR models. This helps address the lack of interpretability in existing TKGR models and provides a universal explanation approach applicable across various models. ",
    "url": "https://arxiv.org/abs/2310.04889",
    "authors": [
      "Chenhan Yuan",
      "Hoda Eldardiry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.04893",
    "title": "Generalized Densest Subgraph in Multiplex Networks",
    "abstract": "Finding dense subgraphs of a large network is a fundamental problem in graph mining that has been studied extensively both for its theoretical richness and its many practical applications over the last five decades. However, most existing studies have focused on graphs with a single type of connection. In applications such as biological, social, and transportation networks, interactions between objects span multiple aspects, yielding multiplex graphs. Existing dense subgraph mining methods in multiplex graphs consider the same importance for different types of connections, while in real-world applications, one relation type can be noisy, insignificant, or irrelevant. Moreover, they are limited to the edge-density measure, unable to change the emphasis on larger/smaller degrees depending on the application. To this end, we define a new family of dense subgraph objectives, parametrized by two variables $p$ and $\\beta$, that can (1) consider different importance weights for each relation type, and (2) change the emphasis on the larger/smaller degrees, depending on the application. Due to the NP-hardness of this problem, we first extend the FirmCore, $k$-core counterpart in multiplex graphs, to layer-weighted multiplex graphs, and based on it, we propose two polynomial-time approximation algorithms for the generalized densest subgraph problem, when $p \\geq 1$ and the general case. Our experimental results show the importance of considering different weights for different relation types and the effectiveness and efficiency of our algorithms. ",
    "url": "https://arxiv.org/abs/2310.04893",
    "authors": [
      "Ali Behrouz",
      "Farnoosh Hashemi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2310.04898",
    "title": "Scalable Multi-domain Trust Infrastructures for Segmented Networks",
    "abstract": "Within a trust infrastructure, a private key is often used to digitally sign a transaction, which can be verified with an associated public key. Using PKI (Public Key Infrastructure), a trusted entity can produce a digital signature, verifying the authenticity of the public key. However, what happens when external entities are not trusted to verify the public key or in cases where there is no Internet connection within an isolated or autonomously acting collection of devices? For this, a trusted entity can be elected to generate a key pair and then split the private key amongst trusted devices. Each node can then sign part of the transaction using their split of the shared secret. The aggregated signature can then define agreement on a consensus within the infrastructure. Unfortunately, this process has two significant problems. The first is when no trusted node can act as a dealer of the shares. The second is the difficulty of scaling the digital signature scheme. This paper outlines a method of creating a leaderless approach to defining trust domains to overcome weaknesses in the scaling of the elliptic curve digital signature algorithm. Instead, it proposes the usage of the Edwards curve digital signature algorithm for the definition of multiple trust zones. The paper shows that the computational overhead of the distributed key generation phase increases with the number of nodes in the trust domain but that the distributed signing has a relatively constant computational overhead. ",
    "url": "https://arxiv.org/abs/2310.04898",
    "authors": [
      "Sam Grierson",
      "William J Buchanan",
      "Craig Thomson",
      "Baraq Ghaleb",
      "Leandros Maglaras",
      "Chris Eckle"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.04910",
    "title": "Faithful Knowledge Graph Explanations for Commonsense Reasoning",
    "abstract": "While fusing language models (LMs) and knowledge graphs (KGs) has become common in commonsense question answering research, enabling faithful chain-of-thought explanations in these models remains an open problem. One major weakness of current KG-based explanation techniques is that they overlook the faithfulness of generated explanations during evaluation. To address this gap, we make two main contributions: (1) We propose and validate two quantitative metrics - graph consistency and graph fidelity - to measure the faithfulness of KG-based explanations. (2) We introduce Consistent GNN (CGNN), a novel training method that adds a consistency regularization term to improve explanation faithfulness. Our analysis shows that predictions from KG often diverge from original model predictions. The proposed CGNN approach boosts consistency and fidelity, demonstrating its potential for producing more faithful explanations. Our work emphasises the importance of explicitly evaluating suggest a path forward for developing architectures for faithful graph-based explanations. ",
    "url": "https://arxiv.org/abs/2310.04910",
    "authors": [
      "Weihe Zhai",
      "Arkaitz Zubiaga",
      "Bingquan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.04911",
    "title": "Interference Networks with Random User Activity and Heterogeneous Delay  Constraints",
    "abstract": "To answer the call for a new theoretical framework to simultaneously accommodate random user activity and heterogeneous delay traffic in Internet of Things (IoT) systems, in this paper we propose coding schemes and information-theoretic converse results for the transmission of heterogeneous delay traffic over interference networks with random user activity and random data arrivals. The heterogeneous traffic is composed of delay-tolerant traffic and delay-sensitive traffic where only the former can benefit from transmitter and receiver cooperation since the latter is subject to stringent decoding delays. The total number of cooperation rounds at transmitter and receiver sides is limited to $\\D$ rounds. Each transmitter is active with probability $\\rho \\in [0,1]$. We consider two different models for the arrival of the mixed-delay traffic: in Model~$1$, each active transmitter sends a delay-tolerant message, and with probability $\\rho_f \\in [0,1]$ also transmits an additional delay-sensitive message; in Model~$2$, each active transmitter sends either a delay-sensitive message with probability $\\rho_f$ or a delay-tolerant message with probability $1-\\rho_f$. We derive inner and outer bounds on the fundamental per-user multiplexing gain (MG) region of the symmetric Wyner network as well as inner bounds on the fundamental MG region of the hexagonal model. Our inner and outer bounds are generally very close and coincide in special cases. They also show that when both transmitters and receivers can cooperate, then under Model~$1$, transmitting delay-sensitive messages hardly causes any penalty on the sum per-user MG, and under Model~$2$, operating at large delay-sensitive per-user MGs incurs no penalty on the delay-tolerant per-user MG and thus increases the sum per-user MG. ",
    "url": "https://arxiv.org/abs/2310.04911",
    "authors": [
      "Homa Nikbakht",
      "Mich\u00e8le Wigger",
      "Shlomo Shamai",
      "Jean-Marie Gorce",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2310.04918",
    "title": "Robust Network Pruning With Sparse Entropic Wasserstein Regression",
    "abstract": "This study unveils a cutting-edge technique for neural network pruning that judiciously addresses noisy gradients during the computation of the empirical Fisher Information Matrix (FIM). We introduce an entropic Wasserstein regression (EWR) formulation, capitalizing on the geometric attributes of the optimal transport (OT) problem. This is analytically showcased to excel in noise mitigation by adopting neighborhood interpolation across data points. The unique strength of the Wasserstein distance is its intrinsic ability to strike a balance between noise reduction and covariance information preservation. Extensive experiments performed on various networks show comparable performance of the proposed method with state-of-the-art (SoTA) network pruning algorithms. Our proposed method outperforms the SoTA when the network size or the target sparsity is large, the gain is even larger with the existence of noisy gradients, possibly from noisy data, analog memory, or adversarial attacks. Notably, our proposed method achieves a gain of 6% improvement in accuracy and 8% improvement in testing loss for MobileNetV1 with less than one-fourth of the network parameters remaining. ",
    "url": "https://arxiv.org/abs/2310.04918",
    "authors": [
      "Lei You",
      "Hei Victor Cheng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.04922",
    "title": "Robust Multivariate Detection and Estimation with Fault Frequency  Content Information",
    "abstract": "This paper studies the problem of fault detection and estimation (FDE) for LTI systems with a particular focus on frequency content information for the faults, possibly as a continuum range, and under both disturbances and stochastic noise. Considering the worst-case fault sensitivity in the frequency range and the effects of disturbances and noise, we introduce a mixed $\\mathcal{H}_2/\\mathcal{H}_{\\_}$ performance index and develop an optimization framework to compute the optimal detection filter. We further propose a thresholding rule that provides guarantees on both false alarm rate (FAR) and fault detection rate (FDR). Next, shifting our attention to the estimation problem, we introduce the restricted $\\mathcal{H}_{\\infty}$ performance index and obtain an exact reformulation of the optimal filter design. This problem is inherently non-convex, however, focusing on finite frequency samples and fixed poles, we then establish a lower bound via a highly tractable quadratic programming (QP) problem. This lower bound together with an alternating optimization approach to the original estimation problem leads to a suboptimality gap for the overall filter design. The effectiveness of the proposed approaches is validated through a synthetic non-minimum phase system and an application of the multi-area power system. ",
    "url": "https://arxiv.org/abs/2310.04922",
    "authors": [
      "Jingwei Dong",
      "Kaikai Pan",
      "Sergio Pequito",
      "Peyman Mohajerin Esfahani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2310.04929",
    "title": "DISCOVER: Making Vision Networks Interpretable via Competition and  Dissection",
    "abstract": "Modern deep networks are highly complex and their inferential outcome very hard to interpret. This is a serious obstacle to their transparent deployment in safety-critical or bias-aware applications. This work contributes to post-hoc interpretability, and specifically Network Dissection. Our goal is to present a framework that makes it easier to discover the individual functionality of each neuron in a network trained on a vision task; discovery is performed in terms of textual description generation. To achieve this objective, we leverage: (i) recent advances in multimodal vision-text models and (ii) network layers founded upon the novel concept of stochastic local competition between linear units. In this setting, only a small subset of layer neurons are activated for a given input, leading to extremely high activation sparsity (as low as only $\\approx 4\\%$). Crucially, our proposed method infers (sparse) neuron activation patterns that enables the neurons to activate/specialize to inputs with specific characteristics, diversifying their individual functionality. This capacity of our method supercharges the potential of dissection processes: human understandable descriptions are generated only for the very few active neurons, thus facilitating the direct investigation of the network's decision process. As we experimentally show, our approach: (i) yields Vision Networks that retain or improve classification performance, and (ii) realizes a principled framework for text-based description and examination of the generated neuronal representations. ",
    "url": "https://arxiv.org/abs/2310.04929",
    "authors": [
      "Konstantinos P. Panousis",
      "Sotirios Chatzis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.04942",
    "title": "Large Language Models for Spatial Trajectory Patterns Mining",
    "abstract": "Identifying anomalous human spatial trajectory patterns can indicate dynamic changes in mobility behavior with applications in domains like infectious disease monitoring and elderly care. Recent advancements in large language models (LLMs) have demonstrated their ability to reason in a manner akin to humans. This presents significant potential for analyzing temporal patterns in human mobility. In this paper, we conduct empirical studies to assess the capabilities of leading LLMs like GPT-4 and Claude-2 in detecting anomalous behaviors from mobility data, by comparing to specialized methods. Our key findings demonstrate that LLMs can attain reasonable anomaly detection performance even without any specific cues. In addition, providing contextual clues about potential irregularities could further enhances their prediction efficacy. Moreover, LLMs can provide reasonable explanations for their judgments, thereby improving transparency. Our work provides insights on the strengths and limitations of LLMs for human spatial trajectory analysis. ",
    "url": "https://arxiv.org/abs/2310.04942",
    "authors": [
      "Zheng Zhang",
      "Hossein Amiri",
      "Zhenke Liu",
      "Andreas Z\u00fcfle",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04944",
    "title": "Beyond Text: A Deep Dive into Large Language Models' Ability on  Understanding Graph Data",
    "abstract": "Large language models (LLMs) have achieved impressive performance on many natural language processing tasks. However, their capabilities on graph-structured data remain relatively unexplored. In this paper, we conduct a series of experiments benchmarking leading LLMs on diverse graph prediction tasks spanning node, edge, and graph levels. We aim to assess whether LLMs can effectively process graph data and leverage topological structures to enhance performance, compared to specialized graph neural networks. Through varied prompt formatting and task/dataset selection, we analyze how well LLMs can interpret and utilize graph structures. By comparing LLMs' performance with specialized graph models, we offer insights into the strengths and limitations of employing LLMs for graph analytics. Our findings provide insights into LLMs' capabilities and suggest avenues for further exploration in applying them to graph analytics. ",
    "url": "https://arxiv.org/abs/2310.04944",
    "authors": [
      "Yuntong Hu",
      "Zheng Zhang",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04949",
    "title": "Domain Knowledge Graph Construction Via A Simple Checker",
    "abstract": "With the availability of large language models, there is a growing interest for semiconductor chip design companies to leverage the technologies. For those companies, deployment of a new methodology must include two important considerations: confidentiality and scalability. In this context, this work tackles the problem of knowledge graph construction from hardware-design domain texts. We propose an oracle-checker scheme to leverage the power of GPT3.5 and demonstrate that the essence of the problem is in distillation of domain expert's background knowledge. Using RISC-V unprivileged ISA specification as an example, we explain key ideas and discuss practicality of our proposed oracle-checker approach. ",
    "url": "https://arxiv.org/abs/2310.04949",
    "authors": [
      "Yueling Zeng",
      "Li-C. Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.04951",
    "title": "CodeTransOcean: A Comprehensive Multilingual Benchmark for Code  Translation",
    "abstract": "Recent code translation techniques exploit neural machine translation models to translate source code from one programming language to another to satisfy production compatibility or to improve efficiency of codebase maintenance. Most existing code translation datasets only focus on a single pair of popular programming languages. To advance research on code translation and meet diverse requirements of real-world applications, we construct CodeTransOcean, a large-scale comprehensive benchmark that supports the largest variety of languages for code translation. CodeTransOcean consists of three novel multilingual datasets, namely, MultilingualTrans supporting translations between multiple popular programming languages, NicheTrans for translating between niche programming languages and popular ones, and LLMTrans for evaluating compilability of translated code by large language models (LLMs). CodeTransOcean also includes a novel cross-framework dataset, DLTrans, for translating deep learning code across different frameworks. We develop multilingual modeling approaches for code translation and demonstrate their great potential in improving the translation quality of both low-resource and high-resource language pairs and boosting the training efficiency. We also propose a novel evaluation metric Debugging Success Rate@K for program-level code translation. Last but not least, we evaluate LLM ChatGPT on our datasets and investigate its potential for fuzzy compilation predictions. We build baselines for CodeTransOcean and analyze challenges of code translation for guiding future research. ",
    "url": "https://arxiv.org/abs/2310.04951",
    "authors": [
      "Weixiang Yan",
      "Yuchen Tian",
      "Yunzhe Li",
      "Qian Chen",
      "Wen Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2310.04955",
    "title": "Information-Theoretic Bounds on The Removal of Attribute-Specific Bias  From Neural Networks",
    "abstract": "Ensuring a neural network is not relying on protected attributes (e.g., race, sex, age) for predictions is crucial in advancing fair and trustworthy AI. While several promising methods for removing attribute bias in neural networks have been proposed, their limitations remain under-explored. In this work, we mathematically and empirically reveal an important limitation of attribute bias removal methods in presence of strong bias. Specifically, we derive a general non-vacuous information-theoretical upper bound on the performance of any attribute bias removal method in terms of the bias strength. We provide extensive experiments on synthetic, image, and census datasets to verify the theoretical bound and its consequences in practice. Our findings show that existing attribute bias removal methods are effective only when the inherent bias in the dataset is relatively weak, thus cautioning against the use of these methods in smaller datasets where strong attribute bias can occur, and advocating the need for methods that can overcome this limitation. ",
    "url": "https://arxiv.org/abs/2310.04955",
    "authors": [
      "Jiazhi Li",
      "Mahyar Khayatkhoei",
      "Jiageng Zhu",
      "Hanchen Xie",
      "Mohamed E. Hussein",
      "Wael AbdAlmageed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04970",
    "title": "Big Data Privacy in Emerging Market Fintech and Financial Services: A  Research Agenda",
    "abstract": "The data revolution in low- and middle-income countries is quickly transforming how companies approach emerging markets. As mobile phones and mobile money proliferate, they generate new streams of data that enable innovation in consumer finance, credit, and insurance. Already, this new generation of products are being used by hundreds of millions of consumers, often to use financial services for the first time. However, the collection, analysis, and use of these data, particularly from economically disadvantaged populations, raises serious privacy concerns. This white paper describes a research agenda to advance our understanding of the problem and solution space of data privacy in emerging market fintech and financial services. We highlight five priority areas for research: conducting comprehensive landscape analyses; understanding local definitions of ``data privacy''; documenting key sources of risk, and potential technical solutions (such as differential privacy and homomorphic encryption); improving non-technical approaches to data privacy (such as policies and practices); and understanding the tradeoffs involved in deploying privacy-enhancing solutions. Taken together, we hope this research agenda will focus attention on the multi-faceted nature of privacy in emerging markets, and catalyze efforts to develop responsible and consumer-oriented approaches to data-intensive applications. ",
    "url": "https://arxiv.org/abs/2310.04970",
    "authors": [
      "Joshua E. Blumenstock",
      "Nitin Kohli"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.04971",
    "title": "Understanding the Robustness of Multi-modal Contrastive Learning to  Distribution Shift",
    "abstract": "Recently, multimodal contrastive learning (MMCL) approaches, such as CLIP, have achieved a remarkable success in learning representations that are robust against distribution shift and generalize to new domains. Despite the empirical success, the mechanism behind learning such generalizable representations is not understood. In this work, we rigorously analyze this problem and uncover two mechanisms behind MMCL's robustness: \\emph{intra-class contrasting}, which allows the model to learn features with a high variance, and \\emph{inter-class feature sharing}, where annotated details in one class help learning other classes better. Both mechanisms prevent spurious features that are over-represented in the training data to overshadow the generalizable core features. This yields superior zero-shot classification accuracy under distribution shift. Furthermore, we theoretically demonstrate the benefits of using rich captions on robustness and explore the effect of annotating different types of details in the captions. We validate our theoretical findings through experiments, including a well-designed synthetic experiment and an experiment involving training CLIP on MS COCO and evaluating the model on variations of shifted ImageNet. ",
    "url": "https://arxiv.org/abs/2310.04971",
    "authors": [
      "Yihao Xue",
      "Siddharth Joshi",
      "Dang Nguyen",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04987",
    "title": "Data-centric Graph Learning: A Survey",
    "abstract": "The history of artificial intelligence (AI) has witnessed the significant impact of high-quality data on various deep learning models, such as ImageNet for AlexNet and ResNet. Recently, instead of designing more complex neural architectures as model-centric approaches, the attention of AI community has shifted to data-centric ones, which focuses on better processing data to strengthen the ability of neural models. Graph learning, which operates on ubiquitous topological data, also plays an important role in the era of deep learning. In this survey, we comprehensively review graph learning approaches from the data-centric perspective, and aim to answer two crucial questions: (1) when to modify graph data and (2) how to modify graph data to unlock the potential of various graph models. Accordingly, we propose a novel taxonomy based on the stages in the graph learning pipeline, and highlight the processing methods for different data structures in the graph data, i.e., topology, feature and label. Furthermore, we analyze some potential problems embedded in graph data and discuss how to solve them in a data-centric manner. Finally, we provide some promising future directions for data-centric graph learning. ",
    "url": "https://arxiv.org/abs/2310.04987",
    "authors": [
      "Cheng Yang",
      "Deyu Bo",
      "Jixi Liu",
      "Yufei Peng",
      "Boyu Chen",
      "Haoran Dai",
      "Ao Sun",
      "Yue Yu",
      "Yixin Xiao",
      "Qi Zhang",
      "Chunchen Wang",
      "Yuxin Guo",
      "Chuan Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.05002",
    "title": "Self-Knowledge Guided Retrieval Augmentation for Large Language Models",
    "abstract": "Large language models (LLMs) have shown superior performance without task-specific fine-tuning. Despite the success, the knowledge stored in the parameters of LLMs could still be incomplete and difficult to update due to the computational costs. As complementary, retrieval-based methods can offer non-parametric world knowledge and improve the performance on tasks such as question answering. However, we find that the retrieved knowledge does not always help and even has a negative impact on original responses occasionally. To better make use of both internal knowledge and external world knowledge, we investigate eliciting the model's ability to recognize what they know and do not know (which is also called self-knowledge) and propose Self-Knowledge guided Retrieval augmentation (SKR), a simple yet effective method which can let LLMs refer to the questions they have previously encountered and adaptively call for external resources when dealing with new questions. We evaluate SKR on multiple datasets and demonstrate that it outperforms chain-of-thought based and fully retrieval-based methods by using either InstructGPT or ChatGPT. ",
    "url": "https://arxiv.org/abs/2310.05002",
    "authors": [
      "Yile Wang",
      "Peng Li",
      "Maosong Sun",
      "Yang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.05007",
    "title": "MinPrompt: Graph-based Minimal Prompt Data Augmentation for Few-shot  Question Answering",
    "abstract": "Few-shot question answering (QA) aims at achieving satisfactory results on machine question answering when only a few training samples are available. Recent advances mostly rely on the power of pre-trained large language models (LLMs) and fine-tuning in specific settings. Although the pre-training stage has already equipped LLMs with powerful reasoning capabilities, LLMs still need to be fine-tuned to adapt to specific domains to achieve the best results. In this paper, we propose to select the most informative data for fine-tuning, thereby improving the efficiency of the fine-tuning process with comparative or even better accuracy on the open-domain QA task. We present MinPrompt, a minimal data augmentation framework for open-domain QA based on an approximate graph algorithm and unsupervised question generation. We transform the raw text into a graph structure to build connections between different factual sentences, then apply graph algorithms to identify the minimal set of sentences needed to cover the most information in the raw text. We then generate QA pairs based on the identified sentence subset and train the model on the selected sentences to obtain the final model. Empirical results on several benchmark datasets and theoretical analysis show that MinPrompt is able to achieve comparable or better results than baselines with a high degree of efficiency, bringing improvements in F-1 scores by up to 27.5%. ",
    "url": "https://arxiv.org/abs/2310.05007",
    "authors": [
      "Xiusi Chen",
      "Jyun-Yu Jiang",
      "Wei-Cheng Chang",
      "Cho-Jui Hsieh",
      "Hsiang-Fu Yu",
      "Wei Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.05022",
    "title": "Fully Spiking Neural Network for Legged Robots",
    "abstract": "In recent years, legged robots based on deep reinforcement learning have made remarkable progress. Quadruped robots have demonstrated the ability to complete challenging tasks in complex environments and have been deployed in real-world scenarios to assist humans. Simultaneously, bipedal and humanoid robots have achieved breakthroughs in various demanding tasks. Current reinforcement learning methods can utilize diverse robot bodies and historical information to perform actions. However, prior research has not emphasized the speed and energy consumption of network inference, as well as the biological significance of the neural networks themselves. Most of the networks employed are traditional artificial neural networks that utilize multilayer perceptrons (MLP). In this paper, we successfully apply a novel Spiking Neural Network (SNN) to process legged robots, achieving outstanding results across a range of simulated terrains. SNN holds a natural advantage over traditional neural networks in terms of inference speed and energy consumption, and their pulse-form processing of body perception signals offers improved biological interpretability. To the best of our knowledge, this is the first work to implement SNN in legged robots. ",
    "url": "https://arxiv.org/abs/2310.05022",
    "authors": [
      "Xiaoyang Jiang",
      "Qiang Zhang",
      "Jingkai Sun",
      "Renjing Xu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05027",
    "title": "Rigid Clumps in the MercuryDPM Particle Dynamics Code",
    "abstract": "Discrete particle simulations have become the standard in science and industrial applications exploring the properties of particulate systems. Most of such simulations rely on the concept of interacting spherical particles to describe the properties of particulates, although, the correct representation of the nonspherical particle shape is crucial for a number of applications. In this work we describe the implementation of clumps, i.e. assemblies of rigidly connected spherical particles, which can approximate given nonspherical shapes, within the \\textit{MercuryDPM} particle dynamics code. \\textit{MercuryDPM} contact detection algorithm is particularly efficient for polydisperse particle systems, which is essential for multilevel clumps approximating complex surfaces. We employ the existing open-source \\texttt{CLUMP} library to generate clump particles. We detail the pre-processing tools providing necessary initial data, as well as the necessary adjustments of the algorithms of contact detection, collision/migration and numerical time integration. The capabilities of our implementation are illustrated for a variety of examples. ",
    "url": "https://arxiv.org/abs/2310.05027",
    "authors": [
      "Igor Ostanin",
      "Vasileios Angelidakis",
      "Timo Plath",
      "Sahar Pourandi",
      "Anthony Thornton",
      "Thomas Weinhart"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ]
  },
  {
    "id": "arXiv:2310.05030",
    "title": "Counter Turing Test CT^2: AI-Generated Text Detection is Not as Easy as  You May Think -- Introducing AI Detectability Index",
    "abstract": "With the rise of prolific ChatGPT, the risk and consequences of AI-generated text has increased alarmingly. To address the inevitable question of ownership attribution for AI-generated artifacts, the US Copyright Office released a statement stating that 'If a work's traditional elements of authorship were produced by a machine, the work lacks human authorship and the Office will not register it'. Furthermore, both the US and the EU governments have recently drafted their initial proposals regarding the regulatory framework for AI. Given this cynosural spotlight on generative AI, AI-generated text detection (AGTD) has emerged as a topic that has already received immediate attention in research, with some initial methods having been proposed, soon followed by emergence of techniques to bypass detection. This paper introduces the Counter Turing Test (CT^2), a benchmark consisting of techniques aiming to offer a comprehensive evaluation of the robustness of existing AGTD techniques. Our empirical findings unequivocally highlight the fragility of the proposed AGTD methods under scrutiny. Amidst the extensive deliberations on policy-making for regulating AI development, it is of utmost importance to assess the detectability of content generated by LLMs. Thus, to establish a quantifiable spectrum facilitating the evaluation and ranking of LLMs according to their detectability levels, we propose the AI Detectability Index (ADI). We conduct a thorough examination of 15 contemporary LLMs, empirically demonstrating that larger LLMs tend to have a higher ADI, indicating they are less detectable compared to smaller LLMs. We firmly believe that ADI holds significant value as a tool for the wider NLP community, with the potential to serve as a rubric in AI-related policy-making. ",
    "url": "https://arxiv.org/abs/2310.05030",
    "authors": [
      "Megha Chakraborty",
      "S.M Towhidul Islam Tonmoy",
      "S M Mehedi Zaman",
      "Krish Sharma",
      "Niyar R Barman",
      "Chandan Gupta",
      "Shreya Gautam",
      "Tanay Kumar",
      "Vinija Jain",
      "Aman Chadha",
      "Amit P. Sheth",
      "Amitava Das"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05032",
    "title": "PASSION: Permissioned Access Control for Segmented Devices and Identity  for IoT Networks",
    "abstract": "In recent years, there has been a significant proliferation of industrial Internet of Things (IoT) applications, with a wide variety of use cases being developed and put into operation. As the industrial IoT landscape expands, the establishment of secure and reliable infrastructure becomes crucial to instil trust among users and stakeholders, particularly in addressing fundamental concerns such as traceability, integrity protection, and privacy that some industries still encounter today. This paper introduces a privacy-preserving method in the industry's IoT systems using blockchain-based data access control for remote industry safety monitoring and maintaining event information confidentiality, integrity and authenticity. ",
    "url": "https://arxiv.org/abs/2310.05032",
    "authors": [
      "Hisham Ali",
      "Mwrwan Abubakar",
      "Jawad Ahmad",
      "William J. Buchanan",
      "Zakwan Jaroucheh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.05034",
    "title": "Deep Reinforcement Learning Based Cross-Layer Design in Terahertz Mesh  Backhaul Networks",
    "abstract": "Supporting ultra-high data rates and flexible reconfigurability, Terahertz (THz) mesh networks are attractive for next-generation wireless backhaul systems that empower the integrated access and backhaul (IAB). In THz mesh backhaul networks, the efficient cross-layer routing and long-term resource allocation is yet an open problem due to dynamic traffic demands as well as possible link failures caused by the high directivity and high non-line-of-sight (NLoS) path loss of THz spectrum. In addition, unpredictable data traffic and the mixed integer programming property with the NP-hard nature further challenge the effective routing and long-term resource allocation design. In this paper, a deep reinforcement learning (DRL) based cross-layer design in THz mesh backhaul networks (DEFLECT) is proposed, by considering dynamic traffic demands and possible sudden link failures. In DEFLECT, a heuristic routing metric is first devised to facilitate resource efficiency (RE) enhancement regarding energy and sub-array usages. Furthermore, a DRL based resource allocation algorithm is developed to realize long-term RE maximization and fast recovery from broken links. Specifically in the DRL method, the exploited multi-task structure cooperatively benefits joint power and sub-array allocation. Additionally, the leveraged hierarchical architecture realizes tailored resource allocation for each base station and learned knowledge transfer for fast recovery. Simulation results show that DEFLECT routing consumes less resource, compared to the minimal hop-count metric. Moreover, unlike conventional DRL methods causing packet loss and second-level latency, DEFLECT DRL realizes the long-term RE maximization with no packet loss and millisecond-level latency, and recovers resource-efficient backhaul from broken links within 1s. ",
    "url": "https://arxiv.org/abs/2310.05034",
    "authors": [
      "Zhifeng Hu",
      "Chong Han",
      "Xudong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05046",
    "title": "Harnessing the Power of ChatGPT in Fake News: An In-Depth Exploration in  Generation, Detection and Explanation",
    "abstract": "The rampant spread of fake news has adversely affected society, resulting in extensive research on curbing its spread. As a notable milestone in large language models (LLMs), ChatGPT has gained significant attention due to its exceptional natural language processing capabilities. In this study, we present a thorough exploration of ChatGPT's proficiency in generating, explaining, and detecting fake news as follows. Generation -- We employ four prompt methods to generate fake news samples and prove the high quality of these samples through both self-assessment and human evaluation. Explanation -- We obtain nine features to characterize fake news based on ChatGPT's explanations and analyze the distribution of these factors across multiple public datasets. Detection -- We examine ChatGPT's capacity to identify fake news. We explore its detection consistency and then propose a reason-aware prompt method to improve its performance. Although our experiments demonstrate that ChatGPT shows commendable performance in detecting fake news, there is still room for its improvement. Consequently, we further probe into the potential extra information that could bolster its effectiveness in detecting fake news. ",
    "url": "https://arxiv.org/abs/2310.05046",
    "authors": [
      "Yue Huang",
      "Lichao Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.05056",
    "title": "Language-driven Open-Vocabulary Keypoint Detection for Animal Body and  Face",
    "abstract": "Current approaches for image-based keypoint detection on animal (including human) body and face are limited to specific keypoints and species. We address the limitation by proposing the Open-Vocabulary Keypoint Detection (OVKD) task. It aims to use text prompts to localize arbitrary keypoints of any species. To accomplish this objective, we propose Open-Vocabulary Keypoint Detection with Semantic-feature Matching (KDSM), which utilizes both vision and language models to harness the relationship between text and vision and thus achieve keypoint detection through associating text prompt with relevant keypoint features. Additionally, KDSM integrates domain distribution matrix matching and some special designs to reinforce the relationship between language and vision, thereby improving the model's generalizability and performance. Extensive experiments show that our proposed components bring significant performance improvements, and our overall method achieves impressive results in OVKD. Remarkably, our method outperforms the state-of-the-art few-shot keypoint detection methods using a zero-shot fashion. We will make the source code publicly accessible. ",
    "url": "https://arxiv.org/abs/2310.05056",
    "authors": [
      "Hao Zhang",
      "Kaipeng Zhang",
      "Lumin Xu",
      "Shenqi Lai",
      "Wenqi Shao",
      "Naning Zheng",
      "Ping Luo",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05060",
    "title": "Video-CSR: Complex Video Digest Creation for Visual-Language Models",
    "abstract": "We present a novel task and human annotated dataset for evaluating the ability for visual-language models to generate captions and summaries for real-world video clips, which we call Video-CSR (Captioning, Summarization and Retrieval). The dataset contains 4.8K YouTube video clips of 20-60 seconds in duration and covers a wide range of topics and interests. Each video clip corresponds to 5 independently annotated captions (1 sentence) and summaries (3-10 sentences). Given any video selected from the dataset and its corresponding ASR information, we evaluate visual-language models on either caption or summary generation that is grounded in both the visual and auditory content of the video. Additionally, models are also evaluated on caption- and summary-based retrieval tasks, where the summary-based retrieval task requires the identification of a target video given excerpts of a corresponding summary. Given the novel nature of the paragraph-length video summarization task, we perform extensive comparative analyses of different existing evaluation metrics and their alignment with human preferences. Finally, we propose a foundation model with competitive generation and retrieval capabilities that serves as a baseline for the Video-CSR task. We aim for Video-CSR to serve as a useful evaluation set in the age of large language models and complex multi-modal tasks. ",
    "url": "https://arxiv.org/abs/2310.05060",
    "authors": [
      "Tingkai Liu",
      "Yunzhe Tao",
      "Haogeng Liu",
      "Qihang Fan",
      "Ding Zhou",
      "Huaibo Huang",
      "Ran He",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05070",
    "title": "CO-ASnet :A Smart Contract Architecture Design based on Blockchain  Technology with Active Sensor Networks",
    "abstract": "The influence of opinion leaders impacts different aspects of social finance. How to analyse the utility of opinion leaders' influence in realizing assets on the blockchain and adopt a compliant regulatory scheme is worth exploring and pondering. Taking Musk's call on social media to buy Dogecoin as an example, this paper uses an event study to empirically investigate the phenomenon in which opinion leaders use ICOs (initial coin offerings) to exert influence. The results show that opinion leaders can use ICOs to influence the price of token assets with money and data traffic in their social network. They can obtain excess returns and reduce the cost of realization so that the closed loop of influence realization will be accelerated. Based on this phenomenon and the results of its impact, we use the ChainLink Oracle with Active Sensor Networks(CO-ASnet) to design a safe and applicable decentralized regulatory scheme that can constructively provide risk assessment strategies and early warning measures for token issuance. The influence realization of opinion leaders in blockchain issuance is bound to receive widespread attention, and this paper will provide an exemplary reference for regulators and enterprises to explore the boundaries of blockchain financial product development and governance. ",
    "url": "https://arxiv.org/abs/2310.05070",
    "authors": [
      "Feng Liu",
      "Jie Yang",
      "Kun-peng Xu",
      "Cang-long Pu",
      "Jiayin Qi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.05083",
    "title": "FLatS: Principled Out-of-Distribution Detection with Feature-Based  Likelihood Ratio Score",
    "abstract": "Detecting out-of-distribution (OOD) instances is crucial for NLP models in practical applications. Although numerous OOD detection methods exist, most of them are empirical. Backed by theoretical analysis, this paper advocates for the measurement of the \"OOD-ness\" of a test case $\\boldsymbol{x}$ through the likelihood ratio between out-distribution $\\mathcal P_{\\textit{out}}$ and in-distribution $\\mathcal P_{\\textit{in}}$. We argue that the state-of-the-art (SOTA) feature-based OOD detection methods, such as Maha and KNN, are suboptimal since they only estimate in-distribution density $p_{\\textit{in}}(\\boldsymbol{x})$. To address this issue, we propose FLatS, a principled solution for OOD detection based on likelihood ratio. Moreover, we demonstrate that FLatS can serve as a general framework capable of enhancing other OOD detection methods by incorporating out-distribution density $p_{\\textit{out}}(\\boldsymbol{x})$ estimation. Experiments show that FLatS establishes a new SOTA on popular benchmarks. Our code is publicly available at https://github.com/linhaowei1/FLatS. ",
    "url": "https://arxiv.org/abs/2310.05083",
    "authors": [
      "Haowei Lin",
      "Yuntian Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.05103",
    "title": "Zero-Shot Detection of Machine-Generated Codes",
    "abstract": "This work proposes a training-free approach for the detection of LLMs-generated codes, mitigating the risks associated with their indiscriminate usage. To the best of our knowledge, our research is the first to investigate zero-shot detection techniques applied to code generated by advanced black-box LLMs like ChatGPT. Firstly, we find that existing training-based or zero-shot text detectors are ineffective in detecting code, likely due to the unique statistical properties found in code structures. We then modify the previous zero-shot text detection method, DetectGPT (Mitchell et al., 2023) by utilizing a surrogate white-box model to estimate the probability of the rightmost tokens, allowing us to identify code snippets generated by language models. Through extensive experiments conducted on the python codes of the CodeContest and APPS dataset, our approach demonstrates its effectiveness by achieving state-of-the-art detection results on text-davinci-003, GPT-3.5, and GPT-4 models. Moreover, our method exhibits robustness against revision attacks and generalizes well to Java codes. We also find that the smaller code language model like PolyCoder-160M performs as a universal code detector, outperforming the billion-scale counterpart. The codes will be available at https://github.com/ Xianjun-Yang/Code_detection.git ",
    "url": "https://arxiv.org/abs/2310.05103",
    "authors": [
      "Xianjun Yang",
      "Kexun Zhang",
      "Haifeng Chen",
      "Linda Petzold",
      "William Yang Wang",
      "Wei Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05105",
    "title": "How Graph Neural Networks Learn: Lessons from Training Dynamics in  Function Space",
    "abstract": "A long-standing goal in deep learning has been to characterize the learning behavior of black-box models in a more interpretable manner. For graph neural networks (GNNs), considerable advances have been made in formalizing what functions they can represent, however it remains less clear whether and how GNNs learn desired functions during the optimization process. To fill this critical gap, we study the learning dynamics of GNNs in function space via the analytic framework of overparameterization. In particular, we find that the seemingly complicated training process of GNNs can be re-cast into a more familiar label propagation framework, due to the graph inductive bias implicit in this process. From this vantage point, we provide explanations for why the learned GNN functions successfully generalize and for their pathological behavior on heterophilic graphs, which are consistent with observations. Practically, sparsifying and implementing the learning dynamics lead to a minimalist semi-supervised learning algorithm with the efficiency of classic algorithms and the effectiveness of modern GNNs. ",
    "url": "https://arxiv.org/abs/2310.05105",
    "authors": [
      "Chenxiao Yang",
      "Qitian Wu",
      "David Wipf",
      "Ruoyu Sun",
      "Junchi Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05108",
    "title": "Enhancing Representations through Heterogeneous Self-Supervised Learning",
    "abstract": "Incorporating heterogeneous representations from different architectures has facilitated various vision tasks, e.g., some hybrid networks combine transformers and convolutions. However, complementarity between such heterogeneous architectures has not been well exploited in self-supervised learning. Thus, we propose Heterogeneous Self-Supervised Learning (HSSL), which enforces a base model to learn from an auxiliary head whose architecture is heterogeneous from the base model. In this process, HSSL endows the base model with new characteristics in a representation learning way without structural changes. To comprehensively understand the HSSL, we conduct experiments on various heterogeneous pairs containing a base model and an auxiliary head. We discover that the representation quality of the base model moves up as their architecture discrepancy grows. This observation motivates us to propose a search strategy that quickly determines the most suitable auxiliary head for a specific base model to learn and several simple but effective methods to enlarge the model discrepancy. The HSSL is compatible with various self-supervised methods, achieving superior performances on various downstream tasks, including image classification, semantic segmentation, instance segmentation, and object detection. Our source code will be made publicly available. ",
    "url": "https://arxiv.org/abs/2310.05108",
    "authors": [
      "Zhong-Yu Li",
      "Bo-Wen Yin",
      "Shanghua Gao",
      "Yongxiang Liu",
      "Li Liu",
      "Ming-Ming Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05119",
    "title": "Dynamic Multi-Domain Knowledge Networks for Chest X-ray Report  Generation",
    "abstract": "The automated generation of radiology diagnostic reports helps radiologists make timely and accurate diagnostic decisions while also enhancing clinical diagnostic efficiency. However, the significant imbalance in the distribution of data between normal and abnormal samples (including visual and textual biases) poses significant challenges for a data-driven task like automatically generating diagnostic radiology reports. Therefore, we propose a Dynamic Multi-Domain Knowledge(DMDK) network for radiology diagnostic report generation. The DMDK network consists of four modules: Chest Feature Extractor(CFE), Dynamic Knowledge Extractor(DKE), Specific Knowledge Extractor(SKE), and Multi-knowledge Integrator(MKI) module. Specifically, the CFE module is primarily responsible for extracting the unprocessed visual medical features of the images. The DKE module is responsible for extracting dynamic disease topic labels from the retrieved radiology diagnostic reports. We then fuse the dynamic disease topic labels with the original visual features of the images to highlight the abnormal regions in the original visual features to alleviate the visual data bias problem. The SKE module expands upon the conventional static knowledge graph to mitigate textual data biases and amplify the interpretability capabilities of the model via domain-specific dynamic knowledge graphs. The MKI distills all the knowledge and generates the final diagnostic radiology report. We performed extensive experiments on two widely used datasets, IU X-Ray and MIMIC-CXR. The experimental results demonstrate the effectiveness of our method, with all evaluation metrics outperforming previous state-of-the-art models. ",
    "url": "https://arxiv.org/abs/2310.05119",
    "authors": [
      "Weihua Liu",
      "Youyuan Xue",
      "Chaochao Lin",
      "Said Boumaraf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05124",
    "title": "Cross-domain Robust Deepfake Bias Expansion Network for Face Forgery  Detection",
    "abstract": "The rapid advancement of deepfake technologies raises significant concerns about the security of face recognition systems. While existing methods leverage the clues left by deepfake techniques for face forgery detection, malicious users may intentionally manipulate forged faces to obscure the traces of deepfake clues and thereby deceive detection tools. Meanwhile, attaining cross-domain robustness for data-based methods poses a challenge due to potential gaps in the training data, which may not encompass samples from all relevant domains. Therefore, in this paper, we introduce a solution - a Cross-Domain Robust Bias Expansion Network (BENet) - designed to enhance face forgery detection. BENet employs an auto-encoder to reconstruct input faces, maintaining the invariance of real faces while selectively enhancing the difference between reconstructed fake faces and their original counterparts. This enhanced bias forms a robust foundation upon which dependable forgery detection can be built. To optimize the reconstruction results in BENet, we employ a bias expansion loss infused with contrastive concepts to attain the aforementioned objective. In addition, to further heighten the amplification of forged clues, BENet incorporates a Latent-Space Attention (LSA) module. This LSA module effectively captures variances in latent features between the auto-encoder's encoder and decoder, placing emphasis on inconsistent forgery-related information. Furthermore, BENet incorporates a cross-domain detector with a threshold to determine whether the sample belongs to a known distribution. The correction of classification results through the cross-domain detector enables BENet to defend against unknown deepfake attacks from cross-domain. Extensive experiments demonstrate the superiority of BENet compared with state-of-the-art methods in intra-database and cross-database evaluations. ",
    "url": "https://arxiv.org/abs/2310.05124",
    "authors": [
      "Weihua Liu",
      "Lin Li",
      "Chaochao Lin",
      "Said Boumaraf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05129",
    "title": "ed-cec: improving rare word recognition using asr postprocessing based  on error detection and context-aware error correction",
    "abstract": "Automatic speech recognition (ASR) systems often encounter difficulties in accurately recognizing rare words, leading to errors that can have a negative impact on downstream tasks such as keyword spotting, intent detection, and text summarization. To address this challenge, we present a novel ASR postprocessing method that focuses on improving the recognition of rare words through error detection and context-aware error correction. Our method optimizes the decoding process by targeting only the predicted error positions, minimizing unnecessary computations. Moreover, we leverage a rare word list to provide additional contextual knowledge, enabling the model to better correct rare words. Experimental results across five datasets demonstrate that our proposed method achieves significantly lower word error rates (WERs) than previous approaches while maintaining a reasonable inference speed. Furthermore, our approach exhibits promising robustness across different ASR systems. ",
    "url": "https://arxiv.org/abs/2310.05129",
    "authors": [
      "Jiajun He",
      "Zekun Yang",
      "Tomoki Toda"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05130",
    "title": "Fast-DetectGPT: Efficient Zero-Shot Detection of Machine-Generated Text  via Conditional Probability Curvature",
    "abstract": "Large language models (LLMs) have shown the ability to produce fluent and cogent content, presenting both productivity opportunities and societal risks. To build trustworthy AI systems, it is imperative to distinguish between machine-generated and human-authored content. The leading zero-shot detector, DetectGPT, showcases commendable performance but is marred by its intensive computational costs. In this paper, we introduce the concept of conditional probability curvature to elucidate discrepancies in word choices between LLMs and humans within a given context. Utilizing this curvature as a foundational metric, we present Fast-DetectGPT, an optimized zero-shot detector, which substitutes DetectGPT's perturbation step with a more efficient sampling step. Our evaluations on various datasets, source models, and test conditions indicate that Fast-DetectGPT not only outperforms DetectGPT in both the white-box and black-box settings but also accelerates the detection process by a factor of 340, as detailed in Table 1. ",
    "url": "https://arxiv.org/abs/2310.05130",
    "authors": [
      "Guangsheng Bao",
      "Yanbin Zhao",
      "Zhiyang Teng",
      "Linyi Yang",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.05136",
    "title": "InstructDET: Diversifying Referring Object Detection with Generalized  Instructions",
    "abstract": "We propose InstructDET, a data-centric method for referring object detection (ROD) that localizes target objects based on user instructions. While deriving from referring expressions (REC), the instructions we leverage are greatly diversified to encompass common user intentions related to object detection. For one image, we produce tremendous instructions that refer to every single object and different combinations of multiple objects. Each instruction and its corresponding object bounding boxes (bbxs) constitute one training data pair. In order to encompass common detection expressions, we involve emerging vision-language model (VLM) and large language model (LLM) to generate instructions guided by text prompts and object bbxs, as the generalizations of foundation models are effective to produce human-like expressions (e.g., describing object property, category, and relationship). We name our constructed dataset as InDET. It contains images, bbxs and generalized instructions that are from foundation models. Our InDET is developed from existing REC datasets and object detection datasets, with the expanding potential that any image with object bbxs can be incorporated through using our InstructDET method. By using our InDET dataset, we show that a conventional ROD model surpasses existing methods on standard REC datasets and our InDET test set. Our data-centric method InstructDET, with automatic data expansion by leveraging foundation models, directs a promising field that ROD can be greatly diversified to execute common object detection instructions. ",
    "url": "https://arxiv.org/abs/2310.05136",
    "authors": [
      "Ronghao Dang",
      "Jiangyan Feng",
      "Haodong Zhang",
      "Chongjian Ge",
      "Lin Song",
      "Lijun Gong",
      "Chengju Liu",
      "Qijun Chen",
      "Feng Zhu",
      "Rui Zhao",
      "Yibing Song"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05139",
    "title": "Maximizing Utilitarian and Egalitarian Welfare of Fractional Hedonic  Games on Tree-like Graphs",
    "abstract": "Fractional hedonic games are coalition formation games where a player's utility is determined by the average value they assign to the members of their coalition. These games are a variation of graph hedonic games, which are a class of coalition formation games that can be succinctly represented. Due to their applicability in network clustering and their relationship to graph hedonic games, fractional hedonic games have been extensively studied from various perspectives. However, finding welfare-maximizing partitions in fractional hedonic games is a challenging task due to the nonlinearity of utilities. In fact, it has been proven to be NP-hard and can be solved in polynomial time only for a limited number of graph classes, such as trees. This paper presents (pseudo)polynomial-time algorithms to compute welfare-maximizing partitions in fractional hedonic games on tree-like graphs. We consider two types of social welfare measures: utilitarian and egalitarian. Tree-like graphs refer to graphs with bounded treewidth and block graphs. A hardness result is provided, demonstrating that the pseudopolynomial-time solvability is the best possible under the assumption P$\\neq$NP. ",
    "url": "https://arxiv.org/abs/2310.05139",
    "authors": [
      "Tesshu Hanaka",
      "Airi Ikeyama",
      "Hirotaka Ono"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05141",
    "title": "Transferable Availability Poisoning Attacks",
    "abstract": "We consider availability data poisoning attacks, where an adversary aims to degrade the overall test accuracy of a machine learning model by crafting small perturbations to its training data. Existing poisoning strategies can achieve the attack goal but assume the victim to employ the same learning method as what the adversary uses to mount the attack. In this paper, we argue that this assumption is strong, since the victim may choose any learning algorithm to train the model as long as it can achieve some targeted performance on clean data. Empirically, we observe a large decrease in the effectiveness of prior poisoning attacks if the victim uses a different learning paradigm to train the model and show marked differences in frequency-level characteristics between perturbations generated with respect to different learners and attack methods. To enhance the attack transferability, we propose Transferable Poisoning, which generates high-frequency poisoning perturbations by alternately leveraging the gradient information with two specific algorithms selected from supervised and unsupervised contrastive learning paradigms. Through extensive experiments on benchmark image datasets, we show that our transferable poisoning attack can produce poisoned samples with significantly improved transferability, not only applicable to the two learners used to devise the attack but also for learning algorithms and even paradigms beyond. ",
    "url": "https://arxiv.org/abs/2310.05141",
    "authors": [
      "Yiyong Liu",
      "Michael Backes",
      "Xiao Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05150",
    "title": "From Data to Dialogue: Leveraging the Structure of Knowledge Graphs for  Conversational Exploratory Search",
    "abstract": "Exploratory search is an open-ended information retrieval process that aims at discovering knowledge about a topic or domain rather than searching for a specific answer or piece of information. Conversational interfaces are particularly suitable for supporting exploratory search, allowing users to refine queries and examine search results through interactive dialogues. In addition to conversational search interfaces, knowledge graphs are also useful in supporting information exploration due to their rich semantic representation of data items. In this study, we demonstrate the synergistic effects of combining knowledge graphs and conversational interfaces for exploratory search, bridging the gap between structured and unstructured information retrieval. To this end, we propose a knowledge-driven dialogue system for exploring news articles by asking natural language questions and using the graph structure to navigate between related topics. Based on a user study with 54 participants, we empirically evaluate the effectiveness of the graph-based exploratory search and discuss design implications for developing such systems. ",
    "url": "https://arxiv.org/abs/2310.05150",
    "authors": [
      "Phillip Schneider",
      "Nils Rehtanz",
      "Kristiina Jokinen",
      "Florian Matthes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.05161",
    "title": "Recurrent Neural Language Models as Probabilistic Finite-state Automata",
    "abstract": "Studying language models (LMs) in terms of well-understood formalisms allows us to precisely characterize their abilities and limitations. Previous work has investigated the representational capacity of recurrent neural network (RNN) LMs in terms of their capacity to recognize unweighted formal languages. However, LMs do not describe unweighted formal languages -- rather, they define probability distributions over strings. In this work, we study what classes of such probability distributions RNN LMs can represent, which allows us to make more direct statements about their capabilities. We show that simple RNNs are equivalent to a subclass of probabilistic finite-state automata, and can thus model a strict subset of probability distributions expressible by finite-state models. Furthermore, we study the space complexity of representing finite-state LMs with RNNs. We show that, to represent an arbitrary deterministic finite-state LM with $N$ states over an alphabet $\\Sigma$, an RNN requires $\\Omega\\left(N |\\Sigma|\\right)$ neurons. These results present a first step towards characterizing the classes of distributions RNN LMs can represent and thus help us understand their capabilities and limitations. ",
    "url": "https://arxiv.org/abs/2310.05161",
    "authors": [
      "Anej Svete",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05171",
    "title": "Multi-Ship Tracking by Robust Similarity metric",
    "abstract": "Multi-ship tracking (MST) as a core technology has been proven to be applied to situational awareness at sea and the development of a navigational system for autonomous ships. Despite impressive tracking outcomes achieved by multi-object tracking (MOT) algorithms for pedestrian and vehicle datasets, these models and techniques exhibit poor performance when applied to ship datasets. Intersection of Union (IoU) is the most popular metric for computing similarity used in object tracking. The low frame rates and severe image shake caused by wave turbulence in ship datasets often result in minimal, or even zero, Intersection of Union (IoU) between the predicted and detected bounding boxes. This issue contributes to frequent identity switches of tracked objects, undermining the tracking performance. In this paper, we address the weaknesses of IoU by incorporating the smallest convex shapes that enclose both the predicted and detected bounding boxes. The calculation of the tracking version of IoU (TIoU) metric considers not only the size of the overlapping area between the detection bounding box and the prediction box, but also the similarity of their shapes. Through the integration of the TIoU into state-of-the-art object tracking frameworks, such as DeepSort and ByteTrack, we consistently achieve improvements in the tracking performance of these frameworks. ",
    "url": "https://arxiv.org/abs/2310.05171",
    "authors": [
      "Hongyu Zhao",
      "Gongming Wei",
      "Yang Xiao",
      "Xianglei Xing"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05172",
    "title": "On the Amplification of Cache Occupancy Attacks in Randomized Cache  Architectures",
    "abstract": "In this work, we explore the applicability of cache occupancy attacks and the implications of secured cache design rationales on such attacks. In particular, we show that one of the well-known cache randomization schemes, MIRAGE, touted to be resilient against eviction-based attacks, amplifies the chances of cache occupancy attack, making it more vulnerable compared to contemporary designs. We leverage MIRAGE's global eviction property to demonstrate covert channel with byte-level granularity, with far less cache occupancy requirement (just $10\\%$ of LLC) than other schemes. For instance, ScatterCache (a randomisation scheme with lesser security guarantees than MIRAGE) and generic set-associative caches require $40\\%$ and $30\\%$ cache occupancy, respectively, to exhibit covert communication. Furthermore, we extend our attack vectors to include side-channel, template-based fingerprinting of workloads in a cross-core setting. We demonstrate the potency of such fingerprinting on both inhouse LLC simulator as well as on SPEC2017 workloads on gem5. Finally, we pinpoint implementation inconsistencies in MIRAGE's publicly available gem5 artifact which motivates a re-evaluation of the performance statistics of MIRAGE with respect to ScatterCache and baseline set-associative cache. We find MIRAGE, in reality, performs worse than what is previously reported in literature, a concern that should be addressed in successor generations of secured caches. ",
    "url": "https://arxiv.org/abs/2310.05172",
    "authors": [
      "Anirban Chakraborty",
      "Nimish Mishra",
      "Sayandeep Saha",
      "Sarani Bhattacharya",
      "Debdeep Mukhopadhyay"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2310.05174",
    "title": "GSLB: The Graph Structure Learning Benchmark",
    "abstract": "Graph Structure Learning (GSL) has recently garnered considerable attention due to its ability to optimize both the parameters of Graph Neural Networks (GNNs) and the computation graph structure simultaneously. Despite the proliferation of GSL methods developed in recent years, there is no standard experimental setting or fair comparison for performance evaluation, which creates a great obstacle to understanding the progress in this field. To fill this gap, we systematically analyze the performance of GSL in different scenarios and develop a comprehensive Graph Structure Learning Benchmark (GSLB) curated from 20 diverse graph datasets and 16 distinct GSL algorithms. Specifically, GSLB systematically investigates the characteristics of GSL in terms of three dimensions: effectiveness, robustness, and complexity. We comprehensively evaluate state-of-the-art GSL algorithms in node- and graph-level tasks, and analyze their performance in robust learning and model complexity. Further, to facilitate reproducible research, we have developed an easy-to-use library for training, evaluating, and visualizing different GSL methods. Empirical results of our extensive experiments demonstrate the ability of GSL and reveal its potential benefits on various downstream tasks, offering insights and opportunities for future research. The code of GSLB is available at: https://github.com/GSL-Benchmark/GSLB. ",
    "url": "https://arxiv.org/abs/2310.05174",
    "authors": [
      "Zhixun Li",
      "Liang Wang",
      "Xin Sun",
      "Yifan Luo",
      "Yanqiao Zhu",
      "Dingshuo Chen",
      "Yingtao Luo",
      "Xiangxin Zhou",
      "Qiang Liu",
      "Shu Wu",
      "Liang Wang",
      "Jeffrey Xu Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05184",
    "title": "AANet: Aggregation and Alignment Network with Semi-hard Positive Sample  Mining for Hierarchical Place Recognition",
    "abstract": "Visual place recognition (VPR) is one of the research hotspots in robotics, which uses visual information to locate robots. Recently, the hierarchical two-stage VPR methods have become popular in this field due to the trade-off between accuracy and efficiency. These methods retrieve the top-k candidate images using the global features in the first stage, then re-rank the candidates by matching the local features in the second stage. However, they usually require additional algorithms (e.g. RANSAC) for geometric consistency verification in re-ranking, which is time-consuming. Here we propose a Dynamically Aligning Local Features (DALF) algorithm to align the local features under spatial constraints. It is significantly more efficient than the methods that need geometric consistency verification. We present a unified network capable of extracting global features for retrieving candidates via an aggregation module and aligning local features for re-ranking via the DALF alignment module. We call this network AANet. Meanwhile, many works use the simplest positive samples in triplet for weakly supervised training, which limits the ability of the network to recognize harder positive pairs. To address this issue, we propose a Semi-hard Positive Sample Mining (ShPSM) strategy to select appropriate hard positive images for training more robust VPR networks. Extensive experiments on four benchmark VPR datasets show that the proposed AANet can outperform several state-of-the-art methods with less time consumption. The code is released at https://github.com/Lu-Feng/AANet. ",
    "url": "https://arxiv.org/abs/2310.05184",
    "authors": [
      "Feng Lu",
      "Lijun Zhang",
      "Shuting Dong",
      "Baifan Chen",
      "Chun Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05185",
    "title": "Text2NKG: Fine-Grained N-ary Relation Extraction for N-ary relational  Knowledge Graph Construction",
    "abstract": "Beyond traditional binary relational facts, n-ary relational knowledge graphs (NKGs) are comprised of n-ary relational facts containing more than two entities, which are closer to real-world facts with broader applications. However, the construction of NKGs still significantly relies on manual labor, and n-ary relation extraction still remains at a course-grained level, which is always in a single schema and fixed arity of entities. To address these restrictions, we propose Text2NKG, a novel fine-grained n-ary relation extraction framework for n-ary relational knowledge graph construction. We introduce a span-tuple classification approach with hetero-ordered merging to accomplish fine-grained n-ary relation extraction in different arity. Furthermore, Text2NKG supports four typical NKG schemas: hyper-relational schema, event-based schema, role-based schema, and hypergraph-based schema, with high flexibility and practicality. Experimental results demonstrate that Text2NKG outperforms the previous state-of-the-art model by nearly 20\\% points in the $F_1$ scores on the fine-grained n-ary relation extraction benchmark in the hyper-relational schema. Our code and datasets are publicly available. ",
    "url": "https://arxiv.org/abs/2310.05185",
    "authors": [
      "Haoran Luo",
      "Haihong E",
      "Yuhao Yang",
      "Tianyu Yao",
      "Yikai Guo",
      "Zichen Tang",
      "Wentai Zhang",
      "Kaiyang Wan",
      "Shiyao Peng",
      "Meina Song",
      "Wei Lin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.05186",
    "title": "Evolutionary Retrosynthetic Route Planning",
    "abstract": "Molecular retrosynthesis is a significant and complex problem in the field of chemistry, however, traditional manual synthesis methods not only need well-trained experts but also are time-consuming. With the development of big data and machine learning, artificial intelligence (AI) based retrosynthesis is attracting more attention and is becoming a valuable tool for molecular retrosynthesis. At present, Monte Carlo tree search is a mainstream search framework employed to address this problem. Nevertheless, its search efficiency is compromised by its large search space. Therefore, we propose a novel approach for retrosynthetic route planning based on evolutionary optimization, marking the first use of Evolutionary Algorithm (EA) in the field of multi-step retrosynthesis. The proposed method involves modeling the retrosynthetic problem into an optimization problem, defining the search space and operators. Additionally, to improve the search efficiency, a parallel strategy is implemented. The new approach is applied to four case products, and is compared with Monte Carlo tree search. The experimental results show that, in comparison to the Monte Carlo tree search algorithm, EA significantly reduces the number of calling single-step model by an average of 53.9%. The time required to search three solutions decreased by an average of 83.9%, and the number of feasible search routes increases by 5 times. ",
    "url": "https://arxiv.org/abs/2310.05186",
    "authors": [
      "Yan Zhang",
      "Hao Hao",
      "Xiao He",
      "Shuanhu Gao",
      "Aimin Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05192",
    "title": "HOD: A Benchmark Dataset for Harmful Object Detection",
    "abstract": "Recent multi-media data such as images and videos have been rapidly spread out on various online services such as social network services (SNS). With the explosive growth of online media services, the number of image content that may harm users is also growing exponentially. Thus, most recent online platforms such as Facebook and Instagram have adopted content filtering systems to prevent the prevalence of harmful content and reduce the possible risk of adverse effects on users. Unfortunately, computer vision research on detecting harmful content has not yet attracted attention enough. Users of each platform still manually click the report button to recognize patterns of harmful content they dislike when exposed to harmful content. However, the problem with manual reporting is that users are already exposed to harmful content. To address these issues, our research goal in this work is to develop automatic harmful object detection systems for online services. We present a new benchmark dataset for harmful object detection. Unlike most related studies focusing on a small subset of object categories, our dataset addresses various categories. Specifically, our proposed dataset contains more than 10,000 images across 6 categories that might be harmful, consisting of not only normal cases but also hard cases that are difficult to detect. Moreover, we have conducted extensive experiments to evaluate the effectiveness of our proposed dataset. We have utilized the recently proposed state-of-the-art (SOTA) object detection architectures and demonstrated our proposed dataset can be greatly useful for the real-time harmful object detection task. The whole source codes and datasets are publicly accessible at https://github.com/poori-nuna/HOD-Benchmark-Dataset. ",
    "url": "https://arxiv.org/abs/2310.05192",
    "authors": [
      "Eungyeom Ha",
      "Heemook Kim",
      "Sung Chul Hong",
      "Dongbin Na"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05202",
    "title": "Enhancing Cross-Dataset Performance of Distracted Driving Detection With  Score-Softmax Classifier",
    "abstract": "Deep neural networks enable real-time monitoring of in-vehicle driver, facilitating the timely prediction of distractions, fatigue, and potential hazards. This technology is now integral to intelligent transportation systems. Recent research has exposed unreliable cross-dataset end-to-end driver behavior recognition due to overfitting, often referred to as ``shortcut learning\", resulting from limited data samples. In this paper, we introduce the Score-Softmax classifier, which addresses this issue by enhancing inter-class independence and Intra-class uncertainty. Motivated by human rating patterns, we designed a two-dimensional supervisory matrix based on marginal Gaussian distributions to train the classifier. Gaussian distributions help amplify intra-class uncertainty while ensuring the Score-Softmax classifier learns accurate knowledge. Furthermore, leveraging the summation of independent Gaussian distributed random variables, we introduced a multi-channel information fusion method. This strategy effectively resolves the multi-information fusion challenge for the Score-Softmax classifier. Concurrently, we substantiate the necessity of transfer learning and multi-dataset combination. We conducted cross-dataset experiments using the SFD, AUCDD-V1, and 100-Driver datasets, demonstrating that Score-Softmax improves cross-dataset performance without modifying the model architecture. This provides a new approach for enhancing neural network generalization. Additionally, our information fusion approach outperforms traditional methods. ",
    "url": "https://arxiv.org/abs/2310.05202",
    "authors": [
      "Cong Duan",
      "Zixuan Liu",
      "Jiahao Xia",
      "Minghai Zhang",
      "Jiacai Liao",
      "Libo Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05207",
    "title": "Boosting Facial Action Unit Detection Through Jointly Learning Facial  Landmark Detection and Domain Separation and Reconstruction",
    "abstract": "Recently how to introduce large amounts of unlabeled facial images in the wild into supervised Facial Action Unit (AU) detection frameworks has become a challenging problem. In this paper, we propose a new AU detection framework where multi-task learning is introduced to jointly learn AU domain separation and reconstruction and facial landmark detection by sharing the parameters of homostructural facial extraction modules. In addition, we propose a new feature alignment scheme based on contrastive learning by simple projectors and an improved contrastive loss, which adds four additional intermediate supervisors to promote the feature reconstruction process. Experimental results on two benchmarks demonstrate our superiority against the state-of-the-art methods for AU detection in the wild. ",
    "url": "https://arxiv.org/abs/2310.05207",
    "authors": [
      "Ziqiao Shang",
      "Li Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05210",
    "title": "TILFA: A Unified Framework for Text, Image, and Layout Fusion in  Argument Mining",
    "abstract": "A main goal of Argument Mining (AM) is to analyze an author's stance. Unlike previous AM datasets focusing only on text, the shared task at the 10th Workshop on Argument Mining introduces a dataset including both text and images. Importantly, these images contain both visual elements and optical characters. Our new framework, TILFA (A Unified Framework for Text, Image, and Layout Fusion in Argument Mining), is designed to handle this mixed data. It excels at not only understanding text but also detecting optical characters and recognizing layout details in images. Our model significantly outperforms existing baselines, earning our team, KnowComp, the 1st place in the leaderboard of Argumentative Stance Classification subtask in this shared task. ",
    "url": "https://arxiv.org/abs/2310.05210",
    "authors": [
      "Qing Zong",
      "Zhaowei Wang",
      "Baixuan Xu",
      "Tianshi Zheng",
      "Haochen Shi",
      "Weiqi Wang",
      "Yangqiu Song",
      "Ginny Y. Wong",
      "Simon See"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05212",
    "title": "Interpretable Semiotics Networks Representing Awareness",
    "abstract": "Humans perceive objects daily and communicate their perceptions using various channels. Here, we describe a computational model that track and simulate objects' perception, and their representations as they pass in communication. We describe two key components of our internal representation ('observed' and 'seen') and relate them to familiar computer vision terms (encoding and decoding). These elements joined together to form semiotic networks, which simulate awareness in object perception and human communication. Nowadays, most neural networks are uninterpretable. On the other hand, our model is free from this disadvantages. We performed several experiments and demonstrated the visibility of our model. We describe how our network may be used as preprocessing unit to any classification network. In our experiments the compound network overperforms in average the classification network at datasets with small training data. Future work would leverage our model to gain better understanding of human communications and personal representations. ",
    "url": "https://arxiv.org/abs/2310.05212",
    "authors": [
      "David Kupeev",
      "Eyal Nitcany"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.05241",
    "title": "SCANet: Scene Complexity Aware Network for Weakly-Supervised Video  Moment Retrieval",
    "abstract": "Video moment retrieval aims to localize moments in video corresponding to a given language query. To avoid the expensive cost of annotating the temporal moments, weakly-supervised VMR (wsVMR) systems have been studied. For such systems, generating a number of proposals as moment candidates and then selecting the most appropriate proposal has been a popular approach. These proposals are assumed to contain many distinguishable scenes in a video as candidates. However, existing proposals of wsVMR systems do not respect the varying numbers of scenes in each video, where the proposals are heuristically determined irrespective of the video. We argue that the retrieval system should be able to counter the complexities caused by varying numbers of scenes in each video. To this end, we present a novel concept of a retrieval system referred to as Scene Complexity Aware Network (SCANet), which measures the `scene complexity' of multiple scenes in each video and generates adaptive proposals responding to variable complexities of scenes in each video. Experimental results on three retrieval benchmarks (i.e., Charades-STA, ActivityNet, TVR) achieve state-of-the-art performances and demonstrate the effectiveness of incorporating the scene complexity. ",
    "url": "https://arxiv.org/abs/2310.05241",
    "authors": [
      "Sunjae Yoon",
      "Gwanhyeong Koo",
      "Dahyun Kim",
      "Chang D. Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05245",
    "title": "Influence of Camera-LiDAR Configuration on 3D Object Detection for  Autonomous Driving",
    "abstract": "Cameras and LiDARs are both important sensors for autonomous driving, playing critical roles for 3D object detection. Camera-LiDAR Fusion has been a prevalent solution for robust and accurate autonomous driving perception. In contrast to the vast majority of existing arts that focus on how to improve the performance of 3D target detection through cross-modal schemes, deep learning algorithms, and training tricks, we devote attention to the impact of sensor configurations on the performance of learning-based methods. To achieve this, we propose a unified information-theoretic surrogate metric for camera and LiDAR evaluation based on the proposed sensor perception model. We also design an accelerated high-quality framework for data acquisition, model training, and performance evaluation that functions with the CARLA simulator. To show the correlation between detection performance and our surrogate metrics, We conduct experiments using several camera-LiDAR placements and parameters inspired by self-driving companies and research institutions. Extensive experimental results of representative algorithms on NuScenes dataset validate the effectiveness of our surrogate metric, demonstrating that sensor configurations significantly impact point-cloud-image fusion based detection models, which contribute up to 30% discrepancy in terms of average precision. ",
    "url": "https://arxiv.org/abs/2310.05245",
    "authors": [
      "Ye Li",
      "Hanjiang Hu",
      "Zuxin Liu",
      "Ding Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.05250",
    "title": "Simplifying GNN Performance with Low Rank Kernel Models",
    "abstract": "We revisit recent spectral GNN approaches to semi-supervised node classification (SSNC). We posit that many of the current GNN architectures may be over-engineered. Instead, simpler, traditional methods from nonparametric estimation, applied in the spectral domain, could replace many deep-learning inspired GNN designs. These conventional techniques appear to be well suited for a variety of graph types reaching state-of-the-art performance on many of the common SSNC benchmarks. Additionally, we show that recent performance improvements in GNN approaches may be partially attributed to shifts in evaluation conventions. Lastly, an ablative study is conducted on the various hyperparameters associated with GNN spectral filtering techniques. Code available at: https://github.com/lucianoAvinas/lowrank-gnn-kernels ",
    "url": "https://arxiv.org/abs/2310.05250",
    "authors": [
      "Luciano Vinas",
      "Arash A. Amini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.05255",
    "title": "Persis: A Persian Font Recognition Pipeline Using Convolutional Neural  Networks",
    "abstract": "What happens if we encounter a suitable font for our design work but do not know its name? Visual Font Recognition (VFR) systems are used to identify the font typeface in an image. These systems can assist graphic designers in identifying fonts used in images. A VFR system also aids in improving the speed and accuracy of Optical Character Recognition (OCR) systems. In this paper, we introduce the first publicly available datasets in the field of Persian font recognition and employ Convolutional Neural Networks (CNN) to address this problem. The results show that the proposed pipeline obtained 78.0% top-1 accuracy on our new datasets, 89.1% on the IDPL-PFOD dataset, and 94.5% on the KAFD dataset. Furthermore, the average time spent in the entire pipeline for one sample of our proposed datasets is 0.54 and 0.017 seconds for CPU and GPU, respectively. We conclude that CNN methods can be used to recognize Persian fonts without the need for additional pre-processing steps such as feature extraction, binarization, normalization, etc. ",
    "url": "https://arxiv.org/abs/2310.05255",
    "authors": [
      "Mehrdad Mohammadian",
      "Neda Maleki",
      "Tobias Olsson",
      "Fredrik Ahlgren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05263",
    "title": "Confidence-driven Sampling for Backdoor Attacks",
    "abstract": "Backdoor attacks aim to surreptitiously insert malicious triggers into DNN models, granting unauthorized control during testing scenarios. Existing methods lack robustness against defense strategies and predominantly focus on enhancing trigger stealthiness while randomly selecting poisoned samples. Our research highlights the overlooked drawbacks of random sampling, which make that attack detectable and defensible. The core idea of this paper is to strategically poison samples near the model's decision boundary and increase defense difficulty. We introduce a straightforward yet highly effective sampling methodology that leverages confidence scores. Specifically, it selects samples with lower confidence scores, significantly increasing the challenge for defenders in identifying and countering these attacks. Importantly, our method operates independently of existing trigger designs, providing versatility and compatibility with various backdoor attack techniques. We substantiate the effectiveness of our approach through a comprehensive set of empirical experiments, demonstrating its potential to significantly enhance resilience against backdoor attacks in DNNs. ",
    "url": "https://arxiv.org/abs/2310.05263",
    "authors": [
      "Pengfei He",
      "Han Xu",
      "Yue Xing",
      "Jie Ren",
      "Yingqian Cui",
      "Shenglai Zeng",
      "Jiliang Tang",
      "Makoto Yamada",
      "Mohammad Sabokrou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.05296",
    "title": "Tailoring Self-Attention for Graph via Rooted Subtrees",
    "abstract": "Attention mechanisms have made significant strides in graph learning, yet they still exhibit notable limitations: local attention faces challenges in capturing long-range information due to the inherent problems of the message-passing scheme, while global attention cannot reflect the hierarchical neighborhood structure and fails to capture fine-grained local information. In this paper, we propose a novel multi-hop graph attention mechanism, named Subtree Attention (STA), to address the aforementioned issues. STA seamlessly bridges the fully-attentional structure and the rooted subtree, with theoretical proof that STA approximates the global attention under extreme settings. By allowing direct computation of attention weights among multi-hop neighbors, STA mitigates the inherent problems in existing graph attention mechanisms. Further we devise an efficient form for STA by employing kernelized softmax, which yields a linear time complexity. Our resulting GNN architecture, the STAGNN, presents a simple yet performant STA-based graph neural network leveraging a hop-aware attention strategy. Comprehensive evaluations on ten node classification datasets demonstrate that STA-based models outperform existing graph transformers and mainstream GNNs. The code is available at https://github.com/LUMIA-Group/SubTree-Attention. ",
    "url": "https://arxiv.org/abs/2310.05296",
    "authors": [
      "Siyuan Huang",
      "Yunchong Song",
      "Jiayue Zhou",
      "Zhouhan Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05306",
    "title": "Progressive Neural Compression for Adaptive Image Offloading under  Timing Constraints",
    "abstract": "IoT devices are increasingly the source of data for machine learning (ML) applications running on edge servers. Data transmissions from devices to servers are often over local wireless networks whose bandwidth is not just limited but, more importantly, variable. Furthermore, in cyber-physical systems interacting with the physical environment, image offloading is also commonly subject to timing constraints. It is, therefore, important to develop an adaptive approach that maximizes the inference performance of ML applications under timing constraints and the resource constraints of IoT devices. In this paper, we use image classification as our target application and propose progressive neural compression (PNC) as an efficient solution to this problem. Although neural compression has been used to compress images for different ML applications, existing solutions often produce fixed-size outputs that are unsuitable for timing-constrained offloading over variable bandwidth. To address this limitation, we train a multi-objective rateless autoencoder that optimizes for multiple compression rates via stochastic taildrop to create a compression solution that produces features ordered according to their importance to inference performance. Features are then transmitted in that order based on available bandwidth, with classification ultimately performed using the (sub)set of features received by the deadline. We demonstrate the benefits of PNC over state-of-the-art neural compression approaches and traditional compression methods on a testbed comprising an IoT device and an edge server connected over a wireless network with varying bandwidth. ",
    "url": "https://arxiv.org/abs/2310.05306",
    "authors": [
      "Ruiqi Wang",
      "Hanyang Liu",
      "Jiaming Qiu",
      "Moran Xu",
      "Roch Guerin",
      "Chenyang Lu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05307",
    "title": "Successive Data Injection in Conditional Quantum GAN Applied to Time  Series Anomaly Detection",
    "abstract": "Classical GAN architectures have shown interesting results for solving anomaly detection problems in general and for time series anomalies in particular, such as those arising in communication networks. In recent years, several quantum GAN architectures have been proposed in the literature. When detecting anomalies in time series using QGANs, huge challenges arise due to the limited number of qubits compared to the size of the data. To address these challenges, we propose a new high-dimensional encoding approach, named Successive Data Injection (SuDaI). In this approach, we explore a larger portion of the quantum state than that in the conventional angle encoding, the method used predominantly in the literature, through repeated data injections into the quantum state. SuDaI encoding allows us to adapt the QGAN for anomaly detection with network data of a much higher dimensionality than with the existing known QGANs implementations. In addition, SuDaI encoding applies to other types of high-dimensional time series and can be used in contexts beyond anomaly detection and QGANs, opening up therefore multiple fields of application. ",
    "url": "https://arxiv.org/abs/2310.05307",
    "authors": [
      "Benjamin Kalfon",
      "Soumaya Cherkaoui",
      "Jean-Fr\u00e9d\u00e9ric Laprade",
      "Ola Ahmad",
      "Shengrui Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.05308",
    "title": "Adversarial Attacks on Combinatorial Multi-Armed Bandits",
    "abstract": "We study reward poisoning attacks on Combinatorial Multi-armed Bandits (CMAB). We first provide a sufficient and necessary condition for the attackability of CMAB, which depends on the intrinsic properties of the corresponding CMAB instance such as the reward distributions of super arms and outcome distributions of base arms. Additionally, we devise an attack algorithm for attackable CMAB instances. Contrary to prior understanding of multi-armed bandits, our work reveals a surprising fact that the attackability of a specific CMAB instance also depends on whether the bandit instance is known or unknown to the adversary. This finding indicates that adversarial attacks on CMAB are difficult in practice and a general attack strategy for any CMAB instance does not exist since the environment is mostly unknown to the adversary. We validate our theoretical findings via extensive experiments on real-world CMAB applications including probabilistic maximum covering problem, online minimum spanning tree, cascading bandits for online ranking, and online shortest path. ",
    "url": "https://arxiv.org/abs/2310.05308",
    "authors": [
      "Rishab Balasubramanian",
      "Jiawei Li",
      "Prasad Tadepalli",
      "Huazheng Wang",
      "Qingyun Wu",
      "Haoyu Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.05312",
    "title": "Quality Assurance of A GPT-based Sentiment Analysis System: Adversarial  Review Data Generation and Detection",
    "abstract": "Large Language Models (LLMs) have been garnering significant attention of AI researchers, especially following the widespread popularity of ChatGPT. However, due to LLMs' intricate architecture and vast parameters, several concerns and challenges regarding their quality assurance require to be addressed. In this paper, a fine-tuned GPT-based sentiment analysis model is first constructed and studied as the reference in AI quality analysis. Then, the quality analysis related to data adequacy is implemented, including employing the content-based approach to generate reasonable adversarial review comments as the wrongly-annotated data, and developing surprise adequacy (SA)-based techniques to detect these abnormal data. Experiments based on Amazon.com review data and a fine-tuned GPT model were implemented. Results were thoroughly discussed from the perspective of AI quality assurance to present the quality analysis of an LLM model on generated adversarial textual data and the effectiveness of using SA on anomaly detection in data quality assurance. ",
    "url": "https://arxiv.org/abs/2310.05312",
    "authors": [
      "Tinghui Ouyang",
      "Hoang-Quoc Nguyen-Son",
      "Huy H. Nguyen",
      "Isao Echizen",
      "Yoshiki Seo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.05313",
    "title": "Accelerating Deep Neural Network guided MCTS using Adaptive Parallelism",
    "abstract": "Deep Neural Network guided Monte-Carlo Tree Search (DNN-MCTS) is a powerful class of AI algorithms. In DNN-MCTS, a Deep Neural Network model is trained collaboratively with a dynamic Monte-Carlo search tree to guide the agent towards actions that yields the highest returns. While the DNN operations are highly parallelizable, the search tree operations involved in MCTS are sequential and often become the system bottleneck. Existing MCTS parallel schemes on shared-memory multi-core CPU platforms either exploit data parallelism but sacrifice memory access latency, or take advantage of local cache for low-latency memory accesses but constrain the tree search to a single thread. In this work, we analyze the tradeoff of these parallel schemes and develop performance models for both parallel schemes based on the application and hardware parameters. We propose a novel implementation that addresses the tradeoff by adaptively choosing the optimal parallel scheme for the MCTS component on the CPU. Furthermore, we propose an efficient method for searching the optimal communication batch size as the MCTS component on the CPU interfaces with DNN operations offloaded to an accelerator (GPU). Using a representative DNN-MCTS algorithm - Alphazero on board game benchmarks, we show that the parallel framework is able to adaptively generate the best-performing parallel implementation, leading to a range of $1.5\\times - 3\\times$ speedup compared with the baseline methods on CPU and CPU-GPU platforms. ",
    "url": "https://arxiv.org/abs/2310.05313",
    "authors": [
      "Yuan Meng",
      "Qian Wang",
      "Tianxin Zu",
      "Viktor Prasanna"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.05316",
    "title": "Understanding the Feature Norm for Out-of-Distribution Detection",
    "abstract": "A neural network trained on a classification dataset often exhibits a higher vector norm of hidden layer features for in-distribution (ID) samples, while producing relatively lower norm values on unseen instances from out-of-distribution (OOD). Despite this intriguing phenomenon being utilized in many applications, the underlying cause has not been thoroughly investigated. In this study, we demystify this very phenomenon by scrutinizing the discriminative structures concealed in the intermediate layers of a neural network. Our analysis leads to the following discoveries: (1) The feature norm is a confidence value of a classifier hidden in the network layer, specifically its maximum logit. Hence, the feature norm distinguishes OOD from ID in the same manner that a classifier confidence does. (2) The feature norm is class-agnostic, thus it can detect OOD samples across diverse discriminative models. (3) The conventional feature norm fails to capture the deactivation tendency of hidden layer neurons, which may lead to misidentification of ID samples as OOD instances. To resolve this drawback, we propose a novel negative-aware norm (NAN) that can capture both the activation and deactivation tendencies of hidden layer neurons. We conduct extensive experiments on NAN, demonstrating its efficacy and compatibility with existing OOD detectors, as well as its capability in label-free environments. ",
    "url": "https://arxiv.org/abs/2310.05316",
    "authors": [
      "Jaewoo Park",
      "Jacky Chen Long Chai",
      "Jaeho Yoon",
      "Andrew Beng Jin Teoh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05318",
    "title": "Resolving the Imbalance Issue in Hierarchical Disciplinary Topic  Inference via LLM-based Data Augmentation",
    "abstract": "In addressing the imbalanced issue of data within the realm of Natural Language Processing, text data augmentation methods have emerged as pivotal solutions. This data imbalance is prevalent in the research proposals submitted during the funding application process. Such imbalances, resulting from the varying popularity of disciplines or the emergence of interdisciplinary studies, significantly impede the precision of downstream topic models that deduce the affiliated disciplines of these proposals. At the data level, proposals penned by experts and scientists are inherently complex technological texts, replete with intricate terminologies, which augmenting such specialized text data poses unique challenges. At the system level, this, in turn, compromises the fairness of AI-assisted reviewer assignment systems, which raises a spotlight on solving this issue. This study leverages large language models (Llama V1) as data generators to augment research proposals categorized within intricate disciplinary hierarchies, aiming to rectify data imbalances and enhance the equity of expert assignments. We first sample within the hierarchical structure to find the under-represented class. Then we designed a prompt for keyword-based research proposal generation. Our experiments attests to the efficacy of the generated data, demonstrating that research proposals produced using the prompts can effectively address the aforementioned issues and generate high quality scientific text data, thus help the model overcome the imbalanced issue. ",
    "url": "https://arxiv.org/abs/2310.05318",
    "authors": [
      "Xunxin Cai",
      "Meng Xiao",
      "Zhiyuan Ning",
      "Yuanchun Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.05330",
    "title": "A Lightweight Video Anomaly Detection Model with Weak Supervision and  Adaptive Instance Selection",
    "abstract": "Video anomaly detection is to determine whether there are any abnormal events, behaviors or objects in a given video, which enables effective and intelligent public safety management. As video anomaly labeling is both time-consuming and expensive, most existing works employ unsupervised or weakly supervised learning methods. This paper focuses on weakly supervised video anomaly detection, in which the training videos are labeled whether or not they contain any anomalies, but there is no information about which frames the anomalies are located. However, the uncertainty of weakly labeled data and the large model size prevent existing methods from wide deployment in real scenarios, especially the resource-limit situations such as edge-computing. In this paper, we develop a lightweight video anomaly detection model. On the one hand, we propose an adaptive instance selection strategy, which is based on the model's current status to select confident instances, thereby mitigating the uncertainty of weakly labeled data and subsequently promoting the model's performance. On the other hand, we design a lightweight multi-level temporal correlation attention module and an hourglass-shaped fully connected layer to construct the model, which can reduce the model parameters to only 0.56\\% of the existing methods (e.g. RTFM). Our extensive experiments on two public datasets UCF-Crime and ShanghaiTech show that our model can achieve comparable or even superior AUC score compared to the state-of-the-art methods, with a significantly reduced number of model parameters. ",
    "url": "https://arxiv.org/abs/2310.05330",
    "authors": [
      "Yang Wang",
      "Jiaogen Zhou",
      "Jihong Guan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05336",
    "title": "GReAT: A Graph Regularized Adversarial Training Method",
    "abstract": "This paper proposes a regularization method called GReAT, Graph Regularized Adversarial Training, to improve deep learning models' classification performance. Adversarial examples are a well-known challenge in machine learning, where small, purposeful perturbations to input data can mislead models. Adversarial training, a powerful and one of the most effective defense strategies, involves training models with both regular and adversarial examples. However, it often neglects the underlying structure of the data. In response, we propose GReAT, a method that leverages data graph structure to enhance model robustness. GReAT deploys the graph structure of the data into the adversarial training process, resulting in more robust models that better generalize its testing performance and defend against adversarial attacks. Through extensive evaluation on benchmark datasets, we demonstrate GReAT's effectiveness compared to state-of-the-art classification methods, highlighting its potential in improving deep learning models' classification performance. ",
    "url": "https://arxiv.org/abs/2310.05336",
    "authors": [
      "Samet Bayram",
      "Kenneth Barner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05343",
    "title": "Investigating Continuous Learning in Spiking Neural Networks",
    "abstract": "In this paper, the use of third-generation machine learning, also known as spiking neural network architecture, for continuous learning was investigated and compared to conventional models. The experimentation was divided into three separate phases. The first phase focused on training the conventional models via transfer learning. The second phase trains a Nengo model from their library. Lastly, each conventional model is converted into a spiking neural network and trained. Initial results from phase 1 are inline with known knowledge about continuous learning within current machine learning literature. All models were able to correctly identify the current classes, but they would immediately see a sharp performance drop in previous classes due to catastrophic forgetting. However, the SNN models were able to retain some information about previous classes. Although many of the previous classes were still identified as the current trained classes, the output probabilities showed a higher than normal value to the actual class. This indicates that the SNN models do have potential to overcome catastrophic forgetting but much work is still needed. ",
    "url": "https://arxiv.org/abs/2310.05343",
    "authors": [
      "C. Tanner Fredieu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05346",
    "title": "Anyview: Generalizable Indoor 3D Object Detection with Variable Frames",
    "abstract": "In this paper, we propose a novel network framework for indoor 3D object detection to handle variable input frame numbers in practical scenarios. Existing methods only consider fixed frames of input data for a single detector, such as monocular RGB-D images or point clouds reconstructed from dense multi-view RGB-D images. While in practical application scenes such as robot navigation and manipulation, the raw input to the 3D detectors is the RGB-D images with variable frame numbers instead of the reconstructed scene point cloud. However, the previous approaches can only handle fixed frame input data and have poor performance with variable frame input. In order to facilitate 3D object detection methods suitable for practical tasks, we present a novel 3D detection framework named AnyView for our practical applications, which generalizes well across different numbers of input frames with a single model. To be specific, we propose a geometric learner to mine the local geometric features of each input RGB-D image frame and implement local-global feature interaction through a designed spatial mixture module. Meanwhile, we further utilize a dynamic token strategy to adaptively adjust the number of extracted features for each frame, which ensures consistent global feature density and further enhances the generalization after fusion. Extensive experiments on the ScanNet dataset show our method achieves both great generalizability and high detection accuracy with a simple and clean architecture containing a similar amount of parameters with the baselines. ",
    "url": "https://arxiv.org/abs/2310.05346",
    "authors": [
      "Zhenyu Wu",
      "Xiuwei Xu",
      "Ziwei Wang",
      "Chong Xia",
      "Linqing Zhao",
      "Jiwen Lu",
      "Haibin Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.05347",
    "title": "Infrared Small Target Detection Using Double-Weighted Multi-Granularity  Patch Tensor Model With Tensor-Train Decomposition",
    "abstract": "Infrared small target detection plays an important role in the remote sensing fields. Therefore, many detection algorithms have been proposed, in which the infrared patch-tensor (IPT) model has become a mainstream tool due to its excellent performance. However, most IPT-based methods face great challenges, such as inaccurate measure of the tensor low-rankness and poor robustness to complex scenes, which will leadto poor detection performance. In order to solve these problems, this paper proposes a novel double-weighted multi-granularity infrared patch tensor (DWMGIPT) model. First, to capture different granularity information of tensor from multiple modes, a multi-granularity infrared patch tensor (MGIPT) model is constructed by collecting nonoverlapping patches and tensor augmentation based on the tensor train (TT) decomposition. Second, to explore the latent structure of tensor more efficiently, we utilize the auto-weighted mechanism to balance the importance of information at different granularity. Then, the steering kernel (SK) is employed to extract local structure prior, which suppresses background interference such as strong edges and noise. Finally, an efficient optimization algorithm based on the alternating direction method of multipliers (ADMM) is presented to solve the model. Extensive experiments in various challenging scenes show that the proposed algorithm is robust to noise and different scenes. Compared with the other eight state-of-the-art methods, different evaluation metrics demonstrate that our method achieves better detection performance in various complex scenes. ",
    "url": "https://arxiv.org/abs/2310.05347",
    "authors": [
      "Guiyu Zhang",
      "Qunbo Lv",
      "Zui Tao",
      "Baoyu Zhu",
      "Zheng Tan",
      "Yuan Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05351",
    "title": "Generalized Neural Collapse for a Large Number of Classes",
    "abstract": "Neural collapse provides an elegant mathematical characterization of learned last layer representations (a.k.a. features) and classifier weights in deep classification models. Such results not only provide insights but also motivate new techniques for improving practical deep models. However, most of the existing empirical and theoretical studies in neural collapse focus on the case that the number of classes is small relative to the dimension of the feature space. This paper extends neural collapse to cases where the number of classes are much larger than the dimension of feature space, which broadly occur for language models, retrieval systems, and face recognition applications. We show that the features and classifier exhibit a generalized neural collapse phenomenon, where the minimum one-vs-rest margins is maximized.We provide empirical study to verify the occurrence of generalized neural collapse in practical deep neural networks. Moreover, we provide theoretical study to show that the generalized neural collapse provably occurs under unconstrained feature model with spherical constraint, under certain technical conditions on feature dimension and number of classes. ",
    "url": "https://arxiv.org/abs/2310.05351",
    "authors": [
      "Jiachen Jiang",
      "Jinxin Zhou",
      "Peng Wang",
      "Qing Qu",
      "Dustin Mixon",
      "Chong You",
      "Zhihui Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2310.05354",
    "title": "An Initial Investigation of Neural Replay Simulator for Over-the-Air  Adversarial Perturbations to Automatic Speaker Verification",
    "abstract": "Deep Learning has advanced Automatic Speaker Verification (ASV) in the past few years. Although it is known that deep learning-based ASV systems are vulnerable to adversarial examples in digital access, there are few studies on adversarial attacks in the context of physical access, where a replay process (i.e., over the air) is involved. An over-the-air attack involves a loudspeaker, a microphone, and a replaying environment that impacts the movement of the sound wave. Our initial experiment confirms that the replay process impacts the effectiveness of the over-the-air attack performance. This study performs an initial investigation towards utilizing a neural replay simulator to improve over-the-air adversarial attack robustness. This is achieved by using a neural waveform synthesizer to simulate the replay process when estimating the adversarial perturbations. Experiments conducted on the ASVspoof2019 dataset confirm that the neural replay simulator can considerably increase the success rates of over-the-air adversarial attacks. This raises the concern for adversarial attacks on speaker verification in physical access applications. ",
    "url": "https://arxiv.org/abs/2310.05354",
    "authors": [
      "Jiaqi Li",
      "Li Wang",
      "Liumeng Xue",
      "Lei Wang",
      "Zhizheng Wu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.05355",
    "title": "C^2M-DoT: Cross-modal consistent multi-view medical report generation  with domain transfer network",
    "abstract": "In clinical scenarios, multiple medical images with different views are usually generated simultaneously, and these images have high semantic consistency. However, most existing medical report generation methods only consider single-view data. The rich multi-view mutual information of medical images can help generate more accurate reports, however, the dependence of multi-view models on multi-view data in the inference stage severely limits their application in clinical practice. In addition, word-level optimization based on numbers ignores the semantics of reports and medical images, and the generated reports often cannot achieve good performance. Therefore, we propose a cross-modal consistent multi-view medical report generation with a domain transfer network (C^2M-DoT). Specifically, (i) a semantic-based multi-view contrastive learning medical report generation framework is adopted to utilize cross-view information to learn the semantic representation of lesions; (ii) a domain transfer network is further proposed to ensure that the multi-view report generation model can still achieve good inference performance under single-view input; (iii) meanwhile, optimization using a cross-modal consistency loss facilitates the generation of textual reports that are semantically consistent with medical images. Extensive experimental studies on two public benchmark datasets demonstrate that C^2M-DoT substantially outperforms state-of-the-art baselines in all metrics. Ablation studies also confirmed the validity and necessity of each component in C^2M-DoT. ",
    "url": "https://arxiv.org/abs/2310.05355",
    "authors": [
      "Ruizhi Wang",
      "Xiangtao Wang",
      "Jie Zhou",
      "Thomas Lukasiewicz",
      "Zhenghua Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05366",
    "title": "Rotation Matters: Generalized Monocular 3D Object Detection for Various  Camera Systems",
    "abstract": "Research on monocular 3D object detection is being actively studied, and as a result, performance has been steadily improving. However, 3D object detection performance is significantly reduced when applied to a camera system different from the system used to capture the training datasets. For example, a 3D detector trained on datasets from a passenger car mostly fails to regress accurate 3D bounding boxes for a camera mounted on a bus. In this paper, we conduct extensive experiments to analyze the factors that cause performance degradation. We find that changing the camera pose, especially camera orientation, relative to the road plane caused performance degradation. In addition, we propose a generalized 3D object detection method that can be universally applied to various camera systems. We newly design a compensation module that corrects the estimated 3D bounding box location and heading direction. The proposed module can be applied to most of the recent 3D object detection networks. It increases AP3D score (KITTI moderate, IoU $> 70\\%$) about 6-to-10-times above the baselines without additional training. Both quantitative and qualitative results show the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2310.05366",
    "authors": [
      "SungHo Moon",
      "JinWoo Bae",
      "SungHoon Im"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05369",
    "title": "AdvSV: An Over-the-Air Adversarial Attack Dataset for Speaker  Verification",
    "abstract": "It is known that deep neural networks are vulnerable to adversarial attacks. Although Automatic Speaker Verification (ASV) built on top of deep neural networks exhibits robust performance in controlled scenarios, many studies confirm that ASV is vulnerable to adversarial attacks. The lack of a standard dataset is a bottleneck for further research, especially reproducible research. In this study, we developed an open-source adversarial attack dataset for speaker verification research. As an initial step, we focused on the over-the-air attack. An over-the-air adversarial attack involves a perturbation generation algorithm, a loudspeaker, a microphone, and an acoustic environment. The variations in the recording configurations make it very challenging to reproduce previous research. The AdvSV dataset is constructed using the Voxceleb1 Verification test set as its foundation. This dataset employs representative ASV models subjected to adversarial attacks and records adversarial samples to simulate over-the-air attack settings. The scope of the dataset can be easily extended to include more types of adversarial attacks. The dataset will be released to the public under the CC-BY license. In addition, we also provide a detection baseline for reproducible research. ",
    "url": "https://arxiv.org/abs/2310.05369",
    "authors": [
      "Li Wang",
      "Jiaqi Li",
      "Yuhao Luo",
      "Jiahao Zheng",
      "Lei Wang",
      "Hao Li",
      "Ke Xu",
      "Chengfang Fang",
      "Jie Shi",
      "Zhizheng Wu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.05370",
    "title": "SocialCircle: Learning the Angle-based Social Interaction Representation  for Pedestrian Trajectory Prediction",
    "abstract": "Analyzing and forecasting trajectories of agents like pedestrians and cars in complex scenes has become more and more significant in many intelligent systems and applications. The diversity and uncertainty in socially interactive behaviors among a rich variety of agents make this task more challenging than other deterministic computer vision tasks. Researchers have made a lot of efforts to quantify the effects of these interactions on future trajectories through different mathematical models and network structures, but this problem has not been well solved. Inspired by marine animals that localize the positions of their companions underwater through echoes, we build a new anglebased trainable social representation, named SocialCircle, for continuously reflecting the context of social interactions at different angular orientations relative to the target agent. We validate the effect of the proposed SocialCircle by training it along with several newly released trajectory prediction models, and experiments show that the SocialCircle not only quantitatively improves the prediction performance, but also qualitatively helps better consider social interactions when forecasting pedestrian trajectories in a way that is consistent with human intuitions. ",
    "url": "https://arxiv.org/abs/2310.05370",
    "authors": [
      "Conghao Wong",
      "Beihao Xia",
      "Xinge You"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05378",
    "title": "Transcending the Attention Paradigm: Implicit Learning from Geospatial  Social Media Data",
    "abstract": "While transformers have pioneered attention-driven architectures as a cornerstone of research, their dependence on explicitly contextual information underscores limitations in their abilities to tacitly learn overarching textual themes. This study investigates social media data as a source of distributed patterns, challenging the heuristic paradigm of performance benchmarking. In stark contrast to networks that rely on capturing complex long-term dependencies, models of online data inherently lack structure and are forced to learn underlying patterns in the aggregate. To properly represent these abstract relationships, this research dissects empirical social media corpora into their elemental components and analyzes over two billion tweets across population-dense locations. Exploring the relationship between location and vernacular in Twitter data, we employ Bag-of-Words models specific to each city and evaluate their respective representation. This demonstrates that hidden insights can be uncovered without the crutch of advanced algorithms and demonstrates that even amidst noisy data, geographic location has a considerable influence on online communication. This evidence presents tangible insights regarding geospatial communication patterns and their implications in social science. It also challenges the notion that intricate models are prerequisites for pattern recognition in natural language, aligning with the evolving landscape that questions the embrace of absolute interpretability over abstract understanding. This study bridges the divide between sophisticated frameworks and intangible relationships, paving the way for systems that blend structured models with conjectural reasoning. ",
    "url": "https://arxiv.org/abs/2310.05378",
    "authors": [
      "Nick DiSanto",
      "Anthony Corso",
      "Benjamin Sanders",
      "Gavin Harding"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.05388",
    "title": "GROVE: A Retrieval-augmented Complex Story Generation Framework with A  Forest of Evidence",
    "abstract": "Conditional story generation is significant in human-machine interaction, particularly in producing stories with complex plots. While Large language models (LLMs) perform well on multiple NLP tasks, including story generation, it is challenging to generate stories with both complex and creative plots. Existing methods often rely on detailed prompts to guide LLMs to meet target conditions, which inadvertently restrict the creative potential of the generated stories. We argue that leveraging information from exemplary human-written stories facilitates generating more diverse plotlines. Delving deeper into story details helps build complex and credible plots. In this paper, we propose a retrieval-au\\textbf{G}mented sto\\textbf{R}y generation framework with a f\\textbf{O}rest of e\\textbf{V}id\\textbf{E}nce (GROVE) to enhance stories' complexity. We build a retrieval repository for target conditions to produce few-shot examples to prompt LLMs. Additionally, we design an ``asking-why'' prompting scheme that extracts a forest of evidence, providing compensation for the ambiguities that may occur in the generated story. This iterative process uncovers underlying story backgrounds. Finally, we select the most fitting chains of evidence from the evidence forest and integrate them into the generated story, thereby enhancing the narrative's complexity and credibility. Experimental results and numerous examples verify the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2310.05388",
    "authors": [
      "Zhihua Wen",
      "Zhiliang Tian",
      "Wei Wu",
      "Yuxin Yang",
      "Yanqi Shi",
      "Zhen Huang",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.05391",
    "title": "Neural Impostor: Editing Neural Radiance Fields with Explicit Shape  Manipulation",
    "abstract": "Neural Radiance Fields (NeRF) have significantly advanced the generation of highly realistic and expressive 3D scenes. However, the task of editing NeRF, particularly in terms of geometry modification, poses a significant challenge. This issue has obstructed NeRF's wider adoption across various applications. To tackle the problem of efficiently editing neural implicit fields, we introduce Neural Impostor, a hybrid representation incorporating an explicit tetrahedral mesh alongside a multigrid implicit field designated for each tetrahedron within the explicit mesh. Our framework bridges the explicit shape manipulation and the geometric editing of implicit fields by utilizing multigrid barycentric coordinate encoding, thus offering a pragmatic solution to deform, composite, and generate neural implicit fields while maintaining a complex volumetric appearance. Furthermore, we propose a comprehensive pipeline for editing neural implicit fields based on a set of explicit geometric editing operations. We show the robustness and adaptability of our system through diverse examples and experiments, including the editing of both synthetic objects and real captured data. Finally, we demonstrate the authoring process of a hybrid synthetic-captured object utilizing a variety of editing operations, underlining the transformative potential of Neural Impostor in the field of 3D content creation and manipulation. ",
    "url": "https://arxiv.org/abs/2310.05391",
    "authors": [
      "Ruiyang Liu",
      "Jinxu Xiang",
      "Bowen Zhao",
      "Ran Zhang",
      "Jingyi Yu",
      "Changxi Zheng"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05395",
    "title": "Robust Image Watermarking based on Cross-Attention and Invariant Domain  Learning",
    "abstract": "Image watermarking involves embedding and extracting watermarks within a cover image, with deep learning approaches emerging to bolster generalization and robustness. Predominantly, current methods employ convolution and concatenation for watermark embedding, while also integrating conceivable augmentation in the training process. This paper explores a robust image watermarking methodology by harnessing cross-attention and invariant domain learning, marking two novel, significant advancements. First, we design a watermark embedding technique utilizing a multi-head cross attention mechanism, enabling information exchange between the cover image and watermark to identify semantically suitable embedding locations. Second, we advocate for learning an invariant domain representation that encapsulates both semantic and noise-invariant information concerning the watermark, shedding light on promising avenues for enhancing image watermarking techniques. ",
    "url": "https://arxiv.org/abs/2310.05395",
    "authors": [
      "Agnibh Dasgupta",
      "Xin Zhong"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05406",
    "title": "GradientSurf: Gradient-Domain Neural Surface Reconstruction from RGB  Video",
    "abstract": "This paper proposes GradientSurf, a novel algorithm for real time surface reconstruction from monocular RGB video. Inspired by Poisson Surface Reconstruction, the proposed method builds on the tight coupling between surface, volume, and oriented point cloud and solves the reconstruction problem in gradient-domain. Unlike Poisson Surface Reconstruction which finds an offline solution to the Poisson equation by solving a linear system after the scanning process is finished, our method finds online solutions from partial scans with a neural network incrementally where the Poisson layer is designed to supervise both local and global reconstruction. The main challenge that existing methods suffer from when reconstructing from RGB signal is a lack of details in the reconstructed surface. We hypothesize this is due to the spectral bias of neural networks towards learning low frequency geometric features. To address this issue, the reconstruction problem is cast onto gradient domain, where zeroth-order and first-order energies are minimized. The zeroth-order term penalizes location of the surface. The first-order term penalizes the difference between the gradient of reconstructed implicit function and the vector field formulated from oriented point clouds sampled at adaptive local densities. For the task of indoor scene reconstruction, visual and quantitative experimental results show that the proposed method reconstructs surfaces with more details in curved regions and higher fidelity for small objects than previous methods. ",
    "url": "https://arxiv.org/abs/2310.05406",
    "authors": [
      "Crane He Chen",
      "Joerg Liebelt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05407",
    "title": "GPS Attack Detection and Mitigation for Safe Autonomous Driving using  Image and Map based Lateral Direction Localization",
    "abstract": "The accuracy and robustness of vehicle localization are critical for achieving safe and reliable high-level autonomy. Recent results show that GPS is vulnerable to spoofing attacks, which is one major threat to autonomous driving. In this paper, a novel anomaly detection and mitigation method against GPS attacks that utilizes onboard camera and high-precision maps is proposed to ensure accurate vehicle localization. First, lateral direction localization in driving lanes is calculated by camera-based lane detection and map matching respectively. Then, a real-time detector for GPS spoofing attack is developed to evaluate the localization data. When the attack is detected, a multi-source fusion-based localization method using Unscented Kalman filter is derived to mitigate GPS attack and improve the localization accuracy. The proposed method is validated in various scenarios in Carla simulator and open-source public dataset to demonstrate its effectiveness in timely GPS attack detection and data recovery. ",
    "url": "https://arxiv.org/abs/2310.05407",
    "authors": [
      "Qingming Chen",
      "Peng Liu",
      "Guoqiang Li",
      "Zhenpo Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.05410",
    "title": "Causal Reasoning through Two Layers of Cognition for Improving  Generalization in Visual Question Answering",
    "abstract": "Generalization in Visual Question Answering (VQA) requires models to answer questions about images with contexts beyond the training distribution. Existing attempts primarily refine unimodal aspects, overlooking enhancements in multimodal aspects. Besides, diverse interpretations of the input lead to various modes of answer generation, highlighting the role of causal reasoning between interpreting and answering steps in VQA. Through this lens, we propose Cognitive pathways VQA (CopVQA) improving the multimodal predictions by emphasizing causal reasoning factors. CopVQA first operates a pool of pathways that capture diverse causal reasoning flows through interpreting and answering stages. Mirroring human cognition, we decompose the responsibility of each stage into distinct experts and a cognition-enabled component (CC). The two CCs strategically execute one expert for each stage at a time. Finally, we prioritize answer predictions governed by pathways involving both CCs while disregarding answers produced by either CC, thereby emphasizing causal reasoning and supporting generalization. Our experiments on real-life and medical data consistently verify that CopVQA improves VQA performance and generalization across baselines and domains. Notably, CopVQA achieves a new state-of-the-art (SOTA) on PathVQA dataset and comparable accuracy to the current SOTA on VQA-CPv2, VQAv2, and VQA RAD, with one-fourth of the model size. ",
    "url": "https://arxiv.org/abs/2310.05410",
    "authors": [
      "Trang Nguyen",
      "Naoaki Okazaki"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05424",
    "title": "Fast and Robust Early-Exiting Framework for Autoregressive Language  Models with Synchronized Parallel Decoding",
    "abstract": "To tackle the high inference latency exhibited by autoregressive language models, previous studies have proposed an early-exiting framework that allocates adaptive computation paths for each token based on the complexity of generating the subsequent token. However, we observed several shortcomings, including performance degradation caused by a state copying mechanism or numerous exit paths, and sensitivity to exit confidence thresholds. Consequently, we propose a Fast and Robust Early-Exiting (FREE) framework, which incorporates a shallow-deep module and a synchronized parallel decoding. Our framework enables faster inference by synchronizing the decoding process of the current token with previously stacked early-exited tokens. Furthermore, as parallel decoding allows us to observe predictions from both shallow and deep models, we present a novel adaptive threshold estimator that exploits a Beta mixture model to determine suitable confidence thresholds. We empirically demonstrated the superiority of our proposed framework on extensive generation tasks. ",
    "url": "https://arxiv.org/abs/2310.05424",
    "authors": [
      "Sangmin Bae",
      "Jongwoo Ko",
      "Hwanjun Song",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.05431",
    "title": "RECESS Vaccine for Federated Learning: Proactive Defense Against Model  Poisoning Attacks",
    "abstract": "Model poisoning attacks greatly jeopardize the application of federated learning (FL). The effectiveness of existing defenses is susceptible to the latest model poisoning attacks, leading to a decrease in prediction accuracy. Besides, these defenses are intractable to distinguish benign outliers from malicious gradients, which further compromises the model generalization. In this work, we propose a novel proactive defense named RECESS against model poisoning attacks. Different from the passive analysis in previous defenses, RECESS proactively queries each participating client with a delicately constructed aggregation gradient, accompanied by the detection of malicious clients according to their responses with higher accuracy. Furthermore, RECESS uses a new trust scoring mechanism to robustly aggregate gradients. Unlike previous methods that score each iteration, RECESS considers clients' performance correlation across multiple iterations to estimate the trust score, substantially increasing fault tolerance. Finally, we extensively evaluate RECESS on typical model architectures and four datasets under various settings. We also evaluated the defensive effectiveness against other types of poisoning attacks, the sensitivity of hyperparameters, and adaptive adversarial attacks. Experimental results show the superiority of RECESS in terms of reducing accuracy loss caused by the latest model poisoning attacks over five classic and two state-of-the-art defenses. ",
    "url": "https://arxiv.org/abs/2310.05431",
    "authors": [
      "Haonan Yan",
      "Wenjing Zhang",
      "Qian Chen",
      "Xiaoguang Li",
      "Wenhai Sun",
      "Hui Li",
      "Xiaodong Lin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.05447",
    "title": "Towards Fair and Comprehensive Comparisons for Image-Based 3D Object  Detection",
    "abstract": "In this work, we build a modular-designed codebase, formulate strong training recipes, design an error diagnosis toolbox, and discuss current methods for image-based 3D object detection. In particular, different from other highly mature tasks, e.g., 2D object detection, the community of image-based 3D object detection is still evolving, where methods often adopt different training recipes and tricks resulting in unfair evaluations and comparisons. What is worse, these tricks may overwhelm their proposed designs in performance, even leading to wrong conclusions. To address this issue, we build a module-designed codebase and formulate unified training standards for the community. Furthermore, we also design an error diagnosis toolbox to measure the detailed characterization of detection models. Using these tools, we analyze current methods in-depth under varying settings and provide discussions for some open questions, e.g., discrepancies in conclusions on KITTI-3D and nuScenes datasets, which have led to different dominant methods for these datasets. We hope that this work will facilitate future research in image-based 3D object detection. Our codes will be released at \\url{https://github.com/OpenGVLab/3dodi} ",
    "url": "https://arxiv.org/abs/2310.05447",
    "authors": [
      "Xinzhu Ma",
      "Yongtao Wan",
      "Yinmin Zhang",
      "Zhiyi Xia",
      "Yuan Meng",
      "Zhihui Wang",
      "Haojie Li",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05450",
    "title": "Empower Nested Boolean Logic via Self-Supervised Curriculum Learning",
    "abstract": "Beyond the great cognitive powers showcased by language models, it is crucial to scrutinize whether their reasoning capabilities stem from strong generalization or merely exposure to relevant data. As opposed to constructing increasingly complex logic, this paper probes into the boolean logic, the root capability of a logical reasoner. We find that any pre-trained language models even including large language models only behave like a random selector in the face of multi-nested boolean logic, a task that humans can handle with ease. To empower language models with this fundamental capability, this paper proposes a new self-supervised learning method \\textit{Curriculum Logical Reasoning} (\\textsc{Clr}), where we augment the training data with nested boolean logic chain step-by-step, and program the training from simpler logical patterns gradually to harder ones. This new training paradigm allows language models to effectively generalize to much harder and longer-hop logic, which can hardly be learned through naive training. Furthermore, we show that boolean logic is a great foundation for improving the subsequent general logical tasks. ",
    "url": "https://arxiv.org/abs/2310.05450",
    "authors": [
      "Hongqiu Wu",
      "Linfeng Liu",
      "Hai Zhao",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.05452",
    "title": "Explaining the Complex Task Reasoning of Large Language Models with  Template-Content Structure",
    "abstract": "The continuous evolution of pre-trained large language models with ever-growing parameters and corpus sizes has augmented their capacity to solve complex tasks. This ability, which obviates the necessity for task-specific training or fine-tuning, relies on providing the model with a language description or some task exemplars -- referred to the prompt -- that guide the desired autoregressive generation. Despite the remarkable success, the underlying mechanisms that facilitate such exceptional generalization abilities remain an open question. In this paper, we present a novel framework that formally conceptualizes answer generation for complex natural language tasks as a hierarchical ``template-content'' structure. According to our modeling, there exist pre-trained models that can automatically decompose tasks into constituent steps during autoregressive generation, through language modeling on a sufficiently large corpus, thereby solving them. Our framework offers an explanatory tool for the complex reasoning abilities of large language models from the perspective of modeling autoregressive generation tasks. Our experiments show that practical models exhibit different behaviors for ``template'' and ``content'' providing support for our modeling. ",
    "url": "https://arxiv.org/abs/2310.05452",
    "authors": [
      "Haotong Yang",
      "Fanxu Meng",
      "Zhouchen Lin",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.05453",
    "title": "Memory-Assisted Sub-Prototype Mining for Universal Domain Adaptation",
    "abstract": "Universal domain adaptation aims to align the classes and reduce the feature gap between the same category of the source and target domains. The target private category is set as the unknown class during the adaptation process, as it is not included in the source domain. However, most existing methods overlook the intra-class structure within a category, especially in cases where there exists significant concept shift between the samples belonging to the same category. When samples with large concept shift are forced to be pushed together, it may negatively affect the adaptation performance. Moreover, from the interpretability aspect, it is unreasonable to align visual features with significant differences, such as fighter jets and civil aircraft, into the same category. Unfortunately, due to such semantic ambiguity and annotation cost, categories are not always classified in detail, making it difficult for the model to perform precise adaptation. To address these issues, we propose a novel Memory-Assisted Sub-Prototype Mining (MemSPM) method that can learn the differences between samples belonging to the same category and mine sub-classes when there exists significant concept shift between them. By doing so, our model learns a more reasonable feature space that enhances the transferability and reflects the inherent differences among samples annotated as the same category. We evaluate the effectiveness of our MemSPM method over multiple scenarios, including UniDA, OSDA, and PDA. Our method achieves state-of-the-art performance on four benchmarks in most cases. ",
    "url": "https://arxiv.org/abs/2310.05453",
    "authors": [
      "Yuxiang Lai",
      "Xinghong Liu",
      "Tao Zhou",
      "Yi Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05456",
    "title": "Ensemble-based Hybrid Optimization of Bayesian Neural Networks and  Traditional Machine Learning Algorithms",
    "abstract": "This research introduces a novel methodology for optimizing Bayesian Neural Networks (BNNs) by synergistically integrating them with traditional machine learning algorithms such as Random Forests (RF), Gradient Boosting (GB), and Support Vector Machines (SVM). Feature integration solidifies these results by emphasizing the second-order conditions for optimality, including stationarity and positive definiteness of the Hessian matrix. Conversely, hyperparameter tuning indicates a subdued impact in improving Expected Improvement (EI), represented by EI(x). Overall, the ensemble method stands out as a robust, algorithmically optimized approach. ",
    "url": "https://arxiv.org/abs/2310.05456",
    "authors": [
      "Peiwen Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05467",
    "title": "Temporal Convolutional Explorer Helps Understand 1D-CNN's Learning  Behavior in Time Series Classification from Frequency Domain",
    "abstract": "While one-dimensional convolutional neural networks (1D-CNNs) have been empirically proven effective in time series classification tasks, we find that there remain undesirable outcomes that could arise in their application, motivating us to further investigate and understand their underlying mechanisms. In this work, we propose a Temporal Convolutional Explorer (TCE) to empirically explore the learning behavior of 1D-CNNs from the perspective of the frequency domain. Our TCE analysis highlights that deeper 1D-CNNs tend to distract the focus from the low-frequency components leading to the accuracy degradation phenomenon, and the disturbing convolution is the driving factor. Then, we leverage our findings to the practical application and propose a regulatory framework, which can easily be integrated into existing 1D-CNNs. It aims to rectify the suboptimal learning behavior by enabling the network to selectively bypass the specified disturbing convolutions. Finally, through comprehensive experiments on widely-used UCR, UEA, and UCI benchmarks, we demonstrate that 1) TCE's insight into 1D-CNN's learning behavior; 2) our regulatory framework enables state-of-the-art 1D-CNNs to get improved performances with less consumption of memory and computational overhead. ",
    "url": "https://arxiv.org/abs/2310.05467",
    "authors": [
      "Junru Zhang",
      "Lang Feng",
      "Yang He",
      "Yuhan Wu",
      "Yabo Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05469",
    "title": "Vibroacoustic Frequency Response Prediction with Query-based Operator  Networks",
    "abstract": "Understanding vibroacoustic wave propagation in mechanical structures like airplanes, cars and houses is crucial to ensure health and comfort of their users. To analyze such systems, designers and engineers primarily consider the dynamic response in the frequency domain, which is computed through expensive numerical simulations like the finite element method. In contrast, data-driven surrogate models offer the promise of speeding up these simulations, thereby facilitating tasks like design optimization, uncertainty quantification, and design space exploration. We present a structured benchmark for a representative vibroacoustic problem: Predicting the frequency response for vibrating plates with varying forms of beadings. The benchmark features a total of 12,000 plate geometries with an associated numerical solution and introduces evaluation metrics to quantify the prediction quality. To address the frequency response prediction task, we propose a novel frequency query operator model, which is trained to map plate geometries to frequency response functions. By integrating principles from operator learning and implicit models for shape encoding, our approach effectively addresses the prediction of resonance peaks of frequency responses. We evaluate the method on our vibrating-plates benchmark and find that it outperforms DeepONets, Fourier Neural Operators and more traditional neural network architectures. The code and dataset are available from https://eckerlab.org/code/delden2023_plate. ",
    "url": "https://arxiv.org/abs/2310.05469",
    "authors": [
      "Jan van Delden",
      "Julius Schultz",
      "Christopher Blech",
      "Sabine C. Langer",
      "Timo L\u00fcddecke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05471",
    "title": "Drawn Tree Decomposition: New Approach for Graph Drawing Problems",
    "abstract": "Over the past decade, we witness an increasing amount of interest in the design of exact exponential-time and parameterized algorithms for problems in Graph Drawing. Unfortunately, we still lack knowledge of general methods to develop such algorithms. An even more serious issue is that, here, \"standard\" parameters very often yield intractability. In particular, for the most common structural parameter, namely, treewidth, we frequently observe NP-hardness already when the input graphs are restricted to have constant (often, being just $1$ or $2$) treewidth. Our work deals with both drawbacks simultaneously. We introduce a novel form of tree decomposition that, roughly speaking, does not decompose (only) a graph, but an entire drawing. As such, its bags and separators are of geometric (rather than only combinatorial) nature. While the corresponding parameter -- like treewidth -- can be arbitrarily smaller than the height (and width) of the drawing, we show that -- unlike treewidth -- it gives rise to efficient algorithms. Specifically, we get slice-wise polynomial (XP) time algorithms parameterized by our parameter. We present a general scheme for the design of such algorithms, and apply it to several central problems in Graph Drawing, including the recognition of grid graphs, minimization of crossings and bends, and compaction. Other than for the class of problems we discussed in the paper, we believe that our decomposition and scheme are of independent interest and can be further extended or generalized to suit even a wider class of problems. Additionally, we discuss classes of drawings where our parameter is bounded by $O(\\sqrt{n})$ (where $n$ is the number of vertices of the graph), yielding subexponential-time algorithms. Lastly, we prove which relations exist between drawn treewidth and other width measures, including treewidth, pathwidth, (dual) carving-width and embedded-width. ",
    "url": "https://arxiv.org/abs/2310.05471",
    "authors": [
      "Siddharth Gupta",
      "Guy Sa'ar",
      "Meirav Zehavi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2310.05480",
    "title": "Collective Graph Exploration Parameterized by Vertex Cover",
    "abstract": "We initiate the study of the parameterized complexity of the {\\sc Collective Graph Exploration} ({\\sc CGE}) problem. In {\\sc CGE}, the input consists of an undirected connected graph $G$ and a collection of $k$ robots, initially placed at the same vertex $r$ of $G$, and each one of them has an energy budget of $B$. The objective is to decide whether $G$ can be \\emph{explored} by the $k$ robots in $B$ time steps, i.e., there exist $k$ closed walks in $G$, one corresponding to each robot, such that every edge is covered by at least one walk, every walk starts and ends at the vertex $r$, and the maximum length of any walk is at most $B$. Unfortunately, this problem is \\textsf{NP}-hard even on trees [Fraigniaud {\\em et~al.}, 2006]. Further, we prove that the problem remains \\textsf{W[1]}-hard parameterized by $k$ even for trees of treedepth $3$. Due to the \\textsf{para-NP}-hardness of the problem parameterized by treedepth, and motivated by real-world scenarios, we study the parameterized complexity of the problem parameterized by the vertex cover number ($\\mathsf{vc}$) of the graph, and prove that the problem is fixed-parameter tractable (\\textsf{FPT}) parameterized by $\\mathsf{vc}$. Additionally, we study the optimization version of {\\sc CGE}, where we want to optimize $B$, and design an approximation algorithm with an additive approximation factor of $O(\\mathsf{vc})$. ",
    "url": "https://arxiv.org/abs/2310.05480",
    "authors": [
      "Siddharth Gupta",
      "Guy Sa'ar",
      "Meirav Zehavi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2310.05483",
    "title": "Geometry-Guided Ray Augmentation for Neural Surface Reconstruction with  Sparse Views",
    "abstract": "In this paper, we propose a novel method for 3D scene and object reconstruction from sparse multi-view images. Different from previous methods that leverage extra information such as depth or generalizable features across scenes, our approach leverages the scene properties embedded in the multi-view inputs to create precise pseudo-labels for optimization without any prior training. Specifically, we introduce a geometry-guided approach that improves surface reconstruction accuracy from sparse views by leveraging spherical harmonics to predict the novel radiance while holistically considering all color observations for a point in the scene. Also, our pipeline exploits proxy geometry and correctly handles the occlusion in generating the pseudo-labels of radiance, which previous image-warping methods fail to avoid. Our method, dubbed Ray Augmentation (RayAug), achieves superior results on DTU and Blender datasets without requiring prior training, demonstrating its effectiveness in addressing the problem of sparse view reconstruction. Our pipeline is flexible and can be integrated into other implicit neural reconstruction methods for sparse views. ",
    "url": "https://arxiv.org/abs/2310.05483",
    "authors": [
      "Jiawei Yao",
      "Chen Wang",
      "Tong Wu",
      "Chuming Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05484",
    "title": "IDTraffickers: An Authorship Attribution Dataset to link and connect  Potential Human-Trafficking Operations on Text Escort Advertisements",
    "abstract": "Human trafficking (HT) is a pervasive global issue affecting vulnerable individuals, violating their fundamental human rights. Investigations reveal that a significant number of HT cases are associated with online advertisements (ads), particularly in escort markets. Consequently, identifying and connecting HT vendors has become increasingly challenging for Law Enforcement Agencies (LEAs). To address this issue, we introduce IDTraffickers, an extensive dataset consisting of 87,595 text ads and 5,244 vendor labels to enable the verification and identification of potential HT vendors on online escort markets. To establish a benchmark for authorship identification, we train a DeCLUTR-small model, achieving a macro-F1 score of 0.8656 in a closed-set classification environment. Next, we leverage the style representations extracted from the trained classifier to conduct authorship verification, resulting in a mean r-precision score of 0.8852 in an open-set ranking environment. Finally, to encourage further research and ensure responsible data sharing, we plan to release IDTraffickers for the authorship attribution task to researchers under specific conditions, considering the sensitive nature of the data. We believe that the availability of our dataset and benchmarks will empower future researchers to utilize our findings, thereby facilitating the effective linkage of escort ads and the development of more robust approaches for identifying HT indicators. ",
    "url": "https://arxiv.org/abs/2310.05484",
    "authors": [
      "Vageesh Saxena",
      "Benjamin Bashpole",
      "Gijs Van Dijck",
      "Gerasimos Spanakis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05495",
    "title": "A Neural Tangent Kernel View on Federated Averaging for Deep Linear  Neural Network",
    "abstract": "Federated averaging (FedAvg) is a widely employed paradigm for collaboratively training models from distributed clients without sharing data. Nowadays, the neural network has achieved remarkable success due to its extraordinary performance, which makes it a preferred choice as the model in FedAvg. However, the optimization problem of the neural network is often non-convex even non-smooth. Furthermore, FedAvg always involves multiple clients and local updates, which results in an inaccurate updating direction. These properties bring difficulties in analyzing the convergence of FedAvg in training neural networks. Recently, neural tangent kernel (NTK) theory has been proposed towards understanding the convergence of first-order methods in tackling the non-convex problem of neural networks. The deep linear neural network is a classical model in theoretical subject due to its simple formulation. Nevertheless, there exists no theoretical result for the convergence of FedAvg in training the deep linear neural network. By applying NTK theory, we make a further step to provide the first theoretical guarantee for the global convergence of FedAvg in training deep linear neural networks. Specifically, we prove FedAvg converges to the global minimum at a linear rate $\\mathcal{O}\\big((1-\\eta K /N)^t\\big)$, where $t$ is the number of iterations, $\\eta$ is the learning rate, $N$ is the number of clients and $K$ is the number of local updates. Finally, experimental evaluations on two benchmark datasets are conducted to empirically validate the correctness of our theoretical findings. ",
    "url": "https://arxiv.org/abs/2310.05495",
    "authors": [
      "Xin Liu",
      "Dazhi Zhan",
      "Wei Tao",
      "Xin Ma",
      "Yu Pan",
      "Yu Ding",
      "Zhisong Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.05498",
    "title": "Semi-Supervised Object Detection with Uncurated Unlabeled Data for  Remote Sensing Images",
    "abstract": "Annotating remote sensing images (RSIs) presents a notable challenge due to its labor-intensive nature. Semi-supervised object detection (SSOD) methods tackle this issue by generating pseudo-labels for the unlabeled data, assuming that all classes found in the unlabeled dataset are also represented in the labeled data. However, real-world situations introduce the possibility of out-of-distribution (OOD) samples being mixed with in-distribution (ID) samples within the unlabeled dataset. In this paper, we delve into techniques for conducting SSOD directly on uncurated unlabeled data, which is termed Open-Set Semi-Supervised Object Detection (OSSOD). Our approach commences by employing labeled in-distribution data to dynamically construct a class-wise feature bank (CFB) that captures features specific to each class. Subsequently, we compare the features of predicted object bounding boxes with the corresponding entries in the CFB to calculate OOD scores. We design an adaptive threshold based on the statistical properties of the CFB, allowing us to filter out OOD samples effectively. The effectiveness of our proposed method is substantiated through extensive experiments on two widely used remote sensing object detection datasets: DIOR and DOTA. These experiments showcase the superior performance and efficacy of our approach for OSSOD on RSIs. ",
    "url": "https://arxiv.org/abs/2310.05498",
    "authors": [
      "Nanqing Liu",
      "Xun Xu",
      "Yingjie Gao",
      "Heng-Chao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05499",
    "title": "Integrating Graphs with Large Language Models: Methods and Prospects",
    "abstract": "Large language models (LLMs) such as GPT-4 have emerged as frontrunners, showcasing unparalleled prowess in diverse applications, including answering queries, code generation, and more. Parallelly, graph-structured data, an intrinsic data type, is pervasive in real-world scenarios. Merging the capabilities of LLMs with graph-structured data has been a topic of keen interest. This paper bifurcates such integrations into two predominant categories. The first leverages LLMs for graph learning, where LLMs can not only augment existing graph algorithms but also stand as prediction models for various graph tasks. Conversely, the second category underscores the pivotal role of graphs in advancing LLMs. Mirroring human cognition, we solve complex tasks by adopting graphs in either reasoning or collaboration. Integrating with such structures can significantly boost the performance of LLMs in various complicated tasks. We also discuss and propose open questions for integrating LLMs with graph-structured data for the future direction of the field. ",
    "url": "https://arxiv.org/abs/2310.05499",
    "authors": [
      "Shirui Pan",
      "Yizhen Zheng",
      "Yixin Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05506",
    "title": "Query and Response Augmentation Cannot Help Out-of-domain Math Reasoning  Generalization",
    "abstract": "In math reasoning with large language models (LLMs), fine-tuning data augmentation by query evolution and diverse reasoning paths is empirically verified effective, profoundly narrowing the gap between open-sourced LLMs and cutting-edge proprietary LLMs. In this paper, we conduct an investigation for such data augmentation in math reasoning and are intended to answer: (1) What strategies of data augmentation are more effective; (2) What is the scaling relationship between the amount of augmented data and model performance; and (3) Can data augmentation incentivize generalization to out-of-domain mathematical reasoning tasks? To this end, we create a new dataset, AugGSM8K, by complicating and diversifying the queries from GSM8K and sampling multiple reasoning paths. We obtained a series of LLMs called MuggleMath by fine-tuning on subsets of AugGSM8K. MuggleMath substantially achieves new state-of-the-art on GSM8K (from 54% to 68.4% at the scale of 7B, and from 63.9% to 74.0% at the scale of 13B). A log-linear relationship is presented between MuggleMath's performance and the amount of augmented data. We also find that MuggleMath is weak in out-of-domain math reasoning generalization to MATH. This is attributed to the differences in query distribution between AugGSM8K and MATH which suggest that augmentation on a single benchmark could not help with overall math reasoning performance. Codes and AugGSM8K will be uploaded to https://github.com/OFA-Sys/gsm8k-ScRel. ",
    "url": "https://arxiv.org/abs/2310.05506",
    "authors": [
      "Chengpeng Li",
      "Zheng Yuan",
      "Guanting Dong",
      "Keming Lu",
      "Jiancan Wu",
      "Chuanqi Tan",
      "Xiang Wang",
      "Chang Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05512",
    "title": "UAVs and Neural Networks for search and rescue missions",
    "abstract": "In this paper, we present a method for detecting objects of interest, including cars, humans, and fire, in aerial images captured by unmanned aerial vehicles (UAVs) usually during vegetation fires. To achieve this, we use artificial neural networks and create a dataset for supervised learning. We accomplish the assisted labeling of the dataset through the implementation of an object detection pipeline that combines classic image processing techniques with pretrained neural networks. In addition, we develop a data augmentation pipeline to augment the dataset with automatically labeled images. Finally, we evaluate the performance of different neural networks. ",
    "url": "https://arxiv.org/abs/2310.05512",
    "authors": [
      "Hartmut Surmann",
      "Artur Leinweber",
      "Gerhard Senkowski",
      "Julien Meine",
      "Dominik Slomma"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05517",
    "title": "WeatherGNN: Exploiting Complicated Relationships in Numerical Weather  Prediction Bias Correction",
    "abstract": "Numerical weather prediction (NWP) may be inaccurate or biased due to incomplete atmospheric physical processes, insufficient spatial-temporal resolution, and inherent uncertainty of weather. Previous studies have attempted to correct biases by using handcrafted features and domain knowledge, or by applying general machine learning models naively. They do not fully explore the complicated meteorologic interactions and spatial dependencies in the atmosphere dynamically, which limits their applicability in NWP bias-correction. Specifically, weather factors interact with each other in complex ways, and these interactions can vary regionally. In addition, the interactions between weather factors are further complicated by the spatial dependencies between regions, which are influenced by varied terrain and atmospheric motions. To address these issues, we propose WeatherGNN, an NWP bias-correction method that utilizes Graph Neural Networks (GNN) to learn meteorologic and geographic relationships in a unified framework. Our approach includes a factor-wise GNN that captures meteorological interactions within each grid (a specific location) adaptively, and a fast hierarchical GNN that captures spatial dependencies between grids dynamically. Notably, the fast hierarchical GNN achieves linear complexity with respect to the number of grids, enhancing model efficiency and scalability. Our experimental results on two real-world datasets demonstrate the superiority of WeatherGNN in comparison with other SOTA methods, with an average improvement of 40.50\\% on RMSE compared to the original NWP. ",
    "url": "https://arxiv.org/abs/2310.05517",
    "authors": [
      "Binqing Wu",
      "Weiqi Chen",
      "Wengwei Wang",
      "Bingqing Peng",
      "Liang Sun",
      "Ling Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05524",
    "title": "Bi-directional Deformation for Parameterization of Neural Implicit  Surfaces",
    "abstract": "The growing capabilities of neural rendering have increased the demand for new techniques that enable the intuitive editing of 3D objects, particularly when they are represented as neural implicit surfaces. In this paper, we present a novel neural algorithm to parameterize neural implicit surfaces to simple parametric domains, such as spheres, cubes or polycubes, where 3D radiance field can be represented as a 2D field, thereby facilitating visualization and various editing tasks. Technically, our method computes a bi-directional deformation between 3D objects and their chosen parametric domains, eliminating the need for any prior information. We adopt a forward mapping of points on the zero level set of the 3D object to a parametric domain, followed by a backward mapping through inverse deformation. To ensure the map is bijective, we employ a cycle loss while optimizing the smoothness of both deformations. Additionally, we leverage a Laplacian regularizer to effectively control angle distortion and offer the flexibility to choose from a range of parametric domains for managing area distortion. Designed for compatibility, our framework integrates seamlessly with existing neural rendering pipelines, taking multi-view images as input to reconstruct 3D geometry and compute the corresponding texture map. We also introduce a simple yet effective technique for intrinsic radiance decomposition, facilitating both view-independent material editing and view-dependent shading editing. Our method allows for the immediate rendering of edited textures through volume rendering, without the need for network re-training. Moreover, our approach supports the co-parameterization of multiple objects and enables texture transfer between them. We demonstrate the effectiveness of our method on images of human heads and man-made objects. We will make the source code publicly available. ",
    "url": "https://arxiv.org/abs/2310.05524",
    "authors": [
      "Baixin Xu",
      "Jiangbei Hu",
      "Fei Hou",
      "Kwan-Yee Lin",
      "Wayne Wu",
      "Chen Qian",
      "Ying He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05525",
    "title": "Physical Layer Security in a Private 5G Network for Industrial and  Mobility Application",
    "abstract": "Cellular communication technologies such as 5G are deployed on a large scale around the world. Compared to other communication technologies such as WiFi, Bluetooth, or Ultra Wideband, the 5G communication standard describes support for a large variety of use cases, e.g., Internet of Things, vehicular, industrial, and campus-wide communications. An organization can operate a Private 5G network to provide connectivity to devices in their manufacturing environment. Physical Layer Key Generation (PLKG) is a method to generate a symmetric secret on two nodes despite the presence of a potential passive eavesdropper. To the best of our knowledge, this work is one of the first to implement PLKG in a real Private 5G network. Therefore, it highlights the possibility of integrating PLKG in the communication technology highly relevant for industrial applications. This paper exemplifies the establishment of a long-term symmetric key between an aerial vehicle and IT infrastructure both located in a manufacturing environment and communicating via the radio interface of the Private 5G network. ",
    "url": "https://arxiv.org/abs/2310.05525",
    "authors": [
      "Shivraj Hanumant Gonde",
      "Christoph Frisch",
      "Svetoslav Duhovnikov",
      "Martin Kubisch",
      "Thomas Meyerhoff",
      "Dominic Schupke"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.05527",
    "title": "Diagonal of Pseudoinverse of Graph Laplacian: Fast Estimation and Exact  Results",
    "abstract": "The diagonal entries of pseudoinverse of the Laplacian matrix of a graph appear in many important practical applications, since they contain much information of the graph and many relevant quantities can be expressed in terms of them, such as Kirchhoff index and current flow centrality. However, a na\\\"{\\i}ve approach for computing the diagonal of a matrix inverse has cubic computational complexity in terms of the matrix dimension, which is not acceptable for large graphs with millions of nodes. Thus, rigorous solutions to the diagonal of the Laplacian matrices for general graphs, even for particluar graphs are much less. In this paper, we propose a theoretically guaranteed estimation algorithm, which approximates all diagonal entries of the pseudoinverse of a graph Laplacian in nearly linear time with respect to the number of edges in the graph. We execute extensive experiments on real-life networks, which indicate that our algorithm is both efficient and accurate. Also, we determine exact expressions for the diagonal elements of pseudoinverse of the Laplacian matrices for Koch networks and uniform recursive trees, and compare them with those obtained by our approximation algorithm. Finally, we use our algorithm to evaluate the Kirchhoff index of three deterministic model networks, for which the Kirchhoff index can be rigorously determined. These results further show the effectiveness and efficiency of our algorithm. ",
    "url": "https://arxiv.org/abs/2310.05527",
    "authors": [
      "Zenan Lu",
      "Wanyue Xu",
      "Zhongzhi Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2310.05530",
    "title": "NetTiSA: Extended IP Flow with Time-series Features for Universal  Bandwidth-constrained High-speed Network Traffic Classification",
    "abstract": "Network traffic monitoring based on IP Flows is a standard monitoring approach that can be deployed to various network infrastructures, even the large IPS-based networks connecting millions of people. Since flow records traditionally contain only limited information (addresses, transport ports, and amount of exchanged data), they are also commonly extended for additional features that enable network traffic analysis with high accuracy. Nevertheless, the flow extensions are often too large or hard to compute, which limits their deployment only to smaller-sized networks. This paper proposes a novel extended IP flow called NetTiSA (Network Time Series Analysed), which is based on the analysis of the time series of packet sizes. By thoroughly testing 25 different network classification tasks, we show the broad applicability and high usability of NetTiSA, which often outperforms the best-performing related works. For practical deployment, we also consider the sizes of flows extended for NetTiSA and evaluate the performance impacts of its computation in the flow exporter. The novel feature set proved universal and deployable to high-speed ISP networks with 100\\,Gbps lines; thus, it enables accurate and widespread network security protection. ",
    "url": "https://arxiv.org/abs/2310.05530",
    "authors": [
      "Josef Koumar",
      "Karel Hynek",
      "Jaroslav Pe\u0161ek",
      "Tom\u00e1\u0161 \u010cejka"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05556",
    "title": "WeatherDepth: Curriculum Contrastive Learning for Self-Supervised Depth  Estimation under Adverse Weather Conditions",
    "abstract": "Depth estimation models have shown promising performance on clear scenes but fail to generalize to adverse weather conditions due to illumination variations, weather particles, etc. In this paper, we propose WeatherDepth, a self-supervised robust depth estimation model with curriculum contrastive learning, to tackle performance degradation in complex weather conditions. Concretely, we first present a progressive curriculum learning scheme with three simple-to-complex curricula to gradually adapt the model from clear to relative adverse, and then to adverse weather scenes. It encourages the model to gradually grasp beneficial depth cues against the weather effect, yielding smoother and better domain adaption. Meanwhile, to prevent the model from forgetting previous curricula, we integrate contrastive learning into different curricula. Drawn the reference knowledge from the previous course, our strategy establishes a depth consistency constraint between different courses towards robust depth estimation in diverse weather. Besides, to reduce manual intervention and better adapt to different models, we designed an adaptive curriculum scheduler to automatically search for the best timing for course switching. In the experiment, the proposed solution is proven to be easily incorporated into various architectures and demonstrates state-of-the-art (SoTA) performance on both synthetic and real weather datasets. ",
    "url": "https://arxiv.org/abs/2310.05556",
    "authors": [
      "Jiyuan Wang",
      "Chunyu Lin",
      "Lang Nie",
      "Shujun Huang",
      "Yao Zhao",
      "Xing Pan",
      "Rui Ai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05563",
    "title": "STREAM: Social data and knowledge collective intelligence platform for  TRaining Ethical AI Models",
    "abstract": "This paper presents Social data and knowledge collective intelligence platform for TRaining Ethical AI Models (STREAM) to address the challenge of aligning AI models with human moral values, and to provide ethics datasets and knowledge bases to help promote AI models \"follow good advice as naturally as a stream follows its course\". By creating a comprehensive and representative platform that accurately mirrors the moral judgments of diverse groups including humans and AIs, we hope to effectively portray cultural and group variations, and capture the dynamic evolution of moral judgments over time, which in turn will facilitate the Establishment, Evaluation, Embedding, Embodiment, Ensemble, and Evolvement (6Es) of the moral capabilities of AI models. Currently, STREAM has already furnished a comprehensive collection of ethical scenarios, and amassed substantial moral judgment data annotated by volunteers and various popular Large Language Models (LLMs), collectively portraying the moral preferences and performances of both humans and AIs across a range of moral contexts. This paper will outline the current structure and construction of STREAM, explore its potential applications, and discuss its future prospects. ",
    "url": "https://arxiv.org/abs/2310.05563",
    "authors": [
      "Yuwei Wang",
      "Enmeng Lu",
      "Zizhe Ruan",
      "Yao Liang",
      "Yi Zeng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05566",
    "title": "Aggregated f-average Neural Network for Interpretable Ensembling",
    "abstract": "Ensemble learning leverages multiple models (i.e., weak learners) on a common machine learning task to enhance prediction performance. Basic ensembling approaches average the weak learners outputs, while more sophisticated ones stack a machine learning model in between the weak learners outputs and the final prediction. This work fuses both aforementioned frameworks. We introduce an aggregated f-average (AFA) shallow neural network which models and combines different types of averages to perform an optimal aggregation of the weak learners predictions. We emphasise its interpretable architecture and simple training strategy, and illustrate its good performance on the problem of few-shot class incremental learning. ",
    "url": "https://arxiv.org/abs/2310.05566",
    "authors": [
      "Mathieu Vu",
      "Emilie Chouzenoux",
      "Jean-Christophe Pesquet",
      "Ismail Ben Ayed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05589",
    "title": "DRIN: Dynamic Relation Interactive Network for Multimodal Entity Linking",
    "abstract": "Multimodal Entity Linking (MEL) is a task that aims to link ambiguous mentions within multimodal contexts to referential entities in a multimodal knowledge base. Recent methods for MEL adopt a common framework: they first interact and fuse the text and image to obtain representations of the mention and entity respectively, and then compute the similarity between them to predict the correct entity. However, these methods still suffer from two limitations: first, as they fuse the features of text and image before matching, they cannot fully exploit the fine-grained alignment relations between the mention and entity. Second, their alignment is static, leading to low performance when dealing with complex and diverse data. To address these issues, we propose a novel framework called Dynamic Relation Interactive Network (DRIN) for MEL tasks. DRIN explicitly models four different types of alignment between a mention and entity and builds a dynamic Graph Convolutional Network (GCN) to dynamically select the corresponding alignment relations for different input samples. Experiments on two datasets show that DRIN outperforms state-of-the-art methods by a large margin, demonstrating the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2310.05589",
    "authors": [
      "Shangyu Xing",
      "Fei Zhao",
      "Zhen Wu",
      "Chunhui Li",
      "Jianbing Zhang",
      "Xinyu Dai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2310.05595",
    "title": "Decoding the Threat Landscape : ChatGPT, FraudGPT, and WormGPT in Social  Engineering Attacks",
    "abstract": "In the ever-evolving realm of cybersecurity, the rise of generative AI models like ChatGPT, FraudGPT, and WormGPT has introduced both innovative solutions and unprecedented challenges. This research delves into the multifaceted applications of generative AI in social engineering attacks, offering insights into the evolving threat landscape using the blog mining technique. Generative AI models have revolutionized the field of cyberattacks, empowering malicious actors to craft convincing and personalized phishing lures, manipulate public opinion through deepfakes, and exploit human cognitive biases. These models, ChatGPT, FraudGPT, and WormGPT, have augmented existing threats and ushered in new dimensions of risk. From phishing campaigns that mimic trusted organizations to deepfake technology impersonating authoritative figures, we explore how generative AI amplifies the arsenal of cybercriminals. Furthermore, we shed light on the vulnerabilities that AI-driven social engineering exploits, including psychological manipulation, targeted phishing, and the crisis of authenticity. To counter these threats, we outline a range of strategies, including traditional security measures, AI-powered security solutions, and collaborative approaches in cybersecurity. We emphasize the importance of staying vigilant, fostering awareness, and strengthening regulations in the battle against AI-enhanced social engineering attacks. In an environment characterized by the rapid evolution of AI models and a lack of training data, defending against generative AI threats requires constant adaptation and the collective efforts of individuals, organizations, and governments. This research seeks to provide a comprehensive understanding of the dynamic interplay between generative AI and social engineering attacks, equipping stakeholders with the knowledge to navigate this intricate cybersecurity landscape. ",
    "url": "https://arxiv.org/abs/2310.05595",
    "authors": [
      "Polra Victor Falade"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.05598",
    "title": "On Prediction-Modelers and Decision-Makers: Why Fairness Requires More  Than a Fair Prediction Model",
    "abstract": "An implicit ambiguity in the field of prediction-based decision-making regards the relation between the concepts of prediction and decision. Much of the literature in the field tends to blur the boundaries between the two concepts and often simply speaks of 'fair prediction.' In this paper, we point out that a differentiation of these concepts is helpful when implementing algorithmic fairness. Even if fairness properties are related to the features of the used prediction model, what is more properly called 'fair' or 'unfair' is a decision system, not a prediction model. This is because fairness is about the consequences on human lives, created by a decision, not by a prediction. We clarify the distinction between the concepts of prediction and decision and show the different ways in which these two elements influence the final fairness properties of a prediction-based decision system. In addition to exploring this relationship conceptually and practically, we propose a framework that enables a better understanding and reasoning of the conceptual logic of creating fairness in prediction-based decision-making. In our framework, we specify different roles, namely the 'prediction-modeler' and the 'decision-maker,' and the information required from each of them for being able to implement fairness of the system. Our framework allows for deriving distinct responsibilities for both roles and discussing some insights related to ethical and legal requirements. Our contribution is twofold. First, we shift the focus from abstract algorithmic fairness to context-dependent decision-making, recognizing diverse actors with unique objectives and independent actions. Second, we provide a conceptual framework that can help structure prediction-based decision problems with respect to fairness issues, identify responsibilities, and implement fairness governance mechanisms in real-world scenarios. ",
    "url": "https://arxiv.org/abs/2310.05598",
    "authors": [
      "Teresa Scantamburlo",
      "Joachim Baumann",
      "Christoph Heitz"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05600",
    "title": "Care3D: An Active 3D Object Detection Dataset of Real Robotic-Care  Environments",
    "abstract": "As labor shortage increases in the health sector, the demand for assistive robotics grows. However, the needed test data to develop those robots is scarce, especially for the application of active 3D object detection, where no real data exists at all. This short paper counters this by introducing such an annotated dataset of real environments. The captured environments represent areas which are already in use in the field of robotic health care research. We further provide ground truth data within one room, for assessing SLAM algorithms running directly on a health care robot. ",
    "url": "https://arxiv.org/abs/2310.05600",
    "authors": [
      "Michael G. Adam",
      "Sebastian Eger",
      "Martin Piccolrovazzi",
      "Maged Iskandar",
      "Joern Vogel",
      "Alexander Dietrich",
      "Seongjien Bien",
      "Jon Skerlj",
      "Abdeldjallil Naceri",
      "Eckehard Steinbach",
      "Alin Albu-Schaeffer",
      "Sami Haddadin",
      "Wolfram Burgard"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05618",
    "title": "ASM: Adaptive Sample Mining for In-The-Wild Facial Expression  Recognition",
    "abstract": "Given the similarity between facial expression categories, the presence of compound facial expressions, and the subjectivity of annotators, facial expression recognition (FER) datasets often suffer from ambiguity and noisy labels. Ambiguous expressions are challenging to differentiate from expressions with noisy labels, which hurt the robustness of FER models. Furthermore, the difficulty of recognition varies across different expression categories, rendering a uniform approach unfair for all expressions. In this paper, we introduce a novel approach called Adaptive Sample Mining (ASM) to dynamically address ambiguity and noise within each expression category. First, the Adaptive Threshold Learning module generates two thresholds, namely the clean and noisy thresholds, for each category. These thresholds are based on the mean class probabilities at each training epoch. Next, the Sample Mining module partitions the dataset into three subsets: clean, ambiguity, and noise, by comparing the sample confidence with the clean and noisy thresholds. Finally, the Tri-Regularization module employs a mutual learning strategy for the ambiguity subset to enhance discrimination ability, and an unsupervised learning strategy for the noise subset to mitigate the impact of noisy labels. Extensive experiments prove that our method can effectively mine both ambiguity and noise, and outperform SOTA methods on both synthetic noisy and original datasets. The supplement material is available at https://github.com/zzzzzzyang/ASM. ",
    "url": "https://arxiv.org/abs/2310.05618",
    "authors": [
      "Ziyang Zhang",
      "Xiao Sun",
      "Liuwei An",
      "Meng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05624",
    "title": "Locality-Aware Generalizable Implicit Neural Representation}",
    "abstract": "Generalizable implicit neural representation (INR) enables a single continuous function, i.e., a coordinate-based neural network, to represent multiple data instances by modulating its weights or intermediate features using latent codes. However, the expressive power of the state-of-the-art modulation is limited due to its inability to localize and capture fine-grained details of data entities such as specific pixels and rays. To address this issue, we propose a novel framework for generalizable INR that combines a transformer encoder with a locality-aware INR decoder. The transformer encoder predicts a set of latent tokens from a data instance to encode local information into each latent token. The locality-aware INR decoder extracts a modulation vector by selectively aggregating the latent tokens via cross-attention for a coordinate input and then predicts the output by progressively decoding with coarse-to-fine modulation through multiple frequency bandwidths. The selective token aggregation and the multi-band feature modulation enable us to learn locality-aware representation in spatial and spectral aspects, respectively. Our framework significantly outperforms previous generalizable INRs and validates the usefulness of the locality-aware latents for downstream tasks such as image generation. ",
    "url": "https://arxiv.org/abs/2310.05624",
    "authors": [
      "Doyup Lee",
      "Chiheon Kim",
      "Minsu Cho",
      "Wook-Shin Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05627",
    "title": "Integrating Stock Features and Global Information via Large Language  Models for Enhanced Stock Return Prediction",
    "abstract": "The remarkable achievements and rapid advancements of Large Language Models (LLMs) such as ChatGPT and GPT-4 have showcased their immense potential in quantitative investment. Traders can effectively leverage these LLMs to analyze financial news and predict stock returns accurately. However, integrating LLMs into existing quantitative models presents two primary challenges: the insufficient utilization of semantic information embedded within LLMs and the difficulties in aligning the latent information within LLMs with pre-existing quantitative stock features. We propose a novel framework consisting of two components to surmount these challenges. The first component, the Local-Global (LG) model, introduces three distinct strategies for modeling global information. These approaches are grounded respectively on stock features, the capabilities of LLMs, and a hybrid method combining the two paradigms. The second component, Self-Correlated Reinforcement Learning (SCRL), focuses on aligning the embeddings of financial news generated by LLMs with stock features within the same semantic space. By implementing our framework, we have demonstrated superior performance in Rank Information Coefficient and returns, particularly compared to models relying only on stock features in the China A-share market. ",
    "url": "https://arxiv.org/abs/2310.05627",
    "authors": [
      "Yujie Ding",
      "Shuai Jia",
      "Tianyi Ma",
      "Bingcheng Mao",
      "Xiuze Zhou",
      "Liuliu Li",
      "Dongming Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)"
    ]
  },
  {
    "id": "arXiv:2310.05651",
    "title": "FENCE: Fairplay Ensuring Network Chain Entity for Real-Time Multiple ID  Detection at Scale In Fantasy Sports",
    "abstract": "Dream11 takes pride in being a unique platform that enables over 190 million fantasy sports users to demonstrate their skills and connect deeper with their favorite sports. While managing such a scale, one issue we are faced with is duplicate/multiple account creation in the system. This is done by some users with the intent of abusing the platform, typically for bonus offers. The challenge is to detect these multiple accounts before it is too late. We propose a graph-based solution to solve this problem in which we first predict edges/associations between users. Using the edge information we highlight clusters of colluding multiple accounts. In this paper, we talk about our distributed ML system which is deployed to serve and support the inferences from our detection models. The challenge is to do this in real-time in order to take corrective actions. A core part of this setup also involves human-in-the-loop components for validation, feedback, and ground-truth labeling. ",
    "url": "https://arxiv.org/abs/2310.05651",
    "authors": [
      "Akriti Upreti",
      "Kartavya Kothari",
      "Utkarsh Thukral",
      "Vishal Verma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05666",
    "title": "Anchor-Intermediate Detector: Decoupling and Coupling Bounding Boxes for  Accurate Object Detection",
    "abstract": "Anchor-based detectors have been continuously developed for object detection. However, the individual anchor box makes it difficult to predict the boundary's offset accurately. Instead of taking each bounding box as a closed individual, we consider using multiple boxes together to get prediction boxes. To this end, this paper proposes the \\textbf{Box Decouple-Couple(BDC) strategy} in the inference, which no longer discards the overlapping boxes, but decouples the corner points of these boxes. Then, according to each corner's score, we couple the corner points to select the most accurate corner pairs. To meet the BDC strategy, a simple but novel model is designed named the \\textbf{Anchor-Intermediate Detector(AID)}, which contains two head networks, i.e., an anchor-based head and an anchor-free \\textbf{Corner-aware head}. The corner-aware head is able to score the corners of each bounding box to facilitate the coupling between corner points. Extensive experiments on MS COCO show that the proposed anchor-intermediate detector respectively outperforms their baseline RetinaNet and GFL method by $\\sim$2.4 and $\\sim$1.2 AP on the MS COCO test-dev dataset without any bells and whistles. Code is available at: https://github.com/YilongLv/AID. ",
    "url": "https://arxiv.org/abs/2310.05666",
    "authors": [
      "Yilong Lv",
      "Min Li",
      "Yujie He",
      "Shaopeng Li",
      "Zhuzhen He",
      "Aitao Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05668",
    "title": "LARA: A Light and Anti-overfitting Retraining Approach for Unsupervised  Anomaly Detection",
    "abstract": "Most of current anomaly detection models assume that the normal pattern remains same all the time. However, the normal patterns of Web services change dramatically and frequently. The model trained on old-distribution data is outdated after such changes. Retraining the whole model every time is expensive. Besides, at the beginning of normal pattern changes, there is not enough observation data from the new distribution. Retraining a large neural network model with limited data is vulnerable to overfitting. Thus, we propose a Light and Anti-overfitting Retraining Approach (LARA) for deep variational auto-encoder based time series anomaly detection methods (VAEs). This work aims to make three novel contributions: 1) the retraining process is formulated as a convex problem and can converge at a fast rate as well as prevent overfitting; 2) designing a ruminate block, which leverages the historical data without the need to store them; 3) mathematically proving that when fine-tuning the latent vector and reconstructed data, the linear formations can achieve the least adjusting errors between the ground truths and the fine-tuned ones. Moreover, we have performed many experiments to verify that retraining LARA with even 43 time slots of data from new distribution can result in its competitive F1 Score in comparison with the state-of-the-art anomaly detection models trained with sufficient data. Besides, we verify its light overhead. ",
    "url": "https://arxiv.org/abs/2310.05668",
    "authors": [
      "Feiyi Chen",
      "Zhen Qing",
      "Yingying Zhang",
      "Shuiguang Deng",
      "Yi Xiao",
      "Guansong Pang",
      "Qingsong Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05692",
    "title": "Based on What We Can Control Artificial Neural Networks",
    "abstract": "How can the stability and efficiency of Artificial Neural Networks (ANNs) be ensured through a systematic analysis method? This paper seeks to address that query. While numerous factors can influence the learning process of ANNs, utilizing knowledge from control systems allows us to analyze its system function and simulate system responses. Although the complexity of most ANNs is extremely high, we still can analyze each factor (e.g., optimiser, hyperparameters) by simulating their system response. This new method also can potentially benefit the development of new optimiser and learning system, especially when discerning which components adversely affect ANNs. Controlling ANNs can benefit from the design of optimiser and learning system, as (1) all optimisers act as controllers, (2) all learning systems operate as control systems with inputs and outputs, and (3) the optimiser should match the learning system. Please find codes: \\url{https://github.com/RandomUserName2023/Control-ANNs}. ",
    "url": "https://arxiv.org/abs/2310.05692",
    "authors": [
      "Cheng Kang",
      "Xujing Yao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05695",
    "title": "Hierarchical Reinforcement Learning for Temporal Pattern Prediction",
    "abstract": "In this work, we explore the use of hierarchical reinforcement learning (HRL) for the task of temporal sequence prediction. Using a combination of deep learning and HRL, we develop a stock agent to predict temporal price sequences from historical stock price data and a vehicle agent to predict steering angles from first person, dash cam images. Our results in both domains indicate that a type of HRL, called feudal reinforcement learning, provides significant improvements to training speed and stability and prediction accuracy over standard RL. A key component to this success is the multi-resolution structure that introduces both temporal and spatial abstraction into the network hierarchy. ",
    "url": "https://arxiv.org/abs/2310.05695",
    "authors": [
      "Faith Johnson",
      "Kristin Dana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05699",
    "title": "Uni3DETR: Unified 3D Detection Transformer",
    "abstract": "Existing point cloud based 3D detectors are designed for the particular scene, either indoor or outdoor ones. Because of the substantial differences in object distribution and point density within point clouds collected from various environments, coupled with the intricate nature of 3D metrics, there is still a lack of a unified network architecture that can accommodate diverse scenes. In this paper, we propose Uni3DETR, a unified 3D detector that addresses indoor and outdoor 3D detection within the same framework. Specifically, we employ the detection transformer with point-voxel interaction for object prediction, which leverages voxel features and points for cross-attention and behaves resistant to the discrepancies from data. We then propose the mixture of query points, which sufficiently exploits global information for dense small-range indoor scenes and local information for large-range sparse outdoor ones. Furthermore, our proposed decoupled IoU provides an easy-to-optimize training target for localization by disentangling the xy and z space. Extensive experiments validate that Uni3DETR exhibits excellent performance consistently on both indoor and outdoor 3D detection. In contrast to previous specialized detectors, which may perform well on some particular datasets but suffer a substantial degradation on different scenes, Uni3DETR demonstrates the strong generalization ability under heterogeneous conditions (Fig. 1). Codes are available at \\href{https://github.com/zhenyuw16/Uni3DETR}{https://github.com/zhenyuw16/Uni3DETR}. ",
    "url": "https://arxiv.org/abs/2310.05699",
    "authors": [
      "Zhenyu Wang",
      "Yali Li",
      "Xi Chen",
      "Hengshuang Zhao",
      "Shengjin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05717",
    "title": "STOPNet: Multiview-based 6-DoF Suction Detection for Transparent Objects  on Production Lines",
    "abstract": "In this work, we present STOPNet, a framework for 6-DoF object suction detection on production lines, with a focus on but not limited to transparent objects, which is an important and challenging problem in robotic systems and modern industry. Current methods requiring depth input fail on transparent objects due to depth cameras' deficiency in sensing their geometry, while we proposed a novel framework to reconstruct the scene on the production line depending only on RGB input, based on multiview stereo. Compared to existing works, our method not only reconstructs the whole 3D scene in order to obtain high-quality 6-DoF suction poses in real time but also generalizes to novel environments, novel arrangements and novel objects, including challenging transparent objects, both in simulation and the real world. Extensive experiments in simulation and the real world show that our method significantly surpasses the baselines and has better generalizability, which caters to practical industrial needs. ",
    "url": "https://arxiv.org/abs/2310.05717",
    "authors": [
      "Yuxuan Kuang",
      "Qin Han",
      "Danshi Li",
      "Qiyu Dai",
      "Lian Ding",
      "Dong Sun",
      "Hanlin Zhao",
      "He Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05727",
    "title": "The Program Testing Ability of Large Language Models for Code",
    "abstract": "Recent development of large language models (LLMs) for code like CodeX and CodeT5+ demonstrates tremendous promise in achieving code intelligence. Their ability of synthesizing code that completes a program for performing a pre-defined task has been intensively tested and verified on benchmark datasets including HumanEval and MBPP. Yet, evaluation of these LLMs from more perspectives (than just program synthesis) is also anticipated, considering their broad scope of applications in software engineering. In this paper, we explore the ability of LLMs for testing programs/code. By performing thorough analyses of recent LLMs for code in program testing, we show a series of intriguing properties of these models and demonstrate how program testing ability of LLMs can be improved. Following recent work which utilizes generated test cases to enhance program synthesis, we further leverage our findings in improving the quality of the synthesized programs and show +11.77% and +4.22% higher code pass rates on HumanEval+ comparing with the GPT-3.5-turbo baseline and the recent state-of-the-art, respectively. ",
    "url": "https://arxiv.org/abs/2310.05727",
    "authors": [
      "Weimin Xiong",
      "Yiwen Guo",
      "Hao Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.05733",
    "title": "Polyhedral approach to weighted connected matchings in general graphs",
    "abstract": "A connected matching in a graph G consists of a set of pairwise disjoint edges whose covered vertices induce a connected subgraph of G. While finding a connected matching of maximum cardinality is a well-solved problem, it is NP-hard to determine an optimal connected matching in an edge-weighted graph, even in the planar bipartite case. We present two mixed integer programming formulations and a sophisticated branch-and-cut scheme to find weighted connected matchings in general graphs. The formulations explore different polyhedra associated to this problem, including strong valid inequalities both from the matching polytope and from the connected subgraph polytope. We conjecture that one attains a tight approximation of the convex hull of connected matchings using our strongest formulation, and report encouraging computational results over DIMACS Implementation Challenge benchmark instances. The source code of the complete implementation is also made available. ",
    "url": "https://arxiv.org/abs/2310.05733",
    "authors": [
      "Phillippe Samer",
      "Phablo F.S. Moura"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2310.05754",
    "title": "Unleashing the power of Neural Collapse for Transferability Estimation",
    "abstract": "Transferability estimation aims to provide heuristics for quantifying how suitable a pre-trained model is for a specific downstream task, without fine-tuning them all. Prior studies have revealed that well-trained models exhibit the phenomenon of Neural Collapse. Based on a widely used neural collapse metric in existing literature, we observe a strong correlation between the neural collapse of pre-trained models and their corresponding fine-tuned models. Inspired by this observation, we propose a novel method termed Fair Collapse (FaCe) for transferability estimation by comprehensively measuring the degree of neural collapse in the pre-trained model. Typically, FaCe comprises two different terms: the variance collapse term, which assesses the class separation and within-class compactness, and the class fairness term, which quantifies the fairness of the pre-trained model towards each class. We investigate FaCe on a variety of pre-trained classification models across different network architectures, source datasets, and training loss functions. Results show that FaCe yields state-of-the-art performance on different tasks including image classification, semantic segmentation, and text classification, which demonstrate the effectiveness and generalization of our method. ",
    "url": "https://arxiv.org/abs/2310.05754",
    "authors": [
      "Yuhe Ding",
      "Bo Jiang",
      "Lijun Sheng",
      "Aihua Zheng",
      "Jian Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05767",
    "title": "Topological Community Detection: A Sheaf-Theoretic Approach",
    "abstract": "We propose a model for network community detection using topological data analysis, a branch of modern data science that leverages theory from algebraic topology to statistical analysis and machine learning. Specifically, we use cellular sheaves, which relate local to global properties of various algebraic topological constructions, to propose three new algorithms for vertex clustering over networks to detect communities. We apply our algorithms to real social network data in numerical experiments and obtain near optimal results in terms of modularity. Our work is the first implementation of sheaves on real social network data and provides a solid proof-of-concept for future work using sheaves as tools to study complex systems captured by networks and simplicial complexes. ",
    "url": "https://arxiv.org/abs/2310.05767",
    "authors": [
      "Arne Wolf",
      "Anthea Monod"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2310.05768",
    "title": "DANet: Enhancing Small Object Detection through an Efficient Deformable  Attention Network",
    "abstract": "Efficient and accurate detection of small objects in manufacturing settings, such as defects and cracks, is crucial for ensuring product quality and safety. To address this issue, we proposed a comprehensive strategy by synergizing Faster R-CNN with cutting-edge methods. By combining Faster R-CNN with Feature Pyramid Network, we enable the model to efficiently handle multi-scale features intrinsic to manufacturing environments. Additionally, Deformable Net is used that contorts and conforms to the geometric variations of defects, bringing precision in detecting even the minuscule and complex features. Then, we incorporated an attention mechanism called Convolutional Block Attention Module in each block of our base ResNet50 network to selectively emphasize informative features and suppress less useful ones. After that we incorporated RoI Align, replacing RoI Pooling for finer region-of-interest alignment and finally the integration of Focal Loss effectively handles class imbalance, crucial for rare defect occurrences. The rigorous evaluation of our model on both the NEU-DET and Pascal VOC datasets underscores its robust performance and generalization capabilities. On the NEU-DET dataset, our model exhibited a profound understanding of steel defects, achieving state-of-the-art accuracy in identifying various defects. Simultaneously, when evaluated on the Pascal VOC dataset, our model showcases its ability to detect objects across a wide spectrum of categories within complex and small scenes. ",
    "url": "https://arxiv.org/abs/2310.05768",
    "authors": [
      "Md Sohag Mia",
      "Abdullah Al Bary Voban",
      "Abu Bakor Hayat Arnob",
      "Abdu Naim",
      "Md Kawsar Ahmed",
      "Md Shariful Islam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05779",
    "title": "Why Should This Article Be Deleted? Transparent Stance Detection in  Multilingual Wikipedia Editor Discussions",
    "abstract": "The moderation of content on online platforms is usually non-transparent. On Wikipedia, however, this discussion is carried out publicly and the editors are encouraged to use the content moderation policies as explanations for making moderation decisions. Currently, only a few comments explicitly mention those policies -- 20% of the English ones, but as few as 2% of the German and Turkish comments. To aid in this process of understanding how content is moderated, we construct a novel multilingual dataset of Wikipedia editor discussions along with their reasoning in three languages. The dataset contains the stances of the editors (keep, delete, merge, comment), along with the stated reason, and a content moderation policy, for each edit decision. We demonstrate that stance and corresponding reason (policy) can be predicted jointly with a high degree of accuracy, adding transparency to the decision-making process. We release both our joint prediction models and the multilingual content moderation dataset for further research on automated transparent content moderation. ",
    "url": "https://arxiv.org/abs/2310.05779",
    "authors": [
      "Lucie-Aim\u00e9e Kaffee",
      "Arnav Arora",
      "Isabelle Augenstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05785",
    "title": "Joint object detection and re-identification for 3D obstacle  multi-camera systems",
    "abstract": "In recent years, the field of autonomous driving has witnessed remarkable advancements, driven by the integration of a multitude of sensors, including cameras and LiDAR systems, in different prototypes. However, with the proliferation of sensor data comes the pressing need for more sophisticated information processing techniques. This research paper introduces a novel modification to an object detection network that uses camera and lidar information, incorporating an additional branch designed for the task of re-identifying objects across adjacent cameras within the same vehicle while elevating the quality of the baseline 3D object detection outcomes. The proposed methodology employs a two-step detection pipeline: initially, an object detection network is employed, followed by a 3D box estimator that operates on the filtered point cloud generated from the network's detections. Extensive experimental evaluations encompassing both 2D and 3D domains validate the effectiveness of the proposed approach and the results underscore the superiority of this method over traditional Non-Maximum Suppression (NMS) techniques, with an improvement of more than 5\\% in the car category in the overlapping areas. ",
    "url": "https://arxiv.org/abs/2310.05785",
    "authors": [
      "Irene Cort\u00e9s",
      "Jorge Beltr\u00e1n",
      "Arturo de la Escalera",
      "Fernando Garc\u00eda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05788",
    "title": "Canonization of a random circulant graph by counting walks",
    "abstract": "It is well known that almost all graphs are canonizable by a simple combinatorial routine known as color refinement. With high probability, this method assigns a unique label to each vertex of a random input graph and, hence, it is applicable only to asymmetric graphs. The strength of combinatorial refinement techniques becomes a subtle issue if the input graphs are highly symmetric. We prove that the combination of color refinement with vertex individualization produces a canonical labeling for almost all circulant digraphs (Cayley digraphs of a cyclic group). To our best knowledge, this is the first application of combinatorial refinement in the realm of vertex-transitive graphs. Remarkably, we do not even need the full power of the color refinement algorithm. We show that the canonical label of a vertex $v$ can be obtained just by counting walks of each length from $v$ to an individualized vertex. ",
    "url": "https://arxiv.org/abs/2310.05788",
    "authors": [
      "Oleg Verbitsky",
      "Maksim Zhukovskii"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2310.05804",
    "title": "Learning Language-guided Adaptive Hyper-modality Representation for  Multimodal Sentiment Analysis",
    "abstract": "Though Multimodal Sentiment Analysis (MSA) proves effective by utilizing rich information from multiple sources (e.g., language, video, and audio), the potential sentiment-irrelevant and conflicting information across modalities may hinder the performance from being further improved. To alleviate this, we present Adaptive Language-guided Multimodal Transformer (ALMT), which incorporates an Adaptive Hyper-modality Learning (AHL) module to learn an irrelevance/conflict-suppressing representation from visual and audio features under the guidance of language features at different scales. With the obtained hyper-modality representation, the model can obtain a complementary and joint representation through multimodal fusion for effective MSA. In practice, ALMT achieves state-of-the-art performance on several popular datasets (e.g., MOSI, MOSEI and CH-SIMS) and an abundance of ablation demonstrates the validity and necessity of our irrelevance/conflict suppression mechanism. ",
    "url": "https://arxiv.org/abs/2310.05804",
    "authors": [
      "Haoyu Zhang",
      "Yu Wang",
      "Guanghao Yin",
      "Kejun Liu",
      "Yuanyuan Liu",
      "Tianshu Yu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2310.05813",
    "title": "Audio compression-assisted feature extraction for voice replay attack  detection",
    "abstract": "Replay attack is one of the most effective and simplest voice spoofing attacks. Detecting replay attacks is challenging, according to the Automatic Speaker Verification Spoofing and Countermeasures Challenge 2021 (ASVspoof 2021), because they involve a loudspeaker, a microphone, and acoustic conditions (e.g., background noise). One obstacle to detecting replay attacks is finding robust feature representations that reflect the channel noise information added to the replayed speech. This study proposes a feature extraction approach that uses audio compression for assistance. Audio compression compresses audio to preserve content and speaker information for transmission. The missed information after decompression is expected to contain content- and speaker-independent information (e.g., channel noise added during the replay process). We conducted a comprehensive experiment with a few data augmentation techniques and 3 classifiers on the ASVspoof 2021 physical access (PA) set and confirmed the effectiveness of the proposed feature extraction approach. To the best of our knowledge, the proposed approach achieves the lowest EER at 22.71% on the ASVspoof 2021 PA evaluation set. ",
    "url": "https://arxiv.org/abs/2310.05813",
    "authors": [
      "Xiangyu Shi",
      "Yuhao Luo",
      "Li Wang",
      "Haorui He",
      "Hao Li",
      "Lei Wang",
      "Zhizheng Wu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.05818",
    "title": "SC-Safety: A Multi-round Open-ended Question Adversarial Safety  Benchmark for Large Language Models in Chinese",
    "abstract": "Large language models (LLMs), like ChatGPT and GPT-4, have demonstrated remarkable abilities in natural language understanding and generation. However, alongside their positive impact on our daily tasks, they can also produce harmful content that negatively affects societal perceptions. To systematically assess the safety of Chinese LLMs, we introduce SuperCLUE-Safety (SC-Safety) - a multi-round adversarial benchmark with 4912 open-ended questions covering more than 20 safety sub-dimensions. Adversarial human-model interactions and conversations significantly increase the challenges compared to existing methods. Experiments on 13 major LLMs supporting Chinese yield the following insights: 1) Closed-source models outperform open-sourced ones in terms of safety; 2) Models released from China demonstrate comparable safety levels to LLMs like GPT-3.5-turbo; 3) Some smaller models with 6B-13B parameters can compete effectively in terms of safety. By introducing SC-Safety, we aim to promote collaborative efforts to create safer and more trustworthy LLMs. The benchmark and findings provide guidance on model selection. Our benchmark can be found at https://www.CLUEbenchmarks.com ",
    "url": "https://arxiv.org/abs/2310.05818",
    "authors": [
      "Liang Xu",
      "Kangkang Zhao",
      "Lei Zhu",
      "Hang Xue"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.05837",
    "title": "A Real-time Method for Inserting Virtual Objects into Neural Radiance  Fields",
    "abstract": "We present the first real-time method for inserting a rigid virtual object into a neural radiance field, which produces realistic lighting and shadowing effects, as well as allows interactive manipulation of the object. By exploiting the rich information about lighting and geometry in a NeRF, our method overcomes several challenges of object insertion in augmented reality. For lighting estimation, we produce accurate, robust and 3D spatially-varying incident lighting that combines the near-field lighting from NeRF and an environment lighting to account for sources not covered by the NeRF. For occlusion, we blend the rendered virtual object with the background scene using an opacity map integrated from the NeRF. For shadows, with a precomputed field of spherical signed distance field, we query the visibility term for any point around the virtual object, and cast soft, detailed shadows onto 3D surfaces. Compared with state-of-the-art techniques, our approach can insert virtual object into scenes with superior fidelity, and has a great potential to be further applied to augmented reality systems. ",
    "url": "https://arxiv.org/abs/2310.05837",
    "authors": [
      "Keyang Ye",
      "Hongzhi Wu",
      "Xin Tong",
      "Kun Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2310.05842",
    "title": "Robust Angular Synchronization via Directed Graph Neural Networks",
    "abstract": "The angular synchronization problem aims to accurately estimate (up to a constant additive phase) a set of unknown angles $\\theta_1, \\dots, \\theta_n\\in[0, 2\\pi)$ from $m$ noisy measurements of their offsets $\\theta_i-\\theta_j \\;\\mbox{mod} \\; 2\\pi.$ Applications include, for example, sensor network localization, phase retrieval, and distributed clock synchronization. An extension of the problem to the heterogeneous setting (dubbed $k$-synchronization) is to estimate $k$ groups of angles simultaneously, given noisy observations (with unknown group assignment) from each group. Existing methods for angular synchronization usually perform poorly in high-noise regimes, which are common in applications. In this paper, we leverage neural networks for the angular synchronization problem, and its heterogeneous extension, by proposing GNNSync, a theoretically-grounded end-to-end trainable framework using directed graph neural networks. In addition, new loss functions are devised to encode synchronization objectives. Experimental results on extensive data sets demonstrate that GNNSync attains competitive, and often superior, performance against a comprehensive set of baselines for the angular synchronization problem and its extension, validating the robustness of GNNSync even at high noise levels. ",
    "url": "https://arxiv.org/abs/2310.05842",
    "authors": [
      "Yixuan He",
      "Gesine Reinert",
      "David Wipf",
      "Mihai Cucuringu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.05845",
    "title": "GraphLLM: Boosting Graph Reasoning Ability of Large Language Model",
    "abstract": "The advancement of Large Language Models (LLMs) has remarkably pushed the boundaries towards artificial general intelligence (AGI), with their exceptional ability on understanding diverse types of information, including but not limited to images and audio. Despite this progress, a critical gap remains in empowering LLMs to proficiently understand and reason on graph data. Recent studies underscore LLMs' underwhelming performance on fundamental graph reasoning tasks. In this paper, we endeavor to unearth the obstacles that impede LLMs in graph reasoning, pinpointing the common practice of converting graphs into natural language descriptions (Graph2Text) as a fundamental bottleneck. To overcome this impediment, we introduce GraphLLM, a pioneering end-to-end approach that synergistically integrates graph learning models with LLMs. This synergy equips LLMs with the ability to proficiently interpret and reason on graph data, harnessing the superior expressive power of graph learning models. Our empirical evaluations across four fundamental graph reasoning tasks validate the effectiveness of GraphLLM. The results exhibit a substantial average accuracy enhancement of 54.44%, alongside a noteworthy context reduction of 96.45% across various graph reasoning tasks. ",
    "url": "https://arxiv.org/abs/2310.05845",
    "authors": [
      "Ziwei Chai",
      "Tianjie Zhang",
      "Liang Wu",
      "Kaiqiao Han",
      "Xiaohai Hu",
      "Xuanwen Huang",
      "Yang Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05848",
    "title": "FMM-Head: Enhancing Autoencoder-based ECG anomaly detection with prior  knowledge",
    "abstract": "Detecting anomalies in electrocardiogram data is crucial to identifying deviations from normal heartbeat patterns and providing timely intervention to at-risk patients. Various AutoEncoder models (AE) have been proposed to tackle the anomaly detection task with ML. However, these models do not consider the specific patterns of ECG leads and are unexplainable black boxes. In contrast, we replace the decoding part of the AE with a reconstruction head (namely, FMM-Head) based on prior knowledge of the ECG shape. Our model consistently achieves higher anomaly detection capabilities than state-of-the-art models, up to 0.31 increase in area under the ROC curve (AUROC), with as little as half the original model size and explainable extracted features. The processing time of our model is four orders of magnitude lower than solving an optimization problem to obtain the same parameters, thus making it suitable for real-time ECG parameters extraction and anomaly detection. ",
    "url": "https://arxiv.org/abs/2310.05848",
    "authors": [
      "Giacomo Verardo",
      "Magnus Boman",
      "Samuel Bruchfeld",
      "Marco Chiesa",
      "Sabine Koch",
      "Gerald Q. Maguire Jr.",
      "Dejan Kostic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.05862",
    "title": "Better Safe than Sorry: Pre-training CLIP against Targeted Data  Poisoning and Backdoor Attacks",
    "abstract": "Contrastive Language-Image Pre-training (CLIP) on large image-caption datasets has achieved remarkable success in zero-shot classification and enabled transferability to new domains. However, CLIP is extremely more vulnerable to targeted data poisoning and backdoor attacks, compared to supervised learning. Perhaps surprisingly, poisoning 0.0001% of CLIP pre-training data is enough to make targeted data poisoning attacks successful. This is four orders of magnitude smaller than what is required to poison supervised models. Despite this vulnerability, existing methods are very limited in defending CLIP models during pre-training. In this work, we propose a strong defense, SAFECLIP, to safely pre-train CLIP against targeted data poisoning and backdoor attacks. SAFECLIP warms up the model by applying unimodal contrastive learning (CL) on image and text modalities separately. Then, it carefully divides the data into safe and risky subsets. SAFECLIP trains on the risky data by applying unimodal CL to image and text modalities separately, and trains on the safe data using the CLIP loss. By gradually increasing the size of the safe subset during the training, SAFECLIP effectively breaks targeted data poisoning and backdoor attacks without harming the CLIP performance. Our extensive experiments show that SAFECLIP decrease the attack success rate of targeted data poisoning attacks from 93.75% to 0% and that of the backdoor attacks from 100% to 0%, without harming the CLIP performance on various datasets. ",
    "url": "https://arxiv.org/abs/2310.05862",
    "authors": [
      "Wenhan Yang",
      "Jingdong Gao",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05867",
    "title": "Domain-wise Invariant Learning for Panoptic Scene Graph Generation",
    "abstract": "Panoptic Scene Graph Generation (PSG) involves the detection of objects and the prediction of their corresponding relationships (predicates). However, the presence of biased predicate annotations poses a significant challenge for PSG models, as it hinders their ability to establish a clear decision boundary among different predicates. This issue substantially impedes the practical utility and real-world applicability of PSG models. To address the intrinsic bias above, we propose a novel framework to infer potentially biased annotations by measuring the predicate prediction risks within each subject-object pair (domain), and adaptively transfer the biased annotations to consistent ones by learning invariant predicate representation embeddings. Experiments show that our method significantly improves the performance of benchmark models, achieving a new state-of-the-art performance, and shows great generalization and effectiveness on PSG dataset. ",
    "url": "https://arxiv.org/abs/2310.05867",
    "authors": [
      "Li Li",
      "You Qin",
      "Wei Ji",
      "Yuxiao Zhou",
      "Roger Zimmermann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05884",
    "title": "A Meta-Learning Perspective on Transformers for Causal Language Modeling",
    "abstract": "The Transformer architecture has become prominent in developing large causal language models. However, mechanisms to explain its capabilities are not well understood. Focused on the training process, here we establish a meta-learning view of the Transformer architecture when trained for the causal language modeling task, by explicating an inner optimization process that may happen within the Transformer. Further, from within the inner optimization, we discover and theoretically analyze a special characteristic of the norms of learned token representations within Transformer-based causal language models. Our analysis is supported by experiments conducted on pre-trained large language models and real-world data. ",
    "url": "https://arxiv.org/abs/2310.05884",
    "authors": [
      "Xinbo Wu",
      "Lav R. Varshney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.05885",
    "title": "DTPP: Differentiable Joint Conditional Prediction and Cost Evaluation  for Tree Policy Planning in Autonomous Driving",
    "abstract": "Motion prediction and cost evaluation are vital components in the decision-making system of autonomous vehicles. However, existing methods often ignore the importance of cost learning and treat them as separate modules. In this study, we employ a tree-structured policy planner and propose a differentiable joint training framework for both ego-conditioned prediction and cost models, resulting in a direct improvement of the final planning performance. For conditional prediction, we introduce a query-centric Transformer model that performs efficient ego-conditioned motion prediction. For planning cost, we propose a learnable context-aware cost function with latent interaction features, facilitating differentiable joint learning. We validate our proposed approach using the real-world nuPlan dataset and its associated planning test platform. Our framework not only matches state-of-the-art planning methods but outperforms other learning-based methods in planning quality, while operating more efficiently in terms of runtime. We show that joint training delivers significantly better performance than separate training of the two modules. Additionally, we find that tree-structured policy planning outperforms the conventional single-stage planning approach. ",
    "url": "https://arxiv.org/abs/2310.05885",
    "authors": [
      "Zhiyu Huang",
      "Peter Karkus",
      "Boris Ivanovic",
      "Yuxiao Chen",
      "Marco Pavone",
      "Chen Lv"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.05899",
    "title": "Enabling Intelligent Vehicular Networks Through Distributed Learning in  the Non-Terrestrial Networks 6G Vision",
    "abstract": "The forthcoming 6G-enabled Intelligent Transportation System (ITS) is set to redefine conventional transportation networks with advanced intelligent services and applications. These technologies, including edge computing, Machine Learning (ML), and network softwarization, pose stringent requirements for latency, energy efficiency, and user data security. Distributed Learning (DL), such as Federated Learning (FL), is essential to meet these demands by distributing the learning process at the network edge. However, traditional FL approaches often require substantial resources for satisfactory learning performance. In contrast, Transfer Learning (TL) and Split Learning (SL) have shown effectiveness in enhancing learning efficiency in resource-constrained wireless scenarios like ITS. Non-terrestrial Networks (NTNs) have recently acquired a central place in the 6G vision, especially for boosting the coverage, capacity, and resilience of traditional terrestrial facilities. Air-based NTN layers, such as High Altitude Platforms (HAPs), can have added advantages in terms of reduced transmission distances and flexible deployments and thus can be exploited to enable intelligent solutions for latency-critical vehicular scenarios. With this motivation, in this work, we introduce the concept of Federated Split Transfer Learning (FSTL) in joint air-ground networks for resource-constrained vehicular scenarios. Simulations carried out in vehicular scenarios validate the efficacy of FSTL on HAPs in NTN, demonstrating significant improvements in addressing the demands of ITS applications. ",
    "url": "https://arxiv.org/abs/2310.05899",
    "authors": [
      "David Naseh",
      "Swapnil Sadashiv Shinde",
      "Daniele Tarchi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.05911",
    "title": "Energy Management in a Cooperative Energy Harvesting Wireless Sensor  Network",
    "abstract": "In this paper, we consider the problem of finding an optimal energy management policy for a network of sensor nodes capable of harvesting their own energy and sharing it with other nodes in the network. We formulate this problem in the discounted cost Markov decision process framework and obtain good energy-sharing policies using the Deep Deterministic Policy Gradient (DDPG) algorithm. Earlier works have attempted to obtain the optimal energy allocation policy for a single sensor and for multiple sensors arranged on a mote with a single centralized energy buffer. Our algorithms, on the other hand, provide optimal policies for a distributed network of sensors individually harvesting energy and capable of sharing energy amongst themselves. Through simulations, we illustrate that the policies obtained by our DDPG algorithm using this enhanced network model outperform algorithms that do not share energy or use a centralized energy buffer in the distributed multi-nodal case. ",
    "url": "https://arxiv.org/abs/2310.05911",
    "authors": [
      "Arghyadeep Barat",
      "Prabuchandran.K.J",
      "Shalabh Bhatnagar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.05916",
    "title": "Interpreting CLIP's Image Representation via Text-Based Decomposition",
    "abstract": "We investigate the CLIP image encoder by analyzing how individual model components affect the final representation. We decompose the image representation as a sum across individual image patches, model layers, and attention heads, and use CLIP's text representation to interpret the summands. Interpreting the attention heads, we characterize each head's role by automatically finding text representations that span its output space, which reveals property-specific roles for many heads (e.g. location or shape). Next, interpreting the image patches, we uncover an emergent spatial localization within CLIP. Finally, we use this understanding to remove spurious features from CLIP and to create a strong zero-shot image segmenter. Our results indicate that a scalable understanding of transformer models is attainable and can be used to repair and improve models. ",
    "url": "https://arxiv.org/abs/2310.05916",
    "authors": [
      "Yossi Gandelsman",
      "Alexei A. Efros",
      "Jacob Steinhardt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.05920",
    "title": "SimPLR: A Simple and Plain Transformer for Object Detection and  Segmentation",
    "abstract": "The ability to detect objects in images at varying scales has played a pivotal role in the design of modern object detectors. Despite considerable progress in removing handcrafted components using transformers, multi-scale feature maps remain a key factor for their empirical success, even with a plain backbone like the Vision Transformer (ViT). In this paper, we show that this reliance on feature pyramids is unnecessary and a transformer-based detector with scale-aware attention enables the plain detector `SimPLR' whose backbone and detection head both operate on single-scale features. The plain architecture allows SimPLR to effectively take advantages of self-supervised learning and scaling approaches with ViTs, yielding strong performance compared to multi-scale counterparts. We demonstrate through our experiments that when scaling to larger backbones, SimPLR indicates better performance than end-to-end detectors (Mask2Former) and plain-backbone detectors (ViTDet), while consistently being faster. The code will be released. ",
    "url": "https://arxiv.org/abs/2310.05920",
    "authors": [
      "Duy-Kien Nguyen",
      "Martin R. Oswald",
      "Cees G. M. Snoek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.04428",
    "title": "Avalanche Prediction and Dynamics using Temperature Variance , Grain  Size Variance and Flow Regimes",
    "abstract": "We investigate the effects of temperature variance, grain size variation, flow regimes, and the use of Support Vector Machines (SVMs) in avalanche studies. The temperature variance experiments involved ice single crystals and polycrystals, revealing that the scale-free pattern of avalanche sizes remains consistent regardless of temperature. The dynamics of dislocations in polycrystals were found to be independent of stress level and temperature. The Material Point Method (MPM) was used to explore snow avalanche behavior and identify flow regimes. The MPM accurately represented various flow patterns of snow avalanches, although challenges remained in capturing powder clouds. SVMs were employed for avalanche forecasting, using meteorological and snowpack variables as input features. The selected features provided insights into snowfall characteristics, snow accumulation, rain interaction, snowdrift patterns, cloud dynamics, snowpack mechanics, and temperature distribution within the snowpack. The findings contribute to a better understanding of avalanche dynamics and offer potential improvements in avalanche trend predictions. ",
    "url": "https://arxiv.org/abs/2310.04428",
    "authors": [
      "Aditya Sharma"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.04606",
    "title": "Robust Transfer Learning with Unreliable Source Data",
    "abstract": "This paper addresses challenges in robust transfer learning stemming from ambiguity in Bayes classifiers and weak transferable signals between the target and source distribution. We introduce a novel quantity called the ''ambiguity level'' that measures the discrepancy between the target and source regression functions, propose a simple transfer learning procedure, and establish a general theorem that shows how this new quantity is related to the transferability of learning in terms of risk improvements. Our proposed ''Transfer Around Boundary'' (TAB) model, with a threshold balancing the performance of target and source data, is shown to be both efficient and robust, improving classification while avoiding negative transfer. Moreover, we demonstrate the effectiveness of the TAB model on non-parametric classification and logistic regression tasks, achieving upper bounds which are optimal up to logarithmic factors. Simulation studies lend further support to the effectiveness of TAB. We also provide simple approaches to bound the excess misclassification error without the need for specialized knowledge in transfer learning. ",
    "url": "https://arxiv.org/abs/2310.04606",
    "authors": [
      "Jianqing Fan",
      "Cheng Gao",
      "Jason M. Klusowski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2310.04622",
    "title": "FluxGAN: A Physics-Aware Generative Adversarial Network Model for  Generating Microstructures That Maintain Target Heat Flux",
    "abstract": "We propose a physics-aware generative adversarial network model, FluxGAN, capable of simultaneously generating high-quality images of large microstructures and description of their thermal properties. During the training phase, the model learns about the relationship between the local structural features and the physical processes, such as the heat flux in the microstructures, due to external temperature gradients. Once trained, the model generates new structural and associated heat flux environments, bypassing the computationally expensive modeling. Our model provides a cost effective and efficient approach over conventional modeling techniques, such as the finite element method (FEM), for describing the thermal properties of microstructures. The conventional approach requires computational modeling that scales with the size of the microstructure model, therefore limiting the simulation to a given size, resolution, and complexity of the model. In contrast, the FluxGAN model uses synthesis-by-part approach and generates arbitrary large size images at low computational cost. We demonstrate that the model can be utilized to generate designs of thermal sprayed coatings that satisfies target thermal properties. Furthermore, the model is capable of generating coating microstructures and physical processes in three-dimensional (3D) domain after being trained on two-dimensional (2D) examples. Our approach has the potential to transform the design and optimization of thermal sprayed coatings for various applications, including high-temperature and long-duration operation of gas turbines for aircraft or ground-based power generators. ",
    "url": "https://arxiv.org/abs/2310.04622",
    "authors": [
      "Artem K. Pimachev",
      "Manoj Settipalli",
      "Sanghamitra Neogi"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04645",
    "title": "Do self-supervised speech and language models extract similar  representations as human brain?",
    "abstract": "Speech and language models trained through self-supervised learning (SSL) demonstrate strong alignment with brain activity during speech and language perception. However, given their distinct training modalities, it remains unclear whether they correlate with the same neural aspects. We directly address this question by evaluating the brain prediction performance of two representative SSL models, Wav2Vec2.0 and GPT-2, designed for speech and language tasks. Our findings reveal that both models accurately predict speech responses in the auditory cortex, with a significant correlation between their brain predictions. Notably, shared speech contextual information between Wav2Vec2.0 and GPT-2 accounts for the majority of explained variance in brain activity, surpassing static semantic and lower-level acoustic-phonetic information. These results underscore the convergence of speech contextual representations in SSL models and their alignment with the neural network underlying speech perception, offering valuable insights into both SSL models and the neural basis of speech and language processing. ",
    "url": "https://arxiv.org/abs/2310.04645",
    "authors": [
      "Peili Chen",
      "Linyang He",
      "Li Fu",
      "Lu Fan",
      "Edward F. Chang",
      "Yuanning Li"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.04705",
    "title": "Multi-scale MRI reconstruction via dilated ensemble networks",
    "abstract": "As aliasing artefacts are highly structural and non-local, many MRI reconstruction networks use pooling to enlarge filter coverage and incorporate global context. However, this inadvertently impedes fine detail recovery as downsampling creates a resolution bottleneck. Moreover, real and imaginary features are commonly split into separate channels, discarding phase information particularly important to high frequency textures. In this work, we introduce an efficient multi-scale reconstruction network using dilated convolutions to preserve resolution and experiment with a complex-valued version using complex convolutions. Inspired by parallel dilated filters, multiple receptive fields are processed simultaneously with branches that see both large structural artefacts and fine local features. We also adopt dense residual connections for feature aggregation to efficiently increase scale and the deep cascade global architecture to reduce overfitting. The real-valued version of this model outperformed common reconstruction architectures as well as a state-of-the-art multi-scale network whilst being three times more efficient. The complex-valued network yielded better qualitative results when more phase information was present. ",
    "url": "https://arxiv.org/abs/2310.04705",
    "authors": [
      "Wendi Ma",
      "Marlon Bran Lorenzana",
      "Wei Dai",
      "Hongfu Sun",
      "Shekhar S. Chandra"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.04715",
    "title": "An Exploration of Task-decoupling on Two-stage Neural Post Filter for  Real-time Personalized Acoustic Echo Cancellation",
    "abstract": "Deep learning based techniques have been popularly adopted in acoustic echo cancellation (AEC). Utilization of speaker representation has extended the frontier of AEC, thus attracting many researchers' interest in personalized acoustic echo cancellation (PAEC). Meanwhile, task-decoupling strategies are widely adopted in speech enhancement. To further explore the task-decoupling approach, we propose to use a two-stage task-decoupling post-filter (TDPF) in PAEC. Furthermore, a multi-scale local-global speaker representation is applied to improve speaker extraction in PAEC. Experimental results indicate that the task-decoupling model can yield better performance than a single joint network. The optimal approach is to decouple the echo cancellation from noise and interference speech suppression. Based on the task-decoupling sequence, optimal training strategies for the two-stage model are explored afterwards. ",
    "url": "https://arxiv.org/abs/2310.04715",
    "authors": [
      "Zihan Zhang",
      "Jiayao Sun",
      "Xianjun Xia",
      "Ziqian Wang",
      "Xiaopeng Yan",
      "Yijian Xiao",
      "Lei Xie"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2310.04762",
    "title": "Robust Low-Rank Matrix Completion via a New Sparsity-Inducing  Regularizer",
    "abstract": "This paper presents a novel loss function referred to as hybrid ordinary-Welsch (HOW) and a new sparsity-inducing regularizer associated with HOW. We theoretically show that the regularizer is quasiconvex and that the corresponding Moreau envelope is convex. Moreover, the closed-form solution to its Moreau envelope, namely, the proximity operator, is derived. Compared with nonconvex regularizers like the lp-norm with 0<p<1 that requires iterations to find the corresponding proximity operator, the developed regularizer has a closed-form proximity operator. We apply our regularizer to the robust matrix completion problem, and develop an efficient algorithm based on the alternating direction method of multipliers. The convergence of the suggested method is analyzed and we prove that any generated accumulation point is a stationary point. Finally, experimental results based on synthetic and real-world datasets demonstrate that our algorithm is superior to the state-of-the-art methods in terms of restoration performance. ",
    "url": "https://arxiv.org/abs/2310.04762",
    "authors": [
      "Zhi-Yong Wang",
      "Hing Cheung So",
      "Abdelhak M. Zoubir"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.04779",
    "title": "TransCC: Transformer Network for Coronary Artery CCTA Segmentation",
    "abstract": "The accurate segmentation of Coronary Computed Tomography Angiography (CCTA) images holds substantial clinical value for the early detection and treatment of Coronary Heart Disease (CHD). The Transformer, utilizing a self-attention mechanism, has demonstrated commendable performance in the realm of medical image processing. However, challenges persist in coronary segmentation tasks due to (1) the damage to target local structures caused by fixed-size image patch embedding, and (2) the critical role of both global and local features in medical image segmentation tasks.To address these challenges, we propose a deep learning framework, TransCC, that effectively amalgamates the Transformer and convolutional neural networks for CCTA segmentation. Firstly, we introduce a Feature Interaction Extraction (FIE) module designed to capture the characteristics of image patches, thereby circumventing the loss of semantic information inherent in the original method. Secondly, we devise a Multilayer Enhanced Perceptron (MEP) to augment attention to local information within spatial dimensions, serving as a complement to the self-attention mechanism. Experimental results indicate that TransCC outperforms existing methods in segmentation performance, boasting an average Dice coefficient of 0.730 and an average Intersection over Union (IoU) of 0.582. These results underscore the effectiveness of TransCC in CCTA image segmentation. ",
    "url": "https://arxiv.org/abs/2310.04779",
    "authors": [
      "Chenchu Xu",
      "Meng Li",
      "Xue Wu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.04859",
    "title": "Universal Graph Random Features",
    "abstract": "We present a novel quasi-Monte Carlo mechanism to improve graph-based sampling, coined repelling random walks. By inducing correlations between the trajectories of an interacting ensemble such that their marginal transition probabilities are unmodified, we are able to explore the graph more efficiently, improving the concentration of statistical estimators whilst leaving them unbiased. The mechanism has a trivial drop-in implementation. We showcase the effectiveness of repelling random walks in a range of settings including estimation of graph kernels, the PageRank vector and graphlet concentrations. We provide detailed experimental evaluation and robust theoretical guarantees. To our knowledge, repelling random walks constitute the first rigorously studied quasi-Monte Carlo scheme correlating the directions of walkers on a graph, inviting new research in this exciting nascent domain. ",
    "url": "https://arxiv.org/abs/2310.04859",
    "authors": [
      "Isaac Reid",
      "Krzysztof Choromanski",
      "Eli Berger",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04871",
    "title": "Machine Learning for Automated Mitral Regurgitation Detection from  Cardiac Imaging",
    "abstract": "Mitral regurgitation (MR) is a heart valve disease with potentially fatal consequences that can only be forestalled through timely diagnosis and treatment. Traditional diagnosis methods are expensive, labor-intensive and require clinical expertise, posing a barrier to screening for MR. To overcome this impediment, we propose a new semi-supervised model for MR classification called CUSSP. CUSSP operates on cardiac imaging slices of the 4-chamber view of the heart. It uses standard computer vision techniques and contrastive models to learn from large amounts of unlabeled data, in conjunction with specialized classifiers to establish the first ever automated MR classification system. Evaluated on a test set of 179 labeled -- 154 non-MR and 25 MR -- sequences, CUSSP attains an F1 score of 0.69 and a ROC-AUC score of 0.88, setting the first benchmark result for this new task. ",
    "url": "https://arxiv.org/abs/2310.04871",
    "authors": [
      "Ke Xiao",
      "Erik Learned-Miller",
      "Evangelos Kalogerakis",
      "James Priest",
      "Madalina Fiterau"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04916",
    "title": "Tight Certified Robustness via Min-Max Representations of ReLU Neural  Networks",
    "abstract": "The reliable deployment of neural networks in control systems requires rigorous robustness guarantees. In this paper, we obtain tight robustness certificates over convex attack sets for min-max representations of ReLU neural networks by developing a convex reformulation of the nonconvex certification problem. This is done by \"lifting\" the problem to an infinite-dimensional optimization over probability measures, leveraging recent results in distributionally robust optimization to solve for an optimal discrete distribution, and proving that solutions of the original nonconvex problem are generated by the discrete distribution under mild boundedness, nonredundancy, and Slater conditions. As a consequence, optimal (worst-case) attacks against the model may be solved for exactly. This contrasts prior state-of-the-art that either requires expensive branch-and-bound schemes or loose relaxation techniques. Experiments on robust control and MNIST image classification examples highlight the benefits of our approach. ",
    "url": "https://arxiv.org/abs/2310.04916",
    "authors": [
      "Brendon G. Anderson",
      "Samuel Pfrommer",
      "Somayeh Sojoudi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04919",
    "title": "The Conditional Prediction Function: A Novel Technique to Control False  Discovery Rate for Complex Models",
    "abstract": "In modern scientific research, the objective is often to identify which variables are associated with an outcome among a large class of potential predictors. This goal can be achieved by selecting variables in a manner that controls the the false discovery rate (FDR), the proportion of irrelevant predictors among the selections. Knockoff filtering is a cutting-edge approach to variable selection that provides FDR control. Existing knockoff statistics frequently employ linear models to assess relationships between features and the response, but the linearity assumption is often violated in real world applications. This may result in poor power to detect truly prognostic variables. We introduce a knockoff statistic based on the conditional prediction function (CPF), which can pair with state-of-art machine learning predictive models, such as deep neural networks. The CPF statistics can capture the nonlinear relationships between predictors and outcomes while also accounting for correlation between features. We illustrate the capability of the CPF statistics to provide superior power over common knockoff statistics with continuous, categorical, and survival outcomes using repeated simulations. Knockoff filtering with the CPF statistics is demonstrated using (1) a residential building dataset to select predictors for the actual sales prices and (2) the TCGA dataset to select genes that are correlated with disease staging in lung cancer patients. ",
    "url": "https://arxiv.org/abs/2310.04919",
    "authors": [
      "Yushu Shi",
      "Michael Martens"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.05078",
    "title": "Partial Rank Similarity Minimization Method for Quality MOS Prediction  of Unseen Speech Synthesis Systems in Zero-Shot and Semi-supervised setting",
    "abstract": "This paper introduces a novel objective function for quality mean opinion score (MOS) prediction of unseen speech synthesis systems. The proposed function measures the similarity of relative positions of predicted MOS values, in a mini-batch, rather than the actual MOS values. That is the partial rank similarity is measured (PRS) rather than the individual MOS values as with the L1 loss. Our experiments on out-of-domain speech synthesis systems demonstrate that the PRS outperforms L1 loss in zero-shot and semi-supervised settings, exhibiting stronger correlation with ground truth. These findings highlight the importance of considering rank order, as done by PRS, when training MOS prediction models. We also argue that mean squared error and linear correlation coefficient metrics may be unreliable for evaluating MOS prediction models. In conclusion, PRS-trained models provide a robust framework for evaluating speech quality and offer insights for developing high-quality speech synthesis systems. Code and models are available at github.com/nii-yamagishilab/partial_rank_similarity/ ",
    "url": "https://arxiv.org/abs/2310.05078",
    "authors": [
      "Hemant Yadav",
      "Erica Cooper",
      "Junichi Yamagishi",
      "Sunayana Sitaram",
      "Rajiv Ratn Shah"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2310.05446",
    "title": "RetSeg: Retention-based Colorectal Polyps Segmentation Network",
    "abstract": "Vision Transformers (ViTs) have revolutionized medical imaging analysis, showcasing superior efficacy compared to conventional Convolutional Neural Networks (CNNs) in vital tasks such as polyp classification, detection, and segmentation. Leveraging attention mechanisms to focus on specific image regions, ViTs exhibit contextual awareness in processing visual data, culminating in robust and precise predictions, even for intricate medical images. Moreover, the inherent self-attention mechanism in Transformers accommodates varying input sizes and resolutions, granting an unprecedented flexibility absent in traditional CNNs. However, Transformers grapple with challenges like excessive memory usage and limited training parallelism due to self-attention, rendering them impractical for real-time disease detection on resource-constrained devices. In this study, we address these hurdles by investigating the integration of the recently introduced retention mechanism into polyp segmentation, introducing RetSeg, an encoder-decoder network featuring multi-head retention blocks. Drawing inspiration from Retentive Networks (RetNet), RetSeg is designed to bridge the gap between precise polyp segmentation and resource utilization, particularly tailored for colonoscopy images. We train and validate RetSeg for polyp segmentation employing two publicly available datasets: Kvasir-SEG and CVC-ClinicDB. Additionally, we showcase RetSeg's promising performance across diverse public datasets, including CVC-ColonDB, ETIS-LaribPolypDB, CVC-300, and BKAI-IGH NeoPolyp. While our work represents an early-stage exploration, further in-depth studies are imperative to advance these promising findings. ",
    "url": "https://arxiv.org/abs/2310.05446",
    "authors": [
      "Khaled ELKarazle",
      "Valliappan Raman",
      "Caslon Chua",
      "Patrick Then"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05526",
    "title": "Projecting infinite time series graphs to finite marginal graphs using  number theory",
    "abstract": "In recent years, a growing number of method and application works have adapted and applied the causal-graphical-model framework to time series data. Many of these works employ time-resolved causal graphs that extend infinitely into the past and future and whose edges are repetitive in time, thereby reflecting the assumption of stationary causal relationships. However, most results and algorithms from the causal-graphical-model framework are not designed for infinite graphs. In this work, we develop a method for projecting infinite time series graphs with repetitive edges to marginal graphical models on a finite time window. These finite marginal graphs provide the answers to $m$-separation queries with respect to the infinite graph, a task that was previously unresolved. Moreover, we argue that these marginal graphs are useful for causal discovery and causal effect estimation in time series, effectively enabling to apply results developed for finite graphs to the infinite graphs. The projection procedure relies on finding common ancestors in the to-be-projected graph and is, by itself, not new. However, the projection procedure has not yet been algorithmically implemented for time series graphs since in these infinite graphs there can be infinite sets of paths that might give rise to common ancestors. We solve the search over these possibly infinite sets of paths by an intriguing combination of path-finding techniques for finite directed graphs and solution theory for linear Diophantine equations. By providing an algorithm that carries out the projection, our paper makes an important step towards a theoretically-grounded and method-agnostic generalization of a range of causal inference methods and results to time series. ",
    "url": "https://arxiv.org/abs/2310.05526",
    "authors": [
      "Andreas Gerhardus",
      "Jonas Wahl",
      "Sofia Faltenbacher",
      "Urmi Ninad",
      "Jakob Runge"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.05534",
    "title": "Thech. Report: Genuinization of Speech waveform PMF for speaker  detection spoofing and countermeasures",
    "abstract": "In the context of spoofing attacks in speaker recognition systems, we observed that the waveform probability mass function (PMF) of genuine speech differs significantly from the PMF of speech resulting from the attacks. This is true for synthesized or converted speech as well as replayed speech. We also noticed that this observation seems to have a significant impact on spoofing detection performance. In this article, we propose an algorithm, denoted genuinization, capable of reducing the waveform distribution gap between authentic speech and spoofing speech. Our genuinization algorithm is evaluated on ASVspoof 2019 challenge datasets, using the baseline system provided by the challenge organization. We first assess the influence of genuinization on spoofing performance. Using genuinization for the spoofing attacks degrades spoofing detection performance by up to a factor of 10. Next, we integrate the genuinization algorithm in the spoofing countermeasures and we observe a huge spoofing detection improvement in different cases. The results of our experiments show clearly that waveform distribution plays an important role and must be taken into account by anti-spoofing systems. ",
    "url": "https://arxiv.org/abs/2310.05534",
    "authors": [
      "Itshak Lapidot",
      "Jean-Francois Bonastre"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2310.05538",
    "title": "M3FPolypSegNet: Segmentation Network with Multi-frequency Feature Fusion  for Polyp Localization in Colonoscopy Images",
    "abstract": "Polyp segmentation is crucial for preventing colorectal cancer a common type of cancer. Deep learning has been used to segment polyps automatically, which reduces the risk of misdiagnosis. Localizing small polyps in colonoscopy images is challenging because of its complex characteristics, such as color, occlusion, and various shapes of polyps. To address this challenge, a novel frequency-based fully convolutional neural network, Multi-Frequency Feature Fusion Polyp Segmentation Network (M3FPolypSegNet) was proposed to decompose the input image into low/high/full-frequency components to use the characteristics of each component. We used three independent multi-frequency encoders to map multiple input images into a high-dimensional feature space. In the Frequency-ASPP Scalable Attention Module (F-ASPP SAM), ASPP was applied between each frequency component to preserve scale information. Subsequently, scalable attention was applied to emphasize polyp regions in a high-dimensional feature space. Finally, we designed three multi-task learning (i.e., region, edge, and distance) in four decoder blocks to learn the structural characteristics of the region. The proposed model outperformed various segmentation models with performance gains of 6.92% and 7.52% on average for all metrics on CVC-ClinicDB and BKAI-IGH-NeoPolyp, respectively. ",
    "url": "https://arxiv.org/abs/2310.05538",
    "authors": [
      "Ju-Hyeon Nam",
      "Seo-Hyeong Park",
      "Nur Suriza Syazwany",
      "Yerim Jung",
      "Yu-Han Im",
      "Sang-Chul Lee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05572",
    "title": "A Simple and Robust Framework for Cross-Modality Medical Image  Segmentation applied to Vision Transformers",
    "abstract": "When it comes to clinical images, automatic segmentation has a wide variety of applications and a considerable diversity of input domains, such as different types of Magnetic Resonance Images (MRIs) and Computerized Tomography (CT) scans. This heterogeneity is a challenge for cross-modality algorithms that should equally perform independently of the input image type fed to them. Often, segmentation models are trained using a single modality, preventing generalization to other types of input data without resorting to transfer learning techniques. Furthermore, the multi-modal or cross-modality architectures proposed in the literature frequently require registered images, which are not easy to collect in clinical environments, or need additional processing steps, such as synthetic image generation. In this work, we propose a simple framework to achieve fair image segmentation of multiple modalities using a single conditional model that adapts its normalization layers based on the input type, trained with non-registered interleaved mixed data. We show that our framework outperforms other cross-modality segmentation methods, when applied to the same 3D UNet baseline model, on the Multi-Modality Whole Heart Segmentation Challenge. Furthermore, we define the Conditional Vision Transformer (C-ViT) encoder, based on the proposed cross-modality framework, and we show that it brings significant improvements to the resulting segmentation, up to 6.87\\% of Dice accuracy, with respect to its baseline reference. The code to reproduce our experiments and the trained model weights are available at https://github.com/matteo-bastico/MI-Seg. ",
    "url": "https://arxiv.org/abs/2310.05572",
    "authors": [
      "Matteo Bastico",
      "David Ryckelynck",
      "Laurent Cort\u00e9",
      "Yannick Tillier",
      "Etienne Decenci\u00e8re"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05655",
    "title": "Causal structure learning with momentum: Sampling distributions over  Markov Equivalence Classes of DAGs",
    "abstract": "In the context of inferring a Bayesian network structure (directed acyclic graph, DAG for short), we devise a non-reversible continuous time Markov chain, the \"Causal Zig-Zag sampler\", that targets a probability distribution over classes of observationally equivalent (Markov equivalent) DAGs. The classes are represented as completed partially directed acyclic graphs (CPDAGs). The non-reversible Markov chain relies on the operators used in Chickering's Greedy Equivalence Search (GES) and is endowed with a momentum variable, which improves mixing significantly as we show empirically. The possible target distributions include posterior distributions based on a prior over DAGs and a Markov equivalent likelihood. We offer an efficient implementation wherein we develop new algorithms for listing, counting, uniformly sampling, and applying possible moves of the GES operators, all of which significantly improve upon the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2310.05655",
    "authors": [
      "Moritz Schauer",
      "Marcel Wien\u00f6bst"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05742",
    "title": "Estimating Shape Distances on Neural Representations with Limited  Samples",
    "abstract": "Measuring geometric similarity between high-dimensional network representations is a topic of longstanding interest to neuroscience and deep learning. Although many methods have been proposed, only a few works have rigorously analyzed their statistical efficiency or quantified estimator uncertainty in data-limited regimes. Here, we derive upper and lower bounds on the worst-case convergence of standard estimators of shape distance$\\unicode{x2014}$a measure of representational dissimilarity proposed by Williams et al. (2021). These bounds reveal the challenging nature of the problem in high-dimensional feature spaces. To overcome these challenges, we introduce a new method-of-moments estimator with a tunable bias-variance tradeoff. We show that this estimator achieves superior performance to standard estimators in simulation and on neural data, particularly in high-dimensional settings. Thus, we lay the foundation for a rigorous statistical theory for high-dimensional shape analysis, and we contribute a new estimation method that is well-suited to practical scientific settings. ",
    "url": "https://arxiv.org/abs/2310.05742",
    "authors": [
      "Dean A. Pospisil",
      "Brett W. Larsen",
      "Sarah E. Harvey",
      "Alex H. Williams"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2310.05892",
    "title": "A Generalization Bound of Deep Neural Networks for Dependent Data",
    "abstract": "Existing generalization bounds for deep neural networks require data to be independent and identically distributed (iid). This assumption may not hold in real-life applications such as evolutionary biology, infectious disease epidemiology, and stock price prediction. This work establishes a generalization bound of feed-forward neural networks for non-stationary $\\phi$-mixing data. ",
    "url": "https://arxiv.org/abs/2310.05892",
    "authors": [
      "Quan Huu Do",
      "Binh T. Nguyen",
      "Lam Si Tung Ho"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05900",
    "title": "Learning to Decode the Surface Code with a Recurrent, Transformer-Based  Neural Network",
    "abstract": "Quantum error-correction is a prerequisite for reliable quantum computation. Towards this goal, we present a recurrent, transformer-based neural network which learns to decode the surface code, the leading quantum error-correction code. Our decoder outperforms state-of-the-art algorithmic decoders on real-world data from Google's Sycamore quantum processor for distance 3 and 5 surface codes. On distances up to 11, the decoder maintains its advantage on simulated data with realistic noise including cross-talk, leakage, and analog readout signals, and sustains its accuracy far beyond the 25 cycles it was trained on. Our work illustrates the ability of machine learning to go beyond human-designed algorithms by learning from data directly, highlighting machine learning as a strong contender for decoding in quantum computers. ",
    "url": "https://arxiv.org/abs/2310.05900",
    "authors": [
      "Johannes Bausch",
      "Andrew W Senior",
      "Francisco J H Heras",
      "Thomas Edlich",
      "Alex Davies",
      "Michael Newman",
      "Cody Jones",
      "Kevin Satzinger",
      "Murphy Yuezhen Niu",
      "Sam Blackwell",
      "George Holland",
      "Dvir Kafri",
      "Juan Atalaya",
      "Craig Gidney",
      "Demis Hassabis",
      "Sergio Boixo",
      "Hartmut Neven",
      "Pushmeet Kohli"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2002.03729",
    "title": "A lightweight target detection algorithm based on Mobilenet Convolution",
    "abstract": " Title: A lightweight target detection algorithm based on Mobilenet Convolution ",
    "url": "https://arxiv.org/abs/2002.03729",
    "authors": [
      "Shengquan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2006.09565",
    "title": "Mining Label Distribution Drift in Unsupervised Domain Adaptation",
    "abstract": " Comments: Accepted to AJCAI'23 ",
    "url": "https://arxiv.org/abs/2006.09565",
    "authors": [
      "Peizhao Li",
      "Zhengming Ding",
      "Hongfu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.02605",
    "title": "GraphFormers: GNN-nested Transformers for Representation Learning on  Textual Graph",
    "abstract": " Comments: Accepted to NeurIPS 2021 ",
    "url": "https://arxiv.org/abs/2105.02605",
    "authors": [
      "Junhan Yang",
      "Zheng Liu",
      "Shitao Xiao",
      "Chaozhuo Li",
      "Defu Lian",
      "Sanjay Agrawal",
      "Amit Singh",
      "Guangzhong Sun",
      "Xing Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2106.01810",
    "title": "Defending Against Backdoor Attacks in Natural Language Generation",
    "abstract": " Comments: To appear at AAAI 2023 ",
    "url": "https://arxiv.org/abs/2106.01810",
    "authors": [
      "Xiaofei Sun",
      "Xiaoya Li",
      "Yuxian Meng",
      "Xiang Ao",
      "Lingjuan Lyu",
      "Jiwei Li",
      "Tianwei Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2109.04684",
    "title": "Enhancing Unsupervised Anomaly Detection with Score-Guided Network",
    "abstract": " Comments: Final version in TNNLS ",
    "url": "https://arxiv.org/abs/2109.04684",
    "authors": [
      "Zongyuan Huang",
      "Baohua Zhang",
      "Guoqiang Hu",
      "Longyuan Li",
      "Yanyan Xu",
      "Yaohui Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.04149",
    "title": "Parasocial diffusion: K-pop fandoms help drive COVID-19 public health  messaging on social media",
    "abstract": " Comments: 10 pages ",
    "url": "https://arxiv.org/abs/2110.04149",
    "authors": [
      "Ho-Chun Herbert Chang",
      "Becky Pham",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2201.00288",
    "title": "Community Search: A Meta-Learning Approach",
    "abstract": " Comments: 14 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2201.00288",
    "authors": [
      "Shuheng Fang",
      "Kangfei Zhao",
      "Guanghua Li",
      "Jeffery Xu Yu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2205.01306",
    "title": "CANShield: Deep Learning-Based Intrusion Detection Framework for  Controller Area Networks at the Signal-Level",
    "abstract": " Comments: 17 pages, 13 figures, A version of this paper is accepted by IEEE Internet of Things Journal ",
    "url": "https://arxiv.org/abs/2205.01306",
    "authors": [
      "Md Hasan Shahriar",
      "Yang Xiao",
      "Pablo Moriano",
      "Wenjing Lou",
      "Y. Thomas Hou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.05628",
    "title": "Extensible Machine Learning for Encrypted Network Traffic Application  Labeling via Uncertainty Quantification",
    "abstract": " Comments: Paper is 15 pages and has 10 figures. Published in IEEE Transactions on Artificial Intelligence (this https URL). For associated dataset, see this https URL ",
    "url": "https://arxiv.org/abs/2205.05628",
    "authors": [
      "Steven Jorgensen",
      "John Holodnak",
      "Jensen Dempsey",
      "Karla de Souza",
      "Ananditha Raghunath",
      "Vernon Rivet",
      "Noah DeMoes",
      "Andr\u00e9s Alejos",
      "Allan Wollaber"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.08821",
    "title": "Lessons Learned: Defending Against Property Inference Attacks",
    "abstract": " Title: Lessons Learned: Defending Against Property Inference Attacks ",
    "url": "https://arxiv.org/abs/2205.08821",
    "authors": [
      "Joshua Stock",
      "Jens Wettlaufer",
      "Daniel Demmler",
      "Hannes Federrath"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11716",
    "title": "Randomly Initialized One-Layer Neural Networks Make Data Linearly  Separable",
    "abstract": " Title: Randomly Initialized One-Layer Neural Networks Make Data Linearly  Separable ",
    "url": "https://arxiv.org/abs/2205.11716",
    "authors": [
      "Promit Ghosal",
      "Srinath Mahankali",
      "Yihang Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.00383",
    "title": "Neural Improvement Heuristics for Graph Combinatorial Optimization  Problems",
    "abstract": " Title: Neural Improvement Heuristics for Graph Combinatorial Optimization  Problems ",
    "url": "https://arxiv.org/abs/2206.00383",
    "authors": [
      "Andoni I. Garmendia",
      "Josu Ceberio",
      "Alexander Mendiburu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.04890",
    "title": "Adversarial Counterfactual Environment Model Learning",
    "abstract": " Title: Adversarial Counterfactual Environment Model Learning ",
    "url": "https://arxiv.org/abs/2206.04890",
    "authors": [
      "Xiong-Hui Chen",
      "Yang Yu",
      "Zheng-Mao Zhu",
      "Zhihua Yu",
      "Zhenjun Chen",
      "Chenghe Wang",
      "Yinan Wu",
      "Hongqiu Wu",
      "Rong-Jun Qin",
      "Ruijin Ding",
      "Fangsheng Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.05225",
    "title": "Susceptibility of Continual Learning Against Adversarial Attacks",
    "abstract": " Comments: 18 pages, 13 figures ",
    "url": "https://arxiv.org/abs/2207.05225",
    "authors": [
      "Hikmat Khan",
      "Pir Masoom Shah",
      "Syed Farhan Alam Zaidi",
      "Saif ul Islam",
      "Qasim Zia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.01239",
    "title": "Complex matrix inversion via real matrix inversions",
    "abstract": " Comments: 29 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2208.01239",
    "authors": [
      "Zhen Dai",
      "Lek-Heng Lim",
      "Ke Ye"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2208.03835",
    "title": "On Transfer of Adversarial Robustness from Pretraining to Downstream  Tasks",
    "abstract": " Title: On Transfer of Adversarial Robustness from Pretraining to Downstream  Tasks ",
    "url": "https://arxiv.org/abs/2208.03835",
    "authors": [
      "Laura Fee Nern",
      "Harsh Raj",
      "Maurice Georgi",
      "Yash Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2208.04173",
    "title": "SIAD: Self-supervised Image Anomaly Detection System",
    "abstract": " Comments: 4 pages, 3 figures, ICCV 2023 Demo Track ",
    "url": "https://arxiv.org/abs/2208.04173",
    "authors": [
      "Jiawei Li",
      "Chenxi Lan",
      "Xinyi Zhang",
      "Bolin Jiang",
      "Yuqiu Xie",
      "Naiqi Li",
      "Yan Liu",
      "Yaowei Li",
      "Enze Huo",
      "Bin Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.04441",
    "title": "Txt2Img-MHN: Remote Sensing Image Generation from Text Using Modern  Hopfield Networks",
    "abstract": " Title: Txt2Img-MHN: Remote Sensing Image Generation from Text Using Modern  Hopfield Networks ",
    "url": "https://arxiv.org/abs/2208.04441",
    "authors": [
      "Yonghao Xu",
      "Weikang Yu",
      "Pedram Ghamisi",
      "Michael Kopp",
      "Sepp Hochreiter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.09652",
    "title": "Unsupervisedly Prompting AlphaFold2 for Few-Shot Learning of Accurate  Folding Landscape and Protein Structure Prediction",
    "abstract": " Comments: version 2.0; 28 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2208.09652",
    "authors": [
      "Jun Zhang",
      "Sirui Liu",
      "Mengyun Chen",
      "Haotian Chu",
      "Min Wang",
      "Zidong Wang",
      "Jialiang Yu",
      "Ningxi Ni",
      "Fan Yu",
      "Diqing Chen",
      "Yi Isaac Yang",
      "Boxin Xue",
      "Lijiang Yang",
      "Yuan Liu",
      "Yi Qin Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biological Physics (physics.bio-ph)"
    ]
  },
  {
    "id": "arXiv:2210.01306",
    "title": "Robust Qubit Mapping Algorithm via Double-Source Optimal Routing on  Large Quantum Circuits",
    "abstract": " Comments: v3: restructured and more new numerical experiments added ",
    "url": "https://arxiv.org/abs/2210.01306",
    "authors": [
      "Chin-Yi Cheng",
      "Chien-Yi Yang",
      "Yi-Hsiang Kuo",
      "Ren-Chu Wang",
      "Hao-Chung Cheng",
      "Chung-Yang Ric Huang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2210.05248",
    "title": "Self-supervised debiasing using low rank regularization",
    "abstract": " Title: Self-supervised debiasing using low rank regularization ",
    "url": "https://arxiv.org/abs/2210.05248",
    "authors": [
      "Geon Yeong Park",
      "Chanyong Jung",
      "Sangmin Lee",
      "Jong Chul Ye",
      "Sang Wan Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.07302",
    "title": "Deep Reinforcement Learning-based Rebalancing Policies for Profit  Maximization of Relay Nodes in Payment Channel Networks",
    "abstract": " Comments: Best Paper Award at the 4th International Conference on Mathematical Research for the Blockchain Economy (MARBLE 2023). 28 pages; minor language edits and fixes; acknowledgments added; results unchanged ",
    "url": "https://arxiv.org/abs/2210.07302",
    "authors": [
      "Nikolaos Papadis",
      "Leandros Tassiulas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2211.16044",
    "title": "Model Extraction Attack against Self-supervised Speech Models",
    "abstract": " Title: Model Extraction Attack against Self-supervised Speech Models ",
    "url": "https://arxiv.org/abs/2211.16044",
    "authors": [
      "Tsu-Yuan Hsu",
      "Chen-An Li",
      "Tung-Yu Wu",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2212.00190",
    "title": "Mixed Neural Voxels for Fast Multi-view Video Synthesis",
    "abstract": " Comments: ICCV 2023 (Oral) ",
    "url": "https://arxiv.org/abs/2212.00190",
    "authors": [
      "Feng Wang",
      "Sinan Tan",
      "Xinghang Li",
      "Zeyue Tian",
      "Yafei Song",
      "Huaping Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.04064",
    "title": "CRC-Aided High-Rate Convolutional Codes With Short Blocklengths for List  Decoding",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2111.07929 ",
    "url": "https://arxiv.org/abs/2212.04064",
    "authors": [
      "Wenhui Sui",
      "Brendan Towell",
      "Ava Asmani",
      "Hengjie Yang",
      "Holden Grissett",
      "Richard D. Wesel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2212.09289",
    "title": "Mining User Privacy Concern Topics from App Reviews",
    "abstract": " Title: Mining User Privacy Concern Topics from App Reviews ",
    "url": "https://arxiv.org/abs/2212.09289",
    "authors": [
      "Jianzhang Zhang",
      "Jinping Hua",
      "Nan Niu",
      "Yiyang Chen",
      "Chuang Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2212.11642",
    "title": "Predictive Coding Based Multiscale Network with Encoder-Decoder LSTM for  Video Prediction",
    "abstract": " Title: Predictive Coding Based Multiscale Network with Encoder-Decoder LSTM for  Video Prediction ",
    "url": "https://arxiv.org/abs/2212.11642",
    "authors": [
      "Chaofan Ling",
      "Junpei Zhong",
      "Weihua Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.12379",
    "title": "FedRC: Tackling Diverse Distribution Shifts Challenge in Federated  Learning by Robust Clustering",
    "abstract": " Title: FedRC: Tackling Diverse Distribution Shifts Challenge in Federated  Learning by Robust Clustering ",
    "url": "https://arxiv.org/abs/2301.12379",
    "authors": [
      "Yongxin Guo",
      "Xiaoying Tang",
      "Tao Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02055",
    "title": "Implicit Geometry and Interaction Embeddings Improve Few-Shot Molecular  Property Prediction",
    "abstract": " Title: Implicit Geometry and Interaction Embeddings Improve Few-Shot Molecular  Property Prediction ",
    "url": "https://arxiv.org/abs/2302.02055",
    "authors": [
      "Christopher Fifty",
      "Joseph M. Paggi",
      "Ehsan Amid",
      "Jure Leskovec",
      "Ron Dror"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04823",
    "title": "Hierarchical Generative Adversarial Imitation Learning with Mid-level  Input Generation for Autonomous Driving on Urban Environments",
    "abstract": " Title: Hierarchical Generative Adversarial Imitation Learning with Mid-level  Input Generation for Autonomous Driving on Urban Environments ",
    "url": "https://arxiv.org/abs/2302.04823",
    "authors": [
      "Gustavo Claudio Karl Couto",
      "Eric Aislan Antonelo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.13417",
    "title": "Training neural networks with structured noise improves classification  and generalization",
    "abstract": " Comments: 21 pages, 17 figures, main text and appendices ",
    "url": "https://arxiv.org/abs/2302.13417",
    "authors": [
      "Marco Benedetti",
      "Enrico Ventura"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.00180",
    "title": "FaceRNET: a Facial Expression Intensity Estimation Network",
    "abstract": " Title: FaceRNET: a Facial Expression Intensity Estimation Network ",
    "url": "https://arxiv.org/abs/2303.00180",
    "authors": [
      "Dimitrios Kollias",
      "Andreas Psaroudakis",
      "Anastasios Arsenos",
      "Paraskevi Theofilou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.03324",
    "title": "Time series anomaly detection with reconstruction-based state-space  models",
    "abstract": " Title: Time series anomaly detection with reconstruction-based state-space  models ",
    "url": "https://arxiv.org/abs/2303.03324",
    "authors": [
      "Fan Wang",
      "Keli Wang",
      "Boyu Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.09079",
    "title": "SSL-Cleanse: Trojan Detection and Mitigation in Self-Supervised Learning",
    "abstract": " Comments: 9 pages, 6 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2303.09079",
    "authors": [
      "Mengxin Zheng",
      "Jiaqi Xue",
      "Zihao Wang",
      "Xun Chen",
      "Qian Lou",
      "Lei Jiang",
      "Xiaofeng Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09599",
    "title": "cito: An R package for training neural networks using torch",
    "abstract": " Comments: 15 pages, 4 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2303.09599",
    "authors": [
      "Christian Amesoeder",
      "Florian Hartig",
      "Maximilian Pichler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.13709",
    "title": "Isolation of regular graphs, stars and $k$-chromatic graphs",
    "abstract": " Comments: 11 pages, minor corrections have been made, Lemma 10 and Proposition 11 have been added ",
    "url": "https://arxiv.org/abs/2303.13709",
    "authors": [
      "Peter Borg"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2303.15620",
    "title": "Optimizing Lead Time in Fall Detection for a Planar Bipedal Robot",
    "abstract": " Comments: \\c{opyright} 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works ",
    "url": "https://arxiv.org/abs/2303.15620",
    "authors": [
      "M. Eva Mungai",
      "Jessy Grizzle"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.16254",
    "title": "CryoFormer: Continuous Heterogeneous Cryo-EM Reconstruction using  Transformer-based Neural Representations",
    "abstract": " Title: CryoFormer: Continuous Heterogeneous Cryo-EM Reconstruction using  Transformer-based Neural Representations ",
    "url": "https://arxiv.org/abs/2303.16254",
    "authors": [
      "Xinhang Liu",
      "Yan Zeng",
      "Yifan Qin",
      "Hao Li",
      "Jiakai Zhang",
      "Lan Xu",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17207",
    "title": "Exploiting Redundancy for UWB Anomaly Detection in Infrastructure-Free  Multi-Robot Relative Localization",
    "abstract": " Title: Exploiting Redundancy for UWB Anomaly Detection in Infrastructure-Free  Multi-Robot Relative Localization ",
    "url": "https://arxiv.org/abs/2303.17207",
    "authors": [
      "Sahar Salimpour",
      "Paola Torrico Mor\u00f3n",
      "Xianjia Yu",
      "Tomi Westerlund",
      "Jorge Pe\u00f1a Queralta"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.18051",
    "title": "Synergistic Graph Fusion via Encoder Embedding",
    "abstract": " Title: Synergistic Graph Fusion via Encoder Embedding ",
    "url": "https://arxiv.org/abs/2303.18051",
    "authors": [
      "Cencheng Shen",
      "Carey E. Priebe",
      "Jonathan Larson",
      "Ha Trinh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.00652",
    "title": "Meeting effectiveness and inclusiveness: large-scale measurement,  identification of key features, and prediction in real-world remote meetings",
    "abstract": " Title: Meeting effectiveness and inclusiveness: large-scale measurement,  identification of key features, and prediction in real-world remote meetings ",
    "url": "https://arxiv.org/abs/2304.00652",
    "authors": [
      "Yasaman Hosseinkashi",
      "Jamie Pool",
      "Lev Tankelevitch",
      "Ross Cutler",
      "Chinmaya Madan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2304.04819",
    "title": "Recent Advancements in Machine Learning For Cybercrime Prediction",
    "abstract": " Comments: Accepted in Journal of Computer Information Systems, 2023 ",
    "url": "https://arxiv.org/abs/2304.04819",
    "authors": [
      "Lavanya Elluri",
      "Varun Mandalapu",
      "Piyush Vyas",
      "Nirmalya Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.06054",
    "title": "Landslide Susceptibility Prediction Modeling Based on Self-Screening  Deep Learning Model",
    "abstract": " Comments: Some contributing authors are not signed ",
    "url": "https://arxiv.org/abs/2304.06054",
    "authors": [
      "Li Zhu",
      "Lekai Liu",
      "Changshi Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2305.04170",
    "title": "YOLOCS: Object Detection based on Dense Channel Compression for Feature  Spatial Solidification",
    "abstract": " Title: YOLOCS: Object Detection based on Dense Channel Compression for Feature  Spatial Solidification ",
    "url": "https://arxiv.org/abs/2305.04170",
    "authors": [
      "Lin Huang",
      "Weisheng Li",
      "Linlin Shen",
      "Haojie Fu",
      "Xue Xiao",
      "Suihan Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.05004",
    "title": "How WEIRD is Usable Privacy and Security Research? (Extended Version)",
    "abstract": " Comments: This paper is the extended version of the paper presented at USENIX SECURITY 2024 ",
    "url": "https://arxiv.org/abs/2305.05004",
    "authors": [
      "Ayako A. Hasegawa",
      "Daisuke Inoue",
      "Mitsuaki Akiyama"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2305.05455",
    "title": "ONCache: A Cache-Based Low-Overhead Container Overlay Network",
    "abstract": " Title: ONCache: A Cache-Based Low-Overhead Container Overlay Network ",
    "url": "https://arxiv.org/abs/2305.05455",
    "authors": [
      "Shengkai Lin",
      "Shizhen Zhao",
      "Peirui Cao",
      "Xinchi Han",
      "Quan Tian",
      "Wenfeng Liu",
      "Qi Wu",
      "Donghai Han",
      "Xinbing Wang",
      "Chenghu Zhou"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Operating Systems (cs.OS)"
    ]
  },
  {
    "id": "arXiv:2305.05640",
    "title": "Representation Learning for Person or Entity-centric Knowledge Graphs:  An Application in Healthcare",
    "abstract": " Comments: Accepted into the Twelfth International Conference on Knowledge Capture (K-CAP 2023) ",
    "url": "https://arxiv.org/abs/2305.05640",
    "authors": [
      "Christos Theodoropoulos",
      "Natasha Mulligan",
      "Thaddeus Stappenbeck",
      "Joao Bettencourt-Silva"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.06176",
    "title": "Fine-tuning Language Models with Generative Adversarial Feedback",
    "abstract": " Comments: 18 pages, 7 figures, 11 tables ",
    "url": "https://arxiv.org/abs/2305.06176",
    "authors": [
      "Zhang Ze Yu",
      "Lau Jia Jaw",
      "Wong Qin Jiang",
      "Zhang Hui",
      "Bryan Kian Hsiang Low"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.06361",
    "title": "Efficient Training of Multi-task Combinarotial Neural Solver with  Multi-armed Bandits",
    "abstract": " Title: Efficient Training of Multi-task Combinarotial Neural Solver with  Multi-armed Bandits ",
    "url": "https://arxiv.org/abs/2305.06361",
    "authors": [
      "Chenguang Wang",
      "Tianshu Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.07208",
    "title": "Making Differential Privacy Work for Census Data Users",
    "abstract": " Comments: 9 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2305.07208",
    "authors": [
      "Cory McCartan",
      "Tyler Simko",
      "Kosuke Imai"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2305.08459",
    "title": "Introduction to dynamical mean-field theory of randomly connected neural  networks with bidirectionally correlated couplings",
    "abstract": " Comments: 27 pages, 5 figures, 44 references, revised version for SciPost Physics Lecture Notes ",
    "url": "https://arxiv.org/abs/2305.08459",
    "authors": [
      "Wenxuan Zou",
      "Haiping Huang"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2305.10613",
    "title": "Temporal Knowledge Graph Forecasting Using In-Context Learning",
    "abstract": " Comments: 14 pages, 4 figures, 10 tables ",
    "url": "https://arxiv.org/abs/2305.10613",
    "authors": [
      "Dong-Ho Lee",
      "Kian Ahrabian",
      "Woojeong Jin",
      "Fred Morstatter",
      "Jay Pujara"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.10906",
    "title": "RobustFair: Adversarial Evaluation through Fairness Confusion Directed  Gradient Search",
    "abstract": " Title: RobustFair: Adversarial Evaluation through Fairness Confusion Directed  Gradient Search ",
    "url": "https://arxiv.org/abs/2305.10906",
    "authors": [
      "Xuran Li",
      "Peng Wu",
      "Kaixiang Dong",
      "Zhen Zhang",
      "Yanting Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2305.12333",
    "title": "GRACE: Loss-Resilient Real-Time Video through Neural Codecs",
    "abstract": " Title: GRACE: Loss-Resilient Real-Time Video through Neural Codecs ",
    "url": "https://arxiv.org/abs/2305.12333",
    "authors": [
      "Yihua Cheng",
      "Ziyi Zhang",
      "Hanchen Li",
      "Anton Arapin",
      "Yue Zhang",
      "Qizheng Zhang",
      "Yuhan Liu",
      "Xu Zhang",
      "Francis Y. Yan",
      "Amrita Mazumdar",
      "Nick Feamster",
      "Junchen Jiang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2305.12530",
    "title": "Towards Robust Family-Infant Audio Analysis Based on Unsupervised  Pretraining of Wav2vec 2.0 on Large-Scale Unlabeled Family Audio",
    "abstract": " Comments: Proceedings of Interspeech 2023 ",
    "url": "https://arxiv.org/abs/2305.12530",
    "authors": [
      "Jialu Li",
      "Mark Hasegawa-Johnson",
      "Nancy L. McElwain"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.14951",
    "title": "DSFFNet: Dual-Side Feature Fusion Network for 3D Pose Transfer",
    "abstract": " Comments: in Chinese language ",
    "url": "https://arxiv.org/abs/2305.14951",
    "authors": [
      "Jue Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15729",
    "title": "Accelerated K-Serial Stable Coalition for Dynamic Capture and Resource  Defense",
    "abstract": " Comments: 8 pages, 10 figures, 1 table ",
    "url": "https://arxiv.org/abs/2305.15729",
    "authors": [
      "Junfeng Chen",
      "Zili Tang",
      "Meng Guo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.16646",
    "title": "Language Models Can Improve Event Prediction by Few-Shot Abductive  Reasoning",
    "abstract": " Comments: NeurIPS 2023 camera-ready ",
    "url": "https://arxiv.org/abs/2305.16646",
    "authors": [
      "Xiaoming Shi",
      "Siqiao Xue",
      "Kangrui Wang",
      "Fan Zhou",
      "James Y. Zhang",
      "Jun Zhou",
      "Chenhao Tan",
      "Hongyuan Mei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16749",
    "title": "Diverse and Expressive Speech Prosody Prediction with Denoising  Diffusion Probabilistic Model",
    "abstract": " Comments: Proceedings of Interspeech 2023 (doi: 10.21437/Interspeech.2023-715), demo site at this https URL ",
    "url": "https://arxiv.org/abs/2305.16749",
    "authors": [
      "Xiang Li",
      "Songxiang Liu",
      "Max W. Y. Lam",
      "Zhiyong Wu",
      "Chao Weng",
      "Helen Meng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.17010",
    "title": "Let the Flows Tell: Solving Graph Combinatorial Optimization Problems  with GFlowNets",
    "abstract": " Comments: Accepted by NeurIPS 2023 as spotlight ",
    "url": "https://arxiv.org/abs/2305.17010",
    "authors": [
      "Dinghuai Zhang",
      "Hanjun Dai",
      "Nikolay Malkin",
      "Aaron Courville",
      "Yoshua Bengio",
      "Ling Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.17866",
    "title": "Sequential Condition Evolved Interaction Knowledge Graph for Traditional  Chinese Medicine Recommendation",
    "abstract": " Title: Sequential Condition Evolved Interaction Knowledge Graph for Traditional  Chinese Medicine Recommendation ",
    "url": "https://arxiv.org/abs/2305.17866",
    "authors": [
      "Jingjin Liu",
      "Hankz Hankui Zhuo",
      "Kebing Jin",
      "Jiamin Yuan",
      "Zhimin Yang",
      "Zhengan Yao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2305.18355",
    "title": "An Efficient Membership Inference Attack for the Diffusion Model by  Proximal Initialization",
    "abstract": " Title: An Efficient Membership Inference Attack for the Diffusion Model by  Proximal Initialization ",
    "url": "https://arxiv.org/abs/2305.18355",
    "authors": [
      "Fei Kong",
      "Jinhao Duan",
      "RuiPeng Ma",
      "Hengtao Shen",
      "Xiaofeng Zhu",
      "Xiaoshuang Shi",
      "Kaidi Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.18414",
    "title": "StEik: Stabilizing the Optimization of Neural Signed Distance Functions  and Finer Shape Representation",
    "abstract": " Title: StEik: Stabilizing the Optimization of Neural Signed Distance Functions  and Finer Shape Representation ",
    "url": "https://arxiv.org/abs/2305.18414",
    "authors": [
      "Huizong Yang",
      "Yuxin Sun",
      "Ganesh Sundaramoorthi",
      "Anthony Yezzi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2305.18460",
    "title": "Minimum Width of Leaky-ReLU Neural Networks for Uniform Universal  Approximation",
    "abstract": " Comments: Fixed known mistakes ",
    "url": "https://arxiv.org/abs/2305.18460",
    "authors": [
      "Li'ang Li",
      "Yifei Duan",
      "Guanghua Ji",
      "Yongqiang Cai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2305.18507",
    "title": "Code Prompting: a Neural Symbolic Method for Complex Reasoning in Large  Language Models",
    "abstract": " Title: Code Prompting: a Neural Symbolic Method for Complex Reasoning in Large  Language Models ",
    "url": "https://arxiv.org/abs/2305.18507",
    "authors": [
      "Yi Hu",
      "Haotong Yang",
      "Zhouchen Lin",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.18543",
    "title": "Robust Lipschitz Bandits to Adversarial Corruptions",
    "abstract": " Comments: Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS 2023) ",
    "url": "https://arxiv.org/abs/2305.18543",
    "authors": [
      "Yue Kang",
      "Cho-Jui Hsieh",
      "Thomas C. M. Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.18907",
    "title": "Multitask learning for recognizing stress and depression in social media",
    "abstract": " Comments: Online Social Networks and Media ",
    "url": "https://arxiv.org/abs/2305.18907",
    "authors": [
      "Loukas Ilias",
      "Dimitris Askounis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.18980",
    "title": "Multi-modal Queried Object Detection in the Wild",
    "abstract": " Title: Multi-modal Queried Object Detection in the Wild ",
    "url": "https://arxiv.org/abs/2305.18980",
    "authors": [
      "Yifan Xu",
      "Mengdan Zhang",
      "Chaoyou Fu",
      "Peixian Chen",
      "Xiaoshan Yang",
      "Ke Li",
      "Changsheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.00412",
    "title": "Beamforming Design for IRS-and-UAV-aided Two-way Amplify-and-Forward  Relay Maritime Communication Networks",
    "abstract": " Title: Beamforming Design for IRS-and-UAV-aided Two-way Amplify-and-Forward  Relay Maritime Communication Networks ",
    "url": "https://arxiv.org/abs/2306.00412",
    "authors": [
      "Xuehui Wang",
      "Feng Shu",
      "Yuanyuan Wu",
      "Shihao Yan",
      "Yifan Zhao",
      "Qiankun Cheng",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.01323",
    "title": "Demystifying Structural Disparity in Graph Neural Networks: Can One Size  Fit All?",
    "abstract": " Comments: 54 pages, 24 figures ",
    "url": "https://arxiv.org/abs/2306.01323",
    "authors": [
      "Haitao Mao",
      "Zhikai Chen",
      "Wei Jin",
      "Haoyu Han",
      "Yao Ma",
      "Tong Zhao",
      "Neil Shah",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.02029",
    "title": "Model-aided Federated Reinforcement Learning for Multi-UAV Trajectory  Planning in IoT Networks",
    "abstract": " Title: Model-aided Federated Reinforcement Learning for Multi-UAV Trajectory  Planning in IoT Networks ",
    "url": "https://arxiv.org/abs/2306.02029",
    "authors": [
      "Jichao Chen",
      "Omid Esrafilian",
      "Harald Bayerlein",
      "David Gesbert",
      "Marco Caccamo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.02270",
    "title": "Crypto-ransomware Detection through Quantitative API-based Behavioral  Profiling",
    "abstract": " Title: Crypto-ransomware Detection through Quantitative API-based Behavioral  Profiling ",
    "url": "https://arxiv.org/abs/2306.02270",
    "authors": [
      "Wenjia Song",
      "Sanjula Karanam",
      "Ya Xiao",
      "Jingyuan Qi",
      "Nathan Dautenhahn",
      "Na Meng",
      "Elena Ferrari",
      "Danfeng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.03389",
    "title": "Phase perturbation improves channel robustness for speech spoofing  countermeasures",
    "abstract": " Comments: 5 pages; Proceedings of Interspeech 2023 ",
    "url": "https://arxiv.org/abs/2306.03389",
    "authors": [
      "Yongyi Zang",
      "You Zhang",
      "Zhiyao Duan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.05036",
    "title": "Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT  and GPT-4 for Mining Insights at Scale",
    "abstract": " Comments: 22 pages, 3 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2306.05036",
    "authors": [
      "Jonas Oppenlaender",
      "Joonas H\u00e4m\u00e4l\u00e4inen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.05718",
    "title": "Learning Domain-Aware Detection Head with Prompt Tuning",
    "abstract": " Comments: Accepted by NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.05718",
    "authors": [
      "Haochen Li",
      "Rui Zhang",
      "Hantao Yao",
      "Xinkai Song",
      "Yifan Hao",
      "Yongwei Zhao",
      "Ling Li",
      "Yunji Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.07521",
    "title": "Evaluating Bias and Noise Induced by the U.S. Census Bureau's Privacy  Protection Methods",
    "abstract": " Comments: 23 pages, 6 figures, 2 tables, plus appendices ",
    "url": "https://arxiv.org/abs/2306.07521",
    "authors": [
      "Christopher T. Kenny",
      "Shiro Kuriwaki",
      "Cory McCartan",
      "Tyler Simko",
      "Kosuke Imai"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2306.08193",
    "title": "Operationalising Representation in Natural Language Processing",
    "abstract": " Comments: Forthcoming in the British Journal for the Philosophy of Science (BJPS) ",
    "url": "https://arxiv.org/abs/2306.08193",
    "authors": [
      "Jacqueline Harding"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.11260",
    "title": "A Novel Counterfactual Data Augmentation Method for Aspect-Based  Sentiment Analysis",
    "abstract": " Comments: Camera-ready for ACML 2023 ",
    "url": "https://arxiv.org/abs/2306.11260",
    "authors": [
      "Dongming Wu",
      "Lulu Wen",
      "Chao Chen",
      "Zhaoshu Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.11974",
    "title": "Universal adversarial perturbations for multiple classification tasks  with quantum classifiers",
    "abstract": " Title: Universal adversarial perturbations for multiple classification tasks  with quantum classifiers ",
    "url": "https://arxiv.org/abs/2306.11974",
    "authors": [
      "Yun-Zhong Qiu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.14939",
    "title": "The Art of Embedding Fusion: Optimizing Hate Speech Detection",
    "abstract": " Comments: Published as a Tiny Paper at ICLR 2023, 12 Pages ",
    "url": "https://arxiv.org/abs/2306.14939",
    "authors": [
      "Mohammad Aflah Khan",
      "Neemesh Yadav",
      "Mohit Jain",
      "Sanyam Goyal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.16361",
    "title": "Beyond NTK with Vanilla Gradient Descent: A Mean-Field Analysis of  Neural Networks with Polynomial Width, Samples, and Time",
    "abstract": " Comments: Added result on projected gradient descent with inverse-polynomial learning rate ",
    "url": "https://arxiv.org/abs/2306.16361",
    "authors": [
      "Arvind Mahankali",
      "Jeff Z. Haochen",
      "Kefan Dong",
      "Margalit Glasgow",
      "Tengyu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.17175",
    "title": "RECAP-KG: Mining Knowledge Graphs from Raw GP Notes for Remote COVID-19  Assessment in Primary Care",
    "abstract": " Title: RECAP-KG: Mining Knowledge Graphs from Raw GP Notes for Remote COVID-19  Assessment in Primary Care ",
    "url": "https://arxiv.org/abs/2306.17175",
    "authors": [
      "Rakhilya Lee Mekhtieva",
      "Brandon Forbes",
      "Dalal Alrajeh",
      "Brendan Delaney",
      "Alessandra Russo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.08671",
    "title": "Deep Cross-Modal Steganography Using Neural Representations",
    "abstract": " Comments: ICIP 2023 Oral ",
    "url": "https://arxiv.org/abs/2307.08671",
    "authors": [
      "Gyojin Han",
      "Dong-Jae Lee",
      "Jiwan Hur",
      "Jaehyun Choi",
      "Junmo Kim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.09052",
    "title": "Connections between Operator-splitting Methods and Deep Neural Networks  with Applications in Image Segmentation",
    "abstract": " Title: Connections between Operator-splitting Methods and Deep Neural Networks  with Applications in Image Segmentation ",
    "url": "https://arxiv.org/abs/2307.09052",
    "authors": [
      "Hao Liu",
      "Xue-Cheng Tai",
      "Raymond Chan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.02580",
    "title": "Gaussian-based Probabilistic Deep Supervision Network for  Noise-Resistant QoS Prediction",
    "abstract": " Title: Gaussian-based Probabilistic Deep Supervision Network for  Noise-Resistant QoS Prediction ",
    "url": "https://arxiv.org/abs/2308.02580",
    "authors": [
      "Ziliang Wang",
      "Xiaohong Zhang",
      "Sheng Huang",
      "Wei Zhang",
      "Dan Yang",
      "Meng Yan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.03272",
    "title": "Feature-Suppressed Contrast for Self-Supervised Food Pre-training",
    "abstract": " Comments: Accepted by ACM MM 2023 ",
    "url": "https://arxiv.org/abs/2308.03272",
    "authors": [
      "Xinda Liu",
      "Yaohui Zhu",
      "Linhu Liu",
      "Jiang Tian",
      "Lili Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.04464",
    "title": "Analysis of Insect-Plant Interactions Affected by Mining Operations, A  Graph Mining Approach",
    "abstract": " Comments: 9 pages, 16 figures ",
    "url": "https://arxiv.org/abs/2308.04464",
    "authors": [
      "Ali Bayat",
      "Mohammad Heydari",
      "Amir Albadvi"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.06838",
    "title": "Generalizing Topological Graph Neural Networks with Paths",
    "abstract": " Title: Generalizing Topological Graph Neural Networks with Paths ",
    "url": "https://arxiv.org/abs/2308.06838",
    "authors": [
      "Quang Truong",
      "Peter Chin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07200",
    "title": "Neural Categorical Priors for Physics-Based Character Control",
    "abstract": " Comments: Accepted to Transactions on Graphics (Proc. ACM SIGGRAPH ASIA 2023) ",
    "url": "https://arxiv.org/abs/2308.07200",
    "authors": [
      "Qingxu Zhu",
      "He Zhang",
      "Mengting Lan",
      "Lei Han"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07688",
    "title": "Enhancing Network Initialization for Medical AI Models Using  Large-Scale, Unlabeled Natural Images",
    "abstract": " Title: Enhancing Network Initialization for Medical AI Models Using  Large-Scale, Unlabeled Natural Images ",
    "url": "https://arxiv.org/abs/2308.07688",
    "authors": [
      "Soroosh Tayebi Arasteh",
      "Leo Misera",
      "Jakob Nikolas Kather",
      "Daniel Truhn",
      "Sven Nebelung"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.07761",
    "title": "NeFL: Nested Federated Learning for Heterogeneous Clients",
    "abstract": " Title: NeFL: Nested Federated Learning for Heterogeneous Clients ",
    "url": "https://arxiv.org/abs/2308.07761",
    "authors": [
      "Honggu Kang",
      "Seohyeon Cha",
      "Jinwoo Shin",
      "Jongmyeong Lee",
      "Joonhyuk Kang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.08653",
    "title": "Reproducing Kernel Hilbert Space Pruning for Sparse Hyperspectral  Abundance Prediction",
    "abstract": " Title: Reproducing Kernel Hilbert Space Pruning for Sparse Hyperspectral  Abundance Prediction ",
    "url": "https://arxiv.org/abs/2308.08653",
    "authors": [
      "Michael G. Rawson",
      "Timothy Doster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2308.10425",
    "title": "STAEformer: Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer  SOTA for Traffic Forecasting",
    "abstract": " Comments: Accepted as CIKM2023 Short Paper ",
    "url": "https://arxiv.org/abs/2308.10425",
    "authors": [
      "Hangchen Liu",
      "Zheng Dong",
      "Renhe Jiang",
      "Jiewen Deng",
      "Jinliang Deng",
      "Quanjun Chen",
      "Xuan Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.12113",
    "title": "Advancements in Point Cloud Data Augmentation for Deep Learning: A  Survey",
    "abstract": " Title: Advancements in Point Cloud Data Augmentation for Deep Learning: A  Survey ",
    "url": "https://arxiv.org/abs/2308.12113",
    "authors": [
      "Qinfeng Zhu",
      "Lei Fan",
      "Ningxin Weng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.02459",
    "title": "Text-Only Domain Adaptation for End-to-End Speech Recognition through  Down-Sampling Acoustic Representation",
    "abstract": " Comments: Proceedings of Interspeech. arXiv admin note: text overlap with arXiv:2309.01437 ",
    "url": "https://arxiv.org/abs/2309.02459",
    "authors": [
      "Jiaxu Zhu",
      "Weinan Tong",
      "Yaoxun Xu",
      "Changhe Song",
      "Zhiyong Wu",
      "Zhao You",
      "Dan Su",
      "Dong Yu",
      "Helen Meng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.03249",
    "title": "Graph Theory Applications in Advanced Geospatial Research",
    "abstract": " Title: Graph Theory Applications in Advanced Geospatial Research ",
    "url": "https://arxiv.org/abs/2309.03249",
    "authors": [
      "Surajit Ghosh",
      "Archita Mallick",
      "Anuva Chowdhury",
      "Kounik De Sarkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computers and Society (cs.CY)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2309.04076",
    "title": "Towards Smaller, Faster, and Greener Language Models of Code",
    "abstract": " Title: Towards Smaller, Faster, and Greener Language Models of Code ",
    "url": "https://arxiv.org/abs/2309.04076",
    "authors": [
      "Jieke Shi",
      "Zhou Yang",
      "Hong Jin Kang",
      "Bowen Xu",
      "Junda He",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2309.04106",
    "title": "Meta predictive learning model of languages in neural circuits",
    "abstract": " Comments: 31 pages, 6 figures, codes are available in the main text with the link ",
    "url": "https://arxiv.org/abs/2309.04106",
    "authors": [
      "Chan Li",
      "Junbin Qiu",
      "Haiping Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2309.05257",
    "title": "FusionFormer: A Multi-sensory Fusion in Bird's-Eye-View and Temporal  Consistent Transformer for 3D Object Detection",
    "abstract": " Title: FusionFormer: A Multi-sensory Fusion in Bird's-Eye-View and Temporal  Consistent Transformer for 3D Object Detection ",
    "url": "https://arxiv.org/abs/2309.05257",
    "authors": [
      "Chunyong Hu",
      "Hang Zheng",
      "Kun Li",
      "Jianyun Xu",
      "Weibo Mao",
      "Maochun Luo",
      "Lingxuan Wang",
      "Mingxia Chen",
      "Qihao Peng",
      "Kaixuan Liu",
      "Yiru Zhao",
      "Peihan Hao",
      "Minzhe Liu",
      "Kaicheng Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.06223",
    "title": "Unveiling Single-Bit-Flip Attacks on DNN Executables",
    "abstract": " Comments: Fix typo ",
    "url": "https://arxiv.org/abs/2309.06223",
    "authors": [
      "Yanzuo Chen",
      "Zhibo Liu",
      "Yuanyuan Yuan",
      "Sihang Hu",
      "Tianxiang Li",
      "Shuai Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.06382",
    "title": "Ensemble Mask Networks",
    "abstract": " Title: Ensemble Mask Networks ",
    "url": "https://arxiv.org/abs/2309.06382",
    "authors": [
      "Jonny Luntzel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.07405",
    "title": "FunCodec: A Fundamental, Reproducible and Integrable Open-source Toolkit  for Neural Speech Codec",
    "abstract": " Comments: 5 pages, 3 figures, submitted to ICASSP 2024 ",
    "url": "https://arxiv.org/abs/2309.07405",
    "authors": [
      "Zhihao Du",
      "Shiliang Zhang",
      "Kai Hu",
      "Siqi Zheng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.07616",
    "title": "Road Disease Detection based on Latent Domain Background Feature  Separation and Suppression",
    "abstract": " Title: Road Disease Detection based on Latent Domain Background Feature  Separation and Suppression ",
    "url": "https://arxiv.org/abs/2309.07616",
    "authors": [
      "Juwu Zheng",
      "Jiangtao Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.09075",
    "title": "Music Generation based on Generative Adversarial Networks with  Transformer",
    "abstract": " Comments: error upload ",
    "url": "https://arxiv.org/abs/2309.09075",
    "authors": [
      "Ziyi Jiang",
      "Ruoxue Wu",
      "Zhenghan Chen",
      "Xiaoxuan Liang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.09550",
    "title": "Adaptive Reorganization of Neural Pathways for Continual Learning with  Spiking Neural Networks",
    "abstract": " Title: Adaptive Reorganization of Neural Pathways for Continual Learning with  Spiking Neural Networks ",
    "url": "https://arxiv.org/abs/2309.09550",
    "authors": [
      "Bing Han",
      "Feifei Zhao",
      "Wenxuan Pan",
      "Zhaoya Zhao",
      "Xianqi Li",
      "Qingqun Kong",
      "Yi Zeng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.10569",
    "title": "Task Graph offloading via Deep Reinforcement Learning in Mobile Edge  Computing",
    "abstract": " Comments: 13 figures ",
    "url": "https://arxiv.org/abs/2309.10569",
    "authors": [
      "Jiagang Liu",
      "Yun Mi",
      "Xinyu Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.11059",
    "title": "Deep Complex U-Net with Conformer for Audio-Visual Speech Enhancement",
    "abstract": " Title: Deep Complex U-Net with Conformer for Audio-Visual Speech Enhancement ",
    "url": "https://arxiv.org/abs/2309.11059",
    "authors": [
      "Shafique Ahmed",
      "Chia-Wei Chen",
      "Wenze Ren",
      "Chin-Jou Li",
      "Ernie Chu",
      "Jun-Cheng Chen",
      "Amir Hussain",
      "Hsin-Min Wang",
      "Yu Tsao",
      "Jen-Cheng Hou"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2309.13038",
    "title": "Privacy Assessment on Reconstructed Images: Are Existing Evaluation  Metrics Faithful to Human Perception?",
    "abstract": " Comments: 15 pages, 9 figures and 3 tables ",
    "url": "https://arxiv.org/abs/2309.13038",
    "authors": [
      "Xiaoxiao Sun",
      "Nidham Gazagnadou",
      "Vivek Sharma",
      "Lingjuan Lyu",
      "Hongdong Li",
      "Liang Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13546",
    "title": "DFRD: Data-Free Robustness Distillation for Heterogeneous Federated  Learning",
    "abstract": " Comments: Published as a conference paper at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2309.13546",
    "authors": [
      "Kangyang Luo",
      "Shuai Wang",
      "Yexuan Fu",
      "Xiang Li",
      "Yunshi Lan",
      "Ming Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13907",
    "title": "HiGNN-TTS: Hierarchical Prosody Modeling with Graph Neural Networks for  Expressive Long-form TTS",
    "abstract": " Comments: Accepted by ASRU2023 ",
    "url": "https://arxiv.org/abs/2309.13907",
    "authors": [
      "Dake Guo",
      "Xinfa Zhu",
      "Liumeng Xue",
      "Tao Li",
      "Yuanjun Lv",
      "Yuepeng Jiang",
      "Lei Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.14065",
    "title": "AsymFormer: Asymmetrical Cross-Modal Representation Learning for Mobile  Platform Real-Time RGB-D Semantic Segmentation",
    "abstract": " Title: AsymFormer: Asymmetrical Cross-Modal Representation Learning for Mobile  Platform Real-Time RGB-D Semantic Segmentation ",
    "url": "https://arxiv.org/abs/2309.14065",
    "authors": [
      "Siqi Du",
      "Weixi Wang",
      "Renzhong Guo",
      "Shengjun Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.16375",
    "title": "A Comprehensive Review on Tree Detection Methods Using Point Cloud and  Aerial Imagery from Unmanned Aerial Vehicles",
    "abstract": " Comments: This paper has been submitted to Computers and Electronics in Agriculture for review ",
    "url": "https://arxiv.org/abs/2309.16375",
    "authors": [
      "Weijie Kuang",
      "Hann Woei Ho",
      "Ye Zhou",
      "Shahrel Azmin Suandi",
      "Farzad Ismail"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.16742",
    "title": "Supervised Learning Models for Early Detection of Albuminuria Risk in  Type-2 Diabetes Mellitus Patients",
    "abstract": " Comments: Presented in the 10th International Conference on Advanced Informatics: Concepts, Theory and Applications (ICAICTA 2023) ",
    "url": "https://arxiv.org/abs/2309.16742",
    "authors": [
      "Arief Purnama Muharram",
      "Dicky Levenus Tahapary",
      "Yeni Dwi Lestari",
      "Randy Sarayar",
      "Valerie Josephine Dirjayanto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2309.16971",
    "title": "Multi-Resolution Active Learning of Fourier Neural Operators",
    "abstract": " Title: Multi-Resolution Active Learning of Fourier Neural Operators ",
    "url": "https://arxiv.org/abs/2309.16971",
    "authors": [
      "Shibo Li",
      "Xin Yu",
      "Wei Xing",
      "Mike Kirby",
      "Akil Narayan",
      "Shandian Zhe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00068",
    "title": "Emotional Listener Portrait: Neural Listener Head Generation with  Emotion",
    "abstract": " Comments: Accepted by ICCV2023 ",
    "url": "https://arxiv.org/abs/2310.00068",
    "authors": [
      "Luchuan Song",
      "Guojun Yin",
      "Zhenchao Jin",
      "Xiaoyi Dong",
      "Chenliang Xu"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2310.00299",
    "title": "RelBERT: Embedding Relations with Language Models",
    "abstract": " Title: RelBERT: Embedding Relations with Language Models ",
    "url": "https://arxiv.org/abs/2310.00299",
    "authors": [
      "Asahi Ushio",
      "Jose Camacho-Collados",
      "Steven Schockaert"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.00451",
    "title": "On the Role of Neural Collapse in Meta Learning Models for Few-shot  Learning",
    "abstract": " Comments: 9 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2310.00451",
    "authors": [
      "Saaketh Medepalli",
      "Naren Doraiswamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00526",
    "title": "Are Graph Neural Networks Optimal Approximation Algorithms?",
    "abstract": " Comments: Updated figure 1 ",
    "url": "https://arxiv.org/abs/2310.00526",
    "authors": [
      "Morris Yau",
      "Eric Lu",
      "Nikolaos Karalias",
      "Jessica Xu",
      "Stefanie Jegelka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2310.01875",
    "title": "Towards Stable Backdoor Purification through Feature Shift Tuning",
    "abstract": " Comments: NeurIPS 2023 paper. The first two authors contributed equally ",
    "url": "https://arxiv.org/abs/2310.01875",
    "authors": [
      "Rui Min",
      "Zeyu Qin",
      "Li Shen",
      "Minhao Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.02164",
    "title": "A Survey of Graph Unlearning",
    "abstract": " Comments: 22 page review paper on graph unlearning ",
    "url": "https://arxiv.org/abs/2310.02164",
    "authors": [
      "Anwar Said",
      "Tyler Derr",
      "Mudassir Shabbir",
      "Waseem Abbas",
      "Xenofon Koutsoukos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.02229",
    "title": "Extraction of Medication and Temporal Relation from Clinical Text using  Neural Language Models",
    "abstract": " Comments: working paper ",
    "url": "https://arxiv.org/abs/2310.02229",
    "authors": [
      "Hangyu Tu",
      "Lifeng Han",
      "Goran Nenadic"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.02244",
    "title": "Tensor Programs VI: Feature Learning in Infinite-Depth Neural Networks",
    "abstract": " Title: Tensor Programs VI: Feature Learning in Infinite-Depth Neural Networks ",
    "url": "https://arxiv.org/abs/2310.02244",
    "authors": [
      "Greg Yang",
      "Dingli Yu",
      "Chen Zhu",
      "Soufiane Hayou"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2310.02724",
    "title": "End-to-End Training of a Neural HMM with Label and Transition  Probabilities",
    "abstract": " Comments: Accepted for Presentation at ASRU2023 ",
    "url": "https://arxiv.org/abs/2310.02724",
    "authors": [
      "Daniel Mann",
      "Tina Raissi",
      "Wilfried Michel",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.02854",
    "title": "Multi-Domain Causal Representation Learning via Weak Distributional  Invariances",
    "abstract": " Title: Multi-Domain Causal Representation Learning via Weak Distributional  Invariances ",
    "url": "https://arxiv.org/abs/2310.02854",
    "authors": [
      "Kartik Ahuja",
      "Amin Mansouri",
      "Yixin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.03334",
    "title": "Untargeted White-box Adversarial Attack with Heuristic Defence Methods  in Real-time Deep Learning based Network Intrusion Detection System",
    "abstract": " Title: Untargeted White-box Adversarial Attack with Heuristic Defence Methods  in Real-time Deep Learning based Network Intrusion Detection System ",
    "url": "https://arxiv.org/abs/2310.03334",
    "authors": [
      "Khushnaseeb Roshan",
      "Aasim Zafar",
      "Sheikh Burhan Ul Haque"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.03388",
    "title": "OpenPatch: a 3D patchwork for Out-Of-Distribution detection",
    "abstract": " Title: OpenPatch: a 3D patchwork for Out-Of-Distribution detection ",
    "url": "https://arxiv.org/abs/2310.03388",
    "authors": [
      "Paolo Rabino",
      "Antonio Alliegro",
      "Francesco Cappio Borlino",
      "Tatiana Tommasi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.03639",
    "title": "Evaluating Self-Supervised Speech Representations for Indigenous  American Languages",
    "abstract": " Title: Evaluating Self-Supervised Speech Representations for Indigenous  American Languages ",
    "url": "https://arxiv.org/abs/2310.03639",
    "authors": [
      "Chih-Chen Chen",
      "William Chen",
      "Rodolfo Zevallos",
      "John E. Ortega"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.03965",
    "title": "Thought Propagation: An Analogical Approach to Complex Reasoning with  Large Language Models",
    "abstract": " Title: Thought Propagation: An Analogical Approach to Complex Reasoning with  Large Language Models ",
    "url": "https://arxiv.org/abs/2310.03965",
    "authors": [
      "Junchi Yu",
      "Ran He",
      "Rex Ying"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.04047",
    "title": "AUTOPARLLM: GNN-Guided Automatic Code Parallelization using Large  Language Models",
    "abstract": " Comments: 10 pages ",
    "url": "https://arxiv.org/abs/2310.04047",
    "authors": [
      "Quazi Ishtiaque Mahmud",
      "Ali TehraniJamsaz",
      "Hung D Phan",
      "Nesreen K. Ahmed",
      "Ali Jannesari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04080",
    "title": "Robust Average Networks for Monte Carlo Denoising",
    "abstract": " Title: Robust Average Networks for Monte Carlo Denoising ",
    "url": "https://arxiv.org/abs/2310.04080",
    "authors": [
      "Javor Kalojanov",
      "Kimball Thurston"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2310.04171",
    "title": "Dynamic Relation-Attentive Graph Neural Networks for Fraud Detection",
    "abstract": " Comments: 5 pages, 3 figures, 3 tables. Machine Learning on Graphs (MLoG) Workshop at the 23rd IEEE International Conference on Data Mining (ICDM 2023) ",
    "url": "https://arxiv.org/abs/2310.04171",
    "authors": [
      "Heehyeon Kim",
      "Jinhyeok Choi",
      "Joyce Jiyoung Whang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.04367",
    "title": "A Marketplace Price Anomaly Detection System at Scale",
    "abstract": " Comments: 10 pages, 4 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2310.04367",
    "authors": [
      "Akshit Sarpal",
      "Qiwen Kang",
      "Fangping Huang",
      "Yang Song",
      "Lijie Wan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  }
]