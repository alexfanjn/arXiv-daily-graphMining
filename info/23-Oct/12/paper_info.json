[
  {
    "id": "arXiv:2310.06841",
    "title": "Malware Classification using Deep Neural Networks: Performance  Evaluation and Applications in Edge Devices",
    "abstract": "With the increasing extent of malware attacks in the present day along with the difficulty in detecting modern malware, it is necessary to evaluate the effectiveness and performance of Deep Neural Networks (DNNs) for malware classification. Multiple DNN architectures can be designed and trained to detect and classify malware binaries. Results demonstrate the potential of DNNs in accurately classifying malware with high accuracy rates observed across different malware types. Additionally, the feasibility of deploying these DNN models on edge devices to enable real-time classification, particularly in resource-constrained scenarios proves to be integral to large IoT systems. By optimizing model architectures and leveraging edge computing capabilities, the proposed methodologies achieve efficient performance even with limited resources. This study contributes to advancing malware detection techniques and emphasizes the significance of integrating cybersecurity measures for the early detection of malware and further preventing the adverse effects caused by such attacks. Optimal considerations regarding the distribution of security tasks to edge devices are addressed to ensure that the integrity and availability of large scale IoT systems are not compromised due to malware attacks, advocating for a more resilient and secure digital ecosystem. ",
    "url": "https://arxiv.org/abs/2310.06841",
    "authors": [
      "Akhil M R",
      "Adithya Krishna V Sharma",
      "Harivardhan Swamy",
      "Pavan A",
      "Ashray Shetty",
      "Anirudh B Sathyanarayana"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.06845",
    "title": "RobustEdge: Low Power Adversarial Detection for Cloud-Edge Systems",
    "abstract": "In practical cloud-edge scenarios, where a resource constrained edge performs data acquisition and a cloud system (having sufficient resources) performs inference tasks with a deep neural network (DNN), adversarial robustness is critical for reliability and ubiquitous deployment. Adversarial detection is a prime adversarial defence technique used in prior literature. However, in prior detection works, the detector is attached to the classifier model and both detector and classifier work in tandem to perform adversarial detection that requires a high computational overhead which is not available at the low-power edge. Therefore, prior works can only perform adversarial detection at the cloud and not at the edge. This means that in case of adversarial attacks, the unfavourable adversarial samples must be communicated to the cloud which leads to energy wastage at the edge device. Therefore, a low-power edge-friendly adversarial detection method is required to improve the energy efficiency of the edge and robustness of the cloud-based classifier. To this end, RobustEdge proposes Quantization-enabled Energy Separation (QES) training with \"early detection and exit\" to perform edge-based low cost adversarial detection. The QES-trained detector implemented at the edge blocks adversarial data transmission to the classifier model, thereby improving adversarial robustness and energy-efficiency of the Cloud-Edge system. ",
    "url": "https://arxiv.org/abs/2310.06845",
    "authors": [
      "Abhishek Moitra",
      "Abhiroop Bhattacharjee",
      "Youngeun Kim",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.06854",
    "title": "Learning with Noisy Labels for Human Fall Events Classification: Joint  Cooperative Training with Trinity Networks",
    "abstract": "With the increasing ageing population, fall events classification has drawn much research attention. In the development of deep learning, the quality of data labels is crucial. Most of the datasets are labelled automatically or semi-automatically, and the samples may be mislabeled, which constrains the performance of Deep Neural Networks (DNNs). Recent research on noisy label learning confirms that neural networks first focus on the clean and simple instances and then follow the noisy and hard instances in the training stage. To address the learning with noisy label problem and protect the human subjects' privacy, we propose a simple but effective approach named Joint Cooperative training with Trinity Networks (JoCoT). To mitigate the privacy issue, human skeleton data are used. The robustness and performance of the noisy label learning framework is improved by using the two teacher modules and one student module in the proposed JoCoT. To mitigate the incorrect selections, the predictions from the teacher modules are applied with the consensus-based method to guide the student module training. The performance evaluation on the widely used UP-Fall dataset and comparison with the state-of-the-art, confirms the effectiveness of the proposed JoCoT in high noise rates. Precisely, JoCoT outperforms the state-of-the-art by 5.17% and 3.35% with the averaged pairflip and symmetric noises, respectively. ",
    "url": "https://arxiv.org/abs/2310.06854",
    "authors": [
      "Leiyu Xie",
      "Yang Sun",
      "Syed Mohsen Naqvi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.06855",
    "title": "Genetic Algorithm-Based Dynamic Backdoor Attack on Federated  Learning-Based Network Traffic Classification",
    "abstract": "Federated learning enables multiple clients to collaboratively contribute to the learning of a global model orchestrated by a central server. This learning scheme promotes clients' data privacy and requires reduced communication overheads. In an application like network traffic classification, this helps hide the network vulnerabilities and weakness points. However, federated learning is susceptible to backdoor attacks, in which adversaries inject manipulated model updates into the global model. These updates inject a salient functionality in the global model that can be launched with specific input patterns. Nonetheless, the vulnerability of network traffic classification models based on federated learning to these attacks remains unexplored. In this paper, we propose GABAttack, a novel genetic algorithm-based backdoor attack against federated learning for network traffic classification. GABAttack utilizes a genetic algorithm to optimize the values and locations of backdoor trigger patterns, ensuring a better fit with the input and the model. This input-tailored dynamic attack is promising for improved attack evasiveness while being effective. Extensive experiments conducted over real-world network datasets validate the success of the proposed GABAttack in various situations while maintaining almost invisible activity. This research serves as an alarming call for network security experts and practitioners to develop robust defense measures against such attacks. ",
    "url": "https://arxiv.org/abs/2310.06855",
    "authors": [
      "Mahmoud Nazzal",
      "Nura Aljaafari",
      "Ahmed Sawalmeh",
      "Abdallah Khreishah",
      "Muhammad Anan",
      "Abdulelah Algosaibi",
      "Mohammed Alnaeem",
      "Adel Aldalbahi",
      "Abdulaziz Alhumam",
      "Conrado P. Vizcarra",
      "Shadan Alhamed"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.06857",
    "title": "Deep Learning-Based Real-Time Rate Control for Live Streaming on  Wireless Networks",
    "abstract": "Providing wireless users with high-quality video content has become increasingly important. However, ensuring consistent video quality poses challenges due to variable encoded bitrate caused by dynamic video content and fluctuating channel bitrate caused by wireless fading effects. Suboptimal selection of encoder parameters can lead to video quality loss due to underutilized bandwidth or the introduction of video artifacts due to packet loss. To address this, a real-time deep learning based H.264 controller is proposed. This controller leverages instantaneous channel quality data driven from the physical layer, along with the video chunk, to dynamically estimate the optimal encoder parameters with a negligible delay in real-time. The objective is to maintain an encoded video bitrate slightly below the available channel bitrate. Experimental results, conducted on both QCIF dataset and a diverse selection of random videos from public datasets, validate the effectiveness of the approach. Remarkably, improvements of 10-20 dB in PSNR with repect to the state-of-the-art adaptive bitrate video streaming is achieved, with an average packet drop rate as low as 0.002. ",
    "url": "https://arxiv.org/abs/2310.06857",
    "authors": [
      "Matin Mortaheb",
      "Mohammad A. Amir Khojastepour",
      "Srimat T. Chakradhar",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.06858",
    "title": "Design of JiuTian Intelligent Network Simulation Platform",
    "abstract": "This paper introduced the JiuTian Intelligent Network Simulation Platform, which can provide wireless communication simulation data services for the Open Innovation Platform. The platform contains a series of scalable simulator functionalities, offering open services that enable users to use reinforcement learning algorithms for model training and inference based on simulation environments and data. Additionally, it allows users to address optimization tasks in different scenarios by uploading and updating parameter configurations. The platform and its open services were primarily introduced from the perspectives of background, overall architecture, simulator, business scenarios, and future directions. ",
    "url": "https://arxiv.org/abs/2310.06858",
    "authors": [
      "Lei Zhao",
      "Miaomiao Zhang",
      "Guangyu Li",
      "Zhuowen Guan",
      "Sijia Liu",
      "Zhaobin Xiao",
      "Yuting Cao",
      "Zhe Lv",
      "Yanping Liang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.06874",
    "title": "Extended Reality via Cooperative NOMA in Hybrid Cloud/Mobile-Edge  Computing Networks",
    "abstract": "Extended reality (XR) applications often perform resource-intensive tasks, which are computed remotely, a process that prioritizes the latency criticality aspect. To this end, this paper shows that through leveraging the power of the central cloud (CC), the close proximity of edge computers (ECs), and the flexibility of uncrewed aerial vehicles (UAVs), a UAV-aided hybrid cloud/mobile-edge computing architecture promises to handle the intricate requirements of future XR applications. In this context, this paper distinguishes between two types of XR devices, namely, strong and weak devices. The paper then introduces a cooperative non-orthogonal multiple access (Co-NOMA) scheme, pairing strong and weak devices, so as to aid the XR devices quality-of-user experience by intelligently selecting either the direct or the relay links toward the weak XR devices. A sum logarithmic-rate maximization problem is, thus, formulated so as to jointly determine the computation and communication resources, and link-selection strategy as a means to strike a trade-off between the system throughput and fairness. Subject to realistic network constraints, e.g., power consumption and delay, the optimization problem is then solved iteratively via discrete relaxations, successive-convex approximation, and fractional programming, an approach which can be implemented in a distributed fashion across the network. Simulation results validate the proposed algorithms performance in terms of log-rate maximization, delay-sensitivity, scalability, and runtime performance. The practical distributed Co-NOMA implementation is particularly shown to offer appreciable benefits over traditional multiple access and NOMA methods, highlighting its applicability in decentralized XR systems. ",
    "url": "https://arxiv.org/abs/2310.06874",
    "authors": [
      "Robert-Jeron Reifert",
      "Hayssam Dahrouj",
      "Aydin Sezgin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.06907",
    "title": "Self-supervised Object-Centric Learning for Videos",
    "abstract": "Unsupervised multi-object segmentation has shown impressive results on images by utilizing powerful semantics learned from self-supervised pretraining. An additional modality such as depth or motion is often used to facilitate the segmentation in video sequences. However, the performance improvements observed in synthetic sequences, which rely on the robustness of an additional cue, do not translate to more challenging real-world scenarios. In this paper, we propose the first fully unsupervised method for segmenting multiple objects in real-world sequences. Our object-centric learning framework spatially binds objects to slots on each frame and then relates these slots across frames. From these temporally-aware slots, the training objective is to reconstruct the middle frame in a high-level semantic feature space. We propose a masking strategy by dropping a significant portion of tokens in the feature space for efficiency and regularization. Additionally, we address over-clustering by merging slots based on similarity. Our method can successfully segment multiple instances of complex and high-variety classes in YouTube videos. ",
    "url": "https://arxiv.org/abs/2310.06907",
    "authors": [
      "G\u00f6rkay Aydemir",
      "Weidi Xie",
      "Fatma G\u00fcney"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.06913",
    "title": "A Comparative Study of Transformer-based Neural Text Representation  Techniques on Bug Triaging",
    "abstract": "Often, the first step in managing bug reports is related to triaging a bug to the appropriate developer who is best suited to understand, localize, and fix the target bug. Additionally, assigning a given bug to a particular part of a software project can help to expedite the fixing process. However, despite the importance of these activities, they are quite challenging, where days can be spent on the manual triaging process. Past studies have attempted to leverage the limited textual data of bug reports to train text classification models that automate this process -- to varying degrees of success. However, the textual representations and machine learning models used in prior work are limited by their expressiveness, often failing to capture nuanced textual patterns that might otherwise aid in the triaging process. Recently, large, transformer-based, pre-trained neural text representation techniques such as BERT have achieved greater performance in several natural language processing tasks. However, the potential for using these techniques to improve upon prior approaches for automated bug triaging is not well studied or understood. Therefore, in this paper we offer one of the first investigations that fine-tunes transformer-based language models for the task of bug triaging on four open source datasets, spanning a collective 53 years of development history with over 400 developers and over 150 software project components. Our study includes both a quantitative and qualitative analysis of effectiveness. Our findings illustrate that DeBERTa is the most effective technique across the triaging tasks of developer and component assignment, and the measured performance delta is statistically significant compared to other techniques. However, through our qualitative analysis, we also observe that each technique possesses unique abilities best suited to certain types of bug reports. ",
    "url": "https://arxiv.org/abs/2310.06913",
    "authors": [
      "Atish Kumar Dipongkor",
      "Kevin Moran"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.06936",
    "title": "LLMs Killed the Script Kiddie: How Agents Supported by Large Language  Models Change the Landscape of Network Threat Testing",
    "abstract": "In this paper, we explore the potential of Large Language Models (LLMs) to reason about threats, generate information about tools, and automate cyber campaigns. We begin with a manual exploration of LLMs in supporting specific threat-related actions and decisions. We proceed by automating the decision process in a cyber campaign. We present prompt engineering approaches for a plan-act-report loop for one action of a threat campaign and and a prompt chaining design that directs the sequential decision process of a multi-action campaign. We assess the extent of LLM's cyber-specific knowledge w.r.t the short campaign we demonstrate and provide insights into prompt design for eliciting actionable responses. We discuss the potential impact of LLMs on the threat landscape and the ethical considerations of using LLMs for accelerating threat actor capabilities. We report a promising, yet concerning, application of generative AI to cyber threats. However, the LLM's capabilities to deal with more complex networks, sophisticated vulnerabilities, and the sensitivity of prompts are open questions. This research should spur deliberations over the inevitable advancements in LLM-supported cyber adversarial landscape. ",
    "url": "https://arxiv.org/abs/2310.06936",
    "authors": [
      "Stephen Moskal",
      "Sam Laney",
      "Erik Hemberg",
      "Una-May O'Reilly"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.06947",
    "title": "Open SYCL on heterogeneous GPU systems: A case of study",
    "abstract": "Computational platforms for high-performance scientific applications are becoming more heterogenous, including hardware accelerators such as multiple GPUs. Applications in a wide variety of scientific fields require an efficient and careful management of the computational resources of this type of hardware to obtain the best possible performance. However, there are currently different GPU vendors, architectures and families that can be found in heterogeneous clusters or machines. Programming with the vendor provided languages or frameworks, and optimizing for specific devices, may become cumbersome and compromise portability to other systems. To overcome this problem, several proposals for high-level heterogeneous programming have appeared, trying to reduce the development effort and increase functional and performance portability, specifically when using GPU hardware accelerators. This paper evaluates the SYCL programming model, using the Open SYCL compiler, from two different perspectives: The performance it offers when dealing with single or multiple GPU devices from the same or different vendors, and the development effort required to implement the code. We use as case of study the Finite Time Lyapunov Exponent calculation over two real-world scenarios and compare the performance and the development effort of its Open SYCL-based version against the equivalent versions that use CUDA or HIP. Based on the experimental results, we observe that the use of SYCL does not lead to a remarkable overhead in terms of the GPU kernels execution time. In general terms, the Open SYCL development effort for the host code is lower than that observed with CUDA or HIP. Moreover, the SYCL version can take advantage of both CUDA and AMD GPU devices simultaneously much easier than directly using the vendor-specific programming solutions. ",
    "url": "https://arxiv.org/abs/2310.06947",
    "authors": [
      "Roc\u00edo Carratal\u00e1-S\u00e1ez",
      "Francisco J. and\u00fajar",
      "Yuri Torres",
      "Arturo Gonzalez-Escribano",
      "Diego R. Llanos"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.06956",
    "title": "Adversarial optimization leads to over-optimistic security-constrained  dispatch, but sampling can help",
    "abstract": "To ensure safe, reliable operation of the electrical grid, we must be able to predict and mitigate likely failures. This need motivates the classic security-constrained AC optimal power flow (SCOPF) problem. SCOPF is commonly solved using adversarial optimization, where the dispatcher and an adversary take turns optimizing a robust dispatch and adversarial attack, respectively. We show that adversarial optimization is liable to severely overestimate the robustness of the optimized dispatch (when the adversary encounters a local minimum), leading the operator to falsely believe that their dispatch is secure. To prevent this overconfidence, we develop a novel adversarial sampling approach that prioritizes diversity in the predicted attacks. We find that our method not only substantially improves the robustness of the optimized dispatch but also avoids overconfidence, accurately characterizing the likelihood of voltage collapse under a given threat model. We demonstrate a proof-of-concept on small-scale transmission systems with 14 and 57 nodes. ",
    "url": "https://arxiv.org/abs/2310.06956",
    "authors": [
      "Charles Dawson",
      "Chuchu Fan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.06958",
    "title": "Comparing the robustness of modern no-reference image- and video-quality  metrics to adversarial attacks",
    "abstract": "Nowadays neural-network-based image- and video-quality metrics show better performance compared to traditional methods. However, they also became more vulnerable to adversarial attacks that increase metrics' scores without improving visual quality. The existing benchmarks of quality metrics compare their performance in terms of correlation with subjective quality and calculation time. However, the adversarial robustness of image-quality metrics is also an area worth researching. In this paper, we analyse modern metrics' robustness to different adversarial attacks. We adopted adversarial attacks from computer vision tasks and compared attacks' efficiency against 15 no-reference image/video-quality metrics. Some metrics showed high resistance to adversarial attacks which makes their usage in benchmarks safer than vulnerable metrics. The benchmark accepts new metrics submissions for researchers who want to make their metrics more robust to attacks or to find such metrics for their needs. Try our benchmark using pip install robustness-benchmark. ",
    "url": "https://arxiv.org/abs/2310.06958",
    "authors": [
      "Anastasia Antsiferova",
      "Khaled Abud",
      "Aleksandr Gushchin",
      "Sergey Lavrushkin",
      "Ekaterina Shumitskaya",
      "Maksim Velikanov",
      "Dmitriy Vatolin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.06983",
    "title": "Violation of Expectation via Metacognitive Prompting Reduces Theory of  Mind Prediction Error in Large Language Models",
    "abstract": "Recent research shows that Large Language Models (LLMs) exhibit a compelling level of proficiency in Theory of Mind (ToM) tasks. This ability to impute unobservable mental states to others is vital to human social cognition and may prove equally important in principal-agent relations between individual humans and Artificial Intelligences (AIs). In this paper, we explore how a mechanism studied in developmental psychology known as Violation of Expectation (VoE) can be implemented to reduce errors in LLM prediction about users by leveraging emergent ToM affordances. And we introduce a \\textit{metacognitive prompting} framework to apply VoE in the context of an AI tutor. By storing and retrieving facts derived in cases where LLM expectation about the user was violated, we find that LLMs are able to learn about users in ways that echo theories of human learning. Finally, we discuss latent hazards and augmentative opportunities associated with modeling user psychology and propose ways to mitigate risk along with possible directions for future inquiry. ",
    "url": "https://arxiv.org/abs/2310.06983",
    "authors": [
      "Courtland Leer",
      "Vincent Trost",
      "Vineeth Voruganti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.06984",
    "title": "Leveraging Neural Radiance Fields for Uncertainty-Aware Visual  Localization",
    "abstract": "As a promising fashion for visual localization, scene coordinate regression (SCR) has seen tremendous progress in the past decade. Most recent methods usually adopt neural networks to learn the mapping from image pixels to 3D scene coordinates, which requires a vast amount of annotated training data. We propose to leverage Neural Radiance Fields (NeRF) to generate training samples for SCR. Despite NeRF's efficiency in rendering, many of the rendered data are polluted by artifacts or only contain minimal information gain, which can hinder the regression accuracy or bring unnecessary computational costs with redundant data. These challenges are addressed in three folds in this paper: (1) A NeRF is designed to separately predict uncertainties for the rendered color and depth images, which reveal data reliability at the pixel level. (2) SCR is formulated as deep evidential learning with epistemic uncertainty, which is used to evaluate information gain and scene coordinate quality. (3) Based on the three arts of uncertainties, a novel view selection policy is formed that significantly improves data efficiency. Experiments on public datasets demonstrate that our method could select the samples that bring the most information gain and promote the performance with the highest efficiency. ",
    "url": "https://arxiv.org/abs/2310.06984",
    "authors": [
      "Le Chen",
      "Weirong Chen",
      "Rui Wang",
      "Marc Pollefeys"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.06989",
    "title": "TDPP: Two-Dimensional Permutation-Based Protection of Memristive Deep  Neural Networks",
    "abstract": "The execution of deep neural network (DNN) algorithms suffers from significant bottlenecks due to the separation of the processing and memory units in traditional computer systems. Emerging memristive computing systems introduce an in situ approach that overcomes this bottleneck. The non-volatility of memristive devices, however, may expose the DNN weights stored in memristive crossbars to potential theft attacks. Therefore, this paper proposes a two-dimensional permutation-based protection (TDPP) method that thwarts such attacks. We first introduce the underlying concept that motivates the TDPP method: permuting both the rows and columns of the DNN weight matrices. This contrasts with previous methods, which focused solely on permuting a single dimension of the weight matrices, either the rows or columns. While it's possible for an adversary to access the matrix values, the original arrangement of rows and columns in the matrices remains concealed. As a result, the extracted DNN model from the accessed matrix values would fail to operate correctly. We consider two different memristive computing systems (designed for layer-by-layer and layer-parallel processing, respectively) and demonstrate the design of the TDPP method that could be embedded into the two systems. Finally, we present a security analysis. Our experiments demonstrate that TDPP can achieve comparable effectiveness to prior approaches, with a high level of security when appropriately parameterized. In addition, TDPP is more scalable than previous methods and results in reduced area and power overheads. The area and power are reduced by, respectively, 1218$\\times$ and 2815$\\times$ for the layer-by-layer system and by 178$\\times$ and 203$\\times$ for the layer-parallel system compared to prior works. ",
    "url": "https://arxiv.org/abs/2310.06989",
    "authors": [
      "Minhui Zou",
      "Zhenhua Zhu",
      "Tzofnat Greenberg-Toledo",
      "Orian Leitersdorf",
      "Jiang Li",
      "Junlong Zhou",
      "Yu Wang",
      "Nan Du",
      "Shahar Kvatinsky"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2310.06993",
    "title": "Ultima: Robust and Tail-Optimal AllReduce for Distributed Deep Learning  in the Cloud",
    "abstract": "We present Ultima, a new collective-communication system for the cloud with bounded, predictable completion times for deep-learning jobs in the presence of varying computation (stragglers) and communication (congestion and gradient drops) variabilities. Ultima exploits the inherent resiliency and the stochastic nature of distributed deep-learning (DDL) training to work with approximated gradients, and provides an efficient balance between (tail) performance and the resulting accuracy of the trained models. Exploiting this domain-specific characteristic of DDL, Ultima introduces (1) mechanisms (e.g., Transpose AllReduce, unreliable connection-oriented transport, and adaptive timeout) to improve the DDL jobs' tail execution time, and (2) strategies (e.g., Hadamard Transform) to mitigate the impact of gradient drops on model accuracy. Our evaluation shows that Ultima achieves 60% faster time-to-accuracy (TTA), on average, when operating in shared environments (e.g., public cloud), and is on par with existing algorithms (e.g., Ring-AllReduce) in dedicated environments (like HPC). ",
    "url": "https://arxiv.org/abs/2310.06993",
    "authors": [
      "Ertza Warraich",
      "Omer Shabtai",
      "Khalid Manaa",
      "Shay Vargaftik",
      "Yonatan Piasetzky",
      "Matty Kadosh",
      "Lalith Suresh",
      "Muhammad Shahbaz"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.07008",
    "title": "Answer Candidate Type Selection: Text-to-Text Language Model for Closed  Book Question Answering Meets Knowledge Graphs",
    "abstract": "Pre-trained Text-to-Text Language Models (LMs), such as T5 or BART yield promising results in the Knowledge Graph Question Answering (KGQA) task. However, the capacity of the models is limited and the quality decreases for questions with less popular entities. In this paper, we present a novel approach which works on top of the pre-trained Text-to-Text QA system to address this issue. Our simple yet effective method performs filtering and re-ranking of generated candidates based on their types derived from Wikidata \"instance_of\" property. ",
    "url": "https://arxiv.org/abs/2310.07008",
    "authors": [
      "Mikhail Salnikov",
      "Maria Lysyuk",
      "Pavel Braslavski",
      "Anton Razzhigaev",
      "Valentin Malykh",
      "Alexander Panchenko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07015",
    "title": "Neural Relational Inference with Fast Modular Meta-learning",
    "abstract": "\\textit{Graph neural networks} (GNNs) are effective models for many dynamical systems consisting of entities and relations. Although most GNN applications assume a single type of entity and relation, many situations involve multiple types of interactions. \\textit{Relational inference} is the problem of inferring these interactions and learning the dynamics from observational data. We frame relational inference as a \\textit{modular meta-learning} problem, where neural modules are trained to be composed in different ways to solve many tasks. This meta-learning framework allows us to implicitly encode time invariance and infer relations in context of one another rather than independently, which increases inference capacity. Framing inference as the inner-loop optimization of meta-learning leads to a model-based approach that is more data-efficient and capable of estimating the state of entities that we do not observe directly, but whose existence can be inferred from their effect on observed entities. To address the large search space of graph neural network compositions, we meta-learn a \\textit{proposal function} that speeds up the inner-loop simulated annealing search within the modular meta-learning algorithm, providing two orders of magnitude increase in the size of problems that can be addressed. ",
    "url": "https://arxiv.org/abs/2310.07015",
    "authors": [
      "Ferran Alet",
      "Erica Weng",
      "Tom\u00e1s Lozano P\u00e9rez",
      "Leslie Pack Kaelbling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07023",
    "title": "Automatic Macro Mining from Interaction Traces at Scale",
    "abstract": "Macros are building block tasks of our everyday smartphone activity (e.g., \"login\", or \"booking a flight\"). Effectively extracting macros is important for understanding mobile interaction and enabling task automation. These macros are however difficult to extract at scale as they can be comprised of multiple steps yet hidden within programmatic components of the app. In this paper, we introduce a novel approach based on Large Language Models (LLMs) to automatically extract semantically meaningful macros from both random and user-curated mobile interaction traces. The macros produced by our approach are automatically tagged with natural language descriptions and are fully executable. To examine the quality of extraction, we conduct multiple studies, including user evaluation, comparative analysis against human-curated tasks, and automatic execution of these macros. These experiments and analyses show the effectiveness of our approach and the usefulness of extracted macros in various downstream applications. ",
    "url": "https://arxiv.org/abs/2310.07023",
    "authors": [
      "Forrest Huang",
      "Gang Li",
      "Tao Li",
      "Yang Li"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07028",
    "title": "Facial Forgery-based Deepfake Detection using Fine-Grained Features",
    "abstract": "Facial forgery by deepfakes has caused major security risks and raised severe societal concerns. As a countermeasure, a number of deepfake detection methods have been proposed. Most of them model deepfake detection as a binary classification problem using a backbone convolutional neural network (CNN) architecture pretrained for the task. These CNN-based methods have demonstrated very high efficacy in deepfake detection with the Area under the Curve (AUC) as high as $0.99$. However, the performance of these methods degrades significantly when evaluated across datasets and deepfake manipulation techniques. This draws our attention towards learning more subtle, local, and discriminative features for deepfake detection. In this paper, we formulate deepfake detection as a fine-grained classification problem and propose a new fine-grained solution to it. Specifically, our method is based on learning subtle and generalizable features by effectively suppressing background noise and learning discriminative features at various scales for deepfake detection. Through extensive experimental validation, we demonstrate the superiority of our method over the published research in cross-dataset and cross-manipulation generalization of deepfake detectors for the majority of the experimental scenarios. ",
    "url": "https://arxiv.org/abs/2310.07028",
    "authors": [
      "Aakash Varma Nadimpalli",
      "Ajita Rattani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07032",
    "title": "Neural Harmonium: An Interpretable Deep Structure for Nonlinear Dynamic  System Identification with Application to Audio Processing",
    "abstract": "Improving the interpretability of deep neural networks has recently gained increased attention, especially when the power of deep learning is leveraged to solve problems in physics. Interpretability helps us understand a model's ability to generalize and reveal its limitations. In this paper, we introduce a causal interpretable deep structure for modeling dynamic systems. Our proposed model makes use of the harmonic analysis by modeling the system in a time-frequency domain while maintaining high temporal and spectral resolution. Moreover, the model is built in an order recursive manner which allows for fast, robust, and exact second order optimization without the need for an explicit Hessian calculation. To circumvent the resulting high dimensionality of the building blocks of our system, a neural network is designed to identify the frequency interdependencies. The proposed model is illustrated and validated on nonlinear system identification problems as required for audio signal processing tasks. Crowd-sourced experimentation contrasting the performance of the proposed approach to other state-of-the-art solutions on an acoustic echo cancellation scenario confirms the effectiveness of our method for real-life applications. ",
    "url": "https://arxiv.org/abs/2310.07032",
    "authors": [
      "Karim Helwani",
      "Erfan Soltanmohammadi",
      "Michael M. Goodwin"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.07033",
    "title": "Computational Pathology at Health System Scale -- Self-Supervised  Foundation Models from Three Billion Images",
    "abstract": "Recent breakthroughs in self-supervised learning have enabled the use of large unlabeled datasets to train visual foundation models that can generalize to a variety of downstream tasks. While this training paradigm is well suited for the medical domain where annotations are scarce, large-scale pre-training in the medical domain, and in particular pathology, has not been extensively studied. Previous work in self-supervised learning in pathology has leveraged smaller datasets for both pre-training and evaluating downstream performance. The aim of this project is to train the largest academic foundation model and benchmark the most prominent self-supervised learning algorithms by pre-training and evaluating downstream performance on large clinical pathology datasets. We collected the largest pathology dataset to date, consisting of over 3 billion images from over 423 thousand microscopy slides. We compared pre-training of visual transformer models using the masked autoencoder (MAE) and DINO algorithms. We evaluated performance on six clinically relevant tasks from three anatomic sites and two institutions: breast cancer detection, inflammatory bowel disease detection, breast cancer estrogen receptor prediction, lung adenocarcinoma EGFR mutation prediction, and lung cancer immunotherapy response prediction. Our results demonstrate that pre-training on pathology data is beneficial for downstream performance compared to pre-training on natural images. Additionally, the DINO algorithm achieved better generalization performance across all tasks tested. The presented results signify a phase change in computational pathology research, paving the way into a new era of more performant models based on large-scale, parallel pre-training at the billion-image scale. ",
    "url": "https://arxiv.org/abs/2310.07033",
    "authors": [
      "Gabriele Campanella",
      "Ricky Kwan",
      "Eugene Fluder",
      "Jennifer Zeng",
      "Aryeh Stock",
      "Brandon Veremis",
      "Alexandros D. Polydorides",
      "Cyrus Hedvat",
      "Adam Schoenfeld",
      "Chad Vanderbilt",
      "Patricia Kovatch",
      "Carlos Cordon-Cardo",
      "Thomas J. Fuchs"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.07056",
    "title": "TextPSG: Panoptic Scene Graph Generation from Textual Descriptions",
    "abstract": "Panoptic Scene Graph has recently been proposed for comprehensive scene understanding. However, previous works adopt a fully-supervised learning manner, requiring large amounts of pixel-wise densely-annotated data, which is always tedious and expensive to obtain. To address this limitation, we study a new problem of Panoptic Scene Graph Generation from Purely Textual Descriptions (Caption-to-PSG). The key idea is to leverage the large collection of free image-caption data on the Web alone to generate panoptic scene graphs. The problem is very challenging for three constraints: 1) no location priors; 2) no explicit links between visual regions and textual entities; and 3) no pre-defined concept sets. To tackle this problem, we propose a new framework TextPSG consisting of four modules, i.e., a region grouper, an entity grounder, a segment merger, and a label generator, with several novel techniques. The region grouper first groups image pixels into different segments and the entity grounder then aligns visual segments with language entities based on the textual description of the segment being referred to. The grounding results can thus serve as pseudo labels enabling the segment merger to learn the segment similarity as well as guiding the label generator to learn object semantics and relation predicates, resulting in a fine-grained structured scene understanding. Our framework is effective, significantly outperforming the baselines and achieving strong out-of-distribution robustness. We perform comprehensive ablation studies to corroborate the effectiveness of our design choices and provide an in-depth analysis to highlight future directions. Our code, data, and results are available on our project page: https://vis-www.cs.umass.edu/TextPSG. ",
    "url": "https://arxiv.org/abs/2310.07056",
    "authors": [
      "Chengyang Zhao",
      "Yikang Shen",
      "Zhenfang Chen",
      "Mingyu Ding",
      "Chuang Gan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07081",
    "title": "Crossing the Threshold: Idiomatic Machine Translation through Retrieval  Augmentation and Loss Weighting",
    "abstract": "Idioms are common in everyday language, but often pose a challenge to translators because their meanings do not follow from the meanings of their parts. Despite significant advances, machine translation systems still struggle to translate idiomatic expressions. We provide a simple characterization of idiomatic translation and related issues. This allows us to conduct a synthetic experiment revealing a tipping point at which transformer-based machine translation models correctly default to idiomatic translations. To expand multilingual resources, we compile a dataset of ~4k natural sentences containing idiomatic expressions in French, Finnish, and Japanese. To improve translation of natural idioms, we introduce two straightforward yet effective techniques: the strategic upweighting of training loss on potentially idiomatic sentences, and using retrieval-augmented models. This not only improves the accuracy of a strong pretrained MT model on idiomatic sentences by up to 13% in absolute accuracy, but also holds potential benefits for non-idiomatic sentences. ",
    "url": "https://arxiv.org/abs/2310.07081",
    "authors": [
      "Emmy Liu",
      "Aditi Chaudhary",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.07084",
    "title": "Investigating the Adversarial Robustness of Density Estimation Using the  Probability Flow ODE",
    "abstract": "Beyond their impressive sampling capabilities, score-based diffusion models offer a powerful analysis tool in the form of unbiased density estimation of a query sample under the training data distribution. In this work, we investigate the robustness of density estimation using the probability flow (PF) neural ordinary differential equation (ODE) model against gradient-based likelihood maximization attacks and the relation to sample complexity, where the compressed size of a sample is used as a measure of its complexity. We introduce and evaluate six gradient-based log-likelihood maximization attacks, including a novel reverse integration attack. Our experimental evaluations on CIFAR-10 show that density estimation using the PF ODE is robust against high-complexity, high-likelihood attacks, and that in some cases adversarial samples are semantically meaningful, as expected from a robust estimator. ",
    "url": "https://arxiv.org/abs/2310.07084",
    "authors": [
      "Marius Arvinte",
      "Cory Cornelius",
      "Jason Martin",
      "Nageen Himayat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07109",
    "title": "SparseCoder: Advancing Source Code Analysis with Sparse Attention and  Learned Token Pruning",
    "abstract": "As software projects rapidly evolve, software artifacts become more complex and defects behind get harder to identify. The emerging Transformer-based approaches, though achieving remarkable performance, struggle with long code sequences due to their self-attention mechanism, which scales quadratically with the sequence length. This paper introduces SparseCoder, an innovative approach incorporating sparse attention and learned token pruning (LTP) method (adapted from natural language processing) to address this limitation. Extensive experiments carried out on a large-scale dataset for vulnerability detection demonstrate the effectiveness and efficiency of SparseCoder, scaling from quadratically to linearly on long code sequence analysis in comparison to CodeBERT and RoBERTa. We further achieve 50% FLOPs reduction with a negligible performance drop of less than 1% comparing to Transformer leveraging sparse attention. Moverover, SparseCoder goes beyond making \"black-box\" decisions by elucidating the rationale behind those decisions. Code segments that contribute to the final decision can be highlighted with importance scores, offering an interpretable, transparent analysis tool for the software engineering landscape. ",
    "url": "https://arxiv.org/abs/2310.07109",
    "authors": [
      "Xueqi Yang",
      "Mariusz Jakubowski",
      "Kelly Kang",
      "Haojie Yu",
      "Tim Menzies"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.07129",
    "title": "The impact when neural min-sum variants meet ordered statistics decoding  of LDPC codes",
    "abstract": "The decoding performance of conventional belief propagation decoders is seriously confined by the existence of message dependence in the code structure for short or moderate LDPC codes. In spite of the similarity of the external performance, we found the corresponding decoding failures of varied decoders, symbolized by the cross-entropy metric, will leave differed room for improvement for the postprocessing of ordered statistical decoding. Bearing in mind the postprocessor of higher order ensures better performance and incurs more expensive complexity, we propose a dynamic assignment of searching scope with respect to each decoding pattern for the order statistical decoding. Furthermore, the segmentation of decoding patterns, determined on the fly by the number of swaps in reducing the code check matrix into its systematic form via Gaussian elimination operation. will also benefit reducing complexity. Compared with the existing methods, our adapted strategy is justified by saving most memory consumption and inefficient searching of code-word candidates in extensive simulation especially for longer codes, at the cost of marginal performance loss. ",
    "url": "https://arxiv.org/abs/2310.07129",
    "authors": [
      "Guangwen Li",
      "Xiao Yu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2310.07146",
    "title": "Empowering Psychotherapy with Large Language Models: Cognitive  Distortion Detection through Diagnosis of Thought Prompting",
    "abstract": "Mental illness remains one of the most critical public health issues of our time, due to the severe scarcity and accessibility limit of professionals. Psychotherapy requires high-level expertise to conduct deep, complex reasoning and analysis on the cognition modeling of the patients. In the era of Large Language Models, we believe it is the right time to develop AI assistance for computational psychotherapy. We study the task of cognitive distortion detection and propose the Diagnosis of Thought (DoT) prompting. DoT performs diagnosis on the patient's speech via three stages: subjectivity assessment to separate the facts and the thoughts; contrastive reasoning to elicit the reasoning processes supporting and contradicting the thoughts; and schema analysis to summarize the cognition schemas. The generated diagnosis rationales through the three stages are essential for assisting the professionals. Experiments demonstrate that DoT obtains significant improvements over ChatGPT for cognitive distortion detection, while generating high-quality rationales approved by human experts. ",
    "url": "https://arxiv.org/abs/2310.07146",
    "authors": [
      "Zhiyu Chen",
      "Yujie Lu",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.07149",
    "title": "Robust Unsupervised Domain Adaptation by Retaining Confident Entropy via  Edge Concatenation",
    "abstract": "The generalization capability of unsupervised domain adaptation can mitigate the need for extensive pixel-level annotations to train semantic segmentation networks by training models on synthetic data as a source with computer-generated annotations. Entropy-based adversarial networks are proposed to improve source domain prediction; however, they disregard significant external information, such as edges, which have the potential to identify and distinguish various objects within an image accurately. To address this issue, we introduce a novel approach to domain adaptation, leveraging the synergy of internal and external information within entropy-based adversarial networks. In this approach, we enrich the discriminator network with edge-predicted probability values within this innovative framework to enhance the clarity of class boundaries. Furthermore, we devised a probability-sharing network that integrates diverse information for more effective segmentation. Incorporating object edges addresses a pivotal aspect of unsupervised domain adaptation that has frequently been neglected in the past -- the precise delineation of object boundaries. Conventional unsupervised domain adaptation methods usually center around aligning feature distributions and may not explicitly model object boundaries. Our approach effectively bridges this gap by offering clear guidance on object boundaries, thereby elevating the quality of domain adaptation. Our approach undergoes rigorous evaluation on the established unsupervised domain adaptation benchmarks, specifically in adapting SYNTHIA $\\rightarrow$ Cityscapes and SYNTHIA $\\rightarrow$ Mapillary. Experimental results show that the proposed model attains better performance than state-of-the-art methods. The superior performance across different unsupervised domain adaptation scenarios highlights the versatility and robustness of the proposed method. ",
    "url": "https://arxiv.org/abs/2310.07149",
    "authors": [
      "Hye-Seong Hong",
      "Abhishek Kumar",
      "Dong-Gyu Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07152",
    "title": "No Privacy Left Outside: On the (In-)Security of TEE-Shielded DNN  Partition for On-Device ML",
    "abstract": "On-device ML introduces new security challenges: DNN models become white-box accessible to device users. Based on white-box information, adversaries can conduct effective model stealing (MS) and membership inference attack (MIA). Using Trusted Execution Environments (TEEs) to shield on-device DNN models aims to downgrade (easy) white-box attacks to (harder) black-box attacks. However, one major shortcoming is the sharply increased latency (up to 50X). To accelerate TEE-shield DNN computation with GPUs, researchers proposed several model partition techniques. These solutions, referred to as TEE-Shielded DNN Partition (TSDP), partition a DNN model into two parts, offloading the privacy-insensitive part to the GPU while shielding the privacy-sensitive part within the TEE. This paper benchmarks existing TSDP solutions using both MS and MIA across a variety of DNN models, datasets, and metrics. We show important findings that existing TSDP solutions are vulnerable to privacy-stealing attacks and are not as safe as commonly believed. We also unveil the inherent difficulty in deciding optimal DNN partition configurations (i.e., the highest security with minimal utility cost) for present TSDP solutions. The experiments show that such ``sweet spot'' configurations vary across datasets and models. Based on lessons harvested from the experiments, we present TEESlice, a novel TSDP method that defends against MS and MIA during DNN inference. TEESlice follows a partition-before-training strategy, which allows for accurate separation between privacy-related weights from public weights. TEESlice delivers the same security protection as shielding the entire DNN model inside TEE (the ``upper-bound'' security guarantees) with over 10X less overhead (in both experimental and real-world environments) than prior TSDP solutions and no accuracy loss. ",
    "url": "https://arxiv.org/abs/2310.07152",
    "authors": [
      "Ziqi Zhang",
      "Chen Gong",
      "Yifeng Cai",
      "Yuanyuan Yuan",
      "Bingyan Liu",
      "Ding Li",
      "Yao Guo",
      "Xiangqun Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07155",
    "title": "\"A Tale of Two Movements\": Identifying and Comparing Perspectives in  #BlackLivesMatter and #BlueLivesMatter Movements-related Tweets using Weakly  Supervised Graph-based Structured Prediction",
    "abstract": "Social media has become a major driver of social change, by facilitating the formation of online social movements. Automatically understanding the perspectives driving the movement and the voices opposing it, is a challenging task as annotated data is difficult to obtain. We propose a weakly supervised graph-based approach that explicitly models perspectives in #BackLivesMatter-related tweets. Our proposed approach utilizes a social-linguistic representation of the data. We convert the text to a graph by breaking it into structured elements and connect it with the social network of authors, then structured prediction is done over the elements for identifying perspectives. Our approach uses a small seed set of labeled examples. We experiment with large language models for generating artificial training examples, compare them to manual annotation, and find that it achieves comparable performance. We perform quantitative and qualitative analyses using a human-annotated test set. Our model outperforms multitask baselines by a large margin, successfully characterizing the perspectives supporting and opposing #BLM. ",
    "url": "https://arxiv.org/abs/2310.07155",
    "authors": [
      "Shamik Roy",
      "Dan Goldwasser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.07159",
    "title": "My Brother Helps Me: Node Injection Based Adversarial Attack on Social  Bot Detection",
    "abstract": "Social platforms such as Twitter are under siege from a multitude of fraudulent users. In response, social bot detection tasks have been developed to identify such fake users. Due to the structure of social networks, the majority of methods are based on the graph neural network(GNN), which is susceptible to attacks. In this study, we propose a node injection-based adversarial attack method designed to deceive bot detection models. Notably, neither the target bot nor the newly injected bot can be detected when a new bot is added around the target bot. This attack operates in a black-box fashion, implying that any information related to the victim model remains unknown. To our knowledge, this is the first study exploring the resilience of bot detection through graph node injection. Furthermore, we develop an attribute recovery module to revert the injected node embedding from the graph embedding space back to the original feature space, enabling the adversary to manipulate node perturbation effectively. We conduct adversarial attacks on four commonly used GNN structures for bot detection on two widely used datasets: Cresci-2015 and TwiBot-22. The attack success rate is over 73\\% and the rate of newly injected nodes being detected as bots is below 13\\% on these two datasets. ",
    "url": "https://arxiv.org/abs/2310.07159",
    "authors": [
      "Lanjun Wang",
      "Xinran Qiao",
      "Yanwei Xie",
      "Weizhi Nie",
      "Yongdong Zhang",
      "Anan Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.07170",
    "title": "PHALM: Building a Knowledge Graph from Scratch by Prompting Humans and a  Language Model",
    "abstract": "Despite the remarkable progress in natural language understanding with pretrained Transformers, neural language models often do not handle commonsense knowledge well. Toward commonsense-aware models, there have been attempts to obtain knowledge, ranging from automatic acquisition to crowdsourcing. However, it is difficult to obtain a high-quality knowledge base at a low cost, especially from scratch. In this paper, we propose PHALM, a method of building a knowledge graph from scratch, by prompting both crowdworkers and a large language model (LLM). We used this method to build a Japanese event knowledge graph and trained Japanese commonsense generation models. Experimental results revealed the acceptability of the built graph and inferences generated by the trained models. We also report the difference in prompting humans and an LLM. Our code, data, and models are available at github.com/nlp-waseda/comet-atomic-ja. ",
    "url": "https://arxiv.org/abs/2310.07170",
    "authors": [
      "Tatsuya Ide",
      "Eiki Murata",
      "Daisuke Kawahara",
      "Takato Yamazaki",
      "Shengzhe Li",
      "Kenta Shinzato",
      "Toshinori Sato"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.07174",
    "title": "Generalized Neural Sorting Networks with Error-Free Differentiable Swap  Functions",
    "abstract": "Sorting is a fundamental operation of all computer systems, having been a long-standing significant research topic. Beyond the problem formulation of traditional sorting algorithms, we consider sorting problems for more abstract yet expressive inputs, e.g., multi-digit images and image fragments, through a neural sorting network. To learn a mapping from a high-dimensional input to an ordinal variable, the differentiability of sorting networks needs to be guaranteed. In this paper we define a softening error by a differentiable swap function, and develop an error-free swap function that holds non-decreasing and differentiability conditions. Furthermore, a permutation-equivariant Transformer network with multi-head attention is adopted to capture dependency between given inputs and also leverage its model capacity with self-attention. Experiments on diverse sorting benchmarks show that our methods perform better than or comparable to baseline methods. ",
    "url": "https://arxiv.org/abs/2310.07174",
    "authors": [
      "Jungtaek Kim",
      "Jeongbeen Yoon",
      "Minsu Cho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.07176",
    "title": "Improving mitosis detection on histopathology images using large  vision-language models",
    "abstract": "In certain types of cancerous tissue, mitotic count has been shown to be associated with tumor proliferation, poor prognosis, and therapeutic resistance. Due to the high inter-rater variability of mitotic counting by pathologists, convolutional neural networks (CNNs) have been employed to reduce the subjectivity of mitosis detection in hematoxylin and eosin (H&E)-stained whole slide images. However, most existing models have performance that lags behind expert panel review and only incorporate visual information. In this work, we demonstrate that pre-trained large-scale vision-language models that leverage both visual features and natural language improve mitosis detection accuracy. We formulate the mitosis detection task as an image captioning task and a visual question answering (VQA) task by including metadata such as tumor and scanner types as context. The effectiveness of our pipeline is demonstrated via comparison with various baseline models using 9,501 mitotic figures and 11,051 hard negatives (non-mitotic figures that are difficult to characterize) from the publicly available Mitosis Domain Generalization Challenge (MIDOG22) dataset. ",
    "url": "https://arxiv.org/abs/2310.07176",
    "authors": [
      "Ruiwen Ding",
      "James Hall",
      "Neil Tenenholtz",
      "Kristen Severson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07179",
    "title": "rpcPRF: Generalizable MPI Neural Radiance Field for Satellite Camera",
    "abstract": "Novel view synthesis of satellite images holds a wide range of practical applications. While recent advances in the Neural Radiance Field have predominantly targeted pin-hole cameras, and models for satellite cameras often demand sufficient input views. This paper presents rpcPRF, a Multiplane Images (MPI) based Planar neural Radiance Field for Rational Polynomial Camera (RPC). Unlike coordinate-based neural radiance fields in need of sufficient views of one scene, our model is applicable to single or few inputs and performs well on images from unseen scenes. To enable generalization across scenes, we propose to use reprojection supervision to induce the predicted MPI to learn the correct geometry between the 3D coordinates and the images. Moreover, we remove the stringent requirement of dense depth supervision from deep multiview-stereo-based methods by introducing rendering techniques of radiance fields. rpcPRF combines the superiority of implicit representations and the advantages of the RPC model, to capture the continuous altitude space while learning the 3D structure. Given an RGB image and its corresponding RPC, the end-to-end model learns to synthesize the novel view with a new RPC and reconstruct the altitude of the scene. When multiple views are provided as inputs, rpcPRF exerts extra supervision provided by the extra views. On the TLC dataset from ZY-3, and the SatMVS3D dataset with urban scenes from WV-3, rpcPRF outperforms state-of-the-art nerf-based methods by a significant margin in terms of image fidelity, reconstruction accuracy, and efficiency, for both single-view and multiview task. ",
    "url": "https://arxiv.org/abs/2310.07179",
    "authors": [
      "Tongtong Zhang",
      "Yuanxiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07189",
    "title": "SpikePoint: An Efficient Point-based Spiking Neural Network for Event  Cameras Action Recognition",
    "abstract": "Event cameras are bio-inspired sensors that respond to local changes in light intensity and feature low latency, high energy efficiency, and high dynamic range. Meanwhile, Spiking Neural Networks (SNNs) have gained significant attention due to their remarkable efficiency and fault tolerance. By synergistically harnessing the energy efficiency inherent in event cameras and the spike-based processing capabilities of SNNs, their integration could enable ultra-low-power application scenarios, such as action recognition tasks. However, existing approaches often entail converting asynchronous events into conventional frames, leading to additional data mapping efforts and a loss of sparsity, contradicting the design concept of SNNs and event cameras. To address this challenge, we propose SpikePoint, a novel end-to-end point-based SNN architecture. SpikePoint excels at processing sparse event cloud data, effectively extracting both global and local features through a singular-stage structure. Leveraging the surrogate training method, SpikePoint achieves high accuracy with few parameters and maintains low power consumption, specifically employing the identity mapping feature extractor on diverse datasets. SpikePoint achieves state-of-the-art (SOTA) performance on four event-based action recognition datasets using only 16 timesteps, surpassing other SNN methods. Moreover, it also achieves SOTA performance across all methods on three datasets, utilizing approximately 0.3\\% of the parameters and 0.5\\% of power consumption employed by artificial neural networks (ANNs). These results emphasize the significance of Point Cloud and pave the way for many ultra-low-power event-based data processing applications. ",
    "url": "https://arxiv.org/abs/2310.07189",
    "authors": [
      "Hongwei Ren",
      "Yue Zhou",
      "Yulong Huang",
      "Haotian Fu",
      "Xiaopeng Lin",
      "Jie Song",
      "Bojun Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07207",
    "title": "Robust Safe Reinforcement Learning under Adversarial Disturbances",
    "abstract": "Safety is a primary concern when applying reinforcement learning to real-world control tasks, especially in the presence of external disturbances. However, existing safe reinforcement learning algorithms rarely account for external disturbances, limiting their applicability and robustness in practice. To address this challenge, this paper proposes a robust safe reinforcement learning framework that tackles worst-case disturbances. First, this paper presents a policy iteration scheme to solve for the robust invariant set, i.e., a subset of the safe set, where persistent safety is only possible for states within. The key idea is to establish a two-player zero-sum game by leveraging the safety value function in Hamilton-Jacobi reachability analysis, in which the protagonist (i.e., control inputs) aims to maintain safety and the adversary (i.e., external disturbances) tries to break down safety. This paper proves that the proposed policy iteration algorithm converges monotonically to the maximal robust invariant set. Second, this paper integrates the proposed policy iteration scheme into a constrained reinforcement learning algorithm that simultaneously synthesizes the robust invariant set and uses it for constrained policy optimization. This algorithm tackles both optimality and safety, i.e., learning a policy that attains high rewards while maintaining safety under worst-case disturbances. Experiments on classic control tasks show that the proposed method achieves zero constraint violation with learned worst-case adversarial disturbances, while other baseline algorithms violate the safety constraints substantially. Our proposed method also attains comparable performance as the baselines even in the absence of the adversary. ",
    "url": "https://arxiv.org/abs/2310.07207",
    "authors": [
      "Zeyang Li",
      "Chuxiong Hu",
      "Shengbo Eben Li",
      "Jia Cheng",
      "Yunan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07217",
    "title": "Enhancing Neural Architecture Search with Multiple Hardware Constraints  for Deep Learning Model Deployment on Tiny IoT Devices",
    "abstract": "The rapid proliferation of computing domains relying on Internet of Things (IoT) devices has created a pressing need for efficient and accurate deep-learning (DL) models that can run on low-power devices. However, traditional DL models tend to be too complex and computationally intensive for typical IoT end-nodes. To address this challenge, Neural Architecture Search (NAS) has emerged as a popular design automation technique for co-optimizing the accuracy and complexity of deep neural networks. Nevertheless, existing NAS techniques require many iterations to produce a network that adheres to specific hardware constraints, such as the maximum memory available on the hardware or the maximum latency allowed by the target application. In this work, we propose a novel approach to incorporate multiple constraints into so-called Differentiable NAS optimization methods, which allows the generation, in a single shot, of a model that respects user-defined constraints on both memory and latency in a time comparable to a single standard training. The proposed approach is evaluated on five IoT-relevant benchmarks, including the MLPerf Tiny suite and Tiny ImageNet, demonstrating that, with a single search, it is possible to reduce memory and latency by 87.4% and 54.2%, respectively (as defined by our targets), while ensuring non-inferior accuracy on state-of-the-art hand-tuned deep neural networks for TinyML. ",
    "url": "https://arxiv.org/abs/2310.07217",
    "authors": [
      "Alessio Burrello",
      "Matteo Risso",
      "Beatrice Alessandra Motetti",
      "Enrico Macii",
      "Luca Benini",
      "Daniele Jahier Pagliari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07219",
    "title": "Improved Membership Inference Attacks Against Language Classification  Models",
    "abstract": "Artificial intelligence systems are prevalent in everyday life, with use cases in retail, manufacturing, health, and many other fields. With the rise in AI adoption, associated risks have been identified, including privacy risks to the people whose data was used to train models. Assessing the privacy risks of machine learning models is crucial to enabling knowledgeable decisions on whether to use, deploy, or share a model. A common approach to privacy risk assessment is to run one or more known attacks against the model and measure their success rate. We present a novel framework for running membership inference attacks against classification models. Our framework takes advantage of the ensemble method, generating many specialized attack models for different subsets of the data. We show that this approach achieves higher accuracy than either a single attack model or an attack model per class label, both on classical and language classification tasks. ",
    "url": "https://arxiv.org/abs/2310.07219",
    "authors": [
      "Shlomit Shachor",
      "Natalia Razinkov",
      "Abigail Goldsteen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.07229",
    "title": "Self-supervised Pocket Pretraining via Protein Fragment-Surroundings  Alignment",
    "abstract": "Pocket representations play a vital role in various biomedical applications, such as druggability estimation, ligand affinity prediction, and de novo drug design. While existing geometric features and pretrained representations have demonstrated promising results, they usually treat pockets independent of ligands, neglecting the fundamental interactions between them. However, the limited pocket-ligand complex structures available in the PDB database (less than 100 thousand non-redundant pairs) hampers large-scale pretraining endeavors for interaction modeling. To address this constraint, we propose a novel pocket pretraining approach that leverages knowledge from high-resolution atomic protein structures, assisted by highly effective pretrained small molecule representations. By segmenting protein structures into drug-like fragments and their corresponding pockets, we obtain a reasonable simulation of ligand-receptor interactions, resulting in the generation of over 5 million complexes. Subsequently, the pocket encoder is trained in a contrastive manner to align with the representation of pseudo-ligand furnished by some pretrained small molecule encoders. Our method, named ProFSA, achieves state-of-the-art performance across various tasks, including pocket druggability prediction, pocket matching, and ligand binding affinity prediction. Notably, ProFSA surpasses other pretraining methods by a substantial margin. Moreover, our work opens up a new avenue for mitigating the scarcity of protein-ligand complex data through the utilization of high-quality and diverse protein structure databases. ",
    "url": "https://arxiv.org/abs/2310.07229",
    "authors": [
      "Bowen Gao",
      "Yinjun Jia",
      "Yuanle Mo",
      "Yuyan Ni",
      "Weiying Ma",
      "Zhiming Ma",
      "Yanyan Lan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07239",
    "title": "Multidimensional Hopfield Networks for clustering",
    "abstract": "We present the Multidimensional Hopfield Network (DHN), a natural generalisation of the Hopfield Network. In our theoretical investigations we focus on DHNs with a certain activation function and provide energy functions for them. We conclude that these DHNs are convergent in finite time, and are equivalent to greedy methods that aim to find graph clusterings of locally minimal cuts. We also show that the general framework of DHNs encapsulates several previously known algorithms used for generating graph embeddings and clusterings. Namely, the Cleora graph embedding algorithm, the Louvain method, and the Newmans method can be cast as DHNs with appropriate activation function and update rule. Motivated by these findings we provide a generalisation of Newmans method to the multidimensional case. ",
    "url": "https://arxiv.org/abs/2310.07239",
    "authors": [
      "Gergely Stomfai",
      "\u0141ukasz Sienkiewicz",
      "Barbara Rychalska"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.07243",
    "title": "Cost-aware Joint Caching and Forwarding in Networks with Heterogeneous  Cache Resources",
    "abstract": "Caching is crucial for enabling high-throughput networks for data intensive applications. Traditional caching technology relies on DRAM, as it can transfer data at a high rate. However, DRAM capacity is subject to contention by most system components and thus is very limited, implying that DRAM-only caches cannot scale to meet growing demand. Fortunately, persistent memory and flash storage technologies are rapidly evolving and can be utilized alongside DRAM to increase cache capacities. To do so without compromising network performance requires caching techniques adapted to the characteristics of these technologies. In this paper, we model the cache as a collection of storage blocks with different rate parameters and utilization costs. We introduce an optimization technique based on the drift-plus-penalty method and apply it in a framework which enables joint caching and forwarding. We show that it achieves an optimal trade-off between throughput and cache utilization costs in a virtual control plane. We then develop a corresponding practical policy in the data plane. Finally, through simulations in several settings, we demonstrate the superior performance of our proposed approach with respect to total user delay and cache utilization costs. ",
    "url": "https://arxiv.org/abs/2310.07243",
    "authors": [
      "Faruk Volkan Mutlu",
      "Edmund Yeh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.07246",
    "title": "Vec-Tok Speech: speech vectorization and tokenization for neural speech  generation",
    "abstract": "Language models (LMs) have recently flourished in natural language processing and computer vision, generating high-fidelity texts or images in various tasks. In contrast, the current speech generative models are still struggling regarding speech quality and task generalization. This paper presents Vec-Tok Speech, an extensible framework that resembles multiple speech generation tasks, generating expressive and high-fidelity speech. Specifically, we propose a novel speech codec based on speech vectors and semantic tokens. Speech vectors contain acoustic details contributing to high-fidelity speech reconstruction, while semantic tokens focus on the linguistic content of speech, facilitating language modeling. Based on the proposed speech codec, Vec-Tok Speech leverages an LM to undertake the core of speech generation. Moreover, Byte-Pair Encoding (BPE) is introduced to reduce the token length and bit rate for lower exposure bias and longer context coverage, improving the performance of LMs. Vec-Tok Speech can be used for intra- and cross-lingual zero-shot voice conversion (VC), zero-shot speaking style transfer text-to-speech (TTS), speech-to-speech translation (S2ST), speech denoising, and speaker de-identification and anonymization. Experiments show that Vec-Tok Speech, built on 50k hours of speech, performs better than other SOTA models. Code will be available at https://github.com/BakerBunker/VecTok . ",
    "url": "https://arxiv.org/abs/2310.07246",
    "authors": [
      "Xinfa Zhu",
      "Yuanjun Lv",
      "Yi Lei",
      "Tao Li",
      "Wendi He",
      "Hongbin Zhou",
      "Heng Lu",
      "Lei Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.07248",
    "title": "IBoxCLA: Towards Robust Box-supervised Segmentation of Polyp via  Improved Box-dice and Contrastive Latent-anchors",
    "abstract": "Box-supervised polyp segmentation attracts increasing attention for its cost-effective potential. Existing solutions often rely on learning-free methods or pretrained models to laboriously generate pseudo masks, triggering Dice constraint subsequently. In this paper, we found that a model guided by the simplest box-filled masks can accurately predict polyp locations/sizes, but suffers from shape collapsing. In response, we propose two innovative learning fashions, Improved Box-dice (IBox) and Contrastive Latent-Anchors (CLA), and combine them to train a robust box-supervised model IBoxCLA. The core idea behind IBoxCLA is to decouple the learning of location/size and shape, allowing for focused constraints on each of them. Specifically, IBox transforms the segmentation map into a proxy map using shape decoupling and confusion-region swapping sequentially. Within the proxy map, shapes are disentangled, while locations/sizes are encoded as box-like responses. By constraining the proxy map instead of the raw prediction, the box-filled mask can well supervise IBoxCLA without misleading its shape learning. Furthermore, CLA contributes to shape learning by generating two types of latent anchors, which are learned and updated using momentum and segmented polyps to steadily represent polyp and background features. The latent anchors facilitate IBoxCLA to capture discriminative features within and outside boxes in a contrastive manner, yielding clearer boundaries. We benchmark IBoxCLA on five public polyp datasets. The experimental results demonstrate the competitive performance of IBoxCLA compared to recent fully-supervised polyp segmentation methods, and its superiority over other box-supervised state-of-the-arts with a relative increase of overall mDice and mIoU by at least 6.5% and 7.5%, respectively. ",
    "url": "https://arxiv.org/abs/2310.07248",
    "authors": [
      "Zhiwei Wang",
      "Qiang Hu",
      "Hongkuan Shi",
      "Li He",
      "Man He",
      "Wenxuan Dai",
      "Ting Li",
      "Yitong Zhang",
      "Dun Li",
      "Mei Liu",
      "Qiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07253",
    "title": "ADMEOOD: Out-of-Distribution Benchmark for Drug Property Prediction",
    "abstract": "Obtaining accurate and valid information for drug molecules is a crucial and challenging task. However, chemical knowledge and information have been accumulated over the past 100 years from various regions, laboratories, and experimental purposes. Little has been explored in terms of the out-of-distribution (OOD) problem with noise and inconsistency, which may lead to weak robustness and unsatisfied performance. This study proposes a novel benchmark ADMEOOD, a systematic OOD dataset curator and benchmark specifically designed for drug property prediction. ADMEOOD obtained 27 ADME (Absorption, Distribution, Metabolism, Excretion) drug properties from Chembl and relevant literature. Additionally, it includes two kinds of OOD data shifts: Noise Shift and Concept Conflict Drift (CCD). Noise Shift responds to the noise level by categorizing the environment into different confidence levels. On the other hand, CCD describes the data which has inconsistent label among the original data. Finally, it tested on a variety of domain generalization models, and the experimental results demonstrate the effectiveness of the proposed partition method in ADMEOOD: ADMEOOD demonstrates a significant difference performance between in-distribution and out-of-distribution data. Moreover, ERM (Empirical Risk Minimization) and other models exhibit distinct trends in performance across different domains and measurement types. ",
    "url": "https://arxiv.org/abs/2310.07253",
    "authors": [
      "Shuoying Wei",
      "Xinlong Wen",
      "Lida Zhu",
      "Songquan Li",
      "Rongbo Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2310.07255",
    "title": "ADASR: An Adversarial Auto-Augmentation Framework for Hyperspectral and  Multispectral Data Fusion",
    "abstract": "Deep learning-based hyperspectral image (HSI) super-resolution, which aims to generate high spatial resolution HSI (HR-HSI) by fusing hyperspectral image (HSI) and multispectral image (MSI) with deep neural networks (DNNs), has attracted lots of attention. However, neural networks require large amounts of training data, hindering their application in real-world scenarios. In this letter, we propose a novel adversarial automatic data augmentation framework ADASR that automatically optimizes and augments HSI-MSI sample pairs to enrich data diversity for HSI-MSI fusion. Our framework is sample-aware and optimizes an augmentor network and two downsampling networks jointly by adversarial learning so that we can learn more robust downsampling networks for training the upsampling network. Extensive experiments on two public classical hyperspectral datasets demonstrate the effectiveness of our ADASR compared to the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2310.07255",
    "authors": [
      "Jinghui Qin",
      "Lihuang Fang",
      "Ruitao Lu",
      "Liang Lin",
      "Yukai Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.07261",
    "title": "Deep ReLU networks and high-order finite element methods II: Chebyshev  emulation",
    "abstract": "Expression rates and stability in Sobolev norms of deep ReLU neural networks (NNs) in terms of the number of parameters defining the NN for continuous, piecewise polynomial functions, on arbitrary, finite partitions $\\mathcal{T}$ of a bounded interval $(a,b)$ are addressed. Novel constructions of ReLU NN surrogates encoding the approximated functions in terms of Chebyshev polynomial expansion coefficients are developed. Chebyshev coefficients can be computed easily from the values of the function in the Clenshaw--Curtis points using the inverse fast Fourier transform. Bounds on expression rates and stability that are superior to those of constructions based on ReLU NN emulations of monomials considered in [Opschoor, Petersen, Schwab, 2020] are obtained. All emulation bounds are explicit in terms of the (arbitrary) partition of the interval, the target emulation accuracy and the polynomial degree in each element of the partition. ReLU NN emulation error estimates are provided for various classes of functions and norms, commonly encountered in numerical analysis. In particular, we show exponential ReLU emulation rate bounds for analytic functions with point singularities and develop an interface between Chebfun approximations and constructive ReLU NN emulations. ",
    "url": "https://arxiv.org/abs/2310.07261",
    "authors": [
      "Joost A. A. Opschoor",
      "Christoph Schwab"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07262",
    "title": "Dynamic Brain Networks with Prescribed Functional Connectivity",
    "abstract": "In this paper, we consider stable stochastic linear systems modeling whole-brain resting-state dynamics. We parametrize the state matrix of the system (effective connectivity) in terms of its steady-state covariance matrix (functional connectivity) and a skew-symmetric matrix $S$. We examine how the matrix $S$ influences some relevant dynamic properties of the system. Specifically, we show that a large $S$ enhances the degree of stability and excitability of the system, and makes the latter more responsive to high-frequency inputs. ",
    "url": "https://arxiv.org/abs/2310.07262",
    "authors": [
      "Umberto Casti",
      "Giacomo Baggio",
      "Danilo Benozzo",
      "Sandro Zampieri",
      "Alessandra Bertoldo",
      "Alessandro Chiuso"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2310.07298",
    "title": "Beyond Memorization: Violating Privacy Via Inference with Large Language  Models",
    "abstract": "Current privacy research on large language models (LLMs) primarily focuses on the issue of extracting memorized training data. At the same time, models' inference capabilities have increased drastically. This raises the key question of whether current LLMs could violate individuals' privacy by inferring personal attributes from text given at inference time. In this work, we present the first comprehensive study on the capabilities of pretrained LLMs to infer personal attributes from text. We construct a dataset consisting of real Reddit profiles, and show that current LLMs can infer a wide range of personal attributes (e.g., location, income, sex), achieving up to $85\\%$ top-1 and $95.8\\%$ top-3 accuracy at a fraction of the cost ($100\\times$) and time ($240\\times$) required by humans. As people increasingly interact with LLM-powered chatbots across all aspects of life, we also explore the emerging threat of privacy-invasive chatbots trying to extract personal information through seemingly benign questions. Finally, we show that common mitigations, i.e., text anonymization and model alignment, are currently ineffective at protecting user privacy against LLM inference. Our findings highlight that current LLMs can infer personal data at a previously unattainable scale. In the absence of working defenses, we advocate for a broader discussion around LLM privacy implications beyond memorization, striving for a wider privacy protection. ",
    "url": "https://arxiv.org/abs/2310.07298",
    "authors": [
      "Robin Staab",
      "Mark Vero",
      "Mislav Balunovi\u0107",
      "Martin Vechev"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07299",
    "title": "RobustGEC: Robust Grammatical Error Correction Against Subtle Context  Perturbation",
    "abstract": "Grammatical Error Correction (GEC) systems play a vital role in assisting people with their daily writing tasks. However, users may sometimes come across a GEC system that initially performs well but fails to correct errors when the inputs are slightly modified. To ensure an ideal user experience, a reliable GEC system should have the ability to provide consistent and accurate suggestions when encountering irrelevant context perturbations, which we refer to as context robustness. In this paper, we introduce RobustGEC, a benchmark designed to evaluate the context robustness of GEC systems. RobustGEC comprises 5,000 GEC cases, each with one original error-correct sentence pair and five variants carefully devised by human annotators. Utilizing RobustGEC, we reveal that state-of-the-art GEC systems still lack sufficient robustness against context perturbations. In addition, we propose a simple yet effective method for remitting this issue. ",
    "url": "https://arxiv.org/abs/2310.07299",
    "authors": [
      "Yue Zhang",
      "Leyang Cui",
      "Enbo Zhao",
      "Wei Bi",
      "Shuming Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07313",
    "title": "Molecule-Edit Templates for Efficient and Accurate Retrosynthesis  Prediction",
    "abstract": "Retrosynthesis involves determining a sequence of reactions to synthesize complex molecules from simpler precursors. As this poses a challenge in organic chemistry, machine learning has offered solutions, particularly for predicting possible reaction substrates for a given target molecule. These solutions mainly fall into template-based and template-free categories. The former is efficient but relies on a vast set of predefined reaction patterns, while the latter, though more flexible, can be computationally intensive and less interpretable. To address these issues, we introduce METRO (Molecule-Edit Templates for RetrOsynthesis), a machine-learning model that predicts reactions using minimal templates - simplified reaction patterns capturing only essential molecular changes - reducing computational overhead and achieving state-of-the-art results on standard benchmarks. ",
    "url": "https://arxiv.org/abs/2310.07313",
    "authors": [
      "Miko\u0142aj Sacha",
      "Micha\u0142 Sadowski",
      "Piotr Kozakowski",
      "Ruard van Workum",
      "Stanis\u0142aw Jastrz\u0119bski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.07325",
    "title": "An Adversarial Example for Direct Logit Attribution: Memory Management  in gelu-4l",
    "abstract": "We provide concrete evidence for memory management in a 4-layer transformer. Specifically, we identify clean-up behavior, in which model components consistently remove the output of preceeding components during a forward pass. Our findings suggest that the interpretability technique Direct Logit Attribution provides misleading results. We show explicit examples where this technique is inaccurate, as it does not account for clean-up behavior. ",
    "url": "https://arxiv.org/abs/2310.07325",
    "authors": [
      "James Dao",
      "Yeu-Tong Lao",
      "Can Rager",
      "Jett Janiak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07327",
    "title": "Code Polymorphism Meets Code Encryption: Confidentiality and  Side-Channel Protection of Software Components",
    "abstract": "In this paper, we consider that, in practice, attack scenarios involving side-channel analysis combine two successive phases:an analysis phase, targeting the extraction of information about the target and the identification of possible vulnerabilities;and an exploitation phase, applying attack techniques on candidate vulnerabilities. We advocate that protections need to coverthese two phases in order to be effective against real-life attacks. We present PolEn, a toolchain and a processor architecturethat combine countermeasures in order to provide an effective mitigation of side-channel attacks: as a countermeasure againstthe analysis phase, our approach considers the use of code encryption; as a countermeasure against the exploitation phase,our approach considers the use of code polymorphism, because it relies on runtime code generation, and its combinationwith code encryption is particularly challenging. Code encryption is supported by a processor extension such that machineinstructions are only decrypted inside the CPU, which effectively prevents reverse engineering or any extraction of usefulinformation from memory dumps. Code polymorphism is implemented by software means. It regularly changes the observablebehaviour of the program, making it unpredictable for an attacker, hence reducing the possibility to exploit side-channelleakages. We present a prototype implementation, based on the RISC-V Spike simulator and a modified LLVM toolchain. Inour experimental evaluation, we illustrate that PolEn effectively reduces side-channel leakages. For the protected functionsevaluated, static memory use increases by a factor of 5 to 22, corresponding to the joint application of code encryption andcode polymorphism. The overhead, in terms of execution time, ranges between a factor of 1.8 and 4.6. ",
    "url": "https://arxiv.org/abs/2310.07327",
    "authors": [
      "Lionel Morel",
      "Damien Courouss\u00e9",
      "Thomas Hiscock"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.07335",
    "title": "Exploring Social Motion Latent Space and Human Awareness for Effective  Robot Navigation in Crowded Environments",
    "abstract": "This work proposes a novel approach to social robot navigation by learning to generate robot controls from a social motion latent space. By leveraging this social motion latent space, the proposed method achieves significant improvements in social navigation metrics such as success rate, navigation time, and trajectory length while producing smoother (less jerk and angular deviations) and more anticipatory trajectories. The superiority of the proposed method is demonstrated through comparison with baseline models in various scenarios. Additionally, the concept of humans' awareness towards the robot is introduced into the social robot navigation framework, showing that incorporating human awareness leads to shorter and smoother trajectories owing to humans' ability to positively interact with the robot. ",
    "url": "https://arxiv.org/abs/2310.07335",
    "authors": [
      "Junaid Ahmed Ansari",
      "Satyajit Tourani",
      "Gourav Kumar",
      "Brojeshwar Bhowmick"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07345",
    "title": "Investigating the Effect of Language Models in Sequence Discriminative  Training for Neural Transducers",
    "abstract": "In this work, we investigate the effect of language models (LMs) with different context lengths and label units (phoneme vs. word) used in sequence discriminative training for phoneme-based neural transducers. Both lattice-free and N-best-list approaches are examined. For lattice-free methods with phoneme-level LMs, we propose a method to approximate the context history to employ LMs with full-context dependency. This approximation can be extended to arbitrary context length and enables the usage of word-level LMs in lattice-free methods. Moreover, a systematic comparison is conducted across lattice-free and N-best-list-based methods. Experimental results on Librispeech show that using the word-level LM in training outperforms the phoneme-level LM. Besides, we find that the context size of the LM used for probability computation has a limited effect on performance. Moreover, our results reveal the pivotal importance of the hypothesis space quality in sequence discriminative training. ",
    "url": "https://arxiv.org/abs/2310.07345",
    "authors": [
      "Zijian Yang",
      "Wei Zhou",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.07346",
    "title": "Preliminary Results of a Scientometric Analysis of the German  Information Retrieval Community 2020-2023",
    "abstract": "The German Information Retrieval community is located in two different sub-fields: Information and computer science. There are no current studies that investigate these communities on a scientometric level. Available studies only focus on the information scientific part of the community. We generated a data set of 401 recent IR-related publications extracted from six core IR conferences from a mainly computer scientific background. We analyze this data set at the institutional and researcher level. The data set is publicly released, and we also demonstrate a mapping use case. ",
    "url": "https://arxiv.org/abs/2310.07346",
    "authors": [
      "Philipp Schaer",
      "Svetlana Myshkina",
      "J\u00fcri Keller"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2310.07348",
    "title": "Semantic Association Rule Learning from Time Series Data and Knowledge  Graphs",
    "abstract": "Digital Twins (DT) are a promising concept in cyber-physical systems research due to their advanced features including monitoring and automated reasoning. Semantic technologies such as Knowledge Graphs (KG) are recently being utilized in DTs especially for information modelling. Building on this move, this paper proposes a pipeline for semantic association rule learning in DTs using KGs and time series data. In addition to this initial pipeline, we also propose new semantic association rule criterion. The approach is evaluated on an industrial water network scenario. Initial evaluation shows that the proposed approach is able to learn a high number of association rules with semantic information which are more generalizable. The paper aims to set a foundation for further work on using semantic association rule learning especially in the context of industrial applications. ",
    "url": "https://arxiv.org/abs/2310.07348",
    "authors": [
      "Erkan Karabulut",
      "Victoria Degeler",
      "Paul Groth"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07351",
    "title": "Atom-Motif Contrastive Transformer for Molecular Property Prediction",
    "abstract": "Recently, Graph Transformer (GT) models have been widely used in the task of Molecular Property Prediction (MPP) due to their high reliability in characterizing the latent relationship among graph nodes (i.e., the atoms in a molecule). However, most existing GT-based methods usually explore the basic interactions between pairwise atoms, and thus they fail to consider the important interactions among critical motifs (e.g., functional groups consisted of several atoms) of molecules. As motifs in a molecule are significant patterns that are of great importance for determining molecular properties (e.g., toxicity and solubility), overlooking motif interactions inevitably hinders the effectiveness of MPP. To address this issue, we propose a novel Atom-Motif Contrastive Transformer (AMCT), which not only explores the atom-level interactions but also considers the motif-level interactions. Since the representations of atoms and motifs for a given molecule are actually two different views of the same instance, they are naturally aligned to generate the self-supervisory signals for model training. Meanwhile, the same motif can exist in different molecules, and hence we also employ the contrastive loss to maximize the representation agreement of identical motifs across different molecules. Finally, in order to clearly identify the motifs that are critical in deciding the properties of each molecule, we further construct a property-aware attention mechanism into our learning framework. Our proposed AMCT is extensively evaluated on seven popular benchmark datasets, and both quantitative and qualitative results firmly demonstrate its effectiveness when compared with the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2310.07351",
    "authors": [
      "Wentao Yu",
      "Shuo Chen",
      "Chen Gong",
      "Gang Niu",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07352",
    "title": "Adaptive Distributionally Robust Planning for Renewable-Powered Fast  Charging Stations Under Decision-Dependent EV Diffusion Uncertainty",
    "abstract": "When deploying fast charging stations (FCSs) to support long-distance trips of electric vehicles (EVs), there exist indirect network effects: while the gradual diffusion of EVs directly influences the timing and capacities of FCS allocation, the decisions for FCS allocations, in turn, impact the drivers' willingness to adopt EVs. This interplay, if neglected, can result in uncovered EVs and security issues on the grid side and even hinder the effective diffusion of EVs. In this paper, we explicitly incorporate this interdependence by quantifying EV adoption rates as decision-dependent uncertainties (DDUs) using decision-dependent ambiguity sets (DDASs). Then, a two-stage decision-dependent distributionally robust FCS planning (D$^3$R-FCSP) model is developed for adaptively deploying FCSs with on-site sources and expanding the coupled distribution network. A multi-period capacitated arc cover-path cover (MCACPC) model is incorporated to capture the EVs' recharging patterns to ensure the feasibility of FCS locations and capacities. To resolve the nonlinearity and nonconvexity, the D$^3$R-FCSP model is equivalently reformulated into a single-level mixed-integer linear programming by exploiting its strong duality and applying the McCormick envelope. Finally, case studies highlight the superior out-of-sample performances of our model in terms of security and cost-efficiency. Furthermore, the byproduct of accelerated EV adoption through an implicit positive feedback loop is highlighted. ",
    "url": "https://arxiv.org/abs/2310.07352",
    "authors": [
      "Yujia Li",
      "Feng Qiu",
      "Chenxi Hu",
      "Yunhe Hou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2310.07354",
    "title": "Give and Take: Federated Transfer Learning for Industrial IoT Network  Intrusion Detection",
    "abstract": "The rapid growth in Internet of Things (IoT) technology has become an integral part of today's industries forming the Industrial IoT (IIoT) initiative, where industries are leveraging IoT to improve communication and connectivity via emerging solutions like data analytics and cloud computing. Unfortunately, the rapid use of IoT has made it an attractive target for cybercriminals. Therefore, protecting these systems is of utmost importance. In this paper, we propose a federated transfer learning (FTL) approach to perform IIoT network intrusion detection. As part of the research, we also propose a combinational neural network as the centerpiece for performing FTL. The proposed technique splits IoT data between the client and server devices to generate corresponding models, and the weights of the client models are combined to update the server model. Results showcase high performance for the FTL setup between iterations on both the IIoT clients and the server. Additionally, the proposed FTL setup achieves better overall performance than contemporary machine learning algorithms at performing network intrusion detection. ",
    "url": "https://arxiv.org/abs/2310.07354",
    "authors": [
      "Lochana Telugu Rajesh",
      "Tapadhir Das",
      "Raj Mani Shukla",
      "Shamik Sengupta"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07365",
    "title": "GraphControl: Adding Conditional Control to Universal Graph Pre-trained  Models for Graph Domain Transfer Learning",
    "abstract": "Graph-structured data is ubiquitous in the world which models complex relationships between objects, enabling various Web applications. Daily influxes of unlabeled graph data on the Web offer immense potential for these applications. Graph self-supervised algorithms have achieved significant success in acquiring generic knowledge from abundant unlabeled graph data. These pre-trained models can be applied to various downstream Web applications, saving training time and improving downstream (target) performance. However, different graphs, even across seemingly similar domains, can differ significantly in terms of attribute semantics, posing difficulties, if not infeasibility, for transferring the pre-trained models to downstream tasks. Concretely speaking, for example, the additional task-specific node information in downstream tasks (specificity) is usually deliberately omitted so that the pre-trained representation (transferability) can be leveraged. The trade-off as such is termed as \"transferability-specificity dilemma\" in this work. To address this challenge, we introduce an innovative deployment module coined as GraphControl, motivated by ControlNet, to realize better graph domain transfer learning. Specifically, by leveraging universal structural pre-trained models and GraphControl, we align the input space across various graphs and incorporate unique characteristics of target data as conditional inputs. These conditions will be progressively integrated into the model during fine-tuning or prompt tuning through ControlNet, facilitating personalized deployment. Extensive experiments show that our method significantly enhances the adaptability of pre-trained models on target attributed datasets, achieving 1.4-3x performance gain. Furthermore, it outperforms training-from-scratch methods on target data with a comparable margin and exhibits faster convergence. ",
    "url": "https://arxiv.org/abs/2310.07365",
    "authors": [
      "Yun Zhu",
      "Yaoke Wang",
      "Haizhou Shi",
      "Zhenshuo Zhang",
      "Siliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07367",
    "title": "Improved Analysis of Sparse Linear Regression in Local Differential  Privacy Model",
    "abstract": "In this paper, we revisit the problem of sparse linear regression in the local differential privacy (LDP) model. Existing research in the non-interactive and sequentially local models has focused on obtaining the lower bounds for the case where the underlying parameter is $1$-sparse, and extending such bounds to the more general $k$-sparse case has proven to be challenging. Moreover, it is unclear whether efficient non-interactive LDP (NLDP) algorithms exist. To address these issues, we first consider the problem in the $\\epsilon$ non-interactive LDP model and provide a lower bound of $\\Omega(\\frac{\\sqrt{dk\\log d}}{\\sqrt{n}\\epsilon})$ on the $\\ell_2$-norm estimation error for sub-Gaussian data, where $n$ is the sample size and $d$ is the dimension of the space. We propose an innovative NLDP algorithm, the very first of its kind for the problem. As a remarkable outcome, this algorithm also yields a novel and highly efficient estimator as a valuable by-product. Our algorithm achieves an upper bound of $\\tilde{O}({\\frac{d\\sqrt{k}}{\\sqrt{n}\\epsilon}})$ for the estimation error when the data is sub-Gaussian, which can be further improved by a factor of $O(\\sqrt{d})$ if the server has additional public but unlabeled data. For the sequentially interactive LDP model, we show a similar lower bound of $\\Omega({\\frac{\\sqrt{dk}}{\\sqrt{n}\\epsilon}})$. As for the upper bound, we rectify a previous method and show that it is possible to achieve a bound of $\\tilde{O}(\\frac{k\\sqrt{d}}{\\sqrt{n}\\epsilon})$. Our findings reveal fundamental differences between the non-private case, central DP model, and local DP model in the sparse linear regression problem. ",
    "url": "https://arxiv.org/abs/2310.07367",
    "authors": [
      "Liyang Zhu",
      "Meng Ding",
      "Vaneet Aggarwal",
      "Jinhui Xu",
      "Di Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07376",
    "title": "Point Cloud Denoising and Outlier Detection with Local Geometric  Structure by Dynamic Graph CNN",
    "abstract": "The digitalization of society is rapidly developing toward the realization of the digital twin and metaverse. In particular, point clouds are attracting attention as a media format for 3D space. Point cloud data is contaminated with noise and outliers due to measurement errors. Therefore, denoising and outlier detection are necessary for point cloud processing. Among them, PointCleanNet is an effective method for point cloud denoising and outlier detection. However, it does not consider the local geometric structure of the patch. We solve this problem by applying two types of graph convolutional layer designed based on the Dynamic Graph CNN. Experimental results show that the proposed methods outperform the conventional method in AUPR, which indicates outlier detection accuracy, and Chamfer Distance, which indicates denoising accuracy. ",
    "url": "https://arxiv.org/abs/2310.07376",
    "authors": [
      "Kosuke Nakayama",
      "Hiroto Fukuta",
      "Hiroshi Watanabe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2310.07379",
    "title": "Causal Unsupervised Semantic Segmentation",
    "abstract": "Unsupervised semantic segmentation aims to achieve high-quality semantic grouping without human-labeled annotations. With the advent of self-supervised pre-training, various frameworks utilize the pre-trained features to train prediction heads for unsupervised dense prediction. However, a significant challenge in this unsupervised setup is determining the appropriate level of clustering required for segmenting concepts. To address it, we propose a novel framework, CAusal Unsupervised Semantic sEgmentation (CAUSE), which leverages insights from causal inference. Specifically, we bridge intervention-oriented approach (i.e., frontdoor adjustment) to define suitable two-step tasks for unsupervised prediction. The first step involves constructing a concept clusterbook as a mediator, which represents possible concept prototypes at different levels of granularity in a discretized form. Then, the mediator establishes an explicit link to the subsequent concept-wise self-supervised learning for pixel-level grouping. Through extensive experiments and analyses on various datasets, we corroborate the effectiveness of CAUSE and achieve state-of-the-art performance in unsupervised semantic segmentation. ",
    "url": "https://arxiv.org/abs/2310.07379",
    "authors": [
      "Junho Kim",
      "Byung-Kwan Lee",
      "Yong Man Ro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07380",
    "title": "Histopathological Image Classification and Vulnerability Analysis using  Federated Learning",
    "abstract": "Healthcare is one of the foremost applications of machine learning (ML). Traditionally, ML models are trained by central servers, which aggregate data from various distributed devices to forecast the results for newly generated data. This is a major concern as models can access sensitive user information, which raises privacy concerns. A federated learning (FL) approach can help address this issue: A global model sends its copy to all clients who train these copies, and the clients send the updates (weights) back to it. Over time, the global model improves and becomes more accurate. Data privacy is protected during training, as it is conducted locally on the clients' devices. However, the global model is susceptible to data poisoning. We develop a privacy-preserving FL technique for a skin cancer dataset and show that the model is prone to data poisoning attacks. Ten clients train the model, but one of them intentionally introduces flipped labels as an attack. This reduces the accuracy of the global model. As the percentage of label flipping increases, there is a noticeable decrease in accuracy. We use a stochastic gradient descent optimization algorithm to find the most optimal accuracy for the model. Although FL can protect user privacy for healthcare diagnostics, it is also vulnerable to data poisoning, which must be addressed. ",
    "url": "https://arxiv.org/abs/2310.07380",
    "authors": [
      "Sankalp Vyas",
      "Amar Nath Patra",
      "Raj Mani Shukla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07402",
    "title": "NuTime: Numerically Multi-Scaled Embedding for Large-Scale Time Series  Pretraining",
    "abstract": "Recent research on time-series self-supervised models shows great promise in learning semantic representations. However, it has been limited to small-scale datasets, e.g., thousands of temporal sequences. In this work, we make key technical contributions that are tailored to the numerical properties of time-series data and allow the model to scale to large datasets, e.g., millions of temporal sequences. We adopt the Transformer architecture by first partitioning the input into non-overlapping windows. Each window is then characterized by its normalized shape and two scalar values denoting the mean and standard deviation within each window. To embed scalar values that may possess arbitrary numerical scales to high-dimensional vectors, we propose a numerically multi-scaled embedding module enumerating all possible scales for the scalar values. The model undergoes pretraining using the proposed numerically multi-scaled embedding with a simple contrastive objective on a large-scale dataset containing over a million sequences. We study its transfer performance on a number of univariate and multivariate classification benchmarks. Our method exhibits remarkable improvement against previous representation learning approaches and establishes the new state of the art, even compared with domain-specific non-learning-based methods. ",
    "url": "https://arxiv.org/abs/2310.07402",
    "authors": [
      "Chenguo Lin",
      "Xumeng Wen",
      "Wei Cao",
      "Congrui Huang",
      "Jiang Bian",
      "Stephen Lin",
      "Zhirong Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07416",
    "title": "A Novel Voronoi-based Convolutional Neural Network Framework for Pushing  Person Detection in Crowd Videos",
    "abstract": "Analyzing the microscopic dynamics of pushing behavior within crowds can offer valuable insights into crowd patterns and interactions. By identifying instances of pushing in crowd videos, a deeper understanding of when, where, and why such behavior occurs can be achieved. This knowledge is crucial to creating more effective crowd management strategies, optimizing crowd flow, and enhancing overall crowd experiences. However, manually identifying pushing behavior at the microscopic level is challenging, and the existing automatic approaches cannot detect such microscopic behavior. Thus, this article introduces a novel automatic framework for identifying pushing in videos of crowds on a microscopic level. The framework comprises two main components: i) Feature extraction and ii) Video labeling. In the feature extraction component, a new Voronoi-based method is developed for determining the local regions associated with each person in the input video. Subsequently, these regions are fed into EfficientNetV1B0 Convolutional Neural Network to extract the deep features of each person over time. In the second component, a combination of a fully connected layer with a Sigmoid activation function is employed to analyze these deep features and annotate the individuals involved in pushing within the video. The framework is trained and evaluated on a new dataset created using six real-world experiments, including their corresponding ground truths. The experimental findings indicate that the suggested framework outperforms seven baseline methods that are employed for comparative analysis purposes. ",
    "url": "https://arxiv.org/abs/2310.07416",
    "authors": [
      "Ahmed Alia",
      "Mohammed Maree",
      "Mohcine Chraibi",
      "Armin Seyfried"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07417",
    "title": "What can knowledge graph alignment gain with Neuro-Symbolic learning  approaches?",
    "abstract": "Knowledge Graphs (KG) are the backbone of many data-intensive applications since they can represent data coupled with its meaning and context. Aligning KGs across different domains and providers is necessary to afford a fuller and integrated representation. A severe limitation of current KG alignment (KGA) algorithms is that they fail to articulate logical thinking and reasoning with lexical, structural, and semantic data learning. Deep learning models are increasingly popular for KGA inspired by their good performance in other tasks, but they suffer from limitations in explainability, reasoning, and data efficiency. Hybrid neurosymbolic learning models hold the promise of integrating logical and data perspectives to produce high-quality alignments that are explainable and support validation through human-centric approaches. This paper examines the current state of the art in KGA and explores the potential for neurosymbolic integration, highlighting promising research directions for combining these fields. ",
    "url": "https://arxiv.org/abs/2310.07417",
    "authors": [
      "Pedro Giesteira Cotovio",
      "Ernesto Jimenez-Ruiz",
      "Catia Pesquita"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Symbolic Computation (cs.SC)"
    ]
  },
  {
    "id": "arXiv:2310.07430",
    "title": "Non-backtracking Graph Neural Networks",
    "abstract": "The celebrated message-passing updates for graph neural networks allow the representation of large-scale graphs with local and computationally tractable updates. However, the local updates suffer from backtracking, i.e., a message flows through the same edge twice and revisits the previously visited node. Since the number of message flows increases exponentially with the number of updates, the redundancy in local updates prevents the graph neural network from accurately recognizing a particular message flow for downstream tasks. In this work, we propose to resolve such a redundancy via the non-backtracking graph neural network (NBA-GNN) that updates a message without incorporating the message from the previously visited node. We further investigate how NBA-GNN alleviates the over-squashing of GNNs, and establish a connection between NBA-GNN and the impressive performance of non-backtracking updates for stochastic block model recovery. We empirically verify the effectiveness of our NBA-GNN on long-range graph benchmark and transductive node classification problems. ",
    "url": "https://arxiv.org/abs/2310.07430",
    "authors": [
      "Seonghyun Park",
      "Narae Ryu",
      "Gahee Kim",
      "Dongyeop Woo",
      "Se-Young Yun",
      "Sungsoo Ahn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.07431",
    "title": "Robust Adaptive Compensation of External Disturbances for Multi-Channel  Linear Systems",
    "abstract": "This paper proposes a new algorithm for compensating external disturbances for class of multi-channel linear systems. The solution to this problem is based on the use of the internal model principle and the extended error adaptation algorithm. It is assumed that the disturbance is the output of an autonomous linear generator with unknown parameters. At the first stage, a full-order observer with unknown input signals (Unknown Input Observer - UIO) is synthesized to solve the problem of estimating the state vector of this plant. Then a new observer of external disturbance is formed on the basis of state vector estimations. At the last stage, based on the new observer's estimations, a system with an extended state vector is formed for which a regulator providing compensation of disturbance is constructed. The performance of the obtained results is confirmed using computer simulation in MATLAB Simulink. ",
    "url": "https://arxiv.org/abs/2310.07431",
    "authors": [
      "V.H. Bui",
      "A.A. Margun"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.07438",
    "title": "DESTINE: Dynamic Goal Queries with Temporal Transductive Alignment for  Trajectory Prediction",
    "abstract": "Predicting temporally consistent road users' trajectories in a multi-agent setting is a challenging task due to unknown characteristics of agents and their varying intentions. Besides using semantic map information and modeling interactions, it is important to build an effective mechanism capable of reasoning about behaviors at different levels of granularity. To this end, we propose Dynamic goal quErieS with temporal Transductive alIgNmEnt (DESTINE) method. Unlike past arts, our approach 1) dynamically predicts agents' goals irrespective of particular road structures, such as lanes, allowing the method to produce a more accurate estimation of destinations; 2) achieves map compliant predictions by generating future trajectories in a coarse-to-fine fashion, where the coarser predictions at a lower frame rate serve as intermediate goals; and 3) uses an attention module designed to temporally align predicted trajectories via masked attention. Using the common Argoverse benchmark dataset, we show that our method achieves state-of-the-art performance on various metrics, and further investigate the contributions of proposed modules via comprehensive ablation studies. ",
    "url": "https://arxiv.org/abs/2310.07438",
    "authors": [
      "Rezaul Karim",
      "Soheil Mohamad Alizadeh Shabestary",
      "Amir Rasouli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.07440",
    "title": "Distance-based Weighted Transformer Network for Image Completion",
    "abstract": "The challenge of image generation has been effectively modeled as a problem of structure priors or transformation. However, existing models have unsatisfactory performance in understanding the global input image structures because of particular inherent features (for example, local inductive prior). Recent studies have shown that self-attention is an efficient modeling technique for image completion problems. In this paper, we propose a new architecture that relies on Distance-based Weighted Transformer (DWT) to better understand the relationships between an image's components. In our model, we leverage the strengths of both Convolutional Neural Networks (CNNs) and DWT blocks to enhance the image completion process. Specifically, CNNs are used to augment the local texture information of coarse priors and DWT blocks are used to recover certain coarse textures and coherent visual structures. Unlike current approaches that generally use CNNs to create feature maps, we use the DWT to encode global dependencies and compute distance-based weighted feature maps, which substantially minimizes the problem of visual ambiguities. Meanwhile, to better produce repeated textures, we introduce Residual Fast Fourier Convolution (Res-FFC) blocks to combine the encoder's skip features with the coarse features provided by our generator. Furthermore, a simple yet effective technique is proposed to normalize the non-zero values of convolutions, and fine-tune the network layers for regularization of the gradient norms to provide an efficient training stabiliser. Extensive quantitative and qualitative experiments on three challenging datasets demonstrate the superiority of our proposed model compared to existing approaches. ",
    "url": "https://arxiv.org/abs/2310.07440",
    "authors": [
      "Pourya Shamsolmoali",
      "Masoumeh Zareapoor",
      "Huiyu Zhou",
      "Xuelong Li",
      "Yue Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07449",
    "title": "PoRF: Pose Residual Field for Accurate Neural Surface Reconstruction",
    "abstract": "Neural surface reconstruction is sensitive to the camera pose noise, even if state-of-the-art pose estimators like COLMAP or ARKit are used. More importantly, existing Pose-NeRF joint optimisation methods have struggled to improve pose accuracy in challenging real-world scenarios. To overcome the challenges, we introduce the pose residual field (\\textbf{PoRF}), a novel implicit representation that uses an MLP for regressing pose updates. This is more robust than the conventional pose parameter optimisation due to parameter sharing that leverages global information over the entire sequence. Furthermore, we propose an epipolar geometry loss to enhance the supervision that leverages the correspondences exported from COLMAP results without the extra computational overhead. Our method yields promising results. On the DTU dataset, we reduce the rotation error by 78\\% for COLMAP poses, leading to the decreased reconstruction Chamfer distance from 3.48mm to 0.85mm. On the MobileBrick dataset that contains casually captured unbounded 360-degree videos, our method refines ARKit poses and improves the reconstruction F1 score from 69.18 to 75.67, outperforming that with the dataset provided ground-truth pose (75.14). These achievements demonstrate the efficacy of our approach in refining camera poses and improving the accuracy of neural surface reconstruction in real-world scenarios. ",
    "url": "https://arxiv.org/abs/2310.07449",
    "authors": [
      "Jia-Wang Bian",
      "Wenjing Bian",
      "Victor Adrian Prisacariu",
      "Philip Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07467",
    "title": "AI/ML-based Load Prediction in IEEE 802.11 Enterprise Networks",
    "abstract": "Enterprise Wi-Fi networks can greatly benefit from Artificial Intelligence and Machine Learning (AI/ML) thanks to their well-developed management and operation capabilities. At the same time, AI/ML-based traffic/load prediction is one of the most appealing data-driven solutions to improve the Wi-Fi experience, either through the enablement of autonomous operation or by boosting troubleshooting with forecasted network utilization. In this paper, we study the suitability and feasibility of adopting AI/ML-based load prediction in practical enterprise Wi-Fi networks. While leveraging AI/ML solutions can potentially contribute to optimizing Wi-Fi networks in terms of energy efficiency, performance, and reliability, their effective adoption is constrained to aspects like data availability and quality, computational capabilities, and energy consumption. Our results show that hardware-constrained AI/ML models can potentially predict network load with less than 20% average error and 3% 85th-percentile error, which constitutes a suitable input for proactively driving Wi-Fi network optimization. ",
    "url": "https://arxiv.org/abs/2310.07467",
    "authors": [
      "Francesc Wilhelmi",
      "Dariush Salami",
      "Gianluca Fontanesi",
      "Lorenzo Galati-Giordano",
      "Mika Kasslin"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.07478",
    "title": "Multimodal Graph Learning for Generative Tasks",
    "abstract": "Multimodal learning combines multiple data modalities, broadening the types and complexity of data our models can utilize: for example, from plain text to image-caption pairs. Most multimodal learning algorithms focus on modeling simple one-to-one pairs of data from two modalities, such as image-caption pairs, or audio-text pairs. However, in most real-world settings, entities of different modalities interact with each other in more complex and multifaceted ways, going beyond one-to-one mappings. We propose to represent these complex relationships as graphs, allowing us to capture data with any number of modalities, and with complex relationships between modalities that can flexibly vary from one sample to another. Toward this goal, we propose Multimodal Graph Learning (MMGL), a general and systematic framework for capturing information from multiple multimodal neighbors with relational structures among them. In particular, we focus on MMGL for generative tasks, building upon pretrained Language Models (LMs), aiming to augment their text generation with multimodal neighbor contexts. We study three research questions raised by MMGL: (1) how can we infuse multiple neighbor information into the pretrained LMs, while avoiding scalability issues? (2) how can we infuse the graph structure information among multimodal neighbors into the LMs? and (3) how can we finetune the pretrained LMs to learn from the neighbor context in a parameter-efficient manner? We conduct extensive experiments to answer these three questions on MMGL and analyze the empirical results to pave the way for future MMGL research. ",
    "url": "https://arxiv.org/abs/2310.07478",
    "authors": [
      "Minji Yoon",
      "Jing Yu Koh",
      "Bryan Hooi",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07485",
    "title": "Nonlinear embeddings for conserving Hamiltonians and other quantities  with Neural Galerkin schemes",
    "abstract": "This work focuses on the conservation of quantities such as Hamiltonians, mass, and momentum when solution fields of partial differential equations are approximated with nonlinear parametrizations such as deep networks. The proposed approach builds on Neural Galerkin schemes that are based on the Dirac--Frenkel variational principle to train nonlinear parametrizations sequentially in time. We first show that only adding constraints that aim to conserve quantities in continuous time can be insufficient because the nonlinear dependence on the parameters implies that even quantities that are linear in the solution fields become nonlinear in the parameters and thus are challenging to discretize in time. Instead, we propose Neural Galerkin schemes that compute at each time step an explicit embedding onto the manifold of nonlinearly parametrized solution fields to guarantee conservation of quantities. The embeddings can be combined with standard explicit and implicit time integration schemes. Numerical experiments demonstrate that the proposed approach conserves quantities up to machine precision. ",
    "url": "https://arxiv.org/abs/2310.07485",
    "authors": [
      "Paul Schwerdtner",
      "Philipp Schulze",
      "Jules Berman",
      "Benjamin Peherstorfer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07487",
    "title": "Cognate Transformer for Automated Phonological Reconstruction and  Cognate Reflex Prediction",
    "abstract": "Phonological reconstruction is one of the central problems in historical linguistics where a proto-word of an ancestral language is determined from the observed cognate words of daughter languages. Computational approaches to historical linguistics attempt to automate the task by learning models on available linguistic data. Several ideas and techniques drawn from computational biology have been successfully applied in the area of computational historical linguistics. Following these lines, we adapt MSA Transformer, a protein language model, to the problem of automated phonological reconstruction. MSA Transformer trains on multiple sequence alignments as input and is, thus, apt for application on aligned cognate words. We, hence, name our model as Cognate Transformer. We also apply the model on another associated task, namely, cognate reflex prediction, where a reflex word in a daughter language is predicted based on cognate words from other daughter languages. We show that our model outperforms the existing models on both tasks, especially when it is pre-trained on masked word prediction task. ",
    "url": "https://arxiv.org/abs/2310.07487",
    "authors": [
      "V.S.D.S. Mahesh Akavarapu",
      "Arnab Bhattacharya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.07492",
    "title": "Boosting Black-box Attack to Deep Neural Networks with Conditional  Diffusion Models",
    "abstract": "Existing black-box attacks have demonstrated promising potential in creating adversarial examples (AE) to deceive deep learning models. Most of these attacks need to handle a vast optimization space and require a large number of queries, hence exhibiting limited practical impacts in real-world scenarios. In this paper, we propose a novel black-box attack strategy, Conditional Diffusion Model Attack (CDMA), to improve the query efficiency of generating AEs under query-limited situations. The key insight of CDMA is to formulate the task of AE synthesis as a distribution transformation problem, i.e., benign examples and their corresponding AEs can be regarded as coming from two distinctive distributions and can transform from each other with a particular converter. Unlike the conventional \\textit{query-and-optimization} approach, we generate eligible AEs with direct conditional transform using the aforementioned data converter, which can significantly reduce the number of queries needed. CDMA adopts the conditional Denoising Diffusion Probabilistic Model as the converter, which can learn the transformation from clean samples to AEs, and ensure the smooth development of perturbed noise resistant to various defense strategies. We demonstrate the effectiveness and efficiency of CDMA by comparing it with nine state-of-the-art black-box attacks across three benchmark datasets. On average, CDMA can reduce the query count to a handful of times; in most cases, the query count is only ONE. We also show that CDMA can obtain $>99\\%$ attack success rate for untarget attacks over all datasets and targeted attack over CIFAR-10 with the noise budget of $\\epsilon=16$. ",
    "url": "https://arxiv.org/abs/2310.07492",
    "authors": [
      "Renyang Liu",
      "Wei Zhou",
      "Tianwei Zhang",
      "Kangjie Chen",
      "Jun Zhao",
      "Kwok-Yan Lam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07510",
    "title": "Heuristic Vision Pre-Training with Self-Supervised and Supervised  Multi-Task Learning",
    "abstract": "To mimic human vision with the way of recognizing the diverse and open world, foundation vision models are much critical. While recent techniques of self-supervised learning show the promising potentiality of this mission, we argue that signals from labelled data are also important for common-sense recognition, and properly chosen pre-text tasks can facilitate the efficiency of vision representation learning. To this end, we propose a novel pre-training framework by adopting both self-supervised and supervised visual pre-text tasks in a multi-task manner. Specifically, given an image, we take a heuristic way by considering its intrinsic style properties, inside objects with their locations and correlations, and how it looks like in 3D space for basic visual understanding. However, large-scale object bounding boxes and correlations are usually hard to achieve. Alternatively, we develop a hybrid method by leveraging both multi-label classification and self-supervised learning. On the one hand, under the multi-label supervision, the pre-trained model can explore the detailed information of an image, e.g., image types, objects, and part of semantic relations. On the other hand, self-supervised learning tasks, with respect to Masked Image Modeling (MIM) and contrastive learning, can help the model learn pixel details and patch correlations. Results show that our pre-trained models can deliver results on par with or better than state-of-the-art (SOTA) results on multiple visual tasks. For example, with a vanilla Swin-B backbone, we achieve 85.3\\% top-1 accuracy on ImageNet-1K classification, 47.9 box AP on COCO object detection for Mask R-CNN, and 50.6 mIoU on ADE-20K semantic segmentation when using Upernet. The performance shows the ability of our vision foundation model to serve general purpose vision tasks. ",
    "url": "https://arxiv.org/abs/2310.07510",
    "authors": [
      "Zhiming Qian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07516",
    "title": "Energy Estimates Across Layers of Computing: From Devices to Large-Scale  Applications in Machine Learning for Natural Language Processing, Scientific  Computing, and Cryptocurrency Mining",
    "abstract": "Estimates of energy usage in layers of computing from devices to algorithms have been determined and analyzed. Building on the previous analysis [3], energy needed from single devices and systems including three large-scale computing applications such as Artificial Intelligence (AI)/Machine Learning for Natural Language Processing, Scientific Simulations, and Cryptocurrency Mining have been estimated. In contrast to the bit-level switching, in which transistors achieved energy efficiency due to geometrical scaling, higher energy is expended both at the at the instructions and simulations levels of an application. Additionally, the analysis based on AI/ML Accelerators indicate that changes in architectures using an older semiconductor technology node have comparable energy efficiency with a different architecture using a newer technology. Further comparisons of the energy in computing systems with the thermodynamic and biological limits, indicate that there is a 27-36 orders of magnitude higher energy requirements for total simulation of an application. These energy estimates underscore the need for serious considerations of energy efficiency in computing by including energy as a design parameter, enabling growing needs of compute-intensive applications in a digital world. ",
    "url": "https://arxiv.org/abs/2310.07516",
    "authors": [
      "Sadasivan Shankar"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07518",
    "title": "Exploiting Causal Graph Priors with Posterior Sampling for Reinforcement  Learning",
    "abstract": "Posterior sampling allows the exploitation of prior knowledge of the environment's transition dynamics to improve the sample efficiency of reinforcement learning. The prior is typically specified as a class of parametric distributions, a task that can be cumbersome in practice, often resulting in the choice of uninformative priors. In this work, we propose a novel posterior sampling approach in which the prior is given as a (partial) causal graph over the environment's variables. The latter is often more natural to design, such as listing known causal dependencies between biometric features in a medical treatment study. Specifically, we propose a hierarchical Bayesian procedure, called C-PSRL, simultaneously learning the full causal graph at the higher level and the parameters of the resulting factored dynamics at the lower level. For this procedure, we provide an analysis of its Bayesian regret, which explicitly connects the regret rate with the degree of prior knowledge. Our numerical evaluation conducted in illustrative domains confirms that C-PSRL strongly improves the efficiency of posterior sampling with an uninformative prior while performing close to posterior sampling with the full causal graph. ",
    "url": "https://arxiv.org/abs/2310.07518",
    "authors": [
      "Mirco Mutti",
      "Riccardo De Santi",
      "Marcello Restelli",
      "Alexander Marx",
      "Giorgia Ramponi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07522",
    "title": "S4C: Self-Supervised Semantic Scene Completion with Neural Fields",
    "abstract": "3D semantic scene understanding is a fundamental challenge in computer vision. It enables mobile agents to autonomously plan and navigate arbitrary environments. SSC formalizes this challenge as jointly estimating dense geometry and semantic information from sparse observations of a scene. Current methods for SSC are generally trained on 3D ground truth based on aggregated LiDAR scans. This process relies on special sensors and annotation by hand which are costly and do not scale well. To overcome this issue, our work presents the first self-supervised approach to SSC called S4C that does not rely on 3D ground truth data. Our proposed method can reconstruct a scene from a single image and only relies on videos and pseudo segmentation ground truth generated from off-the-shelf image segmentation network during training. Unlike existing methods, which use discrete voxel grids, we represent scenes as implicit semantic fields. This formulation allows querying any point within the camera frustum for occupancy and semantic class. Our architecture is trained through rendering-based self-supervised losses. Nonetheless, our method achieves performance close to fully supervised state-of-the-art methods. Additionally, our method demonstrates strong generalization capabilities and can synthesize accurate segmentation maps for far away viewpoints. ",
    "url": "https://arxiv.org/abs/2310.07522",
    "authors": [
      "Adrian Hayler",
      "Felix Wimbauer",
      "Dominik Muhle",
      "Christian Rupprecht",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07526",
    "title": "Interaction-aware Traffic Prediction and Scenario-based Model Predictive  Control for Autonomous Vehicles on Highways",
    "abstract": "This paper addresses the problem of traffic prediction and control of autonomous vehicles on highways. A modified Interacting Multiple Model Kalman filter algorithm is applied to predict the motion behavior of the traffic participants by considering their interactions. A scenario generation component is used to produce plausible scenarios of the vehicles based on the predicted information. A novel integrated decision-making and control system is proposed by applying a Scenario-based Model Predictive Control approach. The designed controller considers safety, driving comfort, and traffic rules. The recursive feasibility of the controller is guaranteed under the inclusion of the `worst case' as an additional scenario to obtain safe inputs. Finally, the proposed scheme is evaluated using the HighD dataset. Simulation results indicate that the vehicle performs safe maneuvers in different traffic situations under the designed control framework. ",
    "url": "https://arxiv.org/abs/2310.07526",
    "authors": [
      "Xiaorong Zhang",
      "Sahar Zeinali",
      "Georg Schildbach"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.07545",
    "title": "Generative Agent-Based Social Networks for Disinformation: Research  Opportunities and Open Challenges",
    "abstract": "This article presents the affordances that Generative Artificial Intelligence can have in disinformation context, one of the major threats to our digitalized society. We present a research framework to generate customized agent-based social networks for disinformation simulations that would enable understanding and evaluation of the phenomena whilst discussing open challenges. ",
    "url": "https://arxiv.org/abs/2310.07545",
    "authors": [
      "Javier Pastor-Galindo",
      "Pantaleone Nespoli",
      "Jos\u00e9 A. Ruip\u00e9rez-Valiente"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2310.07548",
    "title": "Attribute Localization and Revision Network for Zero-Shot Learning",
    "abstract": "Zero-shot learning enables the model to recognize unseen categories with the aid of auxiliary semantic information such as attributes. Current works proposed to detect attributes from local image regions and align extracted features with class-level semantics. In this paper, we find that the choice between local and global features is not a zero-sum game, global features can also contribute to the understanding of attributes. In addition, aligning attribute features with class-level semantics ignores potential intra-class attribute variation. To mitigate these disadvantages, we present Attribute Localization and Revision Network in this paper. First, we design Attribute Localization Module (ALM) to capture both local and global features from image regions, a novel module called Scale Control Unit is incorporated to fuse global and local representations. Second, we propose Attribute Revision Module (ARM), which generates image-level semantics by revising the ground-truth value of each attribute, compensating for performance degradation caused by ignoring intra-class variation. Finally, the output of ALM will be aligned with revised semantics produced by ARM to achieve the training process. Comprehensive experimental results on three widely used benchmarks demonstrate the effectiveness of our model in the zero-shot prediction task. ",
    "url": "https://arxiv.org/abs/2310.07548",
    "authors": [
      "Junzhe Xu",
      "Suling Duan",
      "Chenwei Tang",
      "Zhenan He",
      "Jiancheng Lv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07573",
    "title": "Relational Prior Knowledge Graphs for Detection and Instance  Segmentation",
    "abstract": "Humans have a remarkable ability to perceive and reason about the world around them by understanding the relationships between objects. In this paper, we investigate the effectiveness of using such relationships for object detection and instance segmentation. To this end, we propose a Relational Prior-based Feature Enhancement Model (RP-FEM), a graph transformer that enhances object proposal features using relational priors. The proposed architecture operates on top of scene graphs obtained from initial proposals and aims to concurrently learn relational context modeling for object detection and instance segmentation. Experimental evaluations on COCO show that the utilization of scene graphs, augmented with relational priors, offer benefits for object detection and instance segmentation. RP-FEM demonstrates its capacity to suppress improbable class predictions within the image while also preventing the model from generating duplicate predictions, leading to improvements over the baseline model on which it is built. ",
    "url": "https://arxiv.org/abs/2310.07573",
    "authors": [
      "Osman \u00dclger",
      "Yu Wang",
      "Ysbrand Galama",
      "Sezer Karaoglu",
      "Theo Gevers",
      "Martin R. Oswald"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07585",
    "title": "A Discrepancy Aware Framework for Robust Anomaly Detection",
    "abstract": "Defect detection is a critical research area in artificial intelligence. Recently, synthetic data-based self-supervised learning has shown great potential on this task. Although many sophisticated synthesizing strategies exist, little research has been done to investigate the robustness of models when faced with different strategies. In this paper, we focus on this issue and find that existing methods are highly sensitive to them. To alleviate this issue, we present a Discrepancy Aware Framework (DAF), which demonstrates robust performance consistently with simple and cheap strategies across different anomaly detection benchmarks. We hypothesize that the high sensitivity to synthetic data of existing self-supervised methods arises from their heavy reliance on the visual appearance of synthetic data during decoding. In contrast, our method leverages an appearance-agnostic cue to guide the decoder in identifying defects, thereby alleviating its reliance on synthetic appearance. To this end, inspired by existing knowledge distillation methods, we employ a teacher-student network, which is trained based on synthesized outliers, to compute the discrepancy map as the cue. Extensive experiments on two challenging datasets prove the robustness of our method. Under the simple synthesis strategies, it outperforms existing methods by a large margin. Furthermore, it also achieves the state-of-the-art localization performance. Code is available at: https://github.com/caiyuxuan1120/DAF. ",
    "url": "https://arxiv.org/abs/2310.07585",
    "authors": [
      "Yuxuan Cai",
      "Dingkang Liang",
      "Dongliang Luo",
      "Xinwei He",
      "Xin Yang",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07588",
    "title": "Accurate Use of Label Dependency in Multi-Label Text Classification  Through the Lens of Causality",
    "abstract": "Multi-Label Text Classification (MLTC) aims to assign the most relevant labels to each given text. Existing methods demonstrate that label dependency can help to improve the model's performance. However, the introduction of label dependency may cause the model to suffer from unwanted prediction bias. In this study, we attribute the bias to the model's misuse of label dependency, i.e., the model tends to utilize the correlation shortcut in label dependency rather than fusing text information and label dependency for prediction. Motivated by causal inference, we propose a CounterFactual Text Classifier (CFTC) to eliminate the correlation bias, and make causality-based predictions. Specifically, our CFTC first adopts the predict-then-modify backbone to extract precise label information embedded in label dependency, then blocks the correlation shortcut through the counterfactual de-bias technique with the help of the human causal graph. Experimental results on three datasets demonstrate that our CFTC significantly outperforms the baselines and effectively eliminates the correlation bias in datasets. ",
    "url": "https://arxiv.org/abs/2310.07588",
    "authors": [
      "Caoyun Fan",
      "Wenqing Chen",
      "Jidong Tian",
      "Yitian Li",
      "Hao He",
      "Yaohui Jin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07598",
    "title": "Survey on Imbalanced Data, Representation Learning and SEP Forecasting",
    "abstract": "Deep Learning methods have significantly advanced various data-driven tasks such as regression, classification, and forecasting. However, much of this progress has been predicated on the strong but often unrealistic assumption that training datasets are balanced with respect to the targets they contain. This misalignment with real-world conditions, where data is frequently imbalanced, hampers the effectiveness of such models in practical applications. Methods that reconsider that assumption and tackle real-world imbalances have begun to emerge and explore avenues to address this challenge. One such promising avenue is representation learning, which enables models to capture complex data characteristics and generalize better to minority classes. By focusing on a richer representation of the feature space, these techniques hold the potential to mitigate the impact of data imbalance. In this survey, we present deep learning works that step away from the balanced-data assumption, employing strategies like representation learning to better approximate real-world imbalances. We also highlight a critical application in SEP forecasting where addressing data imbalance is paramount for success. ",
    "url": "https://arxiv.org/abs/2310.07598",
    "authors": [
      "Josias Moukpe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07612",
    "title": "PHYDI: Initializing Parameterized Hypercomplex Neural Networks as  Identity Functions",
    "abstract": "Neural models based on hypercomplex algebra systems are growing and prolificating for a plethora of applications, ranging from computer vision to natural language processing. Hand in hand with their adoption, parameterized hypercomplex neural networks (PHNNs) are growing in size and no techniques have been adopted so far to control their convergence at a large scale. In this paper, we study PHNNs convergence and propose parameterized hypercomplex identity initialization (PHYDI), a method to improve their convergence at different scales, leading to more robust performance when the number of layers scales up, while also reaching the same performance with fewer iterations. We show the effectiveness of this approach in different benchmarks and with common PHNNs with ResNets- and Transformer-based architecture. The code is available at https://github.com/ispamm/PHYDI. ",
    "url": "https://arxiv.org/abs/2310.07612",
    "authors": [
      "Matteo Mancanelli",
      "Eleonora Grassucci",
      "Aurelio Uncini",
      "Danilo Comminiello"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2310.07613",
    "title": "Reinforcement Learning-based Knowledge Graph Reasoning for Explainable  Fact-checking",
    "abstract": "Fact-checking is a crucial task as it ensures the prevention of misinformation. However, manual fact-checking cannot keep up with the rate at which false information is generated and disseminated online. Automated fact-checking by machines is significantly quicker than by humans. But for better trust and transparency of these automated systems, explainability in the fact-checking process is necessary. Fact-checking often entails contrasting a factual assertion with a body of knowledge for such explanations. An effective way of representing knowledge is the Knowledge Graph (KG). There have been sufficient works proposed related to fact-checking with the usage of KG but not much focus is given to the application of reinforcement learning (RL) in such cases. To mitigate this gap, we propose an RL-based KG reasoning approach for explainable fact-checking. Extensive experiments on FB15K-277 and NELL-995 datasets reveal that reasoning over a KG is an effective way of producing human-readable explanations in the form of paths and classifications for fact claims. The RL reasoning agent computes a path that either proves or disproves a factual claim, but does not provide a verdict itself. A verdict is reached by a voting mechanism that utilizes paths produced by the agent. These paths can be presented to human readers so that they themselves can decide whether or not the provided evidence is convincing or not. This work will encourage works in this direction for incorporating RL for explainable fact-checking as it increases trustworthiness by providing a human-in-the-loop approach. ",
    "url": "https://arxiv.org/abs/2310.07613",
    "authors": [
      "Gustav Nikopensius",
      "Mohit Mayank",
      "Orchid Chetia Phukan",
      "Rajesh Sharma"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.07631",
    "title": "Graph Transformer Network for Flood Forecasting with Heterogeneous  Covariates",
    "abstract": "Floods can be very destructive causing heavy damage to life, property, and livelihoods. Global climate change and the consequent sea-level rise have increased the occurrence of extreme weather events, resulting in elevated and frequent flood risk. Therefore, accurate and timely flood forecasting in coastal river systems is critical to facilitate good flood management. However, the computational tools currently used are either slow or inaccurate. In this paper, we propose a Flood prediction tool using Graph Transformer Network (FloodGTN) for river systems. More specifically, FloodGTN learns the spatio-temporal dependencies of water levels at different monitoring stations using Graph Neural Networks (GNNs) and an LSTM. It is currently implemented to consider external covariates such as rainfall, tide, and the settings of hydraulic structures (e.g., outflows of dams, gates, pumps, etc.) along the river. We use a Transformer to learn the attention given to external covariates in computing water levels. We apply the FloodGTN tool to data from the South Florida Water Management District, which manages a coastal area prone to frequent storms and hurricanes. Experimental results show that FloodGTN outperforms the physics-based model (HEC-RAS) by achieving higher accuracy with 70% improvement while speeding up run times by at least 500x. ",
    "url": "https://arxiv.org/abs/2310.07631",
    "authors": [
      "Jimeng Shi",
      "Vitalii Stebliankin",
      "Zhaonan Wang",
      "Shaowen Wang",
      "Giri Narasimhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07638",
    "title": "Context-Enhanced Detector For Building Detection From Remote Sensing  Images",
    "abstract": "The field of building detection from remote sensing images has made significant progress, but faces challenges in achieving high-accuracy detection due to the diversity in building appearances and the complexity of vast scenes. To address these challenges, we propose a novel approach called Context-Enhanced Detector (CEDet). Our approach utilizes a three-stage cascade structure to enhance the extraction of contextual information and improve building detection accuracy. Specifically, we introduce two modules: the Semantic Guided Contextual Mining (SGCM) module, which aggregates multi-scale contexts and incorporates an attention mechanism to capture long-range interactions, and the Instance Context Mining Module (ICMM), which captures instance-level relationship context by constructing a spatial relationship graph and aggregating instance features. Additionally, we introduce a semantic segmentation loss based on pseudo-masks to guide contextual information extraction. Our method achieves state-of-the-art performance on three building detection benchmarks, including CNBuilding-9P, CNBuilding-23P, and SpaceNet. ",
    "url": "https://arxiv.org/abs/2310.07638",
    "authors": [
      "Ziyue Huang",
      "Mingming Zhang",
      "Qingjie Liu",
      "Wei Wang",
      "Zhe Dong",
      "Yunhong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07649",
    "title": "Automated Layout Design and Control of Robust Cooperative Grasped-Load  Aerial Transportation Systems",
    "abstract": "We present a novel approach to cooperative aerial transportation through a team of drones, using optimal control theory and a hierarchical control strategy. We assume the drones are connected to the payload through rigid attachments, essentially transforming the whole system into a larger flying object with \"thrust modules\" at the attachment locations of the drones. We investigate the optimal arrangement of the thrust modules around the payload, so that the resulting system is robust to disturbances. We choose the $\\mathcal{H}_2$ norm as a measure of robustness, and propose an iterative optimization routine to compute the optimal layout of the vehicles around the object. We experimentally validate our approach using four drones and comparing the disturbance rejection performances achieved by two different layouts (the optimal one and a sub-optimal one), and observe that the results match our predictions. ",
    "url": "https://arxiv.org/abs/2310.07649",
    "authors": [
      "Carlo Bosio",
      "Jerry Tang",
      "Ting-Hao Wang",
      "Mark W. Mueller"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.07654",
    "title": "Audio-Visual Neural Syntax Acquisition",
    "abstract": "We study phrase structure induction from visually-grounded speech. The core idea is to first segment the speech waveform into sequences of word segments, and subsequently induce phrase structure using the inferred segment-level continuous representations. We present the Audio-Visual Neural Syntax Learner (AV-NSL) that learns phrase structure by listening to audio and looking at images, without ever being exposed to text. By training on paired images and spoken captions, AV-NSL exhibits the capability to infer meaningful phrase structures that are comparable to those derived by naturally-supervised text parsers, for both English and German. Our findings extend prior work in unsupervised language acquisition from speech and grounded grammar induction, and present one approach to bridge the gap between the two topics. ",
    "url": "https://arxiv.org/abs/2310.07654",
    "authors": [
      "Cheng-I Jeff Lai",
      "Freda Shi",
      "Puyuan Peng",
      "Yoon Kim",
      "Kevin Gimpel",
      "Shiyu Chang",
      "Yung-Sung Chuang",
      "Saurabhchand Bhati",
      "David Cox",
      "David Harwath",
      "Yang Zhang",
      "Karen Livescu",
      "James Glass"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.07664",
    "title": "Accelerating Vision Transformers Based on Heterogeneous Attention  Patterns",
    "abstract": "Recently, Vision Transformers (ViTs) have attracted a lot of attention in the field of computer vision. Generally, the powerful representative capacity of ViTs mainly benefits from the self-attention mechanism, which has a high computation complexity. To accelerate ViTs, we propose an integrated compression pipeline based on observed heterogeneous attention patterns across layers. On one hand, different images share more similar attention patterns in early layers than later layers, indicating that the dynamic query-by-key self-attention matrix may be replaced with a static self-attention matrix in early layers. Then, we propose a dynamic-guided static self-attention (DGSSA) method where the matrix inherits self-attention information from the replaced dynamic self-attention to effectively improve the feature representation ability of ViTs. On the other hand, the attention maps have more low-rank patterns, which reflect token redundancy, in later layers than early layers. In a view of linear dimension reduction, we further propose a method of global aggregation pyramid (GLAD) to reduce the number of tokens in later layers of ViTs, such as Deit. Experimentally, the integrated compression pipeline of DGSSA and GLAD can accelerate up to 121% run-time throughput compared with DeiT, which surpasses all SOTA approaches. ",
    "url": "https://arxiv.org/abs/2310.07664",
    "authors": [
      "Deli Yu",
      "Teng Xi",
      "Jianwei Li",
      "Baopu Li",
      "Gang Zhang",
      "Haocheng Feng",
      "Junyu Han",
      "Jingtuo Liu",
      "Errui Ding",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07668",
    "title": "GRaMuFeN: Graph-based Multi-modal Fake News Detection in Social Media",
    "abstract": "The proliferation of social media platforms such as Twitter, Instagram, and Weibo has significantly enhanced the dissemination of false information. This phenomenon grants both individuals and governmental entities the ability to shape public opinions, highlighting the need for deploying effective detection methods. In this paper, we propose GraMuFeN, a model designed to detect fake content by analyzing both the textual and image content of news. GraMuFeN comprises two primary components: a text encoder and an image encoder. For textual analysis, GraMuFeN treats each text as a graph and employs a Graph Convolutional Neural Network (GCN) as the text encoder. Additionally, the pre-trained ResNet-152, as a Convolutional Neural Network (CNN), has been utilized as the image encoder. By integrating the outputs from these two encoders and implementing a contrastive similarity loss function, GraMuFeN achieves remarkable results. Extensive evaluations conducted on two publicly available benchmark datasets for social media news indicate a 10 % increase in micro F1-Score, signifying improvement over existing state-of-the-art models. These findings underscore the effectiveness of combining GCN and CNN models for detecting fake news in multi-modal data, all while minimizing the additional computational burden imposed by model parameters. ",
    "url": "https://arxiv.org/abs/2310.07668",
    "authors": [
      "Makan Kananian",
      "Fatima Badiei",
      "S. AmirAli Gh. Ghahramani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07669",
    "title": "HaarNet: Large-scale Linear-Morphological Hybrid Network for RGB-D  Semantic Segmentation",
    "abstract": "Signals from different modalities each have their own combination algebra which affects their sampling processing. RGB is mostly linear; depth is a geometric signal following the operations of mathematical morphology. If a network obtaining RGB-D input has both kinds of operators available in its layers, it should be able to give effective output with fewer parameters. In this paper, morphological elements in conjunction with more familiar linear modules are used to construct a mixed linear-morphological network called HaarNet. This is the first large-scale linear-morphological hybrid, evaluated on a set of sizeable real-world datasets. In the network, morphological Haar sampling is applied to both feature channels in several layers, which splits extreme values and high-frequency information such that both can be processed to improve both modalities. Moreover, morphologically parameterised ReLU is used, and morphologically-sound up-sampling is applied to obtain a full-resolution output. Experiments show that HaarNet is competitive with a state-of-the-art CNN, implying that morphological networks are a promising research direction for geometry-based learning tasks. ",
    "url": "https://arxiv.org/abs/2310.07669",
    "authors": [
      "Rick Groenendijk",
      "Leo Dorst",
      "Theo Gevers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07676",
    "title": "Composite Backdoor Attacks Against Large Language Models",
    "abstract": "Large language models (LLMs) have demonstrated superior performance compared to previous methods on various tasks, and often serve as the foundation models for many researches and services. However, the untrustworthy third-party LLMs may covertly introduce vulnerabilities for downstream tasks. In this paper, we explore the vulnerability of LLMs through the lens of backdoor attacks. Different from existing backdoor attacks against LLMs, ours scatters multiple trigger keys in different prompt components. Such a Composite Backdoor Attack (CBA) is shown to be stealthier than implanting the same multiple trigger keys in only a single component. CBA ensures that the backdoor is activated only when all trigger keys appear. Our experiments demonstrate that CBA is effective in both natural language processing (NLP) and multimodal tasks. For instance, with $3\\%$ poisoning samples against the LLaMA-7B model on the Emotion dataset, our attack achieves a $100\\%$ Attack Success Rate (ASR) with a False Triggered Rate (FTR) below $2.06\\%$ and negligible model accuracy degradation. The unique characteristics of our CBA can be tailored for various practical scenarios, e.g., targeting specific user groups. Our work highlights the necessity of increased security research on the trustworthiness of foundation LLMs. ",
    "url": "https://arxiv.org/abs/2310.07676",
    "authors": [
      "Hai Huang",
      "Zhengyu Zhao",
      "Michael Backes",
      "Yun Shen",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07678",
    "title": "Explainable Image Similarity: Integrating Siamese Networks and Grad-CAM",
    "abstract": "With the proliferation of image-based applications in various domains, the need for accurate and interpretable image similarity measures has become increasingly critical. Existing image similarity models often lack transparency, making it challenging to understand the reasons why two images are considered similar. In this paper, we propose the concept of explainable image similarity, where the goal is the development of an approach, which is capable of providing similarity scores along with visual factual and counterfactual explanations. Along this line, we present a new framework, which integrates Siamese Networks and Grad-CAM for providing explainable image similarity and discuss the potential benefits and challenges of adopting this approach. In addition, we provide a comprehensive discussion about factual and counterfactual explanations provided by the proposed framework for assisting decision making. The proposed approach has the potential to enhance the interpretability, trustworthiness and user acceptance of image-based systems in real-world image similarity applications. The implementation code can be found in https://github.com/ioannislivieris/Grad_CAM_Siamese.git. ",
    "url": "https://arxiv.org/abs/2310.07678",
    "authors": [
      "Ioannis E. Livieris",
      "Emmanuel Pintelas",
      "Niki Kiriakidou",
      "Panagiotis Pintelas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07682",
    "title": "Prediction of MET Overexpression in Non-Small Cell Lung Adenocarcinomas  from Hematoxylin and Eosin Images",
    "abstract": "MET protein overexpression is a targetable event in non-small cell lung cancer (NSCLC) and is the subject of active drug development. Challenges in identifying patients for these therapies include lack of access to validated testing, such as standardized immunohistochemistry (IHC) assessment, and consumption of valuable tissue for a single gene/protein assay. Development of pre-screening algorithms using routinely available digitized hematoxylin and eosin (H&E)-stained slides to predict MET overexpression could promote testing for those who will benefit most. While assessment of MET expression using IHC is currently not routinely performed in NSCLC, next-generation sequencing is common and in some cases includes RNA expression panel testing. In this work, we leveraged a large database of matched H&E slides and RNA expression data to train a weakly supervised model to predict MET RNA overexpression directly from H&E images. This model was evaluated on an independent holdout test set of 300 over-expressed and 289 normal patients, demonstrating an ROC-AUC of 0.70 (95th percentile interval: 0.66 - 0.74) with stable performance characteristics across different patient clinical variables and robust to synthetic noise on the test set. These results suggest that H&E-based predictive models could be useful to prioritize patients for confirmatory testing of MET protein or MET gene expression status. ",
    "url": "https://arxiv.org/abs/2310.07682",
    "authors": [
      "Kshitij Ingale",
      "Sun Hae Hong",
      "Josh S.K. Bell",
      "Abbas Rizvi",
      "Amy Welch",
      "Lingdao Sha",
      "Irvin Ho",
      "Kunal Nagpal",
      "Aicha BenTaieb",
      "Rohan P Joshi",
      "Martin C Stumpe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07684",
    "title": "Hypergraph Neural Networks through the Lens of Message Passing: A Common  Perspective to Homophily and Architecture Design",
    "abstract": "Most of the current hypergraph learning methodologies and benchmarking datasets in the hypergraph realm are obtained by lifting procedures from their graph analogs, simultaneously leading to overshadowing hypergraph network foundations. This paper attempts to confront some pending questions in that regard: Can the concept of homophily play a crucial role in Hypergraph Neural Networks (HGNNs), similar to its significance in graph-based research? Is there room for improving current hypergraph architectures and methodologies? (e.g. by carefully addressing the specific characteristics of higher-order networks) Do existing datasets provide a meaningful benchmark for HGNNs? Diving into the details, this paper proposes a novel conceptualization of homophily in higher-order networks based on a message passing scheme; this approach harmonizes the analytical frameworks of datasets and architectures, offering a unified perspective for exploring and interpreting complex, higher-order network structures and dynamics. Further, we propose MultiSet, a novel message passing framework that redefines HGNNs by allowing hyperedge-dependent node representations, as well as introduce a novel architecture MultiSetMixer that leverages a new hyperedge sampling strategy. Finally, we provide an extensive set of experiments that contextualize our proposals and lead to valuable insights in hypergraph representation learning. ",
    "url": "https://arxiv.org/abs/2310.07684",
    "authors": [
      "Lev Telyatnikov",
      "Maria Sofia Bucarelli",
      "Guillermo Bernardez",
      "Olga Zaghen",
      "Simone Scardapane",
      "Pietro Lio"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.07706",
    "title": "Pixel State Value Network for Combined Prediction and Planning in  Interactive Environments",
    "abstract": "Automated vehicles operating in urban environments have to reliably interact with other traffic participants. Planning algorithms often utilize separate prediction modules forecasting probabilistic, multi-modal, and interactive behaviors of objects. Designing prediction and planning as two separate modules introduces significant challenges, particularly due to the interdependence of these modules. This work proposes a deep learning methodology to combine prediction and planning. A conditional GAN with the U-Net architecture is trained to predict two high-resolution image sequences. The sequences represent explicit motion predictions, mainly used to train context understanding, and pixel state values suitable for planning encoding kinematic reachability, object dynamics, safety, and driving comfort. The model can be trained offline on target images rendered by a sampling-based model-predictive planner, leveraging real-world driving data. Our results demonstrate intuitive behavior in complex situations, such as lane changes amidst conflicting objectives. ",
    "url": "https://arxiv.org/abs/2310.07706",
    "authors": [
      "Sascha Rosbach",
      "Stefan M. Leupold",
      "Simon Gro\u00dfjohann",
      "Stefan Roth"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.07716",
    "title": "PAD: A Dataset and Benchmark for Pose-agnostic Anomaly Detection",
    "abstract": "Object anomaly detection is an important problem in the field of machine vision and has seen remarkable progress recently. However, two significant challenges hinder its research and application. First, existing datasets lack comprehensive visual information from various pose angles. They usually have an unrealistic assumption that the anomaly-free training dataset is pose-aligned, and the testing samples have the same pose as the training data. However, in practice, anomaly may exist in any regions on a object, the training and query samples may have different poses, calling for the study on pose-agnostic anomaly detection. Second, the absence of a consensus on experimental protocols for pose-agnostic anomaly detection leads to unfair comparisons of different methods, hindering the research on pose-agnostic anomaly detection. To address these issues, we develop Multi-pose Anomaly Detection (MAD) dataset and Pose-agnostic Anomaly Detection (PAD) benchmark, which takes the first step to address the pose-agnostic anomaly detection problem. Specifically, we build MAD using 20 complex-shaped LEGO toys including 4K views with various poses, and high-quality and diverse 3D anomalies in both simulated and real environments. Additionally, we propose a novel method OmniposeAD, trained using MAD, specifically designed for pose-agnostic anomaly detection. Through comprehensive evaluations, we demonstrate the relevance of our dataset and method. Furthermore, we provide an open-source benchmark library, including dataset and baseline methods that cover 8 anomaly detection paradigms, to facilitate future research and application in this domain. Code, data, and models are publicly available at https://github.com/EricLee0224/PAD. ",
    "url": "https://arxiv.org/abs/2310.07716",
    "authors": [
      "Qiang Zhou",
      "Weize Li",
      "Lihan Jiang",
      "Guoliang Wang",
      "Guyue Zhou",
      "Shanghang Zhang",
      "Hao Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.06921",
    "title": "Hybrid Zonotope-Based Backward Reachability Analysis for Neural Feedback  Systems With Nonlinear System Models",
    "abstract": "The increasing prevalence of neural networks in safety-critical control systems underscores the imperative need for rigorous methods to ensure the reliability and safety of these systems. This work introduces a novel approach employing hybrid zonotopes to compute the over-approximation of backward reachable sets for neural feedback systems with nonlinear system models and general activation functions. Closed-form expressions as hybrid zonotopes are provided for the over-approximated backward reachable sets, and a refinement procedure is proposed to alleviate the potential conservatism of the approximation. Two numerical examples are provided to illustrate the effectiveness of the proposed approach. ",
    "url": "https://arxiv.org/abs/2310.06921",
    "authors": [
      "Hang Zhang",
      "Yuhao Zhang",
      "Xiangru Xu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.06945",
    "title": "End-to-end Evaluation of Practical Video Analytics Systems for Face  Detection and Recognition",
    "abstract": "Practical video analytics systems that are deployed in bandwidth constrained environments like autonomous vehicles perform computer vision tasks such as face detection and recognition. In an end-to-end face analytics system, inputs are first compressed using popular video codecs like HEVC and then passed onto modules that perform face detection, alignment, and recognition sequentially. Typically, the modules of these systems are evaluated independently using task-specific imbalanced datasets that can misconstrue performance estimates. In this paper, we perform a thorough end-to-end evaluation of a face analytics system using a driving-specific dataset, which enables meaningful interpretations. We demonstrate how independent task evaluations, dataset imbalances, and inconsistent annotations can lead to incorrect system performance estimates. We propose strategies to create balanced evaluation subsets of our dataset and to make its annotations consistent across multiple analytics tasks and scenarios. We then evaluate the end-to-end system performance sequentially to account for task interdependencies. Our experiments show that our approach provides consistent, accurate, and interpretable estimates of the system's performance which is critical for real-world applications. ",
    "url": "https://arxiv.org/abs/2310.06945",
    "authors": [
      "Praneet Singh",
      "Edward J. Delp",
      "Amy R. Reibman"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.06973",
    "title": "Federated Quantum Machine Learning with Differential Privacy",
    "abstract": "The preservation of privacy is a critical concern in the implementation of artificial intelligence on sensitive training data. There are several techniques to preserve data privacy but quantum computations are inherently more secure due to the no-cloning theorem, resulting in a most desirable computational platform on top of the potential quantum advantages. There have been prior works in protecting data privacy by Quantum Federated Learning (QFL) and Quantum Differential Privacy (QDP) studied independently. However, to the best of our knowledge, no prior work has addressed both QFL and QDP together yet. Here, we propose to combine these privacy-preserving methods and implement them on the quantum platform, so that we can achieve comprehensive protection against data leakage (QFL) and model inversion attacks (QDP). This implementation promises more efficient and secure artificial intelligence. In this paper, we present a successful implementation of these privacy-preservation methods by performing the binary classification of the Cats vs Dogs dataset. Using our quantum-classical machine learning model, we obtained a test accuracy of over 0.98, while maintaining epsilon values less than 1.3. We show that federated differentially private training is a viable privacy preservation method for quantum machine learning on Noisy Intermediate-Scale Quantum (NISQ) devices. ",
    "url": "https://arxiv.org/abs/2310.06973",
    "authors": [
      "Rod Rofougaran",
      "Shinjae Yoo",
      "Huan-Hsin Tseng",
      "Samuel Yen-Chi Chen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07190",
    "title": "Neural networks: deep, shallow, or in between?",
    "abstract": "We give estimates from below for the error of approximation of a compact subset from a Banach space by the outputs of feed-forward neural networks with width W, depth l and Lipschitz activation functions. We show that, modulo logarithmic factors, rates better that entropy numbers' rates are possibly attainable only for neural networks for which the depth l goes to infinity, and that there is no gain if we fix the depth and let the width W go to infinity. ",
    "url": "https://arxiv.org/abs/2310.07190",
    "authors": [
      "Guergana Petrova",
      "Przemyslaw Wojtaszczyk"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2310.07250",
    "title": "Synthesizing Missing MRI Sequences from Available Modalities using  Generative Adversarial Networks in BraTS Dataset",
    "abstract": "Glioblastoma is a highly aggressive and lethal form of brain cancer. Magnetic resonance imaging (MRI) plays a significant role in the diagnosis, treatment planning, and follow-up of glioblastoma patients due to its non-invasive and radiation-free nature. The International Brain Tumor Segmentation (BraTS) challenge has contributed to generating numerous AI algorithms to accurately and efficiently segment glioblastoma sub-compartments using four structural (T1, T1Gd, T2, T2-FLAIR) MRI scans. However, these four MRI sequences may not always be available. To address this issue, Generative Adversarial Networks (GANs) can be used to synthesize the missing MRI sequences. In this paper, we implement and utilize an open-source GAN approach that takes any three MRI sequences as input to generate the missing fourth structural sequence. Our proposed approach is contributed to the community-driven generally nuanced deep learning framework (GaNDLF) and demonstrates promising results in synthesizing high-quality and realistic MRI sequences, enabling clinicians to improve their diagnostic capabilities and support the application of AI methods to brain tumor MRI quantification. ",
    "url": "https://arxiv.org/abs/2310.07250",
    "authors": [
      "Ibrahim Ethem Hamamci"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.07437",
    "title": "A Branched Deep Convolutional Network for Forecasting the Occurrence of  Hazes in Paris using Meteorological Maps with Different Characteristic  Spatial Scales",
    "abstract": "A deep learning platform has been developed to forecast the occurrence of the low visibility events or hazes. It is trained by using multi-decadal daily regional maps of various meteorological and hydrological variables as input features and surface visibility observations as the targets. To better preserve the characteristic spatial information of different input features for training, two branched architectures have recently been developed for the case of Paris hazes. These new architectures have improved the performance of the network, producing reasonable scores in both validation and a blind forecasting evaluation using the data of 2021 and 2022 that have not been used in the training and validation. ",
    "url": "https://arxiv.org/abs/2310.07437",
    "authors": [
      "Chien Wang"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.07452",
    "title": "On $k$-vertex-edge domination of graph",
    "abstract": "Let $G=(V,E)$ be a simple undirected graph. The open neighbourhood of a vertex $v$ in $G$ is defined as $N_G(v)=\\{u\\in V~|~ uv\\in E\\}$; whereas the closed neighbourhood is defined as $N_G[v]= N_G(v)\\cup \\{v\\}$. For an integer $k$, a subset $D\\subseteq V$ is called a $k$-vertex-edge dominating set of $G$ if for every edge $uv\\in E$, $|(N_G[u]\\cup N_G[v]) \\cap D|\\geq k$. In $k$-vertex-edge domination problem, our goal is to find a $k$-vertex-edge dominating set of minimum cardinality of an input graph $G$. In this paper, we first prove that the decision version of $k$-vertex-edge domination problem is NP-complete for chordal graphs. On the positive side, we design a linear time algorithm for finding a minimum $k$-vertex-edge dominating set of tree. We also prove that there is a $O(\\log(\\Delta(G)))$-approximation algorithm for this problem in general graph $G$, where $\\Delta(G)$ is the maximum degree of $G$. Then we show that for a graph $G$ with $n$ vertices, this problem cannot be approximated within a factor of $(1-\\epsilon) \\ln n$ for any $\\epsilon >0$ unless $NP\\subseteq DTIME(|V|^{O(\\log\\log|V|)})$. Finally, we prove that it is APX-complete for graphs with bounded degree $k+3$. ",
    "url": "https://arxiv.org/abs/2310.07452",
    "authors": [
      "Debojyoti Bhattacharya",
      "Subhabrata Paul"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2310.07499",
    "title": "Functional renormalization group for signal detection and stochastic  ergodicity breaking",
    "abstract": "Signal detection is one of the main challenges of data science. As it often happens in data analysis, the signal in the data may be corrupted by noise. There is a wide range of techniques aimed at extracting the relevant degrees of freedom from data. However, some problems remain difficult. It is notably the case of signal detection in almost continuous spectra when the signal-to-noise ratio is small enough. This paper follows a recent bibliographic line which tackles this issue with field-theoretical methods. Previous analysis focused on equilibrium Boltzmann distributions for some effective field representing the degrees of freedom of data. It was possible to establish a relation between signal detection and $\\mathbb{Z}_2$-symmetry breaking. In this paper, we consider a stochastic field framework inspiring by the so-called \"Model A\", and show that the ability to reach or not an equilibrium state is correlated with the shape of the dataset. In particular, studying the renormalization group of the model, we show that the weak ergodicity prescription is always broken for signals small enough, when the data distribution is close to the Marchenko-Pastur (MP) law. This, in particular, enables the definition of a detection threshold in the regime where the signal-to-noise ratio is small enough. ",
    "url": "https://arxiv.org/abs/2310.07499",
    "authors": [
      "Harold Erbin",
      "Riccardo Finotello",
      "Bio Wahabou Kpera",
      "Vincent Lahoche",
      "Dine Ousmane Samary"
    ],
    "subjectives": [
      "High Energy Physics - Theory (hep-th)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2310.07504",
    "title": "PtychoDV: Vision Transformer-Based Deep Unrolling Network for  Ptychographic Image Reconstruction",
    "abstract": "Ptychography is an imaging technique that captures multiple overlapping snapshots of a sample, illuminated coherently by a moving localized probe. The image recovery from ptychographic data is generally achieved via an iterative algorithm that solves a nonlinear phase-field problem derived from measured diffraction patterns. However, these approaches have high computational cost. In this paper, we introduce PtychoDV, a novel deep model-based network designed for efficient, high-quality ptychographic image reconstruction. PtychoDV comprises a vision transformer that generates an initial image from the set of raw measurements, taking into consideration their mutual correlations. This is followed by a deep unrolling network that refines the initial image using learnable convolutional priors and the ptychography measurement model. Experimental results on simulated data demonstrate that PtychoDV is capable of outperforming existing deep learning methods for this problem, and significantly reduces computational cost compared to iterative methodologies, while maintaining competitive performance. ",
    "url": "https://arxiv.org/abs/2310.07504",
    "authors": [
      "Weijie Gan",
      "Qiuchen Zhai",
      "Michael Thompson McCann",
      "Cristina Garcia Cardona",
      "Ulugbek S. Kamilov",
      "Brendt Wohlberg"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07633",
    "title": "Attention-Map Augmentation for Hypercomplex Breast Cancer Classification",
    "abstract": "Breast cancer is the most widespread neoplasm among women and early detection of this disease is critical. Deep learning techniques have become of great interest to improve diagnostic performance. Nonetheless, discriminating between malignant and benign masses from whole mammograms remains challenging due to them being almost identical to an untrained eye and the region of interest (ROI) occupying a minuscule portion of the entire image. In this paper, we propose a framework, parameterized hypercomplex attention maps (PHAM), to overcome these problems. Specifically, we deploy an augmentation step based on computing attention maps. Then, the attention maps are used to condition the classification step by constructing a multi-dimensional input comprised of the original breast cancer image and the corresponding attention map. In this step, a parameterized hypercomplex neural network (PHNN) is employed to perform breast cancer classification. The framework offers two main advantages. First, attention maps provide critical information regarding the ROI and allow the neural model to concentrate on it. Second, the hypercomplex architecture has the ability to model local relations between input dimensions thanks to hypercomplex algebra rules, thus properly exploiting the information provided by the attention map. We demonstrate the efficacy of the proposed framework on both mammography images as well as histopathological ones, surpassing attention-based state-of-the-art networks and the real-valued counterpart of our method. The code of our work is available at https://github.com/elelo22/AttentionBCS. ",
    "url": "https://arxiv.org/abs/2310.07633",
    "authors": [
      "Eleonora Lopez",
      "Filippo Betello",
      "Federico Carmignani",
      "Eleonora Grassucci",
      "Danilo Comminiello"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.07658",
    "title": "The First Pathloss Radio Map Prediction Challenge",
    "abstract": "To foster research and facilitate fair comparisons among recently proposed pathloss radio map prediction methods, we have launched the ICASSP 2023 First Pathloss Radio Map Prediction Challenge. In this short overview paper, we briefly describe the pathloss prediction problem, the provided datasets, the challenge task and the challenge evaluation methodology. Finally, we present the results of the challenge. ",
    "url": "https://arxiv.org/abs/2310.07658",
    "authors": [
      "\u00c7a\u011fkan Yapar",
      "Fabian Jaensch",
      "Ron Levie",
      "Gitta Kutyniok",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.07711",
    "title": "Growing Brains: Co-emergence of Anatomical and Functional Modularity in  Recurrent Neural Networks",
    "abstract": "Recurrent neural networks (RNNs) trained on compositional tasks can exhibit functional modularity, in which neurons can be clustered by activity similarity and participation in shared computational subtasks. Unlike brains, these RNNs do not exhibit anatomical modularity, in which functional clustering is correlated with strong recurrent coupling and spatial localization of functional clusters. Contrasting with functional modularity, which can be ephemerally dependent on the input, anatomically modular networks form a robust substrate for solving the same subtasks in the future. To examine whether it is possible to grow brain-like anatomical modularity, we apply a recent machine learning method, brain-inspired modular training (BIMT), to a network being trained to solve a set of compositional cognitive tasks. We find that functional and anatomical clustering emerge together, such that functionally similar neurons also become spatially localized and interconnected. Moreover, compared to standard $L_1$ or no regularization settings, the model exhibits superior performance by optimally balancing task performance and network sparsity. In addition to achieving brain-like organization in RNNs, our findings also suggest that BIMT holds promise for applications in neuromorphic computing and enhancing the interpretability of neural network architectures. ",
    "url": "https://arxiv.org/abs/2310.07711",
    "authors": [
      "Ziming Liu",
      "Mikail Khona",
      "Ila R. Fiete",
      "Max Tegmark"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:1505.01695",
    "title": "Proving Termination of Graph Transformation Systems using Weighted Type  Graphs over Semirings",
    "abstract": " Title: Proving Termination of Graph Transformation Systems using Weighted Type  Graphs over Semirings ",
    "url": "https://arxiv.org/abs/1505.01695",
    "authors": [
      "H.J. Sander Bruggink",
      "Barbara K\u00f6nig",
      "Dennis Nolte",
      "Hans Zantema"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2011.00685",
    "title": "Fast Biconnectivity Restoration in Multi-Robot Systems for Robust  Communication Maintenance",
    "abstract": " Comments: 8 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2011.00685",
    "authors": [
      "Md Ishat-E-Rabban",
      "Guangyao Shi",
      "Pratap Tokekar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2110.08898",
    "title": "Algorithms, hardness and graph products on a pursuit-evasion game",
    "abstract": " Comments: 15 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2110.08898",
    "authors": [
      "Eurinardo Costa",
      "Nicolas Martins",
      "Rudini Sampaio"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2111.08117",
    "title": "Neural networks with linear threshold activations: structure and  algorithms",
    "abstract": " Title: Neural networks with linear threshold activations: structure and  algorithms ",
    "url": "https://arxiv.org/abs/2111.08117",
    "authors": [
      "Sammy Khalife",
      "Hongyu Cheng",
      "Amitabh Basu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.06768",
    "title": "Probabilistically Robust Recourse: Navigating the Trade-offs between  Costs and Robustness in Algorithmic Recourse",
    "abstract": " Comments: ICLR 2023, camera ready version ",
    "url": "https://arxiv.org/abs/2203.06768",
    "authors": [
      "Martin Pawelczyk",
      "Teresa Datta",
      "Johannes van-den-Heuvel",
      "Gjergji Kasneci",
      "Himabindu Lakkaraju"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2203.07941",
    "title": "Reachability In Simple Neural Networks",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2108.13179 ",
    "url": "https://arxiv.org/abs/2203.07941",
    "authors": [
      "Marco S\u00e4lzer",
      "Martin Lange"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.12781",
    "title": "Efficiently Leveraging Multi-level User Intent for Session-based  Recommendation via Atten-Mixer Network",
    "abstract": " Title: Efficiently Leveraging Multi-level User Intent for Session-based  Recommendation via Atten-Mixer Network ",
    "url": "https://arxiv.org/abs/2206.12781",
    "authors": [
      "Peiyan Zhang",
      "Jiayan Guo",
      "Chaozhuo Li",
      "Yueqi Xie",
      "Jaeboum Kim",
      "Yan Zhang",
      "Xing Xie",
      "Haohan Wang",
      "Sunghun Kim"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2207.14367",
    "title": "An Equity-Aware Recommender System for Curating Art Exhibits Based on  Locally-Constrained Graph Matching",
    "abstract": " Title: An Equity-Aware Recommender System for Curating Art Exhibits Based on  Locally-Constrained Graph Matching ",
    "url": "https://arxiv.org/abs/2207.14367",
    "authors": [
      "Anna Haensch",
      "Dina Deitsch"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09809",
    "title": "Analysis of Convolutions, Non-linearity and Depth in Graph Neural  Networks using Neural Tangent Kernel",
    "abstract": " Comments: 41 pages, 24 figures. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2210.09809",
    "authors": [
      "Mahalakshmi Sabanayagam",
      "Pascal Esser",
      "Debarghya Ghoshdastidar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13660",
    "title": "SpacePhish: The Evasion-space of Adversarial Attacks against Phishing  Website Detectors using Machine Learning",
    "abstract": " Title: SpacePhish: The Evasion-space of Adversarial Attacks against Phishing  Website Detectors using Machine Learning ",
    "url": "https://arxiv.org/abs/2210.13660",
    "authors": [
      "Ying Yuan",
      "Giovanni Apruzzese",
      "Mauro Conti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2211.03860",
    "title": "Automatic Change-Point Detection in Time Series via Deep Learning",
    "abstract": " Comments: 33 pages, 15 figures and 3 tables ",
    "url": "https://arxiv.org/abs/2211.03860",
    "authors": [
      "Jie Li",
      "Paul Fearnhead",
      "Piotr Fryzlewicz",
      "Tengyao Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2211.08501",
    "title": "Social Mechanism Design: Making Maximally Acceptable Decisions",
    "abstract": " Title: Social Mechanism Design: Making Maximally Acceptable Decisions ",
    "url": "https://arxiv.org/abs/2211.08501",
    "authors": [
      "Ben Abramowitz",
      "Nicholas Mattei"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2211.12421",
    "title": "Data-Driven Network Neuroscience: On Data Collection and Benchmark",
    "abstract": " Title: Data-Driven Network Neuroscience: On Data Collection and Benchmark ",
    "url": "https://arxiv.org/abs/2211.12421",
    "authors": [
      "Jiaxing Xu",
      "Yunhan Yang",
      "David Tse Jung Huang",
      "Sophi Shilpa Gururajapathy",
      "Yiping Ke",
      "Miao Qiao",
      "Alan Wang",
      "Haribalan Kumar",
      "Josh McGeown",
      "Eryn Kwon"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2212.09289",
    "title": "Mining User Privacy Concern Topics from App Reviews",
    "abstract": " Title: Mining User Privacy Concern Topics from App Reviews ",
    "url": "https://arxiv.org/abs/2212.09289",
    "authors": [
      "Jianzhang Zhang",
      "Jinping Hua",
      "Yiyang Chen",
      "Nan Niu",
      "Chuang Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2301.11986",
    "title": "Enhancing Face Recognition with Latent Space Data Augmentation and  Facial Posture Reconstruction",
    "abstract": " Title: Enhancing Face Recognition with Latent Space Data Augmentation and  Facial Posture Reconstruction ",
    "url": "https://arxiv.org/abs/2301.11986",
    "authors": [
      "Soroush Hashemifar",
      "Abdolreza Marefat",
      "Javad Hassannataj Joloudari",
      "Hamid Hassanpour"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.05078",
    "title": "Efficient Transformer-based 3D Object Detection with Dynamic Token  Halting",
    "abstract": " Title: Efficient Transformer-based 3D Object Detection with Dynamic Token  Halting ",
    "url": "https://arxiv.org/abs/2303.05078",
    "authors": [
      "Mao Ye",
      "Gregory P. Meyer",
      "Yuning Chai",
      "Qiang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.08896",
    "title": "SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for  Generative Large Language Models",
    "abstract": " Comments: EMNLP 2023 (main conference) ",
    "url": "https://arxiv.org/abs/2303.08896",
    "authors": [
      "Potsawee Manakul",
      "Adian Liusie",
      "Mark J. F. Gales"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.09902",
    "title": "Contrastive Self-supervised Learning in Recommender Systems: A Survey",
    "abstract": " Comments: Accepted by ACM Transactions on Information Systems (TOIS) ",
    "url": "https://arxiv.org/abs/2303.09902",
    "authors": [
      "Mengyuan Jing",
      "Yanmin Zhu",
      "Tianzi Zang",
      "Ke Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2303.16254",
    "title": "CryoFormer: Continuous Heterogeneous Cryo-EM Reconstruction using  Transformer-based Neural Representations",
    "abstract": " Title: CryoFormer: Continuous Heterogeneous Cryo-EM Reconstruction using  Transformer-based Neural Representations ",
    "url": "https://arxiv.org/abs/2303.16254",
    "authors": [
      "Xinhang Liu",
      "Yan Zeng",
      "Yifan Qin",
      "Hao Li",
      "Jiakai Zhang",
      "Lan Xu",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.16570",
    "title": "Point2Vec for Self-Supervised Representation Learning on Point Clouds",
    "abstract": " Comments: Accepted at GCPR 2023. Project page at this https URL ",
    "url": "https://arxiv.org/abs/2303.16570",
    "authors": [
      "Karim Abou Zeid",
      "Jonas Schult",
      "Alexander Hermans",
      "Bastian Leibe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.17063",
    "title": "Colosseum as a Digital Twin: Bridging Real-World Experimentation and  Wireless Network Emulation",
    "abstract": " Comments: 16 pages, 23 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2303.17063",
    "authors": [
      "Davide Villa",
      "Miead Tehrani-Moayyed",
      "Clifton Paul Robinson",
      "Leonardo Bonati",
      "Pedram Johari",
      "Michele Polese",
      "Stefano Basagni",
      "Tommaso Melodia"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2304.03108",
    "title": "FABRID: Flexible Attestation-Based Routing for Inter-Domain Networks",
    "abstract": " Title: FABRID: Flexible Attestation-Based Routing for Inter-Domain Networks ",
    "url": "https://arxiv.org/abs/2304.03108",
    "authors": [
      "Cyrill Kr\u00e4henb\u00fchl",
      "Marc Wyss",
      "David Basin",
      "Vincent Lenders",
      "Adrian Perrig",
      "Martin Strohmeier"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.03864",
    "title": "SGDP: A Stream-Graph Neural Network Based Data Prefetcher",
    "abstract": " Comments: Accepted by International Joint Conference on Neural Networks (IJCNN 2023) ",
    "url": "https://arxiv.org/abs/2304.03864",
    "authors": [
      "Yiyuan Yang",
      "Rongshang Li",
      "Qiquan Shi",
      "Xijun Li",
      "Gang Hu",
      "Xing Li",
      "Mingxuan Yuan"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.06925",
    "title": "YOLO-Drone:Airborne real-time detection of dense small objects from  high-altitude perspective",
    "abstract": " Comments: Some contributing authors are not signed ",
    "url": "https://arxiv.org/abs/2304.06925",
    "authors": [
      "Li Zhu",
      "Jiahui Xiong",
      "Feng Xiong",
      "Hanzheng Hu",
      "Zhengnan Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.11161",
    "title": "altiro3D: Scene representation from single image and novel view  synthesis",
    "abstract": " Comments: In press (2023) Springer International Journal of Information Technology (IJIT) 10 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2304.11161",
    "authors": [
      "E. Canessa",
      "L. Tenze"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2305.00472",
    "title": "Efficient MILP Decomposition in Quantum Computing for ReLU Network  Robustness",
    "abstract": " Title: Efficient MILP Decomposition in Quantum Computing for ReLU Network  Robustness ",
    "url": "https://arxiv.org/abs/2305.00472",
    "authors": [
      "Nicola Franco",
      "Tom Wollschl\u00e4ger",
      "Benedikt Poggel",
      "Stephan G\u00fcnnemann",
      "Jeanette Miriam Lorenz"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.04080",
    "title": "Robust Tensor CUR Decompositions: Rapid Low-Tucker-Rank Tensor Recovery  with Sparse Corruption",
    "abstract": " Title: Robust Tensor CUR Decompositions: Rapid Low-Tucker-Rank Tensor Recovery  with Sparse Corruption ",
    "url": "https://arxiv.org/abs/2305.04080",
    "authors": [
      "HanQin Cai",
      "Zehan Chao",
      "Longxiu Huang",
      "Deanna Needell"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.08703",
    "title": "Schema-adaptable Knowledge Graph Construction",
    "abstract": " Comments: EMNLP 2023 (Findings) ",
    "url": "https://arxiv.org/abs/2305.08703",
    "authors": [
      "Hongbin Ye",
      "Honghao Gui",
      "Xin Xu",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.11141",
    "title": "Clifford Group Equivariant Neural Networks",
    "abstract": " Comments: Published at NeurIPS 2023 (Oral) ",
    "url": "https://arxiv.org/abs/2305.11141",
    "authors": [
      "David Ruhe",
      "Johannes Brandstetter",
      "Patrick Forr\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17139",
    "title": "A Measure-Theoretic Axiomatisation of Causality",
    "abstract": " Title: A Measure-Theoretic Axiomatisation of Causality ",
    "url": "https://arxiv.org/abs/2305.17139",
    "authors": [
      "Junhyung Park",
      "Simon Buchholz",
      "Bernhard Sch\u00f6lkopf",
      "Krikamol Muandet"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2306.00816",
    "title": "Robust Backdoor Attack with Visible, Semantic, Sample-Specific, and  Compatible Triggers",
    "abstract": " Title: Robust Backdoor Attack with Visible, Semantic, Sample-Specific, and  Compatible Triggers ",
    "url": "https://arxiv.org/abs/2306.00816",
    "authors": [
      "Ruotong Wang",
      "Hongrui Chen",
      "Zihao Zhu",
      "Li Liu",
      "Yong Zhang",
      "Yanbo Fan",
      "Baoyuan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.10347",
    "title": "DCdetector: Dual Attention Contrastive Representation Learning for Time  Series Anomaly Detection",
    "abstract": " Comments: Accepted by ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD 2023) ",
    "url": "https://arxiv.org/abs/2306.10347",
    "authors": [
      "Yiyuan Yang",
      "Chaoli Zhang",
      "Tian Zhou",
      "Qingsong Wen",
      "Liang Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.15142",
    "title": "LRANet: Towards Accurate and Efficient Scene Text Detection with  Low-Rank Approximation Network",
    "abstract": " Title: LRANet: Towards Accurate and Efficient Scene Text Detection with  Low-Rank Approximation Network ",
    "url": "https://arxiv.org/abs/2306.15142",
    "authors": [
      "Yuchen Su",
      "Zhineng Chen",
      "Zhiwen Shao",
      "Yuning Du",
      "Zhilong Ji",
      "Jinfeng Bai",
      "Yong Zhou",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.06555",
    "title": "Deep Network Approximation: Beyond ReLU to Diverse Activation Functions",
    "abstract": " Title: Deep Network Approximation: Beyond ReLU to Diverse Activation Functions ",
    "url": "https://arxiv.org/abs/2307.06555",
    "authors": [
      "Shijun Zhang",
      "Jianfeng Lu",
      "Hongkai Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.09447",
    "title": "Deep Neural Aggregation for Recommending Items to Group of Users",
    "abstract": " Title: Deep Neural Aggregation for Recommending Items to Group of Users ",
    "url": "https://arxiv.org/abs/2307.09447",
    "authors": [
      "Jorge Due\u00f1as-Ler\u00edn",
      "Ra\u00fal Lara-Cabrera",
      "Fernando Ortega",
      "Jes\u00fas Bobadilla"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2307.09855",
    "title": "Cross-thread critical sections and efficient dynamic race prediction  methods",
    "abstract": " Comments: Revised POPL'24 submission. 1. WCP is sound and show that WCP soundness proof can be adapted. 2. Cross-thread critical sections arise in practice, though the impact is not drastic. This in line with other works (like WCP) that advance the state of the art ",
    "url": "https://arxiv.org/abs/2307.09855",
    "authors": [
      "Martin Sulzmann",
      "Peter Thiemann"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2307.12813",
    "title": "Described Object Detection: Liberating Object Detection with Flexible  Expressions",
    "abstract": " Comments: Accepted by NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2307.12813",
    "authors": [
      "Chi Xie",
      "Zhao Zhang",
      "Yixuan Wu",
      "Feng Zhu",
      "Rui Zhao",
      "Shuang Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.13149",
    "title": "Discovering interpretable elastoplasticity models via the neural  polynomial method enabled symbolic regressions",
    "abstract": " Title: Discovering interpretable elastoplasticity models via the neural  polynomial method enabled symbolic regressions ",
    "url": "https://arxiv.org/abs/2307.13149",
    "authors": [
      "Bahador Bahmani",
      "Hyoung Suk Suh",
      "WaiChing Sun"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.14539",
    "title": "Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal  Language Models",
    "abstract": " Title: Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal  Language Models ",
    "url": "https://arxiv.org/abs/2307.14539",
    "authors": [
      "Erfan Shayegani",
      "Yue Dong",
      "Nael Abu-Ghazaleh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2308.08313",
    "title": "ECPC-IDS:A benchmark endometrail cancer PET/CT image dataset for  evaluation of semantic segmentation and detection of hypermetabolic regions",
    "abstract": " Comments: 14 pages,6 figures ",
    "url": "https://arxiv.org/abs/2308.08313",
    "authors": [
      "Dechao Tang",
      "Tianming Du",
      "Deguo Ma",
      "Zhiyu Ma",
      "Hongzan Sun",
      "Marcin Grzegorzek",
      "Huiyan Jiang",
      "Chen Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.11785",
    "title": "Towards Safe Automated Refactoring of Imperative Deep Learning Programs  to Graph Execution",
    "abstract": " Comments: To appear in the NIER track of the IEEE/ACM International Conference on Automated Software Engineering, ASE '23, Kirchberg, Luxembourg, September 2023 ",
    "url": "https://arxiv.org/abs/2308.11785",
    "authors": [
      "Raffi Khatchadourian",
      "Tatiana Castro V\u00e9lez",
      "Mehdi Bagherzadeh",
      "Nan Jia",
      "Anita Raja"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2309.06055",
    "title": "Backdoor Attacks and Countermeasures in Natural Language Processing  Models: A Comprehensive Security Review",
    "abstract": " Comments: 24 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2309.06055",
    "authors": [
      "Pengzhou Cheng",
      "Zongru Wu",
      "Wei Du",
      "Haodong Zhao",
      "Gongshen Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.10187",
    "title": "Automated Interviewer or Augmented Survey? Collecting Social Data with  Large Language Models",
    "abstract": " Title: Automated Interviewer or Augmented Survey? Collecting Social Data with  Large Language Models ",
    "url": "https://arxiv.org/abs/2309.10187",
    "authors": [
      "Alejandro Cuevas Villalba",
      "Eva M. Brown",
      "Jennifer V. Scurrell",
      "Jason Entenmann",
      "Madeleine I. G. Daepp"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2309.14065",
    "title": "AsymFormer: Asymmetrical Cross-Modal Representation Learning for Mobile  Platform Real-Time RGB-D Semantic Segmentation",
    "abstract": " Title: AsymFormer: Asymmetrical Cross-Modal Representation Learning for Mobile  Platform Real-Time RGB-D Semantic Segmentation ",
    "url": "https://arxiv.org/abs/2309.14065",
    "authors": [
      "Siqi Du",
      "Weixi Wang",
      "Renzhong Guo",
      "Shengjun Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.15709",
    "title": "Distributed Pilot Assignment for Distributed Massive-MIMO Networks",
    "abstract": " Title: Distributed Pilot Assignment for Distributed Massive-MIMO Networks ",
    "url": "https://arxiv.org/abs/2309.15709",
    "authors": [
      "Mohd Saif Ali Khan",
      "Samar Agnihotri",
      "Karthik R. M."
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2309.16918",
    "title": "ACGAN-GNNExplainer: Auxiliary Conditional Generative Explainer for Graph  Neural Networks",
    "abstract": " Title: ACGAN-GNNExplainer: Auxiliary Conditional Generative Explainer for Graph  Neural Networks ",
    "url": "https://arxiv.org/abs/2309.16918",
    "authors": [
      "Yiqiao Li",
      "Jianlong Zhou",
      "Yifei Dong",
      "Niusha Shafiabady",
      "Fang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01636",
    "title": "Adaptive Visual Scene Understanding: Incremental Scene Graph Generation",
    "abstract": " Title: Adaptive Visual Scene Understanding: Incremental Scene Graph Generation ",
    "url": "https://arxiv.org/abs/2310.01636",
    "authors": [
      "Naitik Khandelwal",
      "Xiao Liu",
      "Mengmi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.02800",
    "title": "Everest: GPU-Accelerated System For Mining Temporal Motifs",
    "abstract": " Title: Everest: GPU-Accelerated System For Mining Temporal Motifs ",
    "url": "https://arxiv.org/abs/2310.02800",
    "authors": [
      "Yichao Yuan",
      "Haojie Ye",
      "Sanketh Vedula",
      "Wynn Kaza",
      "Nishil Talati"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.04381",
    "title": "Hermes: Unlocking Security Analysis of Cellular Network Protocols by  Synthesizing Finite State Machines from Natural Language Specifications",
    "abstract": " Comments: Accepted at USENIX Security 24 ",
    "url": "https://arxiv.org/abs/2310.04381",
    "authors": [
      "Abdullah Al Ishtiaq",
      "Sarkar Snigdha Sarathi Das",
      "Syed Md Mukit Rashid",
      "Ali Ranjbar",
      "Kai Tu",
      "Tianwei Wu",
      "Zhezheng Song",
      "Weixuan Wang",
      "Mujtahid Akon",
      "Rui Zhang",
      "Syed Rafiul Hussain"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.04764",
    "title": "Characterizations of Definable Context-Free Graphs",
    "abstract": " Title: Characterizations of Definable Context-Free Graphs ",
    "url": "https://arxiv.org/abs/2310.04764",
    "authors": [
      "Radu Iosif",
      "Florian Zuleger"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2310.04780",
    "title": "IPMix: Label-Preserving Data Augmentation Method for Training Robust  Classifiers",
    "abstract": " Title: IPMix: Label-Preserving Data Augmentation Method for Training Robust  Classifiers ",
    "url": "https://arxiv.org/abs/2310.04780",
    "authors": [
      "Zhenglin Huang",
      "Xianan Bao",
      "Na Zhang",
      "Qingqi Zhang",
      "Xiaomei Tu",
      "Biao Wu",
      "Xi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05052",
    "title": "Learning Intra- and Inter-Cell Differences for Accurate Battery Lifespan  Prediction across Diverse Conditions",
    "abstract": " Title: Learning Intra- and Inter-Cell Differences for Accurate Battery Lifespan  Prediction across Diverse Conditions ",
    "url": "https://arxiv.org/abs/2310.05052",
    "authors": [
      "Han Zhang",
      "Yuqi Li",
      "Shun Zheng",
      "Ziheng Lu",
      "Xiaofan Gui",
      "Wei Xu",
      "Jiang Bian"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05136",
    "title": "InstructDET: Diversifying Referring Object Detection with Generalized  Instructions",
    "abstract": " Comments: Adjust the subject ",
    "url": "https://arxiv.org/abs/2310.05136",
    "authors": [
      "Ronghao Dang",
      "Jiangyan Feng",
      "Haodong Zhang",
      "Chongjian Ge",
      "Lin Song",
      "Lijun Gong",
      "Chengju Liu",
      "Qijun Chen",
      "Feng Zhu",
      "Rui Zhao",
      "Yibing Song"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05447",
    "title": "Towards Fair and Comprehensive Comparisons for Image-Based 3D Object  Detection",
    "abstract": " Comments: ICCV23, code will be released soon ",
    "url": "https://arxiv.org/abs/2310.05447",
    "authors": [
      "Xinzhu Ma",
      "Yongtao Wang",
      "Yinmin Zhang",
      "Zhiyi Xia",
      "Yuan Meng",
      "Zhihui Wang",
      "Haojie Li",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.05469",
    "title": "Vibroacoustic Frequency Response Prediction with Query-based Operator  Networks",
    "abstract": " Title: Vibroacoustic Frequency Response Prediction with Query-based Operator  Networks ",
    "url": "https://arxiv.org/abs/2310.05469",
    "authors": [
      "Jan van Delden",
      "Julius Schultz",
      "Christopher Blech",
      "Sabine C. Langer",
      "Timo L\u00fcddecke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  }
]