[
  {
    "id": "arXiv:2310.00011",
    "title": "Joint Self-supervised Depth and Optical Flow Estimation towards Dynamic  Objects",
    "abstract": "Significant attention has been attracted to deep learning-based depth estimates. Dynamic objects become the most hard problems in inter-frame-supervised depth estimates due to the uncertainty in adjacent frames. Thus, integrating optical flow information with depth estimation is a feasible solution, as the optical flow is an essential motion representation. In this work, we construct a joint inter-frame-supervised depth and optical flow estimation framework, which predicts depths in various motions by minimizing pixel wrap errors in bilateral photometric re-projections and optical vectors. For motion segmentation, we adaptively segment the preliminary estimated optical flow map with large areas of connectivity. In self-supervised depth estimation, different motion regions are predicted independently and then composite into a complete depth. Further, the pose and depth estimations re-synthesize the optical flow maps, serving to compute reconstruction errors with the preliminary predictions. Our proposed joint depth and optical flow estimation outperforms existing depth estimators on the KITTI Depth dataset, both with and without Cityscapes pretraining. Additionally, our optical flow results demonstrate competitive performance on the KITTI Flow 2015 dataset. ",
    "url": "https://arxiv.org/abs/2310.00011",
    "authors": [
      "Zhengyang Lu",
      "Ying Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.00014",
    "title": "Fewer-token Neural Speech Codec with Time-invariant Codes",
    "abstract": "Language model based text-to-speech (TTS) models, like VALL-E, have gained attention for their outstanding in-context learning capability in zero-shot scenarios. Neural speech codec is a critical component of these models, which can convert speech into discrete token representations. However, excessive token sequences from the codec may negatively affect prediction accuracy and restrict the progression of Language model based TTS models. To address this issue, this paper proposes a novel neural speech codec with time-invariant codes named TiCodec. By encoding and quantizing time-invariant information into a separate code, TiCodec can reduce the amount of frame-level information that needs encoding, effectively decreasing the number of tokens as codes of speech. Furthermore, this paper introduces a time-invariant encoding consistency loss to enhance the consistency of time-invariant code within an utterance and force it to capture more global information, which can benefit the zero-shot TTS task. Experimental results demonstrate that TiCodec can not only enhance the quality of reconstruction speech with fewer tokens but also increase the similarity and naturalness, as well as reduce the word error rate of the synthesized speech by the TTS model. ",
    "url": "https://arxiv.org/abs/2310.00014",
    "authors": [
      "Yong Ren",
      "Tao Wang",
      "Jiangyan Yi",
      "Le Xu",
      "Jianhua Tao",
      "Chuyuan Zhang",
      "Junzuo Zhou"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.00022",
    "title": "Prompt-Enhanced Self-supervised Representation Learning for Remote  Sensing Image Understanding",
    "abstract": "Learning representations through self-supervision on a large-scale, unlabeled dataset has proven to be highly effective for understanding diverse images, such as those used in remote sensing image analysis. However, remote sensing images often have complex and densely populated scenes, with multiple land objects and no clear foreground objects. This intrinsic property can lead to false positive pairs in contrastive learning, or missing contextual information in reconstructive learning, which can limit the effectiveness of existing self-supervised learning methods. To address these problems, we propose a prompt-enhanced self-supervised representation learning method that uses a simple yet efficient pre-training pipeline. Our approach involves utilizing original image patches as a reconstructive prompt template, and designing a prompt-enhanced generative branch that provides contextual information through semantic consistency constraints. We collected a dataset of over 1.28 million remote sensing images that is comparable to the popular ImageNet dataset, but without specific temporal or geographical constraints. Our experiments show that our method outperforms fully supervised learning models and state-of-the-art self-supervised learning methods on various downstream tasks, including land cover classification, semantic segmentation, object detection, and instance segmentation. These results demonstrate that our approach learns impressive remote sensing representations with high generalization and transferability. ",
    "url": "https://arxiv.org/abs/2310.00022",
    "authors": [
      "Mingming Zhang",
      "Qingjie Liu",
      "Yunhong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00029",
    "title": "Adversarial Driving Behavior Generation Incorporating Human Risk  Cognition for Autonomous Vehicle Evaluation",
    "abstract": "Autonomous vehicle (AV) evaluation has been the subject of increased interest in recent years both in industry and in academia. This paper focuses on the development of a novel framework for generating adversarial driving behavior of background vehicle interfering against the AV to expose effective and rational risky events. Specifically, the adversarial behavior is learned by a reinforcement learning (RL) approach incorporated with the cumulative prospect theory (CPT) which allows representation of human risk cognition. Then, the extended version of deep deterministic policy gradient (DDPG) technique is proposed for training the adversarial policy while ensuring training stability as the CPT action-value function is leveraged. A comparative case study regarding the cut-in scenario is conducted on a high fidelity Hardware-in-the-Loop (HiL) platform and the results demonstrate the adversarial effectiveness to infer the weakness of the tested AV. ",
    "url": "https://arxiv.org/abs/2310.00029",
    "authors": [
      "Zhen Liu",
      "Hang Gao",
      "Hao Ma",
      "Shuo Cai",
      "Yunfeng Hu",
      "Ting Qu",
      "Hong Chen",
      "Xun Gong"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.00057",
    "title": "Fusing simulation and monitoring data for real-time settlement  prediction during tunnel construction: A multi-fidelity deep operator network  (DeepONet)",
    "abstract": "Ground settlement prediction during the process of mechanized tunneling is of paramount importance and remains a challenging research topic. Typically, two different paradigms have been created: a physics-driven approach utilizing advanced process-oriented numerical models for settlement prediction, and a data-driven approach employing machine learning techniques to establish mappings between influencing factors and ground settlement. To integrate the advantages of both approaches and assimilate the data from different sources, we propose a multi-fidelity deep operator network (DeepONet) framework, leveraging the recently developed operator learning methods. The presented framework comprises two components: a low-fidelity subnet that captures the fundamental ground settlement patterns obtained from finite element simulations, and a high-fidelity subnet that learns the nonlinear correlation between numerical models and real engineering monitoring data. A pre-processing strategy for causality is adopted to consider the spatio-temporal characteristic of the settlement during tunnel excavation. Transfer learning is utilized to reduce the training cost for the low-fidelity subnet. The results show that the proposed method can effectively capture the physical laws presented by numerical simulations and accurately fit measured data as well. Remarkably, even with very limited noisy monitoring data, our model can achieve rapid, accurate, and robust prediction of the full-field ground settlement in real-time mechanized tunneling. ",
    "url": "https://arxiv.org/abs/2310.00057",
    "authors": [
      "Chen Xu",
      "Ba Trung Cao",
      "Yong Yuan",
      "G\u00fcnther Meschke"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2310.00070",
    "title": "Adversarial Explainability: Utilizing Explainable Machine Learning in  Bypassing IoT Botnet Detection Systems",
    "abstract": "Botnet detection based on machine learning have witnessed significant leaps in recent years, with the availability of large and reliable datasets that are extracted from real-life scenarios. Consequently, adversarial attacks on machine learning-based cybersecurity systems are posing a significant threat to the practicality of these solutions. In this paper, we introduce a novel attack that utilizes machine learning model's explainability in evading detection by botnet detection systems. The proposed attack utilizes information obtained from model's explainability to build adversarial samples that can evade detection in a blackbox setting. The proposed attack was tested on a trained IoT botnet detection systems and was capable of bypassing the botnet detection with 0% detection by altering one feature only to generate the adversarial samples. ",
    "url": "https://arxiv.org/abs/2310.00070",
    "authors": [
      "Mohammed M. Alani",
      "Atefeh Mashatan",
      "Ali Miri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.00076",
    "title": "Robustness of AI-Image Detectors: Fundamental Limits and Practical  Attacks",
    "abstract": "In light of recent advancements in generative AI models, it has become essential to distinguish genuine content from AI-generated one to prevent the malicious usage of fake materials as authentic ones and vice versa. Various techniques have been introduced for identifying AI-generated images, with watermarking emerging as a promising approach. In this paper, we analyze the robustness of various AI-image detectors including watermarking and classifier-based deepfake detectors. For watermarking methods that introduce subtle image perturbations (i.e., low perturbation budget methods), we reveal a fundamental trade-off between the evasion error rate (i.e., the fraction of watermarked images detected as non-watermarked ones) and the spoofing error rate (i.e., the fraction of non-watermarked images detected as watermarked ones) upon an application of a diffusion purification attack. In this regime, we also empirically show that diffusion purification effectively removes watermarks with minimal changes to images. For high perturbation watermarking methods where notable changes are applied to images, the diffusion purification attack is not effective. In this case, we develop a model substitution adversarial attack that can successfully remove watermarks. Moreover, we show that watermarking methods are vulnerable to spoofing attacks where the attacker aims to have real images (potentially obscene) identified as watermarked ones, damaging the reputation of the developers. In particular, by just having black-box access to the watermarking method, we show that one can generate a watermarked noise image which can be added to the real images to have them falsely flagged as watermarked ones. Finally, we extend our theory to characterize a fundamental trade-off between the robustness and reliability of classifier-based deep fake detectors and demonstrate it through experiments. ",
    "url": "https://arxiv.org/abs/2310.00076",
    "authors": [
      "Mehrdad Saberi",
      "Vinu Sankar Sadasivan",
      "Keivan Rezaei",
      "Aounon Kumar",
      "Atoosa Chegini",
      "Wenxiao Wang",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00098",
    "title": "Federated Learning with Differential Privacy for End-to-End Speech  Recognition",
    "abstract": "While federated learning (FL) has recently emerged as a promising approach to train machine learning models, it is limited to only preliminary explorations in the domain of automatic speech recognition (ASR). Moreover, FL does not inherently guarantee user privacy and requires the use of differential privacy (DP) for robust privacy guarantees. However, we are not aware of prior work on applying DP to FL for ASR. In this paper, we aim to bridge this research gap by formulating an ASR benchmark for FL with DP and establishing the first baselines. First, we extend the existing research on FL for ASR by exploring different aspects of recent $\\textit{large end-to-end transformer models}$: architecture design, seed models, data heterogeneity, domain shift, and impact of cohort size. With a $\\textit{practical}$ number of central aggregations we are able to train $\\textbf{FL models}$ that are \\textbf{nearly optimal} even with heterogeneous data, a seed model from another domain, or no pre-trained seed model. Second, we apply DP to FL for ASR, which is non-trivial since DP noise severely affects model training, especially for large transformer models, due to highly imbalanced gradients in the attention block. We counteract the adverse effect of DP noise by reviving per-layer clipping and explaining why its effect is more apparent in our case than in the prior work. Remarkably, we achieve user-level ($7.2$, $10^{-9}$)-$\\textbf{DP}$ (resp. ($4.5$, $10^{-9}$)-$\\textbf{DP}$) with a 1.3% (resp. 4.6%) absolute drop in the word error rate for extrapolation to high (resp. low) population scale for $\\textbf{FL with DP in ASR}$. ",
    "url": "https://arxiv.org/abs/2310.00098",
    "authors": [
      "Martin Pelikan",
      "Sheikh Shams Azam",
      "Vitaly Feldman",
      "Jan \"Honza\" Silovsky",
      "Kunal Talwar",
      "Tatiana Likhomanenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.00108",
    "title": "Practical Membership Inference Attacks Against Large-Scale Multi-Modal  Models: A Pilot Study",
    "abstract": "Membership inference attacks (MIAs) aim to infer whether a data point has been used to train a machine learning model. These attacks can be employed to identify potential privacy vulnerabilities and detect unauthorized use of personal data. While MIAs have been traditionally studied for simple classification models, recent advancements in multi-modal pre-training, such as CLIP, have demonstrated remarkable zero-shot performance across a range of computer vision tasks. However, the sheer scale of data and models presents significant computational challenges for performing the attacks. This paper takes a first step towards developing practical MIAs against large-scale multi-modal models. We introduce a simple baseline strategy by thresholding the cosine similarity between text and image features of a target point and propose further enhancing the baseline by aggregating cosine similarity across transformations of the target. We also present a new weakly supervised attack method that leverages ground-truth non-members (e.g., obtained by using the publication date of a target model and the timestamps of the open data) to further enhance the attack. Our evaluation shows that CLIP models are susceptible to our attack strategies, with our simple baseline achieving over $75\\%$ membership identification accuracy. Furthermore, our enhanced attacks outperform the baseline across multiple models and datasets, with the weakly supervised attack demonstrating an average-case performance improvement of $17\\%$ and being at least $7$X more effective at low false-positive rates. These findings highlight the importance of protecting the privacy of multi-modal foundational models, which were previously assumed to be less susceptible to MIAs due to less overfitting. Our code is available at https://github.com/ruoxi-jia-group/CLIP-MIA. ",
    "url": "https://arxiv.org/abs/2310.00108",
    "authors": [
      "Myeongseob Ko",
      "Ming Jin",
      "Chenguang Wang",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00116",
    "title": "Certified Robustness via Dynamic Margin Maximization and Improved  Lipschitz Regularization",
    "abstract": "To improve the robustness of deep classifiers against adversarial perturbations, many approaches have been proposed, such as designing new architectures with better robustness properties (e.g., Lipschitz-capped networks), or modifying the training process itself (e.g., min-max optimization, constrained learning, or regularization). These approaches, however, might not be effective at increasing the margin in the input (feature) space. As a result, there has been an increasing interest in developing training procedures that can directly manipulate the decision boundary in the input space. In this paper, we build upon recent developments in this category by developing a robust training algorithm whose objective is to increase the margin in the output (logit) space while regularizing the Lipschitz constant of the model along vulnerable directions. We show that these two objectives can directly promote larger margins in the input space. To this end, we develop a scalable method for calculating guaranteed differentiable upper bounds on the Lipschitz constant of neural networks accurately and efficiently. The relative accuracy of the bounds prevents excessive regularization and allows for more direct manipulation of the decision boundary. Furthermore, our Lipschitz bounding algorithm exploits the monotonicity and Lipschitz continuity of the activation layers, and the resulting bounds can be used to design new layers with controllable bounds on their Lipschitz constant. Experiments on the MNIST, CIFAR-10, and Tiny-ImageNet data sets verify that our proposed algorithm obtains competitively improved results compared to the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2310.00116",
    "authors": [
      "Mahyar Fazlyab",
      "Taha Entesari",
      "Aniket Roy",
      "Rama Chellappa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.00120",
    "title": "Multi-Grid Tensorized Fourier Neural Operator for High-Resolution PDEs",
    "abstract": "Memory complexity and data scarcity have so far prohibited learning solution operators of partial differential equations (PDEs) at high resolutions. We address these limitations by introducing a new data efficient and highly parallelizable operator learning approach with reduced memory requirement and better generalization, called multi-grid tensorized neural operator (MG-TFNO). MG-TFNO scales to large resolutions by leveraging local and global structures of full-scale, real-world phenomena, through a decomposition of both the input domain and the operator's parameter space. Our contributions are threefold: i) we enable parallelization over input samples with a novel multi-grid-based domain decomposition, ii) we represent the parameters of the model in a high-order latent subspace of the Fourier domain, through a global tensor factorization, resulting in an extreme reduction in the number of parameters and improved generalization, and iii) we propose architectural improvements to the backbone FNO. Our approach can be used in any operator learning setting. We demonstrate superior performance on the turbulent Navier-Stokes equations where we achieve less than half the error with over 150x compression. The tensorization combined with the domain decomposition, yields over 150x reduction in the number of parameters and 7x reduction in the domain size without losses in accuracy, while slightly enabling parallelism. ",
    "url": "https://arxiv.org/abs/2310.00120",
    "authors": [
      "Jean Kossaifi",
      "Nikola Kovachki",
      "Kamyar Azizzadenesheli",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00129",
    "title": "ILB: Graph Neural Network Enabled Emergency Demand Response Program For  Electricity",
    "abstract": "Demand Response (DR) programs have become a crucial component of smart electricity grids as they shift the flexibility of electricity consumption from supply to demand in response to the ever-growing demand for electricity. In particular, in times of crisis, an emergency DR program is required to manage unexpected spikes in energy demand. In this paper, we propose the Incentive-Driven Load Balancer (ILB), a program designed to efficiently manage demand and response during crisis situations. By offering incentives to flexible households likely to reduce demand, the ILB facilitates effective demand reduction and prepares them for unexpected events. To enable ILB, we introduce a two-step machine learning-based framework for participant selection, which employs a graph-based approach to identify households capable of easily adjusting their electricity consumption. This framework utilizes two Graph Neural Networks (GNNs): one for pattern recognition and another for household selection. Through extensive experiments on household-level electricity consumption in California, Michigan, and Texas, we demonstrate the ILB program's significant effectiveness in supporting communities during emergencies. ",
    "url": "https://arxiv.org/abs/2310.00129",
    "authors": [
      "Sina Shaham",
      "Bhaskar Krishnamachari",
      "Matthew Kahn"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.00137",
    "title": "On the Disconnect Between Theory and Practice of Overparametrized Neural  Networks",
    "abstract": "The infinite-width limit of neural networks (NNs) has garnered significant attention as a theoretical framework for analyzing the behavior of large-scale, overparametrized networks. By approaching infinite width, NNs effectively converge to a linear model with features characterized by the neural tangent kernel (NTK). This establishes a connection between NNs and kernel methods, the latter of which are well understood. Based on this link, theoretical benefits and algorithmic improvements have been hypothesized and empirically demonstrated in synthetic architectures. These advantages include faster optimization, reliable uncertainty quantification and improved continual learning. However, current results quantifying the rate of convergence to the kernel regime suggest that exploiting these benefits requires architectures that are orders of magnitude wider than they are deep. This assumption raises concerns that practically relevant architectures do not exhibit behavior as predicted via the NTK. In this work, we empirically investigate whether the limiting regime either describes the behavior of large-width architectures used in practice or is informative for algorithmic improvements. Our empirical results demonstrate that this is not the case in optimization, uncertainty quantification or continual learning. This observed disconnect between theory and practice calls into question the practical relevance of the infinite-width limit. ",
    "url": "https://arxiv.org/abs/2310.00137",
    "authors": [
      "Jonathan Wenger",
      "Felix Dangel",
      "Agustinus Kristiadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.00144",
    "title": "Probabilistic Sampling-Enhanced Temporal-Spatial GCN: A Scalable  Framework for Transaction Anomaly Detection in Ethereum Networks",
    "abstract": "The rapid evolution of the Ethereum network necessitates sophisticated techniques to ensure its robustness against potential threats and to maintain transparency. While Graph Neural Networks (GNNs) have pioneered anomaly detection in such platforms, capturing the intricacies of both spatial and temporal transactional patterns has remained a challenge. This study presents a fusion of Graph Convolutional Networks (GCNs) with Temporal Random Walks (TRW) enhanced by probabilistic sampling to bridge this gap. Our approach, unlike traditional GCNs, leverages the strengths of TRW to discern complex temporal sequences in Ethereum transactions, thereby providing a more nuanced transaction anomaly detection mechanism. Preliminary evaluations demonstrate that our TRW-GCN framework substantially advances the performance metrics over conventional GCNs in detecting anomalies and transaction bursts. This research not only underscores the potential of temporal cues in Ethereum transactional data but also offers a scalable and effective methodology for ensuring the security and transparency of decentralized platforms. By harnessing both spatial relationships and time-based transactional sequences as node features, our model introduces an additional layer of granularity, making the detection process more robust and less prone to false positives. This work lays the foundation for future research aimed at optimizing and enhancing the transparency of blockchain technologies, and serves as a testament to the significance of considering both time and space dimensions in the ever-evolving landscape of the decentralized platforms. ",
    "url": "https://arxiv.org/abs/2310.00144",
    "authors": [
      "Stefan Kambiz Behfar",
      "Jon Crowcroft"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.00149",
    "title": "One for All: Towards Training One Graph Model for All Classification  Tasks",
    "abstract": "Designing a single model that addresses multiple tasks has been a long-standing objective in artificial intelligence. Recently, large language models have demonstrated exceptional capability in integrating and solving different tasks within the language domain. However, a unified model for various tasks on graphs remains underexplored, primarily due to the challenges unique to the graph learning domain. First, graph data from different areas carry distinct attributes and follow different distributions. Such discrepancy makes it hard to represent graphs in a single representation space. Second, tasks on graphs diversify into node, link, and graph tasks, requiring distinct embedding strategies. Finally, an appropriate graph prompting paradigm for in-context learning is unclear. Striving to handle all the aforementioned challenges, we propose One for All (OFA), the first general framework that can use a single graph model to address the above challenges. Specifically, OFA proposes text-attributed graphs to unify different graph data by describing nodes and edges with natural language and uses language models to encode the diverse and possibly cross-domain text attributes to feature vectors in the same embedding space. Furthermore, OFA introduces the concept of nodes-of-interest to standardize different tasks with a single task representation. For in-context learning on graphs, OFA introduces a novel graph prompting paradigm that appends prompting substructures to the input graph, which enables it to address varied tasks without fine-tuning. We train the OFA model using graph data from multiple domains (including citation networks, molecular graphs, knowledge graphs, etc.) simultaneously and evaluate its ability in supervised, few-shot, and zero-shot learning scenarios. OFA performs well across different tasks, making it the first general-purpose graph classification model across domains. ",
    "url": "https://arxiv.org/abs/2310.00149",
    "authors": [
      "Hao Liu",
      "Jiarui Feng",
      "Lecheng Kong",
      "Ningyue Liang",
      "Dacheng Tao",
      "Yixin Chen",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00161",
    "title": "Detection-Oriented Image-Text Pretraining for Open-Vocabulary Detection",
    "abstract": "We present a new open-vocabulary detection approach based on detection-oriented image-text pretraining to bridge the gap between image-level pretraining and open-vocabulary object detection. At the pretraining phase, we replace the commonly used classification architecture with the detector architecture, which better serves the region-level recognition needs of detection by enabling the detector heads to learn from noisy image-text pairs. Using only standard contrastive loss and no pseudo-labeling, our approach is a simple yet effective extension of the contrastive learning method to learn emergent object-semantic cues. In addition, we propose a shifted-window learning approach upon window attention to make the backbone representation more robust, translation-invariant, and less biased by the window pattern. On the popular LVIS open-vocabulary detection benchmark, our approach sets a new state of the art of 40.4 mask AP$_r$ using the common ViT-L backbone, significantly outperforming the best existing approach by +6.5 mask AP$_r$ at system level. On the COCO benchmark, we achieve very competitive 40.8 novel AP without pseudo labeling or weak supervision. In addition, we evaluate our approach on the transfer detection setup, where ours outperforms the baseline significantly. Visualization reveals emerging object locality from the pretraining recipes compared to the baseline. Code and models will be publicly released. ",
    "url": "https://arxiv.org/abs/2310.00161",
    "authors": [
      "Dahun Kim",
      "Anelia Angelova",
      "Weicheng Kuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00165",
    "title": "SCoRe: Submodular Combinatorial Representation Learning for Real-World  Class-Imbalanced Settings",
    "abstract": "Representation Learning in real-world class-imbalanced settings has emerged as a challenging task in the evolution of deep learning. Lack of diversity in visual and structural features for rare classes restricts modern neural networks to learn discriminative feature clusters. This manifests in the form of large inter-class bias between rare object classes and elevated intra-class variance among abundant classes in the dataset. Although deep metric learning approaches have shown promise in this domain, significant improvements need to be made to overcome the challenges associated with class-imbalance in mission critical tasks like autonomous navigation and medical diagnostics. Set-based combinatorial functions like Submodular Information Measures exhibit properties that allow them to simultaneously model diversity and cooperation among feature clusters. In this paper, we introduce the SCoRe (Submodular Combinatorial Representation Learning) framework and propose a family of Submodular Combinatorial Loss functions to overcome these pitfalls in contrastive learning. We also show that existing contrastive learning approaches are either submodular or can be re-formulated to create their submodular counterparts. We conduct experiments on the newly introduced family of combinatorial objectives on two image classification benchmarks - pathologically imbalanced CIFAR-10, subsets of MedMNIST and a real-world road object detection benchmark - India Driving Dataset (IDD). Our experiments clearly show that the newly introduced objectives like Facility Location, Graph-Cut and Log Determinant outperform state-of-the-art metric learners by up to 7.6% for the imbalanced classification tasks and up to 19.4% for object detection tasks. ",
    "url": "https://arxiv.org/abs/2310.00165",
    "authors": [
      "Anay Majee",
      "Suraj Kothawade",
      "Krishnateja Killiamsetty",
      "Rishabh Iyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00171",
    "title": "Degree Distribution Identifiability of Stochastic Kronecker Graphs",
    "abstract": "Large-scale analysis of the distributions of the network graphs observed in naturally-occurring phenomena has revealed that the degrees of such graphs follow a power-law or lognormal distribution. Seshadhri, Pinar, and Kolda (J. ACM, 2013) proved that stochastic Kronecker graph (SKG) models cannot generate graphs with degree distribution that follows a power-law or lognormal distribution. As a result, variants of the SKG model have been proposed to generate graphs which approximately follow degree distributions, without any significant oscillations. However, all existing solutions either require significant additional parameterization or have no provable guarantees on the degree distribution. -- In this work, we present statistical and computational identifiability notions which imply the separation of SKG models. Specifically, we prove that SKG models in different identifiability classes can be separated by the existence of isolated vertices and connected components in their corresponding generated graphs. This could explain the large (i.e., $>50\\%$) fraction of isolated vertices in some popular graph generation benchmarks. -- We present and analyze an efficient algorithm that can get rid of oscillations in the degree distribution by mixing seeds of relative prime dimensions. For an initial $2\\times 1$ and $2\\times 2$ seed, a crucial subroutine of this algorithm solves a degree-2 and degree-4 optimization problem in the variables of the initial seed, respectively. We generalize this approach to solving optimization problems for $m\\times n$ seeds, for any $m, n\\in\\mathbb{N}$. -- The use of $3\\times 3$ seeds alone cannot get rid of significant oscillations. We prove that such seeds result in degree distribution that is bounded above by an exponential tail and thus cannot result in a power-law or lognormal. ",
    "url": "https://arxiv.org/abs/2310.00171",
    "authors": [
      "Daniel Alabi",
      "Dimitris Kalimeris"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.00179",
    "title": "Network Preference Dynamics using Lattice Theory",
    "abstract": "Preferences, fundamental in all forms of strategic behavior and collective decision-making, in their raw form, are an abstract ordering on a set of alternatives. Agents, we assume, revise their preferences as they gain more information about other agents. Exploiting the ordered algebraic structure of preferences, we introduce a message-passing algorithm for heterogeneous agents distributed over a network to update their preferences based on aggregations of the preferences of their neighbors in a graph. We demonstrate the existence of equilibrium points of the resulting global dynamical system of local preference updates and provide a sufficient condition for trajectories to converge to equilibria: stable preferences. Finally, we present numerical simulations demonstrating our preliminary results. ",
    "url": "https://arxiv.org/abs/2310.00179",
    "authors": [
      "Hans Riess",
      "Gregory Henselman-Petrusek",
      "Michael C. Munger",
      "Robert Ghrist",
      "Zachary I. Bell",
      "Michael M. Zavlanos"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2310.00180",
    "title": "MARL: Multi-scale Archetype Representation Learning for Urban Building  Energy Modeling",
    "abstract": "Building archetypes, representative models of building stock, are crucial for precise energy simulations in Urban Building Energy Modeling. The current widely adopted building archetypes are developed on a nationwide scale, potentially neglecting the impact of local buildings' geometric specificities. We present Multi-scale Archetype Representation Learning (MARL), an approach that leverages representation learning to extract geometric features from a specific building stock. Built upon VQ-AE, MARL encodes building footprints and purifies geometric information into latent vectors constrained by multiple architectural downstream tasks. These tailored representations are proven valuable for further clustering and building energy modeling. The advantages of our algorithm are its adaptability with respect to the different building footprint sizes, the ability for automatic generation across multi-scale regions, and the preservation of geometric features across neighborhoods and local ecologies. In our study spanning five regions in LA County, we show MARL surpasses both conventional and VQ-AE extracted archetypes in performance. Results demonstrate that geometric feature embeddings significantly improve the accuracy and reliability of energy consumption estimates. Code, dataset and trained models are publicly available: https://github.com/ZixunHuang1997/MARL-BuildingEnergyEstimation ",
    "url": "https://arxiv.org/abs/2310.00180",
    "authors": [
      "Xinwei Zhuang",
      "Zixun Huang",
      "Wentao Zeng",
      "Luisa Caldas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2310.00183",
    "title": "On the Equivalence of Graph Convolution and Mixup",
    "abstract": "This paper investigates the relationship between graph convolution and Mixup techniques. Graph convolution in a graph neural network involves aggregating features from neighboring samples to learn representative features for a specific node or sample. On the other hand, Mixup is a data augmentation technique that generates new examples by averaging features and one-hot labels from multiple samples. One commonality between these techniques is their utilization of information from multiple samples to derive feature representation. This study aims to explore whether a connection exists between these two approaches. Our investigation reveals that, under two mild conditions, graph convolution can be viewed as a specialized form of Mixup that is applied during both the training and testing phases. The two conditions are: 1) \\textit{Homophily Relabel} - assigning the target node's label to all its neighbors, and 2) \\textit{Test-Time Mixup} - Mixup the feature during the test time. We establish this equivalence mathematically by demonstrating that graph convolution networks (GCN) and simplified graph convolution (SGC) can be expressed as a form of Mixup. We also empirically verify the equivalence by training an MLP using the two conditions to achieve comparable performance. ",
    "url": "https://arxiv.org/abs/2310.00183",
    "authors": [
      "Xiaotian Han",
      "Hanqing Zeng",
      "Yu Chen",
      "Shaoliang Nie",
      "Jingzhou Liu",
      "Kanika Narang",
      "Zahra Shakeri",
      "Karthik Abinav Sankararaman",
      "Song Jiang",
      "Madian Khabsa",
      "Qifan Wang",
      "Xia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.00213",
    "title": "LSOR: Longitudinally-Consistent Self-Organized Representation Learning",
    "abstract": "Interpretability is a key issue when applying deep learning models to longitudinal brain MRIs. One way to address this issue is by visualizing the high-dimensional latent spaces generated by deep learning via self-organizing maps (SOM). SOM separates the latent space into clusters and then maps the cluster centers to a discrete (typically 2D) grid preserving the high-dimensional relationship between clusters. However, learning SOM in a high-dimensional latent space tends to be unstable, especially in a self-supervision setting. Furthermore, the learned SOM grid does not necessarily capture clinically interesting information, such as brain age. To resolve these issues, we propose the first self-supervised SOM approach that derives a high-dimensional, interpretable representation stratified by brain age solely based on longitudinal brain MRIs (i.e., without demographic or cognitive information). Called Longitudinally-consistent Self-Organized Representation learning (LSOR), the method is stable during training as it relies on soft clustering (vs. the hard cluster assignments used by existing SOM). Furthermore, our approach generates a latent space stratified according to brain age by aligning trajectories inferred from longitudinal MRIs to the reference vector associated with the corresponding SOM cluster. When applied to longitudinal MRIs of the Alzheimer's Disease Neuroimaging Initiative (ADNI, N=632), LSOR generates an interpretable latent space and achieves comparable or higher accuracy than the state-of-the-art representations with respect to the downstream tasks of classification (static vs. progressive mild cognitive impairment) and regression (determining ADAS-Cog score of all subjects). The code is available at https://github.com/ouyangjiahong/longitudinal-som-single-modality. ",
    "url": "https://arxiv.org/abs/2310.00213",
    "authors": [
      "Jiahong Ouyang",
      "Qingyu Zhao",
      "Ehsan Adeli",
      "Wei Peng",
      "Greg Zaharchuk",
      "Kilian M. Pohl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00222",
    "title": "Source Inference Attacks: Beyond Membership Inference Attacks in  Federated Learning",
    "abstract": "Federated learning (FL) is a popular approach to facilitate privacy-aware machine learning since it allows multiple clients to collaboratively train a global model without granting others access to their private data. It is, however, known that FL can be vulnerable to membership inference attacks (MIAs), where the training records of the global model can be distinguished from the testing records. Surprisingly, research focusing on the investigation of the source inference problem appears to be lacking. We also observe that identifying a training record's source client can result in privacy breaches extending beyond MIAs. For example, consider an FL application where multiple hospitals jointly train a COVID-19 diagnosis model, membership inference attackers can identify the medical records that have been used for training, and any additional identification of the source hospital can result the patient from the particular hospital more prone to discrimination. Seeking to contribute to the literature gap, we take the first step to investigate source privacy in FL. Specifically, we propose a new inference attack (hereafter referred to as source inference attack -- SIA), designed to facilitate an honest-but-curious server to identify the training record's source client. The proposed SIAs leverage the Bayesian theorem to allow the server to implement the attack in a non-intrusive manner without deviating from the defined FL protocol. We then evaluate SIAs in three different FL frameworks to show that in existing FL frameworks, the clients sharing gradients, model parameters, or predictions on a public dataset will leak such source information to the server. We also conduct extensive experiments on various datasets to investigate the key factors in an SIA. The experimental results validate the efficacy of the proposed SIAs. ",
    "url": "https://arxiv.org/abs/2310.00222",
    "authors": [
      "Hongsheng Hu",
      "Xuyun Zhang",
      "Zoran Salcic",
      "Lichao Sun",
      "Kim-Kwang Raymond Choo",
      "Gillian Dobbie"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.00227",
    "title": "Scaling for Training Time and Post-hoc Out-of-distribution Detection  Enhancement",
    "abstract": "The capacity of a modern deep learning system to determine if a sample falls within its realm of knowledge is fundamental and important. In this paper, we offer insights and analyses of recent state-of-the-art out-of-distribution (OOD) detection methods - extremely simple activation shaping (ASH). We demonstrate that activation pruning has a detrimental effect on OOD detection, while activation scaling enhances it. Moreover, we propose SCALE, a simple yet effective post-hoc network enhancement method for OOD detection, which attains state-of-the-art OOD detection performance without compromising in-distribution (ID) accuracy. By integrating scaling concepts into the training process to capture a sample's ID characteristics, we propose Intermediate Tensor SHaping (ISH), a lightweight method for training time OOD detection enhancement. We achieve AUROC scores of +1.85\\% for near-OOD and +0.74\\% for far-OOD datasets on the OpenOOD v1.5 ImageNet-1K benchmark. Our code and models are available at https://github.com/kai422/SCALE. ",
    "url": "https://arxiv.org/abs/2310.00227",
    "authors": [
      "Kai Xu",
      "Rongyu Chen",
      "Gianni Franchi",
      "Angela Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00233",
    "title": "causalimages: An R Package for Causal Inference with Earth Observation,  Bio-medical, and Social Science Images",
    "abstract": "The causalimages R package enables causal inference with image and image sequence data, providing new tools for integrating novel data sources like satellite and bio-medical imagery into the study of cause and effect. One set of functions enables image-based causal inference analyses. For example, one key function decomposes treatment effect heterogeneity by images using an interpretable Bayesian framework. This allows for determining which types of images or image sequences are most responsive to interventions. A second modeling function allows researchers to control for confounding using images. The package also allows investigators to produce embeddings that serve as vector summaries of the image or video content. Finally, infrastructural functions are also provided, such as tools for writing large-scale image and image sequence data as sequentialized byte strings for more rapid image analysis. causalimages therefore opens new capabilities for causal inference in R, letting researchers use informative imagery in substantive analyses in a fast and accessible manner. ",
    "url": "https://arxiv.org/abs/2310.00233",
    "authors": [
      "Connor T. Jerzak",
      "Adel Daoud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2310.00242",
    "title": "Walking = Traversable? : Traversability Prediction via Multiple Human  Object Tracking under Occlusion",
    "abstract": "The emerging ``Floor plan from human trails (PfH)\" technique has great potential for improving indoor robot navigation by predicting the traversability of occluded floors. This study presents an innovative approach that replaces first-person-view sensors with a third-person-view monocular camera mounted on the observer robot. This approach can gather measurements from multiple humans, expanding its range of applications. The key idea is to use two types of trackers, SLAM and MOT, to monitor stationary objects and moving humans and assess their interactions. This method achieves stable predictions of traversability even in challenging visual scenarios, such as occlusions, nonlinear perspectives, depth uncertainty, and intersections involving multiple humans. Additionally, we extend map quality metrics to apply to traversability maps, facilitating future research. We validate our proposed method through fusion and comparison with established techniques. ",
    "url": "https://arxiv.org/abs/2310.00242",
    "authors": [
      "Jonathan Tay Yu Liang",
      "Kanji Tanaka"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00244",
    "title": "Coordinated Rate-Splitting Multiple Access for Integrated  Satellite-Terrestrial Networks with Super-Common Message",
    "abstract": "Rate-splitting multiple access (RSMA) is an emerging multiple access technique for multi-antenna networks that splits messages into common and private parts for flexible interference mitigation. Motivated by its robustness and scalability, it is promising to employ RSMA in integrated satellite-terrestrial networks (ISTN), where a satellite serves satellite users (SUs) broadly with a multibeam multicast transmission while terrestrial base station (BS) serves cellular users (CUs) with a unicast transmission, operating in the same frequency band. To avoid the data exchange between satellite/cellular networks via backhaul, we assume a coordinated ISTN relying on imperfect channel state information. We put forth a coordinated RSMA framework tailored to the coordinated ISTN by applying inter-network rate-splitting (RS) with a super-common message on top of intra-network RS with common/private messages. With the unified RS design for inter- and intra-networks, we jointly optimize the precoding and power allocation of the private/common/super-common messages to achieve max-min fairness among all SUs and CUs through successive convex approximation. By doing so, the power of the super-common message can be adjusted according to interference levels of the satellite towards CUs, thereby potentially mitigating inter-network interference. Simulation results demonstrate the superiority and robustness of our approach to cope with various interference and propagation conditions. ",
    "url": "https://arxiv.org/abs/2310.00244",
    "authors": [
      "Juhwan Lee",
      "Jungwoo Lee",
      "Longfei Yin",
      "Wonjae Shin",
      "Bruno Clerckx"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.00246",
    "title": "A hybrid quantum-classical conditional generative adversarial network  algorithm for human-centered paradigm in cloud",
    "abstract": "As an emerging field that aims to bridge the gap between human activities and computing systems, human-centered computing (HCC) in cloud, edge, fog has had a huge impact on the artificial intelligence algorithms. The quantum generative adversarial network (QGAN) is considered to be one of the quantum machine learning algorithms with great application prospects, which also should be improved to conform to the human-centered paradigm. The generation process of QGAN is relatively random and the generated model does not conform to the human-centered concept, so it is not quite suitable for real scenarios. In order to solve these problems, a hybrid quantum-classical conditional generative adversarial network (QCGAN) algorithm is proposed, which is a knowledge-driven human-computer interaction computing mode that can be implemented in cloud. The purposes of stabilizing the generation process and realizing the interaction between human and computing process are achieved by inputting artificial conditional information in the generator and discriminator. The generator uses the parameterized quantum circuit with an all-to-all connected topology, which facilitates the tuning of network parameters during the training process. The discriminator uses the classical neural network, which effectively avoids the \"input bottleneck\" of quantum machine learning. Finally, the BAS training set is selected to conduct experiment on the quantum cloud computing platform. The result shows that the QCGAN algorithm can effectively converge to the Nash equilibrium point after training and perform human-centered classification generation tasks. ",
    "url": "https://arxiv.org/abs/2310.00246",
    "authors": [
      "Wenjie Liu",
      "Ying Zhang",
      "Zhiliang Deng",
      "Jiaojiao Zhao",
      "Lian Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Emerging Technologies (cs.ET)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2310.00247",
    "title": "Bridging the Gap Between Foundation Models and Heterogeneous Federated  Learning",
    "abstract": "Federated learning (FL) offers privacy-preserving decentralized machine learning, optimizing models at edge clients without sharing private data. Simultaneously, foundation models (FMs) have gained traction in the artificial intelligence (AI) community due to their exceptional performance across various tasks. However, integrating FMs into FL presents challenges, primarily due to their substantial size and intensive resource requirements. This is especially true when considering the resource heterogeneity in edge FL systems. We present an adaptive framework for Resource-aware Federated Foundation Models (RaFFM) to address these challenges. RaFFM introduces specialized model compression algorithms tailored for FL scenarios, such as salient parameter prioritization and high-performance subnetwork extraction. These algorithms enable dynamic scaling of given transformer-based FMs to fit heterogeneous resource constraints at the network edge during both FL's optimization and deployment stages. Experimental results demonstrate that RaFFM shows significant superiority in resource utilization efficiency and uses fewer resources to deploy FMs to FL. Despite the lower resource consumption, target models optimized by RaFFM achieve performance on par with traditional FL methods applied to full-sized FMs. This is evident across tasks in both natural language processing and computer vision domains. ",
    "url": "https://arxiv.org/abs/2310.00247",
    "authors": [
      "Sixing Yu",
      "J. Pablo Mu\u00f1oz",
      "Ali Jannesari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.00248",
    "title": "Learning State-Augmented Policies for Information Routing in  Communication Networks",
    "abstract": "This paper examines the problem of information routing in a large-scale communication network, which can be formulated as a constrained statistical learning problem having access to only local information. We delineate a novel State Augmentation (SA) strategy to maximize the aggregate information at source nodes using graph neural network (GNN) architectures, by deploying graph convolutions over the topological links of the communication network. The proposed technique leverages only the local information available at each node and efficiently routes desired information to the destination nodes. We leverage an unsupervised learning procedure to convert the output of the GNN architecture to optimal information routing strategies. In the experiments, we perform the evaluation on real-time network topologies to validate our algorithms. Numerical simulations depict the improved performance of the proposed method in training a GNN parameterization as compared to baseline algorithms. ",
    "url": "https://arxiv.org/abs/2310.00248",
    "authors": [
      "Sourajit Das",
      "Navid NaderiAlizadeh",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.00249",
    "title": "MMPI: a Flexible Radiance Field Representation by Multiple Multi-plane  Images Blending",
    "abstract": "This paper presents a flexible representation of neural radiance fields based on multi-plane images (MPI), for high-quality view synthesis of complex scenes. MPI with Normalized Device Coordinate (NDC) parameterization is widely used in NeRF learning for its simple definition, easy calculation, and powerful ability to represent unbounded scenes. However, existing NeRF works that adopt MPI representation for novel view synthesis can only handle simple forward-facing unbounded scenes, where the input cameras are all observing in similar directions with small relative translations. Hence, extending these MPI-based methods to more complex scenes like large-range or even 360-degree scenes is very challenging. In this paper, we explore the potential of MPI and show that MPI can synthesize high-quality novel views of complex scenes with diverse camera distributions and view directions, which are not only limited to simple forward-facing scenes. Our key idea is to encode the neural radiance field with multiple MPIs facing different directions and blend them with an adaptive blending operation. For each region of the scene, the blending operation gives larger blending weights to those advantaged MPIs with stronger local representation abilities while giving lower weights to those with weaker representation abilities. Such blending operation automatically modulates the multiple MPIs to appropriately represent the diverse local density and color information. Experiments on the KITTI dataset and ScanNet dataset demonstrate that our proposed MMPI synthesizes high-quality images from diverse camera pose distributions and is fast to train, outperforming the previous fast-training NeRF methods for novel view synthesis. Moreover, we show that MMPI can encode extremely long trajectories and produce novel view renderings, demonstrating its potential in applications like autonomous driving. ",
    "url": "https://arxiv.org/abs/2310.00249",
    "authors": [
      "Yuze He",
      "Peng Wang",
      "Yubin Hu",
      "Wang Zhao",
      "Ran Yi",
      "Yong-Jin Liu",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00262",
    "title": "Robust Integral Consensus Control of Multi-Agent Networks Perturbed by  Matched and Unmatched Disturbances: The Case of Directed Graphs",
    "abstract": "This work presents a new method to design consensus controllers for perturbed double integrator systems whose interconnection is described by a directed graph containing a rooted spanning tree. We propose new robust controllers to solve the consensus and synchronization problems when the systems are under the effects of matched and unmatched disturbances. In both problems, we present simple continuous controllers, whose integral actions allow us to handle the disturbances. A rigorous stability analysis based on Lyapunov's direct method for unperturbed networked systems is presented. To assess the performance of our result, a representative simulation study is presented. ",
    "url": "https://arxiv.org/abs/2310.00262",
    "authors": [
      "Jose Guadalupe Romero",
      "David Navarro-Alarcon"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.00268",
    "title": "Unravel Anomalies: An End-to-end Seasonal-Trend Decomposition Approach  for Time Series Anomaly Detection",
    "abstract": "Traditional Time-series Anomaly Detection (TAD) methods often struggle with the composite nature of complex time-series data and a diverse array of anomalies. We introduce TADNet, an end-to-end TAD model that leverages Seasonal-Trend Decomposition to link various types of anomalies to specific decomposition components, thereby simplifying the analysis of complex time-series and enhancing detection performance. Our training methodology, which includes pre-training on a synthetic dataset followed by fine-tuning, strikes a balance between effective decomposition and precise anomaly detection. Experimental validation on real-world datasets confirms TADNet's state-of-the-art performance across a diverse range of anomalies. ",
    "url": "https://arxiv.org/abs/2310.00268",
    "authors": [
      "Zhenwei Zhang",
      "Ruiqi Wang",
      "Ran Ding",
      "Yuantao Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.00278",
    "title": "A bibliometric Analysis on Spectrum Sensing in Wireless Networks",
    "abstract": "Spectrum scarcity is a prevalent problem in wireless networks due to the strict allotment of the spectrum (frequency bands) to licensed users by network regulatory bodies. Such an operation implies that the unlicensed users (secondary wireless spectrum users) have to evacuate the spectrum when the primary wireless spectrum users (licensed users) are utilizing the frequency bands to avoid interference. Cognitive radio alleviates the spectrum shortage by detecting unoccupied frequency bands. This reduces the underutilization of frequency bands in wireless networks. There have been numerous related studies on spectrum sensing, however, few studies have conducted a bibliometric analysis on this subject. The goal of this study was to conduct a bibliometric analysis on the optimization of spectrum sensing. The PRISMA methodology was the basis for the bibliometric analysis to identify the limitations of the existing spectrum sensing techniques. The findings revealed that various machine learning or hybrid models outperformed the traditional techniques such as matched filter and energy detectors at the lowest signal to noise ratio (SNR). SNR is the ratio of the desired signal magnitude to the background noise magnitude. This study, therefore, recommends researchers propose alternative techniques to optimize (improve) spectrum sensing in wireless networks. More work should be done to develop models that optimize spectrum sensing at low SNR. ",
    "url": "https://arxiv.org/abs/2310.00278",
    "authors": [
      "Nyashadzashe Tamuka",
      "Khulumani Sibanda"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2310.00280",
    "title": "Corex: Pushing the Boundaries of Complex Reasoning through Multi-Model  Collaboration",
    "abstract": "Large Language Models (LLMs) are evolving at an unprecedented pace and have exhibited considerable capability in the realm of natural language processing (NLP) with world knowledge. Benefiting from ultra-large-scale training corpora, a single LLM can manage typical NLP tasks competently. However, its performance in executing reasoning tasks is still confined by the limitations of its internal representations. To push this boundary further, we introduce Corex in this paper, a suite of novel general-purpose strategies that transform LLMs into autonomous agents pioneering multi-model collaborations for complex task-solving. Inspired by human behaviors, Corex is constituted by diverse collaboration paradigms including Debate, Review, and Retrieve modes, which collectively work towards enhancing the factuality, faithfulness, and reliability of the reasoning process. These paradigms foster task-agnostic approaches that enable LLMs to ''think outside the box,'' thereby overcoming hallucinations and providing better solutions. Through extensive experiments across four different types of reasoning tasks, we demonstrate that orchestrating multiple LLMs to work in concert yields substantially better performance compared to existing methods. Further results and in-depth analysis demonstrate the cost-effectiveness of our method, facilitating collaboration among different LLMs and promoting annotation efficiency. ",
    "url": "https://arxiv.org/abs/2310.00280",
    "authors": [
      "Qiushi Sun",
      "Zhangyue Yin",
      "Xiang Li",
      "Zhiyong Wu",
      "Xipeng Qiu",
      "Lingpeng Kong"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.00299",
    "title": "RelBERT: Embedding Relations with Language Models",
    "abstract": "Many applications need access to background knowledge about how different concepts and entities are related. Although Knowledge Graphs (KG) and Large Language Models (LLM) can address this need to some extent, KGs are inevitably incomplete and their relational schema is often too coarse-grained, while LLMs are inefficient and difficult to control. As an alternative, we propose to extract relation embeddings from relatively small language models. In particular, we show that masked language models such as RoBERTa can be straightforwardly fine-tuned for this purpose, using only a small amount of training data. The resulting model, which we call RelBERT, captures relational similarity in a surprisingly fine-grained way, allowing us to set a new state-of-the-art in analogy benchmarks. Crucially, RelBERT is capable of modelling relations that go well beyond what the model has seen during training. For instance, we obtained strong results on relations between named entities with a model that was only trained on lexical relations between concepts, and we observed that RelBERT can recognise morphological analogies despite not being trained on such examples. Overall, we find that RelBERT significantly outperforms strategies based on prompting language models that are several orders of magnitude larger, including recent GPT-based models and open source models. ",
    "url": "https://arxiv.org/abs/2310.00299",
    "authors": [
      "Asahi Ushio",
      "Jose Camacho-Collados",
      "Steven Schockaert"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.00307",
    "title": "Dual-Augmented Transformer Network for Weakly Supervised Semantic  Segmentation",
    "abstract": "Weakly supervised semantic segmentation (WSSS), a fundamental computer vision task, which aims to segment out the object within only class-level labels. The traditional methods adopt the CNN-based network and utilize the class activation map (CAM) strategy to discover the object regions. However, such methods only focus on the most discriminative region of the object, resulting in incomplete segmentation. An alternative is to explore vision transformers (ViT) to encode the image to acquire the global semantic information. Yet, the lack of transductive bias to objects is a flaw of ViT. In this paper, we explore the dual-augmented transformer network with self-regularization constraints for WSSS. Specifically, we propose a dual network with both CNN-based and transformer networks for mutually complementary learning, where both networks augment the final output for enhancement. Massive systemic evaluations on the challenging PASCAL VOC 2012 benchmark demonstrate the effectiveness of our method, outperforming previous state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2310.00307",
    "authors": [
      "Jingliang Deng",
      "Zonghan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00332",
    "title": "MFL Data Preprocessing and CNN-based Oil Pipeline Defects Detection",
    "abstract": "Recently, the application of computer vision for anomaly detection has been under attention in several industrial fields. An important example is oil pipeline defect detection. Failure of one oil pipeline can interrupt the operation of the entire transportation system or cause a far-reaching failure. The automated defect detection could significantly decrease the inspection time and the related costs. However, there is a gap in the related literature when it comes to dealing with this task. The existing studies do not sufficiently cover the research of the Magnetic Flux Leakage data and the preprocessing techniques that allow overcoming the limitations set by the available data. This work focuses on alleviating these issues. Moreover, in doing so, we exploited the recent convolutional neural network structures and proposed robust approaches, aiming to acquire high performance considering the related metrics. The proposed approaches and their applicability were verified using real-world data. ",
    "url": "https://arxiv.org/abs/2310.00332",
    "authors": [
      "Iurii Katser",
      "Vyacheslav Kozitsin",
      "Igor Mozolin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.00335",
    "title": "Anomaly Detection in Power Generation Plants with Generative Adversarial  Networks",
    "abstract": "Anomaly detection is a critical task that involves the identification of data points that deviate from a predefined pattern, useful for fraud detection and related activities. Various techniques are employed for anomaly detection, but recent research indicates that deep learning methods, with their ability to discern intricate data patterns, are well-suited for this task. This study explores the use of Generative Adversarial Networks (GANs) for anomaly detection in power generation plants. The dataset used in this investigation comprises fuel consumption records obtained from power generation plants operated by a telecommunications company. The data was initially collected in response to observed irregularities in the fuel consumption patterns of the generating sets situated at the company's base stations. The dataset was divided into anomalous and normal data points based on specific variables, with 64.88% classified as normal and 35.12% as anomalous. An analysis of feature importance, employing the random forest classifier, revealed that Running Time Per Day exhibited the highest relative importance. A GANs model was trained and fine-tuned both with and without data augmentation, with the goal of increasing the dataset size to enhance performance. The generator model consisted of five dense layers using the tanh activation function, while the discriminator comprised six dense layers, each integrated with a dropout layer to prevent overfitting. Following data augmentation, the model achieved an accuracy rate of 98.99%, compared to 66.45% before augmentation. This demonstrates that the model nearly perfectly classified data points into normal and anomalous categories, with the augmented data significantly enhancing the GANs' performance in anomaly detection. Consequently, this study recommends the use of GANs, particularly when using large datasets, for effective anomaly detection. ",
    "url": "https://arxiv.org/abs/2310.00335",
    "authors": [
      "Marcellin Atemkeng",
      "Toheeb Aduramomi Jimoh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.00336",
    "title": "DURENDAL: Graph deep learning framework for temporal heterogeneous  networks",
    "abstract": "Temporal heterogeneous networks (THNs) are evolving networks that characterize many real-world applications such as citation and events networks, recommender systems, and knowledge graphs. Although different Graph Neural Networks (GNNs) have been successfully applied to dynamic graphs, most of them only support homogeneous graphs or suffer from model design heavily influenced by specific THNs prediction tasks. Furthermore, there is a lack of temporal heterogeneous networked data in current standard graph benchmark datasets. Hence, in this work, we propose DURENDAL, a graph deep learning framework for THNs. DURENDAL can help to easily repurpose any heterogeneous graph learning model to evolving networks by combining design principles from snapshot-based and multirelational message-passing graph learning models. We introduce two different schemes to update embedding representations for THNs, discussing the strengths and weaknesses of both strategies. We also extend the set of benchmarks for TNHs by introducing two novel high-resolution temporal heterogeneous graph datasets derived from an emerging Web3 platform and a well-established e-commerce website. Overall, we conducted the experimental evaluation of the framework over four temporal heterogeneous network datasets on future link prediction tasks in an evaluation setting that takes into account the evolving nature of the data. Experiments show the prediction power of DURENDAL compared to current solutions for evolving and dynamic graphs, and the effectiveness of its model design. ",
    "url": "https://arxiv.org/abs/2310.00336",
    "authors": [
      "Manuel Dileo",
      "Matteo Zignani",
      "Sabrina Gaito"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00337",
    "title": "Quantization of Deep Neural Networks to facilitate self-correction of  weights on Phase Change Memory-based analog hardware",
    "abstract": "In recent years, hardware-accelerated neural networks have gained significant attention for edge computing applications. Among various hardware options, crossbar arrays, offer a promising avenue for efficient storage and manipulation of neural network weights. However, the transition from trained floating-point models to hardware-constrained analog architectures remains a challenge. In this work, we combine a quantization technique specifically designed for such architectures with a novel self-correcting mechanism. By utilizing dual crossbar connections to represent both the positive and negative parts of a single weight, we develop an algorithm to approximate a set of multiplicative weights. These weights, along with their differences, aim to represent the original network's weights with minimal loss in performance. We implement the models using IBM's aihwkit and evaluate their efficacy over time. Our results demonstrate that, when paired with an on-chip pulse generator, our self-correcting neural network performs comparably to those trained with analog-aware algorithms. ",
    "url": "https://arxiv.org/abs/2310.00337",
    "authors": [
      "Arseni Ivanov"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.00342",
    "title": "RBF Weighted Hyper-Involution for RGB-D Object Detection",
    "abstract": "A vast majority of conventional augmented reality devices are equipped with depth sensors. Depth images produced by such sensors contain complementary information for object detection when used with color images. Despite the benefits, it remains a complex task to simultaneously extract photometric and depth features in real time due to the immanent difference between depth and color images. Moreover, standard convolution operations are not sufficient to properly extract information directly from raw depth images leading to intermediate representations of depth which is inefficient. To address these issues, we propose a real-time and two stream RGBD object detection model. The proposed model consists of two new components: a depth guided hyper-involution that adapts dynamically based on the spatial interaction pattern in the raw depth map and an up-sampling based trainable fusion layer that combines the extracted depth and color image features without blocking the information transfer between them. We show that the proposed model outperforms other RGB-D based object detection models on NYU Depth v2 dataset and achieves comparable (second best) results on SUN RGB-D. Additionally, we introduce a new outdoor RGB-D object detection dataset where our proposed model outperforms other models. The performance evaluation on diverse synthetic data generated from CAD models and images shows the potential of the proposed model to be adapted to augmented reality based applications. ",
    "url": "https://arxiv.org/abs/2310.00342",
    "authors": [
      "Mehfuz A Rahman",
      "Jiju Peethambaran",
      "Neil London"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00354",
    "title": "AI-Dentify: Deep learning for proximal caries detection on bitewing  x-ray -- HUNT4 Oral Health Study",
    "abstract": "Background: Dental caries diagnosis requires the manual inspection of diagnostic bitewing images of the patient, followed by a visual inspection and probing of the identified dental pieces with potential lesions. Yet the use of artificial intelligence, and in particular deep-learning, has the potential to aid in the diagnosis by providing a quick and informative analysis of the bitewing images. Methods: A dataset of 13,887 bitewings from the HUNT4 Oral Health Study were annotated individually by six different experts, and used to train three different object detection deep-learning architectures: RetinaNet (ResNet50), YOLOv5 (M size), and EfficientDet (D0 and D1 sizes). A consensus dataset of 197 images, annotated jointly by the same six dentist, was used for evaluation. A five-fold cross validation scheme was used to evaluate the performance of the AI models. Results: the trained models show an increase in average precision and F1-score, and decrease of false negative rate, with respect to the dental clinicians. Out of the three architectures studied, YOLOv5 shows the largest improvement, reporting 0.647 mean average precision, 0.548 mean F1-score, and 0.149 mean false negative rate. Whereas the best annotators on each of these metrics reported 0.299, 0.495, and 0.164 respectively. Conclusion: Deep-learning models have shown the potential to assist dental professionals in the diagnosis of caries. Yet, the task remains challenging due to the artifacts natural to the bitewings. ",
    "url": "https://arxiv.org/abs/2310.00354",
    "authors": [
      "Javier P\u00e9rez de Frutos",
      "Ragnhild Holden Helland",
      "Shreya Desai",
      "Line Cathrine Nymoen",
      "Thomas Lang\u00f8",
      "Theodor Remman",
      "Abhijit Sen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.00357",
    "title": "Structural Adversarial Objectives for\\\\Self-Supervised Representation  Learning",
    "abstract": "Within the framework of generative adversarial networks (GANs), we propose objectives that task the discriminator for self-supervised representation learning via additional structural modeling responsibilities. In combination with an efficient smoothness regularizer imposed on the network, these objectives guide the discriminator to learn to extract informative representations, while maintaining a generator capable of sampling from the domain. Specifically, our objectives encourage the discriminator to structure features at two levels of granularity: aligning distribution characteristics, such as mean and variance, at coarse scales, and grouping features into local clusters at finer scales. Operating as a feature learner within the GAN framework frees our self-supervised system from the reliance on hand-crafted data augmentation schemes that are prevalent across contrastive representation learning methods. Across CIFAR-10/100 and an ImageNet subset, experiments demonstrate that equipping GANs with our self-supervised objectives suffices to produce discriminators which, evaluated in terms of representation learning, compete with networks trained by contrastive learning approaches. ",
    "url": "https://arxiv.org/abs/2310.00357",
    "authors": [
      "Xiao Zhang",
      "Michael Maire"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00359",
    "title": "Improving Cross-dataset Deepfake Detection with Deep Information  Decomposition",
    "abstract": "Deepfake technology poses a significant threat to security and social trust. Although existing detection methods have demonstrated high performance in identifying forgeries within datasets using the same techniques for training and testing, they suffer from sharp performance degradation when faced with cross-dataset scenarios where unseen deepfake techniques are tested. To address this challenge, we propose a deep information decomposition (DID) framework in this paper. Unlike most existing deepfake detection methods, our framework prioritizes high-level semantic features over visual artifacts. Specifically, it decomposes facial features into deepfake-related and irrelevant information and optimizes the deepfake information for real/fake discrimination to be independent of other factors. Our approach improves the robustness of deepfake detection against various irrelevant information changes and enhances the generalization ability of the framework to detect unseen forgery methods. Extensive experimental comparisons with existing state-of-the-art detection methods validate the effectiveness and superiority of the DID framework on cross-dataset deepfake detection. ",
    "url": "https://arxiv.org/abs/2310.00359",
    "authors": [
      "Shanmin Yang",
      "Shu Hu",
      "Bin Zhu",
      "Ying Fu",
      "Siwei Lyu",
      "Xi Wu",
      "Xin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00372",
    "title": "Deep Active Learning with Noisy Oracle in Object Detection",
    "abstract": "Obtaining annotations for complex computer vision tasks such as object detection is an expensive and time-intense endeavor involving a large number of human workers or expert opinions. Reducing the amount of annotations required while maintaining algorithm performance is, therefore, desirable for machine learning practitioners and has been successfully achieved by active learning algorithms. However, it is not merely the amount of annotations which influences model performance but also the annotation quality. In practice, the oracles that are queried for new annotations frequently contain significant amounts of noise. Therefore, cleansing procedures are oftentimes necessary to review and correct given labels. This process is subject to the same budget as the initial annotation itself since it requires human workers or even domain experts. Here, we propose a composite active learning framework including a label review module for deep object detection. We show that utilizing part of the annotation budget to correct the noisy annotations partially in the active dataset leads to early improvements in model performance, especially when coupled with uncertainty-based query strategies. The precision of the label error proposals has a significant influence on the measured effect of the label review. In our experiments we achieve improvements of up to 4.5 mAP points of object detection performance by incorporating label reviews at equal annotation budget. ",
    "url": "https://arxiv.org/abs/2310.00372",
    "authors": [
      "Marius Schubert",
      "Tobias Riedlinger",
      "Karsten Kahl",
      "Matthias Rottmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00384",
    "title": "Joint Power and 3D Trajectory Optimization for UAV-enabled Wireless  Powered Communication Networks with Obstacles",
    "abstract": "Unmanned aerial vehicle (UAV)-enabled wireless powered communication networks (WPCNs) are promising technologies in 5G/6G wireless communications, while there are several challenges about UAV power allocation and scheduling to enhance the energy utilization efficiency, considering the existence of obstacles. In this work, we consider a UAV-enabled WPCN scenario that a UAV needs to cover the ground wireless devices (WDs). During the coverage process, the UAV needs to collect data from the WDs and charge them simultaneously. To this end, we formulate a joint-UAV power and three-dimensional (3D) trajectory optimization problem (JUPTTOP) to simultaneously increase the total number of the covered WDs, increase the time efficiency, and reduce the total flying distance of UAV so as to improve the energy utilization efficiency in the network. Due to the difficulties and complexities, we decompose it into two sub optimization problems, which are the UAV power allocation optimization problem (UPAOP) and UAV 3D trajectory optimization problem (UTTOP), respectively. Then, we propose an improved non-dominated sorting genetic algorithm-II with K-means initialization operator and Variable dimension mechanism (NSGA-II-KV) for solving the UPAOP. For UTTOP, we first introduce a pretreatment method, and then use an improved particle swarm optimization with Normal distribution initialization, Genetic mechanism, Differential mechanism and Pursuit operator (PSO-NGDP) to deal with this sub optimization problem. Simulation results verify the effectiveness of the proposed strategies under different scales and settings of the networks. ",
    "url": "https://arxiv.org/abs/2310.00384",
    "authors": [
      "Hongyang Pan",
      "Yanheng Liu",
      "Geng Sun",
      "Junsong Fan",
      "Shuang Liang",
      "Chau Yuen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.00387",
    "title": "Privacy-Preserving Distributed Market Mechanism for Active Distribution  Networks",
    "abstract": "Amidst the worldwide efforts to decarbonize power networks, Local Electricity Markets (LEMs) in distribution networks are gaining importance due to the increased adoption of renewable energy sources and prosumers. Considering that LEMs involve data exchange among independent entities, privacy and cybersecurity are some of the main practical challenges in LEM design. This paper proposes a secure market protocol using innovations from distributed optimization and Secure MultiParty Computation (SMPC). The considered LEM is formulated as an uncertainty-aware joint market for energy and reserves with affine balancing policies. To achieve scalability and enable the use of SMPC, market clearing is solved using the Consensus ADMM algorithm. Subsequently, the data exchange among participants via ADMM iterations is protected using the Shamir secret-sharing scheme to ensure privacy. The market protocol is further reinforced by a secure and verifiable settlement process that uses SMPC and ElGamal commitments to verify market quantities and by a secure recovery scheme for missing network measurements. Finally, the feasibility and performance of the proposed LEM are evaluated on a 15-bus test network. ",
    "url": "https://arxiv.org/abs/2310.00387",
    "authors": [
      "Matthias Franke",
      "Ognjen Stanojev",
      "Lesia Mitridati",
      "Gabriela Hug"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.00395",
    "title": "Analysis of system capacity and spectral efficiency of fixed-grid  network",
    "abstract": "In this article, the performance of a fixed grid network is examined for various modulation formats to estimate the system's capacity and spectral efficiency. The optical In-phase Quadrature Modulator structure is used to build a fixed grid network modulation, and the homodyne detection approach is used for the receiver. Data multiplexing is accomplished using the Polarization Division Multiplexed technology. 100 Gbps, 150 Gbps, and 200 Gbps data rates are transmitted under these circumstances utilizing various modulation formats. Various pre-processing and signal recovery steps are explained by using modern digital signal processing systems. The achieved spectrum efficiencies for PM-QPSK, PM-8 QAM, and PM-16 QAM, respectively, were 2, 3, and 4 bits/s/Hz. Different modulation like PM-QPSK, PM-8-QAM, and PM-16-QAM each has system capacities of 8-9, 12-13.5, and 16-18 Tbps and it reaches transmission distances of 3000, 1300, and 700 kilometers with acceptable Bit Error Rate less than equal to 2*10-3 respectively. Peak optical power for received signal detection and full width at half maximum is noted for the different modulations under a fixed grind network. ",
    "url": "https://arxiv.org/abs/2310.00395",
    "authors": [
      "Adarsha M",
      "S. Malathi",
      "Santosh Kumar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.00396",
    "title": "Joint Scheduling and Trajectory Optimization of Charging UAV in Wireless  Rechargeable Sensor Networks",
    "abstract": "Wireless rechargeable sensor networks with a charging unmanned aerial vehicle (CUAV) have the broad application prospects in the power supply of the rechargeable sensor nodes (SNs). However, how to schedule a CUAV and design the trajectory to improve the charging efficiency of the entire system is still a vital problem. In this paper, we formulate a joint-CUAV scheduling and trajectory optimization problem (JSTOP) to simultaneously minimize the hovering points of CUAV, the number of the repeatedly covered SNs and the flying distance of CUAV for charging all SNs. Due to the complexity of JSTOP, it is decomposed into two optimization subproblems that are CUAV scheduling optimization problem (CSOP) and CUAV trajectory optimization problem (CTOP). CSOP is a hybrid optimization problem that consists of the continuous and discrete solution space, and the solution dimension in CSOP is not fixed since it should be changed with the number of hovering points of CUAV. Moreover, CTOP is a completely discrete optimization problem. Thus, we propose a particle swarm optimization (PSO) with a flexible dimension mechanism, a K-means operator and a punishment-compensation mechanism (PSOFKP) and a PSO with a discretization factor, a 2-opt operator and a path crossover reduction mechanism (PSOD2P) to solve the converted CSOP and CTOP, respectively. Simulation results evaluate the benefits of PSOFKP and PSOD2P under different scales and settings of the network, and the stability of the proposed algorithms is verified. ",
    "url": "https://arxiv.org/abs/2310.00396",
    "authors": [
      "Yanheng Liu",
      "Hongyang Pan",
      "Geng Sun",
      "Aimin Wang",
      "Jiahui Li",
      "Shuang Liang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.00400",
    "title": "MonoGAE: Roadside Monocular 3D Object Detection with Ground-Aware  Embeddings",
    "abstract": "Although the majority of recent autonomous driving systems concentrate on developing perception methods based on ego-vehicle sensors, there is an overlooked alternative approach that involves leveraging intelligent roadside cameras to help extend the ego-vehicle perception ability beyond the visual range. We discover that most existing monocular 3D object detectors rely on the ego-vehicle prior assumption that the optical axis of the camera is parallel to the ground. However, the roadside camera is installed on a pole with a pitched angle, which makes the existing methods not optimal for roadside scenes. In this paper, we introduce a novel framework for Roadside Monocular 3D object detection with ground-aware embeddings, named MonoGAE. Specifically, the ground plane is a stable and strong prior knowledge due to the fixed installation of cameras in roadside scenarios. In order to reduce the domain gap between the ground geometry information and high-dimensional image features, we employ a supervised training paradigm with a ground plane to predict high-dimensional ground-aware embeddings. These embeddings are subsequently integrated with image features through cross-attention mechanisms. Furthermore, to improve the detector's robustness to the divergences in cameras' installation poses, we replace the ground plane depth map with a novel pixel-level refined ground plane equation map. Our approach demonstrates a substantial performance advantage over all previous monocular 3D object detectors on widely recognized 3D detection benchmarks for roadside cameras. The code and pre-trained models will be released soon. ",
    "url": "https://arxiv.org/abs/2310.00400",
    "authors": [
      "Lei Yang",
      "Jiaxin Yu",
      "Xinyu Zhang",
      "Jun Li",
      "Li Wang",
      "Yi Huang",
      "Chuang Zhang",
      "Hong Wang",
      "Yiming Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00401",
    "title": "Better Situational Graphs by Inferring High-level Semantic-Relational  Concepts",
    "abstract": "Recent works on SLAM extend their pose graphs with higher-level semantic concepts exploiting relationships between them, to provide, not only a richer representation of the situation/environment but also to improve the accuracy of its estimation. Concretely, our previous work, Situational Graphs (S-Graphs), a pioneer in jointly leveraging semantic relationships in the factor optimization process, relies on semantic entities such as wall surfaces and rooms, whose relationship is mathematically defined. Nevertheless, excerpting these high-level concepts relying exclusively on the lower-level factor-graph remains a challenge and it is currently done with ad-hoc algorithms, which limits its capability to include new semantic-relational concepts. To overcome this limitation, in this work, we propose a Graph Neural Network (GNN) for learning high-level semantic-relational concepts that can be inferred from the low-level factor graph. We have demonstrated that we can infer room entities and their relationship to the mapped wall surfaces, more accurately and more computationally efficient than the baseline algorithm. Additionally, to demonstrate the versatility of our method, we provide a new semantic concept, i.e. wall, and its relationship with its wall surfaces. Our proposed method has been integrated into S-Graphs+, and it has been validated in both simulated and real datasets. A docker container with our software will be made available to the scientific community. ",
    "url": "https://arxiv.org/abs/2310.00401",
    "authors": [
      "Jose Andres Millan-Romera",
      "Hriday Bavle",
      "Muhammad Shaheer",
      "Martin R. Oswald",
      "Holger Voos",
      "Jose Luis Sanchez-Lopez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.00402",
    "title": "DiskANN++: Efficient Page-based Search over Isomorphic Mapped Graph  Index using Query-sensitivity Entry Vertex",
    "abstract": "Given a vector dataset $\\mathcal{X}$ and a query vector $\\vec{x}_q$, graph-based Approximate Nearest Neighbor Search (ANNS) aims to build a graph index $G$ and approximately return vectors with minimum distances to $\\vec{x}_q$ by searching over $G$. The main drawback of graph-based ANNS is that a graph index would be too large to fit into the memory especially for a large-scale $\\mathcal{X}$. To solve this, a Product Quantization (PQ)-based hybrid method called DiskANN is proposed to store a low-dimensional PQ index in memory and retain a graph index in SSD, thus reducing memory overhead while ensuring a high search accuracy. However, it suffers from two I/O issues that significantly affect the overall efficiency: (1) long routing path from an entry vertex to the query's neighborhood that results in large number of I/O requests and (2) redundant I/O requests during the routing process. We propose an optimized DiskANN++ to overcome above issues. Specifically, for the first issue, we present a query-sensitive entry vertex selection strategy to replace DiskANN's static graph-central entry vertex by a dynamically determined entry vertex that is close to the query. For the second I/O issue, we present an isomorphic mapping on DiskANN's graph index to optimize the SSD layout and propose an asynchronously optimized Pagesearch based on the optimized SSD layout as an alternative to DiskANN's beamsearch. Comprehensive experimental studies on eight real-world datasets demonstrate our DiskANN++'s superiority on efficiency. We achieve a notable 1.5 X to 2.2 X improvement on QPS compared to DiskANN, given the same accuracy constraint. ",
    "url": "https://arxiv.org/abs/2310.00402",
    "authors": [
      "Jiongkang Ni",
      "Xiaoliang Xu",
      "Yuxiang Wang",
      "Can Li",
      "Jiajie Yao",
      "Shihai Xiao",
      "Xuecang Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2310.00405",
    "title": "Controlling Neural Style Transfer with Deep Reinforcement Learning",
    "abstract": "Controlling the degree of stylization in the Neural Style Transfer (NST) is a little tricky since it usually needs hand-engineering on hyper-parameters. In this paper, we propose the first deep Reinforcement Learning (RL) based architecture that splits one-step style transfer into a step-wise process for the NST task. Our RL-based method tends to preserve more details and structures of the content image in early steps, and synthesize more style patterns in later steps. It is a user-easily-controlled style-transfer method. Additionally, as our RL-based model performs the stylization progressively, it is lightweight and has lower computational complexity than existing one-step Deep Learning (DL) based models. Experimental results demonstrate the effectiveness and robustness of our method. ",
    "url": "https://arxiv.org/abs/2310.00405",
    "authors": [
      "Chengming Feng",
      "Jing Hu",
      "Xin Wang",
      "Shu Hu",
      "Bin Zhu",
      "Xi Wu",
      "Hongtu Zhu",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00413",
    "title": "SSIF: Learning Continuous Image Representation for Spatial-Spectral  Super-Resolution",
    "abstract": "Existing digital sensors capture images at fixed spatial and spectral resolutions (e.g., RGB, multispectral, and hyperspectral images), and each combination requires bespoke machine learning models. Neural Implicit Functions partially overcome the spatial resolution challenge by representing an image in a resolution-independent way. However, they still operate at fixed, pre-defined spectral resolutions. To address this challenge, we propose Spatial-Spectral Implicit Function (SSIF), a neural implicit model that represents an image as a function of both continuous pixel coordinates in the spatial domain and continuous wavelengths in the spectral domain. We empirically demonstrate the effectiveness of SSIF on two challenging spatio-spectral super-resolution benchmarks. We observe that SSIF consistently outperforms state-of-the-art baselines even when the baselines are allowed to train separate models at each spectral resolution. We show that SSIF generalizes well to both unseen spatial resolutions and spectral resolutions. Moreover, SSIF can generate high-resolution images that improve the performance of downstream tasks (e.g., land use classification) by 1.7%-7%. ",
    "url": "https://arxiv.org/abs/2310.00413",
    "authors": [
      "Gengchen Mai",
      "Ni Lao",
      "Weiwei Sun",
      "Yuchi Ma",
      "Jiaming Song",
      "Chenlin Meng",
      "Hongxu Ma",
      "Jinmeng Rao",
      "Ziyuan Li",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.00418",
    "title": "MVC: A Multi-Task Vision Transformer Network for COVID-19 Diagnosis from  Chest X-ray Images",
    "abstract": "Medical image analysis using computer-based algorithms has attracted considerable attention from the research community and achieved tremendous progress in the last decade. With recent advances in computing resources and availability of large-scale medical image datasets, many deep learning models have been developed for disease diagnosis from medical images. However, existing techniques focus on sub-tasks, e.g., disease classification and identification, individually, while there is a lack of a unified framework enabling multi-task diagnosis. Inspired by the capability of Vision Transformers in both local and global representation learning, we propose in this paper a new method, namely Multi-task Vision Transformer (MVC) for simultaneously classifying chest X-ray images and identifying affected regions from the input data. Our method is built upon the Vision Transformer but extends its learning capability in a multi-task setting. We evaluated our proposed method and compared it with existing baselines on a benchmark dataset of COVID-19 chest X-ray images. Experimental results verified the superiority of the proposed method over the baselines on both the image classification and affected region identification tasks. ",
    "url": "https://arxiv.org/abs/2310.00418",
    "authors": [
      "Huyen Tran",
      "Duc Thanh Nguyen",
      "John Yearwood"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00431",
    "title": "ResolvNet: A Graph Convolutional Network with multi-scale Consistency",
    "abstract": "It is by now a well known fact in the graph learning community that the presence of bottlenecks severely limits the ability of graph neural networks to propagate information over long distances. What so far has not been appreciated is that, counter-intuitively, also the presence of strongly connected sub-graphs may severely restrict information flow in common architectures. Motivated by this observation, we introduce the concept of multi-scale consistency. At the node level this concept refers to the retention of a connected propagation graph even if connectivity varies over a given graph. At the graph-level, multi-scale consistency refers to the fact that distinct graphs describing the same object at different resolutions should be assigned similar feature vectors. As we show, both properties are not satisfied by poular graph neural network architectures. To remedy these shortcomings, we introduce ResolvNet, a flexible graph neural network based on the mathematical concept of resolvents. We rigorously establish its multi-scale consistency theoretically and verify it in extensive experiments on real world data: Here networks based on this ResolvNet architecture prove expressive; out-performing baselines significantly on many tasks; in- and outside the multi-scale setting. ",
    "url": "https://arxiv.org/abs/2310.00431",
    "authors": [
      "Christian Koke",
      "Abhishek Saroha",
      "Yuesong Shen",
      "Marvin Eisenberger",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00436",
    "title": "Enhancing Representation Generalization in Authorship Identification",
    "abstract": "Authorship identification ascertains the authorship of texts whose origins remain undisclosed. That authorship identification techniques work as reliably as they do has been attributed to the fact that authorial style is properly captured and represented. Although modern authorship identification methods have evolved significantly over the years and have proven effective in distinguishing authorial styles, the generalization of stylistic features across domains has not been systematically reviewed. The presented work addresses the challenge of enhancing the generalization of stylistic representations in authorship identification, particularly when there are discrepancies between training and testing samples. A comprehensive review of empirical studies was conducted, focusing on various stylistic features and their effectiveness in representing an author's style. The influencing factors such as topic, genre, and register on writing style were also explored, along with strategies to mitigate their impact. While some stylistic features, like character n-grams and function words, have proven to be robust and discriminative, others, such as content words, can introduce biases and hinder cross-domain generalization. Representations learned using deep learning models, especially those incorporating character n-grams and syntactic information, show promise in enhancing representation generalization. The findings underscore the importance of selecting appropriate stylistic features for authorship identification, especially in cross-domain scenarios. The recognition of the strengths and weaknesses of various linguistic features paves the way for more accurate authorship identification in diverse contexts. ",
    "url": "https://arxiv.org/abs/2310.00436",
    "authors": [
      "Haining Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.00438",
    "title": "Human-Producible Adversarial Examples",
    "abstract": "Visual adversarial examples have so far been restricted to pixel-level image manipulations in the digital world, or have required sophisticated equipment such as 2D or 3D printers to be produced in the physical real world. We present the first ever method of generating human-producible adversarial examples for the real world that requires nothing more complicated than a marker pen. We call them $\\textbf{adversarial tags}$. First, building on top of differential rendering, we demonstrate that it is possible to build potent adversarial examples with just lines. We find that by drawing just $4$ lines we can disrupt a YOLO-based model in $54.8\\%$ of cases; increasing this to $9$ lines disrupts $81.8\\%$ of the cases tested. Next, we devise an improved method for line placement to be invariant to human drawing error. We evaluate our system thoroughly in both digital and analogue worlds and demonstrate that our tags can be applied by untrained humans. We demonstrate the effectiveness of our method for producing real-world adversarial examples by conducting a user study where participants were asked to draw over printed images using digital equivalents as guides. We further evaluate the effectiveness of both targeted and untargeted attacks, and discuss various trade-offs and method limitations, as well as the practical and ethical implications of our work. The source code will be released publicly. ",
    "url": "https://arxiv.org/abs/2310.00438",
    "authors": [
      "David Khachaturov",
      "Yue Gao",
      "Ilia Shumailov",
      "Robert Mullins",
      "Ross Anderson",
      "Kassem Fawaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00451",
    "title": "On the Role of Neural Collapse in Meta Learning Models for Few-shot  Learning",
    "abstract": "Meta-learning frameworks for few-shot learning aims to learn models that can learn new skills or adapt to new environments rapidly with a few training examples. This has led to the generalizability of the developed model towards new classes with just a few labelled samples. However these networks are seen as black-box models and understanding the representations learnt under different learning scenarios is crucial. Neural collapse ($\\mathcal{NC}$) is a recently discovered phenomenon which showcases unique properties at the network proceeds towards zero loss. The input features collapse to their respective class means, the class means form a Simplex equiangular tight frame (ETF) where the class means are maximally distant and linearly separable, and the classifier acts as a simple nearest neighbor classifier. While these phenomena have been observed in simple classification networks, this study is the first to explore and understand the properties of neural collapse in meta learning frameworks for few-shot learning. We perform studies on the Omniglot dataset in the few-shot setting and study the neural collapse phenomenon. We observe that the learnt features indeed have the trend of neural collapse, especially as model size grows, but to do not necessarily showcase the complete collapse as measured by the $\\mathcal{NC}$ properties. ",
    "url": "https://arxiv.org/abs/2310.00451",
    "authors": [
      "Saaketh Medepalli",
      "Naren Doraiswamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00454",
    "title": "UniLVSeg: Unified Left Ventricular Segmentation with Sparsely Annotated  Echocardiogram Videos through Self-Supervised Temporal Masking and Weakly  Supervised Training",
    "abstract": "Echocardiography has become an indispensable clinical imaging modality for general heart health assessment. From calculating biomarkers such as ejection fraction to the probability of a patient's heart failure, accurate segmentation of the heart and its structures allows doctors to plan and execute treatments with greater precision and accuracy. However, achieving accurate and robust left ventricle segmentation is time-consuming and challenging due to different reasons. This work introduces a novel approach for consistent left ventricular (LV) segmentation from sparsely annotated echocardiogram videos. We achieve this through (1) self-supervised learning (SSL) using temporal masking followed by (2) weakly supervised training. We investigate two different segmentation approaches: 3D segmentation and a novel 2D superimage (SI). We demonstrate how our proposed method outperforms the state-of-the-art solutions by achieving a 93.32% (95%CI 93.21-93.43%) dice score on a large-scale dataset (EchoNet-Dynamic) while being more efficient. To show the effectiveness of our approach, we provide extensive ablation studies, including pre-training settings and various deep learning backbones. Additionally, we discuss how our proposed methodology achieves high data utility by incorporating unlabeled frames in the training process. To help support the AI in medicine community, the complete solution with the source code will be made publicly available upon acceptance. ",
    "url": "https://arxiv.org/abs/2310.00454",
    "authors": [
      "Fadillah Maani",
      "Asim Ukaye",
      "Nada Saadi",
      "Numan Saeed",
      "Mohammad Yaqub"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00457",
    "title": "Enhancing Mortality Prediction in Heart Failure Patients: Exploring  Preprocessing Methods for Imbalanced Clinical Datasets",
    "abstract": "Heart failure (HF) is a critical condition in which the accurate prediction of mortality plays a vital role in guiding patient management decisions. However, clinical datasets used for mortality prediction in HF often suffer from an imbalanced distribution of classes, posing significant challenges. In this paper, we explore preprocessing methods for enhancing one-month mortality prediction in HF patients. We present a comprehensive preprocessing framework including scaling, outliers processing and resampling as key techniques. We also employed an aware encoding approach to effectively handle missing values in clinical datasets. Our study utilizes a comprehensive dataset from the Persian Registry Of cardio Vascular disease (PROVE) with a significant class imbalance. By leveraging appropriate preprocessing techniques and Machine Learning (ML) algorithms, we aim to improve mortality prediction performance for HF patients. The results reveal an average enhancement of approximately 3.6% in F1 score and 2.7% in MCC for tree-based models, specifically Random Forest (RF) and XGBoost (XGB). This demonstrates the efficiency of our preprocessing approach in effectively handling Imbalanced Clinical Datasets (ICD). Our findings hold promise in guiding healthcare professionals to make informed decisions and improve patient outcomes in HF management. ",
    "url": "https://arxiv.org/abs/2310.00457",
    "authors": [
      "Hanif Kia",
      "Mansour Vali",
      "Hadi Sabahi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00483",
    "title": "Prompting Code Interpreter to Write Better Unit Tests on Quixbugs  Functions",
    "abstract": "Unit testing is a commonly-used approach in software engineering to test the correctness and robustness of written code. Unit tests are tests designed to test small components of a codebase in isolation, such as an individual function or method. Although unit tests have historically been written by human programmers, recent advancements in AI, particularly LLMs, have shown corresponding advances in automatic unit test generation. In this study, we explore the effect of different prompts on the quality of unit tests generated by Code Interpreter, a GPT-4-based LLM, on Python functions provided by the Quixbugs dataset, and we focus on prompting due to the ease with which users can make use of our findings and observations. We find that the quality of the generated unit tests is not sensitive to changes in minor details in the prompts provided. However, we observe that Code Interpreter is often able to effectively identify and correct mistakes in code that it writes, suggesting that providing it runnable code to check the correctness of its outputs would be beneficial, even though we find that it is already often able to generate correctly-formatted unit tests. Our findings suggest that, when prompting models similar to Code Interpreter, it is important to include the basic information necessary to generate unit tests, but minor details are not as important. ",
    "url": "https://arxiv.org/abs/2310.00483",
    "authors": [
      "Vincent Li",
      "Nick Doiron"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00488",
    "title": "On Memorization and Privacy risks of Sharpness Aware Minimization",
    "abstract": "In many recent works, there is an increased focus on designing algorithms that seek flatter optima for neural network loss optimization as there is empirical evidence that it leads to better generalization performance in many datasets. In this work, we dissect these performance gains through the lens of data memorization in overparameterized models. We define a new metric that helps us identify which data points specifically do algorithms seeking flatter optima do better when compared to vanilla SGD. We find that the generalization gains achieved by Sharpness Aware Minimization (SAM) are particularly pronounced for atypical data points, which necessitate memorization. This insight helps us unearth higher privacy risks associated with SAM, which we verify through exhaustive empirical evaluations. Finally, we propose mitigation strategies to achieve a more desirable accuracy vs privacy tradeoff. ",
    "url": "https://arxiv.org/abs/2310.00488",
    "authors": [
      "Young In Kim",
      "Pratiksha Agrawal",
      "Johannes O. Royset",
      "Rajiv Khanna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.00496",
    "title": "The Sparsity Roofline: Understanding the Hardware Limits of Sparse  Neural Networks",
    "abstract": "We introduce the Sparsity Roofline, a visual performance model for evaluating sparsity in neural networks. The Sparsity Roofline jointly models network accuracy, sparsity, and predicted inference speedup. Our approach does not require implementing and benchmarking optimized kernels, and the predicted speedup is equal to what would be measured when the corresponding dense and sparse kernels are equally well-optimized. We achieve this through a novel analytical model for predicting sparse network performance, and validate the predicted speedup using several real-world computer vision architectures pruned across a range of sparsity patterns and degrees. We demonstrate the utility and ease-of-use of our model through two case studies: (1) we show how machine learning researchers can predict the performance of unimplemented or unoptimized block-structured sparsity patterns, and (2) we show how hardware designers can predict the performance implications of new sparsity patterns and sparse data formats in hardware. In both scenarios, the Sparsity Roofline helps performance experts identify sparsity regimes with the highest performance potential. ",
    "url": "https://arxiv.org/abs/2310.00496",
    "authors": [
      "Cameron Shinn",
      "Collin McCarthy",
      "Saurav Muralidharan",
      "Muhammad Osama",
      "John D. Owens"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00503",
    "title": "Black-box Attacks on Image Activity Prediction and its Natural Language  Explanations",
    "abstract": "Explainable AI (XAI) methods aim to describe the decision process of deep neural networks. Early XAI methods produced visual explanations, whereas more recent techniques generate multimodal explanations that include textual information and visual representations. Visual XAI methods have been shown to be vulnerable to white-box and gray-box adversarial attacks, with an attacker having full or partial knowledge of and access to the target system. As the vulnerabilities of multimodal XAI models have not been examined, in this paper we assess for the first time the robustness to black-box attacks of the natural language explanations generated by a self-rationalizing image-based activity recognition model. We generate unrestricted, spatially variant perturbations that disrupt the association between the predictions and the corresponding explanations to mislead the model into generating unfaithful explanations. We show that we can create adversarial images that manipulate the explanations of an activity recognition model by having access only to its final output. ",
    "url": "https://arxiv.org/abs/2310.00503",
    "authors": [
      "Alina Elena Baia",
      "Valentina Poggioni",
      "Andrea Cavallaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00516",
    "title": "Enhancing Efficiency and Privacy in Memory-Based Malware Classification  through Feature Selection",
    "abstract": "Malware poses a significant security risk to individuals, organizations, and critical infrastructure by compromising systems and data. Leveraging memory dumps that offer snapshots of computer memory can aid the analysis and detection of malicious content, including malware. To improve the efficacy and address privacy concerns in malware classification systems, feature selection can play a critical role as it is capable of identifying the most relevant features, thus, minimizing the amount of data fed to classifiers. In this study, we employ three feature selection approaches to identify significant features from memory content and use them with a diverse set of classifiers to enhance the performance and privacy of the classification task. Comprehensive experiments are conducted across three levels of malware classification tasks: i) binary-level benign or malware classification, ii) malware type classification (including Trojan horse, ransomware, and spyware), and iii) malware family classification within each family (with varying numbers of classes). Results demonstrate that the feature selection strategy, incorporating mutual information and other methods, enhances classifier performance for all tasks. Notably, selecting only 25\\% and 50\\% of input features using Mutual Information and then employing the Random Forest classifier yields the best results. Our findings reinforce the importance of feature selection for malware classification and provide valuable insights for identifying appropriate approaches. By advancing the effectiveness and privacy of malware classification systems, this research contributes to safeguarding against security threats posed by malicious software. ",
    "url": "https://arxiv.org/abs/2310.00516",
    "authors": [
      "Salim Sazzed",
      "Sharif Ullah"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00517",
    "title": "Assessing the Generalizability of Deep Neural Networks-Based Models for  Black Skin Lesions",
    "abstract": "Melanoma is the most severe type of skin cancer due to its ability to cause metastasis. It is more common in black people, often affecting acral regions: palms, soles, and nails. Deep neural networks have shown tremendous potential for improving clinical care and skin cancer diagnosis. Nevertheless, prevailing studies predominantly rely on datasets of white skin tones, neglecting to report diagnostic outcomes for diverse patient skin tones. In this work, we evaluate supervised and self-supervised models in skin lesion images extracted from acral regions commonly observed in black individuals. Also, we carefully curate a dataset containing skin lesions in acral regions and assess the datasets concerning the Fitzpatrick scale to verify performance on black skin. Our results expose the poor generalizability of these models, revealing their favorable performance for lesions on white skin. Neglecting to create diverse datasets, which necessitates the development of specialized models, is unacceptable. Deep neural networks have great potential to improve diagnosis, particularly for populations with limited access to dermatology. However, including black skin lesions is necessary to ensure these populations can access the benefits of inclusive technology. ",
    "url": "https://arxiv.org/abs/2310.00517",
    "authors": [
      "Luana Barros",
      "Levy Chaves",
      "Sandra Avila"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00522",
    "title": "Mapping of Internet \"Coastlines\" via Large Scale Anonymized Network  Source Correlations",
    "abstract": "Expanding the scientific tools available to protect computer networks can be aided by a deeper understanding of the underlying statistical distributions of network traffic and their potential geometric interpretations. Analyses of large scale network observations provide a unique window into studying those underlying statistics. Newly developed GraphBLAS hypersparse matrices and D4M associative array technologies enable the efficient anonymized analysis of network traffic on the scale of trillions of events. This work analyzes over 100,000,000,000 anonymized packets from the largest Internet telescope (CAIDA) and over 10,000,000 anonymized sources from the largest commercial honeyfarm (GreyNoise). Neither CAIDA nor GreyNoise actively emit Internet traffic and provide distinct observations of unsolicited Internet traffic (primarily botnets and scanners). Analysis of these observations confirms the previously observed Cauchy-like distributions describing temporal correlations between Internet sources. The Gull lighthouse problem is a well-known geometric characterization of the standard Cauchy distribution and motivates a potential geometric interpretation for Internet observations. This work generalizes the Gull lighthouse problem to accommodate larger classes of coastlines, deriving a closed-form solution for the resulting probability distributions, stating and examining the inverse problem of identifying an appropriate coastline given a continuous probability distribution, identifying a geometric heuristic for solving this problem computationally, and applying that heuristic to examine the temporal geometry of different subsets of network observations. Application of this method to the CAIDA and GreyNoise data reveals a several orders of magnitude difference between known benign and other traffic which can lead to potentially novel ways to protect networks. ",
    "url": "https://arxiv.org/abs/2310.00522",
    "authors": [
      "Hayden Jananthan",
      "Jeremy Kepner",
      "Michael Jones",
      "William Arcand",
      "David Bestor",
      "William Bergeron",
      "Chansup Byun",
      "Timothy Davis",
      "Vijay Gadepally",
      "Daniel Grant",
      "Michael Houle",
      "Matthew Hubbell",
      "Anna Klein",
      "Lauren Milechin",
      "Guillermo Morales",
      "Andrew Morris",
      "Julie Mullen",
      "Ritesh Patel",
      "Alex Pentland",
      "Sandeep Pisharody",
      "Andrew Prout",
      "Albert Reuther",
      "Antonio Rosa",
      "Siddharth Samsi",
      "Tyler Trigg",
      "Gabriel Wachman",
      "Charles Yee",
      "Peter Michaleas"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.00526",
    "title": "Are Graph Neural Networks Optimal Approximation Algorithms?",
    "abstract": "In this work we design graph neural network architectures that can be used to obtain optimal approximation algorithms for a large class of combinatorial optimization problems using powerful algorithmic tools from semidefinite programming (SDP). Concretely, we prove that polynomial-sized message passing algorithms can represent the most powerful polynomial time algorithms for Max Constraint Satisfaction Problems assuming the Unique Games Conjecture. We leverage this result to construct efficient graph neural network architectures, OptGNN, that obtain high-quality approximate solutions on landmark combinatorial optimization problems such as Max Cut and maximum independent set. Our approach achieves strong empirical results across a wide range of real-world and synthetic datasets against both neural baselines and classical algorithms. Finally, we take advantage of OptGNN's ability to capture convex relaxations to design an algorithm for producing dual certificates of optimality (bounds on the optimal solution) from the learned embeddings of OptGNN. ",
    "url": "https://arxiv.org/abs/2310.00526",
    "authors": [
      "Morris Yau",
      "Eric Lu",
      "Nikolaos Karalias",
      "Jessica Xu",
      "Stefanie Jegelka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2310.00527",
    "title": "Self-supervised Learning of Contextualized Local Visual Embeddings",
    "abstract": "We present Contextualized Local Visual Embeddings (CLoVE), a self-supervised convolutional-based method that learns representations suited for dense prediction tasks. CLoVE deviates from current methods and optimizes a single loss function that operates at the level of contextualized local embeddings learned from output feature maps of convolution neural network (CNN) encoders. To learn contextualized embeddings, CLoVE proposes a normalized mult-head self-attention layer that combines local features from different parts of an image based on similarity. We extensively benchmark CLoVE's pre-trained representations on multiple datasets. CLoVE reaches state-of-the-art performance for CNN-based architectures in 4 dense prediction downstream tasks, including object detection, instance segmentation, keypoint detection, and dense pose estimation. Code: $\\href{https://github.com/sthalles/CLoVE}{https://github.com/sthalles/CLoVE}$. ",
    "url": "https://arxiv.org/abs/2310.00527",
    "authors": [
      "Thalles Santos Silva",
      "Helio Pedrini",
      "Ad\u00edn Ram\u00edrez Rivera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00530",
    "title": "Enabling Neural Radiance Fields (NeRF) for Large-scale Aerial Images --  A Multi-tiling Approaching and the Geometry Assessment of NeRF",
    "abstract": "Neural Radiance Fields (NeRF) offer the potential to benefit 3D reconstruction tasks, including aerial photogrammetry. However, the scalability and accuracy of the inferred geometry are not well-documented for large-scale aerial assets,since such datasets usually result in very high memory consumption and slow convergence.. In this paper, we aim to scale the NeRF on large-scael aerial datasets and provide a thorough geometry assessment of NeRF. Specifically, we introduce a location-specific sampling technique as well as a multi-camera tiling (MCT) strategy to reduce memory consumption during image loading for RAM, representation training for GPU memory, and increase the convergence rate within tiles. MCT decomposes a large-frame image into multiple tiled images with different camera models, allowing these small-frame images to be fed into the training process as needed for specific locations without a loss of accuracy. We implement our method on a representative approach, Mip-NeRF, and compare its geometry performance with threephotgrammetric MVS pipelines on two typical aerial datasets against LiDAR reference data. Both qualitative and quantitative results suggest that the proposed NeRF approach produces better completeness and object details than traditional approaches, although as of now, it still falls short in terms of accuracy. ",
    "url": "https://arxiv.org/abs/2310.00530",
    "authors": [
      "Ningli Xu",
      "Rongjun Qin",
      "Debao Huang",
      "Fabio Remondino"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00542",
    "title": "Horizontal Class Backdoor to Deep Learning",
    "abstract": "All existing backdoor attacks to deep learning (DL) models belong to the vertical class backdoor (VCB). That is, any sample from a class will activate the implanted backdoor in the presence of the secret trigger, regardless of source-class-agnostic or source-class-specific backdoor. Current trends of existing defenses are overwhelmingly devised for VCB attacks especially the source-class-agnostic backdoor, which essentially neglects other potential simple but general backdoor types, thus giving false security implications. It is thus urgent to discover unknown backdoor types. This work reveals a new, simple, and general horizontal class backdoor (HCB) attack. We show that the backdoor can be naturally bounded with innocuous natural features that are common and pervasive in the real world. Note that an innocuous feature (e.g., expression) is irrelevant to the main task of the model (e.g., recognizing a person from one to another). The innocuous feature spans across classes horizontally but is exhibited by partial samples per class -- satisfying the horizontal class (HC) property. Only when the trigger is concurrently presented with the HC innocuous feature, can the backdoor be effectively activated. Extensive experiments on attacking performance in terms of high attack success rates with tasks of 1) MNIST, 2) facial recognition, 3) traffic sign recognition, and 4) object detection demonstrate that the HCB is highly efficient and effective. We extensively evaluate the HCB evasiveness against a (chronologically) series of 9 influential countermeasures of Fine-Pruning (RAID 18'), STRIP (ACSAC 19'), Neural Cleanse (Oakland 19'), ABS (CCS 19'), Februus (ACSAC 20'), MNTD (Oakland 21'), SCAn (USENIX SEC 21'), MOTH (Oakland 22'), and Beatrix (NDSS 23'), where none of them can succeed even when a simplest trigger is used. ",
    "url": "https://arxiv.org/abs/2310.00542",
    "authors": [
      "Hua Ma",
      "Shang Wang",
      "Yansong Gao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00551",
    "title": "Derivative based global sensitivity analysis and its entropic link",
    "abstract": "Distribution-based global sensitivity analysis (GSA), such as variance-based and entropy-based approaches, can provide quantitative sensitivity information. However, they can be expensive to evaluate and are thus limited to low dimensional problems. Derivative-based GSA, on the other hand, require much fewer model evaluations. It is known that derivative-based GSA is closely linked to variance-based total sensitivity index, while its relationship with the entropy-based measure is unclear. To fill this gap, we introduce a log-derivative based functional to demonstrate that the entropy-based and derivative-based sensitivity measures are strongly connected. In particular, we give proofs that, similar to the case with variance-based GSA, there is an inequality relationship between entropy-based and derivative-based important measures. Both analytical and numerical verifications are provided. Examples show that the derivative-based methods give similar variable rankings as entropy-based index and can thus be potentially used as a proxy for both variance-based and entropy-based distribution-type GSA. ",
    "url": "https://arxiv.org/abs/2310.00551",
    "authors": [
      "Jiannan Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2310.00552",
    "title": "Siamese Representation Learning for Unsupervised Relation Extraction",
    "abstract": "Unsupervised relation extraction (URE) aims at discovering underlying relations between named entity pairs from open-domain plain text without prior information on relational distribution. Existing URE models utilizing contrastive learning, which attract positive samples and repulse negative samples to promote better separation, have got decent effect. However, fine-grained relational semantic in relationship makes spurious negative samples, damaging the inherent hierarchical structure and hindering performances. To tackle this problem, we propose Siamese Representation Learning for Unsupervised Relation Extraction -- a novel framework to simply leverage positive pairs to representation learning, possessing the capability to effectively optimize relation representation of instances and retain hierarchical information in relational feature space. Experimental results show that our model significantly advances the state-of-the-art results on two benchmark datasets and detailed analyses demonstrate the effectiveness and robustness of our proposed model on unsupervised relation extraction. ",
    "url": "https://arxiv.org/abs/2310.00552",
    "authors": [
      "Guangxin Zhang",
      "Shu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.00564",
    "title": "DYNAP-SE2: a scalable multi-core dynamic neuromorphic asynchronous  spiking neural network processor",
    "abstract": "With the remarkable progress that technology has made, the need for processing data near the sensors at the edge has increased dramatically. The electronic systems used in these applications must process data continuously, in real-time, and extract relevant information using the smallest possible energy budgets. A promising approach for implementing always-on processing of sensory signals that supports on-demand, sparse, and edge-computing is to take inspiration from biological nervous system. Following this approach, we present a brain-inspired platform for prototyping real-time event-based Spiking Neural Networks (SNNs). The system proposed supports the direct emulation of dynamic and realistic neural processing phenomena such as short-term plasticity, NMDA gating, AMPA diffusion, homeostasis, spike frequency adaptation, conductance-based dendritic compartments and spike transmission delays. The analog circuits that implement such primitives are paired with a low latency asynchronous digital circuits for routing and mapping events. This asynchronous infrastructure enables the definition of different network architectures, and provides direct event-based interfaces to convert and encode data from event-based and continuous-signal sensors. Here we describe the overall system architecture, we characterize the mixed signal analog-digital circuits that emulate neural dynamics, demonstrate their features with experimental measurements, and present a low- and high-level software ecosystem that can be used for configuring the system. The flexibility to emulate different biologically plausible neural networks, and the chip's ability to monitor both population and single neuron signals in real-time, allow to develop and validate complex models of neural processing for both basic research and edge-computing applications. ",
    "url": "https://arxiv.org/abs/2310.00564",
    "authors": [
      "Ole Richter",
      "Chenxi Wu",
      "Adrian M. Whatley",
      "German K\u00f6stinger",
      "Carsten Nielsen",
      "Ning Qiao",
      "Giacomo Indiveri"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.00567",
    "title": "Understanding the Robustness of Randomized Feature Defense Against  Query-Based Adversarial Attacks",
    "abstract": "Recent works have shown that deep neural networks are vulnerable to adversarial examples that find samples close to the original image but can make the model misclassify. Even with access only to the model's output, an attacker can employ black-box attacks to generate such adversarial examples. In this work, we propose a simple and lightweight defense against black-box attacks by adding random noise to hidden features at intermediate layers of the model at inference time. Our theoretical analysis confirms that this method effectively enhances the model's resilience against both score-based and decision-based black-box attacks. Importantly, our defense does not necessitate adversarial training and has minimal impact on accuracy, rendering it applicable to any pre-trained model. Our analysis also reveals the significance of selectively adding noise to different parts of the model based on the gradient of the adversarial objective function, which can be varied during the attack. We demonstrate the robustness of our defense against multiple black-box attacks through extensive empirical experiments involving diverse models with various architectures. ",
    "url": "https://arxiv.org/abs/2310.00567",
    "authors": [
      "Quang H. Nguyen",
      "Yingjie Lao",
      "Tung Pham",
      "Kok-Seng Wong",
      "Khoa D. Doan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00568",
    "title": "Image Data Hiding in Neural Compressed Latent Representations",
    "abstract": "We propose an end-to-end learned image data hiding framework that embeds and extracts secrets in the latent representations of a generic neural compressor. By leveraging a perceptual loss function in conjunction with our proposed message encoder and decoder, our approach simultaneously achieves high image quality and high bit accuracy. Compared to existing techniques, our framework offers superior image secrecy and competitive watermarking robustness in the compressed domain while accelerating the embedding speed by over 50 times. These results demonstrate the potential of combining data hiding techniques and neural compression and offer new insights into developing neural compression techniques and their applications. ",
    "url": "https://arxiv.org/abs/2310.00568",
    "authors": [
      "Chen-Hsiu Huang",
      "Ja-Ling Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00569",
    "title": "TDCGL: Two-Level Debiased Contrastive Graph Learning for Recommendation",
    "abstract": "knowledge graph-based recommendation methods have achieved great success in the field of recommender systems. However, over-reliance on high-quality knowledge graphs is a bottleneck for such methods. Specifically, the long-tailed distribution of entities of KG and noise issues in the real world will make item-entity dependent relations deviate from reflecting true characteristics and significantly harm the performance of modeling user preference. Contrastive learning, as a novel method that is employed for data augmentation and denoising, provides inspiration to fill this research gap. However, the mainstream work only focuses on the long-tail properties of the number of items clicked, while ignoring that the long-tail properties of total number of clicks per user may also affect the performance of the recommendation model. Therefore, to tackle these problems, motivated by the Debiased Contrastive Learning of Unsupervised Sentence Representations (DCLR), we propose Two-Level Debiased Contrastive Graph Learning (TDCGL) model. Specifically, we design the Two-Level Debiased Contrastive Learning (TDCL) and deploy it in the KG, which is conducted not only on User-Item pairs but also on User-User pairs for modeling higher-order relations. Also, to reduce the bias caused by random sampling in contrastive learning, with the exception of the negative samples obtained by random sampling, we add a noise-based generation of negation to ensure spatial uniformity. Considerable experiments on open-source datasets demonstrate that our method has excellent anti-noise capability and significantly outperforms state-of-the-art baselines. In addition, ablation studies about the necessity for each level of TDCL are conducted. ",
    "url": "https://arxiv.org/abs/2310.00569",
    "authors": [
      "Yubo Gao",
      "Haotian Wu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.00570",
    "title": "LaPLACE: Probabilistic Local Model-Agnostic Causal Explanations",
    "abstract": "Machine learning models have undeniably achieved impressive performance across a range of applications. However, their often perceived black-box nature, and lack of transparency in decision-making, have raised concerns about understanding their predictions. To tackle this challenge, researchers have developed methods to provide explanations for machine learning models. In this paper, we introduce LaPLACE-explainer, designed to provide probabilistic cause-and-effect explanations for any classifier operating on tabular data, in a human-understandable manner. The LaPLACE-Explainer component leverages the concept of a Markov blanket to establish statistical boundaries between relevant and non-relevant features automatically. This approach results in the automatic generation of optimal feature subsets, serving as explanations for predictions. Importantly, this eliminates the need to predetermine a fixed number N of top features as explanations, enhancing the flexibility and adaptability of our methodology. Through the incorporation of conditional probabilities, our approach offers probabilistic causal explanations and outperforms LIME and SHAP (well-known model-agnostic explainers) in terms of local accuracy and consistency of explained features. LaPLACE's soundness, consistency, local accuracy, and adaptability are rigorously validated across various classification models. Furthermore, we demonstrate the practical utility of these explanations via experiments with both simulated and real-world datasets. This encompasses addressing trust-related issues, such as evaluating prediction reliability, facilitating model selection, enhancing trustworthiness, and identifying fairness-related concerns within classifiers. ",
    "url": "https://arxiv.org/abs/2310.00570",
    "authors": [
      "Sein Minn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.00574",
    "title": "SIMD Dataflow Co-optimization for Efficient Neural Networks Inferences  on CPUs",
    "abstract": "We address the challenges associated with deploying neural networks on CPUs, with a particular focus on minimizing inference time while maintaining accuracy. Our novel approach is to use the dataflow (i.e., computation order) of a neural network to explore data reuse opportunities using heuristic-guided analysis and a code generation framework, which enables exploration of various Single Instruction, Multiple Data (SIMD) implementations to achieve optimized neural network execution. Our results demonstrate that the dataflow that keeps outputs in SIMD registers while also maximizing both input and weight reuse consistently yields the best performance for a wide variety of inference workloads, achieving up to 3x speedup for 8-bit neural networks, and up to 4.8x speedup for binary neural networks, respectively, over the optimized implementations of neural networks today. ",
    "url": "https://arxiv.org/abs/2310.00574",
    "authors": [
      "Cyrus Zhou",
      "Zack Hassman",
      "Ruize Xu",
      "Dhirpal Shah",
      "Vaugnn Richard",
      "Yanjing Li"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2310.00588",
    "title": "Active Anomaly Detection in Confined Spaces Using Ergodic Traversal of  Directed Region Graphs",
    "abstract": "We provide the first step toward developing a hierarchical control-estimation framework to actively plan robot trajectories for anomaly detection in confined spaces. The space is represented globally using a directed region graph, where a region is a landmark that needs to be visited (inspected). We devise a fast mixing Markov chain to find an ergodic route that traverses this graph so that the region visitation frequency is proportional to its anomaly detection uncertainty, while satisfying the edge directionality (region transition) constraint(s). Preliminary simulation results show fast convergence to the ergodic solution and confident estimation of the presence of anomalies in the inspected regions. ",
    "url": "https://arxiv.org/abs/2310.00588",
    "authors": [
      "Benjamin Wong",
      "Tyler M. Paine",
      "Santosh Devasia",
      "Ashis G. Banerjee"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.00594",
    "title": "Performance evaluation of Machine learning algorithms for Intrusion  Detection System",
    "abstract": "The escalation of hazards to safety and hijacking of digital networks are among the strongest perilous difficulties that must be addressed in the present day. Numerous safety procedures were set up to track and recognize any illicit activity on the network's infrastructure. IDS are the best way to resist and recognize intrusions on internet connections and digital technologies. To classify network traffic as normal or anomalous, Machine Learning (ML) classifiers are increasingly utilized. An IDS with machine learning increases the accuracy with which security attacks are detected. This paper focuses on intrusion detection systems (IDSs) analysis using ML techniques. IDSs utilizing ML techniques are efficient and precise at identifying network assaults. In data with large dimensional spaces, however, the efficacy of these systems degrades. correspondingly, the case is essential to execute a feasible feature removal technique capable of getting rid of characteristics that have little effect on the classification process. In this paper, we analyze the KDD CUP-'99' intrusion detection dataset used for training and validating ML models. Then, we implement ML classifiers such as Logistic Regression, Decision Tree, K-Nearest Neighbour, Naive Bayes, Bernoulli Naive Bayes, Multinomial Naive Bayes, XG-Boost Classifier, Ada-Boost, Random Forest, SVM, Rocchio classifier, Ridge, Passive-Aggressive classifier, ANN besides Perceptron (PPN), the optimal classifiers are determined by comparing the results of Stochastic Gradient Descent and back-propagation neural networks for IDS, Conventional categorization indicators, such as \"accuracy, precision, recall, and the f1-measure, have been used to evaluate the performance of the ML classification algorithms. ",
    "url": "https://arxiv.org/abs/2310.00594",
    "authors": [
      "Sudhanshu Sekhar Tripathy",
      "Bichitrananda Behera"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.00607",
    "title": "On the Onset of Robust Overfitting in Adversarial Training",
    "abstract": "Adversarial Training (AT) is a widely-used algorithm for building robust neural networks, but it suffers from the issue of robust overfitting, the fundamental mechanism of which remains unclear. In this work, we consider normal data and adversarial perturbation as separate factors, and identify that the underlying causes of robust overfitting stem from the normal data through factor ablation in AT. Furthermore, we explain the onset of robust overfitting as a result of the model learning features that lack robust generalization, which we refer to as non-effective features. Specifically, we provide a detailed analysis of the generation of non-effective features and how they lead to robust overfitting. Additionally, we explain various empirical behaviors observed in robust overfitting and revisit different techniques to mitigate robust overfitting from the perspective of non-effective features, providing a comprehensive understanding of the robust overfitting phenomenon. This understanding inspires us to propose two measures, attack strength and data augmentation, to hinder the learning of non-effective features by the neural network, thereby alleviating robust overfitting. Extensive experiments conducted on benchmark datasets demonstrate the effectiveness of the proposed methods in mitigating robust overfitting and enhancing adversarial robustness. ",
    "url": "https://arxiv.org/abs/2310.00607",
    "authors": [
      "Chaojian Yu",
      "Xiaolong Shi",
      "Jun Yu",
      "Bo Han",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00614",
    "title": "Hierarchical Adaptation with Hypernetworks for Few-shot Molecular  Property Prediction",
    "abstract": "Molecular property prediction (MPP) is important in biomedical applications, which naturally suffers from a lack of labels, thus forming a few-shot learning problem. State-of-the-art approaches are usually based on gradient-based meta learning strategy, which ignore difference in model parameter and molecule's learning difficulty. To address above problems, we propose a novel hierarchical adaptation mechanism for few-shot MPP (HiMPP). The model follows a encoder-predictor framework. First, to make molecular representation property-adaptive, we selectively adapt encoder's parameter by designing a hypernetwork to modulate node embeddings during message propagation. Next, we make molecule-level adaptation by design another hypernetwork, which assigns larger propagating steps for harder molecules in predictor. In this way, molecular representation is transformed by HiMPP hierarchically from property-level to molecular level. Extensive results show that HiMPP obtains the state-of-the-art performance in few-shot MPP problems, and our proposed hierarchical adaptation mechanism is rational and effective. ",
    "url": "https://arxiv.org/abs/2310.00614",
    "authors": [
      "Shiguang Wu",
      "Yaqing Wang",
      "Quanming Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.00615",
    "title": "Scene-aware Human Motion Forecasting via Mutual Distance Prediction",
    "abstract": "In this paper, we tackle the problem of scene-aware 3D human motion forecasting. A key challenge of this task is to predict future human motions that are consistent with the scene, by modelling the human-scene interactions. While recent works have demonstrated that explicit constraints on human-scene interactions can prevent the occurrence of ghost motion, they only provide constraints on partial human motion e.g., the global motion of the human or a few joints contacting the scene, leaving the rest motion unconstrained. To address this limitation, we propose to model the human-scene interaction with the mutual distance between the human body and the scene. Such mutual distances constrain both the local and global human motion, resulting in a whole-body motion constrained prediction. In particular, mutual distance constraints consist of two components, the signed distance of each vertex on the human mesh to the scene surface, and the distance of basis scene points to the human mesh. We develop a pipeline with two prediction steps that first predicts the future mutual distances from the past human motion sequence and the scene, and then forecasts the future human motion conditioning on the predicted mutual distances. During training, we explicitly encourage consistency between the predicted poses and the mutual distances. Our approach outperforms the state-of-the-art methods on both synthetic and real datasets. ",
    "url": "https://arxiv.org/abs/2310.00615",
    "authors": [
      "Chaoyue Xing",
      "Wei Mao",
      "Miaomiao Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00616",
    "title": "Understanding Adversarial Transferability in Federated Learning",
    "abstract": "We investigate the robustness and security issues from a novel and practical setting: a group of malicious clients has impacted the model during training by disguising their identities and acting as benign clients, and only revealing their adversary position after the training to conduct transferable adversarial attacks with their data, which is usually a subset of the data that FL system is trained with. Our aim is to offer a full understanding of the challenges the FL system faces in this practical setting across a spectrum of configurations. We notice that such an attack is possible, but the federated model is more robust compared with its centralized counterpart when the accuracy on clean images is comparable. Through our study, we hypothesized the robustness is from two factors: the decentralized training on distributed data and the averaging operation. We provide evidence from both the perspective of empirical experiments and theoretical analysis. Our work has implications for understanding the robustness of federated learning systems and poses a practical question for federated learning applications. ",
    "url": "https://arxiv.org/abs/2310.00616",
    "authors": [
      "Yijiang Li",
      "Ying Gao",
      "Haohan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00618",
    "title": "GNRK: Graph Neural Runge-Kutta method for solving partial differential  equations",
    "abstract": "Neural networks have proven to be efficient surrogate models for tackling partial differential equations (PDEs). However, their applicability is often confined to specific PDEs under certain constraints, in contrast to classical PDE solvers that rely on numerical differentiation. Striking a balance between efficiency and versatility, this study introduces a novel approach called Graph Neural Runge-Kutta (GNRK), which integrates graph neural network modules with a recurrent structure inspired by the classical solvers. The GNRK operates on graph structures, ensuring its resilience to changes in spatial and temporal resolutions during domain discretization. Moreover, it demonstrates the capability to address general PDEs, irrespective of initial conditions or PDE coefficients. To assess its performance, we benchmark the GNRK against existing neural network based PDE solvers using the 2-dimensional Burgers' equation, revealing the GNRK's superiority in terms of model size and accuracy. Additionally, this graph-based methodology offers a straightforward extension for solving coupled differential equations, typically necessitating more intricate models. ",
    "url": "https://arxiv.org/abs/2310.00618",
    "authors": [
      "Hoyun Choi",
      "Sungyeop Lee",
      "B. Kahng",
      "Junghyo Jo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00626",
    "title": "GhostEncoder: Stealthy Backdoor Attacks with Dynamic Triggers to  Pre-trained Encoders in Self-supervised Learning",
    "abstract": "Within the realm of computer vision, self-supervised learning (SSL) pertains to training pre-trained image encoders utilizing a substantial quantity of unlabeled images. Pre-trained image encoders can serve as feature extractors, facilitating the construction of downstream classifiers for various tasks. However, the use of SSL has led to an increase in security research related to various backdoor attacks. Currently, the trigger patterns used in backdoor attacks on SSL are mostly visible or static (sample-agnostic), making backdoors less covert and significantly affecting the attack performance. In this work, we propose GhostEncoder, the first dynamic invisible backdoor attack on SSL. Unlike existing backdoor attacks on SSL, which use visible or static trigger patterns, GhostEncoder utilizes image steganography techniques to encode hidden information into benign images and generate backdoor samples. We then fine-tune the pre-trained image encoder on a manipulation dataset to inject the backdoor, enabling downstream classifiers built upon the backdoored encoder to inherit the backdoor behavior for target downstream tasks. We evaluate GhostEncoder on three downstream tasks and results demonstrate that GhostEncoder provides practical stealthiness on images and deceives the victim model with a high attack success rate without compromising its utility. Furthermore, GhostEncoder withstands state-of-the-art defenses, including STRIP, STRIP-Cl, and SSL-Cleanse. ",
    "url": "https://arxiv.org/abs/2310.00626",
    "authors": [
      "Qiannan Wang",
      "Changchun Yin",
      "Zhe Liu",
      "Liming Fang",
      "Run Wang",
      "Chenhao Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.00633",
    "title": "A Survey of Robustness and Safety of 2D and 3D Deep Learning Models  Against Adversarial Attacks",
    "abstract": "Benefiting from the rapid development of deep learning, 2D and 3D computer vision applications are deployed in many safe-critical systems, such as autopilot and identity authentication. However, deep learning models are not trustworthy enough because of their limited robustness against adversarial attacks. The physically realizable adversarial attacks further pose fatal threats to the application and human safety. Lots of papers have emerged to investigate the robustness and safety of deep learning models against adversarial attacks. To lead to trustworthy AI, we first construct a general threat model from different perspectives and then comprehensively review the latest progress of both 2D and 3D adversarial attacks. We extend the concept of adversarial examples beyond imperceptive perturbations and collate over 170 papers to give an overview of deep learning model robustness against various adversarial attacks. To the best of our knowledge, we are the first to systematically investigate adversarial attacks for 3D models, a flourishing field applied to many real-world applications. In addition, we examine physical adversarial attacks that lead to safety violations. Last but not least, we summarize present popular topics, give insights on challenges, and shed light on future research on trustworthy AI. ",
    "url": "https://arxiv.org/abs/2310.00633",
    "authors": [
      "Yanjie Li",
      "Bin Xie",
      "Songtao Guo",
      "Yuanyuan Yang",
      "Bin Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.00648",
    "title": "Fewer is More: Trojan Attacks on Parameter-Efficient Fine-Tuning",
    "abstract": "Parameter-efficient fine-tuning (PEFT) enables efficient adaptation of pre-trained language models (PLMs) to specific tasks. By tuning only a minimal set of (extra) parameters, PEFT achieves performance comparable to full fine-tuning. However, despite its prevalent use, the security implications of PEFT remain largely unexplored. In this paper, we conduct a pilot study revealing that PEFT exhibits unique vulnerability to trojan attacks. Specifically, we present PETA, a novel attack that accounts for downstream adaptation through bilevel optimization: the upper-level objective embeds the backdoor into a PLM while the lower-level objective simulates PEFT to retain the PLM's task-specific performance. With extensive evaluation across a variety of downstream tasks and trigger designs, we demonstrate PETA's effectiveness in terms of both attack success rate and unaffected clean accuracy, even after the victim user performs PEFT over the backdoored PLM using untainted data. Moreover, we empirically provide possible explanations for PETA's efficacy: the bilevel optimization inherently 'orthogonalizes' the backdoor and PEFT modules, thereby retaining the backdoor throughout PEFT. Based on this insight, we explore a simple defense that omits PEFT in selected layers of the backdoored PLM and unfreezes a subset of these layers' parameters, which is shown to effectively neutralize PETA. ",
    "url": "https://arxiv.org/abs/2310.00648",
    "authors": [
      "Lauren Hong",
      "Ting Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.00654",
    "title": "Streamlining Attack Tree Generation: A Fragment-Based Approach",
    "abstract": "Attack graphs are a tool for analyzing security vulnerabilities that capture different and prospective attacks on a system. As a threat modeling tool, it shows possible paths that an attacker can exploit to achieve a particular goal. However, due to the large number of vulnerabilities that are published on a daily basis, they have the potential to rapidly expand in size. Consequently, this necessitates a significant amount of resources to generate attack graphs. In addition, generating composited attack models for complex systems such as self-adaptive or AI is very difficult due to their nature to continuously change. In this paper, we present a novel fragment-based attack graph generation approach that utilizes information from publicly available information security databases. Furthermore, we also propose a domain-specific language for attack modeling, which we employ in the proposed attack graph generation approach. Finally, we present a demonstrator example showcasing the attack generator's capability to replicate a verified attack chain, as previously confirmed by security experts. ",
    "url": "https://arxiv.org/abs/2310.00654",
    "authors": [
      "Irdin Pekaric",
      "Markus Frick",
      "Jubril Gbolahan Adigun",
      "Raffaela Groner",
      "Thomas Witte",
      "Alexander Raschke",
      "Michael Felderer",
      "Matthias Tichy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.00656",
    "title": "LEGO-Prover: Neural Theorem Proving with Growing Libraries",
    "abstract": "Despite the success of large language models (LLMs), the task of theorem proving still remains one of the hardest reasoning tasks that is far from being fully solved. Prior methods using language models have demonstrated promising results, but they still struggle to prove even middle school level theorems. One common limitation of these methods is that they assume a fixed theorem library during the whole theorem proving process. However, as we all know, creating new useful theorems or even new theories is not only helpful but crucial and necessary for advancing mathematics and proving harder and deeper results. In this work, we present LEGO-Prover, which employs a growing skill library containing verified lemmas as skills to augment the capability of LLMs used in theorem proving. By constructing the proof modularly, LEGO-Prover enables LLMs to utilize existing skills retrieved from the library and to create new skills during the proving process. These skills are further evolved (by prompting an LLM) to enrich the library on another scale. Modular and reusable skills are constantly added to the library to enable tackling increasingly intricate mathematical problems. Moreover, the learned library further bridges the gap between human proofs and formal proofs by making it easier to impute missing steps. LEGO-Prover advances the state-of-the-art pass rate on miniF2F-valid (48.0% to 57.0%) and miniF2F-test (45.5% to 47.1%). During the proving process, LEGO-Prover also manages to generate over 20,000 skills (theorems/lemmas) and adds them to the growing library. Our ablation study indicates that these newly added skills are indeed helpful for proving theorems, resulting in an improvement from a success rate of 47.1% to 50.4%. We also release our code and all the generated skills. ",
    "url": "https://arxiv.org/abs/2310.00656",
    "authors": [
      "Huajian Xin",
      "Haiming Wang",
      "Chuanyang Zheng",
      "Lin Li",
      "Zhengying Liu",
      "Qingxing Cao",
      "Yinya Huang",
      "Jing Xiong",
      "Han Shi",
      "Enze Xie",
      "Jian Yin",
      "Zhenguo Li",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.00659",
    "title": "Liveness Detection Competition -- Noncontact-based Fingerprint  Algorithms and Systems (LivDet-2023 Noncontact Fingerprint)",
    "abstract": "Liveness Detection (LivDet) is an international competition series open to academia and industry with the objec-tive to assess and report state-of-the-art in Presentation Attack Detection (PAD). LivDet-2023 Noncontact Fingerprint is the first edition of the noncontact fingerprint-based PAD competition for algorithms and systems. The competition serves as an important benchmark in noncontact-based fingerprint PAD, offering (a) independent assessment of the state-of-the-art in noncontact-based fingerprint PAD for algorithms and systems, and (b) common evaluation protocol, which includes finger photos of a variety of Presentation Attack Instruments (PAIs) and live fingers to the biometric research community (c) provides standard algorithm and system evaluation protocols, along with the comparative analysis of state-of-the-art algorithms from academia and industry with both old and new android smartphones. The winning algorithm achieved an APCER of 11.35% averaged overall PAIs and a BPCER of 0.62%. The winning system achieved an APCER of 13.0.4%, averaged over all PAIs tested over all the smartphones, and a BPCER of 1.68% over all smartphones tested. Four-finger systems that make individual finger-based PAD decisions were also tested. The dataset used for competition will be available 1 to all researchers as per data share protocol ",
    "url": "https://arxiv.org/abs/2310.00659",
    "authors": [
      "Sandip Purnapatra",
      "Humaira Rezaie",
      "Bhavin Jawade",
      "Yu Liu",
      "Yue Pan",
      "Luke Brosell",
      "Mst Rumana Sumi",
      "Lambert Igene",
      "Alden Dimarco",
      "Srirangaraj Setlur",
      "Soumyabrata Dey",
      "Stephanie Schuckers",
      "Marco Huber",
      "Jan Niklas Kolf",
      "Meiling Fang",
      "Naser Damer",
      "Banafsheh Adami",
      "Raul Chitic",
      "Karsten Seelert",
      "Vishesh Mistry",
      "Rahul Parthe",
      "Umit Kacar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00664",
    "title": "Twin Neural Network Improved k-Nearest Neighbor Regression",
    "abstract": "Twin neural network regression is trained to predict differences between regression targets rather than the targets themselves. A solution to the original regression problem can be obtained by ensembling predicted differences between the targets of an unknown data point and multiple known anchor data points. Choosing the anchors to be the nearest neighbors of the unknown data point leads to a neural network-based improvement of k-nearest neighbor regression. This algorithm is shown to outperform both neural networks and k-nearest neighbor regression on small to medium-sized data sets. ",
    "url": "https://arxiv.org/abs/2310.00664",
    "authors": [
      "Sebastian J. Wetzel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00665",
    "title": "Balancing Efficiency vs. Effectiveness and Providing Missing Label  Robustness in Multi-Label Stream Classification",
    "abstract": "Available works addressing multi-label classification in a data stream environment focus on proposing accurate models; however, these models often exhibit inefficiency and cannot balance effectiveness and efficiency. In this work, we propose a neural network-based approach that tackles this issue and is suitable for high-dimensional multi-label classification. Our model uses a selective concept drift adaptation mechanism that makes it suitable for a non-stationary environment. Additionally, we adapt our model to an environment with missing labels using a simple yet effective imputation strategy and demonstrate that it outperforms a vast majority of the state-of-the-art supervised models. To achieve our purposes, we introduce a weighted binary relevance-based approach named ML-BELS using the Broad Ensemble Learning System (BELS) as its base classifier. Instead of a chain of stacked classifiers, our model employs independent weighted ensembles, with the weights generated by the predictions of a BELS classifier. We show that using the weighting strategy on datasets with low label cardinality negatively impacts the accuracy of the model; with this in mind, we use the label cardinality as a trigger for applying the weights. We present an extensive assessment of our model using 11 state-of-the-art baselines, five synthetics, and 13 real-world datasets, all with different characteristics. Our results demonstrate that the proposed approach ML-BELS is successful in balancing effectiveness and efficiency, and is robust to missing labels and concept drift. ",
    "url": "https://arxiv.org/abs/2310.00665",
    "authors": [
      "Sepehr Bakhshi",
      "Fazli Can"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00689",
    "title": "Exchange means change: an unsupervised single-temporal change detection  framework based on intra- and inter-image patch exchange",
    "abstract": "Change detection (CD) is a critical task in studying the dynamics of ecosystems and human activities using multi-temporal remote sensing images. While deep learning has shown promising results in CD tasks, it requires a large number of labeled and paired multi-temporal images to achieve high performance. Pairing and annotating large-scale multi-temporal remote sensing images is both expensive and time-consuming. To make deep learning-based CD techniques more practical and cost-effective, we propose an unsupervised single-temporal CD framework based on intra- and inter-image patch exchange (I3PE). The I3PE framework allows for training deep change detectors on unpaired and unlabeled single-temporal remote sensing images that are readily available in real-world applications. The I3PE framework comprises four steps: 1) intra-image patch exchange method is based on an object-based image analysis method and adaptive clustering algorithm, which generates pseudo-bi-temporal image pairs and corresponding change labels from single-temporal images by exchanging patches within the image; 2) inter-image patch exchange method can generate more types of land-cover changes by exchanging patches between images; 3) a simulation pipeline consisting of several image enhancement methods is proposed to simulate the radiometric difference between pre- and post-event images caused by different imaging conditions in real situations; 4) self-supervised learning based on pseudo-labels is applied to further improve the performance of the change detectors in both unsupervised and semi-supervised cases. Extensive experiments on two large-scale datasets demonstrate that I3PE outperforms representative unsupervised approaches and achieves F1 value improvements of 10.65% and 6.99% to the SOTA method. Moreover, I3PE can improve the performance of the ... (see the original article for full abstract) ",
    "url": "https://arxiv.org/abs/2310.00689",
    "authors": [
      "Hongruixuan Chen",
      "Jian Song",
      "Chen Wu",
      "Bo Du",
      "Naoto Yokoya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.00697",
    "title": "Learning How to Propagate Messages in Graph Neural Networks",
    "abstract": "This paper studies the problem of learning message propagation strategies for graph neural networks (GNNs). One of the challenges for graph neural networks is that of defining the propagation strategy. For instance, the choices of propagation steps are often specialized to a single graph and are not personalized to different nodes. To compensate for this, in this paper, we present learning to propagate, a general learning framework that not only learns the GNN parameters for prediction but more importantly, can explicitly learn the interpretable and personalized propagate strategies for different nodes and various types of graphs. We introduce the optimal propagation steps as latent variables to help find the maximum-likelihood estimation of the GNN parameters in a variational Expectation-Maximization (VEM) framework. Extensive experiments on various types of graph benchmarks demonstrate that our proposed framework can significantly achieve better performance compared with the state-of-the-art methods, and can effectively learn personalized and interpretable propagate strategies of messages in GNNs. ",
    "url": "https://arxiv.org/abs/2310.00697",
    "authors": [
      "Teng Xiao",
      "Zhengyu Chen",
      "Donglin Wang",
      "Suhang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00699",
    "title": "Pianist Identification Using Convolutional Neural Networks",
    "abstract": "This paper presents a comprehensive study of automatic performer identification in expressive piano performances using convolutional neural networks (CNNs) and expressive features. Our work addresses the challenging multi-class classification task of identifying virtuoso pianists, which has substantial implications for building dynamic musical instruments with intelligence and smart musical systems. Incorporating recent advancements, we leveraged large-scale expressive piano performance datasets and deep learning techniques. We refined the scores by expanding repetitions and ornaments for more accurate feature extraction. We demonstrated the capability of one-dimensional CNNs for identifying pianists based on expressive features and analyzed the impact of the input sequence lengths and different features. The proposed model outperforms the baseline, achieving 85.3% accuracy in a 6-way identification task. Our refined dataset proved more apt for training a robust pianist identifier, making a substantial contribution to the field of automatic performer identification. Our codes have been released at https://github.com/BetsyTang/PID-CNN. ",
    "url": "https://arxiv.org/abs/2310.00699",
    "authors": [
      "Jingjing Tang",
      "Geraint Wiggins",
      "Gyorgy Fazekas"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2310.00702",
    "title": "You Do Not Need Additional Priors in Camouflage Object Detection",
    "abstract": "Camouflage object detection (COD) poses a significant challenge due to the high resemblance between camouflaged objects and their surroundings. Although current deep learning methods have made significant progress in detecting camouflaged objects, many of them heavily rely on additional prior information. However, acquiring such additional prior information is both expensive and impractical in real-world scenarios. Therefore, there is a need to develop a network for camouflage object detection that does not depend on additional priors. In this paper, we propose a novel adaptive feature aggregation method that effectively combines multi-layer feature information to generate guidance information. In contrast to previous approaches that rely on edge or ranking priors, our method directly leverages information extracted from image features to guide model training. Through extensive experimental results, we demonstrate that our proposed method achieves comparable or superior performance when compared to state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2310.00702",
    "authors": [
      "Yuchen Dong",
      "Heng Zhou",
      "Chengyang Li",
      "Junjie Xie",
      "Yongqiang Xie",
      "Zhongbo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00712",
    "title": "Logical Bias Learning for Object Relation Prediction",
    "abstract": "Scene graph generation (SGG) aims to automatically map an image into a semantic structural graph for better scene understanding. It has attracted significant attention for its ability to provide object and relation information, enabling graph reasoning for downstream tasks. However, it faces severe limitations in practice due to the biased data and training method. In this paper, we present a more rational and effective strategy based on causal inference for object relation prediction. To further evaluate the superiority of our strategy, we propose an object enhancement module to conduct ablation studies. Experimental results on the Visual Gnome 150 (VG-150) dataset demonstrate the effectiveness of our proposed method. These contributions can provide great potential for foundation models for decision-making. ",
    "url": "https://arxiv.org/abs/2310.00712",
    "authors": [
      "Xinyu Zhou",
      "Zihan Ji",
      "Anna Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00724",
    "title": "Subtractive Mixture Models via Squaring: Representation and Learning",
    "abstract": "Mixture models are traditionally represented and learned by adding several distributions as components. Allowing mixtures to subtract probability mass or density can drastically reduce the number of components needed to model complex distributions. However, learning such subtractive mixtures while ensuring they still encode a non-negative function is challenging. We investigate how to learn and perform inference on deep subtractive mixtures by squaring them. We do this in the framework of probabilistic circuits, which enable us to represent tensorized mixtures and generalize several other subtractive models. We theoretically prove that the class of squared circuits allowing subtractions can be exponentially more expressive than traditional additive mixtures; and, we empirically show this increased expressiveness on a series of real-world distribution estimation tasks. ",
    "url": "https://arxiv.org/abs/2310.00724",
    "authors": [
      "Lorenzo Loconte",
      "Aleksanteri M. Sladek",
      "Stefan Mengel",
      "Martin Trapp",
      "Arno Solin",
      "Nicolas Gillis",
      "Antonio Vergari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.00728",
    "title": "Physics-Informed Graph Neural Network for Dynamic Reconfiguration of  Power Systems",
    "abstract": "To maintain a reliable grid we need fast decision-making algorithms for complex problems like Dynamic Reconfiguration (DyR). DyR optimizes distribution grid switch settings in real-time to minimize grid losses and dispatches resources to supply loads with available generation. DyR is a mixed-integer problem and can be computationally intractable to solve for large grids and at fast timescales. We propose GraPhyR, a Physics-Informed Graph Neural Network (GNNs) framework tailored for DyR. We incorporate essential operational and connectivity constraints directly within the GNN framework and train it end-to-end. Our results show that GraPhyR is able to learn to optimize the DyR task. ",
    "url": "https://arxiv.org/abs/2310.00728",
    "authors": [
      "Jules Authier",
      "Rabab Haider",
      "Anuradha Annaswamy",
      "Florian Dorfler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.00729",
    "title": "Spectral Neural Networks: Approximation Theory and Optimization  Landscape",
    "abstract": "There is a large variety of machine learning methodologies that are based on the extraction of spectral geometric information from data. However, the implementations of many of these methods often depend on traditional eigensolvers, which present limitations when applied in practical online big data scenarios. To address some of these challenges, researchers have proposed different strategies for training neural networks as alternatives to traditional eigensolvers, with one such approach known as Spectral Neural Network (SNN). In this paper, we investigate key theoretical aspects of SNN. First, we present quantitative insights into the tradeoff between the number of neurons and the amount of spectral geometric information a neural network learns. Second, we initiate a theoretical exploration of the optimization landscape of SNN's objective to shed light on the training dynamics of SNN. Unlike typical studies of convergence to global solutions of NN training dynamics, SNN presents an additional complexity due to its non-convex ambient loss function. ",
    "url": "https://arxiv.org/abs/2310.00729",
    "authors": [
      "Chenghui Li",
      "Rishi Sonthalia",
      "Nicolas Garcia Trillos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.00734",
    "title": "Robust Sentiment Analysis for Low Resource languages Using Data  Augmentation Approaches: A Case Study in Marathi",
    "abstract": "Sentiment analysis plays a crucial role in understanding the sentiment expressed in text data. While sentiment analysis research has been extensively conducted in English and other Western languages, there exists a significant gap in research efforts for sentiment analysis in low-resource languages. Limited resources, including datasets and NLP research, hinder the progress in this area. In this work, we present an exhaustive study of data augmentation approaches for the low-resource Indic language Marathi. Although domain-specific datasets for sentiment analysis in Marathi exist, they often fall short when applied to generalized and variable-length inputs. To address this challenge, this research paper proposes four data augmentation techniques for sentiment analysis in Marathi. The paper focuses on augmenting existing datasets to compensate for the lack of sufficient resources. The primary objective is to enhance sentiment analysis model performance in both in-domain and cross-domain scenarios by leveraging data augmentation strategies. The data augmentation approaches proposed showed a significant performance improvement for cross-domain accuracies. The augmentation methods include paraphrasing, back-translation; BERT-based random token replacement, named entity replacement, and pseudo-label generation; GPT-based text and label generation. Furthermore, these techniques can be extended to other low-resource languages and for general text classification tasks. ",
    "url": "https://arxiv.org/abs/2310.00734",
    "authors": [
      "Aabha Pingle",
      "Aditya Vyawahare",
      "Isha Joshi",
      "Rahul Tangsali",
      "Geetanjali Kale",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00744",
    "title": "Robust Feedback Control of Power Systems with Solar Plants and Composite  Loads",
    "abstract": "Due to the rapid developments in synchronized measurement technologies, there exist enormous opportunities to attenuate disturbances in future power grids with high penetration of renewables and complex load demands. To that end, this paper investigates the effectiveness of new robust feedback controllers for interconnected power systems with advanced power electronics-based models of photovoltaic (PV) power plants, composite load dynamics, and detailed higher-order synchronous generator models. Specifically, we design new, advanced control-theoretic wide-area controllers to improve the transient stability of nonlinear differential-algebraic models. Thorough simulation studies are carried out to assess the performance of the proposed controllers. Several fundamental questions on the proposed controllers' computational complexity and disturbance attenuation performance are raised and addressed. Simulation results demonstrate that with the proposed controllers as a secondary control layer, the overall transient stability and system robustness against load and renewables disturbances/uncertainties can be significantly improved compared to the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2310.00744",
    "authors": [
      "Muhammad Nadeem",
      "MirSaleh Bahavarnia",
      "Ahmad F. Taha"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.00761",
    "title": "Counterfactual Image Generation for adversarially robust and  interpretable Classifiers",
    "abstract": "Neural Image Classifiers are effective but inherently hard to interpret and susceptible to adversarial attacks. Solutions to both problems exist, among others, in the form of counterfactual examples generation to enhance explainability or adversarially augment training datasets for improved robustness. However, existing methods exclusively address only one of the issues. We propose a unified framework leveraging image-to-image translation Generative Adversarial Networks (GANs) to produce counterfactual samples that highlight salient regions for interpretability and act as adversarial samples to augment the dataset for more robustness. This is achieved by combining the classifier and discriminator into a single model that attributes real images to their respective classes and flags generated images as \"fake\". We assess the method's effectiveness by evaluating (i) the produced explainability masks on a semantic segmentation task for concrete cracks and (ii) the model's resilience against the Projected Gradient Descent (PGD) attack on a fruit defects detection problem. Our produced saliency maps are highly descriptive, achieving competitive IoU values compared to classical segmentation models despite being trained exclusively on classification labels. Furthermore, the model exhibits improved robustness to adversarial attacks, and we show how the discriminator's \"fakeness\" value serves as an uncertainty measure of the predictions. ",
    "url": "https://arxiv.org/abs/2310.00761",
    "authors": [
      "Rafael Bischof",
      "Florian Scheidegger",
      "Michael A. Kraus",
      "A. Cristiano I. Malossi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.00762",
    "title": "A note on the stabilizer formalism via noncommutative graphs",
    "abstract": "In this short note we formulate a stabilizer formalism in the language of noncommutative graphs. The classes of noncommutative graphs we consider are obtained via unitary representations of compact groups, and suitably chosen operators on finite-dimensional Hilbert spaces. Furthermore, in this framework, we generalize previous results in this area for determining when such noncommutative graphs have anticliques. ",
    "url": "https://arxiv.org/abs/2310.00762",
    "authors": [
      "Roy Araiza",
      "Jihong Cai",
      "Yushan Chen",
      "Abraham Holtermann",
      "Chieh Hsu",
      "Tushar Mohan",
      "Peixue Wu",
      "Zeyuan Yu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Operator Algebras (math.OA)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2310.00763",
    "title": "Data-Efficient Power Flow Learning for Network Contingencies",
    "abstract": "This work presents an efficient data-driven method to learn power flows in grids with network contingencies and to estimate corresponding probabilistic voltage envelopes (PVE). First, a network-aware Gaussian process (GP) termed Vertex-Degree Kernel (VDK-GP), developed in prior work, is used to estimate voltage-power functions for a few network configurations. The paper introduces a novel multi-task vertex degree kernel (MT-VDK) that amalgamates the learned VDK-GPs to determine power flows for unseen networks, with a significant reduction in the computational complexity and hyperparameter requirements compared to alternate approaches. Simulations on the IEEE 30-Bus network demonstrate the retention and transfer of power flow knowledge in both N-1 and N-2 contingency scenarios. The MT-VDK-GP approach achieves over 50% reduction in mean prediction error for novel N-1 contingency network configurations in low training data regimes (50-250 samples) over VDK-GP. Additionally, MT-VDK-GP outperforms a hyper-parameter based transfer learning approach in over 75% of N-2 contingency network structures, even without historical N-2 outage data. The proposed method demonstrates the ability to achieve PVEs using sixteen times fewer power flow solutions compared to Monte-Carlo sampling-based methods. ",
    "url": "https://arxiv.org/abs/2310.00763",
    "authors": [
      "Parikshit Pareek",
      "Deepjyoti Deka",
      "Sidhant Misra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.00781",
    "title": "Mining Java Memory Errors using Subjective Interesting Subgroups with  Hierarchical Targets",
    "abstract": "Software applications, especially Enterprise Resource Planning (ERP) systems, are crucial to the day-to-day operations of many industries. Therefore, it is essential to maintain these systems effectively using tools that can identify, diagnose, and mitigate their incidents. One promising data-driven approach is the Subgroup Discovery (SD) technique, a data mining method that can automatically mine incident datasets and extract discriminant patterns to identify the root causes of issues. However, current SD solutions have limitations in handling complex target concepts with multiple attributes organized hierarchically. To illustrate this scenario, we examine the case of Java out-of-memory incidents among several possible applications. We have a dataset that describes these incidents, including their context and the types of Java objects occupying memory when it reaches saturation, with these types arranged hierarchically. This scenario inspires us to propose a novel Subgroup Discovery approach that can handle complex target concepts with hierarchies. To achieve this, we design a pattern syntax and a quality measure that ensure the identified subgroups are relevant, non-redundant, and resilient to noise. To achieve the desired quality measure, we use the Subjective Interestingness model that incorporates prior knowledge about the data and promotes patterns that are both informative and surprising relative to that knowledge. We apply this framework to investigate out-of-memory errors and demonstrate its usefulness in incident diagnosis. To validate the effectiveness of our approach and the quality of the identified patterns, we present an empirical study. The source code and data used in the evaluation are publicly accessible, ensuring transparency and reproducibility. ",
    "url": "https://arxiv.org/abs/2310.00781",
    "authors": [
      "Youcef Remil",
      "Anes Bendimerad",
      "Mathieu Chambard",
      "Romain Mathonat",
      "Marc Plantevit",
      "Mehdi Kaytoue"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.00793",
    "title": "Revisiting Link Prediction: A Data Perspective",
    "abstract": "Link prediction, a fundamental task on graphs, has proven indispensable in various applications, e.g., friend recommendation, protein analysis, and drug interaction prediction. However, since datasets span a multitude of domains, they could have distinct underlying mechanisms of link formation. Evidence in existing literature underscores the absence of a universally best algorithm suitable for all datasets. In this paper, we endeavor to explore principles of link prediction across diverse datasets from a data-centric perspective. We recognize three fundamental factors critical to link prediction: local structural proximity, global structural proximity, and feature proximity. We then unearth relationships among those factors where (i) global structural proximity only shows effectiveness when local structural proximity is deficient. (ii) The incompatibility can be found between feature and structural proximity. Such incompatibility leads to GNNs for Link Prediction (GNN4LP) consistently underperforming on edges where the feature proximity factor dominates. Inspired by these new insights from a data perspective, we offer practical instruction for GNN4LP model design and guidelines for selecting appropriate benchmark datasets for more comprehensive evaluations. ",
    "url": "https://arxiv.org/abs/2310.00793",
    "authors": [
      "Haitao Mao",
      "Juanhui Li",
      "Harry Shomer",
      "Bingheng Li",
      "Wenqi Fan",
      "Yao Ma",
      "Tong Zhao",
      "Neil Shah",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.00797",
    "title": "Going Beyond Familiar Features for Deep Anomaly Detection",
    "abstract": "Anomaly Detection (AD) is a critical task that involves identifying observations that do not conform to a learned model of normality. Prior work in deep AD is predominantly based on a familiarity hypothesis, where familiar features serve as the reference in a pre-trained embedding space. While this strategy has proven highly successful, it turns out that it causes consistent false negatives when anomalies consist of truly novel features that are not well captured by the pre-trained encoding. We propose a novel approach to AD using explainability to capture novel features as unexplained observations in the input space. We achieve strong performance across a wide range of anomaly benchmarks by combining similarity and novelty in a hybrid approach. Our approach establishes a new state-of-the-art across multiple benchmarks, handling diverse anomaly types while eliminating the need for expensive background models and dense matching. In particular, we show that by taking account of novel features, we reduce false negative anomalies by up to 40% on challenging benchmarks compared to the state-of-the-art. Our method gives visually inspectable explanations for pixel-level anomalies. ",
    "url": "https://arxiv.org/abs/2310.00797",
    "authors": [
      "Sarath Sivaprasad",
      "Mario Fritz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00800",
    "title": "GraphPatcher: Mitigating Degree Bias for Graph Neural Networks via  Test-time Augmentation",
    "abstract": "Recent studies have shown that graph neural networks (GNNs) exhibit strong biases towards the node degree: they usually perform satisfactorily on high-degree nodes with rich neighbor information but struggle with low-degree nodes. Existing works tackle this problem by deriving either designated GNN architectures or training strategies specifically for low-degree nodes. Though effective, these approaches unintentionally create an artificial out-of-distribution scenario, where models mainly or even only observe low-degree nodes during the training, leading to a downgraded performance for high-degree nodes that GNNs originally perform well at. In light of this, we propose a test-time augmentation framework, namely GraphPatcher, to enhance test-time generalization of any GNNs on low-degree nodes. Specifically, GraphPatcher iteratively generates virtual nodes to patch artificially created low-degree nodes via corruptions, aiming at progressively reconstructing target GNN's predictions over a sequence of increasingly corrupted nodes. Through this scheme, GraphPatcher not only learns how to enhance low-degree nodes (when the neighborhoods are heavily corrupted) but also preserves the original superior performance of GNNs on high-degree nodes (when lightly corrupted). Additionally, GraphPatcher is model-agnostic and can also mitigate the degree bias for either self-supervised or supervised GNNs. Comprehensive experiments are conducted over seven benchmark datasets and GraphPatcher consistently enhances common GNNs' overall performance by up to 3.6% and low-degree performance by up to 6.5%, significantly outperforming state-of-the-art baselines. The source code is publicly available at https://github.com/jumxglhf/GraphPatcher. ",
    "url": "https://arxiv.org/abs/2310.00800",
    "authors": [
      "Mingxuan Ju",
      "Tong Zhao",
      "Wenhao Yu",
      "Neil Shah",
      "Yanfang Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.00809",
    "title": "Towards Causal Foundation Model: on Duality between Causal Inference and  Attention",
    "abstract": "Foundation models have brought changes to the landscape of machine learning, demonstrating sparks of human-level intelligence across a diverse array of tasks. However, a gap persists in complex tasks such as causal inference, primarily due to challenges associated with intricate reasoning steps and high numerical precision requirements. In this work, we take a first step towards building causally-aware foundation models for complex tasks. We propose a novel, theoretically sound method called Causal Inference with Attention (CInA), which utilizes multiple unlabeled datasets to perform self-supervised causal learning, and subsequently enables zero-shot causal inference on unseen tasks with new data. This is based on our theoretical results that demonstrate the primal-dual connection between optimal covariate balancing and self-attention, facilitating zero-shot causal inference through the final layer of a trained transformer-type architecture. We demonstrate empirically that our approach CInA effectively generalizes to out-of-distribution datasets and various real-world datasets, matching or even surpassing traditional per-dataset causal inference methodologies. ",
    "url": "https://arxiv.org/abs/2310.00809",
    "authors": [
      "Jiaqi Zhang",
      "Joel Jennings",
      "Cheng Zhang",
      "Chao Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.00813",
    "title": "OceanNet: A principled neural operator-based digital twin for regional  oceans",
    "abstract": "While data-driven approaches demonstrate great potential in atmospheric modeling and weather forecasting, ocean modeling poses distinct challenges due to complex bathymetry, land, vertical structure, and flow non-linearity. This study introduces OceanNet, a principled neural operator-based digital twin for ocean circulation. OceanNet uses a Fourier neural operator and predictor-evaluate-corrector integration scheme to mitigate autoregressive error growth and enhance stability over extended time scales. A spectral regularizer counteracts spectral bias at smaller scales. OceanNet is applied to the northwest Atlantic Ocean western boundary current (the Gulf Stream), focusing on the task of seasonal prediction for Loop Current eddies and the Gulf Stream meander. Trained using historical sea surface height (SSH) data, OceanNet demonstrates competitive forecast skill by outperforming SSH predictions by an uncoupled, state-of-the-art dynamical ocean model forecast, reducing computation by 500,000 times. These accomplishments demonstrate the potential of physics-inspired deep neural operators as cost-effective alternatives to high-resolution numerical ocean models. ",
    "url": "https://arxiv.org/abs/2310.00813",
    "authors": [
      "Ashesh Chattopadhyay",
      "Michael Gray",
      "Tianning Wu",
      "Anna B. Lowe",
      "Ruoying He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Chaotic Dynamics (nlin.CD)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2310.00837",
    "title": "Helios: An Efficient Out-of-core GNN Training System on Terabyte-scale  Graphs with In-memory Performance",
    "abstract": "Training graph neural networks (GNNs) on large-scale graph data holds immense promise for numerous real-world applications but remains a great challenge. Several disk-based GNN systems have been built to train large-scale graphs in a single machine. However, they often fall short in terms of performance, especially when training on terabyte-scale graphs. This is because existing disk-based systems either overly focus on minimizing the number of SSD accesses or do not fully overlap SSD accesses with GNN training, thus resulting in substantial unnecessary overhead on the CPU side and then low GPU utilization. To this end, we propose Helios, a system that can train GNN on terabyte graphs in a single machine while achieving throughput comparable with in-memory systems. To achieve this, we first present a GPU-initiated asynchronous disk IO stack, allowing the GPU to directly access graph data on SSD. This design only requires about 30% GPU cores to reach the almost maximal disk IO throughput and wastes no GPU cores between IO submission and IO completion such that the majority of GPU cores are left for other GNN kernels. Second, we design a GPU-managed heterogeneous cache that extends the cache hierarchy to heterogeneous CPU and GPU memory and thus enhances cache lookup throughput significantly by GPU parallelism. Finally, we build a deep GNN-aware pipeline that seamlessly integrates the computation and communication phases of the entire GNN training process, maximizing the utility of GPU computation cycles. Experimental results demonstrate that Helios can match the training throughput of in-memory GNN systems, even for terabyte-scale graphs. Remarkably, Helios surpasses the state-of-the-art GPU-managed baselines by up to 6.43x and exceeds CPU-managed baselines by over 182x on all terabyte-scale graphs. ",
    "url": "https://arxiv.org/abs/2310.00837",
    "authors": [
      "Jie Sun",
      "Mo Sun",
      "Zheng Zhang",
      "Jun Xie",
      "Zuocheng Shi",
      "Zihan Yang",
      "Jie Zhang",
      "Fei Wu",
      "Zeke Wang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.00840",
    "title": "Error Norm Truncation: Robust Training in the Presence of Data Noise for  Text Generation Models",
    "abstract": "Text generation models are notoriously vulnerable to errors in the training data. With the wide-spread availability of massive amounts of web-crawled data becoming more commonplace, how can we enhance the robustness of models trained on a massive amount of noisy web-crawled text? In our work, we propose Error Norm Truncation (ENT), a robust enhancement method to the standard training objective that truncates noisy data. Compared to methods that only uses the negative log-likelihood loss to estimate data quality, our method provides a more accurate estimation by considering the distribution of non-target tokens, which is often overlooked by previous work. Through comprehensive experiments across language modeling, machine translation, and text summarization, we show that equipping text generation models with ENT improves generation quality over standard training and previous soft and hard truncation methods. Furthermore, we show that our method improves the robustness of models against two of the most detrimental types of noise in machine translation, resulting in an increase of more than 2 BLEU points over the MLE baseline when up to 50% of noise is added to the data. ",
    "url": "https://arxiv.org/abs/2310.00840",
    "authors": [
      "Tianjian Li",
      "Haoran Xu",
      "Philipp Koehn",
      "Daniel Khashabi",
      "Kenton Murray"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.00843",
    "title": "Prov2vec: Learning Provenance Graph Representation for Unsupervised APT  Detection",
    "abstract": "Modern cyber attackers use advanced zero-day exploits, highly targeted spear phishing, and other social engineering techniques to gain access and also use evasion techniques to maintain a prolonged presence within the victim network while working gradually towards the objective. To minimize the damage, it is necessary to detect these Advanced Persistent Threats as early in the campaign as possible. This paper proposes, Prov2Vec, a system for the continuous monitoring of enterprise host's behavior to detect attackers' activities. It leverages the data provenance graph built using system event logs to get complete visibility into the execution state of an enterprise host and the causal relationship between system entities. It proposes a novel provenance graph kernel to obtain the canonical representation of the system behavior, which is compared against its historical behaviors and that of other hosts to detect the deviation from the normality. These representations are used in several machine learning models to evaluate their ability to capture the underlying behavior of an endpoint host. We have empirically demonstrated that the provenance graph kernel produces a much more compact representation compared to existing methods while improving prediction ability. ",
    "url": "https://arxiv.org/abs/2310.00843",
    "authors": [
      "Bibek Bhattarai",
      "H. Howie Huang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2310.00847",
    "title": "Can Pre-trained Networks Detect Familiar Out-of-Distribution Data?",
    "abstract": "Out-of-distribution (OOD) detection is critical for safety-sensitive machine learning applications and has been extensively studied, yielding a plethora of methods developed in the literature. However, most studies for OOD detection did not use pre-trained models and trained a backbone from scratch. In recent years, transferring knowledge from large pre-trained models to downstream tasks by lightweight tuning has become mainstream for training in-distribution (ID) classifiers. To bridge the gap between the practice of OOD detection and current classifiers, the unique and crucial problem is that the samples whose information networks know often come as OOD input. We consider that such data may significantly affect the performance of large pre-trained networks because the discriminability of these OOD data depends on the pre-training algorithm. Here, we define such OOD data as PT-OOD (Pre-Trained OOD) data. In this paper, we aim to reveal the effect of PT-OOD on the OOD detection performance of pre-trained networks from the perspective of pre-training algorithms. To achieve this, we explore the PT-OOD detection performance of supervised and self-supervised pre-training algorithms with linear-probing tuning, the most common efficient tuning method. Through our experiments and analysis, we find that the low linear separability of PT-OOD in the feature space heavily degrades the PT-OOD detection performance, and self-supervised models are more vulnerable to PT-OOD than supervised pre-trained models, even with state-of-the-art detection methods. To solve this vulnerability, we further propose a unique solution to large-scale pre-trained models: Leveraging powerful instance-by-instance discriminative representations of pre-trained models and detecting OOD in the feature space independent of the ID decision boundaries. The code will be available via https://github.com/AtsuMiyai/PT-OOD. ",
    "url": "https://arxiv.org/abs/2310.00847",
    "authors": [
      "Atsuyuki Miyai",
      "Qing Yu",
      "Go Irie",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00856",
    "title": "Multi-triplet Feature Augmentation for Ponzi Scheme Detection in  Ethereum",
    "abstract": "Blockchain technology revolutionizes the Internet, but also poses increasing risks, particularly in cryptocurrency finance. On the Ethereum platform, Ponzi schemes, phishing scams, and a variety of other frauds emerge. Existing Ponzi scheme detection approaches based on heterogeneous transaction graph modeling leverages semantic information between node (account) pairs to establish connections, overlooking the semantic attributes inherent to the edges (interactions). To overcome this, we construct heterogeneous Ethereum interaction graphs with multiple triplet interaction patterns to better depict the real Ethereum environment. Based on this, we design a new framework named multi-triplet augmented heterogeneous graph neural network (MAHGNN) for Ponzi scheme detection. We introduce the Conditional Variational Auto Encoder (CVAE) to capture the semantic information of different triplet interaction patterns, which facilitates the characterization on account features. Extensive experiments demonstrate that MAHGNN is capable of addressing the problem of multi-edge interactions in heterogeneous Ethereum interaction graphs and achieving state-of-the-art performance in Ponzi scheme detection. ",
    "url": "https://arxiv.org/abs/2310.00856",
    "authors": [
      "Chengxiang Jin",
      "Jiajun Zhou",
      "Shengbo Gong",
      "Chenxuan Xie",
      "Qi Xuan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.00871",
    "title": "COMPOSER: Scalable and Robust Modular Policies for Snake Robots",
    "abstract": "Snake robots have showcased remarkable compliance and adaptability in their interaction with environments, mirroring the traits of their natural counterparts. While their hyper-redundant and high-dimensional characteristics add to this adaptability, they also pose great challenges to robot control. Instead of perceiving the hyper-redundancy and flexibility of snake robots as mere challenges, there lies an unexplored potential in leveraging these traits to enhance robustness and generalizability at the control policy level. We seek to develop a control policy that effectively breaks down the high dimensionality of snake robots while harnessing their redundancy. In this work, we consider the snake robot as a modular robot and formulate the control of the snake robot as a cooperative Multi-Agent Reinforcement Learning (MARL) problem. Each segment of the snake robot functions as an individual agent. Specifically, we incorporate a self-attention mechanism to enhance the cooperative behavior between agents. A high-level imagination policy is proposed to provide additional rewards to guide the low-level control policy. We validate the proposed method COMPOSER with five snake robot tasks, including goal reaching, wall climbing, shape formation, tube crossing, and block pushing. COMPOSER achieves the highest success rate across all tasks when compared to a centralized baseline and four modular policy baselines. Additionally, we show enhanced robustness against module corruption and significantly superior zero-shot generalizability in our proposed method. The videos of this work are available on our project page: https://sites.google.com/view/composer-snake/. ",
    "url": "https://arxiv.org/abs/2310.00871",
    "authors": [
      "Yuyou Zhang",
      "Yaru Niu",
      "Xingyu Liu",
      "Ding Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00873",
    "title": "Deep Neural Networks Tend To Extrapolate Predictably",
    "abstract": "Conventional wisdom suggests that neural network predictions tend to be unpredictable and overconfident when faced with out-of-distribution (OOD) inputs. Our work reassesses this assumption for neural networks with high-dimensional inputs. Rather than extrapolating in arbitrary ways, we observe that neural network predictions often tend towards a constant value as input data becomes increasingly OOD. Moreover, we find that this value often closely approximates the optimal constant solution (OCS), i.e., the prediction that minimizes the average loss over the training data without observing the input. We present results showing this phenomenon across 8 datasets with different distributional shifts (including CIFAR10-C and ImageNet-R, S), different loss functions (cross entropy, MSE, and Gaussian NLL), and different architectures (CNNs and transformers). Furthermore, we present an explanation for this behavior, which we first validate empirically and then study theoretically in a simplified setting involving deep homogeneous networks with ReLU activations. Finally, we show how one can leverage our insights in practice to enable risk-sensitive decision-making in the presence of OOD inputs. ",
    "url": "https://arxiv.org/abs/2310.00873",
    "authors": [
      "Katie Kang",
      "Amrith Setlur",
      "Claire Tomlin",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00874",
    "title": "PC-NeRF: Parent-Child Neural Radiance Fields under Partial Sensor Data  Loss in Autonomous Driving Environments",
    "abstract": "Reconstructing large-scale 3D scenes is essential for autonomous vehicles, especially when partial sensor data is lost. Although the recently developed neural radiance fields (NeRF) have shown compelling results in implicit representations, the large-scale 3D scene reconstruction using partially lost LiDAR point cloud data still needs to be explored. To bridge this gap, we propose a novel 3D scene reconstruction framework called parent-child neural radiance field (PC-NeRF). The framework comprises two modules, the parent NeRF and the child NeRF, to simultaneously optimize scene-level, segment-level, and point-level scene representations. Sensor data can be utilized more efficiently by leveraging the segment-level representation capabilities of child NeRFs, and an approximate volumetric representation of the scene can be quickly obtained even with limited observations. With extensive experiments, our proposed PC-NeRF is proven to achieve high-precision 3D reconstruction in large-scale scenes. Moreover, PC-NeRF can effectively tackle situations where partial sensor data is lost and has high deployment efficiency with limited training time. Our approach implementation and the pre-trained models will be available at https://github.com/biter0088/pc-nerf. ",
    "url": "https://arxiv.org/abs/2310.00874",
    "authors": [
      "Xiuzhong Hu",
      "Guangming Xiong",
      "Zheng Zang",
      "Peng Jia",
      "Yuxuan Han",
      "Junyi Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.00893",
    "title": "Engineering the Neural Collapse Geometry of Supervised-Contrastive Loss",
    "abstract": "Supervised-contrastive loss (SCL) is an alternative to cross-entropy (CE) for classification tasks that makes use of similarities in the embedding space to allow for richer representations. In this work, we propose methods to engineer the geometry of these learnt feature embeddings by modifying the contrastive loss. In pursuit of adjusting the geometry we explore the impact of prototypes, fixed embeddings included during training to alter the final feature geometry. Specifically, through empirical findings, we demonstrate that the inclusion of prototypes in every batch induces the geometry of the learnt embeddings to align with that of the prototypes. We gain further insights by considering a limiting scenario where the number of prototypes far outnumber the original batch size. Through this, we establish a connection to cross-entropy (CE) loss with a fixed classifier and normalized embeddings. We validate our findings by conducting a series of experiments with deep neural networks on benchmark vision datasets. ",
    "url": "https://arxiv.org/abs/2310.00893",
    "authors": [
      "Jaidev Gill",
      "Vala Vakilian",
      "Christos Thrampoulidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00896",
    "title": "Organized Event Participant Prediction Enhanced by Social Media  Retweeting Data",
    "abstract": "Nowadays, many platforms on the Web offer organized events, allowing users to be organizers or participants. For such platforms, it is beneficial to predict potential event participants. Existing work on this problem tends to borrow recommendation techniques. However, compared to e-commerce items and purchases, events and participation are usually of a much smaller frequency, and the data may be insufficient to learn an accurate model. In this paper, we propose to utilize social media retweeting activity data to enhance the learning of event participant prediction models. We create a joint knowledge graph to bridge the social media and the target domain, assuming that event descriptions and tweets are written in the same language. Furthermore, we propose a learning model that utilizes retweeting information for the target domain prediction more effectively. We conduct comprehensive experiments in two scenarios with real-world data. In each scenario, we set up training data of different sizes, as well as warm and cold test cases. The evaluation results show that our approach consistently outperforms several baseline models, especially with the warm test cases, and when target domain data is limited. ",
    "url": "https://arxiv.org/abs/2310.00896",
    "authors": [
      "Yihong Zhang",
      "Takahiro Hara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.00897",
    "title": "Practical Radar Sensing Using Two Stage Neural Network for Denoising  OTFS Signals",
    "abstract": "Noise contamination affects the performance of orthogonal time frequency space (OTFS) signals in real-world environments, making radar sensing challenging. Our objective is to derive the range and velocity from the delay-Doppler (DD) domain for radar sensing by using OTFS signaling. This work introduces a two-stage approach to tackle this issue. In the first stage, we use a convolutional neural network (CNN) model to classify the noise levels as moderate or severe. Subsequently, if the noise level is severe, the OTFS samples are denoised using a generative adversarial network (GAN). The proposed approach achieves notable levels of accuracy in the classification of noisy signals and mean absolute error (MAE) for the entire system even in low signal-to-noise ratio (SNR) scenarios. ",
    "url": "https://arxiv.org/abs/2310.00897",
    "authors": [
      "Ashok S Kumar",
      "Sheetal Kalyani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2310.00906",
    "title": "A Decentralized Cooperative Navigation Approach for Visual Homing  Networks",
    "abstract": "Visual homing is a lightweight approach to visual navigation. Given the stored information of an initial 'home' location, the navigation task back to this location is achieved from any other location by comparing the stored home information to the current image and extracting a motion vector. A challenge that constrains the applicability of visual homing is that the home location must be within the robot's field of view to initiate the homing process. Thus, we propose a blockchain approach to visual navigation for a heterogeneous robot team over a wide area of visual navigation. Because it does not require map data structures, the approach is useful for robot platforms with a small computational footprint, and because it leverages current visual information, it supports a resilient and adaptive path selection. Further, we present a lightweight Proof-of-Work (PoW) mechanism for reaching consensus in the untrustworthy visual homing network. ",
    "url": "https://arxiv.org/abs/2310.00906",
    "authors": [
      "Mohamed Rahouti",
      "Damian Lyons",
      "Senthil Kumar Jagatheesaperumal",
      "Kaiqi Xiong"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2310.00920",
    "title": "Every Dataset Counts: Scaling up Monocular 3D Object Detection with  Joint Datasets Training",
    "abstract": "Monocular 3D object detection plays a crucial role in autonomous driving. However, existing monocular 3D detection algorithms depend on 3D labels derived from LiDAR measurements, which are costly to acquire for new datasets and challenging to deploy in novel environments. Specifically, this study investigates the pipeline for training a monocular 3D object detection model on a diverse collection of 3D and 2D datasets. The proposed framework comprises three components: (1) a robust monocular 3D model capable of functioning across various camera settings, (2) a selective-training strategy to accommodate datasets with differing class annotations, and (3) a pseudo 3D training approach using 2D labels to enhance detection performance in scenes containing only 2D labels. With this framework, we could train models on a joint set of various open 3D/2D datasets to obtain models with significantly stronger generalization capability and enhanced performance on new dataset with only 2D labels. We conduct extensive experiments on KITTI/nuScenes/ONCE/Cityscapes/BDD100K datasets to demonstrate the scaling ability of the proposed method. ",
    "url": "https://arxiv.org/abs/2310.00920",
    "authors": [
      "Fulong Ma",
      "Xiaoyang Yan",
      "Yuxuan Liu",
      "Ming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00926",
    "title": "Integration of Graph Neural Network and Neural-ODEs for Tumor Dynamic  Prediction",
    "abstract": "In anti-cancer drug development, a major scientific challenge is disentangling the complex relationships between high-dimensional genomics data from patient tumor samples, the corresponding tumor's organ of origin, the drug targets associated with given treatments and the resulting treatment response. Furthermore, to realize the aspirations of precision medicine in identifying and adjusting treatments for patients depending on the therapeutic response, there is a need for building tumor dynamic models that can integrate both longitudinal tumor size as well as multimodal, high-content data. In this work, we take a step towards enhancing personalized tumor dynamic predictions by proposing a heterogeneous graph encoder that utilizes a bipartite Graph Convolutional Neural network (GCN) combined with Neural Ordinary Differential Equations (Neural-ODEs). We applied the methodology to a large collection of patient-derived xenograft (PDX) data, spanning a wide variety of treatments (as well as their combinations) on tumors that originated from a number of different organs. We first show that the methodology is able to discover a tumor dynamic model that significantly improves upon an empirical model which is in current use. Additionally, we show that the graph encoder is able to effectively utilize multimodal data to enhance tumor predictions. Our findings indicate that the methodology holds significant promise and offers potential applications in pre-clinical settings. ",
    "url": "https://arxiv.org/abs/2310.00926",
    "authors": [
      "Omid Bazgir",
      "Zichen Wang",
      "Marc Hafner",
      "James Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00927",
    "title": "Understanding Transferable Representation Learning and Zero-shot  Transfer in CLIP",
    "abstract": "Multi-modal learning has become increasingly popular due to its ability to leverage information from different data sources (e.g., text and images) to improve the model performance. Recently, CLIP has emerged as an effective approach that employs vision-language contrastive pretraining to learn joint image and text representations and exhibits remarkable performance in zero-shot learning and text-guided natural image generation. Despite the huge practical success of CLIP, its theoretical understanding remains elusive. In this paper, we formally study transferrable representation learning underlying CLIP and demonstrate how features from different modalities get aligned. We also analyze its zero-shot transfer performance on the downstream tasks. Inspired by our analysis, we propose a new CLIP-type approach, which achieves better performance than CLIP and other state-of-the-art methods on benchmark datasets. ",
    "url": "https://arxiv.org/abs/2310.00927",
    "authors": [
      "Zixiang Chen",
      "Yihe Deng",
      "Yuanzhi Li",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.00938",
    "title": "An FPRAS for two terminal reliability in directed acyclic graphs",
    "abstract": "We give a fully polynomial-time randomized approximation scheme (FPRAS) for two terminal reliability in directed acyclic graphs. ",
    "url": "https://arxiv.org/abs/2310.00938",
    "authors": [
      "Weiming Feng",
      "Heng Guo"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2310.00944",
    "title": "Towards Robust 3D Object Detection In Rainy Conditions",
    "abstract": "LiDAR sensors are used in autonomous driving applications to accurately perceive the environment. However, they are affected by adverse weather conditions such as snow, fog, and rain. These everyday phenomena introduce unwanted noise into the measurements, severely degrading the performance of LiDAR-based perception systems. In this work, we propose a framework for improving the robustness of LiDAR-based 3D object detectors against road spray. Our approach uses a state-of-the-art adverse weather detection network to filter out spray from the LiDAR point cloud, which is then used as input for the object detector. In this way, the detected objects are less affected by the adverse weather in the scene, resulting in a more accurate perception of the environment. In addition to adverse weather filtering, we explore the use of radar targets to further filter false positive detections. Tests on real-world data show that our approach improves the robustness to road spray of several popular 3D object detectors. ",
    "url": "https://arxiv.org/abs/2310.00944",
    "authors": [
      "Aldi Piroli",
      "Vinzenz Dallabetta",
      "Johannes Kopp",
      "Marc Walessa",
      "Daniel Meissner",
      "Klaus Dietmayer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00946",
    "title": "Distilling Influences to Mitigate Prediction Churn in Graph Neural  Networks",
    "abstract": "Models with similar performances exhibit significant disagreement in the predictions of individual samples, referred to as prediction churn. Our work explores this phenomenon in graph neural networks by investigating differences between models differing only in their initializations in their utilized features for predictions. We propose a novel metric called Influence Difference (ID) to quantify the variation in reasons used by nodes across models by comparing their influence distribution. Additionally, we consider the differences between nodes with a stable and an unstable prediction, positing that both equally utilize different reasons and thus provide a meaningful gradient signal to closely match two models even when the predictions for nodes are similar. Based on our analysis, we propose to minimize this ID in Knowledge Distillation, a domain where a new model should closely match an established one. As an efficient approximation, we introduce DropDistillation (DD) that matches the output for a graph perturbed by edge deletions. Our empirical evaluation of six benchmark datasets for node classification validates the differences in utilized features. DD outperforms previous methods regarding prediction stability and overall performance in all considered Knowledge Distillation experiments. ",
    "url": "https://arxiv.org/abs/2310.00946",
    "authors": [
      "Andreas Roth",
      "Thomas Liebig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.00956",
    "title": "Semiframes: algebras of heterogeneous consensus",
    "abstract": "Semitopologies model consensus in distributed system by equating the notion of a quorum -- a set of participants sufficient to make local progress -- with that of an open set. This yields a topology-like theory of consensus, but semitopologies generalise topologies, since the intersection of two quorums need not necessarily be a quorum. The semitopological model of consensus is naturally heterogeneous and local, just like topologies can be heterogenous and local, and for the same reasons: points may have different quorums and there is no restriction that open sets / quorums be uniformly generated (e.g. open sets can be something other than two-thirds majorities of the points in the space). Semiframes are an algebraic abstraction of semitopologies. They are to semitopologies as frames are to topologies. We give a notion of semifilter, which plays a role analogous to filters, and show how to build a semiframe out of the open sets of a semitopology, and a semitopology out of the semifilters of a semiframe. We define suitable notions of category and morphism and prove a categorical duality between (sober) semiframes and (spatial) semitopologies, and investigate well-behavedness properties on semitopologies and semiframes across the duality. Surprisingly, the structure of semiframes is not what one might initially expect just from looking at semitopologies, and the canonical structure required for the duality result -- a compatibility relation *, generalising sets intersection -- is also canonical for expressing well-behavedness properties. Overall, we deliver a new categorical, algebraic, abstract framework within which to study consensus on distributed systems, and which is also simply interesting to consider as a mathematical theory in its own right. ",
    "url": "https://arxiv.org/abs/2310.00956",
    "authors": [
      "Murdoch Gabbay",
      "Giuliano Losa"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)",
      "General Topology (math.GN)"
    ]
  },
  {
    "id": "arXiv:2310.00965",
    "title": "Effective Learning with Node Perturbation in Deep Neural Networks",
    "abstract": "Backpropagation (BP) is the dominant and most successful method for training parameters of deep neural network models. However, BP relies on two computationally distinct phases, does not provide a satisfactory explanation of biological learning, and can be challenging to apply for training of networks with discontinuities or noisy node dynamics. By comparison, node perturbation (NP) proposes learning by the injection of noise into the network activations, and subsequent measurement of the induced loss change. NP relies on two forward (inference) passes, does not make use of network derivatives, and has been proposed as a model for learning in biological systems. However, standard NP is highly data inefficient and unstable due to its unguided, noise-based, activity search. In this work, we investigate different formulations of NP and relate it to the concept of directional derivatives as well as combining it with a decorrelating mechanism for layer-wise inputs. We find that a closer alignment with directional derivatives, and induction of decorrelation of inputs at every layer significantly enhances performance of NP learning making it competitive with BP. ",
    "url": "https://arxiv.org/abs/2310.00965",
    "authors": [
      "Sander Dalm",
      "Marcel van Gerven",
      "Nasir Ahmad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01001",
    "title": "Counterfactual Causality for Reachability and Safety based on Distance  Functions",
    "abstract": "Investigations of causality in operational systems aim at providing human-understandable explanations of why a system behaves as it does. There is, in particular, a demand to explain what went wrong on a given counterexample execution that shows that a system does not satisfy a given specification. To this end, this paper investigates a notion of counterfactual causality in transition systems based on Stalnaker's and Lewis' semantics of counterfactuals in terms of most similar possible worlds and introduces a novel corresponding notion of counterfactual causality in two-player games. Using distance functions between paths in transition systems, this notion defines whether reaching a certain set of states is a cause for the violation of a reachability or safety property. Similarly, using distance functions between memoryless strategies in reachability and safety games, it is defined whether reaching a set of states is a cause for the fact that a given strategy for the player under investigation is losing. The contribution of the paper is two-fold: In transition systems, it is shown that counterfactual causality can be checked in polynomial time for three prominent distance functions between paths. In two-player games, the introduced notion of counterfactual causality is shown to be checkable in polynomial time for two natural distance functions between memoryless strategies. Further, a notion of explanation that can be extracted from a counterfactual cause and that pinpoints changes to be made to the given strategy in order to transform it into a winning strategy is defined. For the two distance functions under consideration, the problem to decide whether such an explanation imposes only minimal necessary changes to the given strategy with respect to the used distance function turns out to be coNP-complete and not to be solvable in polynomial time if P is not equal to NP, respectively. ",
    "url": "https://arxiv.org/abs/2310.01001",
    "authors": [
      "Julie Parreaux",
      "Jakob Piribauer",
      "Christel Baier"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2310.01029",
    "title": "Incorporating Supervised Domain Generalization into Data Augmentation",
    "abstract": "With the increasing utilization of deep learning in outdoor settings, its robustness needs to be enhanced to preserve accuracy in the face of distribution shifts, such as compression artifacts. Data augmentation is a widely used technique to improve robustness, thanks to its ease of use and numerous benefits. However, it requires more training epochs, making it difficult to train large models with limited computational resources. To address this problem, we treat data augmentation as supervised domain generalization~(SDG) and benefit from the SDG method, contrastive semantic alignment~(CSA) loss, to improve the robustness and training efficiency of data augmentation. The proposed method only adds loss during model training and can be used as a plug-in for existing data augmentation methods. Experiments on the CIFAR-100 and CUB datasets show that the proposed method improves the robustness and training efficiency of typical data augmentations. ",
    "url": "https://arxiv.org/abs/2310.01029",
    "authors": [
      "Shohei Enomoto",
      "Monikka Roslianna Busto",
      "Takeharu Eda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.01030",
    "title": "A Robust Machine Learning Approach for Path Loss Prediction in 5G  Networks with Nested Cross Validation",
    "abstract": "The design and deployment of fifth-generation (5G) wireless networks pose significant challenges due to the increasing number of wireless devices. Path loss has a landmark importance in network performance optimization, and accurate prediction of the path loss, which characterizes the attenuation of signal power during transmission, is critical for effective network planning, coverage estimation, and optimization. In this sense, we utilize machine learning (ML) methods, which overcome conventional path loss prediction models drawbacks, for path loss prediction in a 5G network system to facilitate more accurate network planning, resource optimization, and performance improvement in wireless communication systems. To this end, we utilize a novel approach, nested cross validation scheme, with ML to prevent overfitting, thereby getting better generalization error and stable results for ML deployment. First, we acquire a publicly available dataset obtained through a comprehensive measurement campaign conducted in an urban macro-cell scenario located in Beijing, China. The dataset includes crucial information such as longitude, latitude, elevation, altitude, clutter height, and distance, which are utilized as essential features to predict the path loss in the 5G network system. We deploy Support Vector Regression (SVR), CatBoost Regression (CBR), eXtreme Gradient Boosting Regression (XGBR), Artificial Neural Network (ANN), and Random Forest (RF) methods to predict the path loss, and compare the prediction results in terms of Mean Absolute Error (MAE) and Mean Square Error (MSE). As per obtained results, XGBR outperforms the rest of the methods. It outperforms CBR with a slight performance differences by 0.4 % and 1 % in terms of MAE and MSE metrics, respectively. On the other hand, it outperforms the rest of the methods with clear performance differences. ",
    "url": "https://arxiv.org/abs/2310.01030",
    "authors": [
      "Ibrahim Yaz\u0131c\u0131",
      "Emre Gures"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.01042",
    "title": "Constrained Flows in Networks",
    "abstract": "The support of a flow $x$ in a network is the subdigraph induced by the arcs $ij$ for which $x_{ij}>0$. We discuss a number of results on flows in networks where we put certain restrictions on structure of the support of the flow. Many of these problems are NP-hard because they generalize linkage problems for digraphs. For example deciding whether a network ${\\cal N}=(D,s,t,c)$ has a maximum flow $x$ such that the maximum out-degree of the support $D_x$ of $x$ is at most 2 is NP-complete as it contains the 2-linkage problem as a very special case. Another problem which is NP-complete for the same reason is that of deciding the maximum flow we can send from $s$ to $t$ along 2 paths (called a maximum 2-path-flow) in ${\\cal N}$. Baier et al. (2005) gave a polynomial algorithm which finds a 2-path-flow $x$ whose value is at least $\\frac{2}{3}$ of the value of a optimum 2-path-flow. This is best possible unless P=NP. They also obtained a $\\frac{2}{p}$-approximation for the maximum value of a $p$-path-flow for every $p\\geq 2$. In this paper we give an algorithm which gets within a factor $\\frac{1}{H(p)}$ of the optimum solution, where $H(p)$ is the $p$'th harmonic number ($H(p) \\sim \\ln(p)$). This improves the approximation bound due to Baier et al. when $p\\geq 5$. We show that in the case where the network is acyclic, we can find a maximum $p$-path-flow in polynomial time for every $p$. We determine the complexity of a number of related problems concerning the structure of flows. For the special case of acyclic digraphs, some of the results we obtain are in some sense best possible. ",
    "url": "https://arxiv.org/abs/2310.01042",
    "authors": [
      "St\u00e9phane Bessy",
      "J\u00f8rgen Bang-Jensen",
      "Lucas Picasarri-Arrieta"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2310.01055",
    "title": "Improved Crop and Weed Detection with Diverse Data Ensemble Learning in  Agriculture",
    "abstract": "Modern agriculture heavily relies on Site-Specific Farm Management practices, necessitating accurate detection, localization, and quantification of crops and weeds in the field, which can be achieved using deep learning techniques. In this regard, crop and weed-specific binary segmentation models have shown promise. However, uncontrolled field conditions limit their performance from one field to the other. To improve semantic model generalization, existing methods augment and synthesize agricultural data to account for uncontrolled field conditions. However, given highly varied field conditions, these methods have limitations. To overcome the challenges of model deterioration in such conditions, we propose utilizing data specific to other crops and weeds for our specific target problem. To achieve this, we propose a novel ensemble framework. Our approach involves utilizing different crop and weed models trained on diverse datasets and employing a teacher-student configuration. By using homogeneous stacking of base models and a trainable meta-architecture to combine their outputs, we achieve significant improvements for Canola crops and Kochia weeds on unseen test data, surpassing the performance of single semantic segmentation models. We identify the UNET meta-architecture as the most effective in this context. Finally, through ablation studies, we demonstrate and validate the effectiveness of our proposed model. We observe that including base models trained on other target crops and weeds can help generalize the model to capture varied field conditions. Lastly, we propose two novel datasets with varied conditions for comparisons. ",
    "url": "https://arxiv.org/abs/2310.01055",
    "authors": [
      "Muhammad Hamza Asad",
      "Saeed Anwar",
      "Abdul Bais"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01065",
    "title": "KGEx: Explaining Knowledge Graph Embeddings via Subgraph Sampling and  Knowledge Distillation",
    "abstract": "Despite being the go-to choice for link prediction on knowledge graphs, research on interpretability of knowledge graph embeddings (KGE) has been relatively unexplored. We present KGEx, a novel post-hoc method that explains individual link predictions by drawing inspiration from surrogate models research. Given a target triple to predict, KGEx trains surrogate KGE models that we use to identify important training triples. To gauge the impact of a training triple, we sample random portions of the target triple neighborhood and we train multiple surrogate KGE models on each of them. To ensure faithfulness, each surrogate is trained by distilling knowledge from the original KGE model. We then assess how well surrogates predict the target triple being explained, the intuition being that those leading to faithful predictions have been trained on impactful neighborhood samples. Under this assumption, we then harvest triples that appear frequently across impactful neighborhoods. We conduct extensive experiments on two publicly available datasets, to demonstrate that KGEx is capable of providing explanations faithful to the black-box model. ",
    "url": "https://arxiv.org/abs/2310.01065",
    "authors": [
      "Vasileios Baltatzis",
      "Luca Costabello"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01080",
    "title": "Rel2Graph: Automated Mapping From Relational Databases to a Unified  Property Knowledge Graph",
    "abstract": "Although a few approaches are proposed to convert relational databases to graphs, there is a genuine lack of systematic evaluation across a wider spectrum of databases. Recognising the important issue of query mapping, this paper proposes an approach Rel2Graph, an automatic knowledge graph construction (KGC) approach from an arbitrary number of relational databases. Our approach also supports the mapping of conjunctive SQL queries into pattern-based NoSQL queries. We evaluate our proposed approach on two widely used relational database-oriented datasets: Spider and KaggleDBQA benchmarks for semantic parsing. We employ the execution accuracy (EA) metric to quantify the proportion of results by executing the NoSQL queries on the property knowledge graph we construct that aligns with the results of SQL queries performed on relational databases. Consequently, the counterpart property knowledge graph of benchmarks with high accuracy and integrity can be ensured. The code and data will be publicly available. The code and data are available at github\\footnote{https://github.com/nlp-tlp/Rel2Graph}. ",
    "url": "https://arxiv.org/abs/2310.01080",
    "authors": [
      "Ziyu Zhao",
      "Wei Liu",
      "Tim French",
      "Michael Stewart"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2310.01081",
    "title": "Unmasking Role-Play Attack Strategies in Exploiting Decentralized  Finance (DeFi) Systems",
    "abstract": "The rapid growth and adoption of decentralized finance (DeFi) systems have been accompanied by various threats, notably those emerging from vulnerabilities in their intricate design. In our work, we introduce and define an attack strategy termed as Role-Play Attack, in which the attacker acts as multiple roles concurrently to exploit the DeFi system and cause substantial financial losses. We provide a formal definition of this strategy and demonstrate its potential impacts by revealing the total loss of \\$435.1M caused by 14 historical attacks with applying this pattern. Besides, we mathematically analyzed the attacks with top 2 losses and retrofitted the corresponding attack pattern by concrete execution, indicating that this strategy could increase the potential profit for original attacks by \\$3.34M (51.4%) and \\$3.76M (12.0%), respectively. ",
    "url": "https://arxiv.org/abs/2310.01081",
    "authors": [
      "Weilin Li",
      "Zhun Wang",
      "Chenyu Li",
      "Heying Chen",
      "Taiyu Wong",
      "Pengyu Sun",
      "Yufei Yu",
      "Chao Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.01084",
    "title": "Non-negative isomorphic neural networks for photonic neuromorphic  accelerators",
    "abstract": "Neuromorphic photonic accelerators are becoming increasingly popular, since they can significantly improve computation speed and energy efficiency, leading to femtojoule per MAC efficiency. However, deploying existing DL models on such platforms is not trivial, since a great range of photonic neural network architectures relies on incoherent setups and power addition operational schemes that cannot natively represent negative quantities. This results in additional hardware complexity that increases cost and reduces energy efficiency. To overcome this, we can train non-negative neural networks and potentially exploit the full range of incoherent neuromorphic photonic capabilities. However, existing approaches cannot achieve the same level of accuracy as their regular counterparts, due to training difficulties, as also recent evidence suggests. To this end, we introduce a methodology to obtain the non-negative isomorphic equivalents of regular neural networks that meet requirements of neuromorphic hardware, overcoming the aforementioned limitations. Furthermore, we also introduce a sign-preserving optimization approach that enables training of such isomorphic networks in a non-negative manner. ",
    "url": "https://arxiv.org/abs/2310.01084",
    "authors": [
      "Manos Kirtas",
      "Nikolaos Passalis",
      "Nikolaos Pleros",
      "Anastasios Tefas"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01089",
    "title": "GraphText: Graph Reasoning in Text Space",
    "abstract": "Large Language Models (LLMs) have gained the ability to assimilate human knowledge and facilitate natural language interactions with both humans and other LLMs. However, despite their impressive achievements, LLMs have not made significant advancements in the realm of graph machine learning. This limitation arises because graphs encapsulate distinct relational data, making it challenging to transform them into natural language that LLMs understand. In this paper, we bridge this gap with a novel framework, GraphText, that translates graphs into natural language. GraphText derives a graph-syntax tree for each graph that encapsulates both the node attributes and inter-node relationships. Traversal of the tree yields a graph text sequence, which is then processed by an LLM to treat graph tasks as text generation tasks. Notably, GraphText offers multiple advantages. It introduces training-free graph reasoning: even without training on graph data, GraphText with ChatGPT can achieve on par with, or even surpassing, the performance of supervised-trained graph neural networks through in-context learning (ICL). Furthermore, GraphText paves the way for interactive graph reasoning, allowing both humans and LLMs to communicate with the model seamlessly using natural language. These capabilities underscore the vast, yet-to-be-explored potential of LLMs in the domain of graph machine learning. ",
    "url": "https://arxiv.org/abs/2310.01089",
    "authors": [
      "Jianan Zhao",
      "Le Zhuo",
      "Yikang Shen",
      "Meng Qu",
      "Kai Liu",
      "Michael Bronstein",
      "Zhaocheng Zhu",
      "Jian Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01098",
    "title": "NP$^2$L: Negative Pseudo Partial Labels Extraction for Graph Neural  Networks",
    "abstract": "How to utilize the pseudo labels has always been a research hotspot in machine learning. However, most methods use pseudo labels as supervised training, and lack of valid assessing for their accuracy. Moreover, applications of pseudo labels in graph neural networks (GNNs) oversee the difference between graph learning and other machine learning tasks such as message passing mechanism. Aiming to address the first issue, we found through a large number of experiments that the pseudo labels are more accurate if they are selected by not overlapping partial labels and defined as negative node pairs relations. Therefore, considering the extraction based on pseudo and partial labels, negative edges are constructed between two nodes by the negative pseudo partial labels extraction (NP$^2$E) module. With that, a signed graph are built containing highly accurate pseudo labels information from the original graph, which effectively assists GNN in learning at the message-passing level, provide one solution to the second issue. Empirical results about link prediction and node classification tasks on several benchmark datasets demonstrate the effectiveness of our method. State-of-the-art performance is achieved on the both tasks. ",
    "url": "https://arxiv.org/abs/2310.01098",
    "authors": [
      "Xinjie Shen",
      "Danyang Wu",
      "Jitao Lu",
      "Junjie Liang",
      "Jin Xu",
      "Feiping Nie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.01113",
    "title": "HyperGraphDis: Leveraging Hypergraphs for Contextual and Social-Based  Disinformation Detection",
    "abstract": "In light of the growing impact of disinformation on social, economic, and political landscapes, accurate and efficient identification methods are increasingly critical. This paper introduces HyperGraphDis, a novel approach for detecting disinformation on Twitter that employs a hypergraph-based representation to capture (i) the intricate social structure arising from retweet cascades, (ii) relational features among users, and (iii) semantic and topical nuances. Evaluated on four Twitter datasets -- focusing on the 2016 U.S. Presidential election and the COVID-19 pandemic -- HyperGraphDis outperforms existing methods in both accuracy and computational efficiency, underscoring its effectiveness and scalability for tackling the challenges posed by disinformation dissemination. The HyperGraphDis displayed exceptional performance in an evaluation using a COVID-19-related dataset, achieving an impressive F1 score of approximately 92.5%. This result represents a notable improvement of around 7% compared to other existing methods. Additionally, significant enhancements in computation time were observed for both model training and inference processes. In terms of model training, completion times were noticeably accelerated, ranging from 1.6 to 16.5 times faster than previous benchmarks. Similarly, during inference, computational times demonstrated increased efficiency, ranging from 1.3 to 17.7 times faster than alternative methods. ",
    "url": "https://arxiv.org/abs/2310.01113",
    "authors": [
      "Nikos Salamanos",
      "Pantelitsa Leonidou",
      "Nikolaos Laoutaris",
      "Michael Sirivianos",
      "Maria Aspri",
      "Marius Paraschiv"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.01119",
    "title": "Text Data Augmentation in Low-Resource Settings via Fine-Tuning of Large  Language Models",
    "abstract": "The in-context learning ability of large language models (LLMs) enables them to generalize to novel downstream tasks with relatively few labeled examples. However, they require enormous computational resources to be deployed. Alternatively, smaller models can solve specific tasks if fine-tuned with enough labeled examples. These examples, however, are expensive to obtain. In pursuit of the best of both worlds, we study the annotation and generation of fine-tuning training data via fine-tuned teacher LLMs to improve the downstream performance of much smaller models. In four text classification and two text generation tasks, we find that both data generation and annotation dramatically improve the respective downstream model's performance, occasionally necessitating only a minor fraction of the original training dataset. ",
    "url": "https://arxiv.org/abs/2310.01119",
    "authors": [
      "Jean Kaddour",
      "Qi Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01129",
    "title": "Strength in Diversity: Multi-Branch Representation Learning for Vehicle  Re-Identification",
    "abstract": "This paper presents an efficient and lightweight multi-branch deep architecture to improve vehicle re-identification (V-ReID). While most V-ReID work uses a combination of complex multi-branch architectures to extract robust and diversified embeddings towards re-identification, we advocate that simple and lightweight architectures can be designed to fulfill the Re-ID task without compromising performance. We propose a combination of Grouped-convolution and Loss-Branch-Split strategies to design a multi-branch architecture that improve feature diversity and feature discriminability. We combine a ResNet50 global branch architecture with a BotNet self-attention branch architecture, both designed within a Loss-Branch-Split (LBS) strategy. We argue that specialized loss-branch-splitting helps to improve re-identification tasks by generating specialized re-identification features. A lightweight solution using grouped convolution is also proposed to mimic the learning of loss-splitting into multiple embeddings while significantly reducing the model size. In addition, we designed an improved solution to leverage additional metadata, such as camera ID and pose information, that uses 97% less parameters, further improving re-identification performance. In comparison to state-of-the-art (SoTA) methods, our approach outperforms competing solutions in Veri-776 by achieving 85.6% mAP and 97.7% CMC1 and obtains competitive results in Veri-Wild with 88.1% mAP and 96.3% CMC1. Overall, our work provides important insights into improving vehicle re-identification and presents a strong basis for other retrieval tasks. Our code is available at the https://github.com/videturfortuna/vehicle_reid_itsc2023. ",
    "url": "https://arxiv.org/abs/2310.01129",
    "authors": [
      "Eurico Almeida",
      "Bruno Silva",
      "Jorge Batista"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.01136",
    "title": "Deterministic Treasure Hunt and Rendezvous in Arbitrary Connected Graphs",
    "abstract": "Treasure hunt and rendezvous are fundamental tasks performed by mobile agents in graphs. In treasure hunt, an agent has to find an inert target (called treasure) situated at an unknown node of the graph. In rendezvous, two agents, initially located at distinct nodes of the graph, traverse its edges in synchronous rounds and have to meet at some node. We assume that the graph is connected (otherwise none of these tasks is feasible) and consider deterministic treasure hunt and rendezvous algorithms. The time of a treasure hunt algorithm is the worst-case number of edge traversals performed by the agent until the treasure is found. The time of a rendezvous algorithm is the worst-case number of rounds since the wakeup of the earlier agent until the meeting. To the best of our knowledge, all known treasure hunt and rendezvous algorithms rely on the assumption that degrees of all nodes are finite, even when the graph itself may be infinite. In the present paper we remove this assumption for the first time, and consider both above tasks in arbitrary connected graphs whose nodes can have either finite or countably infinite degrees. Our main result is the first universal treasure hunt algorithm working for arbitrary connected graphs. We prove that the time of this algorithm has optimal order of magnitude among all possible treasure hunt algorithms working for arbitrary connected graphs. As a consequence of this result we obtain the first universal rendezvous algorithm working for arbitrary connected graphs. The time of this algorithm is polynomial in a lower bound holding in many graphs, in particular in the tree all of whose degrees are infinite. ",
    "url": "https://arxiv.org/abs/2310.01136",
    "authors": [
      "Debasish Pattanayak",
      "Andrzej Pelc"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.01138",
    "title": "Target-Aware Contextual Political Bias Detection in News",
    "abstract": "Media bias detection requires comprehensive integration of information derived from multiple news sources. Sentence-level political bias detection in news is no exception, and has proven to be a challenging task that requires an understanding of bias in consideration of the context. Inspired by the fact that humans exhibit varying degrees of writing styles, resulting in a diverse range of statements with different local and global contexts, previous work in media bias detection has proposed augmentation techniques to exploit this fact. Despite their success, we observe that these techniques introduce noise by over-generalizing bias context boundaries, which hinders performance. To alleviate this issue, we propose techniques to more carefully search for context using a bias-sensitive, target-aware approach for data augmentation. Comprehensive experiments on the well-known BASIL dataset show that when combined with pre-trained models such as BERT, our augmentation techniques lead to state-of-the-art results. Our approach outperforms previous methods significantly, obtaining an F1-score of 58.15 over state-of-the-art bias detection task. ",
    "url": "https://arxiv.org/abs/2310.01138",
    "authors": [
      "Iffat Maab",
      "Edison Marrese-Taylor",
      "Yutaka Matsuo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.01140",
    "title": "Neural Processing of Tri-Plane Hybrid Neural Fields",
    "abstract": "Driven by the appealing properties of neural fields for storing and communicating 3D data, the problem of directly processing them to address tasks such as classification and part segmentation has emerged and has been investigated in recent works. Early approaches employ neural fields parameterized by shared networks trained on the whole dataset, achieving good task performance but sacrificing reconstruction quality. To improve the latter, later methods focus on individual neural fields parameterized as large Multi-Layer Perceptrons (MLPs), which are, however, challenging to process due to the high dimensionality of the weight space, intrinsic weight space symmetries, and sensitivity to random initialization. Hence, results turn out significantly inferior to those achieved by processing explicit representations, e.g., point clouds or meshes. In the meantime, hybrid representations, in particular based on tri-planes, have emerged as a more effective and efficient alternative to realize neural fields, but their direct processing has not been investigated yet. In this paper, we show that the tri-plane discrete data structure encodes rich information, which can be effectively processed by standard deep-learning machinery. We define an extensive benchmark covering a diverse set of fields such as occupancy, signed/unsigned distance, and, for the first time, radiance fields. While processing a field with the same reconstruction quality, we achieve task performance far superior to frameworks that process large MLPs and, for the first time, almost on par with architectures handling explicit representations. ",
    "url": "https://arxiv.org/abs/2310.01140",
    "authors": [
      "Adriano Cardace",
      "Pierluigi Zama Ramirez",
      "Francesco Ballerini",
      "Allan Zhou",
      "Samuele Salti",
      "Luigi Di Stefano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.01142",
    "title": "[Re] CLRNet: Cross Layer Refinement Network for Lane Detection",
    "abstract": "The following work is a reproducibility report for CLRNet: Cross Layer Refinement Network for Lane Detection. The basic code was made available by the author. The paper proposes a novel Cross Layer Refinement Network to utilize both high and low level features for lane detection. The authors assert that the proposed technique sets the new state-of-the-art on three lane-detection benchmarks ",
    "url": "https://arxiv.org/abs/2310.01142",
    "authors": [
      "Viswesh N",
      "Kaushal Jadhav",
      "Avi Amalanshu",
      "Bratin Mondal",
      "Sabaris Waran",
      "Om Sadhwani",
      "Apoorv Kumar",
      "Debashish Chakravarty"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.01143",
    "title": "Preliminary Performance Evaluation of a Satellite-to-HAP Communication  Link",
    "abstract": "The emergence of Fifth-Generation (5G) communication networks has brought forth unprecedented connectivity with ultra-low latency, high data rates, and pervasive coverage. However, meeting the increasing demands of applications for seamless and high-quality communication, especially in rural areas, requires exploring innovative solutions that expand 5G beyond traditional terrestrial networks. Within the context of Non-Terrestrial Networks (NTNs), two promising technologies with vast potential are High Altitude Platforms (HAPs) and satellites. The combination of these two platforms is able to provide wide coverage and reliable communication in remote and inaccessible areas, and/or where terrestrial infrastructure is unavailable. This study evaluates the performance of the communication link between a Geostationary Equatorial Orbit (GEO) satellite and a HAP using the Internet of Drones Simulator (IoD-Sim), implemented in ns-3 and incorporating the 3GPP TR 38.811 channel model. The code base of IoD-Sim is extended to simulate HAPs, accounting for the Earths curvature in various geographic coordinate systems, and considering realistic mobility patterns. A simulation campaign is conducted to evaluate the GEO-to-HAP communication link in terms of Signal-to-Noise Ratio (SNR) in two different scenarios, considering the mobility of the HAP, and as a function of the frequency and the distance. ",
    "url": "https://arxiv.org/abs/2310.01143",
    "authors": [
      "Giovanni Grieco",
      "Giovanni Iacovelli",
      "Mattia Sandri",
      "Marco Giordani",
      "Michele Zorzi",
      "Luigi Alfredo Grieco"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.01144",
    "title": "The Map Equation Goes Neural",
    "abstract": "Community detection and graph clustering are essential for unsupervised data exploration and understanding the high-level organisation of networked systems. Recently, graph clustering has been highlighted as an under-explored primary task for graph neural networks. While hierarchical graph pooling has been shown to improve performance in graph and node classification tasks, it performs poorly in identifying meaningful clusters. Community detection has a long history in network science, but typically relies on optimising objective functions with custom-tailored search algorithms, not leveraging recent advances in deep learning, particularly from graph neural networks. In this paper, we narrow this gap between the deep learning and network science communities. We consider the map equation, an information-theoretic objective function for community detection. Expressing it in a fully differentiable tensor form that produces soft cluster assignments, we optimise the map equation with deep learning through gradient descent. More specifically, the reformulated map equation is a loss function compatible with any graph neural network architecture, enabling flexible clustering and graph pooling that clusters both graph structure and data features in an end-to-end way, automatically finding an optimum number of clusters without explicit regularisation. We evaluate our approach experimentally using different neural network architectures for unsupervised clustering in synthetic and real data. Our results show that our approach achieves competitive performance against baselines, naturally detects overlapping communities, and avoids over-partitioning sparse graphs. ",
    "url": "https://arxiv.org/abs/2310.01144",
    "authors": [
      "Christopher Bl\u00f6cker",
      "Chester Tan",
      "Ingo Scholtes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01146",
    "title": "NewsRecLib: A PyTorch-Lightning Library for Neural News Recommendation",
    "abstract": "NewsRecLib is an open-source library based on Pytorch-Lightning and Hydra developed for training and evaluating neural news recommendation models. The foremost goals of NewsRecLib are to promote reproducible research and rigorous experimental evaluation by (i) providing a unified and highly configurable framework for exhaustive experimental studies and (ii) enabling a thorough analysis of the performance contribution of different model architecture components and training regimes. NewsRecLib is highly modular, allows specifying experiments in a single configuration file, and includes extensive logging facilities. Moreover, NewsRecLib provides out-of-the-box implementations of several prominent neural models, training methods, standard evaluation benchmarks, and evaluation metrics for news recommendation. ",
    "url": "https://arxiv.org/abs/2310.01146",
    "authors": [
      "Andreea Iana",
      "Goran Glava\u0161",
      "Heiko Paulheim"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.01148",
    "title": "Cryptocurrency Portfolio Optimization by Neural Networks",
    "abstract": "Many cryptocurrency brokers nowadays offer a variety of derivative assets that allow traders to perform hedging or speculation. This paper proposes an effective algorithm based on neural networks to take advantage of these investment products. The proposed algorithm constructs a portfolio that contains a pair of negatively correlated assets. A deep neural network, which outputs the allocation weight of each asset at a time interval, is trained to maximize the Sharpe ratio. A novel loss term is proposed to regulate the network's bias towards a specific asset, thus enforcing the network to learn an allocation strategy that is close to a minimum variance strategy. Extensive experiments were conducted using data collected from Binance spanning 19 months to evaluate the effectiveness of our approach. The backtest results show that the proposed algorithm can produce neural networks that are able to make profits in different market situations. ",
    "url": "https://arxiv.org/abs/2310.01148",
    "authors": [
      "Quoc Minh Nguyen",
      "Dat Thanh Tran",
      "Juho Kanniainen",
      "Alexandros Iosifidis",
      "Moncef Gabbouj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01152",
    "title": "Large Language Model-Powered Smart Contract Vulnerability Detection: New  Perspectives",
    "abstract": "This paper provides a systematic analysis of the opportunities, challenges, and potential solutions of harnessing LLMs to dig out vulnerabilities within smart contracts based on our ongoing research. For the smart contract vulnerability detection task, the key to achieving practical usability lies in detecting as many true vulnerabilities as possible while minimizing the number of false positives. However, our empirical study using LLM as a detection tool reveals interesting yet contradictory findings: generating more answers with higher randomness largely increases the likelihood of a correct answer being generated while inevitably leading to a higher number of false positives, resulting in exhaustive manual verification efforts. To mitigate this tension, we propose an adversarial framework dubbed GPTLens that breaks the traditional one-stage detection into two synergistic stages $-$ generation and discrimination, for progressive detection and fine-tuning, wherein the LLM plays dual roles, i.e., auditor and critic, respectively. The goal of auditor is to identify multiple diverse vulnerabilities with intermediate reasoning, while the goal of critic is to evaluate the accuracy of identified vulnerabilities and to examine the integrity of the detection reasoning. Experimental results and illustrative examples demonstrate that auditor and critic work together harmoniously to yield significant improvements over the traditional one-stage detection. GPTLens is intuitive, strategic, and entirely LLM-driven without relying on specialist expertise in smart contracts, showcasing its methodical generality and potential to detect a broad spectrum of vulnerabilities. Our code is available at: https://github.com/git-disl/GPTLens. ",
    "url": "https://arxiv.org/abs/2310.01152",
    "authors": [
      "Sihao Hu",
      "Tiansheng Huang",
      "Fatih \u0130lhan",
      "Selim Fukan Tekin",
      "Ling Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01156",
    "title": "Neural Fiber Activation in Unipolar vs Bipolar Deep Brain Stimulation",
    "abstract": "Deep Brain Stimulation (DBS) is an established and powerful treatment method in various neurological disorders. It involves chronically delivering electrical pulses to a certain stimulation target in the brain in order to alleviate the symptoms of a disease. Traditionally, the effect of DBS on neural tissue has been modeled based on the geometrical intersection of the static Volume of Tissue Activated (VTA) and the stimulation target. Recent studies suggest that the Dentato-Rubro-Thalamic Tract (DRTT) may serve as a potential common underlying stimulation target for tremor control in Essential Tremor (ET). However, clinical observations highlight that the therapeutic effect of DBS, especially in ET, is strongly influenced by the dynamic DBS parameters such as pulse width and frequency, as well as stimulation polarity. This study introduces a computational model to elucidate the effect of the stimulation signal shape on the DRTT under neural input. The simulation results suggest that achieving a specific pulse amplitude threshold is necessary before eliciting the therapeutic effect through adjustments in pulse widths and frequencies becomes feasible. Longer pulse widths proved more likely to induce firing, thus requiring a lower stimulation amplitude. Additionally, the modulation effect of bipolar configurations on neural traffic was found to vary significantly depending on the chosen stimulation polarity and the direction of neural traffic. Further, bipolar configurations demonstrated the ability to selectively influence firing patterns in different fiber tracts. ",
    "url": "https://arxiv.org/abs/2310.01156",
    "authors": [
      "Anna Franziska Frigge",
      "Alexander Medvedev",
      "Elena Jiltsova",
      "Dag Nyholm"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.01157",
    "title": "RRR-Net: Reusing, Reducing, and Recycling a Deep Backbone Network",
    "abstract": "It has become mainstream in computer vision and other machine learning domains to reuse backbone networks pre-trained on large datasets as preprocessors. Typically, the last layer is replaced by a shallow learning machine of sorts; the newly-added classification head and (optionally) deeper layers are fine-tuned on a new task. Due to its strong performance and simplicity, a common pre-trained backbone network is ResNet152.However, ResNet152 is relatively large and induces inference latency. In many cases, a compact and efficient backbone with similar performance would be preferable over a larger, slower one. This paper investigates techniques to reuse a pre-trained backbone with the objective of creating a smaller and faster model. Starting from a large ResNet152 backbone pre-trained on ImageNet, we first reduce it from 51 blocks to 5 blocks, reducing its number of parameters and FLOPs by more than 6 times, without significant performance degradation. Then, we split the model after 3 blocks into several branches, while preserving the same number of parameters and FLOPs, to create an ensemble of sub-networks to improve performance. Our experiments on a large benchmark of $40$ image classification datasets from various domains suggest that our techniques match the performance (if not better) of ``classical backbone fine-tuning'' while achieving a smaller model size and faster inference speed. ",
    "url": "https://arxiv.org/abs/2310.01157",
    "authors": [
      "Haozhe Sun",
      "Isabelle Guyon",
      "Felix Mohr",
      "Hedi Tabia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01166",
    "title": "Gotcha! This Model Uses My Code! Evaluating Membership Leakage Risks in  Code Models",
    "abstract": "Given large-scale source code datasets available in open-source projects and advanced large language models, recent code models have been proposed to address a series of critical software engineering tasks, such as program repair and code completion. The training data of the code models come from various sources, not only the publicly available source code, e.g., open-source projects on GitHub but also the private data such as the confidential source code from companies, which may contain sensitive information (for example, SSH keys and personal information). As a result, the use of these code models may raise new privacy concerns. In this paper, we focus on a critical yet not well-explored question on using code models: what is the risk of membership information leakage in code models? Membership information leakage refers to the risk that an attacker can infer whether a given data point is included in (i.e., a member of) the training data. To answer this question, we propose Gotcha, a novel membership inference attack method specifically for code models. We investigate the membership leakage risk of code models. Our results reveal a worrying fact that the risk of membership leakage is high: although the previous attack methods are close to random guessing, Gotcha can predict the data membership with a high true positive rate of 0.95 and a low false positive rate of 0.10. We also show that the attacker's knowledge of the victim model (e.g., the model architecture and the pre-training data) impacts the success rate of attacks. Further analysis demonstrates that changing the decoding strategy can mitigate the risk of membership leakage. This study calls for more attention to understanding the privacy of code models and developing more effective countermeasures against such attacks. ",
    "url": "https://arxiv.org/abs/2310.01166",
    "authors": [
      "Zhou Yang",
      "Zhipeng Zhao",
      "Chenyu Wang",
      "Jieke Shi",
      "Dongsum Kim",
      "Donggyun Han",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.01180",
    "title": "Evolutionary Neural Architecture Search for Transformer in Knowledge  Tracing",
    "abstract": "Knowledge tracing (KT) aims to trace students' knowledge states by predicting whether students answer correctly on exercises. Despite the excellent performance of existing Transformer-based KT approaches, they are criticized for the manually selected input features for fusion and the defect of single global context modelling to directly capture students' forgetting behavior in KT, when the related records are distant from the current record in terms of time. To address the issues, this paper first considers adding convolution operations to the Transformer to enhance its local context modelling ability used for students' forgetting behavior, then proposes an evolutionary neural architecture search approach to automate the input feature selection and automatically determine where to apply which operation for achieving the balancing of the local/global context modelling. In the search space, the original global path containing the attention module in Transformer is replaced with the sum of a global path and a local path that could contain different convolutions, and the selection of input features is also considered. To search the best architecture, we employ an effective evolutionary algorithm to explore the search space and also suggest a search space reduction strategy to accelerate the convergence of the algorithm. Experimental results on the two largest and most challenging education datasets demonstrate the effectiveness of the architecture found by the proposed approach. ",
    "url": "https://arxiv.org/abs/2310.01180",
    "authors": [
      "Shangshang Yang",
      "Xiaoshan Yu",
      "Ye Tian",
      "Xueming Yan",
      "Haiping Ma",
      "Xingyi Zhang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01181",
    "title": "Graph Isomorphic Networks for Assessing Reliability of the  Medium-Voltage Grid",
    "abstract": "Ensuring electricity grid reliability becomes increasingly challenging with the shift towards renewable energy and declining conventional capacities. Distribution System Operators (DSOs) aim to achieve grid reliability by verifying the n-1 principle, ensuring continuous operation in case of component failure. Electricity networks' complex graph-based data holds crucial information for n-1 assessment: graph structure and data about stations/cables. Unlike traditional machine learning methods, Graph Neural Networks (GNNs) directly handle graph-structured data. This paper proposes using Graph Isomorphic Networks (GINs) for n-1 assessments in medium voltage grids. The GIN framework is designed to generalise to unseen grids and utilise graph structure and data about stations/cables. The proposed GIN approach demonstrates faster and more reliable grid assessments than a traditional mathematical optimisation approach, reducing prediction times by approximately a factor of 1000. The findings offer a promising approach to address computational challenges and enhance the reliability and efficiency of energy grid assessments. ",
    "url": "https://arxiv.org/abs/2310.01181",
    "authors": [
      "Charlotte Cambier van Nooten",
      "Tom van de Poll",
      "Sonja F\u00fcllhase",
      "Jacco Heres",
      "Tom Heskes",
      "Yuliya Shapovalova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01188",
    "title": "Quantifying the Plausibility of Context Reliance in Neural Machine  Translation",
    "abstract": "Establishing whether language models can use contextual information in a human-plausible way is important to ensure their safe adoption in real-world settings. However, the questions of when and which parts of the context affect model generations are typically tackled separately, and current plausibility evaluations are practically limited to a handful of artificial benchmarks. To address this, we introduce Plausibility Evaluation of Context Reliance (PECoRe), an end-to-end interpretability framework designed to quantify context usage in language models' generations. Our approach leverages model internals to (i) contrastively identify context-sensitive target tokens in generated texts and (ii) link them to contextual cues justifying their prediction. We use PECoRe to quantify the plausibility of context-aware machine translation models, comparing model rationales with human annotations across several discourse-level phenomena. Finally, we apply our method to unannotated generations to identify context-mediated predictions and highlight instances of (im)plausible context usage in model translations. ",
    "url": "https://arxiv.org/abs/2310.01188",
    "authors": [
      "Gabriele Sarti",
      "Grzegorz Chrupa\u0142a",
      "Malvina Nissim",
      "Arianna Bisazza"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01220",
    "title": "The benefits and costs of explainable artificial intelligence in visual  quality control: Evidence from fault detection performance and eye movements",
    "abstract": "Visual inspection tasks often require humans to cooperate with AI-based image classifiers. To enhance this cooperation, explainable artificial intelligence (XAI) can highlight those image areas that have contributed to an AI decision. However, the literature on visual cueing suggests that such XAI support might come with costs of its own. To better understand how the benefits and cost of XAI depend on the accuracy of AI classifications and XAI highlights, we conducted two experiments that simulated visual quality control in a chocolate factory. Participants had to decide whether chocolate moulds contained faulty bars or not, and were always informed whether the AI had classified the mould as faulty or not. In half of the experiment, they saw additional XAI highlights that justified this classification. While XAI speeded up performance, its effects on error rates were highly dependent on (X)AI accuracy. XAI benefits were observed when the system correctly detected and highlighted the fault, but XAI costs were evident for misplaced highlights that marked an intact area while the actual fault was located elsewhere. Eye movement analyses indicated that participants spent less time searching the rest of the mould and thus looked at the fault less often. However, we also observed large interindividual differences. Taken together, the results suggest that despite its potentials, XAI can discourage people from investing effort into their own information analysis. ",
    "url": "https://arxiv.org/abs/2310.01220",
    "authors": [
      "Romy M\u00fcller",
      "David F. Reindel",
      "Yannick D. Stadtfeld"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2310.01224",
    "title": "Revisiting Mobility Modeling with Graph: A Graph Transformer Model for  Next Point-of-Interest Recommendation",
    "abstract": "Next Point-of-Interest (POI) recommendation plays a crucial role in urban mobility applications. Recently, POI recommendation models based on Graph Neural Networks (GNN) have been extensively studied and achieved, however, the effective incorporation of both spatial and temporal information into such GNN-based models remains challenging. Extracting distinct fine-grained features unique to each piece of information is difficult since temporal information often includes spatial information, as users tend to visit nearby POIs. To address the challenge, we propose \\textbf{\\underline{Mob}}ility \\textbf{\\underline{G}}raph \\textbf{\\underline{T}}ransformer (MobGT) that enables us to fully leverage graphs to capture both the spatial and temporal features in users' mobility patterns. MobGT combines individual spatial and temporal graph encoders to capture unique features and global user-location relations. Additionally, it incorporates a mobility encoder based on Graph Transformer to extract higher-order information between POIs. To address the long-tailed problem in spatial-temporal data, MobGT introduces a novel loss function, Tail Loss. Experimental results demonstrate that MobGT outperforms state-of-the-art models on various datasets and metrics, achieving 24\\% improvement on average. Our codes are available at \\url{https://github.com/Yukayo/MobGT}. ",
    "url": "https://arxiv.org/abs/2310.01224",
    "authors": [
      "Xiaohang Xu",
      "Toyotaro Suzumura",
      "Jiawei Yong",
      "Masatoshi Hanai",
      "Chuang Yang",
      "Hiroki Kanezashi",
      "Renhe Jiang",
      "Shintaro Fukushima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01247",
    "title": "Self-supervised Learning for Anomaly Detection in Computational  Workflows",
    "abstract": "Anomaly detection is the task of identifying abnormal behavior of a system. Anomaly detection in computational workflows is of special interest because of its wide implications in various domains such as cybersecurity, finance, and social networks. However, anomaly detection in computational workflows~(often modeled as graphs) is a relatively unexplored problem and poses distinct challenges. For instance, when anomaly detection is performed on graph data, the complex interdependency of nodes and edges, the heterogeneity of node attributes, and edge types must be accounted for. Although the use of graph neural networks can help capture complex inter-dependencies, the scarcity of labeled anomalous examples from workflow executions is still a significant challenge. To address this problem, we introduce an autoencoder-driven self-supervised learning~(SSL) approach that learns a summary statistic from unlabeled workflow data and estimates the normal behavior of the computational workflow in the latent space. In this approach, we combine generative and contrastive learning objectives to detect outliers in the summary statistics. We demonstrate that by estimating the distribution of normal behavior in the latent space, we can outperform state-of-the-art anomaly detection methods on our benchmark datasets. ",
    "url": "https://arxiv.org/abs/2310.01247",
    "authors": [
      "Hongwei Jin",
      "Krishnan Raghavan",
      "George Papadimitriou",
      "Cong Wang",
      "Anirban Mandal",
      "Ewa Deelman",
      "Prasanna Balaprakash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.01251",
    "title": "Generating 3D Brain Tumor Regions in MRI using Vector-Quantization  Generative Adversarial Networks",
    "abstract": "Medical image analysis has significantly benefited from advancements in deep learning, particularly in the application of Generative Adversarial Networks (GANs) for generating realistic and diverse images that can augment training datasets. However, the effectiveness of such approaches is often limited by the amount of available data in clinical settings. Additionally, the common GAN-based approach is to generate entire image volumes, rather than solely the region of interest (ROI). Research on deep learning-based brain tumor classification using MRI has shown that it is easier to classify the tumor ROIs compared to the entire image volumes. In this work, we present a novel framework that uses vector-quantization GAN and a transformer incorporating masked token modeling to generate high-resolution and diverse 3D brain tumor ROIs that can be directly used as augmented data for the classification of brain tumor ROI. We apply our method to two imbalanced datasets where we augment the minority class: (1) the Multimodal Brain Tumor Segmentation Challenge (BraTS) 2019 dataset to generate new low-grade glioma (LGG) ROIs to balance with high-grade glioma (HGG) class; (2) the internal pediatric LGG (pLGG) dataset tumor ROIs with BRAF V600E Mutation genetic marker to balance with BRAF Fusion genetic marker class. We show that the proposed method outperforms various baseline models in both qualitative and quantitative measurements. The generated data was used to balance the data in the brain tumor types classification task. Using the augmented data, our approach surpasses baseline models by 6.4% in AUC on the BraTS 2019 dataset and 4.3% in AUC on our internal pLGG dataset. The results indicate the generated tumor ROIs can effectively address the imbalanced data problem. Our proposed method has the potential to facilitate an accurate diagnosis of rare brain tumors using MRI scans. ",
    "url": "https://arxiv.org/abs/2310.01251",
    "authors": [
      "Meng Zhou",
      "Matthias W Wagner",
      "Uri Tabori",
      "Cynthia Hawkins",
      "Birgit B Ertl-Wagner",
      "Farzad Khalvati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01259",
    "title": "Faster and Accurate Neural Networks with Semantic Inference",
    "abstract": "Deep neural networks (DNN) usually come with a significant computational burden. While approaches such as structured pruning and mobile-specific DNNs have been proposed, they incur drastic accuracy loss. In this paper we leverage the intrinsic redundancy in latent representations to reduce the computational load with limited loss in performance. We show that semantically similar inputs share many filters, especially in the earlier layers. Thus, semantically similar classes can be clustered to create cluster-specific subgraphs. To this end, we propose a new framework called Semantic Inference (SINF). In short, SINF (i) identifies the semantic cluster the object belongs to using a small additional classifier and (ii) executes the subgraph extracted from the base DNN related to that semantic cluster for inference. To extract each cluster-specific subgraph, we propose a new approach named Discriminative Capability Score (DCS) that finds the subgraph with the capability to discriminate among the members of a specific semantic cluster. DCS is independent from SINF and can be applied to any DNN. We benchmark the performance of DCS on the VGG16, VGG19, and ResNet50 DNNs trained on the CIFAR100 dataset against 6 state-of-the-art pruning approaches. Our results show that (i) SINF reduces the inference time of VGG19, VGG16, and ResNet50 respectively by up to 35%, 29% and 15% with only 0.17%, 3.75%, and 6.75% accuracy loss (ii) DCS achieves respectively up to 3.65%, 4.25%, and 2.36% better accuracy with VGG16, VGG19, and ResNet50 with respect to existing discriminative scores (iii) when used as a pruning criterion, DCS achieves up to 8.13% accuracy gain with 5.82% less parameters than the existing state of the art work published at ICLR 2023 (iv) when considering per-cluster accuracy, SINF performs on average 5.73%, 8.38% and 6.36% better than the base VGG16, VGG19, and ResNet50. ",
    "url": "https://arxiv.org/abs/2310.01259",
    "authors": [
      "Sazzad Sayyed",
      "Jonathan Ashdown",
      "Francesco Restuccia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01267",
    "title": "Cooperative Graph Neural Networks",
    "abstract": "Graph neural networks are popular architectures for graph machine learning, based on iterative computation of node representations of an input graph through a series of invariant transformations. A large class of graph neural networks follow a standard message-passing paradigm: at every layer, each node state is updated based on an aggregate of messages from its neighborhood. In this work, we propose a novel framework for training graph neural networks, where every node is viewed as a player that can choose to either 'listen', 'broadcast', 'listen and broadcast', or to 'isolate'. The standard message propagation scheme can then be viewed as a special case of this framework where every node 'listens and broadcasts' to all neighbors. Our approach offers a more flexible and dynamic message-passing paradigm, where each node can determine its own strategy based on their state, effectively exploring the graph topology while learning. We provide a theoretical analysis of the new message-passing scheme which is further supported by an extensive empirical analysis on a synthetic dataset and on real-world datasets. ",
    "url": "https://arxiv.org/abs/2310.01267",
    "authors": [
      "Ben Finkelshtein",
      "Xingyue Huang",
      "Michael Bronstein",
      "\u0130smail \u0130lkan Ceylan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01272",
    "title": "A Unified View on Neural Message Passing with Opinion Dynamics for  Social Networks",
    "abstract": "Social networks represent a common form of interconnected data frequently depicted as graphs within the domain of deep learning-based inference. These communities inherently form dynamic systems, achieving stability through continuous internal communications and opinion exchanges among social actors along their social ties. In contrast, neural message passing in deep learning provides a clear and intuitive mathematical framework for understanding information propagation and aggregation among connected nodes in graphs. Node representations are dynamically updated by considering both the connectivity and status of neighboring nodes. This research harmonizes concepts from sociometry and neural message passing to analyze and infer the behavior of dynamic systems. Drawing inspiration from opinion dynamics in sociology, we propose ODNet, a novel message passing scheme incorporating bounded confidence, to refine the influence weight of local nodes for message propagation. We adjust the similarity cutoffs of bounded confidence and influence weights of ODNet and define opinion exchange rules that align with the characteristics of social network graphs. We show that ODNet enhances prediction performance across various graph types and alleviates oversmoothing issues. Furthermore, our approach surpasses conventional baselines in graph representation learning and proves its practical significance in analyzing real-world co-occurrence networks of metabolic genes. Remarkably, our method simplifies complex social network graphs solely by leveraging knowledge of interaction frequencies among entities within the system. It accurately identifies internal communities and the roles of genes in different metabolic pathways, including opinion leaders, bridge communicators, and isolators. ",
    "url": "https://arxiv.org/abs/2310.01272",
    "authors": [
      "Outongyi Lv",
      "Bingxin Zhou",
      "Jing Wang",
      "Xiang Xiao",
      "Weishu Zhao",
      "Lirong Zheng"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2310.01292",
    "title": "Efficient Remote Sensing Segmentation With Generative Adversarial  Transformer",
    "abstract": "Most deep learning methods that achieve high segmentation accuracy require deep network architectures that are too heavy and complex to run on embedded devices with limited storage and memory space. To address this issue, this paper proposes an efficient Generative Adversarial Transfomer (GATrans) for achieving high-precision semantic segmentation while maintaining an extremely efficient size. The framework utilizes a Global Transformer Network (GTNet) as the generator, efficiently extracting multi-level features through residual connections. GTNet employs global transformer blocks with progressively linear computational complexity to reassign global features based on a learnable similarity function. To focus on object-level and pixel-level information, the GATrans optimizes the objective function by combining structural similarity losses. We validate the effectiveness of our approach through extensive experiments on the Vaihingen dataset, achieving an average F1 score of 90.17% and an overall accuracy of 91.92%. ",
    "url": "https://arxiv.org/abs/2310.01292",
    "authors": [
      "Luyi Qiu",
      "Dayu Yu",
      "Xiaofeng Zhang",
      "Chenxiao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.01307",
    "title": "On the Generalization of Training-based ChatGPT Detection Methods",
    "abstract": "ChatGPT is one of the most popular language models which achieve amazing performance on various natural language tasks. Consequently, there is also an urgent need to detect the texts generated ChatGPT from human written. One of the extensively studied methods trains classification models to distinguish both. However, existing studies also demonstrate that the trained models may suffer from distribution shifts (during test), i.e., they are ineffective to predict the generated texts from unseen language tasks or topics. In this work, we aim to have a comprehensive investigation on these methods' generalization behaviors under distribution shift caused by a wide range of factors, including prompts, text lengths, topics, and language tasks. To achieve this goal, we first collect a new dataset with human and ChatGPT texts, and then we conduct extensive studies on the collected dataset. Our studies unveil insightful findings which provide guidance for developing future methodologies or data collection strategies for ChatGPT detection. ",
    "url": "https://arxiv.org/abs/2310.01307",
    "authors": [
      "Han Xu",
      "Jie Ren",
      "Pengfei He",
      "Shenglai Zeng",
      "Yingqian Cui",
      "Amy Liu",
      "Hui Liu",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01330",
    "title": "Towards reporting bias in visual-language datasets: bimodal augmentation  by decoupling object-attribute association",
    "abstract": "Reporting bias arises when people assume that some knowledge is universally understood and hence, do not necessitate explicit elaboration. In this paper, we focus on the wide existence of reporting bias in visual-language datasets, embodied as the object-attribute association, which can subsequentially degrade models trained on them. To mitigate this bias, we propose a bimodal augmentation (BiAug) approach through object-attribute decoupling to flexibly synthesize visual-language examples with a rich array of object-attribute pairing and construct cross-modal hard negatives. We employ large language models (LLMs) in conjunction with a grounding object detector to extract target objects. Subsequently, the LLM generates a detailed attribute description for each object and produces a corresponding hard negative counterpart. An inpainting model is then used to create images based on these detailed object descriptions. By doing so, the synthesized examples explicitly complement omitted objects and attributes to learn, and the hard negative pairs steer the model to distinguish object attributes. Our experiments demonstrated that BiAug is superior in object-attribute understanding. In addition, BiAug also improves the performance on zero-shot retrieval tasks on general benchmarks like MSCOCO and Flickr30K. BiAug refines the way of collecting text-image datasets. Mitigating the reporting bias helps models achieve a deeper understanding of visual-language phenomena, expanding beyond mere frequent patterns to encompass the richness and diversity of real-world scenarios. ",
    "url": "https://arxiv.org/abs/2310.01330",
    "authors": [
      "Qiyu Wu",
      "Mengjie Zhao",
      "Yutong He",
      "Lang Huang",
      "Junya Ono",
      "Hiromi Wakaki",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.01356",
    "title": "Less is More: Toward Zero-Shot Local Scene Graph Generation via  Foundation Models",
    "abstract": "Humans inherently recognize objects via selective visual perception, transform specific regions from the visual field into structured symbolic knowledge, and reason their relationships among regions based on the allocation of limited attention resources in line with humans' goals. While it is intuitive for humans, contemporary perception systems falter in extracting structural information due to the intricate cognitive abilities and commonsense knowledge required. To fill this gap, we present a new task called Local Scene Graph Generation. Distinct from the conventional scene graph generation task, which encompasses generating all objects and relationships in an image, our proposed task aims to abstract pertinent structural information with partial objects and their relationships for boosting downstream tasks that demand advanced comprehension and reasoning capabilities. Correspondingly, we introduce zEro-shot Local scEne GrAph geNeraTion (ELEGANT), a framework harnessing foundation models renowned for their powerful perception and commonsense reasoning, where collaboration and information communication among foundation models yield superior outcomes and realize zero-shot local scene graph generation without requiring labeled supervision. Furthermore, we propose a novel open-ended evaluation metric, Entity-level CLIPScorE (ECLIPSE), surpassing previous closed-set evaluation metrics by transcending their limited label space, offering a broader assessment. Experiment results show that our approach markedly outperforms baselines in the open-ended evaluation setting, and it also achieves a significant performance boost of up to 24.58% over prior methods in the close-set setting, demonstrating the effectiveness and powerful reasoning ability of our proposed framework. ",
    "url": "https://arxiv.org/abs/2310.01356",
    "authors": [
      "Shu Zhao",
      "Huijuan Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.01358",
    "title": "NEUCORE: Neural Concept Reasoning for Composed Image Retrieval",
    "abstract": "Composed image retrieval which combines a reference image and a text modifier to identify the desired target image is a challenging task, and requires the model to comprehend both vision and language modalities and their interactions. Existing approaches focus on holistic multi-modal interaction modeling, and ignore the composed and complimentary property between the reference image and text modifier. In order to better utilize the complementarity of multi-modal inputs for effective information fusion and retrieval, we move the multi-modal understanding to fine-granularity at concept-level, and learn the multi-modal concept alignment to identify the visual location in reference or target images corresponding to text modifier. Toward the end, we propose a NEUral COncept REasoning (NEUCORE) model which incorporates multi-modal concept alignment and progressive multimodal fusion over aligned concepts. Specifically, considering that text modifier may refer to semantic concepts not existing in the reference image and requiring to be added into the target image, we learn the multi-modal concept alignment between the text modifier and the concatenation of reference and target images, under multiple-instance learning framework with image and sentence level weak supervision. Furthermore, based on aligned concepts, to form discriminative fusion features of the input modalities for accurate target image retrieval, we propose a progressive fusion strategy with unified execution architecture instantiated by the attended language semantic concepts. Our proposed approach is evaluated on three datasets and achieves state-of-the-art results. ",
    "url": "https://arxiv.org/abs/2310.01358",
    "authors": [
      "Shu Zhao",
      "Huijuan Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.01365",
    "title": "Elephant Neural Networks: Born to Be a Continual Learner",
    "abstract": "Catastrophic forgetting remains a significant challenge to continual learning for decades. While recent works have proposed effective methods to mitigate this problem, they mainly focus on the algorithmic side. Meanwhile, we do not fully understand what architectural properties of neural networks lead to catastrophic forgetting. This study aims to fill this gap by studying the role of activation functions in the training dynamics of neural networks and their impact on catastrophic forgetting. Our study reveals that, besides sparse representations, the gradient sparsity of activation functions also plays an important role in reducing forgetting. Based on this insight, we propose a new class of activation functions, elephant activation functions, that can generate both sparse representations and sparse gradients. We show that by simply replacing classical activation functions with elephant activation functions, we can significantly improve the resilience of neural networks to catastrophic forgetting. Our method has broad applicability and benefits for continual learning in regression, class incremental learning, and reinforcement learning tasks. Specifically, we achieves excellent performance on Split MNIST dataset in just one single pass, without using replay buffer, task boundary information, or pre-training. ",
    "url": "https://arxiv.org/abs/2310.01365",
    "authors": [
      "Qingfeng Lan",
      "A. Rupam Mahmood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01366",
    "title": "Window-based Model Averaging Improves Generalization in Heterogeneous  Federated Learning",
    "abstract": "Federated Learning (FL) aims to learn a global model from distributed users while protecting their privacy. However, when data are distributed heterogeneously the learning process becomes noisy, unstable, and biased towards the last seen clients' data, slowing down convergence. To address these issues and improve the robustness and generalization capabilities of the global model, we propose WIMA (Window-based Model Averaging). WIMA aggregates global models from different rounds using a window-based approach, effectively capturing knowledge from multiple users and reducing the bias from the last ones. By adopting a windowed view on the rounds, WIMA can be applied from the initial stages of training. Importantly, our method introduces no additional communication or client-side computation overhead. Our experiments demonstrate the robustness of WIMA against distribution shifts and bad client sampling, resulting in smoother and more stable learning trends. Additionally, WIMA can be easily integrated with state-of-the-art algorithms. We extensively evaluate our approach on standard FL benchmarks, demonstrating its effectiveness. ",
    "url": "https://arxiv.org/abs/2310.01366",
    "authors": [
      "Debora Caldarola",
      "Barbara Caputo",
      "Marco Ciccone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01378",
    "title": "On Grid Graph Reachability and Puzzle Games",
    "abstract": "Many puzzle video games, like Sokoban, involve moving some agent in a maze. The reachable locations are usually apparent for a human player, and the difficulty of the game is mainly related to performing actions on objects, such as pushing (reachable) boxes. For this reason, the difficulty of a particular level is often measured as the number of actions on objects, other than agent walking, needed to find a solution. In this paper we study CP and SAT approaches for solving these kind of problems. We review some reachability encodings and propose a new one. We empirically show that the new encoding is well-suited for solving puzzle problems in the planning as SAT paradigm, especially when considering the execution of several actions in parallel. ",
    "url": "https://arxiv.org/abs/2310.01378",
    "authors": [
      "Miquel Bofill",
      "Cristina Borralleras",
      "Joan Espasa",
      "Mateu Villaret"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01393",
    "title": "DST-Det: Simple Dynamic Self-Training for Open-Vocabulary Object  Detection",
    "abstract": "Open-vocabulary object detection (OVOD) aims to detect the objects beyond the set of categories observed during training. This work presents a simple yet effective strategy that leverages the zero-shot classification ability of pre-trained vision-language models (VLM), such as CLIP, to classify proposals for all possible novel classes directly. Unlike previous works that ignore novel classes during training and rely solely on the region proposal network (RPN) for novel object detection, our method selectively filters proposals based on specific design criteria. The resulting sets of identified proposals serve as pseudo-labels for novel classes during the training phase. It enables our self-training strategy to improve the recall and accuracy of novel classes in a self-training manner without requiring additional annotations or datasets. We further propose a simple offline pseudo-label generation strategy to refine the object detector. Empirical evaluations on three datasets, including LVIS, V3Det, and COCO, demonstrate significant improvements over the baseline performance without incurring additional parameters or computational costs during inference. In particular, compared with previous F-VLM, our method achieves a 1.7-2.0% improvement on LVIS dataset and 2.3-3.8% improvement on the recent challenging V3Det dataset. Our method also boosts the strong baseline by 6% mAP on COCO. The code and models will be publicly available at https://github.com/xushilin1/dst-det. ",
    "url": "https://arxiv.org/abs/2310.01393",
    "authors": [
      "Shilin Xu",
      "Xiangtai Li",
      "Size Wu",
      "Wenwei Zhang",
      "Yining Li",
      "Guangliang Cheng",
      "Yunhai Tong",
      "Kai Chen",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.01396",
    "title": "A Learning Based Scheme for Fair Timeliness in Sparse Gossip Networks",
    "abstract": "We consider a gossip network, consisting of $n$ nodes, which tracks the information at a source. The source updates its information with a Poisson arrival process and also sends updates to the nodes in the network. The nodes themselves can exchange information among themselves to become as timely as possible. However, the network structure is sparse and irregular, i.e., not every node is connected to every other node in the network, rather, the order of connectivity is low, and varies across different nodes. This asymmetry of the network implies that the nodes in the network do not perform equally in terms of timelines. Due to the gossiping nature of the network, some nodes are able to track the source very timely, whereas, some nodes fall behind versions quite often. In this work, we investigate how the rate-constrained source should distribute its update rate across the network to maintain fairness regarding timeliness, i.e., the overall worst case performance of the network can be minimized. Due to the continuous search space for optimum rate allocation, we formulate this problem as a continuum-armed bandit problem and employ Gaussian process based Bayesian optimization to meet a trade-off between exploration and exploitation sequentially. ",
    "url": "https://arxiv.org/abs/2310.01396",
    "authors": [
      "Purbesh Mitra",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.01401",
    "title": "Pixel-Aligned Recurrent Queries for Multi-View 3D Object Detection",
    "abstract": "We present PARQ - a multi-view 3D object detector with transformer and pixel-aligned recurrent queries. Unlike previous works that use learnable features or only encode 3D point positions as queries in the decoder, PARQ leverages appearance-enhanced queries initialized from reference points in 3D space and updates their 3D location with recurrent cross-attention operations. Incorporating pixel-aligned features and cross attention enables the model to encode the necessary 3D-to-2D correspondences and capture global contextual information of the input images. PARQ outperforms prior best methods on the ScanNet and ARKitScenes datasets, learns and detects faster, is more robust to distribution shifts in reference points, can leverage additional input views without retraining, and can adapt inference compute by changing the number of recurrent iterations. ",
    "url": "https://arxiv.org/abs/2310.01401",
    "authors": [
      "Yiming Xie",
      "Huaizu Jiang",
      "Georgia Gkioxari",
      "Julian Straub"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.01403",
    "title": "CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense  Prediction",
    "abstract": "Open-vocabulary dense prediction tasks including object detection and image segmentation have been advanced by the success of Contrastive Language-Image Pre-training (CLIP). CLIP models, particularly those incorporating vision transformers (ViTs), have exhibited remarkable generalization ability in zero-shot image classification. However, when transferring the vision-language alignment of CLIP from global image representation to local region representation for the open-vocabulary dense prediction tasks, CLIP ViTs suffer from the domain shift from full images to local image regions. In this paper, we embark on an in-depth analysis of the region-language alignment in CLIP models, which is essential for downstream open-vocabulary dense prediction tasks. Subsequently, we propose an approach named CLIPSelf, which adapts the image-level recognition ability of CLIP ViT to local image regions without needing any region-text pairs. CLIPSelf empowers ViTs to distill itself by aligning a region representation extracted from its dense feature map with the image-level representation of the corresponding image crop. With the enhanced CLIP ViTs, we achieve new state-of-the-art performance on open-vocabulary object detection, semantic segmentation, and panoptic segmentation across various benchmarks. Models and code will be available at https://github.com/wusize/CLIPSelf. ",
    "url": "https://arxiv.org/abs/2310.01403",
    "authors": [
      "Size Wu",
      "Wenwei Zhang",
      "Lumin Xu",
      "Sheng Jin",
      "Xiangtai Li",
      "Wentao Liu",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.01405",
    "title": "Representation Engineering: A Top-Down Approach to AI Transparency",
    "abstract": "In this paper, we identify and characterize the emerging area of representation engineering (RepE), an approach to enhancing the transparency of AI systems that draws on insights from cognitive neuroscience. RepE places population-level representations, rather than neurons or circuits, at the center of analysis, equipping us with novel methods for monitoring and manipulating high-level cognitive phenomena in deep neural networks (DNNs). We provide baselines and an initial analysis of RepE techniques, showing that they offer simple yet effective solutions for improving our understanding and control of large language models. We showcase how these methods can provide traction on a wide range of safety-relevant problems, including honesty, harmlessness, power-seeking, and more, demonstrating the promise of top-down transparency research. We hope that this work catalyzes further exploration of RepE and fosters advancements in the transparency and safety of AI systems. ",
    "url": "https://arxiv.org/abs/2310.01405",
    "authors": [
      "Andy Zou",
      "Long Phan",
      "Sarah Chen",
      "James Campbell",
      "Phillip Guo",
      "Richard Ren",
      "Alexander Pan",
      "Xuwang Yin",
      "Mantas Mazeika",
      "Ann-Kathrin Dombrowski",
      "Shashwat Goel",
      "Nathaniel Li",
      "Michael J. Byun",
      "Zifan Wang",
      "Alex Mallen",
      "Steven Basart",
      "Sanmi Koyejo",
      "Dawn Song",
      "Matt Fredrikson",
      "J. Zico Kolter",
      "Dan Hendrycks"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.00052",
    "title": "AI ensemble for signal detection of higher order gravitational wave  modes of quasi-circular, spinning, non-precessing binary black hole mergers",
    "abstract": "We introduce spatiotemporal-graph models that concurrently process data from the twin advanced LIGO detectors and the advanced Virgo detector. We trained these AI classifiers with 2.4 million \\texttt{IMRPhenomXPHM} waveforms that describe quasi-circular, spinning, non-precessing binary black hole mergers with component masses $m_{\\{1,2\\}}\\in[3M_\\odot, 50 M_\\odot]$, and individual spins $s^z_{\\{1,2\\}}\\in[-0.9, 0.9]$; and which include the $(\\ell, |m|) = \\{(2, 2), (2, 1), (3, 3), (3, 2), (4, 4)\\}$ modes, and mode mixing effects in the $\\ell = 3, |m| = 2$ harmonics. We trained these AI classifiers within 22 hours using distributed training over 96 NVIDIA V100 GPUs in the Summit supercomputer. We then used transfer learning to create AI predictors that estimate the total mass of potential binary black holes identified by all AI classifiers in the ensemble. We used this ensemble, 3 AI classifiers and 2 predictors, to process a year-long test set in which we injected 300,000 signals. This year-long test set was processed within 5.19 minutes using 1024 NVIDIA A100 GPUs in the Polaris supercomputer (for AI inference) and 128 CPU nodes in the ThetaKNL supercomputer (for post-processing of noise triggers), housed at the Argonne Leadership Supercomputing Facility. These studies indicate that our AI ensemble provides state-of-the-art signal detection accuracy, and reports 2 misclassifications for every year of searched data. This is the first AI ensemble designed to search for and find higher order gravitational wave mode signals. ",
    "url": "https://arxiv.org/abs/2310.00052",
    "authors": [
      "Minyang Tian",
      "E. A. Huerta",
      "Huihuo Zheng"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ]
  },
  {
    "id": "arXiv:2310.00121",
    "title": "Construction of a Circuit for the Simulation of a Hamiltonian with a  Tridiagonal Matrix Representation",
    "abstract": "The simulation of quantum systems is an area where quantum computers are promised to achieve an exponential speedup over classical simulations. State-of-the-art quantum algorithms for Hamiltonian simulation achieve this by reducing the amount of oracle queries. Unfortunately, these predicted speedups may be limited by a sub-optimal oracle implementation, thus limiting their use in practical applications. In this paper we present a construction of a circuit for simulation of Hamiltonians with a tridiagonal matrix representation. We claim efficiency by estimating the resulting gate complexity. This is done by determining all Pauli strings present in the decomposition of an arbitrary tridiagonal matrix and dividing them into commuting sets. The union of these sets has a cardinality exponentially smaller than that of the set of all Pauli strings. Furthermore, the number of commuting sets grows logarithmically with the size of the matrix. Additionally, our method for computing the decomposition coefficients requires exponentially fewer multiplications compared to the direct approach. Finally, we exemplify our method in the case of the Hamiltonian of the one-dimensional wave equation and numerically show the dependency of the number of gates on the number of qubits. ",
    "url": "https://arxiv.org/abs/2310.00121",
    "authors": [
      "Boris Arseniev",
      "Dmitry Guskov",
      "Richik Sengupta",
      "Jacob Biamonte",
      "Igor Zacharov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2310.00174",
    "title": "ADMET property prediction through combinations of molecular fingerprints",
    "abstract": "While investigating methods to predict small molecule potencies, we found random forests or support vector machines paired with extended-connectivity fingerprints (ECFP) consistently outperformed recently developed methods. A detailed investigation into regression algorithms and molecular fingerprints revealed gradient-boosted decision trees, particularly CatBoost, in conjunction with a combination of ECFP, Avalon, and ErG fingerprints, as well as 200 molecular properties, to be most effective. Incorporating a graph neural network fingerprint further enhanced performance. We successfully validated our model across 22 Therapeutics Data Commons ADMET benchmarks. Our findings underscore the significance of richer molecular representations for accurate property prediction. ",
    "url": "https://arxiv.org/abs/2310.00174",
    "authors": [
      "James H. Notwell",
      "Michael W. Wood"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00238",
    "title": "Feasibility-Guaranteed Safety Critical Control with Applications to  Heterogeneous Platoons",
    "abstract": "This paper studies safety and feasibility guarantees for systems with tight control bounds. It has been shown that stabilizing an affine control system while optimizing a quadratic cost and satisfying state and control constraints can be mapped to a sequence of Quadratic Programs (QPs) using Control Barrier Functions (CBF) and Control Lyapunov Functions (CLF). One of the main challenges in this method is that the QP could easily become infeasible under safety constraints of high relative degree, especially under tight control bounds. Recent work focused on deriving sufficient conditions for guaranteeing feasibility. The existing results are case-dependent. In this paper, we consider the general case and define a feasibility constraint, and propose a new type of CBF to enforce the feasibility constraint. Our method guarantees the feasibility of the above mentioned QPs, while satisfying safety requirements. We demonstrate the advantages of using the proposed method on a heterogeneous Adaptive Cruise Control (ACC) platoon with tight control bounds, and compare our method to existing CBF-CLF approaches. The results show that our proposed approach can generate gradually transitioned control with guaranteed feasibility and safety. ",
    "url": "https://arxiv.org/abs/2310.00238",
    "authors": [
      "Shuo Liu",
      "Wei Xiao",
      "Calin A. Belta"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.00257",
    "title": "The Lov\u00e1sz Theta Function for Recovering Planted Clique Covers and  Graph Colorings",
    "abstract": "The problems of computing graph colorings and clique covers are central challenges in combinatorial optimization. Both of these are known to be NP-hard, and thus computationally intractable in the worst-case instance. A prominent approach for computing approximate solutions to these problems is the celebrated Lov\\'asz theta function $\\vartheta(G)$, which is specified as the solution of a semidefinite program (SDP), and hence tractable to compute. In this work, we move beyond the worst-case analysis and set out to understand whether the Lov\\'asz theta function recovers clique covers for random instances that have a latent clique cover structure, possibly obscured by noise. We answer this question in the affirmative and show that for graphs generated from the planted clique model we introduce in this work, the SDP formulation of $\\vartheta(G)$ has a unique solution that reveals the underlying clique-cover structure with high-probability. The main technical step is an intermediate result where we prove a deterministic condition of recovery based on an appropriate notion of sparsity. ",
    "url": "https://arxiv.org/abs/2310.00257",
    "authors": [
      "Jiaxin Hou",
      "Yong Sheng Soh",
      "Antonios Varvitsiotis"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2310.00327",
    "title": "Memorization with neural nets: going beyond the worst case",
    "abstract": "In practice, deep neural networks are often able to easily interpolate their training data. To understand this phenomenon, many works have aimed to quantify the memorization capacity of a neural network architecture: the largest number of points such that the architecture can interpolate any placement of these points with any assignment of labels. For real-world data, however, one intuitively expects the presence of a benign structure so that interpolation already occurs at a smaller network size than suggested by memorization capacity. In this paper, we investigate interpolation by adopting an instance-specific viewpoint. We introduce a simple randomized algorithm that, given a fixed finite dataset with two classes, with high probability constructs an interpolating three-layer neural network in polynomial time. The required number of parameters is linked to geometric properties of the two classes and their mutual arrangement. As a result, we obtain guarantees that are independent of the number of samples and hence move beyond worst-case memorization capacity bounds. We illustrate the effectiveness of the algorithm in non-pathological situations with extensive numerical experiments and link the insights back to the theoretical results. ",
    "url": "https://arxiv.org/abs/2310.00327",
    "authors": [
      "Sjoerd Dirksen",
      "Patrick Finke",
      "Martin Genzel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2310.00417",
    "title": "Teaching at the Intersection of Social Justice, Ethics, and the ASA  Ethical Guidelines for Statistical Practice",
    "abstract": "Case studies are typically used to teach 'ethics', but when the content of a course is focused on formulae and proofs, a case analysis and the knowledge, skills, and abilities they require can be distracting. Moreover, case analyses are typically focused narrowly on research issues: obtaining consent, dealing with research team members, and/or research policy violations. Not all students in quantitative courses plan to become researchers, and ethical practice of mathematics, statistics, data science, and computing is an essential topic regardless of the learner's career plans. While it is incorrect to treat 'social justice' as a proxy for 'ethical practice', the topic of 'social justice' may be more interesting to both students and instructors. This paper offers concrete recommendations for integrating social justice content into quantitative courses in ways that limit the burden of new knowledge, skills, and abilities but also support reproducible and actionable assessments. Five tools can be utilized to integrate social justice into a course in a way that also meets calls to integrate 'ethics'; minimizes the burden on instructors to create and grade new materials and assignments; minimizes the burden on learners to develop the skill set to complete a case analysis; and maximizes the likelihood that the ethics content will be embedded in the learners' cognitive representation of the knowledge being taught in the quantitative course. These tools are: a. Curriculum Development Guidelines b. 7-task Statistics and Data Science Pipeline c. ASA Ethical Guidelines for Statistical Practice d. Stakeholder Analysis e. 6-step Ethical Reasoning paradigm This paper discusses how to use these tools in quantitative courses. The tools and frameworks offer structure, and facilitate ensuring that changes made to any course are evaluable and generate actionable assessments for learners. ",
    "url": "https://arxiv.org/abs/2310.00417",
    "authors": [
      "Rochelle E Tractenberg"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.00443",
    "title": "The objective function equality property of infoGAN for two-layer  network",
    "abstract": "Information Maximizing Generative Adversarial Network (infoGAN) can be understood as a minimax problem involving two networks: discriminators and generators with mutual information functions. The infoGAN incorporates various components, including latent variables, mutual information, and objective function. This research demonstrates that the two objective functions in infoGAN become equivalent as the discriminator and generator sample size approaches infinity. This equivalence is established by considering the disparity between the empirical and population versions of the objective function. The bound on this difference is determined by the Rademacher complexity of the discriminator and generator function class. Furthermore, the utilization of a two-layer network for both the discriminator and generator, featuring Lipschitz and non-decreasing activation functions, validates this equality ",
    "url": "https://arxiv.org/abs/2310.00443",
    "authors": [
      "Mahmud Hasan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00509",
    "title": "Smoothing Mixed Traffic with Robust Data-driven Predictive Control for  Connected and Autonomous Vehicles",
    "abstract": "The recently developed DeeP-LCC (Data-EnablEd Predictive Leading Cruise Control) method has shown promising performance for data-driven predictive control of Connected and Autonomous Vehicles (CAVs) in mixed traffic. However, its simplistic zero assumption of the future velocity errors for the head vehicle may pose safety concerns and limit its performance of smoothing traffic flow. In this paper, we propose a robust DeeP-LCC method to control CAVs in mixed traffic with enhanced safety performance. In particular, we first present a robust formulation that enforces a safety constraint for a range of potential velocity error trajectories, and then estimate all potential velocity errors based on the past data from the head vehicle. We also provide efficient computational approaches to solve the robust optimization for online predictive control. Nonlinear traffic simulations show that our robust DeeP-LCC can provide better traffic efficiency and stronger safety performance while requiring less offline data. ",
    "url": "https://arxiv.org/abs/2310.00509",
    "authors": [
      "Xu Shang",
      "Jiawei Wang",
      "Yang Zheng"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.00518",
    "title": "Learning Informative Latent Representation for Quantum State Tomography",
    "abstract": "Quantum state tomography (QST) is the process of reconstructing the complete state of a quantum system (mathematically described as a density matrix) through a series of different measurements. These measurements are performed on a number of identical copies of the quantum system, with outcomes gathered as frequencies. QST aims to recover the density matrix and the corresponding properties of the quantum state from the measured frequencies. Although an informationally complete set of measurements can specify quantum state accurately in an ideal scenario with a large number of identical copies, both measurements and identical copies are restricted and imperfect in practical scenarios, making QST highly ill-posed. The conventional QST methods usually assume adequate or accurate measured frequencies or rely on manually designed regularizers to handle the ill-posed reconstruction problem, suffering from limited applications in realistic scenarios. Recent advances in deep neural networks (DNNs) led to the emergence of deep learning (DL) in QST. However, existing DL-based QST approaches often employ generic DNN models that are not optimized for imperfect conditions of QST. In this paper, we propose a transformer-based autoencoder architecture tailored for QST with imperfect measurement data. Our method leverages a transformer-based encoder to extract an informative latent representation (ILR) from imperfect measurement data and employs a decoder to predict the quantum states based on the ILR. We anticipate that the high-dimensional ILR will capture more comprehensive information about quantum states. To achieve this, we conduct pre-training of the encoder using a pretext task that involves reconstructing high-quality frequencies from measured frequencies. Extensive simulations and experiments demonstrate the remarkable ability of the ILR in dealing with imperfect measurement data in QST. ",
    "url": "https://arxiv.org/abs/2310.00518",
    "authors": [
      "Hailan Ma",
      "Zhenhong Sun",
      "Daoyi Dong",
      "Dong Gong"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.00536",
    "title": "Computing the alpha complex using dual active set methods",
    "abstract": "The alpha complex is a fundamental data structure from computational geometry, which encodes the topological type of a union of balls $B(x; r) \\subset \\mathbb{R}^m$ for $x\\in S$, including a weighted version that allows for varying radii. It consists of the collection of \"simplices\" $\\sigma = \\{x_0, ..., x_k \\} \\subset S$, which correspond to nomempty $(k + 1)$-fold intersections of cells in a radius-restricted version of the Voronoi diagram. Existing algorithms for computing the alpha complex require that the points reside in low dimension because they begin by computing the entire Delaunay complex, which rapidly becomes intractable, even when the alpha complex is of a reasonable size. This paper presents a method for computing the alpha complex without computing the full Delaunay triangulation by applying Lagrangian duality, specifically an algorithm based on dual quadratic programming that seeks to rule simplices out rather than ruling them in. ",
    "url": "https://arxiv.org/abs/2310.00536",
    "authors": [
      "Erik Carlsson",
      "John Carlsson"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2310.00541",
    "title": "Robust Nonparametric Hypothesis Testing to Understand Variability in  Training Neural Networks",
    "abstract": "Training a deep neural network (DNN) often involves stochastic optimization, which means each run will produce a different model. Several works suggest this variability is negligible when models have the same performance, which in the case of classification is test accuracy. However, models with similar test accuracy may not be computing the same function. We propose a new measure of closeness between classification models based on the output of the network before thresholding. Our measure is based on a robust hypothesis-testing framework and can be adapted to other quantities derived from trained models. ",
    "url": "https://arxiv.org/abs/2310.00541",
    "authors": [
      "Sinjini Banerjee",
      "Reilly Cannon",
      "Tim Marrinan",
      "Tony Chiang",
      "Anand D. Sarwate"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00545",
    "title": "Implicit Neural Representations and the Algebra of Complex Wavelets",
    "abstract": "Implicit neural representations (INRs) have arisen as useful methods for representing signals on Euclidean domains. By parameterizing an image as a multilayer perceptron (MLP) on Euclidean space, INRs effectively represent signals in a way that couples spatial and spectral features of the signal that is not obvious in the usual discrete representation, paving the way for continuous signal processing and machine learning approaches that were not previously possible. Although INRs using sinusoidal activation functions have been studied in terms of Fourier theory, recent works have shown the advantage of using wavelets instead of sinusoids as activation functions, due to their ability to simultaneously localize in both frequency and space. In this work, we approach such INRs and demonstrate how they resolve high-frequency features of signals from coarse approximations done in the first layer of the MLP. This leads to multiple prescriptions for the design of INR architectures, including the use of complex wavelets, decoupling of low and band-pass approximations, and initialization schemes based on the singularities of the desired signal. ",
    "url": "https://arxiv.org/abs/2310.00545",
    "authors": [
      "T. Mitchell Roddenberry",
      "Vishwanath Saragadam",
      "Maarten V. de Hoop",
      "Richard G. Baraniuk"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.00549",
    "title": "Convex Restriction of Feasible Sets for AC Radial Networks",
    "abstract": "Many problems in power systems involve optimizing a certain objective function subject to power flow equations and engineering constraints. A long-standing challenge in solving them is the nonconvexity of their feasible sets. In this paper, we propose an analytical method to construct the convex restriction of the feasible set for AC power flows in radial networks. The construction relies on simple geometrical ideas and is explicit, in the sense that it does not involve solving other complicated optimization problems. We also show that the construct restrictions are in some sense maximal, that is, the best possible ones. Optimization problems constrained to these sets are not only simpler to solve but also offer feasibility guarantee for the solutions to the original OPF problem. Furthermore, we present an iterative algorithm to improve on the solution quality by successively constructing a sequence of convex restricted sets and solving the optimization on them. The numerical experiments on the IEEE 123-bus distribution network show that our method finds good feasible solutions within just a few iterations and works well with various objective functions, even in situations where traditional methods fail to return a solution. ",
    "url": "https://arxiv.org/abs/2310.00549",
    "authors": [
      "Ling Zhang",
      "Daniel Tabas",
      "Baosen Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.00561",
    "title": "CausalGPS: An R Package for Causal Inference With Continuous Exposures",
    "abstract": "Quantifying the causal effects of continuous exposures on outcomes of interest is critical for social, economic, health, and medical research. However, most existing software packages focus on binary exposures. We develop the CausalGPS R package that implements a collection of algorithms to provide algorithmic solutions for causal inference with continuous exposures. CausalGPS implements a causal inference workflow, with algorithms based on generalized propensity scores (GPS) as the core, extending propensity scores (the probability of a unit being exposed given pre-exposure covariates) from binary to continuous exposures. As the first step, the package implements efficient and flexible estimations of the GPS, allowing multiple user-specified modeling options. As the second step, the package provides two ways to adjust for confounding: weighting and matching, generating weighted and matched data sets, respectively. Lastly, the package provides built-in functions to fit flexible parametric, semi-parametric, or non-parametric regression models on the weighted or matched data to estimate the exposure-response function relating the outcome with the exposures. The computationally intensive tasks are implemented in C++, and efficient shared-memory parallelization is achieved by OpenMP API. This paper outlines the main components of the CausalGPS R package and demonstrates its application to assess the effect of long-term exposure to PM2.5 on educational attainment using zip code-level data from the contiguous United States from 2000-2016. ",
    "url": "https://arxiv.org/abs/2310.00561",
    "authors": [
      "Naeem Khoshnevis",
      "Xiao Wu",
      "Danielle Braun"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Mathematical Software (cs.MS)",
      "Econometrics (econ.EM)"
    ]
  },
  {
    "id": "arXiv:2310.00585",
    "title": "Quantum generative adversarial learning in photonics",
    "abstract": "Quantum Generative Adversarial Networks (QGANs), an intersection of quantum computing and machine learning, have attracted widespread attention due to their potential advantages over classical analogs. However, in the current era of Noisy Intermediate-Scale Quantum (NISQ) computing, it is essential to investigate whether QGANs can perform learning tasks on near-term quantum devices usually affected by noise and even defects. In this Letter, using a programmable silicon quantum photonic chip, we experimentally demonstrate the QGAN model in photonics for the first time, and investigate the effects of noise and defects on its performance. Our results show that QGANs can generate high-quality quantum data with a fidelity higher than 90\\%, even under conditions where up to half of the generator's phase shifters are damaged, or all of the generator and discriminator's phase shifters are subjected to phase noise up to 0.04$\\pi$. Our work sheds light on the feasibility of implementing QGANs on NISQ-era quantum hardware. ",
    "url": "https://arxiv.org/abs/2310.00585",
    "authors": [
      "Yizhi Wang",
      "Shichuan Xue",
      "Yaxuan Wang",
      "Yong Liu",
      "Jiangfang Ding",
      "Weixu Shi",
      "Dongyang Wang",
      "Yingwen Liu",
      "Xiang Fu",
      "Guangyao Huang",
      "Anqi Huang",
      "Mingtang Deng",
      "Junjie Wu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2310.00639",
    "title": "Segmentation-based Assessment of Tumor-Vessel Involvement for Surgical  Resectability Prediction of Pancreatic Ductal Adenocarcinoma",
    "abstract": "Pancreatic ductal adenocarcinoma (PDAC) is a highly aggressive cancer with limited treatment options. This research proposes a workflow and deep learning-based segmentation models to automatically assess tumor-vessel involvement, a key factor in determining tumor resectability. Correct assessment of resectability is vital to determine treatment options. The proposed workflow involves processing CT scans to segment the tumor and vascular structures, analyzing spatial relationships and the extent of vascular involvement, which follows a similar way of working as expert radiologists in PDAC assessment. Three segmentation architectures (nnU-Net, 3D U-Net, and Probabilistic 3D U-Net) achieve a high accuracy in segmenting veins, arteries, and the tumor. The segmentations enable automated detection of tumor involvement with high accuracy (0.88 sensitivity and 0.86 specificity) and automated computation of the degree of tumor-vessel contact. Additionally, due to significant inter-observer variability in these important structures, we present the uncertainty captured by each of the models to further increase insights into the predicted involvement. This result provides clinicians with a clear indication of tumor-vessel involvement and may be used to facilitate more informed decision-making for surgical interventions. The proposed method offers a valuable tool for improving patient outcomes, personalized treatment strategies and survival rates in pancreatic cancer. ",
    "url": "https://arxiv.org/abs/2310.00639",
    "authors": [
      "Christiaan Viviers",
      "Mark Ramaekers",
      "Amaan Valiuddin",
      "Terese Hellstr\u00f6m",
      "Nick Tasios",
      "John van der Ven",
      "Igor Jacobs",
      "Lotte Ewals",
      "Joost Nederend",
      "Peter de With",
      "Misha Luyer",
      "Fons van der Sommen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.00747",
    "title": "NoxTrader: LSTM-Based Stock Return Momentum Prediction",
    "abstract": "We introduce NoxTrader, which is designed for portfolio construction and trading execution, aims at generating profitable outcomes. The primary focus of NoxTrader is on stock market trading with an emphasis on cultivating moderate to long-term profits. The underlying learning process of NoxTrader hinges on the assimilation of insights gleaned from historical trading data, primarily hinging on time-series analysis due to the inherent nature of the employed dataset. We delineate the sequential progression encompassing data acquisition, feature engineering, predictive modeling, parameter configuration, establishment of a rigorous backtesting framework, and ultimately position NoxTrader as a testament to the prospective viability of algorithmic trading models within real-world trading scenarios. ",
    "url": "https://arxiv.org/abs/2310.00747",
    "authors": [
      "Hsiang-Hui Liu",
      "Han-Jay Shu",
      "Wei-Ning Chiu"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01037",
    "title": "Seismogram Transformer: A generic deep learning backbone network for  multiple earthquake monitoring tasks",
    "abstract": "Seismic records, known as seismograms, are crucial records of ground motion resulting from seismic events, constituting the backbone of earthquake research and monitoring. The latest advancements in deep learning have significantly facilitated various seismic signal processing tasks. This paper introduces a novel backbone neural network model designed for various seismic monitoring tasks, named Seismogram Transformer (SeisT). Thanks to its efficient network architecture, SeisT matches or even outperforms the state-of-the-art models in earthquake detection, seismic phase picking, first-motion polarity classification, magnitude estimation, and azimuth estimation tasks, particularly in terms of out-of-distribution generalization performance. SeisT consists of multiple network layers composed of different foundational blocks, which help the model understand multi-level feature representations of seismograms from low-level to high-level complex features, effectively extracting features such as frequency, phase, and time-frequency relationships from input seismograms. Three different-sized models were customized based on these diverse foundational modules. Through extensive experiments and performance evaluations, this study showcases the capabilities and potential of SeisT in advancing seismic signal processing and earthquake research. ",
    "url": "https://arxiv.org/abs/2310.01037",
    "authors": [
      "Sen Li",
      "Xu Yang",
      "Anye Cao",
      "Changbin Wang",
      "Yaoqi Liu",
      "Yapeng Liu",
      "Qiang Niu"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01046",
    "title": "Epistemic integration and social segregation of AI in neuroscience",
    "abstract": "In recent years, Artificial Intelligence (AI) shows a spectacular ability of insertion inside a variety of disciplines which use it for scientific advancements and which sometimes improve it for their conceptual and methodological needs. According to the transverse science framework originally conceived by Shinn and Joerges, AI can be seen as an instrument which is progressively acquiring an universal character through its diffusion across science. In this paper we address empirically one aspect of this diffusion, namely the penetration of AI into a specific field of research. Taking neuroscience as a case study, we conduct a scientometric analysis of the development of AI in this field We especially study the temporal egocentric citation network around the articles included in this literature, their represented journals and their authors linked together by a temporal collaboration network. We find that AI is driving the constitution of a particular disciplinary ecosystem in neuroscience which is distinct from other subfields when regarding the references, and which is gathering atypical scientific profiles who are coming from neuroscience or outside it. Moreover we observe that this AI community in neuroscience is socially confined in a specific zone of the neuroscience collaboration network, which is also keeping to publish in a small set of dedicated journals that are mostly active in AI research. According to these results, the diffusion of AI in a discipline such as neuroscience didn't really challenge its disciplinary orientations but rather induced the constitution of a dedicated socio-cognitive workforce inside this field. ",
    "url": "https://arxiv.org/abs/2310.01046",
    "authors": [
      "Sylvain Fontaine",
      "Floriana Gargiulo",
      "Michel Dubois",
      "Paola Tubaro"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.01210",
    "title": "Towards Robust Cardiac Segmentation using Graph Convolutional Networks",
    "abstract": "Fully automatic cardiac segmentation can be a fast and reproducible method to extract clinical measurements from an echocardiography examination. The U-Net architecture is the current state-of-the-art deep learning architecture for medical segmentation and can segment cardiac structures in real-time with average errors comparable to inter-observer variability. However, this architecture still generates large outliers that are often anatomically incorrect. This work uses the concept of graph convolutional neural networks that predict the contour points of the structures of interest instead of labeling each pixel. We propose a graph architecture that uses two convolutional rings based on cardiac anatomy and show that this eliminates anatomical incorrect multi-structure segmentations on the publicly available CAMUS dataset. Additionally, this work contributes with an ablation study on the graph convolutional architecture and an evaluation of clinical measurements on the clinical HUNT4 dataset. Finally, we propose to use the inter-model agreement of the U-Net and the graph network as a predictor of both the input and segmentation quality. We show this predictor can detect out-of-distribution and unsuitable input images in real-time. Source code is available online: https://github.com/gillesvntnu/GCN_multistructure ",
    "url": "https://arxiv.org/abs/2310.01210",
    "authors": [
      "Gilles Van De Vyver",
      "Sarina Thomas",
      "Guy Ben-Yosef",
      "Sindre Hellum Olaisen",
      "H\u00e5vard Dalen",
      "Lasse L\u00f8vstakken",
      "Erik Smistad"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01258",
    "title": "MobileNVC: Real-time 1080p Neural Video Compression on a Mobile Device",
    "abstract": "Neural video codecs have recently become competitive with standard codecs such as HEVC in the low-delay setting. However, most neural codecs are large floating-point networks that use pixel-dense warping operations for temporal modeling, making them too computationally expensive for deployment on mobile devices. Recent work has demonstrated that running a neural decoder in real time on mobile is feasible, but shows this only for 720p RGB video, while the YUV420 format is more commonly used in production. This work presents the first neural video codec that decodes 1080p YUV420 video in real time on a mobile device. Our codec relies on two major contributions. First, we design an efficient codec that uses a block-based motion compensation algorithm available on the warping core of the mobile accelerator, and we show how to quantize this model to integer precision. Second, we implement a fast decoder pipeline that concurrently runs neural network components on the neural signal processor, parallel entropy coding on the mobile GPU, and warping on the warping core. Our codec outperforms the previous on-device codec by a large margin with up to 48 % BD-rate savings, while reducing the MAC count on the receiver side by 10x. We perform a careful ablation to demonstrate the effect of the introduced motion compensation scheme, and ablate the effect of model quantization. ",
    "url": "https://arxiv.org/abs/2310.01258",
    "authors": [
      "Ties van Rozendaal",
      "Tushar Singhal",
      "Hoang Le",
      "Guillaume Sautiere",
      "Amir Said",
      "Krishna Buska",
      "Anjuman Raha",
      "Dimitris Kalatzis",
      "Hitarth Mehta",
      "Frank Mayer",
      "Liang Zhang",
      "Markus Nagel",
      "Auke Wiggers"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01285",
    "title": "Automated regime detection in multidimensional time series data using  sliced Wasserstein k-means clustering",
    "abstract": "Recent work has proposed Wasserstein k-means (Wk-means) clustering as a powerful method to identify regimes in time series data, and one-dimensional asset returns in particular. In this paper, we begin by studying in detail the behaviour of the Wasserstein k-means clustering algorithm applied to synthetic one-dimensional time series data. We study the dynamics of the algorithm and investigate how varying different hyperparameters impacts the performance of the clustering algorithm for different random initialisations. We compute simple metrics that we find are useful in identifying high-quality clusterings. Then, we extend the technique of Wasserstein k-means clustering to multidimensional time series data by approximating the multidimensional Wasserstein distance as a sliced Wasserstein distance, resulting in a method we call `sliced Wasserstein k-means (sWk-means) clustering'. We apply the sWk-means clustering method to the problem of automated regime detection in multidimensional time series data, using synthetic data to demonstrate the validity of the approach. Finally, we show that the sWk-means method is effective in identifying distinct market regimes in real multidimensional financial time series, using publicly available foreign exchange spot rate data as a case study. We conclude with remarks about some limitations of our approach and potential complementary or alternative approaches. ",
    "url": "https://arxiv.org/abs/2310.01285",
    "authors": [
      "Qinmeng Luan",
      "James Hamp"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)",
      "Mathematical Finance (q-fin.MF)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.01350",
    "title": "A peridynamic-informed deep learning model for brittle damage prediction",
    "abstract": "In this study, a novel approach that combines the principles of peridynamic (PD) theory with PINN is presented to predict quasi-static damage and crack propagation in brittle materials. To achieve high prediction accuracy and convergence rate, the linearized PD governing equation is enforced in the PINN's residual-based loss function. The proposed PD-INN is able to learn and capture intricate displacement patterns associated with different geometrical parameters, such as pre-crack position and length. Several enhancements like cyclical annealing schedule and deformation gradient aware optimization technique are proposed to ensure the model would not get stuck in its trivial solution. The model's performance assessment is conducted by monitoring the behavior of loss function throughout the training process. The PD-INN predictions are also validated through several benchmark cases with the results obtained from high-fidelity techniques such as PD direct numerical method and Extended-Finite Element Method. Our results show the ability of the nonlocal PD-INN to predict damage and crack propagation accurately and efficiently. ",
    "url": "https://arxiv.org/abs/2310.01350",
    "authors": [
      "Roozbeh Eghbalpoor",
      "Azadeh Sheidaei"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01413",
    "title": "A multi-institutional pediatric dataset of clinical radiology MRIs by  the Children's Brain Tumor Network",
    "abstract": "Pediatric brain and spinal cancers remain the leading cause of cancer-related death in children. Advancements in clinical decision-support in pediatric neuro-oncology utilizing the wealth of radiology imaging data collected through standard care, however, has significantly lagged other domains. Such data is ripe for use with predictive analytics such as artificial intelligence (AI) methods, which require large datasets. To address this unmet need, we provide a multi-institutional, large-scale pediatric dataset of 23,101 multi-parametric MRI exams acquired through routine care for 1,526 brain tumor patients, as part of the Children's Brain Tumor Network. This includes longitudinal MRIs across various cancer diagnoses, with associated patient-level clinical information, digital pathology slides, as well as tissue genotype and omics data. To facilitate downstream analysis, treatment-na\\\"ive images for 370 subjects were processed and released through the NCI Childhood Cancer Data Initiative via the Cancer Data Service. Through ongoing efforts to continuously build these imaging repositories, our aim is to accelerate discovery and translational AI models with real-world data, to ultimately empower precision medicine for children. ",
    "url": "https://arxiv.org/abs/2310.01413",
    "authors": [
      "Ariana M. Familiar",
      "Anahita Fathi Kazerooni",
      "Hannah Anderson",
      "Aliaksandr Lubneuski",
      "Karthik Viswanathan",
      "Rocky Breslow",
      "Nastaran Khalili",
      "Sina Bagheri",
      "Debanjan Haldar",
      "Meen Chul Kim",
      "Sherjeel Arif",
      "Rachel Madhogarhia",
      "Thinh Q. Nguyen",
      "Elizabeth A. Frenkel",
      "Zeinab Helili",
      "Jessica Harrison",
      "Keyvan Farahani",
      "Marius George Linguraru",
      "Ulas Bagci",
      "Yury Velichko",
      "Jeffrey Stevens",
      "Sarah Leary",
      "Robert M. Lober",
      "Stephani Campion",
      "Amy A. Smith",
      "Denise Morinigo",
      "Brian Rood",
      "Kimberly Diamond",
      "Ian F. Pollack",
      "Melissa Williams",
      "Arastoo Vossough",
      "Jeffrey B. Ware",
      "Sabine Mueller",
      "Phillip B. Storm",
      "Allison P. Heath",
      "Angela J. Waanders",
      "Jena V. Lilly",
      "Jennifer L. Mason",
      "Adam C. Resnick",
      "Ali Nabavizadeh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2002.09285",
    "title": "A Convolutional Neural Network into graph space",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:1611.08402 by other authors ",
    "url": "https://arxiv.org/abs/2002.09285",
    "authors": [
      "Chlo\u00e9 Martineau",
      "Romain Raveaux",
      "Donatello Conte",
      "Gilles Venturini"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2102.00851",
    "title": "Rich Prosody Diversity Modelling with Phone-level Mixture Density  Network",
    "abstract": " Comments: Accepted to Interspeech 2021 ",
    "url": "https://arxiv.org/abs/2102.00851",
    "authors": [
      "Chenpeng Du",
      "Kai Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2105.14362",
    "title": "Dash Sylvereye: A WebGL-powered Library for Dashboard-driven  Visualization of Large Street Networks",
    "abstract": " Comments: Re-submitted to IEEE Access on Aug. 11, 2023. The interpretation of the results in Section V has been corrected, as a more in-depth analysis unveiled that the prior results are attributed to the software (CPU) acceleration capabilities of Dash Sylvereye. Additionally, the manuscript now features a performance comparison with Kepler.gl and city-roads ",
    "url": "https://arxiv.org/abs/2105.14362",
    "authors": [
      "Alberto Garcia-Robledo",
      "Mahboobeh Zangiabady"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2106.02626",
    "title": "Dynamics of specialization in neural modules under resource constraints",
    "abstract": " Title: Dynamics of specialization in neural modules under resource constraints ",
    "url": "https://arxiv.org/abs/2106.02626",
    "authors": [
      "Gabriel B\u00e9na",
      "Dan F. M. Goodman"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2107.06178",
    "title": "An Ecological Robustness-Oriented Approach for Power System Network  Expansion",
    "abstract": " Title: An Ecological Robustness-Oriented Approach for Power System Network  Expansion ",
    "url": "https://arxiv.org/abs/2107.06178",
    "authors": [
      "Hao Huang",
      "Zeyu Mao",
      "Varuneswara Panyam",
      "Astrid Layton",
      "Katherine Davis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2109.08346",
    "title": "Comfetch: Federated Learning of Large Networks on Constrained Clients  via Sketching",
    "abstract": " Title: Comfetch: Federated Learning of Large Networks on Constrained Clients  via Sketching ",
    "url": "https://arxiv.org/abs/2109.08346",
    "authors": [
      "Tahseen Rabbani",
      "Brandon Feng",
      "Marco Bornstein",
      "Kyle Rui Sang",
      "Yifan Yang",
      "Arjun Rajkumar",
      "Amitabh Varshney",
      "Furong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.03898",
    "title": "Rapid mixing for the hardcore Glauber dynamics and other Markov chains  in bounded-treewidth graphs",
    "abstract": " Comments: 43 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2111.03898",
    "authors": [
      "David Eppstein",
      "Daniel Frishberg"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2204.06350",
    "title": "LDPC codes: comparing cluster graphs to factor graphs",
    "abstract": " Comments: 8 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2204.06350",
    "authors": [
      "J du Toit",
      "J du Preez",
      "R Wolhuter"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.03601",
    "title": "Decoupled Self-supervised Learning for Non-Homophilous Graphs",
    "abstract": " Title: Decoupled Self-supervised Learning for Non-Homophilous Graphs ",
    "url": "https://arxiv.org/abs/2206.03601",
    "authors": [
      "Teng Xiao",
      "Zhengyu Chen",
      "Zhimeng Guo",
      "Zeyang Zhuang",
      "Suhang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.09380",
    "title": "Supervision Adaptation Balancing In-distribution Generalization and  Out-of-distribution Detection",
    "abstract": " Title: Supervision Adaptation Balancing In-distribution Generalization and  Out-of-distribution Detection ",
    "url": "https://arxiv.org/abs/2206.09380",
    "authors": [
      "Zhilin Zhao",
      "Longbing Cao",
      "Kun-Yu Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.11102",
    "title": "40 Years of Designing Code Comprehension Experiments: A Systematic  Mapping Study",
    "abstract": " Comments: Accepted for publication at ACM Computing Surveys ",
    "url": "https://arxiv.org/abs/2206.11102",
    "authors": [
      "Marvin Wyrich",
      "Justus Bogner",
      "Stefan Wagner"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2208.07978",
    "title": "Enhancing Heterogeneous Federated Learning with Knowledge Extraction and  Multi-Model Fusion",
    "abstract": " Comments: Accept at the 4th workshop on Artificial Intelligence and Machine Learning for Scientific Applications (AI4S), SC 23 ",
    "url": "https://arxiv.org/abs/2208.07978",
    "authors": [
      "Duy Phuong Nguyen",
      "Sixing Yu",
      "J. Pablo Mu\u00f1oz",
      "Ali Jannesari"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.10241",
    "title": "Exact and sampling methods for mining higher-order motifs in large  hypergraphs",
    "abstract": " Comments: In press at Springer Computing ",
    "url": "https://arxiv.org/abs/2209.10241",
    "authors": [
      "Quintino Francesco Lotito",
      "Federico Musciotto",
      "Federico Battiston",
      "Alberto Montresor"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2209.13091",
    "title": "WaterNeRF: Neural Radiance Fields for Underwater Scenes",
    "abstract": " Title: WaterNeRF: Neural Radiance Fields for Underwater Scenes ",
    "url": "https://arxiv.org/abs/2209.13091",
    "authors": [
      "Advaith Venkatramanan Sethuraman",
      "Manikandasriram Srinivasan Ramanagopal",
      "Katherine A. Skinner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2209.14937",
    "title": "NAG-GS: Semi-Implicit, Accelerated and Robust Stochastic Optimizer",
    "abstract": " Comments: We study Nesterov acceleration for the Stochastic Differential Equation ",
    "url": "https://arxiv.org/abs/2209.14937",
    "authors": [
      "Valentin Leplat",
      "Daniil Merkulov",
      "Aleksandr Katrutsa",
      "Daniel Bershatsky",
      "Olga Tsymboi",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2209.15179",
    "title": "Physical Adversarial Attack meets Computer Vision: A Decade Survey",
    "abstract": " Comments: 19 pages. Under Review ",
    "url": "https://arxiv.org/abs/2209.15179",
    "authors": [
      "Hui Wei",
      "Hao Tang",
      "Xuemei Jia",
      "Zhixiang Wang",
      "Hanxun Yu",
      "Zhubo Li",
      "Shin'ichi Satoh",
      "Luc Van Gool",
      "Zheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.02685",
    "title": "A Real2Sim2Real Method for Robust Object Grasping with Neural Surface  Reconstruction",
    "abstract": " Comments: Video presentation available at this https URL ",
    "url": "https://arxiv.org/abs/2210.02685",
    "authors": [
      "Luobin Wang",
      "Runlin Guo",
      "Quan Vuong",
      "Yuzhe Qin",
      "Hao Su",
      "Henrik Christensen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.09997",
    "title": "Bag All You Need: Learning a Generalizable Bagging Strategy for  Heterogeneous Objects",
    "abstract": " Comments: 8 pages, 5 figures, project website: this https URL ",
    "url": "https://arxiv.org/abs/2210.09997",
    "authors": [
      "Arpit Bahety",
      "Shreeya Jain",
      "Huy Ha",
      "Nathalie Hager",
      "Benjamin Burchfiel",
      "Eric Cousineau",
      "Siyuan Feng",
      "Shuran Song"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.08229",
    "title": "CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive  Learning",
    "abstract": " Title: CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive  Learning ",
    "url": "https://arxiv.org/abs/2211.08229",
    "authors": [
      "Jinghuai Zhang",
      "Hongbin Liu",
      "Jinyuan Jia",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08939",
    "title": "Augmented Physics-Informed Neural Networks (APINNs): A gating  network-based soft domain decomposition methodology",
    "abstract": " Comments: Accepted at Engineering Applications of Artificial Intelligence (EAAI) ",
    "url": "https://arxiv.org/abs/2211.08939",
    "authors": [
      "Zheyuan Hu",
      "Ameya D. Jagtap",
      "George Em Karniadakis",
      "Kenji Kawaguchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.15255",
    "title": "ARISE: Graph Anomaly Detection on Attributed Networks via Substructure  Awareness",
    "abstract": " Comments: 13 pages, 8 figures, accepted by IEEE TNNLS ",
    "url": "https://arxiv.org/abs/2211.15255",
    "authors": [
      "Jingcan Duan",
      "Bin Xiao",
      "Siwei Wang",
      "Haifang Zhou",
      "Xinwang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15498",
    "title": "Physics-informed neural networks with unknown measurement noise",
    "abstract": " Title: Physics-informed neural networks with unknown measurement noise ",
    "url": "https://arxiv.org/abs/2211.15498",
    "authors": [
      "Philipp Pilar",
      "Niklas Wahlstr\u00f6m"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.00344",
    "title": "Bayesian Heuristics for Robust Spatial Perception",
    "abstract": " Comments: 10 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2212.00344",
    "authors": [
      "Aamir Hussain Chughtai",
      "Muhammad Tahir",
      "Momin Uppal"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2212.04726",
    "title": "Breaking the Barrier $2^k$ for Subset Feedback Vertex Set in Chordal  Graphs",
    "abstract": " Comments: 30 pages, 9 figures. Full version ",
    "url": "https://arxiv.org/abs/2212.04726",
    "authors": [
      "Tian Bai",
      "Mingyu Xiao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2212.08108",
    "title": "Dataflow Analysis-Inspired Deep Learning for Efficient Vulnerability  Detection",
    "abstract": " Comments: Accepted at ICSE 2024 (Early Cycle). Camera-ready version ",
    "url": "https://arxiv.org/abs/2212.08108",
    "authors": [
      "Benjamin Steenhoek",
      "Hongyang Gao",
      "Wei Le"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.02615",
    "title": "Silent Killer: A Stealthy, Clean-Label, Black-Box Backdoor Attack",
    "abstract": " Title: Silent Killer: A Stealthy, Clean-Label, Black-Box Backdoor Attack ",
    "url": "https://arxiv.org/abs/2301.02615",
    "authors": [
      "Tzvi Lederer",
      "Gallil Maimon",
      "Lior Rokach"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.05599",
    "title": "Short-length SSVEP data extension by a novel generative adversarial  networks based framework",
    "abstract": " Comments: 16 pages, 9 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2301.05599",
    "authors": [
      "Yudong Pan",
      "Ning Li",
      "Yangsong Zhang",
      "Peng Xu",
      "Dezhong Yao"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2301.09043",
    "title": "CodeScore: Evaluating Code Generation by Learning Code Execution",
    "abstract": " Title: CodeScore: Evaluating Code Generation by Learning Code Execution ",
    "url": "https://arxiv.org/abs/2301.09043",
    "authors": [
      "Yihong Dong",
      "Jiazheng Ding",
      "Xue Jiang",
      "Ge Li",
      "Zhuo Li",
      "Zhi Jin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2301.11147",
    "title": "Train Hard, Fight Easy: Robust Meta Reinforcement Learning",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2301.11147",
    "authors": [
      "Ido Greenberg",
      "Shie Mannor",
      "Gal Chechik",
      "Eli Meirom"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11443",
    "title": "Limitless stability for Graph Convolutional Networks",
    "abstract": " Title: Limitless stability for Graph Convolutional Networks ",
    "url": "https://arxiv.org/abs/2301.11443",
    "authors": [
      "Christian Koke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)"
    ]
  },
  {
    "id": "arXiv:2302.13293",
    "title": "PDIWS: Thermal Imaging Dataset for Person Detection in Intrusion Warning  Systems",
    "abstract": " Comments: We are considering some issues in the paper ",
    "url": "https://arxiv.org/abs/2302.13293",
    "authors": [
      "Nguyen Duc Thuan",
      "Le Hai Anh",
      "Hoang Si Hong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.14838",
    "title": "EvoPrompting: Language Models for Code-Level Neural Architecture Search",
    "abstract": " Comments: To be presented at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2302.14838",
    "authors": [
      "Angelica Chen",
      "David M. Dohan",
      "David R. So"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.04281",
    "title": "An Extended Model for Ecological Robustness to Capture Power System  Resilience",
    "abstract": " Comments: Accepted By IEEE PES General Meeting 2023 ",
    "url": "https://arxiv.org/abs/2303.04281",
    "authors": [
      "Hao Huang",
      "Katherine R. Davis",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.06842",
    "title": "Hierarchical Relationships: A New Perspective to Enhance Scene Graph  Generation",
    "abstract": " Title: Hierarchical Relationships: A New Perspective to Enhance Scene Graph  Generation ",
    "url": "https://arxiv.org/abs/2303.06842",
    "authors": [
      "Bowen Jiang",
      "Camillo J. Taylor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09656",
    "title": "Revealing complexities when adult readers engage in the credibility  evaluation of social media posts",
    "abstract": " Comments: 25 pages, 5 figures including the appendix. Submitted to a journal for peer review ",
    "url": "https://arxiv.org/abs/2303.09656",
    "authors": [
      "Miikka Kuutila",
      "Carita Kiili",
      "Reijo Kupiainen",
      "Eetu Huusko",
      "Junhao Li",
      "Simo Hosio",
      "Mika M\u00e4ntyl\u00e4",
      "Julie Coiro",
      "Kristian Kiili"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.09792",
    "title": "Exploring Sparse Visual Prompt for Domain Adaptive Dense Prediction",
    "abstract": " Title: Exploring Sparse Visual Prompt for Domain Adaptive Dense Prediction ",
    "url": "https://arxiv.org/abs/2303.09792",
    "authors": [
      "Senqiao Yang",
      "Jiarui Wu",
      "Jiaming Liu",
      "Xiaoqi Li",
      "Qizhe Zhang",
      "Mingjie Pan",
      "Yulu Gan",
      "Zehui Chen",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09874",
    "title": "Disentangling the Link Between Image Statistics and Human Perception",
    "abstract": " Title: Disentangling the Link Between Image Statistics and Human Perception ",
    "url": "https://arxiv.org/abs/2303.09874",
    "authors": [
      "Alexander Hepburn",
      "Valero Laparra",
      "Ra\u00fal Santos-Rodriguez",
      "Jes\u00fas Malo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2303.13227",
    "title": "Confidence-Aware and Self-Supervised Image Anomaly Localisation",
    "abstract": " Comments: Accepted for MICCAI UNSURE Workshop 2023 (Spotlight) ",
    "url": "https://arxiv.org/abs/2303.13227",
    "authors": [
      "Johanna P. M\u00fcller",
      "Matthew Baugh",
      "Jeremy Tan",
      "Mischa Dombrowski",
      "Bernhard Kainz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.15564",
    "title": "Mask and Restore: Blind Backdoor Defense at Test Time with Masked  Autoencoder",
    "abstract": " Title: Mask and Restore: Blind Backdoor Defense at Test Time with Masked  Autoencoder ",
    "url": "https://arxiv.org/abs/2303.15564",
    "authors": [
      "Tao Sun",
      "Lu Pang",
      "Chao Chen",
      "Haibin Ling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15688",
    "title": "Efficient Deep Learning of Robust, Adaptive Policies using Tube  MPC-Guided Data Augmentation",
    "abstract": " Comments: 8 pages, 6 figures. IROS23 final version, with page numbers added ",
    "url": "https://arxiv.org/abs/2303.15688",
    "authors": [
      "Tong Zhao",
      "Andrea Tagliabue",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.16454",
    "title": "Conductivity Imaging from Internal Measurements with Mixed Least-Squares  Deep Neural Networks",
    "abstract": " Comments: 39 pages. 20 figures ",
    "url": "https://arxiv.org/abs/2303.16454",
    "authors": [
      "Bangti Jin",
      "Xiyao Li",
      "Qimeng Quan",
      "Zhi Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.18154",
    "title": "Direct Data-Driven Computation of Polytopic Robust Control Invariant  Sets and State-Feedback Controllers",
    "abstract": " Comments: 9 pages, 4 figures, accepted for publication, to appear at the 62nd IEEE Conference on Decision and Control (CDC 2023), Singapore ",
    "url": "https://arxiv.org/abs/2303.18154",
    "authors": [
      "Manas Mejari",
      "Ankit Gupta"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.01230",
    "title": "SEENN: Towards Temporal Spiking Early-Exit Neural Networks",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2304.01230",
    "authors": [
      "Yuhang Li",
      "Tamar Geller",
      "Youngeun Kim",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.02858",
    "title": "A review of ensemble learning and data augmentation models for class  imbalanced problems: combination, implementation and evaluation",
    "abstract": " Title: A review of ensemble learning and data augmentation models for class  imbalanced problems: combination, implementation and evaluation ",
    "url": "https://arxiv.org/abs/2304.02858",
    "authors": [
      "Azal Ahmad Khan",
      "Omkar Chaudhari",
      "Rohitash Chandra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.04546",
    "title": "Kinship Representation Learning with Face Componential Relation",
    "abstract": " Comments: ICCV 2023 Workshop (Analysis and Modeling of Faces and Gestures) ",
    "url": "https://arxiv.org/abs/2304.04546",
    "authors": [
      "Weng-Tai Su",
      "Min-Hung Chen",
      "Chien-Yi Wang",
      "Shang-Hong Lai",
      "Trista Pei-Chun Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.06094",
    "title": "Energy-guided Entropic Neural Optimal Transport",
    "abstract": " Title: Energy-guided Entropic Neural Optimal Transport ",
    "url": "https://arxiv.org/abs/2304.06094",
    "authors": [
      "Petr Mokrov",
      "Alexander Korotin",
      "Alexander Kolesov",
      "Nikita Gushchin",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.07866",
    "title": "A New Flexible Modified Impedance Network Converter",
    "abstract": " Comments: To be presented in ITEC2023, Detroit, MI, USA ",
    "url": "https://arxiv.org/abs/2304.07866",
    "authors": [
      "Shirin Besati",
      "Somasundaram Essakiappan",
      "Madhav Manjrekar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.02154",
    "title": "Spectral bound for random Schreier graphs of the general linear group",
    "abstract": " Comments: 31 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2305.02154",
    "authors": [
      "Geoffroy Caillat-Grenier"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2305.06568",
    "title": "Convolutional Neural Networks Rarely Learn Shape for Semantic  Segmentation",
    "abstract": " Comments: Accepted by Pattern Recognition ",
    "url": "https://arxiv.org/abs/2305.06568",
    "authors": [
      "Yixin Zhang",
      "Maciej A. Mazurowski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.09770",
    "title": "ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to  Support Human-AI Scientific Writing",
    "abstract": " Comments: To appear in CSCW 2023 Demo. ConvXAI system code: this https URL ",
    "url": "https://arxiv.org/abs/2305.09770",
    "authors": [
      "Hua Shen",
      "Chieh-Yang Huang",
      "Tongshuang Wu",
      "Ting-Hao 'Kenneth' Huang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12286",
    "title": "Low-Earth Satellite Orbit Determination Using Deep Convolutional  Networks with Satellite Imagery",
    "abstract": " Title: Low-Earth Satellite Orbit Determination Using Deep Convolutional  Networks with Satellite Imagery ",
    "url": "https://arxiv.org/abs/2305.12286",
    "authors": [
      "Rohit Khorana"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.12788",
    "title": "GraphCare: Enhancing Healthcare Predictions with Personalized Knowledge  Graphs",
    "abstract": " Title: GraphCare: Enhancing Healthcare Predictions with Personalized Knowledge  Graphs ",
    "url": "https://arxiv.org/abs/2305.12788",
    "authors": [
      "Pengcheng Jiang",
      "Cao Xiao",
      "Adam Cross",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14062",
    "title": "Amplitude-Independent Machine Learning for PPG through Visibility Graphs  and Transfer Learning",
    "abstract": " Title: Amplitude-Independent Machine Learning for PPG through Visibility Graphs  and Transfer Learning ",
    "url": "https://arxiv.org/abs/2305.14062",
    "authors": [
      "Yuyang Miao",
      "Harry J. Davies",
      "Danilo P. Mandic"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14567",
    "title": "Memory Efficient Neural Processes via Constant Memory Attention Block",
    "abstract": " Title: Memory Efficient Neural Processes via Constant Memory Attention Block ",
    "url": "https://arxiv.org/abs/2305.14567",
    "authors": [
      "Leo Feng",
      "Frederick Tung",
      "Hossein Hajimirsadeghi",
      "Yoshua Bengio",
      "Mohamed Osama Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15611",
    "title": "Size Generalization of Graph Neural Networks on Biological Data:  Insights and Practices from the Spectral Perspective",
    "abstract": " Comments: 17 pages, including appendix ",
    "url": "https://arxiv.org/abs/2305.15611",
    "authors": [
      "Yujun Yan",
      "Gaotang Li",
      "Danai koutra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15852",
    "title": "Self-contradictory Hallucinations of Large Language Models: Evaluation,  Detection and Mitigation",
    "abstract": " Title: Self-contradictory Hallucinations of Large Language Models: Evaluation,  Detection and Mitigation ",
    "url": "https://arxiv.org/abs/2305.15852",
    "authors": [
      "Niels M\u00fcndler",
      "Jingxuan He",
      "Slobodan Jenko",
      "Martin Vechev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16183",
    "title": "Passive learning of active causal strategies in agents and language  models",
    "abstract": " Comments: Advances in Neural Information Processing Systems (NeurIPS 2023). 10 pages main text ",
    "url": "https://arxiv.org/abs/2305.16183",
    "authors": [
      "Andrew Kyle Lampinen",
      "Stephanie C Y Chan",
      "Ishita Dasgupta",
      "Andrew J Nam",
      "Jane X Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17102",
    "title": "GeoVLN: Learning Geometry-Enhanced Visual Representation with Slot  Attention for Vision-and-Language Navigation",
    "abstract": " Comments: Accepted by CVPR 2023 ",
    "url": "https://arxiv.org/abs/2305.17102",
    "authors": [
      "Jingyang Huo",
      "Qiang Sun",
      "Boyan Jiang",
      "Haitao Lin",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18270",
    "title": "How Two-Layer Neural Networks Learn, One (Giant) Step at a Time",
    "abstract": " Title: How Two-Layer Neural Networks Learn, One (Giant) Step at a Time ",
    "url": "https://arxiv.org/abs/2305.18270",
    "authors": [
      "Yatin Dandi",
      "Florent Krzakala",
      "Bruno Loureiro",
      "Luca Pesce",
      "Ludovic Stephan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.00788",
    "title": "Understanding Augmentation-based Self-Supervised Representation Learning  via RKHS Approximation and Regression",
    "abstract": " Comments: 35 pages ",
    "url": "https://arxiv.org/abs/2306.00788",
    "authors": [
      "Runtian Zhai",
      "Bingbin Liu",
      "Andrej Risteski",
      "Zico Kolter",
      "Pradeep Ravikumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.01731",
    "title": "PAGAR: Taming Reward Misalignment in Inverse Reinforcement  Learning-Based Imitation Learning with Protagonist Antagonist Guided  Adversarial Reward",
    "abstract": " Title: PAGAR: Taming Reward Misalignment in Inverse Reinforcement  Learning-Based Imitation Learning with Protagonist Antagonist Guided  Adversarial Reward ",
    "url": "https://arxiv.org/abs/2306.01731",
    "authors": [
      "Weichao Zhou",
      "Wenchao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.04987",
    "title": "Convolutional Recurrent Neural Network with Attention for 3D Speech  Enhancement",
    "abstract": " Comments: 5 pages,5 figures ",
    "url": "https://arxiv.org/abs/2306.04987",
    "authors": [
      "Han Yin",
      "Jisheng Bai",
      "Mou Wang",
      "Siwei Huang",
      "Yafei Jia",
      "Jianfeng Chen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2306.05032",
    "title": "Log-based Anomaly Detection based on EVT Theory with feedback",
    "abstract": " Title: Log-based Anomaly Detection based on EVT Theory with feedback ",
    "url": "https://arxiv.org/abs/2306.05032",
    "authors": [
      "Jinyang Liu",
      "Junjie Huang",
      "Yintong Huo",
      "Zhihan Jiang",
      "Jiazhen Gu",
      "Zhuangbin Chen",
      "Cong Feng",
      "Minzhi Yan",
      "Michael R. Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.05079",
    "title": "Enhancing Robustness of AI Offensive Code Generators via Data  Augmentation",
    "abstract": " Title: Enhancing Robustness of AI Offensive Code Generators via Data  Augmentation ",
    "url": "https://arxiv.org/abs/2306.05079",
    "authors": [
      "Cristina Improta",
      "Pietro Liguori",
      "Roberto Natella",
      "Bojan Cukic",
      "Domenico Cotroneo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.06040",
    "title": "Reconstructing Human Expressiveness in Piano Performances with a  Transformer Network",
    "abstract": " Comments: 12 pages, 5 figures, accepted by CMMR2023, the 16th International Symposium on Computer Music Multidisciplinary Research ",
    "url": "https://arxiv.org/abs/2306.06040",
    "authors": [
      "Jingjing Tang",
      "Geraint Wiggins",
      "Gyorgy Fazekas"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.07879",
    "title": "Rethinking pose estimation in crowds: overcoming the detection  information-bottleneck and ambiguity",
    "abstract": " Comments: Published at ICCV 2023; Code at this https URL Video at this https URL ",
    "url": "https://arxiv.org/abs/2306.07879",
    "authors": [
      "Mu Zhou",
      "Lucas Stoffl",
      "Mackenzie Weygandt Mathis",
      "Alexander Mathis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2306.10060",
    "title": "MUBen: Benchmarking the Uncertainty of Molecular Representation Models",
    "abstract": " Title: MUBen: Benchmarking the Uncertainty of Molecular Representation Models ",
    "url": "https://arxiv.org/abs/2306.10060",
    "authors": [
      "Yinghao Li",
      "Lingkai Kong",
      "Yuanqi Du",
      "Yue Yu",
      "Yuchen Zhuang",
      "Wenhao Mu",
      "Chao Zhang"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.10080",
    "title": "AI Driven Near Real-time Locational Marginal Pricing Method: A  Feasibility and Robustness Study",
    "abstract": " Title: AI Driven Near Real-time Locational Marginal Pricing Method: A  Feasibility and Robustness Study ",
    "url": "https://arxiv.org/abs/2306.10080",
    "authors": [
      "Naga Venkata Sai Jitin Jami",
      "Juraj Kardo\u0161",
      "Olaf Schenk",
      "Harald K\u00f6stler"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.11295",
    "title": "Bounds on the genus for 2-cell embeddings of prefix-reversal graphs",
    "abstract": " Comments: Fixed some typos and improved some exposition. 21 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2306.11295",
    "authors": [
      "Sa\u00fal A. Blanco",
      "Charles Buehrle"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2306.13050",
    "title": "Data augmentation and refinement for recommender system: A  semi-supervised approach using maximum margin matrix factorization",
    "abstract": " Comments: 21 pages ",
    "url": "https://arxiv.org/abs/2306.13050",
    "authors": [
      "Shamal Shaikh",
      "Venkateswara Rao Kagita",
      "Vikas Kumar",
      "Arun K Pujari"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.14975",
    "title": "The Underlying Scaling Laws and Universal Statistical Structure of  Complex Datasets",
    "abstract": " Comments: 18 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2306.14975",
    "authors": [
      "Noam Levi",
      "Yaron Oz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "High Energy Physics - Theory (hep-th)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.15203",
    "title": "Unsupervised Polychromatic Neural Representation for CT Metal Artifact  Reduction",
    "abstract": " Comments: Accepted by NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.15203",
    "authors": [
      "Qing Wu",
      "Lixuan Chen",
      "Ce Wang",
      "Hongjiang Wei",
      "S. Kevin Zhou",
      "Jingyi Yu",
      "Yuyao Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.00301",
    "title": "Words for the Graphs with Permutation-Representation Number at most  Three",
    "abstract": " Title: Words for the Graphs with Permutation-Representation Number at most  Three ",
    "url": "https://arxiv.org/abs/2307.00301",
    "authors": [
      "Khyodeno Mozhui",
      "K. V. Krishna"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2307.02231",
    "title": "Tit-for-Token: Understanding Fairness when Forwarding Data by  Incentivized Peers in Decentralized Storage Networks",
    "abstract": " Comments: 28 pages, 15 figures ",
    "url": "https://arxiv.org/abs/2307.02231",
    "authors": [
      "Vahid Heidaripour Lakhani",
      "Arman Babaei",
      "Leander Jehl",
      "Georgy Ishmaev",
      "Vero Estrada-Gali\u00f1anes"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2307.07697",
    "title": "Think-on-Graph: Deep and Responsible Reasoning of Large Language Model  on Knowledge Graph",
    "abstract": " Comments: 30 pages, 13 figures, 20 tables ",
    "url": "https://arxiv.org/abs/2307.07697",
    "authors": [
      "Jiashuo Sun",
      "Chengjin Xu",
      "Lumingyuan Tang",
      "Saizhuo Wang",
      "Chen Lin",
      "Yeyun Gong",
      "Lionel M. Ni",
      "Heung-Yeung Shum",
      "Jian Guo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.09882",
    "title": "Adversarial Likelihood Estimation With One-Way Flows",
    "abstract": " Title: Adversarial Likelihood Estimation With One-Way Flows ",
    "url": "https://arxiv.org/abs/2307.09882",
    "authors": [
      "Omri Ben-Dov",
      "Pravir Singh Gupta",
      "Victoria Abrevaya",
      "Michael J. Black",
      "Partha Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.10173",
    "title": "DNA-Rendering: A Diverse Neural Actor Repository for High-Fidelity  Human-centric Rendering",
    "abstract": " Comments: This paper is accepted by ICCV2023. Project page: this https URL ",
    "url": "https://arxiv.org/abs/2307.10173",
    "authors": [
      "Wei Cheng",
      "Ruixiang Chen",
      "Wanqi Yin",
      "Siming Fan",
      "Keyu Chen",
      "Honglin He",
      "Huiwen Luo",
      "Zhongang Cai",
      "Jingbo Wang",
      "Yang Gao",
      "Zhengming Yu",
      "Zhengyu Lin",
      "Daxuan Ren",
      "Lei Yang",
      "Ziwei Liu",
      "Chen Change Loy",
      "Chen Qian",
      "Wayne Wu",
      "Dahua Lin",
      "Bo Dai",
      "Kwan-Yee Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.10922",
    "title": "Language-based Action Concept Spaces Improve Video Self-Supervised  Learning",
    "abstract": " Comments: Presented at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2307.10922",
    "authors": [
      "Kanchana Ranasinghe",
      "Michael Ryoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12082",
    "title": "A Quantitative Analysis of Open Source Software Code Quality: Insights  from Metric Distributions",
    "abstract": " Comments: The paper has been revised according to the feedback received from the reviews during IEEE QRS 2023 ",
    "url": "https://arxiv.org/abs/2307.12082",
    "authors": [
      "Siyuan Jin",
      "Mianmian Zhang",
      "Yekai Guo",
      "Yuejiang He",
      "Ziyuan Li",
      "Bichao Chen",
      "Bing Zhu",
      "Yong Xia"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2307.15546",
    "title": "On the Trade-off Between Efficiency and Precision of Neural Abstraction",
    "abstract": " Comments: Appeared at QEST 2023. Added codebase link; corrected Eq. 11 ",
    "url": "https://arxiv.org/abs/2307.15546",
    "authors": [
      "Alec Edwards",
      "Mirco Giacobbe",
      "Alessandro Abate"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.16189",
    "title": "Trustworthy Optimization: A Novel Approach to Counter Numerical  Instability in 16-bit Neural Network Training",
    "abstract": " Title: Trustworthy Optimization: A Novel Approach to Counter Numerical  Instability in 16-bit Neural Network Training ",
    "url": "https://arxiv.org/abs/2307.16189",
    "authors": [
      "Juyoung Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.00180",
    "title": "General Anomaly Detection of Underwater Gliders Validated by Large-scale  Deployment Datasets",
    "abstract": " Comments: Accepted in IEEE/MTS OCEANS Gulf Coast 2023 ",
    "url": "https://arxiv.org/abs/2308.00180",
    "authors": [
      "Ruochu Yang",
      "Chad Lembke",
      "Fumin Zhang",
      "Catherine Edwards"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.02599",
    "title": "Branched Latent Neural Maps",
    "abstract": " Title: Branched Latent Neural Maps ",
    "url": "https://arxiv.org/abs/2308.02599",
    "authors": [
      "Matteo Salvador",
      "Alison Lesley Marsden"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2308.03985",
    "title": "Fourier neural operator for real-time simulation of 3D dynamic urban  microclimate",
    "abstract": " Title: Fourier neural operator for real-time simulation of 3D dynamic urban  microclimate ",
    "url": "https://arxiv.org/abs/2308.03985",
    "authors": [
      "Wenhui Peng",
      "Shaoxiang Qin",
      "Senwen Yang",
      "Jianchun Wang",
      "Xue Liu",
      "Liangzhu Leon Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2308.05320",
    "title": "Generating Transferable and Stealthy Adversarial Patch via  Attention-guided Adversarial Inpainting",
    "abstract": " Comments: Submitted to ICLR2024 ",
    "url": "https://arxiv.org/abs/2308.05320",
    "authors": [
      "Yanjie Li",
      "Mingxing Duan",
      "Xuelong Dai",
      "Bin Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.10047",
    "title": "Towards Probabilistic Causal Discovery, Inference & Explanations for  Autonomous Drones in Mine Surveying Tasks",
    "abstract": " Comments: 3 Pages, 3 Figures, 1 Algorithm, To be published in the Proceedings of the \"Causality for Robotics: Answering the Question of Why\" workshop at the 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Final submission version ",
    "url": "https://arxiv.org/abs/2308.10047",
    "authors": [
      "Ricardo Cannizzaro",
      "Rhys Howard",
      "Paulina Lewinska",
      "Lars Kunze"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.10819",
    "title": "Evaluating the Instruction-Following Robustness of Large Language Models  to Prompt Injection",
    "abstract": " Comments: The data and code can be found at this https URL ",
    "url": "https://arxiv.org/abs/2308.10819",
    "authors": [
      "Zekun Li",
      "Baolin Peng",
      "Pengcheng He",
      "Xifeng Yan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.13328",
    "title": "Compressor-Based Classification for Atrial Fibrillation Detection",
    "abstract": " Comments: This paper is sent for review at the IEEE conference, 2023 ",
    "url": "https://arxiv.org/abs/2308.13328",
    "authors": [
      "Nikita Markov",
      "Konstantin Ushenin",
      "Yakov Bozhko",
      "Olga Solovyova"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.14491",
    "title": "Closeness of Some Line Graphs",
    "abstract": " Comments: 12 pages ",
    "url": "https://arxiv.org/abs/2308.14491",
    "authors": [
      "Chavdar Dangalchev"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2308.16458",
    "title": "BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual  Pragmatic Knowledge",
    "abstract": " Title: BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual  Pragmatic Knowledge ",
    "url": "https://arxiv.org/abs/2308.16458",
    "authors": [
      "Xiangru Tang",
      "Bill Qian",
      "Rick Gao",
      "Jiakang Chen",
      "Xinyun Chen",
      "Mark Gerstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.03038",
    "title": "Cellular Wireless Networks in the Upper Mid-Band",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2309.03038",
    "authors": [
      "Seongjoon Kang",
      "Marco Mezzavilla",
      "Sundeep Rangan",
      "Arjuna Madanayake",
      "Satheesh Bojja Venkatakrishnan",
      "Gregory Hellbourg",
      "Monisha Ghosh",
      "Hamed Rahmani",
      "Aditya Dhananjay"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.03160",
    "title": "ResFields: Residual Neural Fields for Spatiotemporal Signals",
    "abstract": " Comments: Project page and code at this https URL ",
    "url": "https://arxiv.org/abs/2309.03160",
    "authors": [
      "Marko Mihajlovic",
      "Sergey Prokudin",
      "Marc Pollefeys",
      "Siyu Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.05494",
    "title": "CrisisTransformers: Pre-trained language models and sentence encoders  for crisis-related social media texts",
    "abstract": " Title: CrisisTransformers: Pre-trained language models and sentence encoders  for crisis-related social media texts ",
    "url": "https://arxiv.org/abs/2309.05494",
    "authors": [
      "Rabindra Lamsal",
      "Maria Rodriguez Read",
      "Shanika Karunasekera"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.06034",
    "title": "Normality Learning-based Graph Anomaly Detection via Multi-Scale  Contrastive Learning",
    "abstract": " Comments: 10 pages, 7 figures, accepted by ACM MM 2023 ",
    "url": "https://arxiv.org/abs/2309.06034",
    "authors": [
      "Jingcan Duan",
      "Pei Zhang",
      "Siwei Wang",
      "Jingtao Hu",
      "Hu Jin",
      "Jiaxin Zhang",
      "Haifang Zhou",
      "Xinwang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.07431",
    "title": "Asynchronous Spatial Allocation Protocol for Trajectory Planning of  Heterogeneous Multi-Agent Systems",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2309.07431",
    "authors": [
      "Yuda Chen",
      "Haoze Dong",
      "Zhongkui Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.08374",
    "title": "Understanding the limitations of self-supervised learning for tabular  anomaly detection",
    "abstract": " Title: Understanding the limitations of self-supervised learning for tabular  anomaly detection ",
    "url": "https://arxiv.org/abs/2309.08374",
    "authors": [
      "Kimberly T. Mai",
      "Toby Davies",
      "Lewis D. Griffin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.08887",
    "title": "GRaCE: Optimizing Grasps to Satisfy Ranked Criteria in Complex Scenarios",
    "abstract": " Title: GRaCE: Optimizing Grasps to Satisfy Ranked Criteria in Complex Scenarios ",
    "url": "https://arxiv.org/abs/2309.08887",
    "authors": [
      "Tasbolat Taunyazov",
      "Kelvin Lin",
      "Harold Soh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.09075",
    "title": "Music Generation based on Generative Adversarial Networks with  Transformer",
    "abstract": " Comments: co-author want to withdraw ",
    "url": "https://arxiv.org/abs/2309.09075",
    "authors": [
      "Ziyi Jiang",
      "Ruoxue Wu",
      "Zhenghan Chen",
      "Xiaoxuan Liang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.10569",
    "title": "Task Graph offloading via Deep Reinforcement Learning in Mobile Edge  Computing",
    "abstract": " Comments: 13 figures ",
    "url": "https://arxiv.org/abs/2309.10569",
    "authors": [
      "Jiagang Liu",
      "Yun Mi",
      "Xinyu Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13061",
    "title": "Applying BioBERT to Extract Germline Gene-Disease Associations for  Building a Knowledge Graph from the Biomedical Literature",
    "abstract": " Comments: 10 pages ",
    "url": "https://arxiv.org/abs/2309.13061",
    "authors": [
      "Armando D. Diaz Gonzalez",
      "Songhui Yue",
      "Sean T. Hayes",
      "Kevin S. Hughes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2309.13459",
    "title": "A Model-Agnostic Graph Neural Network for Integrating Local and Global  Information",
    "abstract": " Title: A Model-Agnostic Graph Neural Network for Integrating Local and Global  Information ",
    "url": "https://arxiv.org/abs/2309.13459",
    "authors": [
      "Wenzhuo Zhou",
      "Annie Qu",
      "Keiland W. Cooper",
      "Norbert Fortin",
      "Babak Shahbaba"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.13549",
    "title": "Towards Robust Robot 3D Perception in Urban Environments: The UT Campus  Object Dataset",
    "abstract": " Comments: 19 pages, 18 figures, 12 tables ",
    "url": "https://arxiv.org/abs/2309.13549",
    "authors": [
      "Arthur Zhang",
      "Chaitanya Eranki",
      "Christina Zhang",
      "Ji-Hwan Park",
      "Raymond Hong",
      "Pranav Kalyani",
      "Lochana Kalyanaraman",
      "Arsh Gamare",
      "Arnav Bagad",
      "Maria Esteva",
      "Joydeep Biswas"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13837",
    "title": "Backorder Prediction in Inventory Management: Classification Techniques  and Cost Considerations",
    "abstract": " Comments: 8 pages, 4 figures, IEEE (ICSEC 2023) ",
    "url": "https://arxiv.org/abs/2309.13837",
    "authors": [
      "Sarit Maitra",
      "Sukanya Kundu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2309.14327",
    "title": "DeepSpeed-VisualChat: Multi-Round Multi-Image Interleave Chat via  Multi-Modal Causal Attention",
    "abstract": " Title: DeepSpeed-VisualChat: Multi-Round Multi-Image Interleave Chat via  Multi-Modal Causal Attention ",
    "url": "https://arxiv.org/abs/2309.14327",
    "authors": [
      "Zhewei Yao",
      "Xiaoxia Wu",
      "Conglong Li",
      "Minjia Zhang",
      "Heyang Qin",
      "Olatunji Ruwase",
      "Ammar Ahmad Awan",
      "Samyam Rajbhandari",
      "Yuxiong He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.14331",
    "title": "LinGCN: Structural Linearized Graph Convolutional Network for  Homomorphically Encrypted Inference",
    "abstract": " Comments: NeurIPS 2023 accepted publication ",
    "url": "https://arxiv.org/abs/2309.14331",
    "authors": [
      "Hongwu Peng",
      "Ran Ran",
      "Yukui Luo",
      "Jiahui Zhao",
      "Shaoyi Huang",
      "Kiran Thorat",
      "Tong Geng",
      "Chenghong Wang",
      "Xiaolin Xu",
      "Wujie Wen",
      "Caiwen Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.15048",
    "title": "Class Incremental Learning via Likelihood Ratio Based Task Prediction",
    "abstract": " Title: Class Incremental Learning via Likelihood Ratio Based Task Prediction ",
    "url": "https://arxiv.org/abs/2309.15048",
    "authors": [
      "Haowei Lin",
      "Yijia Shao",
      "Weinan Qian",
      "Ningxin Pan",
      "Yiduo Guo",
      "Bing Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.15111",
    "title": "SGD Finds then Tunes Features in Two-Layer Neural Networks with  near-Optimal Sample Complexity: A Case Study in the XOR problem",
    "abstract": " Title: SGD Finds then Tunes Features in Two-Layer Neural Networks with  near-Optimal Sample Complexity: A Case Study in the XOR problem ",
    "url": "https://arxiv.org/abs/2309.15111",
    "authors": [
      "Margalit Glasgow"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.15641",
    "title": "Efficient Exact Subgraph Matching via GNN-based Path Dominance Embedding  (Technical Report)",
    "abstract": " Title: Efficient Exact Subgraph Matching via GNN-based Path Dominance Embedding  (Technical Report) ",
    "url": "https://arxiv.org/abs/2309.15641",
    "authors": [
      "Yutong Ye",
      "Xiang Lian",
      "Mingsong Chen"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2309.16298",
    "title": "At Which Training Stage Does Code Data Help LLMs Reasoning?",
    "abstract": " Title: At Which Training Stage Does Code Data Help LLMs Reasoning? ",
    "url": "https://arxiv.org/abs/2309.16298",
    "authors": [
      "Yingwei Ma",
      "Yue Liu",
      "Yue Yu",
      "Yuanliang Zhang",
      "Yu Jiang",
      "Changjian Wang",
      "Shanshan Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.16595",
    "title": "Can LLMs Effectively Leverage Graph Structural Information: When and Why",
    "abstract": " Title: Can LLMs Effectively Leverage Graph Structural Information: When and Why ",
    "url": "https://arxiv.org/abs/2309.16595",
    "authors": [
      "Jin Huang",
      "Xingjian Zhang",
      "Qiaozhu Mei",
      "Jiaqi Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.17053",
    "title": "On the Power of the Weisfeiler-Leman Test for Graph Motif Parameters",
    "abstract": " Title: On the Power of the Weisfeiler-Leman Test for Graph Motif Parameters ",
    "url": "https://arxiv.org/abs/2309.17053",
    "authors": [
      "Matthias Lanzinger",
      "Pablo Barcel\u00f3"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.17425",
    "title": "Data Filtering Networks",
    "abstract": " Title: Data Filtering Networks ",
    "url": "https://arxiv.org/abs/2309.17425",
    "authors": [
      "Alex Fang",
      "Albin Madappally Jose",
      "Amit Jain",
      "Ludwig Schmidt",
      "Alexander Toshev",
      "Vaishaal Shankar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.17437",
    "title": "Learning Decentralized Flocking Controllers with Spatio-Temporal Graph  Neural Network",
    "abstract": " Title: Learning Decentralized Flocking Controllers with Spatio-Temporal Graph  Neural Network ",
    "url": "https://arxiv.org/abs/2309.17437",
    "authors": [
      "Siji Chen",
      "Yanshen Sun",
      "Peihan Li",
      "Lifeng Zhou",
      "Chang-Tien Lu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]