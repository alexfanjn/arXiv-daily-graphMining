[
  {
    "id": "arXiv:2305.11881",
    "title": "Self-Supervised Learning for Point Clouds Data: A Survey",
    "abstract": "The 3D point cloud is a crucial type of data collected by LiDAR sensors and widely used in transportation-related fields due to its concise description and accurate localization. To better capture the hierarchical representation of the point cloud, deep neural networks (DNNs) are employed to process considerable disorder 3D points and accomplish promising achievements in various computer vision tasks such as pedestrian detection and vehicle recognition. However, point cloud labeling is time-consuming and labor-intensive due to the disordered and sparse attribute of the point cloud. Therefore, self-supervised learning (SSL), an unsupervised training paradigm that mines effective information from the data itself without human annotations, is considered an essential solution for moving away from label dependency via its brilliant pre-training task design. This paper provides a comprehensive survey of recent advances in deep neural network-based point cloud SSL. We initially introduce the definition, motivation, general pipeline as well as background to describe the concept of SSL and its combination with point cloud in detail. In addition, we present an innovative taxonomy of point cloud SSL methods, separating current approaches into four broad categories based on the pretexts' characteristics. We then summarize and compare the performances of the proposed SSL methods in literature on multiple downstream tasks quantitatively and qualitatively on benchmark datasets. Finally, feasible future research directions are provided to alleviate current limitations of point cloud SSL and also enhance feature extraction capability and generalizability of pre-training models. ",
    "url": "https://arxiv.org/abs/2305.11881",
    "authors": [
      "Changyu Zeng",
      "Wei Wang",
      "Anh Nguyen",
      "Yutao Yue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.11891",
    "title": "THRawS: A Novel Dataset for Thermal Hotspots Detection in Raw Sentinel-2  Data",
    "abstract": "Nowadays, most of the datasets leveraging space-borne Earth Observation (EO) data are based on high-end levels products, which are ortho-rectified, coregistered, calibrated, and further processed to mitigate the impact of noise and distortions. Nevertheless, given the growing interest to apply Artificial Intelligence (AI) onboard satellites for time-critical applications, such as natural disaster response, providing raw satellite images could be useful to foster the research on energy-efficient pre-processing algorithms and AI models for onboard-satellite applications. In this framework, we present THRawS, the first dataset composed of Sentinel-2 (S-2) raw data containing warm temperature hotspots (wildfires and volcanic eruptions). To foster the realisation of robust AI architectures, the dataset gathers data from all over the globe. Furthermore, we designed a custom methodology to identify events in raw data starting from the corresponding Level-1C (L1C) products. Indeed, given the availability of state-of-the-art algorithms for thermal anomalies detection on the L1C tiles, we detect such events on these latter and we then re-project them on the corresponding raw images. Additionally, to deal with unprocessed data, we devise a lightweight coarse coregisteration and georeferencing strategy. The developed dataset is comprehensive of more than 100 samples containing wildfires, volcanic eruptions, and event-free volcanic areas to enable both warm-events detection and general classification applications. Finally, we compare performances between the proposed coarse spatial coregistration technique and the SuperGlue Deep Neural Network method to highlight the different constraints in terms of timing and quality of spatial registration to minimise the spatial displacement error for a specific scene. ",
    "url": "https://arxiv.org/abs/2305.11891",
    "authors": [
      "Gabriele Meoni",
      "Roberto Del Prete",
      "Federico Serva",
      "Alix De Beussche",
      "Olivier Colin",
      "Nicolas Long\u00e9p\u00e9"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.11898",
    "title": "Neural information coding for efficient spike-based image denoising",
    "abstract": "In recent years, Deep Convolutional Neural Networks (DCNNs) have outreached the performance of classical algorithms for image restoration tasks. However most of these methods are not suited for computational efficiency and are therefore too expensive to be executed on embedded and mobile devices. In this work we investigate Spiking Neural Networks (SNNs) for Gaussian denoising, with the goal of approaching the performance of conventional DCNN while reducing the computational load. We propose a formal analysis of the information conversion processing carried out by the Leaky Integrate and Fire (LIF) neurons and we compare its performance with the classical rate-coding mechanism. The neural coding schemes are then evaluated through experiments in terms of denoising performance and computation efficiency for a state-of-the-art deep convolutional neural network. Our results show that SNNs with LIF neurons can provide competitive denoising performance but at a reduced computational cost. ",
    "url": "https://arxiv.org/abs/2305.11898",
    "authors": [
      "Andrea Castagnetti",
      "Alain Pegatoquet",
      "Beno\u00eet Miramond"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.11944",
    "title": "Exploring the Viability of Synthetic Query Generation for Relevance  Prediction",
    "abstract": "Query-document relevance prediction is a critical problem in Information Retrieval systems. This problem has increasingly been tackled using (pretrained) transformer-based models which are finetuned using large collections of labeled data. However, in specialized domains such as e-commerce and healthcare, the viability of this approach is limited by the dearth of large in-domain data. To address this paucity, recent methods leverage these powerful models to generate high-quality task and domain-specific synthetic data. Prior work has largely explored synthetic data generation or query generation (QGen) for Question-Answering (QA) and binary (yes/no) relevance prediction, where for instance, the QGen models are given a document, and trained to generate a query relevant to that document. However in many problems, we have a more fine-grained notion of relevance than a simple yes/no label. Thus, in this work, we conduct a detailed study into how QGen approaches can be leveraged for nuanced relevance prediction. We demonstrate that -- contrary to claims from prior works -- current QGen approaches fall short of the more conventional cross-domain transfer-learning approaches. Via empirical studies spanning 3 public e-commerce benchmarks, we identify new shortcomings of existing QGen approaches -- including their inability to distinguish between different grades of relevance. To address this, we introduce label-conditioned QGen models which incorporates knowledge about the different relevance. While our experiments demonstrate that these modifications help improve performance of QGen techniques, we also find that QGen approaches struggle to capture the full nuance of the relevance label space and as a result the generated queries are not faithful to the desired relevance label. ",
    "url": "https://arxiv.org/abs/2305.11944",
    "authors": [
      "Aditi Chaudhary",
      "Karthik Raman",
      "Krishna Srinivasan",
      "Kazuma Hashimoto",
      "Mike Bendersky",
      "Marc Najork"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.11957",
    "title": "Towards understanding neural collapse in supervised contrastive learning  with the information bottleneck method",
    "abstract": "Neural collapse describes the geometry of activation in the final layer of a deep neural network when it is trained beyond performance plateaus. Open questions include whether neural collapse leads to better generalization and, if so, why and how training beyond the plateau helps. We model neural collapse as an information bottleneck (IB) problem in order to investigate whether such a compact representation exists and discover its connection to generalization. We demonstrate that neural collapse leads to good generalization specifically when it approaches an optimal IB solution of the classification problem. Recent research has shown that two deep neural networks independently trained with the same contrastive loss objective are linearly identifiable, meaning that the resulting representations are equivalent up to a matrix transformation. We leverage linear identifiability to approximate an analytical solution of the IB problem. This approximation demonstrates that when class means exhibit $K$-simplex Equiangular Tight Frame (ETF) behavior (e.g., $K$=10 for CIFAR10 and $K$=100 for CIFAR100), they coincide with the critical phase transitions of the corresponding IB problem. The performance plateau occurs once the optimal solution for the IB problem includes all of these phase transitions. We also show that the resulting $K$-simplex ETF can be packed into a $K$-dimensional Gaussian distribution using supervised contrastive learning with a ResNet50 backbone. This geometry suggests that the $K$-simplex ETF learned by supervised contrastive learning approximates the optimal features for source coding. Hence, there is a direct correspondence between optimal IB solutions and generalization in contrastive learning. ",
    "url": "https://arxiv.org/abs/2305.11957",
    "authors": [
      "Siwei Wang",
      "Stephanie E Palmer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.11962",
    "title": "Spatial community structure impedes language amalgamation in a  population-based iterated learning model",
    "abstract": "The iterated learning model is an agent-based model of language evolution notable for demonstrating the emergence of compositional language. In its original form, it modelled language evolution along a single chain of teacher-pupil interactions; here we modify the model to allow more complex patterns of communication within a population and use the extended model to quantify the effect of within-community and between-community communication frequency on language development. We find that a small amount of between-community communication can lead to population-wide language convergence but that this global language amalgamation is more difficult to achieve when communities are spatially embedded. ",
    "url": "https://arxiv.org/abs/2305.11962",
    "authors": [
      "George Sains",
      "Conor Houghton",
      "Seth Bullock"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2305.11965",
    "title": "Not All Semantics are Created Equal: Contrastive Self-supervised  Learning with Automatic Temperature Individualization",
    "abstract": "In this paper, we aim to optimize a contrastive loss with individualized temperatures in a principled and systematic manner for self-supervised learning. The common practice of using a global temperature parameter $\\tau$ ignores the fact that ``not all semantics are created equal\", meaning that different anchor data may have different numbers of samples with similar semantics, especially when data exhibits long-tails. First, we propose a new robust contrastive loss inspired by distributionally robust optimization (DRO), providing us an intuition about the effect of $\\tau$ and a mechanism for automatic temperature individualization. Then, we propose an efficient stochastic algorithm for optimizing the robust contrastive loss with a provable convergence guarantee without using large mini-batch sizes. Theoretical and experimental results show that our algorithm automatically learns a suitable $\\tau$ for each sample. Specifically, samples with frequent semantics use large temperatures to keep local semantic structures, while samples with rare semantics use small temperatures to induce more separable features. Our method not only outperforms prior strong baselines (e.g., SimCLR, CLIP) on unimodal and bimodal datasets with larger improvements on imbalanced data but also is less sensitive to hyper-parameters. To our best knowledge, this is the first methodical approach to optimizing a contrastive loss with individualized temperatures. ",
    "url": "https://arxiv.org/abs/2305.11965",
    "authors": [
      "Zi-Hao Qiu",
      "Quanqi Hu",
      "Zhuoning Yuan",
      "Denny Zhou",
      "Lijun Zhang",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.11976",
    "title": "Unsupervised Change Point Detection for heterogeneous sensor signals",
    "abstract": "Change point detection is a crucial aspect of analyzing time series data, as the presence of a change point indicates an abrupt and significant change in the process generating the data. While many algorithms for the problem of change point detection have been developed over time, it can be challenging to select the appropriate algorithm for a specific problem. The choice of the algorithm heavily depends on the nature of the problem and the underlying data source. In this paper, we will exclusively examine unsupervised techniques due to their flexibility in the application to various data sources without the requirement for abundant annotated training data and the re-calibration of the model. The examined methods will be introduced and evaluated based on several criteria to compare the algorithms. ",
    "url": "https://arxiv.org/abs/2305.11976",
    "authors": [
      "Mario Krause"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.11996",
    "title": "EEG and EMG dataset for the detection of errors introduced by an active  orthosis device",
    "abstract": "This paper presents a dataset containing recordings of the electroencephalogram (EEG) and the electromyogram (EMG) from eight subjects who were assisted in moving their right arm by an active orthosis device. The supported movements were elbow joint movements, i.e., flexion and extension of the right arm. While the orthosis was actively moving the subject's arm, some errors were deliberately introduced for a short duration of time. During this time, the orthosis moved in the opposite direction. In this paper, we explain the experimental setup and present some behavioral analyses across all subjects. Additionally, we present an average event-related potential analysis for one subject to offer insights into the data quality and the EEG activity caused by the error introduction. The dataset described herein is openly accessible. The aim of this study was to provide a dataset to the research community, particularly for the development of new methods in the asynchronous detection of erroneous events from the EEG. We are especially interested in the tactile and haptic-mediated recognition of errors, which has not yet been sufficiently investigated in the literature. We hope that the detailed description of the orthosis and the experiment will enable its reproduction and facilitate a systematic investigation of the influencing factors in the detection of erroneous behavior of assistive systems by a large community. ",
    "url": "https://arxiv.org/abs/2305.11996",
    "authors": [
      "Niklas Kueper",
      "Kartik Chari",
      "Judith B\u00fctef\u00fcr",
      "Julia Habenicht",
      "Su Kyoung Kim",
      "Tobias Rossol",
      "Marc Tabie",
      "Frank Kirchner",
      "Elsa Andrea Kirchner"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.12030",
    "title": "Learning Continually on a Sequence of Graphs -- The Dynamical System Way",
    "abstract": "Continual learning~(CL) is a field concerned with learning a series of inter-related task with the tasks typically defined in the sense of either regression or classification. In recent years, CL has been studied extensively when these tasks are defined using Euclidean data-- data, such as images, that can be described by a set of vectors in an n-dimensional real space. However, the literature is quite sparse, when the data corresponding to a CL task is nonEuclidean-- data , such as graphs, point clouds or manifold, where the notion of similarity in the sense of Euclidean metric does not hold. For instance, a graph is described by a tuple of vertices and edges and similarities between two graphs is not well defined through a Euclidean metric. Due to this fundamental nature of the data, developing CL for nonEuclidean data presents several theoretical and methodological challenges. In particular, CL for graphs requires explicit modelling of nonstationary behavior of vertices and edges and their effects on the learning problem. Therefore, in this work, we develop a adaptive dynamic programming viewpoint for CL with graphs. In this work, we formulate a two-player sequential game between the act of learning new tasks~(generalization) and remembering previously learned tasks~(forgetting). We prove mathematically the existence of a solution to the game and demonstrate convergence to the solution of the game. Finally, we demonstrate the efficacy of our method on a number of graph benchmarks with a comprehensive ablation study while establishing state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2305.12030",
    "authors": [
      "Krishnan Raghavan",
      "Prasanna Balaprakash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2305.12039",
    "title": "Learning for Open-World Calibration with Graph Neural Networks",
    "abstract": "We tackle the problem of threshold calibration for open-world recognition by incorporating representation compactness measures into clustering. Unlike the open-set recognition which focuses on discovering and rejecting the unknown, open-world recognition learns robust representations that are generalizable to disjoint unknown classes at test time. Our proposed method is based on two key observations: (i) representation structures among neighbouring images in high dimensional visual embedding spaces have strong self-similarity which can be leveraged to encourage transferability to the open world, (ii) intra-class embedding structures can be modeled with the marginalized von Mises-Fisher (vMF) probability, whose correlation with the true positive rate is dataset-invariant. Motivated by these, we design a unified framework centered around a graph neural network (GNN) to jointly predict the pseudo-labels and the vMF concentrations which indicate the representation compactness. These predictions can be converted into statistical estimations for recognition accuracy, allowing more robust calibration of the distance threshold to achieve target utility for the open-world classes. Results on a variety of visual recognition benchmarks demonstrate the superiority of our method over traditional posthoc calibration methods for the open world, especially under distribution shift. ",
    "url": "https://arxiv.org/abs/2305.12039",
    "authors": [
      "Qin Zhang",
      "Dongsheng An",
      "Tianjun Xiao",
      "Tong He",
      "Qingming Tang",
      "Ying Nian Wu",
      "Joseph Tighe",
      "Yifan Xing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12050",
    "title": "CodeCompose: A Large-Scale Industrial Deployment of AI-assisted Code  Authoring",
    "abstract": "The rise of large language models (LLMs) has unlocked various applications of this technology in software development. In particular, generative LLMs have been shown to effectively power AI-based code authoring tools that can suggest entire statements or blocks of code during code authoring. In this paper we present CodeCompose, an AI-assisted code authoring tool developed and deployed at Meta internally. CodeCompose is based on the InCoder LLM that merges generative capabilities with bi-directionality. We have scaled up CodeCompose to serve tens of thousands of developers at Meta, across 10+ programming languages and several coding surfaces. We discuss unique challenges in terms of user experience and metrics that arise when deploying such tools in large-scale industrial settings. We present our experience in making design decisions about the model and system architecture for CodeCompose that addresses these challenges. Finally, we present metrics from our large-scale deployment of CodeCompose that shows its impact on Meta's internal code authoring experience over a 15-day time window, where 4.5 million suggestions were made by CodeCompose. Quantitative metrics reveal that (i) CodeCompose has an acceptance rate of 22% across several languages, and (ii) 8% of the code typed by users of CodeCompose is through accepting code suggestions from CodeCompose. Qualitative feedback indicates an overwhelming 91.5% positive reception for CodeCompose. In addition to assisting with code authoring, CodeCompose is also introducing other positive side effects such as encouraging developers to generate more in-code documentation, helping them with the discovery of new APIs, etc. ",
    "url": "https://arxiv.org/abs/2305.12050",
    "authors": [
      "Vijayaraghavan Murali",
      "Chandra Maddila",
      "Imad Ahmad",
      "Michael Bolin",
      "Daniel Cheng",
      "Negar Ghorbani",
      "Renuka Fernandez",
      "Nachiappan Nagappan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12058",
    "title": "DADIN: Domain Adversarial Deep Interest Network for Cross Domain  Recommender Systems",
    "abstract": "Click-Through Rate (CTR) prediction is one of the main tasks of the recommendation system, which is conducted by a user for different items to give the recommendation results. Cross-domain CTR prediction models have been proposed to overcome problems of data sparsity, long tail distribution of user-item interactions, and cold start of items or users. In order to make knowledge transfer from source domain to target domain more smoothly, an innovative deep learning cross-domain CTR prediction model, Domain Adversarial Deep Interest Network (DADIN) is proposed to convert the cross-domain recommendation task into a domain adaptation problem. The joint distribution alignment of two domains is innovatively realized by introducing domain agnostic layers and specially designed loss, and optimized together with CTR prediction loss in a way of adversarial training. It is found that the Area Under Curve (AUC) of DADIN is 0.08% higher than the most competitive baseline on Huawei dataset and is 0.71% higher than its competitors on Amazon dataset, achieving the state-of-the-art results on the basis of the evaluation of this model performance on two real datasets. The ablation study shows that by introducing adversarial method, this model has respectively led to the AUC improvements of 2.34% on Huawei dataset and 16.67% on Amazon dataset. ",
    "url": "https://arxiv.org/abs/2305.12058",
    "authors": [
      "Menglin Kong",
      "Muzhou Hou",
      "Shaojie Zhao",
      "Feng Liu",
      "Ri Su",
      "Yinghao Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12063",
    "title": "Efficient Multimodal Neural Networks for Trigger-less Voice Assistants",
    "abstract": "The adoption of multimodal interactions by Voice Assistants (VAs) is growing rapidly to enhance human-computer interactions. Smartwatches have now incorporated trigger-less methods of invoking VAs, such as Raise To Speak (RTS), where the user raises their watch and speaks to VAs without an explicit trigger. Current state-of-the-art RTS systems rely on heuristics and engineered Finite State Machines to fuse gesture and audio data for multimodal decision-making. However, these methods have limitations, including limited adaptability, scalability, and induced human biases. In this work, we propose a neural network based audio-gesture multimodal fusion system that (1) Better understands temporal correlation between audio and gesture data, leading to precise invocations (2) Generalizes to a wide range of environments and scenarios (3) Is lightweight and deployable on low-power devices, such as smartwatches, with quick launch times (4) Improves productivity in asset development processes. ",
    "url": "https://arxiv.org/abs/2305.12063",
    "authors": [
      "Sai Srujana Buddi",
      "Utkarsh Oggy Sarawgi",
      "Tashweena Heeramun",
      "Karan Sawnhey",
      "Ed Yanosik",
      "Saravana Rathinam",
      "Saurabh Adya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2305.12066",
    "title": "Dynamic Gradient Balancing for Enhanced Adversarial Attacks on  Multi-Task Models",
    "abstract": "Multi-task learning (MTL) creates a single machine learning model called multi-task model to simultaneously perform multiple tasks. Although the security of single task classifiers has been extensively studied, there are several critical security research questions for multi-task models including 1) How secure are multi-task models to single task adversarial machine learning attacks, 2) Can adversarial attacks be designed to attack multiple tasks simultaneously, and 3) Does task sharing and adversarial training increase multi-task model robustness to adversarial attacks? In this paper, we answer these questions through careful analysis and rigorous experimentation. First, we develop na\\\"ive adaptation of single-task white-box attacks and analyze their inherent drawbacks. We then propose a novel attack framework, Dynamic Gradient Balancing Attack (DGBA). Our framework poses the problem of attacking a multi-task model as an optimization problem based on averaged relative loss change, which can be solved by approximating the problem as an integer linear programming problem. Extensive evaluation on two popular MTL benchmarks, NYUv2 and Tiny-Taxonomy, demonstrates the effectiveness of DGBA compared to na\\\"ive multi-task attack baselines on both clean and adversarially trained multi-task models. The results also reveal a fundamental trade-off between improving task accuracy by sharing parameters across tasks and undermining model robustness due to increased attack transferability from parameter sharing. ",
    "url": "https://arxiv.org/abs/2305.12066",
    "authors": [
      "Lijun Zhang",
      "Xiao Liu",
      "Kaleel Mahmood",
      "Caiwen Ding",
      "Hui Guan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12074",
    "title": "DisCo: Distilled Student Models Co-training for Semi-supervised Text  Mining",
    "abstract": "Many text mining models are constructed by fine-tuning a large deep pre-trained language model (PLM) in downstream tasks. However, a significant challenge is maintaining performance when we use a lightweight model with limited labeled samples. We present DisCo, a semi-supervised learning (SSL) framework for fine-tuning a cohort of small student models generated from a large PLM using knowledge distillation. Our key insight is to share complementary knowledge among distilled student cohorts to promote their SSL effectiveness. DisCo employs a novel co-training technique to optimize multiple small student models by promoting knowledge sharing among students under diversified views: model views produced by different distillation strategies and data views produced by various input augmentations. We evaluate DisCo on both semi-supervised text classification and extractive summarization tasks. Experimental results show that DisCo can produce student models that are 7.6 times smaller and 4.8 times faster in inference than the baseline PLMs while maintaining comparable performance. We also show that DisCo-generated student models outperform the similar-sized models elaborately tuned in distinct tasks. ",
    "url": "https://arxiv.org/abs/2305.12074",
    "authors": [
      "Weifeng Jiang",
      "Qianren Mao",
      "Jianxin Li",
      "Chenghua Lin",
      "Weiyi Yang",
      "Ting Deng",
      "Zheng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12081",
    "title": "AnyPredict: Foundation Model for Tabular Prediction",
    "abstract": "Foundation models are pre-trained on massive data to perform well across many downstream tasks. They have demonstrated significant success in natural language processing and computer vision. Nonetheless, the use of such models in tabular prediction tasks has been limited, with the main hurdles consisting of (1) the lack of large-scale and diverse tabular datasets with standardized labels and (2) the schema mismatch and predictive target heterogeneity across domains. This paper proposes a method for building training data at scale for tabular prediction foundation models (AnyPredict) using both in-domain and a wide range of out-domain datasets. The method uses a data engine that leverages large language models (LLMs) to consolidate tabular samples to overcome the barrier across tables with varying schema and align out-domain data with the target task using a ``learn, annotate, and audit'' pipeline. The expanded training data enables the pre-trained AnyPredict to support every tabular dataset in the domain without fine-tuning, resulting in significant improvements over supervised baselines: it reaches an average ranking of 1.57 and 1.00 on 7 patient outcome prediction datasets and 3 trial outcome prediction datasets, respectively. In addition, AnyPredict exhibits impressive zero-shot performances: it outperforms supervised XGBoost models by 8.9% and 17.2% on average in two prediction tasks, respectively. ",
    "url": "https://arxiv.org/abs/2305.12081",
    "authors": [
      "Zifeng Wang",
      "Chufan Gao",
      "Cao Xiao",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12082",
    "title": "SneakyPrompt: Evaluating Robustness of Text-to-image Generative Models'  Safety Filters",
    "abstract": "Text-to-image generative models such as Stable Diffusion and DALL$\\cdot$E 2 have attracted much attention since their publication due to their wide application in the real world. One challenging problem of text-to-image generative models is the generation of Not-Safe-for-Work (NSFW) content, e.g., those related to violence and adult. Therefore, a common practice is to deploy a so-called safety filter, which blocks NSFW content based on either text or image features. Prior works have studied the possible bypass of such safety filters. However, existing works are largely manual and specific to Stable Diffusion's official safety filter. Moreover, the bypass ratio of Stable Diffusion's safety filter is as low as 23.51% based on our evaluation. In this paper, we propose the first automated attack framework, called SneakyPrompt, to evaluate the robustness of real-world safety filters in state-of-the-art text-to-image generative models. Our key insight is to search for alternative tokens in a prompt that generates NSFW images so that the generated prompt (called an adversarial prompt) bypasses existing safety filters. Specifically, SneakyPrompt utilizes reinforcement learning (RL) to guide an agent with positive rewards on semantic similarity and bypass success. Our evaluation shows that SneakyPrompt successfully generated NSFW content using an online model DALL$\\cdot$E 2 with its default, closed-box safety filter enabled. At the same time, we also deploy several open-source state-of-the-art safety filters on a Stable Diffusion model and show that SneakyPrompt not only successfully generates NSFW content, but also outperforms existing adversarial attacks in terms of the number of queries and image qualities. ",
    "url": "https://arxiv.org/abs/2305.12082",
    "authors": [
      "Yuchen Yang",
      "Bo Hui",
      "Haolin Yuan",
      "Neil Gong",
      "Yinzhi Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12087",
    "title": "Semi-Supervised Graph Imbalanced Regression",
    "abstract": "Data imbalance is easily found in annotated data when the observations of certain continuous label values are difficult to collect for regression tasks. When they come to molecule and polymer property predictions, the annotated graph datasets are often small because labeling them requires expensive equipment and effort. To address the lack of examples of rare label values in graph regression tasks, we propose a semi-supervised framework to progressively balance training data and reduce model bias via self-training. The training data balance is achieved by (1) pseudo-labeling more graphs for under-represented labels with a novel regression confidence measurement and (2) augmenting graph examples in latent space for remaining rare labels after data balancing with pseudo-labels. The former is to identify quality examples from unlabeled data whose labels are confidently predicted and sample a subset of them with a reverse distribution from the imbalanced annotated data. The latter collaborates with the former to target a perfect balance using a novel label-anchored mixup algorithm. We perform experiments in seven regression tasks on graph datasets. Results demonstrate that the proposed framework significantly reduces the error of predicted graph properties, especially in under-represented label areas. ",
    "url": "https://arxiv.org/abs/2305.12087",
    "authors": [
      "Gang Liu",
      "Tong Zhao",
      "Eric Inae",
      "Tengfei Luo",
      "Meng Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12095",
    "title": "Make Transformer Great Again for Time Series Forecasting: Channel  Aligned Robust Dual Transformer",
    "abstract": "Recent studies have demonstrated the great power of deep learning methods, particularly Transformer and MLP, for time series forecasting. Despite its success in NLP and CV, many studies found that Transformer is less effective than MLP for time series forecasting. In this work, we design a special Transformer, i.e., channel-aligned robust dual Transformer (CARD for short), that addresses key shortcomings of Transformer in time series forecasting. First, CARD introduces a dual Transformer structure that allows it to capture both temporal correlations among signals and dynamical dependence among multiple variables over time. Second, we introduce a robust loss function for time series forecasting to alleviate the potential overfitting issue. This new loss function weights the importance of forecasting over a finite horizon based on prediction uncertainties. Our evaluation of multiple long-term and short-term forecasting datasets demonstrates that CARD significantly outperforms state-of-the-art time series forecasting methods, including both Transformer and MLP-based models. ",
    "url": "https://arxiv.org/abs/2305.12095",
    "authors": [
      "Wang Xue",
      "Tian Zhou",
      "QingSong Wen",
      "Jinyang Gao",
      "Bolin Ding",
      "Rong Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12099",
    "title": "Soft Actor-Critic Learning-Based Joint Computing, Pushing, and Caching  Framework in MEC Networks",
    "abstract": "To support future 6G mobile applications, the mobile edge computing (MEC) network needs to be jointly optimized for computing, pushing, and caching to reduce transmission load and computation cost. To achieve this, we propose a framework based on deep reinforcement learning that enables the dynamic orchestration of these three activities for the MEC network. The framework can implicitly predict user future requests using deep networks and push or cache the appropriate content to enhance performance. To address the curse of dimensionality resulting from considering three activities collectively, we adopt the soft actor-critic reinforcement learning in continuous space and design the action quantization and correction specifically to fit the discrete optimization problem. We conduct simulations in a single-user single-server MEC network setting and demonstrate that the proposed framework effectively decreases both transmission load and computing cost under various configurations of cache size and tolerable service delay. ",
    "url": "https://arxiv.org/abs/2305.12099",
    "authors": [
      "Xiangyu Gao",
      "Yaping Sun",
      "Hao Chen",
      "Xiaodong Xu",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.12109",
    "title": "Meta Neural Coordination",
    "abstract": "Meta-learning aims to develop algorithms that can learn from other learning algorithms to adapt to new and changing environments. This requires a model of how other learning algorithms operate and perform in different contexts, which is similar to representing and reasoning about mental states in the theory of mind. Furthermore, the problem of uncertainty in the predictions of conventional deep neural networks highlights the partial predictability of the world, requiring the representation of multiple predictions simultaneously. This is facilitated by coordination among neural modules, where different modules' beliefs and desires are attributed to others. The neural coordination among modular and decentralized neural networks is a fundamental prerequisite for building autonomous intelligence machines that can interact flexibly and adaptively. In this work, several pieces of evidence demonstrate a new avenue for tackling the problems above, termed Meta Neural Coordination. We discuss the potential advancements required to build biologically-inspired machine intelligence, drawing from both machine learning and cognitive science communities. ",
    "url": "https://arxiv.org/abs/2305.12109",
    "authors": [
      "Yuwei Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12118",
    "title": "Annealing Self-Distillation Rectification Improves Adversarial Training",
    "abstract": "In standard adversarial training, models are optimized to fit one-hot labels within allowable adversarial perturbation budgets. However, the ignorance of underlying distribution shifts brought by perturbations causes the problem of robust overfitting. To address this issue and enhance adversarial robustness, we analyze the characteristics of robust models and identify that robust models tend to produce smoother and well-calibrated outputs. Based on the observation, we propose a simple yet effective method, Annealing Self-Distillation Rectification (ADR), which generates soft labels as a better guidance mechanism that accurately reflects the distribution shift under attack during adversarial training. By utilizing ADR, we can obtain rectified distributions that significantly improve model robustness without the need for pre-trained models or extensive extra computation. Moreover, our method facilitates seamless plug-and-play integration with other adversarial training techniques by replacing the hard labels in their objectives. We demonstrate the efficacy of ADR through extensive experiments and strong performances across datasets. ",
    "url": "https://arxiv.org/abs/2305.12118",
    "authors": [
      "Yu-Yu Wu",
      "Hung-Jui Wang",
      "Shang-Tse Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12123",
    "title": "Modeling the Q-Diversity in a Min-max Play Game for Robust Optimization",
    "abstract": "Models trained with empirical risk minimization (ERM) are revealed to easily rely on spurious correlations, resulting in poor generalization. Group distributionally robust optimization (group DRO) can alleviate this problem by minimizing the worst-case loss over pre-defined groups. While promising, in practice factors like expensive annotations and privacy preclude the availability of group labels. More crucially, when taking a closer look at the failure modes of out-of-distribution generalization, the typical procedure of reweighting in group DRO loses efficiency. Hinged on the limitations, in this work, we reformulate the group DRO framework by proposing Q-Diversity. Characterized by an interactive training mode, Q-Diversity relaxes the group identification from annotation into direct parameterization. Furthermore, a novel mixing strategy across groups is presented to diversify the under-represented groups. In a series of experiments on both synthetic and real-world text classification tasks, results demonstrate that Q-Diversity can consistently improve worst-case accuracy under different distributional shifts, outperforming state-of-the-art alternatives. ",
    "url": "https://arxiv.org/abs/2305.12123",
    "authors": [
      "Ting Wu",
      "Rui Zheng",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12125",
    "title": "A Framework for Provably Stable and Consistent Training of Deep  Feedforward Networks",
    "abstract": "We present a novel algorithm for training deep neural networks in supervised (classification and regression) and unsupervised (reinforcement learning) scenarios. This algorithm combines the standard stochastic gradient descent and the gradient clipping method. The output layer is updated using clipped gradients, the rest of the neural network is updated using standard gradients. Updating the output layer using clipped gradient stabilizes it. We show that the remaining layers are automatically stabilized provided the neural network is only composed of squashing (compact range) activations. We also present a novel squashing activation function - it is obtained by modifying a Gaussian Error Linear Unit (GELU) to have compact range - we call it Truncated GELU (tGELU). Unlike other squashing activations, such as sigmoid, the range of tGELU can be explicitly specified. As a consequence, the problem of vanishing gradients that arise due to a small range, e.g., in the case of a sigmoid activation, is eliminated. We prove that a NN composed of squashing activations (tGELU, sigmoid, etc.), when updated using the algorithm presented herein, is numerically stable and has consistent performance (low variance). The theory is supported by extensive experiments. Within reinforcement learning, as a consequence of our study, we show that target networks in Deep Q-Learning can be omitted, greatly speeding up learning and alleviating memory requirements. Cross-entropy based classification algorithms that suffer from high variance issues are more consistent when trained using our framework. One symptom of numerical instability in training is the high variance of the neural network update values. We show, in theory and through experiments, that our algorithm updates have low variance, and the training loss reduces in a smooth manner. ",
    "url": "https://arxiv.org/abs/2305.12125",
    "authors": [
      "Arunselvan Ramaswamy",
      "Shalabh Bhatnagar",
      "Naman Saxena"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12133",
    "title": "Loss Spike in Training Neural Networks",
    "abstract": "In this work, we study the mechanism underlying loss spikes observed during neural network training. When the training enters a region, which has a smaller-loss-as-sharper (SLAS) structure, the training becomes unstable and loss exponentially increases once it is too sharp, i.e., the rapid ascent of the loss spike. The training becomes stable when it finds a flat region. The deviation in the first eigen direction (with maximum eigenvalue of the loss Hessian ($\\lambda_{\\mathrm{max}}$) is found to be dominated by low-frequency. Since low-frequency is captured very fast (frequency principle), the rapid descent is then observed. Inspired by our analysis of loss spikes, we revisit the link between $\\lambda_{\\mathrm{max}}$ flatness and generalization. For real datasets, low-frequency is often dominant and well-captured by both the training data and the test data. Then, a solution with good generalization and a solution with bad generalization can both learn low-frequency well, thus, they have little difference in the sharpest direction. Therefore, although $\\lambda_{\\mathrm{max}}$ can indicate the sharpness of the loss landscape, deviation in its corresponding eigen direction is not responsible for the generalization difference. We also find that loss spikes can facilitate condensation, i.e., input weights evolve towards the same, which may be the underlying mechanism for why the loss spike improves generalization, rather than simply controlling the value of $\\lambda_{\\mathrm{max}}$. ",
    "url": "https://arxiv.org/abs/2305.12133",
    "authors": [
      "Zhongwang Zhang",
      "Zhi-Qin John Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12134",
    "title": "Privacy in Multimodal Federated Human Activity Recognition",
    "abstract": "Human Activity Recognition (HAR) training data is often privacy-sensitive or held by non-cooperative entities. Federated Learning (FL) addresses such concerns by training ML models on edge clients. This work studies the impact of privacy in federated HAR at a user, environment, and sensor level. We show that the performance of FL for HAR depends on the assumed privacy level of the FL system and primarily upon the colocation of data from different sensors. By avoiding data sharing and assuming privacy at the human or environment level, as prior works have done, the accuracy decreases by 5-7%. However, extending this to the modality level and strictly separating sensor data between multiple clients may decrease the accuracy by 19-42%. As this form of privacy is necessary for the ethical utilisation of passive sensing methods in HAR, we implement a system where clients mutually train both a general FL model and a group-level one per modality. Our evaluation shows that this method leads to only a 7-13% decrease in accuracy, making it possible to build HAR systems with diverse hardware. ",
    "url": "https://arxiv.org/abs/2305.12134",
    "authors": [
      "Alex Iacob",
      "Pedro P. B. Gusm\u00e3o",
      "Nicholas D. Lane",
      "Armand K. Koupai",
      "Mohammud J. Bocus",
      "Ra\u00fal Santos-Rodr\u00edguez",
      "Robert J. Piechocki",
      "Ryan McConville"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12139",
    "title": "A Unifying Passivity-Based Framework for Pressure and Volume Flow Rate  Control in District Heating Networks",
    "abstract": "A fundamental precondition for the secure and efficient operation of district heating networks (DHNs) is a stable hydraulic behavior. However, the ongoing transition towards a sustainable heat supply, especially the rising integration of distributed heat sources and the increasingly meshed topologies, introduce complex and potentially destabilizing hydraulic dynamics. In this work, we propose a unifying, passivity-based framework which guarantees asymptotic stability of any forced hydraulic DHN equilibrium while allowing for meshed, time-varying topologies and different, dynamically interacting distributed heat sources. To establish the desired hydraulic equilibria, we propose decentralized, passivity-based pressure and volume flow rate controllers for the pumps and valves in the actuated DHN subsystems. In particular, we leverage the equilibrium-independent passivity (EIP) properties of the DHN subsystems, the skew-symmetric nature of their interconnections, and LaSalle's Invariance principle to assess asymptotic stability in a modular manner. The obtained results hold for the state-of-the-art as well as future DHN generations featuring, for example, multiple distributed heat sources, asymmetric pipe networks, and multiple temperature layers. We verify our findings by means of simulations. ",
    "url": "https://arxiv.org/abs/2305.12139",
    "authors": [
      "Felix Strehle",
      "Juan E. Machado",
      "Michele Cucuzzella",
      "Albertus J. Malan",
      "Jacquelien M.A. Scherpen",
      "S\u00f6ren Hohmann"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.12148",
    "title": "Probabilistic Modeling: Proving the Lottery Ticket Hypothesis in Spiking  Neural Network",
    "abstract": "The Lottery Ticket Hypothesis (LTH) states that a randomly-initialized large neural network contains a small sub-network (i.e., winning tickets) which, when trained in isolation, can achieve comparable performance to the large network. LTH opens up a new path for network pruning. Existing proofs of LTH in Artificial Neural Networks (ANNs) are based on continuous activation functions, such as ReLU, which satisfying the Lipschitz condition. However, these theoretical methods are not applicable in Spiking Neural Networks (SNNs) due to the discontinuous of spiking function. We argue that it is possible to extend the scope of LTH by eliminating Lipschitz condition. Specifically, we propose a novel probabilistic modeling approach for spiking neurons with complicated spatio-temporal dynamics. Then we theoretically and experimentally prove that LTH holds in SNNs. According to our theorem, we conclude that pruning directly in accordance with the weight size in existing SNNs is clearly not optimal. We further design a new criterion for pruning based on our theory, which achieves better pruning results than baseline. ",
    "url": "https://arxiv.org/abs/2305.12148",
    "authors": [
      "Man Yao",
      "Yuhong Chou",
      "Guangshe Zhao",
      "Xiawu Zheng",
      "Yonghong Tian",
      "Bo Xu",
      "Guoqi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12162",
    "title": "A Scalable Neural Network for DSIC Affine Maximizer Auction Design",
    "abstract": "Automated auction design aims to find empirically high-revenue mechanisms through machine learning. Existing works on multi item auction scenarios can be roughly divided into RegretNet-like and affine maximizer auctions (AMAs) approaches. However, the former cannot strictly ensure dominant strategy incentive compatibility (DSIC), while the latter faces scalability issue due to the large number of allocation candidates. To address these limitations, we propose AMenuNet, a scalable neural network that constructs the AMA parameters (even including the allocation menu) from bidder and item representations. AMenuNet is always DSIC and individually rational (IR) due to the properties of AMAs, and it enhances scalability by generating candidate allocations through a neural network. Additionally, AMenuNet is permutation equivariant, and its number of parameters is independent of auction scale. We conduct extensive experiments to demonstrate that AMenuNet outperforms strong baselines in both contextual and non-contextual multi-item auctions, scales well to larger auctions, generalizes well to different settings, and identifies useful deterministic allocations. Overall, our proposed approach offers an effective solution to automated DSIC auction design, with improved scalability and strong revenue performance in various settings. ",
    "url": "https://arxiv.org/abs/2305.12162",
    "authors": [
      "Zhijian Duan",
      "Haoran Sun",
      "Yurong Chen",
      "Xiaotie Deng"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2305.12178",
    "title": "Model Debiasing via Gradient-based Explanation on Representation",
    "abstract": "Machine learning systems produce biased results towards certain demographic groups, known as the fairness problem. Recent approaches to tackle this problem learn a latent code (i.e., representation) through disentangled representation learning and then discard the latent code dimensions correlated with sensitive attributes (e.g., gender). Nevertheless, these approaches may suffer from incomplete disentanglement and overlook proxy attributes (proxies for sensitive attributes) when processing real-world data, especially for unstructured data, causing performance degradation in fairness and loss of useful information for downstream tasks. In this paper, we propose a novel fairness framework that performs debiasing with regard to both sensitive attributes and proxy attributes, which boosts the prediction performance of downstream task models without complete disentanglement. The main idea is to, first, leverage gradient-based explanation to find two model focuses, 1) one focus for predicting sensitive attributes and 2) the other focus for predicting downstream task labels, and second, use them to perturb the latent code that guides the training of downstream task models towards fairness and utility goals. We show empirically that our framework works with both disentangled and non-disentangled representation learning methods and achieves better fairness-accuracy trade-off on unstructured and structured datasets than previous state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2305.12178",
    "authors": [
      "Jindi Zhang",
      "Luning Wang",
      "Dan Su",
      "Yongxiang Huang",
      "Caleb Chen Cao",
      "Lei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2305.12209",
    "title": "Self-Distillation with Meta Learning for Knowledge Graph Completion",
    "abstract": "In this paper, we propose a selfdistillation framework with meta learning(MetaSD) for knowledge graph completion with dynamic pruning, which aims to learn compressed graph embeddings and tackle the longtail samples. Specifically, we first propose a dynamic pruning technique to obtain a small pruned model from a large source model, where the pruning mask of the pruned model could be updated adaptively per epoch after the model weights are updated. The pruned model is supposed to be more sensitive to difficult to memorize samples(e.g., longtail samples) than the source model. Then, we propose a onestep meta selfdistillation method for distilling comprehensive knowledge from the source model to the pruned model, where the two models coevolve in a dynamic manner during training. In particular, we exploit the performance of the pruned model, which is trained alongside the source model in one iteration, to improve the source models knowledge transfer ability for the next iteration via meta learning. Extensive experiments show that MetaSD achieves competitive performance compared to strong baselines, while being 10x smaller than baselines. ",
    "url": "https://arxiv.org/abs/2305.12209",
    "authors": [
      "Yunshui Li",
      "Junhao Liu",
      "Chengming Li",
      "Min Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12220",
    "title": "A Novel Framework for Improving the Breakdown Point of Robust Regression  Algorithms",
    "abstract": "We present an effective framework for improving the breakdown point of robust regression algorithms. Robust regression has attracted widespread attention due to the ubiquity of outliers, which significantly affect the estimation results. However, many existing robust least-squares regression algorithms suffer from a low breakdown point, as they become stuck around local optima when facing severe attacks. By expanding on the previous work, we propose a novel framework that enhances the breakdown point of these algorithms by inserting a prior distribution in each iteration step, and adjusting the prior distribution according to historical information. We apply this framework to a specific algorithm and derive the consistent robust regression algorithm with iterative local search (CORALS). The relationship between CORALS and momentum gradient descent is described, and a detailed proof of the theoretical convergence of CORALS is presented. Finally, we demonstrate that the breakdown point of CORALS is indeed higher than that of the algorithm from which it is derived. We apply the proposed framework to other robust algorithms, and show that the improved algorithms achieve better results than the original algorithms, indicating the effectiveness of the proposed framework. ",
    "url": "https://arxiv.org/abs/2305.12220",
    "authors": [
      "Zheyi Fan",
      "Szu Hui Ng",
      "Qingpei Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2305.12236",
    "title": "Embracing Compact and Robust Architectures for Multi-Exposure Image  Fusion",
    "abstract": "In recent years, deep learning-based methods have achieved remarkable progress in multi-exposure image fusion. However, existing methods rely on aligned image pairs, inevitably generating artifacts when faced with device shaking in real-world scenarios. Moreover, these learning-based methods are built on handcrafted architectures and operations by increasing network depth or width, neglecting different exposure characteristics. As a result, these direct cascaded architectures with redundant parameters fail to achieve highly effective inference time and lead to massive computation. To alleviate these issues, in this paper, we propose a search-based paradigm, involving self-alignment and detail repletion modules for robust multi-exposure image fusion. By utilizing scene relighting and deformable convolutions, the self-alignment module can accurately align images despite camera movement. Furthermore, by imposing a hardware-sensitive constraint, we introduce neural architecture search to discover compact and efficient networks, investigating effective feature representation for fusion. We realize the state-of-the-art performance in comparison to various competitive schemes, yielding a 4.02% and 29.34% improvement in PSNR for general and misaligned scenarios, respectively, while reducing inference time by 68.1%. The source code will be available at https://github.com/LiuZhu-CV/CRMEF. ",
    "url": "https://arxiv.org/abs/2305.12236",
    "authors": [
      "Zhu Liu",
      "Jinyuan Liu",
      "Guanyao Wu",
      "Xin Fan",
      "Risheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12240",
    "title": "Bridging Active Exploration and Uncertainty-Aware Deployment Using  Probabilistic Ensemble Neural Network Dynamics",
    "abstract": "In recent years, learning-based control in robotics has gained significant attention due to its capability to address complex tasks in real-world environments. With the advances in machine learning algorithms and computational capabilities, this approach is becoming increasingly important for solving challenging control problems in robotics by learning unknown or partially known robot dynamics. Active exploration, in which a robot directs itself to states that yield the highest information gain, is essential for efficient data collection and minimizing human supervision. Similarly, uncertainty-aware deployment has been a growing concern in robotic control, as uncertain actions informed by the learned model can lead to unstable motions or failure. However, active exploration and uncertainty-aware deployment have been studied independently, and there is limited literature that seamlessly integrates them. This paper presents a unified model-based reinforcement learning framework that bridges these two tasks in the robotics control domain. Our framework uses a probabilistic ensemble neural network for dynamics learning, allowing the quantification of epistemic uncertainty via Jensen-Renyi Divergence. The two opposing tasks of exploration and deployment are optimized through state-of-the-art sampling-based MPC, resulting in efficient collection of training data and successful avoidance of uncertain state-action spaces. We conduct experiments on both autonomous vehicles and wheeled robots, showing promising results for both exploration and deployment. ",
    "url": "https://arxiv.org/abs/2305.12240",
    "authors": [
      "Taekyung Kim",
      "Jungwi Mun",
      "Junwon Seo",
      "Beomsu Kim",
      "Seongil Hong"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12252",
    "title": "Boosting Human-Object Interaction Detection with Text-to-Image Diffusion  Model",
    "abstract": "This paper investigates the problem of the current HOI detection methods and introduces DiffHOI, a novel HOI detection scheme grounded on a pre-trained text-image diffusion model, which enhances the detector's performance via improved data diversity and HOI representation. We demonstrate that the internal representation space of a frozen text-to-image diffusion model is highly relevant to verb concepts and their corresponding context. Accordingly, we propose an adapter-style tuning method to extract the various semantic associated representation from a frozen diffusion model and CLIP model to enhance the human and object representations from the pre-trained detector, further reducing the ambiguity in interaction prediction. Moreover, to fill in the gaps of HOI datasets, we propose SynHOI, a class-balance, large-scale, and high-diversity synthetic dataset containing over 140K HOI images with fully triplet annotations. It is built using an automatic and scalable pipeline designed to scale up the generation of diverse and high-precision HOI-annotated data. SynHOI could effectively relieve the long-tail issue in existing datasets and facilitate learning interaction representations. Extensive experiments demonstrate that DiffHOI significantly outperforms the state-of-the-art in regular detection (i.e., 41.50 mAP) and zero-shot detection. Furthermore, SynHOI can improve the performance of model-agnostic and backbone-agnostic HOI detection, particularly exhibiting an outstanding 11.55% mAP improvement in rare classes. ",
    "url": "https://arxiv.org/abs/2305.12252",
    "authors": [
      "Jie Yang",
      "Bingliang Li",
      "Fengyu Yang",
      "Ailing Zeng",
      "Lei Zhang",
      "Ruimao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12256",
    "title": "Scene Graph as Pivoting: Inference-time Image-free Unsupervised  Multimodal Machine Translation with Visual Scene Hallucination",
    "abstract": "In this work, we investigate a more realistic unsupervised multimodal machine translation (UMMT) setup, inference-time image-free UMMT, where the model is trained with source-text image pairs, and tested with only source-text inputs. First, we represent the input images and texts with the visual and language scene graphs (SG), where such fine-grained vision-language features ensure a holistic understanding of the semantics. To enable pure-text input during inference, we devise a visual scene hallucination mechanism that dynamically generates pseudo visual SG from the given textual SG. Several SG-pivoting based learning objectives are introduced for unsupervised translation training. On the benchmark Multi30K data, our SG-based method outperforms the best-performing baseline by significant BLEU scores on the task and setup, helping yield translations with better completeness, relevance and fluency without relying on paired images. Further in-depth analyses reveal how our model advances in the task setting. ",
    "url": "https://arxiv.org/abs/2305.12256",
    "authors": [
      "Hao Fei",
      "Qian Liu",
      "Meishan Zhang",
      "Min Zhang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12263",
    "title": "Self-supervised representations in speech-based depression detection",
    "abstract": "This paper proposes handling training data sparsity in speech-based automatic depression detection (SDD) using foundation models pre-trained with self-supervised learning (SSL). An analysis of SSL representations derived from different layers of pre-trained foundation models is first presented for SDD, which provides insight to suitable indicator for depression detection. Knowledge transfer is then performed from automatic speech recognition (ASR) and emotion recognition to SDD by fine-tuning the foundation models. Results show that the uses of oracle and ASR transcriptions yield similar SDD performance when the hidden representations of the ASR model is incorporated along with the ASR textual information. By integrating representations from multiple foundation models, state-of-the-art SDD results based on real ASR were achieved on the DAIC-WOZ dataset. ",
    "url": "https://arxiv.org/abs/2305.12263",
    "authors": [
      "Wen Wu",
      "Chao Zhang",
      "Philip C. Woodland"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.12265",
    "title": "Tweetorial Hooks: Generative AI Tools to Motivate Science on Social  Media",
    "abstract": "Communicating science and technology is essential for the public to understand and engage in a rapidly changing world. Tweetorials are an emerging phenomenon where experts explain STEM topics on social media in creative and engaging ways. However, STEM experts struggle to write an engaging \"hook\" in the first tweet that captures the reader's attention. We propose methods to use large language models (LLMs) to help users scaffold their process of writing a relatable hook for complex scientific topics. We demonstrate that LLMs can help writers find everyday experiences that are relatable and interesting to the public, avoid jargon, and spark curiosity. Our evaluation shows that the system reduces cognitive load and helps people write better hooks. Lastly, we discuss the importance of interactivity with LLMs to preserve the correctness, effectiveness, and authenticity of the writing. ",
    "url": "https://arxiv.org/abs/2305.12265",
    "authors": [
      "Tao Long",
      "Dorothy Zhang",
      "Grace Li",
      "Batool Taraif",
      "Samia Menon",
      "Kynnedy Simone Smith",
      "Sitong Wang",
      "Katy Ilonka Gero",
      "Lydia B. Chilton"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2305.12266",
    "title": "LightESD: Fully-Automated and Lightweight Anomaly Detection Framework  for Edge Computing",
    "abstract": "Anomaly detection is widely used in a broad range of domains from cybersecurity to manufacturing, finance, and so on. Deep learning based anomaly detection has recently drawn much attention because of its superior capability of recognizing complex data patterns and identifying outliers accurately. However, deep learning models are typically iteratively optimized in a central server with input data gathered from edge devices, and such data transfer between edge devices and the central server impose substantial overhead on the network and incur additional latency and energy consumption. To overcome this problem, we propose a fully-automated, lightweight, statistical learning based anomaly detection framework called LightESD. It is an on-device learning method without the need for data transfer between edge and server, and is extremely lightweight that most low-end edge devices can easily afford with negligible delay, CPU/memory utilization, and power consumption. Yet, it achieves highly competitive detection accuracy. Another salient feature is that it can auto-adapt to probably any dataset without manually setting or configuring model parameters or hyperparameters, which is a drawback of most existing methods. We focus on time series data due to its pervasiveness in edge applications such as IoT. Our evaluation demonstrates that LightESD outperforms other SOTA methods on detection accuracy, efficiency, and resource consumption. Additionally, its fully automated feature gives it another competitive advantage in terms of practical usability and generalizability. ",
    "url": "https://arxiv.org/abs/2305.12266",
    "authors": [
      "Ronit Das",
      "Tie Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.12268",
    "title": "Patton: Language Model Pretraining on Text-Rich Networks",
    "abstract": "A real-world text corpus sometimes comprises not only text documents but also semantic links between them (e.g., academic papers in a bibliographic network are linked by citations and co-authorships). Text documents and semantic connections form a text-rich network, which empowers a wide range of downstream tasks such as classification and retrieval. However, pretraining methods for such structures are still lacking, making it difficult to build one generic model that can be adapted to various tasks on text-rich networks. Current pretraining objectives, such as masked language modeling, purely model texts and do not take inter-document structure information into consideration. To this end, we propose our PretrAining on TexT-Rich NetwOrk framework Patton. Patton includes two pretraining strategies: network-contextualized masked language modeling and masked node prediction, to capture the inherent dependency between textual attributes and network structure. We conduct experiments on four downstream tasks in five datasets from both academic and e-commerce domains, where Patton outperforms baselines significantly and consistently. ",
    "url": "https://arxiv.org/abs/2305.12268",
    "authors": [
      "Bowen Jin",
      "Wentao Zhang",
      "Yu Zhang",
      "Yu Meng",
      "Xinyang Zhang",
      "Qi Zhu",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12286",
    "title": "Low-Earth Satellite Orbit Determination Using Deep Convolutional  Networks with Satellite Imagery",
    "abstract": "It is increasingly common for satellites to lose connection with the ground stations on Earth with which they communicate, due to signal interruptions from the Earth's ionosphere and magnetosphere. Given the important roles that satellites play in national defense, public safety, and worldwide communications, finding ways to determine satellite trajectories in such situations is a crucially important task. In this paper, we demonstrate the efficacy of a novel computer vision based approach, which relies on earth imagery taken by the satellite itself, to determine the orbit of a satellite that has lost contact with its ground stations. We empirically observe significant improvements by more than an order of magnitude, over the present state of the art approach, namely, the Gibbs method for an initial orbit estimate with the Kalman filter for differential error correction. We further investigate the performance of the approach by comparing various neural networks, namely, ResNet50, ResNet101, VGG19, VGG16, AlexNet, and CoAtNet4. ",
    "url": "https://arxiv.org/abs/2305.12286",
    "authors": [
      "Rohit Khorana"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.12289",
    "title": "Revisiting the Architectures like Pointer Networks to Efficiently  Improve the Next Word Distribution, Summarization Factuality, and Beyond",
    "abstract": "Is the output softmax layer, which is adopted by most language models (LMs), always the best way to compute the next word probability? Given so many attention layers in a modern transformer-based LM, are the pointer networks redundant nowadays? In this study, we discover that the answers to both questions are no. This is because the softmax bottleneck sometimes prevents the LMs from predicting the desired distribution and the pointer networks can be used to break the bottleneck efficiently. Based on the finding, we propose several softmax alternatives by simplifying the pointer networks and accelerating the word-by-word rerankers. In GPT-2, our proposals are significantly better and more efficient than mixture of softmax, a state-of-the-art softmax alternative. In summarization experiments, without significantly decreasing its training/testing speed, our best method based on T5-Small improves factCC score by 2 points in CNN/DM and XSUM dataset, and improves MAUVE scores by 30% in BookSum paragraph-level dataset. ",
    "url": "https://arxiv.org/abs/2305.12289",
    "authors": [
      "Haw-Shiuan Chang",
      "Zonghai Yao",
      "Alolika Gon",
      "Hong Yu",
      "Andrew McCallum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12314",
    "title": "Random Walk Sampling in Social Networks Involving Private Nodes",
    "abstract": "Analysis of social networks with limited data access is challenging for third parties. To address this challenge, a number of studies have developed algorithms that estimate properties of social networks via a simple random walk. However, most existing algorithms do not assume private nodes that do not publish their neighbors' data when they are queried in empirical social networks. Here we propose a practical framework for estimating properties via random walk-based sampling in social networks involving private nodes. First, we develop a sampling algorithm by extending a simple random walk to the case of social networks involving private nodes. Then, we propose estimators with reduced biases induced by private nodes for the network size, average degree, and density of the node label. Our results show that the proposed estimators reduce biases induced by private nodes in the existing estimators by up to 92.6% on social network datasets involving private nodes. ",
    "url": "https://arxiv.org/abs/2305.12314",
    "authors": [
      "Kazuki Nakajima",
      "Kazuyuki Shudo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.12322",
    "title": "Learning Large Graph Property Prediction via Graph Segment Training",
    "abstract": "Learning to predict properties of large graphs is challenging because each prediction requires the knowledge of an entire graph, while the amount of memory available during training is bounded. Here we propose Graph Segment Training (GST), a general framework that utilizes a divide-and-conquer approach to allow learning large graph property prediction with a constant memory footprint. GST first divides a large graph into segments and then backpropagates through only a few segments sampled per training iteration. We refine the GST paradigm by introducing a historical embedding table to efficiently obtain embeddings for segments not sampled for backpropagation. To mitigate the staleness of historical embeddings, we design two novel techniques. First, we finetune the prediction head to fix the input distribution shift. Second, we introduce Stale Embedding Dropout to drop some stale embeddings during training to reduce bias. We evaluate our complete method GST-EFD (with all the techniques together) on two large graph property prediction benchmarks: MalNet and TpuGraphs. Our experiments show that GST-EFD is both memory-efficient and fast, while offering a slight boost on test accuracy over a typical full graph training regime. ",
    "url": "https://arxiv.org/abs/2305.12322",
    "authors": [
      "Kaidi Cao",
      "Phitchaya Mangpo Phothilimthana",
      "Sami Abu-El-Haija",
      "Dustin Zelle",
      "Yanqi Zhou",
      "Charith Mendis",
      "Jure Leskovec",
      "Bryan Perozzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.12327",
    "title": "Coronary Artery Semantic Labeling using Edge Attention Graph Matching  Network",
    "abstract": "Coronary artery disease (CAD) is one of the primary causes leading deaths worldwide. The presence of atherosclerotic lesions in coronary arteries is the underlying pathophysiological basis of CAD, and accurate extraction of individual arterial branches using invasive coronary angiography (ICA) is crucial for stenosis detection and CAD diagnosis. We propose an innovative approach called the Edge Attention Graph Matching Network (EAGMN) for coronary artery semantic labeling. By converting the coronary artery semantic segmentation task into a graph node similarity comparison task, identifying the node-to-node correspondence would assign semantic labels for each arterial branch. More specifically, The EAGMN utilizes the association graph constructed from the two individual graphs as input. Experimental results indicate the EAGMN achieved a weighted accuracy of 0.8653, a weighted precision of 0.8656, a weighted recall of 0.8653 and a weighted F1-score of 0.8643. Furthermore, we employ ZORRO to provide interpretability and explainability of the graph matching for artery semantic labeling. These findings highlight the potential of the EAGMN for accurate and efficient coronary artery semantic labeling using ICAs. By leveraging the inherent characteristics of ICAs and incorporating graph matching techniques, our proposed model provides a promising solution for improving CAD diagnosis and treatment ",
    "url": "https://arxiv.org/abs/2305.12327",
    "authors": [
      "Chen Zhao",
      "Zhihui Xu",
      "Guang-Uei Hung",
      "Weihua Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12329",
    "title": "Anomaly Detection Using One-Class SVM for Logs of Juniper Router Devices",
    "abstract": "The article deals with anomaly detection of Juniper router logs. Abnormal Juniper router logs include logs that are usually different from the normal operation, and they often reflect the abnormal operation of router devices. To prevent router devices from being damaged and help administrator to grasp the situation of error quickly, detecting abnormal operation soon is very important. In this work, we present a new way to get important features from log data of Juniper router devices and use machine learning method (basing on One-Class SVM model) for anomaly detection. One-Class SVM model requires some knowledge and comprehension about logs of Juniper router devices so that it can analyze, interpret, and test the knowledge ac-quired. We collect log data from a lot of real Juniper router devices and clas-sify them based on our knowledge. Before these logs are used for training and testing the One-Class SVM model, the feature extraction phase for these data was carried out. Finally, with the proposed method, the system errors of the routers were dectected quickly and accurately. This may help our com-pany to reduce the operation cost for the router systems. ",
    "url": "https://arxiv.org/abs/2305.12329",
    "authors": [
      "Tat-Bao-Thien Nguyen",
      "Teh-Lu Liao",
      "Tuan-Anh Vu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12333",
    "title": "Grace++: Loss-Resilient Real-Time Video Communication under High Network  Latency",
    "abstract": "In real-time videos, resending any packets, especially in networks with high latency, can lead to stuttering, poor video quality, and user frustration. Despite extensive research, current real-time video systems still use redundancy to handle packet loss, thus compromising on quality in the the absence of packet loss. Since predicting packet loss is challenging, these systems only enhance their resilience to packet loss after it occurs, leaving some frames insufficiently protected against burst packet losses. They may also add too much redundancy even after the packet loss has subsided. We present Grace++, a new real-time video communication system. With Grace++, (i) a video frame can be decoded, as long as any non-empty subset of its packets are received, and (ii) the quality gracefully degrades as more packets are lost, and (iii) approximates that of a standard codec (like H.265) in absence of packet loss. To achieve this, Grace++ encodes and decodes frames by using neural networks (NNs). It uses a new packetization scheme that makes packet loss appear to have the same effect as randomly masking (zeroing) a subset of elements in the NN-encoded output, and the NN encoder and decoder are specially trained to achieve decent quality if a random subset of elements in the NN-encoded output are masked. Using various test videos and real network traces, we show that the quality of Grace++ is slightly lower than H.265 when no packets are lost, but significantly reduces the 95th percentile of frame delay (between encoding a frame and its decoding) by 2x when packet loss occurs compared to other loss-resilient schemes while achieving comparable quality. This is because Grace++ does not require retransmission of packets (unless all packets are lost) or skipping of frames. ",
    "url": "https://arxiv.org/abs/2305.12333",
    "authors": [
      "Yihua Cheng",
      "Anton Arapin",
      "Ziyi Zhang",
      "Qizheng Zhang",
      "Hanchen Li",
      "Nick Feamster",
      "Junchen Jiang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2305.12334",
    "title": "Towards Complex Dynamic Physics System Simulation with Graph Neural ODEs",
    "abstract": "The great learning ability of deep learning models facilitates us to comprehend the real physical world, making learning to simulate complicated particle systems a promising endeavour. However, the complex laws of the physical world pose significant challenges to the learning based simulations, such as the varying spatial dependencies between interacting particles and varying temporal dependencies between particle system states in different time stamps, which dominate particles' interacting behaviour and the physical systems' evolution patterns. Existing learning based simulation methods fail to fully account for the complexities, making them unable to yield satisfactory simulations. To better comprehend the complex physical laws, this paper proposes a novel learning based simulation model- Graph Networks with Spatial-Temporal neural Ordinary Equations (GNSTODE)- that characterizes the varying spatial and temporal dependencies in particle systems using a united end-to-end framework. Through training with real-world particle-particle interaction observations, GNSTODE is able to simulate any possible particle systems with high precisions. We empirically evaluate GNSTODE's simulation performance on two real-world particle systems, Gravity and Coulomb, with varying levels of spatial and temporal dependencies. The results show that the proposed GNSTODE yields significantly better simulations than state-of-the-art learning based simulation methods, which proves that GNSTODE can serve as an effective solution to particle simulations in real-world application. ",
    "url": "https://arxiv.org/abs/2305.12334",
    "authors": [
      "Guangsi Shi",
      "Daokun Zhang",
      "Ming Jin",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Atomic Physics (physics.atom-ph)"
    ]
  },
  {
    "id": "arXiv:2305.12344",
    "title": "YOLOv3 with Spatial Pyramid Pooling for Object Detection with Unmanned  Aerial Vehicles",
    "abstract": "Object detection with Unmanned Aerial Vehicles (UAVs) has attracted much attention in the research field of computer vision. However, not easy to accurately detect objects with data obtained from UAVs, which capture images from very high altitudes, making the image dominated by small object sizes, that difficult to detect. Motivated by that challenge, we aim to improve the performance of the one-stage detector YOLOv3 by adding a Spatial Pyramid Pooling (SPP) layer on the end of the backbone darknet-53 to obtain more efficient feature extraction process in object detection tasks with UAVs. We also conducted an evaluation study on different versions of YOLOv3 methods. Includes YOLOv3 with SPP, YOLOv3, and YOLOv3-tiny, which we analyzed with the VisDrone2019-Det dataset. Here we show that YOLOv3 with SPP can get results mAP 0.6% higher than YOLOv3 and 26.6% than YOLOv3-Tiny at 640x640 input scale and is even able to maintain accuracy at different input image scales than other versions of the YOLOv3 method. Those results prove that the addition of SPP layers to YOLOv3 can be an efficient solution for improving the performance of the object detection method with data obtained from UAVs. ",
    "url": "https://arxiv.org/abs/2305.12344",
    "authors": [
      "Wahyu Pebrianto",
      "Panca Mudjirahardjo",
      "Sholeh Hadi Pramono",
      "Rahmadwati",
      "Raden Arief Setyawan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12348",
    "title": "Social Context-aware GCN for Video Character Search via Scene-prior  Enhancement",
    "abstract": "With the increasing demand for intelligent services of online video platforms, video character search task has attracted wide attention to support downstream applications like fine-grained retrieval and summarization. However, traditional solutions only focus on visual or coarse-grained social information and thus cannot perform well when facing complex scenes, such as changing camera view or character posture. Along this line, we leverage social information and scene context as prior knowledge to solve the problem of character search in complex scenes. Specifically, we propose a scene-prior-enhanced framework, named SoCoSearch. We first integrate multimodal clues for scene context to estimate the prior probability of social relationships, and then capture characters' co-occurrence to generate an enhanced social context graph. Afterwards, we design a social context-aware GCN framework to achieve feature passing between characters to obtain robust representation for the character search task. Extensive experiments have validated the effectiveness of SoCoSearch in various metrics. ",
    "url": "https://arxiv.org/abs/2305.12348",
    "authors": [
      "Wenjun Peng",
      "Weidong He",
      "Derong Xu",
      "Tong Xu",
      "Chen Zhu",
      "Enhong Chen"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2305.12351",
    "title": "Are Your Explanations Reliable? Investigating the Stability of LIME in  Explaining Textual Classification Models via Adversarial Perturbation",
    "abstract": "Local Surrogate models have increased in popularity for use in explaining complex black-box models for diverse types of data, including text, tabular, and image. One particular algorithm, LIME, continues to see use within the field of machine learning due to its inherently interpretable explanations and model-agnostic behavior. But despite continued use, questions about the stability of LIME persist. Stability, a property where similar instances result in similar explanations, has been shown to be lacking in explanations generated for tabular and image data, both of which are continuous domains. Here we explore the stability of LIME's explanations generated on textual data and confirm the trend of instability shown in previous research for other data types. ",
    "url": "https://arxiv.org/abs/2305.12351",
    "authors": [
      "Christopher Burger",
      "Lingwei Chen",
      "Thai Le"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12358",
    "title": "AutoPaint: A Self-Inpainting Method for Unsupervised Anomaly Detection",
    "abstract": "Robust and accurate detection and segmentation of heterogenous tumors appearing in different anatomical organs with supervised methods require large-scale labeled datasets covering all possible types of diseases. Due to the unavailability of such rich datasets and the high cost of annotations, unsupervised anomaly detection (UAD) methods have been developed aiming to detect the pathologies as deviation from the normality by utilizing the unlabeled healthy image data. However, developed UAD models are often trained with an incomplete distribution of healthy anatomies and have difficulties in preserving anatomical constraints. This work intends to, first, propose a robust inpainting model to learn the details of healthy anatomies and reconstruct high-resolution images by preserving anatomical constraints. Second, we propose an autoinpainting pipeline to automatically detect tumors, replace their appearance with the learned healthy anatomies, and based on that segment the tumoral volumes in a purely unsupervised fashion. Three imaging datasets, including PET, CT, and PET-CT scans of lung tumors and head and neck tumors, are studied as benchmarks for evaluation. Experimental results demonstrate the significant superiority of the proposed method over a wide range of state-of-the-art UAD methods. Moreover, the unsupervised method we propose produces comparable results to a robust supervised segmentation method when applied to multimodal images. ",
    "url": "https://arxiv.org/abs/2305.12358",
    "authors": [
      "Mehdi Astaraki",
      "Francesca De Benetti",
      "Yousef Yeganeh",
      "Iuliana Toma-Dasu",
      "\u00d6rjan Smedby",
      "Chunliang Wang",
      "Nassir Navab",
      "Thomas Wendler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.12361",
    "title": "A Dual-level Detection Method for Video Copy Detection",
    "abstract": "With the development of multimedia technology, Video Copy Detection has been a crucial problem for social media platforms. Meta AI hold Video Similarity Challenge on CVPR 2023 to push the technology forward. In this paper, we share our winner solutions on both tracks to help progress in this area. For Descriptor Track, we propose a dual-level detection method with Video Editing Detection (VED) and Frame Scenes Detection (FSD) to tackle the core challenges on Video Copy Detection. Experimental results demonstrate the effectiveness and efficiency of our proposed method. Code is available at https://github.com/FeipengMa6/VSC22-Submission. ",
    "url": "https://arxiv.org/abs/2305.12361",
    "authors": [
      "Tianyi Wang",
      "Feipeng Ma",
      "Zhenhua Liu",
      "Fengyun Rao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12396",
    "title": "Joint Feature and Differentiable $ k $-NN Graph Learning using Dirichlet  Energy",
    "abstract": "Feature selection (FS) plays an important role in machine learning, which extracts important features and accelerates the learning process. In this paper, we propose a deep FS method that simultaneously conducts feature selection and differentiable $ k $-NN graph learning based on the Dirichlet Energy. The Dirichlet Energy identifies important features by measuring their smoothness on the graph structure, and facilitates the learning of a new graph that reflects the inherent structure in the new feature subspace during the training process using selected features. We employ the Gumbel Softmax technique and the Optimal Transport theory to address the non-differentiability issues of learning discrete FS results and learning $ k $-NN graphs in neural networks, which theoretically makes our model applicable to other graph neural networks. Furthermore, the proposed framework is interpretable, since all modules are designed algorithmically. We validate the effectiveness of our model with extensive experiments on both synthetic and real-world datasets. ",
    "url": "https://arxiv.org/abs/2305.12396",
    "authors": [
      "Lei Xu",
      "Lei Chen",
      "Rong Wang",
      "Feiping Nie",
      "Xuelong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12398",
    "title": "Language Knowledge-Assisted Representation Learning for Skeleton-Based  Action Recognition",
    "abstract": "How humans understand and recognize the actions of others is a complex neuroscientific problem that involves a combination of cognitive mechanisms and neural networks. Research has shown that humans have brain areas that recognize actions that process top-down attentional information, such as the temporoparietal association area. Also, humans have brain regions dedicated to understanding the minds of others and analyzing their intentions, such as the medial prefrontal cortex of the temporal lobe. Skeleton-based action recognition creates mappings for the complex connections between the human skeleton movement patterns and behaviors. Although existing studies encoded meaningful node relationships and synthesized action representations for classification with good results, few of them considered incorporating a priori knowledge to aid potential representation learning for better performance. LA-GCN proposes a graph convolution network using large-scale language models (LLM) knowledge assistance. First, the LLM knowledge is mapped into a priori global relationship (GPR) topology and a priori category relationship (CPR) topology between nodes. The GPR guides the generation of new \"bone\" representations, aiming to emphasize essential node information from the data level. The CPR mapping simulates category prior knowledge in human brain regions, encoded by the PC-AC module and used to add additional supervision-forcing the model to learn class-distinguishable features. In addition, to improve information transfer efficiency in topology modeling, we propose multi-hop attention graph convolution. It aggregates each node's k-order neighbor simultaneously to speed up model convergence. LA-GCN reaches state-of-the-art on NTU RGB+D, NTU RGB+D 120, and NW-UCLA datasets. ",
    "url": "https://arxiv.org/abs/2305.12398",
    "authors": [
      "Haojun Xu",
      "Yan Gao",
      "Zheng Hui",
      "Jie Li",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12402",
    "title": "Bandit Multi-linear DR-Submodular Maximization and Its Applications on  Adversarial Submodular Bandits",
    "abstract": "We investigate the online bandit learning of the monotone multi-linear DR-submodular functions, designing the algorithm $\\mathtt{BanditMLSM}$ that attains $O(T^{2/3}\\log T)$ of $(1-1/e)$-regret. Then we reduce submodular bandit with partition matroid constraint and bandit sequential monotone maximization to the online bandit learning of the monotone multi-linear DR-submodular functions, attaining $O(T^{2/3}\\log T)$ of $(1-1/e)$-regret in both problems, which improve the existing results. To the best of our knowledge, we are the first to give a sublinear regret algorithm for the submodular bandit with partition matroid constraint. A special case of this problem is studied by Streeter et al.(2009). They prove a $O(T^{4/5})$ $(1-1/e)$-regret upper bound. For the bandit sequential submodular maximization, the existing work proves an $O(T^{2/3})$ regret with a suboptimal $1/2$ approximation ratio (Niazadeh et al. 2021). ",
    "url": "https://arxiv.org/abs/2305.12402",
    "authors": [
      "Zongqi Wan",
      "Jialin Zhang",
      "Wei Chen",
      "Xiaoming Sun",
      "Zhijie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12407",
    "title": "Federated Offline Policy Learning with Heterogeneous Observational Data",
    "abstract": "We consider the problem of learning personalized decision policies on observational data from heterogeneous data sources. Moreover, we examine this problem in the federated setting where a central server aims to learn a policy on the data distributed across the heterogeneous sources without exchanging their raw data. We present a federated policy learning algorithm based on aggregation of local policies trained with doubly robust offline policy evaluation and learning strategies. We provide a novel regret analysis for our approach that establishes a finite-sample upper bound on a notion of global regret across a distribution of clients. In addition, for any individual client, we establish a corresponding local regret upper bound characterized by the presence of distribution shift relative to all other clients. We support our theoretical findings with experimental results. Our analysis and experiments provide insights into the value of heterogeneous client participation in federation for policy learning in heterogeneous settings. ",
    "url": "https://arxiv.org/abs/2305.12407",
    "authors": [
      "Aldo Gael Carranza",
      "Susan Athey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.12410",
    "title": "DiffUCD:Unsupervised Hyperspectral Image Change Detection with Semantic  Correlation Diffusion Model",
    "abstract": "Hyperspectral image change detection (HSI-CD) has emerged as a crucial research area in remote sensing due to its ability to detect subtle changes on the earth's surface. Recently, diffusional denoising probabilistic models (DDPM) have demonstrated remarkable performance in the generative domain. Apart from their image generation capability, the denoising process in diffusion models can comprehensively account for the semantic correlation of spectral-spatial features in HSI, resulting in the retrieval of semantically relevant features in the original image. In this work, we extend the diffusion model's application to the HSI-CD field and propose a novel unsupervised HSI-CD with semantic correlation diffusion model (DiffUCD). Specifically, the semantic correlation diffusion model (SCDM) leverages abundant unlabeled samples and fully accounts for the semantic correlation of spectral-spatial features, which mitigates pseudo change between multi-temporal images arising from inconsistent imaging conditions. Besides, objects with the same semantic concept at the same spatial location may exhibit inconsistent spectral signatures at different times, resulting in pseudo change. To address this problem, we propose a cross-temporal contrastive learning (CTCL) mechanism that aligns the spectral feature representations of unchanged samples. By doing so, the spectral difference invariant features caused by environmental changes can be obtained. Experiments conducted on three publicly available datasets demonstrate that the proposed method outperforms the other state-of-the-art unsupervised methods in terms of Overall Accuracy (OA), Kappa Coefficient (KC), and F1 scores, achieving improvements of approximately 3.95%, 8.13%, and 4.45%, respectively. Notably, our method can achieve comparable results to those fully supervised methods requiring numerous annotated samples. ",
    "url": "https://arxiv.org/abs/2305.12410",
    "authors": [
      "Xiangrong Zhang",
      "Shunli Tian",
      "Guanchun Wang",
      "Huiyu Zhou",
      "Licheng Jiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12414",
    "title": "Real-time Aerial Detection and Reasoning on Embedded-UAVs",
    "abstract": "We present a unified pipeline architecture for a real-time detection system on an embedded system for UAVs. Neural architectures have been the industry standard for computer vision. However, most existing works focus solely on concatenating deeper layers to achieve higher accuracy with run-time performance as the trade-off. This pipeline of networks can exploit the domain-specific knowledge on aerial pedestrian detection and activity recognition for the emerging UAV applications of autonomous surveying and activity reporting. In particular, our pipeline architectures operate in a time-sensitive manner, have high accuracy in detecting pedestrians from various aerial orientations, use a novel attention map for multi-activities recognition, and jointly refine its detection with temporal information. Numerically, we demonstrate our model's accuracy and fast inference speed on embedded systems. We empirically deployed our prototype hardware with full live feeds in a real-world open-field environment. ",
    "url": "https://arxiv.org/abs/2305.12414",
    "authors": [
      "Tin Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12416",
    "title": "Direct Fact Retrieval from Knowledge Graphs without Entity Linking",
    "abstract": "There has been a surge of interest in utilizing Knowledge Graphs (KGs) for various natural language processing/understanding tasks. The conventional mechanism to retrieve facts in KGs usually involves three steps: entity span detection, entity disambiguation, and relation classification. However, this approach requires additional labels for training each of the three subcomponents in addition to pairs of input texts and facts, and also may accumulate errors propagated from failures in previous steps. To tackle these limitations, we propose a simple knowledge retrieval framework, which directly retrieves facts from the KGs given the input text based on their representational similarities, which we refer to as Direct Fact Retrieval (DiFaR). Specifically, we first embed all facts in KGs onto a dense embedding space by using a language model trained by only pairs of input texts and facts, and then provide the nearest facts in response to the input text. Since the fact, consisting of only two entities and one relation, has little context to encode, we propose to further refine ranks of top-k retrieved facts with a reranker that contextualizes the input text and the fact jointly. We validate our DiFaR framework on multiple fact retrieval tasks, showing that it significantly outperforms relevant baselines that use the three-step approach. ",
    "url": "https://arxiv.org/abs/2305.12416",
    "authors": [
      "Jinheon Baek",
      "Alham Fikri Aji",
      "Jens Lehmann",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2305.12427",
    "title": "VL-Fields: Towards Language-Grounded Neural Implicit Spatial  Representations",
    "abstract": "We present Visual-Language Fields (VL-Fields), a neural implicit spatial representation that enables open-vocabulary semantic queries. Our model encodes and fuses the geometry of a scene with vision-language trained latent features by distilling information from a language-driven segmentation model. VL-Fields is trained without requiring any prior knowledge of the scene object classes, which makes it a promising representation for the field of robotics. Our model outperformed the similar CLIP-Fields model in the task of semantic segmentation by almost 10%. ",
    "url": "https://arxiv.org/abs/2305.12427",
    "authors": [
      "Nikolaos Tsagkas",
      "Oisin Mac Aodha",
      "Chris Xiaoxuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12433",
    "title": "ParticleWNN: a Novel Neural Networks Framework for Solving Partial  Differential Equations",
    "abstract": "Deep neural networks (DNNs) have been widely used to solve partial differential equations (PDEs) in recent years. In this work, a novel deep learning-based framework named Particle Weak-form based Neural Networks (ParticleWNN) is developed for solving PDEs in the weak form. In this framework, the trial space is chosen as the space of DNNs, and the test space is constructed by functions compactly supported in extremely small regions whose centers are particles. To train the neural networks, an R-adaptive strategy is designed to adaptively modify the radius of regions during training. The ParticleWNN inherits the advantages of weak/variational formulation, such as requiring less regularity of the solution and a small number of quadrature points for computing the integrals. Moreover, due to the special construction of the test functions, the ParticleWNN allows local training of networks, parallel implementation, and integral calculations only in extremely small regions. The framework is particularly desirable for solving problems with high-dimensional and complex domains. The efficiency and accuracy of the ParticleWNN are demonstrated with several numerical examples. The numerical results show clear advantages of the ParticleWNN over the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2305.12433",
    "authors": [
      "Yaohua Zang",
      "Gang Bao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2305.12449",
    "title": "Communication Efficient Federated Learning for Multilingual Neural  Machine Translation with Adapter",
    "abstract": "Federated Multilingual Neural Machine Translation (Fed-MNMT) has emerged as a promising paradigm for institutions with limited language resources. This approach allows multiple institutions to act as clients and train a unified model through model synchronization, rather than collecting sensitive data for centralized training. This significantly reduces the cost of corpus collection and preserves data privacy. However, as pre-trained language models (PLMs) continue to increase in size, the communication cost for transmitting parameters during synchronization has become a training speed bottleneck. In this paper, we propose a communication-efficient Fed-MNMT framework that addresses this issue by keeping PLMs frozen and only transferring lightweight adapter modules between clients. Since different language pairs exhibit substantial discrepancies in data distributions, adapter parameters of clients may conflict with each other. To tackle this, we explore various clustering strategies to group parameters for integration and mitigate the negative effects of conflicting parameters. Experimental results demonstrate that our framework reduces communication cost by over 98% while achieving similar or even better performance compared to competitive baselines. Further analysis reveals that clustering strategies effectively solve the problem of linguistic discrepancy and pruning adapter modules further improves communication efficiency. ",
    "url": "https://arxiv.org/abs/2305.12449",
    "authors": [
      "Yi Liu",
      "Xiaohan Bi",
      "Lei Li",
      "Sishuo Chen",
      "Wenkai Yang",
      "Xu Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12457",
    "title": "Unsupervised Multi-view Pedestrian Detection",
    "abstract": "With the prosperity of the video surveillance, multiple visual sensors have been applied for an accurate localization of pedestrians in a specific area, which facilitate various applications like intelligent safety or new retailing. However, previous methods rely on the supervision from the human annotated pedestrian positions in every video frame and camera view, which is a heavy burden in addition to the necessary camera calibration and synchronization. Therefore, we propose in this paper an Unsupervised Multi-view Pedestrian Detection approach (UMPD) to eliminate the need of annotations to learn a multi-view pedestrian detector. 1) Firstly, Semantic-aware Iterative Segmentation (SIS) is proposed to extract discriminative visual representations of the input images from different camera views via an unsupervised pretrained model, then convert them into 2D segments of pedestrians, based on our proposed iterative Principal Component Analysis and the zero-shot semantic classes from the vision-language pretrained models. 2) Secondly, we propose Vertical-aware Differential Rendering (VDR) to not only learn the densities and colors of 3D voxels by the masks of SIS, images and camera poses, but also constraint the voxels to be vertical towards the ground plane, following the physical characteristics of pedestrians. 3) Thirdly, the densities of 3D voxels learned by VDR are projected onto Bird-Eyes-View as the final detection results. Extensive experiments on popular multi-view pedestrian detection benchmarks, i.e., Wildtrack and MultiviewX, show that our proposed UMPD approach, as the first unsupervised method to our best knowledge, performs competitively with the previous state-of-the-art supervised techniques. Code will be available. ",
    "url": "https://arxiv.org/abs/2305.12457",
    "authors": [
      "Mengyin Liu",
      "Chao Zhu",
      "Shiqi Ren",
      "Xu-Cheng Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2305.12461",
    "title": "Towards Tracing Code Provenance with Code Watermarking",
    "abstract": "Recent advances in large language models have raised wide concern in generating abundant plausible source code without scrutiny, and thus tracing the provenance of code emerges as a critical issue. To solve the issue, we propose CodeMark, a watermarking system that hides bit strings into variables respecting the natural and operational semantics of the code. For naturalness, we novelly introduce a contextual watermarking scheme to generate watermarked variables more coherent in the context atop graph neural networks. Each variable is treated as a node on the graph and the node feature gathers neighborhood (context) information through learning. Watermarks embedded into the features are thus reflected not only by the variables but also by the local contexts. We further introduce a pre-trained model on source code as a teacher to guide more natural variable generation. Throughout the embedding, the operational semantics are preserved as only variable names are altered. Beyond guaranteeing code-specific properties, CodeMark is superior in watermarking accuracy, capacity, and efficiency due to a more diversified pattern generated. Experimental results show CodeMark outperforms the SOTA watermarking systems with a better balance of the watermarking requirements. ",
    "url": "https://arxiv.org/abs/2305.12461",
    "authors": [
      "Wei Li",
      "Borui Yang",
      "Yujie Sun",
      "Suyu Chen",
      "Ziyun Song",
      "Liyao Xiang",
      "Xinbing Wang",
      "Chenghu Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.12464",
    "title": "Self-supervised Predictive Coding Models Encode Speaker and Phonetic  Information in Orthogonal Subspaces",
    "abstract": "Self-supervised speech representations are known to encode both speaker and phonetic information, but how they are distributed in the high-dimensional space remains largely unexplored. We hypothesize that they are encoded in orthogonal subspaces, a property that lends itself to simple disentanglement. Applying principal component analysis to representations of two predictive coding models, we identify two subspaces that capture speaker and phonetic variances, and confirm that they are nearly orthogonal. Based on this property, we propose a new speaker normalization method which collapses the subspace that encodes speaker information, without requiring transcriptions. Probing experiments show that our method effectively eliminates speaker information and outperforms a previous baseline in phone discrimination tasks. Moreover, the approach generalizes and can be used to remove information of unseen speakers. ",
    "url": "https://arxiv.org/abs/2305.12464",
    "authors": [
      "Oli Liu",
      "Hao Tang",
      "Sharon Goldwater"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.12467",
    "title": "Understanding Multi-phase Optimization Dynamics and Rich Nonlinear  Behaviors of ReLU Networks",
    "abstract": "The training process of ReLU neural networks often exhibits complicated nonlinear phenomena. The nonlinearity of models and non-convexity of loss pose significant challenges for theoretical analysis. Therefore, most previous theoretical works on the optimization dynamics of neural networks focus either on local analysis (like the end of training) or approximate linear models (like Neural Tangent Kernel). In this work, we conduct a complete theoretical characterization of the training process of a two-layer ReLU network trained by Gradient Flow on a linearly separable data. In this specific setting, our analysis captures the whole optimization process starting from random initialization to final convergence. Despite the relatively simple model and data that we studied, we reveal four different phases from the whole training process showing a general simplifying-to-complicating learning trend. Specific nonlinear behaviors can also be precisely identified and captured theoretically, such as initial condensation, saddle-to-plateau dynamics, plateau escape, changes of activation patterns, learning with increasing complexity, etc. ",
    "url": "https://arxiv.org/abs/2305.12467",
    "authors": [
      "Mingze Wang",
      "Chao Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2305.12476",
    "title": "Zero-shot Visual Relation Detection via Composite Visual Cues from Large  Language Models",
    "abstract": "Pretrained vision-language models, such as CLIP, have demonstrated strong generalization capabilities, making them promising tools in the realm of zero-shot visual recognition. Visual relation detection (VRD) is a typical task that identifies relationship (or interaction) types between object pairs within an image. However, naively utilizing CLIP with prevalent class-based prompts for zero-shot VRD has several weaknesses, e.g., it struggles to distinguish between different fine-grained relation types and it neglects essential spatial information of two objects. To this end, we propose a novel method for zero-shot VRD: RECODE, which solves RElation detection via COmposite DEscription prompts. Specifically, RECODE first decomposes each predicate category into subject, object, and spatial components. Then, it leverages large language models (LLMs) to generate description-based prompts (or visual cues) for each component. Different visual cues enhance the discriminability of similar relation categories from different perspectives, which significantly boosts performance in VRD. To dynamically fuse different cues, we further introduce a chain-of-thought method that prompts LLMs to generate reasonable weights for different visual cues. Extensive experiments on four VRD benchmarks have demonstrated the effectiveness and interpretability of RECODE. ",
    "url": "https://arxiv.org/abs/2305.12476",
    "authors": [
      "Lin Li",
      "Jun Xiao",
      "Guikun Chen",
      "Jian Shao",
      "Yueting Zhuang",
      "Long Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12501",
    "title": "Exploring How Generative Adversarial Networks Learn Phonological  Representations",
    "abstract": "This paper explores how Generative Adversarial Networks (GANs) learn representations of phonological phenomena. We analyze how GANs encode contrastive and non-contrastive nasality in French and English vowels by applying the ciwGAN architecture (Begus 2021a). Begus claims that ciwGAN encodes linguistically meaningful representations with categorical variables in its latent space and manipulating the latent variables shows an almost one to one corresponding control of the phonological features in ciwGAN's generated outputs. However, our results show an interactive effect of latent variables on the features in the generated outputs, which suggests the learned representations in neural networks are different from the phonological representations proposed by linguists. On the other hand, ciwGAN is able to distinguish contrastive and noncontrastive features in English and French by encoding them differently. Comparing the performance of GANs learning from different languages results in a better understanding of what language specific features contribute to developing language specific phonological representations. We also discuss the role of training data frequencies in phonological feature learning. ",
    "url": "https://arxiv.org/abs/2305.12501",
    "authors": [
      "Jingyi Chen",
      "Micha Elsner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.12506",
    "title": "CNN-based Dendrite Core Detection from Microscopic Images of  Directionally Solidified Ni-base Alloys",
    "abstract": "Dendrite core is the center point of the dendrite. The information of dendrite core is very helpful for material scientists to analyze the properties of materials. Therefore, detecting the dendrite core is a very important task in the material science field. Meanwhile, because of some special properties of the dendrites, this task is also very challenging. Different from the typical detection problems in the computer vision field, detecting the dendrite core aims to detect a single point location instead of the bounding-box. As a result, the existing regressing bounding-box based detection methods can not work well on this task because the calculated center point location based on the upper-left and lower-right corners of the bounding-box is usually not precise. In this work, we formulate the dendrite core detection problem as a segmentation task and proposed a novel detection method to detect the dendrite core directly. Our whole pipeline contains three steps: Easy Sample Detection (ESD), Hard Sample Detection(HSD), and Hard Sample Refinement (HSR). Specifically, ESD and HSD focus on the easy samples and hard samples of dendrite cores respectively. Both of them employ the same Central Point Detection Network (CPDN) but do not share parameters. To make HSD only focus on the feature of hard samples of dendrite cores, we destroy the structure of the easy samples of dendrites which are detected by ESD and force HSD to learn the feature of hard samples. HSR is a binary classifier which is used to filter out the false positive prediction of HSD. We evaluate our method on the dendrite dataset. Our method outperforms the state-of-the-art baselines on three metrics, i.e., Recall, Precision, and F-score. ",
    "url": "https://arxiv.org/abs/2305.12506",
    "authors": [
      "Xiaoguang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12514",
    "title": "Towards robust paralinguistic assessment for real-world mobile health  (mHealth) monitoring: an initial study of reverberation effects on speech",
    "abstract": "Speech is promising as an objective, convenient tool to monitor health remotely over time using mobile devices. Numerous paralinguistic features have been demonstrated to contain salient information related to an individual's health. However, mobile device specification and acoustic environments vary widely, risking the reliability of the extracted features. In an initial step towards quantifying these effects, we report the variability of 13 exemplar paralinguistic features commonly reported in the speech-health literature and extracted from the speech of 42 healthy volunteers recorded consecutively in rooms with low and high reverberation with one budget and two higher-end smartphones and a condenser microphone. Our results show reverberation has a clear effect on several features, in particular voice quality markers. They point to new research directions investigating how best to record and process in-the-wild speech for reliable longitudinal health state assessment. ",
    "url": "https://arxiv.org/abs/2305.12514",
    "authors": [
      "Judith Dineley",
      "Ewan Carr",
      "Faith Matcham",
      "Johnny Downs",
      "Richard Dobson",
      "Thomas F Quatieri",
      "Nicholas Cummins"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.12519",
    "title": "GPT Paternity Test: GPT Generated Text Detection with GPT Genetic  Inheritance",
    "abstract": "Large Language Models (LLMs) can generate texts that carry the risk of various misuses, including plagiarism, planting fake reviews on e-commerce platforms, or creating fake social media postings that can sway election results. Detecting whether a text is machine-generated has thus become increasingly important. While machine-learning-based detection strategies exhibit superior performance, they often lack generalizability, limiting their practicality. In this work, we introduce GPT Paternity Test (GPT-Pat), which reliably detects machine-generated text across varied datasets. Given a text under scrutiny, we leverage ChatGPT to generate a corresponding question and provide a re-answer to the question. By comparing the similarity between the original text and the generated re-answered text, it can be determined whether the text is machine-generated. GPT-Pat consists of a Siamese network to compute the similarity between the original text and the generated re-answered text and a binary classifier. Our method achieved an average accuracy of 94.57% on four generalization test sets, surpassing the state-of-the-art RoBERTa-based method by 12.34%. The accuracy drop of our method is only about half of that of the RoBERTa-based method when it is attacked by re-translation and polishing. ",
    "url": "https://arxiv.org/abs/2305.12519",
    "authors": [
      "Xiao Yu",
      "Yuang Qi",
      "Kejiang Chen",
      "Guoqiang Chen",
      "Xi Yang",
      "Pengyuan Zhu",
      "Weiming Zhang",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12522",
    "title": "P-NOC: Adversarial CAM Generation for Weakly Supervised Semantic  Segmentation",
    "abstract": "To mitigate the necessity for large amounts of supervised segmentation annotation sets, multiple Weakly Supervised Semantic Segmentation (WSSS) strategies have been devised. These will often rely on advanced data and model regularization strategies to instigate the development of useful properties (e.g., prediction completeness and fidelity to semantic boundaries) in segmentation priors, notwithstanding the lack of annotated information. In this work, we first create a strong baseline by analyzing complementary WSSS techniques and regularizing strategies, considering their strengths and limitations. We then propose a new Class-specific Adversarial Erasing strategy, comprising two adversarial CAM generating networks being gradually refined to produce robust semantic segmentation proposals. Empirical results suggest that our approach induces substantial improvement in the effectiveness of the baseline, resulting in a noticeable improvement over both Pascal VOC 2012 and MS COCO 2014 datasets. ",
    "url": "https://arxiv.org/abs/2305.12522",
    "authors": [
      "Lucas David",
      "Helio Pedrini",
      "Zanoni Dias"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12523",
    "title": "Multi-Static Target Detection and Power Allocation for Integrated  Sensing and Communication in Cell-Free Massive MIMO",
    "abstract": "This paper studies an integrated sensing and communication (ISAC) system for single-target detection in a cloud radio access network architecture. The system considers downlink communication and multi-static sensing approach, where ISAC transmit access points (APs) jointly serve the user equipments (UEs) and optionally steer a beam toward the target. A centralized operation of cell-free massive MIMO (multiple-input multiple-output) is considered for communication and sensing purposes. A maximum a posteriori ratio test detector is developed to detect the target in the presence of clutter, so-called target-free signals. Moreover, a power allocation algorithm is proposed to maximize the sensing signal-to-interference-plus-noise ratio (SINR) while ensuring a minimum communication SINR value for each UE and meeting per-AP power constraints. Two ISAC setups are studied: i) using only existing communication beams for sensing and ii) using additional sensing beams. The proposed algorithm's efficiency is investigated in both realistic and idealistic scenarios, corresponding to the presence and absence of the target-free channels, respectively. Although detection probability degrades in the presence of target-free channels that act as interference, the proposed algorithm significantly outperforms the interference-unaware benchmark by exploiting the statistics of the clutter. It has also been shown that the proposed algorithm outperforms the fully communication-centric algorithm, both in the presence and absence of clutter. Moreover, using an additional sensing beam improves the detection performance for a target with lower radar cross-section variances compared to the case without sensing beams. ",
    "url": "https://arxiv.org/abs/2305.12523",
    "authors": [
      "Zinat Behdad",
      "\u00d6zlem Tu\u011ffe Demir",
      "Ki Won Sung",
      "Emil Bj\u00f6rnson",
      "Cicek Cavdar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.12529",
    "title": "DreamWaltz: Make a Scene with Complex 3D Animatable Avatars",
    "abstract": "We present DreamWaltz, a novel framework for generating and animating complex avatars given text guidance and parametric human body prior. While recent methods have shown encouraging results in the text-to-3D generation of common objects, creating high-quality and animatable 3D avatars remains challenging. To create high-quality 3D avatars, DreamWaltz proposes 3D-consistent occlusion-aware Score Distillation Sampling (SDS) to optimize implicit neural representations with canonical poses. It provides view-aligned supervision via 3D-aware skeleton conditioning and enables complex avatar generation without artifacts and multiple faces. For animation, our method learns an animatable and generalizable avatar representation which could map arbitrary poses to the canonical pose representation. Extensive evaluations demonstrate that DreamWaltz is an effective and robust approach for creating 3D avatars that can take on complex shapes and appearances as well as novel poses for animation. The proposed framework further enables the creation of complex scenes with diverse compositions, including avatar-avatar, avatar-object and avatar-scene interactions. ",
    "url": "https://arxiv.org/abs/2305.12529",
    "authors": [
      "Yukun Huang",
      "Jianan Wang",
      "Ailing Zeng",
      "He Cao",
      "Xianbiao Qi",
      "Yukai Shi",
      "Zheng-Jun Zha",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12543",
    "title": "A Reinforcement Learning Approach for Robust Supervisory Control of UAVs  Under Disturbances",
    "abstract": "In this work, we present an approach to supervisory reinforcement learning control for unmanned aerial vehicles (UAVs). UAVs are dynamic systems where control decisions in response to disturbances in the environment have to be made in the order of milliseconds. We formulate a supervisory control architecture that interleaves with extant embedded control and demonstrates robustness to environmental disturbances in the form of adverse wind conditions. We run case studies with a Tarot T-18 Octorotor to demonstrate the effectiveness of our approach and compare it against a classic cascade control architecture used in most vehicles. While the results show the performance difference is marginal for nominal operations, substantial performance improvement is obtained with the supervisory RL approach under unseen wind conditions. ",
    "url": "https://arxiv.org/abs/2305.12543",
    "authors": [
      "Ibrahim Ahmed",
      "Marcos Quinones-Grueiro",
      "Gautam Biswas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12554",
    "title": "Towards Globally Consistent Stochastic Human Motion Prediction via  Motion Diffusion",
    "abstract": "Stochastic human motion prediction aims to predict multiple possible upcoming pose sequences based on past human motion trajectories. Prior works focused heavily on generating diverse motion samples, leading to inconsistent, abnormal predictions from the immediate past observations. To address this issue, in this work, we propose DiffMotion, a diffusion-based stochastic human motion prediction framework that considers both the kinematic structure of the human body and the globally temporally consistent nature of motion. Specifically, DiffMotion consists of two modules: 1) a transformer-based network for generating an initial motion reconstruction from corrupted motion, and 2) a multi-stage graph convolutional network to iteratively refine the generated motion based on past observations. Facilitated by the proposed direct target prediction objective and the variance scheduler, our method is capable of predicting accurate, realistic and consistent motion with an appropriate level of diversity. Our results on benchmark datasets demonstrate that DiffMotion outperforms previous methods by large margins in terms of accuracy and fidelity while demonstrating superior robustness. ",
    "url": "https://arxiv.org/abs/2305.12554",
    "authors": [
      "Jiarui Sun",
      "Girish Chowdhary"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12565",
    "title": "Understanding the Effect of Data Augmentation on Knowledge Distillation",
    "abstract": "Knowledge distillation (KD) requires sufficient data to transfer knowledge from large-scale teacher models to small-scale student models. Therefore, data augmentation has been widely used to mitigate the shortage of data under specific scenarios. Classic data augmentation techniques, such as synonym replacement and k-nearest-neighbors, are initially designed for fine-tuning. To avoid severe semantic shifts and preserve task-specific labels, those methods prefer to change only a small proportion of tokens (e.g., changing 10% tokens is generally the best option for fine-tuning). However, such data augmentation methods are sub-optimal for knowledge distillation since the teacher model could provide label distributions and is more tolerant to semantic shifts. We first observe that KD prefers as much data as possible, which is different from fine-tuning that too much data will not gain more performance. Since changing more tokens leads to more semantic shifts, we use the proportion of changed tokens to reflect semantic shift degrees. Then we find that KD prefers augmented data with a larger semantic shift degree (e.g., changing 30% tokens is generally the best option for KD) than fine-tuning (changing 10% tokens). Besides, our findings show that smaller datasets prefer larger degrees until the out-of-distribution problem occurs (e.g., datasets with less than 10k inputs may prefer the 50% degree, and datasets with more than 100k inputs may prefer the 10% degree). Our work sheds light on the preference difference in data augmentation between fine-tuning and knowledge distillation and encourages the community to explore KD-specific data augmentation methods. ",
    "url": "https://arxiv.org/abs/2305.12565",
    "authors": [
      "Ziqi Wang",
      "Chi Han",
      "Wenxuan Bao",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12578",
    "title": "Self-Explainable Graph Neural Networks for Link Prediction",
    "abstract": "Graph Neural Networks (GNNs) have achieved state-of-the-art performance for link prediction. However, GNNs suffer from poor interpretability, which limits their adoptions in critical scenarios that require knowing why certain links are predicted. Despite various methods proposed for the explainability of GNNs, most of them are post-hoc explainers developed for explaining node classification. Directly adopting existing post-hoc explainers for explaining link prediction is sub-optimal because: (i) post-hoc explainers usually adopt another strategy or model to explain a target model, which could misinterpret the target model; and (ii) GNN explainers for node classification identify crucial subgraphs around each node for the explanation; while for link prediction, one needs to explain the prediction for each pair of nodes based on graph structure and node attributes. Therefore, in this paper, we study a novel problem of self-explainable GNNs for link prediction, which can simultaneously give accurate predictions and explanations. Concretely, we propose a new framework and it can find various $K$ important neighbors of one node to learn pair-specific representations for links from this node to other nodes. These $K$ different neighbors represent important characteristics of the node and model various factors for links from it. Thus, $K$ neighbors can provide explanations for the existence of links. Experiments on both synthetic and real-world datasets verify the effectiveness of the proposed framework for link prediction and explanation. ",
    "url": "https://arxiv.org/abs/2305.12578",
    "authors": [
      "Huaisheng Zhu",
      "Dongsheng Luo",
      "Xianfeng Tang",
      "Junjie Xu",
      "Hui Liu",
      "Suhang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12585",
    "title": "GeometricImageNet: Extending convolutional neural networks to vector and  tensor images",
    "abstract": "Convolutional neural networks and their ilk have been very successful for many learning tasks involving images. These methods assume that the input is a scalar image representing the intensity in each pixel, possibly in multiple channels for color images. In natural-science domains however, image-like data sets might have vectors (velocity, say), tensors (polarization, say), pseudovectors (magnetic field, say), or other geometric objects in each pixel. Treating the components of these objects as independent channels in a CNN neglects their structure entirely. Our formulation -- the GeometricImageNet -- combines a geometric generalization of convolution with outer products, tensor index contractions, and tensor index permutations to construct geometric-image functions of geometric images that use and benefit from the tensor structure. The framework permits, with a very simple adjustment, restriction to function spaces that are exactly equivariant to translations, discrete rotations, and reflections. We use representation theory to quantify the dimension of the space of equivariant polynomial functions on 2-dimensional vector images. We give partial results on the expressivity of GeometricImageNet on small images. In numerical experiments, we find that GeometricImageNet has good generalization for a small simulated physics system, even when trained with a small training set. We expect this tool will be valuable for scientific and engineering machine learning, for example in cosmology or ocean dynamics. ",
    "url": "https://arxiv.org/abs/2305.12585",
    "authors": [
      "Wilson Gregory",
      "David W. Hogg",
      "Ben Blum-Smith",
      "Maria Teresa Arias",
      "Kaze W. K. Wong",
      "Soledad Villar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12599",
    "title": "Contrastive Learning with Logic-driven Data Augmentation for Logical  Reasoning over Text",
    "abstract": "Pre-trained large language model (LLM) is under exploration to perform NLP tasks that may require logical reasoning. Logic-driven data augmentation for representation learning has been shown to improve the performance of tasks requiring logical reasoning, but most of these data rely on designed templates and therefore lack generalization. In this regard, we propose an AMR-based logical equivalence-driven data augmentation method (AMR-LE) for generating logically equivalent data. Specifically, we first parse a text into the form of an AMR graph, next apply four logical equivalence laws (contraposition, double negation, commutative and implication laws) on the AMR graph to construct a logically equivalent/inequivalent AMR graph, and then convert it into a logically equivalent/inequivalent sentence. To help the model to better learn these logical equivalence laws, we propose a logical equivalence-driven contrastive learning training paradigm, which aims to distinguish the difference between logical equivalence and inequivalence. Our AMR-LE (Ensemble) achieves #2 on the ReClor leaderboard https://eval.ai/web/challenges/challenge-page/503/leaderboard/1347 . Our model shows better performance on seven downstream tasks, including ReClor, LogiQA, MNLI, MRPC, RTE, QNLI, and QQP. The source code and dataset are public at https://github.com/Strong-AI-Lab/Logical-Equivalence-driven-AMR-Data-Augmentation-for-Representation-Learning . ",
    "url": "https://arxiv.org/abs/2305.12599",
    "authors": [
      "Qiming Bao",
      "Alex Yuxuan Peng",
      "Zhenyun Deng",
      "Wanjun Zhong",
      "Neset Tan",
      "Nathan Young",
      "Yang Chen",
      "Yonghua Zhu",
      "Michael Witbrock",
      "Jiamou Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12600",
    "title": "PRODIGY: Enabling In-context Learning Over Graphs",
    "abstract": "In-context learning is the ability of a pretrained model to adapt to novel and diverse downstream tasks by conditioning on prompt examples, without optimizing any parameters. While large language models have demonstrated this ability, how in-context learning could be performed over graphs is unexplored. In this paper, we develop \\textbf{Pr}etraining \\textbf{O}ver \\textbf{D}iverse \\textbf{I}n-Context \\textbf{G}raph S\\textbf{y}stems (PRODIGY), the first pretraining framework that enables in-context learning over graphs. The key idea of our framework is to formulate in-context learning over graphs with a novel \\emph{prompt graph} representation, which connects prompt examples and queries. We then propose a graph neural network architecture over the prompt graph and a corresponding family of in-context pretraining objectives. With PRODIGY, the pretrained model can directly perform novel downstream classification tasks on unseen graphs via in-context learning. We provide empirical evidence of the effectiveness of our framework by showcasing its strong in-context learning performance on tasks involving citation networks and knowledge graphs. Our approach outperforms the in-context learning accuracy of contrastive pretraining baselines with hard-coded adaptation by 18\\% on average across all setups. Moreover, it also outperforms standard finetuning with limited data by 33\\% on average with in-context learning. ",
    "url": "https://arxiv.org/abs/2305.12600",
    "authors": [
      "Qian Huang",
      "Hongyu Ren",
      "Peng Chen",
      "Gregor Kr\u017emanc",
      "Daniel Zeng",
      "Percy Liang",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12605",
    "title": "Beyond Flat GelSight Sensors: Simulation of Optical Tactile Sensors of  Complex Morphologies for Sim2Real Learning",
    "abstract": "Recently, several morphologies, each with its advantages, have been proposed for the \\textit{GelSight} high-resolution tactile sensors. However, existing simulation methods are limited to flat-surface sensors, which prevents their usage with the newer sensors of non-flat morphologies in Sim2Real experiments. In this paper, we extend a previously proposed GelSight simulation method developed for flat-surface sensors and propose a novel method for curved sensors. In particular, we address the simulation of light rays travelling through a curved tactile membrane in the form of geodesic paths. The method is validated by simulating the finger-shaped GelTip sensor and comparing the generated synthetic tactile images against the corresponding real images. Our extensive experiments show that combining the illumination generated from the geodesic paths, with a background image from the real sensor, produces the best results when compared to the lighting generated by direct linear paths in the same conditions. As the method is parameterised by the sensor mesh, it can be applied in principle to simulate a tactile sensor of any morphology. The proposed method not only unlocks simulating existing optical tactile sensors of complex morphologies but also enables experimenting with sensors of novel morphologies, before the fabrication of the real sensor. Project website: https://danfergo.github.io/geltip-sim ",
    "url": "https://arxiv.org/abs/2305.12605",
    "authors": [
      "Daniel Fernandes Gomes",
      "Paolo Paoletti",
      "Shan Luo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.12606",
    "title": "Comparison of Multilingual Self-Supervised and Weakly-Supervised Speech  Pre-Training for Adaptation to Unseen Languages",
    "abstract": "Recent models such as XLS-R and Whisper have made multilingual speech technologies more accessible by pre-training on audio from around 100 spoken languages each. However, there are thousands of spoken languages worldwide, and adapting to new languages is an important problem. In this work, we aim to understand which model adapts better to languages unseen during pre-training. We fine-tune both models on 13 unseen languages and 18 seen languages. Our results show that the number of hours seen per language and language family during pre-training is predictive of how the models compare, despite the significant differences in the pre-training methods. ",
    "url": "https://arxiv.org/abs/2305.12606",
    "authors": [
      "Andrew Rouditchenko",
      "Sameer Khurana",
      "Samuel Thomas",
      "Rogerio Feris",
      "Leonid Karlinsky",
      "Hilde Kuehne",
      "David Harwath",
      "Brian Kingsbury",
      "James Glass"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.12618",
    "title": "Atomic and Subgraph-aware Bilateral Aggregation for Molecular  Representation Learning",
    "abstract": "Molecular representation learning is a crucial task in predicting molecular properties. Molecules are often modeled as graphs where atoms and chemical bonds are represented as nodes and edges, respectively, and Graph Neural Networks (GNNs) have been commonly utilized to predict atom-related properties, such as reactivity and solubility. However, functional groups (subgraphs) are closely related to some chemical properties of molecules, such as efficacy, and metabolic properties, which cannot be solely determined by individual atoms. In this paper, we introduce a new model for molecular representation learning called the Atomic and Subgraph-aware Bilateral Aggregation (ASBA), which addresses the limitations of previous atom-wise and subgraph-wise models by incorporating both types of information. ASBA consists of two branches, one for atom-wise information and the other for subgraph-wise information. Considering existing atom-wise GNNs cannot properly extract invariant subgraph features, we propose a decomposition-polymerization GNN architecture for the subgraph-wise branch. Furthermore, we propose cooperative node-level and graph-level self-supervised learning strategies for ASBA to improve its generalization. Our method offers a more comprehensive way to learn representations for molecular property prediction and has broad potential in drug and material discovery applications. Extensive experiments have demonstrated the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2305.12618",
    "authors": [
      "Jiahao Chen",
      "Yurou Liu",
      "Jiangmeng Li",
      "Bing Su",
      "Jirong Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2305.12622",
    "title": "Evaluating the Impact of Social Determinants on Health Prediction",
    "abstract": "Social determinants of health (SDOH) -- the conditions in which people live, grow, and age -- play a crucial role in a person's health and well-being. There is a large, compelling body of evidence in population health studies showing that a wide range of SDOH is strongly correlated with health outcomes. Yet, a majority of the risk prediction models based on electronic health records (EHR) do not incorporate a comprehensive set of SDOH features as they are often noisy or simply unavailable. Our work links a publicly available EHR database, MIMIC-IV, to well-documented SDOH features. We investigate the impact of such features on common EHR prediction tasks across different patient populations. We find that community-level SDOH features do not improve model performance for a general patient population, but can improve data-limited model fairness for specific subpopulations. We also demonstrate that SDOH features are vital for conducting thorough audits of algorithmic biases beyond protective attributes. We hope the new integrated EHR-SDOH database will enable studies on the relationship between community health and individual outcomes and provide new benchmarks to study algorithmic biases beyond race, gender, and age. ",
    "url": "https://arxiv.org/abs/2305.12622",
    "authors": [
      "Ming Ying Yang",
      "Gloria Hyunjung Kwak",
      "Tom Pollard",
      "Leo Anthony Celi",
      "Marzyeh Ghassemi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2305.12627",
    "title": "MvP: Multi-view Prompting Improves Aspect Sentiment Tuple Prediction",
    "abstract": "Generative methods greatly promote aspect-based sentiment analysis via generating a sequence of sentiment elements in a specified format. However, existing studies usually predict sentiment elements in a fixed order, which ignores the effect of the interdependence of the elements in a sentiment tuple and the diversity of language expression on the results. In this work, we propose Multi-view Prompting (MvP) that aggregates sentiment elements generated in different orders, leveraging the intuition of human-like problem-solving processes from different views. Specifically, MvP introduces element order prompts to guide the language model to generate multiple sentiment tuples, each with a different element order, and then selects the most reasonable tuples by voting. MvP can naturally model multi-view and multi-task as permutations and combinations of elements, respectively, outperforming previous task-specific designed methods on multiple ABSA tasks with a single model. Extensive experiments show that MvP significantly advances the state-of-the-art performance on 10 datasets of 4 benchmark tasks, and performs quite effectively in low-resource settings. Detailed evaluation verified the effectiveness, flexibility, and cross-task transferability of MvP. ",
    "url": "https://arxiv.org/abs/2305.12627",
    "authors": [
      "Zhibin Gou",
      "Qingyan Guo",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12633",
    "title": "Multi-task Hierarchical Adversarial Inverse Reinforcement Learning",
    "abstract": "Multi-task Imitation Learning (MIL) aims to train a policy capable of performing a distribution of tasks based on multi-task expert demonstrations, which is essential for general-purpose robots. Existing MIL algorithms suffer from low data efficiency and poor performance on complex long-horizontal tasks. We develop Multi-task Hierarchical Adversarial Inverse Reinforcement Learning (MH-AIRL) to learn hierarchically-structured multi-task policies, which is more beneficial for compositional tasks with long horizons and has higher expert data efficiency through identifying and transferring reusable basic skills across tasks. To realize this, MH-AIRL effectively synthesizes context-based multi-task learning, AIRL (an IL approach), and hierarchical policy learning. Further, MH-AIRL can be adopted to demonstrations without the task or skill annotations (i.e., state-action pairs only) which are more accessible in practice. Theoretical justifications are provided for each module of MH-AIRL, and evaluations on challenging multi-task settings demonstrate superior performance and transferability of the multi-task policies learned with MH-AIRL as compared to SOTA MIL baselines. ",
    "url": "https://arxiv.org/abs/2305.12633",
    "authors": [
      "Jiayu Chen",
      "Dipesh Tamboli",
      "Tian Lan",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12634",
    "title": "Data-efficient Active Learning for Structured Prediction with Partial  Annotation and Self-Training",
    "abstract": "In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using active learning. Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative substructures for annotation. We also utilize selftraining to incorporate the current model's automatic predictions as pseudo-labels for unannotated sub-structures. A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label. To address this challenge we adopt an error estimator to decide the partial selection ratio adaptively according to the current model's capability. In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration. ",
    "url": "https://arxiv.org/abs/2305.12634",
    "authors": [
      "Zhisong Zhang",
      "Emma Strubell",
      "Eduard Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12635",
    "title": "A bioinspired three-stage model for camouflaged object detection",
    "abstract": "Camouflaged objects are typically assimilated into their backgrounds and exhibit fuzzy boundaries. The complex environmental conditions and the high intrinsic similarity between camouflaged targets and their surroundings pose significant challenges in accurately locating and segmenting these objects in their entirety. While existing methods have demonstrated remarkable performance in various real-world scenarios, they still face limitations when confronted with difficult cases, such as small targets, thin structures, and indistinct boundaries. Drawing inspiration from human visual perception when observing images containing camouflaged objects, we propose a three-stage model that enables coarse-to-fine segmentation in a single iteration. Specifically, our model employs three decoders to sequentially process subsampled features, cropped features, and high-resolution original features. This proposed approach not only reduces computational overhead but also mitigates interference caused by background noise. Furthermore, considering the significance of multi-scale information, we have designed a multi-scale feature enhancement module that enlarges the receptive field while preserving detailed structural cues. Additionally, a boundary enhancement module has been developed to enhance performance by leveraging boundary information. Subsequently, a mask-guided fusion module is proposed to generate fine-grained results by integrating coarse prediction maps with high-resolution feature maps. Our network surpasses state-of-the-art CNN-based counterparts without unnecessary complexities. Upon acceptance of the paper, the source code will be made publicly available at https://github.com/clelouch/BTSNet. ",
    "url": "https://arxiv.org/abs/2305.12635",
    "authors": [
      "Tianyou Chen",
      "Jin Xiao",
      "Xiaoguang Hu",
      "Guofeng Zhang",
      "Shaojie Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12639",
    "title": "Accelerating Graph Neural Networks via Edge Pruning for Power Allocation  in Wireless Networks",
    "abstract": "Neural Networks (GNNs) have recently emerged as a promising approach to tackling power allocation problems in wireless networks. Since unpaired transmitters and receivers are often spatially distant, the distanced-based threshold is proposed to reduce the computation time by excluding or including the channel state information in GNNs. In this paper, we are the first to introduce a neighbour-based threshold approach to GNNs to reduce the time complexity. Furthermore, we conduct a comprehensive analysis of both distance-based and neighbour-based thresholds and provide recommendations for selecting the appropriate value in different communication channel scenarios. We design the corresponding distance-based and neighbour-based Graph Neural Networks with the aim of allocating transmit powers to maximise the network throughput. Our results show that our proposed GNNs offer significant advantages in terms of reducing time complexity while preserving strong performance. Besides, we show that by choosing a suitable threshold, the time complexity is reduced from O(|V|^2) to O(|V|), where |V| is the total number of transceiver pairs. ",
    "url": "https://arxiv.org/abs/2305.12639",
    "authors": [
      "Lili Chen",
      "Jingge Zhu",
      "Jamie Evans"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.12656",
    "title": "Computing Multi-Eigenpairs of High-Dimensional Eigenvalue Problems Using  Tensor Neural Networks",
    "abstract": "In this paper, we propose a type of tensor-neural-network-based machine learning method to compute multi-eigenpairs of high dimensional eigenvalue problems without Monte-Carlo procedure. Solving multi-eigenvalues and their corresponding eigenfunctions is one of the basic tasks in mathematical and computational physics. With the help of tensor neural network and deep Ritz method, the high dimensional integrations included in the loss functions of the machine learning process can be computed with high accuracy. The high accuracy of high dimensional integrations can improve the accuracy of the machine learning method for computing multi-eigenpairs of high dimensional eigenvalue problems. Here, we introduce the tensor neural network and design the machine learning method for computing multi-eigenpairs of the high dimensional eigenvalue problems. The proposed numerical method is validated with plenty of numerical examples. ",
    "url": "https://arxiv.org/abs/2305.12656",
    "authors": [
      "Yifan Wang",
      "Hehi Xie"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2305.12675",
    "title": "A Frustratingly Simple Decoding Method for Neural Text Generation",
    "abstract": "We introduce a frustratingly simple, super efficient and surprisingly effective decoding method, which we call Frustratingly Simple Decoding (FSD), for neural text generation. The idea behind FSD is straightforward: we build an anti-LM based on previously generated text and use this anti-LM to penalize future generation of what has been generated. The anti-LM can be implemented as simple as an n-gram language model or a vectorized variant. In this way, FSD introduces no extra model parameters and negligible computational overhead (FSD can be as fast as greedy search). Despite the simplicity, FSD is surprisingly effective; Experiments show that FSD can outperform the canonical methods to date (i.e., nucleus sampling) as well as several strong baselines that were proposed recently. ",
    "url": "https://arxiv.org/abs/2305.12675",
    "authors": [
      "Haoran Yang",
      "Deng Cai",
      "Huayang Li",
      "Wei Bi",
      "Wai Lam",
      "Shuming Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12677",
    "title": "Tokenized Graph Transformer with Neighborhood Augmentation for Node  Classification in Large Graphs",
    "abstract": "Graph Transformers, emerging as a new architecture for graph representation learning, suffer from the quadratic complexity on the number of nodes when handling large graphs. To this end, we propose a Neighborhood Aggregation Graph Transformer (NAGphormer) that treats each node as a sequence containing a series of tokens constructed by our proposed Hop2Token module. For each node, Hop2Token aggregates the neighborhood features from different hops into different representations, producing a sequence of token vectors as one input. In this way, NAGphormer could be trained in a mini-batch manner and thus could scale to large graphs. Moreover, we mathematically show that compared to a category of advanced Graph Neural Networks (GNNs), called decoupled Graph Convolutional Networks, NAGphormer could learn more informative node representations from multi-hop neighborhoods. In addition, we propose a new data augmentation method called Neighborhood Augmentation (NrAug) based on the output of Hop2Token that augments simultaneously the features of neighborhoods from global as well as local views to strengthen the training effect of NAGphormer. Extensive experiments on benchmark datasets from small to large demonstrate the superiority of NAGphormer against existing graph Transformers and mainstream GNNs, and the effectiveness of NrAug for further boosting NAGphormer. ",
    "url": "https://arxiv.org/abs/2305.12677",
    "authors": [
      "Jinsong Chen",
      "Chang Liu",
      "Kaiyuan Gao",
      "Gaichao Li",
      "Kun He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12678",
    "title": "Gradient-Boosted Decision Tree for Listwise Context Model in Multimodal  Review Helpfulness Prediction",
    "abstract": "Multimodal Review Helpfulness Prediction (MRHP) aims to rank product reviews based on predicted helpfulness scores and has been widely applied in e-commerce via presenting customers with useful reviews. Previous studies commonly employ fully-connected neural networks (FCNNs) as the final score predictor and pairwise loss as the training objective. However, FCNNs have been shown to perform inefficient splitting for review features, making the model difficult to clearly differentiate helpful from unhelpful reviews. Furthermore, pairwise objective, which works on review pairs, may not completely capture the MRHP goal to produce the ranking for the entire review list, and possibly induces low generalization during testing. To address these issues, we propose a listwise attention network that clearly captures the MRHP ranking context and a listwise optimization objective that enhances model generalization. We further propose gradient-boosted decision tree as the score predictor to efficaciously partition product reviews' representations. Extensive experiments demonstrate that our method achieves state-of-the-art results and polished generalization performance on two large-scale MRHP benchmark datasets. ",
    "url": "https://arxiv.org/abs/2305.12678",
    "authors": [
      "Thong Nguyen",
      "Xiaobao Wu",
      "Xinshuai Dong",
      "Anh Tuan Luu",
      "Cong-Duy Nguyen",
      "Zhen Hai",
      "Lidong Bing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12681",
    "title": "Phased data augmentation for training PixelCNNs with VQ-VAE-2 and  limited data",
    "abstract": "With development of deep learning, researchers have developed generative models in generating realistic images. One of such generative models, a PixelCNNs model with Vector Quantized Variational AutoEncoder 2 (VQ-VAE-2), can generate more various images than other models. However, a PixelCNNs model with VQ-VAE-2, I call it PC-VQ2, requires sufficiently much training data like other deep learning models. Its practical applications are often limited in domains where collecting sufficient data is not difficult. To solve the problem, researchers have recently proposed more data-efficient methods for training generative models with limited unlabeled data from scratch. However, no such methods in PC-VQ2s have been researched. This study provides the first step in this direction, considering generation of images using PC-VQ2s and limited unlabeled data. In this study, I propose a training strategy for training a PC-VQ2 with limited data from scratch, phased data augmentation. In the strategy, ranges of parameters of data augmentation is narrowed in phases through learning. Quantitative evaluation shows that the phased data augmentation enables the model with limited data to generate images competitive with the one with sufficient data in diversity and outperforming it in fidelity. The evaluation suggests that the proposed method should be useful for training a PC-VQ2 with limited data efficiently to generate various and natural images. ",
    "url": "https://arxiv.org/abs/2305.12681",
    "authors": [
      "Yuta Mimura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.12682",
    "title": "Matching Game for Optimized Association in Quantum Communication  Networks",
    "abstract": "Enabling quantum switches (QSs) to serve requests submitted by quantum end nodes in quantum communication networks (QCNs) is a challenging problem due to the heterogeneous fidelity requirements of the submitted requests and the limited resources of the QCN. Effectively determining which requests are served by a given QS is fundamental to foster developments in practical QCN applications, like quantum data centers. However, the state-of-the-art on QS operation has overlooked this association problem, and it mainly focused on QCNs with a single QS. In this paper, the request-QS association problem in QCNs is formulated as a matching game that captures the limited QCN resources, heterogeneous application-specific fidelity requirements, and scheduling of the different QS operations. To solve this game, a swap-stable request-QS association (RQSA) algorithm is proposed while considering partial QCN information availability. Extensive simulations are conducted to validate the effectiveness of the proposed RQSA algorithm. Simulation results show that the proposed RQSA algorithm achieves a near-optimal (within 5%) performance in terms of the percentage of served requests and overall achieved fidelity, while outperforming benchmark greedy solutions by over 13%. Moreover, the proposed RQSA algorithm is shown to be scalable and maintain its near-optimal performance even when the size of the QCN increases. ",
    "url": "https://arxiv.org/abs/2305.12682",
    "authors": [
      "Mahdi Chehimi",
      "Bernd Simon",
      "Walid Saad",
      "Anja Klein",
      "Don Towsley",
      "M\u00e9rouane Debbah"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2305.12683",
    "title": "Mist: Towards Improved Adversarial Examples for Diffusion Models",
    "abstract": "Diffusion Models (DMs) have empowered great success in artificial-intelligence-generated content, especially in artwork creation, yet raising new concerns in intellectual properties and copyright. For example, infringers can make profits by imitating non-authorized human-created paintings with DMs. Recent researches suggest that various adversarial examples for diffusion models can be effective tools against these copyright infringements. However, current adversarial examples show weakness in transferability over different painting-imitating methods and robustness under straightforward adversarial defense, for example, noise purification. We surprisingly find that the transferability of adversarial examples can be significantly enhanced by exploiting a fused and modified adversarial loss term under consistent parameters. In this work, we comprehensively evaluate the cross-method transferability of adversarial examples. The experimental observation shows that our method generates more transferable adversarial examples with even stronger robustness against the simple adversarial defense. ",
    "url": "https://arxiv.org/abs/2305.12683",
    "authors": [
      "Chumeng Liang",
      "Xiaoyu Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12685",
    "title": "Denoised Self-Augmented Learning for Social Recommendation",
    "abstract": "Social recommendation is gaining increasing attention in various online applications, including e-commerce and online streaming, where social information is leveraged to improve user-item interaction modeling. Recently, Self-Supervised Learning (SSL) has proven to be remarkably effective in addressing data sparsity through augmented learning tasks. Inspired by this, researchers have attempted to incorporate SSL into social recommendation by supplementing the primary supervised task with social-aware self-supervised signals. However, social information can be unavoidably noisy in characterizing user preferences due to the ubiquitous presence of interest-irrelevant social connections, such as colleagues or classmates who do not share many common interests. To address this challenge, we propose a novel social recommender called the Denoised Self-Augmented Learning paradigm (DSL). Our model not only preserves helpful social relations to enhance user-item interaction modeling but also enables personalized cross-view knowledge transfer through adaptive semantic alignment in embedding space. Our experimental results on various recommendation benchmarks confirm the superiority of our DSL over state-of-the-art methods. We release our model implementation at: https://github.com/HKUDS/DSL. ",
    "url": "https://arxiv.org/abs/2305.12685",
    "authors": [
      "Tianle Wang",
      "Lianghao Xia",
      "Chao Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2305.12691",
    "title": "Hi-ResNet: A High-Resolution Remote Sensing Network for Semantic  Segmentation",
    "abstract": "High-resolution remote sensing (HRS) semantic segmentation extracts key objects from high-resolution coverage areas. However, objects of the same category within HRS images generally show significant differences in scale and shape across diverse geographical environments, making it difficult to fit the data distribution. Additionally, a complex background environment causes similar appearances of objects of different categories, which precipitates a substantial number of objects into misclassification as background. These issues make existing learning algorithms sub-optimal. In this work, we solve the above-mentioned problems by proposing a High-resolution remote sensing network (Hi-ResNet) with efficient network structure designs, which consists of a funnel module, a multi-branch module with stacks of information aggregation (IA) blocks, and a feature refinement module, sequentially, and Class-agnostic Edge Aware (CEA) loss. Specifically, we propose a funnel module to downsample, which reduces the computational cost, and extract high-resolution semantic information from the initial input image. Secondly, we downsample the processed feature images into multi-resolution branches incrementally to capture image features at different scales and apply IA blocks, which capture key latent information by leveraging attention mechanisms, for effective feature aggregation, distinguishing image features of the same class with variant scales and shapes. Finally, our feature refinement module integrate the CEA loss function, which disambiguates inter-class objects with similar shapes and increases the data distribution distance for correct predictions. With effective pre-training strategies, we demonstrated the superiority of Hi-ResNet over state-of-the-art methods on three HRS segmentation benchmarks. ",
    "url": "https://arxiv.org/abs/2305.12691",
    "authors": [
      "Yuxia Chen",
      "Pengcheng Fang",
      "Jianhui Yu",
      "Xiaoling Zhong",
      "Xiaoming Zhang",
      "Tianrui Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12692",
    "title": "MetaAdapt: Domain Adaptive Few-Shot Misinformation Detection via Meta  Learning",
    "abstract": "With emerging topics (e.g., COVID-19) on social media as a source for the spreading misinformation, overcoming the distributional shifts between the original training domain (i.e., source domain) and such target domains remains a non-trivial task for misinformation detection. This presents an elusive challenge for early-stage misinformation detection, where a good amount of data and annotations from the target domain is not available for training. To address the data scarcity issue, we propose MetaAdapt, a meta learning based approach for domain adaptive few-shot misinformation detection. MetaAdapt leverages limited target examples to provide feedback and guide the knowledge transfer from the source to the target domain (i.e., learn to adapt). In particular, we train the initial model with multiple source tasks and compute their similarity scores to the meta task. Based on the similarity scores, we rescale the meta gradients to adaptively learn from the source tasks. As such, MetaAdapt can learn how to adapt the misinformation detection model and exploit the source data for improved performance in the target domain. To demonstrate the efficiency and effectiveness of our method, we perform extensive experiments to compare MetaAdapt with state-of-the-art baselines and large language models (LLMs) such as LLaMA, where MetaAdapt achieves better performance in domain adaptive few-shot misinformation detection with substantially reduced parameters on real-world datasets. ",
    "url": "https://arxiv.org/abs/2305.12692",
    "authors": [
      "Zhenrui Yue",
      "Huimin Zeng",
      "Yang Zhang",
      "Lanyu Shang",
      "Dong Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12707",
    "title": "Quantifying Association Capabilities of Large Language Models and Its  Implications on Privacy Leakage",
    "abstract": "The advancement of large language models (LLMs) brings notable improvements across various applications, while simultaneously raising concerns about potential private data exposure. One notable capability of LLMs is their ability to form associations between different pieces of information, but this raises concerns when it comes to personally identifiable information (PII). This paper delves into the association capabilities of language models, aiming to uncover the factors that influence their proficiency in associating information. Our study reveals that as models scale up, their capacity to associate entities/information intensifies, particularly when target pairs demonstrate shorter co-occurrence distances or higher co-occurrence frequencies. However, there is a distinct performance gap when associating commonsense knowledge versus PII, with the latter showing lower accuracy. Despite the proportion of accurately predicted PII being relatively small, LLMs still demonstrate the capability to predict specific instances of email addresses and phone numbers when provided with appropriate prompts. These findings underscore the potential risk to PII confidentiality posed by the evolving capabilities of LLMs, especially as they continue to expand in scale and power. ",
    "url": "https://arxiv.org/abs/2305.12707",
    "authors": [
      "Hanyin Shao",
      "Jie Huang",
      "Shen Zheng",
      "Kevin Chen-Chuan Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.12712",
    "title": "LEAN: Light and Efficient Audio Classification Network",
    "abstract": "Over the past few years, audio classification task on large-scale dataset such as AudioSet has been an important research area. Several deeper Convolution-based Neural networks have shown compelling performance notably Vggish, YAMNet, and Pretrained Audio Neural Network (PANN). These models are available as pretrained architecture for transfer learning as well as specific audio task adoption. In this paper, we propose a lightweight on-device deep learning-based model for audio classification, LEAN. LEAN consists of a raw waveform-based temporal feature extractor called as Wave Encoder and logmel-based Pretrained YAMNet. We show that using a combination of trainable wave encoder, Pretrained YAMNet along with cross attention-based temporal realignment, results in competitive performance on downstream audio classification tasks with lesser memory footprints and hence making it suitable for resource constraints devices such as mobile, edge devices, etc . Our proposed system achieves on-device mean average precision(mAP) of .445 with a memory footprint of a mere 4.5MB on the FSD50K dataset which is an improvement of 22% over baseline on-device mAP on same dataset. ",
    "url": "https://arxiv.org/abs/2305.12712",
    "authors": [
      "Shwetank Choudhary",
      "CR Karthik",
      "Punuru Sri Lakshmi",
      "Sumit Kumar"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.12738",
    "title": "Logical Entity Representation in Knowledge-Graphs for Differentiable  Rule Learning",
    "abstract": "Probabilistic logical rule learning has shown great strength in logical rule mining and knowledge graph completion. It learns logical rules to predict missing edges by reasoning on existing edges in the knowledge graph. However, previous efforts have largely been limited to only modeling chain-like Horn clauses such as $R_1(x,z)\\land R_2(z,y)\\Rightarrow H(x,y)$. This formulation overlooks additional contextual information from neighboring sub-graphs of entity variables $x$, $y$ and $z$. Intuitively, there is a large gap here, as local sub-graphs have been found to provide important information for knowledge graph completion. Inspired by these observations, we propose Logical Entity RePresentation (LERP) to encode contextual information of entities in the knowledge graph. A LERP is designed as a vector of probabilistic logical functions on the entity's neighboring sub-graph. It is an interpretable representation while allowing for differentiable optimization. We can then incorporate LERP into probabilistic logical rule learning to learn more expressive rules. Empirical results demonstrate that with LERP, our model outperforms other rule learning methods in knowledge graph completion and is comparable or even superior to state-of-the-art black-box methods. Moreover, we find that our model can discover a more expressive family of logical rules. LERP can also be further combined with embedding learning methods like TransE to make it more interpretable. ",
    "url": "https://arxiv.org/abs/2305.12738",
    "authors": [
      "Chi Han",
      "Qizheng He",
      "Charles Yu",
      "Xinya Du",
      "Hanghang Tong",
      "Heng Ji"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2305.12744",
    "title": "Fact-Checking Complex Claims with Program-Guided Reasoning",
    "abstract": "Fact-checking real-world claims often requires collecting multiple pieces of evidence and applying complex multi-step reasoning. In this paper, we present Program-Guided Fact-Checking (ProgramFC), a novel fact-checking model that decomposes complex claims into simpler sub-tasks that can be solved using a shared library of specialized functions. We first leverage the in-context learning ability of large language models to generate reasoning programs to guide the verification process. Afterward, we execute the program by delegating each sub-task to the corresponding sub-task handler. This process makes our model both explanatory and data-efficient, providing clear explanations of its reasoning process and requiring minimal training data. We evaluate ProgramFC on two challenging fact-checking datasets and show that it outperforms seven fact-checking baselines across different settings of evidence availability, with explicit output programs that benefit human debugging. Our codes and data are publicly available at https://github.com/mbzuai-nlp/ProgramFC. ",
    "url": "https://arxiv.org/abs/2305.12744",
    "authors": [
      "Liangming Pan",
      "Xiaobao Wu",
      "Xinyuan Lu",
      "Anh Tuan Luu",
      "William Yang Wang",
      "Min-Yen Kan",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12747",
    "title": "The \"code'' of Ethics:A Holistic Audit of AI Code Generators",
    "abstract": "AI-powered programming language generation (PLG) models have gained increasing attention due to their ability to generate source code of programs in a few seconds with a plain program description. Despite their remarkable performance, many concerns are raised over the potential risks of their development and deployment, such as legal issues of copyright infringement induced by training usage of licensed code, and malicious consequences due to the unregulated use of these models. In this paper, we present the first-of-its-kind study to systematically investigate the accountability of PLG models from the perspectives of both model development and deployment. In particular, we develop a holistic framework not only to audit the training data usage of PLG models, but also to identify neural code generated by PLG models as well as determine its attribution to a source model. To this end, we propose using membership inference to audit whether a code snippet used is in the PLG model's training data. In addition, we propose a learning-based method to distinguish between human-written code and neural code. In neural code attribution, through both empirical and theoretical analysis, we show that it is impossible to reliably attribute the generation of one code snippet to one model. We then propose two feasible alternative methods: one is to attribute one neural code snippet to one of the candidate PLG models, and the other is to verify whether a set of neural code snippets can be attributed to a given PLG model. The proposed framework thoroughly examines the accountability of PLG models which are verified by extensive experiments. The implementations of our proposed framework are also encapsulated into a new artifact, named CodeForensic, to foster further research. ",
    "url": "https://arxiv.org/abs/2305.12747",
    "authors": [
      "Wanlun Ma",
      "Yiliao Song",
      "Minhui Xue",
      "Sheng Wen",
      "Yang Xiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.12760",
    "title": "Finite Blocklength Regime Performance of Downlink Large Scale Networks",
    "abstract": "Some emerging 5G and beyond use-cases impose stringent latency constraints, which necessitates a paradigm shift towards finite blocklength performance analysis. In contrast to Shannon capacity-achieving codes, the codeword length in the finite blocklength regime (FBR) is a critical design parameter that imposes an intricate tradeoff between delay, reliability, and information coding rate. In this context, this paper presents a novel mathematical analysis to characterize the performance of large-scale downlink networks using short codewords. Theoretical achievable rates, outage probability, and reliability expressions are derived using the finite blocklength coding theory in conjunction with stochastic geometry, and compared to the performance in the asymptotic regime (AR). Achievable rates under practical modulation schemes as well as multilevel polar coded modulation (MLPCM) are investigated. Numerical results provide theoretical performance benchmarks, highlight the potential of MLPCM in achieving close to optimal performance with short codewords, and confirm the discrepancy between the performance in the FBR and that predicted by analysis in the AR. Finally, the meta distribution of the coding rate is derived, providing the percentiles of users that achieve a predefined target rate in a network. ",
    "url": "https://arxiv.org/abs/2305.12760",
    "authors": [
      "Nourhan Hesham",
      "Anas Chaaban",
      "Hesham ElSawy",
      "Jahangir Hossain"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.12768",
    "title": "uCTRL: Unbiased Contrastive Representation Learning via Alignment and  Uniformity for Collaborative Filtering",
    "abstract": "Because implicit user feedback for the collaborative filtering (CF) models is biased toward popular items, CF models tend to yield recommendation lists with popularity bias. Previous studies have utilized inverse propensity weighting (IPW) or causal inference to mitigate this problem. However, they solely employ pointwise or pairwise loss functions and neglect to adopt a contrastive loss function for learning meaningful user and item representations. In this paper, we propose Unbiased ConTrastive Representation Learning (uCTRL), optimizing alignment and uniformity functions derived from the InfoNCE loss function for CF models. Specifically, we formulate an unbiased alignment function used in uCTRL. We also devise a novel IPW estimation method that removes the bias of both users and items. Despite its simplicity, uCTRL equipped with existing CF models consistently outperforms state-of-the-art unbiased recommender models, up to 12.22% for Recall@20 and 16.33% for NDCG@20 gains, on four benchmark datasets. ",
    "url": "https://arxiv.org/abs/2305.12768",
    "authors": [
      "Jae-woong Lee",
      "Seongmin Park",
      "Mincheol Yoon",
      "Jongwuk Lee"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12770",
    "title": "FGAM:Fast Adversarial Malware Generation Method Based on Gradient Sign",
    "abstract": "Malware detection models based on deep learning have been widely used, but recent research shows that deep learning models are vulnerable to adversarial attacks. Adversarial attacks are to deceive the deep learning model by generating adversarial samples. When adversarial attacks are performed on the malware detection model, the attacker will generate adversarial malware with the same malicious functions as the malware, and make the detection model classify it as benign software. Studying adversarial malware generation can help model designers improve the robustness of malware detection models. At present, in the work on adversarial malware generation for byte-to-image malware detection models, there are mainly problems such as large amount of injection perturbation and low generation efficiency. Therefore, this paper proposes FGAM (Fast Generate Adversarial Malware), a method for fast generating adversarial malware, which iterates perturbed bytes according to the gradient sign to enhance adversarial capability of the perturbed bytes until the adversarial malware is successfully generated. It is experimentally verified that the success rate of the adversarial malware deception model generated by FGAM is increased by about 84\\% compared with existing methods. ",
    "url": "https://arxiv.org/abs/2305.12770",
    "authors": [
      "Kun Li",
      "Fan Zhang",
      "Wei Guo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12778",
    "title": "STAR-RIS-UAV Aided Coordinated Multipoint Cellular System for Multi-user  Networks",
    "abstract": "Different with conventional reconfigurable intelligent surface (RIS), simultaneous transmitting and reflecting RIS (STAR-RIS) can reflect and transmit the signals to the receiver. In this paper, to serve more ground users and increase the deployment flexibility, we investigate an unmanned aerial vehicle equipped with a STAR-RIS (STAR-RIS-UAV) aided wireless communications for multi-user networks. Energy splitting (ES) and mode switching (MS) protocols are considered to control the reflection and transmission coefficients of STAR-RIS elements. To maximize the sum rate of the STAR-RIS-UAV aided coordinated multipoint cellular system for multi-user networks, the corresponding beamforming vectors as well as transmitted and reflected coefficients matrices are optimized. Specifically, instead of adopting the alternating optimization, we design an iteration method to optimize all variables for both ES and MS protocols at the same time. Simulation results reveal that STAR-RIS-UAV aided wireless communication system has a much higher sum rate than the system with conventional RIS or without RIS. Furthermore, the proposed structure is more flexible than a fixed STAR-RIS and could greatly promote the sum rate. ",
    "url": "https://arxiv.org/abs/2305.12778",
    "authors": [
      "Baihua Shi",
      "Yang Wang",
      "Danqi Li",
      "Wenlong Cai",
      "Jinyong Lin",
      "Shuo Zhang",
      "Weiping Shi",
      "Shihao Yan",
      "Feng Shu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.12782",
    "title": "Towards Robust Personalized Dialogue Generation via Order-Insensitive  Representation Regularization",
    "abstract": "Generating persona consistent dialogue response is important for developing an intelligent conversational agent. Recent works typically fine-tune large-scale pre-trained models on this task by concatenating persona texts and dialogue history as a single input sequence to generate the target response. While simple and effective, our analysis shows that this popular practice is seriously affected by order sensitivity where different input orders of persona sentences significantly impact the quality and consistency of generated response, resulting in severe performance fluctuations (i.e., 29.4% on GPT2 and 83.2% on BART). To mitigate the order sensitivity problem, we propose a model-agnostic framework, ORder Insensitive Generation (ORIG), which enables dialogue models to learn robust representation under different persona orders and improve the consistency of response generation. Experiments on the Persona-Chat dataset justify the effectiveness and superiority of our method with two dominant pre-trained models (GPT2 and BART). ",
    "url": "https://arxiv.org/abs/2305.12782",
    "authors": [
      "Liang Chen",
      "Hongru Wang",
      "Yang Deng",
      "Wai-Chung Kwan",
      "Zezhong Wang",
      "Kam-Fai Wong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12784",
    "title": "Hot Pixels: Frequency, Power, and Temperature Attacks on GPUs and ARM  SoCs",
    "abstract": "The drive to create thinner, lighter, and more energy efficient devices has resulted in modern SoCs being forced to balance a delicate tradeoff between power consumption, heat dissipation, and execution speed (i.e., frequency). While beneficial, these DVFS mechanisms have also resulted in software-visible hybrid side-channels, which use software to probe analog properties of computing devices. Such hybrid attacks are an emerging threat that can bypass countermeasures for traditional microarchitectural side-channel attacks. Given the rise in popularity of both Arm SoCs and GPUs, in this paper we investigate the susceptibility of these devices to information leakage via power, temperature and frequency, as measured via internal sensors. We demonstrate that the sensor data observed correlates with both instructions executed and data processed, allowing us to mount software-visible hybrid side-channel attacks on these devices. To demonstrate the real-world impact of this issue, we present JavaScript-based pixel stealing and history sniffing attacks on Chrome and Safari, with all side channel countermeasures enabled. Finally, we also show website fingerprinting attacks, without any elevated privileges. ",
    "url": "https://arxiv.org/abs/2305.12784",
    "authors": [
      "Hritvik Taneja",
      "Jason Kim",
      "Jie Jeff Xu",
      "Stephan van Schaik",
      "Daniel Genkin",
      "Yuval Yarom"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.12786",
    "title": "Mitigating Data Imbalance and Representation Degeneration in  Multilingual Machine Translation",
    "abstract": "Despite advances in multilingual neural machine translation (MNMT), we argue that there are still two major challenges in this area: data imbalance and representation degeneration. The data imbalance problem refers to the imbalance in the amount of parallel corpora for all language pairs, especially for long-tail languages (i.e., very low-resource languages). The representation degeneration problem refers to the problem of encoded tokens tending to appear only in a small subspace of the full space available to the MNMT model. To solve these two issues, we propose Bi-ACL, a framework that uses only target-side monolingual data and a bilingual dictionary to improve the performance of the MNMT model. We define two modules, named bidirectional autoencoder and bidirectional contrastive learning, which we combine with an online constrained beam search and a curriculum learning sampling strategy. Extensive experiments show that our proposed method is more effective both in long-tail languages and in high-resource languages. We also demonstrate that our approach is capable of transferring knowledge between domains and languages in zero-shot scenarios. ",
    "url": "https://arxiv.org/abs/2305.12786",
    "authors": [
      "Wen Lai",
      "Alexandra Chronopoulou",
      "Alexander Fraser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12788",
    "title": "GraphCare: Enhancing Healthcare Predictions with Open-World Personalized  Knowledge Graphs",
    "abstract": "Clinical predictive models often rely on patients electronic health records (EHR), but integrating medical knowledge to enhance predictions and decision-making is challenging. This is because personalized predictions require personalized knowledge graphs (KGs), which are difficult to generate from patient EHR data. To address this, we propose GraphCare, an open-world framework that leverages external KGs to improve EHR-based predictions. Our method extracts knowledge from large language models (LLMs) and external biomedical KGs to generate patient-specific KGs, which are then used to train our proposed Bi-attention AugmenTed BAT graph neural network GNN for healthcare predictions. We evaluate GraphCare on two public datasets: MIMIC-III and MIMIC-IV. Our method outperforms baseline models in four vital healthcare prediction tasks: mortality, readmission, length-of-stay, and drug recommendation, improving AUROC on MIMIC-III by average margins of 10.4%, 3.8%, 2.0%, and 1.5%, respectively. Notably, GraphCare demonstrates a substantial edge in scenarios with limited data availability. Our findings highlight the potential of using external KGs in healthcare prediction tasks and demonstrate the promise of GraphCare in generating personalized KGs for promoting personalized medicine. ",
    "url": "https://arxiv.org/abs/2305.12788",
    "authors": [
      "Pengcheng Jiang",
      "Cao Xiao",
      "Adam Cross",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12792",
    "title": "Semantic Structure Enhanced Event Causality Identification",
    "abstract": "Event Causality Identification (ECI) aims to identify causal relations between events in unstructured texts. This is a very challenging task, because causal relations are usually expressed by implicit associations between events. Existing methods usually capture such associations by directly modeling the texts with pre-trained language models, which underestimate two kinds of semantic structures vital to the ECI task, namely, event-centric structure and event-associated structure. The former includes important semantic elements related to the events to describe them more precisely, while the latter contains semantic paths between two events to provide possible supports for ECI. In this paper, we study the implicit associations between events by modeling the above explicit semantic structures, and propose a Semantic Structure Integration model (SemSIn). It utilizes a GNN-based event aggregator to integrate the event-centric structure information, and employs an LSTM-based path aggregator to capture the event-associated structure information between two events. Experimental results on three widely used datasets show that SemSIn achieves significant improvements over baseline methods. ",
    "url": "https://arxiv.org/abs/2305.12792",
    "authors": [
      "Zhilei Hu",
      "Zixuan Li",
      "Xiaolong Jin",
      "Long Bai",
      "Saiping Guan",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12798",
    "title": "LM-Switch: Lightweight Language Model Conditioning in Word Embedding  Space",
    "abstract": "In recent years, large language models (LMs) have achieved remarkable progress across various natural language processing tasks. As pre-training and fine-tuning are costly and might negatively impact model performance, it is desired to efficiently adapt an existing model to different conditions such as styles, sentiments or narratives, when facing different audiences or scenarios. However, efficient adaptation of a language model to diverse conditions remains an open challenge. This work is inspired by the observation that text conditions are often associated with selection of certain words in a context. Therefore we introduce LM-Switch, a theoretically grounded, lightweight and simple method for generative language model conditioning. We begin by investigating the effect of conditions in Hidden Markov Models (HMMs), and establish a theoretical connection with language model. Our finding suggests that condition shifts in HMMs are associated with linear transformations in word embeddings. LM-Switch is then designed to deploy a learnable linear factor in the word embedding space for language model conditioning. We show that LM-Switch can model diverse tasks, and achieves comparable or better performance compared with state-of-the-art baselines in LM detoxification and generation control, despite requiring no more than 1% of parameters compared with baselines and little extra time overhead compared with base LMs. It is also able to learn from as few as a few sentences or one document. Moreover, a learned LM-Switch can be transferred to other LMs of different sizes, achieving a detoxification performance similar to the best baseline. We will make our code available to the research community following publication. ",
    "url": "https://arxiv.org/abs/2305.12798",
    "authors": [
      "Chi Han",
      "Jialiang Xu",
      "Manling Li",
      "Yi Fung",
      "Chenkai Sun",
      "Nan Jiang",
      "Tarek Abdelzaher",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12800",
    "title": "Single Domain Dynamic Generalization for Iris Presentation Attack  Detection",
    "abstract": "Iris presentation attack detection (PAD) has achieved great success under intra-domain settings but easily degrades on unseen domains. Conventional domain generalization methods mitigate the gap by learning domain-invariant features. However, they ignore the discriminative information in the domain-specific features. Moreover, we usually face a more realistic scenario with only one single domain available for training. To tackle the above issues, we propose a Single Domain Dynamic Generalization (SDDG) framework, which simultaneously exploits domain-invariant and domain-specific features on a per-sample basis and learns to generalize to various unseen domains with numerous natural images. Specifically, a dynamic block is designed to adaptively adjust the network with a dynamic adaptor. And an information maximization loss is further combined to increase diversity. The whole network is integrated into the meta-learning paradigm. We generate amplitude perturbed images and cover diverse domains with natural images. Therefore, the network can learn to generalize to the perturbed domains in the meta-test phase. Extensive experiments show the proposed method is effective and outperforms the state-of-the-art on LivDet-Iris 2017 dataset. ",
    "url": "https://arxiv.org/abs/2305.12800",
    "authors": [
      "Yachun Li",
      "Jingjing Wang",
      "Yuhui Chen",
      "Di Xie",
      "Shiliang Pu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12809",
    "title": "Relabel Minimal Training Subset to Flip a Prediction",
    "abstract": "Yang et al. (2023) discovered that removing a mere 1% of training points can often lead to the flipping of a prediction. Given the prevalence of noisy data in machine learning models, we pose the question: can we also result in the flipping of a test prediction by relabeling a small subset of the training data before the model is trained? In this paper, utilizing the extended influence function, we propose an efficient procedure for identifying and relabeling such a subset, demonstrating consistent success. This mechanism serves multiple purposes: (1) providing a complementary approach to challenge model predictions by recovering potentially mislabeled training points; (2) evaluating model resilience, as our research uncovers a significant relationship between the subset's size and the ratio of noisy data in the training set; and (3) offering insights into bias within the training set. To the best of our knowledge, this work represents the first investigation into the problem of identifying and relabeling the minimal training subset required to flip a given prediction. ",
    "url": "https://arxiv.org/abs/2305.12809",
    "authors": [
      "Jinghan Yang",
      "Lequan Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.12817",
    "title": "Conservative Physics-Informed Neural Networks for Non-Conservative  Hyperbolic Conservation Laws Near Critical States",
    "abstract": "In this paper, a modified version of conservative Physics-informed Neural Networks (cPINN for short) is provided to construct the weak solutions of Riemann problem for the hyperbolic scalar conservation laws in non-conservative form. To demonstrate the results, we use the model of generalized Buckley-Leverett equation (GBL equation for short) with discontinuous porosity in porous media. By inventing a new unknown, the GBL equation is transformed into a two-by-two resonant hyperbolic conservation laws in conservative form. The modified method of cPINN is invented to overcome the difficulties due to the discontinuity of the porosity and the appearance of the critical states (near vacuum) in the Riemann data. We experiment with our idea by using a deep learning algorithm to solve the GBL equation in both conservative and non-conservative forms, as well as the cases of critical and non-critical states. This method provides a combination of two different neural networks and corresponding loss functions, one is for the two-by-two resonant hyperbolic system, and the other is for the scalar conservation law with a discontinuous perturbation term in the non-convex flux. The technique of re-scaling to the unknowns is adopted to avoid the oscillation of the Riemann solutions in the cases of critical Riemann data. The solutions constructed by the modified cPINN match the exact solutions constructed by the theoretical analysis for hyperbolic conservation laws. In addition, the solutions are identical in both conservative and non-conservative cases. Finally, we compare the performance of the modified cPINN with numerical method called WENO5. Whereas WENO5 struggles with the highly oscillation of approximate solutions for the Riemann problems of GBL equation in non-conservative form, cPINN works admirably. ",
    "url": "https://arxiv.org/abs/2305.12817",
    "authors": [
      "Reyna Quita",
      "Yu-Shuo Chen",
      "Hsin-Yi Lee Alex C. Hu",
      "John M. Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12818",
    "title": "Crosslingual Transfer Learning for Low-Resource Languages Based on  Multilingual Colexification Graphs",
    "abstract": "Colexification in comparative linguistics refers to the phenomenon of a lexical form conveying two or more distinct meanings. In this paper, we propose simple and effective methods to build multilingual graphs from colexification patterns: ColexNet and ColexNet+. ColexNet's nodes are concepts and its edges are colexifications. In ColexNet+, concept nodes are in addition linked through intermediate nodes, each representing an ngram in one of 1,334 languages. We use ColexNet+ to train high-quality multilingual embeddings $\\overrightarrow{\\mbox{ColexNet+}}$ that are well-suited for transfer learning scenarios. Existing work on colexification patterns relies on annotated word lists. This limits scalability and usefulness in NLP. In contrast, we identify colexification patterns of more than 2,000 concepts across 1,335 languages directly from an unannotated parallel corpus. In our experiments, we first show that ColexNet has a high recall on CLICS, a dataset of crosslingual colexifications. We then evaluate $\\overrightarrow{\\mbox{ColexNet+}}$ on roundtrip translation, verse retrieval and verse classification and show that our embeddings surpass several baselines in a transfer learning setting. This demonstrates the benefits of colexification for multilingual NLP. ",
    "url": "https://arxiv.org/abs/2305.12818",
    "authors": [
      "Yihong Liu",
      "Haotian Ye",
      "Leonie Weissweiler",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12821",
    "title": "FurnitureBench: Reproducible Real-World Benchmark for Long-Horizon  Complex Manipulation",
    "abstract": "Reinforcement learning (RL), imitation learning (IL), and task and motion planning (TAMP) have demonstrated impressive performance across various robotic manipulation tasks. However, these approaches have been limited to learning simple behaviors in current real-world manipulation benchmarks, such as pushing or pick-and-place. To enable more complex, long-horizon behaviors of an autonomous robot, we propose to focus on real-world furniture assembly, a complex, long-horizon robot manipulation task that requires addressing many current robotic manipulation challenges to solve. We present FurnitureBench, a reproducible real-world furniture assembly benchmark aimed at providing a low barrier for entry and being easily reproducible, so that researchers across the world can reliably test their algorithms and compare them against prior work. For ease of use, we provide 200+ hours of pre-collected data (5000+ demonstrations), 3D printable furniture models, a robotic environment setup guide, and systematic task initialization. Furthermore, we provide FurnitureSim, a fast and realistic simulator of FurnitureBench. We benchmark the performance of offline RL and IL algorithms on our assembly tasks and demonstrate the need to improve such algorithms to be able to solve our tasks in the real world, providing ample opportunities for future research. ",
    "url": "https://arxiv.org/abs/2305.12821",
    "authors": [
      "Minho Heo",
      "Youngwoon Lee",
      "Doohyun Lee",
      "Joseph J. Lim"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12823",
    "title": "READMem: Robust Embedding Association for a Diverse Memory in  Unconstrained Video Object Segmentation",
    "abstract": "We present READMem (Robust Embedding Association for a Diverse Memory), a modular framework for semi-automatic video object segmentation (sVOS) methods designed to handle unconstrained videos. Contemporary sVOS works typically aggregate video frames in an ever-expanding memory, demanding high hardware resources for long-term applications. To mitigate memory requirements and prevent near object duplicates (caused by information of adjacent frames), previous methods introduce a hyper-parameter that controls the frequency of frames eligible to be stored. This parameter has to be adjusted according to concrete video properties (such as rapidity of appearance changes and video length) and does not generalize well. Instead, we integrate the embedding of a new frame into the memory only if it increases the diversity of the memory content. Furthermore, we propose a robust association of the embeddings stored in the memory with query embeddings during the update process. Our approach avoids the accumulation of redundant data, allowing us in return, to restrict the memory size and prevent extreme memory demands in long videos. We extend popular sVOS baselines with READMem, which previously showed limited performance on long videos. Our approach achieves competitive results on the Long-time Video dataset (LV1) while not hindering performance on short sequences. Our code is publicly available. ",
    "url": "https://arxiv.org/abs/2305.12823",
    "authors": [
      "St\u00e9phane Vujasinovi\u0107",
      "Sebastian Bullinger",
      "Stefan Becker",
      "Norbert Scherer-Negenborn",
      "Michael Arens",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12825",
    "title": "Uncertainty-based Detection of Adversarial Attacks in Semantic  Segmentation",
    "abstract": "State-of-the-art deep neural networks have proven to be highly powerful in a broad range of tasks, including semantic image segmentation. However, these networks are vulnerable against adversarial attacks, i.e., non-perceptible perturbations added to the input image causing incorrect predictions, which is hazardous in safety-critical applications like automated driving. Adversarial examples and defense strategies are well studied for the image classification task, while there has been limited research in the context of semantic segmentation. First works however show that the segmentation outcome can be severely distorted by adversarial attacks. In this work, we introduce an uncertainty-based method for the detection of adversarial attacks in semantic segmentation. We observe that uncertainty as for example captured by the entropy of the output distribution behaves differently on clean and perturbed images using this property to distinguish between the two cases. Our method works in a light-weight and post-processing manner, i.e., we do not modify the model or need knowledge of the process used for generating adversarial examples. In a thorough empirical analysis, we demonstrate the ability of our approach to detect perturbed images across multiple types of adversarial attacks. ",
    "url": "https://arxiv.org/abs/2305.12825",
    "authors": [
      "Kira Maag",
      "Asja Fischer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12833",
    "title": "Boosting Long-tailed Object Detection via Step-wise Learning on  Smooth-tail Data",
    "abstract": "Real-world data tends to follow a long-tailed distribution, where the class imbalance results in dominance of the head classes during training. In this paper, we propose a frustratingly simple but effective step-wise learning framework to gradually enhance the capability of the model in detecting all categories of long-tailed datasets. Specifically, we build smooth-tail data where the long-tailed distribution of categories decays smoothly to correct the bias towards head classes. We pre-train a model on the whole long-tailed data to preserve discriminability between all categories. We then fine-tune the class-agnostic modules of the pre-trained model on the head class dominant replay data to get a head class expert model with improved decision boundaries from all categories. Finally, we train a unified model on the tail class dominant replay data while transferring knowledge from the head class expert model to ensure accurate detection of all categories. Extensive experiments on long-tailed datasets LVIS v0.5 and LVIS v1.0 demonstrate the superior performance of our method, where we can improve the AP with ResNet-50 backbone from 27.0% to 30.3% AP, and especially for the rare categories from 15.5% to 24.9% AP. Our best model using ResNet-101 backbone can achieve 30.7% AP, which suppresses all existing detectors using the same backbone. ",
    "url": "https://arxiv.org/abs/2305.12833",
    "authors": [
      "Na Dong",
      "Yongqiang Zhang",
      "Mingli Ding",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12835",
    "title": "Open-Domain Event Graph Induction for Mitigating Framing Bias",
    "abstract": "Researchers have proposed various information extraction (IE) techniques to convert news articles into structured knowledge for news understanding. However, none of the existing methods have explicitly addressed the issue of framing bias that is inherent in news articles. We argue that studying and identifying framing bias is a crucial step towards trustworthy event understanding. We propose a novel task, neutral event graph induction, to address this problem. An event graph is a network of events and their temporal relations. Our task aims to induce such structural knowledge with minimal framing bias in an open domain. We propose a three-step framework to induce a neutral event graph from multiple input sources. The process starts by inducing an event graph from each input source, then merging them into one merged event graph, and lastly using a Graph Convolutional Network to remove event nodes with biased connotations. We demonstrate the effectiveness of our framework through the use of graph prediction metrics and bias-focused metrics. ",
    "url": "https://arxiv.org/abs/2305.12835",
    "authors": [
      "Siyi Liu",
      "Hongming Zhang",
      "Hongwei Wang",
      "Kaiqiang Song",
      "Dan Roth",
      "Dong Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12842",
    "title": "Integrated Sensing, Navigation, and Communication for Secure UAV  Networks with a Mobile Eavesdropper",
    "abstract": "This paper proposes an integrated sensing, navigation, and communication (ISNC) framework for safeguarding unmanned aerial vehicle (UAV)-enabled wireless networks against a mobile eavesdropping UAV (E-UAV). To cope with the mobility of the E-UAV, the proposed framework advocates the dual use of artificial noise transmitted by the information UAV (I-UAV) for simultaneous jamming and sensing to facilitate navigation and secure communication. In particular, the I-UAV communicates with legitimate downlink ground users, while avoiding potential information leakage by emitting jamming signals, and estimates the state of the E-UAV with an extended Kalman filter based on the backscattered jamming signals. Exploiting the estimated state of the E-UAV in the previous time slot, the I-UAV determines its flight planning strategy, predicts the wiretap channel, and designs its communication resource allocation policy for the next time slot. To circumvent the severe coupling between these three tasks, a divide-and-conquer approach is adopted. The online navigation design has the objective to minimize the distance between the I-UAV and a pre-defined destination point considering kinematic and geometric constraints. Subsequently, given the predicted wiretap channel, the robust resource allocation design is formulated as an optimization problem to achieve the optimal trade-off between sensing and communication in the next time slot, while taking into account the wiretap channel prediction error and the quality-of-service (QoS) requirements of secure communication. Simulation results demonstrate the superior performance of the proposed design compared with baseline schemes and validate the benefits of integrating sensing and navigation into secure UAV communication systems. ",
    "url": "https://arxiv.org/abs/2305.12842",
    "authors": [
      "Zhiqiang Wei",
      "Fan Liu",
      "Chang Liu",
      "Zai Yang",
      "Derrick Wing Kwan Ng",
      "Robert Schober"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.12843",
    "title": "Registering Neural Radiance Fields as 3D Density Images",
    "abstract": "No significant work has been done to directly merge two partially overlapping scenes using NeRF representations. Given pre-trained NeRF models of a 3D scene with partial overlapping, this paper aligns them with a rigid transform, by generalizing the traditional registration pipeline, that is, key point detection and point set registration, to operate on 3D density fields. To describe corner points as key points in 3D, we propose to use universal pre-trained descriptor-generating neural networks that can be trained and tested on different scenes. We perform experiments to demonstrate that the descriptor networks can be conveniently trained using a contrastive learning strategy. We demonstrate that our method, as a global approach, can effectively register NeRF models, thus making possible future large-scale NeRF construction by registering its smaller and overlapping NeRFs captured individually. ",
    "url": "https://arxiv.org/abs/2305.12843",
    "authors": [
      "Han Jiang",
      "Ruoxuan Li",
      "Haosen Sun",
      "Yu-Wing Tai",
      "Chi-Keung Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12845",
    "title": "Bright Channel Prior Attention for Multispectral Pedestrian Detection",
    "abstract": "Multispectral methods have gained considerable attention due to their promising performance across various fields. However, most existing methods cannot effectively utilize information from two modalities while optimizing time efficiency. These methods often prioritize accuracy or time efficiency, leaving room for improvement in their performance. To this end, we propose a new method bright channel prior attention for enhancing pedestrian detection in low-light conditions by integrating image enhancement and detection within a unified framework. The method uses the V-channel of the HSV image of the thermal image as an attention map to trigger the unsupervised auto-encoder for visible light images, which gradually emphasizes pedestrian features across layers. Moreover, we utilize unsupervised bright channel prior algorithms to address light compensation in low light images. The proposed method includes a self-attention enhancement module and a detection module, which work together to improve object detection. An initial illumination map is estimated using the BCP, guiding the learning of the self-attention map from the enhancement network to obtain more informative representation focused on pedestrians. The extensive experiments show effectiveness of the proposed method is demonstrated through. ",
    "url": "https://arxiv.org/abs/2305.12845",
    "authors": [
      "Chenhang Cui",
      "Jinyu Xie",
      "Yechenhao Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12852",
    "title": "Cycle Consistency-based Uncertainty Quantification of Neural Networks in  Inverse Imaging Problems",
    "abstract": "Uncertainty estimation is critical for numerous applications of deep neural networks and draws growing attention from researchers. Here, we demonstrate an uncertainty quantification approach for deep neural networks used in inverse problems based on cycle consistency. We build forward-backward cycles using the physical forward model available and a trained deep neural network solving the inverse problem at hand, and accordingly derive uncertainty estimators through regression analysis on the consistency of these forward-backward cycles. We theoretically analyze cycle consistency metrics and derive their relationship with respect to uncertainty, bias, and robustness of the neural network inference. To demonstrate the effectiveness of these cycle consistency-based uncertainty estimators, we classified corrupted and out-of-distribution input image data using some of the widely used image deblurring and super-resolution neural networks as testbeds. The blind testing of our method outperformed other models in identifying unseen input data corruption and distribution shifts. This work provides a simple-to-implement and rapid uncertainty quantification method that can be universally applied to various neural networks used for solving inverse problems. ",
    "url": "https://arxiv.org/abs/2305.12852",
    "authors": [
      "Luzhe Huang",
      "Jianing Li",
      "Xiaofu Ding",
      "Yijie Zhang",
      "Hanlong Chen",
      "Aydogan Ozcan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Optics (physics.optics)"
    ]
  },
  {
    "id": "arXiv:2305.12853",
    "title": "Real-Aug: Realistic Scene Synthesis for LiDAR Augmentation in 3D Object  Detection",
    "abstract": "Data and model are the undoubtable two supporting pillars for LiDAR object detection. However, data-centric works have fallen far behind compared with the ever-growing list of fancy new models. In this work, we systematically study the synthesis-based LiDAR data augmentation approach (so-called GT-Aug) which offers maxium controllability over generated data samples. We pinpoint the main shortcoming of existing works is introducing unrealistic LiDAR scan patterns during GT-Aug. In light of this finding, we propose Real-Aug, a synthesis-based augmentation method which prioritizes on generating realistic LiDAR scans. Our method consists a reality-conforming scene composition module which handles the details of the composition and a real-synthesis mixing up training strategy which gradually adapts the data distribution from synthetic data to the real one. To verify the effectiveness of our methods, we conduct extensive ablation studies and validate the proposed Real-Aug on a wide combination of detectors and datasets. We achieve a state-of-the-art 0.744 NDS and 0.702 mAP on nuScenes test set. The code shall be released soon. ",
    "url": "https://arxiv.org/abs/2305.12853",
    "authors": [
      "Jinglin Zhan",
      "Tiejun Liu",
      "Rengang Li",
      "Jingwei Zhang",
      "Zhaoxiang Zhang",
      "Yuntao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12859",
    "title": "Flying Adversarial Patches: Manipulating the Behavior of Deep  Learning-based Autonomous Multirotors",
    "abstract": "Autonomous flying robots, e.g. multirotors, often rely on a neural network that makes predictions based on a camera image. These deep learning (DL) models can compute surprising results if applied to input images outside the training domain. Adversarial attacks exploit this fault, for example, by computing small images, so-called adversarial patches, that can be placed in the environment to manipulate the neural network's prediction. We introduce flying adversarial patches, where an image is mounted on another flying robot and therefore can be placed anywhere in the field of view of a victim multirotor. For an effective attack, we compare three methods that simultaneously optimize the adversarial patch and its position in the input image. We perform an empirical validation on a publicly available DL model and dataset for autonomous multirotors. Ultimately, our attacking multirotor would be able to gain full control over the motions of the victim multirotor. ",
    "url": "https://arxiv.org/abs/2305.12859",
    "authors": [
      "Pia Hanfeld",
      "Marina M.-C. H\u00f6hne",
      "Michael Bussmann",
      "Wolfgang H\u00f6nig"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.12863",
    "title": "Towards Benchmarking and Assessing Visual Naturalness of Physical World  Adversarial Attacks",
    "abstract": "Physical world adversarial attack is a highly practical and threatening attack, which fools real world deep learning systems by generating conspicuous and maliciously crafted real world artifacts. In physical world attacks, evaluating naturalness is highly emphasized since human can easily detect and remove unnatural attacks. However, current studies evaluate naturalness in a case-by-case fashion, which suffers from errors, bias and inconsistencies. In this paper, we take the first step to benchmark and assess visual naturalness of physical world attacks, taking autonomous driving scenario as the first attempt. First, to benchmark attack naturalness, we contribute the first Physical Attack Naturalness (PAN) dataset with human rating and gaze. PAN verifies several insights for the first time: naturalness is (disparately) affected by contextual features (i.e., environmental and semantic variations) and correlates with behavioral feature (i.e., gaze signal). Second, to automatically assess attack naturalness that aligns with human ratings, we further introduce Dual Prior Alignment (DPA) network, which aims to embed human knowledge into model reasoning process. Specifically, DPA imitates human reasoning in naturalness assessment by rating prior alignment and mimics human gaze behavior by attentive prior alignment. We hope our work fosters researches to improve and automatically assess naturalness of physical world attacks. Our code and dataset can be found at https://github.com/zhangsn-19/PAN. ",
    "url": "https://arxiv.org/abs/2305.12863",
    "authors": [
      "Simin Li",
      "Shuing Zhang",
      "Gujun Chen",
      "Dong Wang",
      "Pu Feng",
      "Jiakai Wang",
      "Aishan Liu",
      "Xin Yi",
      "Xianglong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12865",
    "title": "Automatic Code Summarization via ChatGPT: How Far Are We?",
    "abstract": "To support software developers in understanding and maintaining programs, various automatic code summarization techniques have been proposed to generate a concise natural language comment for a given code snippet. Recently, the emergence of large language models (LLMs) has led to a great boost in the performance of natural language processing tasks. Among them, ChatGPT is the most popular one which has attracted wide attention from the software engineering community. However, it still remains unclear how ChatGPT performs in (automatic) code summarization. Therefore, in this paper, we focus on evaluating ChatGPT on a widely-used Python dataset called CSN-Python and comparing it with several state-of-the-art (SOTA) code summarization models. Specifically, we first explore an appropriate prompt to guide ChatGPT to generate in-distribution comments. Then, we use such a prompt to ask ChatGPT to generate comments for all code snippets in the CSN-Python test set. We adopt three widely-used metrics (including BLEU, METEOR, and ROUGE-L) to measure the quality of the comments generated by ChatGPT and SOTA models (including NCS, CodeBERT, and CodeT5). The experimental results show that in terms of BLEU and ROUGE-L, ChatGPT's code summarization performance is significantly worse than all three SOTA models. We also present some cases and discuss the advantages and disadvantages of ChatGPT in code summarization. Based on the findings, we outline several open challenges and opportunities in ChatGPT-based code summarization. ",
    "url": "https://arxiv.org/abs/2305.12865",
    "authors": [
      "Weisong Sun",
      "Chunrong Fang",
      "Yudu You",
      "Yun Miao",
      "Yi Liu",
      "Yuekang Li",
      "Gelei Deng",
      "Shenghan Huang",
      "Yuchen Chen",
      "Quanjun Zhang",
      "Hanwei Qian",
      "Yang Liu",
      "Zhenyu Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12868",
    "title": "NAS-FM: Neural Architecture Search for Tunable and Interpretable Sound  Synthesis based on Frequency Modulation",
    "abstract": "Developing digital sound synthesizers is crucial to the music industry as it provides a low-cost way to produce high-quality sounds with rich timbres. Existing traditional synthesizers often require substantial expertise to determine the overall framework of a synthesizer and the parameters of submodules. Since expert knowledge is hard to acquire, it hinders the flexibility to quickly design and tune digital synthesizers for diverse sounds. In this paper, we propose ``NAS-FM'', which adopts neural architecture search (NAS) to build a differentiable frequency modulation (FM) synthesizer. Tunable synthesizers with interpretable controls can be developed automatically from sounds without any prior expert knowledge and manual operating costs. In detail, we train a supernet with a specifically designed search space, including predicting the envelopes of carriers and modulators with different frequency ratios. An evolutionary search algorithm with adaptive oscillator size is then developed to find the optimal relationship between oscillators and the frequency ratio of FM. Extensive experiments on recordings of different instrument sounds show that our algorithm can build a synthesizer fully automatically, achieving better results than handcrafted synthesizers. Audio samples are available at https://nas-fm.github.io/. ",
    "url": "https://arxiv.org/abs/2305.12868",
    "authors": [
      "Zhen Ye",
      "Wei Xue",
      "Xu Tan",
      "Qifeng Liu",
      "Yike Guo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.12870",
    "title": "Lion: Adversarial Distillation of Closed-Source Large Language Model",
    "abstract": "The practice of transferring knowledge from a sophisticated, closed-source large language model (LLM) to a compact, open-source LLM has garnered considerable attention. Previous works have focused on a unidirectional knowledge distillation way by aligning the responses of the student model with those of the teacher model to a set of instructions. Nevertheless, they overlooked the possibility of incorporating any reciprocal \"feedback\"--identifying challenging instructions where the student model's performance falls short--to boost the student model's proficiency iteratively. To this end, we propose a novel adversarial distillation framework for a more efficient knowledge transfer. Leveraging the versatile role adaptability of LLMs, we prompt the closed-source model to identify \"hard\" instructions and generate new \"hard\" instructions for the student model, creating a three-stage adversarial loop of imitation, discrimination, and generation. By applying this adversarial framework, we successfully transfer knowledge from ChatGPT to a 7B student model (named Lion), achieving nearly 95% capability approximation using a mere 70k training data. We aspire that this proposed model may serve as the baseline to reflect the performance of ChatGPT, especially the open-source instruction-following language model baseline for our community. ",
    "url": "https://arxiv.org/abs/2305.12870",
    "authors": [
      "Yuxin Jiang",
      "Chunkit Chan",
      "Mingyang Chen",
      "Wei Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12872",
    "title": "Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a  Bayesian Game",
    "abstract": "In this study, we explore the robustness of cooperative multi-agent reinforcement learning (c-MARL) against Byzantine failures, where any agent can enact arbitrary, worst-case actions due to malfunction or adversarial attack. To address the uncertainty that any agent can be adversarial, we propose a Bayesian Adversarial Robust Dec-POMDP (BARDec-POMDP) framework, which views Byzantine adversaries as nature-dictated types, represented by a separate transition. This allows agents to learn policies grounded on their posterior beliefs about the type of other agents, fostering collaboration with identified allies and minimizing vulnerability to adversarial manipulation. We define the optimal solution to the BARDec-POMDP as an ex post robust Bayesian Markov perfect equilibrium, which we proof to exist and weakly dominates the equilibrium of previous robust MARL approaches. To realize this equilibrium, we put forward a two-timescale actor-critic algorithm with almost sure convergence under specific conditions. Experimentation on matrix games, level-based foraging and StarCraft II indicate that, even under worst-case perturbations, our method successfully acquires intricate micromanagement skills and adaptively aligns with allies, demonstrating resilience against non-oblivious adversaries, random allies, observation-based attacks, and transfer-based attacks. ",
    "url": "https://arxiv.org/abs/2305.12872",
    "authors": [
      "Simin Li",
      "Jun Guo",
      "Jingqiao Xiu",
      "Xini Yu",
      "Jiakai Wang",
      "Aishan Liu",
      "Yaodong Yang",
      "Xianglong Liu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2305.12875",
    "title": "Powering AI at the Edge: A Robust, Memristor-based Binarized Neural  Network with Near-Memory Computing and Miniaturized Solar Cell",
    "abstract": "Memristor-based neural networks provide an exceptional energy-efficient platform for artificial intelligence (AI), presenting the possibility of self-powered operation when paired with energy harvesters. However, most memristor-based networks rely on analog in-memory computing, necessitating a stable and precise power supply, which is incompatible with the inherently unstable and unreliable energy harvesters. In this work, we fabricated a robust binarized neural network comprising 32,768 memristors, powered by a miniature wide-bandgap solar cell optimized for edge applications. Our circuit employs a resilient digital near-memory computing approach, featuring complementarily programmed memristors and logic-in-sense-amplifier. This design eliminates the need for compensation or calibration, operating effectively under diverse conditions. Under high illumination, the circuit achieves inference performance comparable to that of a lab bench power supply. In low illumination scenarios, it remains functional with slightly reduced accuracy, seamlessly transitioning to an approximate computing mode. Through image classification neural network simulations, we demonstrate that misclassified images under low illumination are primarily difficult-to-classify cases. Our approach lays the groundwork for self-powered AI and the creation of intelligent sensors for various applications in health, safety, and environment monitoring. ",
    "url": "https://arxiv.org/abs/2305.12875",
    "authors": [
      "Fadi Jebali",
      "Atreya Majumdar",
      "Cl\u00e9ment Turck",
      "Kamel-Eddine Harabi",
      "Mathieu-Coumba Faye",
      "Eloi Muhr",
      "Jean-Pierre Walder",
      "Oleksandr Bilousov",
      "Amadeo Michaud",
      "Elisa Vianello",
      "Tifenn Hirtzlin",
      "Fran\u00e7ois Andrieu",
      "Marc Bocquet",
      "St\u00e9phane Collin",
      "Damien Querlioz",
      "Jean-Michel Portal"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2305.12886",
    "title": "End-to-End Stable Imitation Learning via Autonomous Neural Dynamic  Policies",
    "abstract": "State-of-the-art sensorimotor learning algorithms offer policies that can often produce unstable behaviors, damaging the robot and/or the environment. Traditional robot learning, on the contrary, relies on dynamical system-based policies that can be analyzed for stability/safety. Such policies, however, are neither flexible nor generic and usually work only with proprioceptive sensor states. In this work, we bridge the gap between generic neural network policies and dynamical system-based policies, and we introduce Autonomous Neural Dynamic Policies (ANDPs) that: (a) are based on autonomous dynamical systems, (b) always produce asymptotically stable behaviors, and (c) are more flexible than traditional stable dynamical system-based policies. ANDPs are fully differentiable, flexible generic-policies that can be used in imitation learning setups while ensuring asymptotic stability. In this paper, we explore the flexibility and capacity of ANDPs in several imitation learning tasks including experiments with image observations. The results show that ANDPs combine the benefits of both neural network-based and dynamical system-based methods. ",
    "url": "https://arxiv.org/abs/2305.12886",
    "authors": [
      "Dionis Totsila",
      "Konstantinos Chatzilygeroudis",
      "Denis Hadjivelichkov",
      "Valerio Modugno",
      "Ioannis Hatzilygeroudis",
      "Dimitrios Kanoulas"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2305.12895",
    "title": "DEGREE: Decomposition Based Explanation For Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) are gaining extensive attention for their application in graph data. However, the black-box nature of GNNs prevents users from understanding and trusting the models, thus hampering their applicability. Whereas explaining GNNs remains a challenge, most existing methods fall into approximation based and perturbation based approaches with suffer from faithfulness problems and unnatural artifacts, respectively. To tackle these problems, we propose DEGREE \\degree to provide a faithful explanation for GNN predictions. By decomposing the information generation and aggregation mechanism of GNNs, DEGREE allows tracking the contributions of specific components of the input graph to the final prediction. Based on this, we further design a subgraph level interpretation algorithm to reveal complex interactions between graph nodes that are overlooked by previous methods. The efficiency of our algorithm can be further improved by utilizing GNN characteristics. Finally, we conduct quantitative and qualitative experiments on synthetic and real-world datasets to demonstrate the effectiveness of DEGREE on node classification and graph classification tasks. ",
    "url": "https://arxiv.org/abs/2305.12895",
    "authors": [
      "Qizhang Feng",
      "Ninghao Liu",
      "Fan Yang",
      "Ruixiang Tang",
      "Mengnan Du",
      "Xia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12900",
    "title": "Evaluating Prompt-based Question Answering for Object Prediction in the  Open Research Knowledge Graph",
    "abstract": "There have been many recent investigations into prompt-based training of transformer language models for new text genres in low-resource settings. The prompt-based training approach has been found to be effective in generalizing pre-trained or fine-tuned models for transfer to resource-scarce settings. This work, for the first time, reports results on adopting prompt-based training of transformers for \\textit{scholarly knowledge graph object prediction}. The work is unique in the following two main aspects. 1) It deviates from the other works proposing entity and relation extraction pipelines for predicting objects of a scholarly knowledge graph. 2) While other works have tested the method on text genera relatively close to the general knowledge domain, we test the method for a significantly different domain, i.e. scholarly knowledge, in turn testing the linguistic, probabilistic, and factual generalizability of these large-scale transformer models. We find that (i) per expectations, transformer models when tested out-of-the-box underperform on a new domain of data, (ii) prompt-based training of the models achieve performance boosts of up to 40\\% in a relaxed evaluation setting, and (iii) testing the models on a starkly different domain even with a clever training objective in a low resource setting makes evident the domain knowledge capture gap offering an empirically-verified incentive for investing more attention and resources to the scholarly domain in the context of transformer models. ",
    "url": "https://arxiv.org/abs/2305.12900",
    "authors": [
      "Jennifer D'Souza",
      "Moussab Hrou",
      "S\u00f6ren Auer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Digital Libraries (cs.DL)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.12906",
    "title": "Latent Magic: An Investigation into Adversarial Examples Crafted in the  Semantic Latent Space",
    "abstract": "Adversarial attacks against Deep Neural Networks(DNN) have been a crutial topic ever since \\cite{goodfellow} purposed the vulnerability of DNNs. However, most prior works craft adversarial examples in the pixel space, following the $l_p$ norm constraint. In this paper, we give intuitional explain about why crafting adversarial examples in the latent space is equally efficient and important. We purpose a framework for crafting adversarial examples in semantic latent space based on an pre-trained Variational Auto Encoder from state-of-art Stable Diffusion Model\\cite{SDM}. We also show that adversarial examples crafted in the latent space can also achieve a high level of fool rate. However, examples crafted from latent space are often hard to evaluated, as they doesn't follow a certain $l_p$ norm constraint, which is a big challenge for existing researches. To efficiently and accurately evaluate the adversarial examples crafted in the latent space, we purpose \\textbf{a novel evaluation matric} based on SSIM\\cite{SSIM} loss and fool rate.Additionally, we explain why FID\\cite{FID} is not suitable for measuring such adversarial examples. To the best of our knowledge, it's the first evaluation metrics that is specifically designed to evaluate the quality of a adversarial attack. We also investigate the transferability of adversarial examples crafted in the latent space and show that they have superiority over adversarial examples crafted in the pixel space. ",
    "url": "https://arxiv.org/abs/2305.12906",
    "authors": [
      "BoYang Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12932",
    "title": "Forecasting Irregularly Sampled Time Series using Graphs",
    "abstract": "Forecasting irregularly sampled time series with missing values is a crucial task for numerous real-world applications such as healthcare, astronomy, and climate sciences. State-of-the-art approaches to this problem rely on Ordinary Differential Equations (ODEs) but are known to be slow and to require additional features to handle missing values. To address this issue, we propose a novel model using Graphs for Forecasting Irregularly Sampled Time Series with missing values which we call GraFITi. GraFITi first converts the time series to a Sparsity Structure Graph which is a sparse bipartite graph, and then reformulates the forecasting problem as the edge weight prediction task in the graph. It uses the power of Graph Neural Networks to learn the graph and predict the target edge weights. We show that GraFITi can be used not only for our Sparsity Structure Graph but also for alternative graph representations of time series. GraFITi has been tested on 3 real-world and 1 synthetic irregularly sampled time series dataset with missing values and compared with various state-of-the-art models. The experimental results demonstrate that GraFITi improves the forecasting accuracy by up to 17% and reduces the run time up to 5 times compared to the state-of-the-art forecasting models. ",
    "url": "https://arxiv.org/abs/2305.12932",
    "authors": [
      "Vijaya Krishna Yalavarthi",
      "Kiran Madusudanan",
      "Randolf Sholz",
      "Nourhan Ahmed",
      "Johannes Burchert",
      "Shayan Javed",
      "Stefan Born",
      "Lars Schmidt-Thieme"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12934",
    "title": "Position Control of Single Link Flexible Manipulator: A Functional  Observer Based Sliding Mode Approach",
    "abstract": "This paper proposes a functional observer-based sliding mode control technique for position control of a single-link flexible manipulator. The proposed method considers the unmodelled system dynamics as uncertainty and aims to achieve accurate position control. The functional observer is used to directly estimate the sliding mode control design components and a sliding mode controller to generate the control signal, which guarantees the system's robustness and stability. The proposed control scheme is validated using numerical simulations. ",
    "url": "https://arxiv.org/abs/2305.12934",
    "authors": [
      "Atul Sharma",
      "S. Janardhanan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.12940",
    "title": "GEST: the Graph of Events in Space and Time as a Common Representation  between Vision and Language",
    "abstract": "One of the essential human skills is the ability to seamlessly build an inner representation of the world. By exploiting this representation, humans are capable of easily finding consensus between visual, auditory and linguistic perspectives. In this work, we set out to understand and emulate this ability through an explicit representation for both vision and language - Graphs of Events in Space and Time (GEST). GEST alows us to measure the similarity between texts and videos in a semantic and fully explainable way, through graph matching. It also allows us to generate text and videos from a common representation that provides a well understood content. In this work we show that the graph matching similarity metrics based on GEST outperform classical text generation metrics and can also boost the performance of state of art, heavily trained metrics. ",
    "url": "https://arxiv.org/abs/2305.12940",
    "authors": [
      "Mihai Masala",
      "Nicolae Cudlenco",
      "Traian Rebedea",
      "Marius Leordeanu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12941",
    "title": "On the Correspondence between Compositionality and Imitation in Emergent  Neural Communication",
    "abstract": "Compositionality is a hallmark of human language that not only enables linguistic generalization, but also potentially facilitates acquisition. When simulating language emergence with neural networks, compositionality has been shown to improve communication performance; however, its impact on imitation learning has yet to be investigated. Our work explores the link between compositionality and imitation in a Lewis game played by deep neural agents. Our contributions are twofold: first, we show that the learning algorithm used to imitate is crucial: supervised learning tends to produce more average languages, while reinforcement learning introduces a selection pressure toward more compositional languages. Second, our study reveals that compositional languages are easier to imitate, which may induce the pressure toward compositional languages in RL imitation settings. ",
    "url": "https://arxiv.org/abs/2305.12941",
    "authors": [
      "Emily Cheng",
      "Mathieu Rita",
      "Thierry Poibeau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.12947",
    "title": "ChatGPT to Replace Crowdsourcing of Paraphrases for Intent  Classification: Higher Diversity and Comparable Model Robustness",
    "abstract": "The emergence of generative large language models (LLMs) raises the question: what will be its impact on crowdsourcing. Traditionally, crowdsourcing has been used for acquiring solutions to a wide variety of human-intelligence tasks, including ones involving text generation, manipulation or evaluation. For some of these tasks, models like ChatGPT can potentially substitute human workers. In this study, we investigate, whether this is the case for the task of paraphrase generation for intent classification. We quasi-replicated the data collection methodology of an existing crowdsourcing study (similar scale, prompts and seed data) using ChatGPT. We show that ChatGPT-created paraphrases are more diverse and lead to more robust models. ",
    "url": "https://arxiv.org/abs/2305.12947",
    "authors": [
      "Jan Cegin",
      "Jakub Simko",
      "Peter Brusilovsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12958",
    "title": "AD-MERCS: Modeling Normality and Abnormality in Unsupervised Anomaly  Detection",
    "abstract": "Most anomaly detection systems try to model normal behavior and assume anomalies deviate from it in diverse manners. However, there may be patterns in the anomalies as well. Ideally, an anomaly detection system can exploit patterns in both normal and anomalous behavior. In this paper, we present AD-MERCS, an unsupervised approach to anomaly detection that explicitly aims at doing both. AD-MERCS identifies multiple subspaces of the instance space within which patterns exist, and identifies conditions (possibly in other subspaces) that characterize instances that deviate from these patterns. Experiments show that this modeling of both normality and abnormality makes the anomaly detector performant on a wide range of types of anomalies. Moreover, by identifying patterns and conditions in (low-dimensional) subspaces, the anomaly detector can provide simple explanations of why something is considered an anomaly. These explanations can be both negative (deviation from some pattern) as positive (meeting some condition that is typical for anomalies). ",
    "url": "https://arxiv.org/abs/2305.12958",
    "authors": [
      "Jonas Soenen",
      "Elia Van Wolputte",
      "Vincent Vercruyssen",
      "Wannes Meert",
      "Hendrik Blockeel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12959",
    "title": "Contrastive Predictive Autoencoders for Dynamic Point Cloud  Self-Supervised Learning",
    "abstract": "We present a new self-supervised paradigm on point cloud sequence understanding. Inspired by the discriminative and generative self-supervised methods, we design two tasks, namely point cloud sequence based Contrastive Prediction and Reconstruction (CPR), to collaboratively learn more comprehensive spatiotemporal representations. Specifically, dense point cloud segments are first input into an encoder to extract embeddings. All but the last ones are then aggregated by a context-aware autoregressor to make predictions for the last target segment. Towards the goal of modeling multi-granularity structures, local and global contrastive learning are performed between predictions and targets. To further improve the generalization of representations, the predictions are also utilized to reconstruct raw point cloud sequences by a decoder, where point cloud colorization is employed to discriminate against different frames. By combining classic contrast and reconstruction paradigms, it makes the learned representations with both global discrimination and local perception. We conduct experiments on four point cloud sequence benchmarks, and report the results on action recognition and gesture recognition under multiple experimental settings. The performances are comparable with supervised methods and show powerful transferability. ",
    "url": "https://arxiv.org/abs/2305.12959",
    "authors": [
      "Xiaoxiao Sheng",
      "Zhiqiang Shen",
      "Gang Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12971",
    "title": "Neural Cellular Automata Can Respond to Signals",
    "abstract": "Neural Cellular Automata (NCAs) are a model of morphogenesis, capable of growing two-dimensional artificial organisms from a single seed cell. In this paper, we show that NCAs can be trained to respond to signals. Two types of signal are used: internal (genomically-coded) signals, and external (environmental) signals. Signals are presented to a single pixel for a single timestep. Results show NCAs are able to grow into multiple distinct forms based on internal signals, and are able to change colour based on external signals. Overall these contribute to the development of NCAs as a model of artificial morphogenesis, and pave the way for future developments embedding dynamic behaviour into the NCA model. Code and target images are available through GitHub: https://github.com/jstovold/ALIFE2023 ",
    "url": "https://arxiv.org/abs/2305.12971",
    "authors": [
      "James Stovold"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12979",
    "title": "When Computing Power Network Meets Distributed Machine Learning: An  Efficient Federated Split Learning Framework",
    "abstract": "In this paper, we advocate CPN-FedSL, a novel and flexible Federated Split Learning (FedSL) framework over Computing Power Network (CPN). We build a dedicated model to capture the basic settings and learning characteristics (e.g., training flow, latency and convergence). Based on this model, we introduce Resource Usage Effectiveness (RUE), a novel performance metric integrating training utility with system cost, and formulate a multivariate scheduling problem that maxi?mizes RUE by comprehensively taking client admission, model partition, server selection, routing and bandwidth allocation into account (i.e., mixed-integer fractional programming). We design Refinery, an efficient approach that first linearizes the fractional objective and non-convex constraints, and then solves the transformed problem via a greedy based rounding algorithm in multiple iterations. Extensive evaluations corroborate that CPN-FedSL is superior to the standard and state-of-the-art learning frameworks (e.g., FedAvg and SplitFed), and besides Refinery is lightweight and significantly outperforms its variants and de facto heuristic methods under a variety of settings. ",
    "url": "https://arxiv.org/abs/2305.12979",
    "authors": [
      "Xinjing Yuan",
      "Lingjun Pu",
      "Lei Jiao",
      "Xiaofei Wang",
      "Meijuan Yang",
      "Jingdong Xu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12990",
    "title": "Sentence Representations via Gaussian Embedding",
    "abstract": "Recent progress in sentence embedding, which represents the meaning of a sentence as a point in a vector space, has achieved high performance on tasks such as a semantic textual similarity (STS) task. However, sentence representations as a point in a vector space can express only a part of the diverse information that sentences have, such as asymmetrical relationships between sentences. This paper proposes GaussCSE, a Gaussian distribution-based contrastive learning framework for sentence embedding that can handle asymmetric relationships between sentences, along with a similarity measure for identifying inclusion relations. Our experiments show that GaussCSE achieves the same performance as previous methods in natural language inference tasks, and is able to estimate the direction of entailment relations, which is difficult with point representations. ",
    "url": "https://arxiv.org/abs/2305.12990",
    "authors": [
      "Shohei Yoda",
      "Hayato Tsukagoshi",
      "Ryohei Sasano",
      "Koichi Takeda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12997",
    "title": "EXACT: Extensive Attack for Split Learning",
    "abstract": "Privacy-Preserving machine learning (PPML) can help us train and deploy models that utilize private information. In particular, on-device Machine Learning allows us to completely avoid sharing information with a third-party server during inference. However, on-device models are typically less accurate when compared to the server counterparts due to the fact that (1) they typically only rely on a small set of on-device features and (2) they need to be small enough to run efficiently on end-user devices. Split Learning (SL) is a promising approach that can overcome these limitations. In SL, a large machine learning model is divided into two parts, with the bigger part residing on the server-side and a smaller part executing on-device, aiming to incorporate the private features. However, end-to-end training of such models requires exchanging gradients at the cut layer, which might encode private features or labels. In this paper, we provide insights into potential privacy risks associated with SL and introduce a novel attack method, EXACT, to reconstruct private information. Furthermore, we also investigate the effectiveness of various mitigation strategies. Our results indicate that the gradients significantly improve the attacker's effectiveness in all three datasets reaching almost 100% reconstruction accuracy for some features. However, a small amount of differential privacy (DP) is quite effective in mitigating this risk without causing significant training degradation. ",
    "url": "https://arxiv.org/abs/2305.12997",
    "authors": [
      "Xinchi Qiu",
      "Ilias Leontiadis",
      "Luca Melis",
      "Alex Sablayrolles",
      "Pierre Stock"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.13015",
    "title": "3D Rotation and Translation for Hyperbolic Knowledge Graph Embedding",
    "abstract": "The main objective of Knowledge Graph (KG) embeddings is to learn low-dimensional representations of entities and relations, enabling the prediction of missing facts. A significant challenge in achieving better KG embeddings lies in capturing relation patterns, including symmetry, antisymmetry, inversion, commutative composition, non-commutative composition, hierarchy, and multiplicity. This study introduces a novel model called 3H-TH (3D Rotation and Translation in Hyperbolic space) that captures these relation patterns simultaneously. In contrast, previous attempts have not achieved satisfactory performance across all the mentioned properties at the same time. The experimental results demonstrate that the new model outperforms existing state-of-the-art models in terms of accuracy, hierarchy property, and other relation patterns in low-dimensional space, meanwhile performing similarly in high-dimensional space. ",
    "url": "https://arxiv.org/abs/2305.13015",
    "authors": [
      "Yihua Zhu",
      "Hidetoshi Shimodaira"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13021",
    "title": "Can we hear physical and social space together through prosody?",
    "abstract": "When human listeners try to guess the spatial position of a speech source, they are influenced by the speaker's production level, regardless of the intensity level reaching their ears. Because the perception of distance is a very difficult task, they rely on their own experience, which tells them that a whispering talker is close to them, and that a shouting talker is far away. This study aims to test if similar results could be obtained for prosodic variations produced by a human speaker in an everyday life environment. It consists in a localization task, during which blindfolded subjects had to estimate the incoming voice direction, speaker orientation and distance of a trained female speaker, who uttered single words, following instructions concerning intensity and social-affect to be performed. This protocol was implemented in two experiments. First, a complex pretext task was used in order to distract the subjects from the strange behavior of the speaker. On the contrary, during the second experiment, the subjects were fully aware of the prosodic variations, which allowed them to adapt their perception. Results show the importance of the pretext task, and suggest that the perception of the speaker's orientation can be influenced by voice intensity. ",
    "url": "https://arxiv.org/abs/2305.13021",
    "authors": [
      "Ambre Davat",
      "V\u00e9ronique Auberg\u00e9",
      "Gang Feng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.13033",
    "title": "Towards generalizing deep-audio fake detection networks",
    "abstract": "Today's generative neural networks allow the creation of high-quality synthetic speech at scale. While we welcome the creative use of this new technology, we must also recognize the risks. As synthetic speech is abused for both monetary and identity theft, we require a broad set of deep fake identification tools. Furthermore, previous work reported a limited ability of deep classifiers to generalize to unseen audio generators. By leveraging the wavelet-packet and short-time Fourier transform, we train excellent lightweight detectors that generalize. We report improved results on an extension of the WaveFake dataset. To account for the rapid progress in the field, we additionally consider samples drawn from the novel Avocodo and BigVGAN networks. ",
    "url": "https://arxiv.org/abs/2305.13033",
    "authors": [
      "Konstantin Gasenzer",
      "Moritz Wolter"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.13041",
    "title": "Distributed Learning over Networks with Graph-Attention-Based  Personalization",
    "abstract": "In conventional distributed learning over a network, multiple agents collaboratively build a common machine learning model. However, due to the underlying non-i.i.d. data distribution among agents, the unified learning model becomes inefficient for each agent to process its locally accessible data. To address this problem, we propose a graph-attention-based personalized training algorithm (GATTA) for distributed deep learning. The GATTA enables each agent to train its local personalized model while exploiting its correlation with neighboring nodes and utilizing their useful information for aggregation. In particular, the personalized model in each agent is composed of a global part and a node-specific part. By treating each agent as one node in a graph and the node-specific parameters as its features, the benefits of the graph attention mechanism can be inherited. Namely, instead of aggregation based on averaging, it learns the specific weights for different neighboring nodes without requiring prior knowledge about the graph structure or the neighboring nodes' data distribution. Furthermore, relying on the weight-learning procedure, we develop a communication-efficient GATTA by skipping the transmission of information with small aggregation weights. Additionally, we theoretically analyze the convergence properties of GATTA for non-convex loss functions. Numerical results validate the excellent performances of the proposed algorithms in terms of convergence and communication cost. ",
    "url": "https://arxiv.org/abs/2305.13041",
    "authors": [
      "Zhuojun Tian",
      "Zhaoyang Zhang",
      "Zhaohui Yang",
      "Richeng Jin",
      "Huaiyu Dai"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.13043",
    "title": "Self-Replication, Spontaneous Mutations, and Exponential Genetic Drift  in Neural Cellular Automata",
    "abstract": "This paper reports on patterns exhibiting self-replication with spontaneous, inheritable mutations and exponential genetic drift in Neural Cellular Automata. Despite the models not being explicitly trained for mutation or inheritability, the descendant patterns exponentially drift away from ancestral patterns, even when the automaton is deterministic. While this is far from being the first instance of evolutionary dynamics in a cellular automaton, it is the first to do so by exploiting the power and convenience of Neural Cellular Automata, arguably increasing the space of variations and the opportunity for Open Ended Evolution. ",
    "url": "https://arxiv.org/abs/2305.13043",
    "authors": [
      "Lana Sinapayen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2305.13047",
    "title": "Automated stance detection in complex topics and small languages: the  challenging case of immigration in polarizing news media",
    "abstract": "Automated stance detection and related machine learning methods can provide useful insights for media monitoring and academic research. Many of these approaches require annotated training datasets, which limits their applicability for languages where these may not be readily available. This paper explores the applicability of large language models for automated stance detection in a challenging scenario, involving a morphologically complex, lower-resource language, and a socio-culturally complex topic, immigration. If the approach works in this case, it can be expected to perform as well or better in less demanding scenarios. We annotate a large set of pro and anti-immigration examples, and compare the performance of multiple language models as supervised learners. We also probe the usability of ChatGPT as an instructable zero-shot classifier for the same task. Supervised achieves acceptable performance, and ChatGPT yields similar accuracy. This is promising as a potentially simpler and cheaper alternative for text classification tasks, including in lower-resource languages. We further use the best-performing model to investigate diachronic trends over seven years in two corpora of Estonian mainstream and right-wing populist news sources, demonstrating the applicability of the approach for news analytics and media monitoring settings, and discuss correspondences between stance changes and real-world events. ",
    "url": "https://arxiv.org/abs/2305.13047",
    "authors": [
      "Mark Mets",
      "Andres Karjus",
      "Indrek Ibrus",
      "Maximilian Schich"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13052",
    "title": "Federated Learning of Medical Concepts Embedding using BEHRT",
    "abstract": "Electronic Health Records (EHR) data contains medical records such as diagnoses, medications, procedures, and treatments of patients. This data is often considered sensitive medical information. Therefore, the EHR data from the medical centers often cannot be shared, making it difficult to create prediction models using multi-center EHR data, which is essential for such models' robustness and generalizability. Federated Learning (FL) is an algorithmic approach that allows learning a shared model using data in multiple locations without the need to store all data in a central place. An example of a prediction model's task is to predict future diseases. More specifically, the model needs to predict patient's next visit diagnoses, based on current and previous clinical data. Such a prediction model can support care providers in making clinical decisions and even provide preventive treatment. We propose a federated learning approach for learning medical concepts embedding. This pre-trained model can be used for fine-tuning for specific downstream tasks. Our approach is based on an embedding model like BEHRT, a deep neural sequence transduction model for EHR. We train using federated learning, both the Masked Language Modeling (MLM) and the next visit downstream model. We demonstrate our approach on the MIMIC-IV dataset. We compare the performance of a model trained with FL against a model trained on centralized data. We find that our federated learning approach reaches very close to the performance of a centralized model, and it outperforms local models in terms of average precision. We also show that pre-trained MLM improves the model's average precision performance in the next visit prediction task, compared to an MLM model without pre-training. Our code is available at https://github.com/nadavlab/FederatedBEHRT. ",
    "url": "https://arxiv.org/abs/2305.13052",
    "authors": [
      "Ofir Ben Shoham",
      "Nadav Rappoport"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13059",
    "title": "Friendly Neighbors: Contextualized Sequence-to-Sequence Link Prediction",
    "abstract": "We propose KGT5-context, a simple sequence-to-sequence model for link prediction (LP) in knowledge graphs (KG). Our work expands on KGT5, a recent LP model that exploits textual features of the KG, has small model size, and is scalable. To reach good predictive performance, however, KGT5 relies on an ensemble with a knowledge graph embedding model, which itself is excessively large and costly to use. In this short paper, we show empirically that adding contextual information - i.e., information about the direct neighborhood of a query vertex - alleviates the need for a separate KGE model to obtain good performance. The resulting KGT5-context model obtains state-of-the-art performance in our experimental study, while at the same time reducing model size significantly. ",
    "url": "https://arxiv.org/abs/2305.13059",
    "authors": [
      "Adrian Kochsiek",
      "Apoorv Saxena",
      "Inderjeet Nair",
      "Rainer Gemulla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.13064",
    "title": "Gradient Descent Monotonically Decreases the Sharpness of Gradient Flow  Solutions in Scalar Networks and Beyond",
    "abstract": "Recent research shows that when Gradient Descent (GD) is applied to neural networks, the loss almost never decreases monotonically. Instead, the loss oscillates as gradient descent converges to its ''Edge of Stability'' (EoS). Here, we find a quantity that does decrease monotonically throughout GD training: the sharpness attained by the gradient flow solution (GFS)-the solution that would be obtained if, from now until convergence, we train with an infinitesimal step size. Theoretically, we analyze scalar neural networks with the squared loss, perhaps the simplest setting where the EoS phenomena still occur. In this model, we prove that the GFS sharpness decreases monotonically. Using this result, we characterize settings where GD provably converges to the EoS in scalar networks. Empirically, we show that GD monotonically decreases the GFS sharpness in a squared regression model as well as practical neural network architectures. ",
    "url": "https://arxiv.org/abs/2305.13064",
    "authors": [
      "Itai Kreisler",
      "Mor Shpigel Nacson",
      "Daniel Soudry",
      "Yair Carmon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.13067",
    "title": "Improving Robustness in Knowledge Distillation Using Domain-Targeted  Data Augmentation",
    "abstract": "Applying knowledge distillation encourages a student model to behave more like a teacher model, largely retaining the performance of the teacher model, even though the student model may have substantially fewer parameters. However, while distillation helps student models behave more like teacher models in-distribution, this is not necessarily the case out-of-distribution. To address this, we use a language model to create task-specific unlabeled data that mimics the data in targeted out-of-distribution domains. We use this generated data for knowledge distillation on the task of Natural Language Inference (NLI), encouraging the student models to behave more like the teacher models for these examples. Our domain-targeted augmentation is highly effective, and outperforms previous robustness methods when evaluating out-of-distribution performance on MNLI. Surprisingly, this method also improves performance on out-of-distribution domains that the data was not generated for. We additionally introduce Distilled Minority Upsampling (DMU), a method for identifying and upsampling minority examples during the distillation. DMU is complementary to the domain-targeted augmentation, and substantially improves performance on SNLI-hard. Finally, we show out-of-distribution improvements on HANS from both of our methods, despite augmenting the training data with fewer than 5k examples. ",
    "url": "https://arxiv.org/abs/2305.13067",
    "authors": [
      "Joe Stacey",
      "Marek Rei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13073",
    "title": "Text-to-SQL Error Correction with Language Models of Code",
    "abstract": "Despite recent progress in text-to-SQL parsing, current semantic parsers are still not accurate enough for practical use. In this paper, we investigate how to build automatic text-to-SQL error correction models. Noticing that token-level edits are out of context and sometimes ambiguous, we propose building clause-level edit models instead. Besides, while most language models of code are not specifically pre-trained for SQL, they know common data structures and their operations in programming languages such as Python. Thus, we propose a novel representation for SQL queries and their edits that adheres more closely to the pre-training corpora of language models of code. Our error correction model improves the exact set match accuracy of different parsers by 2.4-6.5 and obtains up to 4.3 point absolute improvement over two strong baselines. Our code and data are available at https://github.com/OSU-NLP-Group/Auto-SQL-Correction. ",
    "url": "https://arxiv.org/abs/2305.13073",
    "authors": [
      "Ziru Chen",
      "Shijie Chen",
      "Michael White",
      "Raymond Mooney",
      "Ali Payani",
      "Jayanth Srinivasa",
      "Yu Su",
      "Huan Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13078",
    "title": "Optimality Principles in Spacecraft Neural Guidance and Control",
    "abstract": "Spacecraft and drones aimed at exploring our solar system are designed to operate in conditions where the smart use of onboard resources is vital to the success or failure of the mission. Sensorimotor actions are thus often derived from high-level, quantifiable, optimality principles assigned to each task, utilizing consolidated tools in optimal control theory. The planned actions are derived on the ground and transferred onboard where controllers have the task of tracking the uploaded guidance profile. Here we argue that end-to-end neural guidance and control architectures (here called G&CNets) allow transferring onboard the burden of acting upon these optimality principles. In this way, the sensor information is transformed in real time into optimal plans thus increasing the mission autonomy and robustness. We discuss the main results obtained in training such neural architectures in simulation for interplanetary transfers, landings and close proximity operations, highlighting the successful learning of optimality principles by the neural model. We then suggest drone racing as an ideal gym environment to test these architectures on real robotic platforms, thus increasing confidence in their utilization on future space exploration missions. Drone racing shares with spacecraft missions both limited onboard computational capabilities and similar control structures induced from the optimality principle sought, but it also entails different levels of uncertainties and unmodelled effects. Furthermore, the success of G&CNets on extremely resource-restricted drones illustrates their potential to bring real-time optimal control within reach of a wider variety of robotic systems, both in space and on Earth. ",
    "url": "https://arxiv.org/abs/2305.13078",
    "authors": [
      "Dario Izzo",
      "Emmanuel Blazquez",
      "Robin Ferede",
      "Sebastien Origer",
      "Christophe De Wagter",
      "Guido C.H.E. de Croon"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13079",
    "title": "Robust dynamic operating envelopes for flexibility operation using only  local voltage measurement",
    "abstract": "With growing intermittency and uncertainty in distribution networks around the world, ensuring operational integrity is becoming challenging. Recent use cases of dynamic operating envelopes (DOEs) indicate that it can be utilized for network awareness for autonomous operation of flexibility, maximizing distributed generation integration, coordinating flexibility in different power networks and in resource planning. To this end, we propose a novel framework for generating decentralized, risk-averse, robust DOEs using only the nodal voltage measurement or forecast. Chance constraint level is analytically implemented for avoiding extremely restrictive time-ahead DOEs with insufficient feasible region for local energy optimization. Since the proposed DOE calculation framework uses no centralized feedback, it is resilient to cyberattacks, communication failures, missing data and errors in network layout information. Numerical results showcase DOE calculation framework in real-time using voltage magnitude measurements and in day-ahead timeframe using forecasted voltage scenarios. Furthermore, the DOEs are extended to form P-Q charts while considering power factor and converter capacity limits. ",
    "url": "https://arxiv.org/abs/2305.13079",
    "authors": [
      "Md Umar Hashmi",
      "Dirk Van Hertem"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.13084",
    "title": "A Fractional Graph Laplacian Approach to Oversmoothing",
    "abstract": "Graph neural networks (GNNs) have shown state-of-the-art performances in various applications. However, GNNs often struggle to capture long-range dependencies in graphs due to oversmoothing. In this paper, we generalize the concept of oversmoothing from undirected to directed graphs. To this aim, we extend the notion of Dirichlet energy by considering a directed symmetrically normalized Laplacian. As vanilla graph convolutional networks are prone to oversmooth, we adopt a neural graph ODE framework. Specifically, we propose fractional graph Laplacian neural ODEs, which describe non-local dynamics. We prove that our approach allows propagating information between distant nodes while maintaining a low probability of long-distance jumps. Moreover, we show that our method is more flexible with respect to the convergence of the graph's Dirichlet energy, thereby mitigating oversmoothing. We conduct extensive experiments on synthetic and real-world graphs, both directed and undirected, demonstrating our method's versatility across diverse graph homophily levels. Our code is available at https://github.com/RPaolino/fLode . ",
    "url": "https://arxiv.org/abs/2305.13084",
    "authors": [
      "Sohir Maskey",
      "Raffaele Paolino",
      "Aras Bacho",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13089",
    "title": "An Optimal Separation between Two Property Testing Models for Bounded  Degree Directed Graphs",
    "abstract": "We revisit the relation between two fundamental property testing models for bounded-degree directed graphs: the bidirectional model in which the algorithms are allowed to query both the outgoing edges and incoming edges of a vertex, and the unidirectional model in which only queries to the outgoing edges are allowed. Czumaj, Peng and Sohler [STOC 2016] showed that for directed graphs with both maximum indegree and maximum outdegree upper bounded by $d$, any property that can be tested with query complexity $O_{\\varepsilon,d}(1)$ in the bidirectional model can be tested with $n^{1-\\Omega_{\\varepsilon,d}(1)}$ queries in the unidirectional model. In particular, if the proximity parameter $\\varepsilon$ approaches $0$, then the query complexity of the transformed tester in the unidirectional model approaches $n$. It was left open if this transformation can be further improved or there exists any property that exhibits such an extreme separation. We prove that testing subgraph-freeness in which the subgraph contains $k$ source components, requires $\\Omega(n^{1-\\frac{1}{k}})$ queries in the unidirectional model. This directly gives the first explicit properties that exhibit an $O_{\\varepsilon,d}(1)$ vs $\\Omega(n^{1-f(\\varepsilon,d)})$ separation of the query complexities between the bidirectional model and unidirectional model, where $f(\\varepsilon,d)$ is a function that approaches $0$ as $\\varepsilon$ approaches $0$. Furthermore, our lower bound also resolves a conjecture by Hellweg and Sohler [ESA 2012] on the query complexity of testing $k$-star-freeness. ",
    "url": "https://arxiv.org/abs/2305.13089",
    "authors": [
      "Pan Peng",
      "Yuyang Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2305.13098",
    "title": "Analysis of Media Writing Style Bias through Text-Embedding Networks",
    "abstract": "With the rise of phenomena like `fake news' and the growth of heavily-biased media ecosystems, there has been increased attention on understanding and evaluating media bias. Of particular note in the evaluation of media bias is writing style bias, which includes lexical bias and framing bias. We propose a novel approach to evaluating writing style bias that utilizes natural language similarity estimation and a network-based representation of the shared content between articles to perform bias characterization. Our proposed method presents a new means of evaluating writing style bias that does not rely on human experts or knowledge of a media producer's publication procedures. The results of experimentation on real-world vaccine mandate data demonstrates the utility of the technique and how the standard bias labeling procedures of only having one bias label for a media producer is insufficient to truly characterize the bias of that media producer. ",
    "url": "https://arxiv.org/abs/2305.13098",
    "authors": [
      "Iain J. Cruickshank",
      "Jessica Zhu",
      "Nathaniel D. Bastian"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.13115",
    "title": "Causal-Based Supervision of Attention in Graph Neural Network: A Better  and Simpler Choice towards Powerful Attention",
    "abstract": "In recent years, attention mechanisms have demonstrated significant potential in the field of graph representation learning. However, while variants of attention-based GNNs are setting new benchmarks for numerous real-world datasets, recent works have pointed out that their induced attentions are less robust and generalizable against noisy graphs due to the lack of direct supervision. In this paper, we present a new framework that utilizes the tool of causality to provide a powerful supervision signal for the learning process of attention functions. Specifically, we estimate the direct causal effect of attention on the final prediction and then maximize such effect to guide attention to attend to more meaningful neighbors. Our method can serve as a plug-and-play module for any canonical attention-based GNNs in an end-to-end fashion. Extensive experiments on a wide range of benchmark datasets illustrated that, by directly supervising attention with our method, the model is able to converge faster with a clearer decision boundary, and thus yields better performances. ",
    "url": "https://arxiv.org/abs/2305.13115",
    "authors": [
      "Hongjun Wang",
      "Jiyuan Chen",
      "Lun Du",
      "Qiang Fu",
      "Shi Han",
      "Xuan Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2305.13122",
    "title": "Policy Representation via Diffusion Probability Model for Reinforcement  Learning",
    "abstract": "Popular reinforcement learning (RL) algorithms tend to produce a unimodal policy distribution, which weakens the expressiveness of complicated policy and decays the ability of exploration. The diffusion probability model is powerful to learn complicated multimodal distributions, which has shown promising and potential applications to RL. In this paper, we formally build a theoretical foundation of policy representation via the diffusion probability model and provide practical implementations of diffusion policy for online model-free RL. Concretely, we character diffusion policy as a stochastic process, which is a new approach to representing a policy. Then we present a convergence guarantee for diffusion policy, which provides a theory to understand the multimodality of diffusion policy. Furthermore, we propose the DIPO which is an implementation for model-free online RL with DIffusion POlicy. To the best of our knowledge, DIPO is the first algorithm to solve model-free online RL problems with the diffusion model. Finally, extensive empirical results show the effectiveness and superiority of DIPO on the standard continuous control Mujoco benchmark. ",
    "url": "https://arxiv.org/abs/2305.13122",
    "authors": [
      "Long Yang",
      "Zhixiong Huang",
      "Fenghao Lei",
      "Yucun Zhong",
      "Yiming Yang",
      "Cong Fang",
      "Shiting Wen",
      "Binbin Zhou",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13147",
    "title": "PALoc: Robust Prior-assisted Trajectory Generation for Benchmarking",
    "abstract": "Evaluating simultaneous localization and mapping (SLAM) algorithms necessitates high-precision and dense ground truth (GT) trajectories. But obtaining desirable GT trajectories is sometimes challenging without GT tracking sensors. As an alternative, in this paper, we propose a novel prior-assisted SLAM system to generate a full six-degree-of-freedom ($6$-DOF) trajectory at around $10$Hz for benchmarking under the framework of the factor graph. Our degeneracy-aware map factor utilizes a prior point cloud map and LiDAR frame for point-to-plane optimization, simultaneously detecting degeneration cases to reduce drift and enhancing the consistency of pose estimation. Our system is seamlessly integrated with cutting-edge odometry via a loosely coupled scheme to generate high-rate and precise trajectories. Moreover, we propose a norm-constrained gravity factor for stationary cases, optimizing pose and gravity to boost performance. Extensive evaluations demonstrate our algorithm's superiority over existing SLAM or map-based methods in diverse scenarios in terms of precision, smoothness, and robustness. Our approach substantially advances reliable and accurate SLAM evaluation methods, fostering progress in robotics research. ",
    "url": "https://arxiv.org/abs/2305.13147",
    "authors": [
      "Xiangcheng Hu",
      "Jin Wu",
      "Jianhao Jiao",
      "Ruoyu Geng",
      "Ming Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.13154",
    "title": "Defending Against the Dark Arts: Recognising Dark Patterns in Social  Media",
    "abstract": "Interest in unethical user interfaces has grown in HCI over recent years, with researchers identifying malicious design strategies referred to as ''dark patterns''. While such strategies have been described in numerous domains, we lack a thorough understanding of how they operate in social networking services (SNSs). Pivoting towards regulations against such practices, we address this gap by offering novel insights into the types of dark patterns deployed in SNSs and people's ability to recognise them across four widely used mobile SNS applications. Following a cognitive walkthrough, experts (N=6) could identify instances of dark patterns in all four SNSs, including co-occurrences. Based on the results, we designed a novel rating procedure for evaluating the malice of interfaces. Our evaluation shows that regular users (N=193) could differentiate between interfaces featuring dark patterns and those without. Such rating procedures could support policymakers' current moves to regulate deceptive and manipulative designs in online interfaces. ",
    "url": "https://arxiv.org/abs/2305.13154",
    "authors": [
      "Thomas Mildner",
      "Merle Freye",
      "Gian-Luca Savino",
      "Philip R. Doyle",
      "Benjamin R. Cowan",
      "Rainer Malaka"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2305.13165",
    "title": "Deep Neural Collapse Is Provably Optimal for the Deep Unconstrained  Features Model",
    "abstract": "Neural collapse (NC) refers to the surprising structure of the last layer of deep neural networks in the terminal phase of gradient descent training. Recently, an increasing amount of experimental evidence has pointed to the propagation of NC to earlier layers of neural networks. However, while the NC in the last layer is well studied theoretically, much less is known about its multi-layered counterpart - deep neural collapse (DNC). In particular, existing work focuses either on linear layers or only on the last two layers at the price of an extra assumption. Our paper fills this gap by generalizing the established analytical framework for NC - the unconstrained features model - to multiple non-linear layers. Our key technical contribution is to show that, in a deep unconstrained features model, the unique global optimum for binary classification exhibits all the properties typical of DNC. This explains the existing experimental evidence of DNC. We also empirically show that (i) by optimizing deep unconstrained features models via gradient descent, the resulting solution agrees well with our theory, and (ii) trained networks recover the unconstrained features suitable for the occurrence of DNC, thus supporting the validity of this modeling principle. ",
    "url": "https://arxiv.org/abs/2305.13165",
    "authors": [
      "Peter S\u00faken\u00edk",
      "Marco Mondelli",
      "Christoph Lampert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.13168",
    "title": "LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities  and Future Opportunities",
    "abstract": "This paper presents an exhaustive quantitative and qualitative evaluation of Large Language Models (LLMs) for Knowledge Graph (KG) construction and reasoning. We employ eight distinct datasets that encompass aspects including entity, relation and event extraction, link prediction, and question answering. Empirically, our findings suggest that GPT-4 outperforms ChatGPT in the majority of tasks and even surpasses fine-tuned models in certain reasoning and question-answering datasets. Moreover, our investigation extends to the potential generalization ability of LLMs for information extraction, which culminates in the presentation of the Virtual Knowledge Extraction task and the development of the VINE dataset. Drawing on these empirical findings, we further propose AutoKG, a multi-agent-based approach employing LLMs for KG construction and reasoning, which aims to chart the future of this field and offer exciting opportunities for advancement. We anticipate that our research can provide invaluable insights for future undertakings of KG\\footnote{Code and datasets will be available in https://github.com/zjunlp/AutoKG. ",
    "url": "https://arxiv.org/abs/2305.13168",
    "authors": [
      "Yuqi Zhu",
      "Xiaohan Wang",
      "Jing Chen",
      "Shuofei Qiao",
      "Yixin Ou",
      "Yunzhi Yao",
      "Shumin Deng",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13189",
    "title": "Unsupervised Anomaly Detection with Rejection",
    "abstract": "Anomaly detection aims at detecting unexpected behaviours in the data. Because anomaly detection is usually an unsupervised task, traditional anomaly detectors learn a decision boundary by employing heuristics based on intuitions, which are hard to verify in practice. This introduces some uncertainty, especially close to the decision boundary, that may reduce the user trust in the detector's predictions. A way to combat this is by allowing the detector to reject examples with high uncertainty (Learning to Reject). This requires employing a confidence metric that captures the distance to the decision boundary and setting a rejection threshold to reject low-confidence predictions. However, selecting a proper metric and setting the rejection threshold without labels are challenging tasks. In this paper, we solve these challenges by setting a constant rejection threshold on the stability metric computed by ExCeeD. Our insight relies on a theoretical analysis of such a metric. Moreover, setting a constant threshold results in strong guarantees: we estimate the test rejection rate, and derive a theoretical upper bound for both the rejection rate and the expected prediction cost. Experimentally, we show that our method outperforms some metric-based methods. ",
    "url": "https://arxiv.org/abs/2305.13189",
    "authors": [
      "Lorenzo Perini",
      "Jesse Davis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13207",
    "title": "Real-life Implementation of Internet of Robotic Things Using 5 DoF  Heterogeneous Robotic Arm",
    "abstract": "Establishing a communication bridge by transferring data driven from different embedded sensors via internet or reconcilable network protocols between enormous number of distinctively addressable objects or \"things\", is known as the Internet of Things (IoT). IoT can be amalgamated with multitudinous objects such as thermostats, cars, lights, refrigerators, and many more appliances which will be able to build a connection via internet. Where objects of our diurnal life can establish a network connection and get smarter with IoT, robotics can be another aspect which will get beneficial to be brought under the concept of IoT and is able to add a new perception in robotics having \"Mechanical Smart Intelligence\" which is generally called \"Internet of Robotic Things\" (IoRT). A robotic arm is a part of robotics where it is usually a programmable mechanical arm which has human arm like functionalities. In this paper, IoRT will be represented by a 5 DoF (degree of freedoms) Robotic Arm which will be able to communicate as an IoRT device, controlled with heterogeneous devices using IoT and \"Cloud Robotics\". ",
    "url": "https://arxiv.org/abs/2305.13207",
    "authors": [
      "Sayed Erfan Arefin",
      "Tasnia Ashrafi Heya",
      "Jia Uddin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.13208",
    "title": "Iterative Adversarial Attack on Image-guided Story Ending Generation",
    "abstract": "Multimodal learning involves developing models that can integrate information from various sources like images and texts. In this field, multimodal text generation is a crucial aspect that involves processing data from multiple modalities and outputting text. The image-guided story ending generation (IgSEG) is a particularly significant task, targeting on an understanding of complex relationships between text and image data with a complete story text ending. Unfortunately, deep neural networks, which are the backbone of recent IgSEG models, are vulnerable to adversarial samples. Current adversarial attack methods mainly focus on single-modality data and do not analyze adversarial attacks for multimodal text generation tasks that use cross-modal information. To this end, we propose an iterative adversarial attack method (Iterative-attack) that fuses image and text modality attacks, allowing for an attack search for adversarial text and image in an more effective iterative way. Experimental results demonstrate that the proposed method outperforms existing single-modal and non-iterative multimodal attack methods, indicating the potential for improving the adversarial robustness of multimodal text generation models, such as multimodal machine translation, multimodal question answering, etc. ",
    "url": "https://arxiv.org/abs/2305.13208",
    "authors": [
      "Youze Wang",
      "Wenbo Hu",
      "Richang Hong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.13232",
    "title": "Revisiting Data Augmentation in Model Compression: An Empirical and  Comprehensive Study",
    "abstract": "The excellent performance of deep neural networks is usually accompanied by a large number of parameters and computations, which have limited their usage on the resource-limited edge devices. To address this issue, abundant methods such as pruning, quantization and knowledge distillation have been proposed to compress neural networks and achieved significant breakthroughs. However, most of these compression methods focus on the architecture or the training method of neural networks but ignore the influence from data augmentation. In this paper, we revisit the usage of data augmentation in model compression and give a comprehensive study on the relation between model sizes and their optimal data augmentation policy. To sum up, we mainly have the following three observations: (A) Models in different sizes prefer data augmentation with different magnitudes. Hence, in iterative pruning, data augmentation with varying magnitudes leads to better performance than data augmentation with a consistent magnitude. (B) Data augmentation with a high magnitude may significantly improve the performance of large models but harm the performance of small models. Fortunately, small models can still benefit from strong data augmentations by firstly learning them with \"additional parameters\" and then discard these \"additional parameters\" during inference. (C) The prediction of a pre-trained large model can be utilized to measure the difficulty of data augmentation. Thus it can be utilized as a criterion to design better data augmentation policies. We hope this paper may promote more research on the usage of data augmentation in model compression. ",
    "url": "https://arxiv.org/abs/2305.13232",
    "authors": [
      "Muzhou Yu",
      "Linfeng Zhang",
      "Kaisheng Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.13236",
    "title": "Adaptive Gradient Prediction for DNN Training",
    "abstract": "Neural network training is inherently sequential where the layers finish the forward propagation in succession, followed by the calculation and back-propagation of gradients (based on a loss function) starting from the last layer. The sequential computations significantly slow down neural network training, especially the deeper ones. Prediction has been successfully used in many areas of computer architecture to speed up sequential processing. Therefore, we propose ADA-GP, that uses gradient prediction adaptively to speed up deep neural network (DNN) training while maintaining accuracy. ADA-GP works by incorporating a small neural network to predict gradients for different layers of a DNN model. ADA-GP uses a novel tensor reorganization to make it feasible to predict a large number of gradients. ADA-GP alternates between DNN training using backpropagated gradients and DNN training using predicted gradients. ADA-GP adaptively adjusts when and for how long gradient prediction is used to strike a balance between accuracy and performance. Last but not least, we provide a detailed hardware extension in a typical DNN accelerator to realize the speed up potential from gradient prediction. Our extensive experiments with fourteen DNN models show that ADA-GP can achieve an average speed up of 1.47x with similar or even higher accuracy than the baseline models. Moreover, it consumes, on average, 34% less energy due to reduced off-chip memory accesses compared to the baseline hardware accelerator. ",
    "url": "https://arxiv.org/abs/2305.13236",
    "authors": [
      "Vahid Janfaza",
      "Shantanu Mandal",
      "Farabi Mahmud",
      "Abdullah Muzahid"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.13242",
    "title": "Deepfake Text Detection in the Wild",
    "abstract": "Recent advances in large language models have enabled them to reach a level of text generation comparable to that of humans. These models show powerful capabilities across a wide range of content, including news article writing, story generation, and scientific writing. Such capability further narrows the gap between human-authored and machine-generated texts, highlighting the importance of deepfake text detection to avoid potential risks such as fake news propagation and plagiarism. However, previous work has been limited in that they testify methods on testbed of specific domains or certain language models. In practical scenarios, the detector faces texts from various domains or LLMs without knowing their sources. To this end, we build a wild testbed by gathering texts from various human writings and deepfake texts generated by different LLMs. Human annotators are only slightly better than random guessing at identifying machine-generated texts. Empirical results on automatic detection methods further showcase the challenges of deepfake text detection in a wild testbed. In addition, out-of-distribution poses a greater challenge for a detector to be employed in realistic application scenarios. We release our resources at https://github.com/yafuly/DeepfakeTextDetect. ",
    "url": "https://arxiv.org/abs/2305.13242",
    "authors": [
      "Yafu Li",
      "Qintong Li",
      "Leyang Cui",
      "Wei Bi",
      "Longyue Wang",
      "Linyi Yang",
      "Shuming Shi",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13250",
    "title": "Copy Recurrent Neural Network Structure Network",
    "abstract": "Electronic Health Record (EHR) coding involves automatically classifying EHRs into diagnostic codes. While most previous research treats this as a multi-label classification task, generating probabilities for each code and selecting those above a certain threshold as labels, these approaches often overlook the challenge of identifying complex diseases. In this study, our focus is on detecting complication diseases within EHRs. We propose a novel coarse-to-fine ICD path generation framework called the Copy Recurrent Neural Network Structure Network (CRNNet), which employs a Path Generator (PG) and a Path Discriminator (PD) for EHR coding. By using RNNs to generate sequential outputs and incorporating a copy module, we efficiently identify complication diseases. Our method achieves a 57.30\\% ratio of complex diseases in predictions, outperforming state-of-the-art and previous approaches. Additionally, through an ablation study, we demonstrate that the copy mechanism plays a crucial role in detecting complex diseases. ",
    "url": "https://arxiv.org/abs/2305.13250",
    "authors": [
      "Xiaofan Zhou",
      "Xunzhu Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2305.13258",
    "title": "NeSy4VRD: A Multifaceted Resource for Neurosymbolic AI Research using  Knowledge Graphs in Visual Relationship Detection",
    "abstract": "NeSy4VRD is a multifaceted resource designed to support the development of neurosymbolic AI (NeSy) research. NeSy4VRD re-establishes public access to the images of the VRD dataset and couples them with an extensively revised, quality-improved version of the VRD visual relationship annotations. Crucially, NeSy4VRD provides a well-aligned, companion OWL ontology that describes the dataset domain.It comes with open source infrastructure that provides comprehensive support for extensibility of the annotations (which, in turn, facilitates extensibility of the ontology), and open source code for loading the annotations to/from a knowledge graph. We are contributing NeSy4VRD to the computer vision, NeSy and Semantic Web communities to help foster more NeSy research using OWL-based knowledge graphs. ",
    "url": "https://arxiv.org/abs/2305.13258",
    "authors": [
      "David Herron",
      "Ernesto Jim\u00e9nez-Ruiz",
      "Giacomo Tarroni",
      "Tillman Weyde"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.13259",
    "title": "Network Participation and Accessibility of Proof-of-Stake (PoS)  Blockchains: A Cross-platform Comparative Analysis",
    "abstract": "The comparative analysis examined eleven Proof-of-Stake (PoS) consensus-based blockchain networks to assess their openness based on five indicative metrics. These metrics include those of decentralization-related aspects, such as the number of validators and capital concentration, and participation-related aspects, including entry capital requirements and economic network stability. This is to assess and characterize the openness of Proof-of-Stake blockchain networks. The analysis suggested that networks with higher openness included Solana and Avalanche, while BNB Chain, Klaytn, and Polygon measured with lower levels of openness. According to the comparative analysis, Ethereum scored high on network openness in terms of the number of participants and the cost of running the chain, but scored relatively low on capital concentration and staking ratio, which is likely due to the low ratio of staked ether (ETH) to circulating supply and the significant stakes in staking pools like Lido. Permissioned blockchains such as Klaytn and Polygon have limited openness, which suggests the need to take the level of openness into account when transitioning into a permissionless blockchain architecture with a more decentralized setting. ",
    "url": "https://arxiv.org/abs/2305.13259",
    "authors": [
      "Jiseong Noh",
      "Donghwan Kwon",
      "Soohwan Cho",
      "Neo C.K. Yiu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2305.13261",
    "title": "A Review of Benchmarks for Visual Defect Detection in the Manufacturing  Industry",
    "abstract": "The field of industrial defect detection using machine learning and deep learning is a subject of active research. Datasets, also called benchmarks, are used to compare and assess research results. There is a number of datasets in industrial visual inspection, of varying quality. Thus, it is a difficult task to determine which dataset to use. Generally speaking, datasets which include a testing set, with precise labeling and made in real-world conditions should be preferred. We propose a study of existing benchmarks to compare and expose their characteristics and their use-cases. A study of industrial metrics requirements, as well as testing procedures, will be presented and applied to the studied benchmarks. We discuss our findings by examining the current state of benchmarks for industrial visual inspection, and by exposing guidelines on the usage of benchmarks. ",
    "url": "https://arxiv.org/abs/2305.13261",
    "authors": [
      "Philippe Carvalho",
      "Alexandre Durupt",
      "Yves Grandvalet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13276",
    "title": "Evaluating ChatGPT's Performance for Multilingual and Emoji-based Hate  Speech Detection",
    "abstract": "Hate speech is a severe issue that affects many online platforms. So far, several studies have been performed to develop robust hate speech detection systems. Large language models like ChatGPT have recently shown great potential in performing several tasks, including hate speech detection. However, it is crucial to comprehend the limitations of these models to build more robust hate speech detection systems. Thus to bridge the gap, our study aims to evaluate the weaknesses of the ChatGPT model in detecting hate speech at a granular level across 11 languages. In addition, we investigate the influence of complex emotions, such as the use of emojis in hate speech, on the performance of the ChatGPT model. Through our analysis, we examine and investigate the errors made by the model, shedding light on its shortcomings in detecting certain types of hate speech and highlighting the need for further research and improvements in hate speech detection. ",
    "url": "https://arxiv.org/abs/2305.13276",
    "authors": [
      "Mithun Das",
      "Saurabh Kumar Pandey",
      "Animesh Mukherjee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13282",
    "title": "Is Fine-tuning Needed? Pre-trained Language Models Are Near Perfect for  Out-of-Domain Detection",
    "abstract": "Out-of-distribution (OOD) detection is a critical task for reliable predictions over text. Fine-tuning with pre-trained language models has been a de facto procedure to derive OOD detectors with respect to in-distribution (ID) data. Despite its common use, the understanding of the role of fine-tuning and its necessity for OOD detection is largely unexplored. In this paper, we raise the question: is fine-tuning necessary for OOD detection? We present a study investigating the efficacy of directly leveraging pre-trained language models for OOD detection, without any model fine-tuning on the ID data. We compare the approach with several competitive fine-tuning objectives, and offer new insights under various types of distributional shifts. Extensive evaluations on 8 diverse ID-OOD dataset pairs demonstrate near-perfect OOD detection performance (with 0% FPR95 in many cases), strongly outperforming its fine-tuned counterparts. We show that using distance-based detection methods, pre-trained language models are near-perfect OOD detectors when the distribution shift involves a domain change. Furthermore, we study the effect of fine-tuning on OOD detection and identify how to balance ID accuracy with OOD detection performance. Our code is publically available at https://github.com/Uppaal/lm-ood. ",
    "url": "https://arxiv.org/abs/2305.13282",
    "authors": [
      "Rheeya Uppaal",
      "Junjie Hu",
      "Yixuan Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13287",
    "title": "Data-Centric Machine Learning Approach for Early Ransomware Detection  and Attribution",
    "abstract": "Researchers have proposed a wide range of ransomware detection and analysis schemes. However, most of these efforts have focused on older families targeting Windows 7/8 systems. Hence there is a critical need to develop efficient solutions to tackle the latest threats, many of which may have relatively fewer samples to analyze. This paper presents a machine learning(ML) framework for early ransomware detection and attribution. The solution pursues a data-centric approach which uses a minimalist ransomware dataset and implements static analysis using portable executable(PE) files. Results for several ML classifiers confirm strong performance in terms of accuracy and zero-day threat detection. ",
    "url": "https://arxiv.org/abs/2305.13287",
    "authors": [
      "Aldin Vehabovic",
      "Hadi Zanddizari",
      "Nasir Ghani",
      "Farooq Shaikh",
      "Elias Bou-Harb",
      "Morteza Safaei Pour",
      "Jorge Crichigno"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.13289",
    "title": "Distributionally Robust Optimization Efficiently Solves Offline  Reinforcement Learning",
    "abstract": "Offline reinforcement learning aims to find the optimal policy from a pre-collected dataset without active exploration. This problem is faced with major challenges, such as a limited amount of data and distribution shift. Existing studies employ the principle of pessimism in face of uncertainty, and penalize rewards for less visited state-action pairs. In this paper, we directly model the uncertainty in the transition kernel using an uncertainty set, and then employ the approach of distributionally robust optimization that optimizes the worst-case performance over the uncertainty set. We first design a Hoeffding-style uncertainty set, which guarantees that the true transition kernel lies in the uncertainty set with high probability. We theoretically prove that it achieves an $\\epsilon$-accuracy with a sample complexity of $\\mathcal{O}\\left((1-\\gamma)^{-4}\\epsilon^{-2}SC^{\\pi^*} \\right)$, where $\\gamma$ is the discount factor, $C^{\\pi^*}$ is the single-policy concentrability for any comparator policy $\\pi^*$, and $S$ is the number of states. We further design a Bernstein-style uncertainty set, which does not necessarily guarantee the true transition kernel lies in the uncertainty set. We show an improved and near-optimal sample complexity of $\\mathcal{O}\\left((1-\\gamma)^{-3}\\epsilon^{-2}\\left(SC^{\\pi^*}+(\\mu_{\\min})^{-1}\\right) \\right)$, where $\\mu_{\\min}$ denotes the minimal non-zero entry of the behavior distribution. In addition, the computational complexity of our algorithms is the same as one of the LCB-based methods in the literature. Our results demonstrate that distributionally robust optimization method can also efficiently solve offline reinforcement learning. ",
    "url": "https://arxiv.org/abs/2305.13289",
    "authors": [
      "Yue Wang",
      "Yuting Hu",
      "Jinjun Xiong",
      "Shaofeng Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13290",
    "title": "Uncertainty and Structure in Neural Ordinary Differential Equations",
    "abstract": "Neural ordinary differential equations (ODEs) are an emerging class of deep learning models for dynamical systems. They are particularly useful for learning an ODE vector field from observed trajectories (i.e., inverse problems). We here consider aspects of these models relevant for their application in science and engineering. Scientific predictions generally require structured uncertainty estimates. As a first contribution, we show that basic and lightweight Bayesian deep learning techniques like the Laplace approximation can be applied to neural ODEs to yield structured and meaningful uncertainty quantification. But, in the scientific domain, available information often goes beyond raw trajectories, and also includes mechanistic knowledge, e.g., in the form of conservation laws. We explore how mechanistic knowledge and uncertainty quantification interact on two recently proposed neural ODE frameworks - symplectic neural ODEs and physical models augmented with neural ODEs. In particular, uncertainty reflects the effect of mechanistic information more directly than the predictive power of the trained model could. And vice versa, structure can improve the extrapolation abilities of neural ODEs, a fact that can be best assessed in practice through uncertainty estimates. Our experimental analysis demonstrates the effectiveness of the Laplace approach on both low dimensional ODE problems and a high dimensional partial differential equation. ",
    "url": "https://arxiv.org/abs/2305.13290",
    "authors": [
      "Katharina Ott",
      "Michael Tiemann",
      "Philipp Hennig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13302",
    "title": "Language-Agnostic Bias Detection in Language Models",
    "abstract": "Pretrained language models (PLMs) are key components in NLP, but they contain strong social biases. Quantifying these biases is challenging because current methods focusing on fill-the-mask objectives are sensitive to slight changes in input. To address this, we propose LABDet, a robust language-agnostic method for evaluating bias in PLMs. For nationality as a case study, we show that LABDet \"surfaces\" nationality bias by training a classifier on top of a frozen PLM on non-nationality sentiment detection. Collaborating with political scientists, we find consistent patterns of nationality bias across monolingual PLMs in six languages that align with historical and political context. We also show for English BERT that bias surfaced by LABDet correlates well with bias in the pretraining data; thus, our work is one of the few studies that directly links pretraining data to PLM behavior. Finally, we verify LABDet's reliability and applicability to different templates and languages through an extensive set of robustness checks. ",
    "url": "https://arxiv.org/abs/2305.13302",
    "authors": [
      "Abdullatif K\u00f6ksal",
      "Omer Faruk Yalcin",
      "Ahmet Akbiyik",
      "M. Tahir Kilavuz",
      "Anna Korhonen",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13307",
    "title": "NeRFuser: Large-Scale Scene Representation by NeRF Fusion",
    "abstract": "A practical benefit of implicit visual representations like Neural Radiance Fields (NeRFs) is their memory efficiency: large scenes can be efficiently stored and shared as small neural nets instead of collections of images. However, operating on these implicit visual data structures requires extending classical image-based vision techniques (e.g., registration, blending) from image sets to neural fields. Towards this goal, we propose NeRFuser, a novel architecture for NeRF registration and blending that assumes only access to pre-generated NeRFs, and not the potentially large sets of images used to generate them. We propose registration from re-rendering, a technique to infer the transformation between NeRFs based on images synthesized from individual NeRFs. For blending, we propose sample-based inverse distance weighting to blend visual information at the ray-sample level. We evaluate NeRFuser on public benchmarks and a self-collected object-centric indoor dataset, showing the robustness of our method, including to views that are challenging to render from the individual source NeRFs. ",
    "url": "https://arxiv.org/abs/2305.13307",
    "authors": [
      "Jiading Fang",
      "Shengjie Lin",
      "Igor Vasiljevic",
      "Vitor Guizilini",
      "Rares Ambrus",
      "Adrien Gaidon",
      "Gregory Shakhnarovich",
      "Matthew R. Walter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.08807",
    "title": "4-clique network minor embedding for quantum annealers",
    "abstract": "Quantum annealing is a proposed algorithm for computing solutions to combinatorial optimization problems. Current quantum annealing hardware is relatively sparse and therefore requires graph minor embedding in order to map an arbitrarily structured problem onto the sparse, and relatively small, quantum annealing processor. This paper proposes a new minor embedding method called 4-clique minor embedding. This is in contrast to the standard minor embedding technique of using a path of linearly connected qubits in order to represent a logical variable state. The 4-clique minor embedding is possible because of Pegasus graph connectivity, which is the native hardware graph for some of the current D-Wave quantum annealers. The Pegasus hardware graph has many 4-cliques, and it is possible to form a graph composed entirely of paths of connected 4-cliques, on which a problem can be minor embedded. The 4-clique chains come at the cost of additional qubit usage on the hardware graph, but they allow for stronger coupling within each chain thereby increasing chain integrity and reducing chain breaks. This 4-clique minor embedding technique is described in detail, and is compared against the standard linear path minor embedding with some experiments on two D-Wave quantum annealing processors with Pegasus hardware graphs. 4-clique minor embeddings can use weak chain strengths while successfully carrying out the computation of minimizing random all-to-all spin glass problem instances, in contrast to the linear path minor embeddings which have high chain break frequencies for weak chain strengths. This work shows that non standard minor embedding methods could be useful. For future quantum annealing architectures, distributing minor embeddings over more densely connected regions of hardware instead of linear paths may provide more robust computations for minor embedding problems. ",
    "url": "https://arxiv.org/abs/2301.08807",
    "authors": [
      "Elijah Pelofske"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2305.11917",
    "title": "Interpretable neural architecture search and transfer learning for  understanding sequence dependent enzymatic reactions",
    "abstract": "Finely-tuned enzymatic pathways control cellular processes, and their dysregulation can lead to disease. Creating predictive and interpretable models for these pathways is challenging because of the complexity of the pathways and of the cellular and genomic contexts. Here we introduce Elektrum, a deep learning framework which addresses these challenges with data-driven and biophysically interpretable models for determining the kinetics of biochemical systems. First, it uses in vitro kinetic assays to rapidly hypothesize an ensemble of high-quality Kinetically Interpretable Neural Networks (KINNs) that predict reaction rates. It then employs a novel transfer learning step, where the KINNs are inserted as intermediary layers into deeper convolutional neural networks, fine-tuning the predictions for reaction-dependent in vivo outcomes. Elektrum makes effective use of the limited, but clean in vitro data and the noisy, yet plentiful in vivo data that captures cellular context. We apply Elektrum to predict CRISPR-Cas9 off-target editing probabilities and demonstrate that Elektrum achieves state-of-the-art performance, regularizes neural network architectures, and maintains physical interpretability. ",
    "url": "https://arxiv.org/abs/2305.11917",
    "authors": [
      "Zijun Zhang",
      "Adam R. Lamson",
      "Michael Shelley",
      "Olga Troyanskaya"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.11997",
    "title": "Robust Counterfactual Explanations for Neural Networks With  Probabilistic Guarantees",
    "abstract": "There is an emerging interest in generating robust counterfactual explanations that would remain valid if the model is updated or changed even slightly. Towards finding robust counterfactuals, existing literature often assumes that the original model $m$ and the new model $M$ are bounded in the parameter space, i.e., $\\|\\text{Params}(M){-}\\text{Params}(m)\\|{<}\\Delta$. However, models can often change significantly in the parameter space with little to no change in their predictions or accuracy on the given dataset. In this work, we introduce a mathematical abstraction termed \\emph{naturally-occurring} model change, which allows for arbitrary changes in the parameter space such that the change in predictions on points that lie on the data manifold is limited. Next, we propose a measure -- that we call \\emph{Stability} -- to quantify the robustness of counterfactuals to potential model changes for differentiable models, e.g., neural networks. Our main contribution is to show that counterfactuals with sufficiently high value of \\emph{Stability} as defined by our measure will remain valid after potential ``naturally-occurring'' model changes with high probability (leveraging concentration bounds for Lipschitz function of independent Gaussians). Since our quantification depends on the local Lipschitz constant around a data point which is not always available, we also examine practical relaxations of our proposed measure and demonstrate experimentally how they can be incorporated to find robust counterfactuals for neural networks that are close, realistic, and remain valid after potential model changes. ",
    "url": "https://arxiv.org/abs/2305.11997",
    "authors": [
      "Faisal Hamman",
      "Erfaun Noorani",
      "Saumitra Mishra",
      "Daniele Magazzeni",
      "Sanghamitra Dutta"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12021",
    "title": "A Secure and Robust Approach for Distance-Based Mutual Positioning of  Unmanned Aerial Vehicles",
    "abstract": "Unmanned aerial vehicle (UAV) is becoming increasingly important in modern civilian and military applications. However, its novel use cases is bottlenecked by conventional satellite and terrestrial localization technologies, and calling for complementary solutions. Multi-UAV mutual positioning can be a potential answer, but its accuracy and security are challenged by inaccurate and/or malicious measurements. This paper proposes a novel, robust, and secure approach to address these issues. ",
    "url": "https://arxiv.org/abs/2305.12021",
    "authors": [
      "Bin Han",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2305.12068",
    "title": "Technical outlier detection via convolutional variational autoencoder  for the ADMANI breast mammogram dataset",
    "abstract": "The ADMANI datasets (annotated digital mammograms and associated non-image datasets) from the Transforming Breast Cancer Screening with AI programme (BRAIx) run by BreastScreen Victoria in Australia are multi-centre, large scale, clinically curated, real-world databases. The datasets are expected to aid in the development of clinically relevant Artificial Intelligence (AI) algorithms for breast cancer detection, early diagnosis, and other applications. To ensure high data quality, technical outliers must be removed before any downstream algorithm development. As a first step, we randomly select 30,000 individual mammograms and use Convolutional Variational Autoencoder (CVAE), a deep generative neural network, to detect outliers. CVAE is expected to detect all sorts of outliers, although its detection performance differs among different types of outliers. Traditional image processing techniques such as erosion and pectoral muscle analysis can compensate for the poor performance of CVAE in certain outlier types. We identify seven types of technical outliers: implant, pacemaker, cardiac loop recorder, improper radiography, atypical lesion/calcification, incorrect exposure parameter and improper placement. The outlier recall rate for the test set is 61% if CVAE, erosion and pectoral muscle analysis each select the top 1% images ranked in ascending or descending order according to image outlier score under each detection method, and 83% if each selects the top 5% images. This study offers an overview of technical outliers in the ADMANI dataset and suggests future directions to improve outlier detection effectiveness. ",
    "url": "https://arxiv.org/abs/2305.12068",
    "authors": [
      "Hui Li",
      "Carlos A. Pena Solorzano",
      "Susan Wei",
      "Davis J. McCarthy"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12072",
    "title": "Chest X-ray Image Classification: A Causal Perspective",
    "abstract": "The chest X-ray (CXR) is one of the most common and easy-to-get medical tests used to diagnose common diseases of the chest. Recently, many deep learning-based methods have been proposed that are capable of effectively classifying CXRs. Even though these techniques have worked quite well, it is difficult to establish whether what these algorithms actually learn is the cause-and-effect link between diseases and their causes or just how to map labels to photos.In this paper, we propose a causal approach to address the CXR classification problem, which constructs a structural causal model (SCM) and uses the backdoor adjustment to select effective visual information for CXR classification. Specially, we design different probability optimization functions to eliminate the influence of confounders on the learning of real causality. Experimental results demonstrate that our proposed method outperforms the open-source NIH ChestX-ray14 in terms of classification performance. ",
    "url": "https://arxiv.org/abs/2305.12072",
    "authors": [
      "Weizhi Nie",
      "Chen Zhang",
      "Dan Song",
      "Lina Zhao",
      "Yunpeng Bai",
      "Keliang Xie",
      "Anan Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12111",
    "title": "Joint Generative-Contrastive Representation Learning for Anomalous Sound  Detection",
    "abstract": "In this paper, we propose a joint generative and contrastive representation learning method (GeCo) for anomalous sound detection (ASD). GeCo exploits a Predictive AutoEncoder (PAE) equipped with self-attention as a generative model to perform frame-level prediction. The output of the PAE together with original normal samples, are used for supervised contrastive representative learning in a multi-task framework. Besides cross-entropy loss between classes, contrastive loss is used to separate PAE output and original samples within each class. GeCo aims to better capture context information among frames, thanks to the self-attention mechanism for PAE model. Furthermore, GeCo combines generative and contrastive learning from which we aim to yield more effective and informative representations, compared to existing methods. Extensive experiments have been conducted on the DCASE2020 Task2 development dataset, showing that GeCo outperforms state-of-the-art generative and discriminative methods. ",
    "url": "https://arxiv.org/abs/2305.12111",
    "authors": [
      "Xiao-Min Zeng",
      "Yan Song",
      "Zhu Zhuo",
      "Yu Zhou",
      "Yu-Hong Li",
      "Hui Xue",
      "Li-Rong Dai",
      "Ian McLoughlin"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.12179",
    "title": "Commodity-specific triads in the Dutch inter-industry production network",
    "abstract": "Triadic motifs are the smallest building blocks of higher-order interactions in complex networks and can be detected as over-occurrences with respect to null models with only pair-wise interactions. Recently, the motif structure of production networks has attracted attention in light of its possible role in the propagation of economic shocks. However, its characterization at the level of individual commodities is still poorly understood. Here we analyse both binary and weighted triadic motifs in the Dutch inter-industry production network disaggregated at the level of 187 commodity groups, using data from Statistics Netherlands. We introduce appropriate null models that filter out node heterogeneity and the strong effects of link reciprocity and find that, while the aggregate network that overlays all products is characterized by a multitude of triadic motifs, most single-product layers feature no significant motif, and roughly 80% of the layers feature only two motifs or less. This result paves the way for identifying a simple \"triadic fingerprint\" of each commodity and for reconstructing most product-specific networks from partial information in a pairwise fashion by controlling for their reciprocity structure. We discuss how these results can help statistical bureaus identify fine-grained information in structural analyses of interest for policymakers. ",
    "url": "https://arxiv.org/abs/2305.12179",
    "authors": [
      "Marzio Di Vece",
      "Frank P. Pijpers",
      "Diego Garlaschelli"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Information Theory (cs.IT)",
      "General Economics (econ.GN)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2305.12231",
    "title": "Bi-VLGM : Bi-Level Class-Severity-Aware Vision-Language Graph Matching  for Text Guided Medical Image Segmentation",
    "abstract": "Medical reports with substantial information can be naturally complementary to medical images for computer vision tasks, and the modality gap between vision and language can be solved by vision-language matching (VLM). However, current vision-language models distort the intra-model relation and mainly include class information in prompt learning that is insufficient for segmentation task. In this paper, we introduce a Bi-level class-severity-aware Vision-Language Graph Matching (Bi-VLGM) for text guided medical image segmentation, composed of a word-level VLGM module and a sentence-level VLGM module, to exploit the class-severity-aware relation among visual-textual features. In word-level VLGM, to mitigate the distorted intra-modal relation during VLM, we reformulate VLM as graph matching problem and introduce a vision-language graph matching (VLGM) to exploit the high-order relation among visual-textual features. Then, we perform VLGM between the local features for each class region and class-aware prompts to bridge their gap. In sentence-level VLGM, to provide disease severity information for segmentation task, we introduce a severity-aware prompting to quantify the severity level of retinal lesion, and perform VLGM between the global features and the severity-aware prompts. By exploiting the relation between the local (global) and class (severity) features, the segmentation model can selectively learn the class-aware and severity-aware information to promote performance. Extensive experiments prove the effectiveness of our method and its superiority to existing methods. Source code is to be released. ",
    "url": "https://arxiv.org/abs/2305.12231",
    "authors": [
      "Chen Wenting",
      "Liu Jie",
      "Yuan Yixuan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12331",
    "title": "DCCRN-KWS: an audio bias based model for noise robust small-footprint  keyword spotting",
    "abstract": "Real-world complex acoustic environments especially the ones with a low signal-to-noise ratio (SNR) will bring tremendous challenges to a keyword spotting (KWS) system. Inspired by the recent advances of neural speech enhancement and context bias in speech recognition, we propose a robust audio context bias based DCCRN-KWS model to address this challenge. We form the whole architecture as a multi-task learning framework for both denosing and keyword spotting, where the DCCRN encoder is connected with the KWS model. Helped with the denoising task, we further introduce an audio context bias mod?ule to leverage the real keyword samples and bias the network to better iscriminate keywords in noisy conditions. Feature merge and complex context linear modules are also introduced to strength such discrimination and to effectively leverage contextual information respectively. Experiments on the internal challenging dataset and the HIMIYA public dataset show that our DCCRN-KWS system is superior in performance, while ablation study demonstrates the good design of the whole model. ",
    "url": "https://arxiv.org/abs/2305.12331",
    "authors": [
      "Shubo Lv",
      "Xiong Wang",
      "Sining Sun",
      "Long Ma",
      "Lei Xie"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.12372",
    "title": "Joint Activity-Delay Detection and Channel Estimation for Asynchronous  Massive Random Access",
    "abstract": "Most existing studies on joint activity detection and channel estimation for grant-free massive random access (RA) systems assume perfect synchronization among all active users, which is hard to achieve in practice. Therefore, this paper considers asynchronous grant-free massive RA systems and develops novel algorithms for joint user activity detection, synchronization delay detection, and channel estimation. In particular, the framework of orthogonal approximate message passing (OAMP) is first utilized to deal with the non-independent and identically distributed (i.i.d.) pilot matrix in asynchronous grant-free massive RA systems, and an OAMP-based algorithm capable of leveraging the common sparsity among the received pilot signals from multiple base station antennas is developed. To reduce the computational complexity, a memory AMP (MAMP)based algorithm is further proposed that eliminates the matrix inversions in the OAMP-based algorithm. Simulation results demonstrate the effectiveness of the two proposed algorithms over the baseline methods. Besides, the MAMP-based algorithm reduces 37% of the computations while maintaining comparable detection/estimation accuracy, compared with the OAMP-based algorithm. ",
    "url": "https://arxiv.org/abs/2305.12372",
    "authors": [
      "Xinyu Bian",
      "Yuyi Mao",
      "Jun Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.12447",
    "title": "BreastSAM: A Study of Segment Anything Model for Breast Tumor Detection  in Ultrasound Images",
    "abstract": "Breast cancer is one of the most common cancers among women worldwide, with early detection significantly increasing survival rates. Ultrasound imaging is a critical diagnostic tool that aids in early detection by providing real-time imaging of the breast tissue. We conducted a thorough investigation of the Segment Anything Model (SAM) for the task of interactive segmentation of breast tumors in ultrasound images. We explored three pre-trained model variants: ViT_h, ViT_l, and ViT_b, among which ViT_l demonstrated superior performance in terms of mean pixel accuracy, Dice score, and IoU score. The significance of prompt interaction in improving the model's segmentation performance was also highlighted, with substantial improvements in performance metrics when prompts were incorporated. The study further evaluated the model's differential performance in segmenting malignant and benign breast tumors, with the model showing exceptional proficiency in both categories, albeit with slightly better performance for benign tumors. Furthermore, we analyzed the impacts of various breast tumor characteristics - size, contrast, aspect ratio, and complexity - on segmentation performance. Our findings reveal that tumor contrast and size positively impact the segmentation result, while complex boundaries pose challenges. The study provides valuable insights for using SAM as a robust and effective algorithm for breast tumor segmentation in ultrasound images. ",
    "url": "https://arxiv.org/abs/2305.12447",
    "authors": [
      "Mingzhe Hu",
      "Yuheng Li",
      "Xiaofeng Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12450",
    "title": "Semantic VAD: Low-Latency Voice Activity Detection for Speech  Interaction",
    "abstract": "For speech interaction, voice activity detection (VAD) is often used as a front-end. However, traditional VAD algorithms usually need to wait for a continuous tail silence to reach a preset maximum duration before segmentation, resulting in a large latency that affects user experience. In this paper, we propose a novel semantic VAD for low-latency segmentation. Different from existing methods, a frame-level punctuation prediction task is added to the semantic VAD, and the artificial endpoint is included in the classification category in addition to the often-used speech presence and absence. To enhance the semantic information of the model, we also incorporate an automatic speech recognition (ASR) related semantic loss. Evaluations on an internal dataset show that the proposed method can reduce the average latency by 53.3% without significant deterioration of character error rate in the back-end ASR compared to the traditional VAD approach. ",
    "url": "https://arxiv.org/abs/2305.12450",
    "authors": [
      "Mohan Shi",
      "Yuchun Shu",
      "Lingyun Zuo",
      "Qian Chen",
      "Shiliang Zhang",
      "Jie Zhang",
      "Li-Rong Dai"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.12470",
    "title": "Quasi-Monte Carlo Graph Random Features",
    "abstract": "We present a novel mechanism to improve the accuracy of the recently-introduced class of graph random features (GRFs). Our method induces negative correlations between the lengths of the algorithm's random walks by imposing antithetic termination: a procedure to sample more diverse random walks which may be of independent interest. It has a trivial drop-in implementation. We derive strong theoretical guarantees on the properties of these quasi-Monte Carlo GRFs (q-GRFs), proving that they yield lower-variance estimators of the 2-regularised Laplacian kernel under mild conditions. Remarkably, our results hold for any graph topology. We demonstrate empirical accuracy improvements on a variety of tasks including a new practical application: time-efficient approximation of the graph diffusion process. To our knowledge, q-GRFs constitute the first rigorously studied quasi-Monte Carlo scheme for kernels defined on combinatorial objects, inviting new research on correlations between graph random walks. ",
    "url": "https://arxiv.org/abs/2305.12470",
    "authors": [
      "Isaac Reid",
      "Krzysztof Choromanski",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12493",
    "title": "Contextualized End-to-End Speech Recognition with Contextual Phrase  Prediction Network",
    "abstract": "Contextual information plays a crucial role in speech recognition technologies and incorporating it into the end-to-end speech recognition models has drawn immense interest recently. However, previous deep bias methods lacked explicit supervision for bias tasks. In this study, we introduce a contextual phrase prediction network for an attention-based deep bias method. This network predicts context phrases in utterances using contextual embeddings and calculates bias loss to assist in the training of the contextualized model. Our method achieved a significant word error rate (WER) reduction across various end-to-end speech recognition models. Experiments on the LibriSpeech corpus show that our proposed model obtains a 12.1% relative WER improvement over the baseline model, and the WER of the context phrases decreases relatively by 40.5%. Moreover, by applying a context phrase filtering strategy, we also effectively eliminate the WER degradation when using a larger biasing list. ",
    "url": "https://arxiv.org/abs/2305.12493",
    "authors": [
      "Kaixun Huang",
      "Ao Zhang",
      "Zhanheng Yang",
      "Pengcheng Guo",
      "Bingshen Mu",
      "Tianyi Xu",
      "Lei Xie"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.12530",
    "title": "Towards Robust Family-Infant Audio Analysis Based on Unsupervised  Pretraining of Wav2vec 2.0 on Large-Scale Unlabeled Family Audio",
    "abstract": "To perform automatic family audio analysis, past studies have collected recordings using phone, video, or audio-only recording devices like LENA, investigated supervised learning methods, and used or fine-tuned general-purpose embeddings learned from large pretrained models. In this study, we advance the audio component of a new infant wearable multi-modal device called LittleBeats (LB) by learning family audio representation via wav2vec 2.0 (W2V2) pertaining. We show given a limited number of labeled LB home recordings, W2V2 pretrained using 1k-hour of unlabeled home recordings outperforms oracle W2V2 pretrained on 52k-hour unlabeled audio in terms of parent/infant speaker diarization (SD) and vocalization classifications (VC) at home. Extra relevant external unlabeled and labeled data further benefit W2V2 pretraining and fine-tuning. With SpecAug and environmental speech corruptions, we obtain 12% relative gain on SD and moderate boost on VC. Code and model weights are available. ",
    "url": "https://arxiv.org/abs/2305.12530",
    "authors": [
      "Jialu Li",
      "Mark Hasegawa-Johnson",
      "Nancy L. McElwain"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.12570",
    "title": "Generalizable synthetic MRI with physics-informed convolutional networks",
    "abstract": "In this study, we develop a physics-informed deep learning-based method to synthesize multiple brain magnetic resonance imaging (MRI) contrasts from a single five-minute acquisition and investigate its ability to generalize to arbitrary contrasts to accelerate neuroimaging protocols. A dataset of fifty-five subjects acquired with a standard MRI protocol and a five-minute transient-state sequence was used to develop a physics-informed deep learning-based method. The model, based on a generative adversarial network, maps data acquired from the five-minute scan to \"effective\" quantitative parameter maps, here named q*-maps, by using its generated PD, T1, and T2 values in a signal model to synthesize four standard contrasts (proton density-weighted, T1-weighted, T2-weighted, and T2-weighted fluid-attenuated inversion recovery), from which losses are computed. The q*-maps are compared to literature values and the synthetic contrasts are compared to an end-to-end deep learning-based method proposed by literature. The generalizability of the proposed method is investigated for five volunteers by synthesizing three non-standard contrasts unseen during training and comparing these to respective ground truth acquisitions via contrast-to-noise ratio and quantitative assessment. The physics-informed method was able to match the high-quality synthMRI of the end-to-end method for the four standard contrasts, with mean \\pm standard deviation structural similarity metrics above 0.75 \\pm 0.08 and peak signal-to-noise ratios above 22.4 \\pm 1.9 and 22.6 \\pm 2.1. Additionally, the physics-informed method provided retrospective contrast adjustment, with visually similar signal contrast and comparable contrast-to-noise ratios to the ground truth acquisitions for three sequences unused for model training, demonstrating its generalizability and potential application to accelerate neuroimaging protocols. ",
    "url": "https://arxiv.org/abs/2305.12570",
    "authors": [
      "Luuk Jacobs",
      "Stefano Mandija",
      "Hongyan Liu",
      "Cornelis A.T. van den Berg",
      "Alessandro Sbrizzi",
      "Matteo Maspero"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12688",
    "title": "Testing Isomorphism of Graphs in Polynomial Time",
    "abstract": "Given a graph $G$, the graph $[G]$ obtained by adding, for each pair of vertices of $G$, a unique vertex adjacent to both vertices is called the binding graph of $G$. In this work, we show that the class of binding graphs is graph-isomorphism complete and that the stable partitions of binding graphs by the Weisfeiler-Lehman (WL) algorithm produce automorphism partitions. To test the isomorphism of two graphs $G$ and $H$, one computes the stable graph of the binding graph $[G\\uplus H]$ for the disjoint union graph $G\\uplus H$. The automorphism partition reveals the isomorphism of $G$ and $H$. Because the WL algorithm is a polynomial-time procedure, the claim can be made that the graph-isomorphism problem is in complexity class $\\mathtt{P}$. ",
    "url": "https://arxiv.org/abs/2305.12688",
    "authors": [
      "Rui Xue"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2305.12769",
    "title": "Constructions of $k$-uniform states in heterogeneous systems",
    "abstract": "A pure quantum state of $n$ parties associated with the Hilbert space $\\CC^{d_1}\\otimes \\CC^{d_2}\\otimes\\cdots\\otimes \\CC^{d_n}$ is called $k$-uniform if all the reductions to $k$-parties are maximally mixed. The $n$ partite system is called homogenous if the local dimension $d_1=d_2=\\cdots=d_n$, while it is called heterogeneous if the local dimension are not all equal. $k$-uniform sates play an important role in quantum information theory. There are many progress in characterizing and constructing $k$-uniform states in homogeneous systems. However, the study of entanglement for heterogeneous systems is much more challenging than that for the homogeneous case. There are very few results known for the $k$-uniform states in heterogeneous systems for $k>3$. We present two general methods to construct $k$-uniform states in the heterogeneous systems for general $k$. The first construction is derived from the error correcting codes by establishing a connection between irredundant mixed orthogonal arrays and error correcting codes. We can produce many new $k$-uniform states such that the local dimension of each subsystem can be a prime power. The second construction is derived from a matrix $H$ meeting the condition that $H_{A\\times \\bar{A}}+H^T_{\\bar{A}\\times A}$ has full rank for any row index set $A$ of size $k$. These matrix construction can provide more flexible choices for the local dimensions, i.e., the local dimensions can be any integer (not necessarily prime power) subject to some constraints. Our constructions imply that for any positive integer $k$, one can construct $k$-uniform states of a heterogeneous system in many different Hilbert spaces. ",
    "url": "https://arxiv.org/abs/2305.12769",
    "authors": [
      "Keqin Feng",
      "Lingfei Jin",
      "Chaoping Xing",
      "Chen Yuan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.12822",
    "title": "Quantifying the effect of X-ray scattering for data generation in  real-time defect detection",
    "abstract": "X-ray imaging is widely used for non-destructive detection of defects in industrial products on a conveyor belt. Real-time detection requires highly accurate, robust, and fast algorithms to analyze X-ray images. Deep convolutional neural networks (DCNNs) satisfy these requirements if a large amount of labeled data is available. To overcome the challenge of collecting these data, different methods of X-ray image generation can be considered. Depending on the desired level of similarity to real data, various physical effects either should be simulated or can be ignored. X-ray scattering is known to be computationally expensive to simulate, and this effect can heavily influence the accuracy of a generated X-ray image. We propose a methodology for quantitative evaluation of the effect of scattering on defect detection. This methodology compares the accuracy of DCNNs trained on different versions of the same data that include and exclude the scattering signal. We use the Probability of Detection (POD) curves to find the size of the smallest defect that can be detected with a DCNN and evaluate how this size is affected by the choice of training data. We apply the proposed methodology to a model problem of defect detection in cylinders. Our results show that the exclusion of the scattering signal from the training data has the largest effect on the smallest detectable defects. Furthermore, we demonstrate that accurate inspection is more reliant on high-quality training data for images with a high quantity of scattering. We discuss how the presented methodology can be used for other tasks and objects. ",
    "url": "https://arxiv.org/abs/2305.12822",
    "authors": [
      "Vladyslav Andriiashen",
      "Robert van Liere",
      "Tristan van Leeuwen",
      "K. Joost Batenburg"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12824",
    "title": "FieldHAR: A Fully Integrated End-to-end RTL Framework for Human Activity  Recognition with Neural Networks from Heterogeneous Sensors",
    "abstract": "In this work, we propose an open-source scalable end-to-end RTL framework FieldHAR, for complex human activity recognition (HAR) from heterogeneous sensors using artificial neural networks (ANN) optimized for FPGA or ASIC integration. FieldHAR aims to address the lack of apparatus to transform complex HAR methodologies often limited to offline evaluation to efficient run-time edge applications. The framework uses parallel sensor interfaces and integer-based multi-branch convolutional neural networks (CNNs) to support flexible modality extensions with synchronous sampling at the maximum rate of each sensor. To validate the framework, we used a sensor-rich kitchen scenario HAR application which was demonstrated in a previous offline study. Through resource-aware optimizations, with FieldHAR the entire RTL solution was created from data acquisition to ANN inference taking as low as 25\\% logic elements and 2\\% memory bits of a low-end Cyclone IV FPGA and less than 1\\% accuracy loss from the original FP32 precision offline study. The RTL implementation also shows advantages over MCU-based solutions, including superior data acquisition performance and virtually eliminating ANN inference bottleneck. ",
    "url": "https://arxiv.org/abs/2305.12824",
    "authors": [
      "Mengxi Liu",
      "Bo Zhou",
      "Zimin Zhao",
      "Hyeonseok Hong",
      "Hyun Kim",
      "Sungho Suh",
      "Vitor Fortes Rey",
      "Paul Lukowicz"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2305.12831",
    "title": "Target Active Speaker Detection with Audio-visual Cues",
    "abstract": "In active speaker detection (ASD), we would like to detect whether an on-screen person is speaking based on audio-visual cues. Previous studies have primarily focused on modeling audio-visual synchronization cue, which depends on the video quality of the lip region of a speaker. In real-world applications, it is possible that we can also have the reference speech of the on-screen speaker. To benefit from both facial cue and reference speech, we propose the Target Speaker TalkNet (TS-TalkNet), which leverages a pre-enrolled speaker embedding to complement the audio-visual synchronization cue in detecting whether the target speaker is speaking. Our framework outperforms the popular model, TalkNet on two datasets, achieving absolute improvements of 1.6\\% in mAP on the AVA-ActiveSpeaker validation set, and 0.8\\%, 0.4\\%, and 0.8\\% in terms of AP, AUC and EER on the ASW test set, respectively. Code is available at \\href{https://github.com/Jiang-Yidi/TS-TalkNet/}{\\color{red}{https://github.com/Jiang-Yidi/TS-TalkNet/}}. ",
    "url": "https://arxiv.org/abs/2305.12831",
    "authors": [
      "Yidi Jiang",
      "Ruijie Tao",
      "Zexu Pan",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.12854",
    "title": "RSA-INR: Riemannian Shape Autoencoding via 4D Implicit Neural  Representations",
    "abstract": "Shape encoding and shape analysis are valuable tools for comparing shapes and for dimensionality reduction. A specific framework for shape analysis is the Large Deformation Diffeomorphic Metric Mapping (LDDMM) framework, which is capable of shape matching and dimensionality reduction. Researchers have recently introduced neural networks into this framework. However, these works can not match more than two objects simultaneously or have suboptimal performance in shape variability modeling. The latter limitation occurs as the works do not use state-of-the-art shape encoding methods. Moreover, the literature does not discuss the connection between the LDDMM Riemannian distance and the Riemannian geometry for deep learning literature. Our work aims to bridge this gap by demonstrating how LDDMM can integrate Riemannian geometry into deep learning. Furthermore, we discuss how deep learning solves and generalizes shape matching and dimensionality reduction formulations of LDDMM. We achieve both goals by designing a novel implicit encoder for shapes. This model extends a neural network-based algorithm for LDDMM-based pairwise registration, results in a nonlinear manifold PCA, and adds a Riemannian geometry aspect to deep learning models for shape variability modeling. Additionally, we demonstrate that the Riemannian geometry component improves the reconstruction procedure of the implicit encoder in terms of reconstruction quality and stability to noise. We hope our discussion paves the way to more research into how Riemannian geometry, shape/image analysis, and deep learning can be combined. ",
    "url": "https://arxiv.org/abs/2305.12854",
    "authors": [
      "Sven Dummer",
      "Nicola Strisciuglio",
      "Christoph Brune"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2305.12887",
    "title": "ZS-MSTM: Zero-Shot Style Transfer for Gesture Animation driven by Text  and Speech using Adversarial Disentanglement of Multimodal Style Encoding",
    "abstract": "In this study, we address the importance of modeling behavior style in virtual agents for personalized human-agent interaction. We propose a machine learning approach to synthesize gestures, driven by prosodic features and text, in the style of different speakers, even those unseen during training. Our model incorporates zero-shot multimodal style transfer using multimodal data from the PATS database, which contains videos of diverse speakers. We recognize style as a pervasive element during speech, influencing the expressivity of communicative behaviors, while content is conveyed through multimodal signals and text. By disentangling content and style, we directly infer the style embedding, even for speakers not included in the training phase, without the need for additional training or fine-tuning. Objective and subjective evaluations are conducted to validate our approach and compare it against two baseline methods. ",
    "url": "https://arxiv.org/abs/2305.12887",
    "authors": [
      "Mireille Fares",
      "Catherine Pelachaud",
      "Nicolas Obin"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.12994",
    "title": "Multistatic Integrated Sensing and Communication System in Cellular  Networks",
    "abstract": "A novel multistatic multiple-input multiple-output (MIMO) integrated sensing and communication (ISAC) system in cellular networks is proposed. It can make use of widespread base stations (BSs) to perform cooperative sensing in wide area. This system is important since the deployment of sensing function can be achieved based on the existing mobile communication networks at a low cost. In this system, orthogonal frequency division multiplexing (OFDM) signals transmitted from the central BS are received and processed by each of the neighboring BSs to estimate sensing object parameters. A joint data processing method is then introduced to derive the closed-form solution of objects position and velocity. Numerical simulation shows that the proposed multistatic system can improve the position and velocity estimation accuracy compared with monostatic and bistatic system, demonstrating the effectiveness and promise of implementing ISAC in the upcoming fifth generation advanced (5G-A) and sixth generation (6G) mobile networks. ",
    "url": "https://arxiv.org/abs/2305.12994",
    "authors": [
      "Zixiang Han",
      "Lincong Han",
      "Xiaozhou Zhang",
      "Yajuan Wang",
      "Liang Ma",
      "Mengting Lou",
      "Jing Jin",
      "Guangyi Liu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.13127",
    "title": "What Symptoms and How Long? An Interpretable AI Approach for Depression  Detection in Social Media",
    "abstract": "Depression is the most prevalent and serious mental illness, which induces grave financial and societal ramifications. Depression detection is key for early intervention to mitigate those consequences. Such a high-stake decision inherently necessitates interpretability, which most existing methods fall short of. To connect human expertise in this decision-making, safeguard trust from end users, and ensure algorithm transparency, we develop an interpretable deep learning model: Multi-Scale Temporal Prototype Network (MSTPNet). MSTPNet is built upon the emergent prototype learning methods. In line with the medical practice of depression diagnosis, MSTPNet differs from existing prototype learning models in its capability of capturing the depressive symptoms and their temporal distribution such as frequency and persistence of appearance. Extensive empirical analyses using real-world social media data show that MSTPNet outperforms state-of-the-art benchmarks in depression detection, with an F1-score of 0.851. Moreover, MSTPNet interprets its prediction by identifying what depression symptoms the user presents and how long these related symptoms last. We further conduct a user study to demonstrate its superiority over the benchmarks in interpretability. Methodologically, this study contributes to extant literature with a novel interpretable deep learning model for depression detection in social media. Our proposed method can be implemented in social media platforms to detect depression and its symptoms. Platforms can subsequently provide personalized online resources such as educational and supporting videos and articles, or sources for treatments and social support for depressed patients. ",
    "url": "https://arxiv.org/abs/2305.13127",
    "authors": [
      "Junwei Kuang",
      "Jiaheng Xie",
      "Zhijun Yan"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13161",
    "title": "DeepJSCC-l++: Robust and Bandwidth-Adaptive Wireless Image Transmission",
    "abstract": "This paper presents a novel vision transformer (ViT) based deep joint source channel coding (DeepJSCC) scheme, dubbed DeepJSCC-l++, which can be adaptive to multiple target bandwidth ratios as well as different channel signal-to-noise ratios (SNRs) using a single model. To achieve this, we train the proposed DeepJSCC-l++ model with different bandwidth ratios and SNRs, which are fed to the model as side information. The reconstruction losses corresponding to different bandwidth ratios are calculated, and a new training methodology is proposed, which dynamically assigns different weights to the losses of different bandwidth ratios according to their individual reconstruction qualities. Shifted window (Swin) transformer, is adopted as the backbone for our DeepJSCC-l++ model. Through extensive simulations it is shown that the proposed DeepJSCC-l++ and successive refinement models can adapt to different bandwidth ratios and channel SNRs with marginal performance loss compared to the separately trained models. We also observe the proposed schemes can outperform the digital baseline, which concatenates the BPG compression with capacity-achieving channel code. ",
    "url": "https://arxiv.org/abs/2305.13161",
    "authors": [
      "Chenghong Bian",
      "Yulin Shao",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.13239",
    "title": "Sampling from the random cluster model on random regular graphs at all  temperatures via Glauber dynamics",
    "abstract": "We consider the performance of Glauber dynamics for the random cluster model with real parameter $q>1$ and temperature $\\beta>0$. Recent work by Helmuth, Jenssen and Perkins detailed the ordered/disordered transition of the model on random $\\Delta$-regular graphs for all sufficiently large $q$ and obtained an efficient sampling algorithm for all temperatures $\\beta$ using cluster expansion methods. Despite this major progress, the performance of natural Markov chains, including Glauber dynamics, is not yet well understood on the random regular graph, partly because of the non-local nature of the model (especially at low temperatures) and partly because of severe bottleneck phenomena that emerge in a window around the ordered/disordered transition. Nevertheless, it is widely conjectured that the bottleneck phenomena that impede mixing from worst-case starting configurations can be avoided by initialising the chain more judiciously. Our main result establishes this conjecture for all sufficiently large $q$ (with respect to $\\Delta$). Specifically, we consider the mixing time of Glauber dynamics initialised from the two extreme configurations, the all-in and all-out, and obtain a pair of fast mixing bounds which cover all temperatures $\\beta$, including in particular the bottleneck window. Our result is inspired by the recent approach of Gheissari and Sinclair for the Ising model who obtained a similar-flavoured mixing-time bound on the random regular graph for sufficiently low temperatures. To cover all temperatures in the RC model, we refine appropriately the structural results of Helmuth, Jenssen and Perkins about the ordered/disordered transition and show spatial mixing properties ''within the phase'', which are then related to the evolution of the chain. ",
    "url": "https://arxiv.org/abs/2305.13239",
    "authors": [
      "Andreas Galanis",
      "Leslie Ann Goldberg",
      "Paulina Smolarova"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2305.13248",
    "title": "Bayesian Numerical Integration with Neural Networks",
    "abstract": "Bayesian probabilistic numerical methods for numerical integration offer significant advantages over their non-Bayesian counterparts: they can encode prior information about the integrand, and can quantify uncertainty over estimates of an integral. However, the most popular algorithm in this class, Bayesian quadrature, is based on Gaussian process models and is therefore associated with a high computational cost. To improve scalability, we propose an alternative approach based on Bayesian neural networks which we call Bayesian Stein networks. The key ingredients are a neural network architecture based on Stein operators, and an approximation of the Bayesian posterior based on the Laplace approximation. We show that this leads to orders of magnitude speed-ups on the popular Genz functions benchmark, and on challenging problems arising in the Bayesian analysis of dynamical systems, and the prediction of energy production for a large-scale wind farm. ",
    "url": "https://arxiv.org/abs/2305.13248",
    "authors": [
      "Katharina Ott",
      "Michael Tiemann",
      "Philipp Hennig",
      "Fran\u00e7ois-Xavier Briol"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13271",
    "title": "MAGDiff: Covariate Data Set Shift Detection via Activation Graphs of  Deep Neural Networks",
    "abstract": "Despite their successful application to a variety of tasks, neural networks remain limited, like other machine learning methods, by their sensitivity to shifts in the data: their performance can be severely impacted by differences in distribution between the data on which they were trained and that on which they are deployed. In this article, we propose a new family of representations, called MAGDiff, that we extract from any given neural network classifier and that allows for efficient covariate data shift detection without the need to train a new model dedicated to this task. These representations are computed by comparing the activation graphs of the neural network for samples belonging to the training distribution and to the target distribution, and yield powerful data- and task-adapted statistics for the two-sample tests commonly used for data set shift detection. We demonstrate this empirically by measuring the statistical powers of two-sample Kolmogorov-Smirnov (KS) tests on several different data sets and shift types, and showing that our novel representations induce significant improvements over a state-of-the-art baseline relying on the network output. ",
    "url": "https://arxiv.org/abs/2305.13271",
    "authors": [
      "Felix Hensel",
      "Charles Arnal",
      "Mathieu Carri\u00e8re",
      "Th\u00e9o Lacombe",
      "Hiroaki Kurihara",
      "Yuichi Ike",
      "Fr\u00e9d\u00e9ric Chazal"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1706.00178",
    "title": "Network Capacity Bound for Personalized PageRank in Multimodal Networks",
    "abstract": " Comments: 21 pages. 2 tables, 30 bibliography positions ",
    "url": "https://arxiv.org/abs/1706.00178",
    "authors": [
      "M.A. K\u0142opotek",
      "S.T. Wierzcho\u0144",
      "R.A. K\u0142opotek"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:1909.04652",
    "title": "The detection of relativistic corrections in cosmological N-body  simulations",
    "abstract": " Comments: 15 pages, 8 figures. Replaced with revised version accepted for publication in Celestial Mechanics and Dynamical Astronomy; data available at this https URL ",
    "url": "https://arxiv.org/abs/1909.04652",
    "authors": [
      "Jean-Pierre Eckmann",
      "Farbod Hassani"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:1911.01258",
    "title": "SHARP: An Adaptable, Energy-Efficient Accelerator for Recurrent Neural  Network",
    "abstract": " Title: SHARP: An Adaptable, Energy-Efficient Accelerator for Recurrent Neural  Network ",
    "url": "https://arxiv.org/abs/1911.01258",
    "authors": [
      "Reza Yazdani",
      "Olatunji Ruwase",
      "Minjia Zhang",
      "Yuxiong He",
      "Jose-Maria Arnau",
      "Antonio Gonzalez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:1912.05946",
    "title": "Leveraging End-to-End Speech Recognition with Neural Architecture Search",
    "abstract": " Comments: A large part of the document needs to be reviewed to meet current standards in the Automatic Speech Recognition ",
    "url": "https://arxiv.org/abs/1912.05946",
    "authors": [
      "Ahmed Baruwa",
      "Mojeed Abisiga",
      "Ibrahim Gbadegesin",
      "Afeez Fakunle"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2012.06791",
    "title": "Bayesian graph neural networks for strain-based crack localization",
    "abstract": " Title: Bayesian graph neural networks for strain-based crack localization ",
    "url": "https://arxiv.org/abs/2012.06791",
    "authors": [
      "Charilaos Mylonas",
      "George Tsialiamanis",
      "Keith Worden",
      "Eleni N. Chatzi"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2102.07389",
    "title": "And/or trade-off in artificial neurons: impact on adversarial robustness",
    "abstract": " Title: And/or trade-off in artificial neurons: impact on adversarial robustness ",
    "url": "https://arxiv.org/abs/2102.07389",
    "authors": [
      "Alessandro Fontana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2108.11451",
    "title": "From Statistical Relational to Neural Symbolic Artificial Intelligence:  a Survey",
    "abstract": " Comments: Extended version of IJCAI 2020 survey, this https URL ",
    "url": "https://arxiv.org/abs/2108.11451",
    "authors": [
      "Giuseppe Marra",
      "Sebastijan Duman\u010di\u0107",
      "Robin Manhaeve",
      "Luc De Raedt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.02442",
    "title": "PoNet: Pooling Network for Efficient Token Mixing in Long Sequences",
    "abstract": " Comments: Accepted by ICLR 2022. Codes and checkpoints are also available on huggingface hub: this https URL ",
    "url": "https://arxiv.org/abs/2110.02442",
    "authors": [
      "Chao-Hong Tan",
      "Qian Chen",
      "Wen Wang",
      "Qinglin Zhang",
      "Siqi Zheng",
      "Zhen-Hua Ling"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.07623",
    "title": "D-LNBot: A Scalable, Cost-Free and Covert Hybrid Botnet on Bitcoin's  Lightning Network",
    "abstract": " Comments: Revised version based on anonymous reviewers' comments. Journal extension of this https URL ",
    "url": "https://arxiv.org/abs/2112.07623",
    "authors": [
      "Ahmet Kurt",
      "Enes Erdin",
      "Kemal Akkaya",
      "A. Selcuk Uluagac",
      "Mumin Cebe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2112.13257",
    "title": "A Fast Row-Stochastic Decentralized Method for Distributed Optimization  Over Directed Graphs",
    "abstract": " Title: A Fast Row-Stochastic Decentralized Method for Distributed Optimization  Over Directed Graphs ",
    "url": "https://arxiv.org/abs/2112.13257",
    "authors": [
      "Diyako Ghaderyan",
      "Necdet Serhat Aybat",
      "A. Pedro Aguiar",
      "Fernando Lobo Pereira"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2201.12020",
    "title": "A Robust and Flexible EM Algorithm for Mixtures of Elliptical  Distributions with Missing Data",
    "abstract": " Title: A Robust and Flexible EM Algorithm for Mixtures of Elliptical  Distributions with Missing Data ",
    "url": "https://arxiv.org/abs/2201.12020",
    "authors": [
      "Florian Mouret",
      "Alexandre Hippert-Ferrer",
      "Fr\u00e9d\u00e9ric Pascal",
      "Jean-Yves Tourneret"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.13001",
    "title": "Deep Discriminative to Kernel Generative Networks for Calibrated  Inference",
    "abstract": " Title: Deep Discriminative to Kernel Generative Networks for Calibrated  Inference ",
    "url": "https://arxiv.org/abs/2201.13001",
    "authors": [
      "Jayanta Dey",
      "Haoyin Xu",
      "Ashwin De Silva",
      "Will LeVine",
      "Tyler M. Tomita",
      "Ali Geisa",
      "Tiffany Chu",
      "Jacob Desman",
      "Joshua T. Vogelstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.03277",
    "title": "On The Empirical Effectiveness of Unrealistic Adversarial Hardening  Against Realistic Adversarial Attacks",
    "abstract": " Comments: S&P 2023 ",
    "url": "https://arxiv.org/abs/2202.03277",
    "authors": [
      "Salijona Dyrmishi",
      "Salah Ghamizi",
      "Thibault Simonetto",
      "Yves Le Traon",
      "Maxime Cordy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.05250",
    "title": "Adaptive and Robust Multi-Task Learning",
    "abstract": " Comments: 70 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2202.05250",
    "authors": [
      "Yaqi Duan",
      "Kaizheng Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2202.10206",
    "title": "DECLOAK: Enable Secure and Cheap Multi-Party Transactions on Legacy  Blockchains by a Minimally Trusted TEE Network",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2106.13926 ",
    "url": "https://arxiv.org/abs/2202.10206",
    "authors": [
      "Qian Ren",
      "Yue Li",
      "Yingjun Wu",
      "Yuchen Wu",
      "Hong Lei",
      "Lei Wang",
      "Bangdao Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2202.13060",
    "title": "Graph Attention Retrospective",
    "abstract": " Comments: 45 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2202.13060",
    "authors": [
      "Kimon Fountoulakis",
      "Amit Levi",
      "Shenghao Yang",
      "Aseem Baranwal",
      "Aukosh Jagannath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2203.02431",
    "title": "Rethinking Efficient Lane Detection via Curve Modeling",
    "abstract": " Comments: Fix GT fitting equations and descriptions in Section 3.3. Code: this https URL ",
    "url": "https://arxiv.org/abs/2203.02431",
    "authors": [
      "Zhengyang Feng",
      "Shaohua Guo",
      "Xin Tan",
      "Ke Xu",
      "Min Wang",
      "Lizhuang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.04524",
    "title": "Multi-Agent Active Search using Detection and Location Uncertainty",
    "abstract": " Comments: Accepted to ICRA 2023 ",
    "url": "https://arxiv.org/abs/2203.04524",
    "authors": [
      "Arundhati Banerjee",
      "Ramina Ghods",
      "Jeff Schneider"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2203.10810",
    "title": "Information-theoretic analyses of neural data to minimize the effect of  researchers' assumptions in predictive coding studies",
    "abstract": " Comments: 36 pages, 9 figures, 3 tables; add link to analysis code ",
    "url": "https://arxiv.org/abs/2203.10810",
    "authors": [
      "Patricia Wollstadt",
      "Daniel L. Rathbun",
      "W. Martin Usrey and",
      "Andr\u00e9 Moraes Bastos",
      "Michael Lindner",
      "Viola Priesemann",
      "Michael Wibral"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2204.00618",
    "title": "ASR data augmentation in low-resource settings using cross-lingual  multi-speaker TTS and cross-lingual voice conversion",
    "abstract": " Comments: This paper was accepted at INTERSPEECH 2023 ",
    "url": "https://arxiv.org/abs/2204.00618",
    "authors": [
      "Edresson Casanova",
      "Christopher Shulby",
      "Alexander Korolev",
      "Arnaldo Candido Junior",
      "Anderson da Silva Soares",
      "Sandra Alu\u00edsio",
      "Moacir Antonelli Ponti"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2204.02179",
    "title": "Towards Robust and Accurate Myoelectric Controller Design based on  Multi-objective Optimization using Evolutionary Computation",
    "abstract": " Comments: This is the updated paper ",
    "url": "https://arxiv.org/abs/2204.02179",
    "authors": [
      "Ahmed Aqeel Shaikh",
      "Anand Kumar Mukhopadhyay",
      "Soumyajit Poddar",
      "Suman Samui"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10217",
    "title": "Memorization and Optimization in Deep Neural Networks with Minimum  Over-parameterization",
    "abstract": " Comments: Uniformed with the published NeurIPS 2022 version ",
    "url": "https://arxiv.org/abs/2205.10217",
    "authors": [
      "Simone Bombari",
      "Mohammad Hossein Amani",
      "Marco Mondelli"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12495",
    "title": "ToKen: Task Decomposition and Knowledge Infusion for Few-Shot Hate  Speech Detection",
    "abstract": " Comments: Accepted at EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2205.12495",
    "authors": [
      "Badr AlKhamissi",
      "Faisal Ladhak",
      "Srini Iyer",
      "Ves Stoyanov",
      "Zornitsa Kozareva",
      "Xian Li",
      "Pascale Fung",
      "Lambert Mathias",
      "Asli Celikyilmaz",
      "Mona Diab"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.00606",
    "title": "Topological Deep Learning: Going Beyond Graph Data",
    "abstract": " Title: Topological Deep Learning: Going Beyond Graph Data ",
    "url": "https://arxiv.org/abs/2206.00606",
    "authors": [
      "Mustafa Hajij",
      "Ghada Zamzmi",
      "Theodore Papamarkou",
      "Nina Miolane",
      "Aldo Guzm\u00e1n-S\u00e1enz",
      "Karthikeyan Natesan Ramamurthy",
      "Tolga Birdal",
      "Tamal K. Dey",
      "Soham Mukherjee",
      "Shreyas N. Samaga",
      "Neal Livesay",
      "Robin Walters",
      "Paul Rosen",
      "Michael T. Schaub"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)",
      "Algebraic Topology (math.AT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.02073",
    "title": "A Densely Interconnected Network for Deep Learning Accelerated MRI",
    "abstract": " Title: A Densely Interconnected Network for Deep Learning Accelerated MRI ",
    "url": "https://arxiv.org/abs/2207.02073",
    "authors": [
      "Jon Andre Ottesen",
      "Matthan W.A. Caan",
      "Inge Rasmus Groote",
      "Atle Bj\u00f8rnerud"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.07118",
    "title": "A novel approach for FPGA-to-server data transmission over an  Ethernet-based network using the eXpress Data Path technology",
    "abstract": " Comments: 12 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2208.07118",
    "authors": [
      "Carsten D\u00fclsen",
      "Tobias Flick",
      "Timo G\u00f6hring",
      "Wolfgang Wagner",
      "Marius Wensing"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2208.07144",
    "title": "Quantum bandit with amplitude amplification exploration in an  adversarial environment",
    "abstract": " Comments: Accepted to appear in IEEE TKDE ",
    "url": "https://arxiv.org/abs/2208.07144",
    "authors": [
      "Byungjin Cho",
      "Yu Xiao",
      "Pan Hui",
      "Daoyi Dong"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.07252",
    "title": "Quantifying uncertain system outputs via the multi-level Monte Carlo  method -- distribution and robustness measures",
    "abstract": " Comments: 35 pages, 48 figures. Data available at this https URL ",
    "url": "https://arxiv.org/abs/2208.07252",
    "authors": [
      "Quentin Ayoul-Guilmard",
      "Sundar Ganesh",
      "Sebastian Krumscheid",
      "Fabio Nobile"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2208.07589",
    "title": "Efficient Multimodal Transformer with Dual-Level Feature Restoration for  Robust Multimodal Sentiment Analysis",
    "abstract": " Comments: Accepted by TAC. The code is available at this https URL ",
    "url": "https://arxiv.org/abs/2208.07589",
    "authors": [
      "Licai Sun",
      "Zheng Lian",
      "Bin Liu",
      "Jianhua Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2208.10531",
    "title": "RAIN: RegulArization on Input and Network for Black-Box Domain  Adaptation",
    "abstract": " Comments: Accepted by IJCAI 2023 ",
    "url": "https://arxiv.org/abs/2208.10531",
    "authors": [
      "Qucheng Peng",
      "Zhengming Ding",
      "Lingjuan Lyu",
      "Lichao Sun",
      "Chen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.13579",
    "title": "Shaken, and Stirred: Long-Range Dependencies Enable Robust Outlier  Detection with PixelCNN++",
    "abstract": " Title: Shaken, and Stirred: Long-Range Dependencies Enable Robust Outlier  Detection with PixelCNN++ ",
    "url": "https://arxiv.org/abs/2208.13579",
    "authors": [
      "Barath Mohan Umapathi",
      "Kushal Chauhan",
      "Pradeep Shenoy",
      "Devarajan Sridharan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.03416",
    "title": "Bispectral Neural Networks",
    "abstract": " Title: Bispectral Neural Networks ",
    "url": "https://arxiv.org/abs/2209.03416",
    "authors": [
      "Sophia Sanborn",
      "Christian Shewmake",
      "Bruno Olshausen",
      "Christopher Hillar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.07350",
    "title": "Overhead-Free Blockage Detection and Precoding Through Physics-Based  Graph Neural Networks: LIDAR Data Meets Ray Tracing",
    "abstract": " Comments: Accepted by IEEE for publication ",
    "url": "https://arxiv.org/abs/2209.07350",
    "authors": [
      "Matteo Nerini",
      "Bruno Clerckx"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2209.08030",
    "title": "Detection of Interacting Variables for Generalized Linear Models via  Neural Networks",
    "abstract": " Comments: 30 pages, 6 Figures ",
    "url": "https://arxiv.org/abs/2209.08030",
    "authors": [
      "Yevhen Havrylenko",
      "Julia Heger"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2209.11596",
    "title": "Quantification before Selection: Active Dynamics Preference for Robust  Reinforcement Learning",
    "abstract": " Title: Quantification before Selection: Active Dynamics Preference for Robust  Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2209.11596",
    "authors": [
      "Kang Xu",
      "Yan Ma",
      "Wei Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.12885",
    "title": "Neural variance reduction for stochastic differential equations",
    "abstract": " Comments: Updated version ",
    "url": "https://arxiv.org/abs/2209.12885",
    "authors": [
      "P.D. Hinds",
      "M.V. Tretyakov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Computational Finance (q-fin.CP)"
    ]
  },
  {
    "id": "arXiv:2209.14402",
    "title": "L2XGNN: Learning to Explain Graph Neural Networks",
    "abstract": " Title: L2XGNN: Learning to Explain Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2209.14402",
    "authors": [
      "Giuseppe Serra",
      "Mathias Niepert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.00520",
    "title": "Periodic orbits in deterministic discrete-time evolutionary game  dynamics: An information-theoretic perspective",
    "abstract": " Comments: 12 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2210.00520",
    "authors": [
      "Sayak Bhattacharjee",
      "Vikash Kumar Dubey",
      "Archan Mukhopadhyay",
      "Sagar Chakraborty"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Information Theory (cs.IT)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2210.01969",
    "title": "Hierarchical Adversarial Inverse Reinforcement Learning",
    "abstract": " Title: Hierarchical Adversarial Inverse Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2210.01969",
    "authors": [
      "Jiayu Chen",
      "Tian Lan",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.10260",
    "title": "End-to-End Entity Detection with Proposer and Regressor",
    "abstract": " Comments: Accepted to the Neural Processing Letters (2023) ",
    "url": "https://arxiv.org/abs/2210.10260",
    "authors": [
      "Xueru Wen",
      "Changjiang Zhou",
      "Haotian Tang",
      "Luguang Liang",
      "Yu Jiang",
      "Hong Qi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.14833",
    "title": "Ballot stuffing and participation privacy in pollsite voting",
    "abstract": " Comments: We are withdrawing this paper because we have further developed and expanded the \"ZKP of reverse set membership\" technique introduced in Section 5 of this paper in another one of our papers titled \"Traceable mixnets\" (arXiv:2305.08138) and do not wish the technical contributions of the two papers to overlap ",
    "url": "https://arxiv.org/abs/2210.14833",
    "authors": [
      "Prashant Agrawal",
      "Abhinav Nakarmi",
      "Mahabir Prasad Jhanwar",
      "Subodh Sharma",
      "Subhashis Banerjee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2211.00313",
    "title": "RGMIM: Region-Guided Masked Image Modeling for Learning Meaningful  Representation from X-Ray Images",
    "abstract": " Title: RGMIM: Region-Guided Masked Image Modeling for Learning Meaningful  Representation from X-Ray Images ",
    "url": "https://arxiv.org/abs/2211.00313",
    "authors": [
      "Guang Li",
      "Ren Togo",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.01576",
    "title": "Sequence-Based Plan Feasibility Prediction for Efficient Task and Motion  Planning",
    "abstract": " Title: Sequence-Based Plan Feasibility Prediction for Efficient Task and Motion  Planning ",
    "url": "https://arxiv.org/abs/2211.01576",
    "authors": [
      "Zhutian Yang",
      "Caelan Reed Garrett",
      "Tom\u00e1s Lozano-P\u00e9rez",
      "Leslie Kaelbling",
      "Dieter Fox"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.01696",
    "title": "An Empirical Bayes Analysis of Object Trajectory Representation Models",
    "abstract": " Title: An Empirical Bayes Analysis of Object Trajectory Representation Models ",
    "url": "https://arxiv.org/abs/2211.01696",
    "authors": [
      "Yue Yao",
      "Daniel Goehring",
      "Joerg Reichardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05560",
    "title": "Finite basis physics-informed neural networks as a Schwarz domain  decomposition method",
    "abstract": " Title: Finite basis physics-informed neural networks as a Schwarz domain  decomposition method ",
    "url": "https://arxiv.org/abs/2211.05560",
    "authors": [
      "Victorita Dolean",
      "Alexander Heinlein",
      "Siddhartha Mishra",
      "Ben Moseley"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2211.07166",
    "title": "Optimal Privacy Preserving for Federated Learning in Mobile Edge  Computing",
    "abstract": " Comments: 16 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2211.07166",
    "authors": [
      "Hai M. Nguyen",
      "Nam H. Chu",
      "Diep N. Nguyen",
      "Dinh Thai Hoang",
      "Van-Dinh Nguyen",
      "Minh Hoang Ha",
      "Eryk Dutkiewicz",
      "Marwan Krunz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2211.08691",
    "title": "Towards Long-Tailed 3D Detection",
    "abstract": " Comments: This work has been accepted to the Conference on Robot Learning (CoRL) 2022 ",
    "url": "https://arxiv.org/abs/2211.08691",
    "authors": [
      "Neehar Peri",
      "Achal Dave",
      "Deva Ramanan",
      "Shu Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2211.11534",
    "title": "Towards Adversarially Robust Recommendation from Adaptive Fraudster  Detection",
    "abstract": " Title: Towards Adversarially Robust Recommendation from Adaptive Fraudster  Detection ",
    "url": "https://arxiv.org/abs/2211.11534",
    "authors": [
      "Yuni Lai",
      "Yulin Zhu",
      "Wenqi Fan",
      "Xiaoge Zhang",
      "Kai Zhou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.14302",
    "title": "Neural DAEs: Constrained neural networks",
    "abstract": " Comments: Improved all the results significantly and submitted the article to SIAM SISC ",
    "url": "https://arxiv.org/abs/2211.14302",
    "authors": [
      "Tue Boesen",
      "Eldad Haber",
      "Uri Michael Ascher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2212.07205",
    "title": "Unfoldings and coverings of weighted graphs",
    "abstract": " Title: Unfoldings and coverings of weighted graphs ",
    "url": "https://arxiv.org/abs/2212.07205",
    "authors": [
      "Bruno Courcelle"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2212.09663",
    "title": "Norm of Word Embedding Encodes Information Gain",
    "abstract": " Title: Norm of Word Embedding Encodes Information Gain ",
    "url": "https://arxiv.org/abs/2212.09663",
    "authors": [
      "Momose Oyama",
      "Sho Yokoi",
      "Hidetoshi Shimodaira"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.00511",
    "title": "Asteria-Pro: Enhancing Deep-Learning Based Binary Code Similarity  Detection by Incorporating Domain Knowledge",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2108.06082 ",
    "url": "https://arxiv.org/abs/2301.00511",
    "authors": [
      "Shouguo Yang",
      "Chaopeng Dong",
      "Yang Xiao",
      "Yiran Cheng",
      "Zhiqiang Shi",
      "Zhi Li",
      "Limin Sun"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.01380",
    "title": "Ego-Only: Egocentric Action Detection without Exocentric Transferring",
    "abstract": " Title: Ego-Only: Egocentric Action Detection without Exocentric Transferring ",
    "url": "https://arxiv.org/abs/2301.01380",
    "authors": [
      "Huiyu Wang",
      "Mitesh Kumar Singh",
      "Lorenzo Torresani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.02129",
    "title": "Algorithms and Complexity for Computing Nash Equilibria in Adversarial  Team Games",
    "abstract": " Comments: To appear at the conference on Economics and Computation (EC) 2023 ",
    "url": "https://arxiv.org/abs/2301.02129",
    "authors": [
      "Ioannis Anagnostides",
      "Fivos Kalogiannis",
      "Ioannis Panageas",
      "Emmanouil-Vasileios Vlatakis-Gkaragkounis",
      "Stephen McAleer"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2301.07068",
    "title": "The #DNN-Verification Problem: Counting Unsafe Inputs for Deep Neural  Networks",
    "abstract": " Comments: Accepted in the International Joint Conference on Artificial Intelligence (IJCAI), 2023. [Marzari and Corsi contributed equally] ",
    "url": "https://arxiv.org/abs/2301.07068",
    "authors": [
      "Luca Marzari",
      "Davide Corsi",
      "Ferdinando Cicalese",
      "Alessandro Farinelli"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11233",
    "title": "BiBench: Benchmarking and Analyzing Network Binarization",
    "abstract": " Title: BiBench: Benchmarking and Analyzing Network Binarization ",
    "url": "https://arxiv.org/abs/2301.11233",
    "authors": [
      "Haotong Qin",
      "Mingyuan Zhang",
      "Yifu Ding",
      "Aoyu Li",
      "Zhongang Cai",
      "Ziwei Liu",
      "Fisher Yu",
      "Xianglong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.12814",
    "title": "Complexity of Gaussian boson sampling with tensor networks",
    "abstract": " Comments: 9 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2301.12814",
    "authors": [
      "Minzhao Liu",
      "Changhun Oh",
      "Junyu Liu",
      "Liang Jiang",
      "Yuri Alexeev"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2302.00997",
    "title": "Constrained Online Two-stage Stochastic Optimization: Near Optimal  Algorithms via Adversarial Learning",
    "abstract": " Title: Constrained Online Two-stage Stochastic Optimization: Near Optimal  Algorithms via Adversarial Learning ",
    "url": "https://arxiv.org/abs/2302.00997",
    "authors": [
      "Jiashuo Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.01073",
    "title": "Learning in Multi-Memory Games Triggers Complex Dynamics Diverging from  Nash Equilibrium",
    "abstract": " Comments: 8 pages & 4 figures (main), 6 pages & 1figure (appendix) ",
    "url": "https://arxiv.org/abs/2302.01073",
    "authors": [
      "Yuma Fujimoto",
      "Kaito Ariu",
      "Kenshi Abe"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2302.01471",
    "title": "User-centric Heterogeneous-action Deep Reinforcement Learning for  Virtual Reality in the Metaverse over Wireless Networks",
    "abstract": " Comments: The paper appears in IEEE Transactions on Wireless Communications (TWC), 2023 ",
    "url": "https://arxiv.org/abs/2302.01471",
    "authors": [
      "Wenhan Yu",
      "Terence Jie Chua",
      "Jun Zhao"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02318",
    "title": "Contrast with Reconstruct: Contrastive 3D Representation Learning Guided  by Generative Pretraining",
    "abstract": " Comments: Accepted at ICML 2023 ",
    "url": "https://arxiv.org/abs/2302.02318",
    "authors": [
      "Zekun Qi",
      "Runpei Dong",
      "Guofan Fan",
      "Zheng Ge",
      "Xiangyu Zhang",
      "Kaisheng Ma",
      "Li Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.12600",
    "title": "EvoTorch: Scalable Evolutionary Computation in Python",
    "abstract": " Title: EvoTorch: Scalable Evolutionary Computation in Python ",
    "url": "https://arxiv.org/abs/2302.12600",
    "authors": [
      "Nihat Engin Toklu",
      "Timothy Atkinson",
      "Vojt\u011bch Micka",
      "Pawe\u0142 Liskowski",
      "Rupesh Kumar Srivastava"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.02783",
    "title": "Improved Sample Complexity Bounds for Distributionally Robust  Reinforcement Learning",
    "abstract": " Comments: Appeared in AISTATS 2023 ",
    "url": "https://arxiv.org/abs/2303.02783",
    "authors": [
      "Zaiyan Xu",
      "Kishan Panaganti",
      "Dileep Kalathil"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.03667",
    "title": "Run, Don't Walk: Chasing Higher FLOPS for Faster Neural Networks",
    "abstract": " Comments: Accepted to CVPR 2023 ",
    "url": "https://arxiv.org/abs/2303.03667",
    "authors": [
      "Jierun Chen",
      "Shiu-hong Kao",
      "Hao He",
      "Weipeng Zhuo",
      "Song Wen",
      "Chul-Ho Lee",
      "S.-H. Gary Chan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05739",
    "title": "Boosting Semi-Supervised Few-Shot Object Detection with SoftER Teacher",
    "abstract": " Comments: Technical Report. Project page at this https URL ",
    "url": "https://arxiv.org/abs/2303.05739",
    "authors": [
      "Phi Vu Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06060",
    "title": "Deep Spiking Neural Networks with High Representation Similarity Model  Visual Pathways of Macaque and Mouse",
    "abstract": " Comments: Accepted by Proceedings of the 37th AAAI Conference on Artificial Intelligence (AAAI-23) ",
    "url": "https://arxiv.org/abs/2303.06060",
    "authors": [
      "Liwei Huang",
      "Zhengyu Ma",
      "Liutao Yu",
      "Huihui Zhou",
      "Yonghong Tian"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2303.06817",
    "title": "Transformation-Invariant Network for Few-Shot Object Detection in Remote  Sensing Images",
    "abstract": " Title: Transformation-Invariant Network for Few-Shot Object Detection in Remote  Sensing Images ",
    "url": "https://arxiv.org/abs/2303.06817",
    "authors": [
      "Nanqing Liu",
      "Xun Xu",
      "Turgay Celik",
      "Zongxin Gan",
      "Heng-Chao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09124",
    "title": "Fiber Tract Shape Measures Inform Prediction of Non-Imaging Phenotypes",
    "abstract": " Title: Fiber Tract Shape Measures Inform Prediction of Non-Imaging Phenotypes ",
    "url": "https://arxiv.org/abs/2303.09124",
    "authors": [
      "Wan Liu",
      "Yuqian Chen",
      "Chuyang Ye",
      "Nikos Makris",
      "Yogesh Rathi",
      "Weidong Cai",
      "Fan Zhang",
      "Lauren J. O'Donnell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.11511",
    "title": "STDLens: Model Hijacking-Resilient Federated Learning for Object  Detection",
    "abstract": " Comments: CVPR 2023. Source Code: this https URL ",
    "url": "https://arxiv.org/abs/2303.11511",
    "authors": [
      "Ka-Ho Chow",
      "Ling Liu",
      "Wenqi Wei",
      "Fatih Ilhan",
      "Yanzhao Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12314",
    "title": "Self-supervised Meta-Prompt Learning with Meta-Gradient Regularization  for Few-shot Generalization",
    "abstract": " Title: Self-supervised Meta-Prompt Learning with Meta-Gradient Regularization  for Few-shot Generalization ",
    "url": "https://arxiv.org/abs/2303.12314",
    "authors": [
      "Kaihang Pan",
      "Juncheng Li",
      "Hongye Song",
      "Jun Lin",
      "Xiaozhong Liu",
      "Siliang Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.06706",
    "title": "Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2304.06706",
    "authors": [
      "Jonathan T. Barron",
      "Ben Mildenhall",
      "Dor Verbin",
      "Pratul P. Srinivasan",
      "Peter Hedman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.00664",
    "title": "Dynamic Transfer Learning across Graphs",
    "abstract": " Title: Dynamic Transfer Learning across Graphs ",
    "url": "https://arxiv.org/abs/2305.00664",
    "authors": [
      "Haohui Wang",
      "Yuzhen Mao",
      "Jianhui Sun",
      "Si Zhang",
      "Dawei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.01101",
    "title": "Leveraging Language Representation for Material Recommendation, Ranking,  and Exploration",
    "abstract": " Title: Leveraging Language Representation for Material Recommendation, Ranking,  and Exploration ",
    "url": "https://arxiv.org/abs/2305.01101",
    "authors": [
      "Jiaxing Qu",
      "Yuxuan Richard Xie",
      "Kamil M. Ciesielski",
      "Claire E. Porter",
      "Eric S. Toberer",
      "Elif Ertekin"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.03169",
    "title": "Sensitive Data Detection with High-Throughput Machine Learning Models in  Electrical Health Records",
    "abstract": " Comments: Add fugire axis label ",
    "url": "https://arxiv.org/abs/2305.03169",
    "authors": [
      "Kai Zhang",
      "Xiaoqian Jiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.04170",
    "title": "YOLOCS: Object Detection based on Dense Channel Compression for Feature  Spatial Solidification",
    "abstract": " Title: YOLOCS: Object Detection based on Dense Channel Compression for Feature  Spatial Solidification ",
    "url": "https://arxiv.org/abs/2305.04170",
    "authors": [
      "Lin Huang",
      "Weisheng Li",
      "Linlin Shen",
      "Haojie Fu",
      "Xue Xiao",
      "Suihan Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.04213",
    "title": "Robust Image Ordinal Regression with Controllable Image Generation",
    "abstract": " Comments: 8 pages, 12 figures, to be published in IJCAI2023 ",
    "url": "https://arxiv.org/abs/2305.04213",
    "authors": [
      "Yi Cheng",
      "Haochao Ying",
      "Renjun Hu",
      "Jinhong Wang",
      "Wenhao Zheng",
      "Xiao Zhang",
      "Danny Chen",
      "Jian Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.04236",
    "title": "RFR-WWANet: Weighted Window Attention-Based Recovery Feature Resolution  Network for Unsupervised Image Registration",
    "abstract": " Title: RFR-WWANet: Weighted Window Attention-Based Recovery Feature Resolution  Network for Unsupervised Image Registration ",
    "url": "https://arxiv.org/abs/2305.04236",
    "authors": [
      "Mingrui Ma",
      "Tao Wang",
      "Lei Song",
      "Weijie Wang",
      "Guixia Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.05896",
    "title": "RNNS: Representation Nearest Neighbor Search Black-Box Attack on Code  Models",
    "abstract": " Title: RNNS: Representation Nearest Neighbor Search Black-Box Attack on Code  Models ",
    "url": "https://arxiv.org/abs/2305.05896",
    "authors": [
      "Jie Zhang",
      "Wei Ma",
      "Qiang Hu",
      "Xiaofei Xie",
      "Yves Le Traon",
      "Yang Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.06480",
    "title": "ST-GIN: An Uncertainty Quantification Approach in Traffic Data  Imputation with Spatio-temporal Graph Attention and Bidirectional Recurrent  United Neural Networks",
    "abstract": " Comments: In submission to IEEE-ITSC 2023 ",
    "url": "https://arxiv.org/abs/2305.06480",
    "authors": [
      "Zepu Wang",
      "Dingyi Zhuang",
      "Yankai Li",
      "Jinhua Zhao",
      "Peng Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.07494",
    "title": "Temporal Network Creation Games",
    "abstract": " Comments: To appear at the 32nd International Joint Conference on Artificial Intelligence (IJCAI 2023), full version ",
    "url": "https://arxiv.org/abs/2305.07494",
    "authors": [
      "Davide Bil\u00f2",
      "Sarel Cohen",
      "Tobias Friedrich",
      "Hans Gawendowicz",
      "Nicolas Klodt",
      "Pascal Lenzner",
      "George Skretas"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2305.07845",
    "title": "Understanding Model Averaging in Federated Learning on Heterogeneous  Data",
    "abstract": " Title: Understanding Model Averaging in Federated Learning on Heterogeneous  Data ",
    "url": "https://arxiv.org/abs/2305.07845",
    "authors": [
      "Tailin Zhou",
      "Zehong Lin",
      "Jun Zhang",
      "Danny H.K. Tsang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.07922",
    "title": "CodeT5+: Open Code Large Language Models for Code Understanding and  Generation",
    "abstract": " Comments: 26 pages, preprint ",
    "url": "https://arxiv.org/abs/2305.07922",
    "authors": [
      "Yue Wang",
      "Hung Le",
      "Akhilesh Deepak Gotmare",
      "Nghi D.Q. Bui",
      "Junnan Li",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2305.08107",
    "title": "Privacy-Preserving Taxi-Demand Prediction Using Federated Learning",
    "abstract": " Title: Privacy-Preserving Taxi-Demand Prediction Using Federated Learning ",
    "url": "https://arxiv.org/abs/2305.08107",
    "authors": [
      "Yumeki Goto",
      "Tomoya Matsumoto",
      "Hamada Rizk",
      "Naoto Yanai",
      "Hirozumi Yamaguchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.08348",
    "title": "Coreference-aware Double-channel Attention Network for Multi-party  Dialogue Reading Comprehension",
    "abstract": " Comments: IJCNN2023 ",
    "url": "https://arxiv.org/abs/2305.08348",
    "authors": [
      "Yanling Li",
      "Bowei Zou",
      "Yifan Fan",
      "Mengxing Dong",
      "Yu Hong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.09480",
    "title": "Cross-Gate MLP with Protein Complex Invariant Embedding is A One-Shot  Antibody Designer",
    "abstract": " Title: Cross-Gate MLP with Protein Complex Invariant Embedding is A One-Shot  Antibody Designer ",
    "url": "https://arxiv.org/abs/2305.09480",
    "authors": [
      "Cheng Tan",
      "Zhangyang Gao",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.09485",
    "title": "Executive Voiced Laughter and Social Approval: An Explorative Machine  Learning Study",
    "abstract": " Comments: Method section needs to be updated ",
    "url": "https://arxiv.org/abs/2305.09485",
    "authors": [
      "Niklas Mueller",
      "Steffen Klug",
      "Andreas Koenig",
      "Alexander Kathan",
      "Lukas Christ",
      "Bjoern Schuller",
      "Shahin Amiriparian"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.09850",
    "title": "MINT: Multiplier-less Integer Quantization for Spiking Neural Networks",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2305.09850",
    "authors": [
      "Ruokai Yin",
      "Yuhang Li",
      "Abhishek Moitra",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.10259",
    "title": "Runtime Analyses of Multi-Objective Evolutionary Algorithms in the  Presence of Noise",
    "abstract": " Comments: Long version of a paper with the same title published at the IJCAI 2023 conference ",
    "url": "https://arxiv.org/abs/2305.10259",
    "authors": [
      "Matthieu Dinot",
      "Benjamin Doerr",
      "Ulysse Hennebelle",
      "Sebastian Will"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.10308",
    "title": "Rethinking Data Augmentation for Tabular Data in Deep Learning",
    "abstract": " Title: Rethinking Data Augmentation for Tabular Data in Deep Learning ",
    "url": "https://arxiv.org/abs/2305.10308",
    "authors": [
      "Soma Onishi",
      "Shoya Meguro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.10352",
    "title": "Appliance Detection Using Very Low-Frequency Smart Meter Time Series",
    "abstract": " Comments: 11 pages, 7 figures. This paper appeared in ACM e-Energy 2023 ",
    "url": "https://arxiv.org/abs/2305.10352",
    "authors": [
      "Adrien Petralia",
      "Philippe Charpentier",
      "Paul Boniol",
      "Themis Palpanas"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10522",
    "title": "On a Doubly Reduced Model for Dynamics of Heterogeneous Mixtures of  Stiffened Gases, its Regularizations and their Implementations",
    "abstract": " Comments: 16 hfgex, 7 figures, 1 table ",
    "url": "https://arxiv.org/abs/2305.10522",
    "authors": [
      "A. Zlotnik",
      "T. Lomonosov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2305.11096",
    "title": "Cross-modality Data Augmentation for End-to-End Sign Language  Translation",
    "abstract": " Comments: 10 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2305.11096",
    "authors": [
      "Jinhui Ye",
      "Wenxiang Jiao",
      "Xing Wang",
      "Zhaopeng Tu",
      "Hui Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.11192",
    "title": "TPMDP: Threshold Personalized Multi-party Differential Privacy via  Optimal Gaussian Mechanism",
    "abstract": " Comments: 12 pages, 4 figures, submitted to MASS 2023, correct typos ",
    "url": "https://arxiv.org/abs/2305.11192",
    "authors": [
      "Jiandong Liu",
      "Lan Zhang",
      "Chaojie Lv",
      "Ting Yu",
      "Nikolaos M. Freris",
      "Xiang-Yang Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2305.11526",
    "title": "Enhancing Short-Term Wind Speed Forecasting using Graph Attention and  Frequency-Enhanced Mechanisms",
    "abstract": " Comments: 9 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2305.11526",
    "authors": [
      "Hao Liu",
      "Huimin Ma",
      "Tianyu Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.11782",
    "title": "Real-time and Robust Feature Detection of Continuous Marker Pattern for  Dense 3-D Deformation Measurement",
    "abstract": " Comments: 17 pages, 14 figures. Submitted to Measurement ",
    "url": "https://arxiv.org/abs/2305.11782",
    "authors": [
      "Mingxuan Li",
      "Yen Hang Zhou",
      "Liemin Li",
      "Yao Jiang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  }
]