[
  {
    "id": "arXiv:2305.14375",
    "title": "Learning to Rank the Importance of Nodes in Road Networks Based on  Multi-Graph Fusion",
    "abstract": "Identifying important nodes with strong propagation capabilities in road networks is a significant topic in the field of urban planning. However, existing methods for evaluating nodes importance consider only topological information and traffic volumes, ignoring the diversity of characteristics in road networks, such as the number of lanes and average speed of road segments, limiting their performance. To address this issue, this paper proposes a graph learning-based node ranking method (MGL2Rank) that integrates the rich characteristics of the road network. In this method, we first develop a sampling algorithm (MGWalk) that utilizes multi-graph fusion to establish association between road segments based on their attributes. Then, an embedding module is proposed to learn latent representation for each road segment. Finally, the obtained node representation is used to learn importance ranking of road segments. We conduct simulation experiments on the regional road network of Shenyang city and demonstrate the effectiveness of our proposed method. The data and source code of MGL2Rank are available at https://github.com/ZJ726. ",
    "url": "https://arxiv.org/abs/2305.14375",
    "authors": [
      "Ming Xu",
      "Jing Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.14384",
    "title": "Adversarial Nibbler: A Data-Centric Challenge for Improving the Safety  of Text-to-Image Models",
    "abstract": "The generative AI revolution in recent years has been spurred by an expansion in compute power and data quantity, which together enable extensive pre-training of powerful text-to-image (T2I) models. With their greater capabilities to generate realistic and creative content, these T2I models like DALL-E, MidJourney, Imagen or Stable Diffusion are reaching ever wider audiences. Any unsafe behaviors inherited from pretraining on uncurated internet-scraped datasets thus have the potential to cause wide-reaching harm, for example, through generated images which are violent, sexually explicit, or contain biased and derogatory stereotypes. Despite this risk of harm, we lack systematic and structured evaluation datasets to scrutinize model behavior, especially adversarial attacks that bypass existing safety filters. A typical bottleneck in safety evaluation is achieving a wide coverage of different types of challenging examples in the evaluation set, i.e., identifying 'unknown unknowns' or long-tail problems. To address this need, we introduce the Adversarial Nibbler challenge. The goal of this challenge is to crowdsource a diverse set of failure modes and reward challenge participants for successfully finding safety vulnerabilities in current state-of-the-art T2I models. Ultimately, we aim to provide greater awareness of these issues and assist developers in improving the future safety and reliability of generative AI models. Adversarial Nibbler is a data-centric challenge, part of the DataPerf challenge suite, organized and supported by Kaggle and MLCommons. ",
    "url": "https://arxiv.org/abs/2305.14384",
    "authors": [
      "Alicia Parrish",
      "Hannah Rose Kirk",
      "Jessica Quaye",
      "Charvi Rastogi",
      "Max Bartolo",
      "Oana Inel",
      "Juan Ciro",
      "Rafael Mosquera",
      "Addison Howard",
      "Will Cukierski",
      "D. Sculley",
      "Vijay Janapa Reddi",
      "Lora Aroyo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14389",
    "title": "Breast Cancer Segmentation using Attention-based Convolutional Network  and Explainable AI",
    "abstract": "Breast cancer (BC) remains a significant health threat, with no long-term cure currently available. Early detection is crucial, yet mammography interpretation is hindered by high false positives and negatives. With BC incidence projected to surpass lung cancer, improving early detection methods is vital. Thermography, using high-resolution infrared cameras, offers promise, especially when combined with artificial intelligence (AI). This work presents an attention-based convolutional neural network for segmentation, providing increased speed and precision in BC detection and classification. The system enhances images and performs cancer segmentation with explainable AI. We propose a transformer-attention-based convolutional architecture (UNet) for fault identification and employ Gradient-weighted Class Activation Mapping (Grad-CAM) to analyze areas of bias and weakness in the UNet architecture with IRT images. The superiority of our proposed framework is confirmed when compared with existing deep learning frameworks. ",
    "url": "https://arxiv.org/abs/2305.14389",
    "authors": [
      "Jai Vardhan",
      "Ghanta Sai Krishna"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14394",
    "title": "Unsupervised Spiking Neural Network Model of Prefrontal Cortex to study  Task Switching with Synaptic deficiency",
    "abstract": "In this study, we build a computational model of Prefrontal Cortex (PFC) using Spiking Neural Networks (SNN) to understand how neurons adapt and respond to tasks switched under short and longer duration of stimulus changes. We also explore behavioral deficits arising out of the PFC lesions by simulating lesioned states in our Spiking architecture model. Although there are some computational models of the PFC, SNN's have not been used to model them. In this study, we use SNN's having parameters close to biologically plausible values and train the model using unsupervised Spike Timing Dependent Plasticity (STDP) learning rule. Our model is based on connectionist architectures and exhibits neural phenomena like sustained activity which helps in generating short-term or working memory. We use these features to simulate lesions by deactivating synaptic pathways and record the weight adjustments of learned patterns and capture the accuracy of learning tasks in such conditions. All our experiments are trained and recorded using a real-world Fashion MNIST (FMNIST) dataset and through this work, we bridge the gap between bio-realistic models and those that perform well in pattern recognition tasks ",
    "url": "https://arxiv.org/abs/2305.14394",
    "authors": [
      "Ashwin Viswanathan Kannan",
      "Goutam Mylavarapu",
      "Johnson P Thomas"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2305.14396",
    "title": "FITNESS: A Causal De-correlation Approach for Mitigating Bias in Machine  Learning Software",
    "abstract": "Software built on top of machine learning algorithms is becoming increasingly prevalent in a variety of fields, including college admissions, healthcare, insurance, and justice. The effectiveness and efficiency of these systems heavily depend on the quality of the training datasets. Biased datasets can lead to unfair and potentially harmful outcomes, particularly in such critical decision-making systems where the allocation of resources may be affected. This can exacerbate discrimination against certain groups and cause significant social disruption. To mitigate such unfairness, a series of bias-mitigating methods are proposed. Generally, these studies improve the fairness of the trained models to a certain degree but with the expense of sacrificing the model performance. In this paper, we propose FITNESS, a bias mitigation approach via de-correlating the causal effects between sensitive features (e.g., the sex) and the label. Our key idea is that by de-correlating such effects from a causality perspective, the model would avoid making predictions based on sensitive features and thus fairness could be improved. Furthermore, FITNESS leverages multi-objective optimization to achieve a better performance-fairness trade-off. To evaluate the effectiveness, we compare FITNESS with 7 state-of-the-art methods in 8 benchmark tasks by multiple metrics. Results show that FITNESS can outperform the state-of-the-art methods on bias mitigation while preserve the model's performance: it improved the model's fairness under all the scenarios while decreased the model's performance under only 26.67% of the scenarios. Additionally, FITNESS surpasses the Fairea Baseline in 96.72% cases, outperforming all methods we compared. ",
    "url": "https://arxiv.org/abs/2305.14396",
    "authors": [
      "Ying Xiao",
      "Shangwen Wang",
      "Sicen Liu",
      "Dingyuan Xue",
      "Xian Zhan",
      "Yepang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.14405",
    "title": "NeuralMatrix: Moving Entire Neural Networks to General Matrix  Multiplication for Efficient Inference",
    "abstract": "In this study, we introduce NeuralMatrix, a novel framework that enables the computation of versatile deep neural networks (DNNs) on a single general matrix multiplication (GEMM) accelerator. The proposed approach overcomes the specificity limitations of ASIC-based accelerators while achieving application-specific acceleration levels compared to general-purpose processors such as CPUs and GPUs. We address the challenges of mapping both linear and nonlinear operations in DNN computation to general matrix multiplications and the impact of using a GEMM accelerator on DNN inference accuracy. Extensive experiments are conducted on various DNN models from three popular categories (i.e., CNN, Transformers, and GNN) as illustrative backbone models. Our results demonstrate that DNNs suffer only up to a 2.02% accuracy loss after being converted to general matrix multiplication, while achieving 113x to 19.44x improvements in throughput per power compared to CPUs and GPUs. ",
    "url": "https://arxiv.org/abs/2305.14405",
    "authors": [
      "Ruiqi Sun",
      "Jie Zhao",
      "Xin He",
      "Yiran Li",
      "An Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2305.14449",
    "title": "Graph Meets LLM: A Novel Approach to Collaborative Filtering for Robust  Conversational Understanding",
    "abstract": "Conversational AI systems (e.g. Alexa, Siri, Google Assistant, etc.) need to understand queries with defects to ensure robust conversational understanding and reduce user frictions. The defective queries are often induced by user ambiguities and mistakes, or errors in the automatic speech recognition (ASR) and natural language understanding (NLU). Personalized query rewriting (personalized QR) targets reducing defects in the torso and tail user query traffic, and it typically relies on an index of past successful user interactions with the conversational AI. This paper presents our \"Collaborative Query Rewriting\" approach that focuses on rewriting novel user interactions unseen in the user history. This approach builds a \"user Feedback Interaction Graph\" (FIG) consisting of historical user-entity interactions, and leverages multi-hop customer affinity to enrich each user's index (i.e. the Collaborative User Index) that would help cover future unseen defective queries. To counteract the precision degradation from the enlarged index, we introduced additional transformer layers to the L1 retrieval model and added multi-hop affinity and guardrail features to the L2 re-ranking model. Given the production constraints of storage cost and runtime retrieval latency, managing the size of the Collaborative User Index is important. As the user index can be pre-computed, we explored using a Large Language Model (LLM) for multi-hop customer affinity retrieval on the Video/Music domains. In particular, this paper looked into the Dolly-V2 7B model. Given limited user index size, We found the user index derived from fine-tuned Dolly-V2 generation significantly enhanced coverage of unseen user interactions. Consequently, this boosted QR performance on unseen user interactions compared to the graph traversal based user index. ",
    "url": "https://arxiv.org/abs/2305.14449",
    "authors": [
      "Zheng Chen",
      "Ziyan Jiang",
      "Fan Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14450",
    "title": "Is Information Extraction Solved by ChatGPT? An Analysis of Performance,  Evaluation Criteria, Robustness and Errors",
    "abstract": "ChatGPT has stimulated the research boom in the field of large language models. In this paper, we assess the capabilities of ChatGPT from four perspectives including Performance, Evaluation Criteria, Robustness and Error Types. Specifically, we first evaluate ChatGPT's performance on 17 datasets with 14 IE sub-tasks under the zero-shot, few-shot and chain-of-thought scenarios, and find a huge performance gap between ChatGPT and SOTA results. Next, we rethink this gap and propose a soft-matching strategy for evaluation to more accurately reflect ChatGPT's performance. Then, we analyze the robustness of ChatGPT on 14 IE sub-tasks, and find that: 1) ChatGPT rarely outputs invalid responses; 2) Irrelevant context and long-tail target types greatly affect ChatGPT's performance; 3) ChatGPT cannot understand well the subject-object relationships in RE task. Finally, we analyze the errors of ChatGPT, and find that \"unannotated spans\" is the most dominant error type. This raises concerns about the quality of annotated data, and indicates the possibility of annotating data with ChatGPT. The data and code are released at Github site. ",
    "url": "https://arxiv.org/abs/2305.14450",
    "authors": [
      "Ridong Han",
      "Tao Peng",
      "Chaohao Yang",
      "Benyou Wang",
      "Lu Liu",
      "Xiang Wan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14452",
    "title": "Fourier Neural Operators for Arbitrary Resolution Climate Data  Downscaling",
    "abstract": "Climate simulations are essential in guiding our understanding of climate change and responding to its effects. However, it is computationally expensive to resolve complex climate processes at high spatial resolution. As one way to speed up climate simulations, neural networks have been used to downscale climate variables from fast-running low-resolution simulations, but high-resolution training data are often unobtainable or scarce, greatly limiting accuracy. In this work, we propose a downscaling method based on the Fourier neural operator. It trains with data of a small upsampling factor and then can zero-shot downscale its input to arbitrary unseen high resolution. Evaluated both on ERA5 climate model data and on the Navier-Stokes equation solution data, our downscaling model significantly outperforms state-of-the-art convolutional and generative adversarial downscaling models, both in standard single-resolution downscaling and in zero-shot generalization to higher upsampling factors. Furthermore, we show that our method also outperforms state-of-the-art data-driven partial differential equation solvers on Navier-Stokes equations. Overall, our work bridges the gap between simulation of a physical process and interpolation of low-resolution output, showing that it is possible to combine both approaches and significantly improve upon each other. ",
    "url": "https://arxiv.org/abs/2305.14452",
    "authors": [
      "Qidong Yang",
      "Alex Hernandez-Garcia",
      "Paula Harder",
      "Venkatesh Ramesh",
      "Prasanna Sattegeri",
      "Daniela Szwarcman",
      "Campbell D. Watson",
      "David Rolnick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2305.14453",
    "title": "On Robustness of Finetuned Transformer-based NLP Models",
    "abstract": "Transformer-based pretrained models like BERT, GPT-2 and T5 have been finetuned for a large number of natural language processing (NLP) tasks, and have been shown to be very effective. However, while finetuning, what changes across layers in these models with respect to pretrained checkpoints is under-studied. Further, how robust are these models to perturbations in input text? Does the robustness vary depending on the NLP task for which the models have been finetuned? While there exists some work on studying robustness of BERT finetuned for a few NLP tasks, there is no rigorous study which compares this robustness across encoder only, decoder only and encoder-decoder models. In this paper, we study the robustness of three language models (BERT, GPT-2 and T5) with eight different text perturbations on the General Language Understanding Evaluation (GLUE) benchmark. Also, we use two metrics (CKA and STIR) to quantify changes between pretrained and finetuned language model representations across layers. GPT-2 representations are more robust than BERT and T5 across multiple types of input perturbation. Although models exhibit good robustness broadly, dropping nouns, verbs or changing characters are the most impactful. Overall, this study provides valuable insights into perturbation-specific weaknesses of popular Transformer-based models which should be kept in mind when passing inputs. ",
    "url": "https://arxiv.org/abs/2305.14453",
    "authors": [
      "Pavan Kalyan Reddy Neerudu",
      "Subba Reddy Oota",
      "Mounika Marreddy",
      "Venkateswara Rao Kagita",
      "Manish Gupta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14462",
    "title": "Sorted Convolutional Network for Achieving Continuous Rotational  Invariance",
    "abstract": "The topic of achieving rotational invariance in convolutional neural networks (CNNs) has gained considerable attention recently, as this invariance is crucial for many computer vision tasks such as image classification and matching. In this letter, we propose a Sorting Convolution (SC) inspired by some hand-crafted features of texture images, which achieves continuous rotational invariance without requiring additional learnable parameters or data augmentation. Further, SC can directly replace the conventional convolution operations in a classic CNN model to achieve its rotational invariance. Based on MNIST-rot dataset, we first analyze the impact of convolutional kernel sizes, different sampling and sorting strategies on SC's rotational invariance, and compare our method with previous rotation-invariant CNN models. Then, we combine SC with VGG, ResNet and DenseNet, and conduct classification experiments on popular texture and remote sensing image datasets. Our results demonstrate that SC achieves the best performance in the aforementioned tasks. ",
    "url": "https://arxiv.org/abs/2305.14462",
    "authors": [
      "Hanlin Mo",
      "Guoying Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14477",
    "title": "A Block-Coordinate Approach of Multi-level Optimization with an  Application to Physics-Informed Neural Networks",
    "abstract": "Multi-level methods are widely used for the solution of large-scale problems, because of their computational advantages and exploitation of the complementarity between the involved sub-problems. After a re-interpretation of multi-level methods from a block-coordinate point of view, we propose a multi-level algorithm for the solution of nonlinear optimization problems and analyze its evaluation complexity. We apply it to the solution of partial differential equations using physics-informed neural networks (PINNs) and show on a few test problems that the approach results in better solutions and significant computational savings ",
    "url": "https://arxiv.org/abs/2305.14477",
    "authors": [
      "Serge Gratton",
      "Valentin Mercier",
      "Elisa Riccietti",
      "Philippe L. Toint"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2305.14481",
    "title": "FOCUS: Effective Embedding Initialization for Specializing Pretrained  Multilingual Models on a Single Language",
    "abstract": "Using model weights pretrained on a high-resource language as a warm start can reduce the need for data and compute to obtain high-quality language models in low-resource languages. To accommodate the new language, the pretrained vocabulary and embeddings need to be adapted. Previous work on embedding initialization for such adapted vocabularies has mostly focused on monolingual source models. In this paper, we investigate the multilingual source model setting and propose FOCUS - Fast Overlapping Token Combinations Using Sparsemax, a novel embedding initialization method that outperforms previous work when adapting XLM-R. FOCUS represents newly added tokens as combinations of tokens in the overlap of the pretrained and new vocabularies. The overlapping tokens are selected based on semantic similarity in an auxiliary token embedding space. Our implementation of FOCUS is publicly available on GitHub. ",
    "url": "https://arxiv.org/abs/2305.14481",
    "authors": [
      "Konstantin Dobler",
      "Gerard de Melo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14485",
    "title": "Knowledge Graphs Querying",
    "abstract": "Knowledge graphs (KGs) such as DBpedia, Freebase, YAGO, Wikidata, and NELL were constructed to store large-scale, real-world facts as (subject, predicate, object) triples -- that can also be modeled as a graph, where a node (a subject or an object) represents an entity with attributes, and a directed edge (a predicate) is a relationship between two entities. Querying KGs is critical in web search, question answering (QA), semantic search, personal assistants, fact checking, and recommendation. While significant progress has been made on KG construction and curation, thanks to deep learning recently we have seen a surge of research on KG querying and QA. The objectives of our survey are two-fold. First, research on KG querying has been conducted by several communities, such as databases, data mining, semantic web, machine learning, information retrieval, and natural language processing (NLP), with different focus and terminologies; and also in diverse topics ranging from graph databases, query languages, join algorithms, graph patterns matching, to more sophisticated KG embedding and natural language questions (NLQs). We aim at uniting different interdisciplinary topics and concepts that have been developed for KG querying. Second, many recent advances on KG and query embedding, multimodal KG, and KG-QA come from deep learning, IR, NLP, and computer vision domains. We identify important challenges of KG querying that received less attention by graph databases, and by the DB community in general, e.g., incomplete KG, semantic matching, multimodal data, and NLQs. We conclude by discussing interesting opportunities for the data management community, for instance, KG as a unified data model and vector-based query processing. ",
    "url": "https://arxiv.org/abs/2305.14485",
    "authors": [
      "Arijit Khan"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14489",
    "title": "Are Large Language Models Robust Zero-shot Coreference Resolvers?",
    "abstract": "Recent progress in domain adaptation for coreference resolution relies on continued training using annotated data from target domains. At the same time, pre-trained large language models (LMs) have exhibited strong zero- and few-shot learning abilities across a wide range of NLP tasks including pronoun resolution. While this demonstrates evidence of coreference ability, previous work has mostly studied this ability using simple sentence-level datasets such as the Winograd Schema Challenge. In this work, we assess the feasibility of zero-shot learning for coreference resolution by evaluating instruction-tuned language models on more difficult, linguistically-complex coreference benchmarks (e.g., CoNLL-2012). We demonstrate that zero-shot prompting outperforms current unsupervised coreference systems. Further investigations reveal the robust zero-shot generalization ability of instruction-tuned LMs across a wide range of domains, languages, and time periods, as well as a strong reliance on high-quality mention detection systems. ",
    "url": "https://arxiv.org/abs/2305.14489",
    "authors": [
      "Nghia T. Le",
      "Alan Ritter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14517",
    "title": "CongFu: Conditional Graph Fusion for Drug Synergy Prediction",
    "abstract": "Drug synergy, characterized by the amplified combined effect of multiple drugs, presents a critical phenomenon for optimizing therapeutic outcomes. However, limited data on drug synergy, arising from the vast number of possible drug combinations and computational costs, motivate the need for predictive methods. In this work, we introduce CongFu, a novel Conditional Graph Fusion Layer, designed to predict drug synergy. CongFu employs an attention mechanism and a bottleneck to extract local graph contexts and conditionally fuse graph data within a global context. Its modular architecture enables flexible replacement of layer modules, including readouts and graph encoders, facilitating customization for diverse applications. To evaluate the performance of CongFu, we conduct comprehensive experiments on four datasets, encompassing three distinct setups for drug synergy prediction. Remarkably, CongFu achieves state-of-the-art results on 11 out of 12 benchmark datasets, demonstrating its ability to capture intricate patterns of drug synergy. Through extensive ablation studies, we validate the significance of individual layer components, affirming their contributions to overall predictive performance. By addressing the challenge of predicting drug synergy in untested drug pairs, CongFu opens new avenues for optimizing drug combinations and advancing personalized medicine. ",
    "url": "https://arxiv.org/abs/2305.14517",
    "authors": [
      "Oleksii Tsepa",
      "Bohdan Naida",
      "Bo Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2305.14534",
    "title": "Detecting Propaganda Techniques in Code-Switched Social Media Text",
    "abstract": "Propaganda is a form of communication intended to influence the opinions and the mindset of the public to promote a particular agenda. With the rise of social media, propaganda has spread rapidly, leading to the need for automatic propaganda detection systems. Most work on propaganda detection has focused on high-resource languages, such as English, and little effort has been made to detect propaganda for low-resource languages. Yet, it is common to find a mix of multiple languages in social media communication, a phenomenon known as code-switching. Code-switching combines different languages within the same text, which poses a challenge for automatic systems. With this in mind, here we propose the novel task of detecting propaganda techniques in code-switched text. To support this task, we create a corpus of 1,030 texts code-switching between English and Roman Urdu, annotated with 20 propaganda techniques, which we make publicly available. We perform a number of experiments contrasting different experimental setups, and we find that it is important to model the multilinguality directly (rather than using translation) as well as to use the right fine-tuning strategy. The code and the dataset are publicly available at https://github.com/mbzuai-nlp/propaganda-codeswitched-text ",
    "url": "https://arxiv.org/abs/2305.14534",
    "authors": [
      "Muhammad Umar Salman",
      "Asif Hanif",
      "Shady Shehata",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14535",
    "title": "Uncertainty Quantification over Graph with Conformalized Graph Neural  Networks",
    "abstract": "Graph Neural Networks (GNNs) are powerful machine learning prediction models on graph-structured data. However, GNNs lack rigorous uncertainty estimates, limiting their reliable deployment in settings where the cost of errors is significant. We propose conformalized GNN (CF-GNN), extending conformal prediction (CP) to graph-based models for guaranteed uncertainty estimates. Given an entity in the graph, CF-GNN produces a prediction set/interval that provably contains the true label with pre-defined coverage probability (e.g. 90%). We establish a permutation invariance condition that enables the validity of CP on graph data and provide an exact characterization of the test-time coverage. Moreover, besides valid coverage, it is crucial to reduce the prediction set size/interval length for practical use. We observe a key connection between non-conformity scores and network structures, which motivates us to develop a topology-aware output correction model that learns to update the prediction and produces more efficient prediction sets/intervals. Extensive experiments show that CF-GNN achieves any pre-defined target marginal coverage while significantly reducing the prediction set/interval size by up to 74% over the baselines. It also empirically achieves satisfactory conditional coverage over various raw and network features. ",
    "url": "https://arxiv.org/abs/2305.14535",
    "authors": [
      "Kexin Huang",
      "Ying Jin",
      "Emmanuel Candes",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.14537",
    "title": "Disincentivizing Polarization in Social Networks",
    "abstract": "On social networks, algorithmic personalization drives users into filter bubbles where they rarely see content that deviates from their interests. We present a model for content curation and personalization that avoids filter bubbles, along with algorithmic guarantees and nearly matching lower bounds. In our model, the platform interacts with $n$ users over $T$ timesteps, choosing content for each user from $k$ categories. The platform receives stochastic rewards as in a multi-arm bandit. To avoid filter bubbles, we draw on the intuition that if some users are shown some category of content, then all users should see at least a small amount of that content. We first analyze a naive formalization of this intuition and show it has unintended consequences: it leads to ``tyranny of the majority'' with the burden of diversification borne disproportionately by those with minority interests. This leads us to our model which distributes this burden more equitably. We require that the probability any user is shown a particular type of content is at least $\\gamma$ times the average probability all users are shown that type of content. Full personalization corresponds to $\\gamma = 0$ and complete homogenization corresponds to $\\gamma = 1$; hence, $\\gamma$ encodes a hard cap on the level of personalization. We also analyze additional formulations where the platform can exceed its cap but pays a penalty proportional to its constraint violation. We provide algorithmic guarantees for optimizing recommendations subject to these constraints. These include nearly matching upper and lower bounds for the entire range of $\\gamma \\in [0,1]$ showing that the reward of a multi-agent variant of UCB is nearly optimal. Using real-world preference data, we empirically verify that under our model, users share the burden of diversification with only minor utility loss under our constraints. ",
    "url": "https://arxiv.org/abs/2305.14537",
    "authors": [
      "Christian Borgs",
      "Jennifer Chayes",
      "Christian Ikeokwu",
      "Ellen Vitercik"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14538",
    "title": "Cascaded Beam Search: Plug-and-Play Terminology-Forcing For Neural  Machine Translation",
    "abstract": "This paper presents a plug-and-play approach for translation with terminology constraints. Terminology constraints are an important aspect of many modern translation pipelines. In both specialized domains and newly emerging domains (such as the COVID-19 pandemic), accurate translation of technical terms is crucial. Recent approaches often train models to copy terminologies from the input into the output sentence by feeding the target terminology along with the input. But this requires expensive training whenever the underlying language model is changed or the system should specialize to a new domain. We propose Cascade Beam Search, a plug-and-play terminology-forcing approach that requires no training. Cascade Beam Search has two parts: 1) logit manipulation to increase the probability of target terminologies and 2) a cascading beam setup based on grid beam search, where beams are grouped by the number of terminologies they contain. We evaluate the performance of our approach by competing against the top submissions of the WMT21 terminology translation task. Our plug-and-play approach performs on par with the winning submissions without using a domain-specific language model and with no additional training. ",
    "url": "https://arxiv.org/abs/2305.14538",
    "authors": [
      "Fr\u00e9d\u00e9ric Odermatt",
      "B\u00e9ni Egressy",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14541",
    "title": "Adversarial Channels with O(1)-Bit Partial Feedback",
    "abstract": "We consider point-to-point communication over $q$-ary adversarial channels with partial noiseless feedback. In this setting, a sender Alice transmits $n$ symbols from a $q$-ary alphabet over a noisy forward channel to a receiver Bob, while Bob sends feedback to Alice over a noiseless reverse channel. In the forward channel, an adversary can inject both symbol errors and erasures up to an error fraction $p \\in [0,1]$ and erasure fraction $r \\in [0,1]$, respectively. In the reverse channel, Bob's feedback is partial such that he can send at most $B(n) \\geq 0$ bits during the communication session. As a case study on minimal partial feedback, we initiate the study of the $O(1)$-bit feedback setting in which $B$ is $O(1)$ in $n$. As our main result, we provide a tight characterization of zero-error capacity under $O(1)$-bit feedback for all $q \\geq 2$, $p \\in [0,1]$ and $r \\in [0,1]$, which we prove this result via novel achievability and converse schemes inspired by recent studies of causal adversarial channels without feedback. Perhaps surprisingly, we show that $O(1)$-bits of feedback are sufficient to achieve the zero-error capacity of the $q$-ary adversarial error channel with full feedback when the error fraction $p$ is sufficiently small. ",
    "url": "https://arxiv.org/abs/2305.14541",
    "authors": [
      "Eric Ruzomberka",
      "Yongkyu Jang",
      "David J. Love",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.14547",
    "title": "Bulk-Switching Memristor-based Compute-In-Memory Module for Deep Neural  Network Training",
    "abstract": "The need for deep neural network (DNN) models with higher performance and better functionality leads to the proliferation of very large models. Model training, however, requires intensive computation time and energy. Memristor-based compute-in-memory (CIM) modules can perform vector-matrix multiplication (VMM) in situ and in parallel, and have shown great promises in DNN inference applications. However, CIM-based model training faces challenges due to non-linear weight updates, device variations, and low-precision in analog computing circuits. In this work, we experimentally implement a mixed-precision training scheme to mitigate these effects using a bulk-switching memristor CIM module. Lowprecision CIM modules are used to accelerate the expensive VMM operations, with high precision weight updates accumulated in digital units. Memristor devices are only changed when the accumulated weight update value exceeds a pre-defined threshold. The proposed scheme is implemented with a system-on-chip (SoC) of fully integrated analog CIM modules and digital sub-systems, showing fast convergence of LeNet training to 97.73%. The efficacy of training larger models is evaluated using realistic hardware parameters and shows that that analog CIM modules can enable efficient mix-precision DNN training with accuracy comparable to full-precision software trained models. Additionally, models trained on chip are inherently robust to hardware variations, allowing direct mapping to CIM inference chips without additional re-training. ",
    "url": "https://arxiv.org/abs/2305.14547",
    "authors": [
      "Yuting Wu",
      "Qiwen Wang",
      "Ziyu Wang",
      "Xinxin Wang",
      "Buvna Ayyagari",
      "Siddarth Krishnan",
      "Michael Chudzik",
      "Wei D. Lu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14548",
    "title": "Interpretable Automatic Fine-grained Inconsistency Detection in Text  Summarization",
    "abstract": "Existing factual consistency evaluation approaches for text summarization provide binary predictions and limited insights into the weakness of summarization systems. Therefore, we propose the task of fine-grained inconsistency detection, the goal of which is to predict the fine-grained types of factual errors in a summary. Motivated by how humans inspect factual inconsistency in summaries, we propose an interpretable fine-grained inconsistency detection model, FineGrainFact, which explicitly represents the facts in the documents and summaries with semantic frames extracted by semantic role labeling, and highlights the related semantic frames to predict inconsistency. The highlighted semantic frames help verify predicted error types and correct inconsistent summaries. Experiment results demonstrate that our model outperforms strong baselines and provides evidence to support or refute the summary. ",
    "url": "https://arxiv.org/abs/2305.14548",
    "authors": [
      "Hou Pong Chan",
      "Qi Zeng",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14550",
    "title": "Sequence Modeling is a Robust Contender for Offline Reinforcement  Learning",
    "abstract": "Offline reinforcement learning (RL) allows agents to learn effective, return-maximizing policies from a static dataset. Three major paradigms for offline RL are Q-Learning, Imitation Learning, and Sequence Modeling. A key open question is: which paradigm is preferred under what conditions? We study this question empirically by exploring the performance of representative algorithms -- Conservative Q-Learning (CQL), Behavior Cloning (BC), and Decision Transformer (DT) -- across the commonly used D4RL and Robomimic benchmarks. We design targeted experiments to understand their behavior concerning data suboptimality and task complexity. Our key findings are: (1) Sequence Modeling requires more data than Q-Learning to learn competitive policies but is more robust; (2) Sequence Modeling is a substantially better choice than both Q-Learning and Imitation Learning in sparse-reward and low-quality data settings; and (3) Sequence Modeling and Imitation Learning are preferable as task horizon increases, or when data is obtained from suboptimal human demonstrators. Based on the overall strength of Sequence Modeling, we also investigate architectural choices and scaling trends for DT on Atari and D4RL and make design recommendations. We find that scaling the amount of data for DT by 5x gives a 2.5x average score improvement on Atari. ",
    "url": "https://arxiv.org/abs/2305.14550",
    "authors": [
      "Prajjwal Bhargava",
      "Rohan Chitnis",
      "Alborz Geramifard",
      "Shagun Sodhani",
      "Amy Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14553",
    "title": "Adversarial Machine Learning and Cybersecurity: Risks, Challenges, and  Legal Implications",
    "abstract": "In July 2022, the Center for Security and Emerging Technology (CSET) at Georgetown University and the Program on Geopolitics, Technology, and Governance at the Stanford Cyber Policy Center convened a workshop of experts to examine the relationship between vulnerabilities in artificial intelligence systems and more traditional types of software vulnerabilities. Topics discussed included the extent to which AI vulnerabilities can be handled under standard cybersecurity processes, the barriers currently preventing the accurate sharing of information about AI vulnerabilities, legal issues associated with adversarial attacks on AI systems, and potential areas where government support could improve AI vulnerability management and mitigation. This report is meant to accomplish two things. First, it provides a high-level discussion of AI vulnerabilities, including the ways in which they are disanalogous to other types of vulnerabilities, and the current state of affairs regarding information sharing and legal oversight of AI vulnerabilities. Second, it attempts to articulate broad recommendations as endorsed by the majority of participants at the workshop. ",
    "url": "https://arxiv.org/abs/2305.14553",
    "authors": [
      "Micah Musser",
      "Andrew Lohn",
      "James X. Dempsey",
      "Jonathan Spring",
      "Ram Shankar Siva Kumar",
      "Brenda Leong",
      "Christina Liaghati",
      "Cindy Martinez",
      "Crystal D. Grant",
      "Daniel Rohrer",
      "Heather Frase",
      "Jonathan Elliott",
      "John Bansemer",
      "Mikel Rodriguez",
      "Mitt Regan",
      "Rumman Chowdhury",
      "Stefan Hermanek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2305.14561",
    "title": "Negative Feedback Training: A Novel Concept to Improve Robustness of  NVCiM DNN Accelerators",
    "abstract": "Compute-in-Memory (CiM) utilizing non-volatile memory (NVM) devices presents a highly promising and efficient approach for accelerating deep neural networks (DNNs). By concurrently storing network weights and performing matrix operations within the same crossbar structure, CiM accelerators offer DNN inference acceleration with minimal area requirements and exceptional energy efficiency. However, the stochasticity and intrinsic variations of NVM devices often lead to performance degradation, such as reduced classification accuracy, compared to expected outcomes. Although several methods have been proposed to mitigate device variation and enhance robustness, most of them rely on overall modulation and lack constraints on the training process. Drawing inspiration from the negative feedback mechanism, we introduce a novel training approach that uses a multi-exit mechanism as negative feedback to enhance the performance of DNN models in the presence of device variation. Our negative feedback training method surpasses state-of-the-art techniques by achieving an impressive improvement of up to 12.49% in addressing DNN robustness against device variation. ",
    "url": "https://arxiv.org/abs/2305.14561",
    "authors": [
      "Yifan Qin",
      "Zheyu Yan",
      "Wujie Wen",
      "Xiaobo Sharon Hu",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2305.14562",
    "title": "GiPH: Generalizable Placement Learning for Adaptive Heterogeneous  Computing",
    "abstract": "Careful placement of a computational application within a target device cluster is critical for achieving low application completion time. The problem is challenging due to its NP-hardness and combinatorial nature. In recent years, learning-based approaches have been proposed to learn a placement policy that can be applied to unseen applications, motivated by the problem of placing a neural network across cloud servers. These approaches, however, generally assume the device cluster is fixed, which is not the case in mobile or edge computing settings, where heterogeneous devices move in and out of range for a particular application. We propose a new learning approach called GiPH, which learns policies that generalize to dynamic device clusters via 1) a novel graph representation gpNet that efficiently encodes the information needed for choosing a good placement, and 2) a scalable graph neural network (GNN) that learns a summary of the gpNet information. GiPH turns the placement problem into that of finding a sequence of placement improvements, learning a policy for selecting this sequence that scales to problems of arbitrary size. We evaluate GiPH with a wide range of task graphs and device clusters and show that our learned policy rapidly find good placements for new problem instances. GiPH finds placements with up to 30.5% lower completion times, searching up to 3X faster than other search-based placement policies. ",
    "url": "https://arxiv.org/abs/2305.14562",
    "authors": [
      "Yi Hu",
      "Chaoran Zhang",
      "Edward Andert",
      "Harshul Singh",
      "Aviral Shrivastava",
      "James Laudon",
      "Yanqi Zhou",
      "Bob Iannucci",
      "Carlee Joe-Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.14567",
    "title": "Constant Memory Attentive Neural Processes",
    "abstract": "Neural Processes (NPs) are efficient methods for estimating predictive uncertainties. NPs comprise of a conditioning phase where a context dataset is encoded, a querying phase where the model makes predictions using the context dataset encoding, and an updating phase where the model updates its encoding with newly received datapoints. However, state-of-the-art methods require additional memory which scales linearly or quadratically with the size of the dataset, limiting their applications, particularly in low-resource settings. In this work, we propose Constant Memory Attentive Neural Processes (CMANPs), an NP variant which only requires constant memory for the conditioning, querying, and updating phases. In building CMANPs, we propose Constant Memory Attention Block (CMAB), a novel general-purpose attention block that can compute its output in constant memory and perform updates in constant computation. Empirically, we show CMANPs achieve state-of-the-art results on meta-regression and image completion tasks while being (1) significantly more memory efficient than prior methods and (2) more scalable to harder settings. ",
    "url": "https://arxiv.org/abs/2305.14567",
    "authors": [
      "Leo Feng",
      "Frederick Tung",
      "Hossein Hajimirsadeghi",
      "Yoshua Bengio",
      "Mohamed Osama Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14575",
    "title": "Towards Early Prediction of Human iPSC Reprogramming Success",
    "abstract": "This paper presents advancements in automated early-stage prediction of the success of reprogramming human induced pluripotent stem cells (iPSCs) as a potential source for regenerative cell therapies.The minuscule success rate of iPSC-reprogramming of around $ 0.01% $ to $ 0.1% $ makes it labor-intensive, time-consuming, and exorbitantly expensive to generate a stable iPSC line. Since that requires culturing of millions of cells and intense biological scrutiny of multiple clones to identify a single optimal clone. The ability to reliably predict which cells are likely to establish as an optimal iPSC line at an early stage of pluripotency would therefore be ground-breaking in rendering this a practical and cost-effective approach to personalized medicine. Temporal information about changes in cellular appearance over time is crucial for predicting its future growth outcomes. In order to generate this data, we first performed continuous time-lapse imaging of iPSCs in culture using an ultra-high resolution microscope. We then annotated the locations and identities of cells in late-stage images where reliable manual identification is possible. Next, we propagated these labels backwards in time using a semi-automated tracking system to obtain labels for early stages of growth. Finally, we used this data to train deep neural networks to perform automatic cell segmentation and classification. Our code and data are available at https://github.com/abhineet123/ipsc_prediction. ",
    "url": "https://arxiv.org/abs/2305.14575",
    "authors": [
      "Abhineet Singh",
      "Ila Jasra",
      "Omar Mouhammed",
      "Nidheesh Dadheech",
      "Nilanjan Ray",
      "James Shapiro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14578",
    "title": "Connecting the Dots: What Graph-Based Text Representations Work Best for  Text Classification using Graph Neural Networks?",
    "abstract": "Given the success of Graph Neural Networks (GNNs) for structure-aware machine learning, numerous studies have explored their application to text classification, as an alternative to traditional feature representation models. However, most studies considered just a specific domain and validated on data with particular characteristics. This work presents an extensive empirical investigation of graph-based text representation methods proposed for text classification, identifying practical implications and open challenges in the field. We compare several GNN architectures as well as BERT across five datasets, encompassing short and also long documents. The results show that: i) graph performance is highly related to the textual input features and domain, ii) despite its outstanding performance, BERT has difficulties converging when dealing with short texts, iii) graph methods are particularly beneficial for longer documents. ",
    "url": "https://arxiv.org/abs/2305.14578",
    "authors": [
      "Margarita Bugue\u00f1o",
      "Gerard de Melo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14579",
    "title": "Real-Time Idling Vehicles Detection Using Combined Audio-Visual Deep  Learning",
    "abstract": "Combustion vehicle emissions contribute to poor air quality and release greenhouse gases into the atmosphere, and vehicle pollution has been associated with numerous adverse health effects. Roadways with extensive waiting and/or passenger drop off, such as schools and hospital drop-off zones, can result in high incidence and density of idling vehicles. This can produce micro-climates of increased vehicle pollution. Thus, the detection of idling vehicles can be helpful in monitoring and responding to unnecessary idling and be integrated into real-time or off-line systems to address the resulting pollution. In this paper we present a real-time, dynamic vehicle idling detection algorithm. The proposed idle detection algorithm and notification rely on an algorithm to detect these idling vehicles. The proposed method relies on a multi-sensor, audio-visual, machine-learning workflow to detect idling vehicles visually under three conditions: moving, static with the engine on, and static with the engine off. The visual vehicle motion detector is built in the first stage, and then a contrastive-learning-based latent space is trained for classifying static vehicle engine sound. We test our system in real-time at a hospital drop-off point in Salt Lake City. This in-situ dataset was collected and annotated, and it includes vehicles of varying models and types. The experiments show that the method can detect engine switching on or off instantly and achieves 71.01 mean average precision (mAP). ",
    "url": "https://arxiv.org/abs/2305.14579",
    "authors": [
      "Xiwen Li",
      "Tristalee Mangin",
      "Surojit Saha",
      "Evan Blanchard",
      "Dillon Tang",
      "Henry Poppe",
      "Nathan Searle",
      "Ouk Choi",
      "Kerry Kelly",
      "Ross Whitaker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14580",
    "title": "Evaluating OpenAI's Whisper ASR for Punctuation Prediction and Topic  Modeling of life histories of the Museum of the Person",
    "abstract": "Automatic speech recognition (ASR) systems play a key role in applications involving human-machine interactions. Despite their importance, ASR models for the Portuguese language proposed in the last decade have limitations in relation to the correct identification of punctuation marks in automatic transcriptions, which hinder the use of transcriptions by other systems, models, and even by humans. However, recently Whisper ASR was proposed by OpenAI, a general-purpose speech recognition model that has generated great expectations in dealing with such limitations. This chapter presents the first study on the performance of Whisper for punctuation prediction in the Portuguese language. We present an experimental evaluation considering both theoretical aspects involving pausing points (comma) and complete ideas (exclamation, question, and fullstop), as well as practical aspects involving transcript-based topic modeling - an application dependent on punctuation marks for promising performance. We analyzed experimental results from videos of Museum of the Person, a virtual museum that aims to tell and preserve people's life histories, thus discussing the pros and cons of Whisper in a real-world scenario. Although our experiments indicate that Whisper achieves state-of-the-art results, we conclude that some punctuation marks require improvements, such as exclamation, semicolon and colon. ",
    "url": "https://arxiv.org/abs/2305.14580",
    "authors": [
      "Lucas Rafael Stefanel Gris",
      "Ricardo Marcacini",
      "Arnaldo Candido Junior",
      "Edresson Casanova",
      "Anderson Soares",
      "Sandra Maria Alu\u00edsio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14585",
    "title": "Robust Explanations for Deep Neural Networks via Pseudo Neural Tangent  Kernel Surrogate Models",
    "abstract": "One of the ways recent progress has been made on explainable AI has been via explain-by-example strategies, specifically, through data attribution tasks. The feature spaces used to attribute decisions to training data, however, have not been compared against one another as to whether they form a truly representative surrogate model of the neural network (NN). Here, we demonstrate the efficacy of surrogate linear feature spaces to neural networks through two means: (1) we establish that a normalized psuedo neural tangent kernel (pNTK) is more correlated to the neural network decision functions than embedding based and influence based alternatives in both computer vision and large language model architectures; (2) we show that the attributions created from the normalized pNTK more accurately select perturbed training data in a data poisoning attribution task than these alternatives. Based on these observations, we conclude that kernel linear models are effective surrogate models across multiple classification architectures and that pNTK-based kernels are the most appropriate surrogate feature space of all kernels studied. ",
    "url": "https://arxiv.org/abs/2305.14585",
    "authors": [
      "Andrew Engel",
      "Zhichao Wang",
      "Natalie S. Frank",
      "Ioana Dumitriu",
      "Sutanay Choudhury",
      "Anand Sarwate",
      "Tony Chiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14599",
    "title": "Bridging Continuous and Discrete Spaces: Interpretable Sentence  Representation Learning via Compositional Operations",
    "abstract": "Traditional sentence embedding models encode sentences into vector representations to capture useful properties such as the semantic similarity between sentences. However, in addition to similarity, sentence semantics can also be interpreted via compositional operations such as sentence fusion or difference. It is unclear whether the compositional semantics of sentences can be directly reflected as compositional operations in the embedding space. To more effectively bridge the continuous embedding and discrete text spaces, we explore the plausibility of incorporating various compositional properties into the sentence embedding space that allows us to interpret embedding transformations as compositional sentence operations. We propose InterSent, an end-to-end framework for learning interpretable sentence embeddings that supports compositional sentence operations in the embedding space. Our method optimizes operator networks and a bottleneck encoder-decoder model to produce meaningful and interpretable sentence embeddings. Experimental results demonstrate that our method significantly improves the interpretability of sentence embeddings on four textual generation tasks over existing approaches while maintaining strong performance on traditional semantic similarity tasks. ",
    "url": "https://arxiv.org/abs/2305.14599",
    "authors": [
      "James Y. Huang",
      "Wenlin Yao",
      "Kaiqiang Song",
      "Hongming Zhang",
      "Muhao Chen",
      "Dong Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14612",
    "title": "Assessment of Anterior Cruciate Ligament Injury Risk Based on Human Key  Points Detection Algorithm",
    "abstract": "This paper aims to detect the potential injury risk of the anterior cruciate ligament (ACL) by proposing an ACL potential injury risk assessment algorithm based on key points of the human body detected using computer vision technology. To obtain the key points data of the human body in each frame, OpenPose, an open source computer vision algorithm, was employed. The obtained data underwent preprocessing and were then fed into an ACL potential injury feature extraction model based on the Landing Error Evaluation System (LESS). This model extracted several important parameters, including the knee flexion angle, the trunk flexion on the sagittal plane, trunk flexion angle on the frontal plane, the ankle knee horizontal distance, and the ankle shoulder horizontal distance. Each of these features was assigned a threshold interval, and a segmented evaluation function was utilized to score them accordingly. To calculate the final score of the participant, the score values were input into a weighted scoring model designed based on the Analytic Hierarchy Process (AHP). The AHP based model takes into account the relative importance of each feature in the overall assessment. The results demonstrate that the proposed algorithm effectively detects the potential risk of ACL injury. The proposed algorithm demonstrates its effectiveness in detecting ACL injury risk, offering valuable insights for injury prevention and intervention strategies in sports and related fields. Code is available at: https://github.com/ZiyuGong-proj/Assessment-of-ACL-Injury-Risk-Based-on-Openpose ",
    "url": "https://arxiv.org/abs/2305.14612",
    "authors": [
      "Ziyu Gong",
      "Xiong Zhao",
      "Chen Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2305.14617",
    "title": "COMET-M: Reasoning about Multiple Events in Complex Sentences",
    "abstract": "Understanding the speaker's intended meaning often involves drawing commonsense inferences to reason about what is not stated explicitly. In multi-event sentences, it requires understanding the relationships between events based on contextual knowledge. We propose COMET-M (Multi-Event), an event-centric commonsense model capable of generating commonsense inferences for a target event within a complex sentence. COMET-M builds upon COMET (Bosselut et al., 2019), which excels at generating event-centric inferences for simple sentences, but struggles with the complexity of multi-event sentences prevalent in natural text. To overcome this limitation, we curate a multi-event inference dataset of 35K human-written inferences. We trained COMET-M on the human-written inferences and also created baselines using automatically labeled examples. Experimental results demonstrate the significant performance improvement of COMET-M over COMET in generating multi-event inferences. Moreover, COMET-M successfully produces distinct inferences for each target event, taking the complete context into consideration. COMET-M holds promise for downstream tasks involving natural text such as coreference resolution, dialogue, and story understanding. ",
    "url": "https://arxiv.org/abs/2305.14617",
    "authors": [
      "Sahithya Ravi",
      "Raymond Ng",
      "Vered Shwartz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14621",
    "title": "Realistically distributing object placements in synthetic training data  improves the performance of vision-based object detection models",
    "abstract": "When training object detection models on synthetic data, it is important to make the distribution of synthetic data as close as possible to the distribution of real data. We investigate specifically the impact of object placement distribution, keeping all other aspects of synthetic data fixed. Our experiment, training a 3D vehicle detection model in CARLA and testing on KITTI, demonstrates a substantial improvement resulting from improving the object placement distribution. ",
    "url": "https://arxiv.org/abs/2305.14621",
    "authors": [
      "Setareh Dabiri",
      "Vasileios Lioutas",
      "Berend Zwartsenberg",
      "Yunpeng Liu",
      "Matthew Niedoba",
      "Xiaoxuan Liang",
      "Dylan Green",
      "Justice Sefas",
      "Jonathan Wilder Lavington",
      "Frank Wood",
      "Adam Scibior"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14630",
    "title": "Testing Causal Models of Word Meaning in GPT-3 and -4",
    "abstract": "Large Language Models (LLMs) have driven extraordinary improvements in NLP. However, it is unclear how such models represent lexical concepts-i.e., the meanings of the words they use. This paper evaluates the lexical representations of GPT-3 and GPT-4 through the lens of HIPE theory, a theory of concept representations which focuses on representations of words describing artifacts (such as \"mop\", \"pencil\", and \"whistle\"). The theory posits a causal graph that relates the meanings of such words to the form, use, and history of the objects to which they refer. We test LLMs using the same stimuli originally used by Chaigneau et al. (2004) to evaluate the theory in humans, and consider a variety of prompt designs. Our experiments concern judgements about causal outcomes, object function, and object naming. We find no evidence that GPT-3 encodes the causal structure hypothesized by HIPE, but do find evidence that GPT-4 encodes such structure. The results contribute to a growing body of research characterizing the representational capacity of large language models. ",
    "url": "https://arxiv.org/abs/2305.14630",
    "authors": [
      "Sam Musker",
      "Ellie Pavlick"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14642",
    "title": "Newton-Cotes Graph Neural Networks: On the Time Evolution of Dynamic  Systems",
    "abstract": "Reasoning system dynamics is one of the most important analytical approaches for many scientific studies. With the initial state of a system as input, the recent graph neural networks (GNNs)-based methods are capable of predicting the future state distant in time with high accuracy. Although these methods have diverse designs in modeling the coordinates and interacting forces of the system, we show that they actually share a common paradigm that learns the integration of the velocity over the interval between the initial and terminal coordinates. However, their integrand is constant w.r.t. time. Inspired by this observation, we propose a new approach to predict the integration based on several velocity estimations with Newton-Cotes formulas and prove its effectiveness theoretically. Extensive experiments on several benchmarks empirically demonstrate consistent and significant improvement compared with the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2305.14642",
    "authors": [
      "Lingbing Guo",
      "Weiqing Wang",
      "Zhuo Chen",
      "Ningyu Zhang",
      "Zequn Sun",
      "Yixuan Lai",
      "Qiang Zhang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2305.14644",
    "title": "KARNet: Kalman Filter Augmented Recurrent Neural Network for Learning  World Models in Autonomous Driving Tasks",
    "abstract": "Autonomous driving has received a great deal of attention in the automotive industry and is often seen as the future of transportation. The development of autonomous driving technology has been greatly accelerated by the growth of end-to-end machine learning techniques that have been successfully used for perception, planning, and control tasks. An important aspect of autonomous driving planning is knowing how the environment evolves in the immediate future and taking appropriate actions. An autonomous driving system should effectively use the information collected from the various sensors to form an abstract representation of the world to maintain situational awareness. For this purpose, deep learning models can be used to learn compact latent representations from a stream of incoming data. However, most deep learning models are trained end-to-end and do not incorporate any prior knowledge (e.g., from physics) of the vehicle in the architecture. In this direction, many works have explored physics-infused neural network (PINN) architectures to infuse physics models during training. Inspired by this observation, we present a Kalman filter augmented recurrent neural network architecture to learn the latent representation of the traffic flow using front camera images only. We demonstrate the efficacy of the proposed model in both imitation and reinforcement learning settings using both simulated and real-world datasets. The results show that incorporating an explicit model of the vehicle (states estimated using Kalman filtering) in the end-to-end learning significantly increases performance. ",
    "url": "https://arxiv.org/abs/2305.14644",
    "authors": [
      "Hemanth Manjunatha",
      "Andrey Pak",
      "Dimitar Filev",
      "Panagiotis Tsiotras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.14660",
    "title": "Complex Mathematical Symbol Definition Structures: A Dataset and Model  for Coordination Resolution in Definition Extraction",
    "abstract": "Mathematical symbol definition extraction is important for improving scholarly reading interfaces and scholarly information extraction (IE). However, the task poses several challenges: math symbols are difficult to process as they are not composed of natural language morphemes; and scholarly papers often contain sentences that require resolving complex coordinate structures. We present SymDef, an English language dataset of 5,927 sentences from full-text scientific papers where each sentence is annotated with all mathematical symbols linked with their corresponding definitions. This dataset focuses specifically on complex coordination structures such as \"respectively\" constructions, which often contain overlapping definition spans. We also introduce a new definition extraction method that masks mathematical symbols, creates a copy of each sentence for each symbol, specifies a target symbol, and predicts its corresponding definition spans using slot filling. Our experiments show that our definition extraction model significantly outperforms RoBERTa and other strong IE baseline systems by 10.9 points with a macro F1 score of 84.82. With our dataset and model, we can detect complex definitions in scholarly documents to make scientific writing more readable. ",
    "url": "https://arxiv.org/abs/2305.14660",
    "authors": [
      "Anna Martin-Boyle",
      "Andrew Head",
      "Kyle Lo",
      "Risham Sidhu",
      "Marti A. Hearst",
      "Dongyeop Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14668",
    "title": "Robust 3D-aware Object Classification via Discriminative  Render-and-Compare",
    "abstract": "In real-world applications, it is essential to jointly estimate the 3D object pose and class label of objects, i.e., to perform 3D-aware classification.While current approaches for either image classification or pose estimation can be extended to 3D-aware classification, we observe that they are inherently limited: 1) Their performance is much lower compared to the respective single-task models, and 2) they are not robust in out-of-distribution (OOD) scenarios. Our main contribution is a novel architecture for 3D-aware classification, which builds upon a recent work and performs comparably to single-task models while being highly robust. In our method, an object category is represented as a 3D cuboid mesh composed of feature vectors at each mesh vertex. Using differentiable rendering, we estimate the 3D object pose by minimizing the reconstruction error between the mesh and the feature representation of the target image. Object classification is then performed by comparing the reconstruction losses across object categories. Notably, the neural texture of the mesh is trained in a discriminative manner to enhance the classification performance while also avoiding local optima in the reconstruction loss. Furthermore, we show how our method and feed-forward neural networks can be combined to scale the render-and-compare approach to larger numbers of categories. Our experiments on PASCAL3D+, occluded-PASCAL3D+, and OOD-CV show that our method outperforms all baselines at 3D-aware classification by a wide margin in terms of performance and robustness. ",
    "url": "https://arxiv.org/abs/2305.14668",
    "authors": [
      "Artur Jesslen",
      "Guofeng Zhang",
      "Angtian Wang",
      "Alan Yuille",
      "Adam Kortylewski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14695",
    "title": "A Causal View of Entity Bias in (Large) Language Models",
    "abstract": "Entity bias widely affects pretrained (large) language models, causing them to excessively rely on (biased) parametric knowledge to make unfaithful predictions. Although causality-inspired methods have shown great potential to mitigate entity bias, it is hard to precisely estimate the parameters of underlying causal models in practice. The rise of black-box LLMs also makes the situation even worse, because of their inaccessible parameters and uncalibrated logits. To address these problems, we propose a specific structured causal model (SCM) whose parameters are comparatively easier to estimate. Building upon this SCM, we propose causal intervention techniques to mitigate entity bias for both white-box and black-box settings. The proposed causal intervention perturbs the original entity with neighboring entities. This intervention reduces specific biasing information pertaining to the original entity while still preserving sufficient common predictive information from similar entities. When evaluated on the relation extraction task, our training-time intervention significantly improves the F1 score of RoBERTa by 5.7 points on EntRED, in which spurious shortcuts between entities and labels are removed. Meanwhile, our in-context intervention effectively reduces the knowledge conflicts between parametric knowledge and contextual knowledge in GPT-3.5 and improves the F1 score by 9.14 points on a challenging test set derived from Re-TACRED. ",
    "url": "https://arxiv.org/abs/2305.14695",
    "authors": [
      "Fei Wang",
      "Wenjie Mo",
      "Yiwei Wang",
      "Wenxuan Zhou",
      "Muhao Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14696",
    "title": "SELFOOD: Self-Supervised Out-Of-Distribution Detection via Learning to  Rank",
    "abstract": "Deep neural classifiers trained with cross-entropy loss (CE loss) often suffer from poor calibration, necessitating the task of out-of-distribution (OOD) detection. Traditional supervised OOD detection methods require expensive manual annotation of in-distribution and OOD samples. To address the annotation bottleneck, we introduce SELFOOD, a self-supervised OOD detection method that requires only in-distribution samples as supervision. We cast OOD detection as an inter-document intra-label (IDIL) ranking problem and train the classifier with our pairwise ranking loss, referred to as IDIL loss. Specifically, given a set of in-distribution documents and their labels, for each label, we train the classifier to rank the softmax scores of documents belonging to that label to be higher than the scores of documents that belong to other labels. Unlike CE loss, our IDIL loss function reaches zero when the desired confidence ranking is achieved and gradients are backpropagated to decrease probabilities associated with incorrect labels rather than continuously increasing the probability of the correct label. Extensive experiments with several classifiers on multiple classification datasets demonstrate the effectiveness of our method in both coarse- and fine-grained settings. ",
    "url": "https://arxiv.org/abs/2305.14696",
    "authors": [
      "Dheeraj Mekala",
      "Adithya Samavedhi",
      "Chengyu Dong",
      "Jingbo Shang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14700",
    "title": "AdvFunMatch: When Consistent Teaching Meets Adversarial Robustness",
    "abstract": "\\emph{Consistent teaching} is an effective paradigm for implementing knowledge distillation (KD), where both student and teacher models receive identical inputs, and KD is treated as a function matching task (FunMatch). However, one limitation of FunMatch is that it does not account for the transfer of adversarial robustness, a model's resistance to adversarial attacks. To tackle this problem, we propose a simple but effective strategy called Adversarial Function Matching (AdvFunMatch), which aims to match distributions for all data points within the $\\ell_p$-norm ball of the training data, in accordance with consistent teaching. Formulated as a min-max optimization problem, AdvFunMatch identifies the worst-case instances that maximizes the KL-divergence between teacher and student model outputs, which we refer to as \"mismatched examples,\" and then matches the outputs on these mismatched examples. Our experimental results show that AdvFunMatch effectively produces student models with both high clean accuracy and robustness. Furthermore, we reveal that strong data augmentations (\\emph{e.g.}, AutoAugment) are beneficial in AdvFunMatch, whereas prior works have found them less effective in adversarial training. Code is available at \\url{https://gitee.com/zihui998/adv-fun-match}. ",
    "url": "https://arxiv.org/abs/2305.14700",
    "authors": [
      "Ziuhi Wu",
      "Haichang Gao",
      "Bingqian Zhou",
      "Ping Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14701",
    "title": "Modeling rapid language learning by distilling Bayesian priors into  artificial neural networks",
    "abstract": "Humans can learn languages from remarkably little experience. Developing computational models that explain this ability has been a major challenge in cognitive science. Bayesian models that build in strong inductive biases - factors that guide generalization - have been successful at explaining how humans might generalize from few examples in controlled settings but are usually too restrictive to be tractably applied to more naturalistic data. By contrast, neural networks have flexible representations that allow them to learn well from naturalistic data but require many more examples than humans receive. We show that learning from limited naturalistic data is possible with an approach that combines the strong inductive biases of a Bayesian model with the flexible representations of a neural network. This approach works by distilling a Bayesian model's biases into a neural network. Like a Bayesian model, the resulting system can learn formal linguistic patterns from a small number of examples. Like a neural network, it can also learn aspects of English syntax from a corpus of natural language - and it outperforms a standard neural network at acquiring the linguistic phenomena of recursion and priming. Bridging the divide between Bayesian models and neural networks makes it possible to handle a broader range of learning scenarios than either approach can handle on its own. ",
    "url": "https://arxiv.org/abs/2305.14701",
    "authors": [
      "R. Thomas McCoy",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14710",
    "title": "Instructions as Backdoors: Backdoor Vulnerabilities of Instruction  Tuning for Large Language Models",
    "abstract": "Instruction-tuned models are trained on crowdsourcing datasets with task instructions to achieve superior performance. However, in this work we raise security concerns about this training paradigm. Our studies demonstrate that an attacker can inject backdoors by issuing very few malicious instructions among thousands of gathered data and control model behavior through data poisoning, without even the need of modifying data instances or labels themselves. Through such instruction attacks, the attacker can achieve over 90% attack success rate across four commonly used NLP datasets, and cause persistent backdoors that are easily transferred to 15 diverse datasets zero-shot. In this way, the attacker can directly apply poisoned instructions designed for one dataset on many other datasets. Moreover, the poisoned model cannot be cured by continual learning. Lastly, instruction attacks show resistance to existing inference-time defense. These findings highlight the need for more robust defenses against data poisoning attacks in instructiontuning models and underscore the importance of ensuring data quality in instruction crowdsourcing. ",
    "url": "https://arxiv.org/abs/2305.14710",
    "authors": [
      "Jiashu Xu",
      "Mingyu Derek Ma",
      "Fei Wang",
      "Chaowei Xiao",
      "Muhao Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14713",
    "title": "Streaming Object Detection on Fisheye Cameras for Automatic Parking",
    "abstract": "Fisheye cameras are widely employed in automatic parking, and the video stream object detection (VSOD) of the fisheye camera is a fundamental perception function to ensure the safe operation of vehicles. In past research work, the difference between the output of the deep learning model and the actual situation at the current moment due to the existence of delay of the perception system is generally ignored. But the environment will inevitably change within the delay time which may cause a potential safety hazard. In this paper, we propose a real-time detection framework equipped with a dual-flow perception module (dynamic and static flows) that can predict the future and alleviate the time-lag problem. Meanwhile, we use a new scheme to evaluate latency and accuracy. The standard bounding box is unsuitable for the object in fisheye camera images due to the strong radial distortion of the fisheye camera and the primary detection objects of parking perception are vehicles and pedestrians, so we adopt the rotate bounding box and propose a new periodic angle loss function to regress the angle of the box, which is the simple and accurate representation method of objects. The instance segmentation ground truth is used to supervise the training. Experiments demonstrate the effectiveness of our approach. Code is released at: https://gitee.com/hiyanyx/fisheye-streaming-perception. ",
    "url": "https://arxiv.org/abs/2305.14713",
    "authors": [
      "Yixiong Yan",
      "Liangzhu Cheng",
      "Yongxu Li",
      "Xinjuan Tuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14715",
    "title": "Leveraging Future Relationship Reasoning for Vehicle Trajectory  Prediction",
    "abstract": "Understanding the interaction between multiple agents is crucial for realistic vehicle trajectory prediction. Existing methods have attempted to infer the interaction from the observed past trajectories of agents using pooling, attention, or graph-based methods, which rely on a deterministic approach. However, these methods can fail under complex road structures, as they cannot predict various interactions that may occur in the future. In this paper, we propose a novel approach that uses lane information to predict a stochastic future relationship among agents. To obtain a coarse future motion of agents, our method first predicts the probability of lane-level waypoint occupancy of vehicles. We then utilize the temporal probability of passing adjacent lanes for each agent pair, assuming that agents passing adjacent lanes will highly interact. We also model the interaction using a probabilistic distribution, which allows for multiple possible future interactions. The distribution is learned from the posterior distribution of interaction obtained from ground truth future trajectories. We validate our method on popular trajectory prediction datasets: nuScenes and Argoverse. The results show that the proposed method brings remarkable performance gain in prediction accuracy, and achieves state-of-the-art performance in long-term prediction benchmark dataset. ",
    "url": "https://arxiv.org/abs/2305.14715",
    "authors": [
      "Daehee Park",
      "Hobin Ryu",
      "Yunseo Yang",
      "Jegyeong Cho",
      "Jiwon Kim",
      "Kuk-Jin Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14720",
    "title": "BLIP-Diffusion: Pre-trained Subject Representation for Controllable  Text-to-Image Generation and Editing",
    "abstract": "Subject-driven text-to-image generation models create novel renditions of an input subject based on text prompts. Existing models suffer from lengthy fine-tuning and difficulties preserving the subject fidelity. To overcome these limitations, we introduce BLIP-Diffusion, a new subject-driven image generation model that supports multimodal control which consumes inputs of subject images and text prompts. Unlike other subject-driven generation models, BLIP-Diffusion introduces a new multimodal encoder which is pre-trained to provide subject representation. We first pre-train the multimodal encoder following BLIP-2 to produce visual representation aligned with the text. Then we design a subject representation learning task which enables a diffusion model to leverage such visual representation and generates new subject renditions. Compared with previous methods such as DreamBooth, our model enables zero-shot subject-driven generation, and efficient fine-tuning for customized subject with up to 20x speedup. We also demonstrate that BLIP-Diffusion can be flexibly combined with existing techniques such as ControlNet and prompt-to-prompt to enable novel subject-driven generation and editing applications. Code and models will be released at https://github.com/salesforce/LAVIS/tree/main/projects/blip-diffusion. Project page at https://dxli94.github.io/BLIP-Diffusion-website/. ",
    "url": "https://arxiv.org/abs/2305.14720",
    "authors": [
      "Dongxu Li",
      "Junnan Li",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14722",
    "title": "Remote Sensing Image Change Detection Towards Continuous Bitemporal  Resolution Differences",
    "abstract": "Most contemporary supervised Remote Sensing (RS) image Change Detection (CD) approaches are customized for equal-resolution bitemporal images. Real-world applications raise the need for cross-resolution change detection, aka, CD based on bitemporal images with different spatial resolutions. Current cross-resolution methods that are trained with samples of a fixed resolution difference (resolution ratio between the high-resolution (HR) image and the low-resolution (LR) one) may fit a certain ratio but lack adaptation to other resolution differences. Toward continuous cross-resolution CD, we propose scale-invariant learning to enforce the model consistently predicting HR results given synthesized samples of varying bitemporal resolution differences. Concretely, we synthesize blurred versions of the HR image by random downsampled reconstructions to reduce the gap between HR and LR images. We introduce coordinate-based representations to decode per-pixel predictions by feeding the coordinate query and corresponding multi-level embedding features into an MLP that implicitly learns the shape of land cover changes, therefore benefiting recognizing blurred objects in the LR image. Moreover, considering that spatial resolution mainly affects the local textures, we apply local-window self-attention to align bitemporal features during the early stages of the encoder. Extensive experiments on two synthesized and one real-world different-resolution CD datasets verify the effectiveness of the proposed method. Our method significantly outperforms several vanilla CD methods and two cross-resolution CD methods on the three datasets both in in-distribution and out-of-distribution settings. The empirical results suggest that our method could yield relatively consistent HR change predictions regardless of varying resolution difference ratios. Our code will be public. ",
    "url": "https://arxiv.org/abs/2305.14722",
    "authors": [
      "Hao Chen",
      "Haotian Zhang",
      "Keyan Chen",
      "Chenyao Zhou",
      "Song Chen",
      "Zhengxia Zhou",
      "Zhenwei Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14734",
    "title": "Advancements in Arabic Grammatical Error Detection and Correction: An  Empirical Investigation",
    "abstract": "Grammatical error correction (GEC) is a well-explored problem in English with many existing models and datasets. However, research on GEC in morphologically rich languages has been limited due to challenges such as data scarcity and language complexity. In this paper, we present the first results on Arabic GEC by using two newly developed Transformer-based pretrained sequence-to-sequence models. We address the task of multi-class Arabic grammatical error detection (GED) and present the first results on multi-class Arabic GED. We show that using GED information as auxiliary input in GEC models improves GEC performance across three datasets spanning different genres. Moreover, we also investigate the use of contextual morphological preprocessing in aiding GEC systems. Our models achieve state-of-the-art results on two Arabic GEC shared tasks datasets and establish a strong benchmark on a newly created dataset. ",
    "url": "https://arxiv.org/abs/2305.14734",
    "authors": [
      "Bashar Alhafni",
      "Go Inoue",
      "Christian Khairallah",
      "Nizar Habash"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14735",
    "title": "Centering the Margins: Outlier-Based Identification of Harmed  Populations in Toxicity Detection",
    "abstract": "A standard method for measuring the impacts of AI on marginalized communities is to determine performance discrepancies between specified demographic groups. These approaches aim to address harms toward vulnerable groups, but they obscure harm patterns faced by intersectional subgroups or shared across demographic groups. We instead operationalize \"the margins\" as data points that are statistical outliers due to having demographic attributes distant from the \"norm\" and measure harms toward these outliers. We propose a Group-Based Performance Disparity Index (GPDI) that measures the extent to which a subdivision of a dataset into subgroups identifies those facing increased harms. We apply our approach to detecting disparities in toxicity detection and find that text targeting outliers is 28% to 86% more toxic for all types of toxicity examined. We also discover that model performance is consistently worse for demographic outliers, with disparities in error between outliers and non-outliers ranging from 28% to 71% across toxicity types. Our outlier-based analysis has comparable or higher GPDI than traditional subgroup-based analyses, suggesting that outlier analysis enhances identification of subgroups facing greater harms. Finally, we find that minoritized racial and religious groups are most associated with outliers, which suggests that outlier analysis is particularly beneficial for identifying harms against those groups. ",
    "url": "https://arxiv.org/abs/2305.14735",
    "authors": [
      "Vyoma Raman",
      "Eve Fleisig",
      "Dan Klein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14740",
    "title": "ECHo: Event Causality Inference via Human-centric Reasoning",
    "abstract": "We introduce ECHo, a diagnostic dataset of event causality inference grounded in visual-and-linguistic social scenarios. ECHo employs real-world human-centric deductive information collected from crime drama, bridging the gap in multimodal reasoning towards higher social intelligence through the elicitation of intermediate Theory-of-Mind (ToM). We propose a unified framework aligned with the Chain-of-Thought (CoT) paradigm to assess the reasoning capability of current AI systems. This ToM-enhanced CoT pipeline can accommodate and integrate various large foundation models in zero-shot visual-and-linguistic understanding. With this framework, we scrutinize the advanced large language and multimodal models via three complementary human-centric ECHo tasks. Further analysis demonstrates ECHo as a challenging dataset to expose imperfections and inconsistencies in reasoning. ",
    "url": "https://arxiv.org/abs/2305.14740",
    "authors": [
      "Yuxi Xie",
      "Guanzhen Li",
      "Min-Yen Kan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14749",
    "title": "Multi-State RNA Design with Geometric Multi-Graph Neural Networks",
    "abstract": "Computational RNA design has broad applications across synthetic biology and therapeutic development. Fundamental to the diverse biological functions of RNA is its conformational flexibility, enabling single sequences to adopt a variety of distinct 3D states. Currently, computational biomolecule design tasks are often posed as inverse problems, where sequences are designed based on adopting a single desired structural conformation. In this work, we propose gRNAde, a geometric RNA design pipeline that operates on sets of 3D RNA backbone structures to explicitly account for and reflect RNA conformational diversity in its designs. We demonstrate the utility of gRNAde for improving native sequence recovery over single-state approaches on a new large-scale 3D RNA design dataset, especially for multi-state and structurally diverse RNAs. Our code is available at https://github.com/chaitjo/geometric-rna-design ",
    "url": "https://arxiv.org/abs/2305.14749",
    "authors": [
      "Chaitanya K. Joshi",
      "Arian R. Jamasb",
      "Ramon Vi\u00f1as",
      "Charles Harris",
      "Simon Mathis",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2305.14750",
    "title": "Mastering the ABCDs of Complex Questions: Answer-Based Claim  Decomposition for Fine-grained Self-Evaluation",
    "abstract": "When answering complex questions, large language models (LLMs) may produce answers that do not satisfy all criteria of the question. While existing self-evaluation techniques aim to detect if such answers are correct, these techniques are unable to determine which criteria of the question are satisfied by the generated answers. To address this issue, we propose answer-based claim decomposition (ABCD), a prompting strategy that decomposes questions into a series of true/false claims that can be used to verify which criteria of the input question an answer satisfies. Using the decomposed ABCD claims, we perform fine-grained self-evaluation. Through preliminary experiments on three datasets, including a newly-collected challenge dataset ObscureQA, we find that GPT-3.5 has some ability to determine to what extent its answer satisfies the criteria of the input question, and can give insights into the errors and knowledge gaps of the model. ",
    "url": "https://arxiv.org/abs/2305.14750",
    "authors": [
      "Nishant Balepur",
      "Jie Huang",
      "Samraj Moorjani",
      "Hari Sundaram",
      "Kevin Chen-Chuan Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14751",
    "title": "DialogVCS: Robust Natural Language Understanding in Dialogue System  Upgrade",
    "abstract": "In the constant updates of the product dialogue systems, we need to retrain the natural language understanding (NLU) model as new data from the real users would be merged into the existent data accumulated in the last updates. Within the newly added data, new intents would emerge and might have semantic entanglement with the existing intents, e.g. new intents that are semantically too specific or generic are actually subset or superset of some existing intents in the semantic space, thus impairing the robustness of the NLU model. As the first attempt to solve this problem, we setup a new benchmark consisting of 4 Dialogue Version Control dataSets (DialogVCS). We formulate the intent detection with imperfect data in the system update as a multi-label classification task with positive but unlabeled intents, which asks the models to recognize all the proper intents, including the ones with semantic entanglement, in the inference. We also propose comprehensive baseline models and conduct in-depth analyses for the benchmark, showing that the semantically entangled intents can be effectively recognized with an automatic workflow. ",
    "url": "https://arxiv.org/abs/2305.14751",
    "authors": [
      "Zefan Cai",
      "Xin Zheng",
      "Tianyu Liu",
      "Xu Wang",
      "Haoran Meng",
      "Jiaqi Han",
      "Gang Yuan",
      "Binghuai Lin",
      "Baobao Chang",
      "Yunbo Cao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14754",
    "title": "SUVR: A Search-based Approach to Unsupervised Visual Representation  Learning",
    "abstract": "Unsupervised learning has grown in popularity because of the difficulty of collecting annotated data and the development of modern frameworks that allow us to learn from unlabeled data. Existing studies, however, either disregard variations at different levels of similarity or only consider negative samples from one batch. We argue that image pairs should have varying degrees of similarity, and the negative samples should be allowed to be drawn from the entire dataset. In this work, we propose Search-based Unsupervised Visual Representation Learning (SUVR) to learn better image representations in an unsupervised manner. We first construct a graph from the image dataset by the similarity between images, and adopt the concept of graph traversal to explore positive samples. In the meantime, we make sure that negative samples can be drawn from the full dataset. Quantitative experiments on five benchmark image classification datasets demonstrate that SUVR can significantly outperform strong competing methods on unsupervised embedding learning. Qualitative experiments also show that SUVR can produce better representations in which similar images are clustered closer together than unrelated images in the latent space. ",
    "url": "https://arxiv.org/abs/2305.14754",
    "authors": [
      "Yi-Zhan Xu",
      "Chih-Yao Chen",
      "Cheng-Te Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14758",
    "title": "MRN: Multiplexed Routing Network for Incremental Multilingual Text  Recognition",
    "abstract": "Traditional Multilingual Text Recognition (MLTR) usually targets a fixed set of languages and thus struggles to handle newly added languages or adapt to ever-changing class distributions. In this paper, we introduce the Incremental Multilingual Text Recognition (IMLTR) task in the incremental learning setting, where new language data comes in batches. Compared to generic incremental learning, IMLTR is even more challenging as it suffers from rehearsal-imbalance (uneven distribution of sample characters in the rehearsal set). To address this issue, we propose a Multiplexed Routing Network (MRN), where a series of recognizers is trained for each language. Subsequently, a language predictor is adopted to weigh the recognizers for voting. Since the recognizers are derived from the original model, MRN effectively reduces the reliance on older data and is better suited for rehearsal-imbalance. We extensively evaluate MRN on MLT17 and MLT19 datasets, outperforming existing state-of-the-art methods by a large margin, i.e., accuracy improvement ranging from 10.3% to 27.4% under different settings. ",
    "url": "https://arxiv.org/abs/2305.14758",
    "authors": [
      "Tianlun Zheng",
      "Zhineng Chen",
      "BingChen Huang",
      "Wei Zhang",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14763",
    "title": "Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in  Large Language Models",
    "abstract": "The escalating debate on AI's capabilities warrants developing reliable metrics to assess machine \"intelligence\". Recently, many anecdotal examples were used to suggest that newer large language models (LLMs) like ChatGPT and GPT-4 exhibit Neural Theory-of-Mind (N-ToM); however, prior work reached conflicting conclusions regarding those abilities. We investigate the extent of LLMs' N-ToM through an extensive evaluation on 6 tasks and find that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust. We further examine the factors impacting performance on N-ToM tasks and discover that LLMs struggle with adversarial examples, indicating reliance on shallow heuristics rather than robust ToM abilities. We caution against drawing conclusions from anecdotal examples, limited benchmark testing, and using human-designed psychological tests to evaluate models. ",
    "url": "https://arxiv.org/abs/2305.14763",
    "authors": [
      "Natalie Shapira",
      "Mosh Levy",
      "Seyed Hossein Alavi",
      "Xuhui Zhou",
      "Yejin Choi",
      "Yoav Goldberg",
      "Maarten Sap",
      "Vered Shwartz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14773",
    "title": "Robust Imaging Sonar-based Place Recognition and Localization in  Underwater Environments",
    "abstract": "Place recognition using SOund Navigation and Ranging (SONAR) images is an important task for simultaneous localization and mapping(SLAM) in underwater environments. This paper proposes a robust and efficient imaging SONAR based place recognition, SONAR context, and loop closure method. Unlike previous methods, our approach encodes geometric information based on the characteristics of raw SONAR measurements without prior knowledge or training. We also design a hierarchical searching procedure for fast retrieval of candidate SONAR frames and apply adaptive shifting and padding to achieve robust matching on rotation and translation changes. In addition, we can derive the initial pose through adaptive shifting and apply it to the iterative closest point (ICP) based loop closure factor. We evaluate the performance of SONAR context in the various underwater sequences such as simulated open water, real water tank, and real underwater environments. The proposed approach shows the robustness and improvements of place recognition on various datasets and evaluation metrics. Supplementary materials are available at https://github.com/sparolab/sonar_context.git. ",
    "url": "https://arxiv.org/abs/2305.14773",
    "authors": [
      "Hogyun Kim",
      "Gilhwan Kang",
      "Seokhwan Jeong",
      "Seungjun Ma",
      "Younggun Cho"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.14783",
    "title": "Disentangled Phonetic Representation for Chinese Spelling Correction",
    "abstract": "Chinese Spelling Correction (CSC) aims to detect and correct erroneous characters in Chinese texts. Although efforts have been made to introduce phonetic information (Hanyu Pinyin) in this task, they typically merge phonetic representations with character representations, which tends to weaken the representation effect of normal texts. In this work, we propose to disentangle the two types of features to allow for direct interaction between textual and phonetic information. To learn useful phonetic representations, we introduce a pinyin-to-character objective to ask the model to predict the correct characters based solely on phonetic information, where a separation mask is imposed to disable attention from phonetic input to text. To avoid overfitting the phonetics, we further design a self-distillation module to ensure that semantic information plays a major role in the prediction. Extensive experiments on three CSC benchmarks demonstrate the superiority of our method in using phonetic information. ",
    "url": "https://arxiv.org/abs/2305.14783",
    "authors": [
      "Zihong Liang",
      "Xiaojun Quan",
      "Qifan Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14792",
    "title": "ACE: Adversarial Correspondence Embedding for Cross Morphology Motion  Retargeting from Human to Nonhuman Characters",
    "abstract": "Motion retargeting is a promising approach for generating natural and compelling animations for nonhuman characters. However, it is challenging to translate human movements into semantically equivalent motions for target characters with different morphologies due to the ambiguous nature of the problem. This work presents a novel learning-based motion retargeting framework, Adversarial Correspondence Embedding (ACE), to retarget human motions onto target characters with different body dimensions and structures. Our framework is designed to produce natural and feasible robot motions by leveraging generative-adversarial networks (GANs) while preserving high-level motion semantics by introducing an additional feature loss. In addition, we pretrain a robot motion prior that can be controlled in a latent embedding space and seek to establish a compact correspondence. We demonstrate that the proposed framework can produce retargeted motions for three different characters -- a quadrupedal robot with a manipulator, a crab character, and a wheeled manipulator. We further validate the design choices of our framework by conducting baseline comparisons and a user study. We also showcase sim-to-real transfer of the retargeted motions by transferring them to a real Spot robot. ",
    "url": "https://arxiv.org/abs/2305.14792",
    "authors": [
      "Tianyu Li",
      "Jungdam Won",
      "Alexander Clegg",
      "Jeonghwan Kim",
      "Akshara Rai",
      "Sehoon Ha"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2305.14797",
    "title": "Multi-Abstractive Neural Controller: An Efficient Hierarchical Control  Architecture for Interactive Driving",
    "abstract": "As learning-based methods make their way from perception systems to planning/control stacks, robot control systems have started to enjoy the benefits that data-driven methods provide. Because control systems directly affect the motion of the robot, data-driven methods, especially black box approaches, need to be used with caution considering aspects such as stability and interpretability. In this paper, we describe a differentiable and hierarchical control architecture. The proposed representation, called \\textit{multi-abstractive neural controller}, uses the input image to control the transitions within a novel discrete behavior planner (referred to as the visual automaton generative network, or \\textit{vAGN}). The output of a vAGN controls the parameters of a set of dynamic movement primitives which provides the system controls. We train this neural controller with real-world driving data via behavior cloning and show improved explainability, sample efficiency, and similarity to human driving. ",
    "url": "https://arxiv.org/abs/2305.14797",
    "authors": [
      "Xiao Li",
      "Igor Gilitschenski",
      "Guy Rosman",
      "Sertac Karaman",
      "Daniela Rus"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.14813",
    "title": "Semi-Supervised and Long-Tailed Object Detection with CascadeMatch",
    "abstract": "This paper focuses on long-tailed object detection in the semi-supervised learning setting, which poses realistic challenges, but has rarely been studied in the literature. We propose a novel pseudo-labeling-based detector called CascadeMatch. Our detector features a cascade network architecture, which has multi-stage detection heads with progressive confidence thresholds. To avoid manually tuning the thresholds, we design a new adaptive pseudo-label mining mechanism to automatically identify suitable values from data. To mitigate confirmation bias, where a model is negatively reinforced by incorrect pseudo-labels produced by itself, each detection head is trained by the ensemble pseudo-labels of all detection heads. Experiments on two long-tailed datasets, i.e., LVIS and COCO-LT, demonstrate that CascadeMatch surpasses existing state-of-the-art semi-supervised approaches -- across a wide range of detection architectures -- in handling long-tailed object detection. For instance, CascadeMatch outperforms Unbiased Teacher by 1.9 AP Fix on LVIS when using a ResNet50-based Cascade R-CNN structure, and by 1.7 AP Fix when using Sparse R-CNN with a Transformer encoder. We also show that CascadeMatch can even handle the challenging sparsely annotated object detection problem. ",
    "url": "https://arxiv.org/abs/2305.14813",
    "authors": [
      "Yuhang Zang",
      "Kaiyang Zhou",
      "Chen Huang",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14814",
    "title": "What functions can Graph Neural Networks compute on random graphs? The  role of Positional Encoding",
    "abstract": "We aim to deepen the theoretical understanding of Graph Neural Networks (GNNs) on large graphs, with a focus on their expressive power. Existing analyses relate this notion to the graph isomorphism problem, which is mostly relevant for graphs of small sizes, or studied graph classification or regression tasks, while prediction tasks on nodes are far more relevant on large graphs. Recently, several works showed that, on very general random graphs models, GNNs converge to certains functions as the number of nodes grows. In this paper, we provide a more complete and intuitive description of the function space generated by equivariant GNNs for node-tasks, through general notions of convergence that encompass several previous examples. We emphasize the role of input node features, and study the impact of node Positional Encodings (PEs), a recent line of work that has been shown to yield state-of-the-art results in practice. Through the study of several examples of PEs on large random graphs, we extend previously known universality results to significantly more general models. Our theoretical results hint at some normalization tricks, which is shown numerically to have a positive impact on GNN generalization on synthetic and real data. Our proofs contain new concentration inequalities of independent interest. ",
    "url": "https://arxiv.org/abs/2305.14814",
    "authors": [
      "Nicolas Keriven",
      "Samuel Vaiter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.14819",
    "title": "Directed Message Passing Based on Attention for Prediction of Molecular  Properties",
    "abstract": "Molecular representation learning (MRL) has long been crucial in the fields of drug discovery and materials science, and it has made significant progress due to the development of natural language processing (NLP) and graph neural networks (GNNs). NLP treats the molecules as one dimensional sequential tokens while GNNs treat them as two dimensional topology graphs. Based on different message passing algorithms, GNNs have various performance on detecting chemical environments and predicting molecular properties. Herein, we propose Directed Graph Attention Networks (D-GATs): the expressive GNNs with directed bonds. The key to the success of our strategy is to treat the molecular graph as directed graph and update the bond states and atom states by scaled dot-product attention mechanism. This allows the model to better capture the sub-structure of molecular graph, i.e., functional groups. Compared to other GNNs or Message Passing Neural Networks (MPNNs), D-GATs outperform the state-of-the-art on 13 out of 15 important molecular property prediction benchmarks. ",
    "url": "https://arxiv.org/abs/2305.14819",
    "authors": [
      "Chen Gong",
      "Yvon Maday"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.14826",
    "title": "Building Transportation Foundation Model via Generative Graph  Transformer",
    "abstract": "Efficient traffic management is crucial for maintaining urban mobility, especially in densely populated areas where congestion, accidents, and delays can lead to frustrating and expensive commutes. However, existing prediction methods face challenges in terms of optimizing a single objective and understanding the complex composition of the transportation system. Moreover, they lack the ability to understand the macroscopic system and cannot efficiently utilize big data. In this paper, we propose a novel approach, Transportation Foundation Model (TFM), which integrates the principles of traffic simulation into traffic prediction. TFM uses graph structures and dynamic graph generation algorithms to capture the participatory behavior and interaction of transportation system actors. This data-driven and model-free simulation method addresses the challenges faced by traditional systems in terms of structural complexity and model accuracy and provides a foundation for solving complex transportation problems with real data. The proposed approach shows promising results in accurately predicting traffic outcomes in an urban transportation setting. ",
    "url": "https://arxiv.org/abs/2305.14826",
    "authors": [
      "Xuhong Wang",
      "Ding Wang",
      "Liang Chen",
      "Yilun Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14828",
    "title": "Towards Few-shot Entity Recognition in Document Images: A Graph Neural  Network Approach Robust to Image Manipulation",
    "abstract": "Recent advances of incorporating layout information, typically bounding box coordinates, into pre-trained language models have achieved significant performance in entity recognition from document images. Using coordinates can easily model the absolute position of each token, but they might be sensitive to manipulations in document images (e.g., shifting, rotation or scaling), especially when the training data is limited in few-shot settings. In this paper, we propose to further introduce the topological adjacency relationship among the tokens, emphasizing their relative position information. Specifically, we consider the tokens in the documents as nodes and formulate the edges based on the topological heuristics from the k-nearest bounding boxes. Such adjacency graphs are invariant to affine transformations including shifting, rotations and scaling. We incorporate these graphs into the pre-trained language model by adding graph neural network layers on top of the language model embeddings, leading to a novel model LAGER. Extensive experiments on two benchmark datasets show that LAGER significantly outperforms strong baselines under different few-shot settings and also demonstrate better robustness to manipulations. ",
    "url": "https://arxiv.org/abs/2305.14828",
    "authors": [
      "Prashant Krishnan",
      "Zilong Wang",
      "Yangkun Wang",
      "Jingbo Shang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14831",
    "title": "OD-NeRF: Efficient Training of On-the-Fly Dynamic Neural Radiance Fields",
    "abstract": "Dynamic neural radiance fields (dynamic NeRFs) have demonstrated impressive results in novel view synthesis on 3D dynamic scenes. However, they often require complete video sequences for training followed by novel view synthesis, which is similar to playing back the recording of a dynamic 3D scene. In contrast, we propose OD-NeRF to efficiently train and render dynamic NeRFs on-the-fly which instead is capable of streaming the dynamic scene. When training on-the-fly, the training frames become available sequentially and the model is trained and rendered frame-by-frame. The key challenge of efficient on-the-fly training is how to utilize the radiance field estimated from the previous frames effectively. To tackle this challenge, we propose: 1) a NeRF model conditioned on the multi-view projected colors to implicitly track correspondence between the current and previous frames, and 2) a transition and update algorithm that leverages the occupancy grid from the last frame to sample efficiently at the current frame. Our algorithm can achieve an interactive speed of 6FPS training and rendering on synthetic dynamic scenes on-the-fly, and a significant speed-up compared to the state-of-the-art on real-world dynamic scenes. ",
    "url": "https://arxiv.org/abs/2305.14831",
    "authors": [
      "Zhiwen Yan",
      "Chen Li",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14837",
    "title": "Using the Uniqueness of Global Identifiers to Determine the Provenance  of Python Software Source Code",
    "abstract": "We consider the problem of identifying the provenance of free/open source software (FOSS) and specifically the need of identifying where reused source code has been copied from. We propose a lightweight approach to solve the problem based on software identifiers-such as the names of variables, classes, and functions chosen by programmers. The proposed approach is able to efficiently narrow down to a small set of candidate origin products, to be further analyzed with more expensive techniques to make a final provenance determination.By analyzing the PyPI (Python Packaging Index) open source ecosystem we find that globally defined identifiers are very distinct. Across PyPI's 244 K packages we found 11.2 M different global identifiers (classes and method/function names-with only 0.6% of identifiers shared among the two types of entities); 76% of identifiers were used only in one package, and 93% in at most 3. Randomly selecting 3 non-frequent global identifiers from an input product is enough to narrow down its origins to a maximum of 3 products within 89% of the cases.We validate the proposed approach by mapping Debian source packages implemented in Python to the corresponding PyPI packages; this approach uses at most five trials, where each trial uses three randomly chosen global identifiers from a randomly chosen python file of the subject software package, then ranks results using a popularity index and requires to inspect only the top result. In our experiments, this method is effective at finding the true origin of a project with a recall of 0.9 and precision of 0.77. ",
    "url": "https://arxiv.org/abs/2305.14837",
    "authors": [
      "Yiming Sun",
      "Daniel M. German",
      "Stefano Zacchiroli"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.14846",
    "title": "Introducing Competition to Boost the Transferability of Targeted  Adversarial Examples through Clean Feature Mixup",
    "abstract": "Deep neural networks are widely known to be susceptible to adversarial examples, which can cause incorrect predictions through subtle input modifications. These adversarial examples tend to be transferable between models, but targeted attacks still have lower attack success rates due to significant variations in decision boundaries. To enhance the transferability of targeted adversarial examples, we propose introducing competition into the optimization process. Our idea is to craft adversarial perturbations in the presence of two new types of competitor noises: adversarial perturbations towards different target classes and friendly perturbations towards the correct class. With these competitors, even if an adversarial example deceives a network to extract specific features leading to the target class, this disturbance can be suppressed by other competitors. Therefore, within this competition, adversarial examples should take different attack strategies by leveraging more diverse features to overwhelm their interference, leading to improving their transferability to different models. Considering the computational complexity, we efficiently simulate various interference from these two types of competitors in feature space by randomly mixing up stored clean features in the model inference and named this method Clean Feature Mixup (CFM). Our extensive experimental results on the ImageNet-Compatible and CIFAR-10 datasets show that the proposed method outperforms the existing baselines with a clear margin. Our code is available at https://github.com/dreamflake/CFM. ",
    "url": "https://arxiv.org/abs/2305.14846",
    "authors": [
      "Junyoung Byun",
      "Myung-Joon Kwon",
      "Seungju Cho",
      "Yoonji Kim",
      "Changick Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14851",
    "title": "Sharpness-Aware Data Poisoning Attack",
    "abstract": "Recent research has highlighted the vulnerability of Deep Neural Networks (DNNs) against data poisoning attacks. These attacks aim to inject poisoning samples into the models' training dataset such that the trained models have inference failures. While previous studies have executed different types of attacks, one major challenge that greatly limits their effectiveness is the uncertainty of the re-training process after the injection of poisoning samples, including the re-training initialization or algorithms. To address this challenge, we propose a novel attack method called ''Sharpness-Aware Data Poisoning Attack (SAPA)''. In particular, it leverages the concept of DNNs' loss landscape sharpness to optimize the poisoning effect on the worst re-trained model. It helps enhance the preservation of the poisoning effect, regardless of the specific retraining procedure employed. Extensive experiments demonstrate that SAPA offers a general and principled strategy that significantly enhances various types of poisoning attacks. ",
    "url": "https://arxiv.org/abs/2305.14851",
    "authors": [
      "Pengfei He",
      "Han Xu",
      "Jie Ren",
      "Yingqian Cui",
      "Hui Liu",
      "Charu C. Aggarwal",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.14859",
    "title": "Utility-Probability Duality of Neural Networks",
    "abstract": "It is typically understood that the training of modern neural networks is a process of fitting the probability distribution of desired output. However, recent paradoxical observations in a number of language generation tasks let one wonder if this canonical probability-based explanation can really account for the empirical success of deep learning. To resolve this issue, we propose an alternative utility-based explanation to the standard supervised learning procedure in deep learning. The basic idea is to interpret the learned neural network not as a probability model but as an ordinal utility function that encodes the preference revealed in training data. In this perspective, training of the neural network corresponds to a utility learning process. Specifically, we show that for all neural networks with softmax outputs, the SGD learning dynamic of maximum likelihood estimation (MLE) can be seen as an iteration process that optimizes the neural network toward an optimal utility function. This utility-based interpretation can explain several otherwise-paradoxical observations about the neural networks thus trained. Moreover, our utility-based theory also entails an equation that can transform the learned utility values back to a new kind of probability estimation with which probability-compatible decision rules enjoy dramatic (double-digits) performance improvements. These evidences collectively reveal a phenomenon of utility-probability duality in terms of what modern neural networks are (truly) modeling: We thought they are one thing (probabilities), until the unexplainable showed up; changing mindset and treating them as another thing (utility values) largely reconcile the theory, despite remaining subtleties regarding its original (probabilistic) identity. ",
    "url": "https://arxiv.org/abs/2305.14859",
    "authors": [
      "Huang Bojun",
      "Fei Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.14867",
    "title": "Interactive Neural Resonators",
    "abstract": "In this work, we propose a method for the controllable synthesis of real-time contact sounds using neural resonators. Previous works have used physically inspired statistical methods and physical modelling for object materials and excitation signals. Our method incorporates differentiable second-order resonators and estimates their coefficients using a neural network that is conditioned on physical parameters. This allows for interactive dynamic control and the generation of novel sounds in an intuitive manner. We demonstrate the practical implementation of our method and explore its potential creative applications. ",
    "url": "https://arxiv.org/abs/2305.14867",
    "authors": [
      "Rodrigo Diaz",
      "Charalampos Saitis",
      "Mark Sandler"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.14876",
    "title": "Reconstructive Neuron Pruning for Backdoor Defense",
    "abstract": "Deep neural networks (DNNs) have been found to be vulnerable to backdoor attacks, raising security concerns about their deployment in mission-critical applications. While existing defense methods have demonstrated promising results, it is still not clear how to effectively remove backdoor-associated neurons in backdoored DNNs. In this paper, we propose a novel defense called \\emph{Reconstructive Neuron Pruning} (RNP) to expose and prune backdoor neurons via an unlearning and then recovering process. Specifically, RNP first unlearns the neurons by maximizing the model's error on a small subset of clean samples and then recovers the neurons by minimizing the model's error on the same data. In RNP, unlearning is operated at the neuron level while recovering is operated at the filter level, forming an asymmetric reconstructive learning procedure. We show that such an asymmetric process on only a few clean samples can effectively expose and prune the backdoor neurons implanted by a wide range of attacks, achieving a new state-of-the-art defense performance. Moreover, the unlearned model at the intermediate step of our RNP can be directly used to improve other backdoor defense tasks including backdoor removal, trigger recovery, backdoor label detection, and backdoor sample detection. Code is available at \\url{https://github.com/bboylyg/RNP}. ",
    "url": "https://arxiv.org/abs/2305.14876",
    "authors": [
      "Yige Li",
      "Xixiang Lyu",
      "Xingjun Ma",
      "Nodens Koren",
      "Lingjuan Lyu",
      "Bo Li",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.14880",
    "title": "Multiresolution Feature Guidance Based Transformer for Anomaly Detection",
    "abstract": "Anomaly detection is represented as an unsupervised learning to identify deviated images from normal images. In general, there are two main challenges of anomaly detection tasks, i.e., the class imbalance and the unexpectedness of anomalies. In this paper, we propose a multiresolution feature guidance method based on Transformer named GTrans for unsupervised anomaly detection and localization. In GTrans, an Anomaly Guided Network (AGN) pre-trained on ImageNet is developed to provide surrogate labels for features and tokens. Under the tacit knowledge guidance of the AGN, the anomaly detection network named Trans utilizes Transformer to effectively establish a relationship between features with multiresolution, enhancing the ability of the Trans in fitting the normal data manifold. Due to the strong generalization ability of AGN, GTrans locates anomalies by comparing the differences in spatial distance and direction of multi-scale features extracted from the AGN and the Trans. Our experiments demonstrate that the proposed GTrans achieves state-of-the-art performance in both detection and localization on the MVTec AD dataset. GTrans achieves image-level and pixel-level anomaly detection AUROC scores of 99.0% and 97.9% on the MVTec AD dataset, respectively. ",
    "url": "https://arxiv.org/abs/2305.14880",
    "authors": [
      "Shuting Yan",
      "Pingping Chen",
      "Honghui Chen",
      "Huan Mao",
      "Feng Chen",
      "Zhijian Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14885",
    "title": "Towards View-invariant and Accurate Loop Detection Based on Scene Graph",
    "abstract": "Loop detection plays a key role in visual Simultaneous Localization and Mapping (SLAM) by correcting the accumulated pose drift. In indoor scenarios, the richly distributed semantic landmarks are view-point invariant and hold strong descriptive power in loop detection. The current semantic-aided loop detection embeds the topology between semantic instances to search a loop. However, current semantic-aided loop detection methods face challenges in dealing with ambiguous semantic instances and drastic viewpoint differences, which are not fully addressed in the literature. This paper introduces a novel loop detection method based on an incrementally created scene graph, targeting the visual SLAM at indoor scenes. It jointly considers the macro-view topology, micro-view topology, and occupancy of semantic instances to find correct correspondences. Experiments using handheld RGB-D sequence show our method is able to accurately detect loops in drastically changed viewpoints. It maintains a high precision in observing objects with similar topology and appearance. Our method also demonstrates that it is robust in changed indoor scenes. ",
    "url": "https://arxiv.org/abs/2305.14885",
    "authors": [
      "Chuhao Liu",
      "Shaojie Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.14886",
    "title": "How Graph Convolutions Amplify Popularity Bias for Recommendation?",
    "abstract": "Graph convolutional networks (GCNs) have become prevalent in recommender system (RS) due to their superiority in modeling collaborative patterns. Although improving the overall accuracy, GCNs unfortunately amplify popularity bias -- tail items are less likely to be recommended. This effect prevents the GCN-based RS from making precise and fair recommendations, decreasing the effectiveness of recommender systems in the long run. In this paper, we investigate how graph convolutions amplify the popularity bias in RS. Through theoretical analyses, we identify two fundamental factors: (1) with graph convolution (\\textit{i.e.,} neighborhood aggregation), popular items exert larger influence than tail items on neighbor users, making the users move towards popular items in the representation space; (2) after multiple times of graph convolution, popular items would affect more high-order neighbors and become more influential. The two points make popular items get closer to almost users and thus being recommended more frequently. To rectify this, we propose to estimate the amplified effect of popular nodes on each node's representation, and intervene the effect after each graph convolution. Specifically, we adopt clustering to discover highly-influential nodes and estimate the amplification effect of each node, then remove the effect from the node embeddings at each graph convolution layer. Our method is simple and generic -- it can be used in the inference stage to correct existing models rather than training a new model from scratch, and can be applied to various GCN models. We demonstrate our method on two representative GCN backbones LightGCN and UltraGCN, verifying its ability in improving the recommendations of tail items without sacrificing the performance of popular items. Codes are open-sourced \\footnote{https://github.com/MEICRS/DAP}. ",
    "url": "https://arxiv.org/abs/2305.14886",
    "authors": [
      "Jiajia Chen",
      "Jiancan Wu",
      "Jiawei Chen",
      "Xin Xin",
      "Yong Li",
      "Xiangnan He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2305.14888",
    "title": "Privacy Implications of Retrieval-Based Language Models",
    "abstract": "Retrieval-based language models (LMs) have demonstrated improved interpretability, factuality, and adaptability compared to their parametric counterparts, by incorporating retrieved text from external datastores. While it is well known that parametric models are prone to leaking private data, it remains unclear how the addition of a retrieval datastore impacts model privacy. In this work, we present the first study of privacy risks in retrieval-based LMs, particularly $k$NN-LMs. Our goal is to explore the optimal design and training procedure in domains where privacy is of concern, aiming to strike a balance between utility and privacy. Crucially, we find that $k$NN-LMs are more susceptible to leaking private information from their private datastore than parametric models. We further explore mitigations of privacy risks. When privacy information is targeted and readily detected in the text, we find that a simple sanitization step would completely eliminate the risks, while decoupling query and key encoders achieves an even better utility-privacy trade-off. Otherwise, we consider strategies of mixing public and private data in both datastore and encoder training. While these methods offer modest improvements, they leave considerable room for future work. Together, our findings provide insights for practitioners to better understand and mitigate privacy risks in retrieval-based LMs. Our code is available at: https://github.com/Princeton-SysML/kNNLM_privacy . ",
    "url": "https://arxiv.org/abs/2305.14888",
    "authors": [
      "Yangsibo Huang",
      "Samyak Gupta",
      "Zexuan Zhong",
      "Kai Li",
      "Danqi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14890",
    "title": "HARD: Hard Augmentations for Robust Distillation",
    "abstract": "Knowledge distillation (KD) is a simple and successful method to transfer knowledge from a teacher to a student model solely based on functional activity. However, current KD has a few shortcomings: it has recently been shown that this method is unsuitable to transfer simple inductive biases like shift equivariance, struggles to transfer out of domain generalization, and optimization time is magnitudes longer compared to default non-KD model training. To improve these aspects of KD, we propose Hard Augmentations for Robust Distillation (HARD), a generally applicable data augmentation framework, that generates synthetic data points for which the teacher and the student disagree. We show in a simple toy example that our augmentation framework solves the problem of transferring simple equivariances with KD. We then apply our framework in real-world tasks for a variety of augmentation models, ranging from simple spatial transformations to unconstrained image manipulations with a pretrained variational autoencoder. We find that our learned augmentations significantly improve KD performance on in-domain and out-of-domain evaluation. Moreover, our method outperforms even state-of-the-art data augmentations and since the augmented training inputs can be visualized, they offer a qualitative insight into the properties that are transferred from the teacher to the student. Thus HARD represents a generally applicable, dynamically optimized data augmentation technique tailored to improve the generalization and convergence speed of models trained with KD. ",
    "url": "https://arxiv.org/abs/2305.14890",
    "authors": [
      "Arne F. Nix",
      "Max F. Burg",
      "Fabian H. Sinz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14901",
    "title": "Chain-of-Questions Training with Latent Answers for Robust Multistep  Question Answering",
    "abstract": "We train a language model (LM) to robustly answer multistep questions by generating and answering sub-questions. We propose Chain-of-Questions, a framework that trains a model to generate sub-questions and sub-answers one at a time by leveraging human annotated question decomposition meaning representation (QDMR). The key technical challenge is that QDMR only contains sub-questions but not answers to those sub-questions, so we treat sub-answers as latent variables and optimize them using a novel dynamic mixture of Hard-EM and MAPO. Chain-of-Questions greatly outperforms strong neuro-symbolic methods by 9.0 F1 on DROP contrast set, and outperforms GPT-3.5 by 24.3 F1 on HOTPOTQA adversarial set, thus demonstrating the effectiveness and robustness of our framework. ",
    "url": "https://arxiv.org/abs/2305.14901",
    "authors": [
      "Wang Zhu",
      "Jesse Thomason",
      "Robin Jia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14902",
    "title": "M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box  Machine-Generated Text Detection",
    "abstract": "Large language models (LLMs) have demonstrated remarkable capability to generate fluent responses to a wide variety of user queries, but this has also resulted in concerns regarding the potential misuse of such texts in journalism, educational, and academic context. In this work, we aim to develop automatic systems to identify machine-generated text and to detect potential misuse. We first introduce a large-scale benchmark M4, which is multi-generator, multi-domain, and multi-lingual corpus for machine-generated text detection. Using the dataset, we experiment with a number of methods and we show that it is challenging for detectors to generalize well on unseen examples if they are either from different domains or are generated by different large language models. In such cases, detectors tend to misclassify machine-generated text as human-written. These results show that the problem is far from solved and there is a lot of room for improvement. We believe that our dataset M4, which covers different generators, domains and languages, will enable future research towards more robust approaches for this pressing societal problem. The M4 dataset is available at https://github.com/mbzuai-nlp/M4. ",
    "url": "https://arxiv.org/abs/2305.14902",
    "authors": [
      "Yuxia Wang",
      "Jonibek Mansurov",
      "Petar Ivanov",
      "Jinyan Su",
      "Artem Shelmanov",
      "Akim Tsvigun",
      "Chenxi Whitehouse",
      "Osama Mohammed Afzal",
      "Tarek Mahmoud",
      "Alham Fikri Aji",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14910",
    "title": "From Shortcuts to Triggers: Backdoor Defense with Denoised PoE",
    "abstract": "Language models are often at risk of diverse backdoor attacks, especially data poisoning. Thus, it is important to investigate defense solutions for addressing them. Existing backdoor defense methods mainly focus on backdoor attacks with explicit triggers, leaving a universal defense against various backdoor attacks with diverse triggers largely unexplored. In this paper, we propose an end-to-end ensemble-based backdoor defense framework, DPoE (Denoised Product-of-Experts), which is inspired by the shortcut nature of backdoor attacks, to defend various backdoor attacks. DPoE consists of two models: a shallow model that captures the backdoor shortcuts and a main model that is prevented from learning the backdoor shortcuts. To address the label flip caused by backdoor attackers, DPoE incorporates a denoising design. Experiments on SST-2 dataset show that DPoE significantly improves the defense performance against various types of backdoor triggers including word-level, sentence-level, and syntactic triggers. Furthermore, DPoE is also effective under a more challenging but practical setting that mixes multiple types of trigger. ",
    "url": "https://arxiv.org/abs/2305.14910",
    "authors": [
      "Qin Liu",
      "Fei Wang",
      "Chaowei Xiao",
      "Muhao Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14912",
    "title": "SVDinsTN: An Integrated Method for Tensor Network Representation with  Efficient Structure Search",
    "abstract": "Tensor network (TN) representation is a powerful technique for data analysis and machine learning. It practically involves a challenging TN structure search (TN-SS) problem, which aims to search for the optimal structure to achieve a compact representation. Existing TN-SS methods mainly adopt a bi-level optimization method that leads to excessive computational costs due to repeated structure evaluations. To address this issue, we propose an efficient integrated (single-level) method named SVD-inspired TN decomposition (SVDinsTN), eliminating the need for repeated tedious structure evaluation. By inserting a diagonal factor for each edge of the fully-connected TN, we calculate TN cores and diagonal factors simultaneously, with factor sparsity revealing the most compact TN structure. Experimental results on real-world data demonstrate that SVDinsTN achieves approximately $10^2\\sim{}10^3$ times acceleration in runtime compared to the existing TN-SS methods while maintaining a comparable level of representation ability. ",
    "url": "https://arxiv.org/abs/2305.14912",
    "authors": [
      "Yu-Bang Zheng",
      "Xi-Le Zhao",
      "Junhua Zeng",
      "Chao Li",
      "Qibin Zhao",
      "Heng-Chao Li",
      "Ting-Zhu Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14936",
    "title": "Trade-Offs Between Fairness and Privacy in Language Modeling",
    "abstract": "Protecting privacy in contemporary NLP models is gaining in importance. So does the need to mitigate social biases of such models. But can we have both at the same time? Existing research suggests that privacy preservation comes at the price of worsening biases in classification tasks. In this paper, we explore the extent to which this tradeoff really holds when we incorporate both privacy preservation and de-biasing techniques into training text generation models. How does improving the model along one dimension affect the other dimension as well as the utility of the model? We conduct an extensive set of experiments that include bias detection, privacy attacks, language modeling, and performance on downstream tasks. ",
    "url": "https://arxiv.org/abs/2305.14936",
    "authors": [
      "Cleo Matzken",
      "Steffen Eger",
      "Ivan Habernal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14938",
    "title": "Do LLMs Understand Social Knowledge? Evaluating the Sociability of Large  Language Models with SocKET Benchmark",
    "abstract": "Large language models (LLMs) have been shown to perform well at a variety of syntactic, discourse, and reasoning tasks. While LLMs are increasingly deployed in many forms including conversational agents that interact with humans, we lack a grounded benchmark to measure how well LLMs understand \\textit{social} language. Here, we introduce a new theory-driven benchmark, SocKET, that contains 58 NLP tasks testing social knowledge which we group into five categories: humor & sarcasm, offensiveness, sentiment & emotion, and trustworthiness. In tests on the benchmark, we demonstrate that current models attain only moderate performance but reveal significant potential for task transfer among different types and categories of tasks, which were predicted from theory. Through zero-shot evaluations, we show that pretrained models already possess some innate but limited capabilities of social language understanding and training on one category of tasks can improve zero-shot testing on others. Our benchmark provides a systematic way to analyze model performance on an important dimension of language and points to clear room for improvement to build more socially-aware LLMs. The associated resources are released at https://github.com/minjechoi/SOCKET. ",
    "url": "https://arxiv.org/abs/2305.14938",
    "authors": [
      "Minje Choi",
      "Jiaxin Pei",
      "Sagar Kumar",
      "Chang Shu",
      "David Jurgens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14949",
    "title": "Cross-lingual Data Augmentation for Document-grounded Dialog Systems in  Low Resource Languages",
    "abstract": "This paper proposes a framework to address the issue of data scarcity in Document-Grounded Dialogue Systems(DGDS). Our model leverages high-resource languages to enhance the capability of dialogue generation in low-resource languages. Specifically, We present a novel pipeline CLEM (Cross-Lingual Enhanced Model) including adversarial training retrieval (Retriever and Re-ranker), and Fid (fusion-in-decoder) generator. To further leverage high-resource language, we also propose an innovative architecture to conduct alignment across different languages with translated training. Extensive experiment results demonstrate the effectiveness of our model and we achieved 4th place in the DialDoc 2023 Competition. Therefore, CLEM can serve as a solution to resource scarcity in DGDS and provide useful guidance for multi-lingual alignment tasks. ",
    "url": "https://arxiv.org/abs/2305.14949",
    "authors": [
      "Qi Gou",
      "Zehua Xia",
      "Wenzhe Du"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14950",
    "title": "Adversarial Demonstration Attacks on Large Language Models",
    "abstract": "With the emergence of more powerful large language models (LLMs), such as ChatGPT and GPT-4, in-context learning (ICL) has gained significant prominence in leveraging these models for specific tasks by utilizing data-label pairs as precondition prompts. While incorporating demonstrations can greatly enhance the performance of LLMs across various tasks, it may introduce a new security concern: attackers can manipulate only the demonstrations without changing the input to perform an attack. In this paper, we investigate the security concern of ICL from an adversarial perspective, focusing on the impact of demonstrations. We propose an ICL attack based on TextAttack, which aims to only manipulate the demonstration without changing the input to mislead the models. Our results demonstrate that as the number of demonstrations increases, the robustness of in-context learning would decreases. Furthermore, we also observe that adversarially attacked demonstrations exhibit transferability to diverse input examples. These findings emphasize the critical security risks associated with ICL and underscore the necessity for extensive research on the robustness of ICL, particularly given its increasing significance in the advancement of LLMs. ",
    "url": "https://arxiv.org/abs/2305.14950",
    "authors": [
      "Jiongxiao Wang",
      "Zichen Liu",
      "Keun Hee Park",
      "Muhao Chen",
      "Chaowei Xiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14955",
    "title": "DC-Net: Divide-and-Conquer for Salient Object Detection",
    "abstract": "In this paper, we introduce Divide-and-Conquer into the salient object detection (SOD) task to enable the model to learn prior knowledge that is for predicting the saliency map. We design a novel network, Divide-and-Conquer Network (DC-Net) which uses two encoders to solve different subtasks that are conducive to predicting the final saliency map, here is to predict the edge maps with width 4 and location maps of salient objects and then aggregate the feature maps with different semantic information into the decoder to predict the final saliency map. The decoder of DC-Net consists of our newly designed two-level Residual nested-ASPP (ResASPP$^{2}$) modules, which have the ability to capture a large number of different scale features with a small number of convolution operations and have the advantages of maintaining high resolution all the time and being able to obtain a large and compact effective receptive field (ERF). Based on the advantage of Divide-and-Conquer's parallel computing, we use Parallel Acceleration to speed up DC-Net, allowing it to achieve competitive performance on six LR-SOD and five HR-SOD datasets under high efficiency (60 FPS and 55 FPS). Codes and results are available: https://github.com/PiggyJerry/DC-Net. ",
    "url": "https://arxiv.org/abs/2305.14955",
    "authors": [
      "Jiayi Zhu",
      "Xuebin Qin",
      "Abdulmotaleb Elsaddik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14959",
    "title": "UAV Trajectory Optimization and Tracking for User Localization in  Wireless Networks",
    "abstract": "In this paper, we investigate the problem of UAV-aided user localization in wireless networks. Unlike the existing works, we do not assume perfect knowledge of the UAV location, hence we not only need to localize the users but also to track the UAV location. To do so, we utilize the time-of-arrival along with received signal strength radio measurements collected from users using a UAV. A simultaneous localization and mapping (SLAM) framework building on the Expectation-Maximization-based least-squares method is proposed to classify measurements into line-of-sight or non-line-of-sight categories and learn the radio channel, and at the same, localize the users and track the UAV. This framework also allows us to exploit other types of measurements such as the rough estimate of the UAV location available from GPS, and the UAV velocity measured by an inertial measurement unit (IMU) on-board, to achieve better localization accuracy. Moreover, the trajectory of the UAV is optimized which brings considerable improvement to the localization performance. The simulations show the out-performance of the developed algorithm when compared to other approaches. ",
    "url": "https://arxiv.org/abs/2305.14959",
    "authors": [
      "Omid Esrafilian",
      "Rajeev Gangula",
      "David Gesbert"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.14962",
    "title": "ICDAR 2023 Competition on Robust Layout Segmentation in Corporate  Documents",
    "abstract": "Transforming documents into machine-processable representations is a challenging task due to their complex structures and variability in formats. Recovering the layout structure and content from PDF files or scanned material has remained a key problem for decades. ICDAR has a long tradition in hosting competitions to benchmark the state-of-the-art and encourage the development of novel solutions to document layout understanding. In this report, we present the results of our \\textit{ICDAR 2023 Competition on Robust Layout Segmentation in Corporate Documents}, which posed the challenge to accurately segment the page layout in a broad range of document styles and domains, including corporate reports, technical literature and patents. To raise the bar over previous competitions, we engineered a hard competition dataset and proposed the recent DocLayNet dataset for training. We recorded 45 team registrations and received official submissions from 21 teams. In the presented solutions, we recognize interesting combinations of recent computer vision models, data augmentation strategies and ensemble methods to achieve remarkable accuracy in the task we posed. A clear trend towards adoption of vision-transformer based methods is evident. The results demonstrate substantial progress towards achieving robust and highly generalizing methods for document layout understanding. ",
    "url": "https://arxiv.org/abs/2305.14962",
    "authors": [
      "Christoph Auer",
      "Ahmed Nassar",
      "Maksym Lysak",
      "Michele Dolfi",
      "Nikolaos Livathinos",
      "Peter Staar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14964",
    "title": "Detecting and Characterizing Political Incivility on Social Media",
    "abstract": "Researchers of political communication study the impact and perceptions of political incivility on social media. Yet, so far, relatively few works attempted to automatically detect and characterize political incivility. In our work, we study political incivility in Twitter, presenting several research contributions. First, we present state-of-the-art incivility detection results using a large dataset, which we collected and labeled via crowd sourcing. Importantly, we distinguish between uncivil political speech that is impolite and intolerant anti-democratic discourse. Applying political incivility detection at large-scale, we derive insights regarding the prevalence of this phenomenon across users, and explore the network characteristics of users who are susceptible to disseminating uncivil political content online. Finally, we propose an approach for modeling social context information about the tweet author alongside the tweet content, showing that this leads to significantly improved performance on the task of political incivility detection. This result holds promise for related tasks, such as hate speech and stance detection. ",
    "url": "https://arxiv.org/abs/2305.14964",
    "authors": [
      "Sagi Penzel",
      "Nir Lotan",
      "Alon Zoizner",
      "Einat Minkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14969",
    "title": "MMNet: Multi-Mask Network for Referring Image Segmentation",
    "abstract": "Referring image segmentation aims to segment an object referred to by natural language expression from an image. However, this task is challenging due to the distinct data properties between text and image, and the randomness introduced by diverse objects and unrestricted language expression. Most of previous work focus on improving cross-modal feature fusion while not fully addressing the inherent uncertainty caused by diverse objects and unrestricted language. To tackle these problems, we propose an end-to-end Multi-Mask Network for referring image segmentation(MMNet). we first combine picture and language and then employ an attention mechanism to generate multiple queries that represent different aspects of the language expression. We then utilize these queries to produce a series of corresponding segmentation masks, assigning a score to each mask that reflects its importance. The final result is obtained through the weighted sum of all masks, which greatly reduces the randomness of the language expression. Our proposed framework demonstrates superior performance compared to state-of-the-art approaches on the two most commonly used datasets, RefCOCO, RefCOCO+ and G-Ref, without the need for any post-processing. This further validates the efficacy of our proposed framework. ",
    "url": "https://arxiv.org/abs/2305.14969",
    "authors": [
      "Yichen Yan",
      "Xingjian He",
      "Wenxuan Wan",
      "Jing Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14977",
    "title": "Sampling-based Uncertainty Estimation for an Instance Segmentation  Network",
    "abstract": "The examination of uncertainty in the predictions of machine learning (ML) models is receiving increasing attention. One uncertainty modeling technique used for this purpose is Monte-Carlo (MC)-Dropout, where repeated predictions are generated for a single input. Therefore, clustering is required to describe the resulting uncertainty, but only through efficient clustering is it possible to describe the uncertainty from the model attached to each object. This article uses Bayesian Gaussian Mixture (BGM) to solve this problem. In addition, we investigate different values for the dropout rate and other techniques, such as focal loss and calibration, which we integrate into the Mask-RCNN model to obtain the most accurate uncertainty approximation of each instance and showcase it graphically. ",
    "url": "https://arxiv.org/abs/2305.14977",
    "authors": [
      "Florian Heidecker",
      "Ahmad El-Khateeb",
      "Bernhard Sick"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14984",
    "title": "Adversarial robustness of amortized Bayesian inference",
    "abstract": "Bayesian inference usually requires running potentially costly inference procedures separately for every new observation. In contrast, the idea of amortized Bayesian inference is to initially invest computational cost in training an inference network on simulated data, which can subsequently be used to rapidly perform inference (i.e., to return estimates of posterior distributions) for new observations. This approach has been applied to many real-world models in the sciences and engineering, but it is unclear how robust the approach is to adversarial perturbations in the observed data. Here, we study the adversarial robustness of amortized Bayesian inference, focusing on simulation-based estimation of multi-dimensional posterior distributions. We show that almost unrecognizable, targeted perturbations of the observations can lead to drastic changes in the predicted posterior and highly unrealistic posterior predictive samples, across several benchmark tasks and a real-world example from neuroscience. We propose a computationally efficient regularization scheme based on penalizing the Fisher information of the conditional density estimator, and show how it improves the adversarial robustness of amortized Bayesian inference. ",
    "url": "https://arxiv.org/abs/2305.14984",
    "authors": [
      "Manuel Gl\u00f6ckler",
      "Michael Deistler",
      "Jakob H. Macke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.14986",
    "title": "Non-adversarial Robustness of Deep Learning Methods for Computer Vision",
    "abstract": "Non-adversarial robustness, also known as natural robustness, is a property of deep learning models that enables them to maintain performance even when faced with distribution shifts caused by natural variations in data. However, achieving this property is challenging because it is difficult to predict in advance the types of distribution shifts that may occur. To address this challenge, researchers have proposed various approaches, some of which anticipate potential distribution shifts, while others utilize knowledge about the shifts that have already occurred to enhance model generalizability. In this paper, we present a brief overview of the most recent techniques for improving the robustness of computer vision methods, as well as a summary of commonly used robustness benchmark datasets for evaluating the model's performance under data distribution shifts. Finally, we examine the strengths and limitations of the approaches reviewed and identify general trends in deep learning robustness improvement for computer vision. ",
    "url": "https://arxiv.org/abs/2305.14986",
    "authors": [
      "Gorana Goji\u0107",
      "Vladimir Vincan",
      "Ognjen Kunda\u010dina",
      "Dragi\u0161a Mi\u0161kovi\u0107",
      "Dinu Dragan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14998",
    "title": "An Examination of the Robustness of Reference-Free Image Captioning  Evaluation Metrics",
    "abstract": "Recently, reference-free metrics such as CLIPScore (Hessel et al., 2021) and UMIC (Lee et al., 2021) have been proposed for automatic evaluation of image captions, demonstrating a high correlation with human judgment. In this work, our focus lies in evaluating the robustness of these metrics in scenarios that require distinguishing between two captions with high lexical overlap but very different meanings. Our findings reveal that despite their high correlation with human judgment, both CLIPScore and UMIC struggle to identify fine-grained errors in captions. However, when comparing different types of fine-grained errors, both metrics exhibit limited sensitivity to implausibility of captions and strong sensitivity to lack of sufficient visual grounding. Probing further into the visual grounding aspect, we found that both CLIPScore and UMIC are impacted by the size of image-relevant objects mentioned in the caption, and that CLIPScore is also sensitive to the number of mentions of image-relevant objects in the caption. In terms of linguistic aspects of a caption, we found that both metrics lack the ability to comprehend negation, UMIC is sensitive to caption lengths, and CLIPScore is insensitive to the structure of the sentence. We hope our findings will serve as a valuable guide towards improving reference-free evaluation in image captioning. ",
    "url": "https://arxiv.org/abs/2305.14998",
    "authors": [
      "Saba Ahmadi",
      "Aishwarya Agrawal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15003",
    "title": "Measuring Causal Responsibility in Multi-Agent Spatial Interactions with  Feasible Action-Space Reduction",
    "abstract": "Modelling causal responsibility in multi-agent spatial interactions is crucial for safety and efficiency of interactions of humans with autonomous agents. However, current formal metrics and models of responsibility either lack grounding in ethical and philosophical concepts of responsibility, or cannot be applied to spatial interactions. In this work we propose a metric of causal responsibility which is tailored to multi-agent spatial interactions, for instance interactions in traffic. In such interactions, a given agent can, by reducing another agent's feasible action space, influence the latter. Therefore, we propose feasible action space reduction (FeAR) as a metric for causal responsibility among agents. Specifically, we look at ex-post causal responsibility for simultaneous actions. We propose the use of Moves de Rigueur - a consistent set of prescribed actions for agents - to model the effect of norms on responsibility allocation. We apply the metric in a grid world simulation for spatial interactions and show how the actions, contexts, and norms affect the causal responsibility ascribed to agents. Finally, we demonstrate the application of this metric in complex multi-agent interactions. We argue that the FeAR metric is a step towards an interdisciplinary framework for quantifying responsibility that is needed to ensure safety and meaningful human control in human-AI systems. ",
    "url": "https://arxiv.org/abs/2305.15003",
    "authors": [
      "Ashwin George",
      "Luciano Cavalcante Siebert",
      "David Abbink",
      "Arkady Zgonnikov"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2305.15004",
    "title": "LLMDet: A Large Language Models Detection Tool",
    "abstract": "With the advancement of generative language models, the generated text has come remarkably close to high-quality human-authored text in terms of fluency and diversity. This calls for a highly practical detection tool that can identify the source of text, preferably pinpointing the language model it originates from. However, existing detection tools typically require access to language models and can only differentiate between machine-generated and human-authored text, failing to meet the requirements of rapid detection and text tracing. Therefore, in this paper, we propose an efficient, secure, and scalable detection tool called LLMDet, which calculates the proxy perplexity of text by utilizing the prior information of the model's next-token probabilities, obtained through pre-training. Subsequently, we use the self-watermarking information of the model, as measured by proxy perplexity, to detect the source of the text. We found that our method demonstrates impressive detection performance while ensuring speed and security, particularly achieving a recognition accuracy of 97.97\\% for human-authored text. Furthermore, our detection tool also shows promising results in identifying the large language model (e.g., GPT-2, OPT, LLaMA, Vicuna...) responsible for the text. We release the code and processed data at \\url{https://github.com/TrustedLLM/LLMDet}. ",
    "url": "https://arxiv.org/abs/2305.15004",
    "authors": [
      "Kangxi Wu",
      "Liang Pang",
      "Huawei Shen",
      "Xueqi Cheng",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.15006",
    "title": "A Human-in-the-Loop Approach for Information Extraction from Privacy  Policies under Data Scarcity",
    "abstract": "Machine-readable representations of privacy policies are door openers for a broad variety of novel privacy-enhancing and, in particular, transparency-enhancing technologies (TETs). In order to generate such representations, transparency information needs to be extracted from written privacy policies. However, respective manual annotation and extraction processes are laborious and require expert knowledge. Approaches for fully automated annotation, in turn, have so far not succeeded due to overly high error rates in the specific domain of privacy policies. In the end, a lack of properly annotated privacy policies and respective machine-readable representations persists and enduringly hinders the development and establishment of novel technical approaches fostering policy perception and data subject informedness. In this work, we present a prototype system for a `Human-in-the-Loop' approach to privacy policy annotation that integrates ML-generated suggestions and ultimately human annotation decisions. We propose an ML-based suggestion system specifically tailored to the constraint of data scarcity prevalent in the domain of privacy policy annotation. On this basis, we provide meaningful predictions to users thereby streamlining the annotation process. Additionally, we also evaluate our approach through a prototypical implementation to show that our ML-based extraction approach provides superior performance over other recently used extraction models for legal documents. ",
    "url": "https://arxiv.org/abs/2305.15006",
    "authors": [
      "Michael Gebauer",
      "Faraz Mashhur",
      "Nicola Leschke",
      "Elias Gr\u00fcnewald",
      "Frank Pallas"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15014",
    "title": "Unlocking Temporal Question Answering for Large Language Models Using  Code Execution",
    "abstract": "Large language models (LLMs) have made significant progress in natural language processing (NLP), and are utilized extensively in various applications. Recent works, such as chain-of-thought (CoT), have shown that intermediate reasoning steps can improve the performance of LLMs for complex reasoning tasks, such as math problems and symbolic question-answering tasks. However, we notice the challenge that LLMs face when it comes to temporal reasoning. Our preliminary experiments show that generating intermediate reasoning steps does not always boost the performance of complex temporal question-answering tasks. Therefore, we propose a novel framework that combines the extraction capability of LLMs and the logical reasoning capability of a Python solver to tackle this issue. Extensive experiments and analysis demonstrate the effectiveness of our framework in handling intricate time-bound reasoning tasks. ",
    "url": "https://arxiv.org/abs/2305.15014",
    "authors": [
      "Xingxuan Li",
      "Liying Cheng",
      "Qingyu Tan",
      "Hwee Tou Ng",
      "Shafiq Joty",
      "Lidong Bing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.15041",
    "title": "Generating Faithful Synthetic Data with Large Language Models: A Case  Study in Computational Social Science",
    "abstract": "Large Language Models (LLMs) have democratized synthetic data generation, which in turn has the potential to simplify and broaden a wide gamut of NLP tasks. Here, we tackle a pervasive problem in synthetic data generation: its generative distribution often differs from the distribution of real-world data researchers care about (in other words, it is unfaithful). In a case study on sarcasm detection, we study three strategies to increase the faithfulness of synthetic data: grounding, filtering, and taxonomy-based generation. We evaluate these strategies using the performance of classifiers trained with generated synthetic data on real-world data. While all three strategies improve the performance of classifiers, we find that grounding works best for the task at hand. As synthetic data generation plays an ever-increasing role in NLP research, we expect this work to be a stepping stone in improving its utility. We conclude this paper with some recommendations on how to generate high(er)-fidelity synthetic data for specific tasks. ",
    "url": "https://arxiv.org/abs/2305.15041",
    "authors": [
      "Veniamin Veselovsky",
      "Manoel Horta Ribeiro",
      "Akhil Arora",
      "Martin Josifoski",
      "Ashton Anderson",
      "Robert West"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.15053",
    "title": "Decomposing Complex Queries for Tip-of-the-tongue Retrieval",
    "abstract": "When re-finding items, users who forget or are uncertain about identifying details often rely on creative strategies for expressing their information needs -- complex queries that describe content elements (e.g., book characters or events), information beyond the document text (e.g., descriptions of book covers), or personal context (e.g., when they read a book). This retrieval setting, called tip of the tongue (TOT), is especially challenging for models heavily reliant on lexical and semantic overlap between query and document text. In this work, we introduce a simple yet effective framework for handling such complex queries by decomposing the query into individual clues, routing those as sub-queries to specialized retrievers, and ensembling the results. This approach allows us to take advantage of off-the-shelf retrievers (e.g., CLIP for retrieving images of book covers) or incorporate retriever-specific logic (e.g., date constraints). We show that our framework incorportating query decompositions into retrievers can improve gold book recall up to 7% relative again for Recall@5 on a new collection of 14,441 real-world query-book pairs from an online community for resolving TOT inquiries. ",
    "url": "https://arxiv.org/abs/2305.15053",
    "authors": [
      "Kevin Lin",
      "Kyle Lo",
      "Joseph E. Gonzalez",
      "Dan Klein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2305.15054",
    "title": "Understanding Arithmetic Reasoning in Language Models using Causal  Mediation Analysis",
    "abstract": "Mathematical reasoning in large language models (LLMs) has garnered attention in recent research, but there is limited understanding of how these models process and store information related to arithmetic tasks. In this paper, we present a mechanistic interpretation of LLMs for arithmetic-based questions using a causal mediation analysis framework. By intervening on the activations of specific model components and measuring the resulting changes in predicted probabilities, we identify the subset of parameters responsible for specific predictions. We analyze two pre-trained language models with different sizes (2.8B and 6B parameters). Experimental results reveal that a small set of mid-late layers significantly affect predictions for arithmetic-based questions, with distinct activation patterns for correct and wrong predictions. We also investigate the role of the attention mechanism and compare the model's activation patterns for arithmetic queries with the prediction of factual knowledge. Our findings provide insights into the mechanistic interpretation of LLMs for arithmetic tasks and highlight the specific components involved in arithmetic reasoning. ",
    "url": "https://arxiv.org/abs/2305.15054",
    "authors": [
      "Alessandro Stolfo",
      "Yonatan Belinkov",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15060",
    "title": "Who Wrote this Code? Watermarking for Code Generation",
    "abstract": "Large language models for code have recently shown remarkable performance in generating executable code. However, this rapid advancement has been accompanied by many legal and ethical concerns, such as code licensing issues, code plagiarism, and malware generation, making watermarking machine-generated code a very timely problem. Despite such imminent needs, we discover that existing watermarking and machine-generated text detection methods for LLMs fail to function with code generation tasks properly. Hence, in this work, we propose a new watermarking method, SWEET, that significantly improves upon previous approaches when watermarking machine-generated code. Our proposed method selectively applies watermarking to the tokens with high enough entropy, surpassing a defined threshold. The experiments on code generation benchmarks show that our watermarked code has superior quality compared to code produced by the previous state-of-the-art LLM watermarking method. Furthermore, our watermark method also outperforms DetectGPT for the task of machine-generated code detection. ",
    "url": "https://arxiv.org/abs/2305.15060",
    "authors": [
      "Taehyun Lee",
      "Seokhee Hong",
      "Jaewoo Ahn",
      "Ilgee Hong",
      "Hwaran Lee",
      "Sangdoo Yun",
      "Jamin Shin",
      "Gunhee Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.15066",
    "title": "GPT4Graph: Can Large Language Models Understand Graph Structured Data ?  An Empirical Evaluation and Benchmarking",
    "abstract": "Large language models~(LLM) like ChatGPT have become indispensable to artificial general intelligence~(AGI), demonstrating excellent performance in various natural language processing tasks. In the real world, graph data is ubiquitous and an essential part of AGI and prevails in domains like social network analysis, bioinformatics and recommender systems. The training corpus of large language models often includes some algorithmic components, which allows them to achieve certain effects on some graph data-related problems. However, there is still little research on their performance on a broader range of graph-structured data. In this study, we conduct an extensive investigation to assess the proficiency of LLMs in comprehending graph data, employing a diverse range of structural and semantic-related tasks. Our analysis encompasses 10 distinct tasks that evaluate the LLMs' capabilities in graph understanding. Through our study, we not only uncover the current limitations of language models in comprehending graph structures and performing associated reasoning tasks but also emphasize the necessity for further advancements and novel approaches to enhance their graph processing capabilities. Our findings contribute valuable insights towards bridging the gap between language models and graph understanding, paving the way for more effective graph mining and knowledge extraction. ",
    "url": "https://arxiv.org/abs/2305.15066",
    "authors": [
      "Jiayan Guo",
      "Lun Du",
      "Hengyu Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.15084",
    "title": "Audio-Visual Dataset and Method for Anomaly Detection in Traffic Videos",
    "abstract": "We introduce the first audio-visual dataset for traffic anomaly detection taken from real-world scenes, called MAVAD, with a diverse range of weather and illumination conditions. In addition, we propose a novel method named AVACA that combines visual and audio features extracted from video sequences by means of cross-attention to detect anomalies. We demonstrate that the addition of audio improves the performance of AVACA by up to 5.2%. We also evaluate the impact of image anonymization, showing only a minor decrease in performance averaging at 1.7%. ",
    "url": "https://arxiv.org/abs/2305.15084",
    "authors": [
      "B\u0142a\u017cej Leporowski",
      "Arian Bakhtiarnia",
      "Nicole Bonnici",
      "Adrian Muscat",
      "Luca Zanella",
      "Yiming Wang",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15086",
    "title": "Unpaired Image-to-Image Translation via Neural Schr\u00f6dinger Bridge",
    "abstract": "Diffusion models are a powerful class of generative models which simulate stochastic differential equations (SDEs) to generate data from noise. Although diffusion models have achieved remarkable progress in recent years, they have limitations in the unpaired image-to-image translation tasks due to the Gaussian prior assumption. Schr\\\"odinger Bridge (SB), which learns an SDE to translate between two arbitrary distributions, have risen as an attractive solution to this problem. However, none of SB models so far have been successful at unpaired translation between high-resolution images. In this work, we propose the Unpaired Neural Schr\\\"odinger Bridge (UNSB), which combines SB with adversarial training and regularization to learn a SB between unpaired data. We demonstrate that UNSB is scalable, and that it successfully solves various unpaired image-to-image translation tasks. Code: \\url{https://github.com/cyclomon/UNSB} ",
    "url": "https://arxiv.org/abs/2305.15086",
    "authors": [
      "Beomsu Kim",
      "Gihyun Kwon",
      "Kwanyoung Kim",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.15091",
    "title": "Modeling Complex Object Changes in Satellite Image Time-Series: Approach  based on CSP and Spatiotemporal Graph",
    "abstract": "This paper proposes a method for automatically monitoring and analyzing the evolution of complex geographic objects. The objects are modeled as a spatiotemporal graph, which separates filiation relations, spatial relations, and spatiotemporal relations, and is analyzed by detecting frequent sub-graphs using constraint satisfaction problems (CSP). The process is divided into four steps: first, the identification of complex objects in each satellite image; second, the construction of a spatiotemporal graph to model the spatiotemporal changes of the complex objects; third, the creation of sub-graphs to be detected in the base spatiotemporal graph; and fourth, the analysis of the spatiotemporal graph by detecting the sub-graphs and solving a constraint network to determine relevant sub-graphs. The final step is further broken down into two sub-steps: (i) the modeling of the constraint network with defined variables and constraints, and (ii) the solving of the constraint network to find relevant sub-graphs in the spatiotemporal graph. Experiments were conducted using real-world satellite images representing several cities in Saudi Arabia, and the results demonstrate the effectiveness of the proposed approach. ",
    "url": "https://arxiv.org/abs/2305.15091",
    "authors": [
      "Zouhayra Ayadi",
      "Wadii Boulila",
      "Imed Riadh Farah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15094",
    "title": "InpaintNeRF360: Text-Guided 3D Inpainting on Unbounded Neural Radiance  Fields",
    "abstract": "Neural Radiance Fields (NeRF) can generate highly realistic novel views. However, editing 3D scenes represented by NeRF across 360-degree views, particularly removing objects while preserving geometric and photometric consistency, remains a challenging problem due to NeRF's implicit scene representation. In this paper, we propose InpaintNeRF360, a unified framework that utilizes natural language instructions as guidance for inpainting NeRF-based 3D scenes.Our approach employs a promptable segmentation model by generating multi-modal prompts from the encoded text for multiview segmentation. We apply depth-space warping to enforce viewing consistency in the segmentations, and further refine the inpainted NeRF model using perceptual priors to ensure visual plausibility. InpaintNeRF360 is capable of simultaneously removing multiple objects or modifying object appearance based on text instructions while synthesizing 3D viewing-consistent and photo-realistic inpainting. Through extensive experiments on both unbounded and frontal-facing scenes trained through NeRF, we demonstrate the effectiveness of our approach and showcase its potential to enhance the editability of implicit radiance fields. ",
    "url": "https://arxiv.org/abs/2305.15094",
    "authors": [
      "Dongqing Wang",
      "Tong Zhang",
      "Alaa Abboud",
      "Sabine S\u00fcsstrunk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15097",
    "title": "Computer Vision for Construction Progress Monitoring: A Real-Time Object  Detection Approach",
    "abstract": "Construction progress monitoring (CPM) is essential for effective project management, ensuring on-time and on-budget delivery. Traditional CPM methods often rely on manual inspection and reporting, which are time-consuming and prone to errors. This paper proposes a novel approach for automated CPM using state-of-the-art object detection algorithms. The proposed method leverages e.g. YOLOv8's real-time capabilities and high accuracy to identify and track construction elements within site images and videos. A dataset was created, consisting of various building elements and annotated with relevant objects for training and validation. The performance of the proposed approach was evaluated using standard metrics, such as precision, recall, and F1-score, demonstrating significant improvement over existing methods. The integration of Computer Vision into CPM provides stakeholders with reliable, efficient, and cost-effective means to monitor project progress, facilitating timely decision-making and ultimately contributing to the successful completion of construction projects. ",
    "url": "https://arxiv.org/abs/2305.15097",
    "authors": [
      "Jiesheng Yang",
      "Andreas Wilde",
      "Karsten Menzel",
      "Md Zubair Sheikh",
      "Boris Kuznetsov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15098",
    "title": "Referral Augmentation for Zero-Shot Information Retrieval",
    "abstract": "We propose Referral-Augmented Retrieval (RAR), a simple technique that concatenates document indices with referrals, i.e. text from other documents that cite or link to the given document, to provide significant performance gains for zero-shot information retrieval. The key insight behind our method is that referrals provide a more complete, multi-view representation of a document, much like incoming page links in algorithms like PageRank provide a comprehensive idea of a webpage's importance. RAR works with both sparse and dense retrievers, and outperforms generative text expansion techniques such as DocT5Query and Query2Doc a 37% and 21% absolute improvement on ACL paper retrieval Recall@10 -- while also eliminating expensive model training and inference. We also analyze different methods for multi-referral aggregation and show that RAR enables up-to-date information retrieval without re-training. ",
    "url": "https://arxiv.org/abs/2305.15098",
    "authors": [
      "Michael Tang",
      "Shunyu Yao",
      "John Yang",
      "Karthik Narasimhan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.15114",
    "title": "Thinking Twice: Clinical-Inspired Thyroid Ultrasound Lesion Detection  Based on Feature Feedback",
    "abstract": "Accurate detection of thyroid lesions is a critical aspect of computer-aided diagnosis. However, most existing detection methods perform only one feature extraction process and then fuse multi-scale features, which can be affected by noise and blurred features in ultrasound images. In this study, we propose a novel detection network based on a feature feedback mechanism inspired by clinical diagnosis. The mechanism involves first roughly observing the overall picture and then focusing on the details of interest. It comprises two parts: a feedback feature selection module and a feature feedback pyramid. The feedback feature selection module efficiently selects the features extracted in the first phase in both space and channel dimensions to generate high semantic prior knowledge, which is similar to coarse observation. The feature feedback pyramid then uses this high semantic prior knowledge to enhance feature extraction in the second phase and adaptively fuses the two features, similar to fine observation. Additionally, since radiologists often focus on the shape and size of lesions for diagnosis, we propose an adaptive detection head strategy to aggregate multi-scale features. Our proposed method achieves an AP of 70.3% and AP50 of 99.0% on the thyroid ultrasound dataset and meets the real-time requirement. The code is available at https://github.com/HIT-wanglingtao/Thinking-Twice. ",
    "url": "https://arxiv.org/abs/2305.15114",
    "authors": [
      "Lingtao Wang",
      "Jianrui Ding",
      "Fenghe Tang",
      "Chunping Ning"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15121",
    "title": "Beyond Individual Input for Deep Anomaly Detection on Tabular Data",
    "abstract": "Anomaly detection is crucial in various domains, such as finance, healthcare, and cybersecurity. In this paper, we propose a novel deep anomaly detection method for tabular data that leverages Non-Parametric Transformers (NPTs), a model initially proposed for supervised tasks, to capture both feature-feature and sample-sample dependencies. In a reconstruction-based framework, we train the NPT model to reconstruct masked features of normal samples. We use the model's ability to reconstruct the masked features during inference to generate an anomaly score. To the best of our knowledge, our proposed method is the first to combine both feature-feature and sample-sample dependencies for anomaly detection on tabular datasets. We evaluate our method on an extensive benchmark of tabular datasets and demonstrate that our approach outperforms existing state-of-the-art methods based on both the F1-Score and AUROC. Moreover, our work opens up new research directions for exploring the potential of NPTs for other tasks on tabular data. ",
    "url": "https://arxiv.org/abs/2305.15121",
    "authors": [
      "Hugo Thimonier",
      "Fabrice Popineau",
      "Arpad Rimmel",
      "Bich-Li\u00ean Doan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15128",
    "title": "Age of Information in Reservation Multi-Access Networks with Stochastic  Arrivals: Analysis and Optimization",
    "abstract": "This paper analyzes and optimizes the average Age of Information (AAoI) of Frame Slotted ALOHA with Reservation and Data slots (FSA-RD) in a multi-access network, where multiple users transmit their randomly generated status updates to a common access point in a framed manner. Each frame consists of one reservation slot and several data slots. The reservation slot is further split into several mini-slots. In each reservation slot, users that want to transmit a status update will randomly send short reservation packets in one of the mini-slots to contend for data slots of the current frame. The reservation is successful only if one reservation packet is sent in a mini-slot. The data slots are then allocated to those users that succeed in the reservation slot. In the considered FSA-RD scheme, one user with a status update for transmission, termed active user, may need to perform multiple reservation attempts before successfully delivering it. As such, the number of active user(s) in different frames are dependent and thus the probability of making a successful reservation varies from frame to frame, making the AAoI analysis non-trivial. We manage to derive an analytical expression of AAoI for FSA-RD by characterizing the evolution of the number of active user(s) in each frame as a discrete-time Markov chain. We then consider the FSA-RD scheme with one reservation attempt per status update, termed FSA-RD-One. Thanks to the independent frame behaviors of FSA-RD-One, we attain a closed-form expression for its AAoI, which is further used to find the near-optimal reservation probability. Our analysis reveals the impact of key protocol parameters, such as frame size and reservation probability, on the AAoI. Simulation results validate our analysis and show that the optimized FSA-RD outperforms the optimized slotted ALOHA. ",
    "url": "https://arxiv.org/abs/2305.15128",
    "authors": [
      "Qian Wang",
      "Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2305.15134",
    "title": "Networks are Slacking Off: Understanding Generalization Problem in Image  Deraining",
    "abstract": "Deep deraining networks, while successful in laboratory benchmarks, consistently encounter substantial generalization issues when deployed in real-world applications. A prevailing perspective in deep learning encourages the use of highly complex training data, with the expectation that a richer image content knowledge will facilitate overcoming the generalization problem. However, through comprehensive and systematic experimentation, we discovered that this strategy does not enhance the generalization capability of these networks. On the contrary, it exacerbates the tendency of networks to overfit to specific degradations. Our experiments reveal that better generalization in a deraining network can be achieved by simplifying the complexity of the training data. This is due to the networks are slacking off during training, that is, learning the least complex elements in the image content and degradation to minimize training loss. When the complexity of the background image is less than that of the rain streaks, the network will prioritize the reconstruction of the background, thereby avoiding overfitting to the rain patterns and resulting in improved generalization performance. Our research not only offers a valuable perspective and methodology for better understanding the generalization problem in low-level vision tasks, but also displays promising practical potential. ",
    "url": "https://arxiv.org/abs/2305.15134",
    "authors": [
      "Jinjin Gu",
      "Xianzheng Ma",
      "Xiangtao Kong",
      "Yu Qiao",
      "Chao Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15138",
    "title": "Topic-Guided Self-Introduction Generation for Social Media Users",
    "abstract": "Millions of users are active on social media. To allow users to better showcase themselves and network with others, we explore the auto-generation of social media self-introduction, a short sentence outlining a user's personal interests. While most prior work profiles users with tags (e.g., ages), we investigate sentence-level self-introductions to provide a more natural and engaging way for users to know each other. Here we exploit a user's tweeting history to generate their self-introduction. The task is non-trivial because the history content may be lengthy, noisy, and exhibit various personal interests. To address this challenge, we propose a novel unified topic-guided encoder-decoder (UTGED) framework; it models latent topics to reflect salient user interest, whose topic mixture then guides encoding a user's history and topic words control decoding their self-introduction. For experiments, we collect a large-scale Twitter dataset, and extensive results show the superiority of our UTGED to the advanced encoder-decoder models without topic modeling. ",
    "url": "https://arxiv.org/abs/2305.15138",
    "authors": [
      "Chunpu Xu",
      "Jing Li",
      "Piji Li",
      "Min Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15141",
    "title": "From Tempered to Benign Overfitting in ReLU Neural Networks",
    "abstract": "Overparameterized neural networks (NNs) are observed to generalize well even when trained to perfectly fit noisy data. This phenomenon motivated a large body of work on \"benign overfitting\", where interpolating predictors achieve near-optimal performance. Recently, it was conjectured and empirically observed that the behavior of NNs is often better described as \"tempered overfitting\", where the performance is non-optimal yet also non-trivial, and degrades as a function of the noise level. However, a theoretical justification of this claim for non-linear NNs has been lacking so far. In this work, we provide several results that aim at bridging these complementing views. We study a simple classification setting with 2-layer ReLU NNs, and prove that under various assumptions, the type of overfitting transitions from tempered in the extreme case of one-dimensional data, to benign in high dimensions. Thus, we show that the input dimension has a crucial role on the type of overfitting in this setting, which we also validate empirically for intermediate dimensions. Overall, our results shed light on the intricate connections between the dimension, sample size, architecture and training algorithm on the one hand, and the type of resulting overfitting on the other hand. ",
    "url": "https://arxiv.org/abs/2305.15141",
    "authors": [
      "Guy Kornowski",
      "Gilad Yehudai",
      "Ohad Shamir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.15148",
    "title": "Theoretically Principled Federated Learning for Balancing Privacy and  Utility",
    "abstract": "We propose a general learning framework for the protection mechanisms that protects privacy via distorting model parameters, which facilitates the trade-off between privacy and utility. The algorithm is applicable to arbitrary privacy measurements that maps from the distortion to a real value. It can achieve personalized utility-privacy trade-off for each model parameter, on each client, at each communication round in federated learning. Such adaptive and fine-grained protection can improve the effectiveness of privacy-preserved federated learning. Theoretically, we show that gap between the utility loss of the protection hyperparameter output by our algorithm and that of the optimal protection hyperparameter is sub-linear in the total number of iterations. The sublinearity of our algorithm indicates that the average gap between the performance of our algorithm and that of the optimal performance goes to zero when the number of iterations goes to infinity. Further, we provide the convergence rate of our proposed algorithm. We conduct empirical results on benchmark datasets to verify that our method achieves better utility than the baseline methods under the same privacy budget. ",
    "url": "https://arxiv.org/abs/2305.15148",
    "authors": [
      "Xiaojin Zhang",
      "Wenjie Li",
      "Kai Chen",
      "Shutao Xia",
      "Qiang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.15149",
    "title": "Reliability Scores from Saliency Map Clusters for Improved Image-based  Harvest-Readiness Prediction in Cauliflower",
    "abstract": "Cauliflower is a hand-harvested crop that must fulfill high-quality standards in sales making the timing of harvest important. However, accurately determining harvest-readiness can be challenging due to the cauliflower head being covered by its canopy. While deep learning enables automated harvest-readiness estimation, errors can occur due to field-variability and limited training data. In this paper, we analyze the reliability of a harvest-readiness classifier with interpretable machine learning. By identifying clusters of saliency maps, we derive reliability scores for each classification result using knowledge about the domain and the image properties. For unseen data, the reliability can be used to (i) inform farmers to improve their decision-making and (ii) increase the model prediction accuracy. Using RGB images of single cauliflower plants at different developmental stages from the GrowliFlower dataset, we investigate various saliency mapping approaches and find that they result in different quality of reliability scores. With the most suitable interpretation tool, we adjust the classification result and achieve a 15.72% improvement of the overall accuracy to 88.14% and a 15.44% improvement of the average class accuracy to 88.52% for the GrowliFlower dataset. ",
    "url": "https://arxiv.org/abs/2305.15149",
    "authors": [
      "Jana Kierdorf",
      "Ribana Roscher"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15182",
    "title": "HiTIN: Hierarchy-aware Tree Isomorphism Network for Hierarchical Text  Classification",
    "abstract": "Hierarchical text classification (HTC) is a challenging subtask of multi-label classification as the labels form a complex hierarchical structure. Existing dual-encoder methods in HTC achieve weak performance gains with huge memory overheads and their structure encoders heavily rely on domain knowledge. Under such observation, we tend to investigate the feasibility of a memory-friendly model with strong generalization capability that could boost the performance of HTC without prior statistics or label semantics. In this paper, we propose Hierarchy-aware Tree Isomorphism Network (HiTIN) to enhance the text representations with only syntactic information of the label hierarchy. Specifically, we convert the label hierarchy into an unweighted tree structure, termed coding tree, with the guidance of structural entropy. Then we design a structure encoder to incorporate hierarchy-aware information in the coding tree into text representations. Besides the text encoder, HiTIN only contains a few multi-layer perceptions and linear transformations, which greatly saves memory. We conduct experiments on three commonly used datasets and the results demonstrate that HiTIN could achieve better test performance and less memory consumption than state-of-the-art (SOTA) methods. ",
    "url": "https://arxiv.org/abs/2305.15182",
    "authors": [
      "He Zhu",
      "Chong Zhang",
      "Junjie Huang",
      "Junran Wu",
      "Ke Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.15188",
    "title": "Policy Learning based on Deep Koopman Representation",
    "abstract": "This paper proposes a policy learning algorithm based on the Koopman operator theory and policy gradient approach, which seeks to approximate an unknown dynamical system and search for optimal policy simultaneously, using the observations gathered through interaction with the environment. The proposed algorithm has two innovations: first, it introduces the so-called deep Koopman representation into the policy gradient to achieve a linear approximation of the unknown dynamical system, all with the purpose of improving data efficiency; second, the accumulated errors for long-term tasks induced by approximating system dynamics are avoided by applying Bellman's principle of optimality. Furthermore, a theoretical analysis is provided to prove the asymptotic convergence of the proposed algorithm and characterize the corresponding sampling complexity. These conclusions are also supported by simulations on several challenging benchmark environments. ",
    "url": "https://arxiv.org/abs/2305.15188",
    "authors": [
      "Wenjian Hao",
      "Paulo C. Heredia",
      "Bowen Huang",
      "Zehui Lu",
      "Zihao Liang",
      "Shaoshuai Mou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.15189",
    "title": "Black-Box vs. Gray-Box: A Case Study on Learning Table Tennis Ball  Trajectory Prediction with Spin and Impacts",
    "abstract": "In this paper, we present a method for table tennis ball trajectory filtering and prediction. Our gray-box approach builds on a physical model. At the same time, we use data to learn parameters of the dynamics model, of an extended Kalman filter, and of a neural model that infers the ball's initial condition. We demonstrate superior prediction performance of our approach over two black-box approaches, which are not supplied with physical prior knowledge. We demonstrate that initializing the spin from parameters of the ball launcher using a neural network drastically improves long-time prediction performance over estimating the spin purely from measured ball positions. An accurate prediction of the ball trajectory is crucial for successful returns. We therefore evaluate the return performance with a pneumatic artificial muscular robot and achieve a return rate of 29/30 (97.7%). ",
    "url": "https://arxiv.org/abs/2305.15189",
    "authors": [
      "Jan Achterhold",
      "Philip Tobuschat",
      "Hao Ma",
      "Dieter Buechler",
      "Michael Muehlebach",
      "Joerg Stueckler"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.15191",
    "title": "IoT Threat Detection Testbed Using Generative Adversarial Networks",
    "abstract": "The Internet of Things(IoT) paradigm provides persistent sensing and data collection capabilities and is becoming increasingly prevalent across many market sectors. However, most IoT devices emphasize usability and function over security, making them very vulnerable to malicious exploits. This concern is evidenced by the increased use of compromised IoT devices in large scale bot networks (botnets) to launch distributed denial of service(DDoS) attacks against high value targets. Unsecured IoT systems can also provide entry points to private networks, allowing adversaries relatively easy access to valuable resources and services. Indeed, these evolving IoT threat vectors (ranging from brute force attacks to remote code execution exploits) are posing key challenges. Moreover, many traditional security mechanisms are not amenable for deployment on smaller resource-constrained IoT platforms. As a result, researchers have been developing a range of methods for IoT security, with many strategies using advanced machine learning(ML) techniques. Along these lines, this paper presents a novel generative adversarial network(GAN) solution to detect threats from malicious IoT devices both inside and outside a network. This model is trained using both benign IoT traffic and global darknet data and further evaluated in a testbed with real IoT devices and malware threats. ",
    "url": "https://arxiv.org/abs/2305.15191",
    "authors": [
      "Farooq Shaikh",
      "Elias Bou-Harb",
      "Aldin Vehabovic",
      "Jorge Crichigno",
      "Aysegul Yayimli",
      "Nasir Ghani"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.15203",
    "title": "Relating Implicit Bias and Adversarial Attacks through Intrinsic  Dimension",
    "abstract": "Despite their impressive performance in classification, neural networks are known to be vulnerable to adversarial attacks. These attacks are small perturbations of the input data designed to fool the model. Naturally, a question arises regarding the potential connection between the architecture, settings, or properties of the model and the nature of the attack. In this work, we aim to shed light on this problem by focusing on the implicit bias of the neural network, which refers to its inherent inclination to favor specific patterns or outcomes. Specifically, we investigate one aspect of the implicit bias, which involves the essential Fourier frequencies required for accurate image classification. We conduct tests to assess the statistical relationship between these frequencies and those necessary for a successful attack. To delve into this relationship, we propose a new method that can uncover non-linear correlations between sets of coordinates, which, in our case, are the aforementioned frequencies. By exploiting the entanglement between intrinsic dimension and correlation, we provide empirical evidence that the network bias in Fourier space and the target frequencies of adversarial attacks are closely tied. ",
    "url": "https://arxiv.org/abs/2305.15203",
    "authors": [
      "Lorenzo Basile",
      "Nikos Karantzas",
      "Alberto D'Onofrio",
      "Luca Bortolussi",
      "Alex Rodriguez",
      "Fabio Anselmi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.15213",
    "title": "GTNet: Graph Transformer Network for 3D Point Cloud Classification and  Semantic Segmentation",
    "abstract": "Recently, graph-based and Transformer-based deep learning networks have demonstrated excellent performances on various point cloud tasks. Most of the existing graph methods are based on static graph, which take a fixed input to establish graph relations. Moreover, many graph methods apply maximization and averaging to aggregate neighboring features, so that only a single neighboring point affects the feature of centroid or different neighboring points have the same influence on the centroid's feature, which ignoring the correlation and difference between points. Most Transformer-based methods extract point cloud features based on global attention and lack the feature learning on local neighbors. To solve the problems of these two types of models, we propose a new feature extraction block named Graph Transformer and construct a 3D point point cloud learning network called GTNet to learn features of point clouds on local and global patterns. Graph Transformer integrates the advantages of graph-based and Transformer-based methods, and consists of Local Transformer and Global Transformer modules. Local Transformer uses a dynamic graph to calculate all neighboring point weights by intra-domain cross-attention with dynamically updated graph relations, so that every neighboring point could affect the features of centroid with different weights; Global Transformer enlarges the receptive field of Local Transformer by a global self-attention. In addition, to avoid the disappearance of the gradient caused by the increasing depth of network, we conduct residual connection for centroid features in GTNet; we also adopt the features of centroid and neighbors to generate the local geometric descriptors in Local Transformer to strengthen the local information learning capability of the model. Finally, we use GTNet for shape classification, part segmentation and semantic segmentation tasks in this paper. ",
    "url": "https://arxiv.org/abs/2305.15213",
    "authors": [
      "Wei Zhou",
      "Qian Wang",
      "Weiwei Jin",
      "Xinzhe Shi",
      "Dekui Wang",
      "Xingxing Hao",
      "Yongxiang Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15219",
    "title": "DynStatF: An Efficient Feature Fusion Strategy for LiDAR 3D Object  Detection",
    "abstract": "Augmenting LiDAR input with multiple previous frames provides richer semantic information and thus boosts performance in 3D object detection, However, crowded point clouds in multi-frames can hurt the precise position information due to the motion blur and inaccurate point projection. In this work, we propose a novel feature fusion strategy, DynStaF (Dynamic-Static Fusion), which enhances the rich semantic information provided by the multi-frame (dynamic branch) with the accurate location information from the current single-frame (static branch). To effectively extract and aggregate complimentary features, DynStaF contains two modules, Neighborhood Cross Attention (NCA) and Dynamic-Static Interaction (DSI), operating through a dual pathway architecture. NCA takes the features in the static branch as queries and the features in the dynamic branch as keys (values). When computing the attention, we address the sparsity of point clouds and take only neighborhood positions into consideration. NCA fuses two features at different feature map scales, followed by DSI providing the comprehensive interaction. To analyze our proposed strategy DynStaF, we conduct extensive experiments on the nuScenes dataset. On the test set, DynStaF increases the performance of PointPillars in NDS by a large margin from 57.7% to 61.6%. When combined with CenterPoint, our framework achieves 61.0% mAP and 67.7% NDS, leading to state-of-the-art performance without bells and whistles. ",
    "url": "https://arxiv.org/abs/2305.15219",
    "authors": [
      "Yao Rong",
      "Xiangyu Wei",
      "Tianwei Lin",
      "Yueyu Wang",
      "Enkelejda Kasneci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15220",
    "title": "Selection for short-term empowerment accelerates the evolution of  homeostatic neural cellular automata",
    "abstract": "Empowerment -- a domain independent, information-theoretic metric -- has previously been shown to assist in the evolutionary search for neural cellular automata (NCA) capable of homeostasis when employed as a fitness function. In our previous study, we successfully extended empowerment, defined as maximum time-lagged mutual information between agents' actions and future sensations, to a distributed sensorimotor system embodied as an NCA. However, the time-delay between actions and their corresponding sensations was arbitrarily chosen. Here, we expand upon previous work by exploring how the time scale at which empowerment operates impacts its efficacy as an auxiliary objective to accelerate the discovery of homeostatic NCAs. We show that shorter time delays result in marked improvements over empowerment with longer delays, when compared to evolutionary selection only for homeostasis. Moreover, we evaluate stability and adaptability of evolved NCAs, both hallmarks of living systems that are of interest to replicate in artificial ones. We find that short-term empowered NCA are more stable and are capable of generalizing better to unseen homeostatic challenges. Taken together, these findings motivate the use of empowerment during the evolution of other artifacts, and suggest how it should be incorporated to accelerate evolution of desired behaviors for them. Source code for the experiments in this paper can be found at: https://github.com/caitlingrasso/empowered-nca-II. ",
    "url": "https://arxiv.org/abs/2305.15220",
    "authors": [
      "Caitlin Grasso",
      "Josh Bongard"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.15222",
    "title": "Neural Summarization of Electronic Health Records",
    "abstract": "Hospital discharge documentation is among the most essential, yet time-consuming documents written by medical practitioners. The objective of this study was to automatically generate hospital discharge summaries using neural network summarization models. We studied various data preparation and neural network training techniques that generate discharge summaries. Using nursing notes and discharge summaries from the MIMIC-III dataset, we studied the viability of the automatic generation of various sections of a discharge summary using four state-of-the-art neural network summarization models (BART, T5, Longformer and FLAN-T5). Our experiments indicated that training environments including nursing notes as the source, and discrete sections of the discharge summary as the target output (e.g. \"History of Present Illness\") improve language model efficiency and text quality. According to our findings, the fine-tuned BART model improved its ROUGE F1 score by 43.6% against its standard off-the-shelf version. We also found that fine-tuning the baseline BART model with other setups caused different degrees of improvement (up to 80% relative improvement). We also observed that a fine-tuned T5 generally achieves higher ROUGE F1 scores than other fine-tuned models and a fine-tuned FLAN-T5 achieves the highest ROUGE score overall, i.e., 45.6. For majority of the fine-tuned language models, summarizing discharge summary report sections separately outperformed the summarization the entire report quantitatively. On the other hand, fine-tuning language models that were previously instruction fine-tuned showed better performance in summarizing entire reports. This study concludes that a focused dataset designed for the automatic generation of discharge summaries by a language model can produce coherent Discharge Summary sections. ",
    "url": "https://arxiv.org/abs/2305.15222",
    "authors": [
      "Koyena Pal",
      "Seyed Ali Bahrainian",
      "Laura Mercurio",
      "Carsten Eickhoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2305.15227",
    "title": "Real time dense anomaly detection by learning on synthetic negative data",
    "abstract": "Most approaches to dense anomaly detection rely on generative modeling or on discriminative methods that train with negative data. We consider a recent hybrid method that optimizes the same shared representation according to cross-entropy of the discriminative predictions, and negative log likelihood of the predicted energy-based density. We extend that work with a jointly trained generative flow that samples synthetic negatives at the border of the inlier distribution. The proposed extension provides potential to learn the hybrid method without real negative data. Our experiments analyze the impact of training with synthetic negative data and validate contribution of the energy-based density during training and evaluation. ",
    "url": "https://arxiv.org/abs/2305.15227",
    "authors": [
      "Anja Deli\u0107",
      "Matej Grci\u0107",
      "Sini\u0161a \u0160egvi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15241",
    "title": "Robust Classification via a Single Diffusion Model",
    "abstract": "Recently, diffusion models have been successfully applied to improving adversarial robustness of image classifiers by purifying the adversarial noises or generating realistic data for adversarial training. However, the diffusion-based purification can be evaded by stronger adaptive attacks while adversarial training does not perform well under unseen threats, exhibiting inevitable limitations of these methods. To better harness the expressive power of diffusion models, in this paper we propose Robust Diffusion Classifier (RDC), a generative classifier that is constructed from a pre-trained diffusion model to be adversarially robust. Our method first maximizes the data likelihood of a given input and then predicts the class probabilities of the optimized input using the conditional likelihood of the diffusion model through Bayes' theorem. Since our method does not require training on particular adversarial attacks, we demonstrate that it is more generalizable to defend against multiple unseen threats. In particular, RDC achieves $73.24\\%$ robust accuracy against $\\ell_\\infty$ norm-bounded perturbations with $\\epsilon_\\infty=8/255$ on CIFAR-10, surpassing the previous state-of-the-art adversarial training models by $+2.34\\%$. The findings highlight the potential of generative classifiers by employing diffusion models for adversarial robustness compared with the commonly studied discriminative classifiers. ",
    "url": "https://arxiv.org/abs/2305.15241",
    "authors": [
      "Huanran Chen",
      "Yinpeng Dong",
      "Zhengyi Wang",
      "Xiao Yang",
      "Chengqi Duan",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15244",
    "title": "Neural Lyapunov and Optimal Control",
    "abstract": "Optimal control (OC) is an effective approach to controlling complex dynamical systems. However, traditional approaches to parameterising and learning controllers in optimal control have been ad-hoc, collecting data and fitting it to neural networks. However, this can lead to learnt controllers ignoring constraints like optimality and time variability. We introduce a unified framework that simultaneously solves control problems while learning corresponding Lyapunov or value functions. Our method formulates OC-like mathematical programs based on the Hamilton-Jacobi-Bellman (HJB) equation. We leverage the HJB optimality constraint and its relaxation to learn time-varying value and Lyapunov functions, implicitly ensuring the inclusion of constraints. We show the effectiveness of our approach on linear and nonlinear control-affine problems. Additionally, we demonstrate significant reductions in planning horizons (up to a factor of 25) when incorporating the learnt functions into Model Predictive Controllers. ",
    "url": "https://arxiv.org/abs/2305.15244",
    "authors": [
      "Daniel Layeghi",
      "Steve Tonneau",
      "Michael Mistry"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.15252",
    "title": "Multi-Connectivity for Multicast Video Streaming in Cellular Networks  (Extended Abstract)",
    "abstract": "In video streaming applications especially during live streaming events (such as the Super Bowl), video traffic can account for a significant portion of network traffic and can lead to severe network congestion. During such events, multicast transmission can be used to avoid network congestion since the same video content is being streamed to multiple users simultaneously. However, providing seamless connectivity to cellular users in multicast streaming remains an open problem. To address this issue, this paper explores the potential of using multi-connectivity (MC) in wireless multicast streaming. Our results reveal that MC significantly improves the performance of multicast services, especially for cell edge users who often suffer from poor channel conditions. We prove that optimal resource allocation in MC multicast streaming is an NP-hard problem. Therefore, we propose a greedy approximation algorithm for this problem with an approximation factor of $(1-1/e)$. We also prove that no other polynomial-time algorithm can provide a better approximation. ",
    "url": "https://arxiv.org/abs/2305.15252",
    "authors": [
      "Sadaf Ul Zuhra",
      "Prasanna Chaporkar",
      "Abhay Karandikar",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2305.15270",
    "title": "Reversible Graph Neural Network-based Reaction Distribution Learning for  Multiple Appropriate Facial Reactions Generation",
    "abstract": "Generating facial reactions in a human-human dyadic interaction is complex and highly dependent on the context since more than one facial reactions can be appropriate for the speaker's behaviour. This has challenged existing machine learning (ML) methods, whose training strategies enforce models to reproduce a specific (not multiple) facial reaction from each input speaker behaviour. This paper proposes the first multiple appropriate facial reaction generation framework that re-formulates the one-to-many mapping facial reaction generation problem as a one-to-one mapping problem. This means that we approach this problem by considering the generation of a distribution of the listener's appropriate facial reactions instead of multiple different appropriate facial reactions, i.e., 'many' appropriate facial reaction labels are summarised as 'one' distribution label during training. Our model consists of a perceptual processor, a cognitive processor, and a motor processor. The motor processor is implemented with a novel Reversible Multi-dimensional Edge Graph Neural Network (REGNN). This allows us to obtain a distribution of appropriate real facial reactions during the training process, enabling the cognitive processor to be trained to predict the appropriate facial reaction distribution. At the inference stage, the REGNN decodes an appropriate facial reaction by using this distribution as input. Experimental results demonstrate that our approach outperforms existing models in generating more appropriate, realistic, and synchronized facial reactions. The improved performance is largely attributed to the proposed appropriate facial reaction distribution learning strategy and the use of a REGNN. The code is available at https://github.com/TongXu-05/REGNN-Multiple-Appropriate-Facial-Reaction-Generation. ",
    "url": "https://arxiv.org/abs/2305.15270",
    "authors": [
      "Tong Xu",
      "Micol Spitale",
      "Hao Tang",
      "Lu Liu",
      "Hatice Gunes",
      "Siyang Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15276",
    "title": "Robust Sparse Mean Estimation via Incremental Learning",
    "abstract": "In this paper, we study the problem of robust sparse mean estimation, where the goal is to estimate a $k$-sparse mean from a collection of partially corrupted samples drawn from a heavy-tailed distribution. Existing estimators face two critical challenges in this setting. First, they are limited by a conjectured computational-statistical tradeoff, implying that any computationally efficient algorithm needs $\\tilde\\Omega(k^2)$ samples, while its statistically-optimal counterpart only requires $\\tilde O(k)$ samples. Second, the existing estimators fall short of practical use as they scale poorly with the ambient dimension. This paper presents a simple mean estimator that overcomes both challenges under moderate conditions: it runs in near-linear time and memory (both with respect to the ambient dimension) while requiring only $\\tilde O(k)$ samples to recover the true mean. At the core of our method lies an incremental learning phenomenon: we introduce a simple nonconvex framework that can incrementally learn the top-$k$ nonzero elements of the mean while keeping the zero elements arbitrarily small. Unlike existing estimators, our method does not need any prior knowledge of the sparsity level $k$. We prove the optimality of our estimator by providing a matching information-theoretic lower bound. Finally, we conduct a series of simulations to corroborate our theoretical findings. Our code is available at https://github.com/huihui0902/Robust_mean_estimation. ",
    "url": "https://arxiv.org/abs/2305.15276",
    "authors": [
      "Jianhao Ma",
      "Rui Ray Chen",
      "Yinghui He",
      "Salar Fattahi",
      "Wei Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.15311",
    "title": "Personalized Dictionary Learning for Heterogeneous Datasets",
    "abstract": "We introduce a relevant yet challenging problem named Personalized Dictionary Learning (PerDL), where the goal is to learn sparse linear representations from heterogeneous datasets that share some commonality. In PerDL, we model each dataset's shared and unique features as global and local dictionaries. Challenges for PerDL not only are inherited from classical dictionary learning (DL), but also arise due to the unknown nature of the shared and unique features. In this paper, we rigorously formulate this problem and provide conditions under which the global and local dictionaries can be provably disentangled. Under these conditions, we provide a meta-algorithm called Personalized Matching and Averaging (PerMA) that can recover both global and local dictionaries from heterogeneous datasets. PerMA is highly efficient; it converges to the ground truth at a linear rate under suitable conditions. Moreover, it automatically borrows strength from strong learners to improve the prediction of weak learners. As a general framework for extracting global and local dictionaries, we show the application of PerDL in different learning tasks, such as training with imbalanced datasets and video surveillance. ",
    "url": "https://arxiv.org/abs/2305.15311",
    "authors": [
      "Geyu Liang",
      "Naichen Shi",
      "Raed Al Kontar",
      "Salar Fattahi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15314",
    "title": "Towards Fine-Grained Localization of Privacy Behaviors",
    "abstract": "Mobile applications are required to give privacy notices to users when they collect or share personal information. Creating consistent and concise privacy notices can be a challenging task for developers. Previous work has attempted to help developers create privacy notices through a questionnaire or predefined templates. In this paper, we propose a novel approach and a framework, called PriGen, that extends these prior work. PriGen uses static analysis to identify Android applications' code segments that process sensitive information (i.e. permission-requiring code segments) and then leverages a Neural Machine Translation model to translate them into privacy captions. We present the initial evaluation of our translation task for ~300,000 code segments. ",
    "url": "https://arxiv.org/abs/2305.15314",
    "authors": [
      "Vijayanta Jain",
      "Sepideh Ghanavati",
      "Sai Teja Peddinti",
      "Collin McMillan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.15331",
    "title": "No-Regret Online Prediction with Strategic Experts",
    "abstract": "We study a generalization of the online binary prediction with expert advice framework where at each round, the learner is allowed to pick $m\\geq 1$ experts from a pool of $K$ experts and the overall utility is a modular or submodular function of the chosen experts. We focus on the setting in which experts act strategically and aim to maximize their influence on the algorithm's predictions by potentially misreporting their beliefs about the events. Among others, this setting finds applications in forecasting competitions where the learner seeks not only to make predictions by aggregating different forecasters but also to rank them according to their relative performance. Our goal is to design algorithms that satisfy the following two requirements: 1) $\\textit{Incentive-compatible}$: Incentivize the experts to report their beliefs truthfully, and 2) $\\textit{No-regret}$: Achieve sublinear regret with respect to the true beliefs of the best fixed set of $m$ experts in hindsight. Prior works have studied this framework when $m=1$ and provided incentive-compatible no-regret algorithms for the problem. We first show that a simple reduction of our problem to the $m=1$ setting is neither efficient nor effective. Then, we provide algorithms that utilize the specific structure of the utility functions to achieve the two desired goals. ",
    "url": "https://arxiv.org/abs/2305.15331",
    "authors": [
      "Omid Sadeghi",
      "Maryam Fazel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2305.15336",
    "title": "From Text to MITRE Techniques: Exploring the Malicious Use of Large  Language Models for Generating Cyber Attack Payloads",
    "abstract": "This research article critically examines the potential risks and implications arising from the malicious utilization of large language models(LLM), focusing specifically on ChatGPT and Google's Bard. Although these large language models have numerous beneficial applications, the misuse of this technology by cybercriminals for creating offensive payloads and tools is a significant concern. In this study, we systematically generated implementable code for the top-10 MITRE Techniques prevalent in 2022, utilizing ChatGPT, and conduct a comparative analysis of its performance with Google's Bard. Our experimentation reveals that ChatGPT has the potential to enable attackers to accelerate the operation of more targeted and sophisticated attacks. Additionally, the technology provides amateur attackers with more capabilities to perform a wide range of attacks and empowers script kiddies to develop customized tools that contribute to the acceleration of cybercrime. Furthermore, LLMs significantly benefits malware authors, particularly ransomware gangs, in generating sophisticated variants of wiper and ransomware attacks with ease. On a positive note, our study also highlights how offensive security researchers and pentesters can make use of LLMs to simulate realistic attack scenarios, identify potential vulnerabilities, and better protect organizations. Overall, we conclude by emphasizing the need for increased vigilance in mitigating the risks associated with LLMs. This includes implementing robust security measures, increasing awareness and education around the potential risks of this technology, and collaborating with security experts to stay ahead of emerging threats. ",
    "url": "https://arxiv.org/abs/2305.15336",
    "authors": [
      "P.V. Sai Charan",
      "Hrushikesh Chunduri",
      "P. Mohan Anand",
      "Sandeep K Shukla"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.15372",
    "title": "What can generic neural networks learn from a child's visual experience?",
    "abstract": "Young children develop sophisticated internal models of the world based on their egocentric visual experience. How much of this is driven by innate constraints and how much is driven by their experience? To investigate these questions, we train state-of-the-art neural networks on a realistic proxy of a child's visual experience without any explicit supervision or domain-specific inductive biases. Specifically, we train both embedding models and generative models on 200 hours of headcam video from a single child collected over two years. We train a total of 72 different models, exploring a range of model architectures and self-supervised learning algorithms, and comprehensively evaluate their performance in downstream tasks. The best embedding models perform at 70% of a highly performant ImageNet-trained model on average. They also learn broad semantic categories without any labeled examples and learn to localize semantic categories in an image without any location supervision. However, these models are less object-centric and more background-sensitive than comparable ImageNet-trained models. Generative models trained with the same data successfully extrapolate simple properties of partially masked objects, such as their texture, color, orientation, and rough outline, but struggle with finer object details. We replicate our experiments with two other children and find very similar results. Broadly useful high-level visual representations are thus robustly learnable from a representative sample of a child's visual experience without strong inductive biases. ",
    "url": "https://arxiv.org/abs/2305.15372",
    "authors": [
      "A. Emin Orhan",
      "Brenden M. Lake"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2305.15374",
    "title": "ASPER: Answer Set Programming Enhanced Neural Network Models for Joint  Entity-Relation Extraction",
    "abstract": "A plethora of approaches have been proposed for joint entity-relation (ER) extraction. Most of these methods largely depend on a large amount of manually annotated training data. However, manual data annotation is time consuming, labor intensive, and error prone. Human beings learn using both data (through induction) and knowledge (through deduction). Answer Set Programming (ASP) has been a widely utilized approach for knowledge representation and reasoning that is elaboration tolerant and adept at reasoning with incomplete information. This paper proposes a new approach, ASP-enhanced Entity-Relation extraction (ASPER), to jointly recognize entities and relations by learning from both data and domain knowledge. In particular, ASPER takes advantage of the factual knowledge (represented as facts in ASP) and derived knowledge (represented as rules in ASP) in the learning process of neural network models. We have conducted experiments on two real datasets and compare our method with three baselines. The results show that our ASPER model consistently outperforms the baselines. ",
    "url": "https://arxiv.org/abs/2305.15374",
    "authors": [
      "Trung Hoang Le",
      "Huiping Cao",
      "Tran Cao Son"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15377",
    "title": "Uncovering and Quantifying Social Biases in Code Generation",
    "abstract": "With the popularity of automatic code generation tools, such as Copilot, the study of the potential hazards of these tools is gaining importance. In this work, we explore the social bias problem in pre-trained code generation models. We propose a new paradigm to construct code prompts and successfully uncover social biases in code generation models. To quantify the severity of social biases in generated code, we develop a dataset along with three metrics to evaluate the overall social bias and fine-grained unfairness across different demographics. Experimental results on three pre-trained code generation models (Codex, InCoder, and CodeGen) with varying sizes, reveal severe social biases. Moreover, we conduct analysis to provide useful insights for further choice of code generation models with low social bias. (This work contains examples that potentially implicate stereotypes, associations, and other harms that could be offensive to individuals in certain social groups.) ",
    "url": "https://arxiv.org/abs/2305.15377",
    "authors": [
      "Yan Liu",
      "Xiaokang Chen",
      "Yan Gao",
      "Zhe Su",
      "Fengji Zhang",
      "Daoguang Zan",
      "Jian-Guang Lou",
      "Pin-Yu Chen",
      "Tsung-Yi Ho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.15383",
    "title": "On the Minimax Regret for Online Learning with Feedback Graphs",
    "abstract": "In this work, we improve on the upper and lower bounds for the regret of online learning with strongly observable undirected feedback graphs. The best known upper bound for this problem is $\\mathcal{O}\\bigl(\\sqrt{\\alpha T\\ln K}\\bigr)$, where $K$ is the number of actions, $\\alpha$ is the independence number of the graph, and $T$ is the time horizon. The $\\sqrt{\\ln K}$ factor is known to be necessary when $\\alpha = 1$ (the experts case). On the other hand, when $\\alpha = K$ (the bandits case), the minimax rate is known to be $\\Theta\\bigl(\\sqrt{KT}\\bigr)$, and a lower bound $\\Omega\\bigl(\\sqrt{\\alpha T}\\bigr)$ is known to hold for any $\\alpha$. Our improved upper bound $\\mathcal{O}\\bigl(\\sqrt{\\alpha T(1+\\ln(K/\\alpha))}\\bigr)$ holds for any $\\alpha$ and matches the lower bounds for bandits and experts, while interpolating intermediate cases. To prove this result, we use FTRL with $q$-Tsallis entropy for a carefully chosen value of $q \\in [1/2, 1)$ that varies with $\\alpha$. The analysis of this algorithm requires a new bound on the variance term in the regret. We also show how to extend our techniques to time-varying graphs, without requiring prior knowledge of their independence numbers. Our upper bound is complemented by an improved $\\Omega\\bigl(\\sqrt{\\alpha T(\\ln K)/(\\ln\\alpha)}\\bigr)$ lower bound for all $\\alpha > 1$, whose analysis relies on a novel reduction to multitask learning. This shows that a logarithmic factor is necessary as soon as $\\alpha < K$. ",
    "url": "https://arxiv.org/abs/2305.15383",
    "authors": [
      "Khaled Eldowa",
      "Emmanuel Esposito",
      "Tommaso Cesari",
      "Nicol\u00f2 Cesa-Bianchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15388",
    "title": "Outage Tradeoff Analysis in a Downlink Integrated Sensing and  Communication Network",
    "abstract": "This paper aims to analyze the stochastic performance of a multiple input multiple output (MIMO) integrated sensing and communication (ISAC) system in a downlink scenario, where a base station (BS) transmits a dual-functional radar-communication (DFRC) signal matrix, serving the purpose of transmitting communication data to the user while simultaneously sensing the angular location of a target. The channel between the BS and the user is modeled as a random channel with Rayleigh fading distribution, and the azimuth angle of the target is assumed to follow a uniform distribution. We use a maximum ratio transmission (MRT) beamformer to share resource between sensing and communication (S \\& C) and observe the trade-off between them. We derive the approximate probability density function (PDF) of the signal-to-noise ratio (SNR) for both the user and the target. Subsequently, leveraging the obtained PDF, we derive the expressions for the user's rate outage probability (OP), as well as the OP for the Cramer-Rao lower bound (CRLB) of the angle of arrival (AOA). In our numerical results, we demonstrate the trade-off between S \\& C, confirmed with simulations. ",
    "url": "https://arxiv.org/abs/2305.15388",
    "authors": [
      "Marziyeh Soltani",
      "Mahtab Mirmohseni",
      "Rahim Tafazolli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.15391",
    "title": "A Neural Space-Time Representation for Text-to-Image Personalization",
    "abstract": "A key aspect of text-to-image personalization methods is the manner in which the target concept is represented within the generative process. This choice greatly affects the visual fidelity, downstream editability, and disk space needed to store the learned concept. In this paper, we explore a new text-conditioning space that is dependent on both the denoising process timestep (time) and the denoising U-Net layers (space) and showcase its compelling properties. A single concept in the space-time representation is composed of hundreds of vectors, one for each combination of time and space, making this space challenging to optimize directly. Instead, we propose to implicitly represent a concept in this space by optimizing a small neural mapper that receives the current time and space parameters and outputs the matching token embedding. In doing so, the entire personalized concept is represented by the parameters of the learned mapper, resulting in a compact, yet expressive, representation. Similarly to other personalization methods, the output of our neural mapper resides in the input space of the text encoder. We observe that one can significantly improve the convergence and visual fidelity of the concept by introducing a textual bypass, where our neural mapper additionally outputs a residual that is added to the output of the text encoder. Finally, we show how one can impose an importance-based ordering over our implicit representation, providing users control over the reconstruction and editability of the learned concept using a single trained model. We demonstrate the effectiveness of our approach over a range of concepts and prompts, showing our method's ability to generate high-quality and controllable compositions without fine-tuning any parameters of the generative model itself. ",
    "url": "https://arxiv.org/abs/2305.15391",
    "authors": [
      "Yuval Alaluf",
      "Elad Richardson",
      "Gal Metzer",
      "Daniel Cohen-Or"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15394",
    "title": "Differentially-Private Decision Trees with Probabilistic Robustness to  Data Poisoning",
    "abstract": "Decision trees are interpretable models that are well-suited to non-linear learning problems. Much work has been done on extending decision tree learning algorithms with differential privacy, a system that guarantees the privacy of samples within the training data. However, current state-of-the-art algorithms for this purpose sacrifice much utility for a small privacy benefit. These solutions create random decision nodes that reduce decision tree accuracy or spend an excessive share of the privacy budget on labeling leaves. Moreover, many works do not support or leak information about feature values when data is continuous. We propose a new method called PrivaTree based on private histograms that chooses good splits while consuming a small privacy budget. The resulting trees provide a significantly better privacy-utility trade-off and accept mixed numerical and categorical data without leaking additional information. Finally, while it is notoriously hard to give robustness guarantees against data poisoning attacks, we prove bounds for the expected success rates of backdoor attacks against differentially-private learners. Our experimental results show that PrivaTree consistently outperforms previous works on predictive accuracy and significantly improves robustness against backdoor attacks compared to regular decision trees. ",
    "url": "https://arxiv.org/abs/2305.15394",
    "authors": [
      "Dani\u00ebl Vos",
      "Jelle Vos",
      "Tianyu Li",
      "Zekeriya Erkin",
      "Sicco Verwer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.15395",
    "title": "Safety-aware Semi-end-to-end Coordinated Decision Model for Voltage  Regulation in Active Distribution Network",
    "abstract": "Prediction plays a vital role in the active distribution network voltage regulation under the high penetration of photovoltaics. Current prediction models aim at minimizing individual prediction errors but overlook their collective impacts on downstream decision-making. Hence, this paper proposes a safety-aware semi-end-to-end coordinated decision model to bridge the gap from the downstream voltage regulation to the upstream multiple prediction models in a coordinated differential way. The semi-end-to-end model maps the input features to the optimal var decisions via prediction, decision-making, and decision-evaluating layers. It leverages the neural network and the second-order cone program (SOCP) to formulate the stochastic PV/load predictions and the var decision-making/evaluating separately. Then the var decision quality is evaluated via the weighted sum of the power loss for economy and the voltage violation penalty for safety, denoted by regulation loss. Based on the regulation loss and prediction errors, this paper proposes the hybrid loss and hybrid stochastic gradient descent algorithm to back-propagate the gradients of the hybrid loss with respect to multiple predictions for enhancing decision quality. Case studies verify the effectiveness of the proposed model with lower power loss for economy and lower voltage violation rate for safety awareness. ",
    "url": "https://arxiv.org/abs/2305.15395",
    "authors": [
      "Linwei Sang",
      "Yinliang Xu",
      "Huan Long",
      "Wenchuan Wu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.15396",
    "title": "An Efficient Key Management Scheme For In-Vehicle Network",
    "abstract": "Vehicle technology has developed rapidly these years, however, the security measures for in-vehicle network does not keep up with the trend. Controller area network(CAN) is the most used protocol in the in-vehicle network. With the characteristic of CAN, there exists many vulnerabilities including lacks of integrity and confidentiality, and hence CAN is vulnerable to various attacks such as impersonation attack, replay attack, etc. In order to implement the authentication and encryption, secret key derivation is necessary. In this work, we proposed an efficient key management scheme for in-vehicle network. In particular, the scheme has five phases. In the first and second phase, we utilize elliptic curve cryptography-based key encapsulation mechanism(KEM) to derive a pairwise secret between each ECU and a central secure ECU in the same group. Then in the third phase, we design secure communication to derive group shared secret among all ECU in a group. In the last two phases, SECU is not needed, regular ECU can derive session key on their own. We presented a possible attack analysis(chosen-ciphertext attack as the main threat) and a security property analysis for our scheme. Our scheme is evaluated based on a hardware-based experiment of three different microcontrollers and a software-based simulation of IVNS. We argue that based on our estimation and the experiment result, our scheme performs better in communication and computation overhead than similar works. ",
    "url": "https://arxiv.org/abs/2305.15396",
    "authors": [
      "Hsinlin Tan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.15403",
    "title": "AV-TranSpeech: Audio-Visual Robust Speech-to-Speech Translation",
    "abstract": "Direct speech-to-speech translation (S2ST) aims to convert speech from one language into another, and has demonstrated significant progress to date. Despite the recent success, current S2ST models still suffer from distinct degradation in noisy environments and fail to translate visual speech (i.e., the movement of lips and teeth). In this work, we present AV-TranSpeech, the first audio-visual speech-to-speech (AV-S2ST) translation model without relying on intermediate text. AV-TranSpeech complements the audio stream with visual information to promote system robustness and opens up a host of practical applications: dictation or dubbing archival films. To mitigate the data scarcity with limited parallel AV-S2ST data, we 1) explore self-supervised pre-training with unlabeled audio-visual data to learn contextual representation, and 2) introduce cross-modal distillation with S2ST models trained on the audio-only corpus to further reduce the requirements of visual data. Experimental results on two language pairs demonstrate that AV-TranSpeech outperforms audio-only models under all settings regardless of the type of noise. With low-resource audio-visual data (10h, 30h), cross-modal distillation yields an improvement of 7.6 BLEU on average compared with baselines. Audio samples are available at https://AV-TranSpeech.github.io ",
    "url": "https://arxiv.org/abs/2305.15403",
    "authors": [
      "Rongjie Huang",
      "Huadai Liu",
      "Xize Cheng",
      "Yi Ren",
      "Linjun Li",
      "Zhenhui Ye",
      "Jinzheng He",
      "Lichao Zhang",
      "Jinglin Liu",
      "Xiang Yin",
      "Zhou Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.15404",
    "title": "RoMa: Revisiting Robust Losses for Dense Feature Matching",
    "abstract": "Dense feature matching is an important computer vision task that involves estimating all correspondences between two images of a 3D scene. In this paper, we revisit robust losses for matching from a Markov chain perspective, yielding theoretical insights and large gains in performance. We begin by constructing a unifying formulation of matching as a Markov chain, based on which we identify two key stages which we argue should be decoupled for matching. The first is the coarse stage, where the estimated result needs to be globally consistent. The second is the refinement stage, where the model needs precise localization capabilities. Inspired by the insight that these stages concern distinct issues, we propose a coarse matcher following the regression-by-classification paradigm that provides excellent globally consistent, albeit not exactly localized, matches. This is followed by a local feature refinement stage using well-motivated robust regression losses, yielding extremely precise matches. Our proposed approach, which we call RoMa, achieves significant improvements compared to the state-of-the-art. Code is available at https://github.com/Parskatt/RoMa ",
    "url": "https://arxiv.org/abs/2305.15404",
    "authors": [
      "Johan Edstedt",
      "Qiyu Sun",
      "Georg B\u00f6kman",
      "M\u00e5rten Wadenb\u00e4ck",
      "Michael Felsberg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14361",
    "title": "Criticality Analysis: Bio-inspired Nonlinear Data Representation",
    "abstract": "The representation of arbitrary data in a biological system is one of the most elusive elements of biological information processing. The often logarithmic nature of information in amplitude and frequency presented to biosystems prevents simple encapsulation of the information contained in the input. Criticality Analysis (CA) is a bio-inspired method of information representation within a controlled self-organised critical system that allows scale-free representation. This is based on the concept of a reservoir of dynamic behaviour in which self-similar data will create dynamic nonlinear representations. This unique projection of data preserves the similarity of data within a multidimensional neighbourhood. The input can be reduced dimensionally to a projection output that retains the features of the overall data, yet has much simpler dynamic response. The method depends only on the rate control of chaos applied to the underlying controlled models, that allows the encoding of arbitrary data, and promises optimal encoding of data given biological relevant networks of oscillators. The CA method allows for a biologically relevant encoding mechanism of arbitrary input to biosystems, creating a suitable model for information processing in varying complexity of organisms and scale-free data representation for machine learning. ",
    "url": "https://arxiv.org/abs/2305.14361",
    "authors": [
      "Tjeerd V. olde Scheper"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14368",
    "title": "Support for Stock Trend Prediction Using Transformers and Sentiment  Analysis",
    "abstract": "Stock trend analysis has been an influential time-series prediction topic due to its lucrative and inherently chaotic nature. Many models looking to accurately predict the trend of stocks have been based on Recurrent Neural Networks (RNNs). However, due to the limitations of RNNs, such as gradient vanish and long-term dependencies being lost as sequence length increases, in this paper we develop a Transformer based model that uses technical stock data and sentiment analysis to conduct accurate stock trend prediction over long time windows. This paper also introduces a novel dataset containing daily technical stock data and top news headline data spanning almost three years. Stock prediction based solely on technical data can suffer from lag caused by the inability of stock indicators to effectively factor in breaking market news. The use of sentiment analysis on top headlines can help account for unforeseen shifts in market conditions caused by news coverage. We measure the performance of our model against RNNs over sequence lengths spanning 5 business days to 30 business days to mimic different length trading strategies. This reveals an improvement in directional accuracy over RNNs as sequence length is increased, with the largest improvement being close to 18.63% at 30 business days. ",
    "url": "https://arxiv.org/abs/2305.14368",
    "authors": [
      "Harsimrat Kaeley",
      "Ye Qiao",
      "Nader Bagherzadeh"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14370",
    "title": "A Survey on the Role of Artificial Intelligence in the Prediction and  Diagnosis of Schizophrenia",
    "abstract": "Machine learning is employed in healthcare to draw approximate conclusions regarding human diseases and mental health problems. Compared to older traditional methods, it can help to analyze data more efficiently and produce better and more dependable results. Millions of people are affected by schizophrenia, which is a chronic mental disorder that can significantly impact their lives. Many machine learning algorithms have been developed to predict and prevent this disease, and they can potentially be implemented in the diagnosis of individuals who have it. This survey aims to review papers that have focused on the use of deep learning to detect and predict schizophrenia using EEG signals, functional magnetic resonance imaging (fMRI), and diffusion magnetic resonance imaging (dMRI). With our chosen search strategy, we assessed ten publications from 2019 to 2022. All studies achieved successful predictions of more than 80%. This review provides summaries of the studies and compares their notable aspects. In the field of artificial intelligence (AI) and machine learning (ML) for schizophrenia, significant advances have been made due to the availability of ML tools, and we are optimistic that this field will continue to grow. ",
    "url": "https://arxiv.org/abs/2305.14370",
    "authors": [
      "Narges Ramesh",
      "Yasmin Ghodsi",
      "Hamidreza Bolhasani"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.14372",
    "title": "Performance assessment of vehicle interdiction strategies in a  simulation based environment on a complex transportation network",
    "abstract": "We consider the escape interdiction problem in a transportation network. In the absence of traffic in the network, the criminal/attacker tries to escape from the city using any of the shortest paths from the crime scene to any randomly chosen exit point. In the presence of traffic, the attacker chooses the optimal path, which takes minimum time to reach his destination. On the contrary, police/defenders try to interdict the criminal on his escape route. This is a challenging task for police with limited resources. Again, a real city road network is also complex in nature. First, we develop a simulation-based model for the optimal allocation of resources using the SUMO simulator. Next, we focus on developing a more advanced search strategy like routing with optimal resource allocation. We develop a novel meta-heuristic approach in a simulation environment to interdict the attacker in a dynamic crime scenario. Like the previous approach, the attacker follows the path with optimal time to escape from the city. In contrast, defenders try to catch the attacker regardless of the path which the attacker takes. The defenders aim is to maximize the interdiction probability. As time plays a vital role, we choose a meta-heuristic approach to provide quality solutions in a time-efficient manner. We test the developed meta-heuristic with a case study on the IIT Kharagpur map, India. We analyze the performance of the mentioned approaches using the SUMO simulator both in the presence of traffic and without traffic. We develop a linear regression model to generate optimal path in the presence of traffic. Here traffic is generated randomly in the whole network using the SUMO simulator. ",
    "url": "https://arxiv.org/abs/2305.14372",
    "authors": [
      "Sukanya Samanta",
      "Jatin Uniyal",
      "Goutam Sen",
      "Soumya Kanti Ghosh"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.14376",
    "title": "PTGB: Pre-Train Graph Neural Networks for Brain Network Analysis",
    "abstract": "The human brain is the central hub of the neurobiological system, controlling behavior and cognition in complex ways. Recent advances in neuroscience and neuroimaging analysis have shown a growing interest in the interactions between brain regions of interest (ROIs) and their impact on neural development and disorder diagnosis. As a powerful deep model for analyzing graph-structured data, Graph Neural Networks (GNNs) have been applied for brain network analysis. However, training deep models requires large amounts of labeled data, which is often scarce in brain network datasets due to the complexities of data acquisition and sharing restrictions. To make the most out of available training data, we propose PTGB, a GNN pre-training framework that captures intrinsic brain network structures, regardless of clinical outcomes, and is easily adaptable to various downstream tasks. PTGB comprises two key components: (1) an unsupervised pre-training technique designed specifically for brain networks, which enables learning from large-scale datasets without task-specific labels; (2) a data-driven parcellation atlas mapping pipeline that facilitates knowledge transfer across datasets with different ROI systems. Extensive evaluations using various GNN models have demonstrated the robust and superior performance of PTGB compared to baseline methods. ",
    "url": "https://arxiv.org/abs/2305.14376",
    "authors": [
      "Yi Yang",
      "Hejie Cui",
      "Carl Yang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14378",
    "title": "Predicting Stock Market Time-Series Data using CNN-LSTM Neural Network  Model",
    "abstract": "Stock market is often important as it represents the ownership claims on businesses. Without sufficient stocks, a company cannot perform well in finance. Predicting a stock market performance of a company is nearly hard because every time the prices of a company stock keeps changing and not constant. So, its complex to determine the stock data. But if the previous performance of a company in stock market is known, then we can track the data and provide predictions to stockholders in order to wisely take decisions on handling the stocks to a company. To handle this, many machine learning models have been invented but they didn't succeed due to many reasons like absence of advanced libraries, inaccuracy of model when made to train with real time data and much more. So, to track the patterns and the features of data, a CNN-LSTM Neural Network can be made. Recently, CNN is now used in Natural Language Processing (NLP) based applications, so by identifying the features from stock data and converting them into tensors, we can obtain the features and then send it to LSTM neural network to find the patterns and thereby predicting the stock market for given period of time. The accuracy of the CNN-LSTM NN model is found to be high even when allowed to train on real-time stock market data. This paper describes about the features of the custom CNN-LSTM model, experiments we made with the model (like training with stock market datasets, performance comparison with other models) and the end product we obtained at final stage. ",
    "url": "https://arxiv.org/abs/2305.14378",
    "authors": [
      "Aadhitya A",
      "Rajapriya R",
      "Vineetha R S",
      "Anurag M Bagde"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14382",
    "title": "Stock and market index prediction using Informer network",
    "abstract": "Applications of deep learning in financial market prediction has attracted huge attention from investors and researchers. In particular, intra-day prediction at the minute scale, the dramatically fluctuating volume and stock prices within short time periods have posed a great challenge for the convergence of networks result. Informer is a more novel network, improved on Transformer with smaller computational complexity, longer prediction length and global time stamp features. We have designed three experiments to compare Informer with the commonly used networks LSTM, Transformer and BERT on 1-minute and 5-minute frequencies for four different stocks/ market indices. The prediction results are measured by three evaluation criteria: MAE, RMSE and MAPE. Informer has obtained best performance among all the networks on every dataset. Network without the global time stamp mechanism has significantly lower prediction effect compared to the complete Informer; it is evident that this mechanism grants the time series to the characteristics and substantially improves the prediction accuracy of the networks. Finally, transfer learning capability experiment is conducted, Informer also achieves a good performance. Informer has good robustness and improved performance in market prediction, which can be exactly adapted to real trading. ",
    "url": "https://arxiv.org/abs/2305.14382",
    "authors": [
      "Yuze Lu",
      "Hailong Zhang",
      "Qiwen Guo"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14404",
    "title": "Brain Structure-Function Fusing Representation Learning using  Adversarial Decomposed-VAE for Analyzing MCI",
    "abstract": "Integrating the brain structural and functional connectivity features is of great significance in both exploring brain science and analyzing cognitive impairment clinically. However, it remains a challenge to effectively fuse structural and functional features in exploring the brain network. In this paper, a novel brain structure-function fusing-representation learning (BSFL) model is proposed to effectively learn fused representation from diffusion tensor imaging (DTI) and resting-state functional magnetic resonance imaging (fMRI) for mild cognitive impairment (MCI) analysis. Specifically, the decomposition-fusion framework is developed to first decompose the feature space into the union of the uniform and the unique spaces for each modality, and then adaptively fuse the decomposed features to learn MCI-related representation. Moreover, a knowledge-aware transformer module is designed to automatically capture local and global connectivity features throughout the brain. Also, a uniform-unique contrastive loss is further devised to make the decomposition more effective and enhance the complementarity of structural and functional features. The extensive experiments demonstrate that the proposed model achieves better performance than other competitive methods in predicting and analyzing MCI. More importantly, the proposed model could be a potential tool for reconstructing unified brain networks and predicting abnormal connections during the degenerative processes in MCI. ",
    "url": "https://arxiv.org/abs/2305.14404",
    "authors": [
      "Qiankun Zuo",
      "Baiying Lei",
      "Ning Zhong",
      "Yi Pan",
      "Shuqiang Wang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.14448",
    "title": "Robust non-computability and stability of dynamical systems",
    "abstract": "In this paper, we examine the relationship between the stability of the dynamical system $x^{\\prime}=f(x)$ and the computability of its basins of attraction. We present a computable $C^{\\infty}$ system $x^{\\prime}=f(x)$ that possesses a computable and stable equilibrium point, yet whose basin of attraction is robustly non-computable in a neighborhood of $f$ in the sense that both the equilibrium point and the non-computability of its associated basin of attraction persist when $f$ is slightly perturbed. This indicates that local stability near a stable equilibrium point alone is insufficient to guarantee the computability of its basin of attraction. However, we also demonstrate that the basins of attraction associated with a structurally stable - globally stable - planar system are computable. Our findings suggest that the global stability of a system plays a pivotal role in determining the computability of its basins of attraction. ",
    "url": "https://arxiv.org/abs/2305.14448",
    "authors": [
      "Daniel S. Gra\u00e7a",
      "Ning Zhong"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2305.14512",
    "title": "Robust Cooperative Output Regulation for Networks of Hyperbolic PIDE-ODE  Systems",
    "abstract": "In this paper the robust cooperative output regulation problem for multi-agent systems (MAS) with general heterodirectional hyperbolic PIDE-ODE agents is considered. This setup also covers networks of ODEs with arbitrarily long input and output delays. The output of the agents can be defined at all boundaries, in-domain and may depend on the ODE state, while disturbances act on the agents in-domain, at the boundaries, the output and the ODE. The communication network is described by a constant digraph and if its Laplacian is reducible, then heterogeneous agents are permitted also in the nominal case. The solution is based on the cooperative internal model principle, which requires to include a diffusively driven internal model in the controller. The corresponding state feedback regulator design starts with a local backstepping stabilization of the coupled hyperbolic PIDE-ODE systems. It is shown that the remaining simultaneous stabilization of the MAS can be traced back to the simultaneous stabilization of the finite-dimensional cooperative internal model. Solvability conditions in terms of the network topology and the agents transfer behavior are presented. The new design method is applied to the formation control of a platoon of uncertain heavy ropes carrying loads to verify its applicability. Simulations confirm the synchronization performance achieved by the resulting networked controller. ",
    "url": "https://arxiv.org/abs/2305.14512",
    "authors": [
      "Jakob Gabriel",
      "Joachim Deutscher"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.14673",
    "title": "ORRN: An ODE-based Recursive Registration Network for Deformable  Respiratory Motion Estimation with Lung 4DCT Images",
    "abstract": "Deformable Image Registration (DIR) plays a significant role in quantifying deformation in medical data. Recent Deep Learning methods have shown promising accuracy and speedup for registering a pair of medical images. However, in 4D (3D + time) medical data, organ motion, such as respiratory motion and heart beating, can not be effectively modeled by pair-wise methods as they were optimized for image pairs but did not consider the organ motion patterns necessary when considering 4D data. This paper presents ORRN, an Ordinary Differential Equations (ODE)-based recursive image registration network. Our network learns to estimate time-varying voxel velocities for an ODE that models deformation in 4D image data. It adopts a recursive registration strategy to progressively estimate a deformation field through ODE integration of voxel velocities. We evaluate the proposed method on two publicly available lung 4DCT datasets, DIRLab and CREATIS, for two tasks: 1) registering all images to the extreme inhale image for 3D+t deformation tracking and 2) registering extreme exhale to inhale phase images. Our method outperforms other learning-based methods in both tasks, producing the smallest Target Registration Error of 1.24mm and 1.26mm, respectively. Additionally, it produces less than 0.001\\% unrealistic image folding, and the computation speed is less than 1 second for each CT volume. ORRN demonstrates promising registration accuracy, deformation plausibility, and computation efficiency on group-wise and pair-wise registration tasks. It has significant implications in enabling fast and accurate respiratory motion estimation for treatment planning in radiation therapy or robot motion planning in thoracic needle insertion. ",
    "url": "https://arxiv.org/abs/2305.14673",
    "authors": [
      "Xiao Liang",
      "Shan Lin",
      "Dimitri Schreiber",
      "Michael Yip"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14723",
    "title": "Downstream Task Agnostic Speech Enhancement with Self-Supervised  Representation Loss",
    "abstract": "Self-supervised learning (SSL) is the latest breakthrough in speech processing, especially for label-scarce downstream tasks by leveraging massive unlabeled audio data. The noise robustness of the SSL is one of the important challenges to expanding its application. We can use speech enhancement (SE) to tackle this issue. However, the mismatch between the SE model and SSL models potentially limits its effect. In this work, we propose a new SE training criterion that minimizes the distance between clean and enhanced signals in the feature representation of the SSL model to alleviate the mismatch. We expect that the loss in the SSL domain could guide SE training to preserve or enhance various levels of characteristics of the speech signals that may be required for high-level downstream tasks. Experiments show that our proposal improves the performance of an SE and SSL pipeline on five downstream tasks with noisy input while maintaining the SE performance. ",
    "url": "https://arxiv.org/abs/2305.14723",
    "authors": [
      "Hiroshi Sato",
      "Ryo Masumura",
      "Tsubasa Ochiai",
      "Marc Delcroix",
      "Takafumi Moriya",
      "Takanori Ashihara",
      "Kentaro Shinayama",
      "Saki Mizuno",
      "Mana Ihori",
      "Tomohiro Tanaka",
      "Nobukatsu Hojo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.14764",
    "title": "Detection of Non-uniformity in Parameters for Magnetic Domain Pattern  Generation by Machine Learning",
    "abstract": "We attempt to estimate the spatial distribution of heterogeneous physical parameters involved in the formation of magnetic domain patterns of polycrystalline thin films by using convolutional neural networks. We propose a method to obtain a spatial map of physical parameters by estimating the parameters from patterns within a small subregion window of the full magnetic domain and subsequently shifting this window. To enhance the accuracy of parameter estimation in such subregions, we employ employ large-scale models utilized for natural image classification and exploit the benefits of pretraining. Using a model with high estimation accuracy on these subregions, we conduct inference on simulation data featuring spatially varying parameters and demonstrate the capability to detect such parameter variations. ",
    "url": "https://arxiv.org/abs/2305.14764",
    "authors": [
      "Naoya Mamada",
      "Masaichiro Mizumaki",
      "Ichiro Akai",
      "Toru Aonishi"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14765",
    "title": "Masked Bayesian Neural Networks : Theoretical Guarantee and its  Posterior Inference",
    "abstract": "Bayesian approaches for learning deep neural networks (BNN) have been received much attention and successfully applied to various applications. Particularly, BNNs have the merit of having better generalization ability as well as better uncertainty quantification. For the success of BNN, search an appropriate architecture of the neural networks is an important task, and various algorithms to find good sparse neural networks have been proposed. In this paper, we propose a new node-sparse BNN model which has good theoretical properties and is computationally feasible. We prove that the posterior concentration rate to the true model is near minimax optimal and adaptive to the smoothness of the true model. In particular the adaptiveness is the first of its kind for node-sparse BNNs. In addition, we develop a novel MCMC algorithm which makes the Bayesian inference of the node-sparse BNN model feasible in practice. ",
    "url": "https://arxiv.org/abs/2305.14765",
    "authors": [
      "Insung Kong",
      "Dongyoon Yang",
      "Jongjin Lee",
      "Ilsang Ohn",
      "Gyuseung Baek",
      "Yongdai Kim"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14778",
    "title": "P-vectors: A Parallel-Coupled TDNN/Transformer Network for Speaker  Verification",
    "abstract": "Typically, the Time-Delay Neural Network (TDNN) and Transformer can serve as a backbone for Speaker Verification (SV). Both of them have advantages and disadvantages from the perspective of global and local feature modeling. How to effectively integrate these two style features is still an open issue. In this paper, we explore a Parallel-coupled TDNN/Transformer Network (p-vectors) to replace the serial hybrid networks. The p-vectors allows TDNN and Transformer to learn the complementary information from each other through Soft Feature Alignment Interaction (SFAI) under the premise of preserving local and global features. Also, p-vectors uses the Spatial Frequency-channel Attention (SFA) to enhance the spatial interdependence modeling for input features. Finally, the outputs of dual branches of p-vectors are combined by Embedding Aggregation Layer (EAL). Experiments show that p-vectors outperforms MACCIF-TDNN and MFA-Conformer with relative improvements of 11.5% and 13.9% in EER on VoxCeleb1-O. ",
    "url": "https://arxiv.org/abs/2305.14778",
    "authors": [
      "Xiyuan wang",
      "Fangyuan Wang",
      "Bo Xu",
      "Liang Xu",
      "Jing Xiao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.15027",
    "title": "A Rigorous Link between Deep Ensembles and (Variational) Bayesian  Methods",
    "abstract": "We establish the first mathematically rigorous link between Bayesian, variational Bayesian, and ensemble methods. A key step towards this it to reformulate the non-convex optimisation problem typically encountered in deep learning as a convex optimisation in the space of probability measures. On a technical level, our contribution amounts to studying generalised variational inference through the lense of Wasserstein gradient flows. The result is a unified theory of various seemingly disconnected approaches that are commonly used for uncertainty quantification in deep learning -- including deep ensembles and (variational) Bayesian methods. This offers a fresh perspective on the reasons behind the success of deep ensembles over procedures based on parameterised variational inference, and allows the derivation of new ensembling schemes with convergence guarantees. We showcase this by proposing a family of interacting deep ensembles with direct parallels to the interactions of particle systems in thermodynamics, and use our theory to prove the convergence of these algorithms to a well-defined global minimiser on the space of probability measures. ",
    "url": "https://arxiv.org/abs/2305.15027",
    "authors": [
      "Veit David Wild",
      "Sahra Ghalebikesabi",
      "Dino Sejdinovic",
      "Jeremias Knoblauch"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2305.15110",
    "title": "Intersection of Longest Cycle and Largest Bond in 3-Connected Graphs",
    "abstract": "A bond in a graph is a minimal nonempty edge-cut. A connected graph $G$ is dual Hamiltonian if the vertex set can be partitioned into two subsets $X$ and $Y$ such that the subgraphs induced by $X$ and $Y$ are both trees. There is much interest in studying the longest cycles and largest bonds in graphs. H. Wu conjectured that any longest cycle must meet any largest bond in a simple 3-connected graph. In this paper, the author proves that the above conjecture is true for certain classes of 3-connected graphs: Let $G$ be a simple 3-connected graph with $n$ vertices and $m$ edges. Suppose $c(G)$ is the size of a longest cycle, and $c^*(G)$ is the size of a largest bond. Then each longest cycle meets each largest bond if either $c(G) \\geq n - 3$ or $c^*(G) \\geq m - n - 1$. Sanford determined in her Ph.D. thesis the cycle spectrum of the well-known generalized Petersen graph $P(n, 2)$ ($n$ is odd) and $P(n, 3)$ ($n$ is even). Flynn proved in her honors thesis that any generalized Petersen graph $P(n, k)$ is dual Hamiltonian. The author studies the bond spectrum (called the co-spectrum) of the generalized Petersen graphs and extends Flynn's result by proving that in any generalized Petersen graph $P(n, k)$, $1 \\leq k < \\frac{n}{2}$, the co-spectrum of $P(n, k)$ is $\\{3, 4, 5, ..., n+2\\}$. ",
    "url": "https://arxiv.org/abs/2305.15110",
    "authors": [
      "Emily Ren"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2305.15132",
    "title": "Rooted Almost-binary Phylogenetic Networks for which the Maximum  Covering Subtree Problem is Solvable in Linear Time",
    "abstract": "Phylogenetic networks are a flexible model of evolution that can represent reticulate evolution and handle complex data. Tree-based networks, which are phylogenetic networks that have a spanning tree with the same root and leaf-set as the network itself, have been well studied. However, not all networks are tree-based. Francis-Semple-Steel (2018) thus introduced several indices to measure the deviation of rooted binary phylogenetic networks $N$ from being tree-based, such as the minimum number $\\delta^\\ast(N)$ of additional leaves needed to make $N$ tree-based, and the minimum difference $\\eta^\\ast(N)$ between the number of vertices of $N$ and the number of vertices of a subtree of $N$ that shares the root and leaf set with $N$. Hayamizu (2021) has established a canonical decomposition of almost-binary phylogenetic networks of $N$, called the maximal zig-zag trail decomposition, which has many implications including a linear time algorithm for computing $\\delta^\\ast(N)$. The Maximum Covering Subtree Problem (MCSP) is the problem of computing $\\eta^\\ast(N)$, and Davidov et al. (2022) showed that this can be solved in polynomial time (in cubic time when $N$ is binary) by an algorithm for the minimum cost flow problem. In this paper, under the assumption that $N$ is almost-binary (i.e. each internal vertex has in-degree and out-degree at most two), we show that $\\delta^\\ast(N)\\leq \\eta^\\ast (N)$ holds, which is tight, and give a characterisation of such phylogenetic networks $N$ that satisfy $\\delta^\\ast(N)=\\eta^\\ast(N)$. Our approach uses the canonical decomposition of $N$ and focuses on how the maximal W-fences (i.e. the forbidden subgraphs of tree-based networks) are connected to maximal M-fences in the network $N$. Our results introduce a new class of phylogenetic networks for which MCSP can be solved in linear time, which can be seen as a generalisation of tree-based networks. ",
    "url": "https://arxiv.org/abs/2305.15132",
    "authors": [
      "Takatora Suzuki",
      "Han Guo",
      "Momoko Hayamizu"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2305.15136",
    "title": "ReSync: Riemannian Subgradient-based Robust Rotation Synchronization",
    "abstract": "This work presents ReSync, a Riemannian subgradient-based algorithm for solving the robust rotation synchronization problem, which arises in various engineering applications. ReSync solves a least-unsquared minimization formulation over the rotation group, which is nonsmooth and nonconvex, and aims at recovering the underlying rotations directly. We provide strong theoretical guarantees for ReSync under the random corruption setting. Specifically, we first show that the initialization procedure of ReSync yields a proper initial point that lies in a local region around the ground-truth rotations. We next establish the weak sharpness property of the aforementioned formulation and then utilize this property to derive the local linear convergence of ReSync to the ground-truth rotations. By combining these guarantees, we conclude that ReSync converges linearly to the ground-truth rotations under appropriate conditions. Experiment results demonstrate the effectiveness of ReSync. ",
    "url": "https://arxiv.org/abs/2305.15136",
    "authors": [
      "Huikang Liu",
      "Xiao Li",
      "Anthony Man-Cho So"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15297",
    "title": "Strong blocking sets and minimal codes from expander graphs",
    "abstract": "A strong blocking set in a finite projective space is a set of points that intersects each hyperplane in a spanning set. We provide a new graph theoretic construction of such sets: combining constant-degree expanders with asymptotically good codes, we explicitly construct strong blocking sets in the $(k-1)$-dimensional projective space over $\\mathbb{F}_q$ that have size $O( q k )$. Since strong blocking sets have recently been shown to be equivalent to minimal linear codes, our construction gives the first explicit construction of $\\mathbb{F}_q$-linear minimal codes of length $n$ and dimension $k$, for every prime power $q$, for which $n = O (q k)$. This solves one of the main open problems on minimal codes. ",
    "url": "https://arxiv.org/abs/2305.15297",
    "authors": [
      "Noga Alon",
      "Anurag Bishnoi",
      "Shagnik Das",
      "Alessandro Neri"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.15317",
    "title": "On the robust learning mixtures of linear regressions",
    "abstract": "In this note, we consider the problem of robust learning mixtures of linear regressions. We connect mixtures of linear regressions and mixtures of Gaussians with a simple thresholding, so that a quasi-polynomial time algorithm can be obtained under some mild separation condition. This algorithm has significantly better robustness than the previous result. ",
    "url": "https://arxiv.org/abs/2305.15317",
    "authors": [
      "Ying Huang",
      "Liang Chen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15385",
    "title": "Behavior quantification as the missing link between fields: Tools for  digital psychiatry and their role in the future of neurobiology",
    "abstract": "The great behavioral heterogeneity observed between individuals with the same psychiatric disorder and even within one individual over time complicates both clinical practice and biomedical research. However, modern technologies are an exciting opportunity to improve behavioral characterization. Existing psychiatry methods that are qualitative or unscalable, such as patient surveys or clinical interviews, can now be collected at a greater capacity and analyzed to produce new quantitative measures. Furthermore, recent capabilities for continuous collection of passive sensor streams, such as phone GPS or smartwatch accelerometer, open avenues of novel questioning that were previously entirely unrealistic. Their temporally dense nature enables a cohesive study of real-time neural and behavioral signals. To develop comprehensive neurobiological models of psychiatric disease, it will be critical to first develop strong methods for behavioral quantification. There is huge potential in what can theoretically be captured by current technologies, but this in itself presents a large computational challenge -- one that will necessitate new data processing tools, new machine learning techniques, and ultimately a shift in how interdisciplinary work is conducted. In my thesis, I detail research projects that take different perspectives on digital psychiatry, subsequently tying ideas together with a concluding discussion on the future of the field. I also provide software infrastructure where relevant, with extensive documentation. Major contributions include scientific arguments and proof of concept results for daily free-form audio journals as an underappreciated psychiatry research datatype, as well as novel stability theorems and pilot empirical success for a proposed multi-area recurrent neural network architecture. ",
    "url": "https://arxiv.org/abs/2305.15385",
    "authors": [
      "Michaela Ennis"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2105.08037",
    "title": "Adversarial Training for Gradient Descent: Analysis Through its  Continuous-time Approximation",
    "abstract": " Title: Adversarial Training for Gradient Descent: Analysis Through its  Continuous-time Approximation ",
    "url": "https://arxiv.org/abs/2105.08037",
    "authors": [
      "Haotian Gu",
      "Xin Guo",
      "Xinyu Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2106.01474",
    "title": "Testing Directed Acyclic Graph via Structural, Supervised and Generative  Adversarial Learning",
    "abstract": " Title: Testing Directed Acyclic Graph via Structural, Supervised and Generative  Adversarial Learning ",
    "url": "https://arxiv.org/abs/2106.01474",
    "authors": [
      "Chengchun Shi",
      "Yunzhe Zhou",
      "Lexin Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.01876",
    "title": "Which Invariance Should We Transfer? A Causal Minimax Learning Approach",
    "abstract": " Comments: Accepted version of ICML-23 ",
    "url": "https://arxiv.org/abs/2107.01876",
    "authors": [
      "Mingzhou Liu",
      "Xiangyu Zheng",
      "Xinwei Sun",
      "Fang Fang",
      "Yizhou Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.11619",
    "title": "Positive First-order Logic on Words and Graphs",
    "abstract": " Comments: LMCS, extended version of LICS 2021 published at arXiv:2101.01968 ",
    "url": "https://arxiv.org/abs/2201.11619",
    "authors": [
      "Denis Kuperberg"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ]
  },
  {
    "id": "arXiv:2202.07255",
    "title": "Enhancing Cross-lingual Prompting with Dual Prompt Augmentation",
    "abstract": " Comments: ACL 2023 Findings ",
    "url": "https://arxiv.org/abs/2202.07255",
    "authors": [
      "Meng Zhou",
      "Xin Li",
      "Yue Jiang",
      "Lidong Bing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.01478",
    "title": "Eigenvector centrality for multilayer networks with dependent node  importance",
    "abstract": " Title: Eigenvector centrality for multilayer networks with dependent node  importance ",
    "url": "https://arxiv.org/abs/2205.01478",
    "authors": [
      "H. Robert Frost"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2205.02919",
    "title": "Action Languages Based Actual Causality for Computational Ethics: a  Sound and Complete Implementation in ASP",
    "abstract": " Comments: 22 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2205.02919",
    "authors": [
      "Camilo Sarmiento",
      "Gauvain Bourgne",
      "Katsumi Inoue",
      "Daniele Cavalli",
      "Jean-Gabriel Ganascia"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.10621",
    "title": "Learning Meta Representations of One-shot Relations for Temporal  Knowledge Graph Link Prediction",
    "abstract": " Comments: IJCNN 2023 oral ",
    "url": "https://arxiv.org/abs/2205.10621",
    "authors": [
      "Zifeng Ding",
      "Bailan He",
      "Yunpu Ma",
      "Zhen Han",
      "Volker Tresp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.07012",
    "title": "Frequency Throttling Side-Channel Attack",
    "abstract": " Title: Frequency Throttling Side-Channel Attack ",
    "url": "https://arxiv.org/abs/2206.07012",
    "authors": [
      "Chen Liu",
      "Abhishek Chakraborty",
      "Nikhil Chawla",
      "Neer Roggel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.10949",
    "title": "Maximizing Nash Social Welfare in 2-Value Instances: Delineating  Tractability",
    "abstract": " Title: Maximizing Nash Social Welfare in 2-Value Instances: Delineating  Tractability ",
    "url": "https://arxiv.org/abs/2207.10949",
    "authors": [
      "Hannaneh Akrami",
      "Bhaskar Ray Chaudhury",
      "Martin Hoefer",
      "Kurt Mehlhorn",
      "Marco Schmalhofer",
      "Golnoosh Shahkarami",
      "Giovanna Varricchio",
      "Quentin Vermande",
      "Ernest van Wijland"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2207.14138",
    "title": "Generating Teammates for Training Robust Ad Hoc Teamwork Agents via  Best-Response Diversity",
    "abstract": " Comments: Accepted in Transactions of Machine Learning Research ",
    "url": "https://arxiv.org/abs/2207.14138",
    "authors": [
      "Arrasy Rahman",
      "Elliot Fosong",
      "Ignacio Carlucho",
      "Stefano V. Albrecht"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.01470",
    "title": "Extremal numbers of disjoint triangles in $r$-partite graphs",
    "abstract": " Title: Extremal numbers of disjoint triangles in $r$-partite graphs ",
    "url": "https://arxiv.org/abs/2208.01470",
    "authors": [
      "Junxue Zhang"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2209.00957",
    "title": "Cohomology of the discrete de Rham complex on domains of general  topology",
    "abstract": " Title: Cohomology of the discrete de Rham complex on domains of general  topology ",
    "url": "https://arxiv.org/abs/2209.00957",
    "authors": [
      "Daniele A. Di Pietro",
      "J\u00e9r\u00f4me Droniou",
      "Silvano Pitassi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2209.15240",
    "title": "Universal Prompt Tuning for Graph Neural Networks",
    "abstract": " Title: Universal Prompt Tuning for Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2209.15240",
    "authors": [
      "Taoran Fang",
      "Yunchao Zhang",
      "Yang Yang",
      "Chunping Wang",
      "Lei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.01703",
    "title": "Improving Label-Deficient Keyword Spotting Through Self-Supervised  Pretraining",
    "abstract": " Comments: To be published at ICASSP2023 Workshop on Self-supervision in Audio, Speech and Beyond, 10th of June 2023, Rhodes, Greece. Copyright (c) 2023 IEEE. 5 pages, 3 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2210.01703",
    "authors": [
      "Holger Severin Bovbjerg",
      "Zheng-Hua Tan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.02753",
    "title": "Community as a Vague Operator: Epistemological Questions for a Critical  Heuristics of Community Detection Algorithms",
    "abstract": " Comments: 31 pages, 3 figures; parts of this article were presented in seminars at the Centre for Digital Inquiry at Warwick University and the Digital Democracies Institute at Simon Fraser University ",
    "url": "https://arxiv.org/abs/2210.02753",
    "authors": [
      "Dominik J. Schindler",
      "Matthew Fuller"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2210.12257",
    "title": "Efficient Automatic Machine Learning via Design Graphs",
    "abstract": " Comments: NeurIPS 2022 New Frontiers in Graph Learning Workshop (NeurIPS GLFrontiers 2022). 20 Pages ",
    "url": "https://arxiv.org/abs/2210.12257",
    "authors": [
      "Shirley Wu",
      "Jiaxuan You",
      "Jure Leskovec",
      "Rex Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.15034",
    "title": "InfoShape: Task-Based Neural Data Shaping via Mutual Information",
    "abstract": " Comments: 5 pages, IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) ",
    "url": "https://arxiv.org/abs/2210.15034",
    "authors": [
      "Homa Esfahanizadeh",
      "William Wu",
      "Manya Ghobadi",
      "Regina Barzilay",
      "Muriel Medard"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.06989",
    "title": "Autovocoder: Fast Waveform Generation from a Learned Speech  Representation using Differentiable Digital Signal Processing",
    "abstract": " Comments: Accepted to the 2023 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2023) ",
    "url": "https://arxiv.org/abs/2211.06989",
    "authors": [
      "Jacob J Webber",
      "Cassia Valentini-Botinhao",
      "Evelyn Williams",
      "Gustav Eje Henter",
      "Simon King"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.09710",
    "title": "Style Classification of Rabbinic Literature for Detection of Lost  Midrash Tanhuma Material",
    "abstract": " Title: Style Classification of Rabbinic Literature for Detection of Lost  Midrash Tanhuma Material ",
    "url": "https://arxiv.org/abs/2211.09710",
    "authors": [
      "Shlomo Tannor",
      "Nachum Dershowitz",
      "Moshe Lavee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11300",
    "title": "Multi-Level Knowledge Distillation for Out-of-Distribution Detection in  Text",
    "abstract": " Comments: ACL 2023. Our code is available at: this https URL ",
    "url": "https://arxiv.org/abs/2211.11300",
    "authors": [
      "Qianhui Wu",
      "Huiqiang Jiang",
      "Haonan Yin",
      "B\u00f6rje F. Karlsson",
      "Chin-Yew Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.11907",
    "title": "Robust Faber--Schauder approximation based on discrete observations of  an antiderivative",
    "abstract": " Title: Robust Faber--Schauder approximation based on discrete observations of  an antiderivative ",
    "url": "https://arxiv.org/abs/2211.11907",
    "authors": [
      "Xiyue Han",
      "Alexander Schied"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Statistical Finance (q-fin.ST)"
    ]
  },
  {
    "id": "arXiv:2212.10007",
    "title": "CoCoMIC: Code Completion By Jointly Modeling In-file and Cross-file  Context",
    "abstract": " Title: CoCoMIC: Code Completion By Jointly Modeling In-file and Cross-file  Context ",
    "url": "https://arxiv.org/abs/2212.10007",
    "authors": [
      "Yangruibo Ding",
      "Zijian Wang",
      "Wasi Uddin Ahmad",
      "Murali Krishna Ramanathan",
      "Ramesh Nallapati",
      "Parminder Bhatia",
      "Dan Roth",
      "Bing Xiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2212.10465",
    "title": "SODA: Million-scale Dialogue Distillation with Social Commonsense  Contextualization",
    "abstract": " Comments: Dataset, model, and code can be found at this https URL ",
    "url": "https://arxiv.org/abs/2212.10465",
    "authors": [
      "Hyunwoo Kim",
      "Jack Hessel",
      "Liwei Jiang",
      "Peter West",
      "Ximing Lu",
      "Youngjae Yu",
      "Pei Zhou",
      "Ronan Le Bras",
      "Malihe Alikhani",
      "Gunhee Kim",
      "Maarten Sap",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.08496",
    "title": "Introducing Expertise Logic into Graph Representation Learning from A  Causal Perspective",
    "abstract": " Title: Introducing Expertise Logic into Graph Representation Learning from A  Causal Perspective ",
    "url": "https://arxiv.org/abs/2301.08496",
    "authors": [
      "Hang Gao",
      "Jiangmeng Li",
      "Wenwen Qiang",
      "Lingyu Si",
      "Xingzhe Su",
      "Fengge Wu",
      "Changwen Zheng",
      "Fuchun Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.08918",
    "title": "Revisiting Signed Propagation for Graph Neural Networks",
    "abstract": " Title: Revisiting Signed Propagation for Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2301.08918",
    "authors": [
      "Yoonhyuk Choi",
      "Jiho Choi",
      "Taewook Ko",
      "Chong-Kwon Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2301.13060",
    "title": "Zero-One Laws of Graph Neural Networks",
    "abstract": " Comments: 10 pages + references + 10 pages appendices, 7 figures ",
    "url": "https://arxiv.org/abs/2301.13060",
    "authors": [
      "Sam Adam-Day",
      "Theodor Mihai Iliant",
      "\u0130smail \u0130lkan Ceylan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00617",
    "title": "Learning Large-scale Neural Fields via Context Pruned Meta-Learning",
    "abstract": " Comments: 23 pages ",
    "url": "https://arxiv.org/abs/2302.00617",
    "authors": [
      "Jihoon Tack",
      "Subin Kim",
      "Sihyun Yu",
      "Jaeho Lee",
      "Jinwoo Shin",
      "Jonathan Richard Schwarz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.01060",
    "title": "Physics Constrained Motion Prediction with Uncertainty Quantification",
    "abstract": " Comments: Accepted at IV 2023 ",
    "url": "https://arxiv.org/abs/2302.01060",
    "authors": [
      "Renukanandan Tumu",
      "Lars Lindemann",
      "Truong Nghiem",
      "Rahul Mangharam"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02503",
    "title": "Leaving Reality to Imagination: Robust Classification via Generated  Datasets",
    "abstract": " Comments: 22 pages, 12 Figures, 9 Tables. Results for ImageNet-C, and finetuned generative model are included now ",
    "url": "https://arxiv.org/abs/2302.02503",
    "authors": [
      "Hritik Bansal",
      "Aditya Grover"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2302.02941",
    "title": "On Over-Squashing in Message Passing Neural Networks: The Impact of  Width, Depth, and Topology",
    "abstract": " Comments: Accepted at ICML 2023; 21 pages ",
    "url": "https://arxiv.org/abs/2302.02941",
    "authors": [
      "Francesco Di Giovanni",
      "Lorenzo Giusti",
      "Federico Barbero",
      "Giulia Luise",
      "Pietro Lio'",
      "Michael Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.03596",
    "title": "Graph Generation with Destination-Predicting Diffusion Mixture",
    "abstract": " Title: Graph Generation with Destination-Predicting Diffusion Mixture ",
    "url": "https://arxiv.org/abs/2302.03596",
    "authors": [
      "Jaehyeong Jo",
      "Dongki Kim",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.04264",
    "title": "Nerfstudio: A Modular Framework for Neural Radiance Field Development",
    "abstract": " Comments: Project page at this https URL ",
    "url": "https://arxiv.org/abs/2302.04264",
    "authors": [
      "Matthew Tancik",
      "Ethan Weber",
      "Evonne Ng",
      "Ruilong Li",
      "Brent Yi",
      "Justin Kerr",
      "Terrance Wang",
      "Alexander Kristoffersen",
      "Jake Austin",
      "Kamyar Salahi",
      "Abhik Ahuja",
      "David McAllister",
      "Angjoo Kanazawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2302.04977",
    "title": "Mithridates: Boosting Natural Resistance to Backdoor Learning",
    "abstract": " Title: Mithridates: Boosting Natural Resistance to Backdoor Learning ",
    "url": "https://arxiv.org/abs/2302.04977",
    "authors": [
      "Eugene Bagdasaryan",
      "Vitaly Shmatikov"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.06280",
    "title": "Causal Strategic Classification: A Tale of Two Shifts",
    "abstract": " Title: Causal Strategic Classification: A Tale of Two Shifts ",
    "url": "https://arxiv.org/abs/2302.06280",
    "authors": [
      "Guy Horowitz",
      "Nir Rosenfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.01590",
    "title": "Technical report: Graph Neural Networks go Grammatical",
    "abstract": " Comments: 27 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2303.01590",
    "authors": [
      "Jason Piquenot",
      "Aldo Moscatelli",
      "Maxime B\u00e9rar",
      "Pierre H\u00e9roux",
      "Romain raveaux",
      "Jean-Yves Ramel",
      "S\u00e9bastien Adam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.09026",
    "title": "Commonsense Knowledge Assisted Deep Learning for Resource-constrained  and Fine-grained Object Detection",
    "abstract": " Comments: 15 pages ",
    "url": "https://arxiv.org/abs/2303.09026",
    "authors": [
      "Pu Zhang",
      "Bin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.10974",
    "title": "Translate your gibberish: black-box adversarial attack on machine  translation systems",
    "abstract": " Title: Translate your gibberish: black-box adversarial attack on machine  translation systems ",
    "url": "https://arxiv.org/abs/2303.10974",
    "authors": [
      "Andrei Chertkov",
      "Olga Tsymboi",
      "Mikhail Pautov",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.12212",
    "title": "Community detection in complex networks via node similarity, graph  representation learning, and hierarchical clustering",
    "abstract": " Title: Community detection in complex networks via node similarity, graph  representation learning, and hierarchical clustering ",
    "url": "https://arxiv.org/abs/2303.12212",
    "authors": [
      "\u0141ukasz Brzozowski",
      "Grzegorz Siudem",
      "Marek Gagolewski"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15471",
    "title": "Embedding Contextual Information through Reward Shaping in Multi-Agent  Learning: A Case Study from Google Football",
    "abstract": " Title: Embedding Contextual Information through Reward Shaping in Multi-Agent  Learning: A Case Study from Google Football ",
    "url": "https://arxiv.org/abs/2303.15471",
    "authors": [
      "Chaoyi Gu",
      "Varuna De Silva",
      "Corentin Artaud",
      "Rafael Pina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.15487",
    "title": "Knowledge Enhanced Graph Neural Networks",
    "abstract": " Title: Knowledge Enhanced Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2303.15487",
    "authors": [
      "Luisa Werner",
      "Nabil Laya\u00efda",
      "Pierre Genev\u00e8s",
      "Sarah Chlyah"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Symbolic Computation (cs.SC)"
    ]
  },
  {
    "id": "arXiv:2304.07063",
    "title": "Rethinking Existential First Order Queries and their Inference on  Knowledge Graphs",
    "abstract": " Title: Rethinking Existential First Order Queries and their Inference on  Knowledge Graphs ",
    "url": "https://arxiv.org/abs/2304.07063",
    "authors": [
      "Hang Yin",
      "Zihao Wang",
      "Yangqiu Song"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2304.07305",
    "title": "1-D Residual Convolutional Neural Network coupled with Data Augmentation  and Regularization for the ICPHM 2023 Data Challenge",
    "abstract": " Comments: Accepted at the IEEE Conference on Prognostics and Health Management (ICPHM) 2023 ",
    "url": "https://arxiv.org/abs/2304.07305",
    "authors": [
      "Matthias Kreuzer",
      "Walter Kellermann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2304.07307",
    "title": "Airborne Sound Analysis for the Detection of Bearing Faults in Railway  Vehicles with Real-World Data",
    "abstract": " Comments: Accepted at the ICPHM 2023 ",
    "url": "https://arxiv.org/abs/2304.07307",
    "authors": [
      "Matthias Kreuzer",
      "David Schmidt",
      "Simon Wokusch",
      "Walter Kellermann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2304.07590",
    "title": "Self-collaboration Code Generation via ChatGPT",
    "abstract": " Title: Self-collaboration Code Generation via ChatGPT ",
    "url": "https://arxiv.org/abs/2304.07590",
    "authors": [
      "Yihong Dong",
      "Xue Jiang",
      "Zhi Jin",
      "Ge Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2304.13377",
    "title": "Optimal Fairness Scheduling for Coded Caching in Multi-AP Wireless Local  Area Networks",
    "abstract": " Title: Optimal Fairness Scheduling for Coded Caching in Multi-AP Wireless Local  Area Networks ",
    "url": "https://arxiv.org/abs/2304.13377",
    "authors": [
      "Kagan Akcay",
      "MohammadJavad Salehi",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2304.14774",
    "title": "A feature selection method based on Shapley values robust to concept  shift in regression",
    "abstract": " Title: A feature selection method based on Shapley values robust to concept  shift in regression ",
    "url": "https://arxiv.org/abs/2304.14774",
    "authors": [
      "Carlos Sebasti\u00e1n",
      "Carlos E. Gonz\u00e1lez-Guill\u00e9n"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2305.00832",
    "title": "First- and Second-Order Bounds for Adversarial Linear Contextual Bandits",
    "abstract": " Title: First- and Second-Order Bounds for Adversarial Linear Contextual Bandits ",
    "url": "https://arxiv.org/abs/2305.00832",
    "authors": [
      "Julia Olkhovskaya",
      "Jack Mayo",
      "Tim van Erven",
      "Gergely Neu",
      "Chen-Yu Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.02192",
    "title": "Inverse Global Illumination using a Neural Radiometric Prior",
    "abstract": " Comments: Homepage: this https URL ",
    "url": "https://arxiv.org/abs/2305.02192",
    "authors": [
      "Saeed Hadadan",
      "Geng Lin",
      "Jan Nov\u00e1k",
      "Fabrice Rousselle",
      "Matthias Zwicker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2305.02559",
    "title": "Madvex: Instrumentation-based Adversarial Attacks on Machine Learning  Malware Detection",
    "abstract": " Comments: 20 pages. To be published in The 20th Conference on Detection of Intrusions and Malware & Vulnerability Assessment (DIMVA 2023) ",
    "url": "https://arxiv.org/abs/2305.02559",
    "authors": [
      "Nils Loose",
      "Felix M\u00e4chtle",
      "Claudius Pott",
      "Volodymyr Bezsmertnyi",
      "Thomas Eisenbarth"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.05105",
    "title": "TinyML Design Contest for Life-Threatening Ventricular Arrhythmia  Detection",
    "abstract": " Comments: The paper is about 1st TinyML design contest for healthcare ",
    "url": "https://arxiv.org/abs/2305.05105",
    "authors": [
      "Zhenge Jia",
      "Dawei Li",
      "Cong Liu",
      "Liqi Liao",
      "Xiaowei Xu",
      "Lichuan Ping",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.05276",
    "title": "Causal Discovery from Subsampled Time Series with Proxy Variables",
    "abstract": " Comments: Preprint, under review ",
    "url": "https://arxiv.org/abs/2305.05276",
    "authors": [
      "Mingzhou Liu",
      "Xinwei Sun",
      "Lingjing Hu",
      "Yizhou Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2305.05281",
    "title": "Causal Discovery with Unobserved Variables: A Proxy Variable Approach",
    "abstract": " Comments: Preprint, under review ",
    "url": "https://arxiv.org/abs/2305.05281",
    "authors": [
      "Mingzhou Liu",
      "Xinwei Sun",
      "Yu Qiao",
      "Yizhou Wang"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.06422",
    "title": "An Empirical Study on the Robustness of the Segment Anything Model (SAM)",
    "abstract": " Comments: 27 pages, in submission ",
    "url": "https://arxiv.org/abs/2305.06422",
    "authors": [
      "Yuqing Wang",
      "Yun Zhao",
      "Linda Petzold"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10361",
    "title": "Human Choice Prediction in Language-based Non-Cooperative Games:  Simulation-based Off-Policy Evaluation",
    "abstract": " Title: Human Choice Prediction in Language-based Non-Cooperative Games:  Simulation-based Off-Policy Evaluation ",
    "url": "https://arxiv.org/abs/2305.10361",
    "authors": [
      "Eilam Shapira",
      "Reut Apel",
      "Moshe Tennenholtz",
      "Roi Reichart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2305.10503",
    "title": "OR-NeRF: Object Removing from 3D Scenes Guided by Multiview Segmentation  with Neural Radiance Fields",
    "abstract": " Comments: project site: this https URL (codes availabel) ",
    "url": "https://arxiv.org/abs/2305.10503",
    "authors": [
      "Youtan Yin",
      "Zhoujie Fu",
      "Fan Yang",
      "Guosheng Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10983",
    "title": "Assessor360: Multi-sequence Network for Blind Omnidirectional Image  Quality Assessment",
    "abstract": " Title: Assessor360: Multi-sequence Network for Blind Omnidirectional Image  Quality Assessment ",
    "url": "https://arxiv.org/abs/2305.10983",
    "authors": [
      "Tianhe Wu",
      "Shuwei Shi",
      "Haoming Cai",
      "Mingdeng Cao",
      "Jing Xiao",
      "Yinqiang Zheng",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.11389",
    "title": "Domain Generalization Deep Graph Transformation",
    "abstract": " Title: Domain Generalization Deep Graph Transformation ",
    "url": "https://arxiv.org/abs/2305.11389",
    "authors": [
      "Shiyu Wang",
      "Guangji Bai",
      "Qingyang Zhu",
      "Zhaohui Qin",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.11421",
    "title": "PastNet: Introducing Physical Inductive Biases for Spatio-temporal Video  Prediction",
    "abstract": " Comments: 11 ",
    "url": "https://arxiv.org/abs/2305.11421",
    "authors": [
      "Hao Wu",
      "Wei Xiong",
      "Fan Xu",
      "Xiao Luo",
      "Chong Chen",
      "Xian-Sheng Hua",
      "Haixin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.11881",
    "title": "Self-Supervised Learning for Point Clouds Data: A Survey",
    "abstract": " Title: Self-Supervised Learning for Point Clouds Data: A Survey ",
    "url": "https://arxiv.org/abs/2305.11881",
    "authors": [
      "Changyu Zeng",
      "Wei Wang",
      "Anh Nguyen",
      "Yutao Yue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.13349",
    "title": "Multiclass classification for multidimensional functional data through  deep neural networks",
    "abstract": " Title: Multiclass classification for multidimensional functional data through  deep neural networks ",
    "url": "https://arxiv.org/abs/2305.13349",
    "authors": [
      "Shuoyang Wang",
      "Guanqun Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2305.13399",
    "title": "Efficient Large-Scale Vision Representation Learning",
    "abstract": " Title: Efficient Large-Scale Vision Representation Learning ",
    "url": "https://arxiv.org/abs/2305.13399",
    "authors": [
      "Eden Dolev",
      "Alaa Awad",
      "Denisa Roberts",
      "Zahra Ebrahimzadeh",
      "Marcin Mejran",
      "Vaibhav Malpani",
      "Mahir Yavuz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13718",
    "title": "LogicLLM: Exploring Self-supervised Logic-enhanced Training for Large  Language Models",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2305.13718",
    "authors": [
      "Fangkai Jiao",
      "Zhiyang Teng",
      "Shafiq Joty",
      "Bosheng Ding",
      "Aixin Sun",
      "Zhengyuan Liu",
      "Nancy F. Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13887",
    "title": "A Vision and An Evolutionary Framework for 6G: Scenarios, Capabilities  and Enablers",
    "abstract": " Comments: Submitted to an IEEE Magazine ",
    "url": "https://arxiv.org/abs/2305.13887",
    "authors": [
      "Ruiqi Liu",
      "Ruyue Yu-Ngok Li",
      "Marco Di Renzo",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.13924",
    "title": "Integrated Sensing and Communication based Outdoor Multi-Target  Detection, Tracking and Localization in Practical 5G Networks",
    "abstract": " Comments: Submitted to an open access journal ",
    "url": "https://arxiv.org/abs/2305.13924",
    "authors": [
      "Ruiqi Liu",
      "Mengnan Jian",
      "Dawei Chen",
      "Xu Lin",
      "Yichao Cheng",
      "Wei Cheng",
      "Shijun Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.14129",
    "title": "GrACE: Generation using Associated Code Edits",
    "abstract": " Title: GrACE: Generation using Associated Code Edits ",
    "url": "https://arxiv.org/abs/2305.14129",
    "authors": [
      "Priyanshu Gupta",
      "Avishree Khare",
      "Yasharth Bajpai",
      "Saikat Chakraborty",
      "Sumit Gulwani",
      "Aditya Kanade",
      "Arjun Radhakrishna",
      "Gustavo Soares",
      "Ashish Tiwari"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14218",
    "title": "DUBLIN -- Document Understanding By Language-Image Network",
    "abstract": " Title: DUBLIN -- Document Understanding By Language-Image Network ",
    "url": "https://arxiv.org/abs/2305.14218",
    "authors": [
      "Kriti Aggarwal",
      "Aditi Khandelwal",
      "Kumar Tanmay",
      "Owais Mohammed Khan",
      "Qiang Liu",
      "Monojit Choudhury",
      "Hardik Hansrajbhai Chauhan",
      "Subhojit Som",
      "Vishrav Chaudhary",
      "Saurabh Tiwary"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]