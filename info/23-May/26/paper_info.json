[
  {
    "id": "arXiv:2305.15430",
    "title": "Bounded Projection Matrix Approximation with Applications to Community  Detection",
    "abstract": "Community detection is an important problem in unsupervised learning. This paper proposes to solve a projection matrix approximation problem with an additional entrywise bounded constraint. Algorithmically, we introduce a new differentiable convex penalty and derive an alternating direction method of multipliers (ADMM) algorithm. Theoretically, we establish the convergence properties of the proposed algorithm. Numerical experiments demonstrate the superiority of our algorithm over its competitors, such as the semi-definite relaxation method and spectral clustering. ",
    "url": "https://arxiv.org/abs/2305.15430",
    "authors": [
      "Zheng Zhai",
      "Hengchao Chen",
      "Qiang Sun"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15436",
    "title": "Drivers of Mobile Payment Acceptance: The Impact of Network  Externalities",
    "abstract": "Mobile payment has become increasingly popular due to the widespread use of smartphones and their applications. However, its adoption in African countries has been limited, despite its potential to simplify our lives. This study aims to enhance our understanding of the factors that affect the acceptance of mobile payment in Nigeria. To achieve this, the paper explores the impact of \"network externalities\" in addition to traditional technology acceptance factors. The study hypothesizes that the key drivers of mobile payment acceptance are performance expectancy, effort expectancy, social influence, trust, and network externality. The research findings suggest that while traditional drivers still play a role in customers' willingness to adopt mobile payment, network externalities have the strongest impact. Although the results did not support the influence of effort expectancy, the paper provides recommendations for future research. ",
    "url": "https://arxiv.org/abs/2305.15436",
    "authors": [
      "Qasim Ajao"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.15452",
    "title": "Adaptive Data Analysis in a Balanced Adversarial Model",
    "abstract": "In adaptive data analysis, a mechanism gets $n$ i.i.d. samples from an unknown distribution $D$, and is required to provide accurate estimations to a sequence of adaptively chosen statistical queries with respect to $D$. Hardt and Ullman (FOCS 2014) and Steinke and Ullman (COLT 2015) showed that in general, it is computationally hard to answer more than $\\Theta(n^2)$ adaptive queries, assuming the existence of one-way functions. However, these negative results strongly rely on an adversarial model that significantly advantages the adversarial analyst over the mechanism, as the analyst, who chooses the adaptive queries, also chooses the underlying distribution $D$. This imbalance raises questions with respect to the applicability of the obtained hardness results -- an analyst who has complete knowledge of the underlying distribution $D$ would have little need, if at all, to issue statistical queries to a mechanism which only holds a finite number of samples from $D$. We consider more restricted adversaries, called \\emph{balanced}, where each such adversary consists of two separated algorithms: The \\emph{sampler} who is the entity that chooses the distribution and provides the samples to the mechanism, and the \\emph{analyst} who chooses the adaptive queries, but does not have a prior knowledge of the underlying distribution. We improve the quality of previous lower bounds by revisiting them using an efficient \\emph{balanced} adversary, under standard public-key cryptography assumptions. We show that these stronger hardness assumptions are unavoidable in the sense that any computationally bounded \\emph{balanced} adversary that has the structure of all known attacks, implies the existence of public-key cryptography. ",
    "url": "https://arxiv.org/abs/2305.15452",
    "authors": [
      "Kobbi Nissim",
      "Uri Stemmer",
      "Eliad Tsfadia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2305.15488",
    "title": "Foundational Models for Malware Embeddings Using Spatio-Temporal  Parallel Convolutional Networks",
    "abstract": "In today's interconnected digital landscape, the proliferation of malware poses a significant threat to the security and stability of computer networks and systems worldwide. As the complexity of malicious tactics, techniques, and procedures (TTPs) continuously grows to evade detection, so does the need for advanced methods capable of capturing and characterizing malware behavior. The current state of the art in malware classification and detection uses task specific objectives; however, this method fails to generalize to other downstream tasks involving the same malware class. In this paper, the authors introduce a novel method that combines convolutional neural networks, standard graph embedding techniques, and a metric learning objective to extract meaningful information from network flow data and create strong embeddings characterizing malware behavior. These embeddings enable the development of highly accurate, efficient, and generalizable machine learning models for tasks such as malware strain classification, zero day threat detection, and closest attack type attribution as demonstrated in this paper. A shift from task specific objectives to strong embeddings will not only allow rapid iteration of cyber-threat detection models, but also allow different modalities to be introduced in the development of these models. ",
    "url": "https://arxiv.org/abs/2305.15488",
    "authors": [
      "Dhruv Nandakumar",
      "Devin Quinn",
      "Elijah Soba",
      "Eunyoung Kim",
      "Christopher Redino",
      "Chris Chan",
      "Kevin Choi",
      "Abdul Rahman",
      "Edward Bowen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.15508",
    "title": "Improving selective classification performance of deep neural networks  through post-hoc logit normalization and temperature scaling",
    "abstract": "This paper addresses the problem of selective classification for deep neural networks, where a model is allowed to abstain from low-confidence predictions to avoid potential errors. Specifically, we tackle the problem of optimizing the confidence estimator of a fixed classifier, aiming to enhance its misclassification detection performance, i.e., its ability to discriminate between correct and incorrect predictions by assigning higher confidence values to the correct ones. Previous work has found that different classifiers exhibit varying levels of misclassification detection performance, particularly when using the maximum softmax probability (MSP) as a measure of confidence. However, we argue that these findings are mainly due to a sub-optimal confidence estimator being used for each model. To overcome this issue, we propose a simple and efficient post-hoc confidence estimator, named $p$-NormSoftmax, which consists of transforming the logits through $p$-norm normalization and temperature scaling, followed by taking the MSP, where $p$ and the temperature are optimized based on a hold-out set. This estimator can be easily applied on top of an already trained model and, in many cases, can significantly improve its selective classification performance. When applied to 84 pretrained Imagenet classifiers, our method yields an average improvement of 16% in the area under the risk-coverage curve (AURC), exceeding 40% for some models. Furthermore, after applying $p$-NormSoftmax, we observe that these models exhibit approximately the same level of misclassification detection performance, implying that a model's selective classification performance is almost entirely determined by its accuracy at full coverage. ",
    "url": "https://arxiv.org/abs/2305.15508",
    "authors": [
      "Lu\u00eds Felipe P. Cattelan",
      "Danilo Silva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15529",
    "title": "Editable Graph Neural Network for Node Classifications",
    "abstract": "Despite Graph Neural Networks (GNNs) have achieved prominent success in many graph-based learning problem, such as credit risk assessment in financial networks and fake news detection in social networks. However, the trained GNNs still make errors and these errors may cause serious negative impact on society. \\textit{Model editing}, which corrects the model behavior on wrongly predicted target samples while leaving model predictions unchanged on unrelated samples, has garnered significant interest in the fields of computer vision and natural language processing. However, model editing for graph neural networks (GNNs) is rarely explored, despite GNNs' widespread applicability. To fill the gap, we first observe that existing model editing methods significantly deteriorate prediction accuracy (up to $50\\%$ accuracy drop) in GNNs while a slight accuracy drop in multi-layer perception (MLP). The rationale behind this observation is that the node aggregation in GNNs will spread the editing effect throughout the whole graph. This propagation pushes the node representation far from its original one. Motivated by this observation, we propose \\underline{E}ditable \\underline{G}raph \\underline{N}eural \\underline{N}etworks (EGNN), a neighbor propagation-free approach to correct the model prediction on misclassified nodes. Specifically, EGNN simply stitches an MLP to the underlying GNNs, where the weights of GNNs are frozen during model editing. In this way, EGNN disables the propagation during editing while still utilizing the neighbor propagation scheme for node prediction to obtain satisfactory results. Experiments demonstrate that EGNN outperforms existing baselines in terms of effectiveness (correcting wrong predictions with lower accuracy drop), generalizability (correcting wrong predictions for other similar nodes), and efficiency (low training time and memory) on various graph datasets. ",
    "url": "https://arxiv.org/abs/2305.15529",
    "authors": [
      "Zirui Liu",
      "Zhimeng Jiang",
      "Shaochen Zhong",
      "Kaixiong Zhou",
      "Li Li",
      "Rui Chen",
      "Soo-Hyun Choi",
      "Xia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.15534",
    "title": "Representation Online Matters: Practical End-to-End Diversification in  Search and Recommender Systems",
    "abstract": "As the use of online platforms continues to grow across all demographics, users often express a desire to feel represented in the content. To improve representation in search results and recommendations, we introduce end-to-end diversification, ensuring that diverse content flows throughout the various stages of these systems, from retrieval to ranking. We develop, experiment, and deploy scalable diversification mechanisms in multiple production surfaces on the Pinterest platform, including Search, Related Products, and New User Homefeed, to improve the representation of different skin tones in beauty and fashion content. Diversification in production systems includes three components: identifying requests that will trigger diversification, ensuring diverse content is retrieved from the large content corpus during the retrieval stage, and finally, balancing the diversity-utility trade-off in a self-adjusting manner in the ranking stage. Our approaches, which evolved from using Strong-OR logical operator to bucketized retrieval at the retrieval stage and from greedy re-rankers to multi-objective optimization using determinantal point processes for the ranking stage, balances diversity and utility while enabling fast iterations and scalable expansion to diversification over multiple dimensions. Our experiments indicate that these approaches significantly improve diversity metrics, with a neutral to a positive impact on utility metrics and improved user satisfaction, both qualitatively and quantitatively, in production. ",
    "url": "https://arxiv.org/abs/2305.15534",
    "authors": [
      "Pedro Silva",
      "Bhawna Juneja",
      "Shloka Desai",
      "Ashudeep Singh",
      "Nadia Fawaz"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15544",
    "title": "Fast Adversarial CNN-based Perturbation Attack on No-Reference Image-  and Video-Quality Metrics",
    "abstract": "Modern neural-network-based no-reference image- and video-quality metrics exhibit performance as high as full-reference metrics. These metrics are widely used to improve visual quality in computer vision methods and compare video processing methods. However, these metrics are not stable to traditional adversarial attacks, which can cause incorrect results. Our goal is to investigate the boundaries of no-reference metrics applicability, and in this paper, we propose a fast adversarial perturbation attack on no-reference quality metrics. The proposed attack (FACPA) can be exploited as a preprocessing step in real-time video processing and compression algorithms. This research can yield insights to further aid in designing of stable neural-network-based no-reference quality metrics. ",
    "url": "https://arxiv.org/abs/2305.15544",
    "authors": [
      "Ekaterina Shumitskaya",
      "Anastasia Antsiferova",
      "Dmitriy Vatolin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.15562",
    "title": "Let There Be Order: Rethinking Ordering in Autoregressive Graph  Generation",
    "abstract": "Conditional graph generation tasks involve training a model to generate a graph given a set of input conditions. Many previous studies employ autoregressive models to incrementally generate graph components such as nodes and edges. However, as graphs typically lack a natural ordering among their components, converting a graph into a sequence of tokens is not straightforward. While prior works mostly rely on conventional heuristics or graph traversal methods like breadth-first search (BFS) or depth-first search (DFS) to convert graphs to sequences, the impact of ordering on graph generation has largely been unexplored. This paper contributes to this problem by: (1) highlighting the crucial role of ordering in autoregressive graph generation models, (2) proposing a novel theoretical framework that perceives ordering as a dimensionality reduction problem, thereby facilitating a deeper understanding of the relationship between orderings and generated graph accuracy, and (3) introducing \"latent sort,\" a learning-based ordering scheme to perform dimensionality reduction of graph tokens. Our experimental results showcase the effectiveness of latent sort across a wide range of graph generation tasks, encouraging future works to further explore and develop learning-based ordering schemes for autoregressive graph generation. ",
    "url": "https://arxiv.org/abs/2305.15562",
    "authors": [
      "Jie Bu",
      "Kazi Sajeed Mehrab",
      "Anuj Karpatne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15587",
    "title": "How do humans perceive adversarial text? A reality check on the validity  and naturalness of word-based adversarial attacks",
    "abstract": "Natural Language Processing (NLP) models based on Machine Learning (ML) are susceptible to adversarial attacks -- malicious algorithms that imperceptibly modify input text to force models into making incorrect predictions. However, evaluations of these attacks ignore the property of imperceptibility or study it under limited settings. This entails that adversarial perturbations would not pass any human quality gate and do not represent real threats to human-checked NLP systems. To bypass this limitation and enable proper assessment (and later, improvement) of NLP model robustness, we have surveyed 378 human participants about the perceptibility of text adversarial examples produced by state-of-the-art methods. Our results underline that existing text attacks are impractical in real-world scenarios where humans are involved. This contrasts with previous smaller-scale human studies, which reported overly optimistic conclusions regarding attack success. Through our work, we hope to position human perceptibility as a first-class success criterion for text attacks, and provide guidance for research to build effective attack algorithms and, in turn, design appropriate defence mechanisms. ",
    "url": "https://arxiv.org/abs/2305.15587",
    "authors": [
      "Salijona Dyrmishi",
      "Salah Ghamizi",
      "Maxime Cordy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15597",
    "title": "Text-Augmented Open Knowledge Graph Completion via Pre-Trained Language  Models",
    "abstract": "The mission of open knowledge graph (KG) completion is to draw new findings from known facts. Existing works that augment KG completion require either (1) factual triples to enlarge the graph reasoning space or (2) manually designed prompts to extract knowledge from a pre-trained language model (PLM), exhibiting limited performance and requiring expensive efforts from experts. To this end, we propose TAGREAL that automatically generates quality query prompts and retrieves support information from large text corpora to probe knowledge from PLM for KG completion. The results show that TAGREAL achieves state-of-the-art performance on two benchmark datasets. We find that TAGREAL has superb performance even with limited training data, outperforming existing embedding-based, graph-based, and PLM-based methods. ",
    "url": "https://arxiv.org/abs/2305.15597",
    "authors": [
      "Pengcheng Jiang",
      "Shivam Agarwal",
      "Bowen Jin",
      "Xuan Wang",
      "Jimeng Sun",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2305.15598",
    "title": "Linear Neural Network Layers Promote Learning Single- and Multiple-Index  Models",
    "abstract": "This paper explores the implicit bias of overparameterized neural networks of depth greater than two layers. Our framework considers a family of networks of varying depths that all have the same capacity but different implicitly defined representation costs. The representation cost of a function induced by a neural network architecture is the minimum sum of squared weights needed for the network to represent the function; it reflects the function space bias associated with the architecture. Our results show that adding linear layers to a ReLU network yields a representation cost that favors functions that can be approximated by a low-rank linear operator composed with a function with low representation cost using a two-layer network. Specifically, using a neural network to fit training data with minimum representation cost yields an interpolating function that is nearly constant in directions orthogonal to a low-dimensional subspace. This means that the learned network will approximately be a single- or multiple-index model. Our experiments show that when this active subspace structure exists in the data, adding linear layers can improve generalization and result in a network that is well-aligned with the true active subspace. ",
    "url": "https://arxiv.org/abs/2305.15598",
    "authors": [
      "Suzanna Parkinson",
      "Greg Ongie",
      "Rebecca Willett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.15602",
    "title": "Control invariant set enhanced safe reinforcement learning: improved  sampling efficiency, guaranteed stability and robustness",
    "abstract": "Reinforcement learning (RL) is an area of significant research interest, and safe RL in particular is attracting attention due to its ability to handle safety-driven constraints that are crucial for real-world applications. This work proposes a novel approach to RL training, called control invariant set (CIS) enhanced RL, which leverages the advantages of utilizing the explicit form of CIS to improve stability guarantees and sampling efficiency. Furthermore, the robustness of the proposed approach is investigated in the presence of uncertainty. The approach consists of two learning stages: offline and online. In the offline stage, CIS is incorporated into the reward design, initial state sampling, and state reset procedures. This incorporation of CIS facilitates improved sampling efficiency during the offline training process. In the online stage, RL is retrained whenever the predicted next step state is outside of the CIS, which serves as a stability criterion, by introducing a Safety Supervisor to examine the safety of the action and make necessary corrections. The stability analysis is conducted for both cases, with and without uncertainty. To evaluate the proposed approach, we apply it to a simulated chemical reactor. The results show a significant improvement in sampling efficiency during offline training and closed-loop stability guarantee in the online implementation, with and without uncertainty. ",
    "url": "https://arxiv.org/abs/2305.15602",
    "authors": [
      "Song Bo",
      "Bernard T. Agyeman",
      "Xunyuan Yin",
      "Jinfeng Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2305.15603",
    "title": "Learning Lagrangian Fluid Mechanics with E($3$)-Equivariant Graph Neural  Networks",
    "abstract": "We contribute to the vastly growing field of machine learning for engineering systems by demonstrating that equivariant graph neural networks have the potential to learn more accurate dynamic-interaction models than their non-equivariant counterparts. We benchmark two well-studied fluid-flow systems, namely 3D decaying Taylor-Green vortex and 3D reverse Poiseuille flow, and evaluate the models based on different performance measures, such as kinetic energy or Sinkhorn distance. In addition, we investigate different embedding methods of physical-information histories for equivariant models. We find that while currently being rather slow to train and evaluate, equivariant models with our proposed history embeddings learn more accurate physical interactions. ",
    "url": "https://arxiv.org/abs/2305.15603",
    "authors": [
      "Artur P. Toshev",
      "Gianluca Galletti",
      "Johannes Brandstetter",
      "Stefan Adami",
      "Nikolaus A. Adams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2305.15611",
    "title": "Size Generalizability of Graph Neural Networks on Biological Data:  Insights and Practices from the Spectral Perspective",
    "abstract": "We investigate the question of whether the knowledge learned by graph neural networks (GNNs) from small graphs is generalizable to large graphs in the same domain. Prior works suggest that the distribution shift, particularly in the degree distribution, between graphs of different sizes can lead to performance degradation in the graph classification task. However, this may not be the case for biological datasets where the degrees are bounded and the distribution shift of degrees is small. Even with little degree distribution shift, our observations show that GNNs' performance on larger graphs from the same datasets still degrades, suggesting other causes. In fact, there has been a lack of exploration in real datasets to understand the types and properties of distribution shifts caused by various graph sizes. Furthermore, previous analyses of size generalizability mostly focus on the spatial domain. To fill these gaps, we take the spectral perspective and study the size generalizability of GNNs on biological data. We identify a distribution shift between small and large graphs in the eigenvalues of the normalized Laplacian/adjacency matrix, indicating a difference in the global node connectivity, which is found to be correlated with the node closeness centrality. We further find that despite of the variations in global connectivity, graphs of different sizes share similar local connectivity, which can be utilized to improve the size generalizability of GNNs. Based on our spectral insights and empirical observations, we propose a model-agnostic strategy, SIA, which uses size-irrelevant local structural features, i.e., the local closeness centrality of a node, to guide the learning process. Our empirical results demonstrate that our strategy improves the graph classification performance of various GNNs on small and large graphs when training with only small graphs. ",
    "url": "https://arxiv.org/abs/2305.15611",
    "authors": [
      "Yujun Yan",
      "Gaotang Li",
      "Danai koutra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15614",
    "title": "Reverse Engineering Self-Supervised Learning",
    "abstract": "Self-supervised learning (SSL) is a powerful tool in machine learning, but understanding the learned representations and their underlying mechanisms remains a challenge. This paper presents an in-depth empirical analysis of SSL-trained representations, encompassing diverse models, architectures, and hyperparameters. Our study reveals an intriguing aspect of the SSL training process: it inherently facilitates the clustering of samples with respect to semantic labels, which is surprisingly driven by the SSL objective's regularization term. This clustering process not only enhances downstream classification but also compresses the data information. Furthermore, we establish that SSL-trained representations align more closely with semantic classes rather than random classes. Remarkably, we show that learned representations align with semantic classes across various hierarchical levels, and this alignment increases during training and when moving deeper into the network. Our findings provide valuable insights into SSL's representation learning mechanisms and their impact on performance across different sets of classes. ",
    "url": "https://arxiv.org/abs/2305.15614",
    "authors": [
      "Ido Ben-Shaul",
      "Ravid Shwartz-Ziv",
      "Tomer Galanti",
      "Shai Dekel",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15616",
    "title": "Reversible and irreversible bracket-based dynamics for deep graph neural  networks",
    "abstract": "Recent works have shown that physics-inspired architectures allow the training of deep graph neural networks (GNNs) without oversmoothing. The role of these physics is unclear, however, with successful examples of both reversible (e.g., Hamiltonian) and irreversible (e.g., diffusion) phenomena producing comparable results despite diametrically opposed mechanisms, and further complications arising due to empirical departures from mathematical theory. This work presents a series of novel GNN architectures based upon structure-preserving bracket-based dynamical systems, which are provably guaranteed to either conserve energy or generate positive dissipation with increasing depth. It is shown that the theoretically principled framework employed here allows for inherently explainable constructions, which contextualize departures from theory in current architectures and better elucidate the roles of reversibility and irreversibility in network performance. ",
    "url": "https://arxiv.org/abs/2305.15616",
    "authors": [
      "Anthony Gruber",
      "Kookjin Lee",
      "Nathaniel Trask"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15622",
    "title": "GFairHint: Improving Individual Fairness for Graph Neural Networks via  Fairness Hint",
    "abstract": "Given the growing concerns about fairness in machine learning and the impressive performance of Graph Neural Networks (GNNs) on graph data learning, algorithmic fairness in GNNs has attracted significant attention. While many existing studies improve fairness at the group level, only a few works promote individual fairness, which renders similar outcomes for similar individuals. A desirable framework that promotes individual fairness should (1) balance between fairness and performance, (2) accommodate two commonly-used individual similarity measures (externally annotated and computed from input features), (3) generalize across various GNN models, and (4) be computationally efficient. Unfortunately, none of the prior work achieves all the desirables. In this work, we propose a novel method, GFairHint, which promotes individual fairness in GNNs and achieves all aforementioned desirables. GFairHint learns fairness representations through an auxiliary link prediction task, and then concatenates the representations with the learned node embeddings in original GNNs as a \"fairness hint\". Through extensive experimental investigations on five real-world graph datasets under three prevalent GNN models covering both individual similarity measures above, GFairHint achieves the best fairness results in almost all combinations of datasets with various backbone models, while generating comparable utility results, with much less computational cost compared to the previous state-of-the-art (SoTA) method. ",
    "url": "https://arxiv.org/abs/2305.15622",
    "authors": [
      "Paiheng Xu",
      "Yuhang Zhou",
      "Bang An",
      "Wei Ai",
      "Furong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.15629",
    "title": "Patient Outcome Predictions Improve Operations at a Large Hospital  Network",
    "abstract": "Problem definition: Access to accurate predictions of patients' outcomes can enhance medical staff's decision-making, which ultimately benefits all stakeholders in the hospitals. A large hospital network in the US has been collaborating with academics and consultants to predict short-term and long-term outcomes for all inpatients across their seven hospitals. Methodology/results: We develop machine learning models that predict the probabilities of next 24-hr/48-hr discharge and intensive care unit transfers, end-of-stay mortality and discharge dispositions. All models achieve high out-of-sample AUC (75.7%-92.5%) and are well calibrated. In addition, combining 48-hr discharge predictions with doctors' predictions simultaneously enables more patient discharges (10%-28.7%) and fewer 7-day/30-day readmissions ($p$-value $<0.001$). We implement an automated pipeline that extracts data and updates predictions every morning, as well as user-friendly software and a color-coded alert system to communicate these patient-level predictions (alongside explanations) to clinical teams. Managerial implications: Since we have been gradually deploying the tool, and training medical staff, over 200 doctors, nurses, and case managers across seven hospitals use it in their daily patient review process. We observe a significant reduction in the average length of stay (0.67 days per patient) following its adoption and anticipate substantial financial benefits (between \\$55 and \\$72 million annually) for the healthcare system. ",
    "url": "https://arxiv.org/abs/2305.15629",
    "authors": [
      "Liangyuan Na",
      "Kimberly Villalobos Carballo",
      "Jean Pauphilet",
      "Ali Haddad-Sisakht",
      "Daniel Kombert",
      "Melissa Boisjoli-Langlois",
      "Andrew Castiglione",
      "Maram Khalifa",
      "Pooja Hebbal",
      "Barry Stein",
      "Dimitris Bertsimas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15641",
    "title": "A Robust Classifier Under Missing-Not-At-Random Sample Selection Bias",
    "abstract": "The shift between the training and testing distributions is commonly due to sample selection bias, a type of bias caused by non-random sampling of examples to be included in the training set. Although there are many approaches proposed to learn a classifier under sample selection bias, few address the case where a subset of labels in the training set are missing-not-at-random (MNAR) as a result of the selection process. In statistics, Greene's method formulates this type of sample selection with logistic regression as the prediction model. However, we find that simply integrating this method into a robust classification framework is not effective for this bias setting. In this paper, we propose BiasCorr, an algorithm that improves on Greene's method by modifying the original training set in order for a classifier to learn under MNAR sample selection bias. We provide theoretical guarantee for the improvement of BiasCorr over Greene's method by analyzing its bias. Experimental results on real-world datasets demonstrate that BiasCorr produces robust classifiers and can be extended to outperform state-of-the-art classifiers that have been proposed to train under sample selection bias. ",
    "url": "https://arxiv.org/abs/2305.15641",
    "authors": [
      "Huy Mai",
      "Wen Huang",
      "Wei Du",
      "Xintao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15642",
    "title": "Learning-Based Automatic Synthesis of Software Code and Configuration",
    "abstract": "Increasing demands in software industry and scarcity of software engineers motivates researchers and practitioners to automate the process of software generation and configuration. Large scale automatic software generation and configuration is a very complex and challenging task. In this proposal, we set out to investigate this problem by breaking down automatic software generation and configuration into two different tasks. In first task, we propose to synthesize software automatically with input output specifications. This task is further broken down into two sub-tasks. The first sub-task is about synthesizing programs with a genetic algorithm which is driven by a neural network based fitness function trained with program traces and specifications. For the second sub-task, we formulate program synthesis as a continuous optimization problem and synthesize programs with covariance matrix adaption evolutionary strategy (a state-of-the-art continuous optimization method). Finally, for the second task, we propose to synthesize configurations of large scale software from different input files (e.g. software manuals, configurations files, online blogs, etc.) using a sequence-to-sequence deep learning mechanism. ",
    "url": "https://arxiv.org/abs/2305.15642",
    "authors": [
      "Shantanu Mandal"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15652",
    "title": "Towards Total Online Unsupervised Anomaly Detection and Localization in  Industrial Vision",
    "abstract": "Although existing image anomaly detection methods yield impressive results, they are mostly an offline learning paradigm that requires excessive data pre-collection, limiting their adaptability in industrial scenarios with online streaming data. Online learning-based image anomaly detection methods are more compatible with industrial online streaming data but are rarely noticed. For the first time, this paper presents a fully online learning image anomaly detection method, namely LeMO, learning memory for online image anomaly detection. LeMO leverages learnable memory initialized with orthogonal random noise, eliminating the need for excessive data in memory initialization and circumventing the inefficiencies of offline data collection. Moreover, a contrastive learning-based loss function for anomaly detection is designed to enable online joint optimization of memory and image target-oriented features. The presented method is simple and highly effective. Extensive experiments demonstrate the superior performance of LeMO in the online setting. Additionally, in the offline setting, LeMO is also competitive with the current state-of-the-art methods and achieves excellent performance in few-shot scenarios. ",
    "url": "https://arxiv.org/abs/2305.15652",
    "authors": [
      "Han Gao",
      "Huiyuan Luo",
      "Fei Shen",
      "Zhengtao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15668",
    "title": "FedHC: A Scalable Federated Learning Framework for Heterogeneous and  Resource-Constrained Clients",
    "abstract": "Federated Learning (FL) is a distributed learning paradigm that empowers edge devices to collaboratively learn a global model leveraging local data. Simulating FL on GPU is essential to expedite FL algorithm prototyping and evaluations. However, current FL frameworks overlook the disparity between algorithm simulation and real-world deployment, which arises from heterogeneous computing capabilities and imbalanced workloads, thus misleading evaluations of new algorithms. Additionally, they lack flexibility and scalability to accommodate resource-constrained clients. In this paper, we present FedHC, a scalable federated learning framework for heterogeneous and resource-constrained clients. FedHC realizes system heterogeneity by allocating a dedicated and constrained GPU resource budget to each client, and also simulates workload heterogeneity in terms of framework-provided runtime. Furthermore, we enhance GPU resource utilization for scalable clients by introducing a dynamic client scheduler, process manager, and resource-sharing mechanism. Our experiments demonstrate that FedHC has the capability to capture the influence of various factors on client execution time. Moreover, despite resource constraints for each client, FedHC achieves state-of-the-art efficiency compared to existing frameworks without limits. When subjecting existing frameworks to the same resource constraints, FedHC achieves a 2.75x speedup. Code has been released on https://github.com/if-lab-repository/FedHC. ",
    "url": "https://arxiv.org/abs/2305.15668",
    "authors": [
      "Min Zhang",
      "Fuxun Yu",
      "Yongbo Yu",
      "Minjia Zhang",
      "Ang Li",
      "Xiang Chen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2305.15684",
    "title": "Perturbation-based Self-supervised Attention for Attention Bias in Text  Classification",
    "abstract": "In text classification, the traditional attention mechanisms usually focus too much on frequent words, and need extensive labeled data in order to learn. This paper proposes a perturbation-based self-supervised attention approach to guide attention learning without any annotation overhead. Specifically, we add as much noise as possible to all the words in the sentence without changing their semantics and predictions. We hypothesize that words that tolerate more noise are less significant, and we can use this information to refine the attention distribution. Experimental results on three text classification tasks show that our approach can significantly improve the performance of current attention-based models, and is more effective than existing self-supervised methods. We also provide a visualization analysis to verify the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2305.15684",
    "authors": [
      "Huawen Feng",
      "Zhenxi Lin",
      "Qianli Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.15688",
    "title": "Frame-Event Alignment and Fusion Network for High Frame Rate Tracking",
    "abstract": "Most existing RGB-based trackers target low frame rate benchmarks of around 30 frames per second. This setting restricts the tracker's functionality in the real world, especially for fast motion. Event-based cameras as bioinspired sensors provide considerable potential for high frame rate tracking due to their high temporal resolution. However, event-based cameras cannot offer fine-grained texture information like conventional cameras. This unique complementarity motivates us to combine conventional frames and events for high frame rate object tracking under various challenging conditions. Inthispaper, we propose an end-to-end network consisting of multi-modality alignment and fusion modules to effectively combine meaningful information from both modalities at different measurement rates. The alignment module is responsible for cross-style and cross-frame-rate alignment between frame and event modalities under the guidance of the moving cues furnished by events. While the fusion module is accountable for emphasizing valuable features and suppressing noise information by the mutual complement between the two modalities. Extensive experiments show that the proposed approach outperforms state-of-the-art trackers by a significant margin in high frame rate tracking. With the FE240hz dataset, our approach achieves high frame rate tracking up to 240Hz. ",
    "url": "https://arxiv.org/abs/2305.15688",
    "authors": [
      "Jiqing Zhang",
      "Yuanchen Wang",
      "Wenxi Liu",
      "Meng Li",
      "Jinpeng Bai",
      "Baocai Yin",
      "Xin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15690",
    "title": "Beryllium: Neural Search for Algorithm Implementations",
    "abstract": "In this paper, we explore the feasibility of finding algorithm implementations from code. Successfully matching code and algorithms can help understand unknown code, provide reference implementations, and automatically collect data for learning-based program synthesis. To achieve the goal, we designed a new language named p-language to specify the algorithms and a static analyzer for the p-language to automatically extract control flow, math, and natural language information from the algorithm descriptions. We embedded the output of p-language (p-code) and source code in a common vector space using self-supervised machine learning methods to match algorithm with code without any manual annotation. We developed a tool named Beryllium. It takes pseudo code as a query and returns a list of ranked code snippets that likely match the algorithm query. Our evaluation on Stony Brook Algorithm Repository and popular GitHub projects show that Beryllium significantly outperformed the state-of-the-art code search tools in both C and Java. Specifically, for 98.5%, 93.8%, and 66.2% queries, we found the algorithm implementations in the top 25, 10, and 1 ranked list, respectively. Given 87 algorithm queries, we found implementations for 74 algorithms in the GitHub projects where we did not know the algorithms before. ",
    "url": "https://arxiv.org/abs/2305.15690",
    "authors": [
      "Adithya Kulkarni",
      "Mohna Chakraborty",
      "Yonas Sium",
      "Sai Charishma Valluri",
      "Wei Le",
      "Qi Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.15692",
    "title": "Deep Neural Networks in Video Human Action Recognition: A Review",
    "abstract": "Currently, video behavior recognition is one of the most foundational tasks of computer vision. The 2D neural networks of deep learning are built for recognizing pixel-level information such as images with RGB, RGB-D, or optical flow formats, with the current increasingly wide usage of surveillance video and more tasks related to human action recognition. There are increasing tasks requiring temporal information for frames dependency analysis. The researchers have widely studied video-based recognition rather than image-based(pixel-based) only to extract more informative elements from geometry tasks. Our current related research addresses multiple novel proposed research works and compares their advantages and disadvantages between the derived deep learning frameworks rather than machine learning frameworks. The comparison happened between existing frameworks and datasets, which are video format data only. Due to the specific properties of human actions and the increasingly wide usage of deep neural networks, we collected all research works within the last three years between 2020 to 2022. In our article, the performance of deep neural networks surpassed most of the techniques in the feature learning and extraction tasks, especially video action recognition. ",
    "url": "https://arxiv.org/abs/2305.15692",
    "authors": [
      "Zihan Wang",
      "Yang Yang",
      "Zhi Liu",
      "Yifan Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2305.15694",
    "title": "Learning Occupancy for Monocular 3D Object Detection",
    "abstract": "Monocular 3D detection is a challenging task due to the lack of accurate 3D information. Existing approaches typically rely on geometry constraints and dense depth estimates to facilitate the learning, but often fail to fully exploit the benefits of three-dimensional feature extraction in frustum and 3D space. In this paper, we propose \\textbf{OccupancyM3D}, a method of learning occupancy for monocular 3D detection. It directly learns occupancy in frustum and 3D space, leading to more discriminative and informative 3D features and representations. Specifically, by using synchronized raw sparse LiDAR point clouds, we define the space status and generate voxel-based occupancy labels. We formulate occupancy prediction as a simple classification problem and design associated occupancy losses. Resulting occupancy estimates are employed to enhance original frustum/3D features. As a result, experiments on KITTI and Waymo open datasets demonstrate that the proposed method achieves a new state of the art and surpasses other methods by a significant margin. Codes and pre-trained models will be available at \\url{https://github.com/SPengLiang/OccupancyM3D}. ",
    "url": "https://arxiv.org/abs/2305.15694",
    "authors": [
      "Liang Peng",
      "Junkai Xu",
      "Haoran Cheng",
      "Zheng Yang",
      "Xiaopei Wu",
      "Wei Qian",
      "Wenxiao Wang",
      "Boxi Wu",
      "Deng Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15697",
    "title": "Privacy Protectability: An Information-theoretical Approach",
    "abstract": "Recently, inference privacy has attracted increasing attention. The inference privacy concern arises most notably in the widely deployed edge-cloud video analytics systems, where the cloud needs the videos captured from the edge. The video data can contain sensitive information and subject to attack when they are transmitted to the cloud for inference. Many privacy protection schemes have been proposed. Yet, the performance of a scheme needs to be determined by experiments or inferred by analyzing the specific case. In this paper, we propose a new metric, \\textit{privacy protectability}, to characterize to what degree a video stream can be protected given a certain video analytics task. Such a metric has strong operational meaning. For example, low protectability means that it may be necessary to set up an overall secure environment. We can also evaluate a privacy protection scheme, e.g., assume it obfuscates the video data, what level of protection this scheme has achieved after obfuscation. Our definition of privacy protectability is rooted in information theory and we develop efficient algorithms to estimate the metric. We use experiments on real data to validate that our metric is consistent with empirical measurements on how well a video stream can be protected for a video analytics task. ",
    "url": "https://arxiv.org/abs/2305.15697",
    "authors": [
      "Siping Shi",
      "Bihai Zhang",
      "Dan Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2305.15709",
    "title": "PEARL: Preprocessing Enhanced Adversarial Robust Learning of Image  Deraining for Semantic Segmentation",
    "abstract": "In light of the significant progress made in the development and application of semantic segmentation tasks, there has been increasing attention towards improving the robustness of segmentation models against natural degradation factors (e.g., rain streaks) or artificially attack factors (e.g., adversarial attack). Whereas, most existing methods are designed to address a single degradation factor and are tailored to specific application scenarios. In this work, we present the first attempt to improve the robustness of semantic segmentation tasks by simultaneously handling different types of degradation factors. Specifically, we introduce the Preprocessing Enhanced Adversarial Robust Learning (PEARL) framework based on the analysis of our proposed Naive Adversarial Training (NAT) framework. Our approach effectively handles both rain streaks and adversarial perturbation by transferring the robustness of the segmentation model to the image derain model. Furthermore, as opposed to the commonly used Negative Adversarial Attack (NAA), we design the Auxiliary Mirror Attack (AMA) to introduce positive information prior to the training of the PEARL framework, which improves defense capability and segmentation performance. Our extensive experiments and ablation studies based on different derain methods and segmentation models have demonstrated the significant performance improvement of PEARL with AMA in defense against various adversarial attacks and rain streaks while maintaining high generalization performance across different datasets. ",
    "url": "https://arxiv.org/abs/2305.15709",
    "authors": [
      "Xianghao Jiao",
      "Yaohua Liu",
      "Jiaxin Gao",
      "Xinyuan Chu",
      "Risheng Liu",
      "Xin Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15719",
    "title": "Efficient Neural Music Generation",
    "abstract": "Recent progress in music generation has been remarkably advanced by the state-of-the-art MusicLM, which comprises a hierarchy of three LMs, respectively, for semantic, coarse acoustic, and fine acoustic modelings. Yet, sampling with the MusicLM requires processing through these LMs one by one to obtain the fine-grained acoustic tokens, making it computationally expensive and prohibitive for a real-time generation. Efficient music generation with a quality on par with MusicLM remains a significant challenge. In this paper, we present MeLoDy (M for music; L for LM; D for diffusion), an LM-guided diffusion model that generates music audios of state-of-the-art quality meanwhile reducing 95.7% or 99.6% forward passes in MusicLM, respectively, for sampling 10s or 30s music. MeLoDy inherits the highest-level LM from MusicLM for semantic modeling, and applies a novel dual-path diffusion (DPD) model and an audio VAE-GAN to efficiently decode the conditioning semantic tokens into waveform. DPD is proposed to simultaneously model the coarse and fine acoustics by incorporating the semantic information into segments of latents effectively via cross-attention at each denoising step. Our experimental results suggest the superiority of MeLoDy, not only in its practical advantages on sampling speed and infinitely continuable generation, but also in its state-of-the-art musicality, audio quality, and text correlation. Our samples are available at https://Efficient-MeLoDy.github.io/. ",
    "url": "https://arxiv.org/abs/2305.15719",
    "authors": [
      "Max W. Y. Lam",
      "Qiao Tian",
      "Tang Li",
      "Zongyu Yin",
      "Siyuan Feng",
      "Ming Tu",
      "Yuliang Ji",
      "Rui Xia",
      "Mingbo Ma",
      "Xuchen Song",
      "Jitong Chen",
      "Yuping Wang",
      "Yuxuan Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.15723",
    "title": "Learning across Data Owners with Joint Differential Privacy",
    "abstract": "In this paper, we study the setting in which data owners train machine learning models collaboratively under a privacy notion called joint differential privacy [Kearns et al., 2018]. In this setting, the model trained for each data owner $j$ uses $j$'s data without privacy consideration and other owners' data with differential privacy guarantees. This setting was initiated in [Jain et al., 2021] with a focus on linear regressions. In this paper, we study this setting for stochastic convex optimization (SCO). We present an algorithm that is a variant of DP-SGD [Song et al., 2013; Abadi et al., 2016] and provides theoretical bounds on its population loss. We compare our algorithm to several baselines and discuss for what parameter setups our algorithm is more preferred. We also empirically study joint differential privacy in the multi-class classification problem over two public datasets. Our empirical findings are well-connected to the insights from our theoretical results. ",
    "url": "https://arxiv.org/abs/2305.15723",
    "authors": [
      "Yangsibo Huang",
      "Haotian Jiang",
      "Daogao Liu",
      "Mohammad Mahdian",
      "Jieming Mao",
      "Vahab Mirrokni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2305.15725",
    "title": "Learn to Not Link: Exploring NIL Prediction in Entity Linking",
    "abstract": "Entity linking models have achieved significant success via utilizing pretrained language models to capture semantic features. However, the NIL prediction problem, which aims to identify mentions without a corresponding entity in the knowledge base, has received insufficient attention. We categorize mentions linking to NIL into Missing Entity and Non-Entity Phrase, and propose an entity linking dataset NEL that focuses on the NIL prediction problem. NEL takes ambiguous entities as seeds, collects relevant mention context in the Wikipedia corpus, and ensures the presence of mentions linking to NIL by human annotation and entity masking. We conduct a series of experiments with the widely used bi-encoder and cross-encoder entity linking models, results show that both types of NIL mentions in training data have a significant influence on the accuracy of NIL prediction. Our code and dataset can be accessed at https://github.com/solitaryzero/NIL_EL ",
    "url": "https://arxiv.org/abs/2305.15725",
    "authors": [
      "Fangwei Zhu",
      "Jifan Yu",
      "Hailong Jin",
      "Juanzi Li",
      "Lei Hou",
      "Zhifang Sui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.15729",
    "title": "Accelerated K-Serial Stable Coalition for Dynamic Capture and Resource  Defense",
    "abstract": "Coalition is an important mean of multi-robot systems to collaborate on common tasks. An effective and adaptive coalition strategy is essential for the online performance in dynamic and unknown environments. In this work, the problem of territory defense by large-scale heterogeneous robotic teams is considered. The tasks include surveillance, capture of dynamic targets, and perimeter defense over valuable resources. Since each robot can choose among many tasks, it remains a challenging problem to coordinate jointly these robots such that the overall utility is maximized. This work proposes a generic coalition strategy called K-serial stable coalition algorithm (KS-COAL). Different from centralized approaches, it is distributed and anytime, meaning that only local communication is required and a K-serial Nash-stable solution is ensured. Furthermore, to accelerate adaptation to dynamic targets and resource distribution that are only perceived online, a heterogeneous graph attention network (HGAN)-based heuristic is learned to select more appropriate parameters and promising initial solutions during local optimization. Compared with manual heuristics or end-to-end predictors, it is shown to both improve online adaptability and retain the quality guarantee. The proposed methods are validated rigorously via large-scale simulations with hundreds of robots, against several strong baselines including GreedyNE and FastMaxSum. ",
    "url": "https://arxiv.org/abs/2305.15729",
    "authors": [
      "Junfeng Chen",
      "Zili Tang",
      "Meng Guo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.15732",
    "title": "CLIP3Dstyler: Language Guided 3D Arbitrary Neural Style Transfer",
    "abstract": "In this paper, we propose a novel language-guided 3D arbitrary neural style transfer method (CLIP3Dstyler). We aim at stylizing any 3D scene with an arbitrary style from a text description, and synthesizing the novel stylized view, which is more flexible than the image-conditioned style transfer. Compared with the previous 2D method CLIPStyler, we are able to stylize a 3D scene and generalize to novel scenes without re-train our model. A straightforward solution is to combine previous image-conditioned 3D style transfer and text-conditioned 2D style transfer \\bigskip methods. However, such a solution cannot achieve our goal due to two main challenges. First, there is no multi-modal model matching point clouds and language at different feature scales (\\eg low-level, high-level). Second, we observe a style mixing issue when we stylize the content with different style conditions from text prompts. To address the first issue, we propose a 3D stylization framework to match the point cloud features with text features in local and global views. For the second issue, we propose an improved directional divergence loss to make arbitrary text styles more distinguishable as a complement to our framework. We conduct extensive experiments to show the effectiveness of our model on text-guided 3D scene style transfer. ",
    "url": "https://arxiv.org/abs/2305.15732",
    "authors": [
      "Ming Gao",
      "YanWu Xu",
      "Yang Zhao",
      "Tingbo Hou",
      "Tingbo Hou",
      "Chenkai Zhao",
      "Mingming Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15738",
    "title": "Maximum Weight Independent Set in Graphs with no Long Claws in  Quasi-Polynomial Time",
    "abstract": "We show that the \\textsc{Maximum Weight Independent Set} problem (\\textsc{MWIS}) can be solved in quasi-polynomial time on $H$-free graphs (graphs excluding a fixed graph $H$ as an induced subgraph) for every $H$ whose every connected component is a path or a subdivided claw (i.e., a tree with at most three leaves). This completes the dichotomy of the complexity of \\textsc{MWIS} in $\\mathcal{F}$-free graphs for any finite set $\\mathcal{F}$ of graphs into NP-hard cases and cases solvable in quasi-polynomial time, and corroborates the conjecture that the cases not known to be NP-hard are actually polynomial-time solvable. The key graph-theoretic ingredient in our result is as follows. Fix an integer $t \\geq 1$. Let $S_{t,t,t}$ be the graph created from three paths on $t$ edges by identifying one endpoint of each path into a single vertex. We show that, given a graph $G$, one can in polynomial time find either an induced $S_{t,t,t}$ in $G$, or a balanced separator consisting of $\\Oh(\\log |V(G)|)$ vertex neighborhoods in $G$, or an extended strip decomposition of $G$ (a decomposition almost as useful for recursion for \\textsc{MWIS} as a partition into connected components) with each particle of weight multiplicatively smaller than the weight of $G$. This is a strengthening of a result of Majewski et al.\\ [ICALP~2022] which provided such an extended strip decomposition only after the deletion of $\\Oh(\\log |V(G)|)$ vertex neighborhoods. To reach the final result, we employ an involved branching strategy that relies on the structural lemma presented above. ",
    "url": "https://arxiv.org/abs/2305.15738",
    "authors": [
      "Peter Gartland",
      "Daniel Lokshtanov",
      "Tom\u00e1\u0161 Masa\u0159\u00edk",
      "Marcin Pilipczuk",
      "Micha\u0142 Pilipczuk",
      "Pawe\u0142 Rz\u0105\u017cewski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2305.15745",
    "title": "Robust Ante-hoc Graph Explainer using Bilevel Optimization",
    "abstract": "Explaining the decisions made by machine learning models for high-stakes applications is critical for increasing transparency and guiding improvements to these decisions. This is particularly true in the case of models for graphs, where decisions often depend on complex patterns combining rich structural and attribute data. While recent work has focused on designing so-called post-hoc explainers, the question of what constitutes a good explanation remains open. One intuitive property is that explanations should be sufficiently informative to enable humans to approximately reproduce the predictions given the data. However, we show that post-hoc explanations do not achieve this goal as their explanations are highly dependent on fixed model parameters (e.g., learned GNN weights). To address this challenge, this paper proposes RAGE (Robust Ante-hoc Graph Explainer), a novel and flexible ante-hoc explainer designed to discover explanations for a broad class of graph neural networks using bilevel optimization. RAGE is able to efficiently identify explanations that contain the full information needed for prediction while still enabling humans to rank these explanations based on their influence. Our experiments, based on graph classification and regression, show that RAGE explanations are more robust than existing post-hoc and ante-hoc approaches and often achieve similar or better accuracy than state-of-the-art models. ",
    "url": "https://arxiv.org/abs/2305.15745",
    "authors": [
      "Mert Kosan",
      "Arlei Silva",
      "Ambuj Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.15747",
    "title": "Union Subgraph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) are widely used for graph representation learning in many application domains. The expressiveness of vanilla GNNs is upper-bounded by 1-dimensional Weisfeiler-Leman (1-WL) test as they operate on rooted subtrees through iterative message passing. In this paper, we empower GNNs by injecting neighbor-connectivity information extracted from a new type of substructure. We first investigate different kinds of connectivities existing in a local neighborhood and identify a substructure called union subgraph, which is able to capture the complete picture of the 1-hop neighborhood of an edge. We then design a shortest-path-based substructure descriptor that possesses three nice properties and can effectively encode the high-order connectivities in union subgraphs. By infusing the encoded neighbor connectivities, we propose a novel model, namely Union Subgraph Neural Network (UnionSNN), which is proven to be strictly more powerful than 1-WL in distinguishing non-isomorphic graphs. Additionally, the local encoding from union subgraphs can also be injected into arbitrary message-passing neural networks (MPNNs) and Transformer-based models as a plugin. Extensive experiments on 17 benchmarks of both graph-level and node-level tasks demonstrate that UnionSNN outperforms state-of-the-art baseline models, with competitive computational efficiency. The injection of our local encoding to existing models is able to boost the performance by up to 11.09%. ",
    "url": "https://arxiv.org/abs/2305.15747",
    "authors": [
      "Jiaxing Xu",
      "Aihu Zhang",
      "Qingtian Bian",
      "Vijay Prakash Dwivedi",
      "Yiping Ke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15762",
    "title": "Dynamic Enhancement Network for Partial Multi-modality Person  Re-identification",
    "abstract": "Many existing multi-modality studies are based on the assumption of modality integrity. However, the problem of missing arbitrary modalities is very common in real life, and this problem is less studied, but actually important in the task of multi-modality person re-identification (Re-ID). To this end, we design a novel dynamic enhancement network (DENet), which allows missing arbitrary modalities while maintaining the representation ability of multiple modalities, for partial multi-modality person Re-ID. To be specific, the multi-modal representation of the RGB, near-infrared (NIR) and thermal-infrared (TIR) images is learned by three branches, in which the information of missing modalities is recovered by the feature transformation module. Since the missing state might be changeable, we design a dynamic enhancement module, which dynamically enhances modality features according to the missing state in an adaptive manner, to improve the multi-modality representation. Extensive experiments on multi-modality person Re-ID dataset RGBNT201 and vehicle Re-ID dataset RGBNT100 comparing to the state-of-the-art methods verify the effectiveness of our method in complex and changeable environments. ",
    "url": "https://arxiv.org/abs/2305.15762",
    "authors": [
      "Aihua Zheng",
      "Ziling He",
      "Zi Wang",
      "Chenglong Li",
      "Jin Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15765",
    "title": "Language-Guided 3D Object Detection in Point Cloud for Autonomous  Driving",
    "abstract": "This paper addresses the problem of 3D referring expression comprehension (REC) in autonomous driving scenario, which aims to ground a natural language to the targeted region in LiDAR point clouds. Previous approaches for REC usually focus on the 2D or 3D-indoor domain, which is not suitable for accurately predicting the location of the queried 3D region in an autonomous driving scene. In addition, the upper-bound limitation and the heavy computation cost motivate us to explore a better solution. In this work, we propose a new multi-modal visual grounding task, termed LiDAR Grounding. Then we devise a Multi-modal Single Shot Grounding (MSSG) approach with an effective token fusion strategy. It jointly learns the LiDAR-based object detector with the language features and predicts the targeted region directly from the detector without any post-processing. Moreover, the image feature can be flexibly integrated into our approach to provide rich texture and color information. The cross-modal learning enforces the detector to concentrate on important regions in the point cloud by considering the informative language expressions, thus leading to much better accuracy and efficiency. Extensive experiments on the Talk2Car dataset demonstrate the effectiveness of the proposed methods. Our work offers a deeper insight into the LiDAR-based grounding task and we expect it presents a promising direction for the autonomous driving community. ",
    "url": "https://arxiv.org/abs/2305.15765",
    "authors": [
      "Wenhao Cheng",
      "Junbo Yin",
      "Wei Li",
      "Ruigang Yang",
      "Jianbing Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15770",
    "title": "TLNets: Transformation Learning Networks for long-range time-series  prediction",
    "abstract": "Time series prediction is a prevalent issue across various disciplines, such as meteorology, traffic surveillance, investment, and energy production and consumption. Many statistical and machine-learning strategies have been developed to tackle this problem. However, these approaches either lack explainability or exhibit less satisfactory performance when the prediction horizon increases. To this end, we propose a novel plan for the designing of networks' architecture based on transformations, possessing the potential to achieve an enhanced receptive field in learning which brings benefits to fuse features across scales. In this context, we introduce four different transformation mechanisms as bases to construct the learning model including Fourier Transform (FT), Singular Value Decomposition (SVD), matrix multiplication and Conv block. Hence, we develop four learning models based on the above building blocks, namely, FT-Matrix, FT-SVD, FT-Conv, and Conv-SVD. Note that the FT and SVD blocks are capable of learning global information, while the Conv blocks focus on learning local information. The matrix block is sparsely designed to learn both global and local information simultaneously. The above Transformation Learning Networks (TLNets) have been extensively tested and compared with multiple baseline models based on several real-world datasets and showed clear potential in long-range time-series forecasting. ",
    "url": "https://arxiv.org/abs/2305.15770",
    "authors": [
      "Wei Wang",
      "Yang Liu",
      "Hao Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15772",
    "title": "Security Impact Analysis of Degree of Field Extension in Lattice Attacks  on Ring-LWE Problem",
    "abstract": "Modern information communications use cryptography to keep the contents of communications confidential. RSA (Rivest-Shamir-Adleman) cryptography and elliptic curve cryptography, which are public-key cryptosystems, are widely used cryptographic schemes. However, it is known that these cryptographic schemes can be deciphered in a very short time by Shor's algorithm when a quantum computer is put into practical use. Therefore, several methods have been proposed for quantum computer-resistant cryptosystems that cannot be cracked even by a quantum computer. A simple implementation of LWE-based lattice cryptography based on the LWE (Learning With Errors) problem requires a key length of $O(n^2)$ to ensure the same level of security as existing public-key cryptography schemes such as RSA and elliptic curve cryptography. In this paper, we attacked the Ring-LWE (RLWE) scheme, which can be implemented with a short key length, with a modified LLL (Lenstra-Lenstra-Lov\\'asz) basis reduction algorithm and investigated the trend in the degree of field extension required to generate a secure and small key. Results showed that the lattice-based cryptography may be strengthened by employing Cullen or Mersenne prime numbers as the degree of field extension. ",
    "url": "https://arxiv.org/abs/2305.15772",
    "authors": [
      "Yuri Lucas Direbieski",
      "Hiroki Tanioka",
      "Kenji Matsuura",
      "Hironori Takeuchi",
      "Masahiko Sano",
      "Tetsushi Ueta"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.15792",
    "title": "IDEA: Invariant Causal Defense for Graph Adversarial Robustness",
    "abstract": "Graph neural networks (GNNs) have achieved remarkable success in various tasks, however, their vulnerability to adversarial attacks raises concerns for the real-world applications. Existing defense methods can resist some attacks, but suffer unbearable performance degradation under other unknown attacks. This is due to their reliance on either limited observed adversarial examples to optimize (adversarial training) or specific heuristics to alter graph or model structures (graph purification or robust aggregation). In this paper, we propose an Invariant causal DEfense method against adversarial Attacks (IDEA), providing a new perspective to address this issue. The method aims to learn causal features that possess strong predictability for labels and invariant predictability across attacks, to achieve graph adversarial robustness. Through modeling and analyzing the causal relationships in graph adversarial attacks, we design two invariance objectives to learn the causal features. Extensive experiments demonstrate that our IDEA significantly outperforms all the baselines under both poisoning and evasion attacks on five benchmark datasets, highlighting the strong and invariant predictability of IDEA. The implementation of IDEA is available at https://anonymous.4open.science/r/IDEA_repo-666B. ",
    "url": "https://arxiv.org/abs/2305.15792",
    "authors": [
      "Shuchang Tao",
      "Qi Cao",
      "Huawei Shen",
      "Yunfan Wu",
      "Bingbing Xu",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.15804",
    "title": "Smoothed Complexity of SWAP in Local Graph Partitioning",
    "abstract": "We give the first quasipolynomial upper bound $\\phi n^{\\text{polylog}(n)}$ for the smoothed complexity of the SWAP algorithm for local Graph Partitioning (also known as Bisection Width), where $n$ is the number of nodes in the graph and $\\phi$ is a parameter that measures the magnitude of perturbations applied on its edge weights. More generally, we show that the same quasipolynomial upper bound holds for the smoothed complexity of the 2-FLIP algorithm for any binary Maximum Constraint Satisfaction Problem, including local Max-Cut, for which similar bounds were only known for $1$-FLIP. Our results are based on an analysis of cycles formed in long sequences of double flips, showing that it is unlikely for every move in a long sequence to incur a positive but small improvement in the cut weight. ",
    "url": "https://arxiv.org/abs/2305.15804",
    "authors": [
      "Xi Chen",
      "Chenghao Guo",
      "Emmanouil-Vasileios Vlatakis-Gkaragkounis",
      "Mihalis Yannakakis"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2305.15811",
    "title": "Unifying gradient regularization for Heterogeneous Graph Neural Networks",
    "abstract": "Heterogeneous Graph Neural Networks (HGNNs) are a class of powerful deep learning methods widely used to learn representations of heterogeneous graphs. Despite the fast development of HGNNs, they still face some challenges such as over-smoothing, and non-robustness. Previous studies have shown that these problems can be reduced by using gradient regularization methods. However, the existing gradient regularization methods focus on either graph topology or node features. There is no universal approach to integrate these features, which severely affects the efficiency of regularization. In addition, the inclusion of gradient regularization into HGNNs sometimes leads to some problems, such as an unstable training process, increased complexity and insufficient coverage regularized information. Furthermore, there is still short of a complete theoretical analysis of the effects of gradient regularization on HGNNs. In this paper, we propose a novel gradient regularization method called Grug, which iteratively applies regularization to the gradients generated by both propagated messages and the node features during the message-passing process. Grug provides a unified framework integrating graph topology and node features, based on which we conduct a detailed theoretical analysis of their effectiveness. Specifically, the theoretical analyses elaborate the advantages of Grug: 1) Decreasing sample variance during the training process (Stability); 2) Enhancing the generalization of the model (Universality); 3) Reducing the complexity of the model (Simplicity); 4) Improving the integrity and diversity of graph information utilization (Diversity). As a result, Grug has the potential to surpass the theoretical upper bounds set by DropMessage (AAAI-23 Distinguished Papers). In addition, we evaluate Grug on five public real-world datasets with two downstream tasks. ",
    "url": "https://arxiv.org/abs/2305.15811",
    "authors": [
      "Xiao Yang",
      "Xuejiao Zhao",
      "Zhiqi Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15815",
    "title": "A Burton-Miller-type boundary element method based on a hybrid integral  representation and its application to cavity scattering",
    "abstract": "This study builds on a recent paper by Lai et al [Appl. Comput. Harmon. Anal., 2018] in which a novel boundary integral formulation is presented for scalar wave scattering analysis in two-dimensional layered and half-spaces. The seminal paper proposes a hybrid integral representation that combines the Sommerfeld integral and layer potential to efficiently deal with the boundaries of infinite length. In this work, we modify the integral formulation to eliminate the fictitious eigenvalues by employing Burton-Miller's approach. We also discuss reasonable parameter settings for the hybrid integral equation to ensure efficient and accurate numerical solutions. Furthermore, we extend the modified formulation for the scattering from a cavity in a half-space whose boundary is locally perturbed. To address the cavity scattering, we introduce a virtual boundary enclosing the cavity and couple the integral equation on it with the hybrid equation. The effectiveness of the proposed method is demonstrated through numerical examples. ",
    "url": "https://arxiv.org/abs/2305.15815",
    "authors": [
      "Riku Toshimitsu",
      "Hiroshi Isakari"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2305.15822",
    "title": "Towards Label Position Bias in Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful tool for semi-supervised node classification tasks. However, recent studies have revealed various biases in GNNs stemming from both node features and graph topology. In this work, we uncover a new bias - label position bias, which indicates that the node closer to the labeled nodes tends to perform better. We introduce a new metric, the Label Proximity Score, to quantify this bias, and find that it is closely related to performance disparities. To address the label position bias, we propose a novel optimization framework for learning a label position unbiased graph structure, which can be applied to existing GNNs. Extensive experiments demonstrate that our proposed method not only outperforms backbone methods but also significantly mitigates the issue of label position bias in GNNs. ",
    "url": "https://arxiv.org/abs/2305.15822",
    "authors": [
      "Haoyu Han",
      "Xiaorui Liu",
      "Feng Shi",
      "MohamadAli Torkamani",
      "Charu C. Aggarwal",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15829",
    "title": "Definition and Detection of Defects in NFT Smart Contracts",
    "abstract": "Recently, the birth of non-fungible tokens (NFTs) has attracted great attention. NFTs are capable of representing users' ownership on the blockchain and have experienced tremendous market sales due to their popularity. Unfortunately, the high value of NFTs also makes them a target for attackers. The defects in NFT smart contracts could be exploited by attackers to harm the security and reliability of the NFT ecosystem. Despite the significance of this issue, there is a lack of systematic work that focuses on analyzing NFT smart contracts, which may raise worries about the security of users' NFTs. To address this gap, in this paper, we introduce 5 defects in NFT smart contracts. Each defect is defined and illustrated with a code example highlighting its features and consequences, paired with possible solutions to fix it. Furthermore, we propose a tool named NFTGuard to detect our defined defects based on a symbolic execution framework. Specifically, NFTGuard extracts the information of the state variables from the contract abstract syntax tree (AST), which is critical for identifying variable-loading and storing operations during symbolic execution. Furthermore, NFTGuard recovers source-code-level features from the bytecode to effectively locate defects and report them based on predefined detection patterns. We run NFTGuard on 16,527 real-world smart contracts and perform an evaluation based on the manually labeled results. We find that 1,331 contracts contain at least one of the 5 defects, and the overall precision achieved by our tool is 92.6%. ",
    "url": "https://arxiv.org/abs/2305.15829",
    "authors": [
      "Shuo Yang",
      "Jiachi Chen",
      "Zibin Zheng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.15836",
    "title": "Improved Multi-Scale Grid Rendering of Point Clouds for Radar Object  Detection Networks",
    "abstract": "Architectures that first convert point clouds to a grid representation and then apply convolutional neural networks achieve good performance for radar-based object detection. However, the transfer from irregular point cloud data to a dense grid structure is often associated with a loss of information, due to the discretization and aggregation of points. In this paper, we propose a novel architecture, multi-scale KPPillarsBEV, that aims to mitigate the negative effects of grid rendering. Specifically, we propose a novel grid rendering method, KPBEV, which leverages the descriptive power of kernel point convolutions to improve the encoding of local point cloud contexts during grid rendering. In addition, we propose a general multi-scale grid rendering formulation to incorporate multi-scale feature maps into convolutional backbones of detection networks with arbitrary grid rendering methods. We perform extensive experiments on the nuScenes dataset and evaluate the methods in terms of detection performance and computational complexity. The proposed multi-scale KPPillarsBEV architecture outperforms the baseline by 5.37% and the previous state of the art by 2.88% in Car AP4.0 (average precision for a matching threshold of 4 meters) on the nuScenes validation set. Moreover, the proposed single-scale KPBEV grid rendering improves the Car AP4.0 by 2.90% over the baseline while maintaining the same inference speed. ",
    "url": "https://arxiv.org/abs/2305.15836",
    "authors": [
      "Daniel K\u00f6hler",
      "Maurice Quach",
      "Michael Ulrich",
      "Frank Meinl",
      "Bastian Bischoff",
      "Holger Blume"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.15843",
    "title": "TabGSL: Graph Structure Learning for Tabular Data Prediction",
    "abstract": "This work presents a novel approach to tabular data prediction leveraging graph structure learning and graph neural networks. Despite the prevalence of tabular data in real-world applications, traditional deep learning methods often overlook the potentially valuable associations between data instances. Such associations can offer beneficial insights for classification tasks, as instances may exhibit similar patterns of correlations among features and target labels. This information can be exploited by graph neural networks, necessitating robust graph structures. However, existing studies primarily focus on improving graph structure from noisy data, largely neglecting the possibility of deriving graph structures from tabular data. We present a novel solution, Tabular Graph Structure Learning (TabGSL), to enhance tabular data prediction by simultaneously learning instance correlation and feature interaction within a unified framework. This is achieved through a proposed graph contrastive learning module, along with transformer-based feature extractor and graph neural network. Comprehensive experiments conducted on 30 benchmark tabular datasets demonstrate that TabGSL markedly outperforms both tree-based models and recent deep learning-based tabular models. Visualizations of the learned instance embeddings further substantiate the effectiveness of TabGSL. ",
    "url": "https://arxiv.org/abs/2305.15843",
    "authors": [
      "Jay Chiehen Liao",
      "Cheng-Te Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.15852",
    "title": "Self-contradictory Hallucinations of Large Language Models: Evaluation,  Detection and Mitigation",
    "abstract": "Large language models (large LMs) are susceptible to producing text with hallucinated content. Self-contradiction, where the LM generates two contradictory sentences within the same context, is an important form of hallucination. In this work, we present a comprehensive analysis on self-contradiction for state-of-the-art, instruction-tuned LMs, including evaluation, detection, and mitigation. To effectively trigger self-contradictions, we design a framework that constrains LMs to generate appropriate sentence pairs. Our evaluation on these sentence pairs reveals that self-contradictions occur frequently across different LMs for both famous and lesser-known topics. Next, we prompt the LMs to detect self-contradictions. Our results indicate that ChatGPT and GPT-4 are able to accurately identify self-contradictions, while Vicuna-13B struggles to do so. For example, with our best prompting method, ChatGPT achieves 91.0% precision and 80.5% recall on the sentence pairs generated by itself. To automatically mitigate self-contradictions, we develop an iterative algorithm that prompts the LMs to remove the detected self-contradictions from the generated text. Our algorithm successfully revises the text such that self-contradictions are significantly reduced, while maintaining its fluency and informativeness. Importantly, our entire pipeline of triggering, detecting, and mitigating self-contradictions is applicable to black-box LMs and does not require any external grounded knowledge. ",
    "url": "https://arxiv.org/abs/2305.15852",
    "authors": [
      "Niels M\u00fcndler",
      "Jingxuan He",
      "Slobodan Jenko",
      "Martin Vechev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15859",
    "title": "Anomalous Sound Detection Based on Sound Separation",
    "abstract": "This paper proposes an unsupervised anomalous sound detection method using sound separation. In factory environments, background noise and non-objective sounds obscure desired machine sounds, making it challenging to detect anomalous sounds. Therefore, using sounds not mixed with background noise or non-purpose sounds in the detection system is desirable. We compared two versions of our proposed method, one using sound separation as a pre-processing step and the other using separation-based outlier exposure that uses the error between two separated sounds. Based on the assumption that differences in separation performance between normal and anomalous sounds affect detection results, a sound separation model specific to a particular product type was used in both versions. Experimental results indicate that the proposed method improved anomalous sound detection performance for all Machine IDs, achieving a maximum improvement of 39%. ",
    "url": "https://arxiv.org/abs/2305.15859",
    "authors": [
      "Kanta Shimonishi",
      "Kota Dohi",
      "Yohei Kawaguchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.15870",
    "title": "Robust asymptotic observer of motion states with nonlinear friction",
    "abstract": "This paper revisits the previously proposed linear asymptotic observer of the motion state variables with nonlinear friction and provides a robust design suitable for both, transient presliding and steady-state sliding phases of the relative motion. The class of motion systems with the only measurable output displacement is considered. The reduced-order Luenberger type observer is designed based on the obtained simplified state-space representation with a time-varying system matrix. The resulted observation error dynamics proves to be robust and appropriate for all variations of the system matrix, which are due to the nonlinear spatially varying friction. A specially designed tribological setup to accurately monitor the relative motion between two contacting friction surfaces is used to collect the experimental data of the deceleration trajectories when excited by a series of impulses. The performance of the state estimation using the proposed observer is shown based on the collected experimental data. ",
    "url": "https://arxiv.org/abs/2305.15870",
    "authors": [
      "Michael Ruderman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.15872",
    "title": "Jointprop: Joint Semi-supervised Learning for Entity and Relation  Extraction with Heterogeneous Graph-based Propagation",
    "abstract": "Semi-supervised learning has been an important approach to address challenges in extracting entities and relations from limited data. However, current semi-supervised works handle the two tasks (i.e., Named Entity Recognition and Relation Extraction) separately and ignore the cross-correlation of entity and relation instances as well as the existence of similar instances across unlabeled data. To alleviate the issues, we propose Jointprop, a Heterogeneous Graph-based Propagation framework for joint semi-supervised entity and relation extraction, which captures the global structure information between individual tasks and exploits interactions within unlabeled data. Specifically, we construct a unified span-based heterogeneous graph from entity and relation candidates and propagate class labels based on confidence scores. We then employ a propagation learning scheme to leverage the affinities between labelled and unlabeled samples. Experiments on benchmark datasets show that our framework outperforms the state-of-the-art semi-supervised approaches on NER and RE tasks. We show that the joint semi-supervised learning of the two tasks benefits from their codependency and validates the importance of utilizing the shared information between unlabeled data. ",
    "url": "https://arxiv.org/abs/2305.15872",
    "authors": [
      "Yandan Zheng",
      "Anran Hao",
      "Anh Tuan Luu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15881",
    "title": "Generative Adversarial Reduced Order Modelling",
    "abstract": "In this work, we present GAROM, a new approach for reduced order modelling (ROM) based on generative adversarial networks (GANs). GANs have the potential to learn data distribution and generate more realistic data. While widely applied in many areas of deep learning, little research is done on their application for ROM, i.e. approximating a high-fidelity model with a simpler one. In this work, we combine the GAN and ROM framework, by introducing a data-driven generative adversarial model able to learn solutions to parametric differential equations. The latter is achieved by modelling the discriminator network as an autoencoder, extracting relevant features of the input, and applying a conditioning mechanism to the generator and discriminator networks specifying the differential equation parameters. We show how to apply our methodology for inference, provide experimental evidence of the model generalisation, and perform a convergence study of the method. ",
    "url": "https://arxiv.org/abs/2305.15881",
    "authors": [
      "Dario Coscia",
      "Nicola Demo",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2305.15882",
    "title": "A filtered Chebyshev spectral method for conservation laws on network",
    "abstract": "We propose a spectral method based on the implementation of Chebyshev polynomials to study a model of conservation laws on network. We avoid the Gibbs phenomenon near shock discontinuities by implementing a filter in the frequency space in order to add local viscosity able to contrast the spurious oscillations appearing in the profile of the solution and we prove the convergence of the semi-discrete method by using the compensated compactness theorem. thanks to several simulation, we make a comparison between the implementation of the proposed method with a first order finite volume scheme. ",
    "url": "https://arxiv.org/abs/2305.15882",
    "authors": [
      "Sabrina Francesca Pellegrino"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2305.15895",
    "title": "Collective Knowledge Graph Completion with Mutual Knowledge Distillation",
    "abstract": "Knowledge graph completion (KGC), the task of predicting missing information based on the existing relational data inside a knowledge graph (KG), has drawn significant attention in recent years. However, the predictive power of KGC methods is often limited by the completeness of the existing knowledge graphs from different sources and languages. In monolingual and multilingual settings, KGs are potentially complementary to each other. In this paper, we study the problem of multi-KG completion, where we focus on maximizing the collective knowledge from different KGs to alleviate the incompleteness of individual KGs. Specifically, we propose a novel method called CKGC-CKD that uses relation-aware graph convolutional network encoder models on both individual KGs and a large fused KG in which seed alignments between KGs are regarded as edges for message propagation. An additional mutual knowledge distillation mechanism is also employed to maximize the knowledge transfer between the models of \"global\" fused KG and the \"local\" individual KGs. Experimental results on multilingual datasets have shown that our method outperforms all state-of-the-art models in the KGC task. ",
    "url": "https://arxiv.org/abs/2305.15895",
    "authors": [
      "Weihang Zhang",
      "Ovidiu Serban",
      "Jiahao Sun",
      "Yi-ke Guo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.15897",
    "title": "Impact of Log Parsing on Log-based Anomaly Detection",
    "abstract": "Software systems log massive amounts of data, recording important runtime information. Such logs are used, for example, for log-based anomaly detection, which aims to automatically detect abnormal behaviors of the system under analysis by processing the information recorded in its logs. Many log-based anomaly detection techniques based on deep-learning models include a pre-processing step called log parsing. However, understanding the impact of log parsing on the accuracy of anomaly detection techniques has received surprisingly little attention so far. Investigating what are the key properties log parsing techniques should ideally have to help anomaly detection is therefore warranted. In this paper, we report on a comprehensive empirical study on the impact of log parsing on anomaly detection accuracy, using 13 log parsing techniques and five deep-learning-based anomaly detection techniques on two publicly available log datasets. Our empirical results show that, despite what is widely assumed, there is no strong correlation between log parsing accuracy and anomaly detection accuracy (regardless of the metric used for measuring log parsing accuracy). Moreover, we experimentally confirm existing theoretical results showing that it is a property that we refer to as distinguishability in log parsing results as opposed to their accuracy that plays an essential role in achieving accurate anomaly detection. ",
    "url": "https://arxiv.org/abs/2305.15897",
    "authors": [
      "Zanis Ali Khan",
      "Donghwan Shin",
      "Domenico Bianculli",
      "Lionel Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.15904",
    "title": "MTCue: Learning Zero-Shot Control of Extra-Textual Attributes by  Leveraging Unstructured Context in Neural Machine Translation",
    "abstract": "Efficient utilisation of both intra- and extra-textual context remains one of the critical gaps between machine and human translation. Existing research has primarily focused on providing individual, well-defined types of context in translation, such as the surrounding text or discrete external variables like the speaker's gender. This work introduces MTCue, a novel neural machine translation (NMT) framework that interprets all context (including discrete variables) as text. MTCue learns an abstract representation of context, enabling transferability across different data settings and leveraging similar attributes in low-resource scenarios. With a focus on a dialogue domain with access to document and metadata context, we extensively evaluate MTCue in four language pairs in both translation directions. Our framework demonstrates significant improvements in translation quality over a parameter-matched non-contextual baseline, as measured by BLEU (+0.88) and Comet (+1.58). Moreover, MTCue significantly outperforms a \"tagging\" baseline at translating English text. Analysis reveals that the context encoder of MTCue learns a representation space that organises context based on specific attributes, such as formality, enabling effective zero-shot control. Pre-training on context embeddings also improves MTCue's few-shot performance compared to the \"tagging\" baseline. Finally, an ablation study conducted on model components and contextual variables further supports the robustness of MTCue for context-based NMT. ",
    "url": "https://arxiv.org/abs/2305.15904",
    "authors": [
      "Sebastian Vincent",
      "Robert Flynn",
      "Carolina Scarton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15908",
    "title": "Response Generation in Longitudinal Dialogues: Which Knowledge  Representation Helps?",
    "abstract": "Longitudinal Dialogues (LD) are the most challenging type of conversation for human-machine dialogue systems. LDs include the recollections of events, personal thoughts, and emotions specific to each individual in a sparse sequence of dialogue sessions. Dialogue systems designed for LDs should uniquely interact with the users over multiple sessions and long periods of time (e.g. weeks), and engage them in personal dialogues to elaborate on their feelings, thoughts, and real-life events. In this paper, we study the task of response generation in LDs. We evaluate whether general-purpose Pre-trained Language Models (PLM) are appropriate for this purpose. We fine-tune two PLMs, GePpeTto (GPT-2) and iT5, using a dataset of LDs. We experiment with different representations of the personal knowledge extracted from LDs for grounded response generation, including the graph representation of the mentioned events and participants. We evaluate the performance of the models via automatic metrics and the contribution of the knowledge via the Integrated Gradients technique. We categorize the natural language generation errors via human evaluations of contextualization, appropriateness and engagement of the user. ",
    "url": "https://arxiv.org/abs/2305.15908",
    "authors": [
      "Seyed Mahed Mousavi",
      "Simone Caldarella",
      "Giuseppe Riccardi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.15912",
    "title": "Neural Characteristic Activation Value Analysis for Improved ReLU  Network Feature Learning",
    "abstract": "We examine the characteristic activation values of individual ReLU units in neural networks. We refer to the corresponding set for such characteristic activation values in the input space as the characteristic activation set of a ReLU unit. We draw an explicit connection between the characteristic activation set and learned features in ReLU networks. This connection leads to new insights into why various neural network normalization techniques used in modern deep learning architectures regularize and stabilize SGD optimization. Utilizing these insights, we propose a geometric approach to parameterize ReLU networks for improved feature learning. We empirically verify its usefulness with less carefully chosen initialization schemes and larger learning rates. We report improved optimization stability, faster convergence speed, and better generalization performance. ",
    "url": "https://arxiv.org/abs/2305.15912",
    "authors": [
      "Wenlin Chen",
      "Hong Ge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.15930",
    "title": "End-to-End Meta-Bayesian Optimisation with Transformer Neural Processes",
    "abstract": "Meta-Bayesian optimisation (meta-BO) aims to improve the sample efficiency of Bayesian optimisation by leveraging data from related tasks. While previous methods successfully meta-learn either a surrogate model or an acquisition function independently, joint training of both components remains an open challenge. This paper proposes the first end-to-end differentiable meta-BO framework that generalises neural processes to learn acquisition functions via transformer architectures. We enable this end-to-end framework with reinforcement learning (RL) to tackle the lack of labelled acquisition data. Early on, we notice that training transformer-based neural processes from scratch with RL is challenging due to insufficient supervision, especially when rewards are sparse. We formalise this claim with a combinatorial analysis showing that the widely used notion of regret as a reward signal exhibits a logarithmic sparsity pattern in trajectory lengths. To tackle this problem, we augment the RL objective with an auxiliary task that guides part of the architecture to learn a valid probabilistic model as an inductive bias. We demonstrate that our method achieves state-of-the-art regret results against various baselines in experiments on standard hyperparameter optimisation tasks and also outperforms others in the real-world problems of mixed-integer programming tuning, antibody design, and logic synthesis for electronic design automation. ",
    "url": "https://arxiv.org/abs/2305.15930",
    "authors": [
      "Alexandre Maraval",
      "Matthieu Zimmer",
      "Antoine Grosnit",
      "Haitham Bou Ammar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15940",
    "title": "Mask Attack Detection Using Vascular-weighted Motion-robust rPPG Signals",
    "abstract": "Detecting 3D mask attacks to a face recognition system is challenging. Although genuine faces and 3D face masks show significantly different remote photoplethysmography (rPPG) signals, rPPG-based face anti-spoofing methods often suffer from performance degradation due to unstable face alignment in the video sequence and weak rPPG signals. To enhance the rPPG signal in a motion-robust way, a landmark-anchored face stitching method is proposed to align the faces robustly and precisely at the pixel-wise level by using both SIFT keypoints and facial landmarks. To better encode the rPPG signal, a weighted spatial-temporal representation is proposed, which emphasizes the face regions with rich blood vessels. In addition, characteristics of rPPG signals in different color spaces are jointly utilized. To improve the generalization capability, a lightweight EfficientNet with a Gated Recurrent Unit (GRU) is designed to extract both spatial and temporal features from the rPPG spatial-temporal representation for classification. The proposed method is compared with the state-of-the-art methods on five benchmark datasets under both intra-dataset and cross-dataset evaluations. The proposed method shows a significant and consistent improvement in performance over other state-of-the-art rPPG-based methods for face spoofing detection. ",
    "url": "https://arxiv.org/abs/2305.15940",
    "authors": [
      "Chenglin Yao",
      "Jianfeng Ren",
      "Ruibin Bai",
      "Heshan Du",
      "Jiang Liu",
      "Xudong Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15942",
    "title": "Comparison of Pedestrian Prediction Models from Trajectory and  Appearance Data for Autonomous Driving",
    "abstract": "The ability to anticipate pedestrian motion changes is a critical capability for autonomous vehicles. In urban environments, pedestrians may enter the road area and create a high risk for driving, and it is important to identify these cases. Typical predictors use the trajectory history to predict future motion, however in cases of motion initiation, motion in the trajectory may only be clearly visible after a delay, which can result in the pedestrian has entered the road area before an accurate prediction can be made. Appearance data includes useful information such as changes of gait, which are early indicators of motion changes, and can inform trajectory prediction. This work presents a comparative evaluation of trajectory-only and appearance-based methods for pedestrian prediction, and introduces a new dataset experiment for prediction using appearance. We create two trajectory and image datasets based on the combination of image and trajectory sequences from the popular NuScenes dataset, and examine prediction of trajectories using observed appearance to influence futures. This shows some advantages over trajectory prediction alone, although problems with the dataset prevent advantages of appearance-based models from being shown. We describe methods for improving the dataset and experiment to allow benefits of appearance-based models to be captured. ",
    "url": "https://arxiv.org/abs/2305.15942",
    "authors": [
      "Anthony Knittel",
      "Morris Antonello",
      "John Redford",
      "Subramanian Ramamoorthy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.15944",
    "title": "How to Turn Your Knowledge Graph Embeddings into Generative Models via  Probabilistic Circuits",
    "abstract": "Some of the most successful knowledge graph embedding (KGE) models for link prediction -- CP, RESCAL, TuckER, ComplEx -- can be interpreted as energy-based models. Under this perspective they are not amenable for exact maximum-likelihood estimation (MLE), sampling and struggle to integrate logical constraints. This work re-interprets the score functions of these KGEs as circuits -- constrained computational graphs allowing efficient marginalisation. Then, we design two recipes to obtain efficient generative circuit models by either restricting their activations to be non-negative or squaring their outputs. Our interpretation comes with little or no loss of performance for link prediction, while the circuits framework unlocks exact learning by MLE, efficient sampling of new triples, and guarantee that logical constraints are satisfied by design. Furthermore, our models scale more gracefully than the original KGEs on graphs with millions of entities. ",
    "url": "https://arxiv.org/abs/2305.15944",
    "authors": [
      "Lorenzo Loconte",
      "Nicola Di Mauro",
      "Robert Peharz",
      "Antonio Vergari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15945",
    "title": "Learning to Act through Evolution of Neural Diversity in Random Neural  Networks",
    "abstract": "Biological nervous systems consist of networks of diverse, sophisticated information processors in the form of neurons of different classes. In most artificial neural networks (ANNs), neural computation is abstracted to an activation function that is usually shared between all neurons within a layer or even the whole network; training of ANNs focuses on synaptic optimization. In this paper, we propose the optimization of neuro-centric parameters to attain a set of diverse neurons that can perform complex computations. Demonstrating the promise of the approach, we show that evolving neural parameters alone allows agents to solve various reinforcement learning tasks without optimizing any synaptic weights. While not aiming to be an accurate biological model, parameterizing neurons to a larger degree than the current common practice, allows us to ask questions about the computational abilities afforded by neural diversity in random neural networks. The presented results open up interesting future research directions, such as combining evolved neural diversity with activity-dependent plasticity. ",
    "url": "https://arxiv.org/abs/2305.15945",
    "authors": [
      "Joachim Winther Pedersen",
      "Sebastian Risi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15956",
    "title": "Anomaly Detection with Conditioned Denoising Diffusion Models",
    "abstract": "Reconstruction-based methods have struggled to achieve competitive performance on anomaly detection. In this paper, we introduce Denoising Diffusion Anomaly Detection (DDAD). We propose a novel denoising process for image reconstruction conditioned on a target image. This results in a coherent restoration that closely resembles the target image. Subsequently, our anomaly detection framework leverages this conditioning where the target image is set as the input image to guide the denoising process, leading to defectless reconstruction while maintaining nominal patterns. We localise anomalies via a pixel-wise and feature-wise comparison of the input and reconstructed image. Finally, to enhance the effectiveness of feature comparison, we introduce a domain adaptation method that utilises generated examples from our conditioned denoising process to fine-tune the feature extractor. The veracity of the approach is demonstrated on various datasets including MVTec and VisA benchmarks, achieving state-of-the-art results of 99.5% and 99.3% image-level AUROC respectively. ",
    "url": "https://arxiv.org/abs/2305.15956",
    "authors": [
      "Arian Mousakhan",
      "Thomas Brox",
      "Jawad Tayyub"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15961",
    "title": "Quantifying the Intrinsic Usefulness of Attributional Explanations for  Graph Neural Networks with Artificial Simulatability Studies",
    "abstract": "Despite the increasing relevance of explainable AI, assessing the quality of explanations remains a challenging issue. Due to the high costs associated with human-subject experiments, various proxy metrics are often used to approximately quantify explanation quality. Generally, one possible interpretation of the quality of an explanation is its inherent value for teaching a related concept to a student. In this work, we extend artificial simulatability studies to the domain of graph neural networks. Instead of costly human trials, we use explanation-supervisable graph neural networks to perform simulatability studies to quantify the inherent usefulness of attributional graph explanations. We perform an extensive ablation study to investigate the conditions under which the proposed analyses are most meaningful. We additionally validate our methods applicability on real-world graph classification and regression datasets. We find that relevant explanations can significantly boost the sample efficiency of graph neural networks and analyze the robustness towards noise and bias in the explanations. We believe that the notion of usefulness obtained from our proposed simulatability analysis provides a dimension of explanation quality that is largely orthogonal to the common practice of faithfulness and has great potential to expand the toolbox of explanation quality assessments, specifically for graph explanations. ",
    "url": "https://arxiv.org/abs/2305.15961",
    "authors": [
      "Jonas Teufel",
      "Luca Torresi",
      "Pascal Friederich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15984",
    "title": "Dynamic Inter-treatment Information Sharing for Heterogeneous Treatment  Effects Estimation",
    "abstract": "Existing heterogeneous treatment effects learners, also known as conditional average treatment effects (CATE) learners, lack a general mechanism for end-to-end inter-treatment information sharing, and data have to be split among potential outcome functions to train CATE learners which can lead to biased estimates with limited observational datasets. To address this issue, we propose a novel deep learning-based framework to train CATE learners that facilitates dynamic end-to-end information sharing among treatment groups. The framework is based on \\textit{soft weight sharing} of \\textit{hypernetworks}, which offers advantages such as parameter efficiency, faster training, and improved results. The proposed framework complements existing CATE learners and introduces a new class of uncertainty-aware CATE learners that we refer to as \\textit{HyperCATE}. We develop HyperCATE versions of commonly used CATE learners and evaluate them on IHDP, ACIC-2016, and Twins benchmarks. Our experimental results show that the proposed framework improves the CATE estimation error via counterfactual inference, with increasing effectiveness for smaller datasets. ",
    "url": "https://arxiv.org/abs/2305.15984",
    "authors": [
      "Vinod Kumar Chauhan",
      "Jiandong Zhou",
      "Soheila Molaei",
      "Ghadeer Ghosheh",
      "David A. Clifton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2305.15987",
    "title": "A graphon-signal analysis of graph neural networks",
    "abstract": "We present an approach for analyzing message passing graph neural networks (MPNNs) based on an extension of graphon analysis to a so called graphon-signal analysis. A MPNN is a function that takes a graph and a signal on the graph (a graph-signal) and returns some value. Since the input space of MPNNs is non-Euclidean, i.e., graphs can be of any size and topology, properties such as generalization are less well understood for MPNNs than for Euclidean neural networks. We claim that one important missing ingredient in past work is a meaningful notion of graph-signal similarity measure, that endows the space of inputs to MPNNs with a regular structure. We present such a similarity measure, called the graphon-signal cut distance, which makes the space of all graph-signals a dense subset of a compact metric space -- the graphon-signal space. Informally, two deterministic graph-signals are close in cut distance if they ``look like'' they were sampled from the same random graph-signal model. Hence, our cut distance is a natural notion of graph-signal similarity, which allows comparing any pair of graph-signals of any size and topology. We prove that MPNNs are Lipschitz continuous functions over the graphon-signal metric space. We then give two applications of this result: 1) a generalization bound for MPNNs, and, 2) the stability of MPNNs to subsampling of graph-signals. Our results apply to any regular enough MPNN on any distribution of graph-signals, making the analysis rather universal. ",
    "url": "https://arxiv.org/abs/2305.15987",
    "authors": [
      "Ron Levie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16001",
    "title": "A Higher-Order Temporal H-Index for Evolving Networks",
    "abstract": "The H-index of a node in a static network is the maximum value $h$ such that at least $h$ of its neighbors have a degree of at least $h$. Recently, a generalized version, the $n$-th order H-index, was introduced, allowing to relate degree centrality, H-index, and the $k$-core of a node. We extend the $n$-th order H-index to temporal networks and define corresponding temporal centrality measures and temporal core decompositions. Our $n$-th order temporal H-index respects the reachability in temporal networks leading to node rankings, which reflect the importance of nodes in spreading processes. We derive natural decompositions of temporal networks into subgraphs with strong temporal coherence. We analyze a recursive computation scheme and develop a highly scalable streaming algorithm. Our experimental evaluation demonstrates the efficiency of our algorithms and the conceptional validity of our approach. Specifically, we show that the $n$-th order temporal H-index is a strong heuristic for identifying super-spreaders in evolving social networks and detects temporally well-connected components. ",
    "url": "https://arxiv.org/abs/2305.16001",
    "authors": [
      "Lutz Oettershagen",
      "Nils M. Kriege",
      "Petra Mutzel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.16035",
    "title": "Detecting Adversarial Data by Probing Multiple Perturbations Using  Expected Perturbation Score",
    "abstract": "Adversarial detection aims to determine whether a given sample is an adversarial one based on the discrepancy between natural and adversarial distributions. Unfortunately, estimating or comparing two data distributions is extremely difficult, especially in high-dimension spaces. Recently, the gradient of log probability density (a.k.a., score) w.r.t. the sample is used as an alternative statistic to compute. However, we find that the score is sensitive in identifying adversarial samples due to insufficient information with one sample only. In this paper, we propose a new statistic called expected perturbation score (EPS), which is essentially the expected score of a sample after various perturbations. Specifically, to obtain adequate information regarding one sample, we perturb it by adding various noises to capture its multi-view observations. We theoretically prove that EPS is a proper statistic to compute the discrepancy between two samples under mild conditions. In practice, we can use a pre-trained diffusion model to estimate EPS for each sample. Last, we propose an EPS-based adversarial detection (EPS-AD) method, in which we develop EPS-based maximum mean discrepancy (MMD) as a metric to measure the discrepancy between the test sample and natural samples. We also prove that the EPS-based MMD between natural and adversarial samples is larger than that among natural samples. Extensive experiments show the superior adversarial detection performance of our EPS-AD. ",
    "url": "https://arxiv.org/abs/2305.16035",
    "authors": [
      "Shuhai Zhang",
      "Feng Liu",
      "Jiahao Yang",
      "Yifan Yang",
      "Changsheng Li",
      "Bo Han",
      "Mingkui Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.16043",
    "title": "Ordered and Binary Speaker Embedding",
    "abstract": "Modern speaker recognition systems represent utterances by embedding vectors. Conventional embedding vectors are dense and non-structural. In this paper, we propose an ordered binary embedding approach that sorts the dimensions of the embedding vector via a nested dropout and converts the sorted vectors to binary codes via Bernoulli sampling. The resultant ordered binary codes offer some important merits such as hierarchical clustering, reduced memory usage, and fast retrieval. These merits were empirically verified by comprehensive experiments on a speaker identification task with the VoxCeleb and CN-Celeb datasets. ",
    "url": "https://arxiv.org/abs/2305.16043",
    "authors": [
      "Jiaying Wang",
      "Xianglong Wang",
      "Namin Wang",
      "Lantian Li",
      "Dong Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.16044",
    "title": "Exploiting Noise as a Resource for Computation and Learning in Spiking  Neural Networks",
    "abstract": "Networks of spiking neurons underpin the extraordinary information-processing capabilities of the brain and have emerged as pillar models in neuromorphic intelligence. Despite extensive research on spiking neural networks (SNNs), most are established on deterministic models. Integrating noise into SNNs leads to biophysically more realistic neural dynamics and may benefit model performance. This work presents the noisy spiking neural network (NSNN) and the noise-driven learning rule (NDL) by introducing a spiking neuron model incorporating noisy neuronal dynamics. Our approach shows how noise may act as a resource for computation and learning and theoretically provides a framework for general SNNs. Moreover, NDL provides an insightful rationale for surrogate gradients. By incorporating various SNN architectures and algorithms, we show that our approach exhibits competitive performance and improved robustness against challenging perturbations than deterministic SNNs. Additionally, we demonstrate the utility of the NSNN model for neural coding studies. Overall, NSNN offers a powerful, flexible, and easy-to-use tool for machine learning practitioners and computational neuroscience researchers. ",
    "url": "https://arxiv.org/abs/2305.16044",
    "authors": [
      "Gehua Ma",
      "Rui Yan",
      "Huajin Tang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16057",
    "title": "Fake News Detection and Behavioral Analysis: Case of COVID-19",
    "abstract": "While the world has been combating COVID-19 for over three years, an ongoing \"Infodemic\" due to the spread of fake news regarding the pandemic has also been a global issue. The existence of the fake news impact different aspect of our daily lives, including politics, public health, economic activities, etc. Readers could mistake fake news for real news, and consequently have less access to authentic information. This phenomenon will likely cause confusion of citizens and conflicts in society. Currently, there are major challenges in fake news research. It is challenging to accurately identify fake news data in social media posts. In-time human identification is infeasible as the amount of the fake news data is overwhelming. Besides, topics discussed in fake news are hard to identify due to their similarity to real news. The goal of this paper is to identify fake news on social media to help stop the spread. We present Deep Learning approaches and an ensemble approach for fake news detection. Our detection models achieved higher accuracy than previous studies. The ensemble approach further improved the detection performance. We discovered feature differences between fake news and real news items. When we added them into the sentence embeddings, we found that they affected the model performance. We applied a hybrid method and built models for recognizing topics from posts. We found half of the identified topics were overlapping in fake news and real news, which could increase confusion in the population. ",
    "url": "https://arxiv.org/abs/2305.16057",
    "authors": [
      "Chih-Yuan Li",
      "Navya Martin Kollapally",
      "Soon Ae Chun",
      "James Geller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.16060",
    "title": "Local Randomized Neural Networks with Discontinuous Galerkin Methods for  Diffusive-Viscous Wave Equation",
    "abstract": "The diffusive-viscous wave equation is an advancement in wave equation theory, as it accounts for both diffusion and viscosity effects. This has a wide range of applications in geophysics, such as the attenuation of seismic waves in fluid-saturated solids and frequency-dependent phenomena in porous media. Therefore, the development of an efficient numerical method for the equation is of both theoretical and practical importance. Recently, local randomized neural networks with discontinuous Galerkin (LRNN-DG) methods have been introduced in \\cite{Sun2022lrnndg} to solve elliptic and parabolic equations. Numerical examples suggest that LRNN-DG can achieve high accuracy, and can handle time-dependent problems naturally and efficiently by using a space-time framework. In this paper, we develop LRNN-DG methods for solving the diffusive-viscous wave equation and present numerical experiments with several cases. The numerical results show that the proposed methods can solve the diffusive-viscous wave equation more accurately with less computing costs than traditional methods. ",
    "url": "https://arxiv.org/abs/2305.16060",
    "authors": [
      "Jingbo Sun",
      "Fei Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2305.16070",
    "title": "Visualizing data augmentation in deep speaker recognition",
    "abstract": "Visualization is of great value in understanding the internal mechanisms of neural networks. Previous work found that LayerCAM is a reliable visualization tool for deep speaker models. In this paper, we use LayerCAM to analyze the widely-adopted data augmentation (DA) approach, to understand how it leads to model robustness. We conduct experiments on the VoxCeleb1 dataset for speaker identification, which shows that both vanilla and activation-based (Act) DA approaches enhance robustness against interference, with Act DA being consistently superior. Visualization with LayerCAM suggests DA helps models learn to delete temporal-frequency (TF) bins that are corrupted by interference. The `learn to delete' behavior explained why DA models are more robust than clean models, and why the Act DA is superior over the vanilla DA when the interference is nontarget speech. However, LayerCAM still cannot clearly explain the superiority of Act DA in other situations, suggesting further research. ",
    "url": "https://arxiv.org/abs/2305.16070",
    "authors": [
      "Pengqi Li",
      "Lantian Li",
      "Askar Hamdulla",
      "Dong Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.16075",
    "title": "Failure Detection and Fault Tolerant Control of a Jet-Powered Flying  Humanoid Robot",
    "abstract": "Failure detection and fault tolerant control are fundamental safety features of any aerial vehicle. With the emergence of complex, multi-body flying systems such as jet-powered humanoid robots, it becomes of crucial importance to design fault detection and control strategies for these systems, too. In this paper we propose a fault detection and control framework for the flying humanoid robot iRonCub in case of loss of one turbine. The framework is composed of a failure detector based on turbines rotational speed, a momentum-based flight control for fault response, and an offline reference generator that produces far-from-singularities configurations and accounts for self and jet exhausts collision avoidance. Simulation results with Gazebo and MATLAB prove the effectiveness of the proposed control strategy. ",
    "url": "https://arxiv.org/abs/2305.16075",
    "authors": [
      "Gabriele Nava",
      "Daniele Pucci"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.16102",
    "title": "Demystifying Oversmoothing in Attention-Based Graph Neural Networks",
    "abstract": "Oversmoothing in Graph Neural Networks (GNNs) refers to the phenomenon where increasing network depth leads to homogeneous node representations. While previous work has established that Graph Convolutional Networks (GCNs) exponentially lose expressive power, it remains controversial whether the graph attention mechanism can mitigate oversmoothing. In this work, we provide a definitive answer to this question through a rigorous mathematical analysis, by viewing attention-based GNNs as nonlinear time-varying dynamical systems and incorporating tools and techniques from the theory of products of inhomogeneous matrices and the joint spectral radius. We establish that, contrary to popular belief, the graph attention mechanism cannot prevent oversmoothing and loses expressive power exponentially. The proposed framework extends the existing results on oversmoothing for symmetric GCNs to a significantly broader class of GNN models. In particular, our analysis accounts for asymmetric, state-dependent and time-varying aggregation operators and a wide range of common nonlinear activation functions, such as ReLU, LeakyReLU, GELU and SiLU. ",
    "url": "https://arxiv.org/abs/2305.16102",
    "authors": [
      "Xinyi Wu",
      "Amir Ajorlou",
      "Zihui Wu",
      "Ali Jadbabaie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.16114",
    "title": "Fascinating Supervisory Signals and Where to Find Them: Deep Anomaly  Detection with Scale Learning",
    "abstract": "Due to the unsupervised nature of anomaly detection, the key to fueling deep models is finding supervisory signals. Different from current reconstruction-guided generative models and transformation-based contrastive models, we devise novel data-driven supervision for tabular data by introducing a characteristic -- scale -- as data labels. By representing varied sub-vectors of data instances, we define scale as the relationship between the dimensionality of original sub-vectors and that of representations. Scales serve as labels attached to transformed representations, thus offering ample labeled data for neural network training. This paper further proposes a scale learning-based anomaly detection method. Supervised by the learning objective of scale distribution alignment, our approach learns the ranking of representations converted from varied subspaces of each data instance. Through this proxy task, our approach models inherent regularities and patterns within data, which well describes data \"normality\". Abnormal degrees of testing instances are obtained by measuring whether they fit these learned patterns. Extensive experiments show that our approach leads to significant improvement over state-of-the-art generative/contrastive anomaly detection methods. ",
    "url": "https://arxiv.org/abs/2305.16114",
    "authors": [
      "Hongzuo Xu",
      "Yijie Wang",
      "Juhui Wei",
      "Songlei Jian",
      "Yizhou Li",
      "Ning Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16124",
    "title": "Robust Category-Level 3D Pose Estimation from Synthetic Data",
    "abstract": "Obtaining accurate 3D object poses is vital for numerous computer vision applications, such as 3D reconstruction and scene understanding. However, annotating real-world objects is time-consuming and challenging. While synthetically generated training data is a viable alternative, the domain shift between real and synthetic data is a significant challenge. In this work, we aim to narrow the performance gap between models trained on synthetic data and few real images and fully supervised models trained on large-scale data. We achieve this by approaching the problem from two perspectives: 1) We introduce SyntheticP3D, a new synthetic dataset for object pose estimation generated from CAD models and enhanced with a novel algorithm. 2) We propose a novel approach (CC3D) for training neural mesh models that perform pose estimation via inverse rendering. In particular, we exploit the spatial relationships between features on the mesh surface and a contrastive learning scheme to guide the domain adaptation process. Combined, these two approaches enable our models to perform competitively with state-of-the-art models using only 10% of the respective real training images, while outperforming the SOTA model by 10.4% with a threshold of pi/18 using only 50% of the real training data. Our trained model further demonstrates robust generalization to out-of-distribution scenarios despite being trained with minimal real data. ",
    "url": "https://arxiv.org/abs/2305.16124",
    "authors": [
      "Jiahao Yang",
      "Wufei Ma",
      "Angtian Wang",
      "Xiaoding Yuan",
      "Alan Yuille",
      "Adam Kortylewski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16129",
    "title": "Energy-based Detection of Adverse Weather Effects in LiDAR Data",
    "abstract": "Autonomous vehicles rely on LiDAR sensors to perceive the environment. Adverse weather conditions like rain, snow, and fog negatively affect these sensors, reducing their reliability by introducing unwanted noise in the measurements. In this work, we tackle this problem by proposing a novel approach for detecting adverse weather effects in LiDAR data. We reformulate this problem as an outlier detection task and use an energy-based framework to detect outliers in point clouds. More specifically, our method learns to associate low energy scores with inlier points and high energy scores with outliers allowing for robust detection of adverse weather effects. In extensive experiments, we show that our method performs better in adverse weather detection and has higher robustness to unseen weather effects than previous state-of-the-art methods. Furthermore, we show how our method can be used to perform simultaneous outlier detection and semantic segmentation. Finally, to help expand the research field of LiDAR perception in adverse weather, we release the SemanticSpray dataset, which contains labeled vehicle spray data in highway-like scenarios. ",
    "url": "https://arxiv.org/abs/2305.16129",
    "authors": [
      "Aldi Piroli",
      "Vinzenz Dallabetta",
      "Johannes Kopp",
      "Marc Walessa",
      "Daniel Meissner",
      "Klaus Dietmayer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16163",
    "title": "PPGenCDR: A Stable and Robust Framework for Privacy-Preserving  Cross-Domain Recommendation",
    "abstract": "Privacy-preserving cross-domain recommendation (PPCDR) refers to preserving the privacy of users when transferring the knowledge from source domain to target domain for better performance, which is vital for the long-term development of recommender systems. Existing work on cross-domain recommendation (CDR) reaches advanced and satisfying recommendation performance, but mostly neglects preserving privacy. To fill this gap, we propose a privacy-preserving generative cross-domain recommendation (PPGenCDR) framework for PPCDR. PPGenCDR includes two main modules, i.e., stable privacy-preserving generator module, and robust cross-domain recommendation module. Specifically, the former isolates data from different domains with a generative adversarial network (GAN) based model, which stably estimates the distribution of private data in the source domain with Renyi differential privacy (RDP) technique. Then the latter aims to robustly leverage the perturbed but effective knowledge from the source domain with the raw data in target domain to improve recommendation performance. Three key modules, i.e., (1) selective privacy preserver, (2) GAN stabilizer, and (3) robustness conductor, guarantee the cost-effective trade-off between utility and privacy, the stability of GAN when using RDP, and the robustness of leveraging transferable knowledge accordingly. The extensive empirical studies on Douban and Amazon datasets demonstrate that PPGenCDR significantly outperforms the state-of-the-art recommendation models while preserving privacy. ",
    "url": "https://arxiv.org/abs/2305.16163",
    "authors": [
      "Xinting Liao",
      "Weiming Liu",
      "Xiaolin Zheng",
      "Binhui Yao",
      "Chaochao Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16165",
    "title": "A Conceptual Model for End-to-End Causal Discovery in Knowledge Tracing",
    "abstract": "In this paper, we take a preliminary step towards solving the problem of causal discovery in knowledge tracing, i.e., finding the underlying causal relationship among different skills from real-world student response data. This problem is important since it can potentially help us understand the causal relationship between different skills without extensive A/B testing, which can potentially help educators to design better curricula according to skill prerequisite information. Specifically, we propose a conceptual solution, a novel causal gated recurrent unit (GRU) module in a modified deep knowledge tracing model, which uses i) a learnable permutation matrix for causal ordering among skills and ii) an optionally learnable lower-triangular matrix for causal structure among skills. We also detail how to learn the model parameters in an end-to-end, differentiable way. Our solution placed among the top entries in Task 3 of the NeurIPS 2022 Challenge on Causal Insights for Learning Paths in Education. We detail preliminary experiments as evaluated on the challenge's public leaderboard since the ground truth causal structure has not been publicly released, making detailed local evaluation impossible. ",
    "url": "https://arxiv.org/abs/2305.16165",
    "authors": [
      "Nischal Ashok Kumar",
      "Wanyong Feng",
      "Jaewook Lee",
      "Hunter McNichols",
      "Aritra Ghosh",
      "Andrew Lan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2305.16170",
    "title": "Multi-Agent Reinforcement Learning for Network Routing in Integrated  Access Backhaul Networks",
    "abstract": "We investigate the problem of wireless routing in integrated access backhaul (IAB) networks consisting of fiber-connected and wireless base stations and multiple users. The physical constraints of these networks prevent the use of a central controller, and base stations have limited access to real-time network conditions. We aim to maximize packet arrival ratio while minimizing their latency, for this purpose, we formulate the problem as a multi-agent partially observed Markov decision process (POMDP). To solve this problem, we develop a Relational Advantage Actor Critic (Relational A2C) algorithm that uses Multi-Agent Reinforcement Learning (MARL) and information about similar destinations to derive a joint routing policy on a distributed basis. We present three training paradigms for this algorithm and demonstrate its ability to achieve near-centralized performance. Our results show that Relational A2C outperforms other reinforcement learning algorithms, leading to increased network efficiency and reduced selfish agent behavior. To the best of our knowledge, this work is the first to optimize routing strategy for IAB networks. ",
    "url": "https://arxiv.org/abs/2305.16170",
    "authors": [
      "Shahaf Yamin",
      "Haim Permuter"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16173",
    "title": "Efficient Bound of Lipschitz Constant for Convolutional Layers by Gram  Iteration",
    "abstract": "Since the control of the Lipschitz constant has a great impact on the training stability, generalization, and robustness of neural networks, the estimation of this value is nowadays a real scientific challenge. In this paper we introduce a precise, fast, and differentiable upper bound for the spectral norm of convolutional layers using circulant matrix theory and a new alternative to the Power iteration. Called the Gram iteration, our approach exhibits a superlinear convergence. First, we show through a comprehensive set of experiments that our approach outperforms other state-of-the-art methods in terms of precision, computational cost, and scalability. Then, it proves highly effective for the Lipschitz regularization of convolutional neural networks, with competitive results against concurrent approaches. ",
    "url": "https://arxiv.org/abs/2305.16173",
    "authors": [
      "Blaise Delattre",
      "Quentin Barth\u00e9lemy",
      "Alexandre Araujo",
      "Alexandre Allauzen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16174",
    "title": "From Latent Graph to Latent Topology Inference: Differentiable Cell  Complex Module",
    "abstract": "Latent Graph Inference (LGI) relaxed the reliance of Graph Neural Networks (GNNs) on a given graph topology by dynamically learning it. However, most of LGI methods assume to have a (noisy, incomplete, improvable, ...) input graph to rewire and can solely learn regular graph topologies. In the wake of the success of Topological Deep Learning (TDL), we study Latent Topology Inference (LTI) for learning higher-order cell complexes (with sparse and not regular topology) describing multi-way interactions between data points. To this aim, we introduce the Differentiable Cell Complex Module (DCM), a novel learnable function that computes cell probabilities in the complex to improve the downstream task. We show how to integrate DCM with cell complex message passing networks layers and train it in a end-to-end fashion, thanks to a two-step inference procedure that avoids an exhaustive search across all possible cells in the input, thus maintaining scalability. Our model is tested on several homophilic and heterophilic graph datasets and it is shown to outperform other state-of-the-art techniques, offering significant improvements especially in cases where an input graph is not provided. ",
    "url": "https://arxiv.org/abs/2305.16174",
    "authors": [
      "Claudio Battiloro",
      "Indro Spinelli",
      "Lev Telyatnikov",
      "Michael Bronstein",
      "Simone Scardapane",
      "Paolo Di Lorenzo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.16183",
    "title": "Passive learning of active causal strategies in agents and language  models",
    "abstract": "What can be learned about causality and experimentation from passive data? This question is salient given recent successes of passively-trained language models in interactive domains such as tool use. Passive learning is inherently limited. However, we show that purely passive learning can in fact allow an agent to learn generalizable strategies for determining and using causal structures, as long as the agent can intervene at test time. We formally illustrate that learning a strategy of first experimenting, then seeking goals, can allow generalization from passive learning in principle. We then show empirically that agents trained via imitation on expert data can indeed generalize at test time to infer and use causal links which are never present in the training data; these agents can also generalize experimentation strategies to novel variable sets never observed in training. We then show that strategies for causal intervention and exploitation can be generalized from passive data even in a more complex environment with high-dimensional observations, with the support of natural language explanations. Explanations can even allow passive learners to generalize out-of-distribution from perfectly-confounded training data. Finally, we show that language models, trained only on passive next-word prediction, can generalize causal intervention strategies from a few-shot prompt containing examples of experimentation, together with explanations and reasoning. These results highlight the surprising power of passive learning of active causal strategies, and may help to understand the behaviors and capabilities of language models. ",
    "url": "https://arxiv.org/abs/2305.16183",
    "authors": [
      "Andrew Kyle Lampinen",
      "Stephanie C Y Chan",
      "Ishita Dasgupta",
      "Andrew J Nam",
      "Jane X Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.16196",
    "title": "Optimization and Interpretability of Graph Attention Networks for Small  Sparse Graph Structures in Automotive Applications",
    "abstract": "For automotive applications, the Graph Attention Network (GAT) is a prominently used architecture to include relational information of a traffic scenario during feature embedding. As shown in this work, however, one of the most popular GAT realizations, namely GATv2, has potential pitfalls that hinder an optimal parameter learning. Especially for small and sparse graph structures a proper optimization is problematic. To surpass limitations, this work proposes architectural modifications of GATv2. In controlled experiments, it is shown that the proposed model adaptions improve prediction performance in a node-level regression task and make it more robust to parameter initialization. This work aims for a better understanding of the attention mechanism and analyzes its interpretability of identifying causal importance. ",
    "url": "https://arxiv.org/abs/2305.16196",
    "authors": [
      "Marion Neumeier",
      "Andreas Tollk\u00fchn",
      "Sebastian Dorn",
      "Michael Botsch",
      "Wolfgang Utschick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16199",
    "title": "Diversity-Aware Coherence Loss for Improving Neural Topic Models",
    "abstract": "The standard approach for neural topic modeling uses a variational autoencoder (VAE) framework that jointly minimizes the KL divergence between the estimated posterior and prior, in addition to the reconstruction loss. Since neural topic models are trained by recreating individual input documents, they do not explicitly capture the coherence between topic words on the corpus level. In this work, we propose a novel diversity-aware coherence loss that encourages the model to learn corpus-level coherence scores while maintaining a high diversity between topics. Experimental results on multiple datasets show that our method significantly improves the performance of neural topic models without requiring any pretraining or additional parameters. ",
    "url": "https://arxiv.org/abs/2305.16199",
    "authors": [
      "Raymond Li",
      "Felipe Gonz\u00e1lez-Pizarro",
      "Linzi Xing",
      "Gabriel Murray",
      "Giuseppe Carenini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16202",
    "title": "DP-SGD Without Clipping: The Lipschitz Neural Network Way",
    "abstract": "State-of-the-art approaches for training Differentially Private (DP) Deep Neural Networks (DNN) faces difficulties to estimate tight bounds on the sensitivity of the network's layers, and instead rely on a process of per-sample gradient clipping. This clipping process not only biases the direction of gradients but also proves costly both in memory consumption and in computation. To provide sensitivity bounds and bypass the drawbacks of the clipping process, our theoretical analysis of Lipschitz constrained networks reveals an unexplored link between the Lipschitz constant with respect to their input and the one with respect to their parameters. By bounding the Lipschitz constant of each layer with respect to its parameters we guarantee DP training of these networks. This analysis not only allows the computation of the aforementioned sensitivities at scale but also provides leads on to how maximize the gradient-to-noise ratio for fixed privacy guarantees. To facilitate the application of Lipschitz networks and foster robust and certifiable learning under privacy guarantees, we provide a Python package that implements building blocks allowing the construction and private training of such networks. ",
    "url": "https://arxiv.org/abs/2305.16202",
    "authors": [
      "Louis Bethune",
      "Thomas Massena",
      "Thibaut Boissin",
      "Yannick Prudent",
      "Corentin Friedrich",
      "Franck Mamalet",
      "Aurelien Bellet",
      "Mathieu Serrurier",
      "David Vigouroux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.16205",
    "title": "Packaging code for reproducible research in the public sector",
    "abstract": "The effective and ethical use of data to inform decision-making offers huge value to the public sector, especially when delivered by transparent, reproducible, and robust data processing workflows. One way that governments are unlocking this value is through making their data publicly available, allowing more people and organisations to derive insights. However, open data is not enough in many cases: publicly available datasets need to be accessible in an analysis-ready form from popular data science tools, such as R and Python, for them to realise their full potential. This paper explores ways to maximise the impact of open data with reference to a case study of packaging code to facilitate reproducible analysis. We present the jtstats project, which consists of R and Python packages for importing, processing, and visualising large and complex datasets representing journey times, for many modes and purposes at multiple geographic levels, released by the UK Department of Transport. jtstats shows how domain specific packages can enable reproducible research within the public sector and beyond, saving duplicated effort and reducing the risks of errors from repeated analyses. We hope that the jtstats project inspires others, particularly those in the public sector, to add value to their data sets by making them more accessible. ",
    "url": "https://arxiv.org/abs/2305.16205",
    "authors": [
      "Federico Botta",
      "Robin Lovelace",
      "Laura Gilbert",
      "Arthur Turrell"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2305.16220",
    "title": "On the Robustness of Segment Anything",
    "abstract": "Segment anything model (SAM) has presented impressive objectness identification capability with the idea of prompt learning and a new collected large-scale dataset. Given a prompt (e.g., points, bounding boxes, or masks) and an input image, SAM is able to generate valid segment masks for all objects indicated by the prompts, presenting high generalization across diverse scenarios and being a general method for zero-shot transfer to downstream vision tasks. Nevertheless, it remains unclear whether SAM may introduce errors in certain threatening scenarios. Clarifying this is of significant importance for applications that require robustness, such as autonomous vehicles. In this paper, we aim to study the testing-time robustness of SAM under adversarial scenarios and common corruptions. To this end, we first build a testing-time robustness evaluation benchmark for SAM by integrating existing public datasets. Second, we extend representative adversarial attacks against SAM and study the influence of different prompts on robustness. Third, we study the robustness of SAM under diverse corruption types by evaluating SAM on corrupted datasets with different prompts. With experiments conducted on SA-1B and KITTI datasets, we find that SAM exhibits remarkable robustness against various corruptions, except for blur-related corruption. Furthermore, SAM remains susceptible to adversarial attacks, particularly when subjected to PGD and BIM attacks. We think such a comprehensive study could highlight the importance of the robustness issues of SAM and trigger a series of new tasks for SAM as well as downstream vision tasks. ",
    "url": "https://arxiv.org/abs/2305.16220",
    "authors": [
      "Yihao Huang",
      "Yue Cao",
      "Tianlin Li",
      "Felix Juefei-Xu",
      "Di Lin",
      "Ivor W.Tsang",
      "Yang Liu",
      "Qing Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16248",
    "title": "Hate Raids on Twitch: Understanding Real-Time Human-Bot Coordinated  Attacks in Live Streaming Communities",
    "abstract": "Online harassment and content moderation have been well-documented in online communities. However, new contexts and systems always bring new ways of harassment and need new moderation mechanisms. This study focuses on hate raids, a form of group attack in real-time in live streaming communities. Through a qualitative analysis of hate raids discussion in the Twitch subreddit (r/Twitch), we found that (1) hate raids as a human-bot coordinated group attack leverages the live stream system to attack marginalized streamers and other potential groups with(out) breaking the rules, (2) marginalized streamers suffer compound harms with insufficient support from the platform, (3) moderation strategies are overwhelmingly technical, but streamers still struggle to balance moderation and participation considering their marginalization status and needs. We use affordances as a lens to explain how hate raids happens in live streaming systems and propose moderation-by-design as a lens when developing new features or systems to mitigate the potential abuse of such designs. ",
    "url": "https://arxiv.org/abs/2305.16248",
    "authors": [
      "Jie Cai",
      "Sagnik Chowdhury",
      "Hongyang Zhou",
      "Donghee Yvette Wohn"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.16253",
    "title": "Uncovering and Categorizing Social Biases in Text-to-SQL",
    "abstract": "Content Warning: This work contains examples that potentially implicate stereotypes, associations, and other harms that could be offensive to individuals in certain social groups.} Large pre-trained language models are acknowledged to carry social biases towards different demographics, which can further amplify existing stereotypes in our society and cause even more harm. Text-to-SQL is an important task, models of which are mainly adopted by administrative industries, where unfair decisions may lead to catastrophic consequences. However, existing Text-to-SQL models are trained on clean, neutral datasets, such as Spider and WikiSQL. This, to some extent, cover up social bias in models under ideal conditions, which nevertheless may emerge in real application scenarios. In this work, we aim to uncover and categorize social biases in Text-to-SQL models. We summarize the categories of social biases that may occur in structured data for Text-to-SQL models. We build test benchmarks and reveal that models with similar task accuracy can contain social biases at very different rates. We show how to take advantage of our methodology to uncover and assess social biases in the downstream Text-to-SQL task. We will release our code and data. ",
    "url": "https://arxiv.org/abs/2305.16253",
    "authors": [
      "Yan Liu",
      "Yan Gao",
      "Zhe Su",
      "Xiaokang Chen",
      "Elliott Ash",
      "Jian-Guang Lou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.16257",
    "title": "Fast Online Node Labeling for Very Large Graphs",
    "abstract": "This paper studies the online node classification problem under a transductive learning setting. Current methods either invert a graph kernel matrix with $\\mathcal{O}(n^3)$ runtime and $\\mathcal{O}(n^2)$ space complexity or sample a large volume of random spanning trees, thus are difficult to scale to large graphs. In this work, we propose an improvement based on the \\textit{online relaxation} technique introduced by a series of works (Rakhlin et al.,2012; Rakhlin and Sridharan, 2015; 2017). We first prove an effective regret $\\mathcal{O}(\\sqrt{n^{1+\\gamma}})$ when suitable parameterized graph kernels are chosen, then propose an approximate algorithm FastONL enjoying $\\mathcal{O}(k\\sqrt{n^{1+\\gamma}})$ regret based on this relaxation. The key of FastONL is a \\textit{generalized local push} method that effectively approximates inverse matrix columns and applies to a series of popular kernels. Furthermore, the per-prediction cost is $\\mathcal{O}(\\text{vol}({\\mathcal{S}})\\log 1/\\epsilon)$ locally dependent on the graph with linear memory cost. Experiments show that our scalable method enjoys a better tradeoff between local and global consistency. ",
    "url": "https://arxiv.org/abs/2305.16257",
    "authors": [
      "Baojian Zhou",
      "Yifan Sun",
      "Reza Babanezhad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Spectral Theory (math.SP)"
    ]
  },
  {
    "id": "arXiv:2305.16259",
    "title": "Neural Natural Language Processing for Long Texts: A Survey of the  State-of-the-Art",
    "abstract": "The adoption of Deep Neural Networks (DNNs) has greatly benefited Natural Language Processing (NLP) during the past decade. However, the demands of long documents analysis are quite different from those of shorter texts, with the ever increasing size of documents uploaded online rendering NLP on long documents a critical area of research. This paper surveys the current state-of-the-art in the domain, overviewing the relevant neural building blocks and subsequently focusing on two main NLP tasks: Document Classification, Summarization as well as mentioning uses in Sentiment Analysis. We detail the challenges, issues and current solutions related to long-document NLP. We also list publicly available, labelled, long-document datasets used in current research. ",
    "url": "https://arxiv.org/abs/2305.16259",
    "authors": [
      "Dimitrios Tsirmpas",
      "Ioannis Gkionis",
      "Ioannis Mademlis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16283",
    "title": "CommonScenes: Generating Commonsense 3D Indoor Scenes with Scene Graphs",
    "abstract": "Controllable scene synthesis aims to create interactive environments for various industrial use cases. Scene graphs provide a highly suitable interface to facilitate these applications by abstracting the scene context in a compact manner. Existing methods, reliant on retrieval from extensive databases or pre-trained shape embeddings, often overlook scene-object and object-object relationships, leading to inconsistent results due to their limited generation capacity. To address this issue, we present CommonScenes, a fully generative model that converts scene graphs into corresponding controllable 3D scenes, which are semantically realistic and conform to commonsense. Our pipeline consists of two branches, one predicting the overall scene layout via a variational auto-encoder and the other generating compatible shapes via latent diffusion, capturing global scene-object and local inter-object relationships while preserving shape diversity. The generated scenes can be manipulated by editing the input scene graph and sampling the noise in the diffusion model. Due to lacking a scene graph dataset offering high-quality object-level meshes with relations, we also construct SG-FRONT, enriching the off-the-shelf indoor dataset 3D-FRONT with additional scene graph labels. Extensive experiments are conducted on SG-FRONT where CommonScenes shows clear advantages over other methods regarding generation consistency, quality, and diversity. Codes and the dataset will be released upon acceptance. ",
    "url": "https://arxiv.org/abs/2305.16283",
    "authors": [
      "Guangyao Zhai",
      "Evin Pinar \u00d6rnek",
      "Shun-Cheng Wu",
      "Yan Di",
      "Federico Tombari",
      "Nassir Navab",
      "Benjamin Busam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16289",
    "title": "Diversify Your Vision Datasets with Automatic Diffusion-Based  Augmentation",
    "abstract": "Many fine-grained classification tasks, like rare animal identification, have limited training data and consequently classifiers trained on these datasets often fail to generalize to variations in the domain like changes in weather or location. As such, we explore how natural language descriptions of the domains seen in training data can be used with large vision models trained on diverse pretraining datasets to generate useful variations of the training data. We introduce ALIA (Automated Language-guided Image Augmentation), a method which utilizes large vision and language models to automatically generate natural language descriptions of a dataset's domains and augment the training data via language-guided image editing. To maintain data integrity, a model trained on the original dataset filters out minimal image edits and those which corrupt class-relevant information. The resulting dataset is visually consistent with the original training data and offers significantly enhanced diversity. On fine-grained and cluttered datasets for classification and detection, ALIA surpasses traditional data augmentation and text-to-image generated data by up to 15\\%, often even outperforming equivalent additions of real data. Code is avilable at https://github.com/lisadunlap/ALIA. ",
    "url": "https://arxiv.org/abs/2305.16289",
    "authors": [
      "Lisa Dunlap",
      "Alyssa Umino",
      "Han Zhang",
      "Jiezhi Yang",
      "Joseph E. Gonzalez",
      "Trevor Darrell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16310",
    "title": "Securing Deep Generative Models with Universal Adversarial Signature",
    "abstract": "Recent advances in deep generative models have led to the development of methods capable of synthesizing high-quality, realistic images. These models pose threats to society due to their potential misuse. Prior research attempted to mitigate these threats by detecting generated images, but the varying traces left by different generative models make it challenging to create a universal detector capable of generalizing to new, unseen generative models. In this paper, we propose to inject a universal adversarial signature into an arbitrary pre-trained generative model, in order to make its generated contents more detectable and traceable. First, the imperceptible optimal signature for each image can be found by a signature injector through adversarial training. Subsequently, the signature can be incorporated into an arbitrary generator by fine-tuning it with the images processed by the signature injector. In this way, the detector corresponding to the signature can be reused for any fine-tuned generator for tracking the generator identity. The proposed method is validated on the FFHQ and ImageNet datasets with various state-of-the-art generative models, consistently showing a promising detection rate. Code will be made publicly available at \\url{https://github.com/zengxianyu/genwm}. ",
    "url": "https://arxiv.org/abs/2305.16310",
    "authors": [
      "Yu Zeng",
      "Mo Zhou",
      "Yuan Xue",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16314",
    "title": "Banana: Banach Fixed-Point Network for Pointcloud Segmentation with  Inter-Part Equivariance",
    "abstract": "Equivariance has gained strong interest as a desirable network property that inherently ensures robust generalization. However, when dealing with complex systems such as articulated objects or multi-object scenes, effectively capturing inter-part transformations poses a challenge, as it becomes entangled with the overall structure and local transformations. The interdependence of part assignment and per-part group action necessitates a novel equivariance formulation that allows for their co-evolution. In this paper, we present Banana, a Banach fixed-point network for equivariant segmentation with inter-part equivariance by construction. Our key insight is to iteratively solve a fixed-point problem, where point-part assignment labels and per-part SE(3)-equivariance co-evolve simultaneously. We provide theoretical derivations of both per-step equivariance and global convergence, which induces an equivariant final convergent state. Our formulation naturally provides a strict definition of inter-part equivariance that generalizes to unseen inter-part configurations. Through experiments conducted on both articulated objects and multi-object scans, we demonstrate the efficacy of our approach in achieving strong generalization under inter-part transformations, even when confronted with substantial changes in pointcloud geometry and topology. ",
    "url": "https://arxiv.org/abs/2305.16314",
    "authors": [
      "Congyue Deng",
      "Jiahui Lei",
      "Bokui Shen",
      "Kostas Daniilidis",
      "Leonidas Guibas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16315",
    "title": "NAP: Neural 3D Articulation Prior",
    "abstract": "We propose Neural 3D Articulation Prior (NAP), the first 3D deep generative model to synthesize 3D articulated object models. Despite the extensive research on generating 3D objects, compositions, or scenes, there remains a lack of focus on capturing the distribution of articulated objects, a common object category for human and robot interaction. To generate articulated objects, we first design a novel articulation tree/graph parameterization and then apply a diffusion-denoising probabilistic model over this representation where articulated objects can be generated via denoising from random complete graphs. In order to capture both the geometry and the motion structure whose distribution will affect each other, we design a graph-attention denoising network for learning the reverse diffusion process. We propose a novel distance that adapts widely used 3D generation metrics to our novel task to evaluate generation quality, and experiments demonstrate our high performance in articulated object generation. We also demonstrate several conditioned generation applications, including Part2Motion, PartNet-Imagination, Motion2Part, and GAPart2Object. ",
    "url": "https://arxiv.org/abs/2305.16315",
    "authors": [
      "Jiahui Lei",
      "Congyue Deng",
      "Bokui Shen",
      "Leonidas Guibas",
      "Kostas Daniilidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15411",
    "title": "Advanced Medical Image Representation for Efficient Processing and  Transfer in Multisite Clouds",
    "abstract": "An important topic in medical research is the process of improving the images obtained from medical devices. As a consequence, there is also a need to improve medical image resolution and analysis. Another issue in this field is the large amount of stored medical data [16]. Human brain databases at medical institutes, for example, can accumulate tens of Terabytes of data per year. In this paper, we propose a novel medical image format representation based on multiple data structures that improve the information maintained in the medical images. The new representation keeps additional metadata information, such as the image class or tags for the objects found in the image. We defined our own ontology to help us classify the objects found in medical images using a multilayer neural network. As we generally deal with large data sets, we used the MapReduce paradigm in the Cloud environment to speed up the image processing. To optimize the transfer between Cloud nodes and to reduce the preprocessing time, we also propose a data compression method based on deduplication. We test our solution for image representation and efficient data transfer in a multisite cloud environment. Our proposed solution optimizes the data transfer with a time improvement of 27% on average. ",
    "url": "https://arxiv.org/abs/2305.15411",
    "authors": [
      "Elena-Simona Apostol",
      "Ciprian-Octavian Truic\u0103"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2305.15417",
    "title": "Entropy-Aware Similarity for Balanced Clustering: A Case Study with  Melanoma Detection",
    "abstract": "Clustering data is an unsupervised learning approach that aims to divide a set of data points into multiple groups. It is a crucial yet demanding subject in machine learning and data mining. Its successful applications span various fields. However, conventional clustering techniques necessitate the consideration of balance significance in specific applications. Therefore, this paper addresses the challenge of imbalanced clustering problems and presents a new method for balanced clustering by utilizing entropy-aware similarity, which can be defined as the degree of balances. We have coined the term, entropy-aware similarity for balanced clustering (EASB), which maximizes balance during clustering by complementary clustering of unbalanced data and incorporating entropy in a novel similarity formula that accounts for both angular differences and distances. The effectiveness of the proposed approach is evaluated on actual melanoma medial data, specifically the International Skin Imaging Collaboration (ISIC) 2019 and 2020 challenge datasets, to demonstrate how it can successfully cluster the data while preserving balance. Lastly, we can confirm that the proposed method exhibited outstanding performance in detecting melanoma, comparing to classical methods. ",
    "url": "https://arxiv.org/abs/2305.15417",
    "authors": [
      "Seok Bin Son",
      "Soohyun Park",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15421",
    "title": "Generative Adversarial Networks for Brain Images Synthesis: A Review",
    "abstract": "In medical imaging, image synthesis is the estimation process of one image (sequence, modality) from another image (sequence, modality). Since images with different modalities provide diverse biomarkers and capture various features, multi-modality imaging is crucial in medicine. While multi-screening is expensive, costly, and time-consuming to report by radiologists, image synthesis methods are capable of artificially generating missing modalities. Deep learning models can automatically capture and extract the high dimensional features. Especially, generative adversarial network (GAN) as one of the most popular generative-based deep learning methods, uses convolutional networks as generators, and estimated images are discriminated as true or false based on a discriminator network. This review provides brain image synthesis via GANs. We summarized the recent developments of GANs for cross-modality brain image synthesis including CT to PET, CT to MRI, MRI to PET, and vice versa. ",
    "url": "https://arxiv.org/abs/2305.15421",
    "authors": [
      "Firoozeh Shomal Zadeh",
      "Sevda Molani",
      "Maysam Orouskhani",
      "Marziyeh Rezaei",
      "Mehrzad Shafiei",
      "Hossein Abbasi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15424",
    "title": "PulseNet: Deep Learning ECG-signal classification using random  augmentation policy and continous wavelet transform for canines",
    "abstract": "Evaluating canine electrocardiograms (ECG) require skilled veterinarians, but current availability of veterinary cardiologists for ECG interpretation and diagnostic support is limited. Developing tools for automated assessment of ECG sequences can improve veterinary care by providing clinicians real-time results and decision support tools. We implement a deep convolutional neural network (CNN) approach for classifying canine electrocardiogram sequences as either normal or abnormal. ECG records are converted into 8 second Lead II sequences and classified as either normal (no evidence of cardiac abnormalities) or abnormal (presence of one or more cardiac abnormalities). For training ECG sequences are randomly augmented using RandomAugmentECG, a new augmentation library implemented specifically for this project. Each chunk is then is converted using a continuous wavelet transform into a 2D scalogram. The 2D scalogram are then classified as either normal or abnormal by a binary CNN classifier. Experimental results are validated against three boarded veterinary cardiologists achieving an AUC-ROC score of 0.9506 on test dataset matching human level performance. Additionally, we describe model deployment to Microsoft Azure using an MLOps approach. To our knowledge, this work is one of the first attempts to implement a deep learning model to automatically classify ECG sequences for canines.Implementing automated ECG classification will enhance veterinary care through improved diagnostic performance and increased clinic efficiency. ",
    "url": "https://arxiv.org/abs/2305.15424",
    "authors": [
      "Andre Dourson",
      "Roberto Santilli",
      "Federica Marchesotti",
      "Jennifer Schneiderman",
      "Oliver Roman Stiel",
      "Fernando Junior",
      "Michael Fitzke",
      "Norbert Sithirangathan",
      "Emil Walleser",
      "Xiaoli Qiao",
      "Mark Parkinson"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15441",
    "title": "Improving few-shot learning-based protein engineering with evolutionary  sampling",
    "abstract": "Designing novel functional proteins remains a slow and expensive process due to a variety of protein engineering challenges; in particular, the number of protein variants that can be experimentally tested in a given assay pales in comparison to the vastness of the overall sequence space, resulting in low hit rates and expensive wet lab testing cycles. In this paper, we propose a few-shot learning approach to novel protein design that aims to accelerate the expensive wet lab testing cycle and is capable of leveraging a training dataset that is both small and skewed ($\\approx 10^5$ datapoints, $< 1\\%$ positive hits). Our approach is composed of two parts: a semi-supervised transfer learning approach to generate a discrete fitness landscape for a desired protein function and a novel evolutionary Monte Carlo Markov Chain sampling algorithm to more efficiently explore the fitness landscape. We demonstrate the performance of our approach by experimentally screening predicted high fitness gene activators, resulting in a dramatically improved hit rate compared to existing methods. Our method can be easily adapted to other protein engineering and design problems, particularly where the cost associated with obtaining labeled data is significantly high. We have provided open source code for our method at https:// github.com/SuperSecretBioTech/evolutionary_monte_carlo_search. ",
    "url": "https://arxiv.org/abs/2305.15441",
    "authors": [
      "M. Zaki Jawaid",
      "Robin W. Yeo",
      "Aayushma Gautam",
      "T. Blair Gainous",
      "Daniel O. Hart",
      "Timothy P. Daley"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15518",
    "title": "Spoofing Attacker Also Benefits from Self-Supervised Pretrained Model",
    "abstract": "Large-scale pretrained models using self-supervised learning have reportedly improved the performance of speech anti-spoofing. However, the attacker side may also make use of such models. Also, since it is very expensive to train such models from scratch, pretrained models on the Internet are often used, but the attacker and defender may possibly use the same pretrained model. This paper investigates whether the improvement in anti-spoofing with pretrained models holds under the condition that the models are available to attackers. As the attacker, we train a model that enhances spoofed utterances so that the speaker embedding extractor based on the pretrained models cannot distinguish between bona fide and spoofed utterances. Experimental results show that the gains the anti-spoofing models obtained by using the pretrained models almost disappear if the attacker also makes use of the pretrained models. ",
    "url": "https://arxiv.org/abs/2305.15518",
    "authors": [
      "Aoi Ito",
      "Shota Horiguchi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.15536",
    "title": "RAND: Robustness Aware Norm Decay For Quantized Seq2seq Models",
    "abstract": "With the rapid increase in the size of neural networks, model compression has become an important area of research. Quantization is an effective technique at decreasing the model size, memory access, and compute load of large models. Despite recent advances in quantization aware training (QAT) technique, most papers present evaluations that are focused on computer vision tasks, which have different training dynamics compared to sequence tasks. In this paper, we first benchmark the impact of popular techniques such as straight through estimator, pseudo-quantization noise, learnable scale parameter, clipping, etc. on 4-bit seq2seq models across a suite of speech recognition datasets ranging from 1,000 hours to 1 million hours, as well as one machine translation dataset to illustrate its applicability outside of speech. Through the experiments, we report that noise based QAT suffers when there is insufficient regularization signal flowing back to the quantization scale. We propose low complexity changes to the QAT process to improve model accuracy (outperforming popular learnable scale and clipping methods). With the improved accuracy, it opens up the possibility to exploit some of the other benefits of noise based QAT: 1) training a single model that performs well in mixed precision mode and 2) improved generalization on long form speech recognition. ",
    "url": "https://arxiv.org/abs/2305.15536",
    "authors": [
      "David Qiu",
      "David Rim",
      "Shaojin Ding",
      "Oleg Rybakov",
      "Yanzhang He"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15558",
    "title": "Online Optimization for Randomized Network Resource Allocation with  Long-Term Constraints",
    "abstract": "In this paper, we study an optimal online resource reservation problem in a simple communication network. The network is composed of two compute nodes linked by a local communication link. The system operates in discrete time; at each time slot, the administrator reserves resources for servers before the actual job requests are known. A cost is incurred for the reservations made. Then, after the client requests are observed, jobs may be transferred from one server to the other to best accommodate the demands by incurring an additional transport cost. If certain job requests cannot be satisfied, there is a violation that engenders a cost to pay for each of the blocked jobs. The goal is to minimize the overall reservation cost over finite horizons while maintaining the cumulative violation and transport costs under a certain budget limit. To study this problem, we first formalize it as a repeated game against nature where the reservations are drawn randomly according to a sequence of probability distributions that are derived from an online optimization problem over the space of allowable reservations. We then propose an online saddle-point algorithm for which we present an upper bound for the associated K-benchmark regret together with an upper bound for the cumulative constraint violations. Finally, we present numerical experiments where we compare the performance of our algorithm with those of simple deterministic resource allocation policies. ",
    "url": "https://arxiv.org/abs/2305.15558",
    "authors": [
      "Ahmed Sid-Ali",
      "Ioannis Lambadaris",
      "Yiqiang Q. Zhao",
      "Gennady Shaikhet",
      "Shima Kheradmand"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.15721",
    "title": "An exponential bound for simultaneous embeddings of planar graphs",
    "abstract": "We show that there are $O(n \\cdot 4^{n/11})$ planar graphs on $n$ vertices which do not admit a simultaneous straight-line embedding on any $n$-point set in the plane. In particular, this improves the best known bound $O(n!)$ significantly. ",
    "url": "https://arxiv.org/abs/2305.15721",
    "authors": [
      "Ritesh Goenka",
      "Pardis Semnani",
      "Chi Hoi Yip"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2305.15767",
    "title": "A Scalable, Fast and Programmable Neural Decoder for Fault-Tolerant  Quantum Computation Using Surface Codes",
    "abstract": "Quantum error-correcting codes (QECCs) can eliminate the negative effects of quantum noise, the major obstacle to the execution of quantum algorithms. However, realizing practical quantum error correction (QEC) requires resolving many challenges to implement a high-performance real-time decoding system. Many decoding algorithms have been proposed and optimized in the past few decades, of which neural network (NNs) based solutions have drawn an increasing amount of attention due to their high efficiency. Unfortunately, previous works on neural decoders are still at an early stage and have only relatively simple architectures, which makes them unsuitable for practical QEC. In this work, we propose a scalable, fast, and programmable neural decoding system to meet the requirements of FTQEC for rotated surface codes (RSC). Firstly, we propose a hardware-efficient NN decoding algorithm with relatively low complexity and high accuracy. Secondly, we develop a customized hardware decoder with architectural optimizations to reduce latency. Thirdly, our proposed programmable architecture boosts the scalability and flexibility of the decoder by maximizing parallelism. Fourthly, we build an FPGA-based decoding system with integrated control hardware for evaluation. Our $L=5$ ($L$ is the code distance) decoder achieves an extremely low decoding latency of 197 ns, and the $L=7$ configuration also requires only 1.136 $\\mu$s, both taking $2L$ rounds of syndrome measurements. The accuracy results of our system are close to minimum weight perfect matching (MWPM). Furthermore, our programmable architecture reduces hardware resource consumption by up to $3.0\\times$ with only a small latency loss. We validated our approach in real-world scenarios by conducting a proof-of-concept benchmark with practical noise models, including one derived from experimental data gathered from physical hardware. ",
    "url": "https://arxiv.org/abs/2305.15767",
    "authors": [
      "Mengyu Zhang",
      "Xiangyu Ren",
      "Guanglei Xi",
      "Zhenxing Zhang",
      "Qiaonian Yu",
      "Fuming Liu",
      "Hualiang Zhang",
      "Shengyu Zhang",
      "Yi-Cong Zheng"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2305.15777",
    "title": "Dynamic Data Augmentation via MCTS for Prostate MRI Segmentation",
    "abstract": "Medical image data are often limited due to the expensive acquisition and annotation process. Hence, training a deep-learning model with only raw data can easily lead to overfitting. One solution to this problem is to augment the raw data with various transformations, improving the model's ability to generalize to new data. However, manually configuring a generic augmentation combination and parameters for different datasets is non-trivial due to inconsistent acquisition approaches and data distributions. Therefore, automatic data augmentation is proposed to learn favorable augmentation strategies for different datasets while incurring large GPU overhead. To this end, we present a novel method, called Dynamic Data Augmentation (DDAug), which is efficient and has negligible computation cost. Our DDAug develops a hierarchical tree structure to represent various augmentations and utilizes an efficient Monte-Carlo tree searching algorithm to update, prune, and sample the tree. As a result, the augmentation pipeline can be optimized for each dataset automatically. Experiments on multiple Prostate MRI datasets show that our method outperforms the current state-of-the-art data augmentation strategies. ",
    "url": "https://arxiv.org/abs/2305.15777",
    "authors": [
      "Xinyue Xu",
      "Yuhan Hsi",
      "Haonan Wang",
      "Xiaomeng Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15813",
    "title": "Leveraging object detection for the identification of lung cancer",
    "abstract": "Lung cancer poses a significant global public health challenge, emphasizing the importance of early detection for improved patient outcomes. Recent advancements in deep learning algorithms have shown promising results in medical image analysis. This study aims to explore the application of object detection particularly YOLOv5, an advanced object identification system, in medical imaging for lung cancer identification. To train and evaluate the algorithm, a dataset comprising chest X-rays and corresponding annotations was obtained from Kaggle. The YOLOv5 model was employed to train an algorithm capable of detecting cancerous lung lesions. The training process involved optimizing hyperparameters and utilizing augmentation techniques to enhance the model's performance. The trained YOLOv5 model exhibited exceptional proficiency in identifying lung cancer lesions, displaying high accuracy and recall rates. It successfully pinpointed malignant areas in chest radiographs, as validated by a separate test set where it outperformed previous techniques. Additionally, the YOLOv5 model demonstrated computational efficiency, enabling real-time detection and making it suitable for integration into clinical procedures. This proposed approach holds promise in assisting radiologists in the early discovery and diagnosis of lung cancer, ultimately leading to prompt treatment and improved patient outcomes. ",
    "url": "https://arxiv.org/abs/2305.15813",
    "authors": [
      "Karthick Prasad Gunasekaran"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15816",
    "title": "DDDM-VC: Decoupled Denoising Diffusion Models with Disentangled  Representation and Prior Mixup for Verified Robust Voice Conversion",
    "abstract": "Diffusion-based generative models have exhibited powerful generative performance in recent years. However, as many attributes exist in the data distribution and owing to several limitations of sharing the model parameters across all levels of the generation process, it remains challenging to control specific styles for each attribute. To address the above problem, this paper presents decoupled denoising diffusion models (DDDMs) with disentangled representations, which can control the style for each attribute in generative models. We apply DDDMs to voice conversion (VC) tasks to address the challenges of disentangling and controlling each speech attribute (e.g., linguistic information, intonation, and timbre). First, we use a self-supervised representation to disentangle the speech representation. Subsequently, the DDDMs are applied to resynthesize the speech from the disentangled representations for denoising with respect to each attribute. Moreover, we also propose the prior mixup for robust voice style transfer, which uses the converted representation of the mixed style as a prior distribution for the diffusion models. The experimental results reveal that our method outperforms publicly available VC models. Furthermore, we show that our method provides robust generative performance regardless of the model size. Audio samples are available https://hayeong0.github.io/DDDM-VC-demo/. ",
    "url": "https://arxiv.org/abs/2305.15816",
    "authors": [
      "Ha-Yeong Choi",
      "Sang-Hoon Lee",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.15861",
    "title": "On the Weisfeiler-Leman dimension of permutation graphs",
    "abstract": "It is proved that the Weisfeiler-Leman dimension of the class of permutation graphs is at most 18. Previously it was only known that this dimension is finite (Gru{\\ss}ien, 2017). ",
    "url": "https://arxiv.org/abs/2305.15861",
    "authors": [
      "Jin Guo",
      "Alexander L. Gavrilyuk",
      "Ilia Ponomarenko"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2305.15871",
    "title": "Learning Robust Statistics for Simulation-based Inference under Model  Misspecification",
    "abstract": "Simulation-based inference (SBI) methods such as approximate Bayesian computation (ABC), synthetic likelihood, and neural posterior estimation (NPE) rely on simulating statistics to infer parameters of intractable likelihood models. However, such methods are known to yield untrustworthy and misleading inference outcomes under model misspecification, thus hindering their widespread applicability. In this work, we propose the first general approach to handle model misspecification that works across different classes of SBI methods. Leveraging the fact that the choice of statistics determines the degree of misspecification in SBI, we introduce a regularized loss function that penalises those statistics that increase the mismatch between the data and the model. Taking NPE and ABC as use cases, we demonstrate the superior performance of our method on high-dimensional time-series models that are artificially misspecified. We also apply our method to real data from the field of radio propagation where the model is known to be misspecified. We show empirically that the method yields robust inference in misspecified scenarios, whilst still being accurate when the model is well-specified. ",
    "url": "https://arxiv.org/abs/2305.15871",
    "authors": [
      "Daolang Huang",
      "Ayush Bharti",
      "Amauri Souza",
      "Luigi Acerbi",
      "Samuel Kaski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2305.15920",
    "title": "Learning and accurate generation of stochastic dynamics based on  multi-model Generative Adversarial Networks",
    "abstract": "Generative Adversarial Networks (GANs) have shown immense potential in fields far from physics, such as in text and image generation. Here we use GANs to learn a prototypical stochastic process on a lattice. By suitably adding noise to the original data we succeed in bringing both the Generator and the Discriminator loss functions close to their ideal value. However, as typical for adversarial approaches, oscillations persist. This undermines model selection and the quality of the generated trajectory. We demonstrate that a suitable multi-model procedure where stochastic trajectories are advanced at each step upon randomly selecting a Generator leads to a remarkable increase in accuracy. Based on the reported findings GANs appears as a promising tool to tackle complex statistical dynamics. ",
    "url": "https://arxiv.org/abs/2305.15920",
    "authors": [
      "Daniele Lanzoni",
      "Olivier Pierre-Louis",
      "Francesco Montalenti"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.15990",
    "title": "PINNslope: seismic data interpolation and local slope estimation with  physics informed neural networks",
    "abstract": "Interpolation of aliased seismic data constitutes a key step in a seismic processing workflow to obtain high quality velocity models and seismic images. Leveraging on the idea of describing seismic wavefields as a superposition of local plane waves, we propose to interpolate seismic data by utilizing a physics informed neural network (PINN). In the proposed framework, two feed-forward neural networks are jointly trained using the local plane wave differential equation as well as the available data as two terms in the objective function: a primary network assisted by positional encoding is tasked with reconstructing the seismic data, whilst an auxiliary, smaller network estimates the associated local slopes. Results on synthetic and field data validate the effectiveness of the proposed method in handling aliased (sampled coarsely) data and data with large gaps. Our method compares favorably against a classic least-squares inversion approach regularized by the local plane-wave equation as well as a PINN-based approach with a single network and pre-computed local slopes. We find that by introducing a second network to estimate the local slopes whilst at the same time interpolating the aliased data, the overall reconstruction capabilities and convergence behavior of the primary network is enhanced. An additional positional encoding, embedded as a network layer, confers to the network the ability to converge faster improving the accuracy of the data term. ",
    "url": "https://arxiv.org/abs/2305.15990",
    "authors": [
      "Francesco Brandolin",
      "Matteo Ravasi",
      "Tariq Alkhalifah"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.16087",
    "title": "Linear Layouts of Bipartite Planar Graphs",
    "abstract": "A linear layout of a graph $ G $ consists of a linear order $\\prec$ of the vertices and a partition of the edges. A part is called a queue (stack) if no two edges nest (cross), that is, two edges $ (v,w) $ and $ (x,y) $ with $ v \\prec x \\prec y \\prec w $ ($ v \\prec x \\prec w \\prec y $) may not be in the same queue (stack). The best known lower and upper bounds for the number of queues needed for planar graphs are 4 [Alam et al., Algorithmica 2020] and 42 [Bekos et al., Algorithmica 2022], respectively. While queue layouts of special classes of planar graphs have received increased attention following the breakthrough result of [Dujmovi\\'c et al., J. ACM 2020], the meaningful class of bipartite planar graphs has remained elusive so far, explicitly asked for by Bekos et al. In this paper we investigate bipartite planar graphs and give an improved upper bound of 28 by refining existing techniques. In contrast, we show that two queues or one queue together with one stack do not suffice; the latter answers an open question by Pupyrev [GD 2018]. We further investigate subclasses of bipartite planar graphs and give improved upper bounds; in particular we construct 5-queue layouts for 2-degenerate quadrangulations. ",
    "url": "https://arxiv.org/abs/2305.16087",
    "authors": [
      "Henry F\u00f6rster",
      "Michael Kaufmann",
      "Laura Merker",
      "Sergey Pupyrev",
      "Chrysanthi Raftopoulou"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2305.16222",
    "title": "Incomplete Multimodal Learning for Complex Brain Disorders Prediction",
    "abstract": "Recent advancements in the acquisition of various brain data sources have created new opportunities for integrating multimodal brain data to assist in early detection of complex brain disorders. However, current data integration approaches typically need a complete set of biomedical data modalities, which may not always be feasible, as some modalities are only available in large-scale research cohorts and are prohibitive to collect in routine clinical practice. Especially in studies of brain diseases, research cohorts may include both neuroimaging data and genetic data, but for practical clinical diagnosis, we often need to make disease predictions only based on neuroimages. As a result, it is desired to design machine learning models which can use all available data (different data could provide complementary information) during training but conduct inference using only the most common data modality. We propose a new incomplete multimodal data integration approach that employs transformers and generative adversarial networks to effectively exploit auxiliary modalities available during training in order to improve the performance of a unimodal model at inference. We apply our new method to predict cognitive degeneration and disease outcomes using the multimodal imaging genetic data from Alzheimer's Disease Neuroimaging Initiative (ADNI) cohort. Experimental results demonstrate that our approach outperforms the related machine learning and deep learning methods by a significant margin. ",
    "url": "https://arxiv.org/abs/2305.16222",
    "authors": [
      "Reza Shirkavand",
      "Liang Zhan",
      "Heng Huang",
      "Li Shen",
      "Paul M. Thompson"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2305.16274",
    "title": "Non-adversarial training of Neural SDEs with signature kernel scores",
    "abstract": "Neural SDEs are continuous-time generative models for sequential data. State-of-the-art performance for irregular time series generation has been previously obtained by training these models adversarially as GANs. However, as typical for GAN architectures, training is notoriously unstable, often suffers from mode collapse, and requires specialised techniques such as weight clipping and gradient penalty to mitigate these issues. In this paper, we introduce a novel class of scoring rules on pathspace based on signature kernels and use them as objective for training Neural SDEs non-adversarially. By showing strict properness of such kernel scores and consistency of the corresponding estimators, we provide existence and uniqueness guarantees for the minimiser. With this formulation, evaluating the generator-discriminator pair amounts to solving a system of linear path-dependent PDEs which allows for memory-efficient adjoint-based backpropagation. Moreover, because the proposed kernel scores are well-defined for paths with values in infinite dimensional spaces of functions, our framework can be easily extended to generate spatiotemporal data. Our procedure permits conditioning on a rich variety of market conditions and significantly outperforms alternative ways of training Neural SDEs on a variety of tasks including the simulation of rough volatility models, the conditional probabilistic forecasts of real-world forex pairs where the conditioning variable is an observed past trajectory, and the mesh-free generation of limit order book dynamics. ",
    "url": "https://arxiv.org/abs/2305.16274",
    "authors": [
      "Zacharia Issa",
      "Blanka Horvath",
      "Maud Lemercier",
      "Cristopher Salvi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)"
    ]
  },
  {
    "id": "arXiv:1910.05483",
    "title": "Frustum VoxNet for 3D object detection from RGB-D or Depth images",
    "abstract": " Comments: Update for v3: Added 2D detection performance of using RGBDHS as input in appendix. page 8, add Acknowledgement. page 10, add Supplementary Material. The paper got accepted by 2020 Winter Conference on Applications of Computer Vision (WACV '20). The first arxiv version can be found here: arXiv:1910.05483 ",
    "url": "https://arxiv.org/abs/1910.05483",
    "authors": [
      "Xiaoke Shen",
      "Ioannis Stamos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2008.09312",
    "title": "Near Optimal Adversarial Attack on UCB Bandits",
    "abstract": " Title: Near Optimal Adversarial Attack on UCB Bandits ",
    "url": "https://arxiv.org/abs/2008.09312",
    "authors": [
      "Shiliang Zuo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2010.09694",
    "title": "Data Assimilation Networks",
    "abstract": " Title: Data Assimilation Networks ",
    "url": "https://arxiv.org/abs/2010.09694",
    "authors": [
      "Pierre Boudier",
      "Anthony Fillion",
      "Serge Gratton",
      "Selime G\u00fcrol",
      "Sixin Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2203.01032",
    "title": "Graph Rewriting and Relabeling with PBPO+: A Unifying Theory for  Quasitoposes",
    "abstract": " Comments: This article significantly extends and improves arXiv:2010.08230. 36 pages ",
    "url": "https://arxiv.org/abs/2203.01032",
    "authors": [
      "Roy Overbeek",
      "J\u00f6rg Endrullis",
      "Alo\u00efs Rosset"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2203.07648",
    "title": "Contrastive Learning of Sociopragmatic Meaning in Social Media",
    "abstract": " Comments: Final camera-ready version for ACL2023 ",
    "url": "https://arxiv.org/abs/2203.07648",
    "authors": [
      "Chiyu Zhang",
      "Muhammad Abdul-Mageed",
      "Ganesh Jawahar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.05953",
    "title": "Explore More Guidance: A Task-aware Instruction Network for Sign  Language Translation Enhanced with Data Augmentation",
    "abstract": " Comments: NAACL 2022 Findings ",
    "url": "https://arxiv.org/abs/2204.05953",
    "authors": [
      "Yong Cao",
      "Wei Li",
      "Xianzhi Li",
      "Min Chen",
      "Guangyong Chen",
      "Long Hu",
      "Zhengdao Li",
      "Hwang Kai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.08099",
    "title": "Dimensionality Reduced Training by Pruning and Freezing Parts of a Deep  Neural Network, a Survey",
    "abstract": " Comments: This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this article is published in Artificial Intelligence Review (2023), and is available online at this https URL ",
    "url": "https://arxiv.org/abs/2205.08099",
    "authors": [
      "Paul Wimmer",
      "Jens Mehnert",
      "Alexandru Paul Condurache"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.00859",
    "title": "Disentangled Generation Network for Enlarged License Plate Recognition  and A Unified Dataset",
    "abstract": " Comments: Submission to CVIU ",
    "url": "https://arxiv.org/abs/2206.00859",
    "authors": [
      "Chenglong Li",
      "Xiaobin Yang",
      "Guohao Wang",
      "Aihua Zheng",
      "Chang Tan",
      "Ruoran Jia",
      "Jin Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.08019",
    "title": "Multi-View Imputation and Cross-Attention Network Based on Incomplete  Longitudinal and Multimodal Data for Conversion Prediction of Mild Cognitive  Impairment",
    "abstract": " Title: Multi-View Imputation and Cross-Attention Network Based on Incomplete  Longitudinal and Multimodal Data for Conversion Prediction of Mild Cognitive  Impairment ",
    "url": "https://arxiv.org/abs/2206.08019",
    "authors": [
      "Tao Wang",
      "Xiumei Chen",
      "Xiaoling Zhang",
      "Shuoling Zhou",
      "Qianjin Feng",
      "Meiyan Huang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.03579",
    "title": "DGraph: A Large-Scale Financial Dataset for Graph Anomaly Detection",
    "abstract": " Comments: Dataset Url: this https URL ",
    "url": "https://arxiv.org/abs/2207.03579",
    "authors": [
      "Xuanwen Huang",
      "Yang Yang",
      "Yang Wang",
      "Chunping Wang",
      "Zhisheng Zhang",
      "Jiarong Xu",
      "Lei Chen",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.08363",
    "title": "Latent-Domain Predictive Neural Speech Coding",
    "abstract": " Comments: Accepted by IEEE/ACM TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE PROCESSING (TASLP) ",
    "url": "https://arxiv.org/abs/2207.08363",
    "authors": [
      "Xue Jiang",
      "Xiulian Peng",
      "Huaying Xue",
      "Yuan Zhang",
      "Yan Lu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.14116",
    "title": "Claim-Dissector: An Interpretable Fact-Checking System with Joint  Re-ranking and Veracity Prediction",
    "abstract": " Comments: Accepted to Findings of ACL'23 ",
    "url": "https://arxiv.org/abs/2207.14116",
    "authors": [
      "Martin Fajcik",
      "Petr Motlicek",
      "Pavel Smrz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.00511",
    "title": "Aggretriever: A Simple Approach to Aggregate Textual Representations for  Robust Dense Passage Retrieval",
    "abstract": " Comments: Published in Transactions of the Association for Computational Linguistics ",
    "url": "https://arxiv.org/abs/2208.00511",
    "authors": [
      "Sheng-Chieh Lin",
      "Minghan Li",
      "Jimmy Lin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2208.12448",
    "title": "CMD: Self-supervised 3D Action Representation Learning with Cross-modal  Mutual Distillation",
    "abstract": " Comments: To appear in ECCV 2022 (Oral) ",
    "url": "https://arxiv.org/abs/2208.12448",
    "authors": [
      "Yunyao Mao",
      "Wengang Zhou",
      "Zhenbo Lu",
      "Jiajun Deng",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.07753",
    "title": "Code as Policies: Language Model Programs for Embodied Control",
    "abstract": " Title: Code as Policies: Language Model Programs for Embodied Control ",
    "url": "https://arxiv.org/abs/2209.07753",
    "authors": [
      "Jacky Liang",
      "Wenlong Huang",
      "Fei Xia",
      "Peng Xu",
      "Karol Hausman",
      "Brian Ichter",
      "Pete Florence",
      "Andy Zeng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.12528",
    "title": "Taming Client Dropout and Improving Efficiency for Distributed  Differential Privacy in Federated Learning",
    "abstract": " Comments: 19 pages, 10 figures, 4 tables, under anonymous submission ",
    "url": "https://arxiv.org/abs/2209.12528",
    "authors": [
      "Zhifeng Jiang",
      "Wei Wang",
      "Ruichuan Chen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.07342",
    "title": "Cognitive-Driven Development Helps Software Teams to Keep Code Units  Under the Limit!",
    "abstract": " Comments: 28 pages, submitted to JSS (in Practice Track) ",
    "url": "https://arxiv.org/abs/2210.07342",
    "authors": [
      "Gustavo Pinto",
      "Alberto de Souza"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.12810",
    "title": "Code4Struct: Code Generation for Few-Shot Event Structure Prediction",
    "abstract": " Comments: ACL 2023 ",
    "url": "https://arxiv.org/abs/2210.12810",
    "authors": [
      "Xingyao Wang",
      "Sha Li",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.13416",
    "title": "A Continuous Convolutional Trainable Filter for Modelling Unstructured  Data",
    "abstract": " Title: A Continuous Convolutional Trainable Filter for Modelling Unstructured  Data ",
    "url": "https://arxiv.org/abs/2210.13416",
    "authors": [
      "Dario Coscia",
      "Laura Meneghetti",
      "Nicola Demo",
      "Giovanni Stabile",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.15876",
    "title": "Random Utterance Concatenation Based Data Augmentation for Improving  Short-video Speech Recognition",
    "abstract": " Comments: 5 pages, 3 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2210.15876",
    "authors": [
      "Yist Y. Lin",
      "Tao Han",
      "Haihua Xu",
      "Van Tung Pham",
      "Yerbolat Khassanov",
      "Tze Yuang Chong",
      "Yi He",
      "Lu Lu",
      "Zejun Ma"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.01069",
    "title": "On Correlation Detection and Alignment Recovery of Gaussian Databases",
    "abstract": " Comments: 43 pages, 20 figures ",
    "url": "https://arxiv.org/abs/2211.01069",
    "authors": [
      "Ran Tamir"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2211.01874",
    "title": "Contextual information integration for stance detection via  cross-attention",
    "abstract": " Comments: *SEM 2023, Data and code at this https URL ",
    "url": "https://arxiv.org/abs/2211.01874",
    "authors": [
      "Tilman Beck",
      "Andreas Waldis",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.04687",
    "title": "Lightweight network towards real-time image denoising on mobile devices",
    "abstract": " Comments: Under review at the 2023 IEEE International Conference on Image Processing (ICIP 2023) ",
    "url": "https://arxiv.org/abs/2211.04687",
    "authors": [
      "Zhuoqun Liu",
      "Meiguang Jin",
      "Ying Chen",
      "Huaida Liu",
      "Canqian Yang",
      "Hongkai Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2211.05523",
    "title": "Impact of Adversarial Training on Robustness and Generalizability of  Language Models",
    "abstract": " Title: Impact of Adversarial Training on Robustness and Generalizability of  Language Models ",
    "url": "https://arxiv.org/abs/2211.05523",
    "authors": [
      "Enes Altinisik",
      "Hassan Sajjad",
      "Husrev Taha Sencar",
      "Safa Messaoud",
      "Sanjay Chawla"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.05528",
    "title": "PAD-Net: An Efficient Framework for Dynamic Networks",
    "abstract": " Comments: Proceedings of ACL 2023 ",
    "url": "https://arxiv.org/abs/2211.05528",
    "authors": [
      "Shwai He",
      "Liang Ding",
      "Daize Dong",
      "Boan Liu",
      "Fuqiang Yu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.05656",
    "title": "On Proper Learnability between Average- and Worst-case Robustness",
    "abstract": " Comments: 19 pages ",
    "url": "https://arxiv.org/abs/2211.05656",
    "authors": [
      "Vinod Raman",
      "Unique Subedi",
      "Ambuj Tewari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.07533",
    "title": "Generalized Balancing Weights via Deep Neural Networks",
    "abstract": " Comments: The description of enhancing the balancing weights was deleted because of an overlearning problem. A description of a curse of dimensionality when balancing multivariate data was added ",
    "url": "https://arxiv.org/abs/2211.07533",
    "authors": [
      "Yoshiaki Kitazawa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08486",
    "title": "Scalar Invariant Networks with Zero Bias",
    "abstract": " Comments: 22 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2211.08486",
    "authors": [
      "Chuqin Geng",
      "Xiaojie Xu",
      "Haolin Ye",
      "Xujie Si"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11238",
    "title": "RobustLoc: Robust Camera Pose Regression in Challenging Driving  Environments",
    "abstract": " Comments: Accepted by AAAI 2023 ",
    "url": "https://arxiv.org/abs/2211.11238",
    "authors": [
      "Sijie Wang",
      "Qiyu Kang",
      "Rui She",
      "Wee Peng Tay",
      "Andreas Hartmannsgruber",
      "Diego Navarro Navarro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.12080",
    "title": "Robust Training for Speaker Verification against Noisy Labels",
    "abstract": " Comments: Accepted by INTERSPEECH 2023 ",
    "url": "https://arxiv.org/abs/2211.12080",
    "authors": [
      "Zhihua Fang",
      "Liang He",
      "Hanhan Ma",
      "Xiaochen Guo",
      "Lin Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.13236",
    "title": "MEGAN: Multi-Explanation Graph Attention Network",
    "abstract": " Comments: 24 pages, accepted for xAI 2023 conference portugal ",
    "url": "https://arxiv.org/abs/2211.13236",
    "authors": [
      "Jonas Teufel",
      "Luca Torresi",
      "Patrick Reiser",
      "Pascal Friederich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.01006",
    "title": "Self-supervised On-device Federated Learning from Unlabeled Streams",
    "abstract": " Title: Self-supervised On-device Federated Learning from Unlabeled Streams ",
    "url": "https://arxiv.org/abs/2212.01006",
    "authors": [
      "Jiahe Shi",
      "Yawen Wu",
      "Dewen Zeng",
      "Jun Tao",
      "Jingtong Hu",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.01758",
    "title": "Improving Zero-shot Generalization and Robustness of Multi-modal Models",
    "abstract": " Comments: CVPR 2023 ",
    "url": "https://arxiv.org/abs/2212.01758",
    "authors": [
      "Yunhao Ge",
      "Jie Ren",
      "Andrew Gallagher",
      "Yuxiao Wang",
      "Ming-Hsuan Yang",
      "Hartwig Adam",
      "Laurent Itti",
      "Balaji Lakshminarayanan",
      "Jiaping Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.04325",
    "title": "Lattice-Free Sequence Discriminative Training for Phoneme-Based Neural  Transducers",
    "abstract": " Comments: accepted at ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2212.04325",
    "authors": [
      "Zijian Yang",
      "Wei Zhou",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2212.04655",
    "title": "MIMO Is All You Need : A Strong Multi-In-Multi-Out Baseline for Video  Prediction",
    "abstract": " Title: MIMO Is All You Need : A Strong Multi-In-Multi-Out Baseline for Video  Prediction ",
    "url": "https://arxiv.org/abs/2212.04655",
    "authors": [
      "Shuliang Ning",
      "Mengcheng Lan",
      "Yanran Li",
      "Chaofeng Chen",
      "Qian Chen",
      "Xunlai Chen",
      "Xiaoguang Han",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.05598",
    "title": "Recurrent Vision Transformers for Object Detection with Event Cameras",
    "abstract": " Title: Recurrent Vision Transformers for Object Detection with Event Cameras ",
    "url": "https://arxiv.org/abs/2212.05598",
    "authors": [
      "Mathias Gehrig",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.04421",
    "title": "Failure Detection for Motion Prediction of Autonomous Driving: An  Uncertainty Perspective",
    "abstract": " Comments: Accepted by 2023 IEEE International Conference on Robotics and Automation (ICRA 2023) ",
    "url": "https://arxiv.org/abs/2301.04421",
    "authors": [
      "Wenbo Shao",
      "Yanchao Xu",
      "Liang Peng",
      "Jun Li",
      "Hong Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.04881",
    "title": "Strengthening the Directed Brooks' Theorem for oriented graphs and  consequences on digraph redicolouring",
    "abstract": " Comments: 13 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2301.04881",
    "authors": [
      "Lucas Picasarri-Arrieta"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2301.06719",
    "title": "FemtoDet: An Object Detection Baseline for Energy Versus Performance  Tradeoffs",
    "abstract": " Comments: 15 pages ",
    "url": "https://arxiv.org/abs/2301.06719",
    "authors": [
      "Peng Tu",
      "Xu Xie",
      "Guo AI",
      "Yuexiang Li",
      "Yawen Huang",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.12594",
    "title": "A theory of continuous generative flow networks",
    "abstract": " Comments: ICML 2023; 32 pages; code: this https URL ",
    "url": "https://arxiv.org/abs/2301.12594",
    "authors": [
      "Salem Lahlou",
      "Tristan Deleu",
      "Pablo Lemos",
      "Dinghuai Zhang",
      "Alexandra Volokhova",
      "Alex Hern\u00e1ndez-Garc\u00eda",
      "L\u00e9na N\u00e9hale Ezzine",
      "Yoshua Bengio",
      "Nikolay Malkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.13764",
    "title": "Semi-Supervised Classification with Graph Convolutional Kernel Machines",
    "abstract": " Title: Semi-Supervised Classification with Graph Convolutional Kernel Machines ",
    "url": "https://arxiv.org/abs/2301.13764",
    "authors": [
      "Sonny Achten",
      "Francesco Tonin",
      "Panagiotis Patrinos",
      "Johan A. K. Suykens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02907",
    "title": "GAT: Guided Adversarial Training with Pareto-optimal Auxiliary Tasks",
    "abstract": " Title: GAT: Guided Adversarial Training with Pareto-optimal Auxiliary Tasks ",
    "url": "https://arxiv.org/abs/2302.02907",
    "authors": [
      "Salah Ghamizi",
      "Jingfeng Zhang",
      "Maxime Cordy",
      "Mike Papadakis",
      "Masashi Sugiyama",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.03025",
    "title": "A Toy Model of Universality: Reverse Engineering How Networks Learn  Group Operations",
    "abstract": " Comments: 9 page main body, 1 page references, 12 page appendix ",
    "url": "https://arxiv.org/abs/2302.03025",
    "authors": [
      "Bilal Chughtai",
      "Lawrence Chan",
      "Neel Nanda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Representation Theory (math.RT)"
    ]
  },
  {
    "id": "arXiv:2303.04506",
    "title": "Radio astronomical images object detection and segmentation: A benchmark  on deep learning methods",
    "abstract": " Title: Radio astronomical images object detection and segmentation: A benchmark  on deep learning methods ",
    "url": "https://arxiv.org/abs/2303.04506",
    "authors": [
      "Renato Sortino",
      "Daniel Magro",
      "Giuseppe Fiameni",
      "Eva Sciacca",
      "Simone Riggi",
      "Andrea DeMarco",
      "Concetto Spampinato",
      "Andrew M. Hopkins",
      "Filomena Bufano",
      "Francesco Schillir\u00f2",
      "Cristobal Bordiu",
      "Carmelo Pino"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07812",
    "title": "Termination of Graph Transformation Systems Using Weighted Subgraph  Counting",
    "abstract": " Comments: 24 pages. Accepted at the 16th International Conference on Graph Transformation (ICGT 2023) ",
    "url": "https://arxiv.org/abs/2303.07812",
    "authors": [
      "Roy Overbeek",
      "J\u00f6rg Endrullis"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2303.08035",
    "title": "ISimDL: Importance Sampling-Driven Acceleration of Fault Injection  Simulations for Evaluating the Robustness of Deep Learning",
    "abstract": " Comments: Submission under review ",
    "url": "https://arxiv.org/abs/2303.08035",
    "authors": [
      "Alessio Colucci",
      "Andreas Steininger",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.15015",
    "title": "Towards Open Temporal Graph Neural Networks",
    "abstract": " Comments: ICLR 2023 Oral, code is available at: this https URL ",
    "url": "https://arxiv.org/abs/2303.15015",
    "authors": [
      "Kaituo Feng",
      "Changsheng Li",
      "Xiaolu Zhang",
      "Jun Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.16524",
    "title": "Ensemble Learning Model on Artificial Neural Network-Backpropagation  (ANN-BP) Architecture for Coal Pillar Stability Classification",
    "abstract": " Comments: The following article has been submitted to AIP Proceeding. After it is published, it will be found at this https URL ",
    "url": "https://arxiv.org/abs/2303.16524",
    "authors": [
      "G. Aileen Mendrofa",
      "Gatot Fatwanto Hertono",
      "Bevina Desjwiandara Handari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.01996",
    "title": "ANTN: Bridging Autoregressive Neural Networks and Tensor Networks for  Quantum Many-Body Simulation",
    "abstract": " Title: ANTN: Bridging Autoregressive Neural Networks and Tensor Networks for  Quantum Many-Body Simulation ",
    "url": "https://arxiv.org/abs/2304.01996",
    "authors": [
      "Zhuo Chen",
      "Laker Newhouse",
      "Eddie Chen",
      "Di Luo",
      "Marin Solja\u010di\u0107"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2304.03996",
    "title": "A Unified Characterization of Private Learnability via Graph Theory",
    "abstract": " Comments: v1.2, acknowledgements ",
    "url": "https://arxiv.org/abs/2304.03996",
    "authors": [
      "Noga Alon",
      "Shay Moran",
      "Hilla Schefler",
      "Amir Yehudayoff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04662",
    "title": "SELFormer: Molecular Representation Learning via SELFIES Language Models",
    "abstract": " Comments: 22 pages, 4 figures, 8 tables ",
    "url": "https://arxiv.org/abs/2304.04662",
    "authors": [
      "Atakan Y\u00fcksel",
      "Erva Ulusoy",
      "Atabey \u00dcnl\u00fc",
      "Tunca Do\u011fan"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.05297",
    "title": "Neural Network Approach to Portfolio Optimization with Leverage  Constraints:a Case Study on High Inflation Investment",
    "abstract": " Title: Neural Network Approach to Portfolio Optimization with Leverage  Constraints:a Case Study on High Inflation Investment ",
    "url": "https://arxiv.org/abs/2304.05297",
    "authors": [
      "Chendi Ni",
      "Yuying Li",
      "Peter A. Forsyth"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computational Finance (q-fin.CP)"
    ]
  },
  {
    "id": "arXiv:2305.01157",
    "title": "Complex Logical Reasoning over Knowledge Graphs using Large Language  Models",
    "abstract": " Comments: Code available at this https URL ",
    "url": "https://arxiv.org/abs/2305.01157",
    "authors": [
      "Nurendra Choudhary",
      "Chandan K. Reddy"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2305.02886",
    "title": "SlipCover: Near Zero-Overhead Code Coverage for Python",
    "abstract": " Comments: Accepted to ISSTA 2023 ",
    "url": "https://arxiv.org/abs/2305.02886",
    "authors": [
      "Juan Altmayer Pizzorno",
      "Emery D Berger"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2305.04647",
    "title": "Criteria for the construction of MDS convolutional codes with good  column distances",
    "abstract": " Title: Criteria for the construction of MDS convolutional codes with good  column distances ",
    "url": "https://arxiv.org/abs/2305.04647",
    "authors": [
      "Zita Abreu",
      "Julia Lieb",
      "Raquel Pinto",
      "Joachim Rosenthal"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.04693",
    "title": "Binary convolutional codes with optimal column distances",
    "abstract": " Title: Binary convolutional codes with optimal column distances ",
    "url": "https://arxiv.org/abs/2305.04693",
    "authors": [
      "Zita Abreu",
      "Julia Lieb",
      "Joachim Rosenthal"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.04706",
    "title": "A new construction of an MDS convolutional code of rate 1/2",
    "abstract": " Title: A new construction of an MDS convolutional code of rate 1/2 ",
    "url": "https://arxiv.org/abs/2305.04706",
    "authors": [
      "Zita Abreu",
      "Raquel Pinto",
      "Rita Sim\u00f5es"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.10974",
    "title": "MonoTDP: Twin Depth Perception for Monocular 3D Object Detection in  Adverse Scenes",
    "abstract": " Comments: 10 pages, 5 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2305.10974",
    "authors": [
      "Xingyuan Li",
      "Jinyuan Liu",
      "Yixin Lei",
      "Long Ma",
      "Xin Fan",
      "Risheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.11442",
    "title": "Zero-Shot Text Classification via Self-Supervised Tuning",
    "abstract": " Comments: Accepted to the Findings of ACL 2023 ",
    "url": "https://arxiv.org/abs/2305.11442",
    "authors": [
      "Chaoqun Liu",
      "Wenxuan Zhang",
      "Guizhen Chen",
      "Xiaobao Wu",
      "Anh Tuan Luu",
      "Chip Hong Chang",
      "Lidong Bing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.11996",
    "title": "EEG and EMG dataset for the detection of errors introduced by an active  orthosis device",
    "abstract": " Comments: Revised references to our datasets, general corrections to typos, and latex template format changes, Overall Content unchanged ",
    "url": "https://arxiv.org/abs/2305.11996",
    "authors": [
      "Niklas Kueper",
      "Kartik Chari",
      "Judith B\u00fctef\u00fcr",
      "Julia Habenicht",
      "Su Kyoung Kim",
      "Tobias Rossol",
      "Marc Tabie",
      "Frank Kirchner",
      "Elsa Andrea Kirchner"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.12095",
    "title": "Make Transformer Great Again for Time Series Forecasting: Channel  Aligned Robust Dual Transformer",
    "abstract": " Title: Make Transformer Great Again for Time Series Forecasting: Channel  Aligned Robust Dual Transformer ",
    "url": "https://arxiv.org/abs/2305.12095",
    "authors": [
      "Wang Xue",
      "Tian Zhou",
      "Qingsong Wen",
      "Jinyang Gao",
      "Bolin Ding",
      "Rong Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12256",
    "title": "Scene Graph as Pivoting: Inference-time Image-free Unsupervised  Multimodal Machine Translation with Visual Scene Hallucination",
    "abstract": " Comments: ACL 2023 ",
    "url": "https://arxiv.org/abs/2305.12256",
    "authors": [
      "Hao Fei",
      "Qian Liu",
      "Meishan Zhang",
      "Min Zhang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12334",
    "title": "Towards Complex Dynamic Physics System Simulation with Graph Neural ODEs",
    "abstract": " Comments: 12 pages,5 figures, 6 tables, 49 references ",
    "url": "https://arxiv.org/abs/2305.12334",
    "authors": [
      "Guangsi Shi",
      "Daokun Zhang",
      "Ming Jin",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Atomic Physics (physics.atom-ph)"
    ]
  },
  {
    "id": "arXiv:2305.12427",
    "title": "VL-Fields: Towards Language-Grounded Neural Implicit Spatial  Representations",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2305.12427",
    "authors": [
      "Nikolaos Tsagkas",
      "Oisin Mac Aodha",
      "Chris Xiaoxuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12678",
    "title": "Gradient-Boosted Decision Tree for Listwise Context Model in Multimodal  Review Helpfulness Prediction",
    "abstract": " Comments: Published in ACL 2023 (Findings) ",
    "url": "https://arxiv.org/abs/2305.12678",
    "authors": [
      "Thong Nguyen",
      "Xiaobao Wu",
      "Xinshuai Dong",
      "Anh Tuan Luu",
      "Cong-Duy Nguyen",
      "Zhen Hai",
      "Lidong Bing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.12997",
    "title": "EXACT: Extensive Attack for Split Learning",
    "abstract": " Comments: 10 pages ",
    "url": "https://arxiv.org/abs/2305.12997",
    "authors": [
      "Xinchi Qiu",
      "Ilias Leontiadis",
      "Luca Melis",
      "Alex Sablayrolles",
      "Pierre Stock"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.13297",
    "title": "Investigating the Role of Feed-Forward Networks in Transformers Using  Parallel Attention and Feed-Forward Net Design",
    "abstract": " Title: Investigating the Role of Feed-Forward Networks in Transformers Using  Parallel Attention and Feed-Forward Net Design ",
    "url": "https://arxiv.org/abs/2305.13297",
    "authors": [
      "Shashank Sonkar",
      "Richard G. Baraniuk"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14046",
    "title": "Towards Automated Security Analysis of Smart Contracts based on  Execution Property Graph",
    "abstract": " Title: Towards Automated Security Analysis of Smart Contracts based on  Execution Property Graph ",
    "url": "https://arxiv.org/abs/2305.14046",
    "authors": [
      "Kaihua Qin",
      "Zhe Ye",
      "Zhun Wang",
      "Weilin Li",
      "Liyi Zhou",
      "Chao Zhang",
      "Dawn Song",
      "Arthur Gervais"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.14477",
    "title": "A Block-Coordinate Approach of Multi-level Optimization with an  Application to Physics-Informed Neural Networks",
    "abstract": " Title: A Block-Coordinate Approach of Multi-level Optimization with an  Application to Physics-Informed Neural Networks ",
    "url": "https://arxiv.org/abs/2305.14477",
    "authors": [
      "Serge Gratton",
      "Valentin Mercier",
      "Elisa Riccietti",
      "Philippe L. Toint"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2305.14673",
    "title": "ORRN: An ODE-based Recursive Registration Network for Deformable  Respiratory Motion Estimation with Lung 4DCT Images",
    "abstract": " Comments: Accepted by IEEE Transactions on Biomedical Engineering ",
    "url": "https://arxiv.org/abs/2305.14673",
    "authors": [
      "Xiao Liang",
      "Shan Lin",
      "Fei Liu",
      "Dimitri Schreiber",
      "Michael Yip"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14700",
    "title": "AdvFunMatch: When Consistent Teaching Meets Adversarial Robustness",
    "abstract": " Title: AdvFunMatch: When Consistent Teaching Meets Adversarial Robustness ",
    "url": "https://arxiv.org/abs/2305.14700",
    "authors": [
      "Zihui Wu",
      "Haichang Gao",
      "Bingqian Zhou",
      "Ping Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14749",
    "title": "Multi-State RNA Design with Geometric Multi-Graph Neural Networks",
    "abstract": " Title: Multi-State RNA Design with Geometric Multi-Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2305.14749",
    "authors": [
      "Chaitanya K. Joshi",
      "Arian R. Jamasb",
      "Ramon Vi\u00f1as",
      "Charles Harris",
      "Simon Mathis",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2305.14778",
    "title": "P-vectors: A Parallel-Coupled TDNN/Transformer Network for Speaker  Verification",
    "abstract": " Comments: Accepted by INTERSPEECH 2023 ",
    "url": "https://arxiv.org/abs/2305.14778",
    "authors": [
      "Xiyuan Wang",
      "Fangyuan Wang",
      "Bo Xu",
      "Liang Xu",
      "Jing Xiao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.14859",
    "title": "Utility-Probability Duality of Neural Networks",
    "abstract": " Title: Utility-Probability Duality of Neural Networks ",
    "url": "https://arxiv.org/abs/2305.14859",
    "authors": [
      "Huang Bojun",
      "Fei Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.14890",
    "title": "HARD: Hard Augmentations for Robust Distillation",
    "abstract": " Title: HARD: Hard Augmentations for Robust Distillation ",
    "url": "https://arxiv.org/abs/2305.14890",
    "authors": [
      "Arne F. Nix",
      "Max F. Burg",
      "Fabian H. Sinz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15128",
    "title": "Age of Information in Reservation Multi-Access Networks with Stochastic  Arrivals: Analysis and Optimization",
    "abstract": " Comments: This work has been submitted for possible publication. arXiv admin note: substantial text overlap with arXiv:2206.00874 ",
    "url": "https://arxiv.org/abs/2305.15128",
    "authors": [
      "Qian Wang",
      "Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2305.15270",
    "title": "Reversible Graph Neural Network-based Reaction Distribution Learning for  Multiple Appropriate Facial Reactions Generation",
    "abstract": " Title: Reversible Graph Neural Network-based Reaction Distribution Learning for  Multiple Appropriate Facial Reactions Generation ",
    "url": "https://arxiv.org/abs/2305.15270",
    "authors": [
      "Tong Xu",
      "Micol Spitale",
      "Hao Tang",
      "Lu Liu",
      "Hatice Gunes",
      "Siyang Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]