[
  {
    "id": "arXiv:2305.13349",
    "title": "Multiclass classification for multidimensional functional data through  deep neural networks",
    "abstract": "The intrinsically infinite-dimensional features of the functional observations over multidimensional domains render the standard classification methods effectively inapplicable. To address this problem, we introduce a novel multiclass functional deep neural network (mfDNN) classifier as an innovative data mining and classification tool. Specifically, we consider sparse deep neural network architecture with rectifier linear unit (ReLU) activation function and minimize the cross-entropy loss in the multiclass classification setup. This neural network architecture allows us to employ modern computational tools in the implementation. The convergence rates of the misclassification risk functions are also derived for both fully observed and discretely observed multidimensional functional data. We demonstrate the performance of mfDNN on simulated data and several benchmark datasets from different application domains. ",
    "url": "https://arxiv.org/abs/2305.13349",
    "authors": [
      "Shuoyang Wang",
      "Guanqun Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2305.13388",
    "title": "The neural dynamics of auditory word recognition and integration",
    "abstract": "Listeners recognize and integrate words in rapid and noisy everyday speech by combining expectations about upcoming content with incremental sensory evidence. We present a computational model of word recognition which formalizes this perceptual process in Bayesian decision theory. We fit this model to explain scalp EEG signals recorded as subjects passively listened to a fictional story, revealing both the dynamics of the online auditory word recognition process and the neural correlates of the recognition and integration of words. The model reveals distinct neural processing of words depending on whether or not they can be quickly recognized. While all words trigger a neural response characteristic of probabilistic integration -- voltage modulations predicted by a word's surprisal in context -- these modulations are amplified for words which require more than roughly 100 ms of input to be recognized. We observe no difference in the latency of these neural responses according to words' recognition times.Our results support a two-part model of speech comprehension, combining an eager and rapid process of word recognition with a temporally independent process of word integration. ",
    "url": "https://arxiv.org/abs/2305.13388",
    "authors": [
      "Jon Gauthier",
      "Roger Levy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2305.13391",
    "title": "EnSiam: Self-Supervised Learning With Ensemble Representations",
    "abstract": "Recently, contrastive self-supervised learning, where the proximity of representations is determined based on the identities of samples, has made remarkable progress in unsupervised representation learning. SimSiam is a well-known example in this area, known for its simplicity yet powerful performance. However, it is known to be sensitive to changes in training configurations, such as hyperparameters and augmentation settings, due to its structural characteristics. To address this issue, we focus on the similarity between contrastive learning and the teacher-student framework in knowledge distillation. Inspired by the ensemble-based knowledge distillation approach, the proposed method, EnSiam, aims to improve the contrastive learning procedure using ensemble representations. This can provide stable pseudo labels, providing better performance. Experiments demonstrate that EnSiam outperforms previous state-of-the-art methods in most cases, including the experiments on ImageNet, which shows that EnSiam is capable of learning high-quality representations. ",
    "url": "https://arxiv.org/abs/2305.13391",
    "authors": [
      "Kyoungmin Han",
      "Minsik Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13396",
    "title": "Developmental Curiosity and Social Interaction in Virtual Agents",
    "abstract": "Infants explore their complex physical and social environment in an organized way. To gain insight into what intrinsic motivations may help structure this exploration, we create a virtual infant agent and place it in a developmentally-inspired 3D environment with no external rewards. The environment has a virtual caregiver agent with the capability to interact contingently with the infant agent in ways that resemble play. We test intrinsic reward functions that are similar to motivations that have been proposed to drive exploration in humans: surprise, uncertainty, novelty, and learning progress. These generic reward functions lead the infant agent to explore its environment and discover the contingencies that are embedded into the caregiver agent. The reward functions that are proxies for novelty and uncertainty are the most successful in generating diverse experiences and activating the environment contingencies. We also find that learning a world model in the presence of an attentive caregiver helps the infant agent learn how to predict scenarios with challenging social and physical dynamics. Taken together, our findings provide insight into how curiosity-like intrinsic rewards and contingent social interaction lead to dynamic social behavior and the creation of a robust predictive world model. ",
    "url": "https://arxiv.org/abs/2305.13396",
    "authors": [
      "Chris Doyle",
      "Sarah Shader",
      "Michelle Lau",
      "Megumi Sano",
      "Daniel L. K. Yamins",
      "Nick Haber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.13398",
    "title": "nnDetection for Intracranial Aneurysms Detection and Localization",
    "abstract": "Intracranial aneurysms are a commonly occurring and life-threatening condition, affecting approximately 3.2% of the general population. Consequently, detecting these aneurysms plays a crucial role in their management. Lesion detection involves the simultaneous localization and categorization of abnormalities within medical images. In this study, we employed the nnDetection framework, a self-configuring framework specifically designed for 3D medical object detection, to detect and localize the 3D coordinates of aneurysms effectively. To capture and extract diverse features associated with aneurysms, we utilized TOF-MRA and structural MRI, both obtained from the ADAM dataset. The performance of our proposed deep learning model was assessed through the utilization of free-response receiver operative characteristics for evaluation purposes. The model's weights and 3D prediction of the bounding box of TOF-MRA are publicly available at https://github.com/orouskhani/AneurysmDetection. ",
    "url": "https://arxiv.org/abs/2305.13398",
    "authors": [
      "Maysam Orouskhani",
      "Negar Firoozeh",
      "Shaojun Xia",
      "Mahmud Mossa-Basha",
      "Chengcheng Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2305.13399",
    "title": "Efficient Large-Scale Vision Representation Learning",
    "abstract": "In this article, we present our approach to single-modality vision representation learning. Understanding vision representations of product content is vital for recommendations, search, and advertising applications in e-commerce. We detail and contrast techniques used to fine tune large-scale vision representation learning models in an efficient manner under low-resource settings, including several pretrained backbone architectures, both in the convolutional neural network as well as the vision transformer family. We highlight the challenges for e-commerce applications at-scale and highlight the efforts to more efficiently train, evaluate, and serve visual representations. We present ablation studies for several downstream tasks, including our visually similar ad recommendations. We evaluate the offline performance of the derived visual representations in downstream tasks. To this end, we present a novel text-to-image generative offline evaluation method for visually similar recommendation systems. Finally, we include online results from deployed machine learning systems in production at Etsy. ",
    "url": "https://arxiv.org/abs/2305.13399",
    "authors": [
      "Eden Dolev",
      "Alaa Awad",
      "Denisa Roberts",
      "Zahra Ebrahimzadeh",
      "Marcin Mejran",
      "Vaibhav Malpani",
      "Mahir Yavuz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13413",
    "title": "Syntactic Knowledge via Graph Attention with BERT in Machine Translation",
    "abstract": "Although the Transformer model can effectively acquire context features via a self-attention mechanism, deeper syntactic knowledge is still not effectively modeled. To alleviate the above problem, we propose Syntactic knowledge via Graph attention with BERT (SGB) in Machine Translation (MT) scenarios. Graph Attention Network (GAT) and BERT jointly represent syntactic dependency feature as explicit knowledge of the source language to enrich source language representations and guide target language generation. Our experiments use gold syntax-annotation sentences and Quality Estimation (QE) model to obtain interpretability of translation quality improvement regarding syntactic knowledge without being limited to a BLEU score. Experiments show that the proposed SGB engines improve translation quality across the three MT tasks without sacrificing BLEU scores. We investigate what length of source sentences benefits the most and what dependencies are better identified by the SGB engines. We also find that learning of specific dependency relations by GAT can be reflected in the translation quality containing such relations and that syntax on the graph leads to new modeling of syntactic aspects of source sentences in the middle and bottom layers of BERT. ",
    "url": "https://arxiv.org/abs/2305.13413",
    "authors": [
      "Yuqian Dai",
      "Serge Sharoff",
      "Marc de Kamps"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13425",
    "title": "EINCASM: Emergent Intelligence in Neural Cellular Automaton Slime Molds",
    "abstract": "This paper presents EINCASM, a prototype system employing a novel framework for studying emergent intelligence in organisms resembling slime molds. EINCASM evolves neural cellular automata with NEAT to maximize cell growth constrained by nutrient and energy costs. These organisms capitalize physically simulated fluid to transport nutrients and chemical-like signals to orchestrate growth and adaptation to complex, changing environments. Our framework builds the foundation for studying how the presence of puzzles, physics, communication, competition and dynamic open-ended environments contribute to the emergence of intelligent behavior. We propose preliminary tests for intelligence in such organisms and suggest future work for more powerful systems employing EINCASM to better understand intelligence in distributed dynamical systems. ",
    "url": "https://arxiv.org/abs/2305.13425",
    "authors": [
      "Aidan Barbieux",
      "Rodrigo Canaan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2305.13464",
    "title": "Detection and mitigation of indirect conflicts between xApps in Open  Radio Access Networks",
    "abstract": "In Open Radio Access Networks, the Conflict Mitigation component, which is part of the Near-RT RIC, aims to detect and resolve any conflicts between xApp decisions. In this paper, we propose a universal method for detecting and resolving of indirect conflicts between xApps. Its efficiency is validated by extensive computer simulations. Our results demonstrate that, in the considered scenario, the mean bitrate satisfaction of users increases by 2%, while the number of radio link failures and ping-pong handovers in the network is significantly reduced. ",
    "url": "https://arxiv.org/abs/2305.13464",
    "authors": [
      "Cezary Adamczyk",
      "Adrian Kliks"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2305.13471",
    "title": "Fast Convergence in Learning Two-Layer Neural Networks with Separable  Data",
    "abstract": "Normalized gradient descent has shown substantial success in speeding up the convergence of exponentially-tailed loss functions (which includes exponential and logistic losses) on linear classifiers with separable data. In this paper, we go beyond linear models by studying normalized GD on two-layer neural nets. We prove for exponentially-tailed losses that using normalized GD leads to linear rate of convergence of the training loss to the global optimum. This is made possible by showing certain gradient self-boundedness conditions and a log-Lipschitzness property. We also study generalization of normalized GD for convex objectives via an algorithmic-stability analysis. In particular, we show that normalized GD does not overfit during training by establishing finite-time generalization bounds. ",
    "url": "https://arxiv.org/abs/2305.13471",
    "authors": [
      "Hossein Taheri",
      "Christos Thrampoulidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13472",
    "title": "A comprehensive theoretical framework for the optimization of neural  networks classification performance with respect to weighted metrics",
    "abstract": "In many contexts, customized and weighted classification scores are designed in order to evaluate the goodness of the predictions carried out by neural networks. However, there exists a discrepancy between the maximization of such scores and the minimization of the loss function in the training phase. In this paper, we provide a complete theoretical setting that formalizes weighted classification metrics and then allows the construction of losses that drive the model to optimize these metrics of interest. After a detailed theoretical analysis, we show that our framework includes as particular instances well-established approaches such as classical cost-sensitive learning, weighted cross entropy loss functions and value-weighted skill scores. ",
    "url": "https://arxiv.org/abs/2305.13472",
    "authors": [
      "Francesco Marchetti",
      "Sabrina Guastavino",
      "Cristina Campi",
      "Federico Benvenuto",
      "Michele Piana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.13485",
    "title": "Advancing Community Engaged Approaches to Identifying Structural Drivers  of Racial Bias in Health Diagnostic Algorithms",
    "abstract": "Much attention and concern has been raised recently about bias and the use of machine learning algorithms in healthcare, especially as it relates to perpetuating racial discrimination and health disparities. Following an initial system dynamics workshop at the Data for Black Lives II conference hosted at MIT in January of 2019, a group of conference participants interested in building capabilities to use system dynamics to understand complex societal issues convened monthly to explore issues related to racial bias in AI and implications for health disparities through qualitative and simulation modeling. In this paper we present results and insights from the modeling process and highlight the importance of centering the discussion of data and healthcare on people and their experiences with healthcare and science, and recognizing the societal context where the algorithm is operating. Collective memory of community trauma, through deaths attributed to poor healthcare, and negative experiences with healthcare are endogenous drivers of seeking treatment and experiencing effective care, which impact the availability and quality of data for algorithms. These drivers have drastically disparate initial conditions for different racial groups and point to limited impact of focusing solely on improving diagnostic algorithms for achieving better health outcomes for some groups. ",
    "url": "https://arxiv.org/abs/2305.13485",
    "authors": [
      "Jill A. Kuhlberg",
      "Irene Headen",
      "Ellis A. Ballard",
      "Donald Martin Jr."
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2305.13490",
    "title": "Detection of healthy and diseased crops in drone captured images using  Deep Learning",
    "abstract": "Monitoring plant health is crucial for maintaining agricultural productivity and food safety. Disruptions in the plant's normal state, caused by diseases, often interfere with essential plant activities, and timely detection of these diseases can significantly mitigate crop loss. In this study, we propose a deep learning-based approach for efficient detection of plant diseases using drone-captured imagery. A comprehensive database of various plant species, exhibiting numerous diseases, was compiled from the Internet and utilized as the training and test dataset. A Convolutional Neural Network (CNN), renowned for its performance in image classification tasks, was employed as our primary predictive model. The CNN model, trained on this rich dataset, demonstrated superior proficiency in crop disease categorization and detection, even under challenging imaging conditions. For field implementation, we deployed a prototype drone model equipped with a high-resolution camera for live monitoring of extensive agricultural fields. The captured images served as the input for our trained model, enabling real-time identification of healthy and diseased plants. Our approach promises an efficient and scalable solution for improving crop health monitoring systems. ",
    "url": "https://arxiv.org/abs/2305.13490",
    "authors": [
      "Jai Vardhan",
      "Kothapalli Sai Swetha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.13504",
    "title": "Neural Machine Translation for Code Generation",
    "abstract": "Neural machine translation (NMT) methods developed for natural language processing have been shown to be highly successful in automating translation from one natural language to another. Recently, these NMT methods have been adapted to the generation of program code. In NMT for code generation, the task is to generate output source code that satisfies constraints expressed in the input. In the literature, a variety of different input scenarios have been explored, including generating code based on natural language description, lower-level representations such as binary or assembly (neural decompilation), partial representations of source code (code completion and repair), and source code in another language (code translation). In this paper we survey the NMT for code generation literature, cataloging the variety of methods that have been explored according to input and output representations, model architectures, optimization techniques used, data sets, and evaluation methods. We discuss the limitations of existing methods and future research directions ",
    "url": "https://arxiv.org/abs/2305.13504",
    "authors": [
      "Dharma KC",
      "Clayton T. Morrison"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13508",
    "title": "DeepBern-Nets: Taming the Complexity of Certifying Neural Networks using  Bernstein Polynomial Activations and Precise Bound Propagation",
    "abstract": "Formal certification of Neural Networks (NNs) is crucial for ensuring their safety, fairness, and robustness. Unfortunately, on the one hand, sound and complete certification algorithms of ReLU-based NNs do not scale to large-scale NNs. On the other hand, incomplete certification algorithms are easier to compute, but they result in loose bounds that deteriorate with the depth of NN, which diminishes their effectiveness. In this paper, we ask the following question; can we replace the ReLU activation function with one that opens the door to incomplete certification algorithms that are easy to compute but can produce tight bounds on the NN's outputs? We introduce DeepBern-Nets, a class of NNs with activation functions based on Bernstein polynomials instead of the commonly used ReLU activation. Bernstein polynomials are smooth and differentiable functions with desirable properties such as the so-called range enclosure and subdivision properties. We design a novel algorithm, called Bern-IBP, to efficiently compute tight bounds on DeepBern-Nets outputs. Our approach leverages the properties of Bernstein polynomials to improve the tractability of neural network certification tasks while maintaining the accuracy of the trained networks. We conduct comprehensive experiments in adversarial robustness and reachability analysis settings to assess the effectiveness of the proposed Bernstein polynomial activation in enhancing the certification process. Our proposed framework achieves high certified accuracy for adversarially-trained NNs, which is often a challenging task for certifiers of ReLU-based NNs. Moreover, using Bern-IBP bounds for certified training results in NNs with state-of-the-art certified accuracy compared to ReLU networks. This work establishes Bernstein polynomial activation as a promising alternative for improving NN certification tasks across various applications. ",
    "url": "https://arxiv.org/abs/2305.13508",
    "authors": [
      "Haitham Khedr",
      "Yasser Shoukry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13509",
    "title": "ColMix -- A Simple Data Augmentation Framework to Improve Object  Detector Performance and Robustness in Aerial Images",
    "abstract": "In the last decade, Convolutional Neural Network (CNN) and transformer based object detectors have achieved high performance on a large variety of datasets. Though the majority of detection literature has developed this capability on datasets such as MS COCO, these detectors have still proven effective for remote sensing applications. Challenges in this particular domain, such as small numbers of annotated objects and low object density, hinder overall performance. In this work, we present a novel augmentation method, called collage pasting, for increasing the object density without a need for segmentation masks, thereby improving the detector performance. We demonstrate that collage pasting improves precision and recall beyond related methods, such as mosaic augmentation, and enables greater control of object density. However, we find that collage pasting is vulnerable to certain out-of-distribution shifts, such as image corruptions. To address this, we introduce two simple approaches for combining collage pasting with PixMix augmentation method, and refer to our combined techniques as ColMix. Through extensive experiments, we show that employing ColMix results in detectors with superior performance on aerial imagery datasets and robust to various corruptions. ",
    "url": "https://arxiv.org/abs/2305.13509",
    "authors": [
      "Cuong Ly",
      "Grayson Jorgenson",
      "Dan Rosa de Jesus",
      "Henry Kvinge",
      "Adam Attarian",
      "Yijing Watkins"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.13520",
    "title": "Tied-Augment: Controlling Representation Similarity Improves Data  Augmentation",
    "abstract": "Data augmentation methods have played an important role in the recent advance of deep learning models, and have become an indispensable component of state-of-the-art models in semi-supervised, self-supervised, and supervised training for vision. Despite incurring no additional latency at test time, data augmentation often requires more epochs of training to be effective. For example, even the simple flips-and-crops augmentation requires training for more than 5 epochs to improve performance, whereas RandAugment requires more than 90 epochs. We propose a general framework called Tied-Augment, which improves the efficacy of data augmentation in a wide range of applications by adding a simple term to the loss that can control the similarity of representations under distortions. Tied-Augment can improve state-of-the-art methods from data augmentation (e.g. RandAugment, mixup), optimization (e.g. SAM), and semi-supervised learning (e.g. FixMatch). For example, Tied-RandAugment can outperform RandAugment by 2.0% on ImageNet. Notably, using Tied-Augment, data augmentation can be made to improve generalization even when training for a few epochs and when fine-tuning. We open source our code at https://github.com/ekurtulus/tied-augment/tree/main. ",
    "url": "https://arxiv.org/abs/2305.13520",
    "authors": [
      "Emirhan Kurtulus",
      "Zichao Li",
      "Yann Dauphin",
      "Ekin Dogus Cubuk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13535",
    "title": "Improving Classifier Robustness through Active Generation of Pairwise  Counterfactuals",
    "abstract": "Counterfactual Data Augmentation (CDA) is a commonly used technique for improving robustness in natural language classifiers. However, one fundamental challenge is how to discover meaningful counterfactuals and efficiently label them, with minimal human labeling cost. Most existing methods either completely rely on human-annotated labels, an expensive process which limits the scale of counterfactual data, or implicitly assume label invariance, which may mislead the model with incorrect labels. In this paper, we present a novel framework that utilizes counterfactual generative models to generate a large number of diverse counterfactuals by actively sampling from regions of uncertainty, and then automatically label them with a learned pairwise classifier. Our key insight is that we can more correctly label the generated counterfactuals by training a pairwise classifier that interpolates the relationship between the original example and the counterfactual. We demonstrate that with a small amount of human-annotated counterfactual data (10%), we can generate a counterfactual augmentation dataset with learned labels, that provides an 18-20% improvement in robustness and a 14-21% reduction in errors on 6 out-of-domain datasets, comparable to that of a fully human-annotated counterfactual dataset for both sentiment classification and question paraphrase tasks. ",
    "url": "https://arxiv.org/abs/2305.13535",
    "authors": [
      "Ananth Balashankar",
      "Xuezhi Wang",
      "Yao Qin",
      "Ben Packer",
      "Nithum Thain",
      "Jilin Chen",
      "Ed H. Chi",
      "Alex Beutel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13542",
    "title": "Bidding Strategies for Proportional Representation in Advertisement  Campaigns",
    "abstract": "Many companies rely on advertising platforms such as Google, Facebook, or Instagram to recruit a large and diverse applicant pool for job openings. Prior works have shown that equitable bidding may not result in equitable outcomes due to heterogeneous levels of competition for different types of individuals. Suggestions have been made to address this problem via revisions to the advertising platform. However, it may be challenging to convince platforms to undergo a costly re-vamp of their system, and in addition it might not offer the flexibility necessary to capture the many types of fairness notions and other constraints that advertisers would like to ensure. Instead, we consider alterations that make no change to the platform mechanism and instead change the bidding strategies used by advertisers. We compare two natural fairness objectives: one in which the advertisers must treat groups equally when bidding in order to achieve a yield with group-parity guarantees, and another in which the bids are not constrained and only the yield must satisfy parity constraints. We show that requiring parity with respect to both bids and yield can result in an arbitrarily large decrease in efficiency compared to requiring equal yield proportions alone. We find that autobidding is a natural way to realize this latter objective and show how existing work in this area can be extended to provide efficient bidding strategies that provide high utility while satisfying group parity constraints as well as deterministic and randomized rounding techniques to uphold these guarantees. Finally, we demonstrate the effectiveness of our proposed solutions on data adapted from a real-world employment dataset. ",
    "url": "https://arxiv.org/abs/2305.13542",
    "authors": [
      "Inbal Livni Navon",
      "Charlotte Peale",
      "Omer Reingold",
      "Judy Hanwen Shen"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2305.13544",
    "title": "Algorithmic Security is Insufficient: A Comprehensive Survey on  Implementation Attacks Haunting Post-Quantum Security",
    "abstract": "This survey is on forward-looking, emerging security concerns in post-quantum era, i.e., the implementation attacks for 2022 winners of NIST post-quantum cryptography (PQC) competition and thus the visions, insights, and discussions can be used as a step forward towards scrutinizing the new standards for applications ranging from Metaverse, Web 3.0 to deeply-embedded systems. The rapid advances in quantum computing have brought immense opportunities for scientific discovery and technological progress; however, it poses a major risk to today's security since advanced quantum computers are believed to break all traditional public-key cryptographic algorithms. This has led to active research on PQC algorithms that are believed to be secure against classical and powerful quantum computers. However, algorithmic security is unfortunately insufficient, and many cryptographic algorithms are vulnerable to side-channel attacks (SCA), where an attacker passively or actively gets side-channel data to compromise the security properties that are assumed to be safe theoretically. In this survey, we explore such imminent threats and their countermeasures with respect to PQC. We provide the respective, latest advancements in PQC research, as well as assessments and providing visions on the different types of SCAs. ",
    "url": "https://arxiv.org/abs/2305.13544",
    "authors": [
      "Alvaro Cintas Canto",
      "Jasmin Kaur",
      "Mehran Mozaffari Kermani",
      "Reza Azarderakhsh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.13546",
    "title": "Neural Functional Transformers",
    "abstract": "The recent success of neural networks as implicit representation of data has driven growing interest in neural functionals: models that can process other neural networks as input by operating directly over their weight spaces. Nevertheless, constructing expressive and efficient neural functional architectures that can handle high-dimensional weight-space objects remains challenging. This paper uses the attention mechanism to define a novel set of permutation equivariant weight-space layers and composes them into deep equivariant models called neural functional Transformers (NFTs). NFTs respect weight-space permutation symmetries while incorporating the advantages of attention, which have exhibited remarkable success across multiple domains. In experiments processing the weights of feedforward MLPs and CNNs, we find that NFTs match or exceed the performance of prior weight-space methods. We also leverage NFTs to develop Inr2Array, a novel method for computing permutation invariant latent representations from the weights of implicit neural representations (INRs). Our proposed method improves INR classification accuracy by up to $+17\\%$ over existing methods. We provide an implementation of our layers at https://github.com/AllanYangZhou/nfn. ",
    "url": "https://arxiv.org/abs/2305.13546",
    "authors": [
      "Allan Zhou",
      "Kaien Yang",
      "Yiding Jiang",
      "Kaylee Burns",
      "Winnie Xu",
      "Samuel Sokota",
      "J. Zico Kolter",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.13547",
    "title": "Self-Evolution Learning for Mixup: Enhance Data Augmentation on Few-Shot  Text Classification Tasks",
    "abstract": "Text classification tasks often encounter few shot scenarios with limited labeled data, and addressing data scarcity is crucial. Data augmentation with mixup has shown to be effective on various text classification tasks. However, most of the mixup methods do not consider the varying degree of learning difficulty in different stages of training and generate new samples with one hot labels, resulting in the model over confidence. In this paper, we propose a self evolution learning (SE) based mixup approach for data augmentation in text classification, which can generate more adaptive and model friendly pesudo samples for the model training. SE focuses on the variation of the model's learning ability. To alleviate the model confidence, we introduce a novel instance specific label smoothing approach, which linearly interpolates the model's output and one hot labels of the original samples to generate new soft for label mixing up. Through experimental analysis, in addition to improving classification accuracy, we demonstrate that SE also enhances the model's generalize ability. ",
    "url": "https://arxiv.org/abs/2305.13547",
    "authors": [
      "Haoqi Zheng",
      "Qihuang Zhong",
      "Liang Ding",
      "Zhiliang Tian",
      "Xin Niu",
      "Dongsheng Li",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2305.13552",
    "title": "Squared Neural Families: A New Class of Tractable Density Models",
    "abstract": "Flexible models for probability distributions are an essential ingredient in many machine learning tasks. We develop and investigate a new class of probability distributions, which we call a Squared Neural Family (SNEFY), formed by squaring the 2-norm of a neural network and normalising it with respect to a base measure. Following the reasoning similar to the well established connections between infinitely wide neural networks and Gaussian processes, we show that SNEFYs admit a closed form normalising constants in many cases of interest, thereby resulting in flexible yet fully tractable density models. SNEFYs strictly generalise classical exponential families, are closed under conditioning, and have tractable marginal distributions. Their utility is illustrated on a variety of density estimation and conditional density estimation tasks. Software available at https://github.com/RussellTsuchida/snefy. ",
    "url": "https://arxiv.org/abs/2305.13552",
    "authors": [
      "Russell Tsuchida",
      "Cheng Soon Ong",
      "Dino Sejdinovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.13562",
    "title": "Understanding and Improving Optimization in Predictive Coding Networks",
    "abstract": "Backpropagation (BP), the standard learning algorithm for artificial neural networks, is often considered biologically implausible. In contrast, the standard learning algorithm for predictive coding (PC) models in neuroscience, known as the inference learning algorithm (IL), is a promising, bio-plausible alternative. However, several challenges and questions hinder IL's application to real-world problems. For example, IL is computationally demanding, and without memory-intensive optimizers like Adam, IL may converge to poor local minima. Moreover, although IL can reduce loss more quickly than BP, the reasons for these speedups or their robustness remains unclear. In this paper, we tackle these challenges by 1) altering the standard implementation of PC circuits to substantially reduce computation, 2) developing a novel optimizer that improves the convergence of IL without increasing memory usage, and 3) establishing theoretical results that help elucidate the conditions under which IL is sensitive to second and higher-order information. ",
    "url": "https://arxiv.org/abs/2305.13562",
    "authors": [
      "Nick Alonso",
      "Jeff Krichmar",
      "Emre Neftci"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2305.13573",
    "title": "SAD: Semi-Supervised Anomaly Detection on Dynamic Graphs",
    "abstract": "Anomaly detection aims to distinguish abnormal instances that deviate significantly from the majority of benign ones. As instances that appear in the real world are naturally connected and can be represented with graphs, graph neural networks become increasingly popular in tackling the anomaly detection problem. Despite the promising results, research on anomaly detection has almost exclusively focused on static graphs while the mining of anomalous patterns from dynamic graphs is rarely studied but has significant application value. In addition, anomaly detection is typically tackled from semi-supervised perspectives due to the lack of sufficient labeled data. However, most proposed methods are limited to merely exploiting labeled data, leaving a large number of unlabeled samples unexplored. In this work, we present semi-supervised anomaly detection (SAD), an end-to-end framework for anomaly detection on dynamic graphs. By a combination of a time-equipped memory bank and a pseudo-label contrastive learning module, SAD is able to fully exploit the potential of large unlabeled samples and uncover underlying anomalies on evolving graph streams. Extensive experiments on four real-world datasets demonstrate that SAD efficiently discovers anomalies from dynamic graphs and outperforms existing advanced methods even when provided with only little labeled data. ",
    "url": "https://arxiv.org/abs/2305.13573",
    "authors": [
      "Sheng Tian",
      "Jihai Dong",
      "Jintang Li",
      "Wenlong Zhao",
      "Xiaolong Xu",
      "Baokun wang",
      "Bowen Song",
      "Changhua Meng",
      "Tianyi Zhang",
      "Liang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.13584",
    "title": "Model Stealing Attack against Multi-Exit Networks",
    "abstract": "Compared to traditional neural networks with a single exit, a multi-exit network has multiple exits that allow for early output from intermediate layers of the model, thus bringing significant improvement in computational efficiency while maintaining similar recognition accuracy. When attempting to steal such valuable models using traditional model stealing attacks, we found that conventional methods can only steal the model's classification function while failing to capture its output strategy. This results in a significant decrease in computational efficiency for the stolen substitute model, thereby losing the advantages of multi-exit networks.In this paper, we propose the first model stealing attack to extract both the model function and output strategy. We employ bayesian changepoint detection to analyze the target model's output strategy and use performance loss and strategy loss to guide the training of the substitute model. Furthermore, we designed a novel output strategy search algorithm that can find the optimal output strategy to maximize the consistency between the victim model and the substitute model's outputs. Through experiments on multiple mainstream multi-exit networks and benchmark datasets, we thoroughly demonstrates the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2305.13584",
    "authors": [
      "Li Pan",
      "Lv Peizhuo",
      "Chen Kai",
      "Cai Yuling",
      "Xiang Fan",
      "Zhang Shengzhi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.13585",
    "title": "Query Structure Modeling for Inductive Logical Reasoning Over Knowledge  Graphs",
    "abstract": "Logical reasoning over incomplete knowledge graphs to answer complex logical queries is a challenging task. With the emergence of new entities and relations in constantly evolving KGs, inductive logical reasoning over KGs has become a crucial problem. However, previous PLMs-based methods struggle to model the logical structures of complex queries, which limits their ability to generalize within the same structure. In this paper, we propose a structure-modeled textual encoding framework for inductive logical reasoning over KGs. It encodes linearized query structures and entities using pre-trained language models to find answers. For structure modeling of complex queries, we design stepwise instructions that implicitly prompt PLMs on the execution order of geometric operations in each query. We further separately model different geometric operations (i.e., projection, intersection, and union) on the representation space using a pre-trained encoder with additional attention and maxout layers to enhance structured modeling. We conduct experiments on two inductive logical reasoning datasets and three transductive datasets. The results demonstrate the effectiveness of our method on logical reasoning over KGs in both inductive and transductive settings. ",
    "url": "https://arxiv.org/abs/2305.13585",
    "authors": [
      "Siyuan Wang",
      "Zhongyu Wei",
      "Meng Han",
      "Zhihao Fan",
      "Haijun Shan",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13589",
    "title": "BiasX: \"Thinking Slow\" in Toxic Content Moderation with Explanations of  Implied Social Biases",
    "abstract": "Toxicity annotators and content moderators often default to mental shortcuts when making decisions. This can lead to subtle toxicity being missed, and seemingly toxic but harmless content being over-detected. We introduce BiasX, a framework that enhances content moderation setups with free-text explanations of statements' implied social biases, and explore its effectiveness through a large-scale crowdsourced user study. We show that indeed, participants substantially benefit from explanations for correctly identifying subtly (non-)toxic content. The quality of explanations is critical: imperfect machine-generated explanations (+2.4% on hard toxic examples) help less compared to expert-written human explanations (+7.2%). Our results showcase the promise of using free-text explanations to encourage more thoughtful toxicity moderation. ",
    "url": "https://arxiv.org/abs/2305.13589",
    "authors": [
      "Yiming Zhang",
      "Sravani Nanduri",
      "Liwei Jiang",
      "Tongshuang Wu",
      "Maarten Sap"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13591",
    "title": "A Single Multi-Task Deep Neural Network with a Multi-Scale Feature  Aggregation Mechanism for Manipulation Relationship Reasoning in Robotic  Grasping",
    "abstract": "Grasping specific objects in complex and irregularly stacked scenes is still challenging for robotics. Because the robot is not only required to identify the object's grasping posture but also needs to reason the manipulation relationship between the objects. In this paper, we propose a manipulation relationship reasoning network with a multi-scale feature aggregation (MSFA) mechanism for robot grasping tasks. MSFA aggregates high-level semantic information and low-level spatial information in a cross-scale connection way to improve the generalization ability of the model. Furthermore, to improve the accuracy, we propose to use intersection features with rich location priors for manipulation relationship reasoning. Experiments are validated in VMRD datasets and real environments, respectively. The experimental results demonstrate that our proposed method can accurately predict the manipulation relationship between objects in the scene of multi-object stacking. Compared with previous methods, it significantly improves reasoning speed and accuracy. ",
    "url": "https://arxiv.org/abs/2305.13591",
    "authors": [
      "Mingshuai Dong",
      "Yuxuan Bai",
      "Shimin Wei",
      "Xiuli Yu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.13593",
    "title": "Neural Image Re-Exposure",
    "abstract": "The shutter strategy applied to the photo-shooting process has a significant influence on the quality of the captured photograph. An improper shutter may lead to a blurry image, video discontinuity, or rolling shutter artifact. Existing works try to provide an independent solution for each issue. In this work, we aim to re-expose the captured photo in post-processing to provide a more flexible way of addressing those issues within a unified framework. Specifically, we propose a neural network-based image re-exposure framework. It consists of an encoder for visual latent space construction, a re-exposure module for aggregating information to neural film with a desired shutter strategy, and a decoder for 'developing' neural film into a desired image. To compensate for information confusion and missing frames, event streams, which can capture almost continuous brightness changes, are leveraged in computing visual latent content. Both self-attention layers and cross-attention layers are employed in the re-exposure module to promote interaction between neural film and visual latent content and information aggregation to neural film. The proposed unified image re-exposure framework is evaluated on several shutter-related image recovery tasks and performs favorably against independent state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2305.13593",
    "authors": [
      "Xinyu Zhang",
      "Hefei Huang",
      "Xu Jia",
      "Dong Wang",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.13605",
    "title": "Adaptive Face Recognition Using Adversarial Information Network",
    "abstract": "In many real-world applications, face recognition models often degenerate when training data (referred to as source domain) are different from testing data (referred to as target domain). To alleviate this mismatch caused by some factors like pose and skin tone, the utilization of pseudo-labels generated by clustering algorithms is an effective way in unsupervised domain adaptation. However, they always miss some hard positive samples. Supervision on pseudo-labeled samples attracts them towards their prototypes and would cause an intra-domain gap between pseudo-labeled samples and the remaining unlabeled samples within target domain, which results in the lack of discrimination in face recognition. In this paper, considering the particularity of face recognition, we propose a novel adversarial information network (AIN) to address it. First, a novel adversarial mutual information (MI) loss is proposed to alternately minimize MI with respect to the target classifier and maximize MI with respect to the feature extractor. By this min-max manner, the positions of target prototypes are adaptively modified which makes unlabeled images clustered more easily such that intra-domain gap can be mitigated. Second, to assist adversarial MI loss, we utilize a graph convolution network to predict linkage likelihoods between target data and generate pseudo-labels. It leverages valuable information in the context of nodes and can achieve more reliable results. The proposed method is evaluated under two scenarios, i.e., domain adaptation across poses and image conditions, and domain adaptation across faces with different skin tones. Extensive experiments show that AIN successfully improves cross-domain generalization and offers a new state-of-the-art on RFW dataset. ",
    "url": "https://arxiv.org/abs/2305.13605",
    "authors": [
      "Mei Wang",
      "Weihong Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.13611",
    "title": "A New Comprehensive Benchmark for Semi-supervised Video Anomaly  Detection and Anticipation",
    "abstract": "Semi-supervised video anomaly detection (VAD) is a critical task in the intelligent surveillance system. However, an essential type of anomaly in VAD named scene-dependent anomaly has not received the attention of researchers. Moreover, there is no research investigating anomaly anticipation, a more significant task for preventing the occurrence of anomalous events. To this end, we propose a new comprehensive dataset, NWPU Campus, containing 43 scenes, 28 classes of abnormal events, and 16 hours of videos. At present, it is the largest semi-supervised VAD dataset with the largest number of scenes and classes of anomalies, the longest duration, and the only one considering the scene-dependent anomaly. Meanwhile, it is also the first dataset proposed for video anomaly anticipation. We further propose a novel model capable of detecting and anticipating anomalous events simultaneously. Compared with 7 outstanding VAD algorithms in recent years, our method can cope with scene-dependent anomaly detection and anomaly anticipation both well, achieving state-of-the-art performance on ShanghaiTech, CUHK Avenue, IITB Corridor and the newly proposed NWPU Campus datasets consistently. Our dataset and code is available at: https://campusvad.github.io. ",
    "url": "https://arxiv.org/abs/2305.13611",
    "authors": [
      "Congqi Cao",
      "Yue Lu",
      "Peng Wang",
      "Yanning Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.13617",
    "title": "SPEECH: Structured Prediction with Energy-Based Event-Centric  Hyperspheres",
    "abstract": "Event-centric structured prediction involves predicting structured outputs of events. In most NLP cases, event structures are complex with manifold dependency, and it is challenging to effectively represent these complicated structured events. To address these issues, we propose Structured Prediction with Energy-based Event-Centric Hyperspheres (SPEECH). SPEECH models complex dependency among event structured components with energy-based modeling, and represents event classes with simple but effective hyperspheres. Experiments on two unified-annotated event datasets indicate that SPEECH is predominant in event detection and event-relation extraction tasks. ",
    "url": "https://arxiv.org/abs/2305.13617",
    "authors": [
      "Shumin Deng",
      "Shengyu Mao",
      "Ningyu Zhang",
      "Bryan Hooi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13625",
    "title": "DiffProtect: Generate Adversarial Examples with Diffusion Models for  Facial Privacy Protection",
    "abstract": "The increasingly pervasive facial recognition (FR) systems raise serious concerns about personal privacy, especially for billions of users who have publicly shared their photos on social media. Several attempts have been made to protect individuals from being identified by unauthorized FR systems utilizing adversarial attacks to generate encrypted face images. However, existing methods suffer from poor visual quality or low attack success rates, which limit their utility. Recently, diffusion models have achieved tremendous success in image generation. In this work, we ask: can diffusion models be used to generate adversarial examples to improve both visual quality and attack performance? We propose DiffProtect, which utilizes a diffusion autoencoder to generate semantically meaningful perturbations on FR systems. Extensive experiments demonstrate that DiffProtect produces more natural-looking encrypted images than state-of-the-art methods while achieving significantly higher attack success rates, e.g., 24.5% and 25.1% absolute improvements on the CelebA-HQ and FFHQ datasets. ",
    "url": "https://arxiv.org/abs/2305.13625",
    "authors": [
      "Jiang Liu",
      "Chun Pong Lau",
      "Rama Chellappa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.13634",
    "title": "SMAP: A Novel Heterogeneous Information Framework for Scenario-based  Optimal Model Assignment",
    "abstract": "The increasing maturity of big data applications has led to a proliferation of models targeting the same objectives within the same scenarios and datasets. However, selecting the most suitable model that considers model's features while taking specific requirements and constraints into account still poses a significant challenge. Existing methods have focused on worker-task assignments based on crowdsourcing, they neglect the scenario-dataset-model assignment problem. To address this challenge, a new problem named the Scenario-based Optimal Model Assignment (SOMA) problem is introduced and a novel framework entitled Scenario and Model Associative percepts (SMAP) is developed. SMAP is a heterogeneous information framework that can integrate various types of information to intelligently select a suitable dataset and allocate the optimal model for a specific scenario. To comprehensively evaluate models, a new score function that utilizes multi-head attention mechanisms is proposed. Moreover, a novel memory mechanism named the mnemonic center is developed to store the matched heterogeneous information and prevent duplicate matching. Six popular traffic scenarios are selected as study cases and extensive experiments are conducted on a dataset to verify the effectiveness and efficiency of SMAP and the score function. ",
    "url": "https://arxiv.org/abs/2305.13634",
    "authors": [
      "Zekun Qiu",
      "Zhipu Xie",
      "Zehua Ji",
      "Yuhao Mao",
      "Ke Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.13648",
    "title": "Non-parametric, Nearest-neighbor-assisted Fine-tuning for Neural Machine  Translation",
    "abstract": "Non-parametric, k-nearest-neighbor algorithms have recently made inroads to assist generative models such as language models and machine translation decoders. We explore whether such non-parametric models can improve machine translation models at the fine-tuning stage by incorporating statistics from the kNN predictions to inform the gradient updates for a baseline translation model. There are multiple methods which could be used to incorporate kNN statistics and we investigate gradient scaling by a gating mechanism, the kNN's ground truth probability, and reinforcement learning. For four standard in-domain machine translation datasets, compared with classic fine-tuning, we report consistent improvements of all of the three methods by as much as 1.45 BLEU and 1.28 BLEU for German-English and English-German translations respectively. Through qualitative analysis, we found particular improvements when it comes to translating grammatical relations or function words, which results in increased fluency of our model. ",
    "url": "https://arxiv.org/abs/2305.13648",
    "authors": [
      "Jiayi Wang",
      "Ke Wang",
      "Yuqi Zhang",
      "Yu Zhao",
      "Pontus Stenetorp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.13650",
    "title": "Property-Guided Generative Modelling for Robust Model-Based Design with  Imbalanced Data",
    "abstract": "The problem of designing protein sequences with desired properties is challenging, as it requires to explore a high-dimensional protein sequence space with extremely sparse meaningful regions. This has led to the development of model-based optimization (MBO) techniques that aid in the design, by using effective search models guided by the properties over the sequence space. However, the intrinsic imbalanced nature of experimentally derived datasets causes existing MBO approaches to struggle or outright fail. We propose a property-guided variational auto-encoder (PGVAE) whose latent space is explicitly structured by the property values such that samples are prioritized according to these properties. Through extensive benchmarking on real and semi-synthetic protein datasets, we demonstrate that MBO with PGVAE robustly finds sequences with improved properties despite significant dataset imbalances. We further showcase the generality of our approach to continuous design spaces, and its robustness to dataset imbalance in an application to physics-informed neural networks. ",
    "url": "https://arxiv.org/abs/2305.13650",
    "authors": [
      "Saba Ghaffari",
      "Ehsan Saleh",
      "Alexander G. Schwing",
      "Yu-Xiong Wang",
      "Martin D. Burke",
      "Saurabh Sinha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.13651",
    "title": "Adversarial Defenses via Vector Quantization",
    "abstract": "Building upon Randomized Discretization, we develop two novel adversarial defenses against white-box PGD attacks, utilizing vector quantization in higher dimensional spaces. These methods, termed pRD and swRD, not only offer a theoretical guarantee in terms of certified accuracy, they are also shown, via abundant experiments, to perform comparably or even superior to the current art of adversarial defenses. These methods can be extended to a version that allows further training of the target classifier and demonstrates further improved performance. ",
    "url": "https://arxiv.org/abs/2305.13651",
    "authors": [
      "Zhiyi Dong",
      "Yongyi Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.13653",
    "title": "RaSa: Relation and Sensitivity Aware Representation Learning for  Text-based Person Search",
    "abstract": "Text-based person search aims to retrieve the specified person images given a textual description. The key to tackling such a challenging task is to learn powerful multi-modal representations. Towards this, we propose a Relation and Sensitivity aware representation learning method (RaSa), including two novel tasks: Relation-Aware learning (RA) and Sensitivity-Aware learning (SA). For one thing, existing methods cluster representations of all positive pairs without distinction and overlook the noise problem caused by the weak positive pairs where the text and the paired image have noise correspondences, thus leading to overfitting learning. RA offsets the overfitting risk by introducing a novel positive relation detection task (i.e., learning to distinguish strong and weak positive pairs). For another thing, learning invariant representation under data augmentation (i.e., being insensitive to some transformations) is a general practice for improving representation's robustness in existing methods. Beyond that, we encourage the representation to perceive the sensitive transformation by SA (i.e., learning to detect the replaced words), thus promoting the representation's robustness. Experiments demonstrate that RaSa outperforms existing state-of-the-art methods by 6.94%, 4.45% and 15.35% in terms of Rank@1 on CUHK-PEDES, ICFG-PEDES and RSTPReid datasets, respectively. Code is available at: https://github.com/Flame-Chasers/RaSa. ",
    "url": "https://arxiv.org/abs/2305.13653",
    "authors": [
      "Yang Bai",
      "Min Cao",
      "Daming Gao",
      "Ziqiang Cao",
      "Chen Chen",
      "Zhenfeng Fan",
      "Liqiang Nie",
      "Min Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.13656",
    "title": "Link Prediction without Graph Neural Networks",
    "abstract": "Link prediction, which consists of predicting edges based on graph features, is a fundamental task in many graph applications. As for several related problems, Graph Neural Networks (GNNs), which are based on an attribute-centric message-passing paradigm, have become the predominant framework for link prediction. GNNs have consistently outperformed traditional topology-based heuristics, but what contributes to their performance? Are there simpler approaches that achieve comparable or better results? To answer these questions, we first identify important limitations in how GNN-based link prediction methods handle the intrinsic class imbalance of the problem -- due to the graph sparsity -- in their training and evaluation. Moreover, we propose Gelato, a novel topology-centric framework that applies a topological heuristic to a graph enhanced by attribute information via graph learning. Our model is trained end-to-end with an N-pair loss on an unbiased training set to address class imbalance. Experiments show that Gelato is 145% more accurate, trains 11 times faster, infers 6,000 times faster, and has less than half of the trainable parameters compared to state-of-the-art GNNs for link prediction. ",
    "url": "https://arxiv.org/abs/2305.13656",
    "authors": [
      "Zexi Huang",
      "Mert Kosan",
      "Arlei Silva",
      "Ambuj Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.13658",
    "title": "Understanding compositional data augmentation in automatic morphological  inflection",
    "abstract": "Data augmentation techniques are widely used in low-resource automatic morphological inflection to address the issue of data sparsity. However, the full implications of these techniques remain poorly understood. In this study, we aim to shed light on the theoretical aspects of the data augmentation strategy StemCorrupt, a method that generates synthetic examples by randomly substituting stem characters in existing gold standard training examples. Our analysis uncovers that StemCorrupt brings about fundamental changes in the underlying data distribution, revealing inherent compositional concatenative structure. To complement our theoretical analysis, we investigate the data-efficiency of StemCorrupt. Through evaluation across a diverse set of seven typologically distinct languages, we demonstrate that selecting a subset of datapoints with both high diversity and high predictive uncertainty significantly enhances the data-efficiency of StemCorrupt compared to competitive baselines. Furthermore, we explore the impact of typological features on the choice of augmentation strategy and find that languages incorporating non-concatenativity, such as morphonological alternations, derive less benefit from synthetic examples with high predictive uncertainty. We attribute this effect to phonotactic violations induced by StemCorrupt, emphasizing the need for further research to ensure optimal performance across the entire spectrum of natural language morphology. ",
    "url": "https://arxiv.org/abs/2305.13658",
    "authors": [
      "Farhan Samir",
      "Miikka Silfverberg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13659",
    "title": "Flare-Aware Cross-modal Enhancement Network for Multi-spectral Vehicle  Re-identification",
    "abstract": "Multi-spectral vehicle re-identification aims to address the challenge of identifying vehicles in complex lighting conditions by incorporating complementary visible and infrared information. However, in harsh environments, the discriminative cues in RGB and NIR modalities are often lost due to strong flares from vehicle lamps or sunlight, and existing multi-modal fusion methods are limited in their ability to recover these important cues. To address this problem, we propose a Flare-Aware Cross-modal Enhancement Network that adaptively restores flare-corrupted RGB and NIR features with guidance from the flare-immunized thermal infrared spectrum. First, to reduce the influence of locally degraded appearance due to intense flare, we propose a Mutual Flare Mask Prediction module to jointly obtain flare-corrupted masks in RGB and NIR modalities in a self-supervised manner. Second, to use the flare-immunized TI information to enhance the masked RGB and NIR, we propose a Flare-Aware Cross-modal Enhancement module that adaptively guides feature extraction of masked RGB and NIR spectra with prior flare-immunized knowledge from the TI spectrum. Third, to extract common informative semantic information from RGB and NIR, we propose an Inter-modality Consistency loss that enforces semantic consistency between the two modalities. Finally, to evaluate the proposed FACENet in handling intense flare, we introduce a new multi-spectral vehicle re-ID dataset, called WMVEID863, with additional challenges such as motion blur, significant background changes, and particularly intense flare degradation. Comprehensive experiments on both the newly collected dataset and public benchmark multi-spectral vehicle re-ID datasets demonstrate the superior performance of the proposed FACENet compared to state-of-the-art methods, especially in handling strong flares. The code and dataset will be released soon. ",
    "url": "https://arxiv.org/abs/2305.13659",
    "authors": [
      "Aihua Zheng",
      "Zhiqi Ma",
      "Zi Wang",
      "Chenglong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.13677",
    "title": "Towards Legally Enforceable Hate Speech Detection for Public Forums",
    "abstract": "Hate speech is a serious issue on public forums, and proper enforcement of hate speech laws is key for protecting groups of people against harmful and discriminatory language. However, determining what constitutes hate speech is a complex task that is highly open to subjective interpretations. Existing works do not align their systems with enforceable definitions of hate speech, which can make their outputs inconsistent with the goals of regulators. Our work introduces a new task for enforceable hate speech detection centred around legal definitions, and a dataset annotated on violations of eleven possible definitions by legal experts. Given the challenge of identifying clear, legally enforceable instances of hate speech, we augment the dataset with expert-generated samples and an automatically mined challenge set. We experiment with grounding the model decision in these definitions using zero-shot and few-shot prompting. We then report results on several large language models (LLMs). With this task definition, automatic hate speech detection can be more closely aligned to enforceable laws, and hence assist in more rigorous enforcement of legal protections against harmful speech in public forums. ",
    "url": "https://arxiv.org/abs/2305.13677",
    "authors": [
      "Chu Fei Luo",
      "Rohan Bhambhoria",
      "Xiaodan Zhu",
      "Samuel Dahan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13678",
    "title": "Enhancing Accuracy and Robustness through Adversarial Training in Class  Incremental Continual Learning",
    "abstract": "In real life, adversarial attack to deep learning models is a fatal security issue. However, the issue has been rarely discussed in a widely used class-incremental continual learning (CICL). In this paper, we address problems of applying adversarial training to CICL, which is well-known defense method against adversarial attack. A well-known problem of CICL is class-imbalance that biases a model to the current task by a few samples of previous tasks. Meeting with the adversarial training, the imbalance causes another imbalance of attack trials over tasks. Lacking clean data of a minority class by the class-imbalance and increasing of attack trials from a majority class by the secondary imbalance, adversarial training distorts optimal decision boundaries. The distortion eventually decreases both accuracy and robustness than adversarial training. To exclude the effects, we propose a straightforward but significantly effective method, External Adversarial Training (EAT) which can be applied to methods using experience replay. This method conduct adversarial training to an auxiliary external model for the current task data at each time step, and applies generated adversarial examples to train the target model. We verify the effects on a toy problem and show significance on CICL benchmarks of image classification. We expect that the results will be used as the first baseline for robustness research of CICL. ",
    "url": "https://arxiv.org/abs/2305.13678",
    "authors": [
      "Minchan Kwon",
      "Kangil Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13683",
    "title": "Error Detection for Text-to-SQL Semantic Parsing",
    "abstract": "Despite remarkable progress in text-to-SQL semantic parsing in recent years, the performance of existing parsers is still far from perfect. At the same time, modern deep learning based text-to-SQL parsers are often over-confident and thus casting doubt on their trustworthiness when deployed for real use. To that end, we propose to build a parser-independent error detection model for text-to-SQL semantic parsing. The proposed model is based on pre-trained language model of code and is enhanced with structural features learned by graph neural networks. We train our model on realistic parsing errors collected from a cross-domain setting. Experiments with three strong text-to-SQL parsers featuring different decoding mechanisms show that our approach outperforms parser-dependent uncertainty metrics and could effectively improve the performance and usability of text-to-SQL semantic parsers regardless of their architectures. ",
    "url": "https://arxiv.org/abs/2305.13683",
    "authors": [
      "Shijie Chen",
      "Ziru Chen",
      "Huan Sun",
      "Yu Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13685",
    "title": "Causal Intervention for Abstractive Related Work Generation",
    "abstract": "Abstractive related work generation has attracted increasing attention in generating coherent related work that better helps readers grasp the background in the current research. However, most existing abstractive models ignore the inherent causality of related work generation, leading to low quality of generated related work and spurious correlations that affect the models' generalizability. In this study, we argue that causal intervention can address these limitations and improve the quality and coherence of the generated related works. To this end, we propose a novel Causal Intervention Module for Related Work Generation (CaM) to effectively capture causalities in the generation process and improve the quality and coherence of the generated related works. Specifically, we first model the relations among sentence order, document relation, and transitional content in related work generation using a causal graph. Then, to implement the causal intervention and mitigate the negative impact of spurious correlations, we use do-calculus to derive ordinary conditional probabilities and identify causal effects through CaM. Finally, we subtly fuse CaM with Transformer to obtain an end-to-end generation model. Extensive experiments on two real-world datasets show that causal interventions in CaM can effectively promote the model to learn causal relations and produce related work of higher quality and coherence. ",
    "url": "https://arxiv.org/abs/2305.13685",
    "authors": [
      "Jiachang Liu",
      "Qi Zhang",
      "Chongyang Shi",
      "Usman Naseem",
      "Shoujin Wang",
      "Ivor Tsang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13689",
    "title": "Know Your Self-supervised Learning: A Survey on Image-based Generative  and Discriminative Training",
    "abstract": "Although supervised learning has been highly successful in improving the state-of-the-art in the domain of image-based computer vision in the past, the margin of improvement has diminished significantly in recent years, indicating that a plateau is in sight. Meanwhile, the use of self-supervised learning (SSL) for the purpose of natural language processing (NLP) has seen tremendous successes during the past couple of years, with this new learning paradigm yielding powerful language models. Inspired by the excellent results obtained in the field of NLP, self-supervised methods that rely on clustering, contrastive learning, distillation, and information-maximization, which all fall under the banner of discriminative SSL, have experienced a swift uptake in the area of computer vision. Shortly afterwards, generative SSL frameworks that are mostly based on masked image modeling, complemented and surpassed the results obtained with discriminative SSL. Consequently, within a span of three years, over $100$ unique general-purpose frameworks for generative and discriminative SSL, with a focus on imaging, were proposed. In this survey, we review a plethora of research efforts conducted on image-oriented SSL, providing a historic view and paying attention to best practices as well as useful software packages. While doing so, we discuss pretext tasks for image-based SSL, as well as techniques that are commonly used in image-based SSL. Lastly, to aid researchers who aim at contributing to image-focused SSL, we outline a number of promising research directions. ",
    "url": "https://arxiv.org/abs/2305.13689",
    "authors": [
      "Utku Ozbulak",
      "Hyun Jung Lee",
      "Beril Boga",
      "Esla Timothy Anzaku",
      "Homin Park",
      "Arnout Van Messem",
      "Wesley De Neve",
      "Joris Vankerschaver"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.13697",
    "title": "UNIMO-3: Multi-granularity Interaction for Vision-Language  Representation Learning",
    "abstract": "Vision-and-language (VL) pre-training, which aims to learn a general representation of image-text pairs that can be transferred to various vision-and-language tasks. Compared with modeling uni-modal data, the main challenge of the VL model is: how to learn the cross-modal interaction from multimodal data, especially the fine-grained interaction. Existing works have shown that fully transformer-based models that adopt attention mechanisms to learn in-layer cross-model interaction can demonstrate impressive performance on various cross-modal downstream tasks. However, they ignored that the semantic information of the different modals at the same layer was not uniform, which leads to the cross-modal interaction collapsing into a limited multi-modal semantic information interaction. In this work, we propose the UNIMO-3 model, which has the capacity to simultaneously learn the multimodal in-layer interaction and cross-layer interaction. UNIMO-3 model can establish effective connections between different layers in a cross-modal encoder, and adaptively capture the interaction between two modalities at different levels. The experimental results show that our model achieves state-of-the-art performance in various downstream tasks, and through ablation study can prove that effective cross-layer learning improves the model's ability of multimodal representation. ",
    "url": "https://arxiv.org/abs/2305.13697",
    "authors": [
      "Hao Yang",
      "Can Gao",
      "Hao L\u00edu",
      "Xinyan Xiao",
      "Yanyan Zhao",
      "Bing Qin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13700",
    "title": "Detection of Cross-Dataset Fake Audio Based on Prosodic and  Pronunciation Features",
    "abstract": "Existing fake audio detection systems perform well in in-domain testing, but still face many challenges in out-of-domain testing. This is due to the mismatch between the training and test data, as well as the poor generalizability of features extracted from limited views. To address this, we propose multi-view features for fake audio detection, which aim to capture more generalized features from prosodic, pronunciation, and wav2vec dimensions. Specifically, the phoneme duration features are extracted from a pre-trained model based on a large amount of speech data. For the pronunciation features, a Conformer-based phoneme recognition model is first trained, keeping the acoustic encoder part as a deeply embedded feature extractor. Furthermore, the prosodic and pronunciation features are fused with wav2vec features based on an attention mechanism to improve the generalization of fake audio detection models. Results show that the proposed approach achieves significant performance gains in several cross-dataset experiments. ",
    "url": "https://arxiv.org/abs/2305.13700",
    "authors": [
      "Chenglong Wang",
      "Jiangyan Yi",
      "Jianhua Tao",
      "Chuyuan Zhang",
      "Shuai Zhang",
      "Xun Chen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.13701",
    "title": "TO-Rawnet: Improving RawNet with TCN and Orthogonal Regularization for  Fake Audio Detection",
    "abstract": "Current fake audio detection relies on hand-crafted features, which lose information during extraction. To overcome this, recent studies use direct feature extraction from raw audio signals. For example, RawNet is one of the representative works in end-to-end fake audio detection. However, existing work on RawNet does not optimize the parameters of the Sinc-conv during training, which limited its performance. In this paper, we propose to incorporate orthogonal convolution into RawNet, which reduces the correlation between filters when optimizing the parameters of Sinc-conv, thus improving discriminability. Additionally, we introduce temporal convolutional networks (TCN) to capture long-term dependencies in speech signals. Experiments on the ASVspoof 2019 show that the Our TO-RawNet system can relatively reduce EER by 66.09\\% on logical access scenario compared with the RawNet, demonstrating its effectiveness in detecting fake audio attacks. ",
    "url": "https://arxiv.org/abs/2305.13701",
    "authors": [
      "Chenglong Wang",
      "Jiangyan Yi",
      "Jianhua Tao",
      "Chuyuan Zhang",
      "Shuai Zhang",
      "Ruibo Fu",
      "Xun Chen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.13704",
    "title": "FlowChroma -- A Deep Recurrent Neural Network for Video Colorization",
    "abstract": "We develop an automated video colorization framework that minimizes the flickering of colors across frames. If we apply image colorization techniques to successive frames of a video, they treat each frame as a separate colorization task. Thus, they do not necessarily maintain the colors of a scene consistently across subsequent frames. The proposed solution includes a novel deep recurrent encoder-decoder architecture which is capable of maintaining temporal and contextual coherence between consecutive frames of a video. We use a high-level semantic feature extractor to automatically identify the context of a scenario including objects, with a custom fusion layer that combines the spatial and temporal features of a frame sequence. We demonstrate experimental results, qualitatively showing that recurrent neural networks can be successfully used to improve color consistency in video colorization. ",
    "url": "https://arxiv.org/abs/2305.13704",
    "authors": [
      "Thejan Wijesinghe",
      "Chamath Abeysinghe",
      "Chanuka Wijayakoon",
      "Lahiru Jayathilake",
      "Uthayasanker Thayasivam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.13718",
    "title": "LogicLLM: Exploring Self-supervised Logic-enhanced Training for Large  Language Models",
    "abstract": "Existing efforts to improve logical reasoning ability of language models have predominantly relied on supervised fine-tuning, hindering generalization to new domains and/or tasks. The development of Large Langauge Models (LLMs) has demonstrated the capacity of compressing abundant knowledge into a single proxy, enabling them to tackle multiple tasks effectively. Our preliminary experiments, nevertheless, show that LLMs do not show capability on logical reasoning. The performance of LLMs on logical reasoning benchmarks is far behind the existing state-of-the-art baselines. In this paper, we make the first attempt to investigate the feasibility of incorporating logical knowledge through self-supervised post-training, and activating it via in-context learning, which we termed as LogicLLM. Specifically, we devise an auto-regressive objective variant of MERIt and integrate it with two LLM series, i.e., FLAN-T5 and LLaMA, with parameter size ranging from 3 billion to 13 billion. The results on two challenging logical reasoning benchmarks demonstrate the effectiveness of LogicLLM. Besides, we conduct extensive ablation studies to analyze the key factors in designing logic-oriented proxy tasks. ",
    "url": "https://arxiv.org/abs/2305.13718",
    "authors": [
      "Fangkai Jiao",
      "Zhiyang Teng",
      "Shafiq Joty",
      "Bosheng Ding",
      "Aixin Sun",
      "Zhengyuan Liu",
      "Nancy F. Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13751",
    "title": "Challenges in Context-Aware Neural Machine Translation",
    "abstract": "Context-aware neural machine translation involves leveraging information beyond sentence-level context to resolve inter-sentential discourse dependencies and improve document-level translation quality, and has given rise to a number of recent techniques. However, despite well-reasoned intuitions, most context-aware translation models show only modest improvements over sentence-level systems. In this work, we investigate several challenges that impede progress within this field, relating to discourse phenomena, context usage, model architectures, and document-level evaluation. To address these problems, we propose a more realistic setting for document-level translation, called paragraph-to-paragraph (para2para) translation, and collect a new dataset of Chinese-English novels to promote future research. ",
    "url": "https://arxiv.org/abs/2305.13751",
    "authors": [
      "Linghao Jin",
      "Jacqueline He",
      "Jonathan May",
      "Xuezhe Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13774",
    "title": "ADD 2023: the Second Audio Deepfake Detection Challenge",
    "abstract": "Audio deepfake detection is an emerging topic in the artificial intelligence community. The second Audio Deepfake Detection Challenge (ADD 2023) aims to spur researchers around the world to build new innovative technologies that can further accelerate and foster research on detecting and analyzing deepfake speech utterances. Different from previous challenges (e.g. ADD 2022), ADD 2023 focuses on surpassing the constraints of binary real/fake classification, and actually localizing the manipulated intervals in a partially fake speech as well as pinpointing the source responsible for generating any fake audio. Furthermore, ADD 2023 includes more rounds of evaluation for the fake audio game sub-challenge. The ADD 2023 challenge includes three subchallenges: audio fake game (FG), manipulation region location (RL) and deepfake algorithm recognition (AR). This paper describes the datasets, evaluation metrics, and protocols. Some findings are also reported in audio deepfake detection tasks. ",
    "url": "https://arxiv.org/abs/2305.13774",
    "authors": [
      "Jiangyan Yi",
      "Jianhua Tao",
      "Ruibo Fu",
      "Xinrui Yan",
      "Chenglong Wang",
      "Tao Wang",
      "Chu Yuan Zhang",
      "Xiaohui Zhang",
      "Yan Zhao",
      "Yong Ren",
      "Le Xu",
      "Junzuo Zhou",
      "Hao Gu",
      "Zhengqi Wen",
      "Shan Liang",
      "Zheng Lian",
      "Shuai Nie",
      "Haizhou Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.13785",
    "title": "Enhancing Black-Box Few-Shot Text Classification with Prompt-Based Data  Augmentation",
    "abstract": "Training or finetuning large-scale language models (LLMs) such as GPT-3 requires substantial computation resources, motivating recent efforts to explore parameter-efficient adaptation to downstream tasks. One practical area of research is to treat these models as black boxes and interact with them through their inference APIs. In this paper, we investigate how to optimize few-shot text classification without accessing the gradients of the LLMs. To achieve this, we treat the black-box model as a feature extractor and train a classifier with the augmented text data. Data augmentation is performed using prompt-based finetuning on an auxiliary language model with a much smaller parameter size than the black-box model. Through extensive experiments on eight text classification datasets, we show that our approach, dubbed BT-Classifier, significantly outperforms state-of-the-art black-box few-shot learners and performs on par with methods that rely on full-model tuning. ",
    "url": "https://arxiv.org/abs/2305.13785",
    "authors": [
      "Danqing Luo",
      "Chen Zhang",
      "Jiahui Xu",
      "Bin Wang",
      "Yiming Chen",
      "Yan Zhang",
      "Haizhou Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13792",
    "title": "Mitigating the Performance Impact of Network Failures in Public Clouds",
    "abstract": "Some faults in data center networks require hours to days to repair because they may need reboots, re-imaging, or manual work by technicians. To reduce traffic impact, cloud providers \\textit{mitigate} the effect of faults, for example, by steering traffic to alternate paths. The state-of-art in automatic network mitigations uses simple safety checks and proxy metrics to determine mitigations. SWARM, the approach described in this paper, can pick orders of magnitude better mitigations by estimating end-to-end connection-level performance (CLP) metrics. At its core is a scalable CLP estimator that quickly ranks mitigations with high fidelity and, on failures observed at a large cloud provider, outperforms the state-of-the-art by over 700$\\times$ in some cases. ",
    "url": "https://arxiv.org/abs/2305.13792",
    "authors": [
      "Pooria Namyar",
      "Behnaz Arzani",
      "Daniel Crankshaw",
      "Daniel S. Berger",
      "Kevin Hsieh",
      "Srikanth Kandula",
      "Ramesh Govindan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2305.13799",
    "title": "Leveraging Uncertainty Quantification for Picking Robust First Break  Times",
    "abstract": "In seismic exploration, the selection of first break times is a crucial aspect in the determination of subsurface velocity models, which in turn significantly influences the placement of wells. Many deep neural network (DNN)-based automatic first break picking methods have been proposed to speed up this picking processing. However, there has been no work on the uncertainty of the first picking results of the output of DNN. In this paper, we propose a new framework for first break picking based on a Bayesian neural network to further explain the uncertainty of the output. In a large number of experiments, we evaluate that the proposed method has better accuracy and robustness than the deterministic DNN-based model. In addition, we also verify that the uncertainty of measurement is meaningful, which can provide a reference for human decision-making. ",
    "url": "https://arxiv.org/abs/2305.13799",
    "authors": [
      "Hongtao Wang",
      "Jiangshe Zhang",
      "Xiaoli Wei",
      "Li Long",
      "Chunxia Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.13800",
    "title": "Generalizable Synthetic Image Detection via Language-guided Contrastive  Learning",
    "abstract": "The heightened realism of AI-generated images can be attributed to the rapid development of synthetic models, including generative adversarial networks (GANs) and diffusion models (DMs). The malevolent use of synthetic images, such as the dissemination of fake news or the creation of fake profiles, however, raises significant concerns regarding the authenticity of images. Though many forensic algorithms have been developed for detecting synthetic images, their performance, especially the generalization capability, is still far from being adequate to cope with the increasing number of synthetic models. In this work, we propose a simple yet very effective synthetic image detection method via a language-guided contrastive learning and a new formulation of the detection problem. We first augment the training images with carefully-designed textual labels, enabling us to use a joint image-text contrastive learning for the forensic feature extraction. In addition, we formulate the synthetic image detection as an identification problem, which is vastly different from the traditional classification-based approaches. It is shown that our proposed LanguAge-guided SynThEsis Detection (LASTED) model achieves much improved generalizability to unseen image generation models and delivers promising performance that far exceeds state-of-the-art competitors by +22.66% accuracy and +15.24% AUC. The code is available at https://github.com/HighwayWu/LASTED. ",
    "url": "https://arxiv.org/abs/2305.13800",
    "authors": [
      "Haiwei Wu",
      "Jiantao Zhou",
      "Shile Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.13802",
    "title": "Online Open-set Semi-supervised Object Detection via Semi-supervised  Outlier Filtering",
    "abstract": "Open-set semi-supervised object detection (OSSOD) methods aim to utilize practical unlabeled datasets with out-of-distribution (OOD) instances for object detection. The main challenge in OSSOD is distinguishing and filtering the OOD instances from the in-distribution (ID) instances during pseudo-labeling. The previous method uses an offline OOD detection network trained only with labeled data for solving this problem. However, the scarcity of available data limits the potential for improvement. Meanwhile, training separately leads to low efficiency. To alleviate the above issues, this paper proposes a novel end-to-end online framework that improves performance and efficiency by mining more valuable instances from unlabeled data. Specifically, we first propose a semi-supervised OOD detection strategy to mine valuable ID and OOD instances in unlabeled datasets for training. Then, we constitute an online end-to-end trainable OSSOD framework by integrating the OOD detection head into the object detector, making it jointly trainable with the original detection task. Our experimental results show that our method works well on several benchmarks, including the partially labeled COCO dataset with open-set classes and the fully labeled COCO dataset with the additional large-scale open-set unlabeled dataset, OpenImages. Compared with previous OSSOD methods, our approach achieves the best performance on COCO with OpenImages by +0.94 mAP, reaching 44.07 mAP. ",
    "url": "https://arxiv.org/abs/2305.13802",
    "authors": [
      "Zerun Wang",
      "Ling Xiao",
      "Liuyu Xiang",
      "Zhaotian Weng",
      "Toshihiko Yamasaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.13803",
    "title": "NORM: Knowledge Distillation via N-to-One Representation Matching",
    "abstract": "Existing feature distillation methods commonly adopt the One-to-one Representation Matching between any pre-selected teacher-student layer pair. In this paper, we present N-to-One Representation (NORM), a new two-stage knowledge distillation method, which relies on a simple Feature Transform (FT) module consisting of two linear layers. In view of preserving the intact information learnt by the teacher network, during training, our FT module is merely inserted after the last convolutional layer of the student network. The first linear layer projects the student representation to a feature space having N times feature channels than the teacher representation from the last convolutional layer, and the second linear layer contracts the expanded output back to the original feature space. By sequentially splitting the expanded student representation into N non-overlapping feature segments having the same number of feature channels as the teacher's, they can be readily forced to approximate the intact teacher representation simultaneously, formulating a novel many-to-one representation matching mechanism conditioned on a single teacher-student layer pair. After training, such an FT module will be naturally merged into the subsequent fully connected layer thanks to its linear property, introducing no extra parameters or architectural modifications to the student network at inference. Extensive experiments on different visual recognition benchmarks demonstrate the leading performance of our method. For instance, the ResNet18|MobileNet|ResNet50-1/4 model trained by NORM reaches 72.14%|74.26%|68.03% top-1 accuracy on the ImageNet dataset when using a pre-trained ResNet34|ResNet50|ResNet50 model as the teacher, achieving an absolute improvement of 2.01%|4.63%|3.03% against the individually trained counterpart. Code is available at https://github.com/OSVAI/NORM ",
    "url": "https://arxiv.org/abs/2305.13803",
    "authors": [
      "Xiaolong Liu",
      "Lujun Li",
      "Chao Li",
      "Anbang Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13814",
    "title": "Leveraging BEV Representation for 360-degree Visual Place Recognition",
    "abstract": "This paper investigates the advantages of using Bird's Eye View (BEV) representation in 360-degree visual place recognition (VPR). We propose a novel network architecture that utilizes the BEV representation in feature extraction, feature aggregation, and vision-LiDAR fusion, which bridges visual cues and spatial awareness. Our method extracts image features using standard convolutional networks and combines the features according to pre-defined 3D grid spatial points. To alleviate the mechanical and time misalignments between cameras, we further introduce deformable attention to learn the compensation. Upon the BEV feature representation, we then employ the polar transform and the Discrete Fourier transform for aggregation, which is shown to be rotation-invariant. In addition, the image and point cloud cues can be easily stated in the same coordinates, which benefits sensor fusion for place recognition. The proposed BEV-based method is evaluated in ablation and comparative studies on two datasets, including on-the-road and off-the-road scenarios. The experimental results verify the hypothesis that BEV can benefit VPR by its superior performance compared to baseline methods. To the best of our knowledge, this is the first trial of employing BEV representation in this task. ",
    "url": "https://arxiv.org/abs/2305.13814",
    "authors": [
      "Xuecheng Xu",
      "Yanmei Jiao",
      "Sha Lu",
      "Xiaqing Ding",
      "Rong Xiong",
      "Yue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.13825",
    "title": "Continual Learning on Dynamic Graphs via Parameter Isolation",
    "abstract": "Many real-world graph learning tasks require handling dynamic graphs where new nodes and edges emerge. Dynamic graph learning methods commonly suffer from the catastrophic forgetting problem, where knowledge learned for previous graphs is overwritten by updates for new graphs. To alleviate the problem, continual graph learning methods are proposed. However, existing continual graph learning methods aim to learn new patterns and maintain old ones with the same set of parameters of fixed size, and thus face a fundamental tradeoff between both goals. In this paper, we propose Parameter Isolation GNN (PI-GNN) for continual learning on dynamic graphs that circumvents the tradeoff via parameter isolation and expansion. Our motivation lies in that different parameters contribute to learning different graph patterns. Based on the idea, we expand model parameters to continually learn emerging graph patterns. Meanwhile, to effectively preserve knowledge for unaffected patterns, we find parameters that correspond to them via optimization and freeze them to prevent them from being rewritten. Experiments on eight real-world datasets corroborate the effectiveness of PI-GNN compared to state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2305.13825",
    "authors": [
      "Peiyan Zhang",
      "Yuchen Yan",
      "Chaozhuo Li",
      "Senzhang Wang",
      "Xing Xie",
      "Guojie Song",
      "Sunghun Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2305.13839",
    "title": "SAR-to-Optical Image Translation via Thermodynamics-inspired Network",
    "abstract": "Synthetic aperture radar (SAR) is prevalent in the remote sensing field but is difficult to interpret in human visual perception. Recently, SAR-to-optical (S2O) image conversion methods have provided a prospective solution for interpretation. However, since there is a huge domain difference between optical and SAR images, they suffer from low image quality and geometric distortion in the produced optical images. Motivated by the analogy between pixels during the S2O image translation and molecules in a heat field, Thermodynamics-inspired Network for SAR-to-Optical Image Translation (S2O-TDN) is proposed in this paper. Specifically, we design a Third-order Finite Difference (TFD) residual structure in light of the TFD equation of thermodynamics, which allows us to efficiently extract inter-domain invariant features and facilitate the learning of the nonlinear translation mapping. In addition, we exploit the first law of thermodynamics (FLT) to devise an FLT-guided branch that promotes the state transition of the feature values from the unstable diffusion state to the stable one, aiming to regularize the feature diffusion and preserve image structures during S2O image translation. S2O-TDN follows an explicit design principle derived from thermodynamic theory and enjoys the advantage of explainability. Experiments on the public SEN1-2 dataset show the advantages of the proposed S2O-TDN over the current methods with more delicate textures and higher quantitative results. ",
    "url": "https://arxiv.org/abs/2305.13839",
    "authors": [
      "Mingjin Zhang",
      "Jiamin Xu",
      "Chengyu He",
      "Wenteng Shang",
      "Yunsong Li",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.13844",
    "title": "Arukikata Travelogue Dataset with Geographic Entity Mention,  Coreference, and Link Annotation",
    "abstract": "Geoparsing is a fundamental technique for analyzing geo-entity information in text. We focus on document-level geoparsing, which considers geographic relatedness among geo-entity mentions, and presents a Japanese travelogue dataset designed for evaluating document-level geoparsing systems. Our dataset comprises 200 travelogue documents with rich geo-entity information: 12,171 mentions, 6,339 coreference clusters, and 2,551 geo-entities linked to geo-database entries. ",
    "url": "https://arxiv.org/abs/2305.13844",
    "authors": [
      "Shohei Higashiyama",
      "Hiroki Ouchi",
      "Hiroki Teranishi",
      "Hiroyuki Otomo",
      "Yusuke Ide",
      "Aitaro Yamamoto",
      "Hiroyuki Shindo",
      "Yuki Matsuda",
      "Shoko Wakamiya",
      "Naoya Inoue",
      "Ikuya Yamada",
      "Taro Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13849",
    "title": "Self-Supervised Gaussian Regularization of Deep Classifiers for  Mahalanobis-Distance-Based Uncertainty Estimation",
    "abstract": "Recent works show that the data distribution in a network's latent space is useful for estimating classification uncertainty and detecting Out-of-distribution (OOD) samples. To obtain a well-regularized latent space that is conducive for uncertainty estimation, existing methods bring in significant changes to model architectures and training procedures. In this paper, we present a lightweight, fast, and high-performance regularization method for Mahalanobis distance-based uncertainty prediction, and that requires minimal changes to the network's architecture. To derive Gaussian latent representation favourable for Mahalanobis Distance calculation, we introduce a self-supervised representation learning method that separates in-class representations into multiple Gaussians. Classes with non-Gaussian representations are automatically identified and dynamically clustered into multiple new classes that are approximately Gaussian. Evaluation on standard OOD benchmarks shows that our method achieves state-of-the-art results on OOD detection with minimal inference time, and is very competitive on predictive probability calibration. Finally, we show the applicability of our method to a real-life computer vision use case on microorganism classification. ",
    "url": "https://arxiv.org/abs/2305.13849",
    "authors": [
      "Aishwarya Venkataramanan",
      "Assia Benbihi",
      "Martin Laviale",
      "Cedric Pradalier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13854",
    "title": "The Evolution of Distributed Systems for Graph Neural Networks and their  Origin in Graph Processing and Deep Learning: A Survey",
    "abstract": "Graph Neural Networks (GNNs) are an emerging research field. This specialized Deep Neural Network (DNN) architecture is capable of processing graph structured data and bridges the gap between graph processing and Deep Learning (DL). As graphs are everywhere, GNNs can be applied to various domains including recommendation systems, computer vision, natural language processing, biology and chemistry. With the rapid growing size of real world graphs, the need for efficient and scalable GNN training solutions has come. Consequently, many works proposing GNN systems have emerged throughout the past few years. However, there is an acute lack of overview, categorization and comparison of such systems. We aim to fill this gap by summarizing and categorizing important methods and techniques for large-scale GNN solutions. In addition, we establish connections between GNN systems, graph processing systems and DL systems. ",
    "url": "https://arxiv.org/abs/2305.13854",
    "authors": [
      "Jana Vatter",
      "Ruben Mayer",
      "Hans-Arno Jacobsen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13871",
    "title": "Improving Heterogeneous Model Reuse by Density Estimation",
    "abstract": "This paper studies multiparty learning, aiming to learn a model using the private data of different participants. Model reuse is a promising solution for multiparty learning, assuming that a local model has been trained for each party. Considering the potential sample selection bias among different parties, some heterogeneous model reuse approaches have been developed. However, although pre-trained local classifiers are utilized in these approaches, the characteristics of the local data are not well exploited. This motivates us to estimate the density of local data and design an auxiliary model together with the local classifiers for reuse. To address the scenarios where some local models are not well pre-trained, we further design a multiparty cross-entropy loss for calibration. Upon existing works, we address a challenging problem of heterogeneous model reuse from a decision theory perspective and take advantage of recent advances in density estimation. Experimental results on both synthetic and benchmark data demonstrate the superiority of the proposed method. ",
    "url": "https://arxiv.org/abs/2305.13871",
    "authors": [
      "Anke Tang",
      "Yong Luo",
      "Han Hu",
      "Fengxiang He",
      "Kehua Su",
      "Bo Du",
      "Yixin Chen",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13875",
    "title": "Fair Oversampling Technique using Heterogeneous Clusters",
    "abstract": "Class imbalance and group (e.g., race, gender, and age) imbalance are acknowledged as two reasons in data that hinder the trade-off between fairness and utility of machine learning classifiers. Existing techniques have jointly addressed issues regarding class imbalance and group imbalance by proposing fair over-sampling techniques. Unlike the common oversampling techniques, which only address class imbalance, fair oversampling techniques significantly improve the abovementioned trade-off, as they can also address group imbalance. However, if the size of the original clusters is too small, these techniques may cause classifier overfitting. To address this problem, we herein develop a fair oversampling technique using data from heterogeneous clusters. The proposed technique generates synthetic data that have class-mix features or group-mix features to make classifiers robust to overfitting. Moreover, we develop an interpolation method that can enhance the validity of generated synthetic data by considering the original cluster distribution and data noise. Finally, we conduct experiments on five realistic datasets and three classifiers, and the experimental results demonstrate the effectiveness of the proposed technique in terms of fairness and utility. ",
    "url": "https://arxiv.org/abs/2305.13875",
    "authors": [
      "Ryosuke Sonoda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.13879",
    "title": "Stochastic PDE representation of random fields for large-scale Gaussian  process regression and statistical finite element analysis",
    "abstract": "The efficient representation of random fields on geometrically complex domains is crucial for Bayesian modelling in engineering and machine learning. Today's prevalent random field representations are restricted to unbounded domains or are too restrictive in terms of possible field properties. As a result, new techniques leveraging the historically established link between stochastic PDEs (SPDEs) and random fields are especially appealing for engineering applications with complex geometries which already have a finite element discretisation for solving the physical conservation equations. Unlike the dense covariance matrix of a random field, its inverse, the precision matrix, is usually sparse and equal to the stiffness matrix of a Helmholtz-like SPDE. In this paper, we use the SPDE representation to develop a scalable framework for large-scale statistical finite element analysis (statFEM) and Gaussian process (GP) regression on geometrically complex domains. We use the SPDE formulation to obtain the relevant prior probability densities with a sparse precision matrix. The properties of the priors are governed by the parameters and possibly fractional order of the Helmholtz-like SPDE so that we can model on bounded domains and manifolds anisotropic, non-homogeneous random fields with arbitrary smoothness. We use for assembling the sparse precision matrix the same finite element mesh used for solving the physical conservation equations. The observation models for statFEM and GP regression are such that the posterior probability densities are Gaussians with a closed-form mean and precision. The expressions for the mean vector and the precision matrix can be evaluated using only sparse matrix operations. We demonstrate the versatility of the proposed framework and its convergence properties with one and two-dimensional Poisson and thin-shell examples. ",
    "url": "https://arxiv.org/abs/2305.13879",
    "authors": [
      "Kim Jie Koh",
      "Fehmi Cirak"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.13884",
    "title": "Multi-Granularity Detector for Vulnerability Fixes",
    "abstract": "With the increasing reliance on Open Source Software, users are exposed to third-party library vulnerabilities. Software Composition Analysis (SCA) tools have been created to alert users of such vulnerabilities. SCA requires the identification of vulnerability-fixing commits. Prior works have proposed methods that can automatically identify such vulnerability-fixing commits. However, identifying such commits is highly challenging, as only a very small minority of commits are vulnerability fixing. Moreover, code changes can be noisy and difficult to analyze. We observe that noise can occur at different levels of detail, making it challenging to detect vulnerability fixes accurately. To address these challenges and boost the effectiveness of prior works, we propose MiDas (Multi-Granularity Detector for Vulnerability Fixes). Unique from prior works, Midas constructs different neural networks for each level of code change granularity, corresponding to commit-level, file-level, hunk-level, and line-level, following their natural organization. It then utilizes an ensemble model that combines all base models to generate the final prediction. This design allows MiDas to better handle the noisy and highly imbalanced nature of vulnerability-fixing commit data. Additionally, to reduce the human effort required to inspect code changes, we have designed an effort-aware adjustment for Midas's outputs based on commit length. The evaluation results demonstrate that MiDas outperforms the current state-of-the-art baseline in terms of AUC by 4.9% and 13.7% on Java and Python-based datasets, respectively. Furthermore, in terms of two effort-aware metrics, EffortCost@L and Popt@L, MiDas also outperforms the state-of-the-art baseline, achieving improvements of up to 28.2% and 15.9% on Java, and 60% and 51.4% on Python, respectively. ",
    "url": "https://arxiv.org/abs/2305.13884",
    "authors": [
      "Truong Giang Nguyen",
      "Thanh Le-Cong",
      "Hong Jin Kang",
      "Ratnadira Widyasari",
      "Chengran Yang",
      "Zhipeng Zhao",
      "Bowen Xu",
      "Jiayuan Zhou",
      "Xin Xia",
      "Ahmed E. Hassan",
      "Xuan-Bach D. Le",
      "David Lo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.13887",
    "title": "A Vision and An Evolutionary Framework for 6G: Scenarios, Capabilities  and Enablers",
    "abstract": "With the standardization and commercialization completed at an unforeseen pace for the 5th generation (5G) wireless networks, researchers, engineers and executives from the academia and industry have turned their attention to new candidate technologies that can support the next generation wireless networks enabling more advanced capabilities in sophisticated scenarios. Explicitly, the 6th generation (6G) terrestrial wireless network aims to providing seamless connectivity not only to users but also to machine type devices for the next decade and beyond. This paper describes the progresses moving towards 6G, which is officially termed as ``international mobile telecommunications (IMT) for 2030 and beyond'' in the International Telecommunication Union Radiocommunication Sector (ITU-R). Specifically, the usage scenarios, their representative capabilities and the supporting technologies are discussed, and the future opportunities and challenges are highlighted. ",
    "url": "https://arxiv.org/abs/2305.13887",
    "authors": [
      "Ruiqi Liu",
      "Ruyue Yu-Ngok Li",
      "Marco Di Renzo",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.13895",
    "title": "The Context Model: A Graph Database Model",
    "abstract": "In the relational model a relation over a set of attributes is defined to be a (finite) subset of the Cartesian product of the attribute domains, separately from the functional dependencies that the relation must satisfy in order to be consistent. In this paper we propose to include the functional dependencies in the definition of a relation by introducing a data model based on a graph in which the nodes are attributes, or Cartesian products of attributes, and the edges are the functional dependencies. Such a graph actually represents the datasets of an application and their relationships, so we call it an application context or simply context. We define a database over a context $\\mathcal C$ to be a function $\\delta$ that associates each node $X$ of $\\mathcal C$ with a finite set of values $\\delta(X)$ from the domain of $X$ and each edge $e: X \\to Y$ with a total function $\\delta(e): \\delta(X) \\to \\delta(Y)$. We combine the nodes and edges of a context using a functional algebra in order to define queries; and the set of all well-formed expressions of this algebra is the query language of the context. A relation over attributes $A_1, \\ldots, A_n$ is then defined as a query whose paths form a tree with leaves $A_1, \\ldots, A_n$ and whose root is the key. The main contributions of this paper are as follows: (a) we introduce a novel graph database model, called the context model, (b) we show that a consistent relational database can be embedded in the context model as a view over the context induced by its functional dependencies, (c) we define analytic queries in the query language of a context in a seamless manner - in contrast to the relational model where analytic queries are defined outside the relational algebra, and (d) we show that the context model can be used as a user-friendly interface to a relational database for data analysis purposes. ",
    "url": "https://arxiv.org/abs/2305.13895",
    "authors": [
      "Nicolas Spyratos"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2305.13896",
    "title": "Towards Optimal Serverless Function Scaling in Edge Computing Network",
    "abstract": "Serverless computing has emerged as a new execution model which gained a lot of attention in cloud computing thanks to the latest advances in containerization technologies. Recently, serverless has been adopted at the edge, where it can help overcome heterogeneity issues, constrained nature and dynamicity of edge devices. Due to the distributed nature of edge devices, however, the scaling of serverless functions presents a major challenge. We address this challenge by studying the optimality of serverless function scaling. To this end, we propose Semi-Markov Decision Process-based (SMDP) theoretical model, which yields optimal solutions by solving the serverless function scaling problem as a decision making problem. We compare the SMDP solution with practical, monitoring-based heuristics. We show that SMDP can be effectively used in edge computing networks, and in combination with monitoring-based approaches also in real-world implementations. ",
    "url": "https://arxiv.org/abs/2305.13896",
    "authors": [
      "Mounir Bensalem",
      "Francisco Carpio",
      "Admela Jukan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2305.13903",
    "title": "Let's Think Frame by Frame: Evaluating Video Chain of Thought with Video  Infilling and Prediction",
    "abstract": "Despite constituting 65% of all internet traffic in 2023, video content is underrepresented in generative AI research. Meanwhile, recent large language models (LLMs) have become increasingly integrated with capabilities in the visual modality. Integrating video with LLMs is a natural next step, so how can this gap be bridged? To advance video reasoning, we propose a new research direction of VideoCOT on video keyframes, which leverages the multimodal generative abilities of vision-language models to enhance video reasoning while reducing the computational complexity of processing hundreds or thousands of frames. We introduce VIP, an inference-time dataset that can be used to evaluate VideoCOT, containing 1) a variety of real-life videos with keyframes and corresponding unstructured and structured scene descriptions, and 2) two new video reasoning tasks: video infilling and scene prediction. We benchmark various vision-language models on VIP, demonstrating the potential to use vision-language models and LLMs to enhance video chain of thought reasoning. ",
    "url": "https://arxiv.org/abs/2305.13903",
    "authors": [
      "Vaishnavi Himakunthala",
      "Andy Ouyang",
      "Daniel Rose",
      "Ryan He",
      "Alex Mei",
      "Yujie Lu",
      "Chinmay Sonar",
      "Michael Saxon",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.13904",
    "title": "Deep GEM-Based Network for Weakly Supervised UWB Ranging Error  Mitigation",
    "abstract": "Ultra-wideband (UWB)-based techniques, while becoming mainstream approaches for high-accurate positioning, tend to be challenged by ranging bias in harsh environments. The emerging learning-based methods for error mitigation have shown great performance improvement via exploiting high semantic features from raw data. However, these methods rely heavily on fully labeled data, leading to a high cost for data acquisition. We present a learning framework based on weak supervision for UWB ranging error mitigation. Specifically, we propose a deep learning method based on the generalized expectation-maximization (GEM) algorithm for robust UWB ranging error mitigation under weak supervision. Such method integrate probabilistic modeling into the deep learning scheme, and adopt weakly supervised labels as prior information. Extensive experiments in various supervision scenarios illustrate the superiority of the proposed method. ",
    "url": "https://arxiv.org/abs/2305.13904",
    "authors": [
      "Yuxiao Li",
      "Santiago Mazuelas",
      "Yuan Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2305.13909",
    "title": "Temporal Contrastive Learning for Spiking Neural Networks",
    "abstract": "Biologically inspired spiking neural networks (SNNs) have garnered considerable attention due to their low-energy consumption and spatio-temporal information processing capabilities. Most existing SNNs training methods first integrate output information across time steps, then adopt the cross-entropy (CE) loss to supervise the prediction of the average representations. However, in this work, we find the method above is not ideal for the SNNs training as it omits the temporal dynamics of SNNs and degrades the performance quickly with the decrease of inference time steps. One tempting method to model temporal correlations is to apply the same label supervision at each time step and treat them identically. Although it can acquire relatively consistent performance across various time steps, it still faces challenges in obtaining SNNs with high performance. Inspired by these observations, we propose Temporal-domain supervised Contrastive Learning (TCL) framework, a novel method to obtain SNNs with low latency and high performance by incorporating contrastive supervision with temporal domain information. Contrastive learning (CL) prompts the network to discern both consistency and variability in the representation space, enabling it to better learn discriminative and generalizable features. We extend this concept to the temporal domain of SNNs, allowing us to flexibly and fully leverage the correlation between representations at different time steps. Furthermore, we propose a Siamese Temporal-domain supervised Contrastive Learning (STCL) framework to enhance the SNNs via augmentation, temporal and class constraints simultaneously. Extensive experimental results demonstrate that SNNs trained by our TCL and STCL can achieve both high performance and low latency, achieving state-of-the-art performance on a variety of datasets (e.g., CIFAR-10, CIFAR-100, and DVS-CIFAR10). ",
    "url": "https://arxiv.org/abs/2305.13909",
    "authors": [
      "Haonan Qiu",
      "Zeyin Song",
      "Yanqi Chen",
      "Munan Ning",
      "Wei Fang",
      "Tao Sun",
      "Zhengyu Ma",
      "Li Yuan",
      "Yonghong Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.13924",
    "title": "Integrated Sensing and Communication based Outdoor Multi-Target  Detection, Tracking and Localization in Practical 5G Networks",
    "abstract": "The 6th generation (6G) wireless networks will likely to support a variety of capabilities beyond communication, such as sensing and localization, through the use of communication networks empowered by advanced technologies. Integrated sensing and communication (ISAC) has been recognized as a critical technology as well as an usage scenario for 6G, as widely agreed by leading global standardization bodies. ISAC utilizes communication infrastructure and devices to provide the capability of sensing the environment with high resolution, as well as tracking and localizing moving objects nearby. Meeting both the requirements for communication and sensing simultaneously, ISAC based approaches celebrate the advantages of higher spectral and energy efficiency compared to two separate systems to serve two purposes, and potentially lower costs and easy deployment. A key step towards the standardization and commercialization of ISAC is to carry out comprehensive field trials in practical networks, such as the 5th generation (5G) network, to demonstrate its true capacities in practical scenarios. In this paper, an ISAC based outdoor multi-target detection, tracking and localization approach is proposed and validated in 5G networks. The proposed system comprises of 5G base stations (BSs) which serve nearby mobile users normally, while accomplishing the task of detecting, tracking and localizing drones, vehicles and pedestrians simultaneously. Comprehensive trial results demonstrate the relatively high accuracy of the proposed method in practical outdoor environment when tracking and localizing single targets and multiple targets. ",
    "url": "https://arxiv.org/abs/2305.13924",
    "authors": [
      "Ruiqi Liu",
      "Mengnan Jian",
      "Dawei Chen",
      "Xu Lin",
      "Yichao Cheng",
      "Wei Cheng",
      "Shijun Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.13931",
    "title": "Improving position bias estimation against sparse and skewed dataset  with item embedding",
    "abstract": "Estimating position bias is a well-known challenge in Learning to rank (L2R). Click data in e-commerce applications, such as advertisement targeting and search engines, provides implicit but abundant feedback to improve personalized rankings. However, click data inherently include various biases like position bias. Click modeling is aimed at denoising biases in click data and extracting reliable signals. Result Randomization and Regression Expectation-maximization algorithm have been proposed to solve position bias. Both methods require various pairs of observations (item, position). However, in real cases of advertising, marketers frequently display advertisements in a fixed pre-determined order, and estimation suffers from it. We propose this sparsity of (item, position) in position bias estimation as a novel problem, and we propose a variant of the Regression EM algorithm which utilizes item embeddings to alleviate the issue of the sparsity. With a synthetic dataset, we first evaluate how the position bias estimation suffers from the sparsity and skewness of the logging dataset. Next, with a real-world dataset, we empirically show that item embedding with Latent Semantic Indexing (LSI) and Variational autoencoder (VAE) improves the estimation of position bias. Our result shows that the Regression EM algorithm with VAE improves RMSE relatively by 10.3% and EM with LSI improves RMSE relatively by 33.4%. ",
    "url": "https://arxiv.org/abs/2305.13931",
    "authors": [
      "Shion Ishikawa",
      "Yun Ching Liu",
      "Young-Joo Chung",
      "Yu Hirate"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2305.13936",
    "title": "Robust Multi-agent Communication via Multi-view Message Certification",
    "abstract": "Many multi-agent scenarios require message sharing among agents to promote coordination, hastening the robustness of multi-agent communication when policies are deployed in a message perturbation environment. Major relevant works tackle this issue under specific assumptions, like a limited number of message channels would sustain perturbations, limiting the efficiency in complex scenarios. In this paper, we take a further step addressing this issue by learning a robust multi-agent communication policy via multi-view message certification, dubbed CroMAC. Agents trained under CroMAC can obtain guaranteed lower bounds on state-action values to identify and choose the optimal action under a worst-case deviation when the received messages are perturbed. Concretely, we first model multi-agent communication as a multi-view problem, where every message stands for a view of the state. Then we extract a certificated joint message representation by a multi-view variational autoencoder (MVAE) that uses a product-of-experts inference network. For the optimization phase, we do perturbations in the latent space of the state for a certificate guarantee. Then the learned joint message representation is used to approximate the certificated state representation during training. Extensive experiments in several cooperative multi-agent benchmarks validate the effectiveness of the proposed CroMAC. ",
    "url": "https://arxiv.org/abs/2305.13936",
    "authors": [
      "Lei Yuan",
      "Tao Jiang",
      "Lihe Li",
      "Feng Chen",
      "Zongzhang Zhang",
      "Yang Yu"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13954",
    "title": "Robust Instruction Optimization for Large Language Models with  Distribution Shifts",
    "abstract": "Large Language Models have demonstrated significant ability in accomplishing a wide range of Natural Language Processing (NLP) tasks. However, their performance is highly sensitive to the even minor changes in the phrasing of the task instructions, leading to a line of research in automatic instruction optimization towards better performance for NLP tasks. Unfortunately, existing methods for instruction optimization fail to consider the distribution shift between the seen training data and the unseen test data, where testing on unseen group of data with a different distribution could potentially lead to performance drop. In this paper, we take an initial step of investigating the problem of LLM instruction optimization across data groups with distribution shifts. We find that the optimal instructions do encounter performance drops on LLM under certain distribution shifts. To this end, we propose a framework to derive more robust optimal instructions that improve the performance on the unseen data group without large sacrifice on the seen data group. Experimental results demonstrate the effectiveness of our proposed framework. ",
    "url": "https://arxiv.org/abs/2305.13954",
    "authors": [
      "Moxin Li",
      "Wenjie Wang",
      "Fuli Feng",
      "Jizhi Zhang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.13967",
    "title": "REGARD: Rules of EngaGement for Automated cybeR Defense to aid in  Intrusion Response",
    "abstract": "Automated Intelligent Cyberdefense Agents (AICAs) that are part Intrusion Detection Systems (IDS) and part Intrusion Response Systems (IRS) are being designed to protect against sophisticated and automated cyber-attacks. An AICA based on the ideas of Self-Adaptive Autonomic Computing Systems (SA-ACS) can be considered as a managing system that protects a managed system like a personal computer, web application, critical infrastructure, etc. An AICA, specifically the IRS components, can compute a wide range of potential responses to meet its security goals and objectives, such as taking actions to prevent the attack from completing, restoring the system to comply with the organizational security policy, containing or confining an attack, attack eradication, deploying forensics measures to enable future attack analysis, counterattack, and so on. To restrict its activities in order to minimize collateral/organizational damage, such an automated system must have set Rules of Engagement (RoE). Automated systems must determine which operations can be completely automated (and when), which actions require human operator confirmation, and which actions must never be undertaken. In this paper, to enable this control functionality over an IRS, we create Rules of EngaGement for Automated cybeR Defense (REGARD) system which holds a set of Rules of Engagement (RoE) to protect the managed system according to the instructions provided by the human operator. These rules help limit the action of the IRS on the managed system in compliance with the recommendations of the domain expert. We provide details of execution, management, operation, and conflict resolution for Rules of Engagement (RoE) to constrain the actions of an automated IRS. We also describe REGARD system implementation, security case studies for cyber defense, and RoE demonstrations. ",
    "url": "https://arxiv.org/abs/2305.13967",
    "authors": [
      "Damodar Panigrahi",
      "William Anderson",
      "Joshua Whitman",
      "Sudip Mittal",
      "Benjamin A Blakely"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.13981",
    "title": "Preserving Knowledge Invariance: Rethinking Robustness Evaluation of  Open Information Extraction",
    "abstract": "The robustness to distribution changes ensures that NLP models can be successfully applied in the realistic world, especially for information extraction tasks. However, most prior evaluation benchmarks have been devoted to validating pairwise matching correctness, ignoring the crucial measurement of robustness. In this paper, we present the first benchmark that simulates the evaluation of open information extraction models in the real world, where the syntactic and expressive distributions under the same knowledge meaning may drift variously. We design and annotate a large-scale testbed in which each example is a knowledge-invariant clique that consists of sentences with structured knowledge of the same meaning but with different syntactic and expressive forms. By further elaborating the robustness metric, a model is judged to be robust if its performance is consistently accurate on the overall cliques. We perform experiments on typical models published in the last decade as well as a popular large language model, the results show that the existing successful models exhibit a frustrating degradation, with a maximum drop of 23.43 F1 score. Our resources and code will be publicly available. ",
    "url": "https://arxiv.org/abs/2305.13981",
    "authors": [
      "Ji Qi",
      "Chuchun Zhang",
      "Xiaozhi Wang",
      "Kaisheng Zeng",
      "Jifan Yu",
      "Jinxin Liu",
      "Jiuding Sun",
      "Yuxiang Chen",
      "Lei How",
      "Juanzi Li",
      "Bin Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.13982",
    "title": "Toward spike-based stochastic neural computing",
    "abstract": "Inspired by the highly irregular spiking activity of cortical neurons, stochastic neural computing is an attractive theory for explaining the operating principles of the brain and the ability to represent uncertainty by intelligent agents. However, computing and learning with high-dimensional joint probability distributions of spiking neural activity across large populations of neurons present as a major challenge. To overcome this, we develop a novel moment embedding approach to enable gradient-based learning in spiking neural networks accounting for the propagation of correlated neural variability. We show under the supervised learning setting a spiking neural network trained this way is able to learn the task while simultaneously minimizing uncertainty, and further demonstrate its application to neuromorphic hardware. Built on the principle of spike-based stochastic neural computing, the proposed method opens up new opportunities for developing machine intelligence capable of computing uncertainty and for designing unconventional computing architectures. ",
    "url": "https://arxiv.org/abs/2305.13982",
    "authors": [
      "Yang Qi",
      "Zhichao Zhu",
      "Yiming Wei",
      "Lu Cao",
      "Zhigang Wang",
      "Wenlian Lu",
      "Jianfeng Feng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Biological Physics (physics.bio-ph)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2305.13986",
    "title": "A Multi-Modal Network Equilibrium Model with Interacting Mobility  Service Providers'Strategies",
    "abstract": "A Mathematical Program with Equilibrium Constraints (MPEC) is formulated to capture the relationships between multiple Mobility Service Providers (MSPs) and the users of a multi-modal transport network. The network supply structure is defined through a novel supernetwork approach where users' daily trip chains are represented to model the mobility services used to reach each destination. At the upper level, a profit maximization formulation is introduced to describe each MSPs' behaviour. At the lower level, users within a class choose minimum cost routes, according to Wardrop's first equilibrium principle. To consider the interactions between modes, non-separable costs between supernetwork links are defined, and users' equilibrium conditions are formulated as a Variational Inequality (VI). To solve the MPEC, an iterative solution algorithm based on a Modified Projection Method is proposed. Numerical examples are presented to illustrate properties of the model, and to examine scenarios showcasing cooperation or competition strategies between MSPs. ",
    "url": "https://arxiv.org/abs/2305.13986",
    "authors": [
      "Claudia Bandiera",
      "Richard D. Connors",
      "Francesco Viti"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2305.13987",
    "title": "On Structural Expressive Power of Graph Transformers",
    "abstract": "Graph Transformer has recently received wide attention in the research community with its outstanding performance, yet its structural expressive power has not been well analyzed. Inspired by the connections between Weisfeiler-Lehman (WL) graph isomorphism test and graph neural network (GNN), we introduce \\textbf{SEG-WL test} (\\textbf{S}tructural \\textbf{E}ncoding enhanced \\textbf{G}lobal \\textbf{W}eisfeiler-\\textbf{L}ehman test), a generalized graph isomorphism test algorithm as a powerful theoretical tool for exploring the structural discriminative power of graph Transformers. We theoretically prove that the SEG-WL test is an expressivity upper bound on a wide range of graph Transformers, and the representational power of SEG-WL test can be approximated by a simple Transformer network arbitrarily under certain conditions. With the SEG-WL test, we show how graph Transformers' expressive power is determined by the design of structural encodings, and present conditions that make the expressivity of graph Transformers beyond WL test and GNNs. Moreover, motivated by the popular shortest path distance encoding, we follow the theory-oriented principles and develop a provably stronger structural encoding method, Shortest Path Induced Subgraph (\\textit{SPIS}) encoding. Our theoretical findings provide a novel and practical paradigm for investigating the expressive power of graph Transformers, and extensive synthetic and real-world experiments empirically verify the strengths of our proposed methods. ",
    "url": "https://arxiv.org/abs/2305.13987",
    "authors": [
      "Wenhao Zhu",
      "Tianyu Wen",
      "Guojie Song",
      "Liang Wang",
      "Bo Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.13991",
    "title": "Expressive Losses for Verified Robustness via Convex Combinations",
    "abstract": "In order to train networks for verified adversarial robustness, previous work typically over-approximates the worst-case loss over (subsets of) perturbation regions or induces verifiability on top of adversarial training. The key to state-of-the-art performance lies in the expressivity of the employed loss function, which should be able to match the tightness of the verifiers to be employed post-training. We formalize a definition of expressivity, and show that it can be satisfied via simple convex combinations between adversarial attacks and IBP bounds. We then show that the resulting algorithms, named CC-IBP and MTL-IBP, yield state-of-the-art results across a variety of settings in spite of their conceptual simplicity. In particular, for $\\ell_\\infty$ perturbations of radius $\\frac{1}{255}$ on TinyImageNet and downscaled ImageNet, MTL-IBP improves on the best standard and verified accuracies from the literature by from $1.98\\%$ to $3.92\\%$ points while only relying on single-step adversarial attacks. ",
    "url": "https://arxiv.org/abs/2305.13991",
    "authors": [
      "Alessandro De Palma",
      "Rudy Bunel",
      "Krishnamurthy Dvijotham",
      "M. Pawan Kumar",
      "Robert Stanforth",
      "Alessio Lomuscio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.13999",
    "title": "Towards A Unified View of Sparse Feed-Forward Network in Pretraining  Large Language Model",
    "abstract": "Large and sparse feed-forward networks (S-FFN) such as Mixture-of-Experts (MoE) have demonstrated to be an efficient approach for scaling up Transformers model size for pretraining large language models. By only activating part of the FFN parameters conditioning on input, S-FFN improves generalization performance while keeping training and inference costs (in FLOPs) fixed. In this work, we analyzed the two major design choices of S-FFN: the memory block (or expert) size and the memory block selection method under a general conceptual framework of sparse neural memory. Using this unified framework, we compare several S-FFN architectures for language modeling and provide insights into their relative efficacy and efficiency. From our analysis results, we found a simpler selection method -- Avg-K that selects blocks through their mean aggregated hidden states, achieves lower perplexity in language modeling pretraining compared to existing MoE architectures. ",
    "url": "https://arxiv.org/abs/2305.13999",
    "authors": [
      "Leo Z. Liu",
      "Tim Dettmers",
      "Xi Victoria Lin",
      "Veselin Stoyanov",
      "Xian Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14000",
    "title": "Node-wise Diffusion for Scalable Graph Learning",
    "abstract": "Graph Neural Networks (GNNs) have shown superior performance for semi-supervised learning of numerous web applications, such as classification on web services and pages, analysis of online social networks, and recommendation in e-commerce. The state of the art derives representations for all nodes in graphs following the same diffusion (message passing) model without discriminating their uniqueness. However, (i) labeled nodes involved in model training usually account for a small portion of graphs in the semisupervised setting, and (ii) different nodes locate at different graph local contexts and it inevitably degrades the representation qualities if treating them undistinguishedly in diffusion. To address the above issues, we develop NDM, a universal node-wise diffusion model, to capture the unique characteristics of each node in diffusion, by which NDM is able to yield high-quality node representations. In what follows, we customize NDM for semisupervised learning and design the NIGCN model. In particular, NIGCN advances the efficiency significantly since it (i) produces representations for labeled nodes only and (ii) adopts well-designed neighbor sampling techniques tailored for node representation generation. Extensive experimental results on various types of web datasets, including citation, social and co-purchasing graphs, not only verify the state-of-the-art effectiveness of NIGCN but also strongly support the remarkable scalability of NIGCN. In particular, NIGCN completes representation generation and training within 10 seconds on the dataset with hundreds of millions of nodes and billions of edges, up to orders of magnitude speedups over the baselines, while achieving the highest F1-scores on classification. ",
    "url": "https://arxiv.org/abs/2305.14000",
    "authors": [
      "Keke Huang",
      "Jing Tang",
      "Juncheng Liu",
      "Renchi Yang",
      "Xiaokui Xiao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.14006",
    "title": "Multi-Granularity Prompts for Topic Shift Detection in Dialogue",
    "abstract": "The goal of dialogue topic shift detection is to identify whether the current topic in a conversation has changed or needs to change. Previous work focused on detecting topic shifts using pre-trained models to encode the utterance, failing to delve into the various levels of topic granularity in the dialogue and understand dialogue contents. To address the above issues, we take a prompt-based approach to fully extract topic information from dialogues at multiple-granularity, i.e., label, turn, and topic. Experimental results on our annotated Chinese Natural Topic Dialogue dataset CNTD and the publicly available English TIAGE dataset show that the proposed model outperforms the baselines. Further experiments show that the information extracted at different levels of granularity effectively helps the model comprehend the conversation topics. ",
    "url": "https://arxiv.org/abs/2305.14006",
    "authors": [
      "Jiangyi Lin",
      "Yaxin Fan",
      "Xiaomin Chu",
      "Peifeng Li",
      "Qiaoming Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14035",
    "title": "Can Self-Supervised Neural Networks Pre-Trained on Human Speech  distinguish Animal Callers?",
    "abstract": "Self-supervised learning (SSL) models use only the intrinsic structure of a given signal, independent of its acoustic domain, to extract essential information from the input to an embedding space. This implies that the utility of such representations is not limited to modeling human speech alone. Building on this understanding, this paper explores the cross-transferability of SSL neural representations learned from human speech to analyze bio-acoustic signals. We conduct a caller discrimination analysis and a caller detection study on Marmoset vocalizations using eleven SSL models pre-trained with various pretext tasks. The results show that the embedding spaces carry meaningful caller information and can successfully distinguish the individual identities of Marmoset callers without fine-tuning. This demonstrates that representations pre-trained on human speech can be effectively applied to the bio-acoustics domain, providing valuable insights for future investigations in this field. ",
    "url": "https://arxiv.org/abs/2305.14035",
    "authors": [
      "Eklavya Sarkar",
      "Mathew Magimai.-Doss"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.14036",
    "title": "Robust Fault Estimators for Nonlinear Systems: An Ultra-Local Model  Design",
    "abstract": "This paper proposes a nonlinear estimator for the robust reconstruction of process and sensor faults for a class of uncertain nonlinear systems. The proposed fault estimation method augments the system dynamics with an ultra-local (in time) internal state-space representation (a finite chain of integrators) of the fault vector. Next, a nonlinear state observer is designed based on the known parts of the augmented dynamics. This nonlinear filter (observer) reconstructs the fault signal as well as the states of the augmented system. We provide sufficient conditions that guarantee stability of the estimation error dynamics: firstly, asymptotic stability (i.e., perfect fault estimation) in the absence of perturbations induced by fault model mismatch (mismatch between internal, ultralocal model for the fault and the actual fault characteristics), uncertainty, external disturbances, and measurement noise and, secondly, Input-to-State Stability (ISS) of the estimation error dynamics is guaranteed in the presence of these perturbations. In addition, to support performance-based estimator design, we provide Linear Matrix Inequality (LMI) conditions for L2-gain and L2 - L_inf induced norm and cast the synthesis of the estimator gains as a semi-definite program where the effect of model mismatch and external disturbances on the fault estimation error is minimized in the sense of L2-gain, for an acceptable L2 - L_inf induced norm with respect to measurement noise. The latter result facilitates a design that explicitly addresses the performance trade-off between noise sensitivity and robustness against model mismatch and external disturbances. Finally, numerical results for a benchmark system illustrate the performance of the proposed methodologies. ",
    "url": "https://arxiv.org/abs/2305.14036",
    "authors": [
      "Farhad Ghanipoor",
      "Carlos Murguia",
      "Peyman Mohajerin Esfahani",
      "Nathan van de Wouw"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.14039",
    "title": "Learning a Single Convolutional Layer Model for Low Light Image  Enhancement",
    "abstract": "Low-light image enhancement (LLIE) aims to improve the illuminance of images due to insufficient light exposure. Recently, various lightweight learning-based LLIE methods have been proposed to handle the challenges of unfavorable prevailing low contrast, low brightness, etc. In this paper, we have streamlined the architecture of the network to the utmost degree. By utilizing the effective structural re-parameterization technique, a single convolutional layer model (SCLM) is proposed that provides global low-light enhancement as the coarsely enhanced results. In addition, we introduce a local adaptation module that learns a set of shared parameters to accomplish local illumination correction to address the issue of varied exposure levels in different image regions. Experimental results demonstrate that the proposed method performs favorably against the state-of-the-art LLIE methods in both objective metrics and subjective visual effects. Additionally, our method has fewer parameters and lower inference complexity compared to other learning-based schemes. ",
    "url": "https://arxiv.org/abs/2305.14039",
    "authors": [
      "Yuantong Zhang",
      "Baoxin Teng",
      "Daiqin Yang",
      "Zhenzhong Chen",
      "Haichuan Ma",
      "Gang Li",
      "Wenpeng Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14046",
    "title": "Towards Automated Security Analysis of Smart Contracts based on  Execution Property Graph",
    "abstract": "Identifying and mitigating vulnerabilities in smart contracts is crucial, especially considering the rapid growth and increasing complexity of Decentralized Finance (DeFi) platforms. To address the challenges associated with securing these contracts, we introduce a versatile dynamic analysis framework specifically designed for the Ethereum Virtual Machine (EVM). This comprehensive framework focuses on tracking contract executions, capturing valuable runtime information, while introducing and employing the Execution Property Graph (EPG) to propose a unique graph traversal technique that swiftly detects potential smart contract attacks. Our approach showcases its efficacy with rapid average graph traversal time per transaction and high true positive rates. The successful identification of a zero-day vulnerability affecting Uniswap highlights the framework's potential to effectively uncover smart contract vulnerabilities in complex DeFi systems. ",
    "url": "https://arxiv.org/abs/2305.14046",
    "authors": [
      "Kaihua Qin",
      "Zhe Ye",
      "Zhun Wang",
      "Weilin Li",
      "Liyi Zhou",
      "Chao Zhang",
      "Dawn Song",
      "Arthur Gervais"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.14065",
    "title": "Do Not Train It: A Linear Neural Architecture Search of Graph Neural  Networks",
    "abstract": "Neural architecture search (NAS) for Graph neural networks (GNNs), called NAS-GNNs, has achieved significant performance over manually designed GNN architectures. However, these methods inherit issues from the conventional NAS methods, such as high computational cost and optimization difficulty. More importantly, previous NAS methods have ignored the uniqueness of GNNs, where GNNs possess expressive power without training. With the randomly-initialized weights, we can then seek the optimal architecture parameters via the sparse coding objective and derive a novel NAS-GNNs method, namely neural architecture coding (NAC). Consequently, our NAC holds a no-update scheme on GNNs and can efficiently compute in linear time. Empirical evaluations on multiple GNN benchmark datasets demonstrate that our approach leads to state-of-the-art performance, which is up to $200\\times$ faster and $18.8\\%$ more accurate than the strong baselines. ",
    "url": "https://arxiv.org/abs/2305.14065",
    "authors": [
      "Peng Xu",
      "Lin Zhang",
      "Xuanzhou Liu",
      "Jiaqi Sun",
      "Yue Zhao",
      "Haiqing Yang",
      "Bei Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14080",
    "title": "Eye-tracked Virtual Reality: A Comprehensive Survey on Methods and  Privacy Challenges",
    "abstract": "Latest developments in computer hardware, sensor technologies, and artificial intelligence can make virtual reality (VR) and virtual spaces an important part of human everyday life. Eye tracking offers not only a hands-free way of interaction but also the possibility of a deeper understanding of human visual attention and cognitive processes in VR. Despite these possibilities, eye-tracking data also reveal privacy-sensitive attributes of users when it is combined with the information about the presented stimulus. To address these possibilities and potential privacy issues, in this survey, we first cover major works in eye tracking, VR, and privacy areas between the years 2012 and 2022. While eye tracking in the VR part covers the complete pipeline of eye-tracking methodology from pupil detection and gaze estimation to offline use and analyses, as for privacy and security, we focus on eye-based authentication as well as computational methods to preserve the privacy of individuals and their eye-tracking data in VR. Later, taking all into consideration, we draw three main directions for the research community by mainly focusing on privacy challenges. In summary, this survey provides an extensive literature review of the utmost possibilities with eye tracking in VR and the privacy implications of those possibilities. ",
    "url": "https://arxiv.org/abs/2305.14080",
    "authors": [
      "Efe Bozkir",
      "S\u00fcleyman \u00d6zdel",
      "Mengdi Wang",
      "Brendan David-John",
      "Hong Gao",
      "Kevin Butler",
      "Eakta Jain",
      "Enkelejda Kasneci"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14081",
    "title": "How to Solve Few-Shot Abusive Content Detection Using the Data We  Actually Have",
    "abstract": "Due to the broad range of social media platforms and their user groups, the requirements of abusive language detection systems are varied and ever-changing. Already a large set of annotated corpora with different properties and label sets were created, such as hate or misogyny detection, but the form and targets of abusive speech are constantly changing. Since, the annotation of new corpora is expensive, in this work we leverage datasets we already have, covering a wide range of tasks related to abusive language detection, in order to build models cheaply for a new target label set and/or language, using only a few training examples of the target domain. We propose a two-step approach: first we train our model in a multitask fashion. We then carry out few-shot adaptation to the target requirements. Our experiments show that by leveraging already existing datasets and only a few-shots of the target task the performance of models can be improved not only monolingually but across languages as well. Our analysis also shows that our models acquire a general understanding of abusive language, since they improve the prediction of labels which are present only in the target dataset. We also analyze the trade-off between specializing the already existing datasets to a given target setup for best performance and its negative effects on model adaptability. ",
    "url": "https://arxiv.org/abs/2305.14081",
    "authors": [
      "Viktor Hangya",
      "Alexander Fraser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14083",
    "title": "Counterfactual Augmentation for Multimodal Learning Under Presentation  Bias",
    "abstract": "In real-world machine learning systems, labels are often derived from user behaviors that the system wishes to encourage. Over time, new models must be trained as new training examples and features become available. However, feedback loops between users and models can bias future user behavior, inducing a presentation bias in the labels that compromises the ability to train new models. In this paper, we propose counterfactual augmentation, a novel causal method for correcting presentation bias using generated counterfactual labels. Our empirical evaluations demonstrate that counterfactual augmentation yields better downstream performance compared to both uncorrected models and existing bias-correction methods. Model analyses further indicate that the generated counterfactuals align closely with true counterfactuals in an oracle setting. ",
    "url": "https://arxiv.org/abs/2305.14083",
    "authors": [
      "Victoria Lin",
      "Louis-Philippe Morency",
      "Dimitrios Dimitriadis",
      "Srinagesh Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14087",
    "title": "BM25 Query Augmentation Learned End-to-End",
    "abstract": "Given BM25's enduring competitiveness as an information retrieval baseline, we investigate to what extent it can be even further improved by augmenting and re-weighting its sparse query-vector representation. We propose an approach to learning an augmentation and a re-weighting end-to-end, and we find that our approach improves performance over BM25 while retaining its speed. We furthermore find that the learned augmentations and re-weightings transfer well to unseen datasets. ",
    "url": "https://arxiv.org/abs/2305.14087",
    "authors": [
      "Xiaoyin Chen",
      "Sam Wiseman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2305.14097",
    "title": "QFA2SR: Query-Free Adversarial Transfer Attacks to Speaker Recognition  Systems",
    "abstract": "Current adversarial attacks against speaker recognition systems (SRSs) require either white-box access or heavy black-box queries to the target SRS, thus still falling behind practical attacks against proprietary commercial APIs and voice-controlled devices. To fill this gap, we propose QFA2SR, an effective and imperceptible query-free black-box attack, by leveraging the transferability of adversarial voices. To improve transferability, we present three novel methods, tailored loss functions, SRS ensemble, and time-freq corrosion. The first one tailors loss functions to different attack scenarios. The latter two augment surrogate SRSs in two different ways. SRS ensemble combines diverse surrogate SRSs with new strategies, amenable to the unique scoring characteristics of SRSs. Time-freq corrosion augments surrogate SRSs by incorporating well-designed time-/frequency-domain modification functions, which simulate and approximate the decision boundary of the target SRS and distortions introduced during over-the-air attacks. QFA2SR boosts the targeted transferability by 20.9%-70.7% on four popular commercial APIs (Microsoft Azure, iFlytek, Jingdong, and TalentedSoft), significantly outperforming existing attacks in query-free setting, with negligible effect on the imperceptibility. QFA2SR is also highly effective when launched over the air against three wide-spread voice assistants (Google Assistant, Apple Siri, and TMall Genie) with 60%, 46%, and 70% targeted transferability, respectively. ",
    "url": "https://arxiv.org/abs/2305.14097",
    "authors": [
      "Guangke Chen",
      "Yedi Zhang",
      "Zhe Zhao",
      "Fu Song"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.14098",
    "title": "Balancing Explainability-Accuracy of Complex Models",
    "abstract": "Explainability of AI models is an important topic that can have a significant impact in all domains and applications from autonomous driving to healthcare. The existing approaches to explainable AI (XAI) are mainly limited to simple machine learning algorithms, and the research regarding the explainability-accuracy tradeoff is still in its infancy especially when we are concerned about complex machine learning techniques like neural networks and deep learning (DL). In this work, we introduce a new approach for complex models based on the co-relation impact which enhances the explainability considerably while also ensuring the accuracy at a high level. We propose approaches for both scenarios of independent features and dependent features. In addition, we study the uncertainty associated with features and output. Furthermore, we provide an upper bound of the computation complexity of our proposed approach for the dependent features. The complexity bound depends on the order of logarithmic of the number of observations which provides a reliable result considering the higher dimension of dependent feature space with a smaller number of observations. ",
    "url": "https://arxiv.org/abs/2305.14098",
    "authors": [
      "Poushali Sengupta",
      "Yan Zhang",
      "Sabita Maharjan",
      "Frank Eliassen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14109",
    "title": "Augmented Random Search for Multi-Objective Bayesian Optimization of  Neural Networks",
    "abstract": "Deploying Deep Neural Networks (DNNs) on tiny devices is a common trend to process the increasing amount of sensor data being generated. Multi-objective optimization approaches can be used to compress DNNs by applying network pruning and weight quantization to minimize the memory footprint (RAM), the number of parameters (ROM) and the number of floating point operations (FLOPs) while maintaining the predictive accuracy. In this paper, we show that existing multi-objective Bayesian optimization (MOBOpt) approaches can fall short in finding optimal candidates on the Pareto front and propose a novel solver based on an ensemble of competing parametric policies trained using an Augmented Random Search Reinforcement Learning (RL) agent. Our methodology aims at finding feasible tradeoffs between a DNN's predictive accuracy, memory consumption on a given target system, and computational complexity. Our experiments show that we outperform existing MOBOpt approaches consistently on different data sets and architectures such as ResNet-18 and MobileNetV3. ",
    "url": "https://arxiv.org/abs/2305.14109",
    "authors": [
      "Mark Deutel",
      "Georgios Kontes",
      "Christopher Mutschler",
      "J\u00fcrgen Teich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14122",
    "title": "Transferring Learning Trajectories of Neural Networks",
    "abstract": "Training deep neural networks (DNNs) is computationally expensive, which is problematic especially when performing duplicated training runs, such as model ensemble or knowledge distillation. Once we have trained one DNN on some dataset, we have its learning trajectory (i.e., a sequence of intermediate parameters during training) which may potentially contain useful information for learning the dataset. However, there has been no attempt to utilize such information of a given learning trajectory for another training. In this paper, we formulate the problem of \"transferring\" a given learning trajectory from one initial parameter to another one, called learning transfer problem, and derive the first algorithm to approximately solve it by matching gradients successively along the trajectory via permutation symmetry. We empirically show that the transferred parameters achieve non-trivial accuracy before any direct training. Also, we analyze the loss landscape property of the transferred parameters, especially from a viewpoint of mode connectivity. ",
    "url": "https://arxiv.org/abs/2305.14122",
    "authors": [
      "Daiki Chijiwa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.14126",
    "title": "To Copy Rather Than Memorize: A Vertical Learning Paradigm for Knowledge  Graph Completion",
    "abstract": "Embedding models have shown great power in knowledge graph completion (KGC) task. By learning structural constraints for each training triple, these methods implicitly memorize intrinsic relation rules to infer missing links. However, this paper points out that the multi-hop relation rules are hard to be reliably memorized due to the inherent deficiencies of such implicit memorization strategy, making embedding models underperform in predicting links between distant entity pairs. To alleviate this problem, we present Vertical Learning Paradigm (VLP), which extends embedding models by allowing to explicitly copy target information from related factual triples for more accurate prediction. Rather than solely relying on the implicit memory, VLP directly provides additional cues to improve the generalization ability of embedding models, especially making the distant link prediction significantly easier. Moreover, we also propose a novel relative distance based negative sampling technique (ReD) for more effective optimization. Experiments demonstrate the validity and generality of our proposals on two standard benchmarks. Our code is available at https://github.com/rui9812/VLP. ",
    "url": "https://arxiv.org/abs/2305.14126",
    "authors": [
      "Rui Li",
      "Xu Chen",
      "Chaozhuo Li",
      "Yanming Shen",
      "Jianan Zhao",
      "Yujing Wang",
      "Weihao Han",
      "Hao Sun",
      "Weiwei Deng",
      "Qi Zhang",
      "Xing Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14129",
    "title": "GrACE: Generation using Associated Code Edits",
    "abstract": "Developers expend a significant amount of time in editing code for a variety of reasons such as bug fixing or adding new features. Designing effective methods to predict code edits has been an active yet challenging area of research due to the diversity of code edits and the difficulty of capturing the developer intent. In this work, we address these challenges by endowing pre-trained large language models (LLMs) of code with the knowledge of prior, relevant edits. The generative capability of the LLMs helps address the diversity in code changes and conditioning code generation on prior edits helps capture the latent developer intent. We evaluate two well-known LLMs, Codex and CodeT5, in zero-shot and fine-tuning settings respectively. In our experiments with two datasets, the knowledge of prior edits boosts the performance of the LLMs significantly and enables them to generate 29% and 54% more correctly edited code in top-1 suggestions relative to the current state-of-the-art symbolic and neural approaches, respectively. ",
    "url": "https://arxiv.org/abs/2305.14129",
    "authors": [
      "Priyanshu Gupta",
      "Avishree Khare",
      "Yasharth Bajpai",
      "Saikat Chakraborty",
      "Sumit Gulwani",
      "Aditya Kanade",
      "Arjun Radhakrishna",
      "Gustavo Soares",
      "Ashish Tiwari"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14141",
    "title": "Learning Remote Sensing Object Detection with Single Point Supervision",
    "abstract": "Pointly Supervised Object Detection (PSOD) has attracted considerable interests due to its lower labeling cost as compared to box-level supervised object detection. However, the complex scenes, densely packed and dynamic-scale objects in Remote Sensing (RS) images hinder the development of PSOD methods in RS field. In this paper, we make the first attempt to achieve RS object detection with single point supervision, and propose a PSOD framework tailored with RS images. Specifically, we design a point label upgrader (PLUG) to generate pseudo box labels from single point labels, and then use the pseudo boxes to supervise the optimization of existing detectors. Moreover, to handle the challenge of the densely packed objects in RS images, we propose a sparse feature guided semantic prediction module which can generate high-quality semantic maps by fully exploiting informative cues from sparse objects. Extensive ablation studies on the DOTA dataset have validated the effectiveness of our method. Our method can achieve significantly better performance as compared to state-of-the-art image-level and point-level supervised detection methods, and reduce the performance gap between PSOD and box-level supervised object detection. Code will be available at https://github.com/heshitian/PLUG. ",
    "url": "https://arxiv.org/abs/2305.14141",
    "authors": [
      "Shitian He",
      "Huanxin Zou",
      "Yingqian Wang",
      "Boyang Li",
      "Xu Cao",
      "Ning Jing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14163",
    "title": "Leveraging Open Information Extraction for Improving Few-Shot Trigger  Detection Domain Transfer",
    "abstract": "Event detection is a crucial information extraction task in many domains, such as Wikipedia or news. The task typically relies on trigger detection (TD) -- identifying token spans in the text that evoke specific events. While the notion of triggers should ideally be universal across domains, domain transfer for TD from high- to low-resource domains results in significant performance drops. We address the problem of negative transfer for TD by coupling triggers between domains using subject-object relations obtained from a rule-based open information extraction (OIE) system. We demonstrate that relations injected through multi-task training can act as mediators between triggers in different domains, enhancing zero- and few-shot TD domain transfer and reducing negative transfer, in particular when transferring from a high-resource source Wikipedia domain to a low-resource target news domain. Additionally, we combine the extracted relations with masked language modeling on the target domain and obtain further TD performance gains. Finally, we demonstrate that the results are robust to the choice of the OIE system. ",
    "url": "https://arxiv.org/abs/2305.14163",
    "authors": [
      "David Duki\u0107",
      "Kiril Gashteovski",
      "Goran Glava\u0161",
      "Jan \u0160najder"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14165",
    "title": "Impact of Light and Shadow on Robustness of Deep Neural Networks",
    "abstract": "Deep neural networks (DNNs) have made remarkable strides in various computer vision tasks, including image classification, segmentation, and object detection. However, recent research has revealed a vulnerability in advanced DNNs when faced with deliberate manipulations of input data, known as adversarial attacks. Moreover, the accuracy of DNNs is heavily influenced by the distribution of the training dataset. Distortions or perturbations in the color space of input images can introduce out-of-distribution data, resulting in misclassification. In this work, we propose a brightness-variation dataset, which incorporates 24 distinct brightness levels for each image within a subset of ImageNet. This dataset enables us to simulate the effects of light and shadow on the images, so as is to investigate the impact of light and shadow on the performance of DNNs. In our study, we conduct experiments using several state-of-the-art DNN architectures on the aforementioned dataset. Through our analysis, we discover a noteworthy positive correlation between the brightness levels and the loss of accuracy in DNNs. Furthermore, we assess the effectiveness of recently proposed robust training techniques and strategies, including AugMix, Revisit, and Free Normalizer, using the ResNet50 architecture on our brightness-variation dataset. Our experimental results demonstrate that these techniques can enhance the robustness of DNNs against brightness variation, leading to improved performance when dealing with images exhibiting varying brightness levels. ",
    "url": "https://arxiv.org/abs/2305.14165",
    "authors": [
      "Chengyin Hu",
      "Weiwen Shi",
      "Chao Li",
      "Jialiang Sun",
      "Donghua Wang",
      "Junqi Wu",
      "Guijian Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14171",
    "title": "Probing in Context: Toward Building Robust Classifiers via Probing Large  Language Models",
    "abstract": "Large language models are able to learn new tasks in context, where they are provided with instructions and a few annotated examples. However, the effectiveness of in-context learning is dependent to the provided context, and the performance on a downstream task can vary a lot depending on the instruction. Importantly, such dependency on the context can happen in unpredictable ways, e.g., a seemingly more informative instruction might lead to a worse performance. In this paper, we propose an alternative approach, which we term in-context probing. Similar to in-context learning, we contextualize the representation of the input with an instruction, but instead of decoding the output prediction, we probe the contextualized representation to predict the label. Through a series of experiments on a diverse set of classification tasks, we show that in-context probing is significantly more robust to changes in instructions. We further show that probing can be particularly helpful to build classifiers on top of smaller models, and with only a hundred training examples. ",
    "url": "https://arxiv.org/abs/2305.14171",
    "authors": [
      "Afra Amini",
      "Massimiliano Ciaramita"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14174",
    "title": "Improving Stability and Performance of Spiking Neural Networks through  Enhancing Temporal Consistency",
    "abstract": "Spiking neural networks have gained significant attention due to their brain-like information processing capabilities. The use of surrogate gradients has made it possible to train spiking neural networks with backpropagation, leading to impressive performance in various tasks. However, spiking neural networks trained with backpropagation typically approximate actual labels using the average output, often necessitating a larger simulation timestep to enhance the network's performance. This delay constraint poses a challenge to the further advancement of SNNs. Current training algorithms tend to overlook the differences in output distribution at various timesteps. Particularly for neuromorphic datasets, inputs at different timesteps can cause inconsistencies in output distribution, leading to a significant deviation from the optimal direction when combining optimization directions from different moments. To tackle this issue, we have designed a method to enhance the temporal consistency of outputs at different timesteps. We have conducted experiments on static datasets such as CIFAR10, CIFAR100, and ImageNet. The results demonstrate that our algorithm can achieve comparable performance to other optimal SNN algorithms. Notably, our algorithm has achieved state-of-the-art performance on neuromorphic datasets DVS-CIFAR10 and N-Caltech101, and can achieve superior performance in the test phase with timestep T=1. ",
    "url": "https://arxiv.org/abs/2305.14174",
    "authors": [
      "Dongcheng Zhao",
      "Guobin Shen",
      "Yiting Dong",
      "Yang Li",
      "Yi Zeng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.14188",
    "title": "The Best Defense is a Good Offense: Adversarial Augmentation against  Adversarial Attacks",
    "abstract": "Many defenses against adversarial attacks (\\eg robust classifiers, randomization, or image purification) use countermeasures put to work only after the attack has been crafted. We adopt a different perspective to introduce $A^5$ (Adversarial Augmentation Against Adversarial Attacks), a novel framework including the first certified preemptive defense against adversarial attacks. The main idea is to craft a defensive perturbation to guarantee that any attack (up to a given magnitude) towards the input in hand will fail. To this aim, we leverage existing automatic perturbation analysis tools for neural networks. We study the conditions to apply $A^5$ effectively, analyze the importance of the robustness of the to-be-defended classifier, and inspect the appearance of the robustified images. We show effective on-the-fly defensive augmentation with a robustifier network that ignores the ground truth label, and demonstrate the benefits of robustifier and classifier co-training. In our tests, $A^5$ consistently beats state of the art certified defenses on MNIST, CIFAR10, FashionMNIST and Tinyimagenet. We also show how to apply $A^5$ to create certifiably robust physical objects. Our code at https://github.com/NVlabs/A5 allows experimenting on a wide range of scenarios beyond the man-in-the-middle attack tested here, including the case of physical attacks. ",
    "url": "https://arxiv.org/abs/2305.14188",
    "authors": [
      "Iuri Frosio",
      "Jan Kautz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14211",
    "title": "Towards Graph-hop Retrieval and Reasoning in Complex Question Answering  over Textual Database",
    "abstract": "In Textual question answering (TQA) systems, complex questions often require retrieving multiple textual fact chains with multiple reasoning steps. While existing benchmarks are limited to single-chain or single-hop retrieval scenarios. In this paper, we propose to conduct Graph-Hop -- a novel multi-chains and multi-hops retrieval and reasoning paradigm in complex question answering. We construct a new benchmark called ReasonGraphQA, which provides explicit and fine-grained evidence graphs for complex questions to support interpretable reasoning, comprehensive and detailed reasoning. And ReasonGraphQA also shows an advantage in reasoning diversity and scale. Moreover, We propose a strong graph-hop baseline called Bidirectional Graph Retrieval (BGR) method for generating an explanation graph of textual evidence in knowledge reasoning and question answering. We have thoroughly evaluated existing evidence retrieval and reasoning models on the ReasonGraphQA. Experiments highlight Graph-Hop is a promising direction for answering complex questions, but it still has certain limitations. We have further studied mitigation strategies to meet these challenges and discuss future directions. ",
    "url": "https://arxiv.org/abs/2305.14211",
    "authors": [
      "Minjun Zhu",
      "Yixuan Weng",
      "Shizhu He",
      "Kang Liu",
      "Jun Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14218",
    "title": "DUBLIN -- Document Understanding By Language-Image Network",
    "abstract": "Visual document understanding is a complex task that involves analyzing both the text and the visual elements in document images. Existing models often rely on manual feature engineering or domain-specific pipelines, which limit their generalization ability across different document types and languages. In this paper, we propose DUBLIN, which is pretrained on webpages using three novel objectives that leverage the spatial and semantic information in the document images: Masked Document Content Generation Task, Bounding Box Task, and Rendered Question Answering Task. We evaluate our model on several benchmarks, such as Web-Based Structural Reading Comprehension, Document Visual Question Answering, Key Information Extraction, Diagram Understanding, and Table Question Answering. We show that our model achieves competitive or better results than the state-of-the-art models on these tasks. In particular, we show that DUBLIN is the first pixel-based model to achieve an EM of 77.75 and F1 of 84.25 on the WebSRC dataset. We also show that our model outperforms the current pixel-based SOTA models on DocVQA and AI2D datasets by significant margins, 2% and 21% increase in performance, respectively. Also, DUBLIN is the first ever pixel-based model which achieves comparable to text-based SOTA methods on XFUND dataset for Semantic Entity Recognition showcasing its multilingual capability. Moreover, we create new baselines for text-based datasets by rendering them as document images and applying this model. ",
    "url": "https://arxiv.org/abs/2305.14218",
    "authors": [
      "Kriti Aggarwal",
      "Aditi Khandelwal",
      "Kumar Tanmay",
      "Owais Mohammed Khan",
      "Qiang Liu",
      "Monojit Choudhury",
      "Subhojit Som",
      "Vishrav Chaudhary",
      "Saurabh Tiwary"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14225",
    "title": "ManiTweet: A New Benchmark for Identifying Manipulation of News on  Social Media",
    "abstract": "Considerable advancements have been made to tackle the misrepresentation of information derived from reference articles in the domains of fact-checking and faithful summarization. However, an unaddressed aspect remains - the identification of social media posts that manipulate information within associated news articles. This task presents a significant challenge, primarily due to the prevalence of personal opinions in such posts. We present a novel task, identifying manipulation of news on social media, which aims to detect manipulation in social media posts and identify manipulated or inserted information. To study this task, we have proposed a data collection schema and curated a dataset called ManiTweet, consisting of 3.6K pairs of tweets and corresponding articles. Our analysis demonstrates that this task is highly challenging, with large language models (LLMs) yielding unsatisfactory performance. Additionally, we have developed a simple yet effective basic model that outperforms LLMs significantly on the ManiTweet dataset. Finally, we have conducted an exploratory analysis of human-written tweets, unveiling intriguing connections between manipulation and the domain and factuality of news articles, as well as revealing that manipulated sentences are more likely to encapsulate the main story or consequences of a news outlet. ",
    "url": "https://arxiv.org/abs/2305.14225",
    "authors": [
      "Kung-Hsiang Huang",
      "Hou Pong Chan",
      "Kathleen McKeown",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14286",
    "title": "Equivariant Neural Simulators for Stochastic Spatiotemporal Dynamics",
    "abstract": "Neural networks are emerging as a tool for scalable data-driven simulation of high-dimensional dynamical systems, especially in settings where numerical methods are infeasible or computationally expensive. Notably, it has been shown that incorporating domain symmetries in deterministic neural simulators can substantially improve their accuracy, sample efficiency, and parameter efficiency. However, to incorporate symmetries in probabilistic neural simulators that can simulate stochastic phenomena, we need a model that produces equivariant distributions over trajectories, rather than equivariant function approximations. In this paper, we propose Equivariant Probabilistic Neural Simulation (EPNS), a framework for autoregressive probabilistic modeling of equivariant distributions over system evolutions. We use EPNS to design models for a stochastic n-body system and stochastic cellular dynamics. Our results show that EPNS considerably outperforms existing neural network-based methods for probabilistic simulation. More specifically, we demonstrate that incorporating equivariance in EPNS improves simulation quality, data efficiency, rollout stability, and uncertainty quantification. We conclude that EPNS is a promising method for efficient and effective data-driven probabilistic simulation in a diverse range of domains. ",
    "url": "https://arxiv.org/abs/2305.14286",
    "authors": [
      "Koen Minartz",
      "Yoeri Poels",
      "Simon Koop",
      "Vlado Menkovski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14288",
    "title": "LLM-powered Data Augmentation for Enhanced Crosslingual Performance",
    "abstract": "This paper aims to explore the potential of leveraging Large Language Models (LLMs) for data augmentation in crosslingual commonsense reasoning datasets, where the available training data is extremely limited. To achieve this, we employ several LLMs including Dolly-v2, StableVicuna, ChatGPT, and GPT-4 to augment three datasets: XCOPA, XWinograd, and XStoryCloze. Subsequently, we assess the effectiveness of fine-tuning smaller crosslingual models, mBERT and XLMR, using the synthesised data. We compare the performance of training with data generated in English and target languages, as well as translating the English-generated data into the target languages. Our experiments reveal the overall advantages of incorporating data generated by LLMs. Training on synthetic data generated by GPT-4, whether English or multilingual, improves performance consistently compared to the baseline. Other models also exhibit an overall increase in performance, however, their effectiveness decreases in some settings. We also ask native speakers to evaluate the naturalness and logical soundness of the generated examples for different languages. Human evaluation reveals that LLMs like ChatGPT and GPT-4 excel at generating natural text in most languages, except a few such as Tamil. Moreover, ChatGPT trails behind in generating plausible alternatives in comparison to the original dataset, while GPT-4 demonstrates competitive logic consistency in the synthesised data. ",
    "url": "https://arxiv.org/abs/2305.14288",
    "authors": [
      "Chenxi Whitehouse",
      "Monojit Choudhury",
      "Alham Fikri Aji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14293",
    "title": "WebIE: Faithful and Robust Information Extraction on the Web",
    "abstract": "Extracting structured and grounded fact triples from raw text is a fundamental task in Information Extraction (IE). Existing IE datasets are typically collected from Wikipedia articles, using hyperlinks to link entities to the Wikidata knowledge base. However, models trained only on Wikipedia have limitations when applied to web domains, which often contain noisy text or text that does not have any factual information. We present WebIE, the first large-scale, entity-linked closed IE dataset consisting of 1.6M sentences automatically collected from the English Common Crawl corpus. WebIE also includes negative examples, i.e. sentences without fact triples, to better reflect the data on the web. We annotate ~25K triples from WebIE through crowdsourcing and introduce mWebIE, a translation of the annotated set in four other languages: French, Spanish, Portuguese, and Hindi. We evaluate the in-domain, out-of-domain, and zero-shot cross-lingual performance of generative IE models and find models trained on WebIE show better generalisability. We also propose three training strategies that use entity linking as an auxiliary task. Our experiments show that adding Entity-Linking objectives improves the faithfulness of our generative IE models. ",
    "url": "https://arxiv.org/abs/2305.14293",
    "authors": [
      "Chenxi Whitehouse",
      "Clara Vania",
      "Alham Fikri Aji",
      "Christos Christodoulopoulos",
      "Andrea Pierleoni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14310",
    "title": "Navigating Prompt Complexity for Zero-Shot Classification: A Study of  Large Language Models in Computational Social Science",
    "abstract": "Instruction-tuned Large Language Models (LLMs) have exhibited impressive language understanding and the capacity to generate responses that follow specific instructions. However, due to the computational demands associated with training these models, their applications often rely on zero-shot settings. In this paper, we evaluate the zero-shot performance of two publicly accessible LLMs, ChatGPT and OpenAssistant, in the context of Computational Social Science classification tasks, while also investigating the effects of various prompting strategies. Our experiment considers the impact of prompt complexity, including the effect of incorporating label definitions into the prompt, using synonyms for label names, and the influence of integrating past memories during the foundation model training. The findings indicate that in a zero-shot setting, the current LLMs are unable to match the performance of smaller, fine-tuned baseline transformer models (such as BERT). Additionally, we find that different prompting strategies can significantly affect classification accuracy, with variations in accuracy and F1 scores exceeding 10%. ",
    "url": "https://arxiv.org/abs/2305.14310",
    "authors": [
      "Yida Mu",
      "Ben P. Wu",
      "William Thorne",
      "Ambrose Robinson",
      "Nikolaos Aletras",
      "Carolina Scarton",
      "Kalina Bontcheva",
      "Xingyi Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14321",
    "title": "ConGraT: Self-Supervised Contrastive Pretraining for Joint Graph and  Text Embeddings",
    "abstract": "We propose ConGraT(Contrastive Graph-Text pretraining), a general, self-supervised method for jointly learning separate representations of texts and nodes in a parent (or ``supervening'') graph, where each text is associated with one of the nodes. Datasets fitting this paradigm are common, from social media (users and posts), to citation networks over articles, to link graphs over web pages. We expand on prior work by providing a general, self-supervised, joint pretraining method, one which does not depend on particular dataset structure or a specific task. Our method uses two separate encoders for graph nodes and texts, which are trained to align their representations within a common latent space. Training uses a batch-wise contrastive learning objective inspired by prior work on joint text and image encoding. As graphs are more structured objects than images, we also extend the training objective to incorporate information about node similarity and plausible next guesses in matching nodes and texts. Experiments on various datasets reveal that ConGraT outperforms strong baselines on various downstream tasks, including node and text category classification and link prediction. Code and certain datasets are available at https://github.com/wwbrannon/congrat. ",
    "url": "https://arxiv.org/abs/2305.14321",
    "authors": [
      "William Brannon",
      "Suyash Fulay",
      "Hang Jiang",
      "Wonjune Kang",
      "Brandon Roy",
      "Jad Kabbara",
      "Deb Roy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14336",
    "title": "Schema-Driven Information Extraction from Heterogeneous Tables",
    "abstract": "In this paper, we explore the question of whether language models (LLMs) can support cost-efficient information extraction from complex tables. We introduce schema-driven information extraction, a new task that uses LLMs to transform tabular data into structured records following a human-authored schema. To assess various LLM's capabilities on this task, we develop a benchmark composed of tables from three diverse domains: machine learning papers, chemistry tables, and webpages. Accompanying the benchmark, we present InstrucTE, a table extraction method based on instruction-tuned LLMs. This method necessitates only a human-constructed extraction schema, and incorporates an error-recovery strategy. Notably, InstrucTE demonstrates competitive performance without task-specific labels, achieving an F1 score ranging from 72.3 to 95.7. Moreover, we validate the feasibility of distilling more compact table extraction models to minimize extraction costs and reduce API reliance. This study paves the way for the future development of instruction-following models for cost-efficient table extraction. ",
    "url": "https://arxiv.org/abs/2305.14336",
    "authors": [
      "Fan Bai",
      "Junmo Kang",
      "Gabriel Stanovsky",
      "Dayne Freitag",
      "Alan Ritter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14343",
    "title": "Video Prediction Models as Rewards for Reinforcement Learning",
    "abstract": "Specifying reward signals that allow agents to learn complex behaviors is a long-standing challenge in reinforcement learning. A promising approach is to extract preferences for behaviors from unlabeled videos, which are widely available on the internet. We present Video Prediction Rewards (VIPER), an algorithm that leverages pretrained video prediction models as action-free reward signals for reinforcement learning. Specifically, we first train an autoregressive transformer on expert videos and then use the video prediction likelihoods as reward signals for a reinforcement learning agent. VIPER enables expert-level control without programmatic task rewards across a wide range of DMC, Atari, and RLBench tasks. Moreover, generalization of the video prediction model allows us to derive rewards for an out-of-distribution environment where no expert data is available, enabling cross-embodiment generalization for tabletop manipulation. We see our work as starting point for scalable reward specification from unlabeled videos that will benefit from the rapid advances in generative modeling. Source code and datasets are available on the project website: https://escontrela.me ",
    "url": "https://arxiv.org/abs/2305.14343",
    "authors": [
      "Alejandro Escontrela",
      "Ademi Adeniji",
      "Wilson Yan",
      "Ajay Jain",
      "Xue Bin Peng",
      "Ken Goldberg",
      "Youngwoon Lee",
      "Danijar Hafner",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14345",
    "title": "NCHO: Unsupervised Learning for Neural 3D Composition of Humans and  Objects",
    "abstract": "Deep generative models have been recently extended to synthesizing 3D digital humans. However, previous approaches treat clothed humans as a single chunk of geometry without considering the compositionality of clothing and accessories. As a result, individual items cannot be naturally composed into novel identities, leading to limited expressiveness and controllability of generative 3D avatars. While several methods attempt to address this by leveraging synthetic data, the interaction between humans and objects is not authentic due to the domain gap, and manual asset creation is difficult to scale for a wide variety of objects. In this work, we present a novel framework for learning a compositional generative model of humans and objects (backpacks, coats, scarves, and more) from real-world 3D scans. Our compositional model is interaction-aware, meaning the spatial relationship between humans and objects, and the mutual shape change by physical contact is fully incorporated. The key challenge is that, since humans and objects are in contact, their 3D scans are merged into a single piece. To decompose them without manual annotations, we propose to leverage two sets of 3D scans of a single person with and without objects. Our approach learns to decompose objects and naturally compose them back into a generative human model in an unsupervised manner. Despite our simple setup requiring only the capture of a single subject with objects, our experiments demonstrate the strong generalization of our model by enabling the natural composition of objects to diverse identities in various poses and the composition of multiple objects, which is unseen in training data. ",
    "url": "https://arxiv.org/abs/2305.14345",
    "authors": [
      "Taeksoo Kim",
      "Shunsuke Saito",
      "Hanbyul Joo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.13314",
    "title": "Simplifying Full Waveform Inversion via Domain-Independent  Self-Supervised Learning",
    "abstract": "Geophysics has witnessed success in applying deep learning to one of its core problems: full waveform inversion (FWI) to predict subsurface velocity maps from seismic data. It is treated as an image-to-image translation problem, jointly training an encoder for seismic data and a decoder for the velocity map from seismic-velocity pairs. In this paper, we report a surprising phenomenon: when training an encoder and decoder separately in their own domains via self-supervised learning, a linear relationship is observed across domains in the latent spaces. Moreover, this phenomenon connects multiple FWI datasets in an elegant manner: these datasets can share the self-learned encoder and decoder with different linear mappings. Based on these findings, we develop SimFWI, a new paradigm that includes two steps: (a) learning a seismic encoder and a velocity decoder separately by masked image modeling over multiple datasets; (b) learning a linear mapping per dataset. Experimental results show that SimFWI can achieve comparable results to a jointly trained model from the supervision of paired seismic data and velocity maps. ",
    "url": "https://arxiv.org/abs/2305.13314",
    "authors": [
      "Yinan Feng",
      "Yinpeng Chen",
      "Peng Jin",
      "Shihang Feng",
      "Zicheng Liu",
      "Youzuo Lin"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.13315",
    "title": "3D Molecular Geometry Analysis with 2D Graphs",
    "abstract": "Ground-state 3D geometries of molecules are essential for many molecular analysis tasks. Modern quantum mechanical methods can compute accurate 3D geometries but are computationally prohibitive. Currently, an efficient alternative to computing ground-state 3D molecular geometries from 2D graphs is lacking. Here, we propose a novel deep learning framework to predict 3D geometries from molecular graphs. To this end, we develop an equilibrium message passing neural network (EMPNN) to better capture ground-state geometries from molecular graphs. To provide a testbed for 3D molecular geometry analysis, we develop a benchmark that includes a large-scale molecular geometry dataset, data splits, and evaluation protocols. Experimental results show that EMPNN can efficiently predict more accurate ground-state 3D geometries than RDKit and other deep learning methods. Results also show that the proposed framework outperforms self-supervised learning methods on property prediction tasks. ",
    "url": "https://arxiv.org/abs/2305.13315",
    "authors": [
      "Zhao Xu",
      "Yaochen Xie",
      "Youzhi Luo",
      "Xuan Zhang",
      "Xinyi Xu",
      "Meng Liu",
      "Kaleb Dickerson",
      "Cheng Deng",
      "Maho Nakata",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13331",
    "title": "A New Benchmark of Aphasia Speech Recognition and Detection Based on  E-Branchformer and Multi-task Learning",
    "abstract": "Aphasia is a language disorder that affects the speaking ability of millions of patients. This paper presents a new benchmark for Aphasia speech recognition and detection tasks using state-of-the-art speech recognition techniques with the AphsiaBank dataset. Specifically, we introduce two multi-task learning methods based on the CTC/Attention architecture to perform both tasks simultaneously. Our system achieves state-of-the-art speaker-level detection accuracy (97.3%), and a relative WER reduction of 11% for moderate Aphasia patients. In addition, we demonstrate the generalizability of our approach by applying it to another disordered speech database, the DementiaBank Pitt corpus. We will make our all-in-one recipes and pre-trained model publicly available to facilitate reproducibility. Our standardized data preprocessing pipeline and open-source recipes enable researchers to compare results directly, promoting progress in disordered speech processing. ",
    "url": "https://arxiv.org/abs/2305.13331",
    "authors": [
      "Jiyang Tang",
      "William Chen",
      "Xuankai Chang",
      "Shinji Watanabe",
      "Brian MacWhinney"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.13341",
    "title": "Discovering Causal Relations and Equations from Data",
    "abstract": "Physics is a field of science that has traditionally used the scientific method to answer questions about why natural phenomena occur and to make testable models that explain the phenomena. Discovering equations, laws and principles that are invariant, robust and causal explanations of the world has been fundamental in physical sciences throughout the centuries. Discoveries emerge from observing the world and, when possible, performing interventional studies in the system under study. With the advent of big data and the use of data-driven methods, causal and equation discovery fields have grown and made progress in computer science, physics, statistics, philosophy, and many applied fields. All these domains are intertwined and can be used to discover causal relations, physical laws, and equations from observational data. This paper reviews the concepts, methods, and relevant works on causal and equation discovery in the broad field of Physics and outlines the most important challenges and promising future lines of research. We also provide a taxonomy for observational causal and equation discovery, point out connections, and showcase a complete set of case studies in Earth and climate sciences, fluid dynamics and mechanics, and the neurosciences. This review demonstrates that discovering fundamental laws and causal relations by observing natural phenomena is being revolutionised with the efficient exploitation of observational data, modern machine learning algorithms and the interaction with domain knowledge. Exciting times are ahead with many challenges and opportunities to improve our understanding of complex systems. ",
    "url": "https://arxiv.org/abs/2305.13341",
    "authors": [
      "Gustau Camps-Valls",
      "Andreas Gerhardus",
      "Urmi Ninad",
      "Gherardo Varando",
      "Georg Martius",
      "Emili Balaguer-Ballester",
      "Ricardo Vinuesa",
      "Emiliano Diaz",
      "Laure Zanna",
      "Jakob Runge"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2305.13454",
    "title": "Dynamical noise can enhance high-order statistical structure in complex  systems",
    "abstract": "Recent research has provided a wealth of evidence highlighting the pivotal role of high-order interdependencies in supporting the information-processing capabilities of distributed complex systems. These findings may suggest that high-order interdependencies constitute a powerful resource that is, however, challenging to harness and can be readily disrupted. In this paper we contest this perspective by demonstrating that high-order interdependencies can not only exhibit robustness to stochastic perturbations, but can in fact be enhanced by them. Using elementary cellular automata as a general testbed, our results unveil the capacity of dynamical noise to enhance the statistical regularities between agents and, intriguingly, even alter the prevailing character of their interdependencies. Furthermore, our results show that these effects are related to the high-order structure of the local rules, which affect the system's susceptibility to noise and characteristic times-scales. These results deepen our understanding of how high-order interdependencies may spontaneously emerge within distributed systems interacting with stochastic environments, thus providing an initial step towards elucidating their origin and function in complex systems like the human brain. ",
    "url": "https://arxiv.org/abs/2305.13454",
    "authors": [
      "Patricio Orio",
      "Pedro A.M. Mediano",
      "Fernando E. Rosas"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.13715",
    "title": "Covariate balancing using the integral probability metric for causal  inference",
    "abstract": "Weighting methods in causal inference have been widely used to achieve a desirable level of covariate balancing. However, the existing weighting methods have desirable theoretical properties only when a certain model, either the propensity score or outcome regression model, is correctly specified. In addition, the corresponding estimators do not behave well for finite samples due to large variance even when the model is correctly specified. In this paper, we consider to use the integral probability metric (IPM), which is a metric between two probability measures, for covariate balancing. Optimal weights are determined so that weighted empirical distributions for the treated and control groups have the smallest IPM value for a given set of discriminators. We prove that the corresponding estimator can be consistent without correctly specifying any model (neither the propensity score nor the outcome regression model). In addition, we empirically show that our proposed method outperforms existing weighting methods with large margins for finite samples. ",
    "url": "https://arxiv.org/abs/2305.13715",
    "authors": [
      "Insung Kong",
      "Yuha Park",
      "Joonhyuk Jung",
      "Kwonsang Lee",
      "Yongdai Kim"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13929",
    "title": "Deep Learning and Image Super-Resolution-Guided Beam and Power  Allocation for mmWave Networks",
    "abstract": "In this paper, we develop a deep learning (DL)-guided hybrid beam and power allocation approach for multiuser millimeter-wave (mmWave) networks, which facilitates swift beamforming at the base station (BS). The following persisting challenges motivated our research: (i) User and vehicular mobility, as well as redundant beam-reselections in mmWave networks, degrade the efficiency; (ii) Due to the large beamforming dimension at the BS, the beamforming weights predicted by the cutting-edge DL-based methods often do not suit the channel distributions; (iii) Co-located user devices may cause a severe beam conflict, thus deteriorating system performance. To address the aforementioned challenges, we exploit the synergy of supervised learning and super-resolution technology to enable low-overhead beam- and power allocation. In the first step, we propose a method for beam-quality prediction. It is based on deep learning and explores the relationship between high- and low-resolution beam images (energy). Afterward, we develop a DL-based allocation approach, which enables high-accuracy beam and power allocation with only a portion of the available time-sequential low-resolution images. Theoretical and numerical results verify the effectiveness of our proposed ",
    "url": "https://arxiv.org/abs/2305.13929",
    "authors": [
      "Yuwen Cao",
      "Tomoaki Ohtsuki",
      "Setareh Maghsudi",
      "Tony Q. S. Quek"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14062",
    "title": "Amplitude-Independent Machine Learning for PPG through Visibility Graphs  and Transfer Learning",
    "abstract": "Photoplethysmography (PPG) signals are omnipresent in wearable devices, as they measure blood volume variations using LED technology. These signals provide insight into the body's circulatory system and can be employed to extract various bio-features, such as heart rate and vascular ageing. Although several algorithms have been proposed for this purpose, many exhibit limitations, including heavy reliance on human calibration, high signal quality requirements, and a lack of generalization. In this paper, we introduce a PPG signal processing framework that integrates graph theory and computer vision algorithms, which is invariant to affine transformations, offers rapid computation speed, and exhibits robust generalization across tasks and datasets. ",
    "url": "https://arxiv.org/abs/2305.14062",
    "authors": [
      "Yuyang Miao",
      "Harry J. Davies",
      "Danilo P. Mandic"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14077",
    "title": "Mind the spikes: Benign overfitting of kernels and neural networks in  fixed dimension",
    "abstract": "The success of over-parameterized neural networks trained to near-zero training error has caused great interest in the phenomenon of benign overfitting, where estimators are statistically consistent even though they interpolate noisy training data. While benign overfitting in fixed dimension has been established for some learning methods, current literature suggests that for regression with typical kernel methods and wide neural networks, benign overfitting requires a high-dimensional setting where the dimension grows with the sample size. In this paper, we show that the smoothness of the estimators, and not the dimension, is the key: benign overfitting is possible if and only if the estimator's derivatives are large enough. We generalize existing inconsistency results to non-interpolating models and more kernels to show that benign overfitting with moderate derivatives is impossible in fixed dimension. Conversely, we show that benign overfitting is possible for regression with a sequence of spiky-smooth kernels with large derivatives. Using neural tangent kernels, we translate our results to wide neural networks. We prove that while infinite-width networks do not overfit benignly with the ReLU activation, this can be fixed by adding small high-frequency fluctuations to the activation function. Our experiments verify that such neural networks, while overfitting, can indeed generalize well even on low-dimensional data sets. ",
    "url": "https://arxiv.org/abs/2305.14077",
    "authors": [
      "Moritz Haas",
      "David Holzm\u00fcller",
      "Ulrike von Luxburg",
      "Ingo Steinwart"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2305.14079",
    "title": "Masked Modeling Duo for Speech: Specializing General-Purpose Audio  Representation to Speech using Denoising Distillation",
    "abstract": "Self-supervised learning general-purpose audio representations have demonstrated high performance in a variety of tasks. Although they can be optimized for application by fine-tuning, even higher performance can be expected if they can be specialized to pre-train for an application. This paper explores the challenges and solutions in specializing general-purpose audio representations for a specific application using speech, a highly demanding field, as an example. We enhance Masked Modeling Duo (M2D), a general-purpose model, to close the performance gap with state-of-the-art (SOTA) speech models. To do so, we propose a new task, denoising distillation, to learn from fine-grained clustered features, and M2D for Speech (M2D-S), which jointly learns the denoising distillation task and M2D masked prediction task. Experimental results show that M2D-S performs comparably to or outperforms SOTA speech models on the SUPERB benchmark, demonstrating that M2D can specialize in a demanding field. Our code is available at: https://github.com/nttcslab/m2d/tree/master/speech ",
    "url": "https://arxiv.org/abs/2305.14079",
    "authors": [
      "Daisuke Niizumi",
      "Daiki Takeuchi",
      "Yasunori Ohishi",
      "Noboru Harada",
      "Kunio Kashino"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.14131",
    "title": "Temporally Causal Discovery Tests for Discrete Time Series and Neural  Spike Trains",
    "abstract": "We consider the problem of detecting causal relationships between discrete time series, in the presence of potential confounders. A hypothesis test is introduced for identifying the temporally causal influence of $(x_n)$ on $(y_n)$, causally conditioned on a possibly confounding third time series $(z_n)$. Under natural Markovian modeling assumptions, it is shown that the null hypothesis, corresponding to the absence of temporally causal influence, is equivalent to the underlying `causal conditional directed information rate' being equal to zero. The plug-in estimator for this functional is identified with the log-likelihood ratio test statistic for the desired test. This statistic is shown that is asymptotically normal under the alternative hypothesis and asymptotically $\\chi^2$ distributed under the null, facilitating the computation of $p$-values when used on empirical data. The effectiveness of the resulting hypothesis test is illustrated on simulated data, validating the underlying theory. The test is also employed in the analysis of spike train data recorded from neurons in the V4 and FEF brain regions of behaving animals during a visual attention task. There, the test results are seen to identify interesting and biologically relevant information. ",
    "url": "https://arxiv.org/abs/2305.14131",
    "authors": [
      "A. Theocharous",
      "G. G. Gregoriou",
      "P. Sapountzis",
      "I. Kontoyiannis"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2305.14301",
    "title": "A Laplacian Pyramid Based Generative H&E Stain Augmentation Network",
    "abstract": "Hematoxylin and Eosin (H&E) staining is a widely used sample preparation procedure for enhancing the saturation of tissue sections and the contrast between nuclei and cytoplasm in histology images for medical diagnostics. However, various factors, such as the differences in the reagents used, result in high variability in the colors of the stains actually recorded. This variability poses a challenge in achieving generalization for machine-learning based computer-aided diagnostic tools. To desensitize the learned models to stain variations, we propose the Generative Stain Augmentation Network (G-SAN) -- a GAN-based framework that augments a collection of cell images with simulated yet realistic stain variations. At its core, G-SAN uses a novel and highly computationally efficient Laplacian Pyramid (LP) based generator architecture, that is capable of disentangling stain from cell morphology. Through the task of patch classification and nucleus segmentation, we show that using G-SAN-augmented training data provides on average 15.7% improvement in F1 score and 7.3% improvement in panoptic quality, respectively. Our code is available at https://github.com/lifangda01/GSAN-Demo. ",
    "url": "https://arxiv.org/abs/2305.14301",
    "authors": [
      "Fangda Li",
      "Zhiqiang Hu",
      "Wen Chen",
      "Avinash Kak"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2012.06694",
    "title": "Consequences of Slow Neural Dynamics for Incremental Learning",
    "abstract": " Title: Consequences of Slow Neural Dynamics for Incremental Learning ",
    "url": "https://arxiv.org/abs/2012.06694",
    "authors": [
      "Shima Rahimi Moghaddam",
      "Fanjun Bu",
      "Christopher J. Honey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2104.04671",
    "title": "A Web Infrastructure for Certifying Multimedia News Content for Fake  News Defense",
    "abstract": " Comments: 7 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2104.04671",
    "authors": [
      "Edward L. Amoruso",
      "Raghu Avula",
      "Stephen P. Johnson",
      "Cliff C. Zou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2105.14261",
    "title": "Computing with Infinite Objects: the Gray Code Case",
    "abstract": " Title: Computing with Infinite Objects: the Gray Code Case ",
    "url": "https://arxiv.org/abs/2105.14261",
    "authors": [
      "Dieter Spreen",
      "Ulrich Berger"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ]
  },
  {
    "id": "arXiv:2111.15319",
    "title": "A framework to measure the robustness of programs in the unpredictable  environment",
    "abstract": " Title: A framework to measure the robustness of programs in the unpredictable  environment ",
    "url": "https://arxiv.org/abs/2111.15319",
    "authors": [
      "Valentina Castiglioni",
      "Michele Loreti",
      "Simone Tini"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2111.15454",
    "title": "Boosting Discriminative Visual Representation Learning with  Scenario-Agnostic Mixup",
    "abstract": " Comments: Preprint version v3 with 9 pages main body and 8 pages appendix. The source code is available at \\url{this https URL} ",
    "url": "https://arxiv.org/abs/2111.15454",
    "authors": [
      "Siyuan Li",
      "Zicheng Liu",
      "Zedong Wang",
      "Di Wu",
      "Zihan Liu",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.01693",
    "title": "Learning Neural Set Functions Under the Optimal Subset Oracle",
    "abstract": " Title: Learning Neural Set Functions Under the Optimal Subset Oracle ",
    "url": "https://arxiv.org/abs/2203.01693",
    "authors": [
      "Zijing Ou",
      "Tingyang Xu",
      "Qinliang Su",
      "Yingzhen Li",
      "Peilin Zhao",
      "Yatao Bian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.01827",
    "title": "Democratic Governance and International Research Collaboration: A  Longitudinal Analysis of the Global Science Network",
    "abstract": " Title: Democratic Governance and International Research Collaboration: A  Longitudinal Analysis of the Global Science Network ",
    "url": "https://arxiv.org/abs/2203.01827",
    "authors": [
      "Travis A. Whetsell"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Digital Libraries (cs.DL)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2204.00853",
    "title": "Adversarial Neon Beam: A Light-based Physical Attack to DNNs",
    "abstract": " Title: Adversarial Neon Beam: A Light-based Physical Attack to DNNs ",
    "url": "https://arxiv.org/abs/2204.00853",
    "authors": [
      "Chengyin Hu",
      "Weiwen Shi",
      "Wen Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.11722",
    "title": "Improving Shape Awareness and Interpretability in Deep Networks Using  Geometric Moments",
    "abstract": " Comments: Accepted at CVPR 2023 Workshop: Deep Learning for Geometric Computing ",
    "url": "https://arxiv.org/abs/2205.11722",
    "authors": [
      "Rajhans Singh",
      "Ankita Shukla",
      "Pavan Turaga"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14268",
    "title": "NeuPSL: Neural Probabilistic Soft Logic",
    "abstract": " Title: NeuPSL: Neural Probabilistic Soft Logic ",
    "url": "https://arxiv.org/abs/2205.14268",
    "authors": [
      "Connor Pryor",
      "Charles Dickens",
      "Eriq Augustine",
      "Alon Albalak",
      "William Wang",
      "Lise Getoor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00853",
    "title": "Masked Bayesian Neural Networks : Computation and Optimality",
    "abstract": " Comments: I will change to another file ",
    "url": "https://arxiv.org/abs/2206.00853",
    "authors": [
      "Insung Kong",
      "Dongyoon Yang",
      "Jongjin Lee",
      "Ilsang Ohn",
      "Yongdai Kim"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.01034",
    "title": "Adversarial Laser Spot: Robust and Covert Physical-World Attack to DNNs",
    "abstract": " Title: Adversarial Laser Spot: Robust and Covert Physical-World Attack to DNNs ",
    "url": "https://arxiv.org/abs/2206.01034",
    "authors": [
      "Chengyin Hu",
      "Yilong Wang",
      "Kalibinuer Tiliwalidi",
      "Wen Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.12251",
    "title": "Adversarial Zoom Lens: A Novel Physical-World Attack to DNNs",
    "abstract": " Title: Adversarial Zoom Lens: A Novel Physical-World Attack to DNNs ",
    "url": "https://arxiv.org/abs/2206.12251",
    "authors": [
      "Chengyin Hu",
      "Weiwen Shi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.14477",
    "title": "Adversarial Ensemble Training by Jointly Learning Label Dependencies and  Member Models",
    "abstract": " Comments: This paper has been accepted by 19th Inter. Conf. on Intelligent Computing (ICIC 2023) ",
    "url": "https://arxiv.org/abs/2206.14477",
    "authors": [
      "Lele Wang",
      "Bin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.01193",
    "title": "A Customized Text Sanitization Mechanism with Differential Privacy",
    "abstract": " Comments: This work has been accepted to the Findings of ACL 2023 ",
    "url": "https://arxiv.org/abs/2207.01193",
    "authors": [
      "Huimin Chen",
      "Fengran Mo",
      "Yanhao Wang",
      "Cen Chen",
      "Jian-Yun Nie",
      "Chengyu Wang",
      "Jamie Cui"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.12599",
    "title": "A Survey of Explainable Graph Neural Networks: Taxonomy and Evaluation  Metrics",
    "abstract": " Title: A Survey of Explainable Graph Neural Networks: Taxonomy and Evaluation  Metrics ",
    "url": "https://arxiv.org/abs/2207.12599",
    "authors": [
      "Yiqiao Li",
      "Jianlong Zhou",
      "Sunny Verma",
      "Fang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.11905",
    "title": "Neural Novel Actor: Learning a Generalized Animatable Neural  Representation for Human Actors",
    "abstract": " Title: Neural Novel Actor: Learning a Generalized Animatable Neural  Representation for Human Actors ",
    "url": "https://arxiv.org/abs/2208.11905",
    "authors": [
      "Yiming Wang",
      "Qingzhe Gao",
      "Libin Liu",
      "Lingjie Liu",
      "Christian Theobalt",
      "Baoquan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.14414",
    "title": "On the (Im)Possibility of Estimating Various Notions of Differential  Privacy",
    "abstract": " Title: On the (Im)Possibility of Estimating Various Notions of Differential  Privacy ",
    "url": "https://arxiv.org/abs/2208.14414",
    "authors": [
      "Daniele Gorla",
      "Louis Jalouzot",
      "Federica Granese",
      "Catuscia Palamidessi",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2209.02132",
    "title": "Impact of Scaled Image on Robustness of Deep Neural Networks",
    "abstract": " Title: Impact of Scaled Image on Robustness of Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2209.02132",
    "authors": [
      "Chengyin Hu",
      "Weiwen Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.02430",
    "title": "Adversarial Color Film: Effective Physical-World Attack to DNNs",
    "abstract": " Title: Adversarial Color Film: Effective Physical-World Attack to DNNs ",
    "url": "https://arxiv.org/abs/2209.02430",
    "authors": [
      "Chengyin Hu",
      "Weiwen Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.02832",
    "title": "Impact of Colour Variation on Robustness of Deep Neural Networks",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2209.02132 ",
    "url": "https://arxiv.org/abs/2209.02832",
    "authors": [
      "Chengyin Hu",
      "Weiwen Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2209.03255",
    "title": "Goldfish: No More Attacks on Proof-of-Stake Ethereum",
    "abstract": " Title: Goldfish: No More Attacks on Proof-of-Stake Ethereum ",
    "url": "https://arxiv.org/abs/2209.03255",
    "authors": [
      "Francesco D'Amato",
      "Joachim Neu",
      "Ertem Nusret Tas",
      "David Tse"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2209.09652",
    "title": "Adversarial Color Projection: A Projector-based Physical Attack to DNNs",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2209.02430 ",
    "url": "https://arxiv.org/abs/2209.09652",
    "authors": [
      "Chengyin Hu",
      "Weiwen Shi",
      "Ling Tian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.11739",
    "title": "Adversarial Catoptric Light: An Effective, Stealthy and Robust  Physical-World Attack to DNNs",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2209.09652, arXiv:2209.02430 ",
    "url": "https://arxiv.org/abs/2209.11739",
    "authors": [
      "Chengyin Hu",
      "Weiwen Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.11820",
    "title": "Expanding the Deployment Envelope of Behavior Prediction via Adaptive  Meta-Learning",
    "abstract": " Comments: 12 pages, 13 figures, 2 tables. ICRA 2023 ",
    "url": "https://arxiv.org/abs/2209.11820",
    "authors": [
      "Boris Ivanovic",
      "James Harrison",
      "Marco Pavone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.14402",
    "title": "L2XGNN: Learning to Explain Graph Neural Networks",
    "abstract": " Title: L2XGNN: Learning to Explain Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2209.14402",
    "authors": [
      "Giuseppe Serra",
      "Mathias Niepert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.14719",
    "title": "In Search of Projectively Equivariant Networks",
    "abstract": " Comments: v2: Significant rewrite. The title has been changed: \"neural network\" -&gt; \"network\". More general description of projectively equivariant linear layers, with new proposed architectures, and a completely new accompanying experiment section, as a result ",
    "url": "https://arxiv.org/abs/2209.14719",
    "authors": [
      "Georg B\u00f6kman",
      "Axel Flinth",
      "Fredrik Kahl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.14734",
    "title": "DiGress: Discrete Denoising diffusion for graph generation",
    "abstract": " Comments: 22 pages. Published as a conference paper at ICLR 2023 ",
    "url": "https://arxiv.org/abs/2209.14734",
    "authors": [
      "Clement Vignac",
      "Igor Krawczuk",
      "Antoine Siraudin",
      "Bohan Wang",
      "Volkan Cevher",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.15525",
    "title": "Slimmable Networks for Contrastive Self-supervised Learning",
    "abstract": " Comments: preprint,work in progress ",
    "url": "https://arxiv.org/abs/2209.15525",
    "authors": [
      "Shuai Zhao",
      "Xiaohan Wang",
      "Linchao Zhu",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.01969",
    "title": "Option-Aware Adversarial Inverse Reinforcement Learning for Robotic  Control",
    "abstract": " Title: Option-Aware Adversarial Inverse Reinforcement Learning for Robotic  Control ",
    "url": "https://arxiv.org/abs/2210.01969",
    "authors": [
      "Jiayu Chen",
      "Tian Lan",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.02271",
    "title": "Extending Conformal Prediction to Hidden Markov Models with Exact  Validity via de Finetti's Theorem for Markov Chains",
    "abstract": " Comments: Accepted to the International Conference on Machine Learning (ICML), 2023 ",
    "url": "https://arxiv.org/abs/2210.02271",
    "authors": [
      "Buddhika Nettasinghe",
      "Samrat Chatterjee",
      "Ramakrishna Tipireddy",
      "Mahantesh Halappanavar"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.05156",
    "title": "Task-Aware Specialization for Efficient and Robust Dense Retrieval for  Open-Domain Question Answering",
    "abstract": " Title: Task-Aware Specialization for Efficient and Robust Dense Retrieval for  Open-Domain Question Answering ",
    "url": "https://arxiv.org/abs/2210.05156",
    "authors": [
      "Hao Cheng",
      "Hao Fang",
      "Xiaodong Liu",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.09466",
    "title": "Integrated Sensing and Communication for Large Networks using Joint  Detection and a Dynamic Transmission Strategy",
    "abstract": " Title: Integrated Sensing and Communication for Large Networks using Joint  Detection and a Dynamic Transmission Strategy ",
    "url": "https://arxiv.org/abs/2211.09466",
    "authors": [
      "Konpal Shaukat Ali",
      "Marwa Chafii"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2212.01762",
    "title": "Self-supervised AutoFlow",
    "abstract": " Title: Self-supervised AutoFlow ",
    "url": "https://arxiv.org/abs/2212.01762",
    "authors": [
      "Hsin-Ping Huang",
      "Charles Herrmann",
      "Junhwa Hur",
      "Erika Lu",
      "Kyle Sargent",
      "Austin Stone",
      "Ming-Hsuan Yang",
      "Deqing Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.02781",
    "title": "QEBVerif: Quantization Error Bound Verification of Neural Networks",
    "abstract": " Title: QEBVerif: Quantization Error Bound Verification of Neural Networks ",
    "url": "https://arxiv.org/abs/2212.02781",
    "authors": [
      "Yedi Zhang",
      "Fu Song",
      "Jun Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2212.03813",
    "title": "Robustness of Learning from Task Instructions",
    "abstract": " Comments: ACL'23 Finding Accepted ",
    "url": "https://arxiv.org/abs/2212.03813",
    "authors": [
      "Jiasheng Gu",
      "Hongyu Zhao",
      "Hanzi Xu",
      "Liangyu Nie",
      "Hongyuan Mei",
      "Wenpeng Yin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.00427",
    "title": "Conditional Diffusion Based on Discrete Graph Structures for Molecular  Graph Generation",
    "abstract": " Comments: Accepted by AAAI 2023 ",
    "url": "https://arxiv.org/abs/2301.00427",
    "authors": [
      "Han Huang",
      "Leilei Sun",
      "Bowen Du",
      "Weifeng Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2301.09489",
    "title": "Contracting Skeletal Kinematics for Human-Related Video Anomaly  Detection",
    "abstract": " Comments: Submitted to Pattern Recognition Journal ",
    "url": "https://arxiv.org/abs/2301.09489",
    "authors": [
      "Alessandro Flaborea",
      "Guido D'Amely",
      "Stefano D'Arrigo",
      "Marco Aurelio Sterpa",
      "Alessio Sampieri",
      "Fabio Galasso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2301.11673",
    "title": "Bayesian Self-Supervised Contrastive Learning",
    "abstract": " Comments: 18 pages ",
    "url": "https://arxiv.org/abs/2301.11673",
    "authors": [
      "Bin Liu",
      "Bang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.03098",
    "title": "One-shot Empirical Privacy Estimation for Federated Learning",
    "abstract": " Title: One-shot Empirical Privacy Estimation for Federated Learning ",
    "url": "https://arxiv.org/abs/2302.03098",
    "authors": [
      "Galen Andrew",
      "Peter Kairouz",
      "Sewoong Oh",
      "Alina Oprea",
      "H. Brendan McMahan",
      "Vinith Suriyakumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.06245",
    "title": "Calibrating a Deep Neural Network with Its Predecessors",
    "abstract": " Comments: IJCAI 2023 Accept ",
    "url": "https://arxiv.org/abs/2302.06245",
    "authors": [
      "Linwei Tao",
      "Minjing Dong",
      "Daochang Liu",
      "Changming Sun",
      "Chang Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.08780",
    "title": "SE(3) symmetry lets graph neural networks learn arterial velocity  estimation from small datasets",
    "abstract": " Comments: 12th International Conference on Functional Imaging and Modeling of the Heart ",
    "url": "https://arxiv.org/abs/2302.08780",
    "authors": [
      "Julian Suk",
      "Christoph Brune",
      "Jelmer M. Wolterink"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Group Theory (math.GR)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2302.09444",
    "title": "mBEST: Realtime Deformable Linear Object Detection Through Minimal  Bending Energy Skeleton Pixel Traversals",
    "abstract": " Comments: YouTube video: this https URL ",
    "url": "https://arxiv.org/abs/2302.09444",
    "authors": [
      "Andrew Choi",
      "Dezhong Tong",
      "Brian Park",
      "Demetri Terzopoulos",
      "Jungseock Joo",
      "Mohammad Khalid Jawed"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2302.10980",
    "title": "MultiRobustBench: Benchmarking Robustness Against Multiple Attacks",
    "abstract": " Comments: ICML 2023 ",
    "url": "https://arxiv.org/abs/2302.10980",
    "authors": [
      "Sihui Dai",
      "Saeed Mahloujifar",
      "Chong Xiang",
      "Vikash Sehwag",
      "Pin-Yu Chen",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.16458",
    "title": "When to Pre-Train Graph Neural Networks? From Data Generation  Perspective!",
    "abstract": " Title: When to Pre-Train Graph Neural Networks? From Data Generation  Perspective! ",
    "url": "https://arxiv.org/abs/2303.16458",
    "authors": [
      "Yuxuan Cao",
      "Jiarong Xu",
      "Carl Yang",
      "Jiaan Wang",
      "Yunchao Zhang",
      "Chunping Wang",
      "Lei Chen",
      "Yang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.16524",
    "title": "Ensemble Learning Model on Artificial Neural Network-Backpropagation  (ANN-BP) Architecture for Coal Pillar Stability Classification",
    "abstract": " Comments: The following article has been submitted to AIP Proceeding. After it is published, it will be found at this https URL ",
    "url": "https://arxiv.org/abs/2303.16524",
    "authors": [
      "G. Aileen Mendrofa",
      "Gatot Fatwanto Hertono",
      "Bevina Desjwiandara Handari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.00354",
    "title": "On Context Distribution Shift in Task Representation Learning for  Offline Meta RL",
    "abstract": " Comments: This paper has been accepted by 19th Inter. Conf. on Intelligent Computing (ICIC 2023) ",
    "url": "https://arxiv.org/abs/2304.00354",
    "authors": [
      "Chenyang Zhao",
      "Zihao Zhou",
      "Bin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.02258",
    "title": "On the Graph Theory of Majority Illusions",
    "abstract": " Title: On the Graph Theory of Majority Illusions ",
    "url": "https://arxiv.org/abs/2304.02258",
    "authors": [
      "Maaike Los",
      "Zo\u00e9 Christoff",
      "Davide Grossi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2304.06287",
    "title": "NeRFVS: Neural Radiance Fields for Free View Synthesis via Geometry  Scaffolds",
    "abstract": " Comments: 10 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2304.06287",
    "authors": [
      "Chen Yang",
      "Peihao Li",
      "Zanwei Zhou",
      "Shanxin Yuan",
      "Bingbing Liu",
      "Xiaokang Yang",
      "Weichao Qiu",
      "Wei Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.10712",
    "title": "Adversarial Infrared Blocks: A Black-box Attack to Thermal Infrared  Detectors at Multiple Angles in Physical World",
    "abstract": " Title: Adversarial Infrared Blocks: A Black-box Attack to Thermal Infrared  Detectors at Multiple Angles in Physical World ",
    "url": "https://arxiv.org/abs/2304.10712",
    "authors": [
      "Chengyin Hu",
      "Weiwen Shi",
      "Tingsong Jiang",
      "Wen Yao",
      "Ling Tian",
      "Xiaoqian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.00832",
    "title": "First- and Second-Order Bounds for Adversarial Linear Contextual Bandits",
    "abstract": " Title: First- and Second-Order Bounds for Adversarial Linear Contextual Bandits ",
    "url": "https://arxiv.org/abs/2305.00832",
    "authors": [
      "Julia Olkhovskaya",
      "Jack Mayo",
      "Tim van Erven",
      "Gergely Neu",
      "Chen-Yu Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.02749",
    "title": "Explainable Reinforcement Learning via a Causal World Model",
    "abstract": " Comments: Accepted by IJCAI 2023 ",
    "url": "https://arxiv.org/abs/2305.02749",
    "authors": [
      "Zhongwei Yu",
      "Jingqing Ruan",
      "Dengpeng Xing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.02783",
    "title": "Automated Code generation for Information Technology Tasks in YAML  through Large Language Models",
    "abstract": " Title: Automated Code generation for Information Technology Tasks in YAML  through Large Language Models ",
    "url": "https://arxiv.org/abs/2305.02783",
    "authors": [
      "Saurabh Pujar",
      "Luca Buratti",
      "Xiaojie Guo",
      "Nicolas Dupuis",
      "Burn Lewis",
      "Sahil Suneja",
      "Atin Sood",
      "Ganesh Nalawade",
      "Matthew Jones",
      "Alessandro Morari",
      "Ruchir Puri"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2305.07664",
    "title": "mAedesID: Android Application for Aedes Mosquito Species Identification  using Convolutional Neural Network",
    "abstract": " Comments: 11 pages, 13 figures, This paper was presented at the International Conference on KnowledgeDiscoveries on Statistical Innovations and Recent Advances in Optimization (ICON-KSRAO)on 29th and 30th December 2022. only abstract is printed in the conference proceedings ",
    "url": "https://arxiv.org/abs/2305.07664",
    "authors": [
      "G. Jeyakodi",
      "Trisha Agarwal",
      "P. Shanthi Bala"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.09126",
    "title": "Transfer Causal Learning: Causal Effect Estimation with Knowledge  Transfer",
    "abstract": " Title: Transfer Causal Learning: Causal Effect Estimation with Knowledge  Transfer ",
    "url": "https://arxiv.org/abs/2305.09126",
    "authors": [
      "Song Wei",
      "Ronald Moore",
      "Hanyu Zhang",
      "Yao Xie",
      "Rishikesan Kamaleswaran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.10358",
    "title": "NUANCE: Near Ultrasound Attack On Networked Communication Environments",
    "abstract": " Title: NUANCE: Near Ultrasound Attack On Networked Communication Environments ",
    "url": "https://arxiv.org/abs/2305.10358",
    "authors": [
      "Forrest McKee",
      "David Noever"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.10469",
    "title": "Object Segmentation by Mining Cross-Modal Semantics",
    "abstract": " Title: Object Segmentation by Mining Cross-Modal Semantics ",
    "url": "https://arxiv.org/abs/2305.10469",
    "authors": [
      "Zongwei Wu",
      "Jingjing Wang",
      "Zhuyun Zhou",
      "Zhaochong An",
      "Qiuping Jiang",
      "C\u00e9dric Demonceaux",
      "Guolei Sun",
      "Radu Timofte"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12331",
    "title": "DCCRN-KWS: an audio bias based model for noise robust small-footprint  keyword spotting",
    "abstract": " Comments: Accepted by INTERSPEECH2023 ",
    "url": "https://arxiv.org/abs/2305.12331",
    "authors": [
      "Shubo Lv",
      "Xiong Wang",
      "Sining Sun",
      "Long Ma",
      "Lei Xie"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.12433",
    "title": "ParticleWNN: a Novel Neural Networks Framework for Solving Partial  Differential Equations",
    "abstract": " Title: ParticleWNN: a Novel Neural Networks Framework for Solving Partial  Differential Equations ",
    "url": "https://arxiv.org/abs/2305.12433",
    "authors": [
      "Yaohua Zang",
      "Gang Bao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2305.12691",
    "title": "Hi-ResNet: A High-Resolution Remote Sensing Network for Semantic  Segmentation",
    "abstract": " Title: Hi-ResNet: A High-Resolution Remote Sensing Network for Semantic  Segmentation ",
    "url": "https://arxiv.org/abs/2305.12691",
    "authors": [
      "Yuxia Chen",
      "Pengcheng Fang",
      "Jianhui Yu",
      "Xiaoling Zhong",
      "Xiaoming Zhang",
      "Tianrui Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.12817",
    "title": "Conservative Physics-Informed Neural Networks for Non-Conservative  Hyperbolic Conservation Laws Near Critical States",
    "abstract": " Comments: 23 pages, 26 figures ",
    "url": "https://arxiv.org/abs/2305.12817",
    "authors": [
      "Reyna Quita",
      "Yu-Shuo Chen",
      "Hsin-Yi Lee Alex C. Hu",
      "John M. Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13276",
    "title": "Evaluating ChatGPT's Performance for Multilingual and Emoji-based Hate  Speech Detection",
    "abstract": " Title: Evaluating ChatGPT's Performance for Multilingual and Emoji-based Hate  Speech Detection ",
    "url": "https://arxiv.org/abs/2305.13276",
    "authors": [
      "Mithun Das",
      "Saurabh Kumar Pandey",
      "Animesh Mukherjee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  }
]