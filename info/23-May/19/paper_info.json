[
  {
    "id": "arXiv:2305.10433",
    "title": "Toxicity Inspector: A Framework to Evaluate Ground Truth in Toxicity  Detection Through Feedback",
    "abstract": "Toxic language is difficult to define, as it is not monolithic and has many variations in perceptions of toxicity. This challenge of detecting toxic language is increased by the highly contextual and subjectivity of its interpretation, which can degrade the reliability of datasets and negatively affect detection model performance. To fill this void, this paper introduces a toxicity inspector framework that incorporates a human-in-the-loop pipeline with the aim of enhancing the reliability of toxicity benchmark datasets by centering the evaluator's values through an iterative feedback cycle. The centerpiece of this framework is the iterative feedback process, which is guided by two metric types (hard and soft) that provide evaluators and dataset creators with insightful examination to balance the tradeoff between performance gains and toxicity avoidance. ",
    "url": "https://arxiv.org/abs/2305.10433",
    "authors": [
      "Huriyyah Althunayan",
      "Rahaf Bahlas",
      "Manar Alharbi",
      "Lena Alsuwailem",
      "Abeer Aldayel",
      "Rehab ALahmadi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.10441",
    "title": "An Intelligent SDWN Routing Algorithm Based on Network Situational  Awareness and Deep Reinforcement Learning",
    "abstract": "Due to the highly dynamic changes in wireless network topologies, efficiently obtaining network status information and flexibly forwarding data to improve communication quality of service are important challenges. This article introduces an intelligent routing algorithm (DRL-PPONSA) based on proximal policy optimization deep reinforcement learning with network situational awareness under a software-defined wireless networking architecture. First, a specific data plane is designed for network topology construction and data forwarding. The control plane collects network traffic information, sends flow tables, and uses a GCN-GRU prediction mechanism to perceive future traffic change trends to achieve network situational awareness. Second, a DRL-based data forwarding mechanism is designed in the knowledge plane. The predicted network traffic matrix and topology information matrix are treated as the environment for DRL agents, while next-hop adjacent nodes are treated as executable actions. Accordingly, action selection strategies are designed for different network conditions to achieve more intelligent, flexible, and efficient routing control. The reward function is designed using network link information and various reward and penalty mechanisms. Additionally, importance sampling and gradient clipping techniques are employed during gradient updating to enhance convergence speed and stability. Experimental results show that DRL-PPONSA outperforms traditional routing methods in network throughput, delay, packet loss rate, and wireless node distance. Compared to value-function-based Dueling DQN routing, the convergence speed is significantly improved, and the convergence effect is more stable. Simultaneously, its consumption of hardware storage space is reduced, and efficient routing decisions can be made in real-time using the current network state information. ",
    "url": "https://arxiv.org/abs/2305.10441",
    "authors": [
      "Jinqiang Li",
      "Miao Ye",
      "Linqiang Huang",
      "Xiaofang Deng",
      "Hongbing Qiu",
      "Yong Wang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.10442",
    "title": "CBAGAN-RRT: Convolutional Block Attention Generative Adversarial Network  for Sampling-Based Path Planning",
    "abstract": "Sampling-based path planning algorithms play an important role in autonomous robotics. However, a common problem among the RRT-based algorithms is that the initial path generated is not optimal and the convergence is too slow to be used in real-world applications. In this paper, we propose a novel image-based learning algorithm (CBAGAN-RRT) using a Convolutional Block Attention Generative Adversarial Network with a combination of spatial and channel attention and a novel loss function to design the heuristics, find a better optimal path, and improve the convergence of the algorithm both concerning time and speed. The probability distribution of the paths generated from our GAN model is used to guide the sampling process for the RRT algorithm. We train and test our network on the dataset generated by \\cite{zhang2021generative} and demonstrate that our algorithm outperforms the previous state-of-the-art algorithms using both the image quality generation metrics like IOU Score, Dice Score, FID score, and path planning metrics like time cost and the number of nodes. We conduct detailed experiments and ablation studies to illustrate the feasibility of our study and show that our model performs well not only on the training dataset but also on the unseen test dataset. The advantage of our approach is that we can avoid the complicated preprocessing in the state space, our model can be generalized to complicated environments like those containing turns and narrow passages without loss of accuracy, and our model can be easily integrated with other sampling-based path planning algorithms. ",
    "url": "https://arxiv.org/abs/2305.10442",
    "authors": [
      "Abhinav Sagar",
      "Sai Teja Gilukara"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10447",
    "title": "The Effectiveness of a Dynamic Loss Function in Neural Network Based  Automated Essay Scoring",
    "abstract": "Neural networks and in particular the attention mechanism have brought significant advances to the field of Automated Essay Scoring. Many of these systems use a regression-based model which may be prone to underfitting when the model only predicts the mean of the training data. In this paper, we present a dynamic loss function that creates an incentive for the model to predict with the correct distribution, as well as predicting the correct values. Our loss function achieves this goal without sacrificing any performance achieving a Quadratic Weighted Kappa score of 0.752 on the Automated Student Assessment Prize Automated Essay Scoring dataset. ",
    "url": "https://arxiv.org/abs/2305.10447",
    "authors": [
      "Oscar Morris"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.10456",
    "title": "LPMM: Intuitive Pose Control for Neural Talking-Head Model via  Landmark-Parameter Morphable Model",
    "abstract": "While current talking head models are capable of generating photorealistic talking head videos, they provide limited pose controllability. Most methods require specific video sequences that should exactly contain the head pose desired, being far from user-friendly pose control. Three-dimensional morphable models (3DMM) offer semantic pose control, but they fail to capture certain expressions. We present a novel method that utilizes parametric control of head orientation and facial expression over a pre-trained neural-talking head model. To enable this, we introduce a landmark-parameter morphable model (LPMM), which offers control over the facial landmark domain through a set of semantic parameters. Using LPMM, it is possible to adjust specific head pose factors, without distorting other facial attributes. The results show our approach provides intuitive rig-like control over neural talking head models, allowing both parameter and image-based inputs. ",
    "url": "https://arxiv.org/abs/2305.10456",
    "authors": [
      "Kwangho Lee",
      "Patrick Kwon",
      "Myung Ki Lee",
      "Namhyuk Ahn",
      "Junsoo Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10457",
    "title": "Time Series Clustering With Random Convolutional Kernels",
    "abstract": "Time series can describe a wide range of natural and social phenomena. A few samples are climate and seismic measures trends, stock prices, or website visits. Time-series clustering helps to find outliers that, related to these instances, could represent temperature anomalies, imminent volcanic eruptions, market disturbances, or fraudulent web traffic. Founded on the success of automatic feature extraction techniques, specifically employing random kernels, we develop a new method for time series clustering consisting of two steps. First, a random convolutional structure transforms the data into an enhanced feature representation. Afterwards, a clustering algorithm classifies the transformed data. The method improves state-of-the-art results on time series clustering benchmarks. ",
    "url": "https://arxiv.org/abs/2305.10457",
    "authors": [
      "Jorge Marco-Blanco",
      "Rub\u00e9n Cuevas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10459",
    "title": "AnalogNAS: A Neural Network Design Framework for Accurate Inference with  Analog In-Memory Computing",
    "abstract": "The advancement of Deep Learning (DL) is driven by efficient Deep Neural Network (DNN) design and new hardware accelerators. Current DNN design is primarily tailored for general-purpose use and deployment on commercially viable platforms. Inference at the edge requires low latency, compact and power-efficient models, and must be cost-effective. Digital processors based on typical von Neumann architectures are not conducive to edge AI given the large amounts of required data movement in and out of memory. Conversely, analog/mixed signal in-memory computing hardware accelerators can easily transcend the memory wall of von Neuman architectures when accelerating inference workloads. They offer increased area and power efficiency, which are paramount in edge resource-constrained environments. In this paper, we propose AnalogNAS, a framework for automated DNN design targeting deployment on analog In-Memory Computing (IMC) inference accelerators. We conduct extensive hardware simulations to demonstrate the performance of AnalogNAS on State-Of-The-Art (SOTA) models in terms of accuracy and deployment efficiency on various Tiny Machine Learning (TinyML) tasks. We also present experimental results that show AnalogNAS models achieving higher accuracy than SOTA models when implemented on a 64-core IMC chip based on Phase Change Memory (PCM). The AnalogNAS search code is released: https://github.com/IBM/analog-nas ",
    "url": "https://arxiv.org/abs/2305.10459",
    "authors": [
      "Hadjer Benmeziane",
      "Corey Lammie",
      "Irem Boybat",
      "Malte Rasch",
      "Manuel Le Gallo",
      "Hsinyu Tsai",
      "Ramachandran Muralidhar",
      "Smail Niar",
      "Ouarnoughi Hamza",
      "Vijay Narayanan",
      "Abu Sebastian",
      "Kaoutar El Maghraoui"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10460",
    "title": "Topology Optimization using Neural Networks with Conditioning Field  Initialization for Improved Efficiency",
    "abstract": "We propose conditioning field initialization for neural network based topology optimization. In this work, we focus on (1) improving upon existing neural network based topology optimization, (2) demonstrating that by using a prior initial field on the unoptimized domain, the efficiency of neural network based topology optimization can be further improved. Our approach consists of a topology neural network that is trained on a case by case basis to represent the geometry for a single topology optimization problem. It takes in domain coordinates as input to represent the density at each coordinate where the topology is represented by a continuous density field. The displacement is solved through a finite element solver. We employ the strain energy field calculated on the initial design domain as an additional conditioning field input to the neural network throughout the optimization. The addition of the strain energy field input improves the convergence speed compared to standalone neural network based topology optimization. ",
    "url": "https://arxiv.org/abs/2305.10460",
    "authors": [
      "Hongrui Chen",
      "Aditya Joglekar",
      "Levent Burak Kara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10462",
    "title": "DualVector: Unsupervised Vector Font Synthesis with Dual-Part  Representation",
    "abstract": "Automatic generation of fonts can be an important aid to typeface design. Many current approaches regard glyphs as pixelated images, which present artifacts when scaling and inevitable quality losses after vectorization. On the other hand, existing vector font synthesis methods either fail to represent the shape concisely or require vector supervision during training. To push the quality of vector font synthesis to the next level, we propose a novel dual-part representation for vector glyphs, where each glyph is modeled as a collection of closed \"positive\" and \"negative\" path pairs. The glyph contour is then obtained by boolean operations on these paths. We first learn such a representation only from glyph images and devise a subsequent contour refinement step to align the contour with an image representation to further enhance details. Our method, named DualVector, outperforms state-of-the-art methods in vector font synthesis both quantitatively and qualitatively. Our synthesized vector fonts can be easily converted to common digital font formats like TrueType Font for practical use. The code is released at https://github.com/thuliu-yt16/dualvector. ",
    "url": "https://arxiv.org/abs/2305.10462",
    "authors": [
      "Ying-Tian Liu",
      "Zhifei Zhang",
      "Yuan-Chen Guo",
      "Matthew Fisher",
      "Zhaowen Wang",
      "Song-Hai Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10464",
    "title": "Reconstruction Error-based Anomaly Detection with Few Outlying Examples",
    "abstract": "Reconstruction error-based neural architectures constitute a classical deep learning approach to anomaly detection which has shown great performances. It consists in training an Autoencoder to reconstruct a set of examples deemed to represent the normality and then to point out as anomalies those data that show a sufficiently large reconstruction error. Unfortunately, these architectures often become able to well reconstruct also the anomalies in the data. This phenomenon is more evident when there are anomalies in the training set. In particular when these anomalies are labeled, a setting called semi-supervised, the best way to train Autoencoders is to ignore anomalies and minimize the reconstruction error on normal data. The goal of this work is to investigate approaches to allow reconstruction error-based architectures to instruct the model to put known anomalies outside of the domain description of the normal data. Specifically, our strategy exploits a limited number of anomalous examples to increase the contrast between the reconstruction error associated with normal examples and those associated with both known and unknown anomalies, thus enhancing anomaly detection performances. The experiments show that this new procedure achieves better performances than the standard Autoencoder approach and the main deep learning techniques for semi-supervised anomaly detection. ",
    "url": "https://arxiv.org/abs/2305.10464",
    "authors": [
      "Fabrizio Angiulli",
      "Fabio Fassetti",
      "Luca Ferragina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10465",
    "title": "Towards Robust Probabilistic Modeling on SO(3) via Rotation Laplace  Distribution",
    "abstract": "Estimating the 3DoF rotation from a single RGB image is an important yet challenging problem. As a popular approach, probabilistic rotation modeling additionally carries prediction uncertainty information, compared to single-prediction rotation regression. For modeling probabilistic distribution over SO(3), it is natural to use Gaussian-like Bingham distribution and matrix Fisher, however they are shown to be sensitive to outlier predictions, e.g. $180^\\circ$ error and thus are unlikely to converge with optimal performance. In this paper, we draw inspiration from multivariate Laplace distribution and propose a novel rotation Laplace distribution on SO(3). Our rotation Laplace distribution is robust to the disturbance of outliers and enforces much gradient to the low-error region that it can improve. In addition, we show that our method also exhibits robustness to small noises and thus tolerates imperfect annotations. With this benefit, we demonstrate its advantages in semi-supervised rotation regression, where the pseudo labels are noisy. To further capture the multi-modal rotation solution space for symmetric objects, we extend our distribution to rotation Laplace mixture model and demonstrate its effectiveness. Our extensive experiments show that our proposed distribution and the mixture model achieve state-of-the-art performance in all the rotation regression experiments over both probabilistic and non-probabilistic baselines. ",
    "url": "https://arxiv.org/abs/2305.10465",
    "authors": [
      "Yingda Yin",
      "Jiangran Lyu",
      "Yang Wang",
      "He Wang",
      "Baoquan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.10468",
    "title": "Connected Hidden Neurons (CHNNet): An Artificial Neural Network for  Rapid Convergence",
    "abstract": "The core purpose of developing artificial neural networks was to mimic the functionalities of biological neural networks. However, unlike biological neural networks, traditional artificial neural networks are often structured hierarchically, which can impede the flow of information between neurons as the neurons in the same layer have no connections between them. Hence, we propose a more robust model of artificial neural networks where the hidden neurons, residing in the same hidden layer, are interconnected, enabling the neurons to learn complex patterns and speeding up the convergence rate. With the experimental study of our proposed model as fully connected layers in shallow and deep networks, we demonstrate that the model results in a significant increase in convergence rate. ",
    "url": "https://arxiv.org/abs/2305.10468",
    "authors": [
      "Rafiad Sadat Shahir",
      "Zayed Humayun",
      "Mashrufa Akter Tamim",
      "Shouri Saha",
      "Md. Golam Rabiul Alam"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10469",
    "title": "Object Segmentation by Mining Cross-Modal Semantics",
    "abstract": "Multi-sensor clues have shown promise for object segmentation, but inherent noise in each sensor, as well as the calibration error in practice, may bias the segmentation accuracy. In this paper, we propose a novel approach by mining the Cross-Modal Semantics to guide the fusion and decoding of multimodal features, with the aim of controlling the modal contribution based on relative entropy. We explore semantics among the multimodal inputs in two aspects: the modality-shared consistency and the modality-specific variation. Specifically, we propose a novel network, termed XMSNet, consisting of (1) all-round attentive fusion (AF), (2) coarse-to-fine decoder (CFD), and (3) cross-layer self-supervision. On the one hand, the AF block explicitly dissociates the shared and specific representation and learns to weight the modal contribution by adjusting the proportion, region, and pattern, depending upon the quality. On the other hand, our CFD initially decodes the shared feature and then refines the output through specificity-aware querying. Further, we enforce semantic consistency across the decoding layers to enable interaction across network hierarchies, improving feature discriminability. Exhaustive comparison on eleven datasets with depth or thermal clues, and on two challenging tasks, namely salient and camouflage object segmentation, validate our effectiveness in terms of both performance and robustness. ",
    "url": "https://arxiv.org/abs/2305.10469",
    "authors": [
      "Zongwei Wu",
      "Jingjing Wang",
      "Zhuyun Zhou",
      "Zhaochong An",
      "Qiuping Jiang",
      "C\u00e9dric Demonceaux",
      "Guolei Sun",
      "Radu Timofte"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10471",
    "title": "Bike2Vec: Vector Embedding Representations of Road Cycling Riders and  Races",
    "abstract": "Vector embeddings have been successfully applied in several domains to obtain effective representations of non-numeric data which can then be used in various downstream tasks. We present a novel application of vector embeddings in professional road cycling by demonstrating a method to learn representations for riders and races based on historical results. We use unsupervised learning techniques to validate that the resultant embeddings capture interesting features of riders and races. These embeddings could be used for downstream prediction tasks such as early talent identification and race outcome prediction. ",
    "url": "https://arxiv.org/abs/2305.10471",
    "authors": [
      "Ethan Baron",
      "Bram Janssens",
      "Matthias Bogaert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10498",
    "title": "Edge Directionality Improves Learning on Heterophilic Graphs",
    "abstract": "Graph Neural Networks (GNNs) have become the de-facto standard tool for modeling relational data. However, while many real-world graphs are directed, the majority of today's GNN models discard this information altogether by simply making the graph undirected. The reasons for this are historical: 1) many early variants of spectral GNNs explicitly required undirected graphs, and 2) the first benchmarks on homophilic graphs did not find significant gain from using direction. In this paper, we show that in heterophilic settings, treating the graph as directed increases the effective homophily of the graph, suggesting a potential gain from the correct use of directionality information. To this end, we introduce Directed Graph Neural Network (Dir-GNN), a novel general framework for deep learning on directed graphs. Dir-GNN can be used to extend any Message Passing Neural Network (MPNN) to account for edge directionality information by performing separate aggregations of the incoming and outgoing edges. We prove that Dir-GNN matches the expressivity of the Directed Weisfeiler-Lehman test, exceeding that of conventional MPNNs. In extensive experiments, we validate that while our framework leaves performance unchanged on homophilic datasets, it leads to large gains over base models such as GCN, GAT and GraphSage on heterophilic benchmarks, outperforming much more complex methods and achieving new state-of-the-art results. ",
    "url": "https://arxiv.org/abs/2305.10498",
    "authors": [
      "Emanuele Rossi",
      "Bertrand Charpentier",
      "Francesco Di Giovanni",
      "Fabrizio Frasca",
      "Stephan G\u00fcnnemann",
      "Michael Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.10503",
    "title": "OR-NeRF: Object Removing from 3D Scenes Guided by Multiview Segmentation  with Neural Radiance Fields",
    "abstract": "The emergence of Neural Radiance Fields (NeRF) for novel view synthesis has led to increased interest in 3D scene editing. One important task in editing is removing objects from a scene while ensuring visual reasonability and multiview consistency. However, current methods face challenges such as time-consuming object labelling, limited capability to remove specific targets, and compromised rendering quality after removal. This paper proposes a novel object-removing pipeline, named OR-NeRF, that can remove objects from 3D scenes with either point or text prompts on a single view, achieving better performance in less time than previous works. Our method uses a points projection strategy to rapidly spread user annotations to all views, significantly reducing the processing burden. This algorithm allows us to leverage the recent 2D segmentation model Segment-Anything (SAM) to predict masks with improved precision and efficiency. Additionally, we obtain colour and depth priors through 2D inpainting methods. Finally, our algorithm employs depth supervision and perceptual loss for scene reconstruction to maintain consistency in geometry and appearance after object removal. Experimental results demonstrate that our method achieves better editing quality with less time than previous works, considering both quality and quantity. ",
    "url": "https://arxiv.org/abs/2305.10503",
    "authors": [
      "Youtan Yin",
      "Zhoujie Fu",
      "Fan Yang",
      "Guosheng Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10504",
    "title": "Model-Free Robust Average-Reward Reinforcement Learning",
    "abstract": "Robust Markov decision processes (MDPs) address the challenge of model uncertainty by optimizing the worst-case performance over an uncertainty set of MDPs. In this paper, we focus on the robust average-reward MDPs under the model-free setting. We first theoretically characterize the structure of solutions to the robust average-reward Bellman equation, which is essential for our later convergence analysis. We then design two model-free algorithms, robust relative value iteration (RVI) TD and robust RVI Q-learning, and theoretically prove their convergence to the optimal solution. We provide several widely used uncertainty sets as examples, including those defined by the contamination model, total variation, Chi-squared divergence, Kullback-Leibler (KL) divergence and Wasserstein distance. ",
    "url": "https://arxiv.org/abs/2305.10504",
    "authors": [
      "Yue Wang",
      "Alvaro Velasquez",
      "George Atia",
      "Ashley Prater-Bennette",
      "Shaofeng Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.10509",
    "title": "Analytic relationship of relative synchronizability to network structure  and motifs",
    "abstract": "Synchronization phenomena on networks have attracted much attention in studies of neural, social, economic, and biological systems, yet we still lack a systematic understanding of how relative synchronizability relates to underlying network structure. Indeed, this question is of central importance to the key theme of how dynamics on networks relate to their structure more generally. We present an analytic technique to directly measure the relative synchronizability of noise-driven time-series processes on networks, in terms of the directed network structure. We consider both discrete-time auto-regressive processes and continuous-time Ornstein-Uhlenbeck dynamics on networks. Our technique builds on computation of the network covariance matrix in the space orthogonal to the synchronized state, enabling it to be more general than previous work in not requiring either symmetric (undirected) or diagonalizable connectivity matrices, and allowing arbitrary self-link weights. More importantly, our approach quantifies the relative synchronisation specifically in terms of the contribution of process motif (walk) structures. We demonstrate that in general the relative abundance of process motifs with convergent directed walks (including feedback and feedforward loops) hinders synchronizability. We also reveal subtle differences between the motifs involved for discrete or continuous-time dynamics. Our insights analytically explain several known general results regarding synchronizability of networks, including that small-world and regular networks are less synchronizable than random networks. ",
    "url": "https://arxiv.org/abs/2305.10509",
    "authors": [
      "Joseph T. Lizier",
      "Frank Bauer",
      "Fatihcan M. Atay",
      "J\u00fcrgen Jost"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Mathematical Physics (math-ph)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2305.10522",
    "title": "On a Doubly Reduced Model for Dynamics of Heterogeneous Mixtures of  Stiffened Gases, its Regularizations and their Implementations",
    "abstract": "We deal with the reduced four-equation model for dynamics of the heterogeneous compressible binary mixtures with the stiffened gas equations of state. We study its further reduced form, with the excluded volume concentrations and a quadratic equation for the common pressure of the components, that can be called quasi-homogeneous form. We prove new properties of this equation, derive a simple formula for the squared speed of sound, give an alternative proof for a formula that relates it to the squared Wood speed of sound, and a short derivation of the pressure balance equation. For the first time, we introduce regularizations of the heterogeneous model (in the quasi-homogeneous form). In the 1D case, we construct the corresponding explicit two-level in time and symmetric three-point in space finite-difference schemes without limiters and present various numerical results for flows with shock waves. ",
    "url": "https://arxiv.org/abs/2305.10522",
    "authors": [
      "A. Zlotnik",
      "T. Lomonosov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2305.10527",
    "title": "Node Attribute Prediction on Multilayer Networks with Weighted and  Directed Edges",
    "abstract": "With the rapid development of digital platforms, users can now interact in endless ways from writing business reviews and comments to sharing information with their friends and followers. As a result, organizations have numerous digital social networks available for graph learning problems with little guidance on how to select the right graph or how to combine multiple edge types. In this paper, we first describe the types of user-to-user networks available across the Facebook (FB) and Instagram (IG) platforms. We observe minimal edge overlap between these networks, indicating users are exhibiting different behaviors and interaction patterns between platforms. We then compare predictive performance metrics across various node attribute prediction tasks for an ads click prediction task on Facebook and for a publicly available dataset from the Open Graph Benchmark. We adapt an existing node attribute prediction method for binary prediction, LINK-Naive Bayes, to account for both edge direction and weights on single-layer networks. We observe meaningful predictive performance gains when incorporating edge direction and weight. We then introduce an approach called MultiLayerLINK-NaiveBayes that can combine multiple network layers during training and observe superior performance over the single-layer results. Ultimately, whether edge direction, edge weights, and multi-layers are practically useful will depend on the particular setting. Our approach enables practitioners to quickly combine multiple layers and additional edge information such as direction or weight. ",
    "url": "https://arxiv.org/abs/2305.10527",
    "authors": [
      "Yiguang Zhang",
      "Kristen Altenburger",
      "Poppy Zhang",
      "Tsutomu Okano",
      "Shawndra Hill"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.10538",
    "title": "Generating Bayesian Network Models from Data Using Tsetlin Machines",
    "abstract": "Bayesian networks (BN) are directed acyclic graphical (DAG) models that have been adopted into many fields for their strengths in transparency, interpretability, probabilistic reasoning, and causal modeling. Given a set of data, one hurdle towards using BNs is in building the network graph from the data that properly handles dependencies, whether correlated or causal. In this paper, we propose an initial methodology for discovering network structures using Tsetlin Machines. ",
    "url": "https://arxiv.org/abs/2305.10538",
    "authors": [
      "Christian D. Blakely"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.10540",
    "title": "Generalization Bounds for Neural Belief Propagation Decoders",
    "abstract": "Machine learning based approaches are being increasingly used for designing decoders for next generation communication systems. One widely used framework is neural belief propagation (NBP), which unfolds the belief propagation (BP) iterations into a deep neural network and the parameters are trained in a data-driven manner. NBP decoders have been shown to improve upon classical decoding algorithms. In this paper, we investigate the generalization capabilities of NBP decoders. Specifically, the generalization gap of a decoder is the difference between empirical and expected bit-error-rate(s). We present new theoretical results which bound this gap and show the dependence on the decoder complexity, in terms of code parameters (blocklength, message length, variable/check node degrees), decoding iterations, and the training dataset size. Results are presented for both regular and irregular parity-check matrices. To the best of our knowledge, this is the first set of theoretical results on generalization performance of neural network based decoders. We present experimental results to show the dependence of generalization gap on the training dataset size, and decoding iterations for different codes. ",
    "url": "https://arxiv.org/abs/2305.10540",
    "authors": [
      "Sudarshan Adiga",
      "Xin Xiao",
      "Ravi Tandon",
      "Bane Vasic",
      "Tamal Bose"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10544",
    "title": "Tractable Probabilistic Graph Representation Learning with Graph-Induced  Sum-Product Networks",
    "abstract": "We introduce Graph-Induced Sum-Product Networks (GSPNs), a new probabilistic framework for graph representation learning that can tractably answer probabilistic queries. Inspired by the computational trees induced by vertices in the context of message-passing neural networks, we build hierarchies of sum-product networks (SPNs) where the parameters of a parent SPN are learnable transformations of the a-posterior mixing probabilities of its children's sum units. Due to weight sharing and the tree-shaped computation graphs of GSPNs, we obtain the efficiency and efficacy of deep graph networks with the additional advantages of a purely probabilistic model. We show the model's competitiveness on scarce supervision scenarios, handling missing data, and graph classification in comparison to popular neural models. We complement the experiments with qualitative analyses on hyper-parameters and the model's ability to answer probabilistic queries. ",
    "url": "https://arxiv.org/abs/2305.10544",
    "authors": [
      "Federico Errica",
      "Mathias Niepert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.10546",
    "title": "Games on Graphs",
    "abstract": "The objective of this collaborative textbook is to present the state of the art on games on graphs, which is part of a larger research topic called game theory. Games on graphs is the field concerned with games whose rules and evolution are represented by a graph. ",
    "url": "https://arxiv.org/abs/2305.10546",
    "authors": [
      "Nathana\u00ebl Fijalkow",
      "Nathalie Bertrand",
      "Patricia Bouyer-Decitre",
      "Romain Brenguier",
      "Arnaud Carayol",
      "John Fearnley",
      "Hugo Gimbert",
      "Florian Horn",
      "Rasmus Ibsen-Jensen",
      "Nicolas Markey",
      "Benjamin Monmege",
      "Petr Novotn\u00fd",
      "Mickael Randour",
      "Ocan Sankur",
      "Sylvain Schmitz",
      "Olivier Serre",
      "Mateusz Skomra"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2305.10550",
    "title": "Sparsity-depth Tradeoff in Infinitely Wide Deep Neural Networks",
    "abstract": "We investigate how sparse neural activity affects the generalization performance of a deep Bayesian neural network at the large width limit. To this end, we derive a neural network Gaussian Process (NNGP) kernel with rectified linear unit (ReLU) activation and a predetermined fraction of active neurons. Using the NNGP kernel, we observe that the sparser networks outperform the non-sparse networks at shallow depths on a variety of datasets. We validate this observation by extending the existing theory on the generalization error of kernel-ridge regression. ",
    "url": "https://arxiv.org/abs/2305.10550",
    "authors": [
      "Chanwoo Chun",
      "Daniel D. Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2305.10553",
    "title": "Optimization and Portability of a Fusion OpenACC-based FORTRAN HPC Code  from NVIDIA to AMD GPUs",
    "abstract": "NVIDIA has been the main provider of GPU hardware in HPC systems for over a decade. Most applications that benefit from GPUs have thus been developed and optimized for the NVIDIA software stack. Recent exascale HPC systems are, however, introducing GPUs from other vendors, e.g. with the AMD GPU-based OLCF Frontier system just becoming available. AMD GPUs cannot be directly accessed using the NVIDIA software stack, and require a porting effort by the application developers. This paper provides an overview of our experience porting and optimizing the CGYRO code, a widely-used fusion simulation tool based on FORTRAN with OpenACC-based GPU acceleration. While the porting from the NVIDIA compilers was relatively straightforward using the CRAY compilers on the AMD systems, the performance optimization required more fine-tuning. In the optimization effort, we uncovered code sections that had performed well on NVIDIA GPUs, but were unexpectedly slow on AMD GPUs. After AMD-targeted code optimizations, performance on AMD GPUs has increased to meet our expectations. Modest speed improvements were also seen on NVIDIA GPUs, which was an unexpected benefit of this exercise. ",
    "url": "https://arxiv.org/abs/2305.10553",
    "authors": [
      "Igor Sfiligoi",
      "Emily A. Belli",
      "Jeff Candy",
      "Reuben D. Budiardja"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)",
      "Plasma Physics (physics.plasm-ph)"
    ]
  },
  {
    "id": "arXiv:2305.10563",
    "title": "Investigating the Effect of Hard Negative Sample Distribution on  Contrastive Knowledge Graph Embedding",
    "abstract": "The success of the knowledge graph completion task heavily depends on the quality of the knowledge graph embeddings (KGEs), which relies on self-supervised learning and augmenting the dataset with negative triples. There is a gap in literature between the theoretical analysis of negative samples on contrastive loss and heuristic generation of quality (i.e., hard) negative triples. In this paper, we modify the InfoNCE loss to explicitly account for the negative sample distribution. We show minimizing InfoNCE loss with hard negatives maximizes the KL-divergence between the given and negative triple embedding. However, we also show that hard negatives can lead to false negatives (i.e., accidentally factual triples) and reduce downstream task performance. To address this issue, we propose a novel negative sample distribution that uses the graph structure of the knowledge graph to remove the false negative triples. We call our algorithm Hardness and Structure-aware (\\textbf{HaSa}) contrastive KGE. Experiments show that our method outperforms state-of-the-art KGE methods in several metrics for WN18RR and FB15k-237 datasets. ",
    "url": "https://arxiv.org/abs/2305.10563",
    "authors": [
      "Honggen Zhang",
      "June Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.10565",
    "title": "Measurement Based Evaluation and Mitigation of Flood Attacks on a LAN  Test-Bed",
    "abstract": "The IoT's vulnerability to network attacks has motivated the design of intrusion detection schemes (IDS) using Machine Learning (ML), with a low computational cost for online detection but intensive offline learning. Such IDS can have high attack detection accuracy and are easily installed on servers that communicate with IoT devices. However, they are seldom evaluated in realistic operational conditions where IDS processing may be held up by the system overload created by attacks. Thus we first present an experimental study of UDP Flood Attacks on a Local Area Network Test-Bed, where the first line of defence is an accurate IDS using an Auto-Associative Dense Random Neural Network. The experiments reveal that during severe attacks, the packet and protocol management software overloads the multi-core server, and paralyses IDS detection. We therefore propose and experimentally evaluate an IDS design where decisions are made from a very small number of incoming packets, so that attacking traffic is dropped within milli-seconds after an attack begins and the paralysing effect of congestion is avoided. ",
    "url": "https://arxiv.org/abs/2305.10565",
    "authors": [
      "Mohammed Nasereddin",
      "Mert Nakip",
      "Erol Gelenbe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2305.10577",
    "title": "Revisiting the Complexity of and Algorithms for the Graph Traversal Edit  Distance and Its Variants",
    "abstract": "The graph traversal edit distance (GTED) is an elegant distance measure defined as the minimum edit distance between strings reconstructed from Eulerian trails in two edge-labeled graphs. GTED can be used to infer evolutionary relationships between species by comparing de Bruijn graphs directly without the computationally costly and error-prone process of genome assembly. Ebrahimpour Boroojeny et al.~(2018) suggest two ILP formulations for GTED and claim that GTED is polynomially solvable because the linear programming relaxation of one of the ILP always yields optimal integer solutions. The result that GTED is polynomially solvable is contradictory to the complexity results of existing string-to-graph matching problems. We resolve this conflict in complexity results by proving that GTED is NP-complete and showing that the ILPs proposed by Ebrahimpour Boroojeny et al. do not solve GTED but instead solve for a lower bound of GTED and are not solvable in polynomial time. In addition, we provide the first two, correct ILP formulations of GTED and evaluate their empirical efficiency. These results provide solid algorithmic foundations for comparing genome graphs and point to the direction of approximation heuristics. The source code to reproduce experimental results is available at https://github.com/Kingsford-Group/gtednewilp/. ",
    "url": "https://arxiv.org/abs/2305.10577",
    "authors": [
      "Yutong Qiu",
      "Yihang Shen",
      "Carl Kingsford"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Genomics (q-bio.GN)"
    ]
  },
  {
    "id": "arXiv:2305.10579",
    "title": "MultiPlaneNeRF: Neural Radiance Field with Non-Trainable Representation",
    "abstract": "NeRF is a popular model that efficiently represents 3D objects from 2D images. However, vanilla NeRF has a few important limitations. NeRF must be trained on each object separately. The training time is long since we encode the object's shape and color in neural network weights. Moreover, NeRF does not generalize well to unseen data. In this paper, we present MultiPlaneNeRF -- a first model that simultaneously solves all the above problems. Our model works directly on 2D images. We project 3D points on 2D images to produce non-trainable representations. The projection step is not parametrized, and a very shallow decoder can efficiently process the representation. Using existing images as part of NeRF can significantly reduce the number of parameters since we train only a small implicit decoder. Furthermore, we can train MultiPlaneNeRF on a large data set and force our implicit decoder to generalize across many objects. Consequently, we can only replace the 2D images (without additional training) to produce a NeRF representation of the new object. In the experimental section, we demonstrate that MultiPlaneNeRF achieves comparable results to state-of-the-art models for synthesizing new views and has generalization properties. ",
    "url": "https://arxiv.org/abs/2305.10579",
    "authors": [
      "Dominik Zimny",
      "Jacek Tabor",
      "Maciej Zi\u0119ba",
      "Przemys\u0142aw Spurek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10589",
    "title": "INCLG: Inpainting for Non-Cleft Lip Generation with a Multi-Task Image  Processing Network",
    "abstract": "We present a software that predicts non-cleft facial images for patients with cleft lip, thereby facilitating the understanding, awareness and discussion of cleft lip surgeries. To protect patients privacy, we design a software framework using image inpainting, which does not require cleft lip images for training, thereby mitigating the risk of model leakage. We implement a novel multi-task architecture that predicts both the non-cleft facial image and facial landmarks, resulting in better performance as evaluated by surgeons. The software is implemented with PyTorch and is usable with consumer-level color images with a fast prediction speed, enabling effective deployment. ",
    "url": "https://arxiv.org/abs/2305.10589",
    "authors": [
      "Shuang Chen",
      "Amir Atapour-Abarghouei",
      "Edmond S. L. Ho",
      "Hubert P. H. Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10593",
    "title": "Inverted Non-maximum Suppression for more Accurate and Neater Face  Detection",
    "abstract": "CNN-based face detection methods have achieved significant progress in recent years. In addition to the strong representation ability of CNN, post-processing methods are also very important for the performance of face detection. In general, the face detection method predicts several candidate bounding-boxes for one face. NMS is used to filter out inaccurate candidate boxes to get the most accurate box. The principle of NMS is to select the box with a higher score as the basic box and then delete the box which has a large overlapping area with the basic box but has a lower score. However, the current NMS method and its improved versions do not perform well when face image quality is poor or faces are in a cluster. In these situations, even after NMS filtering, there is often a face corresponding to multiple predicted boxes. To reduce this kind of negative result, in this paper, we propose a new NMS method that operates in the reverse order of other NMS methods. Our method performs well on low-quality and tiny face samples. Experiments demonstrate that our method is effective as a post-processor for different face detection methods. ",
    "url": "https://arxiv.org/abs/2305.10593",
    "authors": [
      "Lian Liu",
      "liguo Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10596",
    "title": "Towards Invisible Backdoor Attacks in the Frequency Domain against Deep  Neural Networks",
    "abstract": "Deep neural networks (DNNs) have made tremendous progress in the past ten years and have been applied in various critical applications. However, recent studies have shown that deep neural networks are vulnerable to backdoor attacks. By injecting malicious data into the training set, an adversary can plant the backdoor into the original model. The backdoor can remain hidden indefinitely until activated by a sample with a specific trigger, which is hugely concealed, bringing serious security risks to critical applications. However, one main limitation of current backdoor attacks is that the trigger is often visible to human perception. Therefore, it is crucial to study the stealthiness of backdoor triggers. In this paper, we propose a novel frequency-domain backdooring technique. In particular, our method aims to add a backdoor trigger in the frequency domain of original images via Discrete Fourier Transform, thus hidding the trigger. We evaluate our method on three benchmark datasets: MNIST, CIFAR-10 and Imagenette. Our experiments show that we can simultaneously fool human inspection and DNN models. We further apply two image similarity evaluation metrics to illustrate that our method adds the most subtle perturbation without compromising attack success rate and clean sample accuracy. ",
    "url": "https://arxiv.org/abs/2305.10596",
    "authors": [
      "Xinrui Liu",
      "Yajie Wang",
      "Yu-an Tan",
      "Kefan Qiu",
      "Yuanzhang Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.10613",
    "title": "Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context  Learning",
    "abstract": "Temporal knowledge graph (TKG) forecasting benchmarks challenge models to predict future facts using knowledge of past facts. In this paper, we apply large language models (LLMs) to these benchmarks using in-context learning (ICL). We investigate whether and to what extent LLMs can be used for TKG forecasting, especially without any fine-tuning or explicit modules for capturing structural and temporal information. For our experiments, we present a framework that converts relevant historical facts into prompts and generates ranked predictions using token probabilities. Surprisingly, we observe that LLMs, out-of-the-box, perform on par with state-of-the-art TKG models carefully designed and trained for TKG forecasting. Our extensive evaluation presents performances across several models and datasets with different characteristics, compares alternative heuristics for preparing contextual information, and contrasts to prominent TKG methods and simple frequency and recency baselines. We also discover that using numerical indices instead of entity/relation names, i.e., hiding semantic information, does not significantly affect the performance ($\\pm$0.4\\% Hit@1). This shows that prior semantic knowledge is unnecessary; instead, LLMs can leverage the existing patterns in the context to achieve such performance. Our analysis also reveals that ICL enables LLMs to learn irregular patterns from the historical context, going beyond simple predictions based on common or recent information. ",
    "url": "https://arxiv.org/abs/2305.10613",
    "authors": [
      "Dong-Ho Lee",
      "Kian Ahrabian",
      "Woojeong Jin",
      "Fred Morstatter",
      "Jay Pujara"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.10618",
    "title": "Fault-Tolerant Consensus in Quantum Networks",
    "abstract": "Fault-tolerant consensus is about reaching agreement on some of the input values in a limited time by non-faulty autonomous processes, despite of failures of processes or communication medium. This problem is particularly challenging and costly against an adaptive adversary with full information. Bar-Joseph and Ben-Or (PODC'98) were the first who proved an absolute lower bound $\\Omega(\\sqrt{n/\\log n})$ on expected time complexity of consensus in any classic (i.e., randomized or deterministic) message-passing network with $n$ processes succeeding with probability $1$ against such a strong adaptive adversary crashing processes. Seminal work of Ben-Or and Hassidim (STOC'05) broke the $\\Omega(\\sqrt{n/\\log n})$ barrier for consensus in classic (deterministic and randomized) networks by employing quantum computing. They showed an (expected) constant-time quantum algorithm for a linear number of crashes $t<n/3$. In this paper, we improve upon that seminal work by reducing the number of quantum and communication bits to an arbitrarily small polynomial, and even more, to a polylogarithmic number -- though, the latter in the cost of a slightly larger polylogarithmic time (still exponentially smaller than the time lower bound $\\Omega(\\sqrt{n/\\log n})$ for classic computation). ",
    "url": "https://arxiv.org/abs/2305.10618",
    "authors": [
      "MohammadTaghi Hajiaghayi",
      "Dariusz R. Kowalski",
      "Jan Olkowski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2305.10621",
    "title": "TSoR: TCP Socket over RDMA Container Network for Cloud Native Computing",
    "abstract": "Cloud-native containerized applications constantly seek high-performance and easy-to-operate container network solutions. RDMA network is a potential enabler with higher throughput and lower latency than the standard TCP/IP network stack. However, several challenges remain in equipping containerized applications with RDMA network: 1) How to deliver transparent improvements without modifying application code; 2) How to integrate RDMA-based network solutions with container orchestration systems; 3) How to efficiently utilize RDMA for container networks. In this paper, we present an RDMA-based container network solution, TCP Socket over RDMA (TSoR), which addresses all the above challenges. To transparently accelerate applications using POSIX socket interfaces without modifications, we integrate TSoR with a container runtime that can intercept system calls for socket interfaces. To be compatible with orchestration systems like Kubernetes, TSoR implements a container network following the Kubernetes network model and satisfies all requirements of the model. To leverage RDMA benefits, TSoR designs a high-performance network stack that efficiently transfers TCP traffic using RDMA network. Thus, TSoR provides a turn-key solution for existing Kubernetes clusters to adopt the high-performance RDMA network with minimal effort. Our evaluation results show that TSoR provides up to 2.3x higher throughput and 64\\% lower latency for existing containerized applications, such as Redis key-value store and Node.js web server, with no code changes. TSoR code will be open-sourced. ",
    "url": "https://arxiv.org/abs/2305.10621",
    "authors": [
      "Yulin Sun",
      "Qingming Qu",
      "Chenxingyu Zhao",
      "Arvind Krishnamurthy",
      "Hong Chang",
      "Ying Xiong"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2305.10625",
    "title": "Measuring and Mitigating Local Instability in Deep Neural Networks",
    "abstract": "Deep Neural Networks (DNNs) are becoming integral components of real world services relied upon by millions of users. Unfortunately, architects of these systems can find it difficult to ensure reliable performance as irrelevant details like random initialization can unexpectedly change the outputs of a trained system with potentially disastrous consequences. We formulate the model stability problem by studying how the predictions of a model change, even when it is retrained on the same data, as a consequence of stochasticity in the training process. For Natural Language Understanding (NLU) tasks, we find instability in predictions for a significant fraction of queries. We formulate principled metrics, like per-sample ``label entropy'' across training runs or within a single training run, to quantify this phenomenon. Intriguingly, we find that unstable predictions do not appear at random, but rather appear to be clustered in data-specific ways. We study data-agnostic regularization methods to improve stability and propose new data-centric methods that exploit our local stability estimates. We find that our localized data-specific mitigation strategy dramatically outperforms data-agnostic methods, and comes within 90% of the gold standard, achieved by ensembling, at a fraction of the computational cost ",
    "url": "https://arxiv.org/abs/2305.10625",
    "authors": [
      "Arghya Datta",
      "Subhrangshu Nandi",
      "Jingcheng Xu",
      "Greg Ver Steeg",
      "He Xie",
      "Anoop Kumar",
      "Aram Galstyan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10638",
    "title": "Incremental Causal Graph Learning for Online Unsupervised Root Cause  Analysis",
    "abstract": "The task of root cause analysis (RCA) is to identify the root causes of system faults/failures by analyzing system monitoring data. Efficient RCA can greatly accelerate system failure recovery and mitigate system damages or financial losses. However, previous research has mostly focused on developing offline RCA algorithms, which often require manually initiating the RCA process, a significant amount of time and data to train a robust model, and then being retrained from scratch for a new system fault. In this paper, we propose CORAL, a novel online RCA framework that can automatically trigger the RCA process and incrementally update the RCA model. CORAL consists of Trigger Point Detection, Incremental Disentangled Causal Graph Learning, and Network Propagation-based Root Cause Localization. The Trigger Point Detection component aims to detect system state transitions automatically and in near-real-time. To achieve this, we develop an online trigger point detection approach based on multivariate singular spectrum analysis and cumulative sum statistics. To efficiently update the RCA model, we propose an incremental disentangled causal graph learning approach to decouple the state-invariant and state-dependent information. After that, CORAL applies a random walk with restarts to the updated causal graph to accurately identify root causes. The online RCA process terminates when the causal graph and the generated root cause list converge. Extensive experiments on three real-world datasets with case studies demonstrate the effectiveness and superiority of the proposed framework. ",
    "url": "https://arxiv.org/abs/2305.10638",
    "authors": [
      "Dongjie Wang",
      "Zhengzhang Chen",
      "Yanjie Fu",
      "Yanchi Liu",
      "Haifeng Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.10647",
    "title": "BioAug: Conditional Generation based Data Augmentation for Low-Resource  Biomedical NER",
    "abstract": "Biomedical Named Entity Recognition (BioNER) is the fundamental task of identifying named entities from biomedical text. However, BioNER suffers from severe data scarcity and lacks high-quality labeled data due to the highly specialized and expert knowledge required for annotation. Though data augmentation has shown to be highly effective for low-resource NER in general, existing data augmentation techniques fail to produce factual and diverse augmentations for BioNER. In this paper, we present BioAug, a novel data augmentation framework for low-resource BioNER. BioAug, built on BART, is trained to solve a novel text reconstruction task based on selective masking and knowledge augmentation. Post training, we perform conditional generation and generate diverse augmentations conditioning BioAug on selectively corrupted text similar to the training stage. We demonstrate the effectiveness of BioAug on 5 benchmark BioNER datasets and show that BioAug outperforms all our baselines by a significant margin (1.5%-21.5% absolute improvement) and is able to generate augmentations that are both more factual and diverse. Code: https://github.com/Sreyan88/BioAug. ",
    "url": "https://arxiv.org/abs/2305.10647",
    "authors": [
      "Sreyan Ghosh",
      "Utkarsh Tyagi",
      "Sonal Kumar",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2305.10665",
    "title": "Content-based Unrestricted Adversarial Attack",
    "abstract": "Unrestricted adversarial attacks typically manipulate the semantic content of an image (e.g., color or texture) to create adversarial examples that are both effective and photorealistic, demonstrating their ability to deceive human perception and deep neural networks with stealth and success. However, current works usually sacrifice unrestricted degrees and subjectively select some image content to guarantee the photorealism of unrestricted adversarial examples, which limits its attack performance. To ensure the photorealism of adversarial examples and boost attack performance, we propose a novel unrestricted attack framework called Content-based Unrestricted Adversarial Attack. By leveraging a low-dimensional manifold that represents natural images, we map the images onto the manifold and optimize them along its adversarial direction. Therefore, within this framework, we implement Adversarial Content Attack based on Stable Diffusion and can generate high transferable unrestricted adversarial examples with various adversarial contents. Extensive experimentation and visualization demonstrate the efficacy of ACA, particularly in surpassing state-of-the-art attacks by an average of 13.3-50.4% and 16.8-48.0% in normally trained models and defense methods, respectively. ",
    "url": "https://arxiv.org/abs/2305.10665",
    "authors": [
      "Zhaoyu Chen",
      "Bo Li",
      "Shuang Wu",
      "Kaixun Jiang",
      "Shouhong Ding",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.10668",
    "title": "MetaGAD: Learning to Meta Transfer for Few-shot Graph Anomaly Detection",
    "abstract": "Graph anomaly detection has long been an important problem in various domains pertaining to information security such as financial fraud, social spam, network intrusion, etc. The majority of existing methods are performed in an unsupervised manner, as labeled anomalies in a large scale are often too expensive to acquire. However, the identified anomalies may turn out to be data noises or uninteresting data instances due to the lack of prior knowledge on the anomalies. In realistic scenarios, it is often feasible to obtain limited labeled anomalies, which have great potential to advance graph anomaly detection. However, the work exploring limited labeled anomalies and a large amount of unlabeled nodes in graphs to detect anomalies is rather limited. Therefore, in this paper, we study a novel problem of few-shot graph anomaly detection. We propose a new framework MetaGAD to learn to meta-transfer the knowledge between unlabeled and labeled nodes for graph anomaly detection. Experimental results on six real-world datasets with synthetic anomalies and \"organic\" anomalies (available in the dataset) demonstrate the effectiveness of the proposed approach in detecting anomalies with limited labeled anomalies. ",
    "url": "https://arxiv.org/abs/2305.10668",
    "authors": [
      "Xiongxiao Xu",
      "Kaize Ding",
      "Canyu Chen",
      "Kai Shu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.10673",
    "title": "Less Can Be More: Unsupervised Graph Pruning for Large-scale Dynamic  Graphs",
    "abstract": "The prevalence of large-scale graphs poses great challenges in time and storage for training and deploying graph neural networks (GNNs). Several recent works have explored solutions for pruning the large original graph into a small and highly-informative one, such that training and inference on the pruned and large graphs have comparable performance. Although empirically effective, current researches focus on static or non-temporal graphs, which are not directly applicable to dynamic scenarios. In addition, they require labels as ground truth to learn the informative structure, limiting their applicability to new problem domains where labels are hard to obtain. To solve the dilemma, we propose and study the problem of unsupervised graph pruning on dynamic graphs. We approach the problem by our proposed STEP, a self-supervised temporal pruning framework that learns to remove potentially redundant edges from input dynamic graphs. From a technical and industrial viewpoint, our method overcomes the trade-offs between the performance and the time & memory overheads. Our results on three real-world datasets demonstrate the advantages on improving the efficacy, robustness, and efficiency of GNNs on dynamic node classification tasks. Most notably, STEP is able to prune more than 50% of edges on a million-scale industrial graph Alipay (7M nodes, 21M edges) while approximating up to 98% of the original performance. Code is available at https://github.com/EdisonLeeeee/STEP. ",
    "url": "https://arxiv.org/abs/2305.10673",
    "authors": [
      "Jintang Li",
      "Sheng Tian",
      "Ruofan Wu",
      "Liang Zhu",
      "Welong Zhao",
      "Changhua Meng",
      "Liang Chen",
      "Zibin Zheng",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.10679",
    "title": "Think Outside the Code: Brainstorming Boosts Large Language Models in  Code Generation",
    "abstract": "Code generation aims to automatically generate source code from high-level task specifications, which can significantly increase productivity of software engineering. Recently, approaches based on large language models (LLMs) have shown remarkable code generation abilities on simple tasks. However, generate code for more complex tasks, such as competition-level problems, remains challenging. In this paper, we introduce Brainstorm framework for code generation. It leverages a brainstorming step that generates and selects diverse thoughts on the problem to facilitate algorithmic reasoning, where the thoughts are possible blueprint of solving the problem. We demonstrate that Brainstorm significantly enhances the ability of LLMs to solve competition-level programming problems, resulting in a more than 50% increase in the pass@$k$ metrics for ChatGPT on the CodeContests benchmark, achieving state-of-the-art performance. Furthermore, our experiments conducted on LeetCode contests show that our framework boosts the ability of ChatGPT to a level comparable to that of human programmers. ",
    "url": "https://arxiv.org/abs/2305.10679",
    "authors": [
      "Xin-Ye Li",
      "Jiang-Tian Xue",
      "Zheng Xie",
      "Ming Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.10681",
    "title": "Black-Box Targeted Reward Poisoning Attack Against Online Deep  Reinforcement Learning",
    "abstract": "We propose the first black-box targeted attack against online deep reinforcement learning through reward poisoning during training time. Our attack is applicable to general environments with unknown dynamics learned by unknown algorithms and requires limited attack budgets and computational resources. We leverage a general framework and find conditions to ensure efficient attack under a general assumption of the learning algorithms. We show that our attack is optimal in our framework under the conditions. We experimentally verify that with limited budgets, our attack efficiently leads the learning agent to various target policies under a diverse set of popular DRL environments and state-of-the-art learners. ",
    "url": "https://arxiv.org/abs/2305.10681",
    "authors": [
      "Yinglun Xu",
      "Gagandeep Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.10691",
    "title": "Re-thinking Data Availablity Attacks Against Deep Neural Networks",
    "abstract": "The unauthorized use of personal data for commercial purposes and the clandestine acquisition of private data for training machine learning models continue to raise concerns. In response to these issues, researchers have proposed availability attacks that aim to render data unexploitable. However, many current attack methods are rendered ineffective by adversarial training. In this paper, we re-examine the concept of unlearnable examples and discern that the existing robust error-minimizing noise presents an inaccurate optimization objective. Building on these observations, we introduce a novel optimization paradigm that yields improved protection results with reduced computational time requirements. We have conducted extensive experiments to substantiate the soundness of our approach. Moreover, our method establishes a robust foundation for future research in this area. ",
    "url": "https://arxiv.org/abs/2305.10691",
    "authors": [
      "Bin Fang",
      "Bo Li",
      "Shuang Wu",
      "Ran Yi",
      "Shouhong Ding",
      "Lizhuang Ma"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10701",
    "title": "Zero-Day Backdoor Attack against Text-to-Image Diffusion Models via  Personalization",
    "abstract": "Although recent personalization methods have democratized high-resolution image synthesis by enabling swift concept acquisition with minimal examples and lightweight computation, they also present an exploitable avenue for high accessible backdoor attacks. This paper investigates a critical and unexplored aspect of text-to-image (T2I) diffusion models - their potential vulnerability to backdoor attacks via personalization. Our study focuses on a zero-day backdoor vulnerability prevalent in two families of personalization methods, epitomized by Textual Inversion and DreamBooth.Compared to traditional backdoor attacks, our proposed method can facilitate more precise, efficient, and easily accessible attacks with a lower barrier to entry. We provide a comprehensive review of personalization in T2I diffusion models, highlighting the operation and exploitation potential of this backdoor vulnerability. To be specific, by studying the prompt processing of Textual Inversion and DreamBooth, we have devised dedicated backdoor attacks according to the different ways of dealing with unseen tokens and analyzed the influence of triggers and concept images on the attack effect. Our empirical study has shown that the nouveau-token backdoor attack has better attack performance while legacy-token backdoor attack is potentially harder to defend. ",
    "url": "https://arxiv.org/abs/2305.10701",
    "authors": [
      "Yihao Huang",
      "Qing Guo",
      "Felix Juefei-Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10704",
    "title": "Attention-based Encoder-Decoder Network for End-to-End Neural Speaker  Diarization with Target Speaker Attractor",
    "abstract": "This paper proposes a novel Attention-based Encoder-Decoder network for End-to-End Neural speaker Diarization (AED-EEND). In AED-EEND system, we incorporate the target speaker enrollment information used in target speaker voice activity detection (TS-VAD) to calculate the attractor, which can mitigate the speaker permutation problem and facilitate easier model convergence. In the training process, we propose a teacher-forcing strategy to obtain the enrollment information using the ground-truth label. Furthermore, we propose three heuristic decoding methods to identify the enrollment area for each speaker during the evaluation process. Additionally, we enhance the attractor calculation network LSTM used in the end-to-end encoder-decoder based attractor calculation (EEND-EDA) system by incorporating an attention-based model. By utilizing such an attention-based attractor decoder, our proposed AED-EEND system outperforms both the EEND-EDA and TS-VAD systems with only 0.5s of enrollment data. ",
    "url": "https://arxiv.org/abs/2305.10704",
    "authors": [
      "Zhengyang Chen",
      "Bing Han",
      "Shuai Wang",
      "Yanmin Qian"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.10738",
    "title": "Deep Temporal Graph Clustering",
    "abstract": "Deep graph clustering has recently received significant attention due to its ability to enhance the representation learning capabilities of models in unsupervised scenarios. Nevertheless, deep clustering for temporal graphs, which could capture crucial dynamic interaction information, has not been fully explored. It means that in many clustering-oriented real-world scenarios, temporal graphs can only be processed as static graphs. This not only causes the loss of dynamic information but also triggers huge computational consumption. To solve the problem, we propose a general framework for deep Temporal Graph Clustering called TGC, which adjusts deep clustering techniques (clustering assignment distribution and adjacency matrix reconstruction) to suit the interaction sequence-based batch-processing pattern of temporal graphs. In addition, we discuss differences between temporal graph clustering and existing static graph clustering from several levels. To verify the superiority of the proposed framework TGC, we conduct extensive experiments. The experimental results show that temporal graph clustering enables more flexibility in finding a balance between time and space requirements, and our framework can effectively improve the performance of existing temporal graph learning methods. Our code and supplementary material will be released after publication. ",
    "url": "https://arxiv.org/abs/2305.10738",
    "authors": [
      "Meng Liu",
      "Yue Liu",
      "Ke Liang",
      "Siwei Wang",
      "Sihang Zhou",
      "Xinwang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.10747",
    "title": "Strong Structural Controllability of Structured Networks with MIMO node  systems",
    "abstract": "The article addresses the problem of strong structural controllability of structured networks with multi-input multi-output (MIMO) node systems. The authors first present necessary and sufficient conditions for strong structural controllability, which involve both algebraic and graph-theoretic aspects. These conditions are computationally expensive, especially for large-scale networks with high-dimensional state spaces. To overcome this computational complexity, we propose a necessary algebraic condition from a node system's perspective and a graph-theoretic condition from a network topology's perspective. The latter condition is derived from the structured interconnection laws and employs a new color change rule, namely weakly color change rule introduced in this paper. Overall, this article contributes to the study of strong structural controllability in structured networks with MIMO node systems, providing both theoretical and practical insights for their analysis and design. ",
    "url": "https://arxiv.org/abs/2305.10747",
    "authors": [
      "Yanting Ni",
      "Xuyang Lou",
      "Junjie Jiao",
      "Jiajia Jia"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.10758",
    "title": "Extracting Low-/High- Frequency Knowledge from Graph Neural Networks and  Injecting it into MLPs: An Effective GNN-to-MLP Distillation Framework",
    "abstract": "Recent years have witnessed the great success of Graph Neural Networks (GNNs) in handling graph-related tasks. However, MLPs remain the primary workhorse for practical industrial applications due to their desirable inference efficiency and scalability. To reduce their gaps, one can directly distill knowledge from a well-designed teacher GNN to a student MLP, which is termed as GNN-to-MLP distillation. However, the process of distillation usually entails a loss of information, and ``which knowledge patterns of GNNs are more likely to be left and distilled into MLPs?\" becomes an important question. In this paper, we first factorize the knowledge learned by GNNs into low- and high-frequency components in the spectral domain and then derive their correspondence in the spatial domain. Furthermore, we identified a potential information drowning problem for existing GNN-to-MLP distillation, i.e., the high-frequency knowledge of the pre-trained GNNs may be overwhelmed by the low-frequency knowledge during distillation; we have described in detail what it represents, how it arises, what impact it has, and how to deal with it. In this paper, we propose an efficient Full-Frequency GNN-to-MLP (FF-G2M) distillation framework, which extracts both low-frequency and high-frequency knowledge from GNNs and injects it into MLPs. Extensive experiments show that FF-G2M improves over the vanilla MLPs by 12.6% and outperforms its corresponding teacher GNNs by 2.6% averaged over six graph datasets and three common GNN architectures. ",
    "url": "https://arxiv.org/abs/2305.10758",
    "authors": [
      "Lirong Wu",
      "Haitao Lin",
      "Yufei Huang",
      "Tianyu Fan",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10764",
    "title": "OpenShape: Scaling Up 3D Shape Representation Towards Open-World  Understanding",
    "abstract": "We introduce OpenShape, a method for learning multi-modal joint representations of text, image, and point clouds. We adopt the commonly used multi-modal contrastive learning framework for representation alignment, but with a specific focus on scaling up 3D representations to enable open-world 3D shape understanding. To achieve this, we scale up training data by ensembling multiple 3D datasets and propose several strategies to automatically filter and enrich noisy text descriptions. We also explore and compare strategies for scaling 3D backbone networks and introduce a novel hard negative mining module for more efficient training. We evaluate OpenShape on zero-shot 3D classification benchmarks and demonstrate its superior capabilities for open-world recognition. Specifically, OpenShape achieves a zero-shot accuracy of 46.8% on the 1,156-category Objaverse-LVIS benchmark, compared to less than 10% for existing methods. OpenShape also achieves an accuracy of 85.3% on ModelNet40, outperforming previous zero-shot baseline methods by 20% and performing on par with some fully-supervised methods. Furthermore, we show that our learned embeddings encode a wide range of visual and semantic concepts (e.g., subcategories, color, shape, style) and facilitate fine-grained text-3D and image-3D interactions. Due to their alignment with CLIP embeddings, our learned shape representations can also be integrated with off-the-shelf CLIP-based models for various applications, such as point cloud captioning and point cloud-conditioned image generation. ",
    "url": "https://arxiv.org/abs/2305.10764",
    "authors": [
      "Minghua Liu",
      "Ruoxi Shi",
      "Kaiming Kuang",
      "Yinhao Zhu",
      "Xuanlin Li",
      "Shizhong Han",
      "Hong Cai",
      "Fatih Porikli",
      "Hao Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10766",
    "title": "Adversarial Amendment is the Only Force Capable of Transforming an Enemy  into a Friend",
    "abstract": "Adversarial attack is commonly regarded as a huge threat to neural networks because of misleading behavior. This paper presents an opposite perspective: adversarial attacks can be harnessed to improve neural models if amended correctly. Unlike traditional adversarial defense or adversarial training schemes that aim to improve the adversarial robustness, the proposed adversarial amendment (AdvAmd) method aims to improve the original accuracy level of neural models on benign samples. We thoroughly analyze the distribution mismatch between the benign and adversarial samples. This distribution mismatch and the mutual learning mechanism with the same learning ratio applied in prior art defense strategies is the main cause leading the accuracy degradation for benign samples. The proposed AdvAmd is demonstrated to steadily heal the accuracy degradation and even leads to a certain accuracy boost of common neural models on benign classification, object detection, and segmentation tasks. The efficacy of the AdvAmd is contributed by three key components: mediate samples (to reduce the influence of distribution mismatch with a fine-grained amendment), auxiliary batch norm (to solve the mutual learning mechanism and the smoother judgment surface), and AdvAmd loss (to adjust the learning ratios according to different attack vulnerabilities) through quantitative and ablation experiments. ",
    "url": "https://arxiv.org/abs/2305.10766",
    "authors": [
      "Chong Yu",
      "Tao Chen",
      "Zhongxue Gan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10771",
    "title": "Seq-HGNN: Learning Sequential Node Representation on Heterogeneous Graph",
    "abstract": "Recent years have witnessed the rapid development of heterogeneous graph neural networks (HGNNs) in information retrieval (IR) applications. Many existing HGNNs design a variety of tailor-made graph convolutions to capture structural and semantic information in heterogeneous graphs. However, existing HGNNs usually represent each node as a single vector in the multi-layer graph convolution calculation, which makes the high-level graph convolution layer fail to distinguish information from different relations and different orders, resulting in the information loss in the message passing. %insufficient mining of information. To this end, we propose a novel heterogeneous graph neural network with sequential node representation, namely Seq-HGNN. To avoid the information loss caused by the single vector node representation, we first design a sequential node representation learning mechanism to represent each node as a sequence of meta-path representations during the node message passing. Then we propose a heterogeneous representation fusion module, empowering Seq-HGNN to identify important meta-paths and aggregate their representations into a compact one. We conduct extensive experiments on four widely used datasets from Heterogeneous Graph Benchmark (HGB) and Open Graph Benchmark (OGB). Experimental results show that our proposed method outperforms state-of-the-art baselines in both accuracy and efficiency. The source code is available at https://github.com/nobrowning/SEQ_HGNN. ",
    "url": "https://arxiv.org/abs/2305.10771",
    "authors": [
      "Chenguang Du",
      "Kaichun Yao",
      "Hengshu Zhu",
      "Deqing Wang",
      "Fuzhen Zhuang",
      "Hui Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10791",
    "title": "BrutePrint: Expose Smartphone Fingerprint Authentication to Brute-force  Attack",
    "abstract": "Fingerprint authentication has been widely adopted on smartphones to complement traditional password authentication, making it a tempting target for attackers. The smartphone industry is fully aware of existing threats, and especially for the presentation attack studied by most prior works, the threats are nearly eliminated by liveness detection and attempt limit. In this paper, we study the seemingly impossible fingerprint brute-force attack on off-the-shelf smartphones and propose a generic attack framework. We implement BrutePrint to automate the attack, that acts as a middleman to bypass attempt limit and hijack fingerprint images. Specifically, the bypassing exploits two zero-day vulnerabilities in smartphone fingerprint authentication (SFA) framework, and the hijacking leverages the simplicity of SPI protocol. Moreover, we consider a practical cross-device attack scenario and tackle the liveness and matching problems with neural style transfer (NST). We also propose a method based on neural style transfer to generate valid brute-forcing inputs from arbitrary fingerprint images. A case study shows that we always bypasses liveness detection and attempt limit while 71% spoofs are accepted. We evaluate BrutePrint on 10 representative smartphones from top-5 vendors and 3 typical types of applications involving screen lock, payment, and privacy. As all of them are vulnerable to some extent, fingerprint brute-force attack is validated on on all devices except iPhone, where the shortest time to unlock the smartphone without prior knowledge about the victim is estimated at 40 minutes. Furthermore, we suggest software and hardware mitigation measures. ",
    "url": "https://arxiv.org/abs/2305.10791",
    "authors": [
      "Yu Chen",
      "Yiling He"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.10794",
    "title": "Multi-spectral Class Center Network for Face Manipulation Detection and  Localization",
    "abstract": "As Deepfake contents continue to proliferate on the internet, advancing face manipulation forensics has become a pressing issue. To combat this emerging threat, previous methods mainly focus on studying how to distinguish authentic and manipulated face images. Despite impressive, image-level classification lacks explainability and is limited to some specific application scenarios. Existing forgery localization methods suffer from imprecise and inconsistent pixel-level annotations. To alleviate these problems, this paper first re-constructs the FaceForensics++ dataset by introducing pixel-level annotations, then builds an extensive benchmark for localizing tampered regions. Next, a novel Multi-Spectral Class Center Network (MSCCNet) is proposed for face manipulation detection and localization. Specifically, inspired by the power of frequency-related forgery traces, we design Multi-Spectral Class Center (MSCC) module to learn more generalizable and semantic-agnostic features. Based on the features of different frequency bands, the MSCC module collects multispectral class centers and computes pixel-to-class relations. Applying multi-spectral class-level representations suppresses the semantic information of the visual concepts, which is insensitive to manipulations. Furthermore, we propose a Multi-level Features Aggregation (MFA) module to employ more low-level forgery artifacts and structure textures. Experimental results quantitatively and qualitatively indicate the effectiveness and superiority of the proposed MSCCNet on comprehensive localization benchmarks. We expect this work to inspire more studies on pixel-level face manipulation localization. The annotations and code will be available. ",
    "url": "https://arxiv.org/abs/2305.10794",
    "authors": [
      "Changtao Miao",
      "Qi Chu",
      "Zhentao Tan",
      "Zhenchao Jin",
      "Wanyi Zhuang",
      "Yue Wu",
      "Bin Liu",
      "Honggang Hu",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10800",
    "title": "Joint BS Mode Selection and Beamforming Design for Cooperative Cell-Free  ISAC Networks",
    "abstract": "Owing to the promising ability of saving hardware cost and spectrum resources, integrated sensing and communication (ISAC) is regarded as a revolutionary technology for future sixth-generation (6G) networks. The mono-static ISAC systems considered in most of existing works can only obtain limited sensing performance due to the single observation angle and easily blocked transmission links, which motivates researchers to investigate cooperative ISAC networks. In order to further improve the degrees of freedom (DoFs) of cooperative ISAC networks, the transmitter-receiver selection, i.e., BS mode selection problem, is meaningful to be studied. However, to our best knowledge, this crucial problem has not been extensively studied in existing works. In this paper, we consider the joint BS mode selection, transmit beamforming, and receive filter design for cooperative cell-free ISAC networks, where multi-base stations (BSs) cooperatively serve communication users and detect targets. We aim to maximize the sum of sensing signal-to-interference-plus-noise ratio (SINR) under the communication SINR requirements, total power budget, and constraints on the numbers of transmitters and receivers. An efficient joint beamforming design algorithm and three different heuristic BS mode selection methods are proposed to solve this non-convex NP-hard problem. Simulation results demonstrates the advantages of cooperative ISAC networks, the importance of BS mode selection, and the effectiveness of our proposed joint design algorithms. ",
    "url": "https://arxiv.org/abs/2305.10800",
    "authors": [
      "Sifan Liu",
      "Ming Li",
      "Qian Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.10801",
    "title": "Selecting Learnable Training Samples is All DETRs Need in Crowded  Pedestrian Detection",
    "abstract": "DEtection TRansformer (DETR) and its variants (DETRs) achieved impressive performance in general object detection. However, in crowded pedestrian detection, the performance of DETRs is still unsatisfactory due to the inappropriate sample selection method which results in more false positives. To settle the issue, we propose a simple but effective sample selection method for DETRs, Sample Selection for Crowded Pedestrians (SSCP), which consists of the constraint-guided label assignment scheme (CGLA) and the utilizability-aware focal loss (UAFL). Our core idea is to select learnable samples for DETRs and adaptively regulate the loss weights of samples based on their utilizability. Specifically, in CGLA, we proposed a new cost function to ensure that only learnable positive training samples are retained and the rest are negative training samples. Further, considering the utilizability of samples, we designed UAFL to adaptively assign different loss weights to learnable positive samples depending on their gradient ratio and IoU. Experimental results show that the proposed SSCP effectively improves the baselines without introducing any overhead in inference. Especially, Iter Deformable DETR is improved to 39.7(-2.0)% MR on Crowdhuman and 31.8(-0.4)% MR on Citypersons. ",
    "url": "https://arxiv.org/abs/2305.10801",
    "authors": [
      "Feng Gao",
      "Jiaxu Leng",
      "Gan Ji",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10809",
    "title": "CS-TRD: a Cross Sections Tree Ring Detection method",
    "abstract": "This work describes a Tree Ring Detection method for complete Cross-Sections of trees (CS-TRD). The method is based on the detection, processing, and connection of edges corresponding to the tree's growth rings. The method depends on the parameters for the Canny Devernay edge detector ($\\sigma$ and two thresholds), a resize factor, the number of rays, and the pith location. The first five parameters are fixed by default. The pith location can be marked manually or using an automatic pith detection algorithm. Besides the pith localization, the CS-TRD method is fully automated and achieves an F-Score of 89\\% in the UruDendro dataset (of Pinus Taeda) with a mean execution time of 17 seconds and of 97\\% in the Kennel dataset (of Abies Alba) with an average execution time 11 seconds. ",
    "url": "https://arxiv.org/abs/2305.10809",
    "authors": [
      "Henry Marichal",
      "Diego Passarella",
      "Gregory Randall"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2305.10822",
    "title": "When Search Meets Recommendation: Learning Disentangled Search  Representation for Recommendation",
    "abstract": "Modern online service providers such as online shopping platforms often provide both search and recommendation (S&R) services to meet different user needs. Rarely has there been any effective means of incorporating user behavior data from both S&R services. Most existing approaches either simply treat S&R behaviors separately, or jointly optimize them by aggregating data from both services, ignoring the fact that user intents in S&R can be distinctively different. In our paper, we propose a Search-Enhanced framework for the Sequential Recommendation (SESRec) that leverages users' search interests for recommendation, by disentangling similar and dissimilar representations within S&R behaviors. Specifically, SESRec first aligns query and item embeddings based on users' query-item interactions for the computations of their similarities. Two transformer encoders are used to learn the contextual representations of S&R behaviors independently. Then a contrastive learning task is designed to supervise the disentanglement of similar and dissimilar representations from behavior sequences of S&R. Finally, we extract user interests by the attention mechanism from three perspectives, i.e., the contextual representations, the two separated behaviors containing similar and dissimilar interests. Extensive experiments on both industrial and public datasets demonstrate that SESRec consistently outperforms state-of-the-art models. Empirical studies further validate that SESRec successfully disentangle similar and dissimilar user interests from their S&R behaviors. ",
    "url": "https://arxiv.org/abs/2305.10822",
    "authors": [
      "Zihua Si",
      "Zhongxiang Sun",
      "Xiao Zhang",
      "Jun Xu",
      "Xiaoxue Zang",
      "Yang Song",
      "Kun Gai",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.10826",
    "title": "GraphMoco:a Graph Momentum Contrast Model that Using Multimodel  Structure Information for Large-scale Binary Function Representation Learning",
    "abstract": "The ability to compute similarity scores of binary code at the function level is essential for cyber security. A single binary file can contain tens of thousands of functions. A deployable learning framework for cybersecurity applications needs to work not only accurately but also efficiently with large amounts of data. Traditional methods suffer from two drawbacks. First, it is very difficult to annotate different pairs of functions with accurate labels. These supervised learning methods can easily be overtrained with inaccurate labels. The second is that they either use the pre-trained encoder or use the fine-grained graph comparison. However, these methods have shortcomings in terms of time or memory consumption. We focus on large-scale Binary Code Similarity Detection (BCSD) and to mitigate the traditional problems, we propose GraphMoco: a graph momentum contrast model that uses multimodal structure information for large-scale binary function representation learning. We take an unsupervised learning approach and make full use of the structural information in the binary code. It does not require manually labelled similar or dissimilar information. Our models perform efficiently on large amounts of training data. Our experimental results show that our method outperforms the state-of-the-art in terms of accuracy. ",
    "url": "https://arxiv.org/abs/2305.10826",
    "authors": [
      "Sun RuiJin",
      "Guo ShiZe",
      "Guo Xi",
      "Pan ZhiSong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.10837",
    "title": "Adaptive Graph Contrastive Learning for Recommendation",
    "abstract": "Recently, graph neural networks (GNNs) have been successfully applied to recommender systems as an effective collaborative filtering (CF) approach. The key idea of GNN-based recommender system is to recursively perform the message passing along the user-item interaction edge for refining the encoded embeddings, relying on sufficient and high-quality training data. Since user behavior data in practical recommendation scenarios is often noisy and exhibits skewed distribution, some recommendation approaches, e.g., SGL and SimGCL, leverage self-supervised learning to improve user representations against the above issues. Despite their effectiveness, however, they conduct self-supervised learning through creating contrastvie views, depending on the exploration of data augmentations with the problem of tedious trial-and-error selection of augmentation methods. In this paper, we propose a novel Adaptive Graph Contrastive Learning (AdaptiveGCL) framework which conducts graph contrastive learning with two adaptive contrastive view generators to better empower CF paradigm. Specifically, we use two trainable view generators, which are a graph generative model and a graph denoising model respectively, to create contrastive views. Two generators are able to create adaptive contrastive views, addressing the problem of model collapse and achieving adaptive contrastive learning. With two adaptive contrasive views, more additionally high-quality training signals will be introduced into the CF paradigm and help to alleviate the data sparsity and noise issues. Extensive experiments on three benchmark datasets demonstrate the superiority of our model over various state-of-the-art recommendation methods. Further visual analysis intuitively explains why our AdaptiveGCL outperforms existing contrastive learning approaches based on selected data augmentation methods. ",
    "url": "https://arxiv.org/abs/2305.10837",
    "authors": [
      "Yangqin Jiang",
      "Chao Huang",
      "Lianghao Xia"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2305.10838",
    "title": "ProgSG: Cross-Modality Representation Learning for Programs in  Electronic Design Automation",
    "abstract": "Recent years have witnessed the growing popularity of domain-specific accelerators (DSAs), such as Google's TPUs, for accelerating various applications such as deep learning, search, autonomous driving, etc. To facilitate DSA designs, high-level synthesis (HLS) is used, which allows a developer to compile a high-level description in the form of software code in C and C++ into a design in low-level hardware description languages (such as VHDL or Verilog) and eventually synthesized into a DSA on an ASIC (application-specific integrated circuit) or FPGA (field-programmable gate arrays). However, existing HLS tools still require microarchitecture decisions, expressed in terms of pragmas (such as directives for parallelization and pipelining). To enable more people to design DSAs, it is desirable to automate such decisions with the help of deep learning for predicting the quality of HLS designs. This requires us a deeper understanding of the program, which is a combination of original code and pragmas. Naturally, these programs can be considered as sequence data, for which large language models (LLM) can help. In addition, these programs can be compiled and converted into a control data flow graph (CDFG), and the compiler also provides fine-grained alignment between the code tokens and the CDFG nodes. However, existing works either fail to leverage both modalities or combine the two in shallow or coarse ways. We propose ProgSG allowing the source code sequence modality and the graph modalities to interact with each other in a deep and fine-grained way. To alleviate the scarcity of labeled designs, a pre-training method is proposed based on a suite of compiler's data flow analysis tasks. Experimental results on two benchmark datasets show the superiority of ProgSG over baseline methods that either only consider one modality or combine the two without utilizing the alignment information. ",
    "url": "https://arxiv.org/abs/2305.10838",
    "authors": [
      "Yunsheng Bai",
      "Atefeh Sohrabizadeh",
      "Zongyue Qin",
      "Ziniu Hu",
      "Yizhou Sun",
      "Jason Cong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2305.10840",
    "title": "Uncertainty Quantification in Deep Neural Networks through Statistical  Inference on Latent Space",
    "abstract": "Uncertainty-quantification methods are applied to estimate the confidence of deep-neural-networks classifiers over their predictions. However, most widely used methods are known to be overconfident. We address this problem by developing an algorithm that exploits the latent-space representation of data points fed into the network, to assess the accuracy of their prediction. Using the latent-space representation generated by the fraction of training set that the network classifies correctly, we build a statistical model that is able to capture the likelihood of a given prediction. We show on a synthetic dataset that commonly used methods are mostly overconfident. Overconfidence occurs also for predictions made on data points that are outside the distribution that generated the training data. In contrast, our method can detect such out-of-distribution data points as inaccurately predicted, thus aiding in the automatic detection of outliers. ",
    "url": "https://arxiv.org/abs/2305.10840",
    "authors": [
      "Luigi Sbail\u00f2",
      "Luca M. Ghiringhelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.10841",
    "title": "GETMusic: Generating Any Music Tracks with a Unified Representation and  Diffusion Framework",
    "abstract": "Symbolic music generation aims to create musical notes, which can help users compose music, such as generating target instrumental tracks from scratch, or based on user-provided source tracks. Considering the diverse and flexible combination between source and target tracks, a unified model capable of generating any arbitrary tracks is of crucial necessity. Previous works fail to address this need due to inherent constraints in music representations and model architectures. To address this need, we propose a unified representation and diffusion framework named GETMusic (`GET' stands for GEnerate music Tracks), which includes a novel music representation named GETScore, and a diffusion model named GETDiff. GETScore represents notes as tokens and organizes them in a 2D structure, with tracks stacked vertically and progressing horizontally over time. During training, tracks are randomly selected as either the target or source. In the forward process, target tracks are corrupted by masking their tokens, while source tracks remain as ground truth. In the denoising process, GETDiff learns to predict the masked target tokens, conditioning on the source tracks. With separate tracks in GETScore and the non-autoregressive behavior of the model, GETMusic can explicitly control the generation of any target tracks from scratch or conditioning on source tracks. We conduct experiments on music generation involving six instrumental tracks, resulting in a total of 665 combinations. GETMusic provides high-quality results across diverse combinations and surpasses prior works proposed for some specific combinations. ",
    "url": "https://arxiv.org/abs/2305.10841",
    "authors": [
      "Ang Lv",
      "Xu Tan",
      "Peiling Lu",
      "Wei Ye",
      "Shikun Zhang",
      "Jiang Bian",
      "Rui Yan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.10847",
    "title": "Large Language Models can be Guided to Evade AI-Generated Text Detection",
    "abstract": "Large Language Models (LLMs) have demonstrated exceptional performance in a variety of tasks, including essay writing and question answering. However, it is crucial to address the potential misuse of these models, which can lead to detrimental outcomes such as plagiarism and spamming. Recently, several detectors have been proposed, including fine-tuned classifiers and various statistical methods. In this study, we reveal that with the aid of carefully crafted prompts, LLMs can effectively evade these detection systems. We propose a novel Substitution-based In-Context example Optimization method (SICO) to automatically generate such prompts. On three real-world tasks where LLMs can be misused, SICO successfully enables ChatGPT to evade six existing detectors, causing a significant 0.54 AUC drop on average. Surprisingly, in most cases these detectors perform even worse than random classifiers. These results firmly reveal the vulnerability of existing detectors. Finally, the strong performance of SICO suggests itself as a reliable evaluation protocol for any new detector in this field. ",
    "url": "https://arxiv.org/abs/2305.10847",
    "authors": [
      "Ning Lu",
      "Shengcai Liu",
      "Rui He",
      "Ke Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.10856",
    "title": "Towards an Accurate and Secure Detector against Adversarial  Perturbations",
    "abstract": "The vulnerability of deep neural networks to adversarial perturbations has been widely perceived in the computer vision community. From a security perspective, it poses a critical risk for modern vision systems, e.g., the popular Deep Learning as a Service (DLaaS) frameworks. For protecting off-the-shelf deep models while not modifying them, current algorithms typically detect adversarial patterns through discriminative decomposition of natural-artificial data. However, these decompositions are biased towards frequency or spatial discriminability, thus failing to capture subtle adversarial patterns comprehensively. More seriously, they are typically invertible, meaning successful defense-aware (secondary) adversarial attack (i.e., evading the detector as well as fooling the model) is practical under the assumption that the adversary is fully aware of the detector (i.e., the Kerckhoffs's principle). Motivated by such facts, we propose an accurate and secure adversarial example detector, relying on a spatial-frequency discriminative decomposition with secret keys. It expands the above works on two aspects: 1) the introduced Krawtchouk basis provides better spatial-frequency discriminability and thereby is more suitable for capturing adversarial patterns than the common trigonometric or wavelet basis; 2) the extensive parameters for decomposition are generated by a pseudo-random function with secret keys, hence blocking the defense-aware adversarial attack. Theoretical and numerical analysis demonstrates the increased accuracy and security of our detector w.r.t. a number of state-of-the-art algorithms. ",
    "url": "https://arxiv.org/abs/2305.10856",
    "authors": [
      "Chao Wang",
      "Shuren Qi",
      "Zhiqiu Huang",
      "Yushu Zhang",
      "Xiaochun Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10862",
    "title": "How Deep Learning Sees the World: A Survey on Adversarial Attacks &  Defenses",
    "abstract": "Deep Learning is currently used to perform multiple tasks, such as object recognition, face recognition, and natural language processing. However, Deep Neural Networks (DNNs) are vulnerable to perturbations that alter the network prediction (adversarial examples), raising concerns regarding its usage in critical areas, such as self-driving vehicles, malware detection, and healthcare. This paper compiles the most recent adversarial attacks, grouped by the attacker capacity, and modern defenses clustered by protection strategies. We also present the new advances regarding Vision Transformers, summarize the datasets and metrics used in the context of adversarial settings, and compare the state-of-the-art results under different attacks, finishing with the identification of open issues. ",
    "url": "https://arxiv.org/abs/2305.10862",
    "authors": [
      "Joana C. Costa",
      "Tiago Roxo",
      "Hugo Proen\u00e7a",
      "Pedro R. M. In\u00e1cio"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10863",
    "title": "Quiver: Supporting GPUs for Low-Latency, High-Throughput GNN Serving  with Workload Awareness",
    "abstract": "Systems for serving inference requests on graph neural networks (GNN) must combine low latency with high throughout, but they face irregular computation due to skew in the number of sampled graph nodes and aggregated GNN features. This makes it challenging to exploit GPUs effectively: using GPUs to sample only a few graph nodes yields lower performance than CPU-based sampling; and aggregating many features exhibits high data movement costs between GPUs and CPUs. Therefore, current GNN serving systems use CPUs for graph sampling and feature aggregation, limiting throughput. We describe Quiver, a distributed GPU-based GNN serving system with low-latency and high-throughput. Quiver's key idea is to exploit workload metrics for predicting the irregular computation of GNN requests, and governing the use of GPUs for graph sampling and feature aggregation: (1) for graph sampling, Quiver calculates the probabilistic sampled graph size, a metric that predicts the degree of parallelism in graph sampling. Quiver uses this metric to assign sampling tasks to GPUs only when the performance gains surpass CPU-based sampling; and (2) for feature aggregation, Quiver relies on the feature access probability to decide which features to partition and replicate across a distributed GPU NUMA topology. We show that Quiver achieves up to 35 times lower latency with an 8 times higher throughput compared to state-of-the-art GNN approaches (DGL and PyG). ",
    "url": "https://arxiv.org/abs/2305.10863",
    "authors": [
      "Zeyuan Tan",
      "Xiulong Yuan",
      "Congjie He",
      "Man-Kit Sit",
      "Guo Li",
      "Xiaoze Liu",
      "Baole Ai",
      "Kai Zeng",
      "Peter Pietzuch",
      "Luo Mai"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Operating Systems (cs.OS)"
    ]
  },
  {
    "id": "arXiv:2305.10869",
    "title": "Free Lunch for Privacy Preserving Distributed Graph Learning",
    "abstract": "Learning on graphs is becoming prevalent in a wide range of applications including social networks, robotics, communication, medicine, etc. These datasets belonging to entities often contain critical private information. The utilization of data for graph learning applications is hampered by the growing privacy concerns from users on data sharing. Existing privacy-preserving methods pre-process the data to extract user-side features, and only these features are used for subsequent learning. Unfortunately, these methods are vulnerable to adversarial attacks to infer private attributes. We present a novel privacy-respecting framework for distributed graph learning and graph-based machine learning. In order to perform graph learning and other downstream tasks on the server side, this framework aims to learn features as well as distances without requiring actual features while preserving the original structural properties of the raw data. The proposed framework is quite generic and highly adaptable. We demonstrate the utility of the Euclidean space, but it can be applied with any existing method of distance approximation and graph learning for the relevant spaces. Through extensive experimentation on both synthetic and real datasets, we demonstrate the efficacy of the framework in terms of comparing the results obtained without data sharing to those obtained with data sharing as a benchmark. This is, to our knowledge, the first privacy-preserving distributed graph learning framework. ",
    "url": "https://arxiv.org/abs/2305.10869",
    "authors": [
      "Nimesh Agrawal",
      "Nikita Malik",
      "Sandeep Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.10882",
    "title": "StawGAN: Structural-Aware Generative Adversarial Networks for Infrared  Image Translation",
    "abstract": "This paper addresses the problem of translating night-time thermal infrared images, which are the most adopted image modalities to analyze night-time scenes, to daytime color images (NTIT2DC), which provide better perceptions of objects. We introduce a novel model that focuses on enhancing the quality of the target generation without merely colorizing it. The proposed structural aware (StawGAN) enables the translation of better-shaped and high-definition objects in the target domain. We test our model on aerial images of the DroneVeichle dataset containing RGB-IR paired images. The proposed approach produces a more accurate translation with respect to other state-of-the-art image translation models. The source code is available at https://github.com/LuigiSigillo/StawGAN ",
    "url": "https://arxiv.org/abs/2305.10882",
    "authors": [
      "Luigi Sigillo",
      "Eleonora Grassucci",
      "Danilo Comminiello"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.10884",
    "title": "Meta-Auxiliary Network for 3D GAN Inversion",
    "abstract": "Real-world image manipulation has achieved fantastic progress in recent years. GAN inversion, which aims to map the real image to the latent code faithfully, is the first step in this pipeline. However, existing GAN inversion methods fail to achieve high reconstruction quality and fast inference at the same time. In addition, existing methods are built on 2D GANs and lack explicitly mechanisms to enforce multi-view consistency.In this work, we present a novel meta-auxiliary framework, while leveraging the newly developed 3D GANs as generator. The proposed method adopts a two-stage strategy. In the first stage, we invert the input image to an editable latent code using off-the-shelf inversion techniques. The auxiliary network is proposed to refine the generator parameters with the given image as input, which both predicts offsets for weights of convolutional layers and sampling positions of volume rendering. In the second stage, we perform meta-learning to fast adapt the auxiliary network to the input image, then the final reconstructed image is synthesized via the meta-learned auxiliary network. Extensive experiments show that our method achieves better performances on both inversion and editing tasks. ",
    "url": "https://arxiv.org/abs/2305.10884",
    "authors": [
      "Bangrui Jiang",
      "Zhenhua Guo",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10887",
    "title": "Robust Hybrid Transceiver Designs for Linear Decentralized Estimation in  mmWave MIMO IoT Networks in the Face of Imperfect CSI",
    "abstract": "Hybrid transceivers are designed for linear decentralized estimation (LDE) in a mmWave multiple-input multiple-output (MIMO) IoT network (IoTNe). For a noiseless fusion center (FC), it is demonstrated that the MSE performance is determined by the number of RF chains used at each IoT node (IoTNo). Next, the minimum-MSE RF transmit precoders (TPCs) and receive combiner (RC) matrices are designed for this setup using the dominant array response vectors, and subsequently, a closed-form expression is obtained for the baseband (BB) TPC at each IoTNo using Cauchy's interlacing theorem. For a realistic noisy FC, it is shown that the resultant mean squared error (MSE) minimization problem is non-convex. To address this challenge, a block-coordinate descent-based iterative scheme is proposed to obtain the fully digital TPC and RC matrices followed by the simultaneous orthogonal matching pursuit (SOMP) technique for decomposing the fully-digital transceiver into its corresponding RF and BB components. A theoretical proof of the convergence is also presented for the proposed iterative design procedure. Furthermore, robust hybrid transceiver designs are also derived for a practical scenario in the face of channel state information (CSI) uncertainty. The centralized MMSE lower bound has also been derived that benchmarks the performance of the proposed LDE schemes. Finally, our numerical results characterize the performance of the proposed transceivers as well as corroborate our various analytical propositions. ",
    "url": "https://arxiv.org/abs/2305.10887",
    "authors": [
      "Priyanka Maity",
      "Kunwar Pritiraj Rajput",
      "Suraj Srivastava",
      "Naveen K. D. Venkategowda",
      "Aditya K. Jagannatham",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.10889",
    "title": "FLIGHT Mode On: A Feather-Light Network for Low-Light Image Enhancement",
    "abstract": "Low-light image enhancement (LLIE) is an ill-posed inverse problem due to the lack of knowledge of the desired image which is obtained under ideal illumination conditions. Low-light conditions give rise to two main issues: a suppressed image histogram and inconsistent relative color distributions with low signal-to-noise ratio. In order to address these problems, we propose a novel approach named FLIGHT-Net using a sequence of neural architecture blocks. The first block regulates illumination conditions through pixel-wise scene dependent illumination adjustment. The output image is produced in the output of the second block, which includes channel attention and denoising sub-blocks. Our highly efficient neural network architecture delivers state-of-the-art performance with only 25K parameters. The method's code, pretrained models and resulting images will be publicly available. ",
    "url": "https://arxiv.org/abs/2305.10889",
    "authors": [
      "Mustafa Ozcan",
      "Hamza Ergezer",
      "Mustafa Ayazaoglu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10906",
    "title": "RobustFair: Adversarial Evaluation through Fairness Confusion Directed  Gradient Search",
    "abstract": "The trustworthiness of DNNs is often challenged by their vulnerability to minor adversarial perturbations, which may not only undermine prediction accuracy (robustness) but also cause biased predictions for similar inputs (individual fairness). Accurate fairness has been recently proposed to enforce a harmonic balance between accuracy and individual fairness. It induces the notion of fairness confusion matrix to categorize predictions as true fair, true biased, false fair, and false biased. This paper proposes a harmonic evaluation approach, RobustFair, for the accurate fairness of DNNs, using adversarial perturbations crafted through fairness confusion directed gradient search. By using Taylor expansions to approximate the ground truths of adversarial instances, RobustFair can particularly identify the robustness defects entangled for spurious fairness, which are often elusive in robustness evaluation, and missing in individual fairness evaluation. RobustFair can boost robustness and individual fairness evaluations by identifying robustness or fairness defects simultaneously. Empirical case studies on fairness benchmark datasets show that, compared with the state-of-the-art white-box robustness and individual fairness testing approaches, RobustFair detects significantly 1.77-11.87 times adversarial perturbations, yielding 1.83-13.12 times biased and 1.53-8.22 times false instances. The adversarial instances can then be effectively exploited to improve the accurate fairness (and hence accuracy and individual fairness) of the original deep neural network through retraining. The empirical case studies further show that the adversarial instances identified by RobustFair outperform those identified by the other testing approaches, in promoting 21% accurate fairness and 19% individual fairness on multiple sensitive attributes, without losing accuracy at all or even promoting it by up to 4%. ",
    "url": "https://arxiv.org/abs/2305.10906",
    "authors": [
      "Xuran Li",
      "Peng Wu",
      "Kaixiang Dong",
      "Zhen Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2305.10910",
    "title": "Analysis of Library Dependency Networks of Package Managers Used in iOS  Development",
    "abstract": "Reusing existing solutions in the form of third-party libraries is common practice when writing software. Package managers are used to manage dependencies to third-party libraries by automating the process of installing and updating the libraries. Library dependencies themselves can have dependencies to other libraries creating a dependency network with several levels of indirections. The library dependency network in the Swift ecosystem encompasses libraries from CocoaPods, Carthage and Swift Package Manager (PM). These package managers are used when developing, for example, iOS or Mac OS applications in Swift and Objective-C. We provide the first analysis of the library dependency network evolution in the Swift ecosystem. Although CocoaPods is the package manager with the biggest set of libraries, the difference to other package managers is not as big as expected. The youngest package manager and official package manager for Swift, Swift PM, is becoming more and more popular, resulting in a gradual slow-down of the growth of the other two package managers. When analyzing direct and transitive dependencies, we found that the mean total number of dependencies is lower in the Swift ecosystem compared to many other ecosystems. Still, the total number of dependencies shows a clear growing trend over the last five years. ",
    "url": "https://arxiv.org/abs/2305.10910",
    "authors": [
      "Kristiina Rahkema",
      "Dietmar Pfahl",
      "Rudolf Ramler"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.10926",
    "title": "HMSN: Hyperbolic Self-Supervised Learning by Clustering with Ideal  Prototypes",
    "abstract": "Hyperbolic manifolds for visual representation learning allow for effective learning of semantic class hierarchies by naturally embedding tree-like structures with low distortion within a low-dimensional representation space. The highly separable semantic class hierarchies produced by hyperbolic learning have shown to be powerful in low-shot tasks, however, their application in self-supervised learning is yet to be explored fully. In this work, we explore the use of hyperbolic representation space for self-supervised representation learning for prototype-based clustering approaches. First, we extend the Masked Siamese Networks to operate on the Poincar\\'e ball model of hyperbolic space, secondly, we place prototypes on the ideal boundary of the Poincar\\'e ball. Unlike previous methods we project to the hyperbolic space at the output of the encoder network and utilise a hyperbolic projection head to ensure that the representations used for downstream tasks remain hyperbolic. Empirically we demonstrate the ability of these methods to perform comparatively to Euclidean methods in lower dimensions for linear evaluation tasks, whilst showing improvements in extreme few-shot learning tasks. ",
    "url": "https://arxiv.org/abs/2305.10926",
    "authors": [
      "Aiden Durrant",
      "Georgios Leontidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10927",
    "title": "Causal Document-Grounded Dialogue Pre-training",
    "abstract": "The goal of document-grounded dialogue (DocGD) is to generate a response by grounding the evidence in a supporting document in accordance with the dialogue context. This process involves four variables that are causally connected. Recently, task-specific pre-training has greatly boosted performances on many downstream tasks. Existing DocGD methods, however, continue to rely on general pre-trained language models without a specifically tailored pre-training approach that explicitly captures the causal relationships. To tackle this issue, we are the first to present a causally-complete dataset construction strategy for building million-level DocGD pre-training corpora. To better capture causality, we further propose a causally-perturbed pre-training strategy, which introduces causal perturbations on the variables and optimizes the overall causal effect. Experiments on three benchmark datasets demonstrate that our causal pre-training achieves considerable and consistent improvements under fully-supervised, low-resource, few-shot, and zero-shot settings. ",
    "url": "https://arxiv.org/abs/2305.10927",
    "authors": [
      "Yingxiu Zhao",
      "Bowen Yu",
      "Haiyang Yu",
      "Bowen Li",
      "Chao Wang",
      "Fei Huang",
      "Yongbin Li",
      "Nevin L. Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.10929",
    "title": "Architecture-agnostic Iterative Black-box Certified Defense against  Adversarial Patches",
    "abstract": "The adversarial patch attack aims to fool image classifiers within a bounded, contiguous region of arbitrary changes, posing a real threat to computer vision systems (e.g., autonomous driving, content moderation, biometric authentication, medical imaging) in the physical world. To address this problem in a trustworthy way, proposals have been made for certified patch defenses that ensure the robustness of classification models and prevent future patch attacks from breaching the defense. State-of-the-art certified defenses can be compatible with any model architecture, as well as achieve high clean and certified accuracy. Although the methods are adaptive to arbitrary patch positions, they inevitably need to access the size of the adversarial patch, which is unreasonable and impractical in real-world attack scenarios. To improve the feasibility of the architecture-agnostic certified defense in a black-box setting (i.e., position and size of the patch are both unknown), we propose a novel two-stage Iterative Black-box Certified Defense method, termed IBCD.In the first stage, it estimates the patch size in a search-based manner by evaluating the size relationship between the patch and mask with pixel masking. In the second stage, the accuracy results are calculated by the existing white-box certified defense methods with the estimated patch size. The experiments conducted on two popular model architectures and two datasets verify the effectiveness and efficiency of IBCD. ",
    "url": "https://arxiv.org/abs/2305.10929",
    "authors": [
      "Di Yang",
      "Yihao Huang",
      "Qing Guo",
      "Felix Juefei-Xu",
      "Ming Hu",
      "Yang Liu",
      "Geguang Pu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10930",
    "title": "On the Off-Target Problem of Zero-Shot Multilingual Neural Machine  Translation",
    "abstract": "While multilingual neural machine translation has achieved great success, it suffers from the off-target issue, where the translation is in the wrong language. This problem is more pronounced on zero-shot translation tasks. In this work, we find that failing in encoding discriminative target language signal will lead to off-target and a closer lexical distance (i.e., KL-divergence) between two languages' vocabularies is related with a higher off-target rate. We also find that solely isolating the vocab of different languages in the decoder can alleviate the problem. Motivated by the findings, we propose Language Aware Vocabulary Sharing (LAVS), a simple and effective algorithm to construct the multilingual vocabulary, that greatly alleviates the off-target problem of the translation model by increasing the KL-divergence between languages. We conduct experiments on a multilingual machine translation benchmark in 11 languages. Experiments show that the off-target rate for 90 translation tasks is reduced from 29\\% to 8\\%, while the overall BLEU score is improved by an average of 1.9 points without extra training cost or sacrificing the supervised directions' performance. We release the code at \\href{https://github.com/chenllliang/Off-Target-MNMT}{https://github.com/chenllliang/Off-Target-MNMT} for reproduction. ",
    "url": "https://arxiv.org/abs/2305.10930",
    "authors": [
      "Liang Chen",
      "Shuming Ma",
      "Dongdong Zhang",
      "Furu Wei",
      "Baobao Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.10935",
    "title": "Submodularity Gaps for Selected Network Design and Matching Problems",
    "abstract": "Submodularity in combinatorial optimization has been a topic of many studies and various algorithmic techniques exploiting submodularity of a studied problem have been proposed. It is therefore natural to ask, in cases where the cost function of the studied problem is not submodular, whether it is possible to approximate this cost function with a proxy submodular function. We answer this question in the negative for two major problems in metric optimization, namely Steiner Tree and Uncapacitated Facility Location. We do so by proving super-constant lower bounds on the submodularity gap for these problems, which are in contrast to the known constant factor cost sharing schemes known for them. Technically, our lower bounds build on strong lower bounds for the online variants of these two problems. Nevertheless, online lower bounds do not always imply submodularity lower bounds. We show that the problem Maximum Bipartite Matching does not exhibit any submodularity gap, despite its online variant being only (1 - 1/e)-competitive in the randomized setting. ",
    "url": "https://arxiv.org/abs/2305.10935",
    "authors": [
      "Martin B\u00f6hm",
      "Jaros\u0142aw Byrka",
      "Mateusz Lewandowski",
      "Jan Marcinkowski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2305.10947",
    "title": "In Defense of Pure 16-bit Floating-Point Neural Networks",
    "abstract": "Reducing the number of bits needed to encode the weights and activations of neural networks is highly desirable as it speeds up their training and inference time while reducing memory consumption. For these reasons, research in this area has attracted significant attention toward developing neural networks that leverage lower-precision computing, such as mixed-precision training. Interestingly, none of the existing approaches has investigated pure 16-bit floating-point settings. In this paper, we shed light on the overlooked efficiency of pure 16-bit floating-point neural networks. As such, we provide a comprehensive theoretical analysis to investigate the factors contributing to the differences observed between 16-bit and 32-bit models. We formalize the concepts of floating-point error and tolerance, enabling us to quantitatively explain the conditions under which a 16-bit model can closely approximate the results of its 32-bit counterpart. This theoretical exploration offers perspective that is distinct from the literature which attributes the success of low-precision neural networks to its regularization effect. This in-depth analysis is supported by an extensive series of experiments. Our findings demonstrate that pure 16-bit floating-point neural networks can achieve similar or even better performance than their mixed-precision and 32-bit counterparts. We believe the results presented in this paper will have significant implications for machine learning practitioners, offering an opportunity to reconsider using pure 16-bit networks in various applications. ",
    "url": "https://arxiv.org/abs/2305.10947",
    "authors": [
      "Juyoung Yun",
      "Byungkon Kang",
      "Francois Rameau",
      "Zhoulai Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2305.10951",
    "title": "Making More of Little Data: Improving Low-Resource Automatic Speech  Recognition Using Data Augmentation",
    "abstract": "The performance of automatic speech recognition (ASR) systems has advanced substantially in recent years, particularly for languages for which a large amount of transcribed speech is available. Unfortunately, for low-resource languages, such as minority languages, regional languages or dialects, ASR performance generally remains much lower. In this study, we investigate whether data augmentation techniques could help improve low-resource ASR performance, focusing on four typologically diverse minority languages or language variants (West Germanic: Gronings, West-Frisian; Malayo-Polynesian: Besemah, Nasal). For all four languages, we examine the use of self-training, where an ASR system trained with the available human-transcribed data is used to generate transcriptions, which are then combined with the original data to train a new ASR system. For Gronings, for which there was a pre-existing text-to-speech (TTS) system available, we also examined the use of TTS to generate ASR training data from text-only sources. We find that using a self-training approach consistently yields improved performance (a relative WER reduction up to 20.5% compared to using an ASR system trained on 24 minutes of manually transcribed speech). The performance gain from TTS augmentation for Gronings was even stronger (up to 25.5% relative reduction in WER compared to a system based on 24 minutes of manually transcribed speech). In sum, our results show the benefit of using self-training or (if possible) TTS-generated data as an efficient solution to overcome the limitations of data availability for resource-scarce languages in order to improve ASR performance. ",
    "url": "https://arxiv.org/abs/2305.10951",
    "authors": [
      "Martijn Bartelds",
      "Nay San",
      "Bradley McDonnell",
      "Dan Jurafsky",
      "Martijn Wieling"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.10952",
    "title": "Actor-Critic Methods using Physics-Informed Neural Networks: Control of  a 1D PDE Model for Fluid-Cooled Battery Packs",
    "abstract": "This paper proposes an actor-critic algorithm for controlling the temperature of a battery pack using a cooling fluid. This is modeled by a coupled 1D partial differential equation (PDE) with a controlled advection term that determines the speed of the cooling fluid. The Hamilton-Jacobi-Bellman (HJB) equation is a PDE that evaluates the optimality of the value function and determines an optimal controller. We propose an algorithm that treats the value network as a Physics-Informed Neural Network (PINN) to solve for the continuous-time HJB equation rather than a discrete-time Bellman optimality equation, and we derive an optimal controller for the environment that we exploit to achieve optimal control. Our experiments show that a hybrid-policy method that updates the value network using the HJB equation and updates the policy network identically to PPO achieves the best results in the control of this PDE system. ",
    "url": "https://arxiv.org/abs/2305.10952",
    "authors": [
      "Amartya Mukherjee",
      "Jun Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2305.10953",
    "title": "Detecting the driver nodes of temporal networks",
    "abstract": "Detecting the driver nodes of complex networks has garnered significant attention recently to control complex systems to desired behaviors, where nodes represent system components and edges encode their interactions. Driver nodes, which are directly controlled by external inputs, play a crucial role in controlling all network nodes. While many approaches have been proposed to identify driver nodes of static networks, we still lack an effective algorithm to control ubiquitous temporal networks, where network structures evolve over time. Here we propose an effective online time-accelerated heuristic algorithm (OTaHa) to detect driver nodes of temporal networks. Together with theoretical analysis and numerical simulations on synthetic and empirical temporal networks, we show that OTaHa offers multiple sets of driver nodes, and noticeably outperforms existing methods in terms of accuracy and execution time. We further report that most edges are redundant in controlling temporal networks although the complete instantaneous signal-carrying edges cannot be guaranteed. Moreover, removing edges with high edge betweenness (the number of all-pairs shortest paths passing through the edge) significantly impedes the overall controllability. Our work provides an effective algorithm and paves the way for subsequent explorations on achieving the ultimate control of temporal networks. ",
    "url": "https://arxiv.org/abs/2305.10953",
    "authors": [
      "Tingting Qin",
      "Gaopeng Duan",
      "Aming Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.10961",
    "title": "Prevention is better than cure: a case study of the abnormalities  detection in the chest",
    "abstract": "Prevention is better than cure. This old truth applies not only to the prevention of diseases but also to the prevention of issues with AI models used in medicine. The source of malfunctioning of predictive models often lies not in the training process but reaches the data acquisition phase or design of the experiment phase. In this paper, we analyze in detail a single use case - a Kaggle competition related to the detection of abnormalities in X-ray lung images. We demonstrate how a series of simple tests for data imbalance exposes faults in the data acquisition and annotation process. Complex models are able to learn such artifacts and it is difficult to remove this bias during or after the training. Errors made at the data collection stage make it difficult to validate the model correctly. Based on this use case, we show how to monitor data and model balance (fairness) throughout the life cycle of a predictive model, from data acquisition to parity analysis of model scores. ",
    "url": "https://arxiv.org/abs/2305.10961",
    "authors": [
      "Weronika Hryniewska",
      "Piotr Czarnecki",
      "Jakub Wi\u015bniewski",
      "Przemys\u0142aw Bombi\u0144ski",
      "Przemys\u0142aw Biecek"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.10964",
    "title": "Learning Activation Functions for Sparse Neural Networks",
    "abstract": "Sparse Neural Networks (SNNs) can potentially demonstrate similar performance to their dense counterparts while saving significant energy and memory at inference. However, the accuracy drop incurred by SNNs, especially at high pruning ratios, can be an issue in critical deployment conditions. While recent works mitigate this issue through sophisticated pruning techniques, we shift our focus to an overlooked factor: hyperparameters and activation functions. Our analyses have shown that the accuracy drop can additionally be attributed to (i) Using ReLU as the default choice for activation functions unanimously, and (ii) Fine-tuning SNNs with the same hyperparameters as dense counterparts. Thus, we focus on learning a novel way to tune activation functions for sparse networks and combining these with a separate hyperparameter optimization (HPO) regime for sparse networks. By conducting experiments on popular DNN models (LeNet-5, VGG-16, ResNet-18, and EfficientNet-B0) trained on MNIST, CIFAR-10, and ImageNet-16 datasets, we show that the novel combination of these two approaches, dubbed Sparse Activation Function Search, short: SAFS, results in up to 15.53%, 8.88%, and 6.33% absolute improvement in the accuracy for LeNet-5, VGG-16, and ResNet-18 over the default training protocols, especially at high pruning ratios. Our code can be found at https://github.com/automl/SAFS ",
    "url": "https://arxiv.org/abs/2305.10964",
    "authors": [
      "Mohammad Loni",
      "Aditya Mohan",
      "Mehdi Asadi",
      "Marius Lindauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.10974",
    "title": "MonoTDP: Twin Depth Perception for Monocular 3D Object Detection in  Adverse Scenes",
    "abstract": "3D object detection plays a crucial role in numerous intelligent vision systems. Detection in the open world inevitably encounters various adverse scenes, such as dense fog, heavy rain, and low light conditions. Although existing efforts primarily focus on diversifying network architecture or training schemes, resulting in significant progress in 3D object detection, most of these learnable modules fail in adverse scenes, thereby hindering detection performance. To address this issue, this paper proposes a monocular 3D detection model designed to perceive twin depth in adverse scenes, termed MonoTDP, which effectively mitigates the degradation of detection performance in various harsh environments. Specifically, we first introduce an adaptive learning strategy to aid the model in handling uncontrollable weather conditions, significantly resisting degradation caused by various degrading factors. Then, to address the depth/content loss in adverse regions, we propose a novel twin depth perception module that simultaneously estimates scene and object depth, enabling the integration of scene-level features and object-level features. Additionally, we assemble a new adverse 3D object detection dataset encompassing a wide range of challenging scenes, including rainy, foggy, and low light weather conditions, with each type of scene containing 7,481 images. Experimental results demonstrate that our proposed method outperforms current state-of-the-art approaches by an average of 3.12% in terms of AP_R40 for car category across various adverse environments. ",
    "url": "https://arxiv.org/abs/2305.10974",
    "authors": [
      "Xingyuan Li",
      "Jingyuan Liu",
      "Yixin Lei",
      "Long Ma",
      "Xin Fan",
      "Risheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10983",
    "title": "Assessor360: Multi-sequence Network for Blind Omnidirectional Image  Quality Assessment",
    "abstract": "Blind Omnidirectional Image Quality Assessment (BOIQA) aims to objectively assess the human perceptual quality of omnidirectional images (ODIs) without relying on pristine-quality image information. It is becoming more significant with the increasing advancement of virtual reality (VR) technology. However, the quality assessment of ODIs is severely hampered by the fact that the existing BOIQA pipeline lacks the modeling of the observer's browsing process. To tackle this issue, we propose a novel multi-sequence network for BOIQA called Assessor360, which is derived from the realistic multi-assessor ODI quality assessment procedure. Specifically, we propose a generalized Recursive Probability Sampling (RPS) method for the BOIQA task, combining content and detailed information to generate multiple pseudo viewport sequences from a given starting point. Additionally, we design a Multi-scale Feature Aggregation (MFA) module with Distortion-aware Block (DAB) to fuse distorted and semantic features of each viewport. We also devise TMM to learn the viewport transition in the temporal domain. Extensive experimental results demonstrate that Assessor360 outperforms state-of-the-art methods on multiple OIQA datasets. ",
    "url": "https://arxiv.org/abs/2305.10983",
    "authors": [
      "Tianhe Wu",
      "Shuwei Shi",
      "Haoming Cai",
      "Mingdeng Cao",
      "Jing Xiao",
      "Yinqiang Zheng",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.10987",
    "title": "SPENSER: Towards a NeuroEvolutionary Approach for Convolutional Spiking  Neural Networks",
    "abstract": "Spiking Neural Networks (SNNs) have attracted recent interest due to their energy efficiency and biological plausibility. However, the performance of SNNs still lags behind traditional Artificial Neural Networks (ANNs), as there is no consensus on the best learning algorithm for SNNs. Best-performing SNNs are based on ANN to SNN conversion or learning with spike-based backpropagation through surrogate gradients. The focus of recent research has been on developing and testing different learning strategies, with hand-tailored architectures and parameter tuning. Neuroevolution (NE), has proven successful as a way to automatically design ANNs and tune parameters, but its applications to SNNs are still at an early stage. DENSER is a NE framework for the automatic design and parametrization of ANNs, based on the principles of Genetic Algorithms (GA) and Structured Grammatical Evolution (SGE). In this paper, we propose SPENSER, a NE framework for SNN generation based on DENSER, for image classification on the MNIST and Fashion-MNIST datasets. SPENSER generates competitive performing networks with a test accuracy of 99.42% and 91.65% respectively. ",
    "url": "https://arxiv.org/abs/2305.10987",
    "authors": [
      "Henrique Branquinho",
      "Nuno Louren\u00e7o",
      "Ernesto Costa"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10994",
    "title": "Understanding how Differentially Private Generative Models Spend their  Privacy Budget",
    "abstract": "Generative models trained with Differential Privacy (DP) are increasingly used to produce synthetic data while reducing privacy risks. Navigating their specific privacy-utility tradeoffs makes it challenging to determine which models would work best for specific settings/tasks. In this paper, we fill this gap in the context of tabular data by analyzing how DP generative models distribute privacy budgets across rows and columns, arguably the main source of utility degradation. We examine the main factors contributing to how privacy budgets are spent, including underlying modeling techniques, DP mechanisms, and data dimensionality. Our extensive evaluation of both graphical and deep generative models sheds light on the distinctive features that render them suitable for different settings and tasks. We show that graphical models distribute the privacy budget horizontally and thus cannot handle relatively wide datasets while the performance on the task they were optimized for monotonically increases with more data. Deep generative models spend their budget per iteration, so their behavior is less predictable with varying dataset dimensions but could perform better if trained on more features. Also, low levels of privacy ($\\epsilon\\geq100$) could help some models generalize, achieving better results than without applying DP. ",
    "url": "https://arxiv.org/abs/2305.10994",
    "authors": [
      "Georgi Ganev",
      "Kai Xu",
      "Emiliano De Cristofaro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.11004",
    "title": "Taxonomy Completion with Probabilistic Scorer via Box Embedding",
    "abstract": "Taxonomy completion, a task aimed at automatically enriching an existing taxonomy with new concepts, has gained significant interest in recent years. Previous works have introduced complex modules, external information, and pseudo-leaves to enrich the representation and unify the matching process of attachment and insertion. While they have achieved good performance, these introductions may have brought noise and unfairness during training and scoring. In this paper, we present TaxBox, a novel framework for taxonomy completion that maps taxonomy concepts to box embeddings and employs two probabilistic scorers for concept attachment and insertion, avoiding the need for pseudo-leaves. Specifically, TaxBox consists of three components: (1) a graph aggregation module to leverage the structural information of the taxonomy and two lightweight decoders that map features to box embedding and capture complex relationships between concepts; (2) two probabilistic scorers that correspond to attachment and insertion operations and ensure the avoidance of pseudo-leaves; and (3) three learning objectives that assist the model in mapping concepts more granularly onto the box embedding space. Experimental results on four real-world datasets suggest that TaxBox outperforms baseline methods by a considerable margin and surpasses previous state-of-art methods to a certain extent. ",
    "url": "https://arxiv.org/abs/2305.11004",
    "authors": [
      "Wei Xue",
      "Yongliang Shen",
      "Wenqi Ren",
      "Jietian Guo",
      "Siliang Pu",
      "Weiming Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.11031",
    "title": "ConsistentNeRF: Enhancing Neural Radiance Fields with 3D Consistency for  Sparse View Synthesis",
    "abstract": "Neural Radiance Fields (NeRF) has demonstrated remarkable 3D reconstruction capabilities with dense view images. However, its performance significantly deteriorates under sparse view settings. We observe that learning the 3D consistency of pixels among different views is crucial for improving reconstruction quality in such cases. In this paper, we propose ConsistentNeRF, a method that leverages depth information to regularize both multi-view and single-view 3D consistency among pixels. Specifically, ConsistentNeRF employs depth-derived geometry information and a depth-invariant loss to concentrate on pixels that exhibit 3D correspondence and maintain consistent depth relationships. Extensive experiments on recent representative works reveal that our approach can considerably enhance model performance in sparse view conditions, achieving improvements of up to 94% in PSNR, 76% in SSIM, and 31% in LPIPS compared to the vanilla baselines across various benchmarks, including DTU, NeRF Synthetic, and LLFF. ",
    "url": "https://arxiv.org/abs/2305.11031",
    "authors": [
      "Shoukang Hu",
      "Kaichen Zhou",
      "Kaiyu Li",
      "Longhui Yu",
      "Lanqing Hong",
      "Tianyang Hu",
      "Zhenguo Li",
      "Gim Hee Lee",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.11039",
    "title": "Deep PackGen: A Deep Reinforcement Learning Framework for Adversarial  Network Packet Generation",
    "abstract": "Recent advancements in artificial intelligence (AI) and machine learning (ML) algorithms, coupled with the availability of faster computing infrastructure, have enhanced the security posture of cybersecurity operations centers (defenders) through the development of ML-aided network intrusion detection systems (NIDS). Concurrently, the abilities of adversaries to evade security have also increased with the support of AI/ML models. Therefore, defenders need to proactively prepare for evasion attacks that exploit the detection mechanisms of NIDS. Recent studies have found that the perturbation of flow-based and packet-based features can deceive ML models, but these approaches have limitations. Perturbations made to the flow-based features are difficult to reverse-engineer, while samples generated with perturbations to the packet-based features are not playable. Our methodological framework, Deep PackGen, employs deep reinforcement learning to generate adversarial packets and aims to overcome the limitations of approaches in the literature. By taking raw malicious network packets as inputs and systematically making perturbations on them, Deep PackGen camouflages them as benign packets while still maintaining their functionality. In our experiments, using publicly available data, Deep PackGen achieved an average adversarial success rate of 66.4\\% against various ML models and across different attack types. Our investigation also revealed that more than 45\\% of the successful adversarial samples were out-of-distribution packets that evaded the decision boundaries of the classifiers. The knowledge gained from our study on the adversary's ability to make specific evasive perturbations to different types of malicious packets can help defenders enhance the robustness of their NIDS against evolving adversarial attacks. ",
    "url": "https://arxiv.org/abs/2305.11039",
    "authors": [
      "Soumyadeep Hore",
      "Jalal Ghadermazi",
      "Diwas Paudel",
      "Ankit Shah",
      "Tapas K. Das",
      "Nathaniel D. Bastian"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.11048",
    "title": "Robust Single-Point Pushing with Force Feedback",
    "abstract": "We present the first controller for quasistatic robotic planar pushing with single-point contact using only force feedback. We consider a mobile robot equipped with a force-torque sensor to measure the force at the contact point with the pushed object (the \"slider\"). The parameters of the slider are not known to the controller, nor is feedback on the slider's pose. We assume that the global position of the contact point is always known and that the approximate initial position of the slider is provided. We focus specifically on the case when it is desired to push the slider along a straight line. Simulations and real-world experiments show that our controller yields stable pushes that are robust to a wide range of slider parameters and state perturbations. ",
    "url": "https://arxiv.org/abs/2305.11048",
    "authors": [
      "Adam Heins",
      "Angela P. Schoellig"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.11051",
    "title": "The Water Health Open Knowledge Graph",
    "abstract": "Recently, an increasing interest in the management of water and health resources has been recorded. This interest is fed by the global sustainability challenges posed to the humanity that have water scarcity and quality at their core. Thus, the availability of effective, meaningful and open data is crucial to address those issues in the broader context of the Sustainable Development Goals of clean water and sanitation as targeted by the United Nations. In this paper, we present the Water Health Open Knowledge Graph (WHOW-KG) along with its design methodology and analysis on impact. WHOW-KG is a semantic knowledge graph that models data on water consumption, pollution, infectious disease rates and drug distribution. The WHOW-KG is developed in the context of the EU-funded WHOW (Water Health Open Knowledge) project and aims at supporting a wide range of applications: from knowledge discovery to decision-making, making it a valuable resource for researchers, policymakers, and practitioners in the water and health domains. The WHOW-KG consists of a network of five ontologies and related linked open data, modelled according to those ontologies. ",
    "url": "https://arxiv.org/abs/2305.11051",
    "authors": [
      "Gianluca Carletti",
      "Elio Giulianelli",
      "Anna Sofia Lippolis",
      "Giorgia Lodi",
      "Andrea Giovanni Nuzzolese",
      "Marco Picone",
      "Giulio Settanta"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.11052",
    "title": "BERM: Training the Balanced and Extractable Representation for Matching  to Improve Generalization Ability of Dense Retrieval",
    "abstract": "Dense retrieval has shown promise in the first-stage retrieval process when trained on in-domain labeled datasets. However, previous studies have found that dense retrieval is hard to generalize to unseen domains due to its weak modeling of domain-invariant and interpretable feature (i.e., matching signal between two texts, which is the essence of information retrieval). In this paper, we propose a novel method to improve the generalization of dense retrieval via capturing matching signal called BERM. Fully fine-grained expression and query-oriented saliency are two properties of the matching signal. Thus, in BERM, a single passage is segmented into multiple units and two unit-level requirements are proposed for representation as the constraint in training to obtain the effective matching signal. One is semantic unit balance and the other is essential matching unit extractability. Unit-level view and balanced semantics make representation express the text in a fine-grained manner. Essential matching unit extractability makes passage representation sensitive to the given query to extract the pure matching information from the passage containing complex context. Experiments on BEIR show that our method can be effectively combined with different dense retrieval training methods (vanilla, hard negatives mining and knowledge distillation) to improve its generalization ability without any additional inference overhead and target domain data. ",
    "url": "https://arxiv.org/abs/2305.11052",
    "authors": [
      "Shicheng Xu",
      "Liang Pang",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.11063",
    "title": "Medical Data Asset Management and an Approach for Disease Prediction  using Blockchain and Machine Learning",
    "abstract": "In the present medical services, the board, clinical well-being records are as electronic clinical record (EHR/EMR) frameworks. These frameworks store patients' clinical histories in a computerized design. Notwithstanding, a patient's clinical information is gained in a productive and ideal way and is demonstrated to be troublesome through these records. Powerlessness constantly prevents the well-being of the board from getting data, less use of data obtained, unmanageable protection controls, and unfortunate information resource security. In this paper, we present an effective and safe clinical information resource, the executives' framework involving Blockchain, to determine these issues. Blockchain innovation facilitates the openness of all such records by keeping a block for each patient. This paper proposes an engineering utilizing an off-chain arrangement that will empower specialists and patients to get records in a protected manner. Blockchain makes clinical records permanent and scrambles them for information honesty. Clients can notice their well-being records, yet just patients own the confidential key and can impart it to those they want. Smart contracts likewise help our information proprietors to deal with their information access in a permission way. The eventual outcome will be seen as a web and portable connection point to get to, identify, and guarantee high-security information handily. In this adventure, we will give deals with any consequences regarding the issues associated with clinical consideration data and the chiefs using AI and Blockchain. Removing only the imperative information from the data is possible with the use of AI. This is done using arranged estimations. At the point when this data is taken care of, the accompanying issue is information sharing and its constancy. ",
    "url": "https://arxiv.org/abs/2305.11063",
    "authors": [
      "Shruthi K",
      "Poornima A.S"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.11068",
    "title": "ORKG-Leaderboards: A Systematic Workflow for Mining Leaderboards as a  Knowledge Graph",
    "abstract": "The purpose of this work is to describe the Orkg-Leaderboard software designed to extract leaderboards defined as Task-Dataset-Metric tuples automatically from large collections of empirical research papers in Artificial Intelligence (AI). The software can support both the main workflows of scholarly publishing, viz. as LaTeX files or as PDF files. Furthermore, the system is integrated with the Open Research Knowledge Graph (ORKG) platform, which fosters the machine-actionable publishing of scholarly findings. Thus the system output, when integrated within the ORKG's supported Semantic Web infrastructure of representing machine-actionable 'resources' on the Web, enables: 1) broadly, the integration of empirical results of researchers across the world, thus enabling transparency in empirical research with the potential to also being complete contingent on the underlying data source(s) of publications; and 2) specifically, enables researchers to track the progress in AI with an overview of the state-of-the-art (SOTA) across the most common AI tasks and their corresponding datasets via dynamic ORKG frontend views leveraging tables and visualization charts over the machine-actionable data. Our best model achieves performances above 90% F1 on the \\textit{leaderboard} extraction task, thus proving Orkg-Leaderboards a practically viable tool for real-world usage. Going forward, in a sense, Orkg-Leaderboards transforms the leaderboard extraction task to an automated digitalization task, which has been, for a long time in the community, a crowdsourced endeavor. ",
    "url": "https://arxiv.org/abs/2305.11068",
    "authors": [
      "Salomon Kabongo",
      "Jennifer D'Souza",
      "S\u00f6ren Auer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.11072",
    "title": "Self-supervised Fine-tuning for Improved Content Representations by  Speaker-invariant Clustering",
    "abstract": "Self-supervised speech representation models have succeeded in various tasks, but improving them for content-related problems using unlabeled data is challenging. We propose speaker-invariant clustering (Spin), a novel self-supervised learning method that clusters speech representations and performs swapped prediction between the original and speaker-perturbed utterances. Spin disentangles speaker information and preserves content representations with just 45 minutes of fine-tuning on a single GPU. Spin improves pre-trained networks and outperforms prior methods in speech recognition and acoustic unit discovery. ",
    "url": "https://arxiv.org/abs/2305.11072",
    "authors": [
      "Heng-Jui Chang",
      "Alexander H. Liu",
      "James Glass"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.11074",
    "title": "Tram: A Token-level Retrieval-augmented Mechanism for Source Code  Summarization",
    "abstract": "Automatically generating human-readable text describing the functionality of a program is the intent of source code summarization. Although Neural Language Models achieve significant performance in this field, an emerging trend is combining neural models with external knowledge. Most previous approaches rely on the sentence-level retrieval and combination paradigm (retrieval of similar code snippets and use of the corresponding code and summary pairs) on the encoder side. However, this paradigm is coarse-grained and cannot directly take advantage of the high-quality retrieved summary tokens on the decoder side. In this paper, we explore a fine-grained token-level retrieval-augmented mechanism on the decoder side to help the vanilla neural model generate a better code summary. Furthermore, to mitigate the limitation of token-level retrieval on capturing contextual code semantics, we propose to integrate code semantics into summary tokens. Extensive experiments and human evaluation reveal that our token-level retrieval-augmented approach significantly improves performance and is more interpretive. ",
    "url": "https://arxiv.org/abs/2305.11074",
    "authors": [
      "Tong Ye",
      "Lingfei Wu",
      "Tengfei Ma",
      "Xuhong Zhang",
      "Yangkai Du",
      "Peiyu Liu",
      "Wenhai Wang",
      "Shouling Ji"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.11077",
    "title": "A Comparative Study of Face Detection Algorithms for Masked Face  Detection",
    "abstract": "Contemporary face detection algorithms have to deal with many challenges such as variations in pose, illumination, and scale. A subclass of the face detection problem that has recently gained increasing attention is occluded face detection, or more specifically, the detection of masked faces. Three years on since the advent of the COVID-19 pandemic, there is still a complete lack of evidence regarding how well existing face detection algorithms perform on masked faces. This article first offers a brief review of state-of-the-art face detectors and detectors made for the masked face problem, along with a review of the existing masked face datasets. We evaluate and compare the performances of a well-representative set of face detectors at masked face detection and conclude with a discussion on the possible contributing factors to their performance. ",
    "url": "https://arxiv.org/abs/2305.11077",
    "authors": [
      "Sahel Mohammad Iqbal",
      "Danush Shekar",
      "Subhankar Mishra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.11096",
    "title": "Cross-modality Data Augmentation for End-to-End Sign Language  Translation",
    "abstract": "End-to-end sign language translation (SLT) aims to convert sign language videos into spoken language texts directly without intermediate representations. It has been a challenging task due to the modality gap between sign videos and texts and the data scarcity of labeled data. To tackle these challenges, we propose a novel Cross-modality Data Augmentation (XmDA) framework to transfer the powerful gloss-to-text translation capabilities to end-to-end sign language translation (i.e. video-to-text) by exploiting pseudo gloss-text pairs from the sign gloss translation model. Specifically, XmDA consists of two key components, namely, cross-modality mix-up and cross-modality knowledge distillation. The former explicitly encourages the alignment between sign video features and gloss embeddings to bridge the modality gap. The latter utilizes the generation knowledge from gloss-to-text teacher models to guide the spoken language text generation. Experimental results on two widely used SLT datasets, i.e., PHOENIX-2014T and CSL-Daily, demonstrate that the proposed XmDA framework significantly and consistently outperforms the baseline models. Extensive analyses confirm our claim that XmDA enhances spoken language text generation by reducing the representation distance between videos and texts, as well as improving the processing of low-frequency words and long sentences. ",
    "url": "https://arxiv.org/abs/2305.11096",
    "authors": [
      "Jinhui Ye",
      "Wenxiang Jiao",
      "Xing Wang",
      "Zhaopeng Tu",
      "Hui Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.11102",
    "title": "Progressive Learning of 3D Reconstruction Network from 2D GAN Data",
    "abstract": "This paper presents a method to reconstruct high-quality textured 3D models from single images. Current methods rely on datasets with expensive annotations; multi-view images and their camera parameters. Our method relies on GAN generated multi-view image datasets which have a negligible annotation cost. However, they are not strictly multi-view consistent and sometimes GANs output distorted images. This results in degraded reconstruction qualities. In this work, to overcome these limitations of generated datasets, we have two main contributions which lead us to achieve state-of-the-art results on challenging objects: 1) A robust multi-stage learning scheme that gradually relies more on the models own predictions when calculating losses, 2) A novel adversarial learning pipeline with online pseudo-ground truth generations to achieve fine details. Our work provides a bridge from 2D supervisions of GAN models to 3D reconstruction models and removes the expensive annotation efforts. We show significant improvements over previous methods whether they were trained on GAN generated multi-view images or on real images with expensive annotations. Please visit our web-page for 3D visuals: https://research.nvidia.com/labs/adlr/progressive-3d-learning ",
    "url": "https://arxiv.org/abs/2305.11102",
    "authors": [
      "Aysegul Dundar",
      "Jun Gao",
      "Andrew Tao",
      "Bryan Catanzaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.11137",
    "title": "Parallel development of social preferences in fish and machines",
    "abstract": "What are the computational foundations of social grouping? Traditional approaches to this question have focused on verbal reasoning or simple (low-dimensional) quantitative models. In the real world, however, social preferences emerge when high-dimensional learning systems (brains and bodies) interact with high-dimensional sensory inputs during an animal's embodied interactions with the world. A deep understanding of social grouping will therefore require embodied models that learn directly from sensory inputs using high-dimensional learning mechanisms. To this end, we built artificial neural networks (ANNs), embodied those ANNs in virtual fish bodies, and raised the artificial fish in virtual fish tanks that mimicked the rearing conditions of real fish. We then compared the social preferences that emerged in real fish versus artificial fish. We found that when artificial fish had two core learning mechanisms (reinforcement learning and curiosity-driven learning), artificial fish developed fish-like social preferences. Like real fish, the artificial fish spontaneously learned to prefer members of their own group over members of other groups. The artificial fish also spontaneously learned to self-segregate with their in-group, akin to self-segregation behavior seen in nature. Our results suggest that social grouping can emerge from three ingredients: (1) reinforcement learning, (2) intrinsic motivation, and (3) early social experiences with in-group members. This approach lays a foundation for reverse engineering animal-like social behavior with image-computable models, bridging the divide between high-dimensional sensory inputs and social preferences. ",
    "url": "https://arxiv.org/abs/2305.11137",
    "authors": [
      "Joshua McGraw",
      "Donsuk Lee",
      "Justin Wood"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.11141",
    "title": "Clifford Group Equivariant Neural Networks",
    "abstract": "We introduce Clifford Group Equivariant Neural Networks: a novel approach for constructing $\\mathrm{E}(n)$-equivariant networks. We identify and study the $\\textit{Clifford group}$, a subgroup inside the Clifford algebra, whose definition we slightly adjust to achieve several favorable properties. Primarily, the group's action forms an orthogonal automorphism that extends beyond the typical vector space to the entire Clifford algebra while respecting the multivector grading. This leads to several non-equivalent subrepresentations corresponding to the multivector decomposition. Furthermore, we prove that the action respects not just the vector space structure of the Clifford algebra but also its multiplicative structure, i.e., the geometric product. These findings imply that every polynomial in multivectors, including their grade projections, constitutes an equivariant map with respect to the Clifford group, allowing us to parameterize equivariant neural network layers. Notable advantages are that these layers operate directly on a vector basis and elegantly generalize to any dimension. We demonstrate, notably from a single core implementation, state-of-the-art performance on several distinct tasks, including a three-dimensional $n$-body experiment, a four-dimensional Lorentz-equivariant high-energy physics experiment, and a five-dimensional convex hull experiment. ",
    "url": "https://arxiv.org/abs/2305.11141",
    "authors": [
      "David Ruhe",
      "Johannes Brandstetter",
      "Patrick Forr\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.11162",
    "title": "High-Performance Graph Databases That Are Portable, Programmable, and  Scale to Hundreds of Thousands of Cores",
    "abstract": "Graph databases (GDBs) are crucial in academic and industry applications. The key challenges in developing GDBs are achieving high performance, scalability, programmability, and portability. To tackle these challenges, we harness established practices from the HPC landscape to build a system that outperforms all past GDBs presented in the literature by orders of magnitude, for both OLTP and OLAP workloads. For this, we first identify and crystallize performance-critical building blocks in the GDB design, and abstract them into a portable and programmable API specification, called the Graph Database Interface (GDI), inspired by the best practices of MPI. We then use GDI to design a GDB for distributed-memory RDMA architectures. Our implementation harnesses one-sided RDMA communication and collective operations, and it offers architecture-independent theoretical performance guarantees. The resulting design achieves extreme scales of more than a hundred thousand cores. Our work will facilitate the development of next-generation extreme-scale graph databases. ",
    "url": "https://arxiv.org/abs/2305.11162",
    "authors": [
      "Maciej Besta",
      "Robert Gerstenberger",
      "Marc Fischer",
      "Micha\u0142 Podstawski",
      "J\u00fcrgen M\u00fcller",
      "Nils Blach",
      "Berke Egeli",
      "George Mitenkov",
      "Wojciech Chlapek",
      "Marek Michalewicz",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2305.11164",
    "title": "Exploring the Carbon Footprint of Hugging Face's ML Models: A Repository  Mining Study",
    "abstract": "The rise of machine learning (ML) systems has exacerbated their carbon footprint due to increased capabilities and model sizes. However, there is scarce knowledge on how the carbon footprint of ML models is actually measured, reported, and evaluated. In light of this, the paper aims to analyze the measurement of the carbon footprint of 1,417 ML models and associated datasets on Hugging Face, which is the most popular repository for pretrained ML models. The goal is to provide insights and recommendations on how to report and optimize the carbon efficiency of ML models. The study includes the first repository mining study on the Hugging Face Hub API on carbon emissions. This study seeks to answer two research questions: (1) how do ML model creators measure and report carbon emissions on Hugging Face Hub?, and (2) what aspects impact the carbon emissions of training ML models? The study yielded several key findings. These include a decreasing proportion of carbon emissions-reporting models, a slight decrease in reported carbon footprint on Hugging Face over the past 2 years, and a continued dominance of NLP as the main application domain. Furthermore, the study uncovers correlations between carbon emissions and various attributes such as model size, dataset size, and ML application domains. These results highlight the need for software measurements to improve energy reporting practices and promote carbon-efficient model development within the Hugging Face community. In response to this issue, two classifications are proposed: one for categorizing models based on their carbon emission reporting practices and another for their carbon efficiency. The aim of these classification proposals is to foster transparency and sustainable model development within the ML community. ",
    "url": "https://arxiv.org/abs/2305.11164",
    "authors": [
      "Joel Casta\u00f1o",
      "Silverio Mart\u00ednez-Fern\u00e1ndez",
      "Xavier Franch",
      "Justus Bogner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.11172",
    "title": "ONE-PEACE: Exploring One General Representation Model Toward Unlimited  Modalities",
    "abstract": "In this work, we explore a scalable way for building a general representation model toward unlimited modalities. We release ONE-PEACE, a highly extensible model with 4B parameters that can seamlessly align and integrate representations across vision, audio, and language modalities. The architecture of ONE-PEACE comprises modality adapters, shared self-attention layers, and modality FFNs. This design allows for the easy extension of new modalities by adding adapters and FFNs, while also enabling multi-modal fusion through self-attention layers. To pretrain ONE-PEACE, we develop two modality-agnostic pretraining tasks, cross-modal aligning contrast and intra-modal denoising contrast, which align the semantic space of different modalities and capture fine-grained details within modalities concurrently. With the scaling-friendly architecture and pretraining tasks, ONE-PEACE has the potential to expand to unlimited modalities. Without using any vision or language pretrained model for initialization, ONE-PEACE achieves leading results on a wide range of uni-modal and multi-modal tasks, including image classification (ImageNet), semantic segmentation (ADE20K), audio-text retrieval (AudioCaps, Clotho), audio classification (ESC-50, FSD50K, VGGSound), audio question answering (AVQA), image-text retrieval (MSCOCO, Flickr30K), and visual grounding (RefCOCO/+/g). Code is available at https://github.com/OFA-Sys/ONE-PEACE. ",
    "url": "https://arxiv.org/abs/2305.11172",
    "authors": [
      "Peng Wang",
      "Shijie Wang",
      "Junyang Lin",
      "Shuai Bai",
      "Xiaohuan Zhou",
      "Jingren Zhou",
      "Xinggang Wang",
      "Chang Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.00337",
    "title": "A Practical and Economical Bayesian Approach to Gas Price Prediction",
    "abstract": "On the Ethereum network, it is challenging to determine a gas price that ensures a transaction will be included in a block within a user's required timeline without overpaying. One way of addressing this problem is through the use of gas price oracles that utilize historical block data to recommend gas prices. However, when transaction volumes increase rapidly, these oracles often underestimate or overestimate the price. In this paper, we demonstrate how Gaussian process models can predict the distribution of the minimum price in an upcoming block when transaction volumes are increasing. This is effective because these processes account for time correlations between blocks. We performed an empirical analysis using the Gaussian process model on historical block data and compared the performance with GasStation-Express and Geth gas price oracles. The results suggest that when transactions volumes fluctuate greatly, the Gaussian process model offers a better estimation. Further, we demonstrated that GasStation-Express and Geth can be improved upon by using a smaller training sample size which is properly pre-processed. Based on the results of empirical analysis, we recommended a gas price oracle made up of a hybrid model consisting of both the Gaussian process and GasStation-Express. This oracle provides efficiency, accuracy, and better cost. ",
    "url": "https://arxiv.org/abs/2305.00337",
    "authors": [
      "ChihYun Chuang",
      "TingFang Lee"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2305.10450",
    "title": "Understanding of Normal and Abnormal Hearts by Phase Space Analysis and  Convolutional Neural Networks",
    "abstract": "Cardiac diseases are one of the leading mortality factors in modern, industrialized societies, which cause high expenses in public health systems. Due to high costs, developing analytical methods to improve cardiac diagnostics is essential. The heart's electric activity was first modeled using a set of nonlinear differential equations. Following this, variations of cardiac spectra originating from deterministic dynamics are investigated. Analyzing a normal human heart's power spectra offers His-Purkinje network, which possesses a fractal-like structure. Phase space trajectories are extracted from the time series electrocardiogram (ECG) graph with third-order derivate Taylor Series. Here in this study, phase space analysis and Convolutional Neural Networks (CNNs) method are applied to 44 records via the MIT-BIH database recorded with MLII. In order to increase accuracy, a straight line is drawn between the highest Q-R distance in the phase space images of the records. Binary CNN classification is used to determine healthy or unhealthy hearts. With a 90.90% accuracy rate, this model could classify records according to their heart status. ",
    "url": "https://arxiv.org/abs/2305.10450",
    "authors": [
      "Bekir Yavuz Koc",
      "Taner Arsan",
      "Onder Pekcan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.10466",
    "title": "Solitary pulmonary nodules prediction for lung cancer patients using  nomogram and machine learning",
    "abstract": "Lung cancer(LC) is a type of malignant neoplasm that originates in the bronchial mucosa or glands.As a clinically common nodule,solitary pulmonary nodules(SPNs) have a significantly higher probability of malignancy when they are larger than 8 mm in diameter.But there is also a risk of lung cancer when the diameter is less than 8mm,the purpose of this study was to create a nomogram for estimating the likelihood of lung cancer in patients with SPNs of 8 mm or smaller using computed tomography(CT) scans and biomarker information.Use CT scans and various biomarkers as input to build predictive models for the likelihood of lung cancer in patients with SPNs of 8 mm or less.The age,precursor gastrin-releasing peptide (ProGRP),gender,Carcinoembryonic Antigen(CEA),and stress corrosion cracking(SCC) were independent key tumor markers and were entered into the nomogram.The developed nomogram demonstrated strong accuracy in predicting lung cancer risk,with an internal validation area under the receiver operating characteristics curve(ROC) of 0.8474.The calibration curves plotted showed that the nomogram predicted the probability of lung cancer with good agreement with the actual probability.In this study,we finally succeeded in constructing a suitable nomogram that could predict the risk of lung cancer in patients with SPNs<=8 mm in diameter.The model has a high level of accuracy and is able to accurately distinguish between different patients,allowing clinicians to develop personalized treatment plans for individuals with SPNs. ",
    "url": "https://arxiv.org/abs/2305.10466",
    "authors": [
      "Hailan Zhang",
      "Gongjin Song"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.10467",
    "title": "Analysing Biomedical Knowledge Graphs using Prime Adjacency Matrices",
    "abstract": "Most phenomena related to biomedical tasks are inherently complex, and in many cases, are expressed as signals on biomedical Knowledge Graphs (KGs). In this work, we introduce the use of a new representation framework, the Prime Adjacency Matrix (PAM) for biomedical KGs, which allows for very efficient network analysis. PAM utilizes prime numbers to enable representing the whole KG with a single adjacency matrix and the fast computation of multiple properties of the network. We illustrate the applicability of the framework in the biomedical domain by working on different biomedical knowledge graphs and by providing two case studies: one on drug-repurposing for COVID-19 and one on important metapath extraction. We show that we achieve better results than the original proposed workflows, using very simple methods that require no training, in considerably less time. ",
    "url": "https://arxiv.org/abs/2305.10467",
    "authors": [
      "Konstantinos Bougiatiotis",
      "Georgios Paliouras"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10473",
    "title": "Predicting Side Effect of Drug Molecules using Recurrent Neural Networks",
    "abstract": "Identification and verification of molecular properties such as side effects is one of the most important and time-consuming steps in the process of molecule synthesis. For example, failure to identify side effects before submission to regulatory groups can cost millions of dollars and months of additional research to the companies. Failure to identify side effects during the regulatory review can also cost lives. The complexity and expense of this task have made it a candidate for a machine learning-based solution. Prior approaches rely on complex model designs and excessive parameter counts for side effect predictions. We believe reliance on complex models only shifts the difficulty away from chemists rather than alleviating the issue. Implementing large models is also expensive without prior access to high-performance computers. We propose a heuristic approach that allows for the utilization of simple neural networks, specifically the recurrent neural network, with a 98+% reduction in the number of required parameters compared to available large language models while still obtaining near identical results as top-performing models. ",
    "url": "https://arxiv.org/abs/2305.10473",
    "authors": [
      "Collin Beaudoin",
      "Koustubh Phalak",
      "Swaroop Ghosh"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10502",
    "title": "EENED: End-to-End Neural Epilepsy Detection based on Convolutional  Transformer",
    "abstract": "Recently Transformer and Convolution neural network (CNN) based models have shown promising results in EEG signal processing. Transformer models can capture the global dependencies in EEG signals through a self-attention mechanism, while CNN models can capture local features such as sawtooth waves. In this work, we propose an end-to-end neural epilepsy detection model, EENED, that combines CNN and Transformer. Specifically, by introducing the convolution module into the Transformer encoder, EENED can learn the time-dependent relationship of the patient's EEG signal features and notice local EEG abnormal mutations closely related to epilepsy, such as the appearance of spikes and the sprinkling of sharp and slow waves. Our proposed framework combines the ability of Transformer and CNN to capture different scale features of EEG signals and holds promise for improving the accuracy and reliability of epilepsy detection. Our source code will be released soon on GitHub. ",
    "url": "https://arxiv.org/abs/2305.10502",
    "authors": [
      "Chenyu Liu",
      "Xinliang Zhou",
      "Yang Liu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10569",
    "title": "Self-Supervised Learning for Physiologically-Based Pharmacokinetic  Modeling in Dynamic PET",
    "abstract": "Dynamic positron emission tomography imaging (dPET) provides temporally resolved images of a tracer enabling a quantitative measure of physiological processes. Voxel-wise physiologically-based pharmacokinetic (PBPK) modeling of the time activity curves (TAC) can provide relevant diagnostic information for clinical workflow. Conventional fitting strategies for TACs are slow and ignore the spatial relation between neighboring voxels. We train a spatio-temporal UNet to estimate the kinetic parameters given TAC from F-18-fluorodeoxyglucose (FDG) dPET. This work introduces a self-supervised loss formulation to enforce the similarity between the measured TAC and those generated with the learned kinetic parameters. Our method provides quantitatively comparable results at organ-level to the significantly slower conventional approaches, while generating pixel-wise parametric images which are consistent with expected physiology. To the best of our knowledge, this is the first self-supervised network that allows voxel-wise computation of kinetic parameters consistent with a non-linear kinetic model. The code will become publicly available upon acceptance. ",
    "url": "https://arxiv.org/abs/2305.10569",
    "authors": [
      "Francesca De Benetti",
      "Walter Simson",
      "Magdalini Paschali",
      "Hasan Sari",
      "Axel Romiger",
      "Kuangyu Shi",
      "Nassir Navab",
      "Thomas Wendler"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10631",
    "title": "A Subabdominal MRI Image Segmentation Algorithm Based on Multi-Scale  Feature Pyramid Network and Dual Attention Mechanism",
    "abstract": "This study aimed to solve the semantic gap and misalignment issue between encoding and decoding because of multiple convolutional and pooling operations in U-Net when segmenting subabdominal MRI images during rectal cancer treatment. A MRI Image Segmentation is proposed based on a multi-scale feature pyramid network and dual attention mechanism. Our innovation is the design of two modules: 1) a dilated convolution and multi-scale feature pyramid network are used in the encoding to avoid the semantic gap. 2) a dual attention mechanism is designed to maintain spatial information of U-Net and reduce misalignment. Experiments on a subabdominal MRI image dataset show the proposed method achieves better performance than others methods. In conclusion, a multi-scale feature pyramid network can reduce the semantic gap, and the dual attention mechanism can make an alignment of features between encoding and decoding. ",
    "url": "https://arxiv.org/abs/2305.10631",
    "authors": [
      "Yu Xiao",
      "Xin Yang",
      "Sijuan Huang",
      "Yongkai Liu",
      "Lihua Guo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10664",
    "title": "Posterior Inference on Infinitely Wide Bayesian Neural Networks under  Weights with Unbounded Variance",
    "abstract": "From the classical and influential works of Neal (1996), it is known that the infinite width scaling limit of a Bayesian neural network with one hidden layer is a Gaussian process, \\emph{when the network weights have bounded prior variance}. Neal's result has been extended to networks with multiple hidden layers and to convolutional neural networks, also with Gaussian process scaling limits. The tractable properties of Gaussian processes then allow straightforward posterior inference and uncertainty quantification, considerably simplifying the study of the limit process compared to a network of finite width. Neural network weights with unbounded variance, however, pose unique challenges. In this case, the classical central limit theorem breaks down and it is well known that the scaling limit is an $\\alpha$-stable process under suitable conditions. However, current literature is primarily limited to forward simulations under these processes and the problem of posterior inference under such a scaling limit remains largely unaddressed, unlike in the Gaussian process case. To this end, our contribution is an interpretable and computationally efficient procedure for posterior inference, using a \\emph{conditionally Gaussian} representation, that then allows full use of the Gaussian process machinery for tractable posterior inference and uncertainty quantification in the non-Gaussian regime. ",
    "url": "https://arxiv.org/abs/2305.10664",
    "authors": [
      "Jorge Lor\u00eda",
      "Anindya Bhadra"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10684",
    "title": "Data Augmentation for Diverse Voice Conversion in Noisy Environments",
    "abstract": "Voice conversion (VC) models have demonstrated impressive few-shot conversion quality on the clean, native speech populations they're trained on. However, when source or target speech accents, background noise conditions, or microphone characteristics differ from training, quality voice conversion is not guaranteed. These problems are often left unexamined in VC research, giving rise to frustration in users trying to use pretrained VC models on their own data. We are interested in accent-preserving voice conversion for name pronunciation from self-recorded examples, a domain in which all three of the aforementioned conditions are present, and posit that demonstrating higher performance in this domain correlates with creating VC models that are more usable by otherwise frustrated users. We demonstrate that existing SOTA encoder-decoder VC models can be made robust to these variations and endowed with natural denoising capabilities using more diverse data and simple data augmentation techniques in pretraining. ",
    "url": "https://arxiv.org/abs/2305.10684",
    "authors": [
      "Avani Tanna",
      "Michael Saxon",
      "Amr El Abbadi",
      "William Yang Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.10706",
    "title": "A Framework Based on Symbolic Regression Coupled with eXtended  Physics-Informed Neural Networks for Gray-Box Learning of Equations of Motion  from Data",
    "abstract": "We propose a framework and an algorithm to uncover the unknown parts of nonlinear equations directly from data. The framework is based on eXtended Physics-Informed Neural Networks (X-PINNs), domain decomposition in space-time, but we augment the original X-PINN method by imposing flux continuity across the domain interfaces. The well-known Allen-Cahn equation is used to demonstrate the approach. The Frobenius matrix norm is used to evaluate the accuracy of the X-PINN predictions and the results show excellent performance. In addition, symbolic regression is employed to determine the closed form of the unknown part of the equation from the data, and the results confirm the accuracy of the X-PINNs based approach. To test the framework in a situation resembling real-world data, random noise is added to the datasets to mimic scenarios such as the presence of thermal noise or instrument errors. The results show that the framework is stable against significant amount of noise. As the final part, we determine the minimal amount of data required for training the neural network. The framework is able to predict the correct form and coefficients of the underlying dynamical equation when at least 50\\% data is used for training. ",
    "url": "https://arxiv.org/abs/2305.10706",
    "authors": [
      "Elham Kiyani",
      "Khemraj Shukla",
      "George Em Karniadakis",
      "Mikko Karttunen"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10823",
    "title": "FastFit: Towards Real-Time Iterative Neural Vocoder by Replacing U-Net  Encoder With Multiple STFTs",
    "abstract": "This paper presents FastFit, a novel neural vocoder architecture that replaces the U-Net encoder with multiple short-time Fourier transforms (STFTs) to achieve faster generation rates without sacrificing sample quality. We replaced each encoder block with an STFT, with parameters equal to the temporal resolution of each decoder block, leading to the skip connection. FastFit reduces the number of parameters and the generation time of the model by almost half while maintaining high fidelity. Through objective and subjective evaluations, we demonstrated that the proposed model achieves nearly twice the generation speed of baseline iteration-based vocoders while maintaining high sound quality. We further showed that FastFit produces sound qualities similar to those of other baselines in text-to-speech evaluation scenarios, including multi-speaker and zero-shot text-to-speech. ",
    "url": "https://arxiv.org/abs/2305.10823",
    "authors": [
      "Won Jang",
      "Dan Lim",
      "Heayoung Park"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.11049",
    "title": "NODE-ImgNet: a PDE-informed effective and robust model for image  denoising",
    "abstract": "Inspired by the traditional partial differential equation (PDE) approach for image denoising, we propose a novel neural network architecture, referred as NODE-ImgNet, that combines neural ordinary differential equations (NODEs) with convolutional neural network (CNN) blocks. NODE-ImgNet is intrinsically a PDE model, where the dynamic system is learned implicitly without the explicit specification of the PDE. This naturally circumvents the typical issues associated with introducing artifacts during the learning process. By invoking such a NODE structure, which can also be viewed as a continuous variant of a residual network (ResNet) and inherits its advantage in image denoising, our model achieves enhanced accuracy and parameter efficiency. In particular, our model exhibits consistent effectiveness in different scenarios, including denoising gray and color images perturbed by Gaussian noise, as well as real-noisy images, and demonstrates superiority in learning from small image datasets. ",
    "url": "https://arxiv.org/abs/2305.11049",
    "authors": [
      "Xinheng Xie",
      "Yue Wu",
      "Hao Ni",
      "Cuiyu He"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.11097",
    "title": "Statistical Foundations of Prior-Data Fitted Networks",
    "abstract": "Prior-data fitted networks (PFNs) were recently proposed as a new paradigm for machine learning. Instead of training the network to an observed training set, a fixed model is pre-trained offline on small, simulated training sets from a variety of tasks. The pre-trained model is then used to infer class probabilities in-context on fresh training sets with arbitrary size and distribution. Empirically, PFNs achieve state-of-the-art performance on tasks with similar size to the ones used in pre-training. Surprisingly, their accuracy further improves when passed larger data sets during inference. This article establishes a theoretical foundation for PFNs and illuminates the statistical mechanisms governing their behavior. While PFNs are motivated by Bayesian ideas, a purely frequentistic interpretation of PFNs as pre-tuned, but untrained predictors explains their behavior. A predictor's variance vanishes if its sensitivity to individual training samples does and the bias vanishes only if it is appropriately localized around the test feature. The transformer architecture used in current PFN implementations ensures only the former. These findings shall prove useful for designing architectures with favorable empirical behavior. ",
    "url": "https://arxiv.org/abs/2305.11097",
    "authors": [
      "Thomas Nagler"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.11107",
    "title": "From Data-Fitting to Discovery: Interpreting the Neural Dynamics of  Motor Control through Reinforcement Learning",
    "abstract": "In motor neuroscience, artificial recurrent neural networks models often complement animal studies. However, most modeling efforts are limited to data-fitting, and the few that examine virtual embodied agents in a reinforcement learning context, do not draw direct comparisons to their biological counterparts. Our study addressing this gap, by uncovering structured neural activity of a virtual robot performing legged locomotion that directly support experimental findings of primate walking and cycling. We find that embodied agents trained to walk exhibit smooth dynamics that avoid tangling -- or opposing neural trajectories in neighboring neural space -- a core principle in computational neuroscience. Specifically, across a wide suite of gaits, the agent displays neural trajectories in the recurrent layers are less tangled than those in the input-driven actuation layers. To better interpret the neural separation of these elliptical-shaped trajectories, we identify speed axes that maximizes variance of mean activity across different forward, lateral, and rotational speed conditions. ",
    "url": "https://arxiv.org/abs/2305.11107",
    "authors": [
      "Eugene R. Rush",
      "Kaushik Jayaram",
      "J. Sean Humbert"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.11111",
    "title": "PPDONet: Deep Operator Networks for Fast Prediction of Steady-State  Solutions in Disk-Planet Systems",
    "abstract": "We develop a tool, which we name Protoplanetary Disk Operator Network (PPDONet), that can predict the solution of disk-planet interactions in protoplanetary disks in real-time. We base our tool on Deep Operator Networks (DeepONets), a class of neural networks capable of learning non-linear operators to represent deterministic and stochastic differential equations. With PPDONet we map three scalar parameters in a disk-planet system -- the Shakura \\& Sunyaev viscosity $\\alpha$, the disk aspect ratio $h_\\mathrm{0}$, and the planet-star mass ratio $q$ -- to steady-state solutions of the disk surface density, radial velocity, and azimuthal velocity. We demonstrate the accuracy of the PPDONet solutions using a comprehensive set of tests. Our tool is able to predict the outcome of disk-planet interaction for one system in less than a second on a laptop. A public implementation of PPDONet is available at \\url{https://github.com/smao-astro/PPDONet}. ",
    "url": "https://arxiv.org/abs/2305.11111",
    "authors": [
      "Shunyuan Mao",
      "Ruobing Dong",
      "Lu Lu",
      "Kwang Moo Yi",
      "Sifan Wang",
      "Paris Perdikaris"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.11120",
    "title": "A Compound Gaussian Network for Solving Linear Inverse Problems",
    "abstract": "For solving linear inverse problems, particularly of the type that appear in tomographic imaging and compressive sensing, this paper develops two new approaches. The first approach is an iterative algorithm that minimizers a regularized least squares objective function where the regularization is based on a compound Gaussian prior distribution. The Compound Gaussian prior subsumes many of the commonly used priors in image reconstruction, including those of sparsity-based approaches. The developed iterative algorithm gives rise to the paper's second new approach, which is a deep neural network that corresponds to an \"unrolling\" or \"unfolding\" of the iterative algorithm. Unrolled deep neural networks have interpretable layers and outperform standard deep learning methods. This paper includes a detailed computational theory that provides insight into the construction and performance of both algorithms. The conclusion is that both algorithms outperform other state-of-the-art approaches to tomographic image formation and compressive sensing, especially in the difficult regime of low training. ",
    "url": "https://arxiv.org/abs/2305.11120",
    "authors": [
      "Carter Lyons",
      "Raghu G. Raj",
      "Margaret Cheney"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2305.11125",
    "title": "Skin Lesion Diagnosis Using Convolutional Neural Networks",
    "abstract": "Cancerous skin lesions are one of the most common malignancies detected in humans, and if not detected at an early stage, they can lead to death. Therefore, it is crucial to have access to accurate results early on to optimize the chances of survival. Unfortunately, accurate results are typically obtained by highly trained dermatologists, who may not be accessible to many people, particularly in low-income and middle-income countries. Artificial Intelligence (AI) appears to be a potential solution to this problem, as it has proven to provide equal or even better diagnoses than healthcare professionals. This project aims to address the issue by collecting state-of-the-art techniques for image classification from various fields and implementing them. Some of these techniques include mixup, presizing, and test-time augmentation, among others. Three architectures were used for the implementation: DenseNet121, VGG16 with batch normalization, and ResNet50. The models were designed with two main purposes. First, to classify images into seven categories, including melanocytic nevus, melanoma, benign keratosis-like lesions, basal cell carcinoma, actinic keratoses and intraepithelial carcinoma, vascular lesions, and dermatofibroma. Second, to classify images into benign or malignant. The models were trained using a dataset of 8012 images, and their performance was evaluated using 2003 images. It's worth noting that this model is trained end-to-end, directly from the image to the labels, without the need for handcrafted feature extraction. ",
    "url": "https://arxiv.org/abs/2305.11125",
    "authors": [
      "Daniel Alonso Villanueva Nunez",
      "Yongmin Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.11132",
    "title": "Attacks on Online Learners: a Teacher-Student Analysis",
    "abstract": "Machine learning models are famously vulnerable to adversarial attacks: small ad-hoc perturbations of the data that can catastrophically alter the model predictions. While a large literature has studied the case of test-time attacks on pre-trained models, the important case of attacks in an online learning setting has received little attention so far. In this work, we use a control-theoretical perspective to study the scenario where an attacker may perturb data labels to manipulate the learning dynamics of an online learner. We perform a theoretical analysis of the problem in a teacher-student setup, considering different attack strategies, and obtaining analytical results for the steady state of simple linear learners. These results enable us to prove that a discontinuous transition in the learner's accuracy occurs when the attack strength exceeds a critical threshold. We then study empirically attacks on learners with complex architectures using real data, confirming the insights of our theoretical analysis. Our findings show that greedy attacks can be extremely efficient, especially when data stream in small batches. ",
    "url": "https://arxiv.org/abs/2305.11132",
    "authors": [
      "Riccardo Giuseppe Margiotta",
      "Sebastian Goldt",
      "Guido Sanguinetti"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2012.01724",
    "title": "Parallel Residual Bi-Fusion Feature Pyramid Network for Accurate  Single-Shot Object Detection",
    "abstract": " Comments: accepted by IEEE transactions on Image Processing ",
    "url": "https://arxiv.org/abs/2012.01724",
    "authors": [
      "Ping-Yang Chen",
      "Ming-Ching Chang",
      "Jun-Wei Hsieh",
      "Yong-Sheng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.04726",
    "title": "AutoTriggER: Label-Efficient and Robust Named Entity Recognition with  Auxiliary Trigger Extraction",
    "abstract": " Comments: 15 pages, 13 figures, EACL 2023 ",
    "url": "https://arxiv.org/abs/2109.04726",
    "authors": [
      "Dong-Ho Lee",
      "Ravi Kiran Selvam",
      "Sheikh Muhammad Sarwar",
      "Bill Yuchen Lin",
      "Fred Morstatter",
      "Jay Pujara",
      "Elizabeth Boschee",
      "James Allan",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2112.14265",
    "title": "Learning in Repeated Interactions on Networks",
    "abstract": " Comments: 28 pages ",
    "url": "https://arxiv.org/abs/2112.14265",
    "authors": [
      "Wanying Huang",
      "Philipp Strack",
      "Omer Tamuz"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2202.13047",
    "title": "AugESC: Dialogue Augmentation with Large Language Models for Emotional  Support Conversation",
    "abstract": " Comments: Findings of ACL 2023 ",
    "url": "https://arxiv.org/abs/2202.13047",
    "authors": [
      "Chujie Zheng",
      "Sahand Sabour",
      "Jiaxin Wen",
      "Zheng Zhang",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.16973",
    "title": "Analyzing the factors affecting usefulness of Self-Supervised  Pre-trained Representations for Speech Recognition",
    "abstract": " Title: Analyzing the factors affecting usefulness of Self-Supervised  Pre-trained Representations for Speech Recognition ",
    "url": "https://arxiv.org/abs/2203.16973",
    "authors": [
      "Ashish Seth",
      "Lodagala V S V Durga Prasad",
      "Sreyan Ghosh",
      "S. Umesh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.02179",
    "title": "Towards Power-Efficient Design of Myoelectric Controller based on  Evolutionary Computation",
    "abstract": " Comments: There is some error in the experimental result section ",
    "url": "https://arxiv.org/abs/2204.02179",
    "authors": [
      "Ahmed Aqeel Shaikh",
      "Anand Kumar Mukhopadhyay",
      "Soumyajit Poddar",
      "Suman Samui"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.03083",
    "title": "Audio-Visual Person-of-Interest DeepFake Detection",
    "abstract": " Title: Audio-Visual Person-of-Interest DeepFake Detection ",
    "url": "https://arxiv.org/abs/2204.03083",
    "authors": [
      "Davide Cozzolino",
      "Alessandro Pianese",
      "Matthias Nie\u00dfner",
      "Luisa Verdoliva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.07134",
    "title": "Reinforcement Learning Policy Recommendation for Interbank Network  Stability",
    "abstract": " Comments: 63 pages, 24 figures. Submitted the revised version that is going to be published on the Journal of Financial Stability ",
    "url": "https://arxiv.org/abs/2204.07134",
    "authors": [
      "Alessio Brini",
      "Gabriele Tedeschi",
      "Daniele Tantari"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.09397",
    "title": "Adversarial Scratches: Deployable Attacks to CNN Classifiers",
    "abstract": " Comments: This work is published at Pattern Recognition (Elsevier). This paper stems from 'Scratch that! An Evolution-based Adversarial Attack against Neural Networks' for which an arXiv preprint is available at arXiv:1912.02316. Further studies led to a complete overhaul of the work, resulting in this paper ",
    "url": "https://arxiv.org/abs/2204.09397",
    "authors": [
      "Loris Giulivi",
      "Malhar Jere",
      "Loris Rossi",
      "Farinaz Koushanfar",
      "Gabriela Ciocarlie",
      "Briland Hitaj",
      "Giacomo Boracchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.10650",
    "title": "Transformer-based out-of-distribution detection for clinically safe  segmentation",
    "abstract": " Comments: Accepted at MIDL 2022 (Oral) ",
    "url": "https://arxiv.org/abs/2205.10650",
    "authors": [
      "Mark S Graham",
      "Petru-Daniel Tudosiu",
      "Paul Wright",
      "Walter Hugo Lopez Pinaya",
      "U Jean-Marie",
      "Yee Mah",
      "James Teo",
      "Rolf H J\u00e4ger",
      "David Werring",
      "Parashkev Nachev",
      "Sebastien Ourselin",
      "M Jorge Cardoso"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00148",
    "title": "Generating Counterfactual Hard Negative Samples for Graph Contrastive  Learning",
    "abstract": " Comments: ACCEPTED BY WWW'2023 ",
    "url": "https://arxiv.org/abs/2207.00148",
    "authors": [
      "Haoran Yang",
      "Hongxu Chen",
      "Sixiao Zhang",
      "Xiangguo Sun",
      "Qian Li",
      "Xiangyu Zhao",
      "Guandong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.00669",
    "title": "Differentiable Collision Detection for a Set of Convex Primitives",
    "abstract": " Title: Differentiable Collision Detection for a Set of Convex Primitives ",
    "url": "https://arxiv.org/abs/2207.00669",
    "authors": [
      "Kevin Tracy",
      "Taylor A. Howell",
      "Zachary Manchester"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.08610",
    "title": "Rapid and robust synchronization via weak synaptic coupling",
    "abstract": " Comments: 16 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2207.08610",
    "authors": [
      "Jin Gyu Lee",
      "Rodolphe Sepulchre"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.10364",
    "title": "Scaling Up Dynamic Graph Representation Learning via Spiking Neural  Networks",
    "abstract": " Comments: Accepted by AAAI 2023.Contains appendix with additional details about algorithms and experiments. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2208.10364",
    "authors": [
      "Jintang Li",
      "Zhouxin Yu",
      "Zulun Zhu",
      "Liang Chen",
      "Qi Yu",
      "Zibin Zheng",
      "Sheng Tian",
      "Ruofan Wu",
      "Changhua Meng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.04333",
    "title": "Ranking-Enhanced Unsupervised Sentence Representation Learning",
    "abstract": " Comments: ACL 2023 ",
    "url": "https://arxiv.org/abs/2209.04333",
    "authors": [
      "Yeon Seonwoo",
      "Guoyin Wang",
      "Changmin Seo",
      "Sajal Choudhary",
      "Jiwei Li",
      "Xiang Li",
      "Puyang Xu",
      "Sunghyun Park",
      "Alice Oh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2209.10438",
    "title": "A Measure of the Complexity of Neural Representations based on Partial  Information Decomposition",
    "abstract": " Comments: 31 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2209.10438",
    "authors": [
      "David A. Ehrlich",
      "Andreas C. Schneider",
      "Viola Priesemann",
      "Michael Wibral",
      "Abdullah Makkeh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.06015",
    "title": "EC-NAS: Energy Consumption Aware Tabular Benchmarks for Neural  Architecture Search",
    "abstract": " Comments: Source code at this https URL ",
    "url": "https://arxiv.org/abs/2210.06015",
    "authors": [
      "Pedram Bakhtiarifard",
      "Christian Igel",
      "Raghavendra Selvan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.08855",
    "title": "PeerDA: Data Augmentation via Modeling Peer Relation for Span  Identification Tasks",
    "abstract": " Comments: To appear at ACL 2023 main conference ",
    "url": "https://arxiv.org/abs/2210.08855",
    "authors": [
      "Weiwen Xu",
      "Xin Li",
      "Yang Deng",
      "Wai Lam",
      "Lidong Bing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12916",
    "title": "Explaining epsilon in local differential privacy through the lens of  quantitative information flow",
    "abstract": " Title: Explaining epsilon in local differential privacy through the lens of  quantitative information flow ",
    "url": "https://arxiv.org/abs/2210.12916",
    "authors": [
      "Natasha Fernandes",
      "Annabelle McIver",
      "Parastoo Sadeghi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.14675",
    "title": "Comparison of neural closure models for discretised PDEs",
    "abstract": " Comments: 24 pages and 9 figures. Submitted to Computers and Mathematics with Applications. For associated code, see this https URL ",
    "url": "https://arxiv.org/abs/2210.14675",
    "authors": [
      "Hugo Melchers",
      "Daan Crommelin",
      "Barry Koren",
      "Vlado Menkovski",
      "Benjamin Sanderse"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2211.00923",
    "title": "SpeechBlender: Speech Augmentation Framework for Mispronunciation Data  Generation",
    "abstract": " Comments: 5 pages, ",
    "url": "https://arxiv.org/abs/2211.00923",
    "authors": [
      "Yassine El Kheir",
      "Shammur Absar Chowdhury",
      "Hamdy Mubarak",
      "Shazia Afzal",
      "Ahmed Ali"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2211.01519",
    "title": "SLICER: Learning universal audio representations using low-resource  self-supervised pre-training",
    "abstract": " Comments: ICASSP 2023 ",
    "url": "https://arxiv.org/abs/2211.01519",
    "authors": [
      "Ashish Seth",
      "Sreyan Ghosh",
      "S. Umesh",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.12944",
    "title": "SPCXR: Self-supervised Pretraining using Chest X-rays Towards a Domain  Specific Foundation Model",
    "abstract": " Title: SPCXR: Self-supervised Pretraining using Chest X-rays Towards a Domain  Specific Foundation Model ",
    "url": "https://arxiv.org/abs/2211.12944",
    "authors": [
      "Syed Muhammad Anwar",
      "Abhijeet Parida",
      "Sara Atito",
      "Muhammad Awais",
      "Gustavo Nino",
      "Josef Kitler",
      "Marius George Linguraru"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.14047",
    "title": "On the Universal Approximation Property of Deep Fully Convolutional  Neural Networks",
    "abstract": " Comments: 25 pages ",
    "url": "https://arxiv.org/abs/2211.14047",
    "authors": [
      "Ting Lin",
      "Zuowei Shen",
      "Qianxiao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16468",
    "title": "Linear-Time Algorithms for Front-Door Adjustment in Causal Graphs",
    "abstract": " Title: Linear-Time Algorithms for Front-Door Adjustment in Causal Graphs ",
    "url": "https://arxiv.org/abs/2211.16468",
    "authors": [
      "Marcel Wien\u00f6bst",
      "Benito van der Zander",
      "Maciej Li\u015bkiewicz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2212.02055",
    "title": "Graph Convolutional Neural Networks with Diverse Negative Samples via  Decomposed Determinant Point Processes",
    "abstract": " Comments: Submitted to TNNLS and under review. arXiv admin note: text overlap with arXiv:2210.00728 ",
    "url": "https://arxiv.org/abs/2212.02055",
    "authors": [
      "Wei Duan",
      "Junyu Xuan",
      "Maoying Qiao",
      "Jie Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04928",
    "title": "P2T2: a Physically-primed deep-neural-network approach for robust  $T_{2}$ distribution estimation from quantitative $T_{2}$-weighted MRI",
    "abstract": " Title: P2T2: a Physically-primed deep-neural-network approach for robust  $T_{2}$ distribution estimation from quantitative $T_{2}$-weighted MRI ",
    "url": "https://arxiv.org/abs/2212.04928",
    "authors": [
      "Hadas Ben-Atya",
      "Moti Freiman"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.09500",
    "title": "Exploring Tradeoffs in Spiking Neural Networks",
    "abstract": " Title: Exploring Tradeoffs in Spiking Neural Networks ",
    "url": "https://arxiv.org/abs/2212.09500",
    "authors": [
      "Florian Bacho",
      "Dominique Chu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.10409",
    "title": "ClarifyDelphi: Reinforced Clarification Questions with Defeasibility  Rewards for Social and Moral Situations",
    "abstract": " Comments: Accepted to ACL 2023 main conference, 9 pages + bibliography + appendix ",
    "url": "https://arxiv.org/abs/2212.10409",
    "authors": [
      "Valentina Pyatkin",
      "Jena D. Hwang",
      "Vivek Srikumar",
      "Ximing Lu",
      "Liwei Jiang",
      "Yejin Choi",
      "Chandra Bhagavatula"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.05940",
    "title": "SoK: Data Privacy in Virtual Reality",
    "abstract": " Title: SoK: Data Privacy in Virtual Reality ",
    "url": "https://arxiv.org/abs/2301.05940",
    "authors": [
      "Gonzalo Munilla Garrido",
      "Vivek Nair",
      "Dawn Song"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2301.06198",
    "title": "Generalized Neural Closure Models with Interpretability",
    "abstract": " Comments: 26 pages, 7 figures, 11 pages of supplementary information ",
    "url": "https://arxiv.org/abs/2301.06198",
    "authors": [
      "Abhinav Gupta",
      "Pierre F.J. Lermusiaux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Fluid Dynamics (physics.flu-dyn)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2301.06956",
    "title": "Expected Gradients of Maxout Networks and Consequences to Parameter  Initialization",
    "abstract": " Comments: Published at ICML 2023, 42 pages, 11 figures ",
    "url": "https://arxiv.org/abs/2301.06956",
    "authors": [
      "Hanna Tseran",
      "Guido Mont\u00fafar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11237",
    "title": "The Hazards and Benefits of Condescension in Social Learning",
    "abstract": " Comments: 30 pages ",
    "url": "https://arxiv.org/abs/2301.11237",
    "authors": [
      "Itai Arieli",
      "Yakov Babichenko",
      "Stephan M\u00fcller",
      "Farzad Pourbabaee",
      "Omer Tamuz"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2302.05918",
    "title": "Efficient Fraud Detection Using Deep Boosting Decision Trees",
    "abstract": " Comments: 34 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2302.05918",
    "authors": [
      "Biao Xu",
      "Yao Wang",
      "Xiuwu Liao",
      "Kaidong Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2302.09267",
    "title": "Stochastic Approximation Approaches to Group Distributionally Robust  Optimization",
    "abstract": " Title: Stochastic Approximation Approaches to Group Distributionally Robust  Optimization ",
    "url": "https://arxiv.org/abs/2302.09267",
    "authors": [
      "Lijun Zhang",
      "Peng Zhao",
      "Tianbao Yang",
      "Zhi-Hua Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.11121",
    "title": "Counterfactual Prediction Under Outcome Measurement Error",
    "abstract": " Comments: FAccT 2023 ",
    "url": "https://arxiv.org/abs/2302.11121",
    "authors": [
      "Luke Guerdan",
      "Amanda Coston",
      "Kenneth Holstein",
      "Zhiwei Steven Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2302.11716",
    "title": "VRA: Variational Rectified Activation for Out-of-distribution Detection",
    "abstract": " Title: VRA: Variational Rectified Activation for Out-of-distribution Detection ",
    "url": "https://arxiv.org/abs/2302.11716",
    "authors": [
      "Mingyu Xu",
      "Zheng Lian",
      "Bin Liu",
      "Jianhua Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.02251",
    "title": "Certified Robust Neural Networks: Generalization and Corruption  Resistance",
    "abstract": " Title: Certified Robust Neural Networks: Generalization and Corruption  Resistance ",
    "url": "https://arxiv.org/abs/2303.02251",
    "authors": [
      "Amine Bennouna",
      "Ryan Lucas",
      "Bart Van Parys"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.03856",
    "title": "Event Voxel Set Transformer for Spatiotemporal Representation Learning  on Event Streams",
    "abstract": " Comments: 12 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2303.03856",
    "authors": [
      "Bochen Xie",
      "Yongjian Deng",
      "Zhanpeng Shao",
      "Hai Liu",
      "Qingsong Xu",
      "Youfu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.07925",
    "title": "Robust incremental learning pipelines for temporal tabular datasets with  distribution shifts",
    "abstract": " Title: Robust incremental learning pipelines for temporal tabular datasets with  distribution shifts ",
    "url": "https://arxiv.org/abs/2303.07925",
    "authors": [
      "Thomas Wong",
      "Mauricio Barahona"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Finance (q-fin.MF)"
    ]
  },
  {
    "id": "arXiv:2303.10116",
    "title": "Stack and Queue Numbers of Graphs Revisited",
    "abstract": " Comments: Eurocomb 2023 ",
    "url": "https://arxiv.org/abs/2303.10116",
    "authors": [
      "Petr Hlin\u011bn\u00fd",
      "Adam Straka"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2303.17995",
    "title": "Neural Network Entropy (NNetEn): Entropy-Based EEG Signal and Chaotic  Time Series Classification, Python Package for NNetEn Calculation",
    "abstract": " Comments: 26 pages, 18 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2303.17995",
    "authors": [
      "Andrei Velichko",
      "Maksim Belyaev",
      "Yuriy Izotov",
      "Murugappan Murugappan",
      "Hanif Heidari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Chaotic Dynamics (nlin.CD)"
    ]
  },
  {
    "id": "arXiv:2304.01665",
    "title": "Mastering Symbolic Operations: Augmenting Language Models with Compiled  Neural Networks",
    "abstract": " Comments: 31 papers, 16 tables, 13 figures ",
    "url": "https://arxiv.org/abs/2304.01665",
    "authors": [
      "Yixuan Weng",
      "Minjun Zhu",
      "Fei Xia",
      "Bin Li",
      "Shizhu He",
      "Kang Liu",
      "Jun Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2304.01890",
    "title": "Sociocultural knowledge is needed for selection of shots in hate speech  detection tasks",
    "abstract": " Title: Sociocultural knowledge is needed for selection of shots in hate speech  detection tasks ",
    "url": "https://arxiv.org/abs/2304.01890",
    "authors": [
      "Antonis Maronikolakis",
      "Abdullatif K\u00f6ksal",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04403",
    "title": "H2RBox-v2: Incorporating Symmetry for Boosting Horizontal Box Supervised  Oriented Object Detection",
    "abstract": " Comments: 14 pages, 4 figures, 9 tables, the source code is available at this https URL ",
    "url": "https://arxiv.org/abs/2304.04403",
    "authors": [
      "Yi Yu",
      "Xue Yang",
      "Qingyun Li",
      "Yue Zhou",
      "Gefan Zhang",
      "Feipeng Da",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.05197",
    "title": "Multi-step Jailbreaking Privacy Attacks on ChatGPT",
    "abstract": " Comments: Updated with more experiments and improved writing ",
    "url": "https://arxiv.org/abs/2304.05197",
    "authors": [
      "Haoran Li",
      "Dadi Guo",
      "Wei Fan",
      "Mingshi Xu",
      "Jie Huang",
      "Fanpu Meng",
      "Yangqiu Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2304.10770",
    "title": "DEIR: Efficient and Robust Exploration through  Discriminative-Model-Based Episodic Intrinsic Rewards",
    "abstract": " Comments: Accepted as a conference paper to the 32nd International Joint Conference on Artificial Intelligence (IJCAI-23) ",
    "url": "https://arxiv.org/abs/2304.10770",
    "authors": [
      "Shanchuan Wan",
      "Yujin Tang",
      "Yingtao Tian",
      "Tomoyuki Kaneko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2304.12955",
    "title": "Nondeterministic Stacks in Neural Networks",
    "abstract": " Comments: 158 pages, 24 figures. PhD thesis ",
    "url": "https://arxiv.org/abs/2304.12955",
    "authors": [
      "Brian DuSell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.01486",
    "title": "ARBEx: Attentive Feature Extraction with Reliability Balancing for  Robust Facial Expression Learning",
    "abstract": " Comments: 10 pages, 7 figures. Code: this https URL ",
    "url": "https://arxiv.org/abs/2305.01486",
    "authors": [
      "Azmine Toushik Wasi",
      "Karlo \u0160erbetar",
      "Raima Islam",
      "Taki Hasan Rafi",
      "Dong-Kyu Chae"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.02777",
    "title": "Unified Model Learning for Various Neural Machine Translation",
    "abstract": " Title: Unified Model Learning for Various Neural Machine Translation ",
    "url": "https://arxiv.org/abs/2305.02777",
    "authors": [
      "Yunlong Liang",
      "Fandong Meng",
      "Jinan Xu",
      "Jiaan Wang",
      "Yufeng Chen",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.03701",
    "title": "LMEye: An Interactive Perception Network for Large Language Models",
    "abstract": " Comments: working in progress ",
    "url": "https://arxiv.org/abs/2305.03701",
    "authors": [
      "Yunxin Li",
      "Baotian Hu",
      "Xinyu Chen",
      "Lin Ma",
      "Min Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.07375",
    "title": "Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation",
    "abstract": " Title: Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation ",
    "url": "https://arxiv.org/abs/2305.07375",
    "authors": [
      "Jinglong Gao",
      "Xiao Ding",
      "Bing Qin",
      "Ting Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.07424",
    "title": "Instance Smoothed Contrastive Learning for Unsupervised Sentence  Embedding",
    "abstract": " Comments: Accepted to AAAI 2023. The code is available at this https URL ",
    "url": "https://arxiv.org/abs/2305.07424",
    "authors": [
      "Hongliang He",
      "Junlei Zhang",
      "Zhenzhong Lan",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.07804",
    "title": "Dr. LLaMA: Improving Small Language Models on PubMedQA via Generative  Data Augmentation",
    "abstract": " Title: Dr. LLaMA: Improving Small Language Models on PubMedQA via Generative  Data Augmentation ",
    "url": "https://arxiv.org/abs/2305.07804",
    "authors": [
      "Zhen Guo",
      "Peiqi Wang",
      "Yanwei Wang",
      "Shangdi Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.07854",
    "title": "A Federated Learning-based Industrial Health Prognostics for  Heterogeneous Edge Devices using Matched Feature Extraction",
    "abstract": " Comments: 17 pages, 11 figures, and 6 tables ",
    "url": "https://arxiv.org/abs/2305.07854",
    "authors": [
      "Anushiya Arunan",
      "Yan Qin",
      "Xiaoli Li",
      "Chau Yuen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.08099",
    "title": "Self-supervised Neural Factor Analysis for Disentangling Utterance-level  Speech Representations",
    "abstract": " Comments: accepted by ICML 2023 ",
    "url": "https://arxiv.org/abs/2305.08099",
    "authors": [
      "Weiwei Lin",
      "Chenhang He",
      "Man-Wai Mak",
      "Youzhi Tu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.08611",
    "title": "GeNAS: Neural Architecture Search with Better Generalization",
    "abstract": " Comments: Accepted by IJCAI2023 ",
    "url": "https://arxiv.org/abs/2305.08611",
    "authors": [
      "Joonhyun Jeong",
      "Joonsang Yu",
      "Geondo Park",
      "Dongyoon Han",
      "YoungJoon Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.09251",
    "title": "A SKG Security Challenge: Indoor SKG Under an On-The-Shoulder  Eavesdropping Attack",
    "abstract": " Title: A SKG Security Challenge: Indoor SKG Under an On-The-Shoulder  Eavesdropping Attack ",
    "url": "https://arxiv.org/abs/2305.09251",
    "authors": [
      "Amitha Mayya",
      "Miroslav Mitev",
      "Arsenia Chorti",
      "Gerhard Fettweis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.09493",
    "title": "Experiences in Building a Composable and Functional API for Runtime  SPIR-V Code Generation",
    "abstract": " Comments: 16 pages, 9 figures, 11 Listings ",
    "url": "https://arxiv.org/abs/2305.09493",
    "authors": [
      "Juan Fumero",
      "Gy\u00f6rgy Rethy",
      "Athanasios Stratikopoulos",
      "Nikos Foutris",
      "Christos Kotselidis"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2305.10006",
    "title": "EfficientSCI: Densely Connected Network with Space-time Factorization  for Large-scale Video Snapshot Compressive Imaging",
    "abstract": " Title: EfficientSCI: Densely Connected Network with Space-time Factorization  for Large-scale Video Snapshot Compressive Imaging ",
    "url": "https://arxiv.org/abs/2305.10006",
    "authors": [
      "Lishun Wang",
      "Miao Cao",
      "Xin Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.10246",
    "title": "Spiking Generative Adversarial Network with Attention Scoring Decoding",
    "abstract": " Title: Spiking Generative Adversarial Network with Attention Scoring Decoding ",
    "url": "https://arxiv.org/abs/2305.10246",
    "authors": [
      "Linghao Feng",
      "Dongcheng Zhao",
      "Yi Zeng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.10395",
    "title": "Motion Planning (In)feasibility Detection using a Prior Roadmap via Path  and Cut Search",
    "abstract": " Comments: 18 pages, 19 figures, Published in Robotics: Science and Systems (RSS), 2023 ",
    "url": "https://arxiv.org/abs/2305.10395",
    "authors": [
      "Yoonchang Sung",
      "Peter Stone"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  }
]