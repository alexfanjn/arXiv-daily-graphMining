[
  {
    "id": "arXiv:2305.07662",
    "title": "Self-information Domain-based Neural CSI Compression with Feature  Coupling",
    "abstract": "Deep learning (DL)-based channel state information (CSI) feedback methods compressed the CSI matrix by exploiting its delay and angle features straightforwardly, while the measure in terms of information contained in the CSI matrix has rarely been considered. Based on this observation, we introduce self-information as an informative CSI representation from the perspective of information theory, which reflects the amount of information of the original CSI matrix in an explicit way. Then, a novel DL-based network is proposed for temporal CSI compression in the self-information domain, namely SD-CsiNet. The proposed SD-CsiNet projects the raw CSI onto a self-information matrix in the newly-defined self-information domain, extracts both temporal and spatial features of the self-information matrix, and then couples these two features for effective compression. Experimental results verify the effectiveness of the proposed SD-CsiNet by exploiting the self-information of CSI. Particularly for compression ratios 1/8 and 1/16, the SD-CsiNet respectively achieves 7.17 dB and 3.68 dB performance gains compared to state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2305.07662",
    "authors": [
      "Ziqing Yin",
      "Renjie Xie",
      "Wei Xu",
      "Zhaohui Yang",
      "Xiaohu You"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.07663",
    "title": "Quantified Semantic Comparison of Convolutional Neural Networks",
    "abstract": "The state-of-the-art in convolutional neural networks (CNNs) for computer vision excels in performance, while remaining opaque. But due to safety regulations for safety-critical applications, like perception for automated driving, the choice of model should also take into account how candidate models represent semantic information for model transparency reasons. To tackle this yet unsolved problem, our work proposes two methods for quantifying the similarity between semantic information in CNN latent spaces. These allow insights into both the flow and similarity of semantic information within CNN layers, and into the degree of their similitude between different networks. As a basis, we use renown techniques from the field of explainable artificial intelligence (XAI), which are used to obtain global vector representations of semantic concepts in each latent space. These are compared with respect to their activation on test inputs. When applied to three diverse object detectors and two datasets, our methods reveal the findings that (1) similar semantic concepts are learned \\emph{regardless of the CNN architecture}, and (2) similar concepts emerge in similar \\emph{relative} layer depth, independent of the total number of layers. Finally, our approach poses a promising step towards informed model selection and comprehension of how CNNs process semantic information. ",
    "url": "https://arxiv.org/abs/2305.07663",
    "authors": [
      "Georgii Mikriukov",
      "Gesina Schwalbe",
      "Christian Hellert",
      "Korinna Bade"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.07664",
    "title": "mAedesID: Android Application for Aedes Mosquito Species Identification  using Convolutional Neural Network",
    "abstract": "Vector-Borne Disease (VBD) is an infectious disease transmitted through the pathogenic female Aedes mosquito to humans and animals. It is important to control dengue disease by reducing the spread of Aedes mosquito vectors. Community awareness plays acrucial role to ensure Aedes control programmes and encourages the communities to involve active participation. Identifying the species of mosquito will help to recognize the mosquito density in the locality and intensifying mosquito control efforts in particular areas. This willhelp in avoiding Aedes breeding sites around residential areas and reduce adult mosquitoes. To serve this purpose, an android application are developed to identify Aedes species that help the community to contribute in mosquito control events. Several Android applications have been developed to identify species like birds, plant species, and Anopheles mosquito species. In this work, a user-friendly mobile application mAedesID is developed for identifying the Aedes mosquito species using a deep learning Convolutional Neural Network (CNN) algorithm which is best suited for species image classification and achieves better accuracy for voluminous images. The mobile application can be downloaded from the URLhttps://tinyurl.com/mAedesID. ",
    "url": "https://arxiv.org/abs/2305.07664",
    "authors": [
      "G. Jeyakodi",
      "Trisha Agarwal",
      "P. Shanthi Bala"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.07670",
    "title": "Liver Infection Prediction Analysis using Machine Learning to Evaluate  Analytical Performance in Neural Networks by Optimization Techniques",
    "abstract": "Liver infection is a common disease, which poses a great threat to human health, but there is still able to identify an optimal technique that can be used on large-level screening. This paper deals with ML algorithms using different data sets and predictive analyses. Therefore, machine ML can be utilized in different diseases for integrating a piece of pattern for visualization. This paper deals with various machine learning algorithms on different liver illness datasets to evaluate the analytical performance using different types of parameters and optimization techniques. The selected classification algorithms analyze the difference in results and find out the most excellent categorization models for liver disease. Machine learning optimization is the procedure of modifying hyperparameters in arrange to employ one of the optimization approaches to minimise the cost function. To set the hyperparameter, include a number of Phosphotase,Direct Billirubin, Protiens, Albumin and Albumin Globulin. Since it describes the difference linking the predictable parameter's true importance and the model's prediction, it is crucial to minimise the cost function. ",
    "url": "https://arxiv.org/abs/2305.07670",
    "authors": [
      "P. Deivendran",
      "S. Selvakanmani",
      "S. Jegadeesan",
      "V. Vinoth Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.07671",
    "title": "LatentPINNs: Generative physics-informed neural networks via a latent  representation learning",
    "abstract": "Physics-informed neural networks (PINNs) are promising to replace conventional partial differential equation (PDE) solvers by offering more accurate and flexible PDE solutions. However, they are hampered by the relatively slow convergence and the need to perform additional, potentially expensive, training for different PDE parameters. To solve this limitation, we introduce latentPINN, a framework that utilizes latent representations of the PDE parameters as additional (to the coordinates) inputs into PINNs and allows for training over the distribution of these parameters. Motivated by the recent progress on generative models, we promote the use of latent diffusion models to learn compressed latent representations of the PDE parameters distribution and act as input parameters to NN functional solutions. We use a two-stage training scheme in which the first stage, we learn the latent representations for the distribution of PDE parameters. In the second stage, we train a physics-informed neural network over inputs given by randomly drawn samples from the coordinate space within the solution domain and samples from the learned latent representation of the PDE parameters. We test the approach on a class of level set equations given by the nonlinear Eikonal equation. We specifically share results corresponding to three different sets of Eikonal parameters (velocity models). The proposed method performs well on new phase velocity models without the need for any additional training. ",
    "url": "https://arxiv.org/abs/2305.07671",
    "authors": [
      "Mohammad H. Taufik",
      "Tariq Alkhalifah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2305.07713",
    "title": "Multi-Modal 3D Object Detection by Box Matching",
    "abstract": "Multi-modal 3D object detection has received growing attention as the information from different sensors like LiDAR and cameras are complementary. Most fusion methods for 3D detection rely on an accurate alignment and calibration between 3D point clouds and RGB images. However, such an assumption is not reliable in a real-world self-driving system, as the alignment between different modalities is easily affected by asynchronous sensors and disturbed sensor placement. We propose a novel {F}usion network by {B}ox {M}atching (FBMNet) for multi-modal 3D detection, which provides an alternative way for cross-modal feature alignment by learning the correspondence at the bounding box level to free up the dependency of calibration during inference. With the learned assignments between 3D and 2D object proposals, the fusion for detection can be effectively performed by combing their ROI features. Extensive experiments on the nuScenes dataset demonstrate that our method is much more stable in dealing with challenging cases such as asynchronous sensors, misaligned sensor placement, and degenerated camera images than existing fusion methods. We hope that our FBMNet could provide an available solution to dealing with these challenging cases for safety in real autonomous driving scenarios. Codes will be publicly available at https://github.com/happinesslz/FBMNet. ",
    "url": "https://arxiv.org/abs/2305.07713",
    "authors": [
      "Zhe Liu",
      "Xiaoqing Ye",
      "Zhikang Zou",
      "Xinwei He",
      "Xiao Tan",
      "Errui Ding",
      "Jingdong Wang",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.07729",
    "title": "Social Surplus Maximization in Sponsored Search Auctions Requires  Communication",
    "abstract": "We show that computing the optimal social surplus requires $\\Omega(mn)$ bits of communication between the website and the bidders in a sponsored search auction with $n$ slots on the website and with tick size of $2^{-m}$ in the discrete model, even when bidders are allowed to freely communicate with each other. ",
    "url": "https://arxiv.org/abs/2305.07729",
    "authors": [
      "Suat Evren"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Information Theory (cs.IT)",
      "Theoretical Economics (econ.TH)"
    ]
  },
  {
    "id": "arXiv:2305.07731",
    "title": "Predicting COVID-19 pandemic by spatio-temporal graph neural networks: A  New Zealand's study",
    "abstract": "Modeling and simulations of pandemic dynamics play an essential role in understanding and addressing the spreading of highly infectious diseases such as COVID-19. In this work, we propose a novel deep learning architecture named Attention-based Multiresolution Graph Neural Networks (ATMGNN) that learns to combine the spatial graph information, i.e. geographical data, with the temporal information, i.e. timeseries data of number of COVID-19 cases, to predict the future dynamics of the pandemic. The key innovation is that our method can capture the multiscale structures of the spatial graph via a learning to cluster algorithm in a data-driven manner. This allows our architecture to learn to pick up either local or global signals of a pandemic, and model both the long-range spatial and temporal dependencies. Importantly, we collected and assembled a new dataset for New Zealand. We established a comprehensive benchmark of statistical methods, temporal architectures, graph neural networks along with our spatio-temporal model. We also incorporated socioeconomic cross-sectional data to further enhance our prediction. Our proposed model have shown highly robust predictions and outperformed all other baselines in various metrics for our new dataset of New Zealand along with existing datasets of England, France, Italy and Spain. For a future work, we plan to extend our work for real-time prediction and global scale. Our data and source code are publicly available at https://github.com/HySonLab/pandemic_tgnn ",
    "url": "https://arxiv.org/abs/2305.07731",
    "authors": [
      "Viet Bach Nguyen",
      "Truong Son Hy",
      "Long Tran-Thanh",
      "Nhung Nghiem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2305.07762",
    "title": "Impacts of Differential Privacy on Fostering more Racially and  Ethnically Diverse Elementary Schools",
    "abstract": "In the face of increasingly severe privacy threats in the era of data and AI, the US Census Bureau has recently adopted differential privacy, the de facto standard of privacy protection for the 2020 Census release. Enforcing differential privacy involves adding carefully calibrated random noise to sensitive demographic information prior to its release. This change has the potential to impact policy decisions like political redistricting and other high-stakes practices, partly because tremendous federal funds and resources are allocated according to datasets (like Census data) released by the US government. One under-explored yet important application of such data is the redrawing of school attendance boundaries to foster less demographically segregated schools. In this study, we ask: how differential privacy might impact diversity-promoting boundaries in terms of resulting levels of segregation, student travel times, and school switching requirements? Simulating alternative boundaries using differentially-private student counts across 67 Georgia districts, we find that increasing data privacy requirements decreases the extent to which alternative boundaries might reduce segregation and foster more diverse and integrated schools, largely by reducing the number of students who would switch schools under boundary changes. Impacts on travel times are minimal. These findings point to a privacy-diversity tradeoff local educational policymakers may face in forthcoming years, particularly as computational methods are increasingly poised to facilitate attendance boundary redrawings in the pursuit of less segregated schools. ",
    "url": "https://arxiv.org/abs/2305.07762",
    "authors": [
      "Keyu Zhu",
      "Nabeel Gillani",
      "Pascal Van Hentenryck"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2305.07774",
    "title": "PanFlowNet: A Flow-Based Deep Network for Pan-sharpening",
    "abstract": "Pan-sharpening aims to generate a high-resolution multispectral (HRMS) image by integrating the spectral information of a low-resolution multispectral (LRMS) image with the texture details of a high-resolution panchromatic (PAN) image. It essentially inherits the ill-posed nature of the super-resolution (SR) task that diverse HRMS images can degrade into an LRMS image. However, existing deep learning-based methods recover only one HRMS image from the LRMS image and PAN image using a deterministic mapping, thus ignoring the diversity of the HRMS image. In this paper, to alleviate this ill-posed issue, we propose a flow-based pan-sharpening network (PanFlowNet) to directly learn the conditional distribution of HRMS image given LRMS image and PAN image instead of learning a deterministic mapping. Specifically, we first transform this unknown conditional distribution into a given Gaussian distribution by an invertible network, and the conditional distribution can thus be explicitly defined. Then, we design an invertible Conditional Affine Coupling Block (CACB) and further build the architecture of PanFlowNet by stacking a series of CACBs. Finally, the PanFlowNet is trained by maximizing the log-likelihood of the conditional distribution given a training set and can then be used to predict diverse HRMS images. The experimental results verify that the proposed PanFlowNet can generate various HRMS images given an LRMS image and a PAN image. Additionally, the experimental results on different kinds of satellite datasets also demonstrate the superiority of our PanFlowNet compared with other state-of-the-art methods both visually and quantitatively. ",
    "url": "https://arxiv.org/abs/2305.07774",
    "authors": [
      "Gang Yang",
      "Xiangyong Cao",
      "Wenzhe Xiao",
      "Man Zhou",
      "Aiping Liu",
      "Xun chen",
      "Deyu Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.07789",
    "title": "Answering Complex Questions over Text by Hybrid Question Parsing and  Execution",
    "abstract": "The dominant paradigm of textual question answering systems is based on end-to-end neural networks, which excels at answering natural language questions but falls short on complex ones. This stands in contrast to the broad adaptation of semantic parsing approaches over structured data sources (e.g., relational database, knowledge graphs), that convert natural language questions to logical forms and execute them with query engines. Towards combining the strengths of neural and symbolic methods, we propose a framework of question parsing and execution on textual QA. It comprises two central pillars: (1) We parse the question of varying complexity into an intermediate representation, named H-expression, which is composed of simple questions as the primitives and symbolic operations representing the relationships among them; (2) To execute the resulting H-expressions, we design a hybrid executor, which integrates the deterministic rules to translate the symbolic operations with a drop-in neural reader network to answer each decomposed simple question. Hence, the proposed framework can be viewed as a top-down question parsing followed by a bottom-up answer backtracking. The resulting H-expressions closely guide the execution process, offering higher precision besides better interpretability while still preserving the advantages of the neural readers for resolving its primitive elements. Our extensive experiments on MuSiQue, 2WikiQA, HotpotQA, and NQ show that the proposed parsing and hybrid execution framework outperforms existing approaches in supervised, few-shot, and zero-shot settings, while also effectively exposing its underlying reasoning process. ",
    "url": "https://arxiv.org/abs/2305.07789",
    "authors": [
      "Ye Liu",
      "Semih Yavuz",
      "Rui Meng",
      "Dragomir Radev",
      "Caiming Xiong",
      "Yingbo Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.07791",
    "title": "Using Deepfake Technologies for Word Emphasis Detection",
    "abstract": "In this work, we consider the task of automated emphasis detection for spoken language. This problem is challenging in that emphasis is affected by the particularities of speech of the subject, for example the subject accent, dialect or voice. To address this task, we propose to utilize deep fake technology to produce an emphasis devoid speech for this speaker. This requires extracting the text of the spoken voice, and then using a voice sample from the same speaker to produce emphasis devoid speech for this task. By comparing the generated speech with the spoken voice, we are able to isolate patterns of emphasis which are relatively easy to detect. ",
    "url": "https://arxiv.org/abs/2305.07791",
    "authors": [
      "Eran Kaufman",
      "Lee-Ad Gottlieb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.07795",
    "title": "Constructing Holistic Measures for Social Biases in Masked Language  Models",
    "abstract": "Masked Language Models (MLMs) have been successful in many natural language processing tasks. However, real-world stereotype biases are likely to be reflected in MLMs due to their learning from large text corpora. Most of the evaluation metrics proposed in the past adopt different masking strategies, designed with the log-likelihood of MLMs. They lack holistic considerations such as variance for stereotype bias and anti-stereotype bias samples. In this paper, the log-likelihoods of stereotype bias and anti-stereotype bias samples output by MLMs are considered Gaussian distributions. Two evaluation metrics, Kullback Leibler Divergence Score (KLDivS) and Jensen Shannon Divergence Score (JSDivS) are proposed to evaluate social biases in MLMs The experimental results on the public datasets StereoSet and CrowS-Pairs demonstrate that KLDivS and JSDivS are more stable and interpretable compared to the metrics proposed in the past. ",
    "url": "https://arxiv.org/abs/2305.07795",
    "authors": [
      "Yang Liu",
      "Yuexian Hou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.07804",
    "title": "Dr. LLaMA: Improving Small Language Models in Domain-Specific QA via  Generative Data Augmentation",
    "abstract": "Large Language Models (LLMs) have made significant strides in natural language processing but face challenges in terms of computational expense and inefficiency as they grow in size, especially in domain-specific tasks. Small Language Models (SLMs), on the other hand, often struggle in these tasks due to limited capacity and training data. In this paper, we introduce Dr. LLaMA, a method for improving SLMs through generative data augmentation using LLMs, focusing on medical question-answering tasks and the PubMedQA dataset. Our findings indicate that LLMs effectively refine and diversify existing question-answer pairs, resulting in improved performance of a much smaller model on domain-specific QA datasets after fine-tuning. This study highlights the challenges of using LLMs for domain-specific question answering and suggests potential research directions to address these limitations, ultimately aiming to create more efficient and capable models for specialized applications. We have also made our code available for interested researchers ",
    "url": "https://arxiv.org/abs/2305.07804",
    "authors": [
      "Zhen Guo",
      "Peiqi Wang",
      "Yanwei Wang",
      "Shangdi Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.07812",
    "title": "Lightweight Delivery Detection on Doorbell Cameras",
    "abstract": "Despite recent advances in video-based action recognition and robust spatio-temporal modeling, most of the proposed approaches rely on the abundance of computational resources to afford running huge and computation-intensive convolutional or transformer-based neural networks to obtain satisfactory results. This limits the deployment of such models on edge devices with limited power and computing resources. In this work we investigate an important smart home application, video based delivery detection, and present a simple and lightweight pipeline for this task that can run on resource-constrained doorbell cameras. Our proposed pipeline relies on motion cues to generate a set of coarse activity proposals followed by their classification with a mobile-friendly 3DCNN network. For training we design a novel semi-supervised attention module that helps the network to learn robust spatio-temporal features and adopt an evidence-based optimization objective that allows for quantifying the uncertainty of predictions made by the network. Experimental results on our curated delivery dataset shows the significant effectiveness of our pipeline compared to alternatives and highlights the benefits of our training phase novelties to achieve free and considerable inference-time performance gains. ",
    "url": "https://arxiv.org/abs/2305.07812",
    "authors": [
      "Pirazh Khorramshahi",
      "Zhe Wu",
      "Tianchen Wang",
      "Luke Deluccia",
      "Hongcheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.07815",
    "title": "MetaMorphosis: Task-oriented Privacy Cognizant Feature Generation for  Multi-task Learning",
    "abstract": "With the growth of computer vision applications, deep learning, and edge computing contribute to ensuring practical collaborative intelligence (CI) by distributing the workload among edge devices and the cloud. However, running separate single-task models on edge devices is inefficient regarding the required computational resource and time. In this context, multi-task learning allows leveraging a single deep learning model for performing multiple tasks, such as semantic segmentation and depth estimation on incoming video frames. This single processing pipeline generates common deep features that are shared among multi-task modules. However, in a collaborative intelligence scenario, generating common deep features has two major issues. First, the deep features may inadvertently contain input information exposed to the downstream modules (violating input privacy). Second, the generated universal features expose a piece of collective information than what is intended for a certain task, in which features for one task can be utilized to perform another task (violating task privacy). This paper proposes a novel deep learning-based privacy-cognizant feature generation process called MetaMorphosis that limits inference capability to specific tasks at hand. To achieve this, we propose a channel squeeze-excitation based feature metamorphosis module, Cross-SEC, to achieve distinct attention of all tasks and a de-correlation loss function with differential-privacy to train a deep learning model that produces distinct privacy-aware features as an output for the respective tasks. With extensive experimentation on four datasets consisting of diverse images related to scene understanding and facial attributes, we show that MetaMorphosis outperforms recent adversarial learning and universal feature generation methods by guaranteeing privacy requirements in an efficient way for image and video analytics. ",
    "url": "https://arxiv.org/abs/2305.07815",
    "authors": [
      "Md Adnan Arefeen",
      "Zhouyu Li",
      "Md Yusuf Sarwar Uddin",
      "Anupam Das"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2305.07824",
    "title": "A Simple and Plug-and-play Method for Unsupervised Sentence  Representation Enhancement",
    "abstract": "Generating proper embedding of sentences through an unsupervised way is beneficial to semantic matching and retrieval problems in real-world scenarios. This paper presents Representation ALchemy (RepAL), an extremely simple post-processing method that enhances sentence representations. The basic idea in RepAL is to de-emphasize redundant information of sentence embedding generated by pre-trained models. Through comprehensive experiments, we show that RepAL is free of training and is a plug-and-play method that can be combined with most existing unsupervised sentence learning models. We also conducted in-depth analysis to understand RepAL. ",
    "url": "https://arxiv.org/abs/2305.07824",
    "authors": [
      "Lingfeng Shen",
      "Haiyun Jiang",
      "Lemao Liu",
      "Shuming Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.07825",
    "title": "Student Classroom Behavior Detection based on YOLOv7-BRA and Multi-Model  Fusion",
    "abstract": "Accurately detecting student behavior in classroom videos can aid in analyzing their classroom performance and improving teaching effectiveness. However, the current accuracy rate in behavior detection is low. To address this challenge, we propose the Student Classroom Behavior Detection system based on based on YOLOv7-BRA (YOLOv7 with Bi-level Routing Attention ). We identified eight different behavior patterns, including standing, sitting, speaking, listening, walking, raising hands, reading, and writing. We constructed a dataset, which contained 11,248 labels and 4,001 images, with an emphasis on the common behavior of raising hands in a classroom setting (Student Classroom Behavior dataset, SCB-Dataset). To improve detection accuracy, we added the biformer attention module to the YOLOv7 network. Finally, we fused the results from YOLOv7 CrowdHuman, SlowFast, and DeepSort models to obtain student classroom behavior data. We conducted experiments on the SCB-Dataset, and YOLOv7-BRA achieved an mAP@0.5 of 87.1%, resulting in a 2.2% improvement over previous results. Our SCB-dataset can be downloaded from: https://github.com/Whiffe/SCB-datase ",
    "url": "https://arxiv.org/abs/2305.07825",
    "authors": [
      "Fan Yang",
      "Tao Wang",
      "Xiaofei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.07826",
    "title": "Frequency-aware Dimension Selection for Static Word Embedding by Mixed  Product Distance",
    "abstract": "Static word embedding is still useful, particularly for context-unavailable tasks, because in the case of no context available, pre-trained language models often perform worse than static word embeddings. Although dimension is a key factor determining the quality of static word embeddings, automatic dimension selection is rarely discussed. In this paper, we investigate the impact of word frequency on the dimension selection, and empirically find that word frequency is so vital that it needs to be taken into account during dimension selection. Based on such an empirical finding, this paper proposes a dimension selection method that uses a metric (Mixed Product Distance, MPD) to select a proper dimension for word embedding algorithms without training any word embedding. Through applying a post-processing function to oracle matrices, the MPD-based method can de-emphasize the impact of word frequency. Experiments on both context-unavailable and context-available tasks demonstrate the better efficiency-performance trade-off of our MPD-based dimension selection method over baselines. ",
    "url": "https://arxiv.org/abs/2305.07826",
    "authors": [
      "Lingfeng Shen",
      "Haiyun Jiang",
      "Lemao Liu",
      "Ying Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.07828",
    "title": "Description and Discussion on DCASE 2023 Challenge Task 2: First-Shot  Unsupervised Anomalous Sound Detection for Machine Condition Monitoring",
    "abstract": "We present the task description of the Detection and Classification of Acoustic Scenes and Events (DCASE) 2023 Challenge Task 2: \"First-shot unsupervised anomalous sound detection (ASD) for machine condition monitoring\". The main goal is to enable rapid deployment of ASD systems for new kinds of machines using only a few normal samples, without the need for hyperparameter tuning. In the past ASD tasks, developed methods tuned hyperparameters for each machine type, as the development and evaluation datasets had the same machine types. However, collecting normal and anomalous data as the development dataset can be infeasible in practice. In 2023 Task 2, we focus on solving first-shot problem, which is the challenge of training a model on a few machines of a completely novel machine type. Specifically, (i) each machine type has only one section, and (ii) machine types in the development and evaluation datasets are completely different. We will add challenge results and analysis of the submissions after the challenge submission deadline. ",
    "url": "https://arxiv.org/abs/2305.07828",
    "authors": [
      "Kota Dohi",
      "Keisuke Imoto",
      "Noboru Harada",
      "Daisuke Niizumi",
      "Yuma Koizumi",
      "Tomoya Nishida",
      "Harsh Purohit",
      "Ryo Tanabe",
      "Takashi Endo",
      "Yohei Kawaguchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.07829",
    "title": "No-Reference Point Cloud Quality Assessment via Weighted Patch Quality  Prediction",
    "abstract": "With the rapid development of 3D vision applications based on point clouds, point cloud quality assessment(PCQA) is becoming an important research topic. However, the prior PCQA methods ignore the effect of local quality variance across different areas of the point cloud. To take an advantage of the quality distribution imbalance, we propose a no-reference point cloud quality assessment (NR-PCQA) method with local area correlation analysis capability, denoted as COPP-Net. More specifically, we split a point cloud into patches, generate texture and structure features for each patch, and fuse them into patch features to predict patch quality. Then, we gather the features of all the patches of a point cloud for correlation analysis, to obtain the correlation weights. Finally, the predicted qualities and correlation weights for all the patches are used to derive the final quality score. Experimental results show that our method outperforms the state-of-the-art benchmark NR-PCQA methods. The source code for the proposed COPP-Net can be found at https://github.com/philox12358/COPP-Net. ",
    "url": "https://arxiv.org/abs/2305.07829",
    "authors": [
      "Jun Cheng",
      "Honglei Su",
      "Jari Korhonen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.07845",
    "title": "Understanding Model Averaging in Federated Learning on Heterogeneous  Data",
    "abstract": "Model averaging, a widely adopted technique in federated learning (FL), aggregates multiple client models trained on heterogeneous data to obtain a well-performed global model. However, the rationale behind its success is not well understood. To shed light on this issue, we investigate the geometric properties of model averaging by visualizing the loss/error landscape. The geometrical visualization shows that the client models surround the global model within a common basin, and the global model may deviate from the bottom of the basin even though it performs better than the client models. To further understand this phenomenon, we decompose the expected prediction error of the global model into five factors related to client models. Specifically, we find that the global-model error after early training mainly comes from i) the client-model error on non-overlapping data between client datasets and the global dataset and ii) the maximal distance between the global and client models. Inspired by these findings, we propose adopting iterative moving averaging (IMA) on global models to reduce the prediction error and limiting client exploration to control the maximal distance at the late training. Our experiments demonstrate that IMA significantly improves the accuracy and training speed of existing FL methods on benchmark datasets with various data heterogeneity. ",
    "url": "https://arxiv.org/abs/2305.07845",
    "authors": [
      "Tailin Zhou",
      "Zehong Lin",
      "Jun Zhang",
      "Danny H.K. Tsang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.07853",
    "title": "EV-MGRFlowNet: Motion-Guided Recurrent Network for Unsupervised  Event-based Optical Flow with Hybrid Motion-Compensation Loss",
    "abstract": "Event cameras offer promising properties, such as high temporal resolution and high dynamic range. These benefits have been utilized into many machine vision tasks, especially optical flow estimation. Currently, most existing event-based works use deep learning to estimate optical flow. However, their networks have not fully exploited prior hidden states and motion flows. Additionally, their supervision strategy has not fully leveraged the geometric constraints of event data to unlock the potential of networks. In this paper, we propose EV-MGRFlowNet, an unsupervised event-based optical flow estimation pipeline with motion-guided recurrent networks using a hybrid motion-compensation loss. First, we propose a feature-enhanced recurrent encoder network (FERE-Net) which fully utilizes prior hidden states to obtain multi-level motion features. Then, we propose a flow-guided decoder network (FGD-Net) to integrate prior motion flows. Finally, we design a hybrid motion-compensation loss (HMC-Loss) to strengthen geometric constraints for the more accurate alignment of events. Experimental results show that our method outperforms the current state-of-the-art (SOTA) method on the MVSEC dataset, with an average reduction of approximately 22.71% in average endpoint error (AEE). To our knowledge, our method ranks first among unsupervised learning-based methods. ",
    "url": "https://arxiv.org/abs/2305.07853",
    "authors": [
      "Hao Zhuang",
      "Xinjie Huang",
      "Kuanxu Hou",
      "Delei Kong",
      "Chenming Hu",
      "Zheng Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.07854",
    "title": "A Federated Learning-based Industrial Health Prognostics for  Heterogeneous Edge Devices using Matched Feature Extraction",
    "abstract": "Data-driven industrial health prognostics require rich training data to develop accurate and reliable predictive models. However, stringent data privacy laws and the abundance of edge industrial data necessitate decentralized data utilization. Thus, the industrial health prognostics field is well suited to significantly benefit from federated learning (FL), a decentralized and privacy-preserving learning technique. However, FL-based health prognostics tasks have hardly been investigated due to the complexities of meaningfully aggregating model parameters trained from heterogeneous data to form a high performing federated model. Specifically, data heterogeneity among edge devices, stemming from dissimilar degradation mechanisms and unequal dataset sizes, poses a critical statistical challenge for developing accurate federated models. We propose a pioneering FL-based health prognostic model with a feature similarity-matched parameter aggregation algorithm to discriminatingly learn from heterogeneous edge data. The algorithm searches across the heterogeneous locally trained models and matches neurons with probabilistically similar feature extraction functions first, before selectively averaging them to form the federated model parameters. As the algorithm only averages similar neurons, as opposed to conventional naive averaging of coordinate-wise neurons, the distinct feature extractors of local models are carried over with less dilution to the resultant federated model. Using both cyclic degradation data of Li-ion batteries and non-cyclic data of turbofan engines, we demonstrate that the proposed method yields accuracy improvements as high as 44.5\\% and 39.3\\% for state-of-health estimation and remaining useful life estimation, respectively. ",
    "url": "https://arxiv.org/abs/2305.07854",
    "authors": [
      "Anushiya Arunan",
      "Yan Qin",
      "Xiaoli Li",
      "Chau Yuen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.07862",
    "title": "Research on Cooperative Search Technology of Heterogeneous UAVs in  Complex Environments",
    "abstract": "This paper studies heterogeneous UAVs cooperative search technology suitable for complex environments. In the application, a fixed-wing UAV drops rotor UAVs to deploy the cluster rapidly. Meanwhile, the fixed-wing UAV works as a communication relay node to improve the cooperative search performance of the cluster further. Aiming at the cooperative search requirements of heterogeneous UAVs, a jumping grid decision method is proposed to satisfy the maneuverability constraints of UAVs, a parameter dynamic selection method is developed to make search decision more responsive to task requirements, and a search information transmission method with low bandwidth is designed, which significantly improves the communication efficiency of UAVs. The simulation results show that heterogeneous UAVs have the capabilities of adaptive decision-making, threat avoidance, and collision avoidance. The cooperative search performance of the heterogeneous cluster under communication constraints is significantly improved compared to the homogeneous cluster. ",
    "url": "https://arxiv.org/abs/2305.07862",
    "authors": [
      "Zhenchang Liu",
      "Mingrui Hao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.07872",
    "title": "SPP-CNN: An Efficient Framework for Network Robustness Prediction",
    "abstract": "This paper addresses the robustness of a network to sustain its connectivity and controllability against malicious attacks. This kind of network robustness is typically measured by the time-consuming attack simulation, which returns a sequence of values that record the remaining connectivity and controllability after a sequence of node- or edge-removal attacks. For improvement, this paper develops an efficient framework for network robustness prediction, the spatial pyramid pooling convolutional neural network (SPP-CNN). The new framework installs a spatial pyramid pooling layer between the convolutional and fully-connected layers, overcoming the common mismatch issue in the CNN-based prediction approaches and extending its generalizability. Extensive experiments are carried out by comparing SPP-CNN with three state-of-the-art robustness predictors, namely a CNN-based and two graph neural networks-based frameworks. Synthetic and real-world networks, both directed and undirected, are investigated. Experimental results demonstrate that the proposed SPP-CNN achieves better prediction performances and better generalizability to unknown datasets, with significantly lower time-consumption, than its counterparts. ",
    "url": "https://arxiv.org/abs/2305.07872",
    "authors": [
      "Chengpei Wu",
      "Yang Lou",
      "Lin Wang",
      "Junli Li",
      "Xiang Li",
      "Guanrong Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.07889",
    "title": "Neural operator for structural simulation and bridge health monitoring",
    "abstract": "Infusing deep learning with structural engineering has received widespread attention for both forward problems (structural simulation) and inverse problems (structural health monitoring). Based on Fourier Neural Operator, this study proposes VINO (Vehicle-bridge Interaction Neural Operator) to serve as the digital twin of bridge structures. VINO learns mappings between structural response fields and damage fields. In this study, VBI-FE dataset was established by running parametric finite element (FE) simulations considering a random distribution of structural initial damage field. Subsequently, VBI-EXP dataset was produced by conducting an experimental study under four damage scenarios. After VINO was pre-trained by VBI-FE and fine-tuned by VBI-EXP from the bridge at the healthy state, the model achieved the following two improvements. First, forward VINO can predict structural responses from damage field inputs more accurately than the FE model. Second, inverse VINO can determine, localize, and quantify damages in all scenarios, suggesting the practicality of data-driven approaches. ",
    "url": "https://arxiv.org/abs/2305.07889",
    "authors": [
      "Chawit Kaewnuratchadasorn",
      "Jiaji Wang",
      "Chul-Woo Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.07892",
    "title": "DAC-MR: Data Augmentation Consistency Based Meta-Regularization for  Meta-Learning",
    "abstract": "Meta learning recently has been heavily researched and helped advance the contemporary machine learning. However, achieving well-performing meta-learning model requires a large amount of training tasks with high-quality meta-data representing the underlying task generalization goal, which is sometimes difficult and expensive to obtain for real applications. Current meta-data-driven meta-learning approaches, however, are fairly hard to train satisfactory meta-models with imperfect training tasks. To address this issue, we suggest a meta-knowledge informed meta-learning (MKIML) framework to improve meta-learning by additionally integrating compensated meta-knowledge into meta-learning process. We preliminarily integrate meta-knowledge into meta-objective via using an appropriate meta-regularization (MR) objective to regularize capacity complexity of the meta-model function class to facilitate better generalization on unseen tasks. As a practical implementation, we introduce data augmentation consistency to encode invariance as meta-knowledge for instantiating MR objective, denoted by DAC-MR. The proposed DAC-MR is hopeful to learn well-performing meta-models from training tasks with noisy, sparse or unavailable meta-data. We theoretically demonstrate that DAC-MR can be treated as a proxy meta-objective used to evaluate meta-model without high-quality meta-data. Besides, meta-data-driven meta-loss objective combined with DAC-MR is capable of achieving better meta-level generalization. 10 meta-learning tasks with different network architectures and benchmarks substantiate the capability of our DAC-MR on aiding meta-model learning. Fine performance of DAC-MR are obtained across all settings, and are well-aligned with our theoretical insights. This implies that our DAC-MR is problem-agnostic, and hopeful to be readily applied to extensive meta-learning problems and tasks. ",
    "url": "https://arxiv.org/abs/2305.07892",
    "authors": [
      "Jun Shu",
      "Xiang Yuan",
      "Deyu Meng",
      "Zongben Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.07894",
    "title": "Voxel-wise classification for porosity investigation of additive  manufactured parts with 3D unsupervised and (deeply) supervised neural  networks",
    "abstract": "Additive Manufacturing (AM) has emerged as a manufacturing process that allows the direct production of samples from digital models. To ensure that quality standards are met in all manufactured samples of a batch, X-ray computed tomography (X-CT) is often used combined with automated anomaly detection. For the latter, deep learning (DL) anomaly detection techniques are increasingly, as they can be trained to be robust to the material being analysed and resilient towards poor image quality. Unfortunately, most recent and popular DL models have been developed for 2D image processing, thereby disregarding valuable volumetric information. This study revisits recent supervised (UNet, UNet++, UNet 3+, MSS-UNet) and unsupervised (VAE, ceVAE, gmVAE, vqVAE) DL models for porosity analysis of AM samples from X-CT images and extends them to accept 3D input data with a 3D-patch pipeline for lower computational requirements, improved efficiency and generalisability. The supervised models were trained using the Focal Tversky loss to address class imbalance that arises from the low porosity in the training datasets. The output of the unsupervised models is post-processed to reduce misclassifications caused by their inability to adequately represent the object surface. The findings were cross-validated in a 5-fold fashion and include: a performance benchmark of the DL models, an evaluation of the post-processing algorithm, an evaluation of the effect of training supervised models with the output of unsupervised models. In a final performance benchmark on a test set with poor image quality, the best performing supervised model was MSS-UNet with an average precision of 0.808 $\\pm$ 0.013, while the best unsupervised model was the post-processed ceVAE with 0.935 $\\pm$ 0.001. The VAE/ceVAE models demonstrated superior capabilities, particularly when leveraging post-processing techniques. ",
    "url": "https://arxiv.org/abs/2305.07894",
    "authors": [
      "Domenico Iuso",
      "Soumick Chatterjee",
      "Jan De Beenhouwer",
      "Jan Sijbers"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.07911",
    "title": "Delay-Adapted Policy Optimization and Improved Regret for Adversarial  MDP with Delayed Bandit Feedback",
    "abstract": "Policy Optimization (PO) is one of the most popular methods in Reinforcement Learning (RL). Thus, theoretical guarantees for PO algorithms have become especially important to the RL community. In this paper, we study PO in adversarial MDPs with a challenge that arises in almost every real-world application -- \\textit{delayed bandit feedback}. We give the first near-optimal regret bounds for PO in tabular MDPs, and may even surpass state-of-the-art (which uses less efficient methods). Our novel Delay-Adapted PO (DAPO) is easy to implement and to generalize, allowing us to extend our algorithm to: (i) infinite state space under the assumption of linear $Q$-function, proving the first regret bounds for delayed feedback with function approximation. (ii) deep RL, demonstrating its effectiveness in experiments on MuJoCo domains. ",
    "url": "https://arxiv.org/abs/2305.07911",
    "authors": [
      "Tal Lancewicki",
      "Aviv Rosenberg",
      "Dmitry Sotnikov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.07912",
    "title": "Pre-trained Language Model with Prompts for Temporal Knowledge Graph  Completion",
    "abstract": "Temporal Knowledge graph completion (TKGC) is a crucial task that involves reasoning at known timestamps to complete the missing part of facts and has attracted more and more attention in recent years. Most existing methods focus on learning representations based on graph neural networks while inaccurately extracting information from timestamps and insufficiently utilizing the implied information in relations. To address these problems, we propose a novel TKGC model, namely Pre-trained Language Model with Prompts for TKGC (PPT). We convert a series of sampled quadruples into pre-trained language model inputs and convert intervals between timestamps into different prompts to make coherent sentences with implicit semantic information. We train our model with a masking strategy to convert TKGC task into a masked token prediction task, which can leverage the semantic information in pre-trained language models. Experiments on three benchmark datasets and extensive analysis demonstrate that our model has great competitiveness compared to other models with four metrics. Our model can effectively incorporate information from temporal knowledge graphs into the language models. ",
    "url": "https://arxiv.org/abs/2305.07912",
    "authors": [
      "Wenjie Xu",
      "Ben Liu",
      "Miao Peng",
      "Xu Jia",
      "Min Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.07922",
    "title": "CodeT5+: Open Code Large Language Models for Code Understanding and  Generation",
    "abstract": "Large language models (LLMs) pretrained on vast source code have achieved prominent progress in code intelligence. However, existing code LLMs have two main limitations in terms of architecture and pretraining tasks. First, they often adopt a specific architecture (encoder-only or decoder-only) or rely on a unified encoder-decoder network for different downstream tasks. The former paradigm is limited by inflexibility in applications while in the latter, the model is treated as a single system for all tasks, leading to suboptimal performance on a subset of tasks. Secondly, they often employ a limited set of pretraining objectives which might not be relevant to some downstream tasks and hence result in substantial performance degrade. To address these limitations, we propose ``CodeT5+'', a family of encoder-decoder LLMs for code in which component modules can be flexibly combined to suit a wide range of downstream code tasks. Such flexibility is enabled by our proposed mixture of pretraining objectives to mitigate the pretrain-finetune discrepancy. These objectives cover span denoising, contrastive learning, text-code matching, and causal LM pretraining tasks, on both unimodal and bimodal multilingual code corpora. Furthermore, we propose to initialize CodeT5+ with frozen off-the-shelf LLMs without training from scratch to efficiently scale up our models, and explore instruction-tuning to align with natural language instructions. We extensively evaluate CodeT5+ on over 20 code-related benchmarks in different settings, including zero-shot, finetuning, and instruction-tuning. We observe state-of-the-art (SoTA) model performance on various code-related tasks, such as code generation and completion, math programming, and text-to-code retrieval tasks. Particularly, our instruction-tuned CodeT5+ 16B achieves new SoTA results on HumanEval code generation task against other open code LLMs. ",
    "url": "https://arxiv.org/abs/2305.07922",
    "authors": [
      "Yue Wang",
      "Hung Le",
      "Akhilesh Deepak Gotmare",
      "Nghi D.Q. Bui",
      "Junnan Li",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2305.07935",
    "title": "Streaming 360-degree VR Video with Statistical QoS Provisioning in  mmWave Networks from Delay and Rate Perspectives",
    "abstract": "Millimeter-wave(mmWave) technology has emerged as a promising enabler for unleashing the full potential of 360-degree virtual reality (VR). However, the explosive growth of VR services, coupled with the reliability issues of mmWave communications, poses enormous challenges in terms of wireless resource and quality-of-service (QoS) provisioning for mmWave-enabled 360-degree VR. In this paper, we propose an innovative 360-degree VR streaming architecture that addresses three under-exploited issues: overlapping field-of-views (FoVs), statistical QoS provisioning (SQP), and loss-tolerant active data discarding. Specifically, an overlapping FoV-based optimal joint unicast and multicast (JUM) task assignment scheme is designed to implement the non-redundant task assignments, thereby conserving wireless resources remarkably. Furthermore, leveraging stochastic network calculus, we develop a comprehensive SQP theoretical framework that encompasses two SQP schemes from delay and rate perspectives. Additionally, a corresponding optimal adaptive joint time-slot allocation and active-discarding (ADAPT-JTAAT) transmission scheme is proposed to minimize resource consumption while guaranteeing diverse statistical QoS requirements under loss-intolerant and loss-tolerant scenarios from delay and rate perspectives, respectively. Extensive simulations demonstrate the effectiveness of the designed overlapping FoV-based JUM optimal task assignment scheme. Comparisons with six baseline schemes validate that the proposed optimal ADAPTJTAAT transmission scheme can achieve superior SQP performance in resource utilization, flexible rate control, and robust queue behaviors. ",
    "url": "https://arxiv.org/abs/2305.07935",
    "authors": [
      "Yuang Chen",
      "Hancheng Lu",
      "Langtian Qin",
      "Chang Wu",
      "Chang Wen Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.07940",
    "title": "MHDnet: Multi-modes multiscale physics informed neural networks for  solving Magnetohydrodynamics problems",
    "abstract": "Modeling and control of the magnetohydrodynamics (MHD) system remain a challenging problem, which involves the coupling between fluid dynamics and electromagnetism with the nonlinear, multiscale spatiotemporal features. To address these issues, we develop the MHDnet as a physics-informed learning approach to MHD problems with the multi-modes multiscale feature embedding into multiscale neural network architecture, which can accelerate the convergence of the neural networks (NN) by alleviating the interaction of magnetic fluid coupling across different frequency modes. Three different mathematical formulations are considered and named the original formulation ($B$), magnetic vector potential formulation ($A_1$), and divergence-free both magnetic induction and velocity formulation ($A_2$). The residual of them, together with the initial and boundary conditions, are emerged into the loss function of MHDnet. Moreover, the pressure fields of three formulations, as the hidden state, can be obtained without extra data and computational cost. Several numerical experiments are presented to demonstrate the performance of the proposed MHDnet compared with different NN architectures and numerical formulations, and the pressure fields can also be given by MHDnet with $A_1$ and $A_2$ formulations with high accuracy. ",
    "url": "https://arxiv.org/abs/2305.07940",
    "authors": [
      "Xiaofei Guan",
      "Boya Hu",
      "Shipeng Mao",
      "Xintong Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2305.07945",
    "title": "Deep Learning-based Data-aided Activity Detection with Extraction  Network in Grant-free Sparse Code Multiple Access Systems",
    "abstract": "This letter proposes a deep learning-based data-aided active user detection network (D-AUDN) for grant-free sparse code multiple access (SCMA) systems that leverages both SCMA codebook and Zadoff-Chu preamble for activity detection. Due to disparate data and preamble distribution as well as codebook collision, existing D-AUDNs experience performance degradation when multiple preambles are associated with each codebook. To address this, a user activity extraction network (UAEN) is integrated within the D-AUDN to extract a-priori activity information from the codebook, improving activity detection of the associated preambles. Additionally, efficient SCMA codebook design and Zadoff-Chu preamble association are considered to further enhance performance. ",
    "url": "https://arxiv.org/abs/2305.07945",
    "authors": [
      "Minsig Han",
      "Ameha T. Abebe",
      "Chung G. Kang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.07952",
    "title": "APNet: An All-Frame-Level Neural Vocoder Incorporating Direct Prediction  of Amplitude and Phase Spectra",
    "abstract": "This paper presents a novel neural vocoder named APNet which reconstructs speech waveforms from acoustic features by predicting amplitude and phase spectra directly. The APNet vocoder is composed of an amplitude spectrum predictor (ASP) and a phase spectrum predictor (PSP). The ASP is a residual convolution network which predicts frame-level log amplitude spectra from acoustic features. The PSP also adopts a residual convolution network using acoustic features as input, then passes the output of this network through two parallel linear convolution layers respectively, and finally integrates into a phase calculation formula to estimate frame-level phase spectra. Finally, the outputs of ASP and PSP are combined to reconstruct speech waveforms by inverse short-time Fourier transform (ISTFT). All operations of the ASP and PSP are performed at the frame level. We train the ASP and PSP jointly and define multilevel loss functions based on amplitude mean square error, phase anti-wrapping error, short-time spectral inconsistency error and time domain reconstruction error. Experimental results show that our proposed APNet vocoder achieves an approximately 8x faster inference speed than HiFi-GAN v1 on a CPU due to the all-frame-level operations, while its synthesized speech quality is comparable to HiFi-GAN v1. The synthesized speech quality of the APNet vocoder is also better than that of several equally efficient models. Ablation experiments also confirm that the proposed parallel phase estimation architecture is essential to phase modeling and the proposed loss functions are helpful for improving the synthesized speech quality. ",
    "url": "https://arxiv.org/abs/2305.07952",
    "authors": [
      "Yang Ai",
      "Zhen-Hua Ling"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.07954",
    "title": "Image Segmentation via Probabilistic Graph Matching",
    "abstract": "This work presents an unsupervised and semi-automatic image segmentation approach where we formulate the segmentation as a inference problem based on unary and pairwise assignment probabilities computed using low-level image cues. The inference is solved via a probabilistic graph matching scheme, which allows rigorous incorporation of low level image cues and automatic tuning of parameters. The proposed scheme is experimentally shown to compare favorably with contemporary semi-supervised and unsupervised image segmentation schemes, when applied to contemporary state-of-the-art image sets. ",
    "url": "https://arxiv.org/abs/2305.07954",
    "authors": [
      "Ayelet Heimowitz",
      "Yosi Keller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.07978",
    "title": "Network analysis with the aid of the path length matrix",
    "abstract": "Let a network be represented by a simple graph $\\mathcal{G}$ with $n$ vertices. A common approach to investigate properties of a network is to use the adjacency matrix $A=[a_{ij}]_{i,j=1}^n\\in\\R^{n\\times n}$ associated with the graph $\\mathcal{G}$, where $a_{ij}>0$ if there is an edge pointing from vertex $v_i$ to vertex $v_j$, and $a_{ij}=0$ otherwise. Both $A$ and its positive integer powers reveal important properties of the graph. This paper proposes to study properties of a graph $\\mathcal{G}$ by also using the path length matrix for the graph. The $(ij)^{th}$ entry of the path length matrix is the length of the shortest path from vertex $v_i$ to vertex $v_j$; if there is no path between these vertices, then the value of the entry is $\\infty$. Powers of the path length matrix are formed by using min-plus matrix multiplication and are important for exhibiting properties of $\\mathcal{G}$. We show how several known measures of communication such as closeness centrality, harmonic centrality, and eccentricity are related to the path length matrix, and we introduce new measures of communication, such as the harmonic $K$-centrality and global $K$-efficiency, where only (short) paths made up of at most $K$ edges are taken into account. The sensitivity of the global $K$-efficiency to changes of the entries of the adjacency matrix also is considered. ",
    "url": "https://arxiv.org/abs/2305.07978",
    "authors": [
      "Silvia Noschese",
      "Lothar Reichel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2305.07988",
    "title": "Self-Supervised Sentence Compression for Meeting Summarization",
    "abstract": "The conventional summarization model often fails to capture critical information in meeting transcripts, as meeting corpus usually involves multiple parties with lengthy conversations and is stuffed with redundant and trivial content. To tackle this problem, we present SVB, an effective and efficient framework for meeting summarization that `compress' the redundancy while preserving important content via three processes: sliding-window dialogue restoration and \\textbf{S}coring, channel-wise importance score \\textbf{V}oting, and relative positional \\textbf{B}ucketing. Specifically, under the self-supervised paradigm, the sliding-window scoring aims to rate the importance of each token from multiple views. Then these ratings are aggregated by channel-wise voting. Tokens with high ratings will be regarded as salient information and labeled as \\textit{anchors}. Finally, to tailor the lengthy input to an acceptable length for the language model, the relative positional bucketing algorithm is performed to retain the anchors while compressing other irrelevant contents in different granularities. Without large-scale pre-training or expert-grade annotating tools, our proposed method outperforms previous state-of-the-art approaches. A vast amount of evaluations and analyses are conducted to prove the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2305.07988",
    "authors": [
      "Haochen Tan",
      "Han Wu",
      "Wei Shao",
      "Xinyun Zhang",
      "Mingjie Zhan",
      "Zhaohui Hou",
      "Ding Liang",
      "Linqi Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.07996",
    "title": "Successive Affine Learning for Deep Neural Networks",
    "abstract": "This paper introduces a successive affine learning (SAL) model for constructing deep neural networks (DNNs). Traditionally, a DNN is built by solving a non-convex optimization problem. It is often challenging to solve such a problem numerically due to its non-convexity and having a large number of layers. To address this challenge, inspired by the human education system, the multi-grade deep learning (MGDL) model was recently initiated by the author of this paper. The MGDL model learns a DNN in several grades, in each of which one constructs a shallow DNN consisting of a small number of layers. The MGDL model still requires solving several non-convex optimization problems. The proposed SAL model mutates from the MGDL model. Noting that each layer of a DNN consists of an affine map followed by an activation function, we propose to learn the affine map by solving a quadratic/convex optimization problem which involves the activation function only {\\it after} the weight matrix and the bias vector for the current layer have been trained. In the context of function approximation, for a given function the SAL model generates an orthogonal expansion of the function with adaptive basis functions in the form of DNNs. We establish the Pythagorean identity and the Parseval identity for the orthogonal system generated by the SAL model. Moreover, we provide a convergence theorem of the SAL process in the sense that either it terminates after a finite number of grades or the norms of its optimal error functions strictly decrease to a limit as the grade number increases to infinity. Furthermore, we present numerical examples of proof of concept which demonstrate that the proposed SAL model significantly outperforms the traditional deep learning model. ",
    "url": "https://arxiv.org/abs/2305.07996",
    "authors": [
      "Yuesheng Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2305.08012",
    "title": "Quantization in Spiking Neural Networks",
    "abstract": "In spiking neural networks (SNN), at each node, an incoming sequence of weighted Dirac pulses is converted into an output sequence of weighted Dirac pulses by a leaky-integrate-and-fire (LIF) neuron model based on spike aggregation and thresholding. We show that this mapping can be understood as a quantization operator and state a corresponding formula for the quantization error by means of the Alexiewicz norm. This analysis has implications for rethinking re-initialization in the LIF model, leading to the proposal of 'reset-to-mod' as a modulo-based reset variant. ",
    "url": "https://arxiv.org/abs/2305.08012",
    "authors": [
      "Bernhard A. Moser",
      "Michael Lunglmayr"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Discrete Mathematics (cs.DM)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2305.08013",
    "title": "Information Bottleneck Analysis of Deep Neural Networks via Lossy  Compression",
    "abstract": "The Information Bottleneck (IB) principle offers an information-theoretic framework for analyzing the training process of deep neural networks (DNNs). Its essence lies in tracking the dynamics of two mutual information (MI) values: one between the hidden layer and the class label, and the other between the hidden layer and the DNN input. According to the hypothesis put forth by Shwartz-Ziv and Tishby (2017), the training process consists of two distinct phases: fitting and compression. The latter phase is believed to account for the good generalization performance exhibited by DNNs. Due to the challenging nature of estimating MI between high-dimensional random vectors, this hypothesis has only been verified for toy NNs or specific types of NNs, such as quantized NNs and dropout NNs. In this paper, we introduce a comprehensive framework for conducting IB analysis of general NNs. Our approach leverages the stochastic NN method proposed by Goldfeld et al. (2019) and incorporates a compression step to overcome the obstacles associated with high dimensionality. In other words, we estimate the MI between the compressed representations of high-dimensional random vectors. The proposed method is supported by both theoretical and practical justifications. Notably, we demonstrate the accuracy of our estimator through synthetic experiments featuring predefined MI values. Finally, we perform IB analysis on a close-to-real-scale convolutional DNN, which reveals new features of the MI dynamics. ",
    "url": "https://arxiv.org/abs/2305.08013",
    "authors": [
      "Ivan Butakov",
      "Aleksander Tolmachev",
      "Sofia Malanchuk",
      "Anna Neopryatnaya",
      "Alexey Frolov",
      "Kirill Andreev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.08021",
    "title": "TIPS: Topologically Important Path Sampling for Anytime Neural Networks",
    "abstract": "Anytime neural networks (AnytimeNNs) are a promising solution to adaptively adjust the model complexity at runtime under various hardware resource constraints. However, the manually-designed AnytimeNNs are biased by designers' prior experience and thus provide sub-optimal solutions. To address the limitations of existing hand-crafted approaches, we first model the training process of AnytimeNNs as a discrete-time Markov chain (DTMC) and use it to identify the paths that contribute the most to the training of AnytimeNNs. Based on this new DTMC-based analysis, we further propose TIPS, a framework to automatically design AnytimeNNs under various hardware constraints. Our experimental results show that TIPS can improve the convergence rate and test accuracy of AnytimeNNs. Compared to the existing AnytimeNNs approaches, TIPS improves the accuracy by 2%-6.6% on multiple datasets and achieves SOTA accuracy-FLOPs tradeoffs. ",
    "url": "https://arxiv.org/abs/2305.08021",
    "authors": [
      "Guihong Li",
      "Kartikeya Bhardwaj",
      "Yuedong Yang",
      "Radu Marculescu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.08031",
    "title": "On enhancing the robustness of Vision Transformers: Defensive Diffusion",
    "abstract": "Privacy and confidentiality of medical data are of utmost importance in healthcare settings. ViTs, the SOTA vision model, rely on large amounts of patient data for training, which raises concerns about data security and the potential for unauthorized access. Adversaries may exploit vulnerabilities in ViTs to extract sensitive patient information and compromising patient privacy. This work address these vulnerabilities to ensure the trustworthiness and reliability of ViTs in medical applications. In this work, we introduced a defensive diffusion technique as an adversarial purifier to eliminate adversarial noise introduced by attackers in the original image. By utilizing the denoising capabilities of the diffusion model, we employ a reverse diffusion process to effectively eliminate the adversarial noise from the attack sample, resulting in a cleaner image that is then fed into the ViT blocks. Our findings demonstrate the effectiveness of the diffusion model in eliminating attack-agnostic adversarial noise from images. Additionally, we propose combining knowledge distillation with our framework to obtain a lightweight student model that is both computationally efficient and robust against gray box attacks. Comparison of our method with a SOTA baseline method, SEViT, shows that our work is able to outperform the baseline. Extensive experiments conducted on a publicly available Tuberculosis X-ray dataset validate the computational efficiency and improved robustness achieved by our proposed architecture. ",
    "url": "https://arxiv.org/abs/2305.08031",
    "authors": [
      "Raza Imam",
      "Muhammad Huzaifa",
      "Mohammed El-Amine Azz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.08034",
    "title": "DNN-Defender: An in-DRAM Deep Neural Network Defense Mechanism for  Adversarial Weight Attack",
    "abstract": "With deep learning deployed in many security-sensitive areas, machine learning security is becoming progressively important. Recent studies demonstrate attackers can exploit system-level techniques exploiting the RowHammer vulnerability of DRAM to deterministically and precisely flip bits in Deep Neural Networks (DNN) model weights to affect inference accuracy. The existing defense mechanisms are software-based, such as weight reconstruction requiring expensive training overhead or performance degradation. On the other hand, generic hardware-based victim-/aggressor-focused mechanisms impose expensive hardware overheads and preserve the spatial connection between victim and aggressor rows. In this paper, we present the first DRAM-based victim-focused defense mechanism tailored for quantized DNNs, named DNN-Defender that leverages the potential of in-DRAM swapping to withstand the targeted bit-flip attacks. Our results indicate that DNN-Defender can deliver a high level of protection downgrading the performance of targeted RowHammer attacks to a random attack level. In addition, the proposed defense has no accuracy drop on CIFAR-10 and ImageNet datasets without requiring any software training or incurring additional hardware overhead. ",
    "url": "https://arxiv.org/abs/2305.08034",
    "authors": [
      "Ranyang Zhou",
      "Sabbir Ahmed",
      "Adnan Siraj Rakin",
      "Shaahin Angizi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.08037",
    "title": "ChargeX: Exploring State Switching Attack on Electric Vehicle Charging  Systems",
    "abstract": "Electric Vehicle (EV) has become one of the promising solutions to the ever-evolving environmental and energy crisis. The key to the wide adoption of EVs is a pervasive charging infrastructure, composed of both private/home chargers and public/commercial charging stations. The security of EV charging, however, has not been thoroughly investigated. This paper investigates the communication mechanisms between the chargers and EVs, and exposes the lack of protection on the authenticity in the SAE J1772 charging control protocol. To showcase our discoveries, we propose a new class of attacks, ChargeX, which aims to manipulate the charging states or charging rates of EV chargers with the goal of disrupting the charging schedules, causing a denial of service (DoS), or degrading the battery performance. ChargeX inserts a hardware attack circuit to strategically modify the charging control signals. We design and implement multiple attack systems, and evaluate the attacks on a public charging station and two home chargers using a simulated vehicle load in the lab environment. Extensive experiments on different types of chargers demonstrate the effectiveness and generalization of ChargeX. Specifically, we demonstrate that ChargeX can force the switching of an EV's charging state from ``stand by\" to ``charging\", even when the vehicle is not in the charging state. We further validate the attacks on a Tesla Model 3 vehicle to demonstrate the disruptive impacts of ChargeX. If deployed, ChargeX may significantly demolish people's trust in the EV charging infrastructure. ",
    "url": "https://arxiv.org/abs/2305.08037",
    "authors": [
      "Ce Zhou",
      "Qiben Yan",
      "Zhiyuan Yu",
      "Eshan Dixit",
      "Ning Zhang",
      "Huacheng Zeng",
      "Alireza Safdari Ghanhdari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2305.08039",
    "title": "Systematic Meets Unintended: Prior Knowledge Adaptive 5G Vulnerability  Detection via Multi-Fuzzing",
    "abstract": "The virtualization and softwarization of 5G and NextG are critical enablers of the shift to flexibility, but they also present a potential attack surface for threats. However, current security research in communication systems focuses on specific aspects of security challenges and lacks a holistic perspective. To address this challenge, a novel systematic fuzzing approach is proposed to reveal, detect, and predict vulnerabilities with and without prior knowledge assumptions from attackers. It also serves as a digital twin platform for system testing and defense simulation pipeline. Three fuzzing strategies are proposed: Listen-and-Learn (LAL), Synchronize-and-Learn (SyAL), and Source-and-Learn (SoAL). The LAL strategy is a black-box fuzzing strategy used to discover vulnerabilities without prior protocol knowledge, while the SyAL strategy, also a black-box fuzzing method, targets vulnerabilities more accurately with attacker-accessible user information and a novel probability-based fuzzing approach. The white-box fuzzing strategy, SoAL, is then employed to identify and explain vulnerabilities through fuzzing of significant bits. Using the srsRAN 5G platform, the LAL strategy identifies 129 RRC connection vulnerabilities with an average detection duration of 0.072s. Leveraging the probability-based fuzzing algorithm, the SyAL strategy outperforms existing models in precision and recall, using significantly fewer fuzzing cases. SoAL detects three man-in-the-middle vulnerabilities stemming from 5G protocol vulnerabilities. The proposed solution is scalable to other open-source and commercial 5G platforms and protocols beyond RRC. Extensive experimental results demonstrate that the proposed solution is an efficient and efficient approach to validate 5G security; meanwhile, it serves as real-time vulnerability detection and proactive defense. ",
    "url": "https://arxiv.org/abs/2305.08039",
    "authors": [
      "Jingda Yang",
      "Ying Wang",
      "Yanjun Pan",
      "Tuyen X. Tran"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.08048",
    "title": "Towards Understanding the Generalization of Graph Neural Networks",
    "abstract": "Graph neural networks (GNNs) are the most widely adopted model in graph-structured data oriented learning and representation. Despite their extraordinary success in real-world applications, understanding their working mechanism by theory is still on primary stage. In this paper, we move towards this goal from the perspective of generalization. To be specific, we first establish high probability bounds of generalization gap and gradients in transductive learning with consideration of stochastic optimization. After that, we provide high probability bounds of generalization gap for popular GNNs. The theoretical results reveal the architecture specific factors affecting the generalization gap. Experimental results on benchmark datasets show the consistency between theoretical results and empirical evidence. Our results provide new insights in understanding the generalization of GNNs. ",
    "url": "https://arxiv.org/abs/2305.08048",
    "authors": [
      "Huayi Tang",
      "Yong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.08069",
    "title": "Instance-Aware Repeat Factor Sampling for Long-Tailed Object Detection",
    "abstract": "We propose an embarrassingly simple method -- instance-aware repeat factor sampling (IRFS) to address the problem of imbalanced data in long-tailed object detection. Imbalanced datasets in real-world object detection often suffer from a large disparity in the number of instances for each class. To improve the generalization performance of object detection models on rare classes, various data sampling techniques have been proposed. Repeat factor sampling (RFS) has shown promise due to its simplicity and effectiveness. Despite its efficiency, RFS completely neglects the instance counts and solely relies on the image count during re-sampling process. However, instance count may immensely vary for different classes with similar image counts. Such variation highlights the importance of both image and instance for addressing the long-tail distributions. Thus, we propose IRFS which unifies instance and image counts for the re-sampling process to be aware of different perspectives of the imbalance in long-tailed datasets. Our method shows promising results on the challenging LVIS v1.0 benchmark dataset over various architectures and backbones, demonstrating their effectiveness in improving the performance of object detection models on rare classes with a relative $+50\\%$ average precision (AP) improvement over counterpart RFS. IRFS can serve as a strong baseline and be easily incorporated into existing long-tailed frameworks. ",
    "url": "https://arxiv.org/abs/2305.08069",
    "authors": [
      "Burhaneddin Yaman",
      "Tanvir Mahmud",
      "Chun-Hao Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.08077",
    "title": "Optimization of Residential Demand Response Program Cost with  Consideration for Occupants Thermal Comfort and Privacy",
    "abstract": "Residential consumers can use the demand response program (DRP) if they can utilize the home energy management system (HEMS), which reduces consumer costs by automatically adjusting air conditioning (AC) setpoints and shifting some appliances to off-peak hours. If HEMS knows occupancy status, consumers can gain more economic benefits and thermal comfort. However, for the building occupancy status, direct sensing is costly, inaccurate, and intrusive for residents. So, forecasting algorithms could serve as an effective alternative. The goal of this study is to present a non-intrusive, accurate, and cost-effective approach, to develop a multi-objective simulation model for the application of DRPs in a smart residential house, where (a) electrical load demand reduction, (b) adjustment in thermal comfort (AC) temperature setpoints, and (c) , worst cases scenario approach is very conservative. Because that is unlikely all uncertain parameters take their worst values at all times. So, the flexible robust counterpart optimization along with uncertainty budgets is developed to consider uncertainty realistically. Simulated results indicate that considering uncertainty increases the costs by 36 percent and decreases the AC temperature setpoints. Besides, using DRPs reduces demand by shifting some appliance operations to off-peak hours and lowers costs by 13.2 percent. ",
    "url": "https://arxiv.org/abs/2305.08077",
    "authors": [
      "Reza Nematirad",
      "M. M. Ardehali",
      "Amir Khorsandi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.08096",
    "title": "Towards Understanding and Improving Knowledge Distillation for Neural  Machine Translation",
    "abstract": "Knowledge distillation (KD) is a promising technique for model compression in neural machine translation. However, where the knowledge hides in KD is still not clear, which may hinder the development of KD. In this work, we first unravel this mystery from an empirical perspective and show that the knowledge comes from the top-1 predictions of teachers, which also helps us build a potential connection between word- and sequence-level KD. Further, we point out two inherent issues in vanilla word-level KD based on this finding. Firstly, the current objective of KD spreads its focus to whole distributions to learn the knowledge, yet lacks special treatment on the most crucial top-1 information. Secondly, the knowledge is largely covered by the golden information due to the fact that most top-1 predictions of teachers overlap with ground-truth tokens, which further restricts the potential of KD. To address these issues, we propose a novel method named \\textbf{T}op-1 \\textbf{I}nformation \\textbf{E}nhanced \\textbf{K}nowledge \\textbf{D}istillation (TIE-KD). Specifically, we design a hierarchical ranking loss to enforce the learning of the top-1 information from the teacher. Additionally, we develop an iterative KD procedure to infuse more additional knowledge by distilling on the data without ground-truth targets. Experiments on WMT'14 English-German, WMT'14 English-French and WMT'16 English-Romanian demonstrate that our method can respectively boost Transformer$_{base}$ students by +1.04, +0.60 and +1.11 BLEU scores and significantly outperform the vanilla word-level KD baseline. Besides, our method shows higher generalizability on different teacher-student capacity gaps than existing KD techniques. ",
    "url": "https://arxiv.org/abs/2305.08096",
    "authors": [
      "Songming Zhang",
      "Yunlong Liang",
      "Shuaibo Wang",
      "Wenjuan Han",
      "Jian Liu",
      "Jinan Xu",
      "Yufeng Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.08099",
    "title": "Self-supervised Neural Factor Analysis for Disentangling Utterance-level  Speech Representations",
    "abstract": "Self-supervised learning (SSL) speech models such as wav2vec and HuBERT have demonstrated state-of-the-art performance on automatic speech recognition (ASR) and proved to be extremely useful in low label-resource settings. However, the success of SSL models has yet to transfer to utterance-level tasks such as speaker, emotion, and language recognition, which still require supervised fine-tuning of the SSL models to obtain good performance. We argue that the problem is caused by the lack of disentangled representations and an utterance-level learning objective for these tasks. Inspired by how HuBERT uses clustering to discover hidden acoustic units, we formulate a factor analysis (FA) model that uses the discovered hidden acoustic units to align the SSL features. The underlying utterance-level representations are disentangled from the content of speech using probabilistic inference on the aligned features. Furthermore, the variational lower bound derived from the FA model provides an utterance-level objective, allowing error gradients to be backpropagated to the Transformer layers to learn highly discriminative acoustic units. When used in conjunction with HuBERT's masked prediction training, our models outperform the current best model, WavLM, on all utterance-level non-semantic tasks on the SUPERB benchmark with only 20% of labeled data. ",
    "url": "https://arxiv.org/abs/2305.08099",
    "authors": [
      "Weiwei Lin",
      "Chenhang He",
      "Man-Wai Mak",
      "Youzhi Tu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.08107",
    "title": "Balancing Privacy and Utility of Spatio-Temporal Data for Taxi-Demand  Prediction",
    "abstract": "Taxi-demand prediction is an important application of machine learning that enables taxi-providing facilities to optimize their operations and city planners to improve transportation infrastructure and services. However, the use of sensitive data in these systems raises concerns about privacy and security. In this paper, we propose the use of federated learning for taxi-demand prediction that allows multiple parties to train a machine learning model on their own data while keeping the data private and secure. This can enable organizations to build models on data they otherwise would not be able to access. Despite its potential benefits, federated learning for taxi-demand prediction poses several technical challenges, such as class imbalance, data scarcity among some parties, and the need to ensure model generalization to accommodate diverse facilities and geographic regions. To effectively address these challenges, we propose a system that utilizes region-independent encoding for geographic lat-long coordinates. By doing so, the proposed model is not limited to a specific region, enabling it to perform optimally in any area. Furthermore, we employ cost-sensitive learning and various regularization techniques to mitigate issues related to data scarcity and overfitting, respectively. Evaluation with real-world data collected from 16 taxi service providers in Japan over a period of six months showed the proposed system predicted demand level accurately within 1\\% error compared to a single model trained with integrated data. The system also effectively defended against membership inference attacks on passenger data. ",
    "url": "https://arxiv.org/abs/2305.08107",
    "authors": [
      "Yumeki Goto",
      "Tomoya Matsumoto",
      "Hamada Rizk",
      "Naoto Yanai",
      "Hirozumi Yamaguchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.08117",
    "title": "MultiQuant: A Novel Multi-Branch Topology Method for Arbitrary Bit-width  Network Quantization",
    "abstract": "Arbitrary bit-width network quantization has received significant attention due to its high adaptability to various bit-width requirements during runtime. However, in this paper, we investigate existing methods and observe a significant accumulation of quantization errors caused by frequent bit-width switching of weights and activations, leading to limited performance. To address this issue, we propose MultiQuant, a novel method that utilizes a multi-branch topology for arbitrary bit-width quantization. MultiQuant duplicates the network body into multiple independent branches and quantizes the weights of each branch to a fixed 2-bit while retaining the input activations in the expected bit-width. This approach maintains the computational cost as the same while avoiding the switching of weight bit-widths, thereby substantially reducing errors in weight quantization. Additionally, we introduce an amortization branch selection strategy to distribute quantization errors caused by activation bit-width switching among branches to enhance performance. Finally, we design an in-place distillation strategy that facilitates guidance between branches to further enhance MultiQuant's performance. Extensive experiments demonstrate that MultiQuant achieves significant performance gains compared to existing arbitrary bit-width quantization methods. Code is at \\url{https://github.com/zysxmu/MultiQuant}. ",
    "url": "https://arxiv.org/abs/2305.08117",
    "authors": [
      "Yunshan Zhong",
      "Mingbao Lin",
      "Yuyao Zhou",
      "Mengzhao Chen",
      "Yuxin Zhang",
      "Fei Chao",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08125",
    "title": "Robustness of Participatory Budgeting Outcomes: Complexity and  Experiments",
    "abstract": "We study the robustness of approval-based participatory budgeting (PB) rules to random noise in the votes. Our contributions are twofold. First, we study the computational complexity of the #Flip-Bribery problem, where given a PB instance we ask for the number of ways in which we can flip a given number of approvals in the votes, so that a specific project is selected. The idea is that #Flip-Bribery captures the problem of computing the funding probabilities of projects in case random noise is added. Unfortunately, the problem is intractable even for the simplest PB rules. Second, we analyze the robustness of several prominent PB rules (including the basic greedy rule and the Method of Equal Shares) on real-life instances from Pabulib. Since #Flip-Bribery is intractable, we resort to sampling to obtain our results. We quantify the extent to which simple, greedy PB rules are more robust than proportional ones, and we identify three types of (very) non-robust projects in real-life PB instances. ",
    "url": "https://arxiv.org/abs/2305.08125",
    "authors": [
      "Niclas Boehmer",
      "Piotr Faliszewski",
      "\u0141ukasz Janeczko",
      "Andrzej Kaczmarczyk"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ]
  },
  {
    "id": "arXiv:2305.08174",
    "title": "ReSDF: Redistancing Implicit Surfaces using Neural Networks",
    "abstract": "This paper proposes a deep-learning-based method for recovering a signed distance function (SDF) of a given hypersurface represented by an implicit level set function. Using the flexibility of constructing a neural network, we use an augmented network by defining an auxiliary output to represent the gradient of the SDF. There are three advantages of the augmented network; (i) the target interface is accurately captured, (ii) the gradient has a unit norm, and (iii) two outputs are approximated by a single network. Moreover, unlike a conventional loss term which uses a residual of the eikonal equation, a novel training objective consisting of three loss terms is designed. The first loss function enforces a pointwise matching between two outputs of the augmented network. The second loss function leveraged by a geometric characteristic of the SDF imposes the shortest path obtained by the gradient. The third loss function regularizes a singularity of the SDF caused by discontinuities of the gradient. Numerical results across a wide range of complex and irregular interfaces in two and three-dimensional domains confirm the effectiveness and accuracy of the proposed method. We also compare the results of the proposed method with physics-informed neural networks approaches and the fast marching method. ",
    "url": "https://arxiv.org/abs/2305.08174",
    "authors": [
      "Yesom Park",
      "Chang hoon Song",
      "Jooyoung Hahn",
      "Myungjoo Kang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2305.08186",
    "title": "Street Layout Design via Conditional Adversarial Learning",
    "abstract": "Designing high-quality urban street layouts has long been in high demand, but entangles notable challenges. Conventional methods based on deep generative models are yet to fill the gap on integrating both natural and socioeconomic factors in the design loop. In this paper, we propose a novel urban street layout design method based on conditional adversarial learning. Specifically, a conditional generative adversarial network trained on a real-world dataset synthesizes street layout images from the feature map, into which an autoencoder fuses a set of natural and socioeconomic data for a region of interest; The following extraction module generates high-quality street layout graphs corresponding to the synthesized images. Experiments and evaluations suggest that the proposed method outputs various urban street layouts that are visually and structurally alike their real-world counterparts, which can be used to support the creation of high-quality urban virtual environments. ",
    "url": "https://arxiv.org/abs/2305.08186",
    "authors": [
      "Lehao Yang",
      "Long Li",
      "Qihao Chen",
      "Jiling Zhang",
      "Tian Feng",
      "Wei Zhang"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2305.08190",
    "title": "TSGN: Temporal Scene Graph Neural Networks with Projected Vectorized  Representation for Multi-Agent Motion Prediction",
    "abstract": "Predicting future motions of nearby agents is essential for an autonomous vehicle to take safe and effective actions. In this paper, we propose TSGN, a framework using Temporal Scene Graph Neural Networks with projected vectorized representations for multi-agent trajectory prediction. Projected vectorized representation models the traffic scene as a graph which is constructed by a set of vectors. These vectors represent agents, road network, and their spatial relative relationships. All relative features under this representation are both translationand rotation-invariant. Based on this representation, TSGN captures the spatial-temporal features across agents, road network, interactions among them, and temporal dependencies of temporal traffic scenes. TSGN can predict multimodal future trajectories for all agents simultaneously, plausibly, and accurately. Meanwhile, we propose a Hierarchical Lane Transformer for capturing interactions between agents and road network, which filters the surrounding road network and only keeps the most probable lane segments which could have an impact on the future behavior of the target agent. Without sacrificing the prediction performance, this greatly reduces the computational burden. Experiments show TSGN achieves state-of-the-art performance on the Argoverse motion forecasting benchmar. ",
    "url": "https://arxiv.org/abs/2305.08190",
    "authors": [
      "Yunong Wu",
      "Thomas Gilles",
      "Bogdan Stanciulescu",
      "Fabien Moutarde"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08192",
    "title": "Diffusion Models for Imperceptible and Transferable Adversarial Attack",
    "abstract": "Many existing adversarial attacks generate $L_p$-norm perturbations on image RGB space. Despite some achievements in transferability and attack success rate, the crafted adversarial examples are easily perceived by human eyes. Towards visual imperceptibility, some recent works explore unrestricted attacks without $L_p$-norm constraints, yet lacking transferability of attacking black-box models. In this work, we propose a novel imperceptible and transferable attack by leveraging both the generative and discriminative power of diffusion models. Specifically, instead of direct manipulation in pixel space, we craft perturbations in latent space of diffusion models. Combined with well-designed content-preserving structures, we can generate human-insensitive perturbations embedded with semantic clues. For better transferability, we further \"deceive\" the diffusion model which can be viewed as an additional recognition surrogate, by distracting its attention away from the target regions. To our knowledge, our proposed method, DiffAttack, is the first that introduces diffusion models into adversarial attack field. Extensive experiments on various model structures (including CNNs, Transformers, MLPs) and defense methods have demonstrated our superiority over other attack methods. ",
    "url": "https://arxiv.org/abs/2305.08192",
    "authors": [
      "Jianqi Chen",
      "Hao Chen",
      "Keyan Chen",
      "Yilan Zhang",
      "Zhengxia Zou",
      "Zhenwei Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08194",
    "title": "A new iterative method for construction of the Kolmogorov-Arnold  representation",
    "abstract": "The Kolmogorov-Arnold representation of a continuous multivariate function is a decomposition of the function into a structure of inner and outer functions of a single variable. It can be a convenient tool for tasks where it is required to obtain a predictive model that maps some vector input of a black box system into a scalar output. However, the construction of such representation based on the recorded input-output data is a challenging task. In the present paper, it is suggested to decompose the underlying functions of the representation into continuous basis functions and parameters. A novel lightweight algorithm for parameter identification is then proposed. The algorithm is based on the Newton-Kaczmarz method for solving non-linear systems of equations and is locally convergent. Numerical examples show that it is more robust with respect to the section of the initial guess for the parameters than the straightforward application of the Gauss-Newton method for parameter identification. ",
    "url": "https://arxiv.org/abs/2305.08194",
    "authors": [
      "Michael Poluektov",
      "Andrew Polar"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2305.08197",
    "title": "A Dataset Fusion Algorithm for Generalised Anomaly Detection in  Homogeneous Periodic Time Series Datasets",
    "abstract": "The generalisation of Neural Networks (NN) to multiple datasets is often overlooked in literature due to NNs typically being optimised for specific data sources. This becomes especially challenging in time-series-based multi-dataset models due to difficulties in fusing sequential data from different sensors and collection specifications. In a commercial environment, however, generalisation can effectively utilise available data and computational power, which is essential in the context of Green AI, the sustainable development of AI models. This paper introduces \"Dataset Fusion,\" a novel dataset composition algorithm for fusing periodic signals from multiple homogeneous datasets into a single dataset while retaining unique features for generalised anomaly detection. The proposed approach, tested on a case study of 3-phase current data from 2 different homogeneous Induction Motor (IM) fault datasets using an unsupervised LSTMCaps NN, significantly outperforms conventional training approaches with an Average F1 score of 0.879 and effectively generalises across all datasets. The proposed approach was also tested with varying percentages of the training data, in line with the principles of Green AI. Results show that using only 6.25\\% of the training data, translating to a 93.7\\% reduction in computational power, results in a mere 4.04\\% decrease in performance, demonstrating the advantages of the proposed approach in terms of both performance and computational efficiency. Moreover, the algorithm's effectiveness under non-ideal conditions highlights its potential for practical use in real-world applications. ",
    "url": "https://arxiv.org/abs/2305.08197",
    "authors": [
      "Ayman Elhalwagy",
      "Tatiana Kalganova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.08215",
    "title": "Learning Structure Aware Deep Spectral Embedding",
    "abstract": "Spectral Embedding (SE) has often been used to map data points from non-linear manifolds to linear subspaces for the purpose of classification and clustering. Despite significant advantages, the subspace structure of data in the original space is not preserved in the embedding space. To address this issue subspace clustering has been proposed by replacing the SE graph affinity with a self-expression matrix. It works well if the data lies in a union of linear subspaces however, the performance may degrade in real-world applications where data often spans non-linear manifolds. To address this problem we propose a novel structure-aware deep spectral embedding by combining a spectral embedding loss and a structure preservation loss. To this end, a deep neural network architecture is proposed that simultaneously encodes both types of information and aims to generate structure-aware spectral embedding. The subspace structure of the input data is encoded by using attention-based self-expression learning. The proposed algorithm is evaluated on six publicly available real-world datasets. The results demonstrate the excellent clustering performance of the proposed algorithm compared to the existing state-of-the-art methods. The proposed algorithm has also exhibited better generalization to unseen data points and it is scalable to larger datasets without requiring significant computational resources. ",
    "url": "https://arxiv.org/abs/2305.08215",
    "authors": [
      "Hira Yaseen",
      "Arif Mahmood"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08226",
    "title": "NLP-based Cross-Layer 5G Vulnerabilities Detection via Fuzzing Generated  Run-Time Profiling",
    "abstract": "The effectiveness and efficiency of 5G software stack vulnerability and unintended behavior detection are essential for 5G assurance, especially for its applications in critical infrastructures. Scalability and automation are the main challenges in testing approaches and cybersecurity research. In this paper, we propose an innovative approach for automatically detecting vulnerabilities, unintended emergent behaviors, and performance degradation in 5G stacks via run-time profiling documents corresponding to fuzz testing in code repositories. Piloting on srsRAN, we map the run-time profiling via Logging Information (LogInfo) generated by fuzzing test to a high dimensional metric space first and then construct feature spaces based on their timestamp information. Lastly, we further leverage machine learning-based classification algorithms, including Logistic Regression, K-Nearest Neighbors, and Random Forest to categorize the impacts on performance and security attributes. The performance of the proposed approach has high accuracy, ranging from $ 93.4 \\% $ to $ 95.9 \\% $, in detecting the fuzzing impacts. In addition, the proof of concept could identify and prioritize real-time vulnerabilities on 5G infrastructures and critical applications in various verticals. ",
    "url": "https://arxiv.org/abs/2305.08226",
    "authors": [
      "Zhuzhu Wang",
      "Ying Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.08229",
    "title": "A Hybrid 3D Eddy Detection Technique Based on Sea Surface Height and  Velocity Field",
    "abstract": "Eddy detection is a critical task for ocean scientists to understand and analyze ocean circulation. In this paper, we introduce a hybrid eddy detection approach that combines sea surface height (SSH) and velocity fields with geometric criteria defining eddy behavior. Our approach searches for SSH minima and maxima, which oceanographers expect to find at the center of eddies. Geometric criteria are used to verify expected velocity field properties, such as net rotation and symmetry, by tracing velocity components along a circular path surrounding each eddy center. Progressive searches outward and into deeper layers yield each eddy's 3D region of influence. Isolation of each eddy structure from the dataset, using it's cylindrical footprint, facilitates visualization of internal eddy structures using horizontal velocity, vertical velocity, temperature and salinity. A quantitative comparison of Okubo-Weiss vorticity (OW) thresholding, the standard winding angle, and this new SSH-velocity hybrid methods of eddy detection as applied to the Red Sea dataset suggests that detection results are highly dependent on the choices of method, thresholds, and criteria. Our new SSH-velocity hybrid detection approach has the advantages of providing eddy structures with verified rotation properties, 3D visualization of the internal structure of physical properties, and rapid efficient estimations of eddy footprints without calculating streamlines. Our approach combines visualization of internal structure and tracking overall movement to support the study of the transport mechanisms key to understanding the interaction of nutrient distribution and ocean circulation. Our method is applied to three different datasets to showcase the generality of its application. ",
    "url": "https://arxiv.org/abs/2305.08229",
    "authors": [
      "Weiping Hua",
      "Karen Bemis",
      "Dujuan Kang",
      "Sedat Ozer",
      "Deborah Silver"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08233",
    "title": "Addressing Heterophily in Node Classification with Graph Echo State  Networks",
    "abstract": "Node classification tasks on graphs are addressed via fully-trained deep message-passing models that learn a hierarchy of node representations via multiple aggregations of a node's neighbourhood. While effective on graphs that exhibit a high ratio of intra-class edges, this approach poses challenges in the opposite case, i.e. heterophily, where nodes belonging to the same class are usually further apart. In graphs with a high degree of heterophily, the smoothed representations based on close neighbours computed by convolutional models are no longer effective. So far, architectural variations in message-passing models to reduce excessive smoothing or rewiring the input graph to improve longer-range message passing have been proposed. In this paper, we address the challenges of heterophilic graphs with Graph Echo State Network (GESN) for node classification. GESN is a reservoir computing model for graphs, where node embeddings are recursively computed by an untrained message-passing function. Our experiments show that reservoir models are able to achieve better or comparable accuracy with respect to most fully trained deep models that implement ad hoc variations in the architectural bias or perform rewiring as a preprocessing step on the input graph, with an improvement in terms of efficiency/accuracy trade-off. Furthermore, our analysis shows that GESN is able to effectively encode the structural relationships of a graph node, by showing a correlation between iterations of the recursive embedding function and the distribution of shortest paths in a graph. ",
    "url": "https://arxiv.org/abs/2305.08233",
    "authors": [
      "Alessio Micheli",
      "Domenico Tortorella"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.08247",
    "title": "A Fast and Robust Camera-IMU Online Calibration Method For Localization  System",
    "abstract": "Autonomous driving has spurred the development of sensor fusion techniques, which combine data from multiple sensors to improve system performance. In particular, localization system based on sensor fusion , such as Visual Simultaneous Localization and Mapping (VSLAM), is an important component in environment perception, and is the basis of decision-making and motion control for intelligent vehicles. The accuracy of extrinsic calibration parameters between camera and IMU has significant effect on the positioning precision when performing VSLAM system. Currently, existing methods are time-consuming using complex optimization methods and sensitive to noise and outliers due to off-calibration, which can negatively impact system performance. To address these problems, this paper presents a fast and robust camera-IMU online calibration method based space coordinate transformation constraints and SVD (singular Value Decomposition) tricks. First, constraint equations are constructed based on equality of rotation and transformation matrices between camera frames and IMU coordinates at different moments. Secondly, the external parameters of the camera-IMU are solved using quaternion transformation and SVD techniques. Finally, the proposed method is validated using ROS platform, where images from the camera and velocity, acceleration, and angular velocity data from the IMU are recorded in a ROS bag file. The results showed that the proposed method can achieve robust and reliable camera-IMU online calibration parameters results with less tune consuming and less uncertainty. ",
    "url": "https://arxiv.org/abs/2305.08247",
    "authors": [
      "Xiaowen Tao",
      "Pengxiang Meng",
      "Bing Zhu",
      "Jian Zhao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.08265",
    "title": "Vehicle Detection and Classification without Residual Calculation:  Accelerating HEVC Image Decoding with Random Perturbation Injection",
    "abstract": "In the field of video analytics, particularly traffic surveillance, there is a growing need for efficient and effective methods for processing and understanding video data. Traditional full video decoding techniques can be computationally intensive and time-consuming, leading researchers to explore alternative approaches in the compressed domain. This study introduces a novel random perturbation-based compressed domain method for reconstructing images from High Efficiency Video Coding (HEVC) bitstreams, specifically designed for traffic surveillance applications. To the best of our knowledge, our method is the first to propose substituting random perturbations for residual values, creating a condensed representation of the original image while retaining information relevant to video understanding tasks, particularly focusing on vehicle detection and classification as key use cases. By not using residual data, our proposed method significantly reduces the data needed in the image reconstruction process, allowing for more efficient storage and transmission of information. This is particularly important when considering the vast amount of video data involved in surveillance applications. Applied to the public BIT-Vehicle dataset, we demonstrate a significant increase in the reconstruction speed compared to the traditional full decoding approach, with our proposed method being approximately 56% faster than the pixel domain method. Additionally, we achieve a detection accuracy of 99.9%, on par with the pixel domain method, and a classification accuracy of 96.84%, only 0.98% lower than the pixel domain method. Furthermore, we showcase the significant reduction in data size, leading to more efficient storage and transmission. Our research establishes the potential of compressed domain methods in traffic surveillance applications, where speed and data size are critical factors. ",
    "url": "https://arxiv.org/abs/2305.08265",
    "authors": [
      "Muhammet Sebul Berato\u011flu",
      "Beh\u00e7et U\u011fur T\u00f6reyin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.08273",
    "title": "Decoupled Graph Neural Networks for Large Dynamic Graphs",
    "abstract": "Real-world graphs, such as social networks, financial transactions, and recommendation systems, often demonstrate dynamic behavior. This phenomenon, known as graph stream, involves the dynamic changes of nodes and the emergence and disappearance of edges. To effectively capture both the structural and temporal aspects of these dynamic graphs, dynamic graph neural networks have been developed. However, existing methods are usually tailored to process either continuous-time or discrete-time dynamic graphs, and cannot be generalized from one to the other. In this paper, we propose a decoupled graph neural network for large dynamic graphs, including a unified dynamic propagation that supports efficient computation for both continuous and discrete dynamic graphs. Since graph structure-related computations are only performed during the propagation process, the prediction process for the downstream task can be trained separately without expensive graph computations, and therefore any sequence model can be plugged-in and used. As a result, our algorithm achieves exceptional scalability and expressiveness. We evaluate our algorithm on seven real-world datasets of both continuous-time and discrete-time dynamic graphs. The experimental results demonstrate that our algorithm achieves state-of-the-art performance in both kinds of dynamic graphs. Most notably, the scalability of our algorithm is well illustrated by its successful application to large graphs with up to over a billion temporal edges and over a hundred million nodes. ",
    "url": "https://arxiv.org/abs/2305.08273",
    "authors": [
      "Yanping Zheng",
      "Zhewei Wei",
      "Jiajun Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.08277",
    "title": "Local Convergence of Gradient Descent-Ascent for Training Generative  Adversarial Networks",
    "abstract": "Generative Adversarial Networks (GANs) are a popular formulation to train generative models for complex high dimensional data. The standard method for training GANs involves a gradient descent-ascent (GDA) procedure on a minimax optimization problem. This procedure is hard to analyze in general due to the nonlinear nature of the dynamics. We study the local dynamics of GDA for training a GAN with a kernel-based discriminator. This convergence analysis is based on a linearization of a non-linear dynamical system that describes the GDA iterations, under an \\textit{isolated points model} assumption from [Becker et al. 2022]. Our analysis brings out the effect of the learning rates, regularization, and the bandwidth of the kernel discriminator, on the local convergence rate of GDA. Importantly, we show phase transitions that indicate when the system converges, oscillates, or diverges. We also provide numerical simulations that verify our claims. ",
    "url": "https://arxiv.org/abs/2305.08277",
    "authors": [
      "Evan Becker",
      "Parthe Pandit",
      "Sundeep Rangan",
      "Alyson K. Fletcher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.08296",
    "title": "Neural Face Rigging for Animating and Retargeting Facial Meshes in the  Wild",
    "abstract": "We propose an end-to-end deep-learning approach for automatic rigging and retargeting of 3D models of human faces in the wild. Our approach, called Neural Face Rigging (NFR), holds three key properties: (i) NFR's expression space maintains human-interpretable editing parameters for artistic controls; (ii) NFR is readily applicable to arbitrary facial meshes with different connectivity and expressions; (iii) NFR can encode and produce fine-grained details of complex expressions performed by arbitrary subjects. To the best of our knowledge, NFR is the first approach to provide realistic and controllable deformations of in-the-wild facial meshes, without the manual creation of blendshapes or correspondence. We design a deformation autoencoder and train it through a multi-dataset training scheme, which benefits from the unique advantages of two data sources: a linear 3DMM with interpretable control parameters as in FACS, and 4D captures of real faces with fine-grained details. Through various experiments, we show NFR's ability to automatically produce realistic and accurate facial deformations across a wide range of existing datasets as well as noisy facial scans in-the-wild, while providing artist-controlled, editable parameters. ",
    "url": "https://arxiv.org/abs/2305.08296",
    "authors": [
      "Dafei Qin",
      "Jun Saito",
      "Noam Aigerman",
      "Thibault Groueix",
      "Taku Komura"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.08302",
    "title": "t-RAIN: Robust generalization under weather-aliasing label shift attacks",
    "abstract": "In the classical supervised learning settings, classifiers are fit with the assumption of balanced label distributions and produce remarkable results on the same. In the real world, however, these assumptions often bend and in turn adversely impact model performance. Identifying bad learners in skewed target distributions is even more challenging. Thus achieving model robustness under these \"label shift\" settings is an important task in autonomous perception. In this paper, we analyze the impact of label shift on the task of multi-weather classification for autonomous vehicles. We use this information as a prior to better assess pedestrian detection in adverse weather. We model the classification performance as an indicator of robustness under 4 label shift scenarios and study the behavior of multiple classes of models. We propose t-RAIN a similarity mapping technique for synthetic data augmentation using large scale generative models and evaluate the performance on DAWN dataset. This mapping boosts model test accuracy by 2.1, 4.4, 1.9, 2.7 % in no-shift, fog, snow, dust shifts respectively. We present state-of-the-art pedestrian detection results on real and synthetic weather domains with best performing 82.69 AP (snow) and 62.31 AP (fog) respectively. ",
    "url": "https://arxiv.org/abs/2305.08302",
    "authors": [
      "Aboli Marathe",
      "Sanjana Prabhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.08310",
    "title": "Gradient-enhanced physics-informed neural networks based on transfer  learning for inverse problems of the variable coefficient differential  equations",
    "abstract": "We propose gradient-enhanced PINNs based on transfer learning (TL-gPINNs) for inverse problems of the function coefficient discovery in order to overcome deficiency of the discrete characterization of the PDE loss in neural networks and improve accuracy of function feature description, which offers a new angle of view for gPINNs. The TL-gPINN algorithm is applied to infer the unknown variable coefficients of various forms (the polynomial, trigonometric function, hyperbolic function and fractional polynomial) and multiple variable coefficients simultaneously with abundant soliton solutions for the well-known variable coefficient nonlinear Schr\\\"{o}odinger equation. Compared with the PINN and gPINN, TL-gPINN yields considerable improvement in accuracy. Moreover, our method leverages the advantage of the transfer learning technique, which can help to mitigate the problem of inefficiency caused by extra loss terms of the gradient. Numerical results fully demonstrate the effectiveness of the TL-gPINN method in significant accuracy enhancement, and it also outperforms gPINN in efficiency even when the training data was corrupted with different levels of noise or hyper-parameters of neural networks are arbitrarily changed. ",
    "url": "https://arxiv.org/abs/2305.08310",
    "authors": [
      "Shuning Lin",
      "Yong Chen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Pattern Formation and Solitons (nlin.PS)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2305.08317",
    "title": "By-Software Branch Prediction in Loops",
    "abstract": "Load-Dependent Branches (LDB) often do not exhibit regular patterns in their local or global history and thus are inherently hard to predict correctly by conventional branch predictors. We propose a software-to-hardware branch pre-resolution mechanism that allows software to pass branch outcomes to the processor frontend ahead of fetching the branch instruction. A compiler pass identifies the instruction chain leading to the branch (the branch backslice) and generates the pre-execute code that produces the branch outcomes ahead of the frontend observing them. The loop structure helps to unambiguously map the branch outcomes to their corresponding dynamic instances of the branch instruction. Our approach also allows for covering the loop iteration space selectively, with arbitrarily complex patterns. Our method for pre-execution enables important optimizations such as unrolling and vectorization, in order to substantially reduce the pre-execution overhead. Experimental results on select workloads from SPEC CPU 2017 and graph analytics workloads show up to 95% reduction of MPKI (21% on average), up to 39% speedup (7% on average), and up to 3x improvement on IPC (23% on average) compared to a core with TAGE-SC-L-64KB branch predictor. ",
    "url": "https://arxiv.org/abs/2305.08317",
    "authors": [
      "Maziar Goudarzi",
      "Reza Azimi",
      "Julian Humecki",
      "Faizaan Rehman",
      "Richard Zhang",
      "Chirag Sethi",
      "Tanishq Bomman",
      "Yuqi Yang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2305.08326",
    "title": "Learner-Centered Analysis in Educational Metaverse Environments:  Exploring Value Exchange Systems through Natural Interaction and Text Mining",
    "abstract": "This paper explores the potential developments of self-directed learning in the metaverse in response to Education 4.0 and the Fourth Industrial Revolution. It highlights the importance of education keeping up with technological advancements and adopting learner-centered approaches. Additionally, it focuses on exploring value exchange systems through natural interaction, text mining, and analysis. The metaverse concept extends beyond extended reality (XR) technologies, encompassing digital avatars and shared ecological value. The role of educators in exploring new technologies and leveraging text-mining techniques to enhance learning efficiency is emphasized. The metaverse is presented as a platform for value exchange, necessitating meaningful and valuable content to attract users. Integrating virtual and real-world experiences within the metaverse offers practical applications and contributes to its essence. This paper sheds light on the metaverse's potential to create a learner-centered educational environment and adapt to the evolving landscape of Education 4.0. Its findings, supported by text mining analysis, contribute to understanding the metaverse's role in shaping education in the Fourth Industrial Revolution. ",
    "url": "https://arxiv.org/abs/2305.08326",
    "authors": [
      "Yun-Cheng Tsai"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2305.08336",
    "title": "Inverse Rendering of Translucent Objects using Physical and Neural  Renderers",
    "abstract": "In this work, we propose an inverse rendering model that estimates 3D shape, spatially-varying reflectance, homogeneous subsurface scattering parameters, and an environment illumination jointly from only a pair of captured images of a translucent object. In order to solve the ambiguity problem of inverse rendering, we use a physically-based renderer and a neural renderer for scene reconstruction and material editing. Because two renderers are differentiable, we can compute a reconstruction loss to assist parameter estimation. To enhance the supervision of the proposed neural renderer, we also propose an augmented loss. In addition, we use a flash and no-flash image pair as the input. To supervise the training, we constructed a large-scale synthetic dataset of translucent objects, which consists of 117K scenes. Qualitative and quantitative results on both synthetic and real-world datasets demonstrated the effectiveness of the proposed model. ",
    "url": "https://arxiv.org/abs/2305.08336",
    "authors": [
      "Chenhao Li",
      "Trung Thanh Ngo",
      "Hajime Nagahara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08337",
    "title": "Neural Boltzmann Machines",
    "abstract": "Conditional generative models are capable of using contextual information as input to create new imaginative outputs. Conditional Restricted Boltzmann Machines (CRBMs) are one class of conditional generative models that have proven to be especially adept at modeling noisy discrete or continuous data, but the lack of expressivity in CRBMs have limited their widespread adoption. Here we introduce Neural Boltzmann Machines (NBMs) which generalize CRBMs by converting each of the CRBM parameters to their own neural networks that are allowed to be functions of the conditional inputs. NBMs are highly flexible conditional generative models that can be trained via stochastic gradient descent to approximately maximize the log-likelihood of the data. We demonstrate the utility of NBMs especially with normally distributed data which has historically caused problems for Gaussian-Bernoulli CRBMs. Code to reproduce our results can be found at https://github.com/unlearnai/neural-boltzmann-machines. ",
    "url": "https://arxiv.org/abs/2305.08337",
    "authors": [
      "Alex H. Lang",
      "Anton D. Loukianov",
      "Charles K. Fisher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.08344",
    "title": "Enhancing Label Sharing Efficiency in Complementary-Label Learning with  Label Augmentation",
    "abstract": "Complementary-label Learning (CLL) is a form of weakly supervised learning that trains an ordinary classifier using only complementary labels, which are the classes that certain instances do not belong to. While existing CLL studies typically use novel loss functions or training techniques to solve this problem, few studies focus on how complementary labels collectively provide information to train the ordinary classifier. In this paper, we fill the gap by analyzing the implicit sharing of complementary labels on nearby instances during training. Our analysis reveals that the efficiency of implicit label sharing is closely related to the performance of existing CLL models. Based on this analysis, we propose a novel technique that enhances the sharing efficiency via complementary-label augmentation, which explicitly propagates additional complementary labels to each instance. We carefully design the augmentation process to enrich the data with new and accurate complementary labels, which provide CLL models with fresh and valuable information to enhance the sharing efficiency. We then verify our proposed technique by conducting thorough experiments on both synthetic and real-world datasets. Our results confirm that complementary-label augmentation can systematically improve empirical performance over state-of-the-art CLL models. ",
    "url": "https://arxiv.org/abs/2305.08344",
    "authors": [
      "Wei-I Lin",
      "Gang Niu",
      "Hsuan-Tien Lin",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.08348",
    "title": "Coreference-aware Double-channel Attention Network for Multi-party  Dialogue Reading Comprehension",
    "abstract": "We tackle Multi-party Dialogue Reading Comprehension (abbr., MDRC). MDRC stands for an extractive reading comprehension task grounded on a batch of dialogues among multiple interlocutors. It is challenging due to the requirement of understanding cross-utterance contexts and relationships in a multi-turn multi-party conversation. Previous studies have made great efforts on the utterance profiling of a single interlocutor and graph-based interaction modeling. The corresponding solutions contribute to the answer-oriented reasoning on a series of well-organized and thread-aware conversational contexts. However, the current MDRC models still suffer from two bottlenecks. On the one hand, a pronoun like \"it\" most probably produces multi-skip reasoning throughout the utterances of different interlocutors. On the other hand, an MDRC encoder is potentially puzzled by fuzzy features, i.e., the mixture of inner linguistic features in utterances and external interactive features among utterances. To overcome the bottlenecks, we propose a coreference-aware attention modeling method to strengthen the reasoning ability. In addition, we construct a two-channel encoding network. It separately encodes utterance profiles and interactive relationships, so as to relieve the confusion among heterogeneous features. We experiment on the benchmark corpora Molweni and FriendsQA. Experimental results demonstrate that our approach yields substantial improvements on both corpora, compared to the fine-tuned BERT and ELECTRA baselines. The maximum performance gain is about 2.5\\% F1-score. Besides, our MDRC models outperform the state-of-the-art in most cases. ",
    "url": "https://arxiv.org/abs/2305.08348",
    "authors": [
      "Yanling Li",
      "Bowei Zou",
      "Yifan Fan",
      "Mengxing Dong",
      "Yu Hong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.08354",
    "title": "Decoding Chinese phonemes from intracortical brain signals with  hyperbolic-space neural representations",
    "abstract": "Speech brain-computer interfaces (BCIs), which translate brain signals into spoken words or sentences, have shown significant potential for high-performance BCI communication. Phonemes are the fundamental units of pronunciation in most languages. While existing speech BCIs have largely focused on English, where words contain diverse compositions of phonemes, Chinese Mandarin is a monosyllabic language, with words typically consisting of a consonant and a vowel. This feature makes it feasible to develop high-performance Mandarin speech BCIs by decoding phonemes directly from neural signals. This study aimed to decode spoken Mandarin phonemes using intracortical neural signals. We observed that phonemes with similar pronunciations were often represented by inseparable neural patterns, leading to confusion in phoneme decoding. This finding suggests that the neural representation of spoken phonemes has a hierarchical structure. To account for this, we proposed learning the neural representation of phoneme pronunciation in a hyperbolic space, where the hierarchical structure could be more naturally optimized. Experiments with intracortical neural signals from a Chinese participant showed that the proposed model learned discriminative and interpretable hierarchical phoneme representations from neural signals, significantly improving Chinese phoneme decoding performance and achieving state-of-the-art. The findings demonstrate the feasibility of constructing high-performance Chinese speech BCIs based on phoneme decoding. ",
    "url": "https://arxiv.org/abs/2305.08354",
    "authors": [
      "Xianhan Tan",
      "Junming Zhu",
      "Jianmin Zhang",
      "Yueming Wang",
      "Yu Qi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2305.08359",
    "title": "Horizon-free Reinforcement Learning in Adversarial Linear Mixture MDPs",
    "abstract": "Recent studies have shown that episodic reinforcement learning (RL) is no harder than bandits when the total reward is bounded by $1$, and proved regret bounds that have a polylogarithmic dependence on the planning horizon $H$. However, it remains an open question that if such results can be carried over to adversarial RL, where the reward is adversarially chosen at each episode. In this paper, we answer this question affirmatively by proposing the first horizon-free policy search algorithm. To tackle the challenges caused by exploration and adversarially chosen reward, our algorithm employs (1) a variance-uncertainty-aware weighted least square estimator for the transition kernel; and (2) an occupancy measure-based technique for the online search of a \\emph{stochastic} policy. We show that our algorithm achieves an $\\tilde{O}\\big((d+\\log (|\\mathcal{S}|^2 |\\mathcal{A}|))\\sqrt{K}\\big)$ regret with full-information feedback, where $d$ is the dimension of a known feature mapping linearly parametrizing the unknown transition kernel of the MDP, $K$ is the number of episodes, $|\\mathcal{S}|$ and $|\\mathcal{A}|$ are the cardinalities of the state and action spaces. We also provide hardness results and regret lower bounds to justify the near optimality of our algorithm and the unavoidability of $\\log|\\mathcal{S}|$ and $\\log|\\mathcal{A}|$ in the regret bound. ",
    "url": "https://arxiv.org/abs/2305.08359",
    "authors": [
      "Kaixuan Ji",
      "Qingyue Zhao",
      "Jiafan He",
      "Weitong Zhang",
      "Quanquan Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.08360",
    "title": "Improving ChatGPT Prompt for Code Generation",
    "abstract": "Automated code generation can be a powerful technique for software development, significantly reducing developers' efforts and time required to create new code by generating it automatically based on requirements. Recently, OpenAI's language model ChatGPT has emerged as a powerful tool for generating human-like responses to a wide range of textual inputs (i.e., prompts), including those related to code generation. However, the effectiveness of ChatGPT for code generation is not well understood, and the generation performance could be heavily influenced by the choice of prompt. To answer these questions, we conducted experiments using the CodeXGlue dataset to evaluate ChatGPT's capabilities for two code generation tasks, including text-to-code and code-to-code generation. We designed prompts by leveraging the chain-of-thought strategy with multi-step optimizations. Our results showed that by carefully designing prompts to guide ChatGPT, the generation performance can be improved substantially. We also analyzed the factors that influenced the prompt design and provided insights that could guide future research. ",
    "url": "https://arxiv.org/abs/2305.08360",
    "authors": [
      "Chao Liu",
      "Xuanlin Bao",
      "Hongyu Zhang",
      "Neng Zhang",
      "Haibo Hu",
      "Xiaohong Zhang",
      "Meng Yan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.08366",
    "title": "CLRerNet: Improving Confidence of Lane Detection with LaneIoU",
    "abstract": "Lane marker detection is a crucial component of the autonomous driving and driver assistance systems. Modern deep lane detection methods with row-based lane representation exhibit excellent performance on lane detection benchmarks. Through preliminary oracle experiments, we firstly disentangle the lane representation components to determine the direction of our approach. We show that correct lane positions are already among the predictions of an existing row-based detector, and the confidence scores that accurately represent intersection-over-union (IoU) with ground truths are the most beneficial. Based on the finding, we propose LaneIoU that better correlates with the metric, by taking the local lane angles into consideration. We develop a novel detector coined CLRerNet featuring LaneIoU for the target assignment cost and loss functions aiming at the improved quality of confidence scores. Through careful and fair benchmark including cross validation, we demonstrate that CLRerNet outperforms the state-of-the-art by a large margin - enjoying F1 score of 81.43% compared with 80.47% of the existing method on CULane, and 86.47% compared with 86.10% on CurveLanes. ",
    "url": "https://arxiv.org/abs/2305.08366",
    "authors": [
      "Hiroto Honda",
      "Yusuke Uchida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08386",
    "title": "PLIP: Language-Image Pre-training for Person Representation Learning",
    "abstract": "Pre-training has emerged as an effective technique for learning powerful person representations. Most existing methods have shown that pre-training on pure-vision large-scale datasets like ImageNet and LUPerson has achieved remarkable performance. However, solely relying on visual information, the absence of robust explicit indicators poses a challenge for these methods to learn discriminative person representations. Drawing inspiration from the intrinsic fine-grained attribute indicators of person descriptions, we explore introducing the language modality into person representation learning. To this end, we propose a novel language-image pre-training framework for person representation learning, termed PLIP. To explicitly build fine-grained cross-modal associations, we specifically design three pretext tasks, \\ie semantic-fused image colorization, visual-fused attributes prediction, and vision-language matching. In addition, due to the lack of an appropriate dataset, we present a large-scale person dataset named SYNTH-PEDES, where the Stylish Pedestrian Attributes-union Captioning method is proposed to synthesize diverse textual descriptions. We pre-train PLIP on SYNTH-PEDES and evaluate our model by spanning downstream tasks such as text-based Re-ID, image-based Re-ID, and person attribute recognition. Extensive experiments demonstrate that our model not only significantly improves existing methods on all these tasks, but also shows great ability in the few-shot and domain generalization settings. The code, dataset and weights will be released at~\\url{https://github.com/Zplusdragon/PLIP} ",
    "url": "https://arxiv.org/abs/2305.08386",
    "authors": [
      "Jialong Zuo",
      "Changqian Yu",
      "Nong Sang",
      "Changxin Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08388",
    "title": "A lower bound on the field size of convolutional codes with a maximum  distance profile and an improved construction",
    "abstract": "Convolutional codes with a maximum distance profile attain the largest possible column distances for the maximum number of time instants and thus have outstanding error-correcting capability especially for streaming applications. Explicit constructions of such codes are scarce in the literature. In particular, known constructions of convolutional codes with rate k/n and a maximum distance profile require a field of size at least exponential in n for general code parameters. At the same time, the only known lower bound on the field size is the trivial bound that is linear in n. In this paper, we show that a finite field of size $\\Omega_L(n^{L-1})$ is necessary for constructing convolutional codes with rate k/n and a maximum distance profile of length L. As a direct consequence, this rules out the possibility of constructing convolutional codes with a maximum distance profile of length L >= 3 over a finite field of size O(n). Additionally, we also present an explicit construction of convolutional code with rate k/n and a maximum profile of length L = 1 over a finite field of size $O(n^{\\min\\{k,n-k\\}})$, achieving a smaller field size than known constructions with the same profile length. ",
    "url": "https://arxiv.org/abs/2305.08388",
    "authors": [
      "Zitan Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2305.08404",
    "title": "Theoretical Analysis of Inductive Biases in Deep Convolutional Networks",
    "abstract": "In this paper, we study the inductive biases in convolutional neural networks (CNNs), which are believed to be vital drivers behind CNNs' exceptional performance on vision-like tasks. We first analyze the universality of CNNs, i.e., the ability to approximate continuous functions. We prove that a depth of $\\mathcal{O}(\\log d)$ is sufficient for achieving universality, where $d$ is the input dimension. This is a significant improvement over existing results that required a depth of $\\Omega(d)$. We also prove that learning sparse functions with CNNs needs only $\\tilde{\\mathcal{O}}(\\log^2d)$ samples, indicating that deep CNNs can efficiently capture long-range sparse correlations. Note that all these are achieved through a novel combination of increased network depth and the utilization of multichanneling and downsampling. Lastly, we study the inductive biases of weight sharing and locality through the lens of symmetry. To separate two biases, we introduce locally-connected networks (LCNs), which can be viewed as CNNs without weight sharing. Specifically, we compare the performance of CNNs, LCNs, and fully-connected networks (FCNs) on a simple regression task. We prove that LCNs require ${\\Omega}(d)$ samples while CNNs need only $\\tilde{\\mathcal{O}}(\\log^2d)$ samples, which highlights the cruciality of weight sharing. We also prove that FCNs require $\\Omega(d^2)$ samples while LCNs need only $\\tilde{\\mathcal{O}}(d)$ samples, demonstrating the importance of locality. These provable separations quantify the difference between the two biases, and our major observation behind is that weight sharing and locality break different symmetries in the learning process. ",
    "url": "https://arxiv.org/abs/2305.08404",
    "authors": [
      "Zihao Wang",
      "Lei Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.08415",
    "title": "Marsellus: A Heterogeneous RISC-V AI-IoT End-Node SoC with 2-to-8b DNN  Acceleration and 30%-Boost Adaptive Body Biasing",
    "abstract": "Emerging Artificial Intelligence-enabled Internet-of-Things (AI-IoT) System-on-a-Chip (SoC) for augmented reality, personalized healthcare, and nano-robotics need to run many diverse tasks within a power envelope of a few tens of mW over a wide range of operating conditions: compute-intensive but strongly quantized Deep Neural Network (DNN) inference, as well as signal processing and control requiring high-precision floating-point. We present Marsellus, an all-digital heterogeneous SoC for AI-IoT end-nodes fabricated in GlobalFoundries 22nm FDX that combines 1) a general-purpose cluster of 16 RISC-V Digital Signal Processing (DSP) cores attuned for the execution of a diverse range of workloads exploiting 4-bit and 2-bit arithmetic extensions (XpulpNN), combined with fused MAC&LOAD operations and floating-point support; 2) a 2-8bit Reconfigurable Binary Engine (RBE) to accelerate 3x3 and 1x1 (pointwise) convolutions in DNNs; 3) a set of On-Chip Monitoring (OCM) blocks connected to an Adaptive Body Biasing (ABB) generator and a hardware control loop, enabling on-the-fly adaptation of transistor threshold voltages. Marsellus achieves up to 180 Gop/s or 3.32 Top/s/W on 2-bit precision arithmetic in software, and up to 637 Gop/s or 12.4 Top/s/W on hardware-accelerated DNN layers. ",
    "url": "https://arxiv.org/abs/2305.08415",
    "authors": [
      "Francesco Conti",
      "Gianna Paulin",
      "Davide Rossi",
      "Alfio Di Mauro",
      "Georg Rutishauser",
      "Gianmarco Ottavi",
      "Manuel Eggimann",
      "Hayate Okuhara",
      "Luca Benini"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.08439",
    "title": "Exploiting Frequency Spectrum of Adversarial Images for General  Robustness",
    "abstract": "In recent years, there has been growing concern over the vulnerability of convolutional neural networks (CNNs) to image perturbations. However, achieving general robustness against different types of perturbations remains challenging, in which enhancing robustness to some perturbations (e.g., adversarial perturbations) may degrade others (e.g., common corruptions). In this paper, we demonstrate that adversarial training with an emphasis on phase components significantly improves model performance on clean, adversarial, and common corruption accuracies. We propose a frequency-based data augmentation method, Adversarial Amplitude Swap, that swaps the amplitude spectrum between clean and adversarial images to generate two novel training images: adversarial amplitude and adversarial phase images. These images act as substitutes for adversarial images and can be implemented in various adversarial training setups. Through extensive experiments, we demonstrate that our method enables the CNNs to gain general robustness against different types of perturbations and results in a uniform performance against all types of common corruptions. ",
    "url": "https://arxiv.org/abs/2305.08439",
    "authors": [
      "Chun Yang Tan",
      "Kazuhiko Kawamoto",
      "Hiroshi Kera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08457",
    "title": "MolHF: A Hierarchical Normalizing Flow for Molecular Graph Generation",
    "abstract": "Molecular de novo design is a critical yet challenging task in scientific fields, aiming to design novel molecular structures with desired property profiles. Significant progress has been made by resorting to generative models for graphs. However, limited attention is paid to hierarchical generative models, which can exploit the inherent hierarchical structure (with rich semantic information) of the molecular graphs and generate complex molecules of larger size that we shall demonstrate to be difficult for most existing models. The primary challenge to hierarchical generation is the non-differentiable issue caused by the generation of intermediate discrete coarsened graph structures. To sidestep this issue, we cast the tricky hierarchical generation problem over discrete spaces as the reverse process of hierarchical representation learning and propose MolHF, a new hierarchical flow-based model that generates molecular graphs in a coarse-to-fine manner. Specifically, MolHF first generates bonds through a multi-scale architecture, then generates atoms based on the coarsened graph structure at each scale. We demonstrate that MolHF achieves state-of-the-art performance in random generation and property optimization, implying its high capacity to model data distribution. Furthermore, MolHF is the first flow-based model that can be applied to model larger molecules (polymer) with more than 100 heavy atoms. The code and models are available at https://github.com/violet-sto/MolHF. ",
    "url": "https://arxiv.org/abs/2305.08457",
    "authors": [
      "Yiheng Zhu",
      "Zhenqiu Ouyang",
      "Ben Liao",
      "Jialu Wu",
      "Yixuan Wu",
      "Chang-Yu Hsieh",
      "Tingjun Hou",
      "Jian Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.08466",
    "title": "Nearly Optimal VC-Dimension and Pseudo-Dimension Bounds for Deep Neural  Network Derivatives",
    "abstract": "This paper addresses the problem of nearly optimal Vapnik--Chervonenkis dimension (VC-dimension) and pseudo-dimension estimations of the derivative functions of deep neural networks (DNNs). Two important applications of these estimations include: 1) Establishing a nearly tight approximation result of DNNs in the Sobolev space; 2) Characterizing the generalization error of machine learning methods with loss functions involving function derivatives. This theoretical investigation fills the gap of learning error estimations for a wide range of physics-informed machine learning models and applications including generative models, solving partial differential equations, operator learning, network compression, distillation, regularization, etc. ",
    "url": "https://arxiv.org/abs/2305.08466",
    "authors": [
      "Yahong Yang",
      "Haizhao Yang",
      "Yang Xiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2305.08473",
    "title": "Shared and Private Information Learning in Multimodal Sentiment Analysis  with Deep Modal Alignment and Self-supervised Multi-Task Learning",
    "abstract": "Designing an effective representation learning method for multimodal sentiment analysis tasks is a crucial research direction. The challenge lies in learning both shared and private information in a complete modal representation, which is difficult with uniform multimodal labels and a raw feature fusion approach. In this work, we propose a deep modal shared information learning module based on the covariance matrix to capture the shared information between modalities. Additionally, we use a label generation module based on a self-supervised learning strategy to capture the private information of the modalities. Our module is plug-and-play in multimodal tasks, and by changing the parameterization, it can adjust the information exchange relationship between the modes and learn the private or shared information between the specified modes. We also employ a multi-task learning strategy to help the model focus its attention on the modal differentiation training data. We provide a detailed formulation derivation and feasibility proof for the design of the deep modal shared information learning module. We conduct extensive experiments on three common multimodal sentiment analysis baseline datasets, and the experimental results validate the reliability of our model. Furthermore, we explore more combinatorial techniques for the use of the module. Our approach outperforms current state-of-the-art methods on most of the metrics of the three public datasets. ",
    "url": "https://arxiv.org/abs/2305.08473",
    "authors": [
      "Songning Lai",
      "Xifeng Hu",
      "Yulong Li",
      "Zhaoxia Ren",
      "Zhi Liu",
      "Danmin Miao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08495",
    "title": "Similarity-weighted Construction of Contextualized Commonsense Knowledge  Graphs for Knowledge-intense Argumentation Tasks",
    "abstract": "Arguments often do not make explicit how a conclusion follows from its premises. To compensate for this lack, we enrich arguments with structured background knowledge to support knowledge-intense argumentation tasks. We present a new unsupervised method for constructing Contextualized Commonsense Knowledge Graphs (CCKGs) that selects contextually relevant knowledge from large knowledge graphs (KGs) efficiently and at high quality. Our work goes beyond context-insensitive knowledge extraction heuristics by computing semantic similarity between KG triplets and textual arguments. Using these triplet similarities as weights, we extract contextualized knowledge paths that connect a conclusion to its premise, while maximizing similarity to the argument. We combine multiple paths into a CCKG that we optionally prune to reduce noise and raise precision. Intrinsic evaluation of the quality of our graphs shows that our method is effective for (re)constructing human explanation graphs. Manual evaluations in a large-scale knowledge selection setup confirm high recall and precision of implicit CSK in the CCKGs. Finally, we demonstrate the effectiveness of CCKGs in a knowledge-insensitive argument quality rating task, outperforming strong baselines and rivaling a GPT-3 based system. ",
    "url": "https://arxiv.org/abs/2305.08495",
    "authors": [
      "Moritz Plenz",
      "Juri Opitz",
      "Philipp Heinisch",
      "Philipp Cimiano",
      "Anette Frank"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2305.08504",
    "title": "FLARE: Detection and Mitigation of Concept Drift for Federated Learning  based IoT Deployments",
    "abstract": "Intelligent, large-scale IoT ecosystems have become possible due to recent advancements in sensing technologies, distributed learning, and low-power inference in embedded devices. In traditional cloud-centric approaches, raw data is transmitted to a central server for training and inference purposes. On the other hand, Federated Learning migrates both tasks closer to the edge nodes and endpoints. This allows for a significant reduction in data exchange while preserving the privacy of users. Trained models, though, may under-perform in dynamic environments due to changes in the data distribution, affecting the model's ability to infer accurately; this is referred to as concept drift. Such drift may also be adversarial in nature. Therefore, it is of paramount importance to detect such behaviours promptly. In order to simultaneously reduce communication traffic and maintain the integrity of inference models, we introduce FLARE, a novel lightweight dual-scheduler FL framework that conditionally transfers training data, and deploys models between edge and sensor endpoints based on observing the model's training behaviour and inference statistics, respectively. We show that FLARE can significantly reduce the amount of data exchanged between edge and sensor nodes compared to fixed-interval scheduling methods (over 5x reduction), is easily scalable to larger systems, and can successfully detect concept drift reactively with at least a 16x reduction in latency. ",
    "url": "https://arxiv.org/abs/2305.08504",
    "authors": [
      "Theo Chow",
      "Usman Raza",
      "Ioannis Mavromatis",
      "Aftab Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2305.08506",
    "title": "A Knowledge Graph Perspective on Supply Chain Resilience",
    "abstract": "Global crises and regulatory developments require increased supply chain transparency and resilience. Companies do not only need to react to a dynamic environment but have to act proactively and implement measures to prevent production delays and reduce risks in the supply chains. However, information about supply chains, especially at the deeper levels, is often intransparent and incomplete, making it difficult to obtain precise predictions about prospective risks. By connecting different data sources, we model the supply network as a knowledge graph and achieve transparency up to tier-3 suppliers. To predict missing information in the graph, we apply state-of-the-art knowledge graph completion methods and attain a mean reciprocal rank of 0.4377 with the best model. Further, we apply graph analysis algorithms to identify critical entities in the supply network, supporting supply chain managers in automated risk identification. ",
    "url": "https://arxiv.org/abs/2305.08506",
    "authors": [
      "Yushan Liu",
      "Bailan He",
      "Marcel Hildebrandt",
      "Maximilian Buchner",
      "Daniela Inzko",
      "Roger Wernert",
      "Emanuel Weigel",
      "Dagmar Beyer",
      "Martin Berbalk",
      "Volker Tresp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.08509",
    "title": "Component-aware anomaly detection framework for adjustable and logical  industrial visual inspection",
    "abstract": "Industrial visual inspection aims at detecting surface defects in products during the manufacturing process. Although existing anomaly detection models have shown great performance on many public benchmarks, their limited adjustability and ability to detect logical anomalies hinder their broader use in real-world settings. To this end, in this paper, we propose a novel component-aware anomaly detection framework (ComAD) which can simultaneously achieve adjustable and logical anomaly detection for industrial scenarios. Specifically, we propose to segment images into multiple components based on a lightweight and nearly training-free unsupervised semantic segmentation model. Then, we design an interpretable logical anomaly detection model through modeling the metrological features of each component and their relationships. Despite its simplicity, our framework achieves state-of-the-art performance on image-level logical anomaly detection. Meanwhile, segmenting a product image into multiple components provides a novel perspective for industrial visual inspection, demonstrating great potential in model customization, noise resistance, and anomaly classification. The code will be available at https://github.com/liutongkun/ComAD. ",
    "url": "https://arxiv.org/abs/2305.08509",
    "authors": [
      "Tongkun Liu",
      "Bing Li",
      "Xiao Du",
      "Bingke Jiang",
      "Xiao Jin",
      "Liuyi Jin",
      "Zhuo Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08514",
    "title": "Generative Adversarial Networks for Spatio-Spectral Compression of  Hyperspectral Images",
    "abstract": "Deep learning-based image compression methods have led to high rate-distortion performances compared to traditional codecs. Recently, Generative Adversarial Networks (GANs)-based compression models, e.g., High Fidelity Compression (HiFiC), have attracted great attention in the computer vision community. However, most of these works aim for spatial compression only and do not consider the spatio-spectral redundancies observed in hyperspectral images (HSIs). To address this problem, in this paper, we adapt the HiFiC spatial compression model to perform spatio-spectral compression of HSIs. To this end, we introduce two new models: i) HiFiC using Squeeze and Excitation (SE) blocks (denoted as HiFiC$_{SE}$); and ii) HiFiC with 3D convolutions (denoted as HiFiC$_{3D}$). We analyze the effectiveness of HiFiC$_{SE}$ and HiFiC$_{3D}$ in exploiting the spatio-spectral redundancies with channel attention and inter-dependency analysis. Experimental results show the efficacy of the proposed models in performing spatio-spectral compression and reconstruction at reduced bitrates and higher reconstruction quality when compared to JPEG 2000 and the standard HiFiC spatial compression model. The code of the proposed models is publicly available at https://git.tu-berlin.de/rsim/HSI-SSC . ",
    "url": "https://arxiv.org/abs/2305.08514",
    "authors": [
      "Akshara Preethy Byju",
      "Martin Hermann Paul Fuchs",
      "Alisa Walda",
      "Beg\u00fcm Demir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.08518",
    "title": "Beqi: Revitalize the Senegalese Wolof Language with a Robust Spelling  Corrector",
    "abstract": "The progress of Natural Language Processing (NLP), although fast in recent years, is not at the same pace for all languages. African languages in particular are still behind and lack automatic processing tools. Some of these tools are very important for the development of these languages but also have an important role in many NLP applications. This is particularly the case for automatic spell checkers. Several approaches have been studied to address this task and the one modeling spelling correction as a translation task from misspelled (noisy) text to well-spelled (correct) text shows promising results. However, this approach requires a parallel corpus of noisy data on the one hand and correct data on the other hand, whereas Wolof is a low-resource language and does not have such a corpus. In this paper, we present a way to address the constraint related to the lack of data by generating synthetic data and we present sequence-to-sequence models using Deep Learning for spelling correction in Wolof. We evaluated these models in three different scenarios depending on the subwording method applied to the data and showed that the latter had a significant impact on the performance of the models, which opens the way for future research in Wolof spelling correction. ",
    "url": "https://arxiv.org/abs/2305.08518",
    "authors": [
      "Derguene Mbaye",
      "Moussa Diallo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.08522",
    "title": "Cross-Modality Time-Variant Relation Learning for Generating Dynamic  Scene Graphs",
    "abstract": "Dynamic scene graphs generated from video clips could help enhance the semantic visual understanding in a wide range of challenging tasks such as environmental perception, autonomous navigation, and task planning of self-driving vehicles and mobile robots. In the process of temporal and spatial modeling during dynamic scene graph generation, it is particularly intractable to learn time-variant relations in dynamic scene graphs among frames. In this paper, we propose a Time-variant Relation-aware TRansformer (TR$^2$), which aims to model the temporal change of relations in dynamic scene graphs. Explicitly, we leverage the difference of text embeddings of prompted sentences about relation labels as the supervision signal for relations. In this way, cross-modality feature guidance is realized for the learning of time-variant relations. Implicitly, we design a relation feature fusion module with a transformer and an additional message token that describes the difference between adjacent frames. Extensive experiments on the Action Genome dataset prove that our TR$^2$ can effectively model the time-variant relations. TR$^2$ significantly outperforms previous state-of-the-art methods under two different settings by 2.1% and 2.6% respectively. ",
    "url": "https://arxiv.org/abs/2305.08522",
    "authors": [
      "Jingyi Wang",
      "Jinfa Huang",
      "Can Zhang",
      "Zhidong Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08528",
    "title": "NICOL: A Neuro-inspired Collaborative Semi-humanoid Robot that Bridges  Social Interaction and Reliable Manipulation",
    "abstract": "Robotic platforms that can efficiently collaborate with humans in physical tasks constitute a major goal in robotics. However, many existing robotic platforms are either designed for social interaction or industrial object manipulation tasks. The design of collaborative robots seldom emphasizes both their social interaction and physical collaboration abilities. To bridge this gap, we present the novel semi-humanoid NICOL, the Neuro-Inspired COLlaborator. NICOL is a large, newly designed, scaled-up version of its well-evaluated predecessor, the Neuro-Inspired COmpanion (NICO). While we adopt NICO's head and facial expression display, we extend its manipulation abilities in terms of precision, object size and workspace size. To introduce and evaluate NICOL, we first develop and extend different neural and hybrid neuro-genetic visuomotor approaches initially developed for the NICO to the larger NICOL and its more complex kinematics. Furthermore, we present a novel neuro-genetic approach that improves the grasp accuracy of the NICOL to over 99%, outperforming the state-of-the-art IK solvers KDL, TRACK-IK and BIO-IK. Furthermore, we introduce the social interaction capabilities of NICOL, including the auditory and visual capabilities, but also the face and emotion generation capabilities. Overall, this article presents for the first time the humanoid robot NICOL and, thereby, with the neuro-genetic approaches, contributes to the integration of social robotics and neural visuomotor learning for humanoid robots. ",
    "url": "https://arxiv.org/abs/2305.08528",
    "authors": [
      "Matthias Kerzel",
      "Philipp Allgeuer",
      "Erik Strahl",
      "Nicolas Frick",
      "Jan-Gerrit Habekost",
      "Manfred Eppe",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.08552",
    "title": "Curvature-Aware Training for Coordinate Networks",
    "abstract": "Coordinate networks are widely used in computer vision due to their ability to represent signals as compressed, continuous entities. However, training these networks with first-order optimizers can be slow, hindering their use in real-time applications. Recent works have opted for shallow voxel-based representations to achieve faster training, but this sacrifices memory efficiency. This work proposes a solution that leverages second-order optimization methods to significantly reduce training times for coordinate networks while maintaining their compressibility. Experiments demonstrate the effectiveness of this approach on various signal modalities, such as audio, images, videos, shape reconstruction, and neural radiance fields. ",
    "url": "https://arxiv.org/abs/2305.08552",
    "authors": [
      "Hemanth Saratchandran",
      "Shin-Fang Chng",
      "Sameera Ramasinghe",
      "Lachlan MacDonald",
      "Simon Lucey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08553",
    "title": "Distilling Knowledge for Short-to-Long Term Trajectory Prediction",
    "abstract": "Long-term trajectory forecasting is a challenging problem in the field of computer vision and machine learning. In this paper, we propose a new method dubbed Di-Long (\"Distillation for Long-Term trajectory\") for long-term trajectory forecasting, which is based on knowledge distillation. Our approach involves training a student network to solve the long-term trajectory forecasting problem, whereas the teacher network from which the knowledge is distilled has a longer observation, and solves a short-term trajectory prediction problem by regularizing the student's predictions. Specifically, we use a teacher model to generate plausible trajectories for a shorter time horizon, and then distill the knowledge from the teacher model to a student model that solves the problem for a much higher time horizon. Our experiments show that the proposed Di-Long approach is beneficial for long-term forecasting, and our model achieves state-of-the-art performance on the Intersection Drone Dataset (inD) and the Stanford Drone Dataset (SDD). ",
    "url": "https://arxiv.org/abs/2305.08553",
    "authors": [
      "Sourav Das",
      "Guglielmo Camporese",
      "Lamberto Ballan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.08558",
    "title": "Why Rumors Spread Fast in Social Networks, and How to Stop It",
    "abstract": "We study a rumor spreading model where individuals are connected via a network structure. Initially, only a small subset of the individuals are spreading a rumor. Each individual who is connected to a spreader, starts spreading the rumor with some probability as a function of their trust in the spreader, quantified by the Jaccard similarity index. Furthermore, the probability that a spreader diffuses the rumor decreases over time until they fully lose their interest and stop spreading. We focus on determining the graph parameters which govern the magnitude and pace that the rumor spreads in this model. We prove that for the rumor to spread to a sizable fraction of the individuals, the network needs to enjoy ``strong'' expansion properties and most nodes should be in ``well-connected'' communities. Both of these characteristics are, arguably, present in real-world social networks up to a certain degree, shedding light on the driving force behind the extremely fast spread of rumors in social networks. Furthermore, we formulate a large range of countermeasures to cease the spread of a rumor. We introduce four fundamental criteria which a countermeasure ideally should possess. We evaluate all the proposed countermeasures by conducting experiments on real-world social networks such as Facebook and Twitter. We conclude that our novel decentralized countermeasures (which are executed by the individuals) generally outperform the previously studied centralized ones (which need to be imposed by a third entity such as the government). ",
    "url": "https://arxiv.org/abs/2305.08558",
    "authors": [
      "Ahad N. Zehmakan",
      "Charlotte Out",
      "Sajjad Hesamipour Khelejan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2305.08562",
    "title": "FlooNoC: A Multi-Tbps Wide NoC for Heterogeneous AXI4 Traffic",
    "abstract": "Meeting the staggering bandwidth requirements of today's applications challenges the traditional narrow and serialized NoCs, which hit hard bounds on the maximum operating frequency. This paper proposes FlooNoC, an open-source, low-latency, fully AXI4-compatible NoC with wide physical channels for latency-tolerant high-bandwidth non-blocking transactions and decoupled latency-critical short messages. We demonstrate the feasibility of wide channels by integrating a 5x5 router and links within a 9-core compute cluster in 12 nm FinFet technology. Our NoC achieves a bandwidth of 629Gbps per link while running at only 1.23 GHz (at 0.19 pJ/B/hop), with just 10% area overhead post layout. ",
    "url": "https://arxiv.org/abs/2305.08562",
    "authors": [
      "Tim Fischer",
      "Michael Rogenmoser",
      "Matheus Cavalcante",
      "Frank K. G\u00fcrkaynak",
      "Luca Benini"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2305.08572",
    "title": "Estimating the Causal Effects of Natural Logic Features in Neural NLI  Models",
    "abstract": "Rigorous evaluation of the causal effects of semantic features on language model predictions can be hard to achieve for natural language reasoning problems. However, this is such a desirable form of analysis from both an interpretability and model evaluation perspective, that it is valuable to zone in on specific patterns of reasoning with enough structure and regularity to be able to identify and quantify systematic reasoning failures in widely-used models. In this vein, we pick a portion of the NLI task for which an explicit causal diagram can be systematically constructed: in particular, the case where across two sentences (the premise and hypothesis), two related words/terms occur in a shared context. In this work, we apply causal effect estimation strategies to measure the effect of context interventions (whose effect on the entailment label is mediated by the semantic monotonicity characteristic) and interventions on the inserted word-pair (whose effect on the entailment label is mediated by the relation between these words.). Following related work on causal analysis of NLP models in different settings, we adapt the methodology for the NLI task to construct comparative model profiles in terms of robustness to irrelevant changes and sensitivity to impactful changes. ",
    "url": "https://arxiv.org/abs/2305.08572",
    "authors": [
      "Julia Rozanova",
      "Marco Valentino",
      "Andre Freitas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.08573",
    "title": "A graph convolutional autoencoder approach to model order reduction for  parametrized PDEs",
    "abstract": "The present work proposes a framework for nonlinear model order reduction based on a Graph Convolutional Autoencoder (GCA-ROM). In the reduced order modeling (ROM) context, one is interested in obtaining real-time and many-query evaluations of parametric Partial Differential Equations (PDEs). Linear techniques such as Proper Orthogonal Decomposition (POD) and Greedy algorithms have been analyzed thoroughly, but they are more suitable when dealing with linear and affine models showing a fast decay of the Kolmogorov n-width. On one hand, the autoencoder architecture represents a nonlinear generalization of the POD compression procedure, allowing one to encode the main information in a latent set of variables while extracting their main features. On the other hand, Graph Neural Networks (GNNs) constitute a natural framework for studying PDE solutions defined on unstructured meshes. Here, we develop a non-intrusive and data-driven nonlinear reduction approach, exploiting GNNs to encode the reduced manifold and enable fast evaluations of parametrized PDEs. We show the capabilities of the methodology for several models: linear/nonlinear and scalar/vector problems with fast/slow decay in the physically and geometrically parametrized setting. The main properties of our approach consist of (i) high generalizability in the low-data regime even for complex regimes, (ii) physical compliance with general unstructured grids, and (iii) exploitation of pooling and un-pooling operations to learn from scattered data. ",
    "url": "https://arxiv.org/abs/2305.08573",
    "authors": [
      "Federico Pichi",
      "Beatriz Moya",
      "Jan S. Hesthaven"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.08583",
    "title": "Towards efficient multilayer network data management",
    "abstract": "Real-world multilayer networks can be very large and there can be multiple choices regarding what should be modeled as a layer. Therefore, there is a need for their effective storage and manipulation. Currently, multilayer network analysis software use different data structures and manipulation operators. We aim to categorize operators in order to assess which structures work best for certain operator classes and data features. In this work, we propose a preliminary taxonomy of layer and data manipulation operators. We also design and execute a benchmark of select software and operators to identify potential for optimization. ",
    "url": "https://arxiv.org/abs/2305.08583",
    "authors": [
      "Georgios Panayiotou",
      "Matteo Magnani",
      "Bruno Pinaud"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2305.08586",
    "title": "GCNSLIM: Graph Convolutional Network with Sparse Linear Methods for  E-government Service Recommendation",
    "abstract": "Graph Convolutional Networks have made significant strides in Collabora-tive Filtering recommendations. However, existing GCN-based CF methods are mainly based on matrix factorization and incorporate some optimization tech-niques to enhance performance, which are not enough to handle the complexities of diverse real-world recommendation scenarios. E-government service recommendation is a crucial area for recommendation re-search as it involves rigid aspects of people's lives. However, it has not received ad-equate attention in comparison to other recommendation scenarios like news and music recommendation. We empirically find that when existing GCN-based CF methods are directly applied to e-government service recommendation, they are limited by the MF framework and showing poor performance. This is because MF's equal treatment of users and items is not appropriate for scenarios where the number of users and items is unbalanced. In this work, we propose a new model, GCNSLIM, which combines GCN and sparse linear methods instead of combining GCN and MF to accommodate e-government service recommendation. In particular, GCNSLIM explicitly injects high-order collaborative signals obtained from multi-layer light graph convolutions into the item similarity matrix in the SLIM frame-work, effectively improving the recommendation accuracy. In addition, we propose two optimization measures, removing layer 0 embedding and adding nonlinear acti-vation, to further adapt to the characteristics of e-government service recommenda-tion scenarios. Furthermore, we propose a joint optimization mode to adapt to more diverse recommendation scenarios. We conduct extensive experiments on a real e-government service dataset and a common public dataset and demonstrate the ef-fectiveness of GCNSLIM in recommendation accuracy and operational performance. ",
    "url": "https://arxiv.org/abs/2305.08586",
    "authors": [
      "Lingyuan Kong",
      "Hao Ding",
      "Guangwei Hu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2305.08590",
    "title": "NIKI: Neural Inverse Kinematics with Invertible Neural Networks for 3D  Human Pose and Shape Estimation",
    "abstract": "With the progress of 3D human pose and shape estimation, state-of-the-art methods can either be robust to occlusions or obtain pixel-aligned accuracy in non-occlusion cases. However, they cannot obtain robustness and mesh-image alignment at the same time. In this work, we present NIKI (Neural Inverse Kinematics with Invertible Neural Network), which models bi-directional errors to improve the robustness to occlusions and obtain pixel-aligned accuracy. NIKI can learn from both the forward and inverse processes with invertible networks. In the inverse process, the model separates the error from the plausible 3D pose manifold for a robust 3D human pose estimation. In the forward process, we enforce the zero-error boundary conditions to improve the sensitivity to reliable joint positions for better mesh-image alignment. Furthermore, NIKI emulates the analytical inverse kinematics algorithms with the twist-and-swing decomposition for better interpretability. Experiments on standard and occlusion-specific benchmarks demonstrate the effectiveness of NIKI, where we exhibit robust and well-aligned results simultaneously. Code is available at https://github.com/Jeff-sjtu/NIKI ",
    "url": "https://arxiv.org/abs/2305.08590",
    "authors": [
      "Jiefeng Li",
      "Siyuan Bian",
      "Qi Liu",
      "Jiasheng Tang",
      "Fan Wang",
      "Cewu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08600",
    "title": "Evaluating Splitting Approaches in the Context of Student Dropout  Prediction",
    "abstract": "The prediction of academic dropout, with the aim of preventing it, is one of the current challenges of higher education institutions. Machine learning techniques are a great ally in this task. However, attention is needed in the way that academic data are used by such methods, so that it reflects the reality of the prediction problem under study and allows achieving good results. In this paper, we study strategies for splitting and using academic data in order to create training and testing sets. Through a conceptual analysis and experiments with data from a public higher education institution, we show that a random proportional data splitting, and even a simple temporal splitting are not suitable for dropout prediction. The study indicates that a temporal splitting combined with a time-based selection of the students' incremental academic histories leads to the best strategy for the problem in question. ",
    "url": "https://arxiv.org/abs/2305.08600",
    "authors": [
      "Bruno de M. Barros",
      "Hugo A. D. do Nascimento",
      "Raphael Guedes",
      "Sandro E. Monsueto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.08611",
    "title": "GeNAS: Neural Architecture Search with Better Generalization",
    "abstract": "Neural Architecture Search (NAS) aims to automatically excavate the optimal network architecture with superior test performance. Recent neural architecture search (NAS) approaches rely on validation loss or accuracy to find the superior network for the target data. In this paper, we investigate a new neural architecture search measure for excavating architectures with better generalization. We demonstrate that the flatness of the loss surface can be a promising proxy for predicting the generalization capability of neural network architectures. We evaluate our proposed method on various search spaces, showing similar or even better performance compared to the state-of-the-art NAS methods. Notably, the resultant architecture found by flatness measure generalizes robustly to various shifts in data distribution (e.g. ImageNet-V2,-A,-O), as well as various tasks such as object detection and semantic segmentation. Code is available at https://github.com/clovaai/GeNAS. ",
    "url": "https://arxiv.org/abs/2305.08611",
    "authors": [
      "Joonhyun Jeong",
      "Joonsang Yu",
      "Geondo Park",
      "Dongyoon Han",
      "Youngjoon Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08628",
    "title": "Non-Separable Multi-Dimensional Network Flows for Visual Computing",
    "abstract": "Flows in networks (or graphs) play a significant role in numerous computer vision tasks. The scalar-valued edges in these graphs often lead to a loss of information and thereby to limitations in terms of expressiveness. For example, oftentimes high-dimensional data (e.g. feature descriptors) are mapped to a single scalar value (e.g. the similarity between two feature descriptors). To overcome this limitation, we propose a novel formalism for non-separable multi-dimensional network flows. By doing so, we enable an automatic and adaptive feature selection strategy - since the flow is defined on a per-dimension basis, the maximizing flow automatically chooses the best matching feature dimensions. As a proof of concept, we apply our formalism to the multi-object tracking problem and demonstrate that our approach outperforms scalar formulations on the MOT16 benchmark in terms of robustness to noise. ",
    "url": "https://arxiv.org/abs/2305.08628",
    "authors": [
      "Viktoria Ehm",
      "Daniel Cremers",
      "Florian Bernard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08636",
    "title": "AdamR at SemEval-2023 Task 10: Solving the Class Imbalance Problem in  Sexism Detection with Ensemble Learning",
    "abstract": "The Explainable Detection of Online Sexism task presents the problem of explainable sexism detection through fine-grained categorisation of sexist cases with three subtasks. Our team experimented with different ways to combat class imbalance throughout the tasks using data augmentation and loss alteration techniques. We tackled the challenge by utilising ensembles of Transformer models trained on different datasets, which are tested to find the balance between performance and interpretability. This solution ranked us in the top 40\\% of teams for each of the tracks. ",
    "url": "https://arxiv.org/abs/2305.08636",
    "authors": [
      "Adam Rydelek",
      "Daryna Dementieva",
      "Georg Groh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.08654",
    "title": "Unsupervised Semantic Variation Prediction using the Distribution of  Sibling Embeddings",
    "abstract": "Languages are dynamic entities, where the meanings associated with words constantly change with time. Detecting the semantic variation of words is an important task for various NLP applications that must make time-sensitive predictions. Existing work on semantic variation prediction have predominantly focused on comparing some form of an averaged contextualised representation of a target word computed from a given corpus. However, some of the previously associated meanings of a target word can become obsolete over time (e.g. meaning of gay as happy), while novel usages of existing words are observed (e.g. meaning of cell as a mobile phone). We argue that mean representations alone cannot accurately capture such semantic variations and propose a method that uses the entire cohort of the contextualised embeddings of the target word, which we refer to as the sibling distribution. Experimental results on SemEval-2020 Task 1 benchmark dataset for semantic variation prediction show that our method outperforms prior work that consider only the mean embeddings, and is comparable to the current state-of-the-art. Moreover, a qualitative analysis shows that our method detects important semantic changes in words that are not captured by the existing methods. Source code is available at https://github.com/a1da4/svp-gauss . ",
    "url": "https://arxiv.org/abs/2305.08654",
    "authors": [
      "Taichi Aida",
      "Danushka Bollegala"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.08655",
    "title": "Unsupervised Sentence Representation Learning with Frequency-induced  Adversarial Tuning and Incomplete Sentence Filtering",
    "abstract": "Pre-trained Language Model (PLM) is nowadays the mainstay of Unsupervised Sentence Representation Learning (USRL). However, PLMs are sensitive to the frequency information of words from their pre-training corpora, resulting in anisotropic embedding space, where the embeddings of high-frequency words are clustered but those of low-frequency words disperse sparsely. This anisotropic phenomenon results in two problems of similarity bias and information bias, lowering the quality of sentence embeddings. To solve the problems, we fine-tune PLMs by leveraging the frequency information of words and propose a novel USRL framework, namely Sentence Representation Learning with Frequency-induced Adversarial tuning and Incomplete sentence filtering (SLT-FAI). We calculate the word frequencies over the pre-training corpora of PLMs and assign words thresholding frequency labels. With them, (1) we incorporate a similarity discriminator used to distinguish the embeddings of high-frequency and low-frequency words, and adversarially tune the PLM with it, enabling to achieve uniformly frequency-invariant embedding space; and (2) we propose a novel incomplete sentence detection task, where we incorporate an information discriminator to distinguish the embeddings of original sentences and incomplete sentences by randomly masking several low-frequency words, enabling to emphasize the more informative low-frequency words. Our SLT-FAI is a flexible and plug-and-play framework, and it can be integrated with existing USRL techniques. We evaluate SLT-FAI with various backbones on benchmark datasets. Empirical results indicate that SLT-FAI can be superior to the existing USRL baselines. Our code is released in \\url{https://github.com/wangbing1416/SLT-FAI}. ",
    "url": "https://arxiv.org/abs/2305.08655",
    "authors": [
      "Bing Wang",
      "Ximing Li",
      "Zhiyao Yang",
      "Yuanyuan Guan",
      "Jiayin Li",
      "Shengsheng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.08663",
    "title": "Leveraging Graph Embeddings for Opinion Leader Detection",
    "abstract": "Nowadays, social media plays an important role in many fields, such as the promotion of measures against major infectious diseases, merchandising, etc. In social media, some people are known as opinion leaders due to their strong ability to influence the opinions of others. The detection of opinion leaders has become an important task in social network analysis. Social networks are often represented in the form of graphs which allows a large number of graph analysis methods to be used for opinion leader detection. Some studies have attempted to apply graph representation learning for opinion leader detection and achieved good results. In this paper, we propose a model-agnostic framework that formulate the opinion leader detection problem as a ranking task of node embeddings. A variety of methods and datasets are chosen to analyze the performance of our framework both qualitatively and quantitatively. Based on the analysis results, we propose a strategy that combines opinion leaders detected by two different ranking algorithms to obtain a more comprehensive set of opinion leaders. And we analyze the temporal changes of the opinion leaders in one of the dynamic social networks. ",
    "url": "https://arxiv.org/abs/2305.08663",
    "authors": [
      "Yunming Hui",
      "Luuk Buijsman",
      "Mel Chekol",
      "Shihan Wang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.08673",
    "title": "aUToLights: A Robust Multi-Camera Traffic Light Detection and Tracking  System",
    "abstract": "Following four successful years in the SAE AutoDrive Challenge Series I, the University of Toronto is participating in the Series II competition to develop a Level 4 autonomous passenger vehicle capable of handling various urban driving scenarios by 2025. Accurate detection of traffic lights and correct identification of their states is essential for safe autonomous operation in cities. Herein, we describe our recently-redesigned traffic light perception system for autonomous vehicles like the University of Toronto's self-driving car, Artemis. Similar to most traffic light perception systems, we rely primarily on camera-based object detectors. We deploy the YOLOv5 detector for bounding box regression and traffic light classification across multiple cameras and fuse the observations. To improve robustness, we incorporate priors from high-definition semantic maps and perform state filtering using hidden Markov models. We demonstrate a multi-camera, real time-capable traffic light perception pipeline that handles complex situations including multiple visible intersections, traffic light variations, temporary occlusion, and flashing light states. To validate our system, we collected and annotated a varied dataset incorporating flashing states and a range of occlusion types. Our results show superior performance in challenging real-world scenarios compared to single-frame, single-camera object detection. ",
    "url": "https://arxiv.org/abs/2305.08673",
    "authors": [
      "Sean Wu",
      "Nicole Amenta",
      "Jiachen Zhou",
      "Sandro Papais",
      "Jonathan Kelly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.08676",
    "title": "An Ensemble Approach for Automated Theorem Proving Based on Efficient  Name Invariant Graph Neural Representations",
    "abstract": "Using reinforcement learning for automated theorem proving has recently received much attention. Current approaches use representations of logical statements that often rely on the names used in these statements and, as a result, the models are generally not transferable from one domain to another. The size of these representations and whether to include the whole theory or part of it are other important decisions that affect the performance of these approaches as well as their runtime efficiency. In this paper, we present NIAGRA; an ensemble Name InvAriant Graph RepresentAtion. NIAGRA addresses this problem by using 1) improved Graph Neural Networks for learning name-invariant formula representations that is tailored for their unique characteristics and 2) an efficient ensemble approach for automated theorem proving. Our experimental evaluation shows state-of-the-art performance on multiple datasets from different domains with improvements up to 10% compared to the best learning-based approaches. Furthermore, transfer learning experiments show that our approach significantly outperforms other learning-based approaches by up to 28%. ",
    "url": "https://arxiv.org/abs/2305.08676",
    "authors": [
      "Achille Fokoue",
      "Ibrahim Abdelaziz",
      "Maxwell Crouse",
      "Shajith Ikbal",
      "Akihiro Kishimoto",
      "Guilherme Lima",
      "Ndivhuwo Makondo",
      "Radu Marinescu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2305.08677",
    "title": "Natural Language Decomposition and Interpretation of Complex Utterances",
    "abstract": "Natural language interfaces often require supervised data to translate user requests into programs, database queries, or other structured intent representations. During data collection, it can be difficult to anticipate and formalize the full range of user needs -- for example, in a system designed to handle simple requests (like $\\textit{find my meetings tomorrow}$ or $\\textit{move my meeting with my manager to noon})$, users may also express more elaborate requests (like $\\textit{swap all my calls on Monday and Tuesday}$). We introduce an approach for equipping a simple language-to-code model to handle complex utterances via a process of hierarchical natural language decomposition. Our approach uses a pre-trained language model to decompose a complex utterance into a sequence of smaller natural language steps, then interprets each step using the language-to-code model. To test our approach, we collect and release DeCU -- a new NL-to-program benchmark to evaluate Decomposition of Complex Utterances. Experiments show that the proposed approach enables the interpretation of complex utterances with almost no complex training data, while outperforming standard few-shot prompting approaches. ",
    "url": "https://arxiv.org/abs/2305.08677",
    "authors": [
      "Harsh Jhamtani",
      "Hao Fang",
      "Patrick Xia",
      "Eran Levy",
      "Jacob Andreas",
      "Ben Van Durme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.08680",
    "title": "Efficient and Effective Tree-based and Neural Learning to Rank",
    "abstract": "This monograph takes a step towards promoting the study of efficiency in the era of neural information retrieval by offering a comprehensive survey of the literature on efficiency and effectiveness in ranking, and to a limited extent, retrieval. This monograph was inspired by the parallels that exist between the challenges in neural network-based ranking solutions and their predecessors, decision forest-based learning to rank models, as well as the connections between the solutions the literature to date has to offer. We believe that by understanding the fundamentals underpinning these algorithmic and data structure solutions for containing the contentious relationship between efficiency and effectiveness, one can better identify future directions and more efficiently determine the merits of ideas. We also present what we believe to be important research directions in the forefront of efficiency and effectiveness in retrieval and ranking. ",
    "url": "https://arxiv.org/abs/2305.08680",
    "authors": [
      "Sebastian Bruch",
      "Claudio Lucchese",
      "Franco Maria Nardini"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2305.08696",
    "title": "Scaling Limits of Quantum Repeater Networks",
    "abstract": "Quantum networks (QNs) are a promising platform for secure communications, enhanced sensing, and efficient distributed quantum computing. However, due to the fragile nature of quantum states, these networks face significant challenges in terms of scalability. In this paper, the scaling limits of quantum repeater networks (QRNs) are analyzed. The goal of this work is to maximize the overall length, or scalability of QRNs such that long-distance quantum communications is achieved while application-specific quality-of-service (QoS) requirements are satisfied. In particular, a novel joint optimization framework that aims at maximizing QRN scalability, while satisfying QoS constraints on the end-to-end fidelity and rate is proposed. The proposed approach optimizes the number of QRN repeater nodes, their separation distance, and the number of distillation rounds to be performed at both link and end-to-end levels. Extensive simulations are conducted to analyze the tradeoffs between QRN scalability, rate, and fidelity under gate and measurement errors. The obtained results characterize the QRN scaling limits for a given QoS requirement. The proposed approach offers a promising solution and design guidelines for future QRN deployments. ",
    "url": "https://arxiv.org/abs/2305.08696",
    "authors": [
      "Mahdi Chehimi",
      "Shahrooz Pouryousef",
      "Nitish K. Panigrahy",
      "Don Towsley",
      "Walid Saad"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2305.08698",
    "title": "Continual Multimodal Knowledge Graph Construction",
    "abstract": "Multimodal Knowledge Graph Construction (MMKC) refers to the process of creating a structured representation of entities and relationships through multiple modalities such as text, images, videos, etc. However, existing MMKC models have limitations in handling the introduction of new entities and relations due to the dynamic nature of the real world. Moreover, most state-of-the-art studies in MMKC only consider entity and relation extraction from text data while neglecting other multi-modal sources. Meanwhile, the current continual setting for knowledge graph construction only consider entity and relation extraction from text data while neglecting other multi-modal sources. Therefore, there arises the need to explore the challenge of continuous multimodal knowledge graph construction to address the phenomenon of catastrophic forgetting and ensure the retention of past knowledge extracted from different forms of data. This research focuses on investigating this complex topic by developing lifelong multimodal benchmark datasets. Based on the empirical findings that several state-of-the-art MMKC models, when trained on multimedia data, might unexpectedly underperform compared to those solely utilizing textual resources in a continual setting, we propose a Lifelong MultiModal Consistent Transformer Framework (LMC) for continuous multimodal knowledge graph construction. By combining the advantages of consistent KGC strategies within the context of continual learning, we achieve greater balance between stability and plasticity. Our experiments demonstrate the superior performance of our method over prevailing continual learning techniques or multimodal approaches in dynamic scenarios. Code and datasets can be found at https://github.com/zjunlp/ContinueMKGC. ",
    "url": "https://arxiv.org/abs/2305.08698",
    "authors": [
      "Xiang Chen",
      "Jintian Zhang",
      "Xiaohan Wang",
      "Tongtong Wu",
      "Shumin Deng",
      "Yongheng Wang",
      "Luo Si",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2305.08703",
    "title": "Schema-adaptable Knowledge Graph Construction",
    "abstract": "Conventional Knowledge Graph Construction (KGC) approaches typically follow the static information extraction paradigm with a closed set of pre-defined schema. As a result, such approaches fall short when applied to dynamic scenarios or domains, whereas a new type of knowledge emerges. This necessitates a system that can handle evolving schema automatically to extract information for KGC. To address this need, we propose a new task called schema-adaptable KGC, which aims to continually extract entity, relation, and event based on a dynamically changing schema graph without re-training. We first split and convert existing datasets based on three principles to build a benchmark, i.e., horizontal schema expansion, vertical schema expansion, and hybrid schema expansion; then investigate the schema-adaptable performance of several well-known approaches such as Text2Event, TANL, UIE and GPT-3. We further propose a simple yet effective baseline dubbed AdaKGC, which contains schema-enriched prefix instructor and schema-conditioned dynamic decoding to better handle evolving schema. Comprehensive experimental results illustrate that AdaKGC can outperform baselines but still have room for improvement. We hope the proposed work can deliver benefits to the community. Code and datasets will be available in https://github.com/zjunlp/AdaKGC. ",
    "url": "https://arxiv.org/abs/2305.08703",
    "authors": [
      "Hongbin Ye",
      "Honghao Gui",
      "Xin Xu",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.08714",
    "title": "Sensitivity and Robustness of Large Language Models to Prompt in  Japanese",
    "abstract": "Prompt Engineering has gained significant relevance in recent years, fueled by advancements in pre-trained and large language models. However, a critical issue has been identified within this domain: the lack of sensitivity and robustness of these models towards Prompt Templates, particularly in lesser-studied languages such as Japanese. This paper explores this issue through a comprehensive evaluation of several representative Large Language Models (LLMs) and a widely-utilized pre-trained model(PLM), T5. These models are scrutinized using a benchmark dataset in Japanese, with the aim to assess and analyze the performance of the current multilingual models in this context. Our experimental results reveal startling discrepancies. A simple modification in the sentence structure of the Prompt Template led to a drastic drop in the accuracy of GPT-4 from 49.21 to 25.44. This observation underscores the fact that even the highly performance GPT-4 model encounters significant stability issues when dealing with diverse Japanese prompt templates, rendering the consistency of the model's output results questionable. In light of these findings, we conclude by proposing potential research trajectories to further enhance the development and performance of Large Language Models in their current stage. ",
    "url": "https://arxiv.org/abs/2305.08714",
    "authors": [
      "Chengguang Gan",
      "Tatsunori Mori"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.08722",
    "title": "sataiops: Revamping the Full Life-Cycle Satellite Network Operations",
    "abstract": "Recently advanced non-geostationary (NGSO) satellite networks represented by large constellations and advanced payloads provide great promises for enabling high-quality Internet connectivity to any place on Earth. However, the traditional approach to satellite operations cannot address the new challenges in the NGSO satellite networks imposed by the significant increase in complexity, security, resilience, and environmental concerns. Therefore, a reliable, sustainable, and efficient approach is required for the entire life-cycle of satellite network operations. This paper provides a timely response to the new challenges and proposes a novel approach called ``SatAIOps'' as an overall solution. Through our discussion on the current challenges of the advanced satellite networks, SatAIOps and its functional modules in the entire life-cycle of satellites are proposed, with some example technologies given. SatAIOps provides a new perspective for addressing operational challenges with trustworthy and responsible AI technologies. It enables a new framework for evolving and collaborative efforts from research and industry communities. ",
    "url": "https://arxiv.org/abs/2305.08722",
    "authors": [
      "Peng Hu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.08741",
    "title": "Causal Data Integration",
    "abstract": "Causal inference is fundamental to empirical scientific discoveries in natural and social sciences; however, in the process of conducting causal inference, data management problems can lead to false discoveries. Two such problems are (i) not having all attributes required for analysis, and (ii) misidentifying which attributes are to be included in the analysis. Analysts often only have access to partial data, and they critically rely on (often unavailable or incomplete) domain knowledge to identify attributes to include for analysis, which is often given in the form of a causal DAG. We argue that data management techniques can surmount both of these challenges. In this work, we introduce the Causal Data Integration (CDI) problem, in which unobserved attributes are mined from external sources and a corresponding causal DAG is automatically built. We identify key challenges and research opportunities in designing a CDI system, and present a system architecture for solving the CDI problem. Our preliminary experimental results demonstrate that solving CDI is achievable and pave the way for future research. ",
    "url": "https://arxiv.org/abs/2305.08741",
    "authors": [
      "Brit Youngmann",
      "Michael Cafarella",
      "Babak Salimi",
      "Anna Zeng"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2305.08747",
    "title": "Automating privacy decisions -- where to draw the line?",
    "abstract": "Users are often overwhelmed by privacy decisions to manage their personal data, which can happen on the web, in mobile, and in IoT environments. These decisions can take various forms -- such as decisions for setting privacy permissions or privacy preferences, decisions responding to consent requests, or to intervene and ``reject'' processing of one's personal data --, and each can have different legal impacts. In all cases and for all types of decisions, scholars and industry have been proposing tools to better automate the process of privacy decisions at different levels, in order to enhance usability. We provide in this paper an overview of the main challenges raised by the automation of privacy decisions, together with a classification scheme of the existing and envisioned work and proposals addressing automation of privacy decisions. ",
    "url": "https://arxiv.org/abs/2305.08747",
    "authors": [
      "Victor Morel",
      "Simone Fischer-H\u00fcbner"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.08750",
    "title": "Fast and Attributed Change Detection on Dynamic Graphs with Density of  States",
    "abstract": "How can we detect traffic disturbances from international flight transportation logs or changes to collaboration dynamics in academic networks? These problems can be formulated as detecting anomalous change points in a dynamic graph. Current solutions do not scale well to large real-world graphs, lack robustness to large amounts of node additions/deletions, and overlook changes in node attributes. To address these limitations, we propose a novel spectral method: Scalable Change Point Detection (SCPD). SCPD generates an embedding for each graph snapshot by efficiently approximating the distribution of the Laplacian spectrum at each step. SCPD can also capture shifts in node attributes by tracking correlations between attributes and eigenvectors. Through extensive experiments using synthetic and real-world data, we show that SCPD (a) achieves state-of-the art performance, (b) is significantly faster than the state-of-the-art methods and can easily process millions of edges in a few CPU minutes, (c) can effectively tackle a large quantity of node attributes, additions or deletions and (d) discovers interesting events in large real-world graphs. The code is publicly available at https://github.com/shenyangHuang/SCPD.git ",
    "url": "https://arxiv.org/abs/2305.08750",
    "authors": [
      "Shenyang Huang",
      "Jacob Danovitch",
      "Guillaume Rabusseau",
      "Reihaneh Rabbany"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.08753",
    "title": "Neural Oscillators are Universal",
    "abstract": "Coupled oscillators are being increasingly used as the basis of machine learning (ML) architectures, for instance in sequence modeling, graph representation learning and in physical neural networks that are used in analog ML devices. We introduce an abstract class of neural oscillators that encompasses these architectures and prove that neural oscillators are universal, i.e, they can approximate any continuous and casual operator mapping between time-varying functions, to desired accuracy. This universality result provides theoretical justification for the use of oscillator based ML systems. The proof builds on a fundamental result of independent interest, which shows that a combination of forced harmonic oscillators with a nonlinear read-out suffices to approximate the underlying operators. ",
    "url": "https://arxiv.org/abs/2305.08753",
    "authors": [
      "Samuel Lanthaler",
      "T. Konstantin Rusch",
      "Siddhartha Mishra"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.08767",
    "title": "DA-LSTM: A Dynamic Drift-Adaptive Learning Framework for Interval Load  Forecasting with LSTM Networks",
    "abstract": "Load forecasting is a crucial topic in energy management systems (EMS) due to its vital role in optimizing energy scheduling and enabling more flexible and intelligent power grid systems. As a result, these systems allow power utility companies to respond promptly to demands in the electricity market. Deep learning (DL) models have been commonly employed in load forecasting problems supported by adaptation mechanisms to cope with the changing pattern of consumption by customers, known as concept drift. A drift magnitude threshold should be defined to design change detection methods to identify drifts. While the drift magnitude in load forecasting problems can vary significantly over time, existing literature often assumes a fixed drift magnitude threshold, which should be dynamically adjusted rather than fixed during system evolution. To address this gap, in this paper, we propose a dynamic drift-adaptive Long Short-Term Memory (DA-LSTM) framework that can improve the performance of load forecasting models without requiring a drift threshold setting. We integrate several strategies into the framework based on active and passive adaptation approaches. To evaluate DA-LSTM in real-life settings, we thoroughly analyze the proposed framework and deploy it in a real-world problem through a cloud-based environment. Efficiency is evaluated in terms of the prediction performance of each approach and computational cost. The experiments show performance improvements on multiple evaluation metrics achieved by our framework compared to baseline methods from the literature. Finally, we present a trade-off analysis between prediction performance and computational costs. ",
    "url": "https://arxiv.org/abs/2305.08767",
    "authors": [
      "Firas Bayram",
      "Phil Aupke",
      "Bestoun S. Ahmed",
      "Andreas Kassler",
      "Andreas Theocharis",
      "Jonas Forsman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.08776",
    "title": "Bridging the Domain Gap: Self-Supervised 3D Scene Understanding with  Foundation Models",
    "abstract": "Foundation models have made significant strides in 2D and language tasks such as image segmentation, object detection, and visual-language understanding. Nevertheless, their potential to enhance 3D scene representation learning remains largely untapped due to the domain gap. In this paper, we propose an innovative methodology Bridge3D to address this gap, pre-training 3D models using features, semantic masks, and captions sourced from foundation models. Specifically, our approach utilizes semantic masks from these models to guide the masking and reconstruction process in the masked autoencoder. This strategy enables the network to concentrate more on foreground objects, thereby enhancing 3D representation learning. Additionally, we bridge the 3D-text gap at the scene level by harnessing image captioning foundation models. To further facilitate knowledge distillation from well-learned 2D and text representations to the 3D model, we introduce a novel method that employs foundation models to generate highly accurate object-level masks and semantic text information at the object level. Our approach notably outshines state-of-the-art methods in 3D object detection and semantic segmentation tasks. For instance, on the ScanNet dataset, our method surpasses the previous state-of-the-art method, PiMAE, by a significant margin of 5.3%. ",
    "url": "https://arxiv.org/abs/2305.08776",
    "authors": [
      "Zhimin Chen",
      "Bing Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08779",
    "title": "TAA-GCN: A Temporally Aware Adaptive Graph Convolutional Network for Age  Estimation",
    "abstract": "This paper proposes a novel age estimation algorithm, the Temporally-Aware Adaptive Graph Convolutional Network (TAA-GCN). Using a new representation based on graphs, the TAA-GCN utilizes skeletal, posture, clothing, and facial information to enrich the feature set associated with various ages. Such a novel graph representation has several advantages: First, reduced sensitivity to facial expression and other appearance variances; Second, robustness to partial occlusion and non-frontal-planar viewpoint, which is commonplace in real-world applications such as video surveillance. The TAA-GCN employs two novel components, (1) the Temporal Memory Module (TMM) to compute temporal dependencies in age; (2) Adaptive Graph Convolutional Layer (AGCL) to refine the graphs and accommodate the variance in appearance. The TAA-GCN outperforms the state-of-the-art methods on four public benchmarks, UTKFace, MORPHII, CACD, and FG-NET. Moreover, the TAA-GCN showed reliability in different camera viewpoints and reduced quality images. ",
    "url": "https://arxiv.org/abs/2305.08779",
    "authors": [
      "Matthew Korban",
      "Peter Young",
      "Scott T. Acton"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08801",
    "title": "Black-Box Statistical Prediction of Lossy Compression Ratios for  Scientific Data",
    "abstract": "Lossy compressors are increasingly adopted in scientific research, tackling volumes of data from experiments or parallel numerical simulations and facilitating data storage and movement. In contrast with the notion of entropy in lossless compression, no theoretical or data-based quantification of lossy compressibility exists for scientific data. Users rely on trial and error to assess lossy compression performance. As a strong data-driven effort toward quantifying lossy compressibility of scientific datasets, we provide a statistical framework to predict compression ratios of lossy compressors. Our method is a two-step framework where (i) compressor-agnostic predictors are computed and (ii) statistical prediction models relying on these predictors are trained on observed compression ratios. Proposed predictors exploit spatial correlations and notions of entropy and lossyness via the quantized entropy. We study 8+ compressors on 6 scientific datasets and achieve a median percentage prediction error less than 12%, which is substantially smaller than that of other methods while achieving at least a 8.8x speedup for searching for a specific compression ratio and 7.8x speedup for determining the best compressor out of a collection. ",
    "url": "https://arxiv.org/abs/2305.08801",
    "authors": [
      "Robert Underwood",
      "Julie Bessac",
      "David Krasowska",
      "Jon C. Calhoun",
      "Sheng Di",
      "Franck Cappello"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.08804",
    "title": "Exploring In-Context Learning Capabilities of Foundation Models for  Generating Knowledge Graphs from Text",
    "abstract": "Knowledge graphs can represent information about the real-world using entities and their relations in a structured and semantically rich manner and they enable a variety of downstream applications such as question-answering, recommendation systems, semantic search, and advanced analytics. However, at the moment, building a knowledge graph involves a lot of manual effort and thus hinders their application in some situations and the automation of this process might benefit especially for small organizations. Automatically generating structured knowledge graphs from a large volume of natural language is still a challenging task and the research on sub-tasks such as named entity extraction, relation extraction, entity and relation linking, and knowledge graph construction aims to improve the state of the art of automatic construction and completion of knowledge graphs from text. The recent advancement of foundation models with billions of parameters trained in a self-supervised manner with large volumes of training data that can be adapted to a variety of downstream tasks has helped to demonstrate high performance on a large range of Natural Language Processing (NLP) tasks. In this context, one emerging paradigm is in-context learning where a language model is used as it is with a prompt that provides instructions and some examples to perform a task without changing the parameters of the model using traditional approaches such as fine-tuning. This way, no computing resources are needed for re-training/fine-tuning the models and the engineering effort is minimal. Thus, it would be beneficial to utilize such capabilities for generating knowledge graphs from text. ",
    "url": "https://arxiv.org/abs/2305.08804",
    "authors": [
      "Hanieh Khorashadizadeh",
      "Nandana Mihindukulasooriya",
      "Sanju Tiwari",
      "Jinghua Groppe",
      "Sven Groppe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.08807",
    "title": "Smoothness and monotonicity constraints for neural networks using ICEnet",
    "abstract": "Deep neural networks have become an important tool for use in actuarial tasks, due to the significant gains in accuracy provided by these techniques compared to traditional methods, but also due to the close connection of these models to the Generalized Linear Models (GLMs) currently used in industry. Whereas constraining GLM parameters relating to insurance risk factors to be smooth or exhibit monotonicity is trivial, methods to incorporate such constraints into deep neural networks have not yet been developed. This is a barrier for the adoption of neural networks in insurance practice since actuaries often impose these constraints for commercial or statistical reasons. In this work, we present a novel method for enforcing constraints within deep neural network models, and we show how these models can be trained. Moreover, we provide example applications using real-world datasets. We call our proposed method ICEnet to emphasize the close link of our proposal to the individual conditional expectation (ICE) model interpretability technique. ",
    "url": "https://arxiv.org/abs/2305.08807",
    "authors": [
      "Ronald Richman",
      "Mario W\u00fcthrich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.08808",
    "title": "GeoMAE: Masked Geometric Target Prediction for Self-supervised Point  Cloud Pre-Training",
    "abstract": "This paper tries to address a fundamental question in point cloud self-supervised learning: what is a good signal we should leverage to learn features from point clouds without annotations? To answer that, we introduce a point cloud representation learning framework, based on geometric feature reconstruction. In contrast to recent papers that directly adopt masked autoencoder (MAE) and only predict original coordinates or occupancy from masked point clouds, our method revisits differences between images and point clouds and identifies three self-supervised learning objectives peculiar to point clouds, namely centroid prediction, normal estimation, and curvature prediction. Combined with occupancy prediction, these four objectives yield an nontrivial self-supervised learning task and mutually facilitate models to better reason fine-grained geometry of point clouds. Our pipeline is conceptually simple and it consists of two major steps: first, it randomly masks out groups of points, followed by a Transformer-based point cloud encoder; second, a lightweight Transformer decoder predicts centroid, normal, and curvature for points in each voxel. We transfer the pre-trained Transformer encoder to a downstream peception model. On the nuScene Datset, our model achieves 3.38 mAP improvment for object detection, 2.1 mIoU gain for segmentation, and 1.7 AMOTA gain for multi-object tracking. We also conduct experiments on the Waymo Open Dataset and achieve significant performance improvements over baselines as well. ",
    "url": "https://arxiv.org/abs/2305.08808",
    "authors": [
      "Xiaoyu Tian",
      "Haoxi Ran",
      "Yue Wang",
      "Hang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08809",
    "title": "Interpretability at Scale: Identifying Causal Mechanisms in Alpaca",
    "abstract": "Obtaining human-interpretable explanations of large, general-purpose language models is an urgent goal for AI safety. However, it is just as important that our interpretability methods are faithful to the causal dynamics underlying model behavior and able to robustly generalize to unseen inputs. Distributed Alignment Search (DAS) is a powerful gradient descent method grounded in a theory of causal abstraction that uncovered perfect alignments between interpretable symbolic algorithms and small deep learning models fine-tuned for specific tasks. In the present paper, we scale DAS significantly by replacing the remaining brute-force search steps with learned parameters -- an approach we call DAS. This enables us to efficiently search for interpretable causal structure in large language models while they follow instructions. We apply DAS to the Alpaca model (7B parameters), which, off the shelf, solves a simple numerical reasoning problem. With DAS, we discover that Alpaca does this by implementing a causal model with two interpretable boolean variables. Furthermore, we find that the alignment of neural representations with these variables is robust to changes in inputs and instructions. These findings mark a first step toward deeply understanding the inner-workings of our largest and most widely deployed language models. ",
    "url": "https://arxiv.org/abs/2305.08809",
    "authors": [
      "Zhengxuan Wu",
      "Atticus Geiger",
      "Christopher Potts",
      "Noah D. Goodman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.08813",
    "title": "ReLU soothes the NTK condition number and accelerates optimization for  wide neural networks",
    "abstract": "Rectified linear unit (ReLU), as a non-linear activation function, is well known to improve the expressivity of neural networks such that any continuous function can be approximated to arbitrary precision by a sufficiently wide neural network. In this work, we present another interesting and important feature of ReLU activation function. We show that ReLU leads to: {\\it better separation} for similar data, and {\\it better conditioning} of neural tangent kernel (NTK), which are closely related. Comparing with linear neural networks, we show that a ReLU activated wide neural network at random initialization has a larger angle separation for similar data in the feature space of model gradient, and has a smaller condition number for NTK. Note that, for a linear neural network, the data separation and NTK condition number always remain the same as in the case of a linear model. Furthermore, we show that a deeper ReLU network (i.e., with more ReLU activation operations), has a smaller NTK condition number than a shallower one. Our results imply that ReLU activation, as well as the depth of ReLU network, helps improve the gradient descent convergence rate, which is closely related to the NTK condition number. ",
    "url": "https://arxiv.org/abs/2305.08813",
    "authors": [
      "Chaoyue Liu",
      "Like Hui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.08818",
    "title": "Sentence Level Curriculum Learning for Improved Neural Conversational  Models",
    "abstract": "Designing machine intelligence to converse with a human user necessarily requires an understanding of how humans participate in conversation, and thus conversation modeling is an important task in natural language processing. New breakthroughs in architecture and data gathering continue to push the performance of such conversational AI models. However, designs neglect the gradual buildup in sentence structure and complexity experienced by humans as we learn to communicate. During training, our model accepts one or more sentences as input and attempts to predict the next sentence in the conversation one word at a time, so our goal is to separate training into segments, with each segment's corpus comprised of longer sentence pairs than the previous one. This will mimic the desired \"buildup\" component of human learning. We begin with only \"short\" length sentence pairs, then only \"medium\" length pairs, and so on. A majority of our experiments were toward optimizing this technique, ensuring a proper representation of the technique's potential, since many of the details were new questions. Our segment-trained models were then able to achieve lower validation loss at the end of training than models trained with standard text preparation. This segmented training is straightforward to implement and our results provide a general direction for future research to implement and improve it. ",
    "url": "https://arxiv.org/abs/2305.08818",
    "authors": [
      "Sean Paulsen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.08840",
    "title": "Attacking Perceptual Similarity Metrics",
    "abstract": "Perceptual similarity metrics have progressively become more correlated with human judgments on perceptual similarity; however, despite recent advances, the addition of an imperceptible distortion can still compromise these metrics. In our study, we systematically examine the robustness of these metrics to imperceptible adversarial perturbations. Following the two-alternative forced-choice experimental design with two distorted images and one reference image, we perturb the distorted image closer to the reference via an adversarial attack until the metric flips its judgment. We first show that all metrics in our study are susceptible to perturbations generated via common adversarial attacks such as FGSM, PGD, and the One-pixel attack. Next, we attack the widely adopted LPIPS metric using spatial-transformation-based adversarial perturbations (stAdv) in a white-box setting to craft adversarial examples that can effectively transfer to other similarity metrics in a black-box setting. We also combine the spatial attack stAdv with PGD ($\\ell_\\infty$-bounded) attack to increase transferability and use these adversarial examples to benchmark the robustness of both traditional and recently developed metrics. Our benchmark provides a good starting point for discussion and further research on the robustness of metrics to imperceptible adversarial perturbations. ",
    "url": "https://arxiv.org/abs/2305.08840",
    "authors": [
      "Abhijay Ghildyal",
      "Feng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.08842",
    "title": "Straightening Out the Straight-Through Estimator: Overcoming  Optimization Challenges in Vector Quantized Networks",
    "abstract": "This work examines the challenges of training neural networks using vector quantization using straight-through estimation. We find that a primary cause of training instability is the discrepancy between the model embedding and the code-vector distribution. We identify the factors that contribute to this issue, including the codebook gradient sparsity and the asymmetric nature of the commitment loss, which leads to misaligned code-vector assignments. We propose to address this issue via affine re-parameterization of the code vectors. Additionally, we introduce an alternating optimization to reduce the gradient error introduced by the straight-through estimation. Moreover, we propose an improvement to the commitment loss to ensure better alignment between the codebook representation and the model embedding. These optimization methods improve the mathematical approximation of the straight-through estimation and, ultimately, the model performance. We demonstrate the effectiveness of our methods on several common model architectures, such as AlexNet, ResNet, and ViT, across various tasks, including image classification and generative modeling. ",
    "url": "https://arxiv.org/abs/2305.08842",
    "authors": [
      "Minyoung Huh",
      "Brian Cheung",
      "Pulkit Agrawal",
      "Phillip Isola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.08846",
    "title": "Privacy Auditing with One (1) Training Run",
    "abstract": "We propose a scheme for auditing differentially private machine learning systems with a single training run. This exploits the parallelism of being able to add or remove multiple training examples independently. We analyze this using the connection between differential privacy and statistical generalization, which avoids the cost of group privacy. Our auditing scheme requires minimal assumptions about the algorithm and can be applied in the black-box or white-box setting. ",
    "url": "https://arxiv.org/abs/2305.08846",
    "authors": [
      "Thomas Steinke",
      "Milad Nasr",
      "Matthew Jagielski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2305.07678",
    "title": "Exploring the Rate-Distortion-Complexity Optimization in Neural Image  Compression",
    "abstract": "Despite a short history, neural image codecs have been shown to surpass classical image codecs in terms of rate-distortion performance. However, most of them suffer from significantly longer decoding times, which hinders the practical applications of neural image codecs. This issue is especially pronounced when employing an effective yet time-consuming autoregressive context model since it would increase entropy decoding time by orders of magnitude. In this paper, unlike most previous works that pursue optimal RD performance while temporally overlooking the coding complexity, we make a systematical investigation on the rate-distortion-complexity (RDC) optimization in neural image compression. By quantifying the decoding complexity as a factor in the optimization goal, we are now able to precisely control the RDC trade-off and then demonstrate how the rate-distortion performance of neural image codecs could adapt to various complexity demands. Going beyond the investigation of RDC optimization, a variable-complexity neural codec is designed to leverage the spatial dependencies adaptively according to industrial demands, which supports fine-grained complexity adjustment by balancing the RDC tradeoff. By implementing this scheme in a powerful base model, we demonstrate the feasibility and flexibility of RDC optimization for neural image codecs. ",
    "url": "https://arxiv.org/abs/2305.07678",
    "authors": [
      "Yixin Gao",
      "Runsen Feng",
      "Zongyu Guo",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.07822",
    "title": "Deep Learning-based Prediction of Electrical Arrhythmia Circuits from  Cardiac Motion: An In-Silico Study",
    "abstract": "The heart's contraction is caused by electrical excitation which propagates through the heart muscle. It was recently shown that the electrical excitation can be computed from the contractile motion of a simulated piece of heart muscle tissue using deep learning. In cardiac electrophysiology, a primary diagnostic goal is to identify electrical triggers or drivers of heart rhythm disorders. However, using electrical mapping techniques, it is currently impossible to map the three-dimensional morphology of the electrical waves throughout the entire heart muscle, especially during ventricular arrhythmias. Therefore, the approach to calculate or predict electrical excitation from the hearts motion could be a promising alternative diagnostic approach. Here, we demonstrate in computer simulations that it is possible to predict three-dimensional electrical wave dynamics from ventricular deformation mechanics using deep learning. We performed thousands of simulations of electromechanical activation dynamics in ventricular geometries and used the data to train a neural network which subsequently predicts the three-dimensional electrical wave pattern that caused the deformation. We demonstrate that, next to focal wave patterns, even complicated three-dimensional electrical wave patterns can be reconstructed, even if the network has never seen the particular arrhythmia. We show that the deep learning model has the ability to generalize by training it on data generated with the smoothed particle hydrodynamics (SPH) method and subsequently applying it to data generated with the finite element method (FEM). Predictions can be performed in the presence of scars and with significant heterogeneity. Our results suggest that, deep neural networks could be used to calculate intramural action potential wave patterns from imaging data of the motion of the heart muscle. ",
    "url": "https://arxiv.org/abs/2305.07822",
    "authors": [
      "Jan Lebert",
      "Daniel Deng",
      "Lei Fan",
      "Lik Chuan Lee",
      "Jan Christoph"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Biological Physics (physics.bio-ph)"
    ]
  },
  {
    "id": "arXiv:2305.07971",
    "title": "Tight and fast generalization error bound of graph embedding in metric  space",
    "abstract": "Recent studies have experimentally shown that we can achieve in non-Euclidean metric space effective and efficient graph embedding, which aims to obtain the vertices' representations reflecting the graph's structure in the metric space. Specifically, graph embedding in hyperbolic space has experimentally succeeded in embedding graphs with hierarchical-tree structure, e.g., data in natural languages, social networks, and knowledge bases. However, recent theoretical analyses have shown a much higher upper bound on non-Euclidean graph embedding's generalization error than Euclidean one's, where a high generalization error indicates that the incompleteness and noise in the data can significantly damage learning performance. It implies that the existing bound cannot guarantee the success of graph embedding in non-Euclidean metric space in a practical training data size, which can prevent non-Euclidean graph embedding's application in real problems. This paper provides a novel upper bound of graph embedding's generalization error by evaluating the local Rademacher complexity of the model as a function set of the distances of representation couples. Our bound clarifies that the performance of graph embedding in non-Euclidean metric space, including hyperbolic space, is better than the existing upper bounds suggest. Specifically, our new upper bound is polynomial in the metric space's geometric radius $R$ and can be $O(\\frac{1}{S})$ at the fastest, where $S$ is the training data size. Our bound is significantly tighter and faster than the existing one, which can be exponential to $R$ and $O(\\frac{1}{\\sqrt{S}})$ at the fastest. Specific calculations on example cases show that graph embedding in non-Euclidean metric space can outperform that in Euclidean space with much smaller training data than the existing bound has suggested. ",
    "url": "https://arxiv.org/abs/2305.07971",
    "authors": [
      "Atsushi Suzuki",
      "Atsushi Nitanda",
      "Taiji Suzuki",
      "Jing Wang",
      "Feng Tian",
      "Kenji Yamanishi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.08159",
    "title": "Altered Topological Properties of Functional Brain Network Associated  with Alzheimer's Disease",
    "abstract": "Functional Magnetic Resonance Imaging (fMRI) is commonly utilized to study human brain activity, including abnormal functional properties related to neurodegenerative diseases. This study aims to investigate the differences in the topological properties of functional brain networks between individuals with Alzheimer's Disease (AD) and normal controls. A total of 590 subjects, consisting of 175 with AD dementia and 415 age-, gender-, and handedness-matched controls, were included. The topological properties of the brain network were quantified using graph-theory-based analyses. The results indicate abnormal network integration and segregation in the AD group. These findings enhance our understanding of AD pathophysiology from a functional brain network structure perspective and may aid in identifying AD biomarkers. We provided more information to asist the validation of this study at https://github.com/YongchengYAO/AD-FunctionalBrainNetwork. ",
    "url": "https://arxiv.org/abs/2305.08159",
    "authors": [
      "Yongcheng Yao"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.08316",
    "title": "SemiGNN-PPI: Self-Ensembling Multi-Graph Neural Network for Efficient  and Generalizable Protein-Protein Interaction Prediction",
    "abstract": "Protein-protein interactions (PPIs) are crucial in various biological processes and their study has significant implications for drug development and disease diagnosis. Existing deep learning methods suffer from significant performance degradation under complex real-world scenarios due to various factors, e.g., label scarcity and domain shift. In this paper, we propose a self-ensembling multigraph neural network (SemiGNN-PPI) that can effectively predict PPIs while being both efficient and generalizable. In SemiGNN-PPI, we not only model the protein correlations but explore the label dependencies by constructing and processing multiple graphs from the perspectives of both features and labels in the graph learning process. We further marry GNN with Mean Teacher to effectively leverage unlabeled graph-structured PPI data for self-ensemble graph learning. We also design multiple graph consistency constraints to align the student and teacher graphs in the feature embedding space, enabling the student model to better learn from the teacher model by incorporating more relationships. Extensive experiments on PPI datasets of different scales with different evaluation settings demonstrate that SemiGNN-PPI outperforms state-of-the-art PPI prediction methods, particularly in challenging scenarios such as training with limited annotations and testing on unseen data. ",
    "url": "https://arxiv.org/abs/2305.08316",
    "authors": [
      "Ziyuan Zhao",
      "Peisheng Qian",
      "Xulei Yang",
      "Zeng Zeng",
      "Cuntai Guan",
      "Wai Leong Tam",
      "Xiaoli Li"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.08459",
    "title": "Introduction to dynamical mean-field theory of generic random neural  networks",
    "abstract": "Dynamical mean-field theory is a powerful physics tool used to analyze the typical behavior of neural networks, where neurons can be recurrently connected, or multiple layers of neurons can be stacked. However, it is not easy for beginners to access the essence of this tool and the underlying physics. Here, we give a pedagogical introduction of this method in a particular example of generic random neural networks, where neurons are randomly and fully connected by correlated synapses and therefore the network exhibits rich emergent collective dynamics. We also review related past and recent important works applying this tool. In addition, a physically transparent and alternative method, namely the dynamical cavity method, is also introduced to derive exactly the same results. The numerical implementation of solving the integro-differential mean-field equations is also detailed, with an illustration of exploring the fluctuation dissipation theorem. ",
    "url": "https://arxiv.org/abs/2305.08459",
    "authors": [
      "Wenxuan Zou",
      "Haiping Huang"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2305.08544",
    "title": "Quantum Neural Network for Quantum Neural Computing",
    "abstract": "Neural networks have achieved impressive breakthroughs in both industry and academia. How to effectively develop neural networks on quantum computing devices is a challenging open problem. Here, we propose a new quantum neural network model for quantum neural computing using (classically-controlled) single-qubit operations and measurements on real-world quantum systems with naturally occurring environment-induced decoherence, which greatly reduces the difficulties of physical implementations. Our model circumvents the problem that the state-space size grows exponentially with the number of neurons, thereby greatly reducing memory requirements and allowing for fast optimization with traditional optimization algorithms. We benchmark our model for handwritten digit recognition and other nonlinear classification tasks. The results show that our model has an amazing nonlinear classification ability and robustness to noise. Furthermore, our model allows quantum computing to be applied in a wider context and inspires the earlier development of a quantum neural computer than standard quantum computers. ",
    "url": "https://arxiv.org/abs/2305.08544",
    "authors": [
      "Min-Gang Zhou",
      "Zhi-Ping Liu",
      "Hua-Lei Yin",
      "Chen-Long Li",
      "Tong-Kai Xu",
      "Zeng-Bing Chen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.08740",
    "title": "Temporal and Heterogeneous Graph Neural Network for Financial Time  Series Prediction",
    "abstract": "The price movement prediction of stock market has been a classical yet challenging problem, with the attention of both economists and computer scientists. In recent years, graph neural network has significantly improved the prediction performance by employing deep learning on company relations. However, existing relation graphs are usually constructed by handcraft human labeling or nature language processing, which are suffering from heavy resource requirement and low accuracy. Besides, they cannot effectively response to the dynamic changes in relation graphs. Therefore, in this paper, we propose a temporal and heterogeneous graph neural network-based (THGNN) approach to learn the dynamic relations among price movements in financial time series. In particular, we first generate the company relation graph for each trading day according to their historic price. Then we leverage a transformer encoder to encode the price movement information into temporal representations. Afterward, we propose a heterogeneous graph attention network to jointly optimize the embeddings of the financial time series data by transformer encoder and infer the probability of target movements. Finally, we conduct extensive experiments on the stock market in the United States and China. The results demonstrate the effectiveness and superior performance of our proposed methods compared with state-of-the-art baselines. Moreover, we also deploy the proposed THGNN in a real-world quantitative algorithm trading system, the accumulated portfolio return obtained by our method significantly outperforms other baselines. ",
    "url": "https://arxiv.org/abs/2305.08740",
    "authors": [
      "Sheng Xiang",
      "Dawei Cheng",
      "Chencheng Shang",
      "Ying Zhang",
      "Yuqi Liang"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Portfolio Management (q-fin.PM)"
    ]
  },
  {
    "id": "arXiv:2305.08744",
    "title": "Integrating Uncertainty into Neural Network-based Speech Enhancement",
    "abstract": "Supervised masking approaches in the time-frequency domain aim to employ deep neural networks to estimate a multiplicative mask to extract clean speech. This leads to a single estimate for each input without any guarantees or measures of reliability. In this paper, we study the benefits of modeling uncertainty in clean speech estimation. Prediction uncertainty is typically categorized into aleatoric uncertainty and epistemic uncertainty. The former refers to inherent randomness in data, while the latter describes uncertainty in the model parameters. In this work, we propose a framework to jointly model aleatoric and epistemic uncertainties in neural network-based speech enhancement. The proposed approach captures aleatoric uncertainty by estimating the statistical moments of the speech posterior distribution and explicitly incorporates the uncertainty estimate to further improve clean speech estimation. For epistemic uncertainty, we investigate two Bayesian deep learning approaches: Monte Carlo dropout and Deep ensembles to quantify the uncertainty of the neural network parameters. Our analyses show that the proposed framework promotes capturing practical and reliable uncertainty, while combining different sources of uncertainties yields more reliable predictive uncertainty estimates. Furthermore, we demonstrate the benefits of modeling uncertainty on speech enhancement performance by evaluating the framework on different datasets, exhibiting notable improvement over comparable models that fail to account for uncertainty. ",
    "url": "https://arxiv.org/abs/2305.08744",
    "authors": [
      "Huajian Fang",
      "Dennis Becker",
      "Stefan Wermter",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.08791",
    "title": "Fair Information Spread on Social Networks with Community Structure",
    "abstract": "Information spread through social networks is ubiquitous. Influence maximiza- tion (IM) algorithms aim to identify individuals who will generate the greatest spread through the social network if provided with information, and have been largely devel- oped with marketing in mind. In social networks with community structure, which are very common, IM algorithms focused solely on maximizing spread may yield signifi- cant disparities in information coverage between communities, which is problematic in settings such as public health messaging. While some IM algorithms aim to remedy disparity in information coverage using node attributes, none use the empirical com- munity structure within the network itself, which may be beneficial since communities directly affect the spread of information. Further, the use of empirical network struc- ture allows us to leverage community detection techniques, making it possible to run fair-aware algorithms when there are no relevant node attributes available, or when node attributes do not accurately capture network community structure. In contrast to other fair IM algorithms, this work relies on fitting a model to the social network which is then used to determine a seed allocation strategy for optimal fair information spread. We develop an algorithm to determine optimal seed allocations for expected fair coverage, defined through maximum entropy, provide some theoretical guarantees under appropriate conditions, and demonstrate its empirical accuracy on both simu- lated and real networks. Because this algorithm relies on a fitted network model and not on the network directly, it is well-suited for partially observed and noisy social networks. ",
    "url": "https://arxiv.org/abs/2305.08791",
    "authors": [
      "Octavio Mesner",
      "Elizaveta Levina",
      "Ji Zhu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.08849",
    "title": "Learning on Manifolds: Universal Approximations Properties using  Geometric Controllability Conditions for Neural ODEs",
    "abstract": "In numerous robotics and mechanical engineering applications, among others, data is often constrained on smooth manifolds due to the presence of rotational degrees of freedom. Common datadriven and learning-based methods such as neural ordinary differential equations (ODEs), however, typically fail to satisfy these manifold constraints and perform poorly for these applications. To address this shortcoming, in this paper we study a class of neural ordinary differential equations that, by design, leave a given manifold invariant, and characterize their properties by leveraging the controllability properties of control affine systems. In particular, using a result due to Agrachev and Caponigro on approximating diffeomorphisms with flows of feedback control systems, we show that any map that can be represented as the flow of a manifold-constrained dynamical system can also be approximated using the flow of manifold-constrained neural ODE, whenever a certain controllability condition is satisfied. Additionally, we show that this universal approximation property holds when the neural ODE has limited width in each layer, thus leveraging the depth of network instead for approximation. We verify our theoretical findings using numerical experiments on PyTorch for the manifolds S2 and the 3-dimensional orthogonal group SO(3), which are model manifolds for mechanical systems such as spacecrafts and satellites. We also compare the performance of the manifold invariant neural ODE with classical neural ODEs that ignore the manifold invariant properties and show the superiority of our approach in terms of accuracy and sample complexity. ",
    "url": "https://arxiv.org/abs/2305.08849",
    "authors": [
      "Karthik Elamvazhuthi",
      "Xuechen Zhang",
      "Samet Oymak",
      "Fabio Pasqualetti"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2002.11064",
    "title": "Pricing ASICs for Cryptocurrency Mining",
    "abstract": " Comments: 31 pages, 6 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2002.11064",
    "authors": [
      "Aviv Yaish",
      "Aviv Zohar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2006.05691",
    "title": "On Low Rank Directed Acyclic Graphs and Causal Structure Learning",
    "abstract": " Comments: This paper has been accepted by the IEEE Transactions on Neural Networks and Learning Systems ",
    "url": "https://arxiv.org/abs/2006.05691",
    "authors": [
      "Zhuangyan Fang",
      "Shengyu Zhu",
      "Jiji Zhang",
      "Yue Liu",
      "Zhitang Chen",
      "Yangbo He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2102.12227",
    "title": "Multi-Task Attentive Residual Networks for Argument Mining",
    "abstract": " Comments: 16 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2102.12227",
    "authors": [
      "Andrea Galassi",
      "Marco Lippi",
      "Paolo Torroni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2103.09803",
    "title": "Adjacency Graphs of Polyhedral Surfaces",
    "abstract": " Comments: The conference version of this paper appeared in Proc. SoCG 2021 ",
    "url": "https://arxiv.org/abs/2103.09803",
    "authors": [
      "Elena Arseneva",
      "Linda Kleist",
      "Boris Klemz",
      "Maarten L\u00f6ffler",
      "Andr\u00e9 Schulz",
      "Birgit Vogtenhuber",
      "Alexander Wolff"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2107.02378",
    "title": "Learning an Explicit Hyperparameter Prediction Function Conditioned on  Tasks",
    "abstract": " Comments: 74 pages ",
    "url": "https://arxiv.org/abs/2107.02378",
    "authors": [
      "Jun Shu",
      "Deyu Meng",
      "Zongben Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.02757",
    "title": "Generalized splines on graphs with two labels and polynomial splines on  cycles",
    "abstract": " Comments: 39 pages, 7 figures; v2: Added Section 5 on quotient splines and homogenization. Many improvements to the exposition, especially in Section 6 ",
    "url": "https://arxiv.org/abs/2108.02757",
    "authors": [
      "Portia Anderson",
      "Jacob P. Matherne",
      "Julianna Tymoczko"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Commutative Algebra (math.AC)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2109.03958",
    "title": "TrAISformer-A generative transformer for AIS trajectory prediction",
    "abstract": " Title: TrAISformer-A generative transformer for AIS trajectory prediction ",
    "url": "https://arxiv.org/abs/2109.03958",
    "authors": [
      "Duong Nguyen",
      "Ronan Fablet"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.01694",
    "title": "On the Existence of the Adversarial Bayes Classifier (Extended Version)",
    "abstract": " Comments: 27 pages, 3 figures. Corrects 2 errors in the paper \"On the Existence of the Adversarial Bayes Classifier\" published in NeurIPS ",
    "url": "https://arxiv.org/abs/2112.01694",
    "authors": [
      "Pranjal Awasthi",
      "Natalie S. Frank",
      "Mehryar Mohri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.11989",
    "title": "Existence and Estimation of Critical Batch Size for Training Generative  Adversarial Networks with Two Time-Scale Update Rule",
    "abstract": " Comments: Accepted at the 40th International Conference on Machine Learning (ICML 2023) ",
    "url": "https://arxiv.org/abs/2201.11989",
    "authors": [
      "Naoki Sato",
      "Hideaki Iiduka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2203.00948",
    "title": "CD-GAN: a robust fusion-based generative adversarial network for  unsupervised remote sensing change detection with heterogeneous sensors",
    "abstract": " Title: CD-GAN: a robust fusion-based generative adversarial network for  unsupervised remote sensing change detection with heterogeneous sensors ",
    "url": "https://arxiv.org/abs/2203.00948",
    "authors": [
      "Jin-Ju Wang",
      "Nicolas Dobigeon",
      "Marie Chabert",
      "Ding-Cheng Wang",
      "Ting-Zhu Huang",
      "Jie Huang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.03382",
    "title": "Self-supervised Implicit Glyph Attention for Text Recognition",
    "abstract": " Comments: CVPR2023 ",
    "url": "https://arxiv.org/abs/2203.03382",
    "authors": [
      "Tongkun Guan",
      "Chaochen Gu",
      "Jingzheng Tu",
      "Xue Yang",
      "Qi Feng",
      "Yudi Zhao",
      "Xiaokang Yang",
      "Wei Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.16965",
    "title": "PADA: Pruning Assisted Domain Adaptation for Self-Supervised Speech  Representations",
    "abstract": " Comments: Accepted to IEEE SLT 2022 ",
    "url": "https://arxiv.org/abs/2203.16965",
    "authors": [
      "Lodagala V S V Durga Prasad",
      "Sreyan Ghosh",
      "S. Umesh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.08465",
    "title": "Intelligent Spatial Interpolation-based Frost Prediction Methodology  using Artificial Neural Networks with Limited Local Data",
    "abstract": " Comments: 31 pages, 16 figures ",
    "url": "https://arxiv.org/abs/2204.08465",
    "authors": [
      "Ian Zhou",
      "Justin Lipman",
      "Mehran Abolhasan",
      "Negin Shariati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.10038",
    "title": "On the location of chromatic zeros of series-parallel graphs",
    "abstract": " Comments: Small changes based on referee comments. Accepted for publication in the Electronic Journal of Combinatorics ",
    "url": "https://arxiv.org/abs/2204.10038",
    "authors": [
      "Ferenc Bencs",
      "Jeroen Huijben",
      "Guus Regts"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2206.01290",
    "title": "Points2NeRF: Generating Neural Radiance Fields from 3D point cloud",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2003.08934 by other authors ",
    "url": "https://arxiv.org/abs/2206.01290",
    "authors": [
      "D. Zimny",
      "T. Trzci\u0144ski",
      "P. Spurek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.12498",
    "title": "Optimal and Robust Category-level Perception: Object Pose and Shape  Estimation from 2D and 3D Semantic Keypoints",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2104.08383 ",
    "url": "https://arxiv.org/abs/2206.12498",
    "authors": [
      "Jingnan Shi",
      "Heng Yang",
      "Luca Carlone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2207.00414",
    "title": "Artificial Intelligence Techniques for Next-Generation Mega Satellite  Networks",
    "abstract": " Title: Artificial Intelligence Techniques for Next-Generation Mega Satellite  Networks ",
    "url": "https://arxiv.org/abs/2207.00414",
    "authors": [
      "Bassel Al Homssi",
      "Kosta Dakic",
      "Ke Wang",
      "Tansu Alpcan",
      "Ben Allen",
      "Sithamparanathan Kandeepan",
      "Akram Al-Hourani",
      "Walid Saad"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.00574",
    "title": "Embedding phylogenetic trees in networks of low treewidth",
    "abstract": " Title: Embedding phylogenetic trees in networks of low treewidth ",
    "url": "https://arxiv.org/abs/2207.00574",
    "authors": [
      "Leo van Iersel",
      "Mark Jones",
      "Mathias Weller"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2207.01105",
    "title": "Scalable Polar Code Construction for Successive Cancellation List  Decoding: A Graph Neural Network-Based Approach",
    "abstract": " Comments: 33 pages, 11 figures, submitted to IEEE Transactions on Communications ",
    "url": "https://arxiv.org/abs/2207.01105",
    "authors": [
      "Yun Liao",
      "Seyyed Ali Hashemi",
      "Hengjie Yang",
      "John M. Cioffi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.03820",
    "title": "Deep Learning for Anomaly Detection in Log Data: A Survey",
    "abstract": " Title: Deep Learning for Anomaly Detection in Log Data: A Survey ",
    "url": "https://arxiv.org/abs/2207.03820",
    "authors": [
      "Max Landauer",
      "Sebastian Onder",
      "Florian Skopik",
      "Markus Wurzenberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.06874",
    "title": "Kernelization for Graph Packing Problems via Rainbow Matching",
    "abstract": " Comments: Accepted to SODA 2023 ",
    "url": "https://arxiv.org/abs/2207.06874",
    "authors": [
      "St\u00e9phane Bessy",
      "Marin Bougeret",
      "Dimitrios M. Thilikos",
      "Sebastian Wiederrecht"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2208.08085",
    "title": "Detection and Mitigation of Byzantine Attacks in Distributed Training",
    "abstract": " Comments: 21 pages, 17 figures, 6 tables. The material in this work appeared in part at arXiv:2108.02416 which has been published at the 2022 IEEE International Symposium on Information Theory ",
    "url": "https://arxiv.org/abs/2208.08085",
    "authors": [
      "Konstantinos Konstantinidis",
      "Namrata Vaswani",
      "Aditya Ramamoorthy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2208.08769",
    "title": "Memory and Capacity of Graph Embedding Methods",
    "abstract": " Comments: 23 Pages, 2 Figures ",
    "url": "https://arxiv.org/abs/2208.08769",
    "authors": [
      "Frank Qiu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.10917",
    "title": "Graph Embeddings via Tensor Products and Approximately Orthonormal Codes",
    "abstract": " Comments: 54 pages, 3 figures. arxiv admin note: substantial text overlap with arXiv:2208.08769 ",
    "url": "https://arxiv.org/abs/2208.10917",
    "authors": [
      "Frank Qiu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.03511",
    "title": "A Secure and Efficient Multi-Object Grasping Detection Approach for  Robotic Arms",
    "abstract": " Title: A Secure and Efficient Multi-Object Grasping Detection Approach for  Robotic Arms ",
    "url": "https://arxiv.org/abs/2209.03511",
    "authors": [
      "Hui Wang",
      "Jieren Cheng",
      "Yichen Xu",
      "Sirui Ni",
      "Zaijia Yang",
      "Jiangpeng Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.08391",
    "title": "Distributionally Robust RRT with Risk Allocation",
    "abstract": " Title: Distributionally Robust RRT with Risk Allocation ",
    "url": "https://arxiv.org/abs/2209.08391",
    "authors": [
      "Kajsa Ekenberg",
      "Venkatraman Renganathan",
      "Bj\u00f6rn Olofsson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2209.09178",
    "title": "ViT-DD: Multi-Task Vision Transformer for Semi-Supervised Driver  Distraction Detection",
    "abstract": " Comments: Accepted at the 2023 IEEE Intelligent Vehicles Symposium (IV) ",
    "url": "https://arxiv.org/abs/2209.09178",
    "authors": [
      "Yunsheng Ma",
      "Ziran Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.11661",
    "title": "Exact conservation laws for neural network integrators of dynamical  systems",
    "abstract": " Comments: 24 pages, 16 figures; to appear in Journal of Computational Physics ",
    "url": "https://arxiv.org/abs/2209.11661",
    "authors": [
      "Eike Hermann M\u00fcller"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2209.13940",
    "title": "Revamping Multilingual Agreement Bidirectionally via Switched  Back-translation for Multilingual Neural Machine Translation",
    "abstract": " Title: Revamping Multilingual Agreement Bidirectionally via Switched  Back-translation for Multilingual Neural Machine Translation ",
    "url": "https://arxiv.org/abs/2209.13940",
    "authors": [
      "Hongyuan Lu",
      "Haoyang Huang",
      "Shuming Ma",
      "Dongdong Zhang",
      "Furu Wei",
      "Wai Lam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2209.15315",
    "title": "FusionRetro: Molecule Representation Fusion via In-context Reactions for  Retrosynthetic Planning",
    "abstract": " Comments: Accepted by ICML 2023 ",
    "url": "https://arxiv.org/abs/2209.15315",
    "authors": [
      "Songtao Liu",
      "Zhengkai Tu",
      "Minkai Xu",
      "Zuobai Zhang",
      "Lu Lin",
      "Rex Ying",
      "Jian Tang",
      "Peilin Zhao",
      "Dinghao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2210.02592",
    "title": "CCC-wav2vec 2.0: Clustering aided Cross Contrastive Self-supervised  learning of speech representations",
    "abstract": " Comments: Accepted to IEEE SLT 2022 ",
    "url": "https://arxiv.org/abs/2210.02592",
    "authors": [
      "Vasista Sai Lodagala",
      "Sreyan Ghosh",
      "S. Umesh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.09167",
    "title": "How do we get there? Evaluating transformer neural networks as cognitive  models for English past tense inflection",
    "abstract": " Comments: AACL-IJCNLP 2022 camera-ready ",
    "url": "https://arxiv.org/abs/2210.09167",
    "authors": [
      "Xiaomeng Ma",
      "Lingyu Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12871",
    "title": "Tighter Abstract Queries in Neural Network Verification",
    "abstract": " Title: Tighter Abstract Queries in Neural Network Verification ",
    "url": "https://arxiv.org/abs/2210.12871",
    "authors": [
      "Elazar Cohen",
      "Yizhak Yisrael Elboher",
      "Clark Barrett",
      "Guy Katz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.13088",
    "title": "Your Router is My Prober: Measuring IPv6 Networks via ICMP Rate Limiting  Side Channels",
    "abstract": " Title: Your Router is My Prober: Measuring IPv6 Networks via ICMP Rate Limiting  Side Channels ",
    "url": "https://arxiv.org/abs/2210.13088",
    "authors": [
      "Long Pan",
      "Jiahai Yang",
      "Lin He",
      "Zhiliang Wang",
      "Leyao Nie",
      "Guanglei Song",
      "Yaozhong Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.14571",
    "title": "Towards the Detection of Diffusion Model Deepfakes",
    "abstract": " Comments: 27 pages, 25 figures ",
    "url": "https://arxiv.org/abs/2210.14571",
    "authors": [
      "Jonas Ricker",
      "Simon Damm",
      "Thorsten Holz",
      "Asja Fischer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.08804",
    "title": "Analysis and Detectability of Offline Data Poisoning Attacks on Linear  Dynamical Systems",
    "abstract": " Title: Analysis and Detectability of Offline Data Poisoning Attacks on Linear  Dynamical Systems ",
    "url": "https://arxiv.org/abs/2211.08804",
    "authors": [
      "Alessio Russo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.10381",
    "title": "Environmental Sensor Placement with Convolutional Gaussian Neural  Processes",
    "abstract": " Comments: Accepted in Environmental Data Science (Climate Informatics 2023 Special Issue) ",
    "url": "https://arxiv.org/abs/2211.10381",
    "authors": [
      "Tom R. Andersson",
      "Wessel P. Bruinsma",
      "Stratis Markou",
      "James Requeima",
      "Alejandro Coca-Castro",
      "Anna Vaughan",
      "Anna-Louise Ellis",
      "Matthew A. Lazzara",
      "Dani Jones",
      "J. Scott Hosking",
      "Richard E. Turner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11571",
    "title": "SLLEN: Semantic-aware Low-light Image Enhancement Network",
    "abstract": " Title: SLLEN: Semantic-aware Low-light Image Enhancement Network ",
    "url": "https://arxiv.org/abs/2211.11571",
    "authors": [
      "Mingye Ju",
      "Chuheng Chen",
      "Charles A. Guo",
      "Jinshan Pan",
      "Jinhui Tang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.16006",
    "title": "Lie Group Forced Variational Integrator Networks for Learning and  Control of Robot Systems",
    "abstract": " Comments: 24 pages ",
    "url": "https://arxiv.org/abs/2211.16006",
    "authors": [
      "Valentin Duruisseaux",
      "Thai Duong",
      "Melvin Leok",
      "Nikolay Atanasov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2211.16865",
    "title": "Logic and Commonsense-Guided Temporal Knowledge Graph Completion",
    "abstract": " Comments: The full version of a long paper accepted to AAAI 2023 ",
    "url": "https://arxiv.org/abs/2211.16865",
    "authors": [
      "Guanglin Niu",
      "Bo Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.00893",
    "title": "Compositional Learning of Dynamical System Models Using Port-Hamiltonian  Neural Networks",
    "abstract": " Comments: Paper accepted for publication at L4DC 2023 ",
    "url": "https://arxiv.org/abs/2212.00893",
    "authors": [
      "Cyrus Neary",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.02804",
    "title": "MUS-CDB: Mixed Uncertainty Sampling with Class Distribution Balancing  for Active Annotation in Aerial Object Detection",
    "abstract": " Comments: 13 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2212.02804",
    "authors": [
      "Dong Liang",
      "Jing-Wei Zhang",
      "Ying-Peng Tang",
      "Sheng-Jun Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.03760",
    "title": "Pivotal Role of Language Modeling in Recommender Systems: Enriching  Task-specific and Task-agnostic Representation Learning",
    "abstract": " Comments: ACL 2023 main conference ",
    "url": "https://arxiv.org/abs/2212.03760",
    "authors": [
      "Kyuyong Shin",
      "Hanock Kwak",
      "Wonjae Kim",
      "Jisu Jeong",
      "Seungjae Jung",
      "Kyung-Min Kim",
      "Jung-Woo Ha",
      "Sang-Woo Lee"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.04831",
    "title": "Uncertainty Estimation in Deep Speech Enhancement Using Complex Gaussian  Mixture Models",
    "abstract": " Comments: \\copyright 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works ",
    "url": "https://arxiv.org/abs/2212.04831",
    "authors": [
      "Huajian Fang",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2212.05332",
    "title": "An approach to robust ICP initialization",
    "abstract": " Comments: 8 pages, 14 figures; GitHub repository at (this https URL) ",
    "url": "https://arxiv.org/abs/2212.05332",
    "authors": [
      "Alexander Kolpakov",
      "Michael Werman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2212.05632",
    "title": "Blockchain Network Analysis: A Comparative Study of Decentralized Banks",
    "abstract": " Title: Blockchain Network Analysis: A Comparative Study of Decentralized Banks ",
    "url": "https://arxiv.org/abs/2212.05632",
    "authors": [
      "Yufan Zhang",
      "Zichao Chen",
      "Yutong Sun",
      "Yulin Liu",
      "Luyao Zhang"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)",
      "Trading and Market Microstructure (q-fin.TR)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2212.06925",
    "title": "On the Relationship Between Explanation and Prediction: A Causal View",
    "abstract": " Title: On the Relationship Between Explanation and Prediction: A Causal View ",
    "url": "https://arxiv.org/abs/2212.06925",
    "authors": [
      "Amir-Hossein Karimi",
      "Krikamol Muandet",
      "Simon Kornblith",
      "Bernhard Sch\u00f6lkopf",
      "Been Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2212.10002",
    "title": "Defending Against Misinformation Attacks in Open-Domain Question  Answering",
    "abstract": " Title: Defending Against Misinformation Attacks in Open-Domain Question  Answering ",
    "url": "https://arxiv.org/abs/2212.10002",
    "authors": [
      "Orion Weller",
      "Aleem Khan",
      "Nathaniel Weir",
      "Dawn Lawrie",
      "Benjamin Van Durme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2212.14457",
    "title": "Bayesian Interpolation with Deep Linear Networks",
    "abstract": " Title: Bayesian Interpolation with Deep Linear Networks ",
    "url": "https://arxiv.org/abs/2212.14457",
    "authors": [
      "Boris Hanin",
      "Alexander Zlokapa"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2212.14776",
    "title": "On the Interpretability of Attention Networks",
    "abstract": " Comments: ACML 2022,PMLR, Volume 189, this https URL ",
    "url": "https://arxiv.org/abs/2212.14776",
    "authors": [
      "Lakshmi Narayan Pandey",
      "Rahul Vashisht",
      "Harish G. Ramaswamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.02288",
    "title": "gRoMA: a Tool for Measuring Deep Neural Networks Global Robustness",
    "abstract": " Comments: 4 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2301.02288",
    "authors": [
      "Natan Levy",
      "Raz Yerushalmi",
      "Guy Katz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.04312",
    "title": "Word-Graph2vec: An efficient word embedding approach on word  co-occurrence graph using random walk sampling",
    "abstract": " Title: Word-Graph2vec: An efficient word embedding approach on word  co-occurrence graph using random walk sampling ",
    "url": "https://arxiv.org/abs/2301.04312",
    "authors": [
      "Wenting Li",
      "Jiahong Xue",
      "Xi Zhang",
      "Huacan Chen",
      "Zeyu Chen",
      "Yuanzhe Cai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.12348",
    "title": "Demystifying Privacy Policy of Third-Party Libraries in Mobile Apps",
    "abstract": " Title: Demystifying Privacy Policy of Third-Party Libraries in Mobile Apps ",
    "url": "https://arxiv.org/abs/2301.12348",
    "authors": [
      "Kaifa Zhao",
      "Xian Zhan",
      "Le Yu",
      "Shiyao Zhou",
      "Hao Zhou",
      "Xiapu Luo",
      "Haoyu Wang",
      "Yepang Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.01060",
    "title": "Physics Constrained Motion Prediction with Uncertainty Quantification",
    "abstract": " Comments: Accepted at IV 2023 ",
    "url": "https://arxiv.org/abs/2302.01060",
    "authors": [
      "Renukanandan Tumu",
      "Lars Lindemann",
      "Truong Nghiem",
      "Rahul Mangharam"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.01313",
    "title": "Double Permutation Equivariance for Knowledge Graph Completion",
    "abstract": " Title: Double Permutation Equivariance for Knowledge Graph Completion ",
    "url": "https://arxiv.org/abs/2302.01313",
    "authors": [
      "Jianfei Gao",
      "Yangze Zhou",
      "Bruno Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.03068",
    "title": "Evaluating Self-Supervised Learning via Risk Decomposition",
    "abstract": " Comments: Oral at ICML 2023 ",
    "url": "https://arxiv.org/abs/2302.03068",
    "authors": [
      "Yann Dubois",
      "Tatsunori Hashimoto",
      "Percy Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.05045",
    "title": "Exploiting Sparsity in Pruned Neural Networks to Optimize Large Model  Training",
    "abstract": " Title: Exploiting Sparsity in Pruned Neural Networks to Optimize Large Model  Training ",
    "url": "https://arxiv.org/abs/2302.05045",
    "authors": [
      "Siddharth Singh",
      "Abhinav Bhatele"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2302.12971",
    "title": "BrainCLIP: Bridging Brain and Visual-Linguistic Representation Via CLIP  for Generic Natural Visual Stimulus Decoding",
    "abstract": " Title: BrainCLIP: Bridging Brain and Visual-Linguistic Representation Via CLIP  for Generic Natural Visual Stimulus Decoding ",
    "url": "https://arxiv.org/abs/2302.12971",
    "authors": [
      "Yulong Liu",
      "Yongqiang Ma",
      "Wei Zhou",
      "Guibo Zhu",
      "Nanning Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2302.13452",
    "title": "Euclidean Contractivity of Neural Networks with Symmetric Weights",
    "abstract": " Comments: 17 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2302.13452",
    "authors": [
      "Veronica Centorrino",
      "Anand Gokhale",
      "Alexander Davydov",
      "Giovanni Russo",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.05300",
    "title": "CoolPINNs: A Physics-informed Neural Network Modeling of Active Cooling  in Vascular Systems",
    "abstract": " Title: CoolPINNs: A Physics-informed Neural Network Modeling of Active Cooling  in Vascular Systems ",
    "url": "https://arxiv.org/abs/2303.05300",
    "authors": [
      "N. V. Jagtap",
      "M. K. Mudunuru",
      "K. B. Nakshatrala"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.15919",
    "title": "Hyperbolic Geometry in Computer Vision: A Novel Framework for  Convolutional Neural Networks",
    "abstract": " Title: Hyperbolic Geometry in Computer Vision: A Novel Framework for  Convolutional Neural Networks ",
    "url": "https://arxiv.org/abs/2303.15919",
    "authors": [
      "Ahmad Bdeir",
      "Kristian Schwethelm",
      "Niels Landwehr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.17559",
    "title": "DDP: Diffusion Model for Dense Visual Prediction",
    "abstract": " Comments: Added controlnet exp ",
    "url": "https://arxiv.org/abs/2303.17559",
    "authors": [
      "Yuanfeng Ji",
      "Zhe Chen",
      "Enze Xie",
      "Lanqing Hong",
      "Xihui Liu",
      "Zhaoqiang Liu",
      "Tong Lu",
      "Zhenguo Li",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03376",
    "title": "Interpretable statistical representations of neural population dynamics  and geometry",
    "abstract": " Comments: Version before peer review ",
    "url": "https://arxiv.org/abs/2304.03376",
    "authors": [
      "Adam Gosztolai",
      "Robert L. Peach",
      "Alexis Arnaudon",
      "Mauricio Barahona",
      "Pierre Vandergheynst"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Neurons and Cognition (q-bio.NC)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2304.07689",
    "title": "Learning Empirical Bregman Divergence for Uncertain Distance  Representation",
    "abstract": " Comments: Accepted by IEEE FUSION 2023 ",
    "url": "https://arxiv.org/abs/2304.07689",
    "authors": [
      "Zhiyuan Li",
      "Ziru Liu",
      "Anna Zou",
      "Anca L. Ralescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.09987",
    "title": "Tetra-NeRF: Representing Neural Radiance Fields Using Tetrahedra",
    "abstract": " Comments: Web: this https URL ",
    "url": "https://arxiv.org/abs/2304.09987",
    "authors": [
      "Jonas Kulhanek",
      "Torsten Sattler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.14601",
    "title": "Improve Video Representation with Temporal Adversarial Augmentation",
    "abstract": " Comments: To be appeared in IJCAI 2023 ",
    "url": "https://arxiv.org/abs/2304.14601",
    "authors": [
      "Jinhao Duan",
      "Quanfu Fan",
      "Hao Cheng",
      "Xiaoshuang Shi",
      "Kaidi Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.00382",
    "title": "Constructing a Knowledge Graph from Textual Descriptions of Software  Vulnerabilities in the National Vulnerability Database",
    "abstract": " Comments: Accepted for publication in the 24th Nordic Conference on Computational Linguistics (NoDaLiDa), T\\'{o}rshavn, Faroe Islands, May 22nd-24th, 2023. [v2]: added funding acknowledgments ",
    "url": "https://arxiv.org/abs/2305.00382",
    "authors": [
      "Anders M\u00f8lmen H\u00f8st",
      "Pierre Lison",
      "Leon Moonen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.00608",
    "title": "Differentiable Neural Networks with RePU Activation: with Applications  to Score Estimation and Isotonic Regression",
    "abstract": " Comments: 66 pages, 20 figures, and 6 tables. arXiv admin note: text overlap with arXiv:2207.10442 ",
    "url": "https://arxiv.org/abs/2305.00608",
    "authors": [
      "Guohao Shen",
      "Yuling Jiao",
      "Yuanyuan Lin",
      "Jian Huang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.00675",
    "title": "End-to-End Lane detection with One-to-Several Transformer",
    "abstract": " Comments: code: this https URL ",
    "url": "https://arxiv.org/abs/2305.00675",
    "authors": [
      "Kunyang Zhou",
      "Rui Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.02749",
    "title": "Explainable Reinforcement Learning via a Causal World Model",
    "abstract": " Comments: Accepted by IJCAI 2023 ",
    "url": "https://arxiv.org/abs/2305.02749",
    "authors": [
      "Zhongwei Yu",
      "Jingqing Ruan",
      "Dengpeng Xing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.03319",
    "title": "HiPool: Modeling Long Documents Using Graph Neural Networks",
    "abstract": " Title: HiPool: Modeling Long Documents Using Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2305.03319",
    "authors": [
      "Irene Li",
      "Aosong Feng",
      "Dragomir Radev",
      "Rex Ying"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.03465",
    "title": "Modular Polynomial Codes for Secure and Robust Distributed Matrix  Multiplication",
    "abstract": " Title: Modular Polynomial Codes for Secure and Robust Distributed Matrix  Multiplication ",
    "url": "https://arxiv.org/abs/2305.03465",
    "authors": [
      "David Karpuk",
      "Razane Tajeddine"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.05103",
    "title": "Wooden Sleeper Deterioration Detection for Rural Railway Prognostics  Using Unsupervised Deeper FCDDs",
    "abstract": " Comments: 8 pages, 8 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2305.05103",
    "authors": [
      "Takato Yasuno",
      "Masahiro Okano",
      "Junichiro Fujii"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.05471",
    "title": "Beyond Good Intentions: Reporting the Research Landscape of NLP for  Social Good",
    "abstract": " Title: Beyond Good Intentions: Reporting the Research Landscape of NLP for  Social Good ",
    "url": "https://arxiv.org/abs/2305.05471",
    "authors": [
      "Fernando Gonzalez",
      "Zhijing Jin",
      "Bernhard Sch\u00f6lkopf",
      "Tom Hope",
      "Mrinmaya Sachan",
      "Rada Mihalcea"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.06139",
    "title": "A Neural Emulator for Uncertainty Estimation of Fire Propagation",
    "abstract": " Title: A Neural Emulator for Uncertainty Estimation of Fire Propagation ",
    "url": "https://arxiv.org/abs/2305.06139",
    "authors": [
      "Andrew Bolt",
      "Conrad Sanderson",
      "Joel Janek Dabrowski",
      "Carolyn Huston",
      "Petra Kuhnert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.06588",
    "title": "HAHE: Hierarchical Attention for Hyper-Relational Knowledge Graphs in  Global and Local Level",
    "abstract": " Comments: Accepted by ACL 2023 main conference ",
    "url": "https://arxiv.org/abs/2305.06588",
    "authors": [
      "Haoran Luo",
      "Haihong E",
      "Yuhao Yang",
      "Yikai Guo",
      "Mingzhi Sun",
      "Tianyu Yao",
      "Zichen Tang",
      "Kaiyang Wan",
      "Meina Song",
      "Wei Lin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.06657",
    "title": "On Practical Robust Reinforcement Learning: Practical Uncertainty Set  and Double-Agent Algorithm",
    "abstract": " Title: On Practical Robust Reinforcement Learning: Practical Uncertainty Set  and Double-Agent Algorithm ",
    "url": "https://arxiv.org/abs/2305.06657",
    "authors": [
      "Ukjo Hwang",
      "Songnam Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.06754",
    "title": "COCKATIEL: COntinuous Concept ranKed ATtribution with Interpretable  ELements for explaining neural net classifiers on NLP tasks",
    "abstract": " Comments: Accepted for publication at Findings of ACL 2023 ",
    "url": "https://arxiv.org/abs/2305.06754",
    "authors": [
      "Fanny Jourdan",
      "Agustin Picard",
      "Thomas Fel",
      "Laurent Risser",
      "Jean Michel Loubes",
      "Nicholas Asher"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.07205",
    "title": "Mem-Rec: Memory Efficient Recommendation System using Alternative  Representation",
    "abstract": " Title: Mem-Rec: Memory Efficient Recommendation System using Alternative  Representation ",
    "url": "https://arxiv.org/abs/2305.07205",
    "authors": [
      "Gopi Krishna Jha",
      "Anthony Thomas",
      "Nilesh Jain",
      "Sameh Gobriel",
      "Tajana Rosing",
      "Ravi Iyer"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.07375",
    "title": "Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation",
    "abstract": " Title: Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation ",
    "url": "https://arxiv.org/abs/2305.07375",
    "authors": [
      "Jinglong Gao",
      "Xiao Ding",
      "Bing Qin",
      "Ting Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.07437",
    "title": "Continual Vision-Language Representation Learning with Off-Diagonal  Information",
    "abstract": " Title: Continual Vision-Language Representation Learning with Off-Diagonal  Information ",
    "url": "https://arxiv.org/abs/2305.07437",
    "authors": [
      "Zixuan Ni",
      "Longhui Wei",
      "Siliang Tang",
      "Yueting Zhuang",
      "Qi Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.07522",
    "title": "PillarAcc: Sparse PointPillars Accelerator for Real-Time Point Cloud 3D  Object Detection on Edge Devices",
    "abstract": " Comments: 14 pages, 14 figures ",
    "url": "https://arxiv.org/abs/2305.07522",
    "authors": [
      "Minjae Lee",
      "Hyungmin Kim",
      "Seongmin Park",
      "Minyong Yoon",
      "Janghwan Lee",
      "Junwon Choi",
      "Mingu Kang",
      "Jungwook Choi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.07598",
    "title": "RHINO: Rotated DETR with Dynamic Denoising via Hungarian Matching for  Oriented Object Detection",
    "abstract": " Comments: State-of-the-art Rotated Object Detector in DOTA v1.0/v1.5/v2.0 and DIOR-R ",
    "url": "https://arxiv.org/abs/2305.07598",
    "authors": [
      "Hakjin Lee",
      "Minki Song",
      "Jamyoung Koo",
      "Junghoon Seo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  }
]