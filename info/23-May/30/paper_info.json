[
  {
    "id": "arXiv:2305.17139",
    "title": "A Measure-Theoretic Axiomatisation of Causality",
    "abstract": "Causality is a central concept in a wide range of research areas, yet there is still no universally agreed axiomatisation of causality. We view causality both as an extension of probability theory and as a study of \\textit{what happens when one intervenes on a system}, and argue in favour of taking Kolmogorov's measure-theoretic axiomatisation of probability as the starting point towards an axiomatisation of causality. To that end, we propose the notion of a \\textit{causal space}, consisting of a probability space along with a collection of transition probability kernels, called \\textit{causal kernels}, that encode the causal information of the space. Our proposed framework is not only rigorously grounded in measure theory, but it also sheds light on long-standing limitations of existing frameworks including, for example, cycles, latent variables and stochastic processes. ",
    "url": "https://arxiv.org/abs/2305.17139",
    "authors": [
      "Junhyung Park",
      "Simon Buchholz",
      "Bernhard Sch\u00f6lkopf",
      "Krikamol Muandet"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2305.17145",
    "title": "Type Prediction With Program Decomposition and Fill-in-the-Type Training",
    "abstract": "TypeScript and Python are two programming languages that support optional type annotations, which are useful but tedious to introduce and maintain. This has motivated automated type prediction: given an untyped program, produce a well-typed output program. Large language models (LLMs) are promising for type prediction, but there are challenges: fill-in-the-middle performs poorly, programs may not fit into the context window, generated types may not type check, and it is difficult to measure how well-typed the output program is. We address these challenges by building OpenTau, a search-based approach for type prediction that leverages large language models. We propose a new metric for type prediction quality, give a tree-based program decomposition that searches a space of generated types, and present fill-in-the-type fine-tuning for LLMs. We evaluate our work with a new dataset for TypeScript type prediction, and show that 47.4% of files type check (14.5% absolute improvement) with an overall rate of 3.3 type errors per file. All code, data, and models are available at: https://github.com/GammaTauAI/opentau. ",
    "url": "https://arxiv.org/abs/2305.17145",
    "authors": [
      "Federico Cassano",
      "Ming-Ho Yee",
      "Noah Shinn",
      "Arjun Guha",
      "Steven Holtzen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2305.17147",
    "title": "Heterogeneous Value Evaluation for Large Language Models",
    "abstract": "The emergent capabilities of Large Language Models (LLMs) have made it crucial to align their values with those of humans. Current methodologies typically attempt alignment with a homogeneous human value and requires human verification, yet lack consensus on the desired aspect and depth of alignment and resulting human biases. In this paper, we propose A2EHV, an Automated Alignment Evaluation with a Heterogeneous Value system that (1) is automated to minimize individual human biases, and (2) allows assessments against various target values to foster heterogeneous agents. Our approach pivots on the concept of value rationality, which represents the ability for agents to execute behaviors that satisfy a target value the most. The quantification of value rationality is facilitated by the Social Value Orientation framework from social psychology, which partitions the value space into four categories to assess social preferences from agents' behaviors. We evaluate the value rationality of eight mainstream LLMs and observe that large models are more inclined to align neutral values compared to those with strong personal values. By examining the behavior of these LLMs, we contribute to a deeper understanding of value alignment within a heterogeneous value system. ",
    "url": "https://arxiv.org/abs/2305.17147",
    "authors": [
      "Zhaowei Zhang",
      "Nian Liu",
      "Siyuan Qi",
      "Ceyao Zhang",
      "Ziqi Rong",
      "Yaodong Yang",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.17148",
    "title": "Differentially private low-dimensional representation of  high-dimensional data",
    "abstract": "Differentially private synthetic data provide a powerful mechanism to enable data analysis while protecting sensitive information about individuals. However, when the data lie in a high-dimensional space, the accuracy of the synthetic data suffers from the curse of dimensionality. In this paper, we propose a differentially private algorithm to generate low-dimensional synthetic data efficiently from a high-dimensional dataset with a utility guarantee with respect to the Wasserstein distance. A key step of our algorithm is a private principal component analysis (PCA) procedure with a near-optimal accuracy bound that circumvents the curse of dimensionality. Different from the standard perturbation analysis using the Davis-Kahan theorem, our analysis of private PCA works without assuming the spectral gap for the sample covariance matrix. ",
    "url": "https://arxiv.org/abs/2305.17148",
    "authors": [
      "Yiyun He",
      "Thomas Strohmer",
      "Roman Vershynin",
      "Yizhe Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2305.17154",
    "title": "On convex conceptual regions in deep network representations",
    "abstract": "The current study of human-machine alignment aims at understanding the geometry of latent spaces and the correspondence to human representations. G\\\"ardenfors' conceptual spaces is a prominent framework for understanding human representations. Convexity of object regions in conceptual spaces is argued to promote generalizability, few-shot learning, and intersubject alignment. Based on these insights, we investigate the notion of convexity of concept regions in machine-learned latent spaces. We develop a set of tools for measuring convexity in sampled data and evaluate emergent convexity in layered representations of state-of-the-art deep networks. We show that convexity is robust to basic re-parametrization, hence, meaningful as a quality of machine-learned latent spaces. We find that approximate convexity is pervasive in neural representations in multiple application domains, including models of images, audio, human activity, text, and brain data. We measure convexity separately for labels (i.e., targets for fine-tuning) and other concepts. Generally, we observe that fine-tuning increases the convexity of label regions, while for more general concepts, it depends on the alignment of the concept with the fine-tuning objective. We find evidence that pre-training convexity of class label regions predicts subsequent fine-tuning performance. ",
    "url": "https://arxiv.org/abs/2305.17154",
    "authors": [
      "Lenka T\u011btkov\u00e1",
      "Thea Br\u00fcsch",
      "Teresa Karen Scheidt",
      "Fabian Martin Mager",
      "Rasmus \u00d8rtoft Aagaard",
      "Jonathan Foldager",
      "Tommy Sonne Alstr\u00f8m",
      "Lars Kai Hansen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17155",
    "title": "Stability of implicit neural networks for long-term forecasting in  dynamical systems",
    "abstract": "Forecasting physical signals in long time range is among the most challenging tasks in Partial Differential Equations (PDEs) research. To circumvent limitations of traditional solvers, many different Deep Learning methods have been proposed. They are all based on auto-regressive methods and exhibit stability issues. Drawing inspiration from the stability property of implicit numerical schemes, we introduce a stable auto-regressive implicit neural network. We develop a theory based on the stability definition of schemes to ensure the stability in forecasting of this network. It leads us to introduce hard constraints on its weights and propagate the dynamics in the latent space. Our experimental results validate our stability property, and show improved results at long-term forecasting for two transports PDEs. ",
    "url": "https://arxiv.org/abs/2305.17155",
    "authors": [
      "Leon Migus",
      "Julien Salomon",
      "Patrick Gallinari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2305.17156",
    "title": "An Improved Model Ensembled of Different Hyper-parameter Tuned Machine  Learning Algorithms for Fetal Health Prediction",
    "abstract": "Fetal health is a critical concern during pregnancy as it can impact the well-being of both the mother and the baby. Regular monitoring and timely interventions are necessary to ensure the best possible outcomes. While there are various methods to monitor fetal health in the mother's womb, the use of artificial intelligence (AI) can improve the accuracy, efficiency, and speed of diagnosis. In this study, we propose a robust ensemble model called ensemble of tuned Support Vector Machine and ExtraTrees (ETSE) for predicting fetal health. Initially, we employed various data preprocessing techniques such as outlier rejection, missing value imputation, data standardization, and data sampling. Then, seven machine learning (ML) classifiers including Support Vector Machine (SVM), XGBoost (XGB), Light Gradient Boosting Machine (LGBM), Decision Tree (DT), Random Forest (RF), ExtraTrees (ET), and K-Neighbors were implemented. These models were evaluated and then optimized by hyperparameter tuning using the grid search technique. Finally, we analyzed the performance of our proposed ETSE model. The performance analysis of each model revealed that our proposed ETSE model outperformed the other models with 100% precision, 100% recall, 100% F1-score, and 99.66% accuracy. This indicates that the ETSE model can effectively predict fetal health, which can aid in timely interventions and improve outcomes for both the mother and the baby. ",
    "url": "https://arxiv.org/abs/2305.17156",
    "authors": [
      "Md. Simul Hasan Talukder",
      "Sharmin Akter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17191",
    "title": "MT-SLVR: Multi-Task Self-Supervised Learning for Transformation  In(Variant) Representations",
    "abstract": "Contrastive self-supervised learning has gained attention for its ability to create high-quality representations from large unlabelled data sets. A key reason that these powerful features enable data-efficient learning of downstream tasks is that they provide augmentation invariance, which is often a useful inductive bias. However, the amount and type of invariances preferred is not known apriori, and varies across different downstream tasks. We therefore propose a multi-task self-supervised framework (MT-SLVR) that learns both variant and invariant features in a parameter-efficient manner. Our multi-task representation provides a strong and flexible feature that benefits diverse downstream tasks. We evaluate our approach on few-shot classification tasks drawn from a variety of audio domains and demonstrate improved classification performance on all of them ",
    "url": "https://arxiv.org/abs/2305.17191",
    "authors": [
      "Calum Heggan",
      "Tim Hospedales",
      "Sam Budgett",
      "Mehrdad Yaghoobi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.17192",
    "title": "Live American Sign Language Letter Classification with Convolutional  Neural Networks",
    "abstract": "This project is centered around building a neural network that is able to recognize ASL letters in images, particularly within the scope of a live video feed. Initial testing results came up short of expectations when both the convolutional network and VGG16 transfer learning approaches failed to generalize in settings of different backgrounds. The use of a pre-trained hand joint detection model was then adopted with the produced joint locations being fed into a fully-connected neural network. The results of this approach exceeded those of prior methods and generalized well to a live video feed application. ",
    "url": "https://arxiv.org/abs/2305.17192",
    "authors": [
      "Kyle Boone",
      "Ben Wurster",
      "Seth Thao",
      "Yu Hen Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.17197",
    "title": "Entailment as Robust Self-Learner",
    "abstract": "Entailment has been recognized as an important metric for evaluating natural language understanding (NLU) models, and recent studies have found that entailment pretraining benefits weakly supervised fine-tuning. In this work, we design a prompting strategy that formulates a number of different NLU tasks as contextual entailment. This approach improves the zero-shot adaptation of pretrained entailment models. Secondly, we notice that self-training entailment-based models with unlabeled data can significantly improve the adaptation performance on downstream tasks. To achieve more stable improvement, we propose the Simple Pseudo-Label Editing (SimPLE) algorithm for better pseudo-labeling quality in self-training. We also found that both pretrained entailment-based models and the self-trained models are robust against adversarial evaluation data. Experiments on binary and multi-class classification tasks show that SimPLE leads to more robust self-training results, indicating that the self-trained entailment models are more efficient and trustworthy than large language models on language understanding tasks. ",
    "url": "https://arxiv.org/abs/2305.17197",
    "authors": [
      "Jiaxin Ge",
      "Hongyin Luo",
      "Yoon Kim",
      "James Glass"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17205",
    "title": "Ghost Noise for Regularizing Deep Neural Networks",
    "abstract": "Batch Normalization (BN) is widely used to stabilize the optimization process and improve the test performance of deep neural networks. The regularization effect of BN depends on the batch size and explicitly using smaller batch sizes with Batch Normalization, a method known as Ghost Batch Normalization (GBN), has been found to improve generalization in many settings. We investigate the effectiveness of GBN by disentangling the induced \"Ghost Noise\" from normalization and quantitatively analyzing the distribution of noise as well as its impact on model performance. Inspired by our analysis, we propose a new regularization technique called Ghost Noise Injection (GNI) that imitates the noise in GBN without incurring the detrimental train-test discrepancy effects of small batch training. We experimentally show that GNI can provide a greater generalization benefit than GBN. Ghost Noise Injection can also be beneficial in otherwise non-noisy settings such as layer-normalized networks, providing additional evidence of the usefulness of Ghost Noise in Batch Normalization as a regularizer. ",
    "url": "https://arxiv.org/abs/2305.17205",
    "authors": [
      "Atli Kosson",
      "Dongyang Fan",
      "Martin Jaggi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.17207",
    "title": "Building One-class Detector for Anything: Open-vocabulary Zero-shot OOD  Detection Using Text-image Models",
    "abstract": "We focus on the challenge of out-of-distribution (OOD) detection in deep learning models, a crucial aspect in ensuring reliability. Despite considerable effort, the problem remains significantly challenging in deep learning models due to their propensity to output over-confident predictions for OOD inputs. We propose a novel one-class open-set OOD detector that leverages text-image pre-trained models in a zero-shot fashion and incorporates various descriptions of in-domain and OOD. Our approach is designed to detect anything not in-domain and offers the flexibility to detect a wide variety of OOD, defined via fine- or coarse-grained labels, or even in natural language. We evaluate our approach on challenging benchmarks including large-scale datasets containing fine-grained, semantically similar classes, distributionally shifted images, and multi-object images containing a mixture of in-domain and OOD objects. Our method shows superior performance over previous methods on all benchmarks. Code is available at https://github.com/gyhandy/One-Class-Anything ",
    "url": "https://arxiv.org/abs/2305.17207",
    "authors": [
      "Yunhao Ge",
      "Jie Ren",
      "Jiaping Zhao",
      "Kaifeng Chen",
      "Andrew Gallagher",
      "Laurent Itti",
      "Balaji Lakshminarayanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17208",
    "title": "A Categorical Representation Language and Computational System for  Knowledge-Based Planning",
    "abstract": "Classical planning representation languages based on first-order logic have been extensively used to model and solve planning problems, but they struggle to capture implicit preconditions and effects that arise in complex planning scenarios. To address this problem, we propose an alternative approach to representing and transforming world states during planning. Based on the category-theoretic concepts of $\\mathsf{C}$-sets and double-pushout rewriting (DPO), our proposed representation can effectively handle structured knowledge about world states that support domain abstractions at all levels. It formalizes the semantics of predicates according to a user-provided ontology and preserves the semantics when transitioning between world states. This method provides a formal semantics for using knowledge graphs and relational databases to model world states and updates in planning. In this paper, we compare our category-theoretic representation with the classical planning representation. We show that our proposed representation has advantages over the classical representation in terms of handling implicit preconditions and effects, and provides a more structured framework in which to model and solve planning problems. ",
    "url": "https://arxiv.org/abs/2305.17208",
    "authors": [
      "Angeline Aguinaldo",
      "Evan Patterson",
      "James Fairbanks",
      "Jaime Ruiz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ]
  },
  {
    "id": "arXiv:2305.17211",
    "title": "Coping with low data availability for social media crisis message  categorisation",
    "abstract": "During crisis situations, social media allows people to quickly share information, including messages requesting help. This can be valuable to emergency responders, who need to categorise and prioritise these messages based on the type of assistance being requested. However, the high volume of messages makes it difficult to filter and prioritise them without the use of computational techniques. Fully supervised filtering techniques for crisis message categorisation typically require a large amount of annotated training data, but this can be difficult to obtain during an ongoing crisis and is expensive in terms of time and labour to create. This thesis focuses on addressing the challenge of low data availability when categorising crisis messages for emergency response. It first presents domain adaptation as a solution for this problem, which involves learning a categorisation model from annotated data from past crisis events (source domain) and adapting it to categorise messages from an ongoing crisis event (target domain). In many-to-many adaptation, where the model is trained on multiple past events and adapted to multiple ongoing events, a multi-task learning approach is proposed using pre-trained language models. This approach outperforms baselines and an ensemble approach further improves performance... ",
    "url": "https://arxiv.org/abs/2305.17211",
    "authors": [
      "Congcong Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17212",
    "title": "Rotational Optimizers: Simple & Robust DNN Training",
    "abstract": "The training dynamics of modern deep neural networks depend on complex interactions between the learning rate, weight decay, initialization, and other hyperparameters. These interactions can give rise to Spherical Motion Dynamics in scale-invariant layers (e.g., normalized layers), which converge to an equilibrium state, where the weight norm and the expected rotational update size are fixed. Our analysis of this equilibrium in AdamW, SGD with momentum, and Lion provides new insights into the effects of different hyperparameters and their interactions on the training process. We propose rotational variants (RVs) of these optimizers that force the expected angular update size to match the equilibrium value throughout training. This simplifies the training dynamics by removing the transient phase corresponding to the convergence to an equilibrium. Our rotational optimizers can match the performance of the original variants, often with minimal or no tuning of the baseline hyperparameters, showing that these transient phases are not needed. Furthermore, we find that the rotational optimizers have a reduced need for learning rate warmup and improve the optimization of poorly normalized networks. ",
    "url": "https://arxiv.org/abs/2305.17212",
    "authors": [
      "Atli Kosson",
      "Bettina Messmer",
      "Martin Jaggi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.17220",
    "title": "VoxDet: Voxel Learning for Novel Instance Detection",
    "abstract": "Detecting unseen instances based on multi-view templates is a challenging problem due to its open-world nature. Traditional methodologies, which primarily rely on 2D representations and matching techniques, are often inadequate in handling pose variations and occlusions. To solve this, we introduce VoxDet, a pioneer 3D geometry-aware framework that fully utilizes the strong 3D voxel representation and reliable voxel matching mechanism. VoxDet first ingeniously proposes template voxel aggregation (TVA) module, effectively transforming multi-view 2D images into 3D voxel features. By leveraging associated camera poses, these features are aggregated into a compact 3D template voxel. In novel instance detection, this voxel representation demonstrates heightened resilience to occlusion and pose variations. We also discover that a 3D reconstruction objective helps to pre-train the 2D-3D mapping in TVA. Second, to quickly align with the template voxel, VoxDet incorporates a Query Voxel Matching (QVM) module. The 2D queries are first converted into their voxel representation with the learned 2D-3D mapping. We find that since the 3D voxel representations encode the geometry, we can first estimate the relative rotation and then compare the aligned voxels, leading to improved accuracy and efficiency. Exhaustive experiments are conducted on the demanding LineMod-Occlusion, YCB-video, and the newly built RoboTools benchmarks, where VoxDet outperforms various 2D baselines remarkably with 20% higher recall and faster speed. To the best of our knowledge, VoxDet is the first to incorporate implicit 3D knowledge for 2D tasks. ",
    "url": "https://arxiv.org/abs/2305.17220",
    "authors": [
      "Bowen Li",
      "Jiashun Wang",
      "Yaoyu Hu",
      "Chen Wang",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17244",
    "title": "Mitigating Catastrophic Forgetting in Long Short-Term Memory Networks",
    "abstract": "Continual learning on sequential data is critical for many machine learning (ML) deployments. Unfortunately, LSTM networks, which are commonly used to learn on sequential data, suffer from catastrophic forgetting and are limited in their ability to learn multiple tasks continually. We discover that catastrophic forgetting in LSTM networks can be overcome in two novel and readily-implementable ways -- separating the LSTM memory either for each task or for each target label. Our approach eschews the need for explicit regularization, hypernetworks, and other complex methods. We quantify the benefits of our approach on recently-proposed LSTM networks for computer memory access prefetching, an important sequential learning problem in ML-based computer system optimization. Compared to state-of-the-art weight regularization methods to mitigate catastrophic forgetting, our approach is simple, effective, and enables faster learning. We also show that our proposal enables the use of small, non-regularized LSTM networks for complex natural language processing in the offline learning scenario, which was previously considered difficult. ",
    "url": "https://arxiv.org/abs/2305.17244",
    "authors": [
      "Ketaki Joshi",
      "Raghavendra Pradyumna Pothukuchi",
      "Andre Wibisono",
      "Abhishek Bhattacharjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.17246",
    "title": "NASimEmu: Network Attack Simulator & Emulator for Training Agents  Generalizing to Novel Scenarios",
    "abstract": "Current frameworks for training offensive penetration testing agents with deep reinforcement learning struggle to produce agents that perform well in real-world scenarios, due to the reality gap in simulation-based frameworks and the lack of scalability in emulation-based frameworks. Additionally, existing frameworks often use an unrealistic metric that measures the agents' performance on the training data. NASimEmu, a new framework introduced in this paper, addresses these issues by providing both a simulator and an emulator with a shared interface. This approach allows agents to be trained in simulation and deployed in the emulator, thus verifying the realism of the used abstraction. Our framework promotes the development of general agents that can transfer to novel scenarios unseen during their training. For the simulation part, we adopt an existing simulator NASim and enhance its realism. The emulator is implemented with industry-level tools, such as Vagrant, VirtualBox, and Metasploit. Experiments demonstrate that a simulation-trained agent can be deployed in emulation, and we show how to use the framework to train a general agent that transfers into novel, structurally different scenarios. NASimEmu is available as open-source. ",
    "url": "https://arxiv.org/abs/2305.17246",
    "authors": [
      "Jarom\u00edr Janisch",
      "Tom\u00e1\u0161 Pevn\u00fd",
      "Viliam Lis\u00fd"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.17250",
    "title": "Self-Supervised Reinforcement Learning that Transfers using Random  Features",
    "abstract": "Model-free reinforcement learning algorithms have exhibited great potential in solving single-task sequential decision-making problems with high-dimensional observations and long horizons, but are known to be hard to generalize across tasks. Model-based RL, on the other hand, learns task-agnostic models of the world that naturally enables transfer across different reward functions, but struggles to scale to complex environments due to the compounding error. To get the best of both worlds, we propose a self-supervised reinforcement learning method that enables the transfer of behaviors across tasks with different rewards, while circumventing the challenges of model-based RL. In particular, we show self-supervised pre-training of model-free reinforcement learning with a number of random features as rewards allows implicit modeling of long-horizon environment dynamics. Then, planning techniques like model-predictive control using these implicit models enable fast adaptation to problems with new reward functions. Our method is self-supervised in that it can be trained on offline datasets without reward labels, but can then be quickly deployed on new tasks. We validate that our proposed method enables transfer across tasks on a variety of manipulation and locomotion domains in simulation, opening the door to generalist decision-making agents. ",
    "url": "https://arxiv.org/abs/2305.17250",
    "authors": [
      "Boyuan Chen",
      "Chuning Zhu",
      "Pulkit Agrawal",
      "Kaiqing Zhang",
      "Abhishek Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17268",
    "title": "Metaphor Detection via Explicit Basic Meanings Modelling",
    "abstract": "One noticeable trend in metaphor detection is the embrace of linguistic theories such as the metaphor identification procedure (MIP) for model architecture design. While MIP clearly defines that the metaphoricity of a lexical unit is determined based on the contrast between its \\textit{contextual meaning} and its \\textit{basic meaning}, existing work does not strictly follow this principle, typically using the \\textit{aggregated meaning} to approximate the basic meaning of target words. In this paper, we propose a novel metaphor detection method, which models the basic meaning of the word based on literal annotation from the training set, and then compares this with the contextual meaning in a target sentence to identify metaphors. Empirical results show that our method outperforms the state-of-the-art method significantly by 1.0\\% in F1 score. Moreover, our performance even reaches the theoretical upper bound on the VUA18 benchmark for targets with basic annotations, which demonstrates the importance of modelling basic meanings for metaphor detection. ",
    "url": "https://arxiv.org/abs/2305.17268",
    "authors": [
      "Yucheng Li",
      "Shun Wang",
      "Chenghua Lin",
      "Guerin Frank"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17271",
    "title": "Robust Lane Detection through Self Pre-training with Masked Sequential  Autoencoders and Fine-tuning with Customized PolyLoss",
    "abstract": "Lane detection is crucial for vehicle localization which makes it the foundation for automated driving and many intelligent and advanced driving assistant systems. Available vision-based lane detection methods do not make full use of the valuable features and aggregate contextual information, especially the interrelationships between lane lines and other regions of the images in continuous frames. To fill this research gap and upgrade lane detection performance, this paper proposes a pipeline consisting of self pre-training with masked sequential autoencoders and fine-tuning with customized PolyLoss for the end-to-end neural network models using multi-continuous image frames. The masked sequential autoencoders are adopted to pre-train the neural network models with reconstructing the missing pixels from a random masked image as the objective. Then, in the fine-tuning segmentation phase where lane detection segmentation is performed, the continuous image frames are served as the inputs, and the pre-trained model weights are transferred and further updated using the backpropagation mechanism with customized PolyLoss calculating the weighted errors between the output lane detection results and the labeled ground truth. Extensive experiment results demonstrate that, with the proposed pipeline, the lane detection model performance on both normal and challenging scenes can be advanced beyond the state-of-the-art, delivering the best testing accuracy (98.38%), precision (0.937), and F1-measure (0.924) on the normal scene testing set, together with the best overall accuracy (98.36%) and precision (0.844) in the challenging scene test set, while the training time can be substantially shortened. ",
    "url": "https://arxiv.org/abs/2305.17271",
    "authors": [
      "Ruohan Li",
      "Yongqi Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.17284",
    "title": "GC-Flow: A Graph-Based Flow Network for Effective Clustering",
    "abstract": "Graph convolutional networks (GCNs) are \\emph{discriminative models} that directly model the class posterior $p(y|\\mathbf{x})$ for semi-supervised classification of graph data. While being effective, as a representation learning approach, the node representations extracted from a GCN often miss useful information for effective clustering, because the objectives are different. In this work, we design normalizing flows that replace GCN layers, leading to a \\emph{generative model} that models both the class conditional likelihood $p(\\mathbf{x}|y)$ and the class prior $p(y)$. The resulting neural network, GC-Flow, retains the graph convolution operations while being equipped with a Gaussian mixture representation space. It enjoys two benefits: it not only maintains the predictive power of GCN, but also produces well-separated clusters, due to the structuring of the representation space. We demonstrate these benefits on a variety of benchmark data sets. Moreover, we show that additional parameterization, such as that on the adjacency matrix used for graph convolutions, yields additional improvement in clustering. ",
    "url": "https://arxiv.org/abs/2305.17284",
    "authors": [
      "Tianchun Wang",
      "Farzaneh Mirzazadeh",
      "Xiang Zhang",
      "Jie Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.17289",
    "title": "Fourier-DeepONet: Fourier-enhanced deep operator networks for full  waveform inversion with improved accuracy, generalizability, and robustness",
    "abstract": "Full waveform inversion (FWI) infers the subsurface structure information from seismic waveform data by solving a non-convex optimization problem. Data-driven FWI has been increasingly studied with various neural network architectures to improve accuracy and computational efficiency. Nevertheless, the applicability of pre-trained neural networks is severely restricted by potential discrepancies between the source function used in the field survey and the one utilized during training. Here, we develop a Fourier-enhanced deep operator network (Fourier-DeepONet) for FWI with the generalization of seismic sources, including the frequencies and locations of sources. Specifically, we employ the Fourier neural operator as the decoder of DeepONet, and we utilize source parameters as one input of Fourier-DeepONet, facilitating the resolution of FWI with variable sources. To test Fourier-DeepONet, we develop two new and realistic FWI benchmark datasets (FWI-F and FWI-L) with varying source frequencies and locations. Our experiments demonstrate that compared with existing data-driven FWI methods, Fourier-DeepONet obtains more accurate predictions of subsurface structures in a wide range of source parameters. Moreover, the proposed Fourier-DeepONet exhibits superior robustness when dealing with noisy inputs or inputs with missing traces, paving the way for more reliable and accurate subsurface imaging across diverse real conditions. ",
    "url": "https://arxiv.org/abs/2305.17289",
    "authors": [
      "Min Zhu",
      "Shihang Feng",
      "Youzuo Lin",
      "Lu Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Geophysics (physics.geo-ph)"
    ]
  },
  {
    "id": "arXiv:2305.17304",
    "title": "External Language Model Integration for Factorized Neural Transducers",
    "abstract": "We propose an adaptation method for factorized neural transducers (FNT) with external language models. We demonstrate that both neural and n-gram external LMs add significantly more value when linearly interpolated with predictor output compared to shallow fusion, thus confirming that FNT forces the predictor to act like regular language models. Further, we propose a method to integrate class-based n-gram language models into FNT framework resulting in accuracy gains similar to a hybrid setup. We show average gains of 18% WERR with lexical adaptation across various scenarios and additive gains of up to 60% WERR in one entity-rich scenario through a combination of class-based n-gram and neural LMs. ",
    "url": "https://arxiv.org/abs/2305.17304",
    "authors": [
      "Michael Levit",
      "Sarangarajan Parthasarathy",
      "Cem Aksoylar",
      "Mohammad Sadegh Rasooli",
      "Shuangyu Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17310",
    "title": "DotHash: Estimating Set Similarity Metrics for Link Prediction and  Document Deduplication",
    "abstract": "Metrics for set similarity are a core aspect of several data mining tasks. To remove duplicate results in a Web search, for example, a common approach looks at the Jaccard index between all pairs of pages. In social network analysis, a much-celebrated metric is the Adamic-Adar index, widely used to compare node neighborhood sets in the important problem of predicting links. However, with the increasing amount of data to be processed, calculating the exact similarity between all pairs can be intractable. The challenge of working at this scale has motivated research into efficient estimators for set similarity metrics. The two most popular estimators, MinHash and SimHash, are indeed used in applications such as document deduplication and recommender systems where large volumes of data need to be processed. Given the importance of these tasks, the demand for advancing estimators is evident. We propose DotHash, an unbiased estimator for the intersection size of two sets. DotHash can be used to estimate the Jaccard index and, to the best of our knowledge, is the first method that can also estimate the Adamic-Adar index and a family of related metrics. We formally define this family of metrics, provide theoretical bounds on the probability of estimate errors, and analyze its empirical performance. Our experimental results indicate that DotHash is more accurate than the other estimators in link prediction and detecting duplicate documents with the same complexity and similar comparison time. ",
    "url": "https://arxiv.org/abs/2305.17310",
    "authors": [
      "Igor Nunes",
      "Mike Heddes",
      "Pere Verg\u00e9s",
      "Danny Abraham",
      "Alexander Veidenbaum",
      "Alexandru Nicolau",
      "Tony Givargis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2305.17321",
    "title": "Optimal Resource Allocation with Delay Guarantees for Network Slicing in  Disaggregated RAN",
    "abstract": "In this article, we propose a novel formulation for the resource allocation problem of a sliced and disaggregated Radio Access Network (RAN) and its transport network. Our proposal assures an end-to-end delay bound for the Ultra-Reliable and Low-Latency Communication (URLLC) use case while jointly considering the number of admitted users, the transmission rate allocation per slice, the functional split of RAN nodes and the routing paths in the transport network. We use deterministic network calculus theory to calculate delay along the transport network connecting disaggregated RANs deploying network functions at the Radio Unit (RU), Distributed Unit (DU), and Central Unit (CU) nodes. The maximum end-to-end delay is a constraint in the optimization-based formulation that aims to maximize Mobile Network Operator (MNO) profit, considering a cash flow analysis to model revenue and operational costs using data from one of the world's leading MNOs. The optimization model leverages a Flexible Functional Split (FFS) approach to provide a new degree of freedom to the resource allocation strategy. Simulation results reveal that, due to its non-linear nature, there is no trivial solution to the proposed optimization problem formulation. Our proposal guarantees a maximum delay for URLLC services while satisfying minimal bandwidth requirements for enhanced Mobile BroadBand (eMBB) services and maximizing the MNO's profit. ",
    "url": "https://arxiv.org/abs/2305.17321",
    "authors": [
      "Fl\u00e1vio G. C. Rocha",
      "Gabriel M. F. de Almeida",
      "Kleber V. Cardoso",
      "Cristiano B. Both",
      "Jos\u00e9 F. de Rezende"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.17326",
    "title": "Kernel-SSL: Kernel KL Divergence for Self-supervised Learning",
    "abstract": "Contrastive learning usually compares one positive anchor sample with lots of negative samples to perform Self-Supervised Learning (SSL). Alternatively, non-contrastive learning, as exemplified by methods like BYOL, SimSiam, and Barlow Twins, accomplishes SSL without the explicit use of negative samples. Inspired by the existing analysis for contrastive learning, we provide a reproducing kernel Hilbert space (RKHS) understanding of many existing non-contrastive learning methods. Subsequently, we propose a novel loss function, Kernel-SSL, which directly optimizes the mean embedding and the covariance operator within the RKHS. In experiments, our method Kernel-SSL outperforms state-of-the-art methods by a large margin on ImageNet datasets under the linear evaluation settings. Specifically, when performing 100 epochs pre-training, our method outperforms SimCLR by 4.6%. ",
    "url": "https://arxiv.org/abs/2305.17326",
    "authors": [
      "Yifan Zhang",
      "Zhiquan Tan",
      "Jingqin Yang",
      "Yang Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17328",
    "title": "Zero-TPrune: Zero-Shot Token Pruning through Leveraging of the Attention  Graph in Pre-Trained Transformers",
    "abstract": "Deployment of Transformer models on the edge is increasingly challenging due to the exponentially growing model size and inference cost that scales quadratically with the number of tokens in the input sequence. Token pruning is an emerging solution to address this challenge due to its ease of deployment on various Transformer backbones. However, most token pruning methods require a computationally-expensive fine-tuning process after or during pruning, which is not desirable in many cases. Some recent works explore pruning of off-the-shelf pre-trained Transformers without fine-tuning. However, they only take the importance of tokens into consideration. In this work, we propose Zero-TPrune, the first zero-shot method that considers both the importance and similarity of tokens in performing token pruning. Zero-TPrune leverages the attention graph of pre-trained Transformer models to produce an importance rank for tokens and removes the less informative tokens. The attention matrix can be thought of as an adjacency matrix of a directed graph, to which a graph shift operator can be applied iteratively to obtain the importance score distribution. This distribution guides the partition of tokens into two groups and measures similarity between them. Due to the elimination of the fine-tuning overhead, Zero-TPrune can easily prune large models and perform hyperparameter tuning efficiently. We evaluate the performance of Zero-TPrune on vision tasks by applying it to various vision Transformer backbones. Compared with state-of-the-art pruning methods that require fine-tuning, Zero-TPrune not only eliminates the need for fine-tuning after pruning, but does so with only around 0.3% accuracy loss. Compared with state-of-the-art fine-tuning-free pruning methods, Zero-TPrune reduces accuracy loss by up to 45% on medium-sized models. ",
    "url": "https://arxiv.org/abs/2305.17328",
    "authors": [
      "Hongjie Wang",
      "Bhishma Dedhia",
      "Niraj K. Jha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.17342",
    "title": "Rethinking Adversarial Policies: A Generalized Attack Formulation and  Provable Defense in Multi-Agent RL",
    "abstract": "Most existing works consider direct perturbations of victim's state/action or the underlying transition dynamics to show vulnerability of reinforcement learning agents under adversarial attacks. However, such direct manipulation may not always be feasible in practice. In this paper, we consider another common and realistic attack setup: in a multi-agent RL setting with well-trained agents, during deployment time, the victim agent $\\nu$ is exploited by an attacker who controls another agent $\\alpha$ to act adversarially against the victim using an \\textit{adversarial policy}. Prior attack models under such setup do not consider that the attacker can confront resistance and thus can only take partial control of the agent $\\alpha$, as well as introducing perceivable ``abnormal'' behaviors that are easily detectable. A provable defense against these adversarial policies is also lacking. To resolve these issues, we introduce a more general attack formulation that models to what extent the adversary is able to control the agent to produce the adversarial policy. Based on such a generalized attack framework, the attacker can also regulate the state distribution shift caused by the attack through an attack budget, and thus produce stealthy adversarial policies that can exploit the victim agent. Furthermore, we provide the first provably robust defenses with convergence guarantee to the most robust victim policy via adversarial training with timescale separation, in sharp contrast to adversarial training in supervised learning which may only provide {\\it empirical} defenses. ",
    "url": "https://arxiv.org/abs/2305.17342",
    "authors": [
      "Xiangyu Liu",
      "Souradip Chakraborty",
      "Yanchao Sun",
      "Furong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17346",
    "title": "Input-Aware Dynamic Timestep Spiking Neural Networks for Efficient  In-Memory Computing",
    "abstract": "Spiking Neural Networks (SNNs) have recently attracted widespread research interest as an efficient alternative to traditional Artificial Neural Networks (ANNs) because of their capability to process sparse and binary spike information and avoid expensive multiplication operations. Although the efficiency of SNNs can be realized on the In-Memory Computing (IMC) architecture, we show that the energy cost and latency of SNNs scale linearly with the number of timesteps used on IMC hardware. Therefore, in order to maximize the efficiency of SNNs, we propose input-aware Dynamic Timestep SNN (DT-SNN), a novel algorithmic solution to dynamically determine the number of timesteps during inference on an input-dependent basis. By calculating the entropy of the accumulated output after each timestep, we can compare it to a predefined threshold and decide if the information processed at the current timestep is sufficient for a confident prediction. We deploy DT-SNN on an IMC architecture and show that it incurs negligible computational overhead. We demonstrate that our method only uses 1.46 average timesteps to achieve the accuracy of a 4-timestep static SNN while reducing the energy-delay-product by 80%. ",
    "url": "https://arxiv.org/abs/2305.17346",
    "authors": [
      "Yuhang Li",
      "Abhishek Moitra",
      "Tamar Geller",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.17351",
    "title": "Disambiguated Lexically Constrained Neural Machine Translation",
    "abstract": "Lexically constrained neural machine translation (LCNMT), which controls the translation generation with pre-specified constraints, is important in many practical applications. Current approaches to LCNMT typically assume that the pre-specified lexical constraints are contextually appropriate. This assumption limits their application to real-world scenarios where a source lexicon may have multiple target constraints, and disambiguation is needed to select the most suitable one. In this paper, we propose disambiguated LCNMT (D-LCNMT) to solve the problem. D-LCNMT is a robust and effective two-stage framework that disambiguates the constraints based on contexts at first, then integrates the disambiguated constraints into LCNMT. Experimental results show that our approach outperforms strong baselines including existing data augmentation based approaches on benchmark datasets, and comprehensive experiments in scenarios where a source lexicon corresponds to multiple target constraints demonstrate the constraint disambiguation superiority of our approach. ",
    "url": "https://arxiv.org/abs/2305.17351",
    "authors": [
      "Jinpeng Zhang",
      "Nini Xiao",
      "Ke Wang",
      "Chuanqi Dong",
      "Xiangyu Duan",
      "Yuqi Zhang",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17355",
    "title": "Rethinking PRL: A Multiscale Progressively Residual Learning Network for  Inverse Halftoning",
    "abstract": "Image inverse halftoning is a classic image restoration task, aiming to recover continuous-tone images from halftone images with only bilevel pixels. Because the halftone images lose much of the original image content, inverse halftoning is a classic ill-problem. Although existing inverse halftoning algorithms achieve good performance, their results lose image details and features. Therefore, it is still a challenge to recover high-quality continuous-tone images. In this paper, we propose an end-to-end multiscale progressively residual learning network (MSPRL), which has a UNet architecture and takes multiscale input images. To make full use of different input image information, we design a shallow feature extraction module to capture similar features between images of different scales. We systematically study the performance of different methods and compare them with our proposed method. In addition, we employ different training strategies to optimize the model, which is important for optimizing the training process and improving performance. Extensive experiments demonstrate that our MSPRL model obtains considerable performance gains in detail restoration. ",
    "url": "https://arxiv.org/abs/2305.17355",
    "authors": [
      "Feiyu Li",
      "Jun Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.17359",
    "title": "DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of  GPT-Generated Text",
    "abstract": "Large language models (LLMs) have notably enhanced the fluency and diversity of machine-generated text. However, this progress also presents a significant challenge in detecting the origin of a given text, and current research on detection methods lags behind the rapid evolution of LLMs. Conventional training-based methods have limitations in flexibility, particularly when adapting to new domains, and they often lack explanatory power. To address this gap, we propose a novel training-free detection strategy called Divergent N-Gram Analysis (DNA-GPT). Given a text, we first truncate it in the middle and then use only the preceding portion as input to the LLMs to regenerate the new remaining parts. By analyzing the differences between the original and new remaining parts through N-gram analysis in black-box or probability divergence in white-box, we can clearly illustrate significant discrepancies between machine-generated and human-written text. We conducted extensive experiments on the most advanced LLMs from OpenAI, including text-davinci-003, GPT-3.5-turbo, and GPT-4, as well as open-source models such as GPT-NeoX-20B and LLaMa-13B. Results show that our zero-shot approach exhibits state-of-the-art performance in distinguishing between human and GPT-generated text on four English and one German dataset, outperforming OpenAI's own classifier, which is trained on millions of text. Additionally, our methods provide reasonable explanations and evidence to support our claim, which is a unique feature of explainable detection. Our method is also robust under the revised text attack and can additionally solve model sourcing. Codes are available at https://github.com/Xianjun-Yang/DNA-GPT. ",
    "url": "https://arxiv.org/abs/2305.17359",
    "authors": [
      "Xianjun Yang",
      "Wei Cheng",
      "Linda Petzold",
      "William Yang Wang",
      "Haifeng Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17373",
    "title": "Zero- and Few-Shot Event Detection via Prompt-Based Meta Learning",
    "abstract": "With emerging online topics as a source for numerous new events, detecting unseen / rare event types presents an elusive challenge for existing event detection methods, where only limited data access is provided for training. To address the data scarcity problem in event detection, we propose MetaEvent, a meta learning-based framework for zero- and few-shot event detection. Specifically, we sample training tasks from existing event types and perform meta training to search for optimal parameters that quickly adapt to unseen tasks. In our framework, we propose to use the cloze-based prompt and a trigger-aware soft verbalizer to efficiently project output to unseen event types. Moreover, we design a contrastive meta objective based on maximum mean discrepancy (MMD) to learn class-separating features. As such, the proposed MetaEvent can perform zero-shot event detection by mapping features to event types without any prior knowledge. In our experiments, we demonstrate the effectiveness of MetaEvent in both zero-shot and few-shot scenarios, where the proposed method achieves state-of-the-art performance in extensive experiments on benchmark datasets FewEvent and MAVEN. ",
    "url": "https://arxiv.org/abs/2305.17373",
    "authors": [
      "Zhenrui Yue",
      "Huimin Zeng",
      "Mengfei Lan",
      "Heng Ji",
      "Dong Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17375",
    "title": "Attention Schema in Neural Agents",
    "abstract": "Attention has become a common ingredient in deep learning architectures. It adds a dynamical selection of information on top of the static selection of information supported by weights. In the same way, we can imagine a higher-order informational filter built on top of attention: an Attention Schema (AS), namely, a descriptive and predictive model of attention. In cognitive neuroscience, Attention Schema Theory (AST) supports this idea of distinguishing attention from AS. A strong prediction of this theory is that an agent can use its own AS to also infer the states of other agents' attention and consequently enhance coordination with other agents. As such, multi-agent reinforcement learning would be an ideal setting to experimentally test the validity of AST. We explore different ways in which attention and AS interact with each other. Our preliminary results indicate that agents that implement the AS as a recurrent internal control achieve the best performance. In general, these exploratory experiments suggest that equipping artificial agents with a model of attention can enhance their social intelligence. ",
    "url": "https://arxiv.org/abs/2305.17375",
    "authors": [
      "Dianbo Liu",
      "Samuele Bolotta",
      "He Zhu",
      "Yoshua Bengio",
      "Guillaume Dumas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.17380",
    "title": "No-Regret Online Reinforcement Learning with Adversarial Losses and  Transitions",
    "abstract": "Existing online learning algorithms for adversarial Markov Decision Processes achieve ${O}(\\sqrt{T})$ regret after $T$ rounds of interactions even if the loss functions are chosen arbitrarily by an adversary, with the caveat that the transition function has to be fixed. This is because it has been shown that adversarial transition functions make no-regret learning impossible. Despite such impossibility results, in this work, we develop algorithms that can handle both adversarial losses and adversarial transitions, with regret increasing smoothly in the degree of maliciousness of the adversary. More concretely, we first propose an algorithm that enjoys $\\widetilde{{O}}(\\sqrt{T} + C^{\\textsf{P}})$ regret where $C^{\\textsf{P}}$ measures how adversarial the transition functions are and can be at most ${O}(T)$. While this algorithm itself requires knowledge of $C^{\\textsf{P}}$, we further develop a black-box reduction approach that removes this requirement. Moreover, we also show that further refinements of the algorithm not only maintains the same regret bound, but also simultaneously adapts to easier environments (where losses are generated in a certain stochastically constrained manner as in Jin et al.[2021]) and achieves $\\widetilde{{O}}(U + \\sqrt{UC^{\\textsf{L}}} + C^{\\textsf{P}})$ regret, where $U$ is some standard gap-dependent coefficient and $C^{\\textsf{L}}$ is the amount of corruption on losses. ",
    "url": "https://arxiv.org/abs/2305.17380",
    "authors": [
      "Tiancheng Jin",
      "Junyan Liu",
      "Chlo\u00e9 Rouyer",
      "William Chan",
      "Chen-Yu We",
      "Haipeng Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.17387",
    "title": "Learning from Integral Losses in Physics Informed Neural Networks",
    "abstract": "This work proposes a solution for the problem of training physics informed networks under partial integro-differential equations. These equations require infinite or a large number of neural evaluations to construct a single residual for training. As a result, accurate evaluation may be impractical, and we show that naive approximations at replacing these integrals with unbiased estimates lead to biased loss functions and solutions. To overcome this bias, we investigate three types of solutions: the deterministic sampling approach, the double-sampling trick, and the delayed target method. We consider three classes of PDEs for benchmarking; one defining a Poisson problem with singular charges and weak solutions, another involving weak solutions on electro-magnetic fields and a Maxwell equation, and a third one defining a Smoluchowski coagulation problem. Our numerical results confirm the existence of the aforementioned bias in practice, and also show that our proposed delayed target approach can lead to accurate solutions with comparable quality to ones estimated with a large number of samples. Our implementation is open-source and available at https://github.com/ehsansaleh/btspinn. ",
    "url": "https://arxiv.org/abs/2305.17387",
    "authors": [
      "Ehsan Saleh",
      "Saba Ghaffari",
      "Timothy Bretl",
      "Luke Olson",
      "Matthew West"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2305.17390",
    "title": "SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex  Interactive Tasks",
    "abstract": "We introduce SwiftSage, a novel agent framework inspired by the dual-process theory of human cognition, designed to excel in action planning for complex interactive reasoning tasks. SwiftSage integrates the strengths of behavior cloning and prompting large language models (LLMs) to enhance task completion performance. The framework comprises two primary modules: the Swift module, representing fast and intuitive thinking, and the Sage module, emulating deliberate thought processes. The Swift module is a small encoder-decoder LM fine-tuned on the oracle agent's action trajectories, while the Sage module employs LLMs such as GPT-4 for subgoal planning and grounding. We develop a heuristic method to harmoniously integrate the two modules, resulting in a more efficient and robust problem-solving process. In 30 tasks from the ScienceWorld benchmark, SwiftSage significantly outperforms other methods such as SayCan, ReAct, and Reflexion, demonstrating its effectiveness in solving complex real-world tasks. ",
    "url": "https://arxiv.org/abs/2305.17390",
    "authors": [
      "Bill Yuchen Lin",
      "Yicheng Fu",
      "Karina Yang",
      "Prithviraj Ammanabrolu",
      "Faeze Brahman",
      "Shiyu Huang",
      "Chandra Bhagavatula",
      "Yejin Choi",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.17398",
    "title": "NeRO: Neural Geometry and BRDF Reconstruction of Reflective Objects from  Multiview Images",
    "abstract": "We present a neural rendering-based method called NeRO for reconstructing the geometry and the BRDF of reflective objects from multiview images captured in an unknown environment. Multiview reconstruction of reflective objects is extremely challenging because specular reflections are view-dependent and thus violate the multiview consistency, which is the cornerstone for most multiview reconstruction methods. Recent neural rendering techniques can model the interaction between environment lights and the object surfaces to fit the view-dependent reflections, thus making it possible to reconstruct reflective objects from multiview images. However, accurately modeling environment lights in the neural rendering is intractable, especially when the geometry is unknown. Most existing neural rendering methods, which can model environment lights, only consider direct lights and rely on object masks to reconstruct objects with weak specular reflections. Therefore, these methods fail to reconstruct reflective objects, especially when the object mask is not available and the object is illuminated by indirect lights. We propose a two-step approach to tackle this problem. First, by applying the split-sum approximation and the integrated directional encoding to approximate the shading effects of both direct and indirect lights, we are able to accurately reconstruct the geometry of reflective objects without any object masks. Then, with the object geometry fixed, we use more accurate sampling to recover the environment lights and the BRDF of the object. Extensive experiments demonstrate that our method is capable of accurately reconstructing the geometry and the BRDF of reflective objects from only posed RGB images without knowing the environment lights and the object masks. Codes and datasets are available at https://github.com/liuyuan-pal/NeRO. ",
    "url": "https://arxiv.org/abs/2305.17398",
    "authors": [
      "Yuan Liu",
      "Peng Wang",
      "Cheng Lin",
      "Xiaoxiao Long",
      "Jiepeng Wang",
      "Lingjie Liu",
      "Taku Komura",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2305.17408",
    "title": "AdaptGear: Accelerating GNN Training via Adaptive Subgraph-Level Kernels  on GPUs",
    "abstract": "Graph neural networks (GNNs) are powerful tools for exploring and learning from graph structures and features. As such, achieving high-performance execution for GNNs becomes crucially important. Prior works have proposed to explore the sparsity (i.e., low density) in the input graph to accelerate GNNs, which uses the full-graph-level or block-level sparsity format. We show that they fail to balance the sparsity benefit and kernel execution efficiency. In this paper, we propose a novel system, referred to as AdaptGear, that addresses the challenge of optimizing GNNs performance by leveraging kernels tailored to the density characteristics at the subgraph level. Meanwhile, we also propose a method that dynamically chooses the optimal set of kernels for a given input graph. Our evaluation shows that AdaptGear can achieve a significant performance improvement, up to $6.49 \\times$ ($1.87 \\times$ on average), over the state-of-the-art works on two mainstream NVIDIA GPUs across various datasets. ",
    "url": "https://arxiv.org/abs/2305.17408",
    "authors": [
      "Yangjie Zhou",
      "Yaoxu Song",
      "Jingwen Leng",
      "Zihan Liu",
      "Weihao Cui",
      "Zhendong Zhang",
      "Cong Guo",
      "Quan Chen",
      "Li Li",
      "Minyi Guo"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.17417",
    "title": "Modeling Dynamic Heterogeneous Graph and Node Importance for Future  Citation Prediction",
    "abstract": "Accurate citation count prediction of newly published papers could help editors and readers rapidly figure out the influential papers in the future. Though many approaches are proposed to predict a paper's future citation, most ignore the dynamic heterogeneous graph structure or node importance in academic networks. To cope with this problem, we propose a Dynamic heterogeneous Graph and Node Importance network (DGNI) learning framework, which fully leverages the dynamic heterogeneous graph and node importance information to predict future citation trends of newly published papers. First, a dynamic heterogeneous network embedding module is provided to capture the dynamic evolutionary trends of the whole academic network. Then, a node importance embedding module is proposed to capture the global consistency relationship to figure out each paper's node importance. Finally, the dynamic evolutionary trend embeddings and node importance embeddings calculated above are combined to jointly predict the future citation counts of each paper, by a log-normal distribution model according to multi-faced paper node representations. Extensive experiments on two large-scale datasets demonstrate that our model significantly improves all indicators compared to the SOTA models. ",
    "url": "https://arxiv.org/abs/2305.17417",
    "authors": [
      "Hao Geng",
      "Deqing Wang",
      "Fuzhen Zhuang",
      "Xuehua Ming",
      "Chenguang Du",
      "Ting Jiang",
      "Haolong Guo",
      "Rui Liu"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2305.17420",
    "title": "CCDWT-GAN: Generative Adversarial Networks Based on Color Channel Using  Discrete Wavelet Transform for Document Image Binarization",
    "abstract": "To efficiently extract the textual information from color degraded document images is an important research topic. Long-term imperfect preservation of ancient documents has led to various types of degradation such as page staining, paper yellowing, and ink bleeding; these degradations badly impact the image processing for information extraction. In this paper, we present CCDWT-GAN, a generative adversarial network (GAN) that utilizes the discrete wavelet transform (DWT) on RGB (red, green, blue) channel splited images. The proposed method comprises three stages: image preprocessing, image enhancement, and image binarization. This work conducts comparative experiments in the image preprocessing stage to determine the optimal selection of DWT with normalization. Additionally, we perform an ablation study on the results of the image enhancement stage and the image binarization stage to validate their positive effect on the model performance. This work compares the performance of the proposed method with other state-of-the-art (SOTA) methods on DIBCO and H-DIBCO ((Handwritten) Document Image Binarization Competition) datasets. The experimental results demonstrate that CCDWT-GAN achieves a top two performance on multiple benchmark datasets, and outperforms other SOTA methods. ",
    "url": "https://arxiv.org/abs/2305.17420",
    "authors": [
      "Rui-Yang Ju",
      "Yu-Shian Lin",
      "Jen-Shiun Chiang",
      "Chih-Chia Chen",
      "Wei-Han Chen",
      "Chun-Tse Chien"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17437",
    "title": "GIMM: InfoMin-Max for Automated Graph Contrastive Learning",
    "abstract": "Graph contrastive learning (GCL) shows great potential in unsupervised graph representation learning. Data augmentation plays a vital role in GCL, and its optimal choice heavily depends on the downstream task. Many GCL methods with automated data augmentation face the risk of insufficient information as they fail to preserve the essential information necessary for the downstream task. To solve this problem, we propose InfoMin-Max for automated Graph contrastive learning (GIMM), which prevents GCL from encoding redundant information and losing essential information. GIMM consists of two major modules: (1) automated graph view generator, which acquires the approximation of InfoMin's optimal views through adversarial training without requiring task-relevant information; (2) view comparison, which learns an excellent encoder by applying InfoMax to view representations. To the best of our knowledge, GIMM is the first method that combines the InfoMin and InfoMax principles in GCL. Besides, GIMM introduces randomness to augmentation, thus stabilizing the model against perturbations. Extensive experiments on unsupervised and semi-supervised learning for node and graph classification demonstrate the superiority of our GIMM over state-of-the-art GCL methods with automated and manual data augmentation. ",
    "url": "https://arxiv.org/abs/2305.17437",
    "authors": [
      "Xin Xiong",
      "Furao Shen",
      "Xiangyu Wang",
      "Jian Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17438",
    "title": "On the Importance of Backbone to the Adversarial Robustness of Object  Detectors",
    "abstract": "Object detection is a critical component of various security-sensitive applications, such as autonomous driving and video surveillance. However, existing deep learning-based object detectors are vulnerable to adversarial attacks, which poses a significant challenge to their reliability and safety. Through experiments, we found that existing works on improving the adversarial robustness of object detectors have given a false sense of security. We argue that using adversarially pre-trained backbone networks is essential for enhancing the adversarial robustness of object detectors. We propose a simple yet effective recipe for fast adversarial fine-tuning on object detectors with adversarially pre-trained backbones. Without any modifications to the structure of object detectors, our recipe achieved significantly better adversarial robustness than previous works. Moreover, we explore the potential of different modern object detectors to improve adversarial robustness using our recipe and demonstrate several interesting findings. Our empirical results set a new milestone and deepen the understanding of adversarially robust object detection. Code and trained checkpoints will be publicly available. ",
    "url": "https://arxiv.org/abs/2305.17438",
    "authors": [
      "Xiao Li",
      "Hang Chen",
      "Xiaolin Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.17440",
    "title": "Modeling Adversarial Attack on Pre-trained Language Models as Sequential  Decision Making",
    "abstract": "Pre-trained language models (PLMs) have been widely used to underpin various downstream tasks. However, the adversarial attack task has found that PLMs are vulnerable to small perturbations. Mainstream methods adopt a detached two-stage framework to attack without considering the subsequent influence of substitution at each step. In this paper, we formally model the adversarial attack task on PLMs as a sequential decision-making problem, where the whole attack process is sequential with two decision-making problems, i.e., word finder and word substitution. Considering the attack process can only receive the final state without any direct intermediate signals, we propose to use reinforcement learning to find an appropriate sequential attack path to generate adversaries, named SDM-Attack. Extensive experimental results show that SDM-Attack achieves the highest attack success rate with a comparable modification rate and semantic similarity to attack fine-tuned BERT. Furthermore, our analyses demonstrate the generalization and transferability of SDM-Attack. The code is available at https://github.com/fduxuan/SDM-Attack. ",
    "url": "https://arxiv.org/abs/2305.17440",
    "authors": [
      "Xuanjie Fang",
      "Sijie Cheng",
      "Yang Liu",
      "Wei Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17443",
    "title": "Resilience in Platoons of Cooperative Heterogeneous Vehicles:  Self-organization Strategies and Provably-correct Design",
    "abstract": "This work proposes provably-correct self-organizing strategies for platoons of heterogeneous vehicles. We refer to self-organization as the capability of a platoon to autonomously homogenize to a common group behavior. We show that self-organization promotes resilience to acceleration limits and communication failures, i.e., homogenizing to a common group behavior makes the platoon recover from these causes of impairments. In the presence of acceleration limits, resilience is achieved by self-organizing to a common constrained group behavior that prevents the vehicles from hitting their acceleration limits. In the presence of communication failures, resilience is achieved by self-organizing to a common group observer to estimate the missing information. Stability of the self-organization mechanism is studied analytically, and correctness with respect to traffic actions (e.g. emergency braking, cut-in, merging) is realized through a provably-correct safety layer. Numerical validations via the platooning toolbox OpenCDA in CARLA and via the CommonRoad platform confirm improved performance through self-organization and the provably-correct safety layer. ",
    "url": "https://arxiv.org/abs/2305.17443",
    "authors": [
      "Di Liu",
      "Sebastian Mair",
      "Kang Yang",
      "Simone Baldi",
      "Paolo Frasca",
      "Matthias Althoff"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.17449",
    "title": "FishEye8K: A Benchmark and Dataset for Fisheye Camera Object Detection",
    "abstract": "With the advance of AI, road object detection has been a prominent topic in computer vision, mostly using perspective cameras. Fisheye lens provides omnidirectional wide coverage for using fewer cameras to monitor road intersections, however with view distortions. To our knowledge, there is no existing open dataset prepared for traffic surveillance on fisheye cameras. This paper introduces an open FishEye8K benchmark dataset for road object detection tasks, which comprises 157K bounding boxes across five classes (Pedestrian, Bike, Car, Bus, and Truck). In addition, we present benchmark results of State-of-The-Art (SoTA) models, including variations of YOLOv5, YOLOR, YOLO7, and YOLOv8. The dataset comprises 8,000 images recorded in 22 videos using 18 fisheye cameras for traffic monitoring in Hsinchu, Taiwan, at resolutions of 1080$\\times$1080 and 1280$\\times$1280. The data annotation and validation process were arduous and time-consuming, due to the ultra-wide panoramic and hemispherical fisheye camera images with large distortion and numerous road participants, particularly people riding scooters. To avoid bias, frames from a particular camera were assigned to either the training or test sets, maintaining a ratio of about 70:30 for both the number of images and bounding boxes in each class. Experimental results show that YOLOv8 and YOLOR outperform on input sizes 640$\\times$640 and 1280$\\times$1280, respectively. The dataset will be available on GitHub with PASCAL VOC, MS COCO, and YOLO annotation formats. The FishEye8K benchmark will provide significant contributions to the fisheye video analytics and smart city applications. ",
    "url": "https://arxiv.org/abs/2305.17449",
    "authors": [
      "Munkhjargal Gochoo",
      "Munkh-Erdene Otgonbold",
      "Erkhembayar Ganbold",
      "Jun-Wei Hsieh",
      "Ming-Ching Chang",
      "Ping-Yang Chen",
      "Byambaa Dorj",
      "Hamad Al Jassmi",
      "Ganzorig Batnasan",
      "Fady Alnajjar",
      "Mohammed Abduljabbar",
      "Fang-Pang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17476",
    "title": "Toward Understanding Generative Data Augmentation",
    "abstract": "Generative data augmentation, which scales datasets by obtaining fake labeled examples from a trained conditional generative model, boosts classification performance in various learning tasks including (semi-)supervised learning, few-shot learning, and adversarially robust learning. However, little work has theoretically investigated the effect of generative data augmentation. To fill this gap, we establish a general stability bound in this not independently and identically distributed (non-i.i.d.) setting, where the learned distribution is dependent on the original train set and generally not the same as the true distribution. Our theoretical result includes the divergence between the learned distribution and the true distribution. It shows that generative data augmentation can enjoy a faster learning rate when the order of divergence term is $o(\\max\\left( \\log(m)\\beta_m, 1 / \\sqrt{m})\\right)$, where $m$ is the train set size and $\\beta_m$ is the corresponding stability constant. We further specify the learning setup to the Gaussian mixture model and generative adversarial nets. We prove that in both cases, though generative data augmentation does not enjoy a faster learning rate, it can improve the learning guarantees at a constant level when the train set is small, which is significant when the awful overfitting occurs. Simulation results on the Gaussian mixture model and empirical results on generative adversarial nets support our theoretical conclusions. Our code is available at https://github.com/ML-GSAI/Understanding-GDA. ",
    "url": "https://arxiv.org/abs/2305.17476",
    "authors": [
      "Chenyu Zheng",
      "Guoqiang Wu",
      "Chongxuan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.17479",
    "title": "Inferring Causal Effects Under Heterogeneous Peer Influence",
    "abstract": "Causal inference in networks should account for interference, which occurs when a unit's outcome is influenced by treatments or outcomes of peers. There can be heterogeneous peer influence between units when a unit's outcome is subjected to variable influence from different peers based on their attributes and relationships, or when each unit has a different susceptibility to peer influence. Existing solutions to causal inference under interference consider either homogeneous influence from peers or specific heterogeneous influence mechanisms (e.g., based on local neighborhood structure). This paper presents a methodology for estimating individual causal effects in the presence of heterogeneous peer influence due to arbitrary mechanisms. We propose a structural causal model for networks that can capture arbitrary assumptions about network structure, interference conditions, and causal dependence. We identify potential heterogeneous contexts using the causal model and propose a novel graph neural network-based estimator to estimate individual causal effects. We show that existing state-of-the-art methods for individual causal effect estimation produce biased results in the presence of heterogeneous peer influence, and that our proposed estimator is robust. ",
    "url": "https://arxiv.org/abs/2305.17479",
    "authors": [
      "Shishir Adhikari",
      "Elena Zheleva"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.17480",
    "title": "A Match Made in Heaven: A Multi-task Framework for Hyperbole and  Metaphor Detection",
    "abstract": "Hyperbole and metaphor are common in day-to-day communication (e.g., \"I am in deep trouble\": how does trouble have depth?), which makes their detection important, especially in a conversational AI setting. Existing approaches to automatically detect metaphor and hyperbole have studied these language phenomena independently, but their relationship has hardly, if ever, been explored computationally. In this paper, we propose a multi-task deep learning framework to detect hyperbole and metaphor simultaneously. We hypothesize that metaphors help in hyperbole detection, and vice-versa. To test this hypothesis, we annotate two hyperbole datasets- HYPO and HYPO-L- with metaphor labels. Simultaneously, we annotate two metaphor datasets- TroFi and LCC- with hyperbole labels. Experiments using these datasets give an improvement of the state of the art of hyperbole detection by 12%. Additionally, our multi-task learning (MTL) approach shows an improvement of up to 17% over single-task learning (STL) for both hyperbole and metaphor detection, supporting our hypothesis. To the best of our knowledge, ours is the first demonstration of computational leveraging of linguistic intimacy between metaphor and hyperbole, leading to showing the superiority of MTL over STL for hyperbole and metaphor detection. ",
    "url": "https://arxiv.org/abs/2305.17480",
    "authors": [
      "Naveen Badathala",
      "Abisek Rajakumar Kalarani",
      "Tejpalsingh Siledar",
      "Pushpak Bhattacharyya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17497",
    "title": "FACTUAL: A Benchmark for Faithful and Consistent Textual Scene Graph  Parsing",
    "abstract": "Textual scene graph parsing has become increasingly important in various vision-language applications, including image caption evaluation and image retrieval. However, existing scene graph parsers that convert image captions into scene graphs often suffer from two types of errors. First, the generated scene graphs fail to capture the true semantics of the captions or the corresponding images, resulting in a lack of faithfulness. Second, the generated scene graphs have high inconsistency, with the same semantics represented by different annotations. To address these challenges, we propose a novel dataset, which involves re-annotating the captions in Visual Genome (VG) using a new intermediate representation called FACTUAL-MR. FACTUAL-MR can be directly converted into faithful and consistent scene graph annotations. Our experimental results clearly demonstrate that the parser trained on our dataset outperforms existing approaches in terms of faithfulness and consistency. This improvement leads to a significant performance boost in both image caption evaluation and zero-shot image retrieval tasks. Furthermore, we introduce a novel metric for measuring scene graph similarity, which, when combined with the improved scene graph parser, achieves state-of-the-art (SOTA) results on multiple benchmark datasets for the aforementioned tasks. The code and dataset are available at https://github.com/zhuang-li/FACTUAL . ",
    "url": "https://arxiv.org/abs/2305.17497",
    "authors": [
      "Zhuang Li",
      "Yuyang Chai",
      "Terry Zhuo Yue",
      "Lizhen Qu",
      "Gholamreza Haffari",
      "Fei Li",
      "Donghong Ji",
      "Quan Hung Tran"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17506",
    "title": "Backdooring Neural Code Search",
    "abstract": "Reusing off-the-shelf code snippets from online repositories is a common practice, which significantly enhances the productivity of software developers. To find desired code snippets, developers resort to code search engines through natural language queries. Neural code search models are hence behind many such engines. These models are based on deep learning and gain substantial attention due to their impressive performance. However, the security aspect of these models is rarely studied. Particularly, an adversary can inject a backdoor in neural code search models, which return buggy or even vulnerable code with security/privacy issues. This may impact the downstream software (e.g., stock trading systems and autonomous driving) and cause financial loss and/or life-threatening incidents. In this paper, we demonstrate such attacks are feasible and can be quite stealthy. By simply modifying one variable/function name, the attacker can make buggy/vulnerable code rank in the top 11%. Our attack BADCODE features a special trigger generation and injection procedure, making the attack more effective and stealthy. The evaluation is conducted on two neural code search models and the results show our attack outperforms baselines by 60%. Our user study demonstrates that our attack is more stealthy than the baseline by two times based on the F1 score. ",
    "url": "https://arxiv.org/abs/2305.17506",
    "authors": [
      "Weisong Sun",
      "Yuchen Chen",
      "Guanhong Tao",
      "Chunrong Fang",
      "Xiangyu Zhang",
      "Quanjun Zhang",
      "Bin Luo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17510",
    "title": "A Hybrid Quantum-Classical Approach based on the Hadamard Transform for  the Convolutional Layer",
    "abstract": "In this paper, we propose a novel Hadamard Transform (HT)-based neural network layer for hybrid quantum-classical computing. It implements the regular convolutional layers in the Hadamard transform domain. The idea is based on the HT convolution theorem which states that the dyadic convolution between two vectors is equivalent to the element-wise multiplication of their HT representation. Computing the HT is simply the application of a Hadamard gate to each qubit individually, so the HT computations of our proposed layer can be implemented on a quantum computer. Compared to the regular Conv2D layer, the proposed HT-perceptron layer is computationally more efficient. Compared to a CNN with the same number of trainable parameters and 99.26\\% test accuracy, our HT network reaches 99.31\\% test accuracy with 57.1\\% MACs reduced in the MNIST dataset; and in our ImageNet-1K experiments, our HT-based ResNet-50 exceeds the accuracy of the baseline ResNet-50 by 0.59\\% center-crop top-1 accuracy using 11.5\\% fewer parameters with 12.6\\% fewer MACs. ",
    "url": "https://arxiv.org/abs/2305.17510",
    "authors": [
      "Hongyi Pan",
      "Xin Zhu",
      "Salih Atici",
      "Ahmet Enis Cetin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.17522",
    "title": "Deep Learning based Fingerprint Presentation Attack Detection: A  Comprehensive Survey",
    "abstract": "The vulnerabilities of fingerprint authentication systems have raised security concerns when adapting them to highly secure access-control applications. Therefore, Fingerprint Presentation Attack Detection (FPAD) methods are essential for ensuring reliable fingerprint authentication. Owing to the lack of generation capacity of traditional handcrafted based approaches, deep learning-based FPAD has become mainstream and has achieved remarkable performance in the past decade. Existing reviews have focused more on hand-cratfed rather than deep learning-based methods, which are outdated. To stimulate future research, we will concentrate only on recent deep-learning-based FPAD methods. In this paper, we first briefly introduce the most common Presentation Attack Instruments (PAIs) and publicly available fingerprint Presentation Attack (PA) datasets. We then describe the existing deep-learning FPAD by categorizing them into contact, contactless, and smartphone-based approaches. Finally, we conclude the paper by discussing the open challenges at the current stage and emphasizing the potential future perspective. ",
    "url": "https://arxiv.org/abs/2305.17522",
    "authors": [
      "Hailin Li",
      "Raghavendra Ramachandra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17524",
    "title": "Secure and Privacy-preserving Network Slicing in 3GPP 5G System  Architecture",
    "abstract": "Network slicing in 3GPP 5G system architecture has introduced significant improvements in the flexibility and efficiency of mobile communication. However, this new functionality poses challenges in maintaining the privacy of mobile users, especially in multi-hop environments. In this paper, we propose a secure and privacy-preserving network slicing protocol (SPNS) that combines 5G network slicing and onion routing to address these challenges and provide secure and efficient communication. Our approach enables mobile users to select network slices while incorporating measures to prevent curious RAN nodes or external attackers from accessing full slice information. Additionally, we ensure that the 5G core network can authenticate all RANs, while avoiding reliance on a single RAN for service provision. Besides, SPNS implements end-to-end encryption for data transmission within the network slices, providing an extra layer of privacy and security. Finally, we conducted extensive experiments to evaluate the time cost of establishing network slice links under varying conditions. SPNS provides a promising solution for enhancing the privacy and security of communication in 5G networks. ",
    "url": "https://arxiv.org/abs/2305.17524",
    "authors": [
      "Xiangman Li",
      "Miao He",
      "Jianbing Ni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.17528",
    "title": "Two Heads are Better than One: Towards Better Adversarial Robustness by  Combining Transduction and Rejection",
    "abstract": "Both transduction and rejection have emerged as important techniques for defending against adversarial perturbations. A recent work by Tram\\`er showed that, in the rejection-only case (no transduction), a strong rejection-solution can be turned into a strong (but computationally inefficient) non-rejection solution. This detector-to-classifier reduction has been mostly applied to give evidence that certain claims of strong selective-model solutions are susceptible, leaving the benefits of rejection unclear. On the other hand, a recent work by Goldwasser et al. showed that rejection combined with transduction can give provable guarantees (for certain problems) that cannot be achieved otherwise. Nevertheless, under recent strong adversarial attacks (GMSA, which has been shown to be much more effective than AutoAttack against transduction), Goldwasser et al.'s work was shown to have low performance in a practical deep-learning setting. In this paper, we take a step towards realizing the promise of transduction+rejection in more realistic scenarios. Theoretically, we show that a novel application of Tram\\`er's classifier-to-detector technique in the transductive setting can give significantly improved sample-complexity for robust generalization. While our theoretical construction is computationally inefficient, it guides us to identify an efficient transductive algorithm to learn a selective model. Extensive experiments using state of the art attacks (AutoAttack, GMSA) show that our solutions provide significantly better robust accuracy. ",
    "url": "https://arxiv.org/abs/2305.17528",
    "authors": [
      "Nils Palumbo",
      "Yang Guo",
      "Xi Wu",
      "Jiefeng Chen",
      "Yingyu Liang",
      "Somesh Jha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.17537",
    "title": "Modeling Dynamic Environments with Scene Graph memory",
    "abstract": "Embodied AI agents that search for objects in large environments such as households often need to make efficient decisions by predicting object locations based on partial information. We pose this as a new type of link prediction problem: link prediction on partially observable dynamic graphs. Our graph is a representation of a scene in which rooms and objects are nodes, and their relationships are encoded in the edges; only parts of the changing graph are known to the agent at each timestep. This partial observability poses a challenge to existing link prediction approaches, which we address. We propose a novel state representation -- Scene Graph Memory (SGM) -- with captures the agent's accumulated set of observations, as well as a neural net architecture called a Node Edge Predictor (NEP) that extracts information from the SGM to search efficiently. We evaluate our method in the Dynamic House Simulator, a new benchmark that creates diverse dynamic graphs following the semantic patterns typically seen at homes, and show that NEP can be trained to predict the locations of objects in a variety of environments with diverse object movement dynamics, outperforming baselines both in terms of new scene adaptability and overall accuracy. The codebase and more can be found at https://www.scenegraphmemory.com. ",
    "url": "https://arxiv.org/abs/2305.17537",
    "authors": [
      "Andrey Kurenkov",
      "Michael Lingelbach",
      "Tanmay Agarwal",
      "Chengshu Li",
      "Emily Jin",
      "Ruohan Zhang",
      "Fei-Fei Li",
      "Jiajun Wu",
      "Silvio Savarese",
      "Roberto Mart\u00edn-Mart\u00edn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17542",
    "title": "Non-Sequential Graph Script Induction via Multimedia Grounding",
    "abstract": "Online resources such as WikiHow compile a wide range of scripts for performing everyday tasks, which can assist models in learning to reason about procedures. However, the scripts are always presented in a linear manner, which does not reflect the flexibility displayed by people executing tasks in real life. For example, in the CrossTask Dataset, 64.5% of consecutive step pairs are also observed in the reverse order, suggesting their ordering is not fixed. In addition, each step has an average of 2.56 frequent next steps, demonstrating \"branching\". In this paper, we propose the new challenging task of non-sequential graph script induction, aiming to capture optional and interchangeable steps in procedural planning. To automate the induction of such graph scripts for given tasks, we propose to take advantage of loosely aligned videos of people performing the tasks. In particular, we design a multimodal framework to ground procedural videos to WikiHow textual steps and thus transform each video into an observed step path on the latent ground truth graph script. This key transformation enables us to train a script knowledge model capable of both generating explicit graph scripts for learnt tasks and predicting future steps given a partial step sequence. Our best model outperforms the strongest pure text/vision baselines by 17.52% absolute gains on F1@3 for next step prediction and 13.8% absolute gains on Acc@1 for partial sequence completion. Human evaluation shows our model outperforming the WikiHow linear baseline by 48.76% absolute gains in capturing sequential and non-sequential step relationships. ",
    "url": "https://arxiv.org/abs/2305.17542",
    "authors": [
      "Yu Zhou",
      "Sha Li",
      "Manling Li",
      "Xudong Lin",
      "Shih-Fu Chang",
      "Mohit Bansal",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2305.17556",
    "title": "Scheduling Fork-Join Task Graphs to Heterogeneous Processors",
    "abstract": "The scheduling of task graphs with communication delays has been extensively studied. Recently, new results for the common sub-case of fork-join shaped task graphs were published, including an EPTAS and polynomial algorithms for special cases. These new results modelled the target architecture to consist of homogeneous processors. However, forms of heterogeneity become more and more common in contemporary parallel systems, such as CPU--accelerator systems, with their two types of resources. In this work, we study the scheduling of fork-join task graphs with communication delays, which is representative of highly parallel workloads, onto heterogeneous systems of related processors. We present an EPAS, and some polynomial time algorithms for special cases, such as with equal processing costs or unlimited resources. Lastly, we briefly look at the above described case of two resource-types and its implications. It is interesting to note, that all results here also apply to scheduling independent tasks with release times and deadlines. ",
    "url": "https://arxiv.org/abs/2305.17556",
    "authors": [
      "Huijun Wang",
      "Oliver Sinnen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2305.17565",
    "title": "Self-Supervised Learning of Action Affordances as Interaction Modes",
    "abstract": "When humans perform a task with an articulated object, they interact with the object only in a handful of ways, while the space of all possible interactions is nearly endless. This is because humans have prior knowledge about what interactions are likely to be successful, i.e., to open a new door we first try the handle. While learning such priors without supervision is easy for humans, it is notoriously hard for machines. In this work, we tackle unsupervised learning of priors of useful interactions with articulated objects, which we call interaction modes. In contrast to the prior art, we use no supervision or privileged information; we only assume access to the depth sensor in the simulator to learn the interaction modes. More precisely, we define a successful interaction as the one changing the visual environment substantially and learn a generative model of such interactions, that can be conditioned on the desired goal state of the object. In our experiments, we show that our model covers most of the human interaction modes, outperforms existing state-of-the-art methods for affordance learning, and can generalize to objects never seen during training. Additionally, we show promising results in the goal-conditional setup, where our model can be quickly fine-tuned to perform a given task. We show in the experiments that such affordance learning predicts interaction which covers most modes of interaction for the querying articulated object and can be fine-tuned to a goal-conditional model. For supplementary: https://actaim.github.io. ",
    "url": "https://arxiv.org/abs/2305.17565",
    "authors": [
      "Liquan Wang",
      "Nikita Dvornik",
      "Rafael Dubeau",
      "Mayank Mittal",
      "Animesh Garg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.17589",
    "title": "Graph Inductive Biases in Transformers without Message Passing",
    "abstract": "Transformers for graph data are increasingly widely studied and successful in numerous learning tasks. Graph inductive biases are crucial for Graph Transformers, and previous works incorporate them using message-passing modules and/or positional encodings. However, Graph Transformers that use message-passing inherit known issues of message-passing, and differ significantly from Transformers used in other domains, thus making transfer of research advances more difficult. On the other hand, Graph Transformers without message-passing often perform poorly on smaller datasets, where inductive biases are more crucial. To bridge this gap, we propose the Graph Inductive bias Transformer (GRIT) -- a new Graph Transformer that incorporates graph inductive biases without using message passing. GRIT is based on several architectural changes that are each theoretically and empirically justified, including: learned relative positional encodings initialized with random walk probabilities, a flexible attention mechanism that updates node and node-pair representations, and injection of degree information in each layer. We prove that GRIT is expressive -- it can express shortest path distances and various graph propagation matrices. GRIT achieves state-of-the-art empirical performance across a variety of graph datasets, thus showing the power that Graph Transformers without message-passing can deliver. ",
    "url": "https://arxiv.org/abs/2305.17589",
    "authors": [
      "Liheng Ma",
      "Chen Lin",
      "Derek Lim",
      "Adriana Romero-Soriano",
      "Puneet K. Dokania",
      "Mark Coates",
      "Philip Torr",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17598",
    "title": "Overlapping and Robust Edge-Colored Clustering in Hypergraphs",
    "abstract": "A recent trend in data mining has explored (hyper)graph clustering algorithms for data with categorical relationship types. Such algorithms have applications in the analysis of social, co-authorship, and protein interaction networks, to name a few. Many such applications naturally have some overlap between clusters, a nuance which is missing from current combinatorial models. Additionally, existing models lack a mechanism for handling noise in datasets. We address these concerns by generalizing Edge-Colored Clustering, a recent framework for categorical clustering of hypergraphs. Our generalizations allow for a budgeted number of either (a) overlapping cluster assignments or (b) node deletions. For each new model we present a greedy algorithm which approximately minimizes an edge mistake objective, as well as bicriteria approximations where the second approximation factor is on the budget. Additionally, we address the parameterized complexity of each problem, providing FPT algorithms and hardness results. ",
    "url": "https://arxiv.org/abs/2305.17598",
    "authors": [
      "Alex Crane",
      "Brian Lavallee",
      "Blair D. Sullivan",
      "Nate Veldt"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2305.17600",
    "title": "GAME-UP: Game-Aware Mode Enumeration and Understanding for Trajectory  Prediction",
    "abstract": "Interactions between road agents present a significant challenge in trajectory prediction, especially in cases involving multiple agents. Because existing diversity-aware predictors do not account for the interactive nature of multi-agent predictions, they may miss these important interaction outcomes. In this paper, we propose GAME-UP, a framework for trajectory prediction that leverages game-theoretic inverse reinforcement learning to improve coverage of multi-modal predictions. We use a training-time game-theoretic numerical analysis as an auxiliary loss resulting in improved coverage and accuracy without presuming a taxonomy of actions for the agents. We demonstrate our approach on the interactive subset of Waymo Open Motion Dataset, including three subsets involving scenarios with high interaction complexity. Experiment results show that our predictor produces accurate predictions while covering twice as many possible interactions versus a baseline model. ",
    "url": "https://arxiv.org/abs/2305.17600",
    "authors": [
      "Justin Lidard",
      "Oswin So",
      "Yanxia Zhang",
      "Jonathan DeCastro",
      "Xiongyi Cui",
      "Xin Huang",
      "Yen-Ling Kuo",
      "John Leonard",
      "Avinash Balachandran",
      "Naomi Leonard",
      "Guy Rosman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computer Science and Game Theory (cs.GT)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2305.17624",
    "title": "SimpSON: Simplifying Photo Cleanup with Single-Click Distracting Object  Segmentation Network",
    "abstract": "In photo editing, it is common practice to remove visual distractions to improve the overall image quality and highlight the primary subject. However, manually selecting and removing these small and dense distracting regions can be a laborious and time-consuming task. In this paper, we propose an interactive distractor selection method that is optimized to achieve the task with just a single click. Our method surpasses the precision and recall achieved by the traditional method of running panoptic segmentation and then selecting the segments containing the clicks. We also showcase how a transformer-based module can be used to identify more distracting regions similar to the user's click position. Our experiments demonstrate that the model can effectively and accurately segment unknown distracting objects interactively and in groups. By significantly simplifying the photo cleaning and retouching process, our proposed model provides inspiration for exploring rare object segmentation and group selection with a single click. ",
    "url": "https://arxiv.org/abs/2305.17624",
    "authors": [
      "Chuong Huynh",
      "Yuqian Zhou",
      "Zhe Lin",
      "Connelly Barnes",
      "Eli Shechtman",
      "Sohrab Amirghodsi",
      "Abhinav Shrivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17627",
    "title": "Robust Natural Language Understanding with Residual Attention Debiasing",
    "abstract": "Natural language understanding (NLU) models often suffer from unintended dataset biases. Among bias mitigation methods, ensemble-based debiasing methods, especially product-of-experts (PoE), have stood out for their impressive empirical success. However, previous ensemble-based debiasing methods typically apply debiasing on top-level logits without directly addressing biased attention patterns. Attention serves as the main media of feature interaction and aggregation in PLMs and plays a crucial role in providing robust prediction. In this paper, we propose REsidual Attention Debiasing (READ), an end-to-end debiasing method that mitigates unintended biases from attention. Experiments on three NLU tasks show that READ significantly improves the performance of BERT-based models on OOD data with shortcuts removed, including +12.9% accuracy on HANS, +11.0% accuracy on FEVER-Symmetric, and +2.7% F1 on PAWS. Detailed analyses demonstrate the crucial role of unbiased attention in robust NLU models and that READ effectively mitigates biases in attention. Code is available at https://github.com/luka-group/READ. ",
    "url": "https://arxiv.org/abs/2305.17627",
    "authors": [
      "Fei Wang",
      "James Y. Huang",
      "Tianyi Yan",
      "Wenxuan Zhou",
      "Muhao Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.17650",
    "title": "Evolving Connectivity for Recurrent Spiking Neural Networks",
    "abstract": "Recurrent spiking neural networks (RSNNs) hold great potential for advancing artificial general intelligence, as they draw inspiration from the biological nervous system and show promise in modeling complex dynamics. However, the widely-used surrogate gradient-based training methods for RSNNs are inherently inaccurate and unfriendly to neuromorphic hardware. To address these limitations, we propose the evolving connectivity (EC) framework, an inference-only method for training RSNNs. The EC framework reformulates weight-tuning as a search into parameterized connection probability distributions, and employs Natural Evolution Strategies (NES) for optimizing these distributions. Our EC framework circumvents the need for gradients and features hardware-friendly characteristics, including sparse boolean connections and high scalability. We evaluate EC on a series of standard robotic locomotion tasks, where it achieves comparable performance with deep neural networks and outperforms gradient-trained RSNNs, even solving the complex 17-DoF humanoid task. Additionally, the EC framework demonstrates a two to three fold speedup in efficiency compared to directly evolving parameters. By providing a performant and hardware-friendly alternative, the EC framework lays the groundwork for further energy-efficient applications of RSNNs and advances the development of neuromorphic devices. ",
    "url": "https://arxiv.org/abs/2305.17650",
    "authors": [
      "Guan Wang",
      "Yuhao Sun",
      "Sijie Cheng",
      "Sen Song"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.17651",
    "title": "DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech  Models",
    "abstract": "Self-supervised learning (SSL) has achieved notable success in many speech processing tasks, but the large model size and heavy computational cost hinder the deployment. Knowledge distillation trains a small student model to mimic the behavior of a large teacher model. However, the student architecture usually needs to be manually designed and will remain fixed during training, which requires prior knowledge and can lead to suboptimal performance. Inspired by recent success of task-specific structured pruning, we propose DPHuBERT, a novel task-agnostic compression method for speech SSL based on joint distillation and pruning. Experiments on SUPERB show that DPHuBERT outperforms pure distillation methods in almost all tasks. Moreover, DPHuBERT requires little training time and performs well with limited training data, making it suitable for resource-constrained applications. Our method can also be applied to various speech SSL models. Our code and models will be publicly available. ",
    "url": "https://arxiv.org/abs/2305.17651",
    "authors": [
      "Yifan Peng",
      "Yui Sudo",
      "Shakeel Muhammad",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.17652",
    "title": "ConaCLIP: Exploring Distillation of Fully-Connected Knowledge  Interaction Graph for Lightweight Text-Image Retrieval",
    "abstract": "Large-scale pre-trained text-image models with dual-encoder architectures (such as CLIP) are typically adopted for various vision-language applications, including text-image retrieval. However,these models are still less practical on edge devices or for real-time situations, due to the substantial indexing and inference time and the large consumption of computational resources. Although knowledge distillation techniques have been widely utilized for uni-modal model compression, how to expand them to the situation when the numbers of modalities and teachers/students are doubled has been rarely studied. In this paper, we conduct comprehensive experiments on this topic and propose the fully-Connected knowledge interaction graph (Cona) technique for cross-modal pre-training distillation. Based on our findings, the resulting ConaCLIP achieves SOTA performances on the widely-used Flickr30K and MSCOCO benchmarks under the lightweight setting. An industry application of our method on an e-commercial platform further demonstrates the significant effectiveness of ConaCLIP. ",
    "url": "https://arxiv.org/abs/2305.17652",
    "authors": [
      "Jiapeng Wang",
      "Chengyu Wang",
      "Xiaodan Wang",
      "Jun Huang",
      "Lianwen Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17653",
    "title": "Prompt-Guided Retrieval Augmentation for Non-Knowledge-Intensive Tasks",
    "abstract": "Retrieval-augmented methods have received increasing attention to support downstream tasks by leveraging useful information from external resources. Recent studies mainly focus on exploring retrieval to solve knowledge-intensive (KI) tasks. However, the potential of retrieval for most non-knowledge-intensive (NKI) tasks remains under-explored. There are two main challenges to leveraging retrieval-augmented methods for NKI tasks: 1) the demand for diverse relevance score functions and 2) the dilemma between training cost and task performance. To address these challenges, we propose a two-stage framework for NKI tasks, named PGRA. In the first stage, we adopt a task-agnostic retriever to build a shared static index and select candidate evidence efficiently. In the second stage, we design a prompt-guided reranker to rerank the nearest evidence according to task-specific relevance for the reader. Experimental results show that PGRA outperforms other state-of-the-art retrieval-augmented methods. Our analyses further investigate the influence factors to model performance and demonstrate the generality of PGRA. Codes are available at https://github.com/THUNLP-MT/PGRA. ",
    "url": "https://arxiv.org/abs/2305.17653",
    "authors": [
      "Zhicheng Guo",
      "Sijie Cheng",
      "Yile Wang",
      "Peng Li",
      "Yang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17654",
    "title": "MixDehazeNet : Mix Structure Block For Image Dehazing Network",
    "abstract": "Image dehazing is a typical task in the low-level vision field. Previous studies verified the effectiveness of the large convolutional kernel and attention mechanism in dehazing. However, there are two drawbacks: the multi-scale properties of an image are readily ignored when a large convolutional kernel is introduced, and the standard series connection of an attention module does not sufficiently consider an uneven hazy distribution. In this paper, we propose a novel framework named Mix Structure Image Dehazing Network (MixDehazeNet), which solves two issues mentioned above. Specifically, it mainly consists of two parts: the multi-scale parallel large convolution kernel module and the enhanced parallel attention module. Compared with a single large kernel, parallel large kernels with multi-scale are more capable of taking partial texture into account during the dehazing phase. In addition, an enhanced parallel attention module is developed, in which parallel connections of attention perform better at dehazing uneven hazy distribution. Extensive experiments on three benchmarks demonstrate the effectiveness of our proposed methods. For example, compared with the previous state-of-the-art methods, MixDehazeNet achieves a significant improvement (42.62dB PSNR) on the SOTS indoor dataset. The code is released in https://github.com/AmeryXiong/MixDehazeNet. ",
    "url": "https://arxiv.org/abs/2305.17654",
    "authors": [
      "LiPing Lu",
      "Qian Xiong",
      "DuanFeng Chu",
      "BingRong Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17666",
    "title": "Assessing Network Operator Actions to Enhance Digital Sovereignty and  Strengthen Network Resilience: A Longitudinal Analysis during the  Russia-Ukraine Conflict",
    "abstract": "We conduct longitudinal and temporal analyses on active DNS measurement data to investigate how the Russia-Ukraine conflict impacted the network infrastructures supporting domain names under ICANN's CZDS new gTLDs. Our findings revealed changes in the physical locations of network infrastructures, utilization of managed DNS services, infrastructure redundancy, and distribution, which started right after the first reported Russian military movements in February 2022. We also found that domains from different countries had varying location preferences when moving their hosting infrastructure. These observed changes suggest that network operators took proactive measures in anticipation of an armed conflict to promote resilience and protect the sovereignty of their networks in response to the conflict. ",
    "url": "https://arxiv.org/abs/2305.17666",
    "authors": [
      "Muhammad Yasir Muzayan Haq",
      "Abhishta Abhishta",
      "Raffaele Sommese",
      "Mattijs Jonker",
      "Lambert J.M. Nieuwenhuis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.17677",
    "title": "BFRT: Blockchained Federated Learning for Real-time Traffic Flow  Prediction",
    "abstract": "Accurate real-time traffic flow prediction can be leveraged to relieve traffic congestion and associated negative impacts. The existing centralized deep learning methodologies have demonstrated high prediction accuracy, but suffer from privacy concerns due to the sensitive nature of transportation data. Moreover, the emerging literature on traffic prediction by distributed learning approaches, including federated learning, primarily focuses on offline learning. This paper proposes BFRT, a blockchained federated learning architecture for online traffic flow prediction using real-time data and edge computing. The proposed approach provides privacy for the underlying data, while enabling decentralized model training in real-time at the Internet of Vehicles edge. We federate GRU and LSTM models and conduct extensive experiments with dynamically collected arterial traffic data shards. We prototype the proposed permissioned blockchain network on Hyperledger Fabric and perform extensive tests using virtual machines to simulate the edge nodes. Experimental results outperform the centralized models, highlighting the feasibility of our approach for facilitating privacy-preserving and decentralized real-time traffic flow prediction. ",
    "url": "https://arxiv.org/abs/2305.17677",
    "authors": [
      "Collin Meese",
      "Hang Chen",
      "Syed Ali Asif",
      "Wanxin Li",
      "Chien-Chung Shen",
      "Mark Nejad"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2305.17688",
    "title": "Amplification trojan network: Attack deep neural networks by amplifying  their inherent weakness",
    "abstract": "Recent works found that deep neural networks (DNNs) can be fooled by adversarial examples, which are crafted by adding adversarial noise on clean inputs. The accuracy of DNNs on adversarial examples will decrease as the magnitude of the adversarial noise increase. In this study, we show that DNNs can be also fooled when the noise is very small under certain circumstances. This new type of attack is called Amplification Trojan Attack (ATAttack). Specifically, we use a trojan network to transform the inputs before sending them to the target DNN. This trojan network serves as an amplifier to amplify the inherent weakness of the target DNN. The target DNN, which is infected by the trojan network, performs normally on clean data while being more vulnerable to adversarial examples. Since it only transforms the inputs, the trojan network can hide in DNN-based pipelines, e.g. by infecting the pre-processing procedure of the inputs before sending them to the DNNs. This new type of threat should be considered in developing safe DNNs. ",
    "url": "https://arxiv.org/abs/2305.17688",
    "authors": [
      "Zhanhao Hu",
      "Jun Zhu",
      "Bo Zhang",
      "Xiaolin Hu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17695",
    "title": "k-NNN: Nearest Neighbors of Neighbors for Anomaly Detection",
    "abstract": "Anomaly detection aims at identifying images that deviate significantly from the norm. We focus on algorithms that embed the normal training examples in space and when given a test image, detect anomalies based on the features distance to the k-nearest training neighbors. We propose a new operator that takes into account the varying structure & importance of the features in the embedding space. Interestingly, this is done by taking into account not only the nearest neighbors, but also the neighbors of these neighbors (k-NNN). We show that by simply replacing the nearest neighbor component in existing algorithms by our k-NNN operator, while leaving the rest of the algorithms untouched, each algorithms own results are improved. This is the case both for common homogeneous datasets, such as flowers or nuts of a specific type, as well as for more diverse datasets ",
    "url": "https://arxiv.org/abs/2305.17695",
    "authors": [
      "Ori Nizan",
      "Ayellet Tal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17698",
    "title": "Neural Machine Translation with Dynamic Graph Convolutional Decoder",
    "abstract": "Existing wisdom demonstrates the significance of syntactic knowledge for the improvement of neural machine translation models. However, most previous works merely focus on leveraging the source syntax in the well-known encoder-decoder framework. In sharp contrast, this paper proposes an end-to-end translation architecture from the (graph \\& sequence) structural inputs to the (graph \\& sequence) outputs, where the target translation and its corresponding syntactic graph are jointly modeled and generated. We propose a customized Dynamic Spatial-Temporal Graph Convolutional Decoder (Dyn-STGCD), which is designed for consuming source feature representations and their syntactic graph, and auto-regressively generating the target syntactic graph and tokens simultaneously. We conduct extensive experiments on five widely acknowledged translation benchmarks, verifying that our proposal achieves consistent improvements over baselines and other syntax-aware variants. ",
    "url": "https://arxiv.org/abs/2305.17698",
    "authors": [
      "Lei Li",
      "Kai Fan",
      "Lingyu Yang",
      "Hongjia Li",
      "Chun Yuan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17699",
    "title": "Decoupling Pseudo Label Disambiguation and Representation Learning for  Generalized Intent Discovery",
    "abstract": "Generalized intent discovery aims to extend a closed-set in-domain intent classifier to an open-world intent set including in-domain and out-of-domain intents. The key challenges lie in pseudo label disambiguation and representation learning. Previous methods suffer from a coupling of pseudo label disambiguation and representation learning, that is, the reliability of pseudo labels relies on representation learning, and representation learning is restricted by pseudo labels in turn. In this paper, we propose a decoupled prototype learning framework (DPL) to decouple pseudo label disambiguation and representation learning. Specifically, we firstly introduce prototypical contrastive representation learning (PCL) to get discriminative representations. And then we adopt a prototype-based label disambiguation method (PLD) to obtain pseudo labels. We theoretically prove that PCL and PLD work in a collaborative fashion and facilitate pseudo label disambiguation. Experiments and analysis on three benchmark datasets show the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2305.17699",
    "authors": [
      "Yutao Mou",
      "Xiaoshuai Song",
      "Keqing He",
      "Chen Zeng",
      "Pei Wang",
      "Jingang Wang",
      "Yunsen Xian",
      "Weiran Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17701",
    "title": "KoSBI: A Dataset for Mitigating Social Bias Risks Towards Safer Large  Language Model Application",
    "abstract": "Large language models (LLMs) learn not only natural text generation abilities but also social biases against different demographic groups from real-world data. This poses a critical risk when deploying LLM-based applications. Existing research and resources are not readily applicable in South Korea due to the differences in language and culture, both of which significantly affect the biases and targeted demographic groups. This limitation requires localized social bias datasets to ensure the safe and effective deployment of LLMs. To this end, we present KO SB I, a new social bias dataset of 34k pairs of contexts and sentences in Korean covering 72 demographic groups in 15 categories. We find that through filtering-based moderation, social biases in generated content can be reduced by 16.47%p on average for HyperCLOVA (30B and 82B), and GPT-3. ",
    "url": "https://arxiv.org/abs/2305.17701",
    "authors": [
      "Hwaran Lee",
      "Seokhee Hong",
      "Joonsuk Park",
      "Takyoung Kim",
      "Gunhee Kim",
      "Jung-Woo Ha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17709",
    "title": "Parallel Data Helps Neural Entity Coreference Resolution",
    "abstract": "Coreference resolution is the task of finding expressions that refer to the same entity in a text. Coreference models are generally trained on monolingual annotated data but annotating coreference is expensive and challenging. Hardmeier et al.(2013) have shown that parallel data contains latent anaphoric knowledge, but it has not been explored in end-to-end neural models yet. In this paper, we propose a simple yet effective model to exploit coreference knowledge from parallel data. In addition to the conventional modules learning coreference from annotations, we introduce an unsupervised module to capture cross-lingual coreference knowledge. Our proposed cross-lingual model achieves consistent improvements, up to 1.74 percentage points, on the OntoNotes 5.0 English dataset using 9 different synthetic parallel datasets. These experimental results confirm that parallel data can provide additional coreference knowledge which is beneficial to coreference resolution tasks. ",
    "url": "https://arxiv.org/abs/2305.17709",
    "authors": [
      "Gongbo Tang",
      "Christian Hardmeier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17727",
    "title": "Learning a Structural Causal Model for Intuition Reasoning in  Conversation",
    "abstract": "Reasoning, a crucial aspect of NLP research, has not been adequately addressed by prevailing models including Large Language Model. Conversation reasoning, as a critical component of it, remains largely unexplored due to the absence of a well-designed cognitive model. In this paper, inspired by intuition theory on conversation cognition, we develop a conversation cognitive model (CCM) that explains how each utterance receives and activates channels of information recursively. Besides, we algebraically transformed CCM into a structural causal model (SCM) under some mild assumptions, rendering it compatible with various causal discovery methods. We further propose a probabilistic implementation of the SCM for utterance-level relation reasoning. By leveraging variational inference, it explores substitutes for implicit causes, addresses the issue of their unobservability, and reconstructs the causal representations of utterances through the evidence lower bounds. Moreover, we constructed synthetic and simulated datasets incorporating implicit causes and complete cause labels, alleviating the current situation where all available datasets are implicit-causes-agnostic. Extensive experiments demonstrate that our proposed method significantly outperforms existing methods on synthetic, simulated, and real-world datasets. Finally, we analyze the performance of CCM under latent confounders and propose theoretical ideas for addressing this currently unresolved issue. ",
    "url": "https://arxiv.org/abs/2305.17727",
    "authors": [
      "Hang Chen",
      "Bingyu Liao",
      "Jing Luo",
      "Wenjing Zhu",
      "Xinyu Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17748",
    "title": "Image Hash Minimization for Tamper Detection",
    "abstract": "Tamper detection using image hash is a very common problem of modern days. Several research and advancements have already been done to address this problem. However, most of the existing methods lack the accuracy of tamper detection when the tampered area is low, as well as requiring long image hashes. In this paper, we propose a novel method objectively to minimize the hash length while enhancing the performance at low tampered area. ",
    "url": "https://arxiv.org/abs/2305.17748",
    "authors": [
      "Subhajit Maity",
      "Ram Kumar Karsh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.17749",
    "title": "Bayesian inference and neural estimation of acoustic wave propagation",
    "abstract": "In this work, we introduce a novel framework which combines physics and machine learning methods to analyse acoustic signals. Three methods are developed for this task: a Bayesian inference approach for inferring the spectral acoustics characteristics, a neural-physical model which equips a neural network with forward and backward physical losses, and the non-linear least squares approach which serves as benchmark. The inferred propagation coefficient leads to the room impulse response (RIR) quantity which can be used for relocalisation with uncertainty. The simplicity and efficiency of this framework is empirically validated on simulated data. ",
    "url": "https://arxiv.org/abs/2305.17749",
    "authors": [
      "Yongchao Huang",
      "Yuhang He",
      "Hong Ge"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2305.17750",
    "title": "Reliable and Interpretable Drift Detection in Streams of Short Texts",
    "abstract": "Data drift is the change in model input data that is one of the key factors leading to machine learning models performance degradation over time. Monitoring drift helps detecting these issues and preventing their harmful consequences. Meaningful drift interpretation is a fundamental step towards effective re-training of the model. In this study we propose an end-to-end framework for reliable model-agnostic change-point detection and interpretation in large task-oriented dialog systems, proven effective in multiple customer deployments. We evaluate our approach and demonstrate its benefits with a novel variant of intent classification training dataset, simulating customer requests to a dialog system. We make the data publicly available. ",
    "url": "https://arxiv.org/abs/2305.17750",
    "authors": [
      "Ella Rabinovich",
      "Matan Vetzler",
      "Samuel Ackerman",
      "Ateret Anaby-Tavor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17757",
    "title": "Diversity-seeking Jump Games in Networks",
    "abstract": "Recently, many researchers have studied strategic games inspired by Schelling's influential model of residential segregation. In this model, agents belonging to $k$ different types are placed at the nodes of a network. Agents can be either stubborn, in which case they will always choose their preferred location, or strategic, in which case they aim to maximize the fraction of agents of their own type in their neighborhood. In the so-called Schelling games inspired by this model, strategic agents are assumed to be similarity-seeking: their utility is defined as the fraction of its neighbors of the same type as itself. In this paper, we introduce a new type of strategic jump game in which agents are instead diversity-seeking: the utility of an agent is defined as the fraction of its neighbors that is of a different type than itself. We show that it is NP-hard to determine the existence of an equilibrium in such games, if some agents are stubborn. However, in trees, our diversity-seeking jump game always admits a pure Nash equilibrium, if all agents are strategic. In regular graphs and spider graphs with a single empty node, as well as in all paths, we prove a stronger result: the game is a potential game, that is, improving response dynamics will always converge to a Nash equilibrium from any initial placement of agents. ",
    "url": "https://arxiv.org/abs/2305.17757",
    "authors": [
      "Lata Narayanan",
      "Yasaman Sabbagh"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2305.17763",
    "title": "NeurOCS: Neural NOCS Supervision for Monocular 3D Object Localization",
    "abstract": "Monocular 3D object localization in driving scenes is a crucial task, but challenging due to its ill-posed nature. Estimating 3D coordinates for each pixel on the object surface holds great potential as it provides dense 2D-3D geometric constraints for the underlying PnP problem. However, high-quality ground truth supervision is not available in driving scenes due to sparsity and various artifacts of Lidar data, as well as the practical infeasibility of collecting per-instance CAD models. In this work, we present NeurOCS, a framework that uses instance masks and 3D boxes as input to learn 3D object shapes by means of differentiable rendering, which further serves as supervision for learning dense object coordinates. Our approach rests on insights in learning a category-level shape prior directly from real driving scenes, while properly handling single-view ambiguities. Furthermore, we study and make critical design choices to learn object coordinates more effectively from an object-centric view. Altogether, our framework leads to new state-of-the-art in monocular 3D localization that ranks 1st on the KITTI-Object benchmark among published monocular methods. ",
    "url": "https://arxiv.org/abs/2305.17763",
    "authors": [
      "Zhixiang Min",
      "Bingbing Zhuang",
      "Samuel Schulter",
      "Buyu Liu",
      "Enrique Dunn",
      "Manmohan Chandraker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17770",
    "title": "Point-PC: Point Cloud Completion Guided by Prior Knowledge via Causal  Inference",
    "abstract": "Point cloud completion aims to recover raw point clouds captured by scanners from partial observations caused by occlusion and limited view angles. Many approaches utilize a partial-complete paradigm in which missing parts are directly predicted by a global feature learned from partial inputs. This makes it hard to recover details because the global feature is unlikely to capture the full details of all missing parts. In this paper, we propose a novel approach to point cloud completion called Point-PC, which uses a memory network to retrieve shape priors and designs an effective causal inference model to choose missing shape information as additional geometric information to aid point cloud completion. Specifically, we propose a memory operating mechanism where the complete shape features and the corresponding shapes are stored in the form of ``key-value'' pairs. To retrieve similar shapes from the partial input, we also apply a contrastive learning-based pre-training scheme to transfer features of incomplete shapes into the domain of complete shape features. Moreover, we use backdoor adjustment to get rid of the confounder, which is a part of the shape prior that has the same semantic structure as the partial input. Experimental results on the ShapeNet-55, PCN, and KITTI datasets demonstrate that Point-PC performs favorably against the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2305.17770",
    "authors": [
      "Weizhi Nie",
      "Chuanqi Jiao",
      "Ruidong Chen",
      "Weijie Wang",
      "Bruno Lepri",
      "Nicu Sebe",
      "Anan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17783",
    "title": "Visual Affordance Prediction for Guiding Robot Exploration",
    "abstract": "Motivated by the intuitive understanding humans have about the space of possible interactions, and the ease with which they can generalize this understanding to previously unseen scenes, we develop an approach for learning visual affordances for guiding robot exploration. Given an input image of a scene, we infer a distribution over plausible future states that can be achieved via interactions with it. We use a Transformer-based model to learn a conditional distribution in the latent embedding space of a VQ-VAE and show that these models can be trained using large-scale and diverse passive data, and that the learned models exhibit compositional generalization to diverse objects beyond the training distribution. We show how the trained affordance model can be used for guiding exploration by acting as a goal-sampling distribution, during visual goal-conditioned policy learning in robotic manipulation. ",
    "url": "https://arxiv.org/abs/2305.17783",
    "authors": [
      "Homanga Bharadhwaj",
      "Abhinav Gupta",
      "Shubham Tulsiani"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17797",
    "title": "T2FNorm: Extremely Simple Scaled Train-time Feature Normalization for  OOD Detection",
    "abstract": "Neural networks are notorious for being overconfident predictors, posing a significant challenge to their safe deployment in real-world applications. While feature normalization has garnered considerable attention within the deep learning literature, current train-time regularization methods for Out-of-Distribution(OOD) detection are yet to fully exploit this potential. Indeed, the naive incorporation of feature normalization within neural networks does not guarantee an improvement in OOD detection performance. In this work, we introduce T2FNorm, a novel approach to training neural networks that transforms features to hyperspherical space through normalization, while employing non-transformed space for OOD-scoring purposes. This method yields a surprising enhancement in OOD detection capabilities without compromising model accuracy in in-distribution(ID). Our investigation demonstrates that the proposed technique substantially diminishes the norm of the features of all samples, more so in the case of out-of-distribution samples, thereby addressing the prevalent concern of overconfidence in neural networks. The proposed method also significantly improves various post-hoc OOD detection methods. ",
    "url": "https://arxiv.org/abs/2305.17797",
    "authors": [
      "Sudarshan Regmi",
      "Bibek Panthi",
      "Sakar Dotel",
      "Prashnna K. Gyawali",
      "Danail Stoynov",
      "Binod Bhattarai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17799",
    "title": "I-FENN for thermoelasticity based on physics-informed temporal  convolutional network (PI-TCN)",
    "abstract": "We propose an integrated finite element neural network (I-FENN) framework to expedite the solution of coupled multiphysics problems. A physics-informed temporal convolutional network (PI-TCN) is embedded within the finite element framework to leverage the fast inference of neural networks (NNs). The PI-TCN model captures some of the fields in the multiphysics problem, and their derivatives are calculated via automatic differentiation available in most machine learning platforms. The other fields of interest are computed using the finite element method. We introduce I-FENN for the solution of transient thermoelasticity, where the thermo-mechanical fields are fully coupled. We establish a framework that computationally decouples the energy equation from the linear momentum equation. We first develop a PI-TCN model to predict the temperature field based on the energy equation and available strain data. The PI-TCN model is integrated into the finite element framework, where the PI-TCN output (temperature) is used to introduce the temperature effect to the linear momentum equation. The finite element problem is solved using the implicit Euler time discretization scheme, resulting in a computational cost comparable to that of a weakly-coupled thermoelasticity problem but with the ability to solve fully-coupled problems. Finally, we demonstrate the computational efficiency and generalization capability of I-FENN in thermoelasticity through several numerical examples. ",
    "url": "https://arxiv.org/abs/2305.17799",
    "authors": [
      "Diab W. Abueidda",
      "Mostafa E. Mobasher"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2305.17813",
    "title": "Meerkat: A framework for Dynamic Graph Algorithms on GPUs",
    "abstract": "Graph algorithms are challenging to implement due to their varying topology and irregular access patterns. Real-world graphs are dynamic in nature and routinely undergo edge and vertex additions, as well as, deletions. Typical examples of dynamic graphs are social networks, collaboration networks, and road networks. Applying static algorithms repeatedly on dynamic graphs is inefficient. Unfortunately, we know little about how to efficiently process dynamic graphs on massively parallel architectures such as GPUs. Existing approaches to represent and process dynamic graphs are either not general or inefficient. In this work, we propose a library-based framework for dynamic graph algorithms that proposes a GPU-tailored graph representation and exploits the warp-cooperative execution model. The library, named Meerkat, builds upon a recently proposed dynamic graph representation on GPUs. This representation exploits a hashtable-based mechanism to store a vertex's neighborhood. Meerkat also enables fast iteration through a group of vertices, such as the whole set of vertices or the neighbors of a vertex. Based on the efficient iterative patterns encoded in Meerkat, we implement dynamic versions of the popular graph algorithms such as breadth-first search, single-source shortest paths, triangle counting, weakly connected components, and PageRank. Compared to the state-of-the-art dynamic graph analytics framework Hornet, Meerkat is $12.6\\times$, $12.94\\times$, and $6.1\\times$ faster, for query, insert, and delete operations, respectively. Using a variety of real-world graphs, we observe that Meerkat significantly improves the efficiency of the underlying dynamic graph algorithm. Meerkat performs $1.17\\times$ for BFS, $1.32\\times$ for SSSP, $1.74\\times$ for PageRank, and $6.08\\times$ for WCC, better than Hornet on average. ",
    "url": "https://arxiv.org/abs/2305.17813",
    "authors": [
      "Kevin Jude Concessao",
      "Unnikrishnan Cheramangalath",
      "MJ Ricky Dev",
      "Rupesh Nasre"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2305.17817",
    "title": "Transfer Learning for Power Outage Detection Task with Limited Training  Data",
    "abstract": "Early detection of power outages is crucial for maintaining a reliable power distribution system. This research investigates the use of transfer learning and language models in detecting outages with limited labeled data. By leveraging pretraining and transfer learning, models can generalize to unseen classes. Using a curated balanced dataset of social media tweets related to power outages, we conducted experiments using zero-shot and few-shot learning. Our hypothesis is that Language Models pretrained with limited data could achieve high performance in outage detection tasks over baseline models. Results show that while classical models outperform zero-shot Language Models, few-shot fine-tuning significantly improves their performance. For example, with 10% fine-tuning, BERT achieves 81.3% accuracy (+15.3%), and GPT achieves 74.5% accuracy (+8.5%). This has practical implications for analyzing and localizing outages in scenarios with limited data availability. Our evaluation provides insights into the potential of few-shot fine-tuning with Language Models for power outage detection, highlighting their strengths and limitations. This research contributes to the knowledge base of leveraging advanced natural language processing techniques for managing critical infrastructure. ",
    "url": "https://arxiv.org/abs/2305.17817",
    "authors": [
      "Olukunle Owolabi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2305.17826",
    "title": "NOTABLE: Transferable Backdoor Attacks Against Prompt-based NLP Models",
    "abstract": "Prompt-based learning is vulnerable to backdoor attacks. Existing backdoor attacks against prompt-based models consider injecting backdoors into the entire embedding layers or word embedding vectors. Such attacks can be easily affected by retraining on downstream tasks and with different prompting strategies, limiting the transferability of backdoor attacks. In this work, we propose transferable backdoor attacks against prompt-based models, called NOTABLE, which is independent of downstream tasks and prompting strategies. Specifically, NOTABLE injects backdoors into the encoders of PLMs by utilizing an adaptive verbalizer to bind triggers to specific words (i.e., anchors). It activates the backdoor by pasting input with triggers to reach adversary-desired anchors, achieving independence from downstream tasks and prompting strategies. We conduct experiments on six NLP tasks, three popular models, and three prompting strategies. Empirical results show that NOTABLE achieves superior attack performance (i.e., attack success rate over 90% on all the datasets), and outperforms two state-of-the-art baselines. Evaluations on three defenses show the robustness of NOTABLE. Our code can be found at https://github.com/RU-System-Software-and-Security/Notable. ",
    "url": "https://arxiv.org/abs/2305.17826",
    "authors": [
      "Kai Mei",
      "Zheng Li",
      "Zhenting Wang",
      "Yang Zhang",
      "Shiqing Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.17852",
    "title": "Hierarchical Neural Memory Network for Low Latency Event Processing",
    "abstract": "This paper proposes a low latency neural network architecture for event-based dense prediction tasks. Conventional architectures encode entire scene contents at a fixed rate regardless of their temporal characteristics. Instead, the proposed network encodes contents at a proper temporal scale depending on its movement speed. We achieve this by constructing temporal hierarchy using stacked latent memories that operate at different rates. Given low latency event steams, the multi-level memories gradually extract dynamic to static scene contents by propagating information from the fast to the slow memory modules. The architecture not only reduces the redundancy of conventional architectures but also exploits long-term dependencies. Furthermore, an attention-based event representation efficiently encodes sparse event streams into the memory cells. We conduct extensive evaluations on three event-based dense prediction tasks, where the proposed approach outperforms the existing methods on accuracy and latency, while demonstrating effective event and image fusion capabilities. The code is available at https://hamarh.github.io/hmnet/ ",
    "url": "https://arxiv.org/abs/2305.17852",
    "authors": [
      "Ryuhei Hamaguchi",
      "Yasutaka Furukawa",
      "Masaki Onishi",
      "Ken Sakurada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17858",
    "title": "FastMESH: Fast Surface Reconstruction by Hexagonal Mesh-based Neural  Rendering",
    "abstract": "Despite the promising results of multi-view reconstruction, the recent neural rendering-based methods, such as implicit surface rendering (IDR) and volume rendering (NeuS), not only incur a heavy computational burden on training but also have the difficulties in disentangling the geometric and appearance. Although having achieved faster training speed than implicit representation and hash coding, the explicit voxel-based method obtains the inferior results on recovering surface. To address these challenges, we propose an effective mesh-based neural rendering approach, named FastMESH, which only samples at the intersection of ray and mesh. A coarse-to-fine scheme is introduced to efficiently extract the initial mesh by space carving. More importantly, we suggest a hexagonal mesh model to preserve surface regularity by constraining the second-order derivatives of vertices, where only low level of positional encoding is engaged for neural rendering. The experiments demonstrate that our approach achieves the state-of-the-art results on both reconstruction and novel view synthesis. Besides, we obtain 10-fold acceleration on training comparing to the implicit representation-based methods. ",
    "url": "https://arxiv.org/abs/2305.17858",
    "authors": [
      "Yisu Zhang",
      "Jianke Zhu",
      "Lixiang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17860",
    "title": "speech and noise dual-stream spectrogram refine network with speech  distortion loss for robust speech recognition",
    "abstract": "In recent years, the joint training of speech enhancement front-end and automatic speech recognition (ASR) back-end has been widely used to improve the robustness of ASR systems. Traditional joint training methods only use enhanced speech as input for the backend. However, it is difficult for speech enhancement systems to directly separate speech from input due to the diverse types of noise with different intensities. Furthermore, speech distortion and residual noise are often observed in enhanced speech, and the distortion of speech and noise is different. Most existing methods focus on fusing enhanced and noisy features to address this issue. In this paper, we propose a dual-stream spectrogram refine network to simultaneously refine the speech and noise and decouple the noise from the noisy input. Our proposed method can achieve better performance with a relative 8.6% CER reduction. ",
    "url": "https://arxiv.org/abs/2305.17860",
    "authors": [
      "Haoyu Lu",
      "Nan Li",
      "Tongtong Song",
      "Longbiao Wang",
      "Jianwu Dang",
      "Xiaobao Wang",
      "Shiliang Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.17866",
    "title": "Sequential Condition Evolved Interaction Knowledge Graph for Traditional  Chinese Medicine Recommendation",
    "abstract": "Traditional Chinese Medicine (TCM) has a rich history of utilizing natural herbs to treat a diversity of illnesses. In practice, TCM diagnosis and treatment are highly personalized and organically holistic, requiring comprehensive consideration of the patient's state and symptoms over time. However, existing TCM recommendation approaches overlook the changes in patient status and only explore potential patterns between symptoms and prescriptions. In this paper, we propose a novel Sequential Condition Evolved Interaction Knowledge Graph (SCEIKG), a framework that treats the model as a sequential prescription-making problem by considering the dynamics of the patient's condition across multiple visits. In addition, we incorporate an interaction knowledge graph to enhance the accuracy of recommendations by considering the interactions between different herbs and the patient's condition. Experimental results on a real-world dataset demonstrate that our approach outperforms existing TCM recommendation methods, achieving state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2305.17866",
    "authors": [
      "Jingjin Liu",
      "Hankz Hankui Zhuo",
      "Kebing Jin",
      "Jiamin Yuan",
      "Zhimin Yang",
      "Zhengan Yao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2305.17868",
    "title": "NaturalFinger: Generating Natural Fingerprint with Generative  Adversarial Networks",
    "abstract": "Deep neural network (DNN) models have become a critical asset of the model owner as training them requires a large amount of resource (i.e. labeled data). Therefore, many fingerprinting schemes have been proposed to safeguard the intellectual property (IP) of the model owner against model extraction and illegal redistribution. However, previous schemes adopt unnatural images as the fingerprint, such as adversarial examples and noisy images, which can be easily perceived and rejected by the adversary. In this paper, we propose NaturalFinger which generates natural fingerprint with generative adversarial networks (GANs). Besides, our proposed NaturalFinger fingerprints the decision difference areas rather than the decision boundary, which is more robust. The application of GAN not only allows us to generate more imperceptible samples, but also enables us to generate unrestricted samples to explore the decision boundary.To demonstrate the effectiveness of our fingerprint approach, we evaluate our approach against four model modification attacks including adversarial training and two model extraction attacks. Experiments show that our approach achieves 0.91 ARUC value on the FingerBench dataset (154 models), exceeding the optimal baseline (MetaV) over 17\\%. ",
    "url": "https://arxiv.org/abs/2305.17868",
    "authors": [
      "Kang Yang",
      "Kunhao Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.17879",
    "title": "Reversible Deep Neural Network Watermarking:Matching the Floating-point  Weights",
    "abstract": "Static deep neural network (DNN) watermarking embeds watermarks into the weights of DNN model by irreversible methods, but this will cause permanent damage to watermarked model and can not meet the requirements of integrity authentication. For these reasons, reversible data hiding (RDH) seems more attractive for the copyright protection of DNNs. This paper proposes a novel RDH-based static DNN watermarking method by improving the non-reversible quantization index modulation (QIM). Targeting the floating-point weights of DNNs, the idea of our RDH method is to add a scaled quantization error back to the cover object. Two schemes are designed to realize the integrity protection and legitimate authentication of DNNs. Simulation results on training loss and classification accuracy justify the superior feasibility, effectiveness and adaptability of the proposed method over histogram shifting (HS). ",
    "url": "https://arxiv.org/abs/2305.17879",
    "authors": [
      "Junren Qin",
      "Fan Yang",
      "Jiarui Deng",
      "Shanxiang Lyu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17898",
    "title": "Convolutional neural network based on sparse graph attention mechanism  for MRI super-resolution",
    "abstract": "Magnetic resonance imaging (MRI) is a valuable clinical tool for displaying anatomical structures and aiding in accurate diagnosis. Medical image super-resolution (SR) reconstruction using deep learning techniques can enhance lesion analysis and assist doctors in improving diagnostic efficiency and accuracy. However, existing deep learning-based SR methods predominantly rely on convolutional neural networks (CNNs), which inherently limit the expressive capabilities of these models and therefore make it challenging to discover potential relationships between different image features. To overcome this limitation, we propose an A-network that utilizes multiple convolution operator feature extraction modules (MCO) for extracting image features using multiple convolution operators. These extracted features are passed through multiple sets of cross-feature extraction modules (MSC) to highlight key features through inter-channel feature interactions, enabling subsequent feature learning. An attention-based sparse graph neural network module is incorporated to establish relationships between pixel features, learning which adjacent pixels have the greatest impact on determining the features to be filled. To evaluate our model's effectiveness, we conducted experiments using different models on data generated from multiple datasets with different degradation multiples, and the experimental results show that our method is a significant improvement over the current state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2305.17898",
    "authors": [
      "Xin Hua",
      "Zhijiang Du",
      "Hongjian Yu",
      "Jixin Maa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17911",
    "title": "TotalDefMeme: A Multi-Attribute Meme dataset on Total Defence in  Singapore",
    "abstract": "Total Defence is a defence policy combining and extending the concept of military defence and civil defence. While several countries have adopted total defence as their defence policy, very few studies have investigated its effectiveness. With the rapid proliferation of social media and digitalisation, many social studies have been focused on investigating policy effectiveness through specially curated surveys and questionnaires either through digital media or traditional forms. However, such references may not truly reflect the underlying sentiments about the target policies or initiatives of interest. People are more likely to express their sentiment using communication mediums such as starting topic thread on forums or sharing memes on social media. Using Singapore as a case reference, this study aims to address this research gap by proposing TotalDefMeme, a large-scale multi-modal and multi-attribute meme dataset that captures public sentiments toward Singapore's Total Defence policy. Besides supporting social informatics and public policy analysis of the Total Defence policy, TotalDefMeme can also support many downstream multi-modal machine learning tasks, such as aspect-based stance classification and multi-modal meme clustering. We perform baseline machine learning experiments on TotalDefMeme and evaluate its technical validity, and present possible future interdisciplinary research directions and application scenarios using the dataset as a baseline. ",
    "url": "https://arxiv.org/abs/2305.17911",
    "authors": [
      "Nirmalendu Prakash",
      "Ming Shan Hee",
      "Roy Ka-Wei Lee"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17916",
    "title": "Volume Feature Rendering for Fast Neural Radiance Field Reconstruction",
    "abstract": "Neural radiance fields (NeRFs) are able to synthesize realistic novel views from multi-view images captured from distinct positions and perspectives. In NeRF's rendering pipeline, neural networks are used to represent a scene independently or transform queried learnable feature vector of a point to the expected color or density. With the aid of geometry guides either in occupancy grids or proposal networks, the number of neural network evaluations can be reduced from hundreds to dozens in the standard volume rendering framework. Instead of rendering yielded color after neural network evaluation, we propose to render the queried feature vectors of a ray first and then transform the rendered feature vector to the final pixel color by a neural network. This fundamental change to the standard volume rendering framework requires only one single neural network evaluation to render a pixel, which substantially lowers the high computational complexity of the rendering framework attributed to a large number of neural network evaluations. Consequently, we can use a comparably larger neural network to achieve a better rendering quality while maintaining the same training and rendering time costs. Our model achieves the state-of-the-art rendering quality on both synthetic and real-world datasets while requiring a training time of several minutes. ",
    "url": "https://arxiv.org/abs/2305.17916",
    "authors": [
      "Kang Han",
      "Wei Xiang",
      "Lu Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17921",
    "title": "Robust Queue Length Estimation for Ramp Metering in a Connected Vehicle  Environment",
    "abstract": "Connected vehicles (CVs) can provide numerous new data via vehicle-to-vehicle or vehicle-to-infrastructure communication. These data can in turn be used to facilitate real-time traffic state estimation. In this paper, we focus on ramp queue length estimation in a connected vehicle environment, which improves control design and implementation of ramp metering algorithms. One major challenge of the estimation problem is that the CV data only represent partial traffic observations and could introduce new uncertainties if real-time CV penetration rates are unknown. To address this, we build our estimation approach on both traditional freeway sensors and new CV data. We first formulate a ramp queue model that considers i) variations in the penetration rate and ii) noise in measurements. Then we develop a robust filter that minimizes the impacts of these two kinds of uncertainties on queue estimation. More importantly, we show that the designed filter has guaranteed long-term estimation accuracy. It allows us to quantify in a theoretical way the relationship between estimation error and fluctuation of CV penetration rates. We also provide a series of simulation results to verify our approach. ",
    "url": "https://arxiv.org/abs/2305.17921",
    "authors": [
      "Yu Tang",
      "Kaan Ozbay",
      "Li Jin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.17932",
    "title": "CamoDiffusion: Camouflaged Object Detection via Conditional Diffusion  Models",
    "abstract": "Camouflaged Object Detection (COD) is a challenging task in computer vision due to the high similarity between camouflaged objects and their surroundings. Existing COD methods primarily employ semantic segmentation, which suffers from overconfident incorrect predictions. In this paper, we propose a new paradigm that treats COD as a conditional mask-generation task leveraging diffusion models. Our method, dubbed CamoDiffusion, employs the denoising process of diffusion models to iteratively reduce the noise of the mask. Due to the stochastic sampling process of diffusion, our model is capable of sampling multiple possible predictions from the mask distribution, avoiding the problem of overconfident point estimation. Moreover, we develop specialized learning strategies that include an innovative ensemble approach for generating robust predictions and tailored forward diffusion methods for efficient training, specifically for the COD task. Extensive experiments on three COD datasets attest the superior performance of our model compared to existing state-of-the-art methods, particularly on the most challenging COD10K dataset, where our approach achieves 0.019 in terms of MAE. ",
    "url": "https://arxiv.org/abs/2305.17932",
    "authors": [
      "Zhongxi Chen",
      "Ke Sun",
      "Xianming Lin",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17938",
    "title": "Integrated Sensing and Communication Complex CNN CSI Enhancer for 6G  Networks",
    "abstract": "In this paper, we propose a novel integrated sensing and communication (ISAC) complex convolution neural network (CNN) CSI enhancer for 6G networks, which exploits the correlation between the sensing parameters, such as angle-of-arrival (AoA) and range, and the channel state information (CSI) to significantly improve the CSI estimation accuracy and further enhance the sensing accuracy. The ISAC complex CNN CSI enhancer uses the complex-value computation layers to form the CNN to better maintain the phase information of CSI. Furthermore, we incorporate the ISAC transform modules into the CNN enhancer to transform the CSI into the sparse angle-delay domain, which can be treated as images with prominent peaks and are suitable to be processed by CNN. Then, we further propose a novel biased FFT-based sensing scheme, where we actively add known phase bias terms to the original CSI to generate multiple estimation results using a simple FFT-based sensing method, and we finally calculate the average of all the debiased sensing results to obtain more accurate range estimates. The extensive simulation results show that the ISAC complex CNN CSI enhancer can converge within 30 training epochs. Its CSI estimation normalized mean square error (NMSE) is about 17 dB lower than the MMSE method, and the bit error rate (BER) of demodulation using the enhanced CSI approaches the perfect CSI. Finally, the range estimation MSE of the proposed biased FFT-based sensing method can approach the subspace-based method with much lower complexity. ",
    "url": "https://arxiv.org/abs/2305.17938",
    "authors": [
      "Xu Chen",
      "Zhiyong Feng",
      "J. Andrew Zhang",
      "Xin Yuan",
      "Ping Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.17939",
    "title": "Fourier Analysis on Robustness of Graph Convolutional Neural Networks  for Skeleton-based Action Recognition",
    "abstract": "Using Fourier analysis, we explore the robustness and vulnerability of graph convolutional neural networks (GCNs) for skeleton-based action recognition. We adopt a joint Fourier transform (JFT), a combination of the graph Fourier transform (GFT) and the discrete Fourier transform (DFT), to examine the robustness of adversarially-trained GCNs against adversarial attacks and common corruptions. Experimental results with the NTU RGB+D dataset reveal that adversarial training does not introduce a robustness trade-off between adversarial attacks and low-frequency perturbations, which typically occurs during image classification based on convolutional neural networks. This finding indicates that adversarial training is a practical approach to enhancing robustness against adversarial attacks and common corruptions in skeleton-based action recognition. Furthermore, we find that the Fourier approach cannot explain vulnerability against skeletal part occlusion corruption, which highlights its limitations. These findings extend our understanding of the robustness of GCNs, potentially guiding the development of more robust learning methods for skeleton-based action recognition. ",
    "url": "https://arxiv.org/abs/2305.17939",
    "authors": [
      "Nariki Tanaka",
      "Hiroshi Kera",
      "Kazuhiko Kawamoto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17957",
    "title": "Improving Confidence in Evolutionary Mine Scheduling via Uncertainty  Discounting",
    "abstract": "Mine planning is a complex task that involves many uncertainties. During early stage feasibility, available mineral resources can only be estimated based on limited sampling of ore grades from sparse drilling, leading to large uncertainty in under-sampled parts of the deposit. Planning the extraction schedule of ore over the life of a mine is crucial for its economic viability. We introduce a new approach for determining an \"optimal schedule under uncertainty\" that provides probabilistic bounds on the profits obtained in each period. This treatment of uncertainty within an economic framework reduces previously difficult-to-use models of variability into actionable insights. The new method discounts profits based on uncertainty within an evolutionary algorithm, sacrificing economic optimality of a single geological model for improving the downside risk over an ensemble of equally likely models. We provide experimental studies using Maptek's mine planning software Evolution. Our results show that our new approach is successful for effectively making use of uncertainty information in the mine planning process. ",
    "url": "https://arxiv.org/abs/2305.17957",
    "authors": [
      "Michael Stimson",
      "William Reid",
      "Aneta Neumann",
      "Simon Ratcliffe",
      "Frank Neumann"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17965",
    "title": "Improving the Generalizability of Trajectory Prediction Models with  Frenet-Based Domain Normalization",
    "abstract": "Predicting the future trajectories of nearby objects plays a pivotal role in Robotics and Automation such as autonomous driving. While learning-based trajectory prediction methods have achieved remarkable performance on public benchmarks, the generalization ability of these approaches remains questionable. The poor generalizability on unseen domains, a well-recognized defect of data-driven approaches, can potentially harm the real-world performance of trajectory prediction models. We are thus motivated to improve generalization ability of models instead of merely pursuing high accuracy on average. Due to the lack of benchmarks for quantifying the generalization ability of trajectory predictors, we first construct a new benchmark called argoverse-shift, where the data distributions of domains are significantly different. Using this benchmark for evaluation, we identify that the domain shift problem seriously hinders the generalization of trajectory predictors since state-of-the-art approaches suffer from severe performance degradation when facing those out-of-distribution scenes. To enhance the robustness of models against domain shift problem, we propose a plug-and-play strategy for domain normalization in trajectory prediction. Our strategy utilizes the Frenet coordinate frame for modeling and can effectively narrow the domain gap of different scenes caused by the variety of road geometry and topology. Experiments show that our strategy noticeably boosts the prediction performance of the state-of-the-art in domains that were previously unseen to the models, thereby improving the generalization ability of data-driven trajectory prediction methods. ",
    "url": "https://arxiv.org/abs/2305.17965",
    "authors": [
      "Luyao Ye",
      "Zikang Zhou",
      "Jianping Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.17968",
    "title": "Data Augmentation for Low-Resource Keyphrase Generation",
    "abstract": "Keyphrase generation is the task of summarizing the contents of any given article into a few salient phrases (or keyphrases). Existing works for the task mostly rely on large-scale annotated datasets, which are not easy to acquire. Very few works address the problem of keyphrase generation in low-resource settings, but they still rely on a lot of additional unlabeled data for pretraining and on automatic methods for pseudo-annotations. In this paper, we present data augmentation strategies specifically to address keyphrase generation in purely resource-constrained domains. We design techniques that use the full text of the articles to improve both present and absent keyphrase generation. We test our approach comprehensively on three datasets and show that the data augmentation strategies consistently improve the state-of-the-art performance. We release our source code at https://github.com/kgarg8/kpgen-lowres-data-aug. ",
    "url": "https://arxiv.org/abs/2305.17968",
    "authors": [
      "Krishna Garg",
      "Jishnu Ray Chowdhury",
      "Cornelia Caragea"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17972",
    "title": "View-to-Label: Multi-View Consistency for Self-Supervised 3D Object  Detection",
    "abstract": "For autonomous vehicles, driving safely is highly dependent on the capability to correctly perceive the environment in 3D space, hence the task of 3D object detection represents a fundamental aspect of perception. While 3D sensors deliver accurate metric perception, monocular approaches enjoy cost and availability advantages that are valuable in a wide range of applications. Unfortunately, training monocular methods requires a vast amount of annotated data. Interestingly, self-supervised approaches have recently been successfully applied to ease the training process and unlock access to widely available unlabelled data. While related research leverages different priors including LIDAR scans and stereo images, such priors again limit usability. Therefore, in this work, we propose a novel approach to self-supervise 3D object detection purely from RGB sequences alone, leveraging multi-view constraints and weak labels. Our experiments on KITTI 3D dataset demonstrate performance on par with state-of-the-art self-supervised methods using LIDAR scans or stereo images. ",
    "url": "https://arxiv.org/abs/2305.17972",
    "authors": [
      "Issa Mouawad",
      "Nikolas Brasch",
      "Fabian Manhardt",
      "Federico Tombari",
      "Francesca Odone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18008",
    "title": "Pedestrian detection with high-resolution event camera",
    "abstract": "Despite the dynamic development of computer vision algorithms, the implementation of perception and control systems for autonomous vehicles such as drones and self-driving cars still poses many challenges. A video stream captured by traditional cameras is often prone to problems such as motion blur or degraded image quality due to challenging lighting conditions. In addition, the frame rate - typically 30 or 60 frames per second - can be a limiting factor in certain scenarios. Event cameras (DVS -- Dynamic Vision Sensor) are a potentially interesting technology to address the above mentioned problems. In this paper, we compare two methods of processing event data by means of deep learning for the task of pedestrian detection. We used a representation in the form of video frames, convolutional neural networks and asynchronous sparse convolutional neural networks. The results obtained illustrate the potential of event cameras and allow the evaluation of the accuracy and efficiency of the methods used for high-resolution (1280 x 720 pixels) footage. ",
    "url": "https://arxiv.org/abs/2305.18008",
    "authors": [
      "Piotr Wzorek",
      "Tomasz Kryjak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.18023",
    "title": "Abstractive Summarization as Augmentation for Document-Level Event  Detection",
    "abstract": "Transformer-based models have consistently produced substantial performance gains across a variety of NLP tasks, compared to shallow models. However, deep models are orders of magnitude more computationally expensive than shallow models, especially on tasks with large sequence lengths, such as document-level event detection. In this work, we attempt to bridge the performance gap between shallow and deep models on document-level event detection by using abstractive text summarization as an augmentation method. We augment the DocEE dataset by generating abstractive summaries of examples from low-resource classes. For classification, we use linear SVM with TF-IDF representations and RoBERTa-base. We use BART for zero-shot abstractive summarization, making our augmentation setup less resource-intensive compared to supervised fine-tuning. We experiment with four decoding methods for text generation, namely beam search, top-k sampling, top-p sampling, and contrastive search. Furthermore, we investigate the impact of using document titles as additional input for classification. Our results show that using the document title offers 2.04% and 3.19% absolute improvement in macro F1-score for linear SVM and RoBERTa, respectively. Augmentation via summarization further improves the performance of linear SVM by about 0.5%, varying slightly across decoding methods. Overall, our augmentation setup yields insufficient improvements for linear SVM compared to RoBERTa. ",
    "url": "https://arxiv.org/abs/2305.18023",
    "authors": [
      "Janko Vidakovi\u0107",
      "Filip Karlo Do\u0161ilovi\u0107",
      "Domagoj Plu\u0161\u010dec"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.18026",
    "title": "Semantic Role Labeling Guided Out-of-distribution Detection",
    "abstract": "Identifying unexpected domain-shifted instances in natural language processing is crucial in real-world applications. Previous works identify the OOD instance by leveraging a single global feature embedding to represent the sentence, which cannot characterize subtle OOD patterns well. Another major challenge current OOD methods face is learning effective low-dimensional sentence representations to identify the hard OOD instances that are semantically similar to the ID data. In this paper, we propose a new unsupervised OOD detection method, namely Semantic Role Labeling Guided Out-of-distribution Detection (SRLOOD), that separates, extracts, and learns the semantic role labeling (SRL) guided fine-grained local feature representations from different arguments of a sentence and the global feature representations of the full sentence using a margin-based contrastive loss. A novel self-supervised approach is also introduced to enhance such global-local feature learning by predicting the SRL extracted role. The resulting model achieves SOTA performance on four OOD benchmarks, indicating the effectiveness of our approach. Codes will be available upon acceptance. ",
    "url": "https://arxiv.org/abs/2305.18026",
    "authors": [
      "Jinan Zou",
      "Maihao Guo",
      "Yu Tian",
      "Yuhao Lin",
      "Haiyao Cao",
      "Lingqiao Liu",
      "Ehsan Abbasnejad",
      "Javen Qinfeng Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.18030",
    "title": "Towards Automatic Neural Architecture Search within General  Super-Networks",
    "abstract": "Existing neural architecture search (NAS) methods typically rely on pre-specified super deep neural networks (super-networks) with handcrafted search spaces beforehand. Such requirements make it challenging to extend them onto general scenarios without significant human expertise and manual intervention. To overcome the limitations, we propose the third generation of Only-Train-Once (OTOv3). OTOv3 is perhaps the first automated system that trains general super-networks and produces high-performing sub-networks in the one shot manner without pretraining and fine-tuning. Technologically, OTOv3 delivers three noticeable contributions to minimize human efforts: (i) automatic search space construction for general super-networks; (ii) a Hierarchical Half-Space Projected Gradient (H2SPG) that leverages the dependency graph to ensure the network validity during optimization and reliably produces a solution with both high performance and hierarchical group sparsity; and (iii) automatic sub-network construction based on the super-network and the H2SPG solution. Numerically, we demonstrate the effectiveness of OTOv3 on a variety of super-networks, including RegNet, StackedUnets, SuperResNet, and DARTS, over benchmark datasets such as CIFAR10, Fashion-MNIST, ImageNet, STL-10, and SVNH. The sub-networks computed by OTOv3 achieve competitive even superior performance compared to the super-networks and other state-of-the-arts. The library will be released at https://github.com/tianyic/only_train_once. ",
    "url": "https://arxiv.org/abs/2305.18030",
    "authors": [
      "Tianyi Chen",
      "Luming Liang",
      "Tianyu Ding",
      "Ilya Zharkov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18034",
    "title": "A Corpus for Sentence-level Subjectivity Detection on English News  Articles",
    "abstract": "We present a novel corpus for subjectivity detection at the sentence level. We develop new annotation guidelines for the task, which are not limited to language-specific cues, and apply them to produce a new corpus in English. The corpus consists of 411 subjective and 638 objective sentences extracted from ongoing coverage of political affairs from online news outlets. This new resource paves the way for the development of models for subjectivity detection in English and across other languages, without relying on language-specific tools like lexicons or machine translation. We evaluate state-of-the-art multilingual transformer-based models on the task, both in mono- and cross-lingual settings, the latter with a similar existing corpus in Italian language. We observe that enriching our corpus with resources in other languages improves the results on the task. ",
    "url": "https://arxiv.org/abs/2305.18034",
    "authors": [
      "Francesco Antici",
      "Andrea Galassi",
      "Federico Ruggeri",
      "Katerina Korre",
      "Arianna Muti",
      "Alessandra Bardi",
      "Alice Fedotova",
      "Alberto Barr\u00f3n-Cede\u00f1o"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.18057",
    "title": "CPU-GPU Heterogeneous Code Acceleration of a Finite Volume Computational  Fluid Dynamics Solver",
    "abstract": "This work deals with the CPU-GPU heterogeneous code acceleration of a finite-volume CFD solver utilizing multiple CPUs and GPUs at the same time. First, a high-level description of the CFD solver called SENSEI, the discretization of SENSEI, and the CPU-GPU heterogeneous computing workflow in SENSEI leveraging MPI and OpenACC are given. Then, a performance model for CPU-GPU heterogeneous computing requiring ghost cell exchange is proposed to help estimate the performance of the heterogeneous implementation. The scaling performance of the CPU-GPU heterogeneous computing and its comparison with the pure multi-CPU/GPU performance for a supersonic inlet test case is presented to display the advantages of leveraging the computational power of both the CPU and the GPU. Using CPUs and GPUs as workers together, the performance can be improved further compared to using pure CPUs or GPUs, and the advantages can be fairly estimated by the performance model proposed in this work. Finally, conclusions are drawn to provide 1) suggestions for application users who have an interest to leverage the computational power of the CPU and GPU to accelerate their own scientific computing simulations and 2) feedback for hardware architects who have an interest to design a better CPU-GPU heterogeneous system for heterogeneous computing. ",
    "url": "https://arxiv.org/abs/2305.18057",
    "authors": [
      "Weicheng Xue",
      "Hongyu Wang",
      "Christopher J. Roy"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2305.18060",
    "title": "Mining Negative Temporal Contexts For False Positive Suppression In  Real-Time Ultrasound Lesion Detection",
    "abstract": "During ultrasonic scanning processes, real-time lesion detection can assist radiologists in accurate cancer diagnosis. However, this essential task remains challenging and underexplored. General-purpose real-time object detection models can mistakenly report obvious false positives (FPs) when applied to ultrasound videos, potentially misleading junior radiologists. One key issue is their failure to utilize negative symptoms in previous frames, denoted as negative temporal contexts (NTC). To address this issue, we propose to extract contexts from previous frames, including NTC, with the guidance of inverse optical flow. By aggregating extracted contexts, we endow the model with the ability to suppress FPs by leveraging NTC. We call the resulting model UltraDet. The proposed UltraDet demonstrates significant improvement over previous state-of-the-arts and achieves real-time inference speed. To facilitate future research, we will release the code, checkpoints, and high-quality labels of the CVA-BUS dataset used in our experiments. ",
    "url": "https://arxiv.org/abs/2305.18060",
    "authors": [
      "Haojun Yu",
      "Youcheng Li",
      "QuanLin Wu",
      "Ziwei Zhao",
      "Dengbo Chen",
      "Dong Wang",
      "Liwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.18061",
    "title": "Leveraging Evolutionary Changes for Software Process Quality",
    "abstract": "Real-world software applications must constantly evolve to remain relevant. This evolution occurs when developing new applications or adapting existing ones to meet new requirements, make corrections, or incorporate future functionality. Traditional methods of software quality control involve software quality models and continuous code inspection tools. These measures focus on directly assessing the quality of the software. However, there is a strong correlation and causation between the quality of the development process and the resulting software product. Therefore, improving the development process indirectly improves the software product, too. To achieve this, effective learning from past processes is necessary, often embraced through post mortem organizational learning. While qualitative evaluation of large artifacts is common, smaller quantitative changes captured by application lifecycle management are often overlooked. In addition to software metrics, these smaller changes can reveal complex phenomena related to project culture and management. Leveraging these changes can help detect and address such complex issues. Software evolution was previously measured by the size of changes, but the lack of consensus on a reliable and versatile quantification method prevents its use as a dependable metric. Different size classifications fail to reliably describe the nature of evolution. While application lifecycle management data is rich, identifying which artifacts can model detrimental managerial practices remains uncertain. Approaches such as simulation modeling, discrete events simulation, or Bayesian networks have only limited ability to exploit continuous-time process models of such phenomena. Even worse, the accessibility and mechanistic insight into such gray- or black-box models are typically very low. To address these challenges, we suggest leveraging objectively [...] ",
    "url": "https://arxiv.org/abs/2305.18061",
    "authors": [
      "Sebastian H\u00f6nel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Optimization and Control (math.OC)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.18063",
    "title": "Vector-based Representation is the Key: A Study on Disentanglement and  Compositional Generalization",
    "abstract": "Recognizing elementary underlying concepts from observations (disentanglement) and generating novel combinations of these concepts (compositional generalization) are fundamental abilities for humans to support rapid knowledge learning and generalize to new tasks, with which the deep learning models struggle. Towards human-like intelligence, various works on disentangled representation learning have been proposed, and recently some studies on compositional generalization have been presented. However, few works study the relationship between disentanglement and compositional generalization, and the observed results are inconsistent. In this paper, we study several typical disentangled representation learning works in terms of both disentanglement and compositional generalization abilities, and we provide an important insight: vector-based representation (using a vector instead of a scalar to represent a concept) is the key to empower both good disentanglement and strong compositional generalization. This insight also resonates the neuroscience research that the brain encodes information in neuron population activity rather than individual neurons. Motivated by this observation, we further propose a method to reform the scalar-based disentanglement works ($\\beta$-TCVAE and FactorVAE) to be vector-based to increase both capabilities. We investigate the impact of the dimensions of vector-based representation and one important question: whether better disentanglement indicates higher compositional generalization. In summary, our study demonstrates that it is possible to achieve both good concept recognition and novel concept composition, contributing an important step towards human-like intelligence. ",
    "url": "https://arxiv.org/abs/2305.18063",
    "authors": [
      "Tao Yang",
      "Yuwang Wang",
      "Cuiling Lan",
      "Yan Lu",
      "Nanning Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18070",
    "title": "Forensic Video Steganalysis in Spatial Domain by Noise Residual  Convolutional Neural Network",
    "abstract": "This research evaluates a convolutional neural network (CNN) based approach to forensic video steganalysis. A video steganography dataset is created to train a CNN to conduct forensic steganalysis in the spatial domain. We use a noise residual convolutional neural network to detect embedded secrets since a steganographic embedding process will always result in the modification of pixel values in video frames. Experimental results show that the CNN-based approach can be an effective method for forensic video steganalysis and can reach a detection rate of 99.96%. Keywords: Forensic, Steganalysis, Deep Steganography, MSU StegoVideo, Convolutional Neural Networks ",
    "url": "https://arxiv.org/abs/2305.18070",
    "authors": [
      "Mart Keizer",
      "Zeno Geradts",
      "Meike Kombrink"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.18079",
    "title": "Towards a Robust Framework for NeRF Evaluation",
    "abstract": "Neural Radiance Field (NeRF) research has attracted significant attention recently, with 3D modelling, virtual/augmented reality, and visual effects driving its application. While current NeRF implementations can produce high quality visual results, there is a conspicuous lack of reliable methods for evaluating them. Conventional image quality assessment methods and analytical metrics (e.g. PSNR, SSIM, LPIPS etc.) only provide approximate indicators of performance since they generalise the ability of the entire NeRF pipeline. Hence, in this paper, we propose a new test framework which isolates the neural rendering network from the NeRF pipeline and then performs a parametric evaluation by training and evaluating the NeRF on an explicit radiance field representation. We also introduce a configurable approach for generating representations specifically for evaluation purposes. This employs ray-casting to transform mesh models into explicit NeRF samples, as well as to \"shade\" these representations. Combining these two approaches, we demonstrate how different \"tasks\" (scenes with different visual effects or learning strategies) and types of networks (NeRFs and depth-wise implicit neural representations (INRs)) can be evaluated within this framework. Additionally, we propose a novel metric to measure task complexity of the framework which accounts for the visual parameters and the distribution of the spatial data. Our approach offers the potential to create a comparative objective evaluation framework for NeRF methods. ",
    "url": "https://arxiv.org/abs/2305.18079",
    "authors": [
      "Adrian Azzarelli",
      "Nantheera Anantrasirichai",
      "David R Bull"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2305.18081",
    "title": "Game of Tones: Faculty detection of GPT-4 generated content in  university assessments",
    "abstract": "This study explores the robustness of university assessments against the use of Open AI's Generative Pre-Trained Transformer 4 (GPT-4) generated content and evaluates the ability of academic staff to detect its use when supported by the Turnitin Artificial Intelligence (AI) detection tool. The research involved twenty-two GPT-4 generated submissions being created and included in the assessment process to be marked by fifteen different faculty members. The study reveals that although the detection tool identified 91% of the experimental submissions as containing some AI-generated content, the total detected content was only 54.8%. This suggests that the use of adversarial techniques regarding prompt engineering is an effective method in evading AI detection tools and highlights that improvements to AI detection software are needed. Using the Turnitin AI detect tool, faculty reported 54.5% of the experimental submissions to the academic misconduct process, suggesting the need for increased awareness and training into these tools. Genuine submissions received a mean score of 54.4, whereas AI-generated content scored 52.3, indicating the comparable performance of GPT-4 in real-life situations. Recommendations include adjusting assessment strategies to make them more resistant to the use of AI tools, using AI-inclusive assessment where possible, and providing comprehensive training programs for faculty and students. This research contributes to understanding the relationship between AI-generated content and academic assessment, urging further investigation to preserve academic integrity. ",
    "url": "https://arxiv.org/abs/2305.18081",
    "authors": [
      "Mike Perkins",
      "Jasper Roe",
      "Darius Postma",
      "James McGaughran",
      "Don Hickerson"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.18092",
    "title": "Contrastive Learning Based Recursive Dynamic Multi-Scale Network for  Image Deraining",
    "abstract": "Rain streaks significantly decrease the visibility of captured images and are also a stumbling block that restricts the performance of subsequent computer vision applications. The existing deep learning-based image deraining methods employ manually crafted networks and learn a straightforward projection from rainy images to clear images. In pursuit of better deraining performance, they focus on elaborating a more complicated architecture rather than exploiting the intrinsic properties of the positive and negative information. In this paper, we propose a contrastive learning-based image deraining method that investigates the correlation between rainy and clear images and leverages a contrastive prior to optimize the mutual information of the rainy and restored counterparts. Given the complex and varied real-world rain patterns, we develop a recursive mechanism. It involves multi-scale feature extraction and dynamic cross-level information recruitment modules. The former advances the portrayal of diverse rain patterns more precisely, while the latter can selectively compensate high-level features for shallow-level information. We term the proposed recursive dynamic multi-scale network with a contrastive prior, RDMC. Extensive experiments on synthetic benchmarks and real-world images demonstrate that the proposed RDMC delivers strong performance on the depiction of rain streaks and outperforms the state-of-the-art methods. Moreover, a practical evaluation of object detection and semantic segmentation shows the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2305.18092",
    "authors": [
      "Zhiying Jiang",
      "Risheng Liu",
      "Shuzhou Yang",
      "Zengxi Zhang",
      "Xin Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18097",
    "title": "Performance Analysis of Discrete-Phase-Shifter IRS-aided  Amplify-and-Forward Relay Network",
    "abstract": "As a new technology to reconfigure wireless communication environment by signal reflection controlled by software, intelligent reflecting surface (IRS) has attracted lots of attention in recent years. Compared with conventional relay system, the relay system aided by IRS can effectively reduce the cost and energy consumption, and significantly enhance the system performance. However, the phase quantization error generated by IRS with discrete phase shifter may degrade the receiving performance of the receiver. To analyze the performance loss caused by IRS phase quantization error, based on the law of large numbers and Rayleigh distribution, the closed-form expressions for the signal-to-noise ratio (SNR) performance loss and achievable rate of the IRS-aided amplify-and-forward (AF) relay network, which are related to the number of phase shifter quantization bits, are derived under the line-of-sight (LoS) channels and Rayleigh channels, respectively. Moreover, their approximate performance loss closed-form expressions are also derived based on the Taylor series expansion. Simulation results show that the performance losses of SNR and achievable rate decrease with the number of quantization bits increases gradually. When the number of quantization bits is larger than or equal to 3, the SNR performance loss of the system is smaller than 0.23dB, and the achievable rate loss is less than 0.04bits/s/Hz, regardless of the LoS channels or Rayleigh channels. ",
    "url": "https://arxiv.org/abs/2305.18097",
    "authors": [
      "Rongen Dong",
      "Zhongyi Xie",
      "Feng Shu",
      "Mengxing Huang",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.18108",
    "title": "Exploration of Efficient End-to-End ASR using Discretized Input from  Self-Supervised Learning",
    "abstract": "Self-supervised learning (SSL) of speech has shown impressive results in speech-related tasks, particularly in automatic speech recognition (ASR). While most methods employ the output of intermediate layers of the SSL model as real-valued features for downstream tasks, there is potential in exploring alternative approaches that use discretized token sequences. This approach offers benefits such as lower storage requirements and the ability to apply techniques from natural language processing. In this paper, we propose a new protocol that utilizes discretized token sequences in ASR tasks, which includes de-duplication and sub-word modeling to enhance the input sequence. It reduces computational cost by decreasing the length of the sequence. Our experiments on the LibriSpeech dataset demonstrate that our proposed protocol performs competitively with conventional ASR systems using continuous input features, while reducing computational and storage costs. ",
    "url": "https://arxiv.org/abs/2305.18108",
    "authors": [
      "Xuankai Chang",
      "Brian Yan",
      "Yuya Fujita",
      "Takashi Maekaku",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.18149",
    "title": "Multiscale Positive-Unlabeled Detection of AI-Generated Texts",
    "abstract": "Recent releases of Large Language Models (LLMs), e.g. ChatGPT, are astonishing at generating human-like texts, but they may get misused for fake scholarly texts, fake news, fake tweets, et cetera. Previous works have proposed methods to detect these multiscale AI-generated texts, including simple ML classifiers, pretrained-model-based training-agnostic methods, and finetuned language classification models. However, mainstream detectors are formulated without considering the factor of corpus length: shorter corpuses are harder to detect compared with longer ones for shortage of informative features. In this paper, a Multiscale Positive-Unlabeled (MPU) training framework is proposed to address the challenge of multiscale text detection. Firstly, we acknowledge the human-resemblance property of short machine texts, and rephrase text classification as a Positive-Unlabeled (PU) problem by marking these short machine texts as \"unlabeled\" during training. In this PU context, we propose the length-sensitive Multiscale PU Loss, where we use a recurrent model in abstraction to estimate positive priors of scale-variant corpuses. Additionally, we introduce a Text Multiscaling module to enrich training corpuses. Experiments show that our MPU method augments detection performance on long AI-generated text, and significantly improves short-corpus detection of language model detectors. Language Models trained with MPU could outcompete existing detectors by large margins on multiscale AI-generated texts. The codes are available at https://github.com/mindspore-lab/mindone/tree/master/examples/detect_chatgpt and https://github.com/huawei-noah/Efficient-Computing/AIGC_text_detector. ",
    "url": "https://arxiv.org/abs/2305.18149",
    "authors": [
      "Yuchuan Tian",
      "Hanting Chen",
      "Xutao Wang",
      "Zheyuan Bai",
      "Qinghua Zhang",
      "Ruifeng Li",
      "Chao Xu",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.18158",
    "title": "Out-of-Distributed Semantic Pruning for Robust Semi-Supervised Learning",
    "abstract": "Recent advances in robust semi-supervised learning (SSL) typically filter out-of-distribution (OOD) information at the sample level. We argue that an overlooked problem of robust SSL is its corrupted information on semantic level, practically limiting the development of the field. In this paper, we take an initial step to explore and propose a unified framework termed OOD Semantic Pruning (OSP), which aims at pruning OOD semantics out from in-distribution (ID) features. Specifically, (i) we propose an aliasing OOD matching module to pair each ID sample with an OOD sample with semantic overlap. (ii) We design a soft orthogonality regularization, which first transforms each ID feature by suppressing its semantic component that is collinear with paired OOD sample. It then forces the predictions before and after soft orthogonality decomposition to be consistent. Being practically simple, our method shows a strong performance in OOD detection and ID classification on challenging benchmarks. In particular, OSP surpasses the previous state-of-the-art by 13.7% on accuracy for ID classification and 5.9% on AUROC for OOD detection on TinyImageNet dataset. The source codes are publicly available at https://github.com/rain305f/OSP. ",
    "url": "https://arxiv.org/abs/2305.18158",
    "authors": [
      "Yu Wang",
      "Pengchong",
      "Qiao",
      "Chang Liu",
      "Guoli Song",
      "Xiawu Zheng",
      "Jie Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.18163",
    "title": "Compact Real-time Radiance Fields with Neural Codebook",
    "abstract": "Reconstructing neural radiance fields with explicit volumetric representations, demonstrated by Plenoxels, has shown remarkable advantages on training and rendering efficiency, while grid-based representations typically induce considerable overhead for storage and transmission. In this work, we present a simple and effective framework for pursuing compact radiance fields from the perspective of compression methodology. By exploiting intrinsic properties exhibiting in grid models, a non-uniform compression stem is developed to significantly reduce model complexity and a novel parameterized module, named Neural Codebook, is introduced for better encoding high-frequency details specific to per-scene models via a fast optimization. Our approach can achieve over 40 $\\times$ reduction on grid model storage with competitive rendering quality. In addition, the method can achieve real-time rendering speed with 180 fps, realizing significant advantage on storage cost compared to real-time rendering methods. ",
    "url": "https://arxiv.org/abs/2305.18163",
    "authors": [
      "Lingzhi Li",
      "Zhongshu Wang",
      "Zhen Shen",
      "Li Shen",
      "Ping Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18169",
    "title": "LM-CPPF: Paraphrasing-Guided Data Augmentation for Contrastive  Prompt-Based Few-Shot Fine-Tuning",
    "abstract": "In recent years, there has been significant progress in developing pre-trained language models for NLP. However, these models often struggle when fine-tuned on small datasets. To address this issue, researchers have proposed various adaptation approaches. Prompt-based tuning is arguably the most common way, especially for larger models. Previous research shows that adding contrastive learning to prompt-based fine-tuning is effective as it helps the model generate embeddings that are more distinguishable between classes, and it can also be more sample-efficient as the model learns from positive and negative examples simultaneously. One of the most important components of contrastive learning is data augmentation, but unlike computer vision, effective data augmentation for NLP is still challenging. This paper proposes LM-CPPF, Contrastive Paraphrasing-guided Prompt-based Fine-tuning of Language Models, which leverages prompt-based few-shot paraphrasing using generative language models, especially large language models such as GPT-3 and OPT-175B, for data augmentation. Our experiments on multiple text classification benchmarks show that this augmentation method outperforms other methods, such as easy data augmentation, back translation, and multiple templates. ",
    "url": "https://arxiv.org/abs/2305.18169",
    "authors": [
      "Amirhossein Abaskohi",
      "Sascha Rothe",
      "Yadollah Yaghoobzadeh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.18183",
    "title": "Rethinking Counterfactual Data Augmentation Under Confounding",
    "abstract": "Counterfactual data augmentation has recently emerged as a method to mitigate confounding biases in the training data for a machine learning model. These biases, such as spurious correlations, arise due to various observed and unobserved confounding variables in the data generation process. In this paper, we formally analyze how confounding biases impact downstream classifiers and present a causal viewpoint to the solutions based on counterfactual data augmentation. We explore how removing confounding biases serves as a means to learn invariant features, ultimately aiding in generalization beyond the observed data distribution. Additionally, we present a straightforward yet powerful algorithm for generating counterfactual images, which effectively mitigates the influence of confounding effects on downstream classifiers. Through experiments on MNIST variants and the CelebA datasets, we demonstrate the effectiveness and practicality of our approach. ",
    "url": "https://arxiv.org/abs/2305.18183",
    "authors": [
      "Abbavaram Gowtham Reddy",
      "Saketh Bachu",
      "Saloni Dash",
      "Charchit Sharma",
      "Amit Sharma",
      "Vineeth N Balasubramanian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.18193",
    "title": "Active Collaborative Localization in Heterogeneous Robot Teams",
    "abstract": "Accurate and robust state estimation is critical for autonomous navigation of robot teams. This task is especially challenging for large groups of size, weight, and power (SWAP) constrained aerial robots operating in perceptually-degraded GPS-denied environments. We can, however, actively increase the amount of perceptual information available to such robots by augmenting them with a small number of more expensive, but less resource-constrained, agents. Specifically, the latter can serve as sources of perceptual information themselves. In this paper, we study the problem of optimally positioning (and potentially navigating) a small number of more capable agents to enhance the perceptual environment for their lightweight,inexpensive, teammates that only need to rely on cameras and IMUs. We propose a numerically robust, computationally efficient approach to solve this problem via nonlinear optimization. Our method outperforms the standard approach based on the greedy algorithm, while matching the accuracy of a heuristic evolutionary scheme for global optimization at a fraction of its running time. Ultimately, we validate our solution in both photorealistic simulations and real-world experiments. In these experiments, we use lidar-based autonomous ground vehicles as the more capable agents, and vision-based aerial robots as their SWAP-constrained teammates. Our method is able to reduce drift in visual-inertial odometry by as much as 90%, and it outperforms random positioning of lidar-equipped agents by a significant margin. Furthermore, our method can be generalized to different types of robot teams with heterogeneous perception capabilities. It has a wide range of applications, such as surveying and mapping challenging dynamic environments, and enabling resilience to large-scale perturbations that can be caused by earthquakes or storms. ",
    "url": "https://arxiv.org/abs/2305.18193",
    "authors": [
      "Igor Spasojevic",
      "Xu Liu",
      "Alejandro Ribeiro",
      "George J. Pappas",
      "Vijay Kumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.18216",
    "title": "Towards minimizing efforts for Morphing Attacks -- Deep embeddings for  morphing pair selection and improved Morphing Attack Detection",
    "abstract": "Face Morphing Attacks pose a threat to the security of identity documents, especially with respect to a subsequent access control process, because it enables both individuals involved to exploit the same document. In this study, face embeddings serve two purposes: pre-selecting images for large-scale Morphing Attack generation and detecting potential Morphing Attacks. We build upon previous embedding studies in both use cases using the MagFace model. For the first objective, we employ an pre-selection algorithm that pairs individuals based on face embedding similarity. We quantify the attack potential of differently morphed face images to compare the usability of pre-selection in automatically generating numerous successful Morphing Attacks. Regarding the second objective, we compare embeddings from two state-of-the-art face recognition systems in terms of their ability to detect Morphing Attacks. Our findings demonstrate that ArcFace and MagFace provide valuable face embeddings for image pre-selection. Both open-source and COTS face recognition systems are susceptible to generated attacks, particularly when pre-selection is based on embeddings rather than random pairing which was only constrained by soft biometrics. More accurate face recognition systems exhibit greater vulnerability to attacks, with COTS systems being the most susceptible. Additionally, MagFace embeddings serve as a robust alternative for detecting morphed face images compared to the previously used ArcFace embeddings. The results endorse the advantages of face embeddings in more effective image pre-selection for face morphing and accurate detection of morphed face images. This is supported by extensive analysis of various designed attacks. The MagFace model proves to be a powerful alternative to the commonly used ArcFace model for both objectives, pre-selection and attack detection. ",
    "url": "https://arxiv.org/abs/2305.18216",
    "authors": [
      "Roman Kessler",
      "Kiran Raja",
      "Juan Tapia",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18221",
    "title": "GazeGNN: A Gaze-Guided Graph Neural Network for Disease Classification",
    "abstract": "The application of eye-tracking techniques in medical image analysis has become increasingly popular in recent years. It collects the visual search patterns of the domain experts, containing much important information about health and disease. Therefore, how to efficiently integrate radiologists' gaze patterns into the diagnostic analysis turns into a critical question. Existing works usually transform gaze information into visual attention maps (VAMs) to supervise the learning process. However, this time-consuming procedure makes it difficult to develop end-to-end algorithms. In this work, we propose a novel gaze-guided graph neural network (GNN), GazeGNN, to perform disease classification from medical scans. In GazeGNN, we create a unified representation graph that models both the image and gaze pattern information. Hence, the eye-gaze information is directly utilized without being converted into VAMs. With this benefit, we develop a real-time, real-world, end-to-end disease classification algorithm for the first time and avoid the noise and time consumption introduced during the VAM preparation. To our best knowledge, GazeGNN is the first work that adopts GNN to integrate image and eye-gaze data. Our experiments on the public chest X-ray dataset show that our proposed method exhibits the best classification performance compared to existing methods. ",
    "url": "https://arxiv.org/abs/2305.18221",
    "authors": [
      "Bin Wang",
      "Hongyi Pan",
      "Armstrong Aboah",
      "Zheyuan Zhang",
      "Ahmet Cetin",
      "Drew Torigian",
      "Baris Turkbey",
      "Elizabeth Krupinski",
      "Jayaram Udupa",
      "Ulas Bagci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18225",
    "title": "Locksynth: Deriving Synchronization Code for Concurrent Data Structures  with ASP",
    "abstract": "We present Locksynth, a tool that automatically derives synchronization needed for destructive updates to concurrent data structures that involve a constant number of shared heap memory write operations. Locksynth serves as the implementation of our prior work on deriving abstract synchronization code. Designing concurrent data structures involves inferring correct synchronization code starting with a prior understanding of the sequential data structure's operations. Further, an understanding of shared memory model and the synchronization primitives is also required. The reasoning involved transforming a sequential data structure into its concurrent version can be performed using Answer Set Programming and we mechanized our approach in previous work. The reasoning involves deduction and abduction that can be succinctly modeled in ASP. We assume that the abstract sequential code of the data structure's operations is provided, alongside axioms that describe concurrent behavior. This information is used to automatically derive concurrent code for that data structure, such as dictionary operations for linked lists and binary search trees that involve a constant number of destructive update operations. We also are able to infer the correct set of locks (but not code synthesis) for external height-balanced binary search trees that involve left/right tree rotations. Locksynth performs the analyses required to infer correct sets of locks and as a final step, also derives the C++ synchronization code for the synthesized data structures. We also provide a performance analysis of the C++ code synthesized by Locksynth with the hand-crafted versions available from the Synchrobench microbenchmark suite. To the best of our knowledge, our tool is the first to employ ASP as a backend reasoner to perform concurrent data structure synthesis. ",
    "url": "https://arxiv.org/abs/2305.18225",
    "authors": [
      "Sarat Chandra Varanasi",
      "Neeraj Mittal",
      "Gopal Gupta"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.18226",
    "title": "HowkGPT: Investigating the Detection of ChatGPT-generated University  Student Homework through Context-Aware Perplexity Analysis",
    "abstract": "As the use of Large Language Models (LLMs) in text generation tasks proliferates, concerns arise over their potential to compromise academic integrity. The education sector currently tussles with distinguishing student-authored homework assignments from AI-generated ones. This paper addresses the challenge by introducing HowkGPT, designed to identify homework assignments generated by AI. HowkGPT is built upon a dataset of academic assignments and accompanying metadata [17] and employs a pretrained LLM to compute perplexity scores for student-authored and ChatGPT-generated responses. These scores then assist in establishing a threshold for discerning the origin of a submitted assignment. Given the specificity and contextual nature of academic work, HowkGPT further refines its analysis by defining category-specific thresholds derived from the metadata, enhancing the precision of the detection. This study emphasizes the critical need for effective strategies to uphold academic integrity amidst the growing influence of LLMs and provides an approach to ensuring fair and accurate grading in educational institutions. ",
    "url": "https://arxiv.org/abs/2305.18226",
    "authors": [
      "Christoforos Vasilatos",
      "Manaar Alam",
      "Talal Rahwan",
      "Yasir Zaki",
      "Michail Maniatakos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.18228",
    "title": "SR-OOD: Out-of-Distribution Detection via Sample Repairing",
    "abstract": "It is widely reported that deep generative models can classify out-of-distribution (OOD) samples as in-distribution with high confidence. In this work, we propose a hypothesis that this phenomenon is due to the reconstruction task, which can cause the generative model to focus too much on low-level features and not enough on semantic information. To address this issue, we introduce SR-OOD, an OOD detection framework that utilizes sample repairing to encourage the generative model to learn more than just an identity map. By focusing on semantics, our framework improves OOD detection performance without external data and label information. Our experimental results demonstrate the competitiveness of our approach in detecting OOD samples. ",
    "url": "https://arxiv.org/abs/2305.18228",
    "authors": [
      "Rui Sun",
      "Andi Zhang",
      "Haiming Zhang",
      "Yao Zhu",
      "Ruimao Zhang",
      "Zhen Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.18238",
    "title": "Multi-behavior Self-supervised Learning for Recommendation",
    "abstract": "Modern recommender systems often deal with a variety of user interactions, e.g., click, forward, purchase, etc., which requires the underlying recommender engines to fully understand and leverage multi-behavior data from users. Despite recent efforts towards making use of heterogeneous data, multi-behavior recommendation still faces great challenges. Firstly, sparse target signals and noisy auxiliary interactions remain an issue. Secondly, existing methods utilizing self-supervised learning (SSL) to tackle the data sparsity neglect the serious optimization imbalance between the SSL task and the target task. Hence, we propose a Multi-Behavior Self-Supervised Learning (MBSSL) framework together with an adaptive optimization method. Specifically, we devise a behavior-aware graph neural network incorporating the self-attention mechanism to capture behavior multiplicity and dependencies. To increase the robustness to data sparsity under the target behavior and noisy interactions from auxiliary behaviors, we propose a novel self-supervised learning paradigm to conduct node self-discrimination at both inter-behavior and intra-behavior levels. In addition, we develop a customized optimization strategy through hybrid manipulation on gradients to adaptively balance the self-supervised learning task and the main supervised recommendation task. Extensive experiments on five real-world datasets demonstrate the consistent improvements obtained by MBSSL over ten state-of-the art (SOTA) baselines. We release our model implementation at: https://github.com/Scofield666/MBSSL.git. ",
    "url": "https://arxiv.org/abs/2305.18238",
    "authors": [
      "Jingcao Xu",
      "Chaokun Wang",
      "Cheng Wu",
      "Yang Song",
      "Kai Zheng",
      "Xiaowei Wang",
      "Changping Wang",
      "Guorui Zhou",
      "Kun Gai"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.18240",
    "title": "XGrad: Boosting Gradient-Based Optimizers With Weight Prediction",
    "abstract": "In this paper, we propose a general deep learning training framework XGrad which introduces weight prediction into the popular gradient-based optimizers to boost their convergence and generalization when training the deep neural network (DNN) models. In particular, ahead of each mini-batch training, the future weights are predicted according to the update rule of the used optimizer and are then applied to both the forward pass and backward propagation. In this way, during the whole training period, the optimizer always utilizes the gradients w.r.t. the future weights to update the DNN parameters, making the gradient-based optimizer achieve better convergence and generalization compared to the original optimizer without weight prediction. XGrad is rather straightforward to implement yet pretty effective in boosting the convergence of gradient-based optimizers and the accuracy of DNN models. Empirical results concerning the most three popular gradient-based optimizers including SGD with momentum, Adam, and AdamW demonstrate the effectiveness of our proposal. The experimental results validate that XGrad can attain higher model accuracy than the original optimizers when training the DNN models. The code of XGrad will be available at: https://github.com/guanleics/XGrad. ",
    "url": "https://arxiv.org/abs/2305.18240",
    "authors": [
      "Lei Guan",
      "Dongsheng Li",
      "Jian Meng",
      "Yanqi Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.18256",
    "title": "Representation Learning on Hyper-Relational and Numeric Knowledge Graphs  with Transformers",
    "abstract": "A hyper-relational knowledge graph has been recently studied where a triplet is associated with a set of qualifiers; a qualifier is composed of a relation and an entity, providing auxiliary information for a triplet. While existing hyper-relational knowledge graph embedding methods assume that the entities are discrete objects, some information should be represented using numeric values, e.g., (J.R.R., was born in, 1892). Also, a triplet (J.R.R., educated at, Oxford Univ.) can be associated with a qualifier such as (start time, 1911). In this paper, we propose a unified framework named HyNT that learns representations of a hyper-relational knowledge graph containing numeric literals in either triplets or qualifiers. We define a context transformer and a prediction transformer to learn the representations based not only on the correlations between a triplet and its qualifiers but also on the numeric information. By learning compact representations of triplets and qualifiers and feeding them into the transformers, we reduce the computation cost of using transformers. Using HyNT, we can predict missing numeric values in addition to missing entities or relations in a hyper-relational knowledge graph. Experimental results show that HyNT significantly outperforms state-of-the-art methods on real-world datasets. ",
    "url": "https://arxiv.org/abs/2305.18256",
    "authors": [
      "Chanyoung Chung",
      "Jaejun Lee",
      "Joyce Jiyoung Whang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.18279",
    "title": "Contextual Object Detection with Multimodal Large Language Models",
    "abstract": "Recent Multimodal Large Language Models (MLLMs) are remarkable in vision-language tasks, such as image captioning and question answering, but lack the essential perception ability, i.e., object detection. In this work, we address this limitation by introducing a novel research problem of contextual object detection -- understanding visible objects within different human-AI interactive contexts. Three representative scenarios are investigated, including the language cloze test, visual captioning, and question answering. Moreover, we present ContextDET, a unified multimodal model that is capable of end-to-end differentiable modeling of visual-language contexts, so as to locate, identify, and associate visual objects with language inputs for human-AI interaction. Our ContextDET involves three key submodels: (i) a visual encoder for extracting visual representations, (ii) a pre-trained LLM for multimodal context decoding, and (iii) a visual decoder for predicting bounding boxes given contextual object words. The new generate-then-detect framework enables us to detect object words within human vocabulary. Extensive experiments show the advantages of ContextDET on our proposed CODE benchmark, open-vocabulary detection, and referring image segmentation. Github: https://github.com/yuhangzang/ContextDET. ",
    "url": "https://arxiv.org/abs/2305.18279",
    "authors": [
      "Yuhang Zang",
      "Wei Li",
      "Jun Han",
      "Kaiyang Zhou",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.18294",
    "title": "Transformer Language Models Handle Word Frequency in Prediction Head",
    "abstract": "Prediction head is a crucial component of Transformer language models. Despite its direct impact on prediction, this component has often been overlooked in analyzing Transformers. In this study, we investigate the inner workings of the prediction head, specifically focusing on bias parameters. Our experiments with BERT and GPT-2 models reveal that the biases in their word prediction heads play a significant role in the models' ability to reflect word frequency in a corpus, aligning with the logit adjustment method commonly used in long-tailed learning. We also quantify the effect of controlling the biases in practical auto-regressive text generation scenarios; under a particular setting, more diverse text can be generated without compromising text quality. ",
    "url": "https://arxiv.org/abs/2305.18294",
    "authors": [
      "Goro Kobayashi",
      "Tatsuki Kuribayashi",
      "Sho Yokoi",
      "Kentaro Inui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17225",
    "title": "Causal Component Analysis",
    "abstract": "Independent Component Analysis (ICA) aims to recover independent latent variables from observed mixtures thereof. Causal Representation Learning (CRL) aims instead to infer causally related (thus often statistically dependent) latent variables, together with the unknown graph encoding their causal relationships. We introduce an intermediate problem termed Causal Component Analysis (CauCA). CauCA can be viewed as a generalization of ICA, modelling the causal dependence among the latent components, and as a special case of CRL. In contrast to CRL, it presupposes knowledge of the causal graph, focusing solely on learning the unmixing function and the causal mechanisms. Any impossibility results regarding the recovery of the ground truth in CauCA also apply for CRL, while possibility results may serve as a stepping stone for extensions to CRL. We characterize CauCA identifiability from multiple datasets generated through different types of interventions on the latent causal variables. As a corollary, this interventional perspective also leads to new identifiability results for nonlinear ICA -- a special case of CauCA with an empty graph -- requiring strictly fewer datasets than previous results. We introduce a likelihood-based approach using normalizing flows to estimate both the unmixing function and the causal mechanisms, and demonstrate its effectiveness through extensive synthetic experiments in the CauCA and ICA setting. ",
    "url": "https://arxiv.org/abs/2305.17225",
    "authors": [
      "Wendong Liang",
      "Armin Keki\u0107",
      "Julius von K\u00fcgelgen",
      "Simon Buchholz",
      "Michel Besserve",
      "Luigi Gresele",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.17394",
    "title": "One-Step Knowledge Distillation and Fine-Tuning in Using Large  Pre-Trained Self-Supervised Learning Models for Speaker Verification",
    "abstract": "The application of speech self-supervised learning (SSL) models has achieved remarkable performance in speaker verification (SV). However, there is a computational cost hurdle in employing them, which makes development and deployment difficult. Several studies have simply compressed SSL models through knowledge distillation (KD) without considering the target task. Consequently, these methods could not extract SV-tailored features. This paper suggests One-Step Knowledge Distillation and Fine-Tuning (OS-KDFT), which incorporates KD and fine-tuning (FT). We optimize a student model for SV during KD training to avert the distillation of inappropriate information for the SV. OS-KDFT could downsize Wav2Vec 2.0 based ECAPA-TDNN size by approximately 76.2%, and reduce the SSL model's inference time by 79% while presenting an EER of 0.98%. The proposed OS-KDFT is validated across VoxCeleb1 and VoxCeleb2 datasets and W2V2 and HuBERT SSL models. Experiments are available on our GitHub. ",
    "url": "https://arxiv.org/abs/2305.17394",
    "authors": [
      "Jungwoo Heo",
      "Chan-yeong Lim",
      "Ju-ho Kim",
      "Hyun-seo Shin",
      "Ha-Jin Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.17536",
    "title": "On Locally Identifying Coloring of Cartesian Product and Tensor Product  of Graphs",
    "abstract": "For a positive integer $k$, a proper $k$-coloring of a graph $G$ is a mapping $f: V(G) \\rightarrow \\{1,2, \\ldots, k\\}$ such that $f(u) \\neq f(v)$ for each edge $uv \\in E(G)$. The smallest integer $k$ for which there is a proper $k$-coloring of $G$ is called chromatic number of $G$, denoted by $\\chi(G)$. A \\emph{locally identifying coloring} (for short, lid-coloring) of a graph $G$ is a proper $k$-coloring of $G$ such that every pair of adjacent vertices with distinct closed neighborhoods has distinct set of colors in their closed neighborhoods. The smallest integer $k$ such that $G$ has a lid-coloring with $k$ colors is called \\emph{locally identifying chromatic number} (for short, \\emph{lid-chromatic number}) of $G$, denoted by $\\chi_{lid}(G)$. In this paper, we study lid-coloring of Cartesian product and tensor product of two graphs. We prove that if $G$ and $H$ are two connected graphs having at least two vertices then (a) $\\chi_{lid}(G \\square H) \\leq \\chi(G) \\chi(H)-1$ and (b) $\\chi_{lid}(G \\times H) \\leq \\chi(G) \\chi(H)$. Here $G \\square H$ and $G \\times H$ denote the Cartesian and tensor products of $G$ and $H$ respectively. We also give exact values of lid-chromatic number of Cartesian product (resp. tensor product) of two paths, a cycle and a path, and two cycles. ",
    "url": "https://arxiv.org/abs/2305.17536",
    "authors": [
      "Sriram Bhyravarapu",
      "Swati Kumari",
      "I. Vinod Reddy"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2305.17583",
    "title": "On Neural Networks as Infinite Tree-Structured Probabilistic Graphical  Models",
    "abstract": "Deep neural networks (DNNs) lack the precise semantics and definitive probabilistic interpretation of probabilistic graphical models (PGMs). In this paper, we propose an innovative solution by constructing infinite tree-structured PGMs that correspond exactly to neural networks. Our research reveals that DNNs, during forward propagation, indeed perform approximations of PGM inference that are precise in this alternative PGM structure. Not only does our research complement existing studies that describe neural networks as kernel machines or infinite-sized Gaussian processes, it also elucidates a more direct approximation that DNNs make to exact inference in PGMs. Potential benefits include improved pedagogy and interpretation of DNNs, and algorithms that can merge the strengths of PGMs and DNNs. ",
    "url": "https://arxiv.org/abs/2305.17583",
    "authors": [
      "Boyao Li",
      "Alexandar J. Thomson",
      "Matthew M. Engelhard",
      "David Page"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.17724",
    "title": "Stochastic Pitch Prediction Improves the Diversity and Naturalness of  Speech in Glow-TTS",
    "abstract": "Flow-based generative models are widely used in text-to-speech (TTS) systems to learn the distribution of audio features (e.g., Mel-spectrograms) given the input tokens and to sample from this distribution to generate diverse utterances. However, in the zero-shot multi-speaker TTS scenario, the generated utterances lack diversity and naturalness. In this paper, we propose to improve the diversity of utterances by explicitly learning the distribution of fundamental frequency sequences (pitch contours) of each speaker during training using a stochastic flow-based pitch predictor, then conditioning the model on generated pitch contours during inference. The experimental results demonstrate that the proposed method yields a significant improvement in the naturalness and diversity of speech generated by a Glow-TTS model that uses explicit stochastic pitch prediction, over a Glow-TTS baseline and an improved Glow-TTS model that uses a stochastic duration predictor. ",
    "url": "https://arxiv.org/abs/2305.17724",
    "authors": [
      "Sewade Ogun",
      "Vincent Colotte",
      "Emmanuel Vincent"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.17956",
    "title": "On Color Critical Graphs of Star Coloring",
    "abstract": "A \\emph{star coloring} of a graph $G$ is a proper vertex-coloring such that no path on four vertices is $2$-colored. The minimum number of colors required to obtain a star coloring of a graph $G$ is called star chromatic number and it is denoted by $\\chi_s(G)$. A graph $G$ is called $k$-critical if $\\chi_s(G)=k$ and $\\chi_s(G -e) < \\chi_s(G)$ for every edge $e \\in E(G)$. In this paper, we give a characterization of 3-critical, $(n-1)$-critical and $(n-2)$-critical graphs with respect to star coloring, where $n$ denotes the number of vertices of $G$. We also give upper and lower bounds on the minimum number of edges in $(n-1)$-critical and $(n-2)$-critical graphs. ",
    "url": "https://arxiv.org/abs/2305.17956",
    "authors": [
      "Harshit Kumar Choudhary",
      "I. Vinod Reddy"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2305.18164",
    "title": "Generative Adversarial Networks based Skin Lesion Segmentation",
    "abstract": "Skin cancer is a serious condition that requires accurate identification and treatment. One way to assist clinicians in this task is by using computer-aided diagnosis (CAD) tools that can automatically segment skin lesions from dermoscopic images. To this end, a new adversarial learning-based framework called EGAN has been developed. This framework uses an unsupervised generative network to generate accurate lesion masks. It consists of a generator module with a top-down squeeze excitation-based compound scaled path and an asymmetric lateral connection-based bottom-up path, and a discriminator module that distinguishes between original and synthetic masks. Additionally, a morphology-based smoothing loss is implemented to encourage the network to create smooth semantic boundaries of lesions. The framework is evaluated on the International Skin Imaging Collaboration (ISIC) Lesion Dataset 2018 and outperforms the current state-of-the-art skin lesion segmentation approaches with a Dice coefficient, Jaccard similarity, and Accuracy of 90.1%, 83.6%, and 94.5%, respectively. This represents a 2% increase in Dice Coefficient, 1% increase in Jaccard Index, and 1% increase in Accuracy. ",
    "url": "https://arxiv.org/abs/2305.18164",
    "authors": [
      "Shubham Innani",
      "Prasad Dutande",
      "Bhakti Baheti",
      "Venu Pokuri",
      "Ujjwal Baid",
      "Sanjay Talbar",
      "Sharath Chandra Guntuku"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18210",
    "title": "Learning Causal Graphs via Monotone Triangular Transport Maps",
    "abstract": "We study the problem of causal structure learning from data using optimal transport (OT). Specifically, we first provide a constraint-based method which builds upon lower-triangular monotone parametric transport maps to design conditional independence tests which are agnostic to the noise distribution. We provide an algorithm for causal discovery up to Markov Equivalence with no assumptions on the structural equations/noise distributions, which allows for settings with latent variables. Our approach also extends to score-based causal discovery by providing a novel means for defining scores. This allows us to uniquely recover the causal graph under additional identifiability and structural assumptions, such as additive noise or post-nonlinear models. We provide experimental results to compare the proposed approach with the state of the art on both synthetic and real-world datasets. ",
    "url": "https://arxiv.org/abs/2305.18210",
    "authors": [
      "Sina Akbari",
      "Luca Ganassali",
      "Negar Kiyavash"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.18211",
    "title": "TCN AA: A Wi Fi based Temporal Convolution Network for Human to Human  Interaction Recognition with Augmentation and Attention",
    "abstract": "The utilization of Wi-Fi-based human activity recognition (HAR) has gained considerable interest in recent times, primarily owing to its applications in various domains such as healthcare for monitoring breath and heart rate, security, elderly care, and others. These Wi-Fi-based methods exhibit several advantages over conventional state-of-the-art techniques that rely on cameras and sensors, including lower costs and ease of deployment. However, a significant challenge associated with Wi-Fi-based HAR is the significant decline in performance when the scene or subject changes. To mitigate this issue, it is imperative to train the model using an extensive dataset. In recent studies, the utilization of CNN-based models or sequence-to-sequence models such as LSTM, GRU, or Transformer has become prevalent. While sequence-to-sequence models can be more precise, they are also more computationally intensive and require a larger amount of training data. To tackle these limitations, we propose a novel approach that leverages a temporal convolution network with augmentations and attention, referred to as TCN-AA. Our proposed method is computationally efficient and exhibits improved accuracy even when the data size is increased threefold through our augmentation techniques. Our experiments on a publicly available dataset indicate that our approach outperforms existing state-of-the-art methods, with a final accuracy of 99.42%. ",
    "url": "https://arxiv.org/abs/2305.18211",
    "authors": [
      "Chia-Yu Lin",
      "Yu-Tso Liu",
      "Chih-Yang Lin",
      "Timothy K. Shih"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.18234",
    "title": "Temporal Aware Mixed Attention-based Convolution and Transformer Network  (MACTN) for EEG Emotion Recognition",
    "abstract": "Emotion recognition plays a crucial role in human-computer interaction, and electroencephalography (EEG) is advantageous for reflecting human emotional states. In this study, we propose MACTN, a hierarchical hybrid model for jointly modeling local and global temporal information. The model is inspired by neuroscience research on the temporal dynamics of emotions. MACTN extracts local emotional features through a convolutional neural network (CNN) and integrates sparse global emotional features through a transformer. Moreover, we employ channel attention mechanisms to identify the most task-relevant channels. Through extensive experimentation on two publicly available datasets, namely THU-EP and DEAP, our proposed method, MACTN, consistently achieves superior classification accuracy and F1 scores compared to other existing methods in most experimental settings. Furthermore, ablation studies have shown that the integration of both self-attention mechanisms and channel attention mechanisms leads to improved classification performance. Finally, an earlier version of this method, which shares the same ideas, won the Emotional BCI Competition's final championship in the 2022 World Robot Contest. ",
    "url": "https://arxiv.org/abs/2305.18234",
    "authors": [
      "Xiaopeng Si",
      "Dong Huang",
      "Yulin Sun",
      "Dong Ming"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.18270",
    "title": "Learning Two-Layer Neural Networks, One (Giant) Step at a Time",
    "abstract": "We study the training dynamics of shallow neural networks, investigating the conditions under which a limited number of large batch gradient descent steps can facilitate feature learning beyond the kernel regime. We compare the influence of batch size and that of multiple (but finitely many) steps. Our analysis of a single-step process reveals that while a batch size of $n = O(d)$ enables feature learning, it is only adequate for learning a single direction, or a single-index model. In contrast, $n = O(d^2)$ is essential for learning multiple directions and specialization. Moreover, we demonstrate that ``hard'' directions, which lack the first $\\ell$ Hermite coefficients, remain unobserved and require a batch size of $n = O(d^\\ell)$ for being captured by gradient descent. Upon iterating a few steps, the scenario changes: a batch-size of $n = O(d)$ is enough to learn new target directions spanning the subspace linearly connected in the Hermite basis to the previously learned directions, thereby a staircase property. Our analysis utilizes a blend of techniques related to concentration, projection-based conditioning, and Gaussian equivalence that are of independent interest. By determining the conditions necessary for learning and specialization, our results highlight the interaction between batch size and number of iterations, and lead to a hierarchical depiction where learning performance exhibits a stairway to accuracy over time and batch size, shedding new light on feature learning in neural networks. ",
    "url": "https://arxiv.org/abs/2305.18270",
    "authors": [
      "Yatin Dandi",
      "Florent Krzakala",
      "Bruno Loureiro",
      "Luca Pesce",
      "Ludovic Stephan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2005.00858",
    "title": "Minimum Cuts in Geometric Intersection Graphs",
    "abstract": " Comments: 11 pages, 4 figures; this version corrects a small bug in the proof of Lemma 5. We thank Matej Marinko for pointing this out ",
    "url": "https://arxiv.org/abs/2005.00858",
    "authors": [
      "Sergio Cabello",
      "Wolfgang Mulzer"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2006.07356",
    "title": "Implicit Bias of Gradient Descent for Mean Squared Error Regression with  Two-Layer Wide Neural Networks",
    "abstract": " Comments: 97 pages, 14 figures. Added the discussion of SGD and implications to generalization ",
    "url": "https://arxiv.org/abs/2006.07356",
    "authors": [
      "Hui Jin",
      "Guido Mont\u00fafar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.11760",
    "title": "Fingerprinting Generative Adversarial Networks",
    "abstract": " Title: Fingerprinting Generative Adversarial Networks ",
    "url": "https://arxiv.org/abs/2106.11760",
    "authors": [
      "Guanlin Li",
      "Guowen Xu",
      "Han Qiu",
      "Shangwei Guo",
      "Run Wang",
      "Jiwei Li",
      "Tianwei Zhang",
      "Rongxing Lu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2107.05225",
    "title": "Compositional Vulnerability Detection with Insecurity Separation Logic",
    "abstract": " Title: Compositional Vulnerability Detection with Insecurity Separation Logic ",
    "url": "https://arxiv.org/abs/2107.05225",
    "authors": [
      "Toby Murray",
      "Pengbo Yan",
      "Gidon Ernst"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Cryptography and Security (cs.CR)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2109.11926",
    "title": "Sinkhorn Distributionally Robust Optimization",
    "abstract": " Comments: 56 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2109.11926",
    "authors": [
      "Jie Wang",
      "Rui Gao",
      "Yao Xie"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.06174",
    "title": "Does the Brain Infer Invariance Transformations from Graph Symmetries?",
    "abstract": " Title: Does the Brain Infer Invariance Transformations from Graph Symmetries? ",
    "url": "https://arxiv.org/abs/2111.06174",
    "authors": [
      "Helmut Linde"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2111.10635",
    "title": "HeterPS: Distributed Deep Learning With Reinforcement Learning Based  Scheduling in Heterogeneous Environments",
    "abstract": " Comments: 14 pages, 11 figures, 2 tables; To appear in Future Generation Computer Systems (FGCS) ",
    "url": "https://arxiv.org/abs/2111.10635",
    "authors": [
      "Ji Liu",
      "Zhihua Wu",
      "Dianhai Yu",
      "Yanjun Ma",
      "Danlei Feng",
      "Minxu Zhang",
      "Xinxuan Wu",
      "Xuefeng Yao",
      "Dejing Dou"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2112.14869",
    "title": "Label Distributionally Robust Losses for Multi-class Classification:  Consistency, Robustness and Adaptivity",
    "abstract": " Comments: To appear in ICML2023; 37 pages ",
    "url": "https://arxiv.org/abs/2112.14869",
    "authors": [
      "Dixian Zhu",
      "Yiming Ying",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.09186",
    "title": "pvCNN: Privacy-Preserving and Verifiable Convolutional Neural Network  Testing",
    "abstract": " Title: pvCNN: Privacy-Preserving and Verifiable Convolutional Neural Network  Testing ",
    "url": "https://arxiv.org/abs/2201.09186",
    "authors": [
      "Jiasi Weng",
      "Jian Weng",
      "Gui Tang",
      "Anjia Yang",
      "Ming Li",
      "Jia-Nan Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02751",
    "title": "Tubes Among Us: Analog Attack on Automatic Speaker Identification",
    "abstract": " Comments: Published at USENIX Security 2023 this https URL ",
    "url": "https://arxiv.org/abs/2202.02751",
    "authors": [
      "Shimaa Ahmed",
      "Yash Wani",
      "Ali Shahin Shamsabadi",
      "Mohammad Yaghini",
      "Ilia Shumailov",
      "Nicolas Papernot",
      "Kassem Fawaz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2204.11970",
    "title": "Visual Acuity Prediction on Real-Life Patient Data Using a Machine  Learning Based Multistage System",
    "abstract": " Comments: Scientific Reports preprint ",
    "url": "https://arxiv.org/abs/2204.11970",
    "authors": [
      "Tobias Schlosser",
      "Frederik Beuth",
      "Trixy Meyer",
      "Arunodhayan Sampath Kumar",
      "Gabriel Stolze",
      "Olga Furashova",
      "Katrin Engelmann",
      "Danny Kowerko"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10053",
    "title": "What's Behind the Mask: Understanding Masked Graph Modeling for Graph  Autoencoders",
    "abstract": " Comments: KDD 2023 research track. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2205.10053",
    "authors": [
      "Jintang Li",
      "Ruofan Wu",
      "Wangbin Sun",
      "Liang Chen",
      "Sheng Tian",
      "Liang Zhu",
      "Changhua Meng",
      "Zibin Zheng",
      "Weiqiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.12700",
    "title": "BITE: Textual Backdoor Attacks with Iterative Trigger Injection",
    "abstract": " Comments: Accepted to ACL 2023 ",
    "url": "https://arxiv.org/abs/2205.12700",
    "authors": [
      "Jun Yan",
      "Vansh Gupta",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2206.02139",
    "title": "Early Stage Convergence and Global Convergence of Training Mildly  Parameterized Neural Networks",
    "abstract": " Comments: 73 pages ",
    "url": "https://arxiv.org/abs/2206.02139",
    "authors": [
      "Mingze Wang",
      "Chao Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2206.03299",
    "title": "Generalization Error Bounds for Deep Neural Networks Trained by SGD",
    "abstract": " Comments: 32 pages ",
    "url": "https://arxiv.org/abs/2206.03299",
    "authors": [
      "Mingze Wang",
      "Chao Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.05764",
    "title": "Mining Multi-Label Samples from Single Positive Labels",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2206.05764",
    "authors": [
      "Youngin Cho",
      "Daejin Kim",
      "Mohammad Azam Khan",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.03367",
    "title": "Joint Super-Resolution and Inverse Tone-Mapping: A Feature Decomposition  Aggregation Network and A New Benchmark",
    "abstract": " Title: Joint Super-Resolution and Inverse Tone-Mapping: A Feature Decomposition  Aggregation Network and A New Benchmark ",
    "url": "https://arxiv.org/abs/2207.03367",
    "authors": [
      "Gang Xu",
      "Yu-chen Yang",
      "Liang Wang",
      "Jun Xu",
      "Xian-Tong Zhen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09529",
    "title": "COVID-19 Detection from Respiratory Sounds with Hierarchical Spectrogram  Transformers",
    "abstract": " Title: COVID-19 Detection from Respiratory Sounds with Hierarchical Spectrogram  Transformers ",
    "url": "https://arxiv.org/abs/2207.09529",
    "authors": [
      "Idil Aytekin",
      "Onat Dalmaz",
      "Kaan Gonc",
      "Haydar Ankishan",
      "Emine U Saritas",
      "Ulas Bagci",
      "Haydar Celik",
      "Tolga Cukur"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2207.09531",
    "title": "LR-Net: A Block-based Convolutional Neural Network for Low-Resolution  Image Classification",
    "abstract": " Comments: Accepted on Iranian Journal of Science and Technology, Transactions of Electrical Engineering. Containing 7 pages, 5 figures and 2 tables ",
    "url": "https://arxiv.org/abs/2207.09531",
    "authors": [
      "Ashkan Ganj",
      "Mohsen Ebadpour",
      "Mahdi Darvish",
      "Hamid Bahador"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.02448",
    "title": "Deep Progressive Feature Aggregation Network for High Dynamic Range  Imaging",
    "abstract": " Title: Deep Progressive Feature Aggregation Network for High Dynamic Range  Imaging ",
    "url": "https://arxiv.org/abs/2208.02448",
    "authors": [
      "Jun Xiao",
      "Qian Ye",
      "Tianshan Liu",
      "Cong Zhang",
      "Kin-Man Lam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2208.05447",
    "title": "Robust Methods for High-Dimensional Linear Learning",
    "abstract": " Comments: accepted version ",
    "url": "https://arxiv.org/abs/2208.05447",
    "authors": [
      "Ibrahim Merad",
      "St\u00e9phane Ga\u00efffas"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.06800",
    "title": "MGG: Accelerating Graph Neural Networks with Fine-grained intra-kernel  Communication-Computation Pipelining on Multi-GPU Platforms",
    "abstract": " Title: MGG: Accelerating Graph Neural Networks with Fine-grained intra-kernel  Communication-Computation Pipelining on Multi-GPU Platforms ",
    "url": "https://arxiv.org/abs/2209.06800",
    "authors": [
      "Yuke Wang",
      "Boyuan Feng",
      "Zheng Wang",
      "Tong Geng",
      "Kevin Barker",
      "Ang Li",
      "Yufei Ding"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.10837",
    "title": "A Spatial-channel-temporal-fused Attention for Spiking Neural Networks",
    "abstract": " Comments: 14 pages, 9 figures, 5 tabes; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2209.10837",
    "authors": [
      "Wuque Cai",
      "Hongze Sun",
      "Rui Liu",
      "Yan Cui",
      "Jun Wang",
      "Yang Xia",
      "Dezhong Yao",
      "Daqing Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2209.15097",
    "title": "Likelihood Adjusted Semidefinite Programs for Clustering Heterogeneous  Data",
    "abstract": " Comments: Accepted to ICML 2023 ",
    "url": "https://arxiv.org/abs/2209.15097",
    "authors": [
      "Yubo Zhuang",
      "Xiaohui Chen",
      "Yun Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2209.15135",
    "title": "Learning an Efficient Terrain Representation for Haptic Localization of  a Legged Robot",
    "abstract": " Comments: Accepted for IEEE International Conference on Robotics and Automation (ICRA) 2023 ",
    "url": "https://arxiv.org/abs/2209.15135",
    "authors": [
      "Damian S\u00f3jka",
      "Micha\u0142 R. Nowicki",
      "Piotr Skrzypczy\u0144ski"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.15483",
    "title": "Augmentation Invariant Discrete Representation for Generative Spoken  Language Modeling",
    "abstract": " Title: Augmentation Invariant Discrete Representation for Generative Spoken  Language Modeling ",
    "url": "https://arxiv.org/abs/2209.15483",
    "authors": [
      "Itai Gat",
      "Felix Kreuk",
      "Tu Anh Nguyen",
      "Ann Lee",
      "Jade Copet",
      "Gabriel Synnaeve",
      "Emmanuel Dupoux",
      "Yossi Adi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.00313",
    "title": "CRISP: Curriculum based Sequential Neural Decoders for Polar Code Family",
    "abstract": " Comments: 23 pages, 23 figures. ICML 2023 ",
    "url": "https://arxiv.org/abs/2210.00313",
    "authors": [
      "S Ashwin Hebbar",
      "Viraj Nadkarni",
      "Ashok Vardhan Makkuva",
      "Suma Bhat",
      "Sewoong Oh",
      "Pramod Viswanath"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.04813",
    "title": "Stochastic Robustness Interval for Motion Planning with Signal Temporal  Logic",
    "abstract": " Title: Stochastic Robustness Interval for Motion Planning with Signal Temporal  Logic ",
    "url": "https://arxiv.org/abs/2210.04813",
    "authors": [
      "Roland B. Ilyes",
      "Qi Heng Ho",
      "Morteza Lahijanian"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.10175",
    "title": "Intra-Source Style Augmentation for Improved Domain Generalization",
    "abstract": " Comments: Accepted at WACV 2023. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2210.10175",
    "authors": [
      "Yumeng Li",
      "Dan Zhang",
      "Margret Keuper",
      "Anna Khoreva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13710",
    "title": "Motif-Backdoor: Rethinking the Backdoor Attack on Graph Neural Networks  via Motifs",
    "abstract": " Title: Motif-Backdoor: Rethinking the Backdoor Attack on Graph Neural Networks  via Motifs ",
    "url": "https://arxiv.org/abs/2210.13710",
    "authors": [
      "Haibin Zheng",
      "Haiyang Xiong",
      "Jinyin Chen",
      "Haonan Ma",
      "Guohan Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.14016",
    "title": "Shortest Edit Path Crossover: A Theory-driven Solution to the  Permutation Problem in Evolutionary Neural Architecture Search",
    "abstract": " Comments: Published in ICML 2023 ",
    "url": "https://arxiv.org/abs/2210.14016",
    "authors": [
      "Xin Qiu",
      "Risto Miikkulainen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.16658",
    "title": "Perturbation Analysis of Neural Collapse",
    "abstract": " Comments: ICML 2023 ",
    "url": "https://arxiv.org/abs/2210.16658",
    "authors": [
      "Tom Tirer",
      "Haoxiang Huang",
      "Jonathan Niles-Weed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.17152",
    "title": "Audio Time-Scale Modification with Temporal Compressing Networks",
    "abstract": " Title: Audio Time-Scale Modification with Temporal Compressing Networks ",
    "url": "https://arxiv.org/abs/2210.17152",
    "authors": [
      "Ernie Chu",
      "Ju-Ting Chen",
      "Chia-Ping Chen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.17456",
    "title": "Audio-Visual Speech Enhancement and Separation by Leveraging Multi-Modal  Self-Supervised Embeddings",
    "abstract": " Comments: ICASSP AMHAT 2023 ",
    "url": "https://arxiv.org/abs/2210.17456",
    "authors": [
      "I-Chun Chern",
      "Kuo-Hsuan Hung",
      "Yi-Ting Chen",
      "Tassadaq Hussain",
      "Mandar Gogate",
      "Amir Hussain",
      "Yu Tsao",
      "Jen-Cheng Hou"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.06302",
    "title": "GCondNet: A Novel Method for Improving Neural Networks on Small  High-Dimensional Tabular Data",
    "abstract": " Comments: Early version presented at the 17th Machine Learning in Computational Biology (MLCB) meeting, 2022 ",
    "url": "https://arxiv.org/abs/2211.06302",
    "authors": [
      "Andrei Margeloiu",
      "Nikola Simidjievski",
      "Pietro Lio",
      "Mateja Jamnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2211.06892",
    "title": "OverFlow: Putting flows on top of neural transducers for better TTS",
    "abstract": " Comments: 5 pages, 2 figures. Accepted for publication at Interspeech 2023 ",
    "url": "https://arxiv.org/abs/2211.06892",
    "authors": [
      "Shivam Mehta",
      "Ambika Kirkland",
      "Harm Lameris",
      "Jonas Beskow",
      "\u00c9va Sz\u00e9kely",
      "Gustav Eje Henter"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.07044",
    "title": "SSL4EO-S12: A Large-Scale Multi-Modal, Multi-Temporal Dataset for  Self-Supervised Learning in Earth Observation",
    "abstract": " Comments: Accepted by IEEE Geoscience and Remote Sensing Magazine. 18 pages ",
    "url": "https://arxiv.org/abs/2211.07044",
    "authors": [
      "Yi Wang",
      "Nassim Ait Ali Braham",
      "Zhitong Xiong",
      "Chenying Liu",
      "Conrad M Albrecht",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.07159",
    "title": "Gallai's Path Decomposition for 2-degenerate Graphs",
    "abstract": " Comments: 11 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2211.07159",
    "authors": [
      "Nevil Anto",
      "Manu Basavaraju"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2211.08257",
    "title": "AutoTherm: A Dataset and Ablation Study for Thermal Comfort Prediction  in Vehicles",
    "abstract": " Title: AutoTherm: A Dataset and Ablation Study for Thermal Comfort Prediction  in Vehicles ",
    "url": "https://arxiv.org/abs/2211.08257",
    "authors": [
      "Mark Colley",
      "Sebastian Hartwig",
      "Albin Zeqiri",
      "Timo Ropinski",
      "Enrico Rukzio"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2211.08486",
    "title": "Scalar Invariant Networks with Zero Bias",
    "abstract": " Comments: 22 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2211.08486",
    "authors": [
      "Chuqin Geng",
      "Xiaojie Xu",
      "Haolin Ye",
      "Xujie Si"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11616",
    "title": "Learning Heterogeneous Agent Cooperation via Multiagent League Training",
    "abstract": " Title: Learning Heterogeneous Agent Cooperation via Multiagent League Training ",
    "url": "https://arxiv.org/abs/2211.11616",
    "authors": [
      "Qingxu Fu",
      "Xiaolin Ai",
      "Jianqiang Yi",
      "Tenghai Qiu",
      "Wanmai Yuan",
      "Zhiqiang Pu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.14221",
    "title": "Learning Large Causal Structures from Inverse Covariance Matrix via  Matrix Decomposition",
    "abstract": " Title: Learning Large Causal Structures from Inverse Covariance Matrix via  Matrix Decomposition ",
    "url": "https://arxiv.org/abs/2211.14221",
    "authors": [
      "Shuyu Dong",
      "Kento Uemura",
      "Akito Fujii",
      "Shuang Chang",
      "Yusuke Koyanagi",
      "Koji Maruhashi",
      "Mich\u00e8le Sebag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2211.14545",
    "title": "Ensemble Multi-Quantiles: Adaptively Flexible Distribution Prediction  for Uncertainty Quantification",
    "abstract": " Title: Ensemble Multi-Quantiles: Adaptively Flexible Distribution Prediction  for Uncertainty Quantification ",
    "url": "https://arxiv.org/abs/2211.14545",
    "authors": [
      "Xing Yan",
      "Yonghua Su",
      "Wenxuan Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.15762",
    "title": "Understanding the Impact of Adversarial Robustness on Accuracy Disparity",
    "abstract": " Comments: Accepted at ICML 2023 ",
    "url": "https://arxiv.org/abs/2211.15762",
    "authors": [
      "Yuzheng Hu",
      "Fan Wu",
      "Hongyang Zhang",
      "Han Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.16098",
    "title": "Three-stage binarization of color document images based on discrete  wavelet transform and generative adversarial networks",
    "abstract": " Title: Three-stage binarization of color document images based on discrete  wavelet transform and generative adversarial networks ",
    "url": "https://arxiv.org/abs/2211.16098",
    "authors": [
      "Yu-Shian Lin",
      "Rui-Yang Ju",
      "Chih-Chia Chen",
      "Ting-Yu Lin",
      "Jen-Shiun Chiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.03228",
    "title": "ISAACS: Iterative Soft Adversarial Actor-Critic for Safety",
    "abstract": " Comments: Accepted in 5th Annual Learning for Dynamics & Control Conference (L4DC), University of Pennsylvania ",
    "url": "https://arxiv.org/abs/2212.03228",
    "authors": [
      "Kai-Chieh Hsu",
      "Duy Phuong Nguyen",
      "Jaime Fern\u00e1ndez Fisac"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.05581",
    "title": "Efficient Relation-aware Neighborhood Aggregation in Graph Neural  Networks via Tensor Decomposition",
    "abstract": " Comments: 13 pages, 5 Tables, 2 Figures ",
    "url": "https://arxiv.org/abs/2212.05581",
    "authors": [
      "Peyman Baghershahi",
      "Reshad Hosseini",
      "Hadi Moradi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.08909",
    "title": "Controlling Styles in Neural Machine Translation with Activation Prompt",
    "abstract": " Comments: Accepted by Findings of ACL 2023; The code is available at this https URL ",
    "url": "https://arxiv.org/abs/2212.08909",
    "authors": [
      "Yifan Wang",
      "Zewei Sun",
      "Shanbo Cheng",
      "Weiguo Zheng",
      "Mingxuan Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.08929",
    "title": "Modeling Instance Interactions for Joint Information Extraction with  Neural High-Order Conditional Random Field",
    "abstract": " Title: Modeling Instance Interactions for Joint Information Extraction with  Neural High-Order Conditional Random Field ",
    "url": "https://arxiv.org/abs/2212.08929",
    "authors": [
      "Zixia Jia",
      "Zhaohui Yan",
      "Wenjuan Han",
      "Zilong Zheng",
      "Kewei Tu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.09170",
    "title": "On Isotropy, Contextualization and Learning Dynamics of  Contrastive-based Sentence Representation Learning",
    "abstract": " Comments: Accepted by ACL 2023 (Findings, long paper) ",
    "url": "https://arxiv.org/abs/2212.09170",
    "authors": [
      "Chenghao Xiao",
      "Yang Long",
      "Noura Al Moubayed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.05308",
    "title": "Incremental Dead State Detection in Logarithmic Time",
    "abstract": " Comments: 22 pages + references ",
    "url": "https://arxiv.org/abs/2301.05308",
    "authors": [
      "Caleb Stanford",
      "Margus Veanes"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2301.07475",
    "title": "Curvilinear object segmentation in medical images based on ODoS filter  and deep learning network",
    "abstract": " Comments: 20 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2301.07475",
    "authors": [
      "Yuanyuan Peng",
      "Lin Pan",
      "Pengpeng Luan",
      "Hongbin Tu",
      "Xiong Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.11351",
    "title": "Estimating Causal Effects using a Multi-task Deep Ensemble",
    "abstract": " Comments: 18 pages, 7 figures, 3 tables, published at the 40th International Conference on Machine Learning (ICML 2023) ",
    "url": "https://arxiv.org/abs/2301.11351",
    "authors": [
      "Ziyang Jiang",
      "Zhuoran Hou",
      "Yiling Liu",
      "Yiman Ren",
      "Keyu Li",
      "David Carlson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.11374",
    "title": "Certifiably Robust Reinforcement Learning through Model-Based Abstract  Interpretation",
    "abstract": " Title: Certifiably Robust Reinforcement Learning through Model-Based Abstract  Interpretation ",
    "url": "https://arxiv.org/abs/2301.11374",
    "authors": [
      "Chenxi Yang",
      "Greg Anderson",
      "Swarat Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.11508",
    "title": "Theme-driven Keyphrase Extraction to Analyze Social Media Discourse",
    "abstract": " Comments: 11 pages, 2 figures, submitted to ICWSM. This version represents a substantial expansion and refocus of the previous manuscript, including new experiments, expanded data analysis, and comprehensive discussions ",
    "url": "https://arxiv.org/abs/2301.11508",
    "authors": [
      "William Romano",
      "Omar Sharif",
      "Madhusudan Basak",
      "Joseph Gatto",
      "Sarah Preum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2301.12874",
    "title": "Extremal Domain Translation with Neural Optimal Transport",
    "abstract": " Title: Extremal Domain Translation with Neural Optimal Transport ",
    "url": "https://arxiv.org/abs/2301.12874",
    "authors": [
      "Milena Gazdieva",
      "Alexander Korotin",
      "Daniil Selikhanovych",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.00878",
    "title": "The contextual lasso: Sparse linear models via deep neural networks",
    "abstract": " Title: The contextual lasso: Sparse linear models via deep neural networks ",
    "url": "https://arxiv.org/abs/2302.00878",
    "authors": [
      "Ryan Thompson",
      "Amir Dezfouli",
      "Robert Kohn"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2302.01313",
    "title": "Inductive Link Prediction for Both New Nodes and New Relation Types via  Double Equivariance",
    "abstract": " Title: Inductive Link Prediction for Both New Nodes and New Relation Types via  Double Equivariance ",
    "url": "https://arxiv.org/abs/2302.01313",
    "authors": [
      "Jianfei Gao",
      "Yangze Zhou",
      "Jincheng Zhou",
      "Bruno Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.01375",
    "title": "On the Robustness of Randomized Ensembles to Adversarial Perturbations",
    "abstract": " Comments: Published as a conference paper in ICML 2023 ",
    "url": "https://arxiv.org/abs/2302.01375",
    "authors": [
      "Hassan Dbouk",
      "Naresh R. Shanbhag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.01629",
    "title": "Beyond the Universal Law of Robustness: Sharper Laws for Random Features  and Neural Tangent Kernels",
    "abstract": " Comments: Second arxiv version, updated to the icml23 version of the paper ",
    "url": "https://arxiv.org/abs/2302.01629",
    "authors": [
      "Simone Bombari",
      "Shayan Kiyani",
      "Marco Mondelli"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.02013",
    "title": "IoT Botnet Detection Using an Economic Deep Learning Model",
    "abstract": " Comments: Accepted in IEEE AIIoT 2023 conference ",
    "url": "https://arxiv.org/abs/2302.02013",
    "authors": [
      "Nelly Elsayed",
      "Zag ElSayed",
      "Magdy Bayoumi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.03519",
    "title": "Efficient Parametric Approximations of Neural Network Function Space  Distance",
    "abstract": " Comments: 18 pages, 5 figures, ICML 2023 ",
    "url": "https://arxiv.org/abs/2302.03519",
    "authors": [
      "Nikita Dhawan",
      "Sicong Huang",
      "Juhan Bae",
      "Roger Grosse"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.04237",
    "title": "Black Box Adversarial Prompting for Foundation Models",
    "abstract": " Title: Black Box Adversarial Prompting for Foundation Models ",
    "url": "https://arxiv.org/abs/2302.04237",
    "authors": [
      "Natalie Maus",
      "Patrick Chao",
      "Eric Wong",
      "Jacob Gardner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.06381",
    "title": "Self-supervised phase unwrapping in fringe projection profilometry",
    "abstract": " Title: Self-supervised phase unwrapping in fringe projection profilometry ",
    "url": "https://arxiv.org/abs/2302.06381",
    "authors": [
      "Xiaomin Gao",
      "Wanzhong Song",
      "Chunqian Tan",
      "Junzhe Lei"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.06594",
    "title": "Geometric Clifford Algebra Networks",
    "abstract": " Title: Geometric Clifford Algebra Networks ",
    "url": "https://arxiv.org/abs/2302.06594",
    "authors": [
      "David Ruhe",
      "Jayesh K. Gupta",
      "Steven de Keninck",
      "Max Welling",
      "Johannes Brandstetter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.07025",
    "title": "Optimal Transport for Change Detection on LiDAR Point Clouds",
    "abstract": " Comments: Accepted to IEEE International Geoscience and Remote Sensing Symposium 2023 (IGARSS 2023) @IEEE copyright ",
    "url": "https://arxiv.org/abs/2302.07025",
    "authors": [
      "Marco Fiorucci",
      "Peter Naylor",
      "Makoto Yamada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.07106",
    "title": "Normalizing Flow based Feature Synthesis for Outlier-Aware Object  Detection",
    "abstract": " Comments: Accepted as CVPR 2023 Highlight (Top 10% of all acceptance) ",
    "url": "https://arxiv.org/abs/2302.07106",
    "authors": [
      "Nishant Kumar",
      "Sini\u0161a \u0160egvi\u0107",
      "Abouzar Eslami",
      "Stefan Gumhold"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.09527",
    "title": "SanskritShala: A Neural Sanskrit NLP Toolkit with Web-Based Interface  for Pedagogical and Annotation Purposes",
    "abstract": " Comments: 7 pages, Accepted at ACL23 (Demo track) to be held at Toronto, Canada ",
    "url": "https://arxiv.org/abs/2302.09527",
    "authors": [
      "Jivnesh Sandhan",
      "Anshul Agarwal",
      "Laxmidhar Behera",
      "Tushar Sandhan",
      "Pawan Goyal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2302.09712",
    "title": "Depth Degeneracy in Neural Networks: Vanishing Angles in Fully Connected  ReLU Networks on Initialization",
    "abstract": " Comments: Minor updates and exposition improved. 37 pages, comments welcome ",
    "url": "https://arxiv.org/abs/2302.09712",
    "authors": [
      "Cameron Jakub",
      "Mihai Nica"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2302.10255",
    "title": "NeuralStagger: Accelerating Physics-constrained Neural PDE Solver with  Spatial-temporal Decomposition",
    "abstract": " Comments: ICML 2023 accepted ",
    "url": "https://arxiv.org/abs/2302.10255",
    "authors": [
      "Xinquan Huang",
      "Wenlei Shi",
      "Qi Meng",
      "Yue Wang",
      "Xiaotian Gao",
      "Jia Zhang",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2302.10802",
    "title": "A Novel Noise Injection-based Training Scheme for Better Model  Robustness",
    "abstract": " Title: A Novel Noise Injection-based Training Scheme for Better Model  Robustness ",
    "url": "https://arxiv.org/abs/2302.10802",
    "authors": [
      "Zeliang Zhang",
      "Jinyang Jiang",
      "Minjie Chen",
      "Zhiyuan Wang",
      "Yijie Peng",
      "Zhaofei Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.12597",
    "title": "Active Velocity Estimation using Light Curtains via Self-Supervised  Multi-Armed Bandits",
    "abstract": " Comments: 9 pages (main paper), 3 pages (references), 9 pages (appendix) ",
    "url": "https://arxiv.org/abs/2302.12597",
    "authors": [
      "Siddharth Ancha",
      "Gaurav Pathak",
      "Ji Zhang",
      "Srinivasa Narasimhan",
      "David Held"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.13390",
    "title": "MDF-Net for Abnormality Detection by Fusing X-Rays with Clinical Data",
    "abstract": " Title: MDF-Net for Abnormality Detection by Fusing X-Rays with Clinical Data ",
    "url": "https://arxiv.org/abs/2302.13390",
    "authors": [
      "Chihcheng Hsieh",
      "Isabel Blanco Nobre",
      "Sandra Costa Sousa",
      "Chun Ouyang",
      "Margot Brereton",
      "Jacinto C. Nascimento",
      "Joaquim Jorge",
      "Catarina Moreira"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.13457",
    "title": "A Self-Supervised Learning-based Approach to Clustering Multivariate  Time-Series Data with Missing Values (SLAC-Time): An Application to TBI  Phenotyping",
    "abstract": " Comments: Submitted to the Journal of Biomedical Informatics ",
    "url": "https://arxiv.org/abs/2302.13457",
    "authors": [
      "Hamid Ghaderi",
      "Brandon Foreman",
      "Amin Nayebi",
      "Sindhu Tipirneni",
      "Chandan K. Reddy",
      "Vignesh Subbian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.14349",
    "title": "Advantages of Asynchronous Measurement-Device-Independent Quantum Key  Distribution in Intercity Networks",
    "abstract": " Title: Advantages of Asynchronous Measurement-Device-Independent Quantum Key  Distribution in Intercity Networks ",
    "url": "https://arxiv.org/abs/2302.14349",
    "authors": [
      "Yuan-Mei Xie",
      "Jun-Lin Bai",
      "Yu-Shuo Lu",
      "Chen-Xun Weng",
      "Hua-Lei Yin",
      "Zeng-Bing Chen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2303.02876",
    "title": "Metaheuristic conditional neural network for harvesting skyrmionic  metastable states",
    "abstract": " Title: Metaheuristic conditional neural network for harvesting skyrmionic  metastable states ",
    "url": "https://arxiv.org/abs/2303.02876",
    "authors": [
      "Qichen Xu",
      "I. P. Miranda",
      "Manuel Pereiro",
      "Filipp N. Rybakov",
      "Danny Thonig",
      "Erik Sj\u00f6qvist",
      "Pavel Bessarab",
      "Anders Bergman",
      "Olle Eriksson",
      "Pawel Herman",
      "Anna Delin"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.03320",
    "title": "Learning to Backdoor Federated Learning",
    "abstract": " Title: Learning to Backdoor Federated Learning ",
    "url": "https://arxiv.org/abs/2303.03320",
    "authors": [
      "Henger Li",
      "Chen Wu",
      "Sencun Zhu",
      "Zizhan Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2303.05329",
    "title": "Tucker Bilinear Attention Network for Multi-scale Remote Sensing Object  Detection",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:1705.06676, arXiv:2209.13351 by other authors ",
    "url": "https://arxiv.org/abs/2303.05329",
    "authors": [
      "Tao Chen",
      "Ruirui Li",
      "Jiafeng Fu",
      "Daguang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.05607",
    "title": "An Improved Data Augmentation Scheme for Model Predictive Control Policy  Approximation",
    "abstract": " Comments: Extended version of the paper published in IEEE Control System Letters Journal ",
    "url": "https://arxiv.org/abs/2303.05607",
    "authors": [
      "Dinesh Krishnamoorthy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2303.13589",
    "title": "On the Efficacy of Generalization Error Prediction Scoring Functions",
    "abstract": " Comments: Accepted to ICASSP 2023. (Previous title: A Closer Look at Scoring Functions and Generalization Prediction.) ",
    "url": "https://arxiv.org/abs/2303.13589",
    "authors": [
      "Puja Trivedi",
      "Danai Koutra",
      "Jayaraman J. Thiagarajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.15266",
    "title": "Multi-Granularity Archaeological Dating of Chinese Bronze Dings Based on  a Knowledge-Guided Relation Graph",
    "abstract": " Comments: CVPR2023 accepted ",
    "url": "https://arxiv.org/abs/2303.15266",
    "authors": [
      "Rixin Zhou",
      "Jiafu Wei",
      "Qian Zhang",
      "Ruihua Qi",
      "Xi Yang",
      "Chuntao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.03297",
    "title": "Neural Operator Learning for Ultrasound Tomography Inversion",
    "abstract": " Comments: 4 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2304.03297",
    "authors": [
      "Haocheng Dai",
      "Michael Penwarden",
      "Robert M. Kirby",
      "Sarang Joshi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.04589",
    "title": "Hyperspectral Image Super-Resolution via Dual-domain Network Based on  Hybrid Convolution",
    "abstract": " Title: Hyperspectral Image Super-Resolution via Dual-domain Network Based on  Hybrid Convolution ",
    "url": "https://arxiv.org/abs/2304.04589",
    "authors": [
      "Tingting Liu",
      "Yuan Liu",
      "Chuncheng Zhang",
      "Yuan Liyin",
      "Xiubao Sui",
      "Qian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2304.11056",
    "title": "PowerGAN: A Machine Learning Approach for Power Side-Channel Attack on  Compute-in-Memory Accelerators",
    "abstract": " Title: PowerGAN: A Machine Learning Approach for Power Side-Channel Attack on  Compute-in-Memory Accelerators ",
    "url": "https://arxiv.org/abs/2304.11056",
    "authors": [
      "Ziyu Wang",
      "Yuting Wu",
      "Yongmo Park",
      "Sangmin Yoo",
      "Xinxin Wang",
      "Jason K. Eshraghian",
      "Wei D. Lu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.12875",
    "title": "Alternating Local Enumeration (TnALE): Solving Tensor Network Structure  Search with Fewer Evaluations",
    "abstract": " Comments: Accepted by ICML2023, pre-printed version ",
    "url": "https://arxiv.org/abs/2304.12875",
    "authors": [
      "Chao Li",
      "Junhua Zeng",
      "Chunmei Li",
      "Cesar Caiafa",
      "Qibin Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2304.14274",
    "title": "When Do Graph Neural Networks Help with Node Classification:  Investigating the Homophily Principle on Node Distinguishability",
    "abstract": " Title: When Do Graph Neural Networks Help with Node Classification:  Investigating the Homophily Principle on Node Distinguishability ",
    "url": "https://arxiv.org/abs/2304.14274",
    "authors": [
      "Sitao Luan",
      "Chenqing Hua",
      "Minkai Xu",
      "Qincheng Lu",
      "Jiaqi Zhu",
      "Xiao-Wen Chang",
      "Jie Fu",
      "Jure Leskovec",
      "Doina Precup"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.14757",
    "title": "Polynomial time key-recovery attack on high rate random alternant codes",
    "abstract": " Title: Polynomial time key-recovery attack on high rate random alternant codes ",
    "url": "https://arxiv.org/abs/2304.14757",
    "authors": [
      "Magali Bardet",
      "Rocco Mora",
      "Jean-Pierre Tillich"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.00075",
    "title": "On the existence of solutions to adversarial training in multiclass  classification",
    "abstract": " Title: On the existence of solutions to adversarial training in multiclass  classification ",
    "url": "https://arxiv.org/abs/2305.00075",
    "authors": [
      "Nicolas Garcia Trillos",
      "Matt Jacobs",
      "Jakwang Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.03355",
    "title": "A Comprehensive Study on Dataset Distillation: Performance, Privacy,  Robustness and Fairness",
    "abstract": " Title: A Comprehensive Study on Dataset Distillation: Performance, Privacy,  Robustness and Fairness ",
    "url": "https://arxiv.org/abs/2305.03355",
    "authors": [
      "Zongxiong Chen",
      "Jiahui Geng",
      "Derui Zhu",
      "Herbert Woisetschlaeger",
      "Qing Li",
      "Sonja Schimmler",
      "Ruben Mayer",
      "Chunming Rong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.05103",
    "title": "Wooden Sleeper Deterioration Detection for Rural Railway Prognostics  Using Unsupervised Deeper FCDDs",
    "abstract": " Comments: 9 pages, 9 figures, 8 tables ",
    "url": "https://arxiv.org/abs/2305.05103",
    "authors": [
      "Takato Yasuno",
      "Masahiro Okano",
      "Junichiro Fujii"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.05228",
    "title": "Semantic Embedded Deep Neural Network: A Generic Approach to Boost  Multi-Label Image Classification Performance",
    "abstract": " Title: Semantic Embedded Deep Neural Network: A Generic Approach to Boost  Multi-Label Image Classification Performance ",
    "url": "https://arxiv.org/abs/2305.05228",
    "authors": [
      "Xin Shen",
      "Xiaonan Zhao",
      "Rui Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.05351",
    "title": "GPT-NAS: Evolutionary Neural Architecture Search with the Generative  Pre-Trained Model",
    "abstract": " Title: GPT-NAS: Evolutionary Neural Architecture Search with the Generative  Pre-Trained Model ",
    "url": "https://arxiv.org/abs/2305.05351",
    "authors": [
      "Caiyang Yu",
      "Xianggen Liu",
      "Wentao Feng",
      "Chenwei Tang",
      "Jiancheng Lv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.05921",
    "title": "Decker: Double Check with Heterogeneous Knowledge for Commonsense Fact  Verification",
    "abstract": " Comments: Accepted to ACL 2023 Findings ",
    "url": "https://arxiv.org/abs/2305.05921",
    "authors": [
      "Anni Zou",
      "Zhuosheng Zhang",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.06142",
    "title": "Feature Expansion for Graph Neural Networks",
    "abstract": " Comments: Accepted by ICML'23 ",
    "url": "https://arxiv.org/abs/2305.06142",
    "authors": [
      "Jiaqi Sun",
      "Lin Zhang",
      "Guangyi Chen",
      "Kun Zhang",
      "Peng XU",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.06704",
    "title": "Robust Detection of Lead-Lag Relationships in Lagged Multi-Factor Models",
    "abstract": " Title: Robust Detection of Lead-Lag Relationships in Lagged Multi-Factor Models ",
    "url": "https://arxiv.org/abs/2305.06704",
    "authors": [
      "Yichi Zhang",
      "Mihai Cucuringu",
      "Alexander Y. Shestopaloff",
      "Stefan Zohren"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)",
      "Portfolio Management (q-fin.PM)",
      "Statistical Finance (q-fin.ST)",
      "Trading and Market Microstructure (q-fin.TR)"
    ]
  },
  {
    "id": "arXiv:2305.08277",
    "title": "Local Convergence of Gradient Descent-Ascent for Training Generative  Adversarial Networks",
    "abstract": " Title: Local Convergence of Gradient Descent-Ascent for Training Generative  Adversarial Networks ",
    "url": "https://arxiv.org/abs/2305.08277",
    "authors": [
      "Evan Becker",
      "Parthe Pandit",
      "Sundeep Rangan",
      "Alyson K. Fletcher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.09770",
    "title": "ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to  Support Human-AI Scientific Writing",
    "abstract": " Title: ConvXAI: Delivering Heterogeneous AI Explanations via Conversations to  Support Human-AI Scientific Writing ",
    "url": "https://arxiv.org/abs/2305.09770",
    "authors": [
      "Hua Shen",
      "Chieh-Yang Huang",
      "Tongshuang Wu",
      "Ting-Hao 'Kenneth' Huang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.09938",
    "title": "Characterizing Long-Tail Categories on Graphs",
    "abstract": " Title: Characterizing Long-Tail Categories on Graphs ",
    "url": "https://arxiv.org/abs/2305.09938",
    "authors": [
      "Haohui Wang",
      "Baoyu Jing",
      "Kaize Ding",
      "Yada Zhu",
      "Dawei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.12082",
    "title": "SneakyPrompt: Evaluating Robustness of Text-to-image Generative Models'  Safety Filters",
    "abstract": " Title: SneakyPrompt: Evaluating Robustness of Text-to-image Generative Models'  Safety Filters ",
    "url": "https://arxiv.org/abs/2305.12082",
    "authors": [
      "Yuchen Yang",
      "Bo Hui",
      "Haolin Yuan",
      "Neil Gong",
      "Yinzhi Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12095",
    "title": "Make Transformer Great Again for Time Series Forecasting: Channel  Aligned Robust Dual Transformer",
    "abstract": " Title: Make Transformer Great Again for Time Series Forecasting: Channel  Aligned Robust Dual Transformer ",
    "url": "https://arxiv.org/abs/2305.12095",
    "authors": [
      "Wang Xue",
      "Tian Zhou",
      "Qingsong Wen",
      "Jinyang Gao",
      "Bolin Ding",
      "Rong Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12240",
    "title": "Bridging Active Exploration and Uncertainty-Aware Deployment Using  Probabilistic Ensemble Neural Network Dynamics",
    "abstract": " Comments: 2023 Robotics: Science and Systems (RSS). Project page: this https URL ",
    "url": "https://arxiv.org/abs/2305.12240",
    "authors": [
      "Taekyung Kim",
      "Jungwi Mun",
      "Junwon Seo",
      "Beomsu Kim",
      "Seongil Hong"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.12322",
    "title": "Learning Large Graph Property Prediction via Graph Segment Training",
    "abstract": " Title: Learning Large Graph Property Prediction via Graph Segment Training ",
    "url": "https://arxiv.org/abs/2305.12322",
    "authors": [
      "Kaidi Cao",
      "Phitchaya Mangpo Phothilimthana",
      "Sami Abu-El-Haija",
      "Dustin Zelle",
      "Yanqi Zhou",
      "Charith Mendis",
      "Jure Leskovec",
      "Bryan Perozzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.12467",
    "title": "Understanding Multi-phase Optimization Dynamics and Rich Nonlinear  Behaviors of ReLU Networks",
    "abstract": " Comments: 88 pages ",
    "url": "https://arxiv.org/abs/2305.12467",
    "authors": [
      "Mingze Wang",
      "Chao Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2305.12493",
    "title": "Contextualized End-to-End Speech Recognition with Contextual Phrase  Prediction Network",
    "abstract": " Comments: Accepted by interspeech2023 ",
    "url": "https://arxiv.org/abs/2305.12493",
    "authors": [
      "Kaixun Huang",
      "Ao Zhang",
      "Zhanheng Yang",
      "Pengcheng Guo",
      "Bingshen Mu",
      "Tianyi Xu",
      "Lei Xie"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.13073",
    "title": "Text-to-SQL Error Correction with Language Models of Code",
    "abstract": " Comments: ACL 2023 Short Paper ",
    "url": "https://arxiv.org/abs/2305.13073",
    "authors": [
      "Ziru Chen",
      "Shijie Chen",
      "Michael White",
      "Raymond Mooney",
      "Ali Payani",
      "Jayanth Srinivasa",
      "Yu Su",
      "Huan Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.13625",
    "title": "DiffProtect: Generate Adversarial Examples with Diffusion Models for  Facial Privacy Protection",
    "abstract": " Comments: Code will be available at this https URL ",
    "url": "https://arxiv.org/abs/2305.13625",
    "authors": [
      "Jiang Liu",
      "Chun Pong Lau",
      "Rama Chellappa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.14345",
    "title": "NCHO: Unsupervised Learning for Neural 3D Composition of Humans and  Objects",
    "abstract": " Comments: The project page is available at this https URL ",
    "url": "https://arxiv.org/abs/2305.14345",
    "authors": [
      "Taeksoo Kim",
      "Shunsuke Saito",
      "Hanbyul Joo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14641",
    "title": "Graph Analysis Using a GPU-based Parallel Algorithm: Quantum Clustering",
    "abstract": " Title: Graph Analysis Using a GPU-based Parallel Algorithm: Quantum Clustering ",
    "url": "https://arxiv.org/abs/2305.14641",
    "authors": [
      "Zhe Wang",
      "ZhiJie He",
      "Ding Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14749",
    "title": "Multi-State RNA Design with Geometric Multi-Graph Neural Networks",
    "abstract": " Title: Multi-State RNA Design with Geometric Multi-Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2305.14749",
    "authors": [
      "Chaitanya K. Joshi",
      "Arian R. Jamasb",
      "Ramon Vi\u00f1as",
      "Charles Harris",
      "Simon Mathis",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2305.15128",
    "title": "Age of Information in Reservation Multi-Access Networks with Stochastic  Arrivals: Analysis and Optimization",
    "abstract": " Comments: This work has been submitted for possible publication. arXiv admin note: substantial text overlap with arXiv:2206.00874 ",
    "url": "https://arxiv.org/abs/2305.15128",
    "authors": [
      "Qian Wang",
      "Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2305.16044",
    "title": "Exploiting Noise as a Resource for Computation and Learning in Spiking  Neural Networks",
    "abstract": " Comments: Fixed the bug in the BBL file generated with bibliography management program ",
    "url": "https://arxiv.org/abs/2305.16044",
    "authors": [
      "Gehua Ma",
      "Rui Yan",
      "Huajin Tang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16257",
    "title": "Fast Online Node Labeling for Very Large Graphs",
    "abstract": " Comments: 40 pages,17 figures, ICML 2023 ",
    "url": "https://arxiv.org/abs/2305.16257",
    "authors": [
      "Baojian Zhou",
      "Yifan Sun",
      "Reza Babanezhad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Spectral Theory (math.SP)"
    ]
  },
  {
    "id": "arXiv:2305.16618",
    "title": "Confidence-Based Feature Imputation for Graphs with Partially Known  Features",
    "abstract": " Comments: Accepted to ICLR 2023. 28 pages ",
    "url": "https://arxiv.org/abs/2305.16618",
    "authors": [
      "Daeho Um",
      "Jiwoong Park",
      "Seulki Park",
      "Jin Young Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.16791",
    "title": "On the Generalization Capacities of Neural Controlled Differential  Equations",
    "abstract": " Comments: Edited typos ",
    "url": "https://arxiv.org/abs/2305.16791",
    "authors": [
      "Linus Bleistein",
      "Agathe Guilloux"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16910",
    "title": "Universal approximation with complex-valued deep narrow neural networks",
    "abstract": " Comments: v2: correct typo in arxiv abstract ",
    "url": "https://arxiv.org/abs/2305.16910",
    "authors": [
      "Paul Geuchen",
      "Thomas Jahn",
      "Hannes Matt"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  }
]