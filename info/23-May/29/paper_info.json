[
  {
    "id": "arXiv:2305.16323",
    "title": "Detecting Concept Drift for the reliability prediction of Software  Defects using Instance Interpretation",
    "abstract": "In the context of Just-In-Time Software Defect Prediction (JIT-SDP), Concept drift (CD) can occur due to changes in the software development process, the complexity of the software, or changes in user behavior that may affect the stability of the JIT-SDP model over time. Additionally, the challenge of class imbalance in JIT-SDP data poses a potential risk to the accuracy of CD detection methods if rebalancing is implemented. This issue has not been explored to the best of our knowledge. Furthermore, methods to check the stability of JIT-SDP models over time by considering labeled evaluation data have been proposed. However, it should be noted that future data labels may not always be available promptly. We aim to develop a reliable JIT-SDP model using CD point detection directly by identifying changes in the interpretation of unlabeled simplified and resampled data. To evaluate our approach, we first obtained baseline methods based on model performance monitoring to identify CD points on labeled data. We then compared the output of the proposed methods with baseline methods based on performance monitoring of threshold-dependent and threshold-independent criteria using well-known performance measures in CD detection methods, such as accuracy, MDR, MTD, MTFA, and MTR. We also utilize the Friedman statistical test to assess the effectiveness of our approach. As a result, our proposed methods show higher compatibility with baseline methods based on threshold-independent criteria when applied to rebalanced data, and with baseline methods based on threshold-dependent criteria when applied to simple data. ",
    "url": "https://arxiv.org/abs/2305.16323",
    "authors": [
      "Zeynab Chitsazian",
      "Saeed Sedighian Kashi",
      "Amin Nikanjam"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16333",
    "title": "Text Generation with Speech Synthesis for ASR Data Augmentation",
    "abstract": "Aiming at reducing the reliance on expensive human annotations, data synthesis for Automatic Speech Recognition (ASR) has remained an active area of research. While prior work mainly focuses on synthetic speech generation for ASR data augmentation, its combination with text generation methods is considerably less explored. In this work, we explore text augmentation for ASR using large-scale pre-trained neural networks, and systematically compare those to traditional text augmentation methods. The generated synthetic texts are then converted to synthetic speech using a text-to-speech (TTS) system and added to the ASR training data. In experiments conducted on three datasets, we find that neural models achieve 9%-15% relative WER improvement and outperform traditional methods. We conclude that text augmentation, particularly through modern neural approaches, is a viable tool for improving the accuracy of ASR systems. ",
    "url": "https://arxiv.org/abs/2305.16333",
    "authors": [
      "Zhuangqun Huang",
      "Gil Keren",
      "Ziran Jiang",
      "Shashank Jain",
      "David Goss-Grubbs",
      "Nelson Cheng",
      "Farnaz Abtahi",
      "Duc Le",
      "David Zhang",
      "Antony D'Avirro",
      "Ethan Campbell-Taylor",
      "Jessie Salas",
      "Irina-Elena Veliche",
      "Xi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.16335",
    "title": "Robust Representation Learning with Reliable Pseudo-labels Generation  via Self-Adaptive Optimal Transport for Short Text Clustering",
    "abstract": "Short text clustering is challenging since it takes imbalanced and noisy data as inputs. Existing approaches cannot solve this problem well, since (1) they are prone to obtain degenerate solutions especially on heavy imbalanced datasets, and (2) they are vulnerable to noises. To tackle the above issues, we propose a Robust Short Text Clustering (RSTC) model to improve robustness against imbalanced and noisy data. RSTC includes two modules, i.e., pseudo-label generation module and robust representation learning module. The former generates pseudo-labels to provide supervision for the later, which contributes to more robust representations and correctly separated clusters. To provide robustness against the imbalance in data, we propose self-adaptive optimal transport in the pseudo-label generation module. To improve robustness against the noise in data, we further introduce both class-wise and instance-wise contrastive learning in the robust representation learning module. Our empirical studies on eight short text clustering datasets demonstrate that RSTC significantly outperforms the state-of-the-art models. The code is available at: https://github.com/hmllmh/RSTC. ",
    "url": "https://arxiv.org/abs/2305.16335",
    "authors": [
      "Xiaolin Zheng",
      "Mengling Hu",
      "Weiming Liu",
      "Chaochao Chen",
      "Xinting Liao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16346",
    "title": "Artificial Intelligence-Based Methods for Precision Medicine: Diabetes  Risk Prediction",
    "abstract": "The rising prevalence of type 2 diabetes mellitus (T2DM) necessitates the development of predictive models for T2DM risk assessment. Artificial intelligence (AI) models are being extensively used for this purpose, but a comprehensive review of their advancements and challenges is lacking. This scoping review analyzes existing literature on AI-based models for T2DM risk prediction. Forty studies were included, mainly published in the past four years. Traditional machine learning models were more prevalent than deep learning models. Electronic health records were the most commonly used data source. Unimodal AI models relying on EHR data were prominent, while only a few utilized multimodal models. Both unimodal and multimodal models showed promising performance, with the latter outperforming the former. Internal validation was common, while external validation was limited. Interpretability methods were reported in half of the studies. Few studies reported novel biomarkers, and open-source code availability was limited. This review provides insights into the current state and limitations of AI-based T2DM risk prediction models and highlights challenges for their development and clinical implementation. ",
    "url": "https://arxiv.org/abs/2305.16346",
    "authors": [
      "Farida Mohsen",
      "Hamada R. H. Al-Absi",
      "Noha A.Yousri",
      "Nady El Hajj",
      "Zubair Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16350",
    "title": "Using evolutionary machine learning to characterize and optimize  co-pyrolysis of biomass feedstocks and polymeric wastes",
    "abstract": "Co-pyrolysis of biomass feedstocks with polymeric wastes is a promising strategy for improving the quantity and quality parameters of the resulting liquid fuel. Numerous experimental measurements are typically conducted to find the optimal operating conditions. However, performing co-pyrolysis experiments is highly challenging due to the need for costly and lengthy procedures. Machine learning (ML) provides capabilities to cope with such issues by leveraging on existing data. This work aims to introduce an evolutionary ML approach to quantify the (by)products of the biomass-polymer co-pyrolysis process. A comprehensive dataset covering various biomass-polymer mixtures under a broad range of process conditions is compiled from the qualified literature. The database was subjected to statistical analysis and mechanistic discussion. The input features are constructed using an innovative approach to reflect the physics of the process. The constructed features are subjected to principal component analysis to reduce their dimensionality. The obtained scores are introduced into six ML models. Gaussian process regression model tuned by particle swarm optimization algorithm presents better prediction performance (R2 > 0.9, MAE < 0.03, and RMSE < 0.06) than other developed models. The multi-objective particle swarm optimization algorithm successfully finds optimal independent parameters. ",
    "url": "https://arxiv.org/abs/2305.16350",
    "authors": [
      "Hossein Shahbeik",
      "Alireza Shafizadeh",
      "Mohammad Hossein Nadian",
      "Dorsa Jeddi",
      "Seyedali Mirjalili",
      "Yadong Yang",
      "Su Shiung Lam",
      "Junting Pan",
      "Meisam Tabatabaei",
      "Mortaza Aghbashlo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16353",
    "title": "Betray Oneself: A Novel Audio DeepFake Detection Model via  Mono-to-Stereo Conversion",
    "abstract": "Audio Deepfake Detection (ADD) aims to detect the fake audio generated by text-to-speech (TTS), voice conversion (VC) and replay, etc., which is an emerging topic. Traditionally we take the mono signal as input and focus on robust feature extraction and effective classifier design. However, the dual-channel stereo information in the audio signal also includes important cues for deepfake, which has not been studied in the prior work. In this paper, we propose a novel ADD model, termed as M2S-ADD, that attempts to discover audio authenticity cues during the mono-to-stereo conversion process. We first projects the mono to a stereo signal using a pretrained stereo synthesizer, then employs a dual-branch neural architecture to process the left and right channel signals, respectively. In this way, we effectively reveal the artifacts in the fake audio, thus improve the ADD performance. The experiments on the ASVspoof2019 database show that M2S-ADD outperforms all baselines that input mono. We release the source code at \\url{https://github.com/AI-S2-Lab/M2S-ADD}. ",
    "url": "https://arxiv.org/abs/2305.16353",
    "authors": [
      "Rui Liu",
      "Jinhua Zhang",
      "Guanglai Gao",
      "Haizhou Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.16357",
    "title": "EDM3: Event Detection as Multi-task Text Generation",
    "abstract": "Event detection refers to identifying event occurrences in a text and comprises of two subtasks; event identification and classification. We present EDM3, a novel approach for Event Detection that formulates three generative tasks: identification, classification, and combined detection. We show that EDM3 helps to learn transferable knowledge that can be leveraged to perform Event Detection and its subtasks concurrently, mitigating the error propagation inherent in pipelined approaches. Unlike previous dataset- or domain-specific approaches, EDM3 utilizes the existing knowledge of language models, allowing it to be trained over any classification schema. We evaluate EDM3 on multiple event detection datasets: RAMS, WikiEvents, MAVEN, and MLEE, showing that EDM3 outperforms 1) single-task performance by 8.4% on average and 2) multi-task performance without instructional prompts by 2.4% on average. We obtain SOTA results on RAMS (71.3% vs. 65.1% F-1) and competitive performance on other datasets. We analyze our approach to demonstrate its efficacy in low-resource and multi-sentence settings. We also show the effectiveness of this approach on non-standard event configurations such as multi-word and multi-class event triggers. Overall, our results show that EDM3 is a promising approach for Event Detection that has the potential for real-world applications. ",
    "url": "https://arxiv.org/abs/2305.16357",
    "authors": [
      "Ujjwala Anantheswaran",
      "Himanshu Gupta",
      "Mihir Parmar",
      "Kuntal Kumar Pal",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.16369",
    "title": "A Semi-Automated Corner Case Detection and Evaluation Pipeline",
    "abstract": "In order to deploy automated vehicles to the public, it has to be proven that the vehicle can safely and robustly handle traffic in many different scenarios. One important component of automated vehicles is the perception system that captures and processes the environment around the vehicle. Perception systems require large datasets for training their deep neural network. Knowing which parts of the data in these datasets describe a corner case is an advantage during training or testing of the network. These corner cases describe situations that are rare and potentially challenging for the network. We propose a pipeline that converts collective expert knowledge descriptions into the extended KI Absicherung ontology. The ontology is used to describe scenes and scenarios that can be mapped to perception datasets. The corner cases can then be extracted from the datasets. In addition, the pipeline enables the evaluation of the detection networks against the extracted corner cases to measure their performance. ",
    "url": "https://arxiv.org/abs/2305.16369",
    "authors": [
      "Isabelle Tulleners",
      "Tobias Moers",
      "Thomas Schulik",
      "Martin Sedlacek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16371",
    "title": "INTapt: Information-Theoretic Adversarial Prompt Tuning for Enhanced  Non-Native Speech Recognition",
    "abstract": "Automatic Speech Recognition (ASR) systems have attained unprecedented performance with large speech models pre-trained based on self-supervised speech representation learning. However, these pre-trained speech models suffer from representational bias as they tend to better represent those prominent accents (i.e., native (L1) English accent) in the pre-training speech corpus than less represented accents, resulting in a deteriorated performance for non-native (L2) English accents. Although there have been some approaches to mitigate this issue, all of these methods require updating the pre-trained model weights. In this paper, we propose Information Theoretic Adversarial Prompt Tuning (INTapt), which introduces prompts concatenated to the original input that can re-modulate the attention of the pre-trained model such that the corresponding input resembles a native (L1) English speech without updating the backbone weights. INTapt is trained simultaneously in the following two manners: (1) adversarial training to reduce accent feature dependence between the original input and the prompt-concatenated input and (2) training to minimize CTC loss for improving ASR performance to a prompt-concatenated input. Experimental results show that INTapt improves the performance of L2 English and increases feature similarity between L2 and L1 accents. ",
    "url": "https://arxiv.org/abs/2305.16371",
    "authors": [
      "Eunseop Yoon",
      "Hee Suk Yoon",
      "John Harvill",
      "Mark Hasegawa-Johnson",
      "Chang D. Yoo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.16373",
    "title": "DeepGate2: Functionality-Aware Circuit Representation Learning",
    "abstract": "Circuit representation learning aims to obtain neural representations of circuit elements and has emerged as a promising research direction that can be applied to various EDA and logic reasoning tasks. Existing solutions, such as DeepGate, have the potential to embed both circuit structural information and functional behavior. However, their capabilities are limited due to weak supervision or flawed model design, resulting in unsatisfactory performance in downstream tasks. In this paper, we introduce DeepGate2, a novel functionality-aware learning framework that significantly improves upon the original DeepGate solution in terms of both learning effectiveness and efficiency. Our approach involves using pairwise truth table differences between sampled logic gates as training supervision, along with a well-designed and scalable loss function that explicitly considers circuit functionality. Additionally, we consider inherent circuit characteristics and design an efficient one-round graph neural network (GNN), resulting in an order of magnitude faster learning speed than the original DeepGate solution. Experimental results demonstrate significant improvements in two practical downstream tasks: logic synthesis and Boolean satisfiability solving. The code is available at https://github.com/cure-lab/DeepGate2 ",
    "url": "https://arxiv.org/abs/2305.16373",
    "authors": [
      "Zhengyuan Shi",
      "Hongyang Pan",
      "Sadaf Khan",
      "Min Li",
      "Yi Liu",
      "Junhua Huang",
      "Hui-Ling Zhen",
      "Mingxuan Yuan",
      "Zhufei Chu",
      "Qiang Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2305.16375",
    "title": "Data Topology-Dependent Upper Bounds of Neural Network Widths",
    "abstract": "This paper investigates the relationship between the universal approximation property of deep neural networks and topological characteristics of datasets. Our primary contribution is to introduce data topology-dependent upper bounds on the network width. Specifically, we first show that a three-layer neural network, applying a ReLU activation function and max pooling, can be designed to approximate an indicator function over a compact set, one that is encompassed by a tight convex polytope. This is then extended to a simplicial complex, deriving width upper bounds based on its topological structure. Further, we calculate upper bounds in relation to the Betti numbers of select topological spaces. Finally, we prove the universal approximation property of three-layer ReLU networks using our topological approach. We also verify that gradient descent converges to the network structure proposed in our study. ",
    "url": "https://arxiv.org/abs/2305.16375",
    "authors": [
      "Sangmin Lee",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.16379",
    "title": "Learning Better with Less: Effective Augmentation for Sample-Efficient  Visual Reinforcement Learning",
    "abstract": "Data augmentation (DA) is a crucial technique for enhancing the sample efficiency of visual reinforcement learning (RL) algorithms. Notably, employing simple observation transformations alone can yield outstanding performance without extra auxiliary representation tasks or pre-trained encoders. However, it remains unclear which attributes of DA account for its effectiveness in achieving sample-efficient visual RL. To investigate this issue and further explore the potential of DA, this work conducts comprehensive experiments to assess the impact of DA's attributes on its efficacy and provides the following insights and improvements: (1) For individual DA operations, we reveal that both ample spatial diversity and slight hardness are indispensable. Building on this finding, we introduce Random PadResize (Rand PR), a new DA operation that offers abundant spatial diversity with minimal hardness. (2) For multi-type DA fusion schemes, the increased DA hardness and unstable data distribution result in the current fusion schemes being unable to achieve higher sample efficiency than their corresponding individual operations. Taking the non-stationary nature of RL into account, we propose a RL-tailored multi-type DA fusion scheme called Cycling Augmentation (CycAug), which performs periodic cycles of different DA operations to increase type diversity while maintaining data distribution consistency. Extensive evaluations on the DeepMind Control suite and CARLA driving simulator demonstrate that our methods achieve superior sample efficiency compared with the prior state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2305.16379",
    "authors": [
      "Guozheng Ma",
      "Linrui Zhang",
      "Haoyu Wang",
      "Lu Li",
      "Zilin Wang",
      "Zhen Wang",
      "Li Shen",
      "Xueqian Wang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16389",
    "title": "FIDS: Fuzzy Intrusion Detection System for simultaneous detection of  DoS/DDoS attacks in Cloud computing",
    "abstract": "In recent times, I've encountered a principle known as cloud computing, a model that simplifies user access to data and computing power on a demand basis. The main objective of cloud computing is to accommodate users' growing needs by decreasing dependence on human resources, minimizing expenses, and enhancing the speed of data access. Nevertheless, preserving security and privacy in cloud computing systems pose notable challenges. This issue arises because these systems have a distributed structure, which is susceptible to unsanctioned access - a fundamental problem. In the context of cloud computing, the provision of services on demand makes them targets for common assaults like Denial of Service (DoS) attacks, which include Economic Denial of Sustainability (EDoS) and Distributed Denial of Service (DDoS). These onslaughts can be classified into three categories: bandwidth consumption attacks, specific application attacks, and connection layer attacks. Most of the studies conducted in this arena have concentrated on a singular type of attack, with the concurrent detection of multiple DoS attacks often overlooked. This article proposes a suitable method to identify four types of assaults: HTTP, Database, TCP SYN, and DNS Flood. The aim is to present a universal algorithm that performs effectively in detecting all four attacks instead of using separate algorithms for each one. In this technique, seventeen server parameters like memory usage, CPU usage, and input/output counts are extracted and monitored for changes, identifying the failure point using the CUSUM algorithm to calculate the likelihood of each attack. Subsequently, a fuzzy neural network is employed to determine the occurrence of an attack. When compared to the Snort software, the proposed method's results show a significant improvement in the average detection rate, jumping from 57% to 95%. ",
    "url": "https://arxiv.org/abs/2305.16389",
    "authors": [
      "Peyman Khordadpour",
      "Saeed Ahmadi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.16405",
    "title": "Automatic Extraction of Time-windowed ROS Computation Graphs from ROS  Bag Files",
    "abstract": "Robotic systems react to different environmental stimuli, potentially resulting in the dynamic reconfiguration of the software controlling such systems. One effect of such dynamism is the reconfiguration of the software architecture reconfiguration of the system at runtime. Such reconfigurations might severely impact the runtime properties of robotic systems, e.g., in terms of performance and energy efficiency. The ROS \\emph{rosbag} package enables developers to record and store timestamped data related to the execution of robotic missions, implicitly containing relevant information about the architecture of the monitored system during its execution. In this study, we discuss about our approach for statically extracting (time-windowed) architectural information from ROS bag files. The proposed approach can support the robotics community in better discussing and reasoning the software architecture (and its runtime reconfigurations) of ROS-based systems. We evaluate our approach against hundreds of ROS bag files systematically mined from 4,434 public GitHub repositories. ",
    "url": "https://arxiv.org/abs/2305.16405",
    "authors": [
      "Zhuojun Chen",
      "Michel Albonico",
      "Ivano Malvolta"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.16415",
    "title": "Performance-Robustness Tradeoffs in Adversarially Robust Control and  Estimation",
    "abstract": "While $\\mathcal{H}_\\infty$ methods can introduce robustness against worst-case perturbations, their nominal performance under conventional stochastic disturbances is often drastically reduced. Though this fundamental tradeoff between nominal performance and robustness is known to exist, it is not well-characterized in quantitative terms. Toward addressing this issue, we borrow the increasingly ubiquitous notion of adversarial training from machine learning to construct a class of controllers which are optimized for disturbances consisting of mixed stochastic and worst-case components. We find that this problem admits a linear time invariant optimal controller that has a form closely related to suboptimal $\\mathcal{H}_\\infty$ solutions. We then provide a quantitative performance-robustness tradeoff analysis in two analytically tractable cases: state feedback control, and state estimation. In these special cases, we demonstrate that the severity of the tradeoff depends in an interpretable manner upon system-theoretic properties such as the spectrum of the controllability gramian, the spectrum of the observability gramian, and the stability of the system. This provides practitioners with general guidance for determining how much robustness to incorporate based on a priori system knowledge. We empirically validate our results by comparing the performance of our controller against standard baselines, and plotting tradeoff curves. ",
    "url": "https://arxiv.org/abs/2305.16415",
    "authors": [
      "Bruce D. Lee",
      "Thomas T.C.K. Zhang",
      "Hamed Hassani",
      "Nikolai Matni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.16416",
    "title": "Federated Neural Compression Under Heterogeneous Data",
    "abstract": "We discuss a federated learned compression problem, where the goal is to learn a compressor from real-world data which is scattered across clients and may be statistically heterogeneous, yet share a common underlying representation. We propose a distributed source model that encompasses both characteristics, and naturally suggests a compressor architecture that uses analysis and synthesis transforms shared by clients. Inspired by personalized federated learning methods, we employ an entropy model that is personalized to each client. This allows for a global latent space to be learned across clients, and personalized entropy models that adapt to the clients' latent distributions. We show empirically that this strategy outperforms solely local methods, which indicates that learned compression also benefits from a shared global representation in statistically heterogeneous federated settings. ",
    "url": "https://arxiv.org/abs/2305.16416",
    "authors": [
      "Eric Lei",
      "Hamed Hassani",
      "Shirin Saeedi Bidokhti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.16421",
    "title": "NODDLE: Node2vec based deep learning model for link prediction",
    "abstract": "Computing the probability of an edge's existence in a graph network is known as link prediction. While traditional methods calculate the similarity between two given nodes in a static network, recent research has focused on evaluating networks that evolve dynamically. Although deep learning techniques and network representation learning algorithms, such as node2vec, show remarkable improvements in prediction accuracy, the Stochastic Gradient Descent (SGD) method of node2vec tends to fall into a mediocre local optimum value due to a shortage of prior network information, resulting in failure to capture the global structure of the network. To tackle this problem, we propose NODDLE (integration of NOde2vec anD Deep Learning mEthod), a deep learning model which incorporates the features extracted by node2vec and feeds them into a four layer hidden neural network. NODDLE takes advantage of adaptive learning optimizers such as Adam, Adamax, Adadelta, and Adagrad to improve the performance of link prediction. Experimental results show that this method yields better results than the traditional methods on various social network datasets. ",
    "url": "https://arxiv.org/abs/2305.16421",
    "authors": [
      "Kazi Zainab Khanam",
      "Aditya Singhal",
      "Vijay Mago"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16427",
    "title": "Neural (Tangent Kernel) Collapse",
    "abstract": "This work bridges two important concepts: the Neural Tangent Kernel (NTK), which captures the evolution of deep neural networks (DNNs) during training, and the Neural Collapse (NC) phenomenon, which refers to the emergence of symmetry and structure in the last-layer features of well-trained classification DNNs. We adopt the natural assumption that the empirical NTK develops a block structure aligned with the class labels, i.e., samples within the same class have stronger correlations than samples from different classes. Under this assumption, we derive the dynamics of DNNs trained with mean squared (MSE) loss and break them into interpretable phases. Moreover, we identify an invariant that captures the essence of the dynamics, and use it to prove the emergence of NC in DNNs with block-structured NTK. We provide large-scale numerical experiments on three common DNN architectures and three benchmark datasets to support our theory. ",
    "url": "https://arxiv.org/abs/2305.16427",
    "authors": [
      "Mariia Seleznova",
      "Dana Weitzner",
      "Raja Giryes",
      "Gitta Kutyniok",
      "Hung-Hsu Chou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16430",
    "title": "Too Few Bug Reports? Exploring Data Augmentation for Improved  Changeset-based Bug Localization",
    "abstract": "Modern Deep Learning (DL) architectures based on transformers (e.g., BERT, RoBERTa) are exhibiting performance improvements across a number of natural language tasks. While such DL models have shown tremendous potential for use in software engineering applications, they are often hampered by insufficient training data. Particularly constrained are applications that require project-specific data, such as bug localization, which aims at recommending code to fix a newly submitted bug report. Deep learning models for bug localization require a substantial training set of fixed bug reports, which are at a limited quantity even in popular and actively developed software projects. In this paper, we examine the effect of using synthetic training data on transformer-based DL models that perform a more complex variant of bug localization, which has the goal of retrieving bug-inducing changesets for each bug report. To generate high-quality synthetic data, we propose novel data augmentation operators that act on different constituent components of bug reports. We also describe a data balancing strategy that aims to create a corpus of augmented bug reports that better reflects the entire source code base, because existing bug reports used as training data usually reference a small part of the code base. ",
    "url": "https://arxiv.org/abs/2305.16430",
    "authors": [
      "Agnieszka Ciborowska",
      "Kostadin Damevski"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.16433",
    "title": "Neural Machine Translation for Mathematical Formulae",
    "abstract": "We tackle the problem of neural machine translation of mathematical formulae between ambiguous presentation languages and unambiguous content languages. Compared to neural machine translation on natural language, mathematical formulae have a much smaller vocabulary and much longer sequences of symbols, while their translation requires extreme precision to satisfy mathematical information needs. In this work, we perform the tasks of translating from LaTeX to Mathematica as well as from LaTeX to semantic LaTeX. While recurrent, recursive, and transformer networks struggle with preserving all contained information, we find that convolutional sequence-to-sequence networks achieve 95.1% and 90.7% exact matches, respectively. ",
    "url": "https://arxiv.org/abs/2305.16433",
    "authors": [
      "Felix Petersen",
      "Moritz Schubotz",
      "Andre Greiner-Petter",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Symbolic Computation (cs.SC)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2305.16437",
    "title": "KeyPosS: Plug-and-Play Facial Landmark Detection through GPS-Inspired  True-Range Multilateration",
    "abstract": "In the realm of facial analysis, accurate landmark detection is crucial for various applications, ranging from face recognition and expression analysis to animation. Conventional heatmap or coordinate regression-based techniques, however, often face challenges in terms of computational burden and quantization errors. To address these issues, we present the KeyPoint Positioning System (KeyPosS), a groundbreaking facial landmark detection framework that stands out from existing methods. For the first time, KeyPosS employs the True-range Multilateration algorithm, a technique originally used in GPS systems, to achieve rapid and precise facial landmark detection without relying on computationally intensive regression approaches. The framework utilizes a fully convolutional network to predict a distance map, which computes the distance between a Point of Interest (POI) and multiple anchor points. These anchor points are ingeniously harnessed to triangulate the POI's position through the True-range Multilateration algorithm. Notably, the plug-and-play nature of KeyPosS enables seamless integration into any decoding stage, ensuring a versatile and adaptable solution. We conducted a thorough evaluation of KeyPosS's performance by benchmarking it against state-of-the-art models on four different datasets. The results show that KeyPosS substantially outperforms leading methods in low-resolution settings while requiring a minimal time overhead. The code is available at https://github.com/zhiqic/KeyPosS. ",
    "url": "https://arxiv.org/abs/2305.16437",
    "authors": [
      "Xu Bao",
      "Zhi-Qi Cheng",
      "Jun-Yan He",
      "Chenyang Li",
      "Wangmeng Xiang",
      "Jingdong Sun",
      "Hanbing Liu",
      "Wei Liu",
      "Bin Luo",
      "Yifeng Geng",
      "Xuansong Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2305.16439",
    "title": "Polylogarithmic Approximation for Robust s-t Path",
    "abstract": "The paper revisits the robust $s$-$t$ path problem, one of the most fundamental problems in robust optimization. In the problem, we are given a directed graph with $n$ vertices and $k$ distinct cost functions (scenarios) defined over edges, and aim to choose an $s$-$t$ path such that the total cost of the path is always provable no matter which scenario is realized. With the view of each cost function being associated with an agent, our goal is to find a common $s$-$t$ path minimizing the maximum objective among all agents, and thus create a fair solution for them. The problem is hard to approximate within $o(\\log k)$ by any quasi-polynomial time algorithm unless $\\mathrm{NP} \\subseteq \\mathrm{DTIME}(n^{\\mathrm{poly}\\log n})$, and the best approximation ratio known to date is $\\widetilde{O}(\\sqrt{n})$ which is based on the natural flow linear program. A longstanding open question is whether we can achieve a polylogarithmic approximation even when a quasi-polynomial running time is allowed. We give the first polylogarithmic approximation for robust $s$-$t$ path since the problem was proposed more than two decades ago. In particular, we introduce a $O(\\log n \\log k)$-approximate algorithm running in quasi-polynomial time. The algorithm is built on a novel linear program formulation for a decision-tree-type structure which enables us to get rid of the $\\Omega(\\max\\{k,\\sqrt{n}\\})$ integrality gap of the natural flow LP. Further, we also consider some well-known graph classes, e.g., graphs with bounded treewidth, and show that the polylogarithmic approximation can be achieved polynomially on these graphs. We hope the new proposed techniques in the paper can offer new insights into the robust $s$-$t$ path problem and related problems in robust optimization. ",
    "url": "https://arxiv.org/abs/2305.16439",
    "authors": [
      "Shi Li",
      "Chenyang Xu",
      "Ruilong Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2305.16440",
    "title": "Representation Transfer Learning via Multiple Pre-trained models for  Linear Regression",
    "abstract": "In this paper, we consider the problem of learning a linear regression model on a data domain of interest (target) given few samples. To aid learning, we are provided with a set of pre-trained regression models that are trained on potentially different data domains (sources). Assuming a representation structure for the data generating linear models at the sources and the target domains, we propose a representation transfer based learning method for constructing the target model. The proposed scheme is comprised of two phases: (i) utilizing the different source representations to construct a representation that is adapted to the target data, and (ii) using the obtained model as an initialization to a fine-tuning procedure that re-trains the entire (over-parameterized) regression model on the target data. For each phase of the training method, we provide excess risk bounds for the learned model compared to the true data generating target model. The derived bounds show a gain in sample complexity for our proposed method compared to the baseline method of not leveraging source representations when achieving the same excess risk, therefore, theoretically demonstrating the effectiveness of transfer learning for linear regression. ",
    "url": "https://arxiv.org/abs/2305.16440",
    "authors": [
      "Navjot Singh",
      "Suhas Diggavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.16444",
    "title": "Don't Retrain, Just Rewrite: Countering Adversarial Perturbations by  Rewriting Text",
    "abstract": "Can language models transform inputs to protect text classifiers against adversarial attacks? In this work, we present ATINTER, a model that intercepts and learns to rewrite adversarial inputs to make them non-adversarial for a downstream text classifier. Our experiments on four datasets and five attack mechanisms reveal that ATINTER is effective at providing better adversarial robustness than existing defense approaches, without compromising task accuracy. For example, on sentiment classification using the SST-2 dataset, our method improves the adversarial accuracy over the best existing defense approach by more than 4% with a smaller decrease in task accuracy (0.5% vs 2.5%). Moreover, we show that ATINTER generalizes across multiple downstream tasks and classifiers without having to explicitly retrain it for those settings. Specifically, we find that when ATINTER is trained to remove adversarial perturbations for the sentiment classification task on the SST-2 dataset, it even transfers to a semantically different task of news classification (on AGNews) and improves the adversarial robustness by more than 10%. ",
    "url": "https://arxiv.org/abs/2305.16444",
    "authors": [
      "Ashim Gupta",
      "Carter Wood Blum",
      "Temma Choji",
      "Yingjie Fei",
      "Shalin Shah",
      "Alakananda Vempala",
      "Vivek Srikumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.16446",
    "title": "The Representation Jensen-Shannon Divergence",
    "abstract": "Statistical divergences quantify the difference between probability distributions finding multiple uses in machine-learning. However, a fundamental challenge is to estimate divergence from empirical samples since the underlying distributions of the data are usually unknown. In this work, we propose the representation Jensen-Shannon Divergence, a novel divergence based on covariance operators in reproducing kernel Hilbert spaces (RKHS). Our approach embeds the data distributions in an RKHS and exploits the spectrum of the covariance operators of the representations. We provide an estimator from empirical covariance matrices by explicitly mapping the data to an RKHS using Fourier features. This estimator is flexible, scalable, differentiable, and suitable for minibatch-based optimization problems. Additionally, we provide an estimator based on kernel matrices without having an explicit mapping to the RKHS. We show that this quantity is a lower bound on the Jensen-Shannon divergence, and we propose a variational approach to estimate it. We applied our divergence to two-sample testing outperforming related state-of-the-art techniques in several datasets. We used the representation Jensen-Shannon divergence as a cost function to train generative adversarial networks which intrinsically avoids mode collapse and encourages diversity. ",
    "url": "https://arxiv.org/abs/2305.16446",
    "authors": [
      "Jhoan K. Hoyos-Osorio",
      "Luis G. Sanchez-Giraldo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.16450",
    "title": "Vision-based UAV Detection in Complex Backgrounds and Rainy Conditions",
    "abstract": "To detect UAVs in real-time, computer vision and deep learning approaches are developing areas of research. There have been concerns raised regarding the possible hazards and misuse of employing unmanned aerial vehicles (UAVs) in many applications. These include potential privacy violations, safety-related issues, and security threats. Vision-based detection systems often comprise a combination of hardware components such as cameras and software components. In this work, the performance of recent and popular vision-based object detection techniques is investigated for the task of UAV detection under challenging conditions such as complex backgrounds, varying UAV sizes, complex background scenarios, and low-to-heavy rainy conditions. To study the performance of selected methods under these conditions, two datasets were curated: one with a sky background and one with complex background. In this paper, one-stage detectors and two-stage detectors are studied and evaluated. The findings presented in the paper shall help provide insights concerning the performance of the selected models for the task of UAV detection under challenging conditions and pave the way to develop more robust UAV detection methods ",
    "url": "https://arxiv.org/abs/2305.16450",
    "authors": [
      "Adnan Munir",
      "Abdul Jabbar Siddiqui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2305.16460",
    "title": "Optimized Custom Dataset for Efficient Detection of Underwater Trash",
    "abstract": "Accurately quantifying and removing submerged underwater waste plays a crucial role in safeguarding marine life and preserving the environment. While detecting floating and surface debris is relatively straightforward, quantifying submerged waste presents significant challenges due to factors like light refraction, absorption, suspended particles, and color distortion. This paper addresses these challenges by proposing the development of a custom dataset and an efficient detection approach for submerged marine debris. The dataset encompasses diverse underwater environments and incorporates annotations for precise labeling of debris instances. Ultimately, the primary objective of this custom dataset is to enhance the diversity of litter instances and improve their detection accuracy in deep submerged environments by leveraging state-of-the-art deep learning architectures. ",
    "url": "https://arxiv.org/abs/2305.16460",
    "authors": [
      "Jaskaran Singh Walia",
      "Karthik Seemakurthy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.16474",
    "title": "FairDP: Certified Fairness with Differential Privacy",
    "abstract": "This paper introduces FairDP, a novel mechanism designed to simultaneously ensure differential privacy (DP) and fairness. FairDP operates by independently training models for distinct individual groups, using group-specific clipping terms to assess and bound the disparate impacts of DP. Throughout the training process, the mechanism progressively integrates knowledge from group models to formulate a comprehensive model that balances privacy, utility, and fairness in downstream tasks. Extensive theoretical and empirical analyses validate the efficacy of FairDP, demonstrating improved trade-offs between model utility, privacy, and fairness compared with existing methods. ",
    "url": "https://arxiv.org/abs/2305.16474",
    "authors": [
      "Khang Tran",
      "Ferdinando Fioretto",
      "Issa Khalil",
      "My T. Thai",
      "NhatHai Phan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2305.16475",
    "title": "Initialization-Dependent Sample Complexity of Linear Predictors and  Neural Networks",
    "abstract": "We provide several new results on the sample complexity of vector-valued linear predictors (parameterized by a matrix), and more generally neural networks. Focusing on size-independent bounds, where only the Frobenius norm distance of the parameters from some fixed reference matrix $W_0$ is controlled, we show that the sample complexity behavior can be surprisingly different than what we may expect considering the well-studied setting of scalar-valued linear predictors. This also leads to new sample complexity bounds for feed-forward neural networks, tackling some open questions in the literature, and establishing a new convex linear prediction problem that is provably learnable without uniform convergence. ",
    "url": "https://arxiv.org/abs/2305.16475",
    "authors": [
      "Roey Magen",
      "Ohad Shamir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.16483",
    "title": "Sample Efficient Reinforcement Learning in Mixed Systems through  Augmented Samples and Its Applications to Queueing Networks",
    "abstract": "This paper considers a class of reinforcement learning problems, which involve systems with two types of states: stochastic and pseudo-stochastic. In such systems, stochastic states follow a stochastic transition kernel while the transitions of pseudo-stochastic states are deterministic given the stochastic states/transitions. We refer to such systems as mixed systems, which are widely used in various applications, including manufacturing systems, communication networks, and queueing networks. We propose a sample efficient RL method that accelerates learning by generating augmented data samples. The proposed algorithm is data-driven and learns the policy from data samples from both real and augmented samples. This method significantly improves learning by reducing the sample complexity such that the dataset only needs to have sufficient coverage of the stochastic states. We analyze the sample complexity of the proposed method under Fitted Q Iteration (FQI) and demonstrate that the optimality gap decreases as $\\tilde{\\mathcal{O}}(\\sqrt{{1}/{n}}+\\sqrt{{1}/{m}}),$ where $n$ is the number of real samples and $m$ is the number of augmented samples per real sample. It is important to note that without augmented samples, the optimality gap is $\\tilde{\\mathcal{O}}(1)$ due to insufficient data coverage of the pseudo-stochastic states. Our experimental results on multiple queueing network applications confirm that the proposed method indeed significantly accelerates learning in both deep Q-learning and deep policy gradient. ",
    "url": "https://arxiv.org/abs/2305.16483",
    "authors": [
      "Honghao Wei",
      "Xin Liu",
      "Weina Wang",
      "Lei Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16490",
    "title": "Prototype-Based Interpretability for Legal Citation Prediction",
    "abstract": "Deep learning has made significant progress in the past decade, and demonstrates potential to solve problems with extensive social impact. In high-stakes decision making areas such as law, experts often require interpretability for automatic systems to be utilized in practical settings. In this work, we attempt to address these requirements applied to the important problem of legal citation prediction (LCP). We design the task with parallels to the thought-process of lawyers, i.e., with reference to both precedents and legislative provisions. After initial experimental results, we refine the target citation predictions with the feedback of legal experts. Additionally, we introduce a prototype architecture to add interpretability, achieving strong performance while adhering to decision parameters used by lawyers. Our study builds on and leverages the state-of-the-art language processing models for law, while addressing vital considerations for high-stakes tasks with practical societal impact. ",
    "url": "https://arxiv.org/abs/2305.16490",
    "authors": [
      "Chu Fei Luo",
      "Rohan Bhambhoria",
      "Samuel Dahan",
      "Xiaodan Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.16492",
    "title": "Image Classification of Stroke Blood Clot Origin using Deep  Convolutional Neural Networks and Visual Transformers",
    "abstract": "Stroke is one of two main causes of death worldwide. Many individuals suffer from ischemic stroke every year. Only in US more over 700,000 individuals meet ischemic stroke due to blood clot blocking an artery to the brain every year. The paper describes particular approach how to apply Artificial Intelligence for purposes of separating two major acute ischemic stroke (AIS) etiology subtypes: cardiac and large artery atherosclerosis. Four deep neural network architectures and simple ensemble method are used in the approach. ",
    "url": "https://arxiv.org/abs/2305.16492",
    "authors": [
      "David Azatyan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16494",
    "title": "Diffusion-Based Adversarial Sample Generation for Improved Stealthiness  and Controllability",
    "abstract": "Neural networks are known to be susceptible to adversarial samples: small variations of natural examples crafted to deliberately mislead the models. While they can be easily generated using gradient-based techniques in digital and physical scenarios, they often differ greatly from the actual data distribution of natural images, resulting in a trade-off between strength and stealthiness. In this paper, we propose a novel framework dubbed Diffusion-Based Projected Gradient Descent (Diff-PGD) for generating realistic adversarial samples. By exploiting a gradient guided by a diffusion model, Diff-PGD ensures that adversarial samples remain close to the original data distribution while maintaining their effectiveness. Moreover, our framework can be easily customized for specific tasks such as digital attacks, physical-world attacks, and style-based attacks. Compared with existing methods for generating natural-style adversarial samples, our framework enables the separation of optimizing adversarial loss from other surrogate losses (e.g., content/smoothness/style loss), making it more stable and controllable. Finally, we demonstrate that the samples generated using Diff-PGD have better transferability and anti-purification power than traditional gradient-based methods. Code will be released in https://github.com/xavihart/Diff-PGD ",
    "url": "https://arxiv.org/abs/2305.16494",
    "authors": [
      "Haotian Xue",
      "Alexandre Araujo",
      "Bin Hu",
      "Yongxin Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16497",
    "title": "AD-NEV: A Scalable Multi-level Neuroevolution Framework for Multivariate  Anomaly Detection",
    "abstract": "Anomaly detection tools and methods present a key capability in modern cyberphysical and failure prediction systems. Despite the fast-paced development in deep learning architectures for anomaly detection, model optimization for a given dataset is a cumbersome and time consuming process. Neuroevolution could be an effective and efficient solution to this problem, as a fully automated search method for learning optimal neural networks, supporting both gradient and non-gradient fine tuning. However, existing methods mostly focus on optimizing model architectures without taking into account feature subspaces and model weights. In this work, we propose Anomaly Detection Neuroevolution (AD-NEv) - a scalable multi-level optimized neuroevolution framework for multivariate time series anomaly detection. The method represents a novel approach to synergically: i) optimize feature subspaces for an ensemble model based on the bagging technique; ii) optimize the model architecture of single anomaly detection models; iii) perform non-gradient fine-tuning of network weights. An extensive experimental evaluation on widely adopted multivariate anomaly detection benchmark datasets shows that the models extracted by AD-NEv outperform well-known deep learning architectures for anomaly detection. Moreover, results show that AD-NEv can perform the whole process efficiently, presenting high scalability when multiple GPUs are available. ",
    "url": "https://arxiv.org/abs/2305.16497",
    "authors": [
      "Marcin Pietron",
      "Dominik Zurek",
      "Kamil Faber",
      "Roberto Corizzo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.16503",
    "title": "IMBERT: Making BERT Immune to Insertion-based Backdoor Attacks",
    "abstract": "Backdoor attacks are an insidious security threat against machine learning models. Adversaries can manipulate the predictions of compromised models by inserting triggers into the training phase. Various backdoor attacks have been devised which can achieve nearly perfect attack success without affecting model predictions for clean inputs. Means of mitigating such vulnerabilities are underdeveloped, especially in natural language processing. To fill this gap, we introduce IMBERT, which uses either gradients or self-attention scores derived from victim models to self-defend against backdoor attacks at inference time. Our empirical studies demonstrate that IMBERT can effectively identify up to 98.5% of inserted triggers. Thus, it significantly reduces the attack success rate while attaining competitive accuracy on the clean dataset across widespread insertion-based attacks compared to two baselines. Finally, we show that our approach is model-agnostic, and can be easily ported to several pre-trained transformer models. ",
    "url": "https://arxiv.org/abs/2305.16503",
    "authors": [
      "Xuanli He",
      "Jun Wang",
      "Benjamin Rubinstein",
      "Trevor Cohn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.16508",
    "title": "Most Neural Networks Are Almost Learnable",
    "abstract": "We present a PTAS for learning random constant-depth networks. We show that for any fixed $\\epsilon>0$ and depth $i$, there is a poly-time algorithm that for any distribution on $\\sqrt{d} \\cdot \\mathbb{S}^{d-1}$ learns random Xavier networks of depth $i$, up to an additive error of $\\epsilon$. The algorithm runs in time and sample complexity of $(\\bar{d})^{\\mathrm{poly}(\\epsilon^{-1})}$, where $\\bar d$ is the size of the network. For some cases of sigmoid and ReLU-like activations the bound can be improved to $(\\bar{d})^{\\mathrm{polylog}(\\epsilon^{-1})}$, resulting in a quasi-poly-time algorithm for learning constant depth random networks. ",
    "url": "https://arxiv.org/abs/2305.16508",
    "authors": [
      "Amit Daniely",
      "Nathan Srebro",
      "Gal Vardi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.16509",
    "title": "RoLA: A Real-Time Online Lightweight Anomaly Detection System for  Multivariate Time Series",
    "abstract": "A multivariate time series refers to observations of two or more variables taken from a device or a system simultaneously over time. There is an increasing need to monitor multivariate time series and detect anomalies in real time to ensure proper system operation and good service quality. It is also highly desirable to have a lightweight anomaly detection system that considers correlations between different variables, adapts to changes in the pattern of the multivariate time series, offers immediate responses, and provides supportive information regarding detection results based on unsupervised learning and online model training. In the past decade, many multivariate time series anomaly detection approaches have been introduced. However, they are unable to offer all the above-mentioned features. In this paper, we propose RoLA, a real-time online lightweight anomaly detection system for multivariate time series based on a divide-and-conquer strategy, parallel processing, and the majority rule. RoLA employs multiple lightweight anomaly detectors to monitor multivariate time series in parallel, determine the correlations between variables dynamically on the fly, and then jointly detect anomalies based on the majority rule in real time. To demonstrate the performance of RoLA, we conducted an experiment based on a public dataset provided by the FerryBox of the One Ocean Expedition. The results show that RoLA provides satisfactory detection accuracy and lightweight performance. ",
    "url": "https://arxiv.org/abs/2305.16509",
    "authors": [
      "Ming-Chang Lee",
      "Jia-Chun Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16513",
    "title": "Sliding Window Sum Algorithms for Deep Neural Networks",
    "abstract": "Sliding window sums are widely used for string indexing, hashing and time series analysis. We have developed a family of the generic vectorized sliding sum algorithms that provide speedup of O(P/w) for window size $w$ and number of processors P. For a sum with a commutative operator the speedup is improved to O(P/log(w)). Even more important, our algorithms exhibit efficient memory access patterns. In this paper we study the application of the sliding sum algorithms to the training and inference of the Deep Neural Networks. We demonstrate how both pooling and convolution primitives could be expressed as sliding sums and evaluated by the compute kernels with the shared structure. We show that the sliding sum convolution kernels are more efficient than the commonly used GEMM kernels on the CPU, and could even outperform their GPU counterparts. ",
    "url": "https://arxiv.org/abs/2305.16513",
    "authors": [
      "Roman Snytsar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2305.16544",
    "title": "Inductive detection of Influence Operations via Graph Learning",
    "abstract": "Influence operations are large-scale efforts to manipulate public opinion. The rapid detection and disruption of these operations is critical for healthy public discourse. Emergent AI technologies may enable novel operations which evade current detection methods and influence public discourse on social media with greater scale, reach, and specificity. New methods with inductive learning capacity will be needed to identify these novel operations before they indelibly alter public opinion and events. We develop an inductive learning framework which: 1) determines content- and graph-based indicators that are not specific to any operation; 2) uses graph learning to encode abstract signatures of coordinated manipulation; and 3) evaluates generalization capacity by training and testing models across operations originating from Russia, China, and Iran. We find that this framework enables strong cross-operation generalization while also revealing salient indicators$\\unicode{x2013}$illustrating a generic approach which directly complements transductive methodologies, thereby enhancing detection coverage. ",
    "url": "https://arxiv.org/abs/2305.16544",
    "authors": [
      "Nicholas A. Gabriel",
      "David A. Broniatowski",
      "Neil F. Johnson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2305.16546",
    "title": "Comparing Long Short-Term Memory (LSTM) and Bidirectional LSTM Deep  Neural Networks for power consumption prediction",
    "abstract": "Electric consumption prediction methods are investigated for many reasons such as decision-making related to energy efficiency as well as for anticipating demand in the energy market dynamics. The objective of the present work is the comparison between two Deep Learning models, namely the Long Short-Term Memory (LSTM) and Bi-directional LSTM (BLSTM) for univariate electric consumption Time Series (TS) short-term forecast. The Data Sets (DSs) were selected for their different contexts and scales, aiming the assessment of the models' robustness. Four DSs were used, related to the power consumption of: (a) a household in France; (b) a university building in Santar\\'em, Brazil; (c) the T\\'etouan city zones, in Morocco; and (c) the Singapore aggregated electric demand. The metrics RMSE, MAE, MAPE and R2 were calculated in a TS cross-validation scheme. The Friedman's test was applied to normalized RMSE (NRMSE) results, showing that BLSTM outperforms LSTM with statistically significant difference (p = 0.0455), corroborating the fact that bidirectional weight updating improves significantly the LSTM performance concerning different scales of electric power consumption. ",
    "url": "https://arxiv.org/abs/2305.16546",
    "authors": [
      "Davi Guimar\u00e3es da Silva",
      "Anderson Alvarenga de Moura Meneses"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16562",
    "title": "Unsupervised Embedding Quality Evaluation",
    "abstract": "Unsupervised learning has recently significantly gained in popularity, especially with deep learning-based approaches. Despite numerous successes and approaching supervised-level performance on a variety of academic benchmarks, it is still hard to train and evaluate SSL models in practice due to the unsupervised nature of the problem. Even with networks trained in a supervised fashion, it is often unclear whether they will perform well when transferred to another domain. Past works are generally limited to assessing the amount of information contained in embeddings, which is most relevant for self-supervised learning of deep neural networks. This works chooses to follow a different approach: can we quantify how easy it is to linearly separate the data in a stable way? We survey the literature and uncover three methods that could be potentially used for evaluating quality of representations. We also introduce one novel method based on recent advances in understanding the high-dimensional geometric structure self-supervised learning. We conduct extensive experiments and study the properties of these metrics and ones introduced in the previous work. Our results suggest that while there is no free lunch, there are metrics that can robustly estimate embedding quality in an unsupervised way. ",
    "url": "https://arxiv.org/abs/2305.16562",
    "authors": [
      "Anton Tsitsulin",
      "Marina Munkhoeva",
      "Bryan Perozzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.16580",
    "title": "TFDet: Target-aware Fusion for RGB-T Pedestrian Detection",
    "abstract": "Pedestrian detection is a critical task in computer vision because of its role in ensuring traffic safety. However, existing methods that rely solely on RGB images suffer from performance degradation under low-light conditions due to the lack of useful information. To address this issue, recent multispectral detection approaches combine thermal images to provide complementary information. Nevertheless, these approaches have limitations such as the noisy fused feature maps and the loss of informative features. In this paper, we propose a novel target-aware fusion strategy for multispectral pedestrian detection, named TFDet. Unlike existing methods, TFDet enhances features by supervising the fusion process with a correlation-maximum loss function. Our fusion strategy highlights the pedestrian-related features while suppressing the unrelated ones. TFDet achieves state-of-the-art performances on both KAIST and LLVIP benchmarks, with a speed comparable to the previous state-of-the-art counterpart. Importantly, TFDet performs remarkably well under low-light conditions, which is a significant advancement for road safety. ",
    "url": "https://arxiv.org/abs/2305.16580",
    "authors": [
      "Xue Zhang",
      "Xiaohan Zhang",
      "Zehua Sheng",
      "Hui-Liang Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16588",
    "title": "Legion: Automatically Pushing the Envelope of Multi-GPU System for  Billion-Scale GNN Training",
    "abstract": "Graph neural network(GNN) has been widely applied in real-world applications, such as product recommendation in e-commerce platforms and risk control in financial management systems. Several cache-based GNN systems have been built to accelerate GNN training in a single machine with multiple GPUs. However, these systems fail to train billion-scale graphs efficiently, which is a common challenge in the industry. In this work, we propose Legion, a system that automatically pushes the envelope of multi-GPU systems for accelerating billion-scale GNN training. First, we design a hierarchical graph partitioning mechanism that significantly improves the multi-GPU cache performance. Second, we build a unified multi-GPU cache that helps to minimize the PCIe traffic incurred by caching both graph topology and features with the highest hotness. Third, we develop an automatic caching management mechanism that adapts the multi-GPU cache plan according to the hardware specifications and various graphs to maximize the overall training throughput. Evaluations on various GNN models and multiple datasets show that Legion supports training billion-scale GNNs in a single machine and significantly outperforms the state-of-the-art cache-based systems on small graphs. ",
    "url": "https://arxiv.org/abs/2305.16588",
    "authors": [
      "Jie Sun",
      "Li Su",
      "Zuocheng Shi",
      "Wenting Shen",
      "Zeke Wang",
      "Lei Wang",
      "Jie Zhang",
      "Yong Li",
      "Wenyuan Yu",
      "Jingren Zhou",
      "Fei Wu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2305.16589",
    "title": "The Curious Price of Distributional Robustness in Reinforcement Learning  with a Generative Model",
    "abstract": "This paper investigates model robustness in reinforcement learning (RL) to reduce the sim-to-real gap in practice. We adopt the framework of distributionally robust Markov decision processes (RMDPs), aimed at learning a policy that optimizes the worst-case performance when the deployed environment falls within a prescribed uncertainty set around the nominal MDP. Despite recent efforts, the sample complexity of RMDPs remained mostly unsettled regardless of the uncertainty set in use. It was unclear if distributional robustness bears any statistical consequences when benchmarked against standard RL. Assuming access to a generative model that draws samples based on the nominal MDP, we characterize the sample complexity of RMDPs when the uncertainty set is specified via either the total variation (TV) distance or $\\chi^2$ divergence. The algorithm studied here is a model-based method called {\\em distributionally robust value iteration}, which is shown to be near-optimal for the full range of uncertainty levels. Somewhat surprisingly, our results uncover that RMDPs are not necessarily easier or harder to learn than standard MDPs. The statistical consequence incurred by the robustness requirement depends heavily on the size and shape of the uncertainty set: in the case w.r.t.~the TV distance, the minimax sample complexity of RMDPs is always smaller than that of standard MDPs; in the case w.r.t.~the $\\chi^2$ divergence, the sample complexity of RMDPs can often far exceed the standard MDP counterpart. ",
    "url": "https://arxiv.org/abs/2305.16589",
    "authors": [
      "Laixi Shi",
      "Gen Li",
      "Yuting Wei",
      "Yuxin Chen",
      "Matthieu Geist",
      "Yuejie Chi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2305.16590",
    "title": "Seeding with Differentially Private Network Information",
    "abstract": "When designing interventions in public health, development, and education, decision makers rely on social network data to target a small number of people, capitalizing on peer effects and social contagion to bring about the most welfare benefits to the population. Developing new methods that are privacy-preserving for network data collection and targeted interventions is critical for designing sustainable public health and development interventions on social networks. In a similar vein, social media platforms rely on network data and information from past diffusions to organize their ad campaign and improve the efficacy of targeted advertising. Ensuring that these network operations do not violate users' privacy is critical to the sustainability of social media platforms and their ad economies. We study privacy guarantees for influence maximization algorithms when the social network is unknown, and the inputs are samples of prior influence cascades that are collected at random. Building on recent results that address seeding with costly network information, our privacy-preserving algorithms introduce randomization in the collected data or the algorithm output, and can bound each node's (or group of nodes') privacy loss in deciding whether or not their data should be included in the algorithm input. We provide theoretical guarantees of the seeding performance with a limited sample size subject to differential privacy budgets in both central and local privacy regimes. Simulations on synthetic and empirical network datasets reveal the diminishing value of network information with decreasing privacy budget in both regimes. ",
    "url": "https://arxiv.org/abs/2305.16590",
    "authors": [
      "M. Amin Rahimian",
      "Fang-Yi Yu",
      "Carlos Hurtado"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computational Complexity (cs.CC)",
      "Multiagent Systems (cs.MA)",
      "Probability (math.PR)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2305.16593",
    "title": "A Multi-Resolution Physics-Informed Recurrent Neural Network:  Formulation and Application to Musculoskeletal Systems",
    "abstract": "This work presents a multi-resolution physics-informed recurrent neural network (MR PI-RNN), for simultaneous prediction of musculoskeletal (MSK) motion and parameter identification of the MSK systems. The MSK application was selected as the model problem due to its challenging nature in mapping the high-frequency surface electromyography (sEMG) signals to the low-frequency body joint motion controlled by the MSK and muscle contraction dynamics. The proposed method utilizes the fast wavelet transform to decompose the mixed frequency input sEMG and output joint motion signals into nested multi-resolution signals. The prediction model is subsequently trained on coarser-scale input-output signals using a gated recurrent unit (GRU), and then the trained parameters are transferred to the next level of training with finer-scale signals. These training processes are repeated recursively under a transfer-learning fashion until the full-scale training (i.e., with unfiltered signals) is achieved, while satisfying the underlying dynamic equilibrium. Numerical examples on recorded subject data demonstrate the effectiveness of the proposed framework in generating a physics-informed forward-dynamics surrogate, which yields higher accuracy in motion predictions of elbow flexion-extension of an MSK system compared to the case with single-scale training. The framework is also capable of identifying muscle parameters that are physiologically consistent with the subject's kinematics data. ",
    "url": "https://arxiv.org/abs/2305.16593",
    "authors": [
      "Karan Taneja",
      "Xiaolong He",
      "Qizhi He",
      "J. S. Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16594",
    "title": "A Hybrid Neural Coding Approach for Pattern Recognition with Spiking  Neural Networks",
    "abstract": "The biological neural systems evolved to adapt to ecological environment for efficiency and effectiveness, wherein neurons with heterogeneous structures and rich dynamics are optimized to accomplish complex cognitive tasks. Most of the current research of biologically inspired spiking neural networks (SNNs) are, however, grounded on a homogeneous neural coding scheme, which limits their overall performance in terms of accuracy, latency, efficiency, and robustness, etc. In this work, we argue that one should holistically design the network architecture to incorporate diverse neuronal functions and neural coding schemes for best performance. As an early attempt in this research direction, we put forward a hybrid neural coding framework that integrates multiple neural coding schemes discovered in neuroscience. We demonstrate that the proposed hybrid coding scheme achieves a comparable accuracy with the state-of-the-art SNNs with homogeneous neural coding on CIFAR-10, CIFAR-100, and Tiny-ImageNet datasets with less than eight time steps and at least 3.90x fewer computations. Furthermore, we demonstrate accurate, rapid, and robust sound source localization on SoClas dataset. This study yields valuable insights into the performance of various hybrid neural coding designs and hold significant implications for designing high performance SNNs. ",
    "url": "https://arxiv.org/abs/2305.16594",
    "authors": [
      "Xinyi Chen",
      "Qu Yang",
      "Jibin Wu",
      "Haizhou Li",
      "Kay Chen Tan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.16597",
    "title": "Neural Architecture Search for Parameter-Efficient Fine-tuning of Large  Pre-trained Language Models",
    "abstract": "Parameter-efficient tuning (PET) methods fit pre-trained language models (PLMs) to downstream tasks by either computing a small compressed update for a subset of model parameters, or appending and fine-tuning a small number of new model parameters to the pre-trained network. Hand-designed PET architectures from the literature perform well in practice, but have the potential to be improved via automated neural architecture search (NAS). We propose an efficient NAS method for learning PET architectures via structured and unstructured pruning. We present experiments on GLUE demonstrating the effectiveness of our algorithm and discuss how PET architectural design choices affect performance in practice. ",
    "url": "https://arxiv.org/abs/2305.16597",
    "authors": [
      "Neal Lawton",
      "Anoop Kumar",
      "Govind Thattai",
      "Aram Galstyan",
      "Greg Ver Steeg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16599",
    "title": "Bridging the Domain Gaps in Context Representations for k-Nearest  Neighbor Neural Machine Translation",
    "abstract": "$k$-Nearest neighbor machine translation ($k$NN-MT) has attracted increasing attention due to its ability to non-parametrically adapt to new translation domains. By using an upstream NMT model to traverse the downstream training corpus, it is equipped with a datastore containing vectorized key-value pairs, which are retrieved during inference to benefit translation. However, there often exists a significant gap between upstream and downstream domains, which hurts the retrieval accuracy and the final translation quality. To deal with this issue, we propose a novel approach to boost the datastore retrieval of $k$NN-MT by reconstructing the original datastore. Concretely, we design a reviser to revise the key representations, making them better fit for the downstream domain. The reviser is trained using the collected semantically-related key-queries pairs, and optimized by two proposed losses: one is the key-queries semantic distance ensuring each revised key representation is semantically related to its corresponding queries, and the other is an L2-norm loss encouraging revised key representations to effectively retain the knowledge learned by the upstream NMT model. Extensive experiments on domain adaptation tasks demonstrate that our method can effectively boost the datastore retrieval and translation quality of $k$NN-MT.\\footnote{Our code is available at \\url{https://github.com/DeepLearnXMU/RevisedKey-knn-mt}.} ",
    "url": "https://arxiv.org/abs/2305.16599",
    "authors": [
      "Zhiwei Cao",
      "Baosong Yang",
      "Huan Lin",
      "Suhang Wu",
      "Xiangpeng Wei",
      "Dayiheng Liu",
      "Jun Xie",
      "Min Zhang",
      "Jinsong Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.16617",
    "title": "Efficient Detection of LLM-generated Texts with a Bayesian Surrogate  Model",
    "abstract": "The detection of machine-generated text, especially from large language models (LLMs), is crucial in preventing serious social problems resulting from their misuse. Some methods train dedicated detectors on specific datasets but fall short in generalizing to unseen test data, while other zero-shot ones often yield suboptimal performance. Although the recent DetectGPT has shown promising detection performance, it suffers from significant inefficiency issues, as detecting a single candidate requires scoring hundreds of its perturbations with the source LLM. This paper aims to bridge this gap. Technically, we propose to incorporate a Bayesian surrogate model, which allows us to select typical samples based on Bayesian uncertainty and interpolate scores from typical samples to other ones, to improve query efficiency. Our empirical results demonstrate that our method significantly outperforms existing approaches under a low query budget. Notably, our method achieves similar performance with up to 2 times fewer queries than DetectGPT and 3.7% higher AUROC at a query number of 5. ",
    "url": "https://arxiv.org/abs/2305.16617",
    "authors": [
      "Zhijie Deng",
      "Hongcheng Gao",
      "Yibo Miao",
      "Hao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.16618",
    "title": "Confidence-Based Feature Imputation for Graphs with Partially Known  Features",
    "abstract": "This paper investigates a missing feature imputation problem for graph learning tasks. Several methods have previously addressed learning tasks on graphs with missing features. However, in cases of high rates of missing features, they were unable to avoid significant performance degradation. To overcome this limitation, we introduce a novel concept of channel-wise confidence in a node feature, which is assigned to each imputed channel feature of a node for reflecting certainty of the imputation. We then design pseudo-confidence using the channel-wise shortest path distance between a missing-feature node and its nearest known-feature node to replace unavailable true confidence in an actual learning process. Based on the pseudo-confidence, we propose a novel feature imputation scheme that performs channel-wise inter-node diffusion and node-wise inter-channel propagation. The scheme can endure even at an exceedingly high missing rate (e.g., 99.5\\%) and it achieves state-of-the-art accuracy for both semi-supervised node classification and link prediction on various datasets containing a high rate of missing features. Codes are available at \\url{https://github.com/daehoum1/pcfi}. ",
    "url": "https://arxiv.org/abs/2305.16618",
    "authors": [
      "Daeho Um",
      "Jiwoong Park",
      "Seulki Park",
      "Jin Young Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.16625",
    "title": "Set-based Neural Network Encoding",
    "abstract": "We propose an approach to neural network weight encoding for generalization performance prediction that utilizes set-to-set and set-to-vector functions to efficiently encode neural network parameters. Our approach is capable of encoding neural networks in a modelzoo of mixed architecture and different parameter sizes as opposed to previous approaches that require custom encoding models for different architectures. Furthermore, our \\textbf{S}et-based \\textbf{N}eural network \\textbf{E}ncoder (SNE) takes into consideration the hierarchical computational structure of neural networks by utilizing a layer-wise encoding scheme that culminates to encoding all layer-wise encodings to obtain the neural network encoding vector. Additionally, we introduce a \\textit{pad-chunk-encode} pipeline to efficiently encode neural network layers that is adjustable to computational and memory constraints. We also introduce two new tasks for neural network generalization performance prediction: cross-dataset and cross-architecture. In cross-dataset performance prediction, we evaluate how well performance predictors generalize across modelzoos trained on different datasets but of the same architecture. In cross-architecture performance prediction, we evaluate how well generalization performance predictors transfer to modelzoos of different architecture. Experimentally, we show that SNE outperforms the relevant baselines on the cross-dataset task and provide the first set of results on the cross-architecture task. ",
    "url": "https://arxiv.org/abs/2305.16625",
    "authors": [
      "Bruno Andreis",
      "Soro Bedionita",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.16638",
    "title": "Adversarial Multi-task Learning for End-to-end Metaphor Detection",
    "abstract": "Metaphor detection (MD) suffers from limited training data. In this paper, we started with a linguistic rule called Metaphor Identification Procedure and then proposed a novel multi-task learning framework to transfer knowledge in basic sense discrimination (BSD) to MD. BSD is constructed from word sense disambiguation (WSD), which has copious amounts of data. We leverage adversarial training to align the data distributions of MD and BSD in the same feature space, so task-invariant representations can be learned. To capture fine-grained alignment patterns, we utilize the multi-mode structures of MD and BSD. Our method is totally end-to-end and can mitigate the data scarcity problem in MD. Competitive results are reported on four public datasets. Our code and datasets are available. ",
    "url": "https://arxiv.org/abs/2305.16638",
    "authors": [
      "Shenglong Zhang",
      "Ying Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.16639",
    "title": "Universal Approximation and the Topological Neural Network",
    "abstract": "A topological neural network (TNN), which takes data from a Tychonoff topological space instead of the usual finite dimensional space, is introduced. As a consequence, a distributional neural network (DNN) that takes Borel measures as data is also introduced. Combined these new neural networks facilitate things like recognizing long range dependence, heavy tails and other properties in stochastic process paths or like acting on belief states produced by particle filtering or hidden Markov model algorithms. The veracity of the TNN and DNN are then established herein by a strong universal approximation theorem for Tychonoff spaces and its corollary for spaces of measures. These theorems show that neural networks can arbitrarily approximate uniformly continuous functions (with respect to the sup metric) associated with a unique uniformity. We also provide some discussion showing that neural networks on positive-finite measures are a generalization of the recent deep learning notion of deep sets. ",
    "url": "https://arxiv.org/abs/2305.16639",
    "authors": [
      "Michael A. Kouritzin",
      "Daniel Richard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16646",
    "title": "Language Models Can Improve Event Prediction by Few-Shot Abductive  Reasoning",
    "abstract": "Large language models have shown astonishing performance on a wide range of reasoning tasks. In this paper, we investigate whether they could reason about real-world events and help improve the prediction accuracy of event sequence models. We design a modeling and prediction framework where a large language model performs abductive reasoning to assist an event sequence model: the event model proposes predictions on future events given the past; instructed by a few expert-annotated demonstrations, the language model learns to suggest possible causes for each proposal; a search module finds out the previous events that match the causes; a scoring function learns to examine whether the retrieved events could actually cause the proposal. Through extensive experiments on two challenging real-world datasets (Amazon Review and GDELT), we demonstrate that our framework -- thanks to the reasoning ability of language models -- could significantly outperform the state-of-the-art event sequence models. ",
    "url": "https://arxiv.org/abs/2305.16646",
    "authors": [
      "Xiaoming Shi",
      "Siqiao Xue",
      "Kangrui Wang",
      "Fan Zhou",
      "James Y. Zhang",
      "Jun Zhou",
      "Chenhao Tan",
      "Hongyuan Mei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16649",
    "title": "FSD: Fully-Specialized Detector via Neural Architecture Search",
    "abstract": "In this paper, we first propose and examine a fully-automatic pipeline to design a fully-specialized detector (FSD) which mainly incorporates a neural-architectural-searched model by exploring ideal network structures over the backbone and task-specific head. ",
    "url": "https://arxiv.org/abs/2305.16649",
    "authors": [
      "Zhe Huang",
      "Yudian Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16652",
    "title": "Faster Ray Tracing through Hierarchy Cut Code",
    "abstract": "We propose a novel ray reordering technique to accelerate the ray tracing process by encoding and sorting rays prior to traversal. Instead of spatial coordinates, our method encodes rays according to the cuts of the hierarchical acceleration structure, which is called the \\textbf{hierarchy cut code}. This approach can better adapt to the acceleration structure and obtain a more reliable encoding result. We also propose a compression scheme to decrease the sorting overhead by a shorter sorting key. In addition, based on the phenomenon of boundary drift, we theoretically explain the reason why existing reordering methods cannot achieve better performance by using longer sorting keys. The experiment demonstrates that our method can accelerate secondary ray tracing by up to 1.81 times, outperforming the existing methods. Such result proves the effectiveness of hierarchy cut code, and indicate that the reordering technique can achieve greater performance improvement, which worth further research. ",
    "url": "https://arxiv.org/abs/2305.16652",
    "authors": [
      "WeiLai Xiang",
      "FengQi Liu",
      "Dan Li",
      "ZhaoNan Tan",
      "PengZhan Xu",
      "MeiZhi Liu",
      "QiLong Kou"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2305.16658",
    "title": "Decentralised adaptive-gain control for eliminating epidemic spreading  on networks",
    "abstract": "This paper considers the classical Susceptible--Infected--Susceptible (SIS) network epidemic model, which describes a disease spreading through $n$ nodes, with the network links governing the possible transmission pathways of the disease between nodes. We consider feedback control to eliminate the disease in scenarios where the disease would otherwise persist in an uncontrolled network. We propose a family of decentralised adaptive-gain control algorithms, in which each node has a control gain that adaptively evolves according to a differential equation, independent of the gains of other nodes. The adaptive gain is applied multiplicatively to either decrease the infection rate or increase the recovery rate. To begin, we assume all nodes are controlled, and prove that both infection rate control and recovery rate control algorithms eliminate the disease with the limiting gains being positive and finite. Then, we consider the possibility of controlling a subset of the nodes, for both the infection rate control and recovery rate control. We first identify a necessary and sufficient condition for the existence of a subset of nodes, which if controlled would result in the elimination of the disease. For a given network, there may exist several such viable subsets, and we propose an iterative algorithm to identify such a subset. Simulations are provided to demonstrate the effectiveness of the various proposed controllers. ",
    "url": "https://arxiv.org/abs/2305.16658",
    "authors": [
      "Liam Walsh",
      "Mengbin Ye",
      "Brian D.O. Anderson",
      "Zhiyong Sun"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2305.16661",
    "title": "Gender, Smoking History and Age Prediction from Laryngeal Images",
    "abstract": "Flexible laryngoscopy is commonly performed by otolaryngologists to detect laryngeal diseases and to recognize potentially malignant lesions. Recently, researchers have introduced machine learning techniques to facilitate automated diagnosis using laryngeal images and achieved promising results. Diagnostic performance can be improved when patients' demographic information is incorporated into models. However, manual entry of patient data is time consuming for clinicians. In this study, we made the first endeavor to employ deep learning models to predict patient demographic information to improve detector model performance. The overall accuracy for gender, smoking history, and age was 85.5%, 65.2%, and 75.9%, respectively. We also created a new laryngoscopic image set for machine learning study and benchmarked the performance of 8 classical deep learning models based on CNNs and Transformers. The results can be integrated into current learning models to improve their performance by incorporating the patient's demographic information. ",
    "url": "https://arxiv.org/abs/2305.16661",
    "authors": [
      "Tianxiao Zhang",
      "Andr\u00e9s M. Bur",
      "Shannon Kraft",
      "Hannah Kavookjian",
      "Bryan Renslo",
      "Xiangyu Chen",
      "Bo Luo",
      "Guanghui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16663",
    "title": "GDA: Generative Data Augmentation Techniques for Relation Extraction  Tasks",
    "abstract": "Relation extraction (RE) tasks show promising performance in extracting relations from two entities mentioned in sentences, given sufficient annotations available during training. Such annotations would be labor-intensive to obtain in practice. Existing work adopts data augmentation techniques to generate pseudo-annotated sentences beyond limited annotations. These techniques neither preserve the semantic consistency of the original sentences when rule-based augmentations are adopted, nor preserve the syntax structure of sentences when expressing relations using seq2seq models, resulting in less diverse augmentations. In this work, we propose a dedicated augmentation technique for relational texts, named GDA, which uses two complementary modules to preserve both semantic consistency and syntax structures. We adopt a generative formulation and design a multi-tasking solution to achieve synergies. Furthermore, GDA adopts entity hints as the prior knowledge of the generative model to augment diverse sentences. Experimental results in three datasets under a low-resource setting showed that GDA could bring {\\em 2.0\\%} F1 improvements compared with no augmentation technique. Source code and data are available. ",
    "url": "https://arxiv.org/abs/2305.16663",
    "authors": [
      "Xuming Hu",
      "Aiwei Liu",
      "Zeqi Tan",
      "Xin Zhang",
      "Chenwei Zhang",
      "Irwin King",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.16682",
    "title": "Sharpend Cosine Similarity based Neural Network for Hyperspectral Image  Classification",
    "abstract": "Hyperspectral Image Classification (HSIC) is a difficult task due to high inter and intra-class similarity and variability, nested regions, and overlapping. 2D Convolutional Neural Networks (CNN) emerged as a viable network whereas, 3D CNNs are a better alternative due to accurate classification. However, 3D CNNs are highly computationally complex due to their volume and spectral dimensions. Moreover, down-sampling and hierarchical filtering (high frequency) i.e., texture features need to be smoothed during the forward pass which is crucial for accurate HSIC. Furthermore, CNN requires tons of tuning parameters which increases the training time. Therefore, to overcome the aforesaid issues, Sharpened Cosine Similarity (SCS) concept as an alternative to convolutions in a Neural Network for HSIC is introduced. SCS is exceptionally parameter efficient due to skipping the non-linear activation layers, normalization, and dropout after the SCS layer. Use of MaxAbsPool instead of MaxPool which selects the element with the highest magnitude of activity, even if it's negative. Experimental results on publicly available HSI datasets proved the performance of SCS as compared to the convolutions in Neural Networks. ",
    "url": "https://arxiv.org/abs/2305.16682",
    "authors": [
      "Muhammad Ahmad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16691",
    "title": "Dual Bayesian ResNet: A Deep Learning Approach to Heart Murmur Detection",
    "abstract": "This study presents our team PathToMyHeart's contribution to the George B. Moody PhysioNet Challenge 2022. Two models are implemented. The first model is a Dual Bayesian ResNet (DBRes), where each patient's recording is segmented into overlapping log mel spectrograms. These undergo two binary classifications: present versus unknown or absent, and unknown versus present or absent. The classifications are aggregated to give a patient's final classification. The second model is the output of DBRes integrated with demographic data and signal features using XGBoost.DBRes achieved our best weighted accuracy of $0.771$ on the hidden test set for murmur classification, which placed us fourth for the murmur task. (On the clinical outcome task, which we neglected, we scored 17th with costs of $12637$.) On our held-out subset of the training set, integrating the demographic data and signal features improved DBRes's accuracy from $0.762$ to $0.820$. However, this decreased DBRes's weighted accuracy from $0.780$ to $0.749$. Our results demonstrate that log mel spectrograms are an effective representation of heart sound recordings, Bayesian networks provide strong supervised classification performance, and treating the ternary classification as two binary classifications increases performance on the weighted accuracy. ",
    "url": "https://arxiv.org/abs/2305.16691",
    "authors": [
      "Benjamin Walker",
      "Felix Krones",
      "Ivan Kiskin",
      "Guy Parsons",
      "Terry Lyons",
      "Adam Mahdi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16692",
    "title": "Attacks on Continuous Chaos Communication and Remedies for Resource  Limited Devices",
    "abstract": "The Global Wearable market is anticipated to rise at a considerable rate in the next coming years and communication is a fundamental block in any wearable device. In communication, encryption methods are being used with the aid of microcontrollers or software implementations, which are power-consuming and incorporate complex hardware implementation. Internet of Things (IoT) devices are considered as resource-constrained devices that are expected to operate with low computational power and resource utilization criteria. At the same time, recent research has shown that IoT devices are highly vulnerable to emerging security threats, which elevates the need for low-power and small-size hardware-based security countermeasures. Chaotic encryption is a method of data encryption that utilizes chaotic systems and non-linear dynamics to generate secure encryption keys. It aims to provide high-level security by creating encryption keys that are sensitive to initial conditions and difficult to predict, making it challenging for unauthorized parties to intercept and decode encrypted data. Since the discovery of chaotic equations, there have been various encryption applications associated with them. In this paper, we comprehensively analyze the physical and encryption attacks on continuous chaotic systems in resource-constrained devices and their potential remedies. To this aim, we introduce different categories of attacks of chaotic encryption. Our experiments focus on chaotic equations implemented using Chua's equation and leverages circuit architectures and provide simulations proof of remedies for different attacks. These remedies are provided to block the attackers from stealing users' information (e.g., a pulse message) with negligible cost to the power and area of the design. ",
    "url": "https://arxiv.org/abs/2305.16692",
    "authors": [
      "Rahul Vishwakarma",
      "Ravi Monani",
      "Amin Rezaei",
      "Hossein Sayadi",
      "Mehrdad Aliasgari",
      "Ava Hedayatipour"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.16698",
    "title": "Detect Any Shadow: Segment Anything for Video Shadow Detection",
    "abstract": "Segment anything model (SAM) has achieved great success in the field of natural image segmentation. Nevertheless, SAM tends to classify shadows as background, resulting in poor segmentation performance for shadow detection task. In this paper, we propose an simple but effective approach for fine tuning SAM to detect shadows. Additionally, we also combine it with long short-term attention mechanism to extend its capabilities to video shadow detection. Specifically, we first fine tune SAM by utilizing shadow data combined with sparse prompts and apply the fine-tuned model to detect a specific frame (e.g., first frame) in the video with a little user assistance. Subsequently, using the detected frame as a reference, we employ a long short-term network to learn spatial correlations between distant frames and temporal consistency between contiguous frames, thereby achieving shadow information propagation across frames. Extensive experimental results demonstrate that our method outperforms the state-of-the-art techniques, with improvements of 17.2% and 3.3% in terms of MAE and IoU, respectively, validating the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2305.16698",
    "authors": [
      "Yonghui Wang",
      "Wengang Zhou",
      "Yunyao Mao",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16713",
    "title": "ReConPatch : Contrastive Patch Representation Learning for Industrial  Anomaly Detection",
    "abstract": "Anomaly detection is crucial to the advanced identification of product defects such as incorrect parts, misaligned components, and damages in industrial manufacturing. Due to the rare observations and unknown types of defects, anomaly detection is considered to be challenging in machine learning. To overcome this difficulty, recent approaches utilize the common visual representations from natural image datasets and distill the relevant features. However, existing approaches still have the discrepancy between the pre-trained feature and the target data, or require the input augmentation which should be carefully designed particularly for the industrial dataset. In this paper, we introduce ReConPatch, which constructs discriminative features for anomaly detection by training a linear modulation attached to a pre-trained model. ReConPatch employs contrastive representation learning to collect and distribute features in a way that produces a target-oriented and easily separable representation. To address the absence of labeled pairs for the contrastive learning, we utilize two similarity measures, pairwise and contextual similarities, between data representations as a pseudo-label. Unlike previous work, ReConPatch achieves robust anomaly detection performance without extensive input augmentation. Our method achieves the state-of-the-art anomaly detection performance (99.72%) for the widely used and challenging MVTec AD dataset. ",
    "url": "https://arxiv.org/abs/2305.16713",
    "authors": [
      "Jeeho Hyun",
      "Sangyun Kim",
      "Giyoung Jeon",
      "Seung Hwan Kim",
      "Kyunghoon Bae",
      "Byung Jun Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16727",
    "title": "A novel application for real-time arrhythmia detection using YOLOv8",
    "abstract": "In recent years, there has been an increasing need to reduce healthcare costs in remote monitoring of cardiovascular health. Detecting and classifying cardiac arrhythmia is critical to diagnosing patients with cardiac abnormalities. This paper shows that complex systems such as electrocardiograms (ECG) can be applicable for at-home monitoring. This paper proposes a novel application for arrhythmia detection using the state-of-the-art You-Only-Look-Once (YOLO)v8 algorithm to classify single-lead ECG signals. A custom YOLOv8 model was fine-tuned on the MIT-BIH dataset to detect arrhythmia in real-time to allow continuous monitoring. Results show that our model can detect heartbeats with a mAP@50 of 0.961 with a detection time of 0.002s on an NVIDIA Tesla V100. Our study demonstrated the potential of real-time arrhythmia detection, where the model output can be visually interpreted for at-home users. Furthermore, this study could be extended into a real-time XAI model, deployed in the healthcare industry, and significantly advancing healthcare needs. ",
    "url": "https://arxiv.org/abs/2305.16727",
    "authors": [
      "G. J. N. Ang",
      "A. K. Goil",
      "H. Chan",
      "X. C. Lee",
      "R. B. A. Mustaffa",
      "T. Jason",
      "Z. T. Woon",
      "B. Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16729",
    "title": "Evaluating generation of chaotic time series by convolutional generative  adversarial networks",
    "abstract": "To understand the ability and limitations of convolutional neural networks to generate time series that mimic complex temporal signals, we trained a generative adversarial network consisting of deep convolutional networks to generate chaotic time series and used nonlinear time series analysis to evaluate the generated time series. A numerical measure of determinism and the Lyapunov exponent, a measure of trajectory instability, showed that the generated time series well reproduce the chaotic properties of the original time series. However, error distribution analyses showed that large errors appeared at a low but non-negligible rate. Such errors would not be expected if the distribution were assumed to be exponential. ",
    "url": "https://arxiv.org/abs/2305.16729",
    "authors": [
      "Yuki Tanaka",
      "Yutaka Yamaguti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16744",
    "title": "Demo2Code: From Summarizing Demonstrations to Synthesizing Code via  Extended Chain-of-Thought",
    "abstract": "Language instructions and demonstrations are two natural ways for users to teach robots personalized tasks. Recent progress in Large Language Models (LLMs) has shown impressive performance in translating language instructions into code for robotic tasks. However, translating demonstrations into task code continues to be a challenge due to the length and complexity of both demonstrations and code, making learning a direct mapping intractable. This paper presents Demo2Code, a novel framework that generates robot task code from demonstrations via an extended chain-of-thought and defines a common latent specification to connect the two. Our framework employs a robust two-stage process: (1) a recursive summarization technique that condenses demonstrations into concise specifications, and (2) a code synthesis approach that expands each function recursively from the generated specifications. We conduct extensive evaluation on various robot task benchmarks, including a novel game benchmark Robotouille, designed to simulate diverse cooking tasks in a kitchen environment. ",
    "url": "https://arxiv.org/abs/2305.16744",
    "authors": [
      "Huaxiaoyue Wang",
      "Gonzalo Gonzalez-Pumariega",
      "Yash Sharma",
      "Sanjiban Choudhury"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.16746",
    "title": "CNN Feature Map Augmentation for Single-Source Domain Generalization",
    "abstract": "In search of robust and generalizable machine learning models, Domain Generalization (DG) has gained significant traction during the past few years. The goal in DG is to produce models which continue to perform well when presented with data distributions different from the ones seen during training. While deep convolutional neural networks (CNN) have been able to achieve outstanding performance on downstream computer vision tasks, they still often fail to generalize on previously unseen data Domains. Therefore, in this work we focus on producing a model which is able to remain robust under data distribution shift and propose an alternative regularization technique for convolutional neural network architectures in the single-source DG image classification setting. To mitigate the problem caused by domain shift between source and target data, we propose augmenting intermediate feature maps of CNNs. Specifically, we pass them through a novel Augmentation Layer to prevent models from overfitting on the training set and improve their cross-domain generalization. To the best of our knowledge, this is the first paper proposing such a setup for the DG image classification setting. Experiments on the DG benchmark datasets of PACS, VLCS, Office-Home and TerraIncognita validate the effectiveness of our method, in which our model surpasses state-of-the-art algorithms in most cases. ",
    "url": "https://arxiv.org/abs/2305.16746",
    "authors": [
      "Aristotelis Ballas",
      "Christos Diou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16748",
    "title": "A Decentralized Spike-based Learning Framework for Sequential Capture in  Discrete Perimeter Defense Problem",
    "abstract": "This paper proposes a novel Decentralized Spike-based Learning (DSL) framework for the discrete Perimeter Defense Problem (d-PDP). A team of defenders is operating on the perimeter to protect the circular territory from radially incoming intruders. At first, the d-PDP is formulated as a spatio-temporal multi-task assignment problem (STMTA). The problem of STMTA is then converted into a multi-label learning problem to obtain labels of segments that defenders have to visit in order to protect the perimeter. The DSL framework uses a Multi-Label Classifier using Synaptic Efficacy Function spiking neuRON (MLC-SEFRON) network for deterministic multi-label learning. Each defender contains a single MLC-SEFRON network. Each MLC-SEFRON network is trained independently using input from its own perspective for decentralized operations. The input spikes to the MLC-SEFRON network can be directly obtained from the spatio-temporal information of defenders and intruders without any extra pre-processing step. The output of MLC-SEFRON contains the labels of segments that a defender has to visit in order to protect the perimeter. Based on the multi-label output from the MLC-SEFRON a trajectory is generated for a defender using a Consensus-Based Bundle Algorithm (CBBA) in order to capture the intruders. The target multi-label output for training MLC-SEFRON is obtained from an expert policy. Also, the MLC-SEFRON trained for a defender can be directly used for obtaining labels of segments assigned to another defender without any retraining. The performance of MLC-SEFRON has been evaluated for full observation and partial observation scenarios of the defender. The overall performance of the DSL framework is then compared with expert policy along with other existing learning algorithms. The scalability of the DSL has been evaluated using an increasing number of defenders. ",
    "url": "https://arxiv.org/abs/2305.16748",
    "authors": [
      "Mohammed Thousif",
      "Shridhar Velhal",
      "Suresh Sundaram",
      "Shirin Dora"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.16749",
    "title": "Diverse and Expressive Speech Prosody Prediction with Denoising  Diffusion Probabilistic Model",
    "abstract": "Expressive human speech generally abounds with rich and flexible speech prosody variations. The speech prosody predictors in existing expressive speech synthesis methods mostly produce deterministic predictions, which are learned by directly minimizing the norm of prosody prediction error. Its unimodal nature leads to a mismatch with ground truth distribution and harms the model's ability in making diverse predictions. Thus, we propose a novel prosody predictor based on the denoising diffusion probabilistic model to take advantage of its high-quality generative modeling and training stability. Experiment results confirm that the proposed prosody predictor outperforms the deterministic baseline on both the expressiveness and diversity of prediction results with even fewer network parameters. ",
    "url": "https://arxiv.org/abs/2305.16749",
    "authors": [
      "Xiang Li",
      "Songxiang Liu",
      "Max W. Y. Lam",
      "Zhiyong Wu",
      "Chao Weng",
      "Helen Meng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.16757",
    "title": "Incentive Attacks on DAG-Based Blockchains with Random Transaction  Selection",
    "abstract": "Several blockchain consensus protocols proposed to use of Directed Acyclic Graphs (DAGs) to solve the limited processing throughput of traditional single-chain Proof-of-Work (PoW) blockchains. Many such protocols utilize a random transaction selection (RTS) strategy (e.g., PHANTOM, GHOSTDAG, SPECTRE, Inclusive, and Prism) to avoid transaction duplicates across parallel blocks in DAG and thus maximize the network throughput. However, previous research has not rigorously examined incentive-oriented greedy behaviors when transaction selection deviates from the protocol. In this work, we first perform a generic game-theoretic analysis abstracting several DAG-based blockchain protocols that use the RTS strategy, and we prove that such a strategy does not constitute a Nash equilibrium, which is contradictory to the proof in the Inclusive paper. Next, we develop a blockchain simulator that extends existing open-source tools to support multiple chains and explore incentive-based deviations from the protocol. We perform simulations with ten miners to confirm our conclusion from the game-theoretic analysis. The simulations confirm that greedy actors who do not follow the RTS strategy can profit more than honest miners and harm the processing throughput of the protocol because duplicate transactions are included in more than one block of different chains. We show that this effect is indirectly proportional to the network propagation delay. Finally, we show that greedy miners are incentivized to form a shared mining pool to increase their profits. This undermines the decentralization and degrades the design of the protocols in question. To further support our claims, we execute more complex experiments on a realistic Bitcoin-like network with more than 7000 nodes. ",
    "url": "https://arxiv.org/abs/2305.16757",
    "authors": [
      "Martin Pere\u0161\u00edni",
      "Ivan Homoliak",
      "Federico Matteo Ben\u010di\u0107",
      "Martin Hrub\u00fd",
      "Kamil Malinka"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.16777",
    "title": "Unleashing the Potential of Unsupervised Deep Outlier Detection through  Automated Training Stopping",
    "abstract": "Outlier detection (OD) has received continuous research interests due to its wide applications. With the development of deep learning, increasingly deep OD algorithms are proposed. Despite the availability of numerous deep OD models, existing research has reported that the performance of deep models is extremely sensitive to the configuration of hyperparameters (HPs). However, the selection of HPs for deep OD models remains a notoriously difficult task due to the lack of any labels and long list of HPs. In our study. we shed light on an essential factor, training time, that can introduce significant variation in the performance of deep model. Even the performance is stable across other HPs, training time itself can cause a serious HP sensitivity issue. Motivated by this finding, we are dedicated to formulating a strategy to terminate model training at the optimal iteration. Specifically, we propose a novel metric called loss entropy to internally evaluate the model performance during training while an automated training stopping algorithm is devised. To our knowledge, our approach is the first to enable reliable identification of the optimal training iteration during training without requiring any labels. Our experiments on tabular, image datasets show that our approach can be applied to diverse deep models and datasets. It not only enhances the robustness of deep models to their HPs, but also improves the performance and reduces plenty of training time compared to naive training. ",
    "url": "https://arxiv.org/abs/2305.16777",
    "authors": [
      "Yihong Huang",
      "Yuang Zhang",
      "Liping Wang",
      "Xuemin Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16780",
    "title": "Graph Neural Convection-Diffusion with Heterophily",
    "abstract": "Graph neural networks (GNNs) have shown promising results across various graph learning tasks, but they often assume homophily, which can result in poor performance on heterophilic graphs. The connected nodes are likely to be from different classes or have dissimilar features on heterophilic graphs. In this paper, we propose a novel GNN that incorporates the principle of heterophily by modeling the flow of information on nodes using the convection-diffusion equation (CDE). This allows the CDE to take into account both the diffusion of information due to homophily and the ``convection'' of information due to heterophily. We conduct extensive experiments, which suggest that our framework can achieve competitive performance on node classification tasks for heterophilic graphs, compared to the state-of-the-art methods. The code is available at \\url{https://github.com/zknus/Graph-Diffusion-CDE}. ",
    "url": "https://arxiv.org/abs/2305.16780",
    "authors": [
      "Kai Zhao",
      "Qiyu Kang",
      "Yang Song",
      "Rui She",
      "Sijie Wang",
      "Wee Peng Tay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.16789",
    "title": "Modulate Your Spectrum in Self-Supervised Learning",
    "abstract": "Whitening loss provides theoretical guarantee in avoiding feature collapse for self-supervised learning (SSL) using joint embedding architectures. One typical implementation of whitening loss is hard whitening that designs whitening transformation over embedding and imposes the loss on the whitened output. In this paper, we propose spectral transformation (ST) framework to map the spectrum of embedding to a desired distribution during forward pass, and to modulate the spectrum of embedding by implicit gradient update during backward pass. We show that whitening transformation is a special instance of ST by definition, and there exist other instances that can avoid collapse by our empirical investigation. Furthermore, we propose a new instance of ST, called IterNorm with trace loss (INTL). We theoretically prove that INTL can avoid collapse and modulate the spectrum of embedding towards an equal-eigenvalue distribution during the course of optimization. Moreover, INTL achieves 76.6% top-1 accuracy in linear evaluation on ImageNet using ResNet-50, which exceeds the performance of the supervised baseline, and this result is obtained by using a batch size of only 256. Comprehensive experiments show that INTL is a promising SSL method in practice. The code is available at https://github.com/winci-ai/intl. ",
    "url": "https://arxiv.org/abs/2305.16789",
    "authors": [
      "Xi Weng",
      "Yunhao Ni",
      "Tengwei Song",
      "Jie Luo",
      "Rao Muhammad Anwer",
      "Salman Khan",
      "Fahad Shahbaz Khan",
      "Lei Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.16793",
    "title": "Incentive Mechanism for Uncertain Tasks under Differential Privacy",
    "abstract": "Mobile crowd sensing (MCS) has emerged as an increasingly popular sensing paradigm due to its cost-effectiveness. This approach relies on platforms to outsource tasks to participating workers when prompted by task publishers. Although incentive mechanisms have been devised to foster widespread participation in MCS, most of them focus only on static tasks (i.e., tasks for which the timing and type are known in advance) and do not protect the privacy of worker bids. In a dynamic and resource-constrained environment, tasks are often uncertain (i.e., the platform lacks a priori knowledge about the tasks) and worker bids may be vulnerable to inference attacks. This paper presents HERALD*, an incentive mechanism that addresses these issues through the use of uncertainty and hidden bids. Theoretical analysis reveals that HERALD* satisfies a range of critical criteria, including truthfulness, individual rationality, differential privacy, low computational complexity, and low social cost. These properties are then corroborated through a series of evaluations. ",
    "url": "https://arxiv.org/abs/2305.16793",
    "authors": [
      "Xikun Jiang",
      "Chenhao Ying",
      "Lei Li",
      "Haiqin Wu",
      "Yuan Luo",
      "Boris D\u00fcdder"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.16797",
    "title": "Calibration of Transformer-based Models for Identifying Stress and  Depression in Social Media",
    "abstract": "In today's fast-paced world, the rates of stress and depression present a surge. Social media provide assistance for the early detection of mental health conditions. Existing methods mainly introduce feature extraction approaches and train shallow machine learning classifiers. Other researches use deep neural networks or transformers. Despite the fact that transformer-based models achieve noticeable improvements, they cannot often capture rich factual knowledge. Although there have been proposed a number of studies aiming to enhance the pretrained transformer-based models with extra information or additional modalities, no prior work has exploited these modifications for detecting stress and depression through social media. In addition, although the reliability of a machine learning model's confidence in its predictions is critical for high-risk applications, there is no prior work taken into consideration the model calibration. To resolve the above issues, we present the first study in the task of depression and stress detection in social media, which injects extra linguistic information in transformer-based models, namely BERT and MentalBERT. Specifically, the proposed approach employs a Multimodal Adaptation Gate for creating the combined embeddings, which are given as input to a BERT (or MentalBERT) model. For taking into account the model calibration, we apply label smoothing. We test our proposed approaches in three publicly available datasets and demonstrate that the integration of linguistic features into transformer-based models presents a surge in the performance. Also, the usage of label smoothing contributes to both the improvement of the model's performance and the calibration of the model. We finally perform a linguistic analysis of the posts and show differences in language between stressful and non-stressful texts, as well as depressive and non-depressive posts. ",
    "url": "https://arxiv.org/abs/2305.16797",
    "authors": [
      "Loukas Ilias",
      "Spiros Mouzakitis",
      "Dimitris Askounis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.16800",
    "title": "Joint Optimization of Triangle Mesh, Material, and Light from Neural  Fields with Neural Radiance Cache",
    "abstract": "Traditional inverse rendering techniques are based on textured meshes, which naturally adapts to modern graphics pipelines, but costly differentiable multi-bounce Monte Carlo (MC) ray tracing poses challenges for modeling global illumination. Recently, neural fields has demonstrated impressive reconstruction quality but falls short in modeling indirect illumination. In this paper, we introduce a simple yet efficient inverse rendering framework that combines the strengths of both methods. Specifically, given pre-trained neural field representing the scene, we can obtain an initial estimate of the signed distance field (SDF) and create a Neural Radiance Cache (NRC), an enhancement over the traditional radiance cache used in real-time rendering. By using the former to initialize differentiable marching tetrahedrons (DMTet) and the latter to model indirect illumination, we can compute the global illumination via single-bounce differentiable MC ray tracing and jointly optimize the geometry, material, and light through back propagation. Experiments demonstrate that, compared to previous methods, our approach effectively prevents indirect illumination effects from being baked into materials, thus obtaining the high-quality reconstruction of triangle mesh, Physically-Based (PBR) materials, and High Dynamic Range (HDR) light probe. ",
    "url": "https://arxiv.org/abs/2305.16800",
    "authors": [
      "Jiakai Sun",
      "Zhanjie Zhang",
      "Tianyi Chu",
      "Guangyuan Li",
      "Lei Zhao",
      "Wei Xing"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2305.16815",
    "title": "Sublinear-Space Streaming Algorithms for Estimating Graph Parameters on  Sparse Graphs",
    "abstract": "In this paper, we design sub-linear space streaming algorithms for estimating three fundamental parameters -- maximum independent set, minimum dominating set and maximum matching -- on sparse graph classes, i.e., graphs which satisfy $m=O(n)$ where $m,n$ is the number of edges, vertices respectively. Each of the three graph parameters we consider can have size $\\Omega(n)$ even on sparse graph classes, and hence for sublinear-space algorithms we are restricted to parameter estimation instead of attempting to find a solution. ",
    "url": "https://arxiv.org/abs/2305.16815",
    "authors": [
      "Xiuge Chen",
      "Rajesh Chitnis",
      "Patrick Eades",
      "Anthony Wirth"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2305.16816",
    "title": "Songs Across Borders: Singable and Controllable Neural Lyric Translation",
    "abstract": "The development of general-domain neural machine translation (NMT) methods has advanced significantly in recent years, but the lack of naturalness and musical constraints in the outputs makes them unable to produce singable lyric translations. This paper bridges the singability quality gap by formalizing lyric translation into a constrained translation problem, converting theoretical guidance and practical techniques from translatology literature to prompt-driven NMT approaches, exploring better adaptation methods, and instantiating them to an English-Chinese lyric translation system. Our model achieves 99.85%, 99.00%, and 95.52% on length accuracy, rhyme accuracy, and word boundary recall. In our subjective evaluation, our model shows a 75% relative enhancement on overall quality, compared against naive fine-tuning (Code available at https://github.com/Sonata165/ControllableLyricTranslation). ",
    "url": "https://arxiv.org/abs/2305.16816",
    "authors": [
      "Longshen Ou",
      "Xichu Ma",
      "Min-Yen Kan",
      "Ye Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.16829",
    "title": "BEV-IO: Enhancing Bird's-Eye-View 3D Detection with Instance Occupancy",
    "abstract": "A popular approach for constructing bird's-eye-view (BEV) representation in 3D detection is to lift 2D image features onto the viewing frustum space based on explicitly predicted depth distribution. However, depth distribution can only characterize the 3D geometry of visible object surfaces but fails to capture their internal space and overall geometric structure, leading to sparse and unsatisfactory 3D representations. To mitigate this issue, we present BEV-IO, a new 3D detection paradigm to enhance BEV representation with instance occupancy information. At the core of our method is the newly-designed instance occupancy prediction (IOP) module, which aims to infer point-level occupancy status for each instance in the frustum space. To ensure training efficiency while maintaining representational flexibility, it is trained using the combination of both explicit and implicit supervision. With the predicted occupancy, we further design a geometry-aware feature propagation mechanism (GFP), which performs self-attention based on occupancy distribution along each ray in frustum and is able to enforce instance-level feature consistency. By integrating the IOP module with GFP mechanism, our BEV-IO detector is able to render highly informative 3D scene structures with more comprehensive BEV representations. Experimental results demonstrate that BEV-IO can outperform state-of-the-art methods while only adding a negligible increase in parameters (0.2%) and computational overhead (0.24%in GFLOPs). ",
    "url": "https://arxiv.org/abs/2305.16829",
    "authors": [
      "Zaibin Zhang",
      "Lijun Wang",
      "Yifan Wang",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16834",
    "title": "Free Lunch: Robust Cross-Lingual Transfer via Model Checkpoint Averaging",
    "abstract": "Massively multilingual language models have displayed strong performance in zero-shot (ZS-XLT) and few-shot (FS-XLT) cross-lingual transfer setups, where models fine-tuned on task data in a source language are transferred without any or with only a few annotated instances to the target language(s). However, current work typically overestimates model performance as fine-tuned models are frequently evaluated at model checkpoints that generalize best to validation instances in the target languages. This effectively violates the main assumptions of \"true\" ZS-XLT and FS-XLT. Such XLT setups require robust methods that do not depend on labeled target language data for validation and model selection. In this work, aiming to improve the robustness of \"true\" ZS-XLT and FS-XLT, we propose a simple and effective method that averages different checkpoints (i.e., model snapshots) during task fine-tuning. We conduct exhaustive ZS-XLT and FS-XLT experiments across higher-level semantic tasks (NLI, extractive QA) and lower-level token classification tasks (NER, POS). The results indicate that averaging model checkpoints yields systematic and consistent performance gains across diverse target languages in all tasks. Importantly, it simultaneously substantially desensitizes XLT to varying hyperparameter choices in the absence of target language validation. We also show that checkpoint averaging benefits performance when further combined with run averaging (i.e., averaging the parameters of models fine-tuned over independent runs). ",
    "url": "https://arxiv.org/abs/2305.16834",
    "authors": [
      "Fabian David Schmidt",
      "Ivan Vuli\u0107",
      "Goran Glava\u0161"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.16846",
    "title": "Lagrangian Flow Networks for Conservation Laws",
    "abstract": "We introduce Lagrangian Flow Networks (LFlows) for modeling fluid densities and velocities continuously in space and time. The proposed LFlows satisfy by construction the continuity equation, a PDE describing mass conservation in its differentiable form. Our model is based on the insight that solutions to the continuity equation can be expressed as time-dependent density transformations via differentiable and invertible maps. This follows from classical theory of existence and uniqueness of Lagrangian flows for smooth vector fields. Hence, we model fluid densities by transforming a base density with parameterized diffeomorphisms conditioned on time. The key benefit compared to methods relying on Neural-ODE or PINNs is that the analytic expression of the velocity is always consistent with the density. Furthermore, there is no need for expensive numerical solvers, nor for enforcing the PDE with penalty methods. Lagrangian Flow Networks show improved predictive accuracy on synthetic density modeling tasks compared to competing models in both 2D and 3D. We conclude with a real-world application of modeling bird migration based on sparse weather radar measurements. ",
    "url": "https://arxiv.org/abs/2305.16846",
    "authors": [
      "F. Arend Torres",
      "Marcello Massimo Negri",
      "Marco Inversi",
      "Jonathan Aellen",
      "Volker Roth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.16870",
    "title": "Non-Elitist Evolutionary Multi-Objective Optimisation:  Proof-of-Principle Results",
    "abstract": "Elitism, which constructs the new population by preserving best solutions out of the old population and newly-generated solutions, has been a default way for population update since its introduction into multi-objective evolutionary algorithms (MOEAs) in the late 1990s. In this paper, we take an opposite perspective to conduct the population update in MOEAs by simply discarding elitism. That is, we treat the newly-generated solutions as the new population directly (so that all selection pressure comes from mating selection). We propose a simple non-elitist MOEA (called NE-MOEA) that only uses Pareto dominance sorting to compare solutions, without involving any diversity-related selection criterion. Preliminary experimental results show that NE-MOEA can compete with well-known elitist MOEAs (NSGA-II, SMS-EMOA and NSGA-III) on several combinatorial problems. Lastly, we discuss limitations of the proposed non-elitist algorithm and suggest possible future research directions. ",
    "url": "https://arxiv.org/abs/2305.16870",
    "authors": [
      "Zimin Liang",
      "Miqing Li",
      "Per Kristian Lehre"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.16882",
    "title": "Link Residual Closeness of Harary Graphs",
    "abstract": "The study of networks characteristics is an important subject in different fields, like math, chemistry, transportation, social network analysis etc. The residual closeness is one of the most sensitive measure of graphs vulnerability. In this article we calculate the link residual closeness of Harary graphs. ",
    "url": "https://arxiv.org/abs/2305.16882",
    "authors": [
      "Ch. Dangalchev"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2305.16886",
    "title": "Peeking inside Sparse Neural Networks using Multi-Partite Graph  Representations",
    "abstract": "Modern Deep Neural Networks (DNNs) have achieved very high performance at the expense of computational resources. To decrease the computational burden, several techniques have proposed to extract, from a given DNN, efficient subnetworks which are able to preserve performance while reducing the number of network parameters. The literature provides a broad set of techniques to discover such subnetworks, but few works have studied the peculiar topologies of such pruned architectures. In this paper, we propose a novel \\emph{unrolled input-aware} bipartite Graph Encoding (GE) that is able to generate, for each layer in an either sparse or dense neural network, its corresponding graph representation based on its relation with the input data. We also extend it into a multipartite GE, to capture the relation between layers. Then, we leverage on topological properties to study the difference between the existing pruning algorithms and algorithm categories, as well as the relation between topologies and performance. ",
    "url": "https://arxiv.org/abs/2305.16886",
    "authors": [
      "Elia Cunegatti",
      "Doina Bucur",
      "Giovanni Iacca"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16891",
    "title": "Generalization Guarantees of Gradient Descent for Multi-Layer Neural  Networks",
    "abstract": "Recently, significant progress has been made in understanding the generalization of neural networks (NNs) trained by gradient descent (GD) using the algorithmic stability approach. However, most of the existing research has focused on one-hidden-layer NNs and has not addressed the impact of different network scaling parameters. In this paper, we greatly extend the previous work \\cite{lei2022stability,richards2021stability} by conducting a comprehensive stability and generalization analysis of GD for multi-layer NNs. For two-layer NNs, our results are established under general network scaling parameters, relaxing previous conditions. In the case of three-layer NNs, our technical contribution lies in demonstrating its nearly co-coercive property by utilizing a novel induction strategy that thoroughly explores the effects of over-parameterization. As a direct application of our general findings, we derive the excess risk rate of $O(1/\\sqrt{n})$ for GD algorithms in both two-layer and three-layer NNs. This sheds light on sufficient or necessary conditions for under-parameterized and over-parameterized NNs trained by GD to attain the desired risk rate of $O(1/\\sqrt{n})$. Moreover, we demonstrate that as the scaling parameter increases or the network complexity decreases, less over-parameterization is required for GD to achieve the desired error rates. Additionally, under a low-noise condition, we obtain a fast risk rate of $O(1/n)$ for GD in both two-layer and three-layer NNs. ",
    "url": "https://arxiv.org/abs/2305.16891",
    "authors": [
      "Puyu Wang",
      "Yunwen Lei",
      "Di Wang",
      "Yiming Ying",
      "Ding-Xuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.16894",
    "title": "Robustness of Multi-Source MT to Transcription Errors",
    "abstract": "Automatic speech translation is sensitive to speech recognition errors, but in a multilingual scenario, the same content may be available in various languages via simultaneous interpreting, dubbing or subtitling. In this paper, we hypothesize that leveraging multiple sources will improve translation quality if the sources complement one another in terms of correct information they contain. To this end, we first show that on a 10-hour ESIC corpus, the ASR errors in the original English speech and its simultaneous interpreting into German and Czech are mutually independent. We then use two sources, English and German, in a multi-source setting for translation into Czech to establish its robustness to ASR errors. Furthermore, we observe this robustness when translating both noisy sources together in a simultaneous translation setting. Our results show that multi-source neural machine translation has the potential to be useful in a real-time simultaneous translation setting, thereby motivating further investigation in this area. ",
    "url": "https://arxiv.org/abs/2305.16894",
    "authors": [
      "Dominik Mach\u00e1\u010dek",
      "Peter Pol\u00e1k",
      "Ond\u0159ej Bojar",
      "Raj Dabre"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.16907",
    "title": "CyPhERS: A Cyber-Physical Event Reasoning System providing real-time  situational awareness for attack and fault response",
    "abstract": "Cyber-physical systems (CPSs) constitute the backbone of critical infrastructures such as power grids or water distribution networks. Operating failures in these systems can cause serious risks for society. To avoid or minimize downtime, operators require real-time awareness about critical incidents. However, online event identification in CPSs is challenged by the complex interdependency of numerous physical and digital components, requiring to take cyber attacks and physical failures equally into account. The online event identification problem is further complicated through the lack of historical observations of critical but rare events, and the continuous evolution of cyber attack strategies. This work introduces and demonstrates CyPhERS, a Cyber-Physical Event Reasoning System. CyPhERS provides real-time information pertaining the occurrence, location, physical impact, and root cause of potentially critical events in CPSs, without the need for historical event observations. Key novelty of CyPhERS is the capability to generate informative and interpretable event signatures of known and unknown types of both cyber attacks and physical failures. The concept is evaluated and benchmarked on a demonstration case that comprises a multitude of attack and fault events targeting various components of a CPS. The results demonstrate that the event signatures provide relevant and inferable information on both known and unknown event types. ",
    "url": "https://arxiv.org/abs/2305.16907",
    "authors": [
      "Nils M\u00fcller",
      "Kaibin Bao",
      "J\u00f6rg Matthes",
      "Kai Heussen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.16912",
    "title": "Disambiguated Attention Embedding for Multi-Instance Partial-Label  Learning",
    "abstract": "In many real-world tasks, the concerned objects can be represented as a multi-instance bag associated with a candidate label set, which consists of one ground-truth label and several false positive labels. Multi-instance partial-label learning (MIPL) is a learning paradigm to deal with such tasks and has achieved favorable performances. Existing MIPL approach follows the instance-space paradigm by assigning augmented candidate label sets of bags to each instance and aggregating bag-level labels from instance-level labels. However, this scheme may be suboptimal as global bag-level information is ignored and the predicted labels of bags are sensitive to predictions of negative instances. In this paper, we study an alternative scheme where a multi-instance bag is embedded into a single vector representation. Accordingly, an intuitive algorithm named DEMIPL, i.e., Disambiguated attention Embedding for Multi-Instance Partial-Label learning, is proposed. DEMIPL employs a disambiguation attention mechanism to aggregate a multi-instance bag into a single vector representation, followed by a momentum-based disambiguation strategy to identify the ground-truth label from the candidate label set. Furthermore, we introduce a real-world MIPL dataset for colorectal cancer classification. Experimental results on benchmark and real-world datasets validate the superiority of DEMIPL against other well-established MIPL and partial-label learning methods. Our code and datasets will be made publicly available. ",
    "url": "https://arxiv.org/abs/2305.16912",
    "authors": [
      "Wei Tang",
      "Weijia Zhang",
      "Min-Ling Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16932",
    "title": "A Neural State-Space Model Approach to Efficient Speech Separation",
    "abstract": "In this work, we introduce S4M, a new efficient speech separation framework based on neural state-space models (SSM). Motivated by linear time-invariant systems for sequence modeling, our SSM-based approach can efficiently model input signals into a format of linear ordinary differential equations (ODEs) for representation learning. To extend the SSM technique into speech separation tasks, we first decompose the input mixture into multi-scale representations with different resolutions. This mechanism enables S4M to learn globally coherent separation and reconstruction. The experimental results show that S4M performs comparably to other separation backbones in terms of SI-SDRi, while having a much lower model complexity with significantly fewer trainable parameters. In addition, our S4M-tiny model (1.8M parameters) even surpasses attention-based Sepformer (26.0M parameters) in noisy conditions with only 9.2 of multiply-accumulate operation (MACs). ",
    "url": "https://arxiv.org/abs/2305.16932",
    "authors": [
      "Chen Chen",
      "Chao-Han Huck Yang",
      "Kai Li",
      "Yuchen Hu",
      "Pin-Jui Ku",
      "Eng Siong Chng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.16934",
    "title": "On Evaluating Adversarial Robustness of Large Vision-Language Models",
    "abstract": "Large vision-language models (VLMs) such as GPT-4 have achieved unprecedented performance in response generation, especially with visual inputs, enabling more creative and adaptable interaction than large language models such as ChatGPT. Nonetheless, multimodal generation exacerbates safety concerns, since adversaries may successfully evade the entire system by subtly manipulating the most vulnerable modality (e.g., vision). To this end, we propose evaluating the robustness of open-source large VLMs in the most realistic and high-risk setting, where adversaries have only black-box system access and seek to deceive the model into returning the targeted responses. In particular, we first craft targeted adversarial examples against pretrained models such as CLIP and BLIP, and then transfer these adversarial examples to other VLMs such as MiniGPT-4, LLaVA, UniDiffuser, BLIP-2, and Img2Prompt. In addition, we observe that black-box queries on these VLMs can further improve the effectiveness of targeted evasion, resulting in a surprisingly high success rate for generating targeted responses. Our findings provide a quantitative understanding regarding the adversarial vulnerability of large VLMs and call for a more thorough examination of their potential security flaws before deployment in practice. Code is at https://github.com/yunqing-me/AttackVLM. ",
    "url": "https://arxiv.org/abs/2305.16934",
    "authors": [
      "Yunqing Zhao",
      "Tianyu Pang",
      "Chao Du",
      "Xiao Yang",
      "Chongxuan Li",
      "Ngai-Man Cheung",
      "Min Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2305.16936",
    "title": "CRoSS: Diffusion Model Makes Controllable, Robust and Secure Image  Steganography",
    "abstract": "Current image steganography techniques are mainly focused on cover-based methods, which commonly have the risk of leaking secret images and poor robustness against degraded container images. Inspired by recent developments in diffusion models, we discovered that two properties of diffusion models, the ability to achieve translation between two images without training, and robustness to noisy data, can be used to improve security and natural robustness in image steganography tasks. For the choice of diffusion model, we selected Stable Diffusion, a type of conditional diffusion model, and fully utilized the latest tools from open-source communities, such as LoRAs and ControlNets, to improve the controllability and diversity of container images. In summary, we propose a novel image steganography framework, named Controllable, Robust and Secure Image Steganography (CRoSS), which has significant advantages in controllability, robustness, and security compared to cover-based image steganography methods. These benefits are obtained without additional training. To our knowledge, this is the first work to introduce diffusion models to the field of image steganography. In the experimental section, we conducted detailed experiments to demonstrate the advantages of our proposed CRoSS framework in controllability, robustness, and security. ",
    "url": "https://arxiv.org/abs/2305.16936",
    "authors": [
      "Jiwen Yu",
      "Xuanyu Zhang",
      "Youmin Xu",
      "Jian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16943",
    "title": "DiffusionNAG: Task-guided Neural Architecture Generation with Diffusion  Models",
    "abstract": "Neural Architecture Search (NAS) has emerged as a powerful technique for automating neural architecture design. However, existing NAS methods either require an excessive amount of time for repetitive training or sampling of many task-irrelevant architectures. Moreover, they lack generalization across different tasks and usually require searching for optimal architectures for each task from scratch without reusing the knowledge from the previous NAS tasks. To tackle such limitations of existing NAS methods, we propose a novel transferable task-guided Neural Architecture Generation (NAG) framework based on diffusion models, dubbed DiffusionNAG. With the guidance of a surrogate model, such as a performance predictor for a given task, our DiffusionNAG can generate task-optimal architectures for diverse tasks, including unseen tasks. DiffusionNAG is highly efficient as it generates task-optimal neural architectures by leveraging the prior knowledge obtained from the previous tasks and neural architecture distribution. Furthermore, we introduce a score network to ensure the generation of valid architectures represented as directed acyclic graphs, unlike existing graph generative models that focus on generating undirected graphs. Extensive experiments demonstrate that DiffusionNAG significantly outperforms the state-of-the-art transferable NAG model in architecture generation quality, as well as previous NAS methods on four computer vision datasets with largely reduced computational cost. ",
    "url": "https://arxiv.org/abs/2305.16943",
    "authors": [
      "Sohyun An",
      "Hayeon Lee",
      "Jaehyeong Jo",
      "Seanie Lee",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16947",
    "title": "Sentence-Incremental Neural Coreference Resolution",
    "abstract": "We propose a sentence-incremental neural coreference resolution system which incrementally builds clusters after marking mention boundaries in a shift-reduce method. The system is aimed at bridging two recent approaches at coreference resolution: (1) state-of-the-art non-incremental models that incur quadratic complexity in document length with high computational cost, and (2) memory network-based models which operate incrementally but do not generalize beyond pronouns. For comparison, we simulate an incremental setting by constraining non-incremental systems to form partial coreference chains before observing new sentences. In this setting, our system outperforms comparable state-of-the-art methods by 2 F1 on OntoNotes and 7 F1 on the CODI-CRAC 2021 corpus. In a conventional coreference setup, our system achieves 76.3 F1 on OntoNotes and 45.8 F1 on CODI-CRAC 2021, which is comparable to state-of-the-art baselines. We also analyze variations of our system and show that the degree of incrementality in the encoder has a surprisingly large effect on the resulting performance. ",
    "url": "https://arxiv.org/abs/2305.16947",
    "authors": [
      "Matt Grenander",
      "Shay B. Cohen",
      "Mark Steedman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.16962",
    "title": "A Location-based and Hierarchical Framework for Fast Consensus in  Blockchain Networks",
    "abstract": "Blockchain-based IoT systems can manage IoT devices and achieve a high level of data integrity, security, and provenance. However, incorporating the existing consensus protocols in many IoT systems limits scalability and leads to high computational cost and network latency. We propose a hierar-chical and location-aware consensus protocol for IoI-blockchain applications inspired by the original Raft protocol to address these limitations. The proposed consensus protocol generates the consensus candidate groups based on nodes' individual reputation and distance information to elect the leader in each sub-layer blockchain and uses our threshold signature scheme to reach global consensus. Experimental results show that the proposed consensus protocol is scalable for large IoT applications and significantly reduces the communication cost, network latency, and agreement time by more than 50% compared with the Raft protocol for consensus processing. ",
    "url": "https://arxiv.org/abs/2305.16962",
    "authors": [
      "Hao Guo",
      "Wanxin Li",
      "Mark Nejad"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2305.16966",
    "title": "Hybrid Energy Based Model in the Feature Space for Out-of-Distribution  Detection",
    "abstract": "Out-of-distribution (OOD) detection is a critical requirement for the deployment of deep neural networks. This paper introduces the HEAT model, a new post-hoc OOD detection method estimating the density of in-distribution (ID) samples using hybrid energy-based models (EBM) in the feature space of a pre-trained backbone. HEAT complements prior density estimators of the ID density, e.g. parametric models like the Gaussian Mixture Model (GMM), to provide an accurate yet robust density estimation. A second contribution is to leverage the EBM framework to provide a unified density estimation and to compose several energy terms. Extensive experiments demonstrate the significance of the two contributions. HEAT sets new state-of-the-art OOD detection results on the CIFAR-10 / CIFAR-100 benchmark as well as on the large-scale Imagenet benchmark. The code is available at: https://github.com/MarcLafon/heat_ood. ",
    "url": "https://arxiv.org/abs/2305.16966",
    "authors": [
      "Marc Lafon",
      "Elias Ramzi",
      "Cl\u00e9ment Rambour",
      "Nicolas Thome"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16967",
    "title": "Evaluating Open-Domain Dialogues in Latent Space with Next Sentence  Prediction and Mutual Information",
    "abstract": "The long-standing one-to-many issue of the open-domain dialogues poses significant challenges for automatic evaluation methods, i.e., there may be multiple suitable responses which differ in semantics for a given a conversational context. To tackle this challenge, we propose a novel learning-based automatic evaluation metric (CMN), which can robustly evaluate open-domain dialogues by augmenting Conditional Variational Autoencoders (CVAEs) with a Next Sentence Prediction (NSP) objective and employing Mutual Information (MI) to model the semantic similarity of text in the latent space. Experimental results on two open-domain dialogue datasets demonstrate the superiority of our method compared with a wide range of baselines, especially in handling responses which are distant to the golden reference responses in semantics. ",
    "url": "https://arxiv.org/abs/2305.16967",
    "authors": [
      "Kun Zhao",
      "Bohao Yang",
      "Chenghua Lin",
      "Wenge Rong",
      "Aline Villavicencio",
      "Xiaohui Cui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.16968",
    "title": "Linear Object Detection in Document Images using Multiple Object  Tracking",
    "abstract": "Linear objects convey substantial information about document structure, but are challenging to detect accurately because of degradation (curved, erased) or decoration (doubled, dashed). Many approaches can recover some vector representation, but only one closed-source technique introduced in 1994, based on Kalman filters (a particular case of Multiple Object Tracking algorithm), can perform a pixel-accurate instance segmentation of linear objects and enable to selectively remove them from the original image. We aim at re-popularizing this approach and propose: 1. a framework for accurate instance segmentation of linear objects in document images using Multiple Object Tracking (MOT); 2. document image datasets and metrics which enable both vector- and pixel-based evaluation of linear object detection; 3. performance measures of MOT approaches against modern segment detectors; 4. performance measures of various tracking strategies, exhibiting alternatives to the original Kalman filters approach; and 5. an open-source implementation of a detector which can discriminate instances of curved, erased, dashed, intersecting and/or overlapping linear objects. ",
    "url": "https://arxiv.org/abs/2305.16968",
    "authors": [
      "Philippe Bernet",
      "Joseph Chazalon",
      "Edwin Carlinet",
      "Alexandre Bourquelot",
      "Elodie Puybareau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16980",
    "title": "Spawning Nodes Generate Deterministic Scale-Free Networks",
    "abstract": "In this paper we present a deterministic vertex spawning model that yields a scale-free network. The model specifies that a parent vertex produces a child vertex in a time interval approximately proportional to the current time and inversely proportional to the number of edges currently connected to the parent. Spawned offspring maintain an undirected edge with its parent. No information about the network as a whole is required to obtain scale-invariant behavior. Although the algorithm is deterministic, the number of nodes spawning in a small time interval quickly becomes randomized. We show theoretically and with simulations that such a spawned network will have a degree distribution obeying a power law with exponent 2.5. Simulations show that the distribution matches a Zipf distribution. ",
    "url": "https://arxiv.org/abs/2305.16980",
    "authors": [
      "Peter R. Conwell",
      "Kaushik Chakram",
      "Valeria J. Villegas-Medina"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2305.16988",
    "title": "Sharp Bounds for Generalized Causal Sensitivity Analysis",
    "abstract": "Causal inference from observational data is crucial for many disciplines such as medicine and economics. However, sharp bounds for causal effects under relaxations of the unconfoundedness assumption (causal sensitivity analysis) are subject to ongoing research. So far, works with sharp bounds are restricted to fairly simple settings (e.g., a single binary treatment). In this paper, we propose a unified framework for causal sensitivity analysis under unobserved confounding in various settings. For this, we propose a flexible generalization of the marginal sensitivity model (MSM) and then derive sharp bounds for a large class of causal effects. This includes (conditional) average treatment effects, effects for mediation analysis and path analysis, and distributional effects. Furthermore, our sensitivity model is applicable to discrete, continuous, and time-varying treatments. It allows us to interpret the partial identification problem under unobserved confounding as a distribution shift in the latent confounders while evaluating the causal effect of interest. In the special case of a single binary treatment, our bounds for (conditional) average treatment effects coincide with recent optimality results for causal sensitivity analysis. Finally, we propose a scalable algorithm to estimate our sharp bounds from observational data. ",
    "url": "https://arxiv.org/abs/2305.16988",
    "authors": [
      "Dennis Frauen",
      "Valentyn Melnychuk",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16998",
    "title": "A Tale of Two Approximations: Tightening Over-Approximation for DNN  Robustness Verification via Under-Approximation",
    "abstract": "The robustness of deep neural networks (DNNs) is crucial to the hosting system's reliability and security. Formal verification has been demonstrated to be effective in providing provable robustness guarantees. To improve its scalability, over-approximating the non-linear activation functions in DNNs by linear constraints has been widely adopted, which transforms the verification problem into an efficiently solvable linear programming problem. Many efforts have been dedicated to defining the so-called tightest approximations to reduce overestimation imposed by over-approximation. In this paper, we study existing approaches and identify a dominant factor in defining tight approximation, namely the approximation domain of the activation function. We find out that tight approximations defined on approximation domains may not be as tight as the ones on their actual domains, yet existing approaches all rely only on approximation domains. Based on this observation, we propose a novel dual-approximation approach to tighten over-approximations, leveraging an activation function's underestimated domain to define tight approximation bounds. We implement our approach with two complementary algorithms based respectively on Monte Carlo simulation and gradient descent into a tool called DualApp. We assess it on a comprehensive benchmark of DNNs with different architectures. Our experimental results show that DualApp significantly outperforms the state-of-the-art approaches with 100% - 1000% improvement on the verified robustness ratio and 10.64% on average (up to 66.53%) on the certified lower bound. ",
    "url": "https://arxiv.org/abs/2305.16998",
    "authors": [
      "Zhiyi Xue",
      "Si Liu",
      "Zhaodi Zhang",
      "Yiting Wu",
      "Min Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.17000",
    "title": "Leveraging characteristics of the output probability distribution for  identifying adversarial audio examples",
    "abstract": "Adversarial attacks represent a security threat to machine learning based automatic speech recognition (ASR) systems. To prevent such attacks we propose an adversarial example detection strategy applicable to any ASR system that predicts a probability distribution over output tokens in each time step. We measure a set of characteristics of this distribution: the median, maximum, and minimum over the output probabilities, the entropy, and the Jensen-Shannon divergence of the distributions of subsequent time steps. Then, we fit a Gaussian distribution to the characteristics observed for benign data. By computing the likelihood of incoming new audio we can distinguish malicious inputs from samples from clean data with an area under the receiving operator characteristic (AUROC) higher than 0.99, which drops to 0.98 for less-quality audio. To assess the robustness of our method we build adaptive attacks. This reduces the AUROC to 0.96 but results in more noisy adversarial clips. ",
    "url": "https://arxiv.org/abs/2305.17000",
    "authors": [
      "Mat\u00edas P. Pizarro B.",
      "Dorothea Kolossa",
      "Asja Fischer"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.17008",
    "title": "NormBank: A Knowledge Bank of Situational Social Norms",
    "abstract": "We present NormBank, a knowledge bank of 155k situational norms. This resource is designed to ground flexible normative reasoning for interactive, assistive, and collaborative AI systems. Unlike prior commonsense resources, NormBank grounds each inference within a multivalent sociocultural frame, which includes the setting (e.g., restaurant), the agents' contingent roles (waiter, customer), their attributes (age, gender), and other physical, social, and cultural constraints (e.g., the temperature or the country of operation). In total, NormBank contains 63k unique constraints from a taxonomy that we introduce and iteratively refine here. Constraints then apply in different combinations to frame social norms. Under these manipulations, norms are non-monotonic - one can cancel an inference by updating its frame even slightly. Still, we find evidence that neural models can help reliably extend the scope and coverage of NormBank. We further demonstrate the utility of this resource with a series of transfer experiments. ",
    "url": "https://arxiv.org/abs/2305.17008",
    "authors": [
      "Caleb Ziems",
      "Jane Dwivedi-Yu",
      "Yi-Chia Wang",
      "Alon Halevy",
      "Diyi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17010",
    "title": "Let the Flows Tell: Solving Graph Combinatorial Optimization Problems  with GFlowNets",
    "abstract": "Combinatorial optimization (CO) problems are often NP-hard and thus out of reach for exact algorithms, making them a tempting domain to apply machine learning methods. The highly structured constraints in these problems can hinder either optimization or sampling directly in the solution space. On the other hand, GFlowNets have recently emerged as a powerful machinery to efficiently sample from composite unnormalized densities sequentially and have the potential to amortize such solution-searching processes in CO, as well as generate diverse solution candidates. In this paper, we design Markov decision processes (MDPs) for different combinatorial problems and propose to train conditional GFlowNets to sample from the solution space. Efficient training techniques are also developed to benefit long-range credit assignment. Through extensive experiments on a variety of different CO tasks with synthetic and realistic data, we demonstrate that GFlowNet policies can efficiently find high-quality solutions. ",
    "url": "https://arxiv.org/abs/2305.17010",
    "authors": [
      "Dinghuai Zhang",
      "Hanjun Dai",
      "Nikolay Malkin",
      "Aaron Courville",
      "Yoshua Bengio",
      "Ling Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.17019",
    "title": "Commonsense Knowledge Graph Completion Via Contrastive Pretraining and  Node Clustering",
    "abstract": "The nodes in the commonsense knowledge graph (CSKG) are normally represented by free-form short text (e.g., word or phrase). Different nodes may represent the same concept. This leads to the problems of edge sparsity and node redundancy, which challenges CSKG representation and completion. On the one hand, edge sparsity limits the performance of graph representation learning; On the other hand, node redundancy makes different nodes corresponding to the same concept have inconsistent relations with other nodes. To address the two problems, we propose a new CSKG completion framework based on Contrastive Pretraining and Node Clustering (CPNC). Contrastive Pretraining constructs positive and negative head-tail node pairs on CSKG and utilizes contrastive learning to obtain better semantic node representation. Node Clustering aggregates nodes with the same concept into a latent concept, assisting the task of CSKG completion. We evaluate our CPNC approach on two CSKG completion benchmarks (CN-100K and ATOMIC), where CPNC outperforms the state-of-the-art methods. Extensive experiments demonstrate that both Contrastive Pretraining and Node Clustering can significantly improve the performance of CSKG completion. The source code of CPNC is publicly available on \\url{https://github.com/NUSTM/CPNC}. ",
    "url": "https://arxiv.org/abs/2305.17019",
    "authors": [
      "Siwei Wu",
      "Xiangqing Shen",
      "Rui Xia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17023",
    "title": "Are Deep Neural Networks Adequate Behavioural Models of Human Visual  Perception?",
    "abstract": "Deep neural networks (DNNs) are machine learning algorithms that have revolutionised computer vision due to their remarkable successes in tasks like object classification and segmentation. The success of DNNs as computer vision algorithms has led to the suggestion that DNNs may also be good models of human visual perception. We here review evidence regarding current DNNs as adequate behavioural models of human core object recognition. To this end, we argue that it is important to distinguish between statistical tools and computational models, and to understand model quality as a multidimensional concept where clarity about modelling goals is key. Reviewing a large number of psychophysical and computational explorations of core object recognition performance in humans and DNNs, we argue that DNNs are highly valuable scientific tools but that as of today DNNs should only be regarded as promising -- but not yet adequate -- computational models of human core object recognition behaviour. On the way we dispel a number of myths surrounding DNNs in vision science. ",
    "url": "https://arxiv.org/abs/2305.17023",
    "authors": [
      "Felix A. Wichmann",
      "Robert Geirhos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2305.17047",
    "title": "Towards More Realistic Evaluation for Neural Test Oracle Generation",
    "abstract": "Effective unit tests can help guard and improve software quality but require a substantial amount of time and effort to write and maintain. A unit test consists of a test prefix and a test oracle. Synthesizing test oracles, especially functional oracles, is a well-known challenging problem. Recent studies proposed to leverage neural models to generate test oracles, i.e., neural test oracle generation (NTOG), and obtained promising results. However, after a systematic inspection, we find there are some inappropriate settings in existing evaluation methods for NTOG. These settings could mislead the understanding of existing NTOG approaches' performance. We summarize them as 1) generating test prefixes from bug-fixed program versions, 2) evaluating with an unrealistic metric, and 3) lacking a straightforward baseline. In this paper, we first investigate the impacts of these settings on evaluating and understanding the performance of NTOG approaches. We find that 1) unrealistically generating test prefixes from bug-fixed program versions inflates the number of bugs found by the state-of-the-art NTOG approach TOGA by 61.8%, 2) FPR (False Positive Rate) is not a realistic evaluation metric and the Precision of TOGA is only 0.38%, and 3) a straightforward baseline NoException, which simply expects no exception should be raised, can find 61% of the bugs found by TOGA with twice the Precision. Furthermore, we introduce an additional ranking step to existing evaluation methods and propose an evaluation metric named Found@K to better measure the cost-effectiveness of NTOG approaches. We propose a novel unsupervised ranking method to instantiate this ranking step, significantly improving the cost-effectiveness of TOGA. Eventually, we propose a more realistic evaluation method TEval+ for NTOG and summarize seven rules of thumb to boost NTOG approaches into their practical usages. ",
    "url": "https://arxiv.org/abs/2305.17047",
    "authors": [
      "Zhongxin Liu",
      "Kui Liu",
      "Xin Xia",
      "Xiaohu Yang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2305.17048",
    "title": "SelfClean: A Self-Supervised Data Cleaning Strategy",
    "abstract": "Most commonly used benchmark datasets for computer vision contain irrelevant images, near duplicates, and label errors. Consequently, model performance on these benchmarks may not be an accurate estimate of generalization ability. This is a particularly acute concern in computer vision for medicine where datasets are typically small, stakes are high, and annotation processes are expensive and error-prone. In this paper, we propose SelfClean, a general procedure to clean up image datasets exploiting a latent space learned with self-supervision. By relying on self-supervised learning, our approach focuses on intrinsic properties of the data and avoids annotation biases. We formulate dataset cleaning as either a set of ranking problems, where human experts can make decisions with significantly reduced effort, or a set of scoring problems, where decisions can be fully automated based on score distributions. We compare SelfClean against other algorithms on common computer vision benchmarks enhanced with synthetic noise and demonstrate state-of-the-art performance on detecting irrelevant images, near duplicates, and label errors. In addition, we apply our method to multiple image datasets and confirm an improvement in evaluation reliability. ",
    "url": "https://arxiv.org/abs/2305.17048",
    "authors": [
      "Fabian Gr\u00f6ger",
      "Simone Lionetti",
      "Philippe Gottfrois",
      "Alvaro Gonzalez-Jimenez",
      "Ludovic Amruthalingam",
      "Labelling Consortium",
      "Matthew Groh",
      "Alexander A. Navarini",
      "Marc Pouly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17050",
    "title": "Exploiting Abstract Meaning Representation for Open-Domain Question  Answering",
    "abstract": "The Open-Domain Question Answering (ODQA) task involves retrieving and subsequently generating answers from fine-grained relevant passages within a database. Current systems leverage Pretrained Language Models (PLMs) to model the relationship between questions and passages. However, the diversity in surface form expressions can hinder the model's ability to capture accurate correlations, especially within complex contexts. Therefore, we utilize Abstract Meaning Representation (AMR) graphs to assist the model in understanding complex semantic information. We introduce a method known as Graph-as-Token (GST) to incorporate AMRs into PLMs. Results from Natural Questions (NQ) and TriviaQA (TQ) demonstrate that our GST method can significantly improve performance, resulting in up to 2.44/3.17 Exact Match score improvements on NQ/TQ respectively. Furthermore, our method enhances robustness and outperforms alternative Graph Neural Network (GNN) methods for integrating AMRs. To the best of our knowledge, we are the first to employ semantic graphs in ODQA. ",
    "url": "https://arxiv.org/abs/2305.17050",
    "authors": [
      "Cunxiang Wang",
      "Zhikun Xu",
      "Qipeng Guo",
      "Xiangkun Hu",
      "Xuefeng Bai",
      "Zheng Zhang",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17071",
    "title": "Adversarial Attacks on Online Learning to Rank with Click Feedback",
    "abstract": "Online learning to rank (OLTR) is a sequential decision-making problem where a learning agent selects an ordered list of items and receives feedback through user clicks. Although potential attacks against OLTR algorithms may cause serious losses in real-world applications, little is known about adversarial attacks on OLTR. This paper studies attack strategies against multiple variants of OLTR. Our first result provides an attack strategy against the UCB algorithm on classical stochastic bandits with binary feedback, which solves the key issues caused by bounded and discrete feedback that previous works can not handle. Building on this result, we design attack algorithms against UCB-based OLTR algorithms in position-based and cascade models. Finally, we propose a general attack strategy against any algorithm under the general click model. Each attack algorithm manipulates the learning agent into choosing the target attack item $T-o(T)$ times, incurring a cumulative cost of $o(T)$. Experiments on synthetic and real data further validate the effectiveness of our proposed attack algorithms. ",
    "url": "https://arxiv.org/abs/2305.17071",
    "authors": [
      "Jinhang Zuo",
      "Zhiyao Zhang",
      "Zhiyong Wang",
      "Shuai Li",
      "Mohammad Hajiesmaili",
      "Adam Wierman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2305.17076",
    "title": "Exact Generalization Guarantees for (Regularized) Wasserstein  Distributionally Robust Models",
    "abstract": "Wasserstein distributionally robust estimators have emerged as powerful models for prediction and decision-making under uncertainty. These estimators provide attractive generalization guarantees: the robust objective obtained from the training distribution is an exact upper bound on the true risk with high probability. However, existing guarantees either suffer from the curse of dimensionality, are restricted to specific settings, or lead to spurious error terms. In this paper, we show that these generalization guarantees actually hold on general classes of models, do not suffer from the curse of dimensionality, and can even cover distribution shifts at testing. We also prove that these results carry over to the newly-introduced regularized versions of Wasserstein distributionally robust problems. ",
    "url": "https://arxiv.org/abs/2305.17076",
    "authors": [
      "Wa\u00efss Azizian",
      "Franck Iutzeler",
      "J\u00e9r\u00f4me Malick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.17087",
    "title": "Communication-Efficient Reinforcement Learning in Swarm Robotic Networks  for Maze Exploration",
    "abstract": "Smooth coordination within a swarm robotic system is essential for the effective execution of collective robot missions. Having efficient communication is key to the successful coordination of swarm robots. This paper proposes a new communication-efficient decentralized cooperative reinforcement learning algorithm for coordinating swarm robots. It is made efficient by hierarchically building on the use of local information exchanges. We consider a case study application of maze solving through cooperation among a group of robots, where the time and costs are minimized while avoiding inter-robot collisions and path overlaps during exploration. With a solid theoretical basis, we extensively analyze the algorithm with realistic CORE network simulations and evaluate it against state-of-the-art solutions in terms of maze coverage percentage and efficiency under communication-degraded environments. The results demonstrate significantly higher coverage accuracy and efficiency while reducing costs and overlaps even in high packet loss and low communication range scenarios. ",
    "url": "https://arxiv.org/abs/2305.17087",
    "authors": [
      "Ehsan Latif",
      "WenZhan Song",
      "Ramviyas Parasuraman"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2305.17102",
    "title": "GeoVLN: Learning Geometry-Enhanced Visual Representation with Slot  Attention for Vision-and-Language Navigation",
    "abstract": "Most existing works solving Room-to-Room VLN problem only utilize RGB images and do not consider local context around candidate views, which lack sufficient visual cues about surrounding environment. Moreover, natural language contains complex semantic information thus its correlations with visual inputs are hard to model merely with cross attention. In this paper, we propose GeoVLN, which learns Geometry-enhanced visual representation based on slot attention for robust Visual-and-Language Navigation. The RGB images are compensated with the corresponding depth maps and normal maps predicted by Omnidata as visual inputs. Technically, we introduce a two-stage module that combine local slot attention and CLIP model to produce geometry-enhanced representation from such input. We employ V&L BERT to learn a cross-modal representation that incorporate both language and vision informations. Additionally, a novel multiway attention module is designed, encouraging different phrases of input instruction to exploit the most related features from visual input. Extensive experiments demonstrate the effectiveness of our newly designed modules and show the compelling performance of the proposed method. ",
    "url": "https://arxiv.org/abs/2305.17102",
    "authors": [
      "Jingyang Huo",
      "Qiang Sun",
      "Boyan Jiang",
      "Haitao Lin",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17105",
    "title": "Random-Access Neural Compression of Material Textures",
    "abstract": "The continuous advancement of photorealism in rendering is accompanied by a growth in texture data and, consequently, increasing storage and memory demands. To address this issue, we propose a novel neural compression technique specifically designed for material textures. We unlock two more levels of detail, i.e., 16x more texels, using low bitrate compression, with image quality that is better than advanced image compression techniques, such as AVIF and JPEG XL. At the same time, our method allows on-demand, real-time decompression with random access similar to block texture compression on GPUs, enabling compression on disk and memory. The key idea behind our approach is compressing multiple material textures and their mipmap chains together, and using a small neural network, that is optimized for each material, to decompress them. Finally, we use a custom training implementation to achieve practical compression speeds, whose performance surpasses that of general frameworks, like PyTorch, by an order of magnitude. ",
    "url": "https://arxiv.org/abs/2305.17105",
    "authors": [
      "Karthik Vaidyanathan",
      "Marco Salvi",
      "Bartlomiej Wronski",
      "Tomas Akenine-M\u00f6ller",
      "Pontus Ebelin",
      "Aaron Lefohn"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17119",
    "title": "Manifold Regularization for Memory-Efficient Training of Deep Neural  Networks",
    "abstract": "One of the prevailing trends in the machine- and deep-learning community is to gravitate towards the use of increasingly larger models in order to keep pushing the state-of-the-art performance envelope. This tendency makes access to the associated technologies more difficult for the average practitioner and runs contrary to the desire to democratize knowledge production in the field. In this paper, we propose a framework for achieving improved memory efficiency in the process of learning traditional neural networks by leveraging inductive-bias-driven network design principles and layer-wise manifold-oriented regularization objectives. Use of the framework results in improved absolute performance and empirical generalization error relative to traditional learning techniques. We provide empirical validation of the framework, including qualitative and quantitative evidence of its effectiveness on two standard image datasets, namely CIFAR-10 and CIFAR-100. The proposed framework can be seamlessly combined with existing network compression methods for further memory savings. ",
    "url": "https://arxiv.org/abs/2305.17119",
    "authors": [
      "Shadi Sartipi",
      "Edgar A. Bernal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.17134",
    "title": "NeuManifold: Neural Watertight Manifold Reconstruction with Efficient  and High-Quality Rendering Support",
    "abstract": "We present a method for generating high-quality watertight manifold meshes from multi-view input images. Existing volumetric rendering methods are robust in optimization but tend to generate noisy meshes with poor topology. Differentiable rasterization-based methods can generate high-quality meshes but are sensitive to initialization. Our method combines the benefits of both worlds; we take the geometry initialization obtained from neural volumetric fields, and further optimize the geometry as well as a compact neural texture representation with differentiable rasterizers. Through extensive experiments, we demonstrate that our method can generate accurate mesh reconstructions with faithful appearance that are comparable to previous volume rendering methods while being an order of magnitude faster in rendering. We also show that our generated mesh and neural texture reconstruction is compatible with existing graphics pipelines and enables downstream 3D applications such as simulation. Project page: https://sarahweiii.github.io/neumanifold/ ",
    "url": "https://arxiv.org/abs/2305.17134",
    "authors": [
      "Xinyue Wei",
      "Fanbo Xiang",
      "Sai Bi",
      "Anpei Chen",
      "Kalyan Sunkavalli",
      "Zexiang Xu",
      "Hao Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16325",
    "title": "Graph Neural Network Interatomic Potential Ensembles with Calibrated  Aleatoric and Epistemic Uncertainty on Energy and Forces",
    "abstract": "Inexpensive machine learning potentials are increasingly being used to speed up structural optimization and molecular dynamics simulations of materials by iteratively predicting and applying interatomic forces. In these settings, it is crucial to detect when predictions are unreliable to avoid wrong or misleading results. Here, we present a complete framework for training and recalibrating graph neural network ensemble models to produce accurate predictions of energy and forces with calibrated uncertainty estimates. The proposed method considers both epistemic and aleatoric uncertainty and the total uncertainties are recalibrated post hoc using a nonlinear scaling function to achieve good calibration on previously unseen data, without loss of predictive accuracy. The method is demonstrated and evaluated on two challenging, publicly available datasets, ANI-1x (Smith et al.) and Transition1x (Schreiner et al.), both containing diverse conformations far from equilibrium. A detailed analysis of the predictive performance and uncertainty calibration is provided. In all experiments, the proposed method achieved low prediction error and good uncertainty calibration, with predicted uncertainty correlating with expected error, on energy and forces. To the best of our knowledge, the method presented in this paper is the first to consider a complete framework for obtaining calibrated epistemic and aleatoric uncertainty predictions on both energy and forces in ML potentials. ",
    "url": "https://arxiv.org/abs/2305.16325",
    "authors": [
      "Jonas Busk",
      "Mikkel N. Schmidt",
      "Ole Winther",
      "Tejs Vegge",
      "Peter Bj\u00f8rn J\u00f8rgensen"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16354",
    "title": "On composition and decomposition operations for vector spaces, graphs  and matroids",
    "abstract": "In this paper, we study the ideas of composition and decomposition in the context of vector spaces, graphs and matroids. For vector spaces $\\V_{AB},$ treated as collection of row vectors, with specified column set $A\\uplus B,$ we define $\\V_{SP}\\lrarv \\V_{PQ}, S\\cap Q= \\emptyset, $ to be the collection of all vectors $(f_S,f_Q)$ such that $(f_S,f_P)\\in \\V_{SP}, (f_P,f_Q)\\in \\V_{PQ}$. An analogous operation $\\G_{SP}\\lrarg \\G_{PQ}\\equivd \\G_{PQ}$ can be defined in relation to graphs $\\G_{SP}, \\G_{PQ},$ on edge sets $S\\uplus P, P\\uplus Q,$ respectively in terms of an overlapping subgraph $\\G_P$ which gets deleted in the right side graph (see for instance the notion of $k-sum$ \\cite{oxley}). For matroids we define the `linking' $\\M_{SP}\\lrarm \\M_{PQ} \\equivd (\\M_{SP}\\vee \\M_{PQ})\\times (S\\uplus Q)$, denoting the contraction operation by '$\\times$'. In each case, we examine how to minimize the size of the `overlap' set $P,$ without affecting the right side entity. In the case of vector spaces, there is a polynomial time algorithm for achieving the minimum, which we present. Similar ideas work for graphs and for matroids under appropriate conditions. Next we consider the problem of decomposition. Here, in the case of vector spaces, the problem is to decompose $\\V_{SQ}$ as $\\V_{SP}\\lrarv \\V_{PQ},$ with minimum size $P.$ We give a polynomial time algorithm for this purpose. In the case of graphs and matroids we give a solution to this problem under certain restrictions. ",
    "url": "https://arxiv.org/abs/2305.16354",
    "authors": [
      "H. Narayanan"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.16368",
    "title": "Neural incomplete factorization: learning preconditioners for the  conjugate gradient method",
    "abstract": "In this paper, we develop a novel data-driven approach to accelerate solving large-scale linear equation systems encountered in scientific computing and optimization. Our method utilizes self-supervised training of a graph neural network to generate an effective preconditioner tailored to the specific problem domain. By replacing conventional hand-crafted preconditioners used with the conjugate gradient method, our approach, named neural incomplete factorization (NeuralIF), significantly speeds-up convergence and computational efficiency. At the core of our method is a novel message-passing block, inspired by sparse matrix theory, that aligns with the objective to find a sparse factorization of the matrix. We evaluate our proposed method on both a synthetic and a real-world problem arising from scientific computing. Our results demonstrate that NeuralIF consistently outperforms the most common general-purpose preconditioners, including the incomplete Cholesky method, achieving competitive performance across various metrics even outside the training data distribution. ",
    "url": "https://arxiv.org/abs/2305.16368",
    "authors": [
      "Paul H\u00e4usner",
      "Ozan \u00d6ktem",
      "Jens Sj\u00f6lund"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.16392",
    "title": "Using neural networks to model Main Belt Asteroid albedos as a function  of their proper orbital elements",
    "abstract": "Asteroid diameters are traditionally difficult to estimate. When a direct measurement of the diameter cannot be made through either occultation or direct radar observation, the most common method is to approximate the diameter from infrared observations. Once the diameter is known, a comparison with visible light observations can be used to find the visible geometric albedo of the body. One of the largest datasets of asteroid albedos comes from the NEOWISE mission, which measured asteroid albedos both in the visible and infrared. We model these albedos as a function of proper elements available from the Asteroid Families Portal using an ensemble of neural networks. We find that both the visible and infrared geometric albedos are significantly correlated with asteroid position in the belt and occur in both asteroid families and in the background belt. We find that the ensemble's prediction reduces the average error in albedo by about 37% compared to a model that simply adopts an average albedo, with no regard for the dynamical state of the body. We then use this model to predict albedos for the half million main belt asteroids with proper elements available in the Asteroid Families Portal and provide the results in a catalog. Finally, we show that several presently categorized asteroid families exist within much larger groups of asteroids of similar albedos - this may suggest that further improvements in family identification can be made. ",
    "url": "https://arxiv.org/abs/2305.16392",
    "authors": [
      "Zachary Murray"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16527",
    "title": "When can Regression-Adjusted Control Variates Help? Rare Events, Sobolev  Embedding and Minimax Optimality",
    "abstract": "This paper studies the use of a machine learning-based estimator as a control variate for mitigating the variance of Monte Carlo sampling. Specifically, we seek to uncover the key factors that influence the efficiency of control variates in reducing variance. We examine a prototype estimation problem that involves simulating the moments of a Sobolev function based on observations obtained from (random) quadrature nodes. Firstly, we establish an information-theoretic lower bound for the problem. We then study a specific quadrature rule that employs a nonparametric regression-adjusted control variate to reduce the variance of the Monte Carlo simulation. We demonstrate that this kind of quadrature rule can improve the Monte Carlo rate and achieve the minimax optimal rate under a sufficient smoothness assumption. Due to the Sobolev Embedding Theorem, the sufficient smoothness assumption eliminates the existence of rare and extreme events. Finally, we show that, in the presence of rare and extreme events, a truncated version of the Monte Carlo algorithm can achieve the minimax optimal rate while the control variate cannot improve the convergence rate. ",
    "url": "https://arxiv.org/abs/2305.16527",
    "authors": [
      "Jose Blanchet",
      "Haoxuan Chen",
      "Yiping Lu",
      "Lexing Ying"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.16540",
    "title": "A Score-Based Model for Learning Neural Wavefunctions",
    "abstract": "Quantum Monte Carlo coupled with neural network wavefunctions has shown success in computing ground states of quantum many-body systems. Existing optimization approaches compute the energy by sampling local energy from an explicit probability distribution given by the wavefunction. In this work, we provide a new optimization framework for obtaining properties of quantum many-body ground states using score-based neural networks. Our new framework does not require explicit probability distribution and performs the sampling via Langevin dynamics. Our method is based on the key observation that the local energy is directly related to scores, defined as the gradient of the logarithmic wavefunction. Inspired by the score matching and diffusion Monte Carlo methods, we derive a weighted score matching objective to guide our score-based models to converge correctly to ground states. We first evaluate our approach with experiments on quantum harmonic traps, and results show that it can accurately learn ground states of atomic systems. By implicitly modeling high-dimensional data distributions, our work paves the way toward a more efficient representation of quantum systems. ",
    "url": "https://arxiv.org/abs/2305.16540",
    "authors": [
      "Xuan Zhang",
      "Shenglong Xu",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2305.16561",
    "title": "Proper network randomization is key to assessing social balance",
    "abstract": "Studying significant network patterns, known as graphlets (or motifs), has been a popular approach to understand the underlying organizing principles of complex networks. Statistical significance is routinely assessed by comparing to null models that randomize the connections while preserving some key aspects of the data. However, in signed networks, capturing both positive (friendly) and negative (hostile) relations, the results have been controversial and also at odds with the classical theory of structural balance. We show that this is largely due to the fact that large-scale signed networks exhibit a poor correlation between the number of positive and negative ties of each node. As a solution, here we propose a null model based on the maximum entropy framework that preserves both the signed degrees and the network topology (STP randomization). With STP randomization the results change qualitatively and most social networks consistently satisfy strong structural balance, both at the level of triangles and larger graphlets. We propose a potential underlying mechanism of the observed patterns in signed social networks and outline further applications of STP randomization. ",
    "url": "https://arxiv.org/abs/2305.16561",
    "authors": [
      "Bingjie Hao",
      "Istv\u00e1n A. Kov\u00e1cs"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.16771",
    "title": "Robust Nonparametric Regression under Poisoning Attack",
    "abstract": "This paper studies robust nonparametric regression, in which an adversarial attacker can modify the values of up to $q$ samples from a training dataset of size $N$. Our initial solution is an M-estimator based on Huber loss minimization. Compared with simple kernel regression, i.e. the Nadaraya-Watson estimator, this method can significantly weaken the impact of malicious samples on the regression performance. We provide the convergence rate as well as the corresponding minimax lower bound. The result shows that, with proper bandwidth selection, $\\ell_\\infty$ error is minimax optimal. The $\\ell_2$ error is optimal if $q\\lesssim \\sqrt{N/\\ln^2 N}$, but is suboptimal with larger $q$. The reason is that this estimator is vulnerable if there are many attacked samples concentrating in a small region. To address this issue, we propose a correction method by projecting the initial estimate to the space of Lipschitz functions. The final estimate is nearly minimax optimal for arbitrary $q$, up to a $\\ln N$ factor. ",
    "url": "https://arxiv.org/abs/2305.16771",
    "authors": [
      "Puning Zhao",
      "Zhiguo Wan"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16791",
    "title": "On the Generalization Capacities of Neural Controlled Differential  Equations",
    "abstract": "We consider a supervised learning setup in which the goal is to predicts an outcome from a sample of irregularly sampled time series using Neural Controlled Differential Equations (Kidger, Morrill, et al. 2020). In our framework, the time series is a discretization of an unobserved continuous path, and the outcome depends on this path through a controlled differential equation with unknown vector field. Learning with discrete data thus induces a discretization bias, which we precisely quantify. Using theoretical results on the continuity of the flow of controlled differential equations, we show that the approximation bias is directly related to the approximation error of a Lipschitz function defining the generative model by a shallow neural network. By combining these result with recent work linking the Lipschitz constant of neural networks to their generalization capacities, we upper bound the generalization gap between the expected loss attained by the empirical risk minimizer and the expected loss of the true predictor. ",
    "url": "https://arxiv.org/abs/2305.16791",
    "authors": [
      "Linus Bleistein",
      "Agathe Guilloux"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16836",
    "title": "A Robust Probabilistic Approach to Stochastic Subspace Identification",
    "abstract": "Modal parameter estimation of operational structures is often a challenging task when confronted with unwanted distortions (outliers) in field measurements. Atypical observations present a problem to operational modal analysis (OMA) algorithms, such as stochastic subspace identification (SSI), severely biasing parameter estimates and resulting in misidentification of the system. Despite this predicament, no simple mechanism currently exists capable of dealing with such anomalies in SSI. Addressing this problem, this paper first introduces a novel probabilistic formulation of stochastic subspace identification (Prob-SSI), realised using probabilistic projections. Mathematically, the equivalence between this model and the classic algorithm is demonstrated. This fresh perspective, viewing SSI as a problem in probabilistic inference, lays the necessary mathematical foundation to enable a plethora of new, more sophisticated OMA approaches. To this end, a statistically robust SSI algorithm (robust Prob-SSI) is developed, capable of providing a principled and automatic way of handling outlying or anomalous data in the measured timeseries, such as may occur in field recordings, e.g. intermittent sensor dropout. Robust Prob-SSI is shown to outperform conventional SSI when confronted with 'corrupted' data, exhibiting improved identification performance and higher levels of confidence in the found poles when viewing consistency (stabilisation) diagrams. Similar benefits are also demonstrated on the Z24 Bridge benchmark dataset, highlighting enhanced performance on measured systems. ",
    "url": "https://arxiv.org/abs/2305.16836",
    "authors": [
      "Brandon J. O'Connell",
      "Timothy J. Rogers"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.16862",
    "title": "Neural modeling of magnetic tape recorders",
    "abstract": "The sound of magnetic recording media, such as open-reel and cassette tape recorders, is still sought after by today's sound practitioners due to the imperfections embedded in the physics of the magnetic recording process. This paper proposes a method for digitally emulating this character using neural networks. The signal chain of the proposed system consists of three main components: the hysteretic nonlinearity and filtering jointly produced by the magnetic recording process as well as the record and playback amplifiers, the fluctuating delay originating from the tape transport, and the combined additive noise component from various electromagnetic origins. In our approach, the hysteretic nonlinear block is modeled using a recurrent neural network, while the delay trajectories and the noise component are generated using separate diffusion models, which employ U-net deep convolutional neural networks. According to the conducted objective evaluation, the proposed architecture faithfully captures the character of the magnetic tape recorder. The results of this study can be used to construct virtual replicas of vintage sound recording devices with applications in music production and audio antiquing tasks. ",
    "url": "https://arxiv.org/abs/2305.16862",
    "authors": [
      "Otto Mikkonen",
      "Alec Wright",
      "Eloi Moliner",
      "Vesa V\u00e4lim\u00e4ki"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.16905",
    "title": "Laplace-Approximated Neural Additive Models: Improving Interpretability  with Bayesian Inference",
    "abstract": "Deep neural networks (DNNs) have found successful applications in many fields, but their black-box nature hinders interpretability. This is addressed by the neural additive model (NAM), in which the network is divided into additive sub-networks, thus making apparent the interaction between input features and predictions. In this paper, we approach the additive structure from a Bayesian perspective and develop a practical Laplace approximation. This enhances interpretability in three primary ways: a) It provides credible intervals for the recovered feature interactions by estimating function-space uncertainty of the sub-networks; b) it yields a tractable estimate of the marginal likelihood, which can be used to perform an implicit selection of features through an empirical Bayes procedure; and c) it can be used to rank feature pairs as candidates for second-order interactions in fine-tuned interaction models. We show empirically that our proposed Laplace-approximated NAM (LA-NAM) improves performance and interpretability on tabular regression and classification datasets and challenging real-world medical tasks. ",
    "url": "https://arxiv.org/abs/2305.16905",
    "authors": [
      "Kouroche Bouchiat",
      "Alexander Immer",
      "Hugo Y\u00e8che",
      "Gunnar R\u00e4tsch",
      "Vincent Fortuin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16910",
    "title": "Universal approximation with complex-valued deep narrow neural networks",
    "abstract": "We study the universality of complex-valued neural networks with bounded widths and arbitrary depths. Under mild assumptions, we give a full description of those activation functions $\\varrho:\\mathbb{CC}\\to \\mathbb{C}$ that have the property that their associated networks are universal, i.e., are capable of approximating continuous functions to arbitrary accuracy on compact domains. Precisely, we show that deep narrow complex-valued networks are universal if and only if their activation function is neither holomorphic, nor antiholomorphic, nor $\\mathbb{R}$-affine. This is a much larger class of functions than in the dual setting of arbitrary width and fixed depth. Unlike in the real case, the sufficient width differs significantly depending on the considered activation function. We show that a width of $2n+2m+5$ is always sufficient and that in general a width of $\\max\\{2n,2m\\}$ is necessary. We prove, however, that a width of $n+m+4$ suffices for a rich subclass of the admissible activation functions. Here, $n$ and $m$ denote the input and output dimensions of the considered networks. ",
    "url": "https://arxiv.org/abs/2305.16910",
    "authors": [
      "Paul Geuchen",
      "Thomas Jahn",
      "Hannes Matt"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.16922",
    "title": "Fast refacing of MR images with a generative neural network lowers  re-identification risk and preserves volumetric consistency",
    "abstract": "With the rise of open data, identifiability of individuals based on 3D renderings obtained from routine structural magnetic resonance imaging (MRI) scans of the head has become a growing privacy concern. To protect subject privacy, several algorithms have been developed to de-identify imaging data using blurring, defacing or refacing. Completely removing facial structures provides the best re-identification protection but can significantly impact post-processing steps, like brain morphometry. As an alternative, refacing methods that replace individual facial structures with generic templates have a lower effect on the geometry and intensity distribution of original scans, and are able to provide more consistent post-processing results by the price of higher re-identification risk and computational complexity. In the current study, we propose a novel method for anonymised face generation for defaced 3D T1-weighted scans based on a 3D conditional generative adversarial network. To evaluate the performance of the proposed de-identification tool, a comparative study was conducted between several existing defacing and refacing tools, with two different segmentation algorithms (FAST and Morphobox). The aim was to evaluate (i) impact on brain morphometry reproducibility, (ii) re-identification risk, (iii) balance between (i) and (ii), and (iv) the processing time. The proposed method takes 9 seconds for face generation and is suitable for recovering consistent post-processing results after defacing. ",
    "url": "https://arxiv.org/abs/2305.16922",
    "authors": [
      "Nataliia Molchanova",
      "B\u00e9n\u00e9dicte Mar\u00e9chal",
      "Jean-Philippe Thiran",
      "Tobias Kober",
      "Till Huelnhagen",
      "Jonas Richiardi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.17037",
    "title": "Distributionally Robust Linear Quadratic Control",
    "abstract": "Linear-Quadratic-Gaussian (LQG) control is a fundamental control paradigm that is studied in various fields such as engineering, computer science, economics, and neuroscience. It involves controlling a system with linear dynamics and imperfect observations, subject to additive noise, with the goal of minimizing a quadratic cost function for the state and control variables. In this work, we consider a generalization of the discrete-time, finite-horizon LQG problem, where the noise distributions are unknown and belong to Wasserstein ambiguity sets centered at nominal (Gaussian) distributions. The objective is to minimize a worst-case cost across all distributions in the ambiguity set, including non-Gaussian distributions. Despite the added complexity, we prove that a control policy that is linear in the observations is optimal for this problem, as in the classic LQG problem. We propose a numerical solution method that efficiently characterizes this optimal control policy. Our method uses the Frank-Wolfe algorithm to identify the least-favorable distributions within the Wasserstein ambiguity sets and computes the controller's optimal policy using Kalman filter estimation under these distributions. ",
    "url": "https://arxiv.org/abs/2305.17037",
    "authors": [
      "Bahar Ta\u015fkesen",
      "Dan A. Iancu",
      "\u00c7a\u011f\u0131l Ko\u00e7yi\u011fit",
      "Daniel Kuhn"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2305.17063",
    "title": "Vecchia Gaussian Process Ensembles on Internal Representations of Deep  Neural Networks",
    "abstract": "For regression tasks, standard Gaussian processes (GPs) provide natural uncertainty quantification, while deep neural networks (DNNs) excel at representation learning. We propose to synergistically combine these two approaches in a hybrid method consisting of an ensemble of GPs built on the output of hidden layers of a DNN. GP scalability is achieved via Vecchia approximations that exploit nearest-neighbor conditional independence. The resulting deep Vecchia ensemble not only imbues the DNN with uncertainty quantification but can also provide more accurate and robust predictions. We demonstrate the utility of our model on several datasets and carry out experiments to understand the inner workings of the proposed method. ",
    "url": "https://arxiv.org/abs/2305.17063",
    "authors": [
      "Felix Jimenez",
      "Matthias Katzfuss"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2102.07238",
    "title": "Double-descent curves in neural networks: a new perspective using  Gaussian processes",
    "abstract": " Title: Double-descent curves in neural networks: a new perspective using  Gaussian processes ",
    "url": "https://arxiv.org/abs/2102.07238",
    "authors": [
      "Ouns El Harzli",
      "Bernardo Cuenca Grau",
      "Guillermo Valle-P\u00e9rez",
      "Ard A. Louis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2102.12227",
    "title": "Multi-Task Attentive Residual Networks for Argument Mining",
    "abstract": " Comments: 16 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2102.12227",
    "authors": [
      "Andrea Galassi",
      "Marco Lippi",
      "Paolo Torroni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.12120",
    "title": "Sampling random graphs with specified degree sequences",
    "abstract": " Comments: 27 pages, 16 figures, code did not change (available at this http URL), added more exposition on alternative methods ",
    "url": "https://arxiv.org/abs/2105.12120",
    "authors": [
      "Upasana Dutta",
      "Bailey K. Fosdick",
      "Aaron Clauset"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2111.15160",
    "title": "Mitigating Adversarial Attacks by Distributing Different Copies to  Different Users",
    "abstract": " Title: Mitigating Adversarial Attacks by Distributing Different Copies to  Different Users ",
    "url": "https://arxiv.org/abs/2111.15160",
    "authors": [
      "Jiyi Zhang",
      "Han Fang",
      "Wesley Joon-Wie Tann",
      "Ke Xu",
      "Chengfang Fang",
      "Ee-Chien Chang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.02731",
    "title": "Detecting DeFi Securities Violations from Token Smart Contract Code",
    "abstract": " Title: Detecting DeFi Securities Violations from Token Smart Contract Code ",
    "url": "https://arxiv.org/abs/2112.02731",
    "authors": [
      "Arianna Trozze",
      "Bennett Kleinberg",
      "Toby Davies"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02006",
    "title": "5G Network on Wings: A Deep Reinforcement Learning Approach to the  UAV-based Integrated Access and Backhaul",
    "abstract": " Title: 5G Network on Wings: A Deep Reinforcement Learning Approach to the  UAV-based Integrated Access and Backhaul ",
    "url": "https://arxiv.org/abs/2202.02006",
    "authors": [
      "Hongyi Zhang",
      "Zhiqiang Qi",
      "Jingya Li",
      "Anders Aronsson",
      "Jan Bosch",
      "Helena Holmstr\u00f6m Olsson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2203.03624",
    "title": "FCNet: A Convolutional Neural Network for Arbitrary-Length Exposure  Estimation",
    "abstract": " Title: FCNet: A Convolutional Neural Network for Arbitrary-Length Exposure  Estimation ",
    "url": "https://arxiv.org/abs/2203.03624",
    "authors": [
      "Jin Liang",
      "Yuchen Yang",
      "Anran Zhang",
      "Jun Xu",
      "Hui Li",
      "Xiantong Zhen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.04176",
    "title": "Path Defense in Dynamic Defender-Attacker Blotto Games (dDAB) with  Limited Information",
    "abstract": " Title: Path Defense in Dynamic Defender-Attacker Blotto Games (dDAB) with  Limited Information ",
    "url": "https://arxiv.org/abs/2204.04176",
    "authors": [
      "Austin K. Chen",
      "Bryce L. Ferguson",
      "Daigo Shishika",
      "Michael Dorothy",
      "Jason R. Marden",
      "George J. Pappas",
      "Vijay Kumar"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2204.12676",
    "title": "The Multimarginal Optimal Transport Formulation of Adversarial  Multiclass Classification",
    "abstract": " Title: The Multimarginal Optimal Transport Formulation of Adversarial  Multiclass Classification ",
    "url": "https://arxiv.org/abs/2204.12676",
    "authors": [
      "Nicolas Garcia Trillos",
      "Matt Jacobs",
      "Jakwang Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.12551",
    "title": "Masked Jigsaw Puzzle: A Versatile Position Embedding for Vision  Transformers",
    "abstract": " Comments: Accepted to CVPR2023 ",
    "url": "https://arxiv.org/abs/2205.12551",
    "authors": [
      "Bin Ren",
      "Yahui Liu",
      "Yue Song",
      "Wei Bi",
      "Rita Cucchiara",
      "Nicu Sebe",
      "Wei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2207.03777",
    "title": "Hidden Schema Networks",
    "abstract": " Comments: accepted at ACL 2023 ",
    "url": "https://arxiv.org/abs/2207.03777",
    "authors": [
      "Rams\u00e9s J. S\u00e1nchez",
      "Lukas Conrads",
      "Pascal Welke",
      "Kostadin Cvejoski",
      "C\u00e9sar Ojeda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.05205",
    "title": "Scaling Novel Object Detection with Weakly Supervised Detection  Transformers",
    "abstract": " Comments: WACV 2023. Preliminary version appeared in CVPR 2022 Workshop on Transformers for Vision ",
    "url": "https://arxiv.org/abs/2207.05205",
    "authors": [
      "Tyler LaBonte",
      "Yale Song",
      "Xin Wang",
      "Vibhav Vineet",
      "Neel Joshi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.00507",
    "title": "Environmental Claim Detection",
    "abstract": " Title: Environmental Claim Detection ",
    "url": "https://arxiv.org/abs/2209.00507",
    "authors": [
      "Dominik Stammbach",
      "Nicolas Webersinke",
      "Julia Anna Bingler",
      "Mathias Kraus",
      "Markus Leippold"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2209.10200",
    "title": "Performance Optimization for Variable Bitwidth Federated Learning in  Wireless Networks",
    "abstract": " Title: Performance Optimization for Variable Bitwidth Federated Learning in  Wireless Networks ",
    "url": "https://arxiv.org/abs/2209.10200",
    "authors": [
      "Sihua Wang",
      "Mingzhe Chen",
      "Christopher G. Brinton",
      "Changchuan Yin",
      "Walid Saad",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.12288",
    "title": "On Representing Linear Programs by Graph Neural Networks",
    "abstract": " Comments: ICLR 2023 spotlight ",
    "url": "https://arxiv.org/abs/2209.12288",
    "authors": [
      "Ziang Chen",
      "Jialin Liu",
      "Xinshang Wang",
      "Jianfeng Lu",
      "Wotao Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2210.01969",
    "title": "Option-Aware Adversarial Inverse Reinforcement Learning for Robotic  Control",
    "abstract": " Comments: This paper is partly presented at IEEE International Conference on Robotics and Automation (ICRA 2023) ",
    "url": "https://arxiv.org/abs/2210.01969",
    "authors": [
      "Jiayu Chen",
      "Tian Lan",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.02157",
    "title": "The Influence of Learning Rule on Representation Dynamics in Wide Neural  Networks",
    "abstract": " Comments: ICLR 2023 Camera Ready ",
    "url": "https://arxiv.org/abs/2210.02157",
    "authors": [
      "Blake Bordelon",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.03589",
    "title": "Tracing, Ranking and Valuation of Aggregated DER Flexibility in Active  Distribution Networks",
    "abstract": " Title: Tracing, Ranking and Valuation of Aggregated DER Flexibility in Active  Distribution Networks ",
    "url": "https://arxiv.org/abs/2210.03589",
    "authors": [
      "Andrey Churkin",
      "Wangwei Kong",
      "Jose N. Melchor Gutierrez",
      "Eduardo A. Mart\u00ednez Cese\u00f1a",
      "Pierluigi Mancarella"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.08291",
    "title": "Bidirectional Semi-supervised Dual-branch CNN for Robust 3D  Reconstruction of Stereo Endoscopic Images via Adaptive Cross and Parallel  Supervisions",
    "abstract": " Comments: Accepted by IEEE Transactions on Medical Imaging ",
    "url": "https://arxiv.org/abs/2210.08291",
    "authors": [
      "Hongkuan Shi",
      "Zhiwei Wang",
      "Ying Zhou",
      "Dun Li",
      "Xin Yang",
      "Qiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.10343",
    "title": "Entity-to-Text based Data Augmentation for various Named Entity  Recognition Tasks",
    "abstract": " Comments: Accepted to ACL 2023 (Findings), Long Paper, 14 pages ",
    "url": "https://arxiv.org/abs/2210.10343",
    "authors": [
      "Xuming Hu",
      "Yong Jiang",
      "Aiwei Liu",
      "Zhongqiang Huang",
      "Pengjun Xie",
      "Fei Huang",
      "Lijie Wen",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.10759",
    "title": "On Representing Mixed-Integer Linear Programs by Graph Neural Networks",
    "abstract": " Comments: ICLR 2023 ",
    "url": "https://arxiv.org/abs/2210.10759",
    "authors": [
      "Ziang Chen",
      "Jialin Liu",
      "Xinshang Wang",
      "Jianfeng Lu",
      "Wotao Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2210.12078",
    "title": "Experiencer-Specific Emotion and Appraisal Prediction",
    "abstract": " Comments: accepted to the NLPCSS workshop at EMNLP 2022: this https URL ",
    "url": "https://arxiv.org/abs/2210.12078",
    "authors": [
      "Maximilian Wegge",
      "Enrica Troiano",
      "Laura Oberl\u00e4nder",
      "Roman Klinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.17546",
    "title": "Preventing Verbatim Memorization in Language Models Gives a False Sense  of Privacy",
    "abstract": " Comments: Update May 25: Small writing cleanups and fixed buggy Figure 4 ",
    "url": "https://arxiv.org/abs/2210.17546",
    "authors": [
      "Daphne Ippolito",
      "Florian Tram\u00e8r",
      "Milad Nasr",
      "Chiyuan Zhang",
      "Matthew Jagielski",
      "Katherine Lee",
      "Christopher A. Choquette-Choo",
      "Nicholas Carlini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2211.01668",
    "title": "Quantum Similarity Testing with Convolutional Neural Networks",
    "abstract": " Title: Quantum Similarity Testing with Convolutional Neural Networks ",
    "url": "https://arxiv.org/abs/2211.01668",
    "authors": [
      "Ya-Dong Wu",
      "Yan Zhu",
      "Ge Bai",
      "Yuexuan Wang",
      "Giulio Chiribella"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.01716",
    "title": "Discussion of Features for Acoustic Anomaly Detection under Industrial  Disturbing Noise in an End-of-Line Test of Geared Motors",
    "abstract": " Comments: \\c{opyright} 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works ",
    "url": "https://arxiv.org/abs/2211.01716",
    "authors": [
      "Peter Wissbrock",
      "David Pelkmann",
      "Yvonne Richter"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2211.01912",
    "title": "Matching Augmentation via Simultaneous Contractions",
    "abstract": " Comments: 60 pages, 16 figures. Accepted at ICALP 2023 ",
    "url": "https://arxiv.org/abs/2211.01912",
    "authors": [
      "Mohit Garg",
      "Felix Hommelsheim",
      "Nicole Megow"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2211.05528",
    "title": "PAD-Net: An Efficient Framework for Dynamic Networks",
    "abstract": " Comments: Proceedings of ACL 2023 ",
    "url": "https://arxiv.org/abs/2211.05528",
    "authors": [
      "Shwai He",
      "Liang Ding",
      "Daize Dong",
      "Boan Liu",
      "Fuqiang Yu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08486",
    "title": "Scalar Invariant Networks with Zero Bias",
    "abstract": " Comments: 22 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2211.08486",
    "authors": [
      "Chuqin Geng",
      "Xiaojie Xu",
      "Haolin Ye",
      "Xujie Si"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.08794",
    "title": "Towards Robust Low-Resource Fine-Tuning with Multi-View Compressed  Representations",
    "abstract": " Comments: Accepted by ACL 2023 ",
    "url": "https://arxiv.org/abs/2211.08794",
    "authors": [
      "Linlin Liu",
      "Xingxuan Li",
      "Megh Thakkar",
      "Xin Li",
      "Shafiq Joty",
      "Luo Si",
      "Lidong Bing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.11567",
    "title": "Neural networks trained with SGD learn distributions of increasing  complexity",
    "abstract": " Comments: Source code available at this https URL ",
    "url": "https://arxiv.org/abs/2211.11567",
    "authors": [
      "Maria Refinetti",
      "Alessandro Ingrosso",
      "Sebastian Goldt"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.12345",
    "title": "Understanding Sparse Feature Updates in Deep Networks using Iterative  Linearisation",
    "abstract": " Title: Understanding Sparse Feature Updates in Deep Networks using Iterative  Linearisation ",
    "url": "https://arxiv.org/abs/2211.12345",
    "authors": [
      "Adrian Goldwaser",
      "Hong Ge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2211.13118",
    "title": "Decision Diagram-Based Branch-and-Bound with Caching for Dominance and  Suboptimality Detection",
    "abstract": " Comments: Submitted to INFORMS Journal on Computing ",
    "url": "https://arxiv.org/abs/2211.13118",
    "authors": [
      "Vianney Copp\u00e9",
      "Xavier Gillard",
      "Pierre Schaus"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2211.16550",
    "title": "Soft Alignment Objectives for Robust Adaptation of Language Generation",
    "abstract": " Comments: Annual Meeting of The ACL 2023: Main conference long paper ",
    "url": "https://arxiv.org/abs/2211.16550",
    "authors": [
      "Michal \u0160tef\u00e1nik",
      "Marek Kadl\u010d\u00edk",
      "Petr Sojka"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2211.17179",
    "title": "Investigation of Proper Orthogonal Decomposition for Echo State Networks",
    "abstract": " Comments: Accepted in Neurocomputing, not yet published ",
    "url": "https://arxiv.org/abs/2211.17179",
    "authors": [
      "Jean Panaioti Jordanou",
      "Eric Aislan Antonelo",
      "Eduardo Camponogara",
      "Eduardo Gildin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2212.01117",
    "title": "Zero-Shot Rumor Detection with Propagation Structure via Prompt Learning",
    "abstract": " Comments: AAAI 2023 ",
    "url": "https://arxiv.org/abs/2212.01117",
    "authors": [
      "Hongzhan Lin",
      "Pengyao Yi",
      "Jing Ma",
      "Haiyun Jiang",
      "Ziyang Luo",
      "Shuming Shi",
      "Ruifang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.07295",
    "title": "Maximal Initial Learning Rates in Deep ReLU Networks",
    "abstract": " Comments: International Conference on Machine Learning (ICML) 2023 ",
    "url": "https://arxiv.org/abs/2212.07295",
    "authors": [
      "Gaurav Iyer",
      "Boris Hanin",
      "David Rolnick"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.09885",
    "title": "Python Code Generation by Asking Clarification Questions",
    "abstract": " Comments: 9 pages (excluding Limitations and Ethics Concerns) ",
    "url": "https://arxiv.org/abs/2212.09885",
    "authors": [
      "Haau-Sing Li",
      "Mohsen Mesgar",
      "Andr\u00e9 F. T. Martins",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.10957",
    "title": "TruFor: Leveraging all-round clues for trustworthy image forgery  detection and localization",
    "abstract": " Title: TruFor: Leveraging all-round clues for trustworthy image forgery  detection and localization ",
    "url": "https://arxiv.org/abs/2212.10957",
    "authors": [
      "Fabrizio Guillaro",
      "Davide Cozzolino",
      "Avneesh Sud",
      "Nicholas Dufour",
      "Luisa Verdoliva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.12317",
    "title": "Matching Cuts in Graphs of High Girth and H-Free Graphs",
    "abstract": " Title: Matching Cuts in Graphs of High Girth and H-Free Graphs ",
    "url": "https://arxiv.org/abs/2212.12317",
    "authors": [
      "Carl Feghali",
      "Felicia Lucke",
      "Daniel Paulusma",
      "Bernard Ries"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2302.06503",
    "title": "Ground(less) Truth: A Causal Framework for Proxy Labels in  Human-Algorithm Decision-Making",
    "abstract": " Comments: FAccT 23' ",
    "url": "https://arxiv.org/abs/2302.06503",
    "authors": [
      "Luke Guerdan",
      "Amanda Coston",
      "Zhiwei Steven Wu",
      "Kenneth Holstein"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2302.07944",
    "title": "Effective Data Augmentation With Diffusion Models",
    "abstract": " Comments: Updated paper with new results ",
    "url": "https://arxiv.org/abs/2302.07944",
    "authors": [
      "Brandon Trabucco",
      "Kyle Doherty",
      "Max Gurinas",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.08942",
    "title": "PAC-Bayesian Generalization Bounds for Adversarial Generative Models",
    "abstract": " Title: PAC-Bayesian Generalization Bounds for Adversarial Generative Models ",
    "url": "https://arxiv.org/abs/2302.08942",
    "authors": [
      "Sokhna Diarra Mbacke",
      "Florence Clerc",
      "Pascal Germain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.09554",
    "title": "Mixed Hierarchy Network for Image Restoration",
    "abstract": " Title: Mixed Hierarchy Network for Image Restoration ",
    "url": "https://arxiv.org/abs/2302.09554",
    "authors": [
      "Hu Gao",
      "Depeng Dang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.09578",
    "title": "On Feasibility of Server-side Backdoor Attacks on Split Learning",
    "abstract": " Title: On Feasibility of Server-side Backdoor Attacks on Split Learning ",
    "url": "https://arxiv.org/abs/2302.09578",
    "authors": [
      "Behrad Tajalli",
      "Oguzhan Ersoy",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.01076",
    "title": "Hallucinated Adversarial Control for Conservative Offline Policy  Evaluation",
    "abstract": " Comments: Conference on Uncertainty in Artificial Intelligence (UAI) 2023, first three authors contributed equally ",
    "url": "https://arxiv.org/abs/2303.01076",
    "authors": [
      "Jonas Rothfuss",
      "Bhavya Sukhija",
      "Tobias Birchler",
      "Parnian Kassraie",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.02859",
    "title": "Bayesian inference with finitely wide neural networks",
    "abstract": " Comments: v2: added relevant references, example of simple non-Gaussian bivariate distribution and corresponding inference ",
    "url": "https://arxiv.org/abs/2303.02859",
    "authors": [
      "Chi-Ken Lu"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2304.03408",
    "title": "Dynamics of Finite Width Kernel and Prediction Fluctuations in Mean  Field Neural Networks",
    "abstract": " Comments: 43 Pages ",
    "url": "https://arxiv.org/abs/2304.03408",
    "authors": [
      "Blake Bordelon",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.05516",
    "title": "Echo of Neighbors: Privacy Amplification for Personalized Private  Federated Learning with Shuffle Model",
    "abstract": " Title: Echo of Neighbors: Privacy Amplification for Personalized Private  Federated Learning with Shuffle Model ",
    "url": "https://arxiv.org/abs/2304.05516",
    "authors": [
      "Yixuan Liu",
      "Suyun Zhao",
      "Li Xiong",
      "Yuhan Liu",
      "Hong Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.14787",
    "title": "A Network Perspective on the Influence of Code Review Bots on the  Structure of Developer Collaborations",
    "abstract": " Comments: 8 pages ",
    "url": "https://arxiv.org/abs/2304.14787",
    "authors": [
      "Leonore R\u00f6seler",
      "Ingo Scholtes",
      "Christoph Gote"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.04087",
    "title": "Self-Edit: Fault-Aware Code Editor for Code Generation",
    "abstract": " Comments: Accepted by ACL2023 ",
    "url": "https://arxiv.org/abs/2305.04087",
    "authors": [
      "Kechi Zhang",
      "Zhuo Li",
      "Jia Li",
      "Ge Li",
      "Zhi Jin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.04575",
    "title": "A physics-based reduced order model for urban air pollution prediction",
    "abstract": " Title: A physics-based reduced order model for urban air pollution prediction ",
    "url": "https://arxiv.org/abs/2305.04575",
    "authors": [
      "Moaad Khamlich",
      "Giovanni Stabile",
      "Gianluigi Rozza",
      "L\u00e1szl\u00f3 K\u00f6rnyei",
      "Zolt\u00e1n Horv\u00e1th"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2305.04990",
    "title": "Explanation-based Finetuning Makes Models More Robust to Spurious Cues",
    "abstract": " Title: Explanation-based Finetuning Makes Models More Robust to Spurious Cues ",
    "url": "https://arxiv.org/abs/2305.04990",
    "authors": [
      "Josh Magnus Ludan",
      "Yixuan Meng",
      "Tai Nguyen",
      "Saurabh Shah",
      "Qing Lyu",
      "Marianna Apidianaki",
      "Chris Callison-Burch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.12760",
    "title": "Finite Blocklength Regime Performance of Downlink Large Scale Networks",
    "abstract": " Comments: This paper is submitted in IEEE Transactions on Wireless Communications (Status: Accepted). This is a 32-pages paper with 11 figures ",
    "url": "https://arxiv.org/abs/2305.12760",
    "authors": [
      "Nourhan Hesham",
      "Anas Chaaban",
      "Hesham ElSawy",
      "Jahangir Hossain"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2305.12831",
    "title": "Target Active Speaker Detection with Audio-visual Cues",
    "abstract": " Comments: Accepted to INTERSPEECH2023 ",
    "url": "https://arxiv.org/abs/2305.12831",
    "authors": [
      "Yidi Jiang",
      "Ruijie Tao",
      "Zexu Pan",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2305.13617",
    "title": "SPEECH: Structured Prediction with Energy-Based Event-Centric  Hyperspheres",
    "abstract": " Comments: Accepted by ACL 2023 Main Conference. Code is released at \\url{this https URL} ",
    "url": "https://arxiv.org/abs/2305.13617",
    "authors": [
      "Shumin Deng",
      "Shengyu Mao",
      "Ningyu Zhang",
      "Bryan Hooi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14550",
    "title": "Sequence Modeling is a Robust Contender for Offline Reinforcement  Learning",
    "abstract": " Title: Sequence Modeling is a Robust Contender for Offline Reinforcement  Learning ",
    "url": "https://arxiv.org/abs/2305.14550",
    "authors": [
      "Prajjwal Bhargava",
      "Rohan Chitnis",
      "Alborz Geramifard",
      "Shagun Sodhani",
      "Amy Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.14580",
    "title": "Evaluating OpenAI's Whisper ASR for Punctuation Prediction and Topic  Modeling of life histories of the Museum of the Person",
    "abstract": " Title: Evaluating OpenAI's Whisper ASR for Punctuation Prediction and Topic  Modeling of life histories of the Museum of the Person ",
    "url": "https://arxiv.org/abs/2305.14580",
    "authors": [
      "Lucas Rafael Stefanel Gris",
      "Ricardo Marcacini",
      "Arnaldo Candido Junior",
      "Edresson Casanova",
      "Anderson Soares",
      "Sandra Maria Alu\u00edsio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15441",
    "title": "Improving few-shot learning-based protein engineering with evolutionary  sampling",
    "abstract": " Title: Improving few-shot learning-based protein engineering with evolutionary  sampling ",
    "url": "https://arxiv.org/abs/2305.15441",
    "authors": [
      "M. Zaki Jawaid",
      "Robin W. Yeo",
      "Aayushma Gautam",
      "T. Blair Gainous",
      "Daniel O. Hart",
      "Timothy P. Daley"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15534",
    "title": "Representation Online Matters: Practical End-to-End Diversification in  Search and Recommender Systems",
    "abstract": " Comments: In Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency (FAccT '23), June 12--15, 2023, Chicago, IL, USA ",
    "url": "https://arxiv.org/abs/2305.15534",
    "authors": [
      "Pedro Silva",
      "Bhawna Juneja",
      "Shloka Desai",
      "Ashudeep Singh",
      "Nadia Fawaz"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.15732",
    "title": "CLIP3Dstyler: Language Guided 3D Arbitrary Neural Style Transfer",
    "abstract": " Comments: 17 pages, 14 figures ",
    "url": "https://arxiv.org/abs/2305.15732",
    "authors": [
      "Ming Gao",
      "YanWu Xu",
      "Yang Zhao",
      "Tingbo Hou",
      "Chenkai Zhao",
      "Mingming Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15811",
    "title": "Unifying gradient regularization for Heterogeneous Graph Neural Networks",
    "abstract": " Title: Unifying gradient regularization for Heterogeneous Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2305.15811",
    "authors": [
      "Xiao Yang",
      "Xuejiao Zhao",
      "Zhiqi Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16129",
    "title": "Energy-based Detection of Adverse Weather Effects in LiDAR Data",
    "abstract": " Comments: Accepted for publication in IEEE Robotics and Automation Letters (RA-L) ",
    "url": "https://arxiv.org/abs/2305.16129",
    "authors": [
      "Aldi Piroli",
      "Vinzenz Dallabetta",
      "Johannes Kopp",
      "Marc Walessa",
      "Daniel Meissner",
      "Klaus Dietmayer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16173",
    "title": "Efficient Bound of Lipschitz Constant for Convolutional Layers by Gram  Iteration",
    "abstract": " Comments: ICML 2023 ",
    "url": "https://arxiv.org/abs/2305.16173",
    "authors": [
      "Blaise Delattre",
      "Quentin Barth\u00e9lemy",
      "Alexandre Araujo",
      "Alexandre Allauzen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.16199",
    "title": "Diversity-Aware Coherence Loss for Improving Neural Topic Models",
    "abstract": " Comments: Minor Fixes, 11 pages, Camera-Ready for ACL 2023 (Short Paper) ",
    "url": "https://arxiv.org/abs/2305.16199",
    "authors": [
      "Raymond Li",
      "Felipe Gonz\u00e1lez-Pizarro",
      "Linzi Xing",
      "Gabriel Murray",
      "Giuseppe Carenini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.16314",
    "title": "Banana: Banach Fixed-Point Network for Pointcloud Segmentation with  Inter-Part Equivariance",
    "abstract": " Title: Banana: Banach Fixed-Point Network for Pointcloud Segmentation with  Inter-Part Equivariance ",
    "url": "https://arxiv.org/abs/2305.16314",
    "authors": [
      "Congyue Deng",
      "Jiahui Lei",
      "Bokui Shen",
      "Kostas Daniilidis",
      "Leonidas Guibas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  }
]