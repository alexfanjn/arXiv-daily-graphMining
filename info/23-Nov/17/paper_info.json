[
  {
    "id": "arXiv:2311.09224",
    "title": "The Cybersecurity Crisis of Artificial Intelligence: Unrestrained  Adoption and Natural Language-Based Attacks",
    "abstract": "The widespread integration of autoregressive-large language models (AR-LLMs), such as ChatGPT, across established applications, like search engines, has introduced critical vulnerabilities with uniquely scalable characteristics. In this commentary, we analyse these vulnerabilities, their dependence on natural language as a vector of attack, and their challenges to cybersecurity best practices. We offer recommendations designed to mitigate these challenges. ",
    "url": "https://arxiv.org/abs/2311.09224",
    "authors": [
      "Andreas Tsamados",
      "Luciano Floridi",
      "Mariarosaria Taddeo"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.09225",
    "title": "Autonomous Driving using Spiking Neural Networks on Dynamic Vision  Sensor Data: A Case Study of Traffic Light Change Detection",
    "abstract": "Autonomous driving is a challenging task that has gained broad attention from both academia and industry. Current solutions using convolutional neural networks require large amounts of computational resources, leading to high power consumption. Spiking neural networks (SNNs) provide an alternative computation model to process information and make decisions. This biologically plausible model has the advantage of low latency and energy efficiency. Recent work using SNNs for autonomous driving mostly focused on simple tasks like lane keeping in simplified simulation environments. This project studies SNNs on photo-realistic driving scenes in the CARLA simulator, which is an important step toward using SNNs on real vehicles. The efficacy and generalizability of the method will be investigated. ",
    "url": "https://arxiv.org/abs/2311.09225",
    "authors": [
      "Xuelei Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2311.09230",
    "title": "Evaluating and Improving Value Judgments in AI: A Scenario-Based Study  on Large Language Models' Depiction of Social Conventions",
    "abstract": "The adoption of generative AI technologies is swiftly expanding. Services employing both linguistic and mul-timodal models are evolving, offering users increasingly precise responses. Consequently, human reliance on these technologies is expected to grow rapidly. With the premise that people will be impacted by the output of AI, we explored approaches to help AI output produce better results. Initially, we evaluated how contemporary AI services competitively meet user needs, then examined society's depiction as mirrored by Large Language Models (LLMs). We did a query experiment, querying about social conventions in various countries and eliciting a one-word response. We compared the LLMs' value judgments with public data and suggested an model of decision-making in value-conflicting scenarios which could be adopted for future machine value judgments. This paper advocates for a practical approach to using AI as a tool for investigating other remote worlds. This re-search has significance in implicitly rejecting the notion of AI making value judgments and instead arguing a more critical perspective on the environment that defers judgmental capabilities to individuals. We anticipate this study will empower anyone, regardless of their capacity, to receive safe and accurate value judgment-based out-puts effectively. ",
    "url": "https://arxiv.org/abs/2311.09230",
    "authors": [
      "Jaeyoun You",
      "Bongwon Suh"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2311.09233",
    "title": "Neural Packing: from Visual Sensing to Reinforcement Learning",
    "abstract": "We present a novel learning framework to solve the transport-and-packing (TAP) problem in 3D. It constitutes a full solution pipeline from partial observations of input objects via RGBD sensing and recognition to final box placement, via robotic motion planning, to arrive at a compact packing in a target container. The technical core of our method is a neural network for TAP, trained via reinforcement learning (RL), to solve the NP-hard combinatorial optimization problem. Our network simultaneously selects an object to pack and determines the final packing location, based on a judicious encoding of the continuously evolving states of partially observed source objects and available spaces in the target container, using separate encoders both enabled with attention mechanisms. The encoded feature vectors are employed to compute the matching scores and feasibility masks of different pairings of box selection and available space configuration for packing strategy optimization. Extensive experiments, including ablation studies and physical packing execution by a real robot (Universal Robot UR5e), are conducted to evaluate our method in terms of its design choices, scalability, generalizability, and comparisons to baselines, including the most recent RL-based TAP solution. We also contribute the first benchmark for TAP which covers a variety of input settings and difficulty levels. ",
    "url": "https://arxiv.org/abs/2311.09233",
    "authors": [
      "Juzhan Xu",
      "Minglun Gong",
      "Hao Zhang",
      "Hui Huang",
      "Ruizhen Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.09237",
    "title": "An Innovative Tool for Uploading/Scraping Large Image Datasets on Social  Networks",
    "abstract": "Nowadays, people can retrieve and share digital information in an increasingly easy and fast fashion through the well-known digital platforms, including sensitive data, inappropriate or illegal content, and, in general, information that might serve as probative evidence in court. Consequently, to assess forensics issues, we need to figure out how to trace back to the posting chain of a digital evidence (e.g., a picture, an audio) throughout the involved platforms -- this is what Digital (also Forensics) Ballistics basically deals with. With the entry of Machine Learning as a tool of the trade in many research areas, the need for vast amounts of data has been dramatically increasing over the last few years. However, collecting or simply find the \"right\" datasets that properly enables data-driven research studies can turn out to be not trivial in some cases, if not extremely challenging, especially when it comes with highly specialized tasks, such as creating datasets analyzed to detect the source media platform of a given digital media. In this paper we propose an automated approach by means of a digital tool that we created on purpose. The tool is capable of automatically uploading an entire image dataset to the desired digital platform and then downloading all the uploaded pictures, thus shortening the overall time required to output the final dataset to be analyzed. ",
    "url": "https://arxiv.org/abs/2311.09237",
    "authors": [
      "Nicol\u00f2 Fabio Arceri",
      "Oliver Giudice",
      "Sebastiano Battiato"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.09245",
    "title": "Affine Invariance in Continuous-Domain Convolutional Neural Networks",
    "abstract": "The notion of group invariance helps neural networks in recognizing patterns and features under geometric transformations. Indeed, it has been shown that group invariance can largely improve deep learning performances in practice, where such transformations are very common. This research studies affine invariance on continuous-domain convolutional neural networks. Despite other research considering isometric invariance or similarity invariance, we focus on the full structure of affine transforms generated by the generalized linear group $\\mathrm{GL}_2(\\mathbb{R})$. We introduce a new criterion to assess the similarity of two input signals under affine transformations. Then, unlike conventional methods that involve solving complex optimization problems on the Lie group $G_2$, we analyze the convolution of lifted signals and compute the corresponding integration over $G_2$. In sum, our research could eventually extend the scope of geometrical transformations that practical deep-learning pipelines can handle. ",
    "url": "https://arxiv.org/abs/2311.09245",
    "authors": [
      "Ali Mohaddes",
      "Johannes Lederer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.09251",
    "title": "A Simple and Powerful Framework for Stable Dynamic Network Embedding",
    "abstract": "In this paper, we address the problem of dynamic network embedding, that is, representing the nodes of a dynamic network as evolving vectors within a low-dimensional space. While the field of static network embedding is wide and established, the field of dynamic network embedding is comparatively in its infancy. We propose that a wide class of established static network embedding methods can be used to produce interpretable and powerful dynamic network embeddings when they are applied to the dilated unfolded adjacency matrix. We provide a theoretical guarantee that, regardless of embedding dimension, these unfolded methods will produce stable embeddings, meaning that nodes with identical latent behaviour will be exchangeable, regardless of their position in time or space. We additionally define a hypothesis testing framework which can be used to evaluate the quality of a dynamic network embedding by testing for planted structure in simulated networks. Using this, we demonstrate that, even in trivial cases, unstable methods are often either conservative or encode incorrect structure. In contrast, we demonstrate that our suite of stable unfolded methods are not only more interpretable but also more powerful in comparison to their unstable counterparts. ",
    "url": "https://arxiv.org/abs/2311.09251",
    "authors": [
      "Ed Davis",
      "Ian Gallagher",
      "Daniel John Lawson",
      "Patrick Rubin-Delanchy"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.09252",
    "title": "In the Red(dit): Social Media and Stock Prices",
    "abstract": "Spearheaded by retail traders on the website reddit, the GameStop short squeeze of early 2021 shows that social media embeds information that correlates with market movements. This paper seeks to examine this relationship by using daily frequencies of classified comments and buzzwords as additional factors in a Fama-French three factor model. Comments are classified using an unsupervised clustering method, while past studies have used pretrained models that are not specific to the domains being studied. ",
    "url": "https://arxiv.org/abs/2311.09252",
    "authors": [
      "James Baker"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09254",
    "title": "A Bayesian Agent-Based Framework for Argument Exchange Across Networks",
    "abstract": "In this paper, we introduce a new framework for modelling the exchange of multiple arguments across agents in a social network. To date, most modelling work concerned with opinion dynamics, testimony, or communication across social networks has involved only the simulated exchange of a single opinion or single claim. By contrast, real-world debate involves the provision of numerous individual arguments relevant to such an opinion. This may include arguments both for and against, and arguments varying in strength. This prompts the need for appropriate aggregation rules for combining diverse evidence as well as rules for communication. Here, we draw on the Bayesian framework to create an agent-based modelling environment that allows the study of belief dynamics across complex domains characterised by Bayesian Networks. Initial case studies illustrate the scope of the framework. ",
    "url": "https://arxiv.org/abs/2311.09254",
    "authors": [
      "Leon Assaad",
      "Rafael Fuchs",
      "Ammar Jalalimanesh",
      "Kirsty Phillips",
      "Leon Schoeppl",
      "Ulrike Hahn"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.09266",
    "title": "Adversarially Robust Spiking Neural Networks Through Conversion",
    "abstract": "Spiking neural networks (SNNs) provide an energy-efficient alternative to a variety of artificial neural network (ANN) based AI applications. As the progress in neuromorphic computing with SNNs expands their use in applications, the problem of adversarial robustness of SNNs becomes more pronounced. To the contrary of the widely explored end-to-end adversarial training based solutions, we address the limited progress in scalable robust SNN training methods by proposing an adversarially robust ANN-to-SNN conversion algorithm. Our method provides an efficient approach to embrace various computationally demanding robust learning objectives that have been proposed for ANNs. During a post-conversion robust finetuning phase, our method adversarially optimizes both layer-wise firing thresholds and synaptic connectivity weights of the SNN to maintain transferred robustness gains from the pre-trained ANN. We perform experimental evaluations in numerous adaptive adversarial settings that account for the spike-based operation dynamics of SNNs, and show that our approach yields a scalable state-of-the-art solution for adversarially robust deep SNNs with low-latency. ",
    "url": "https://arxiv.org/abs/2311.09266",
    "authors": [
      "Ozan \u00d6zdenizci",
      "Robert Legenstein"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.09274",
    "title": "Constructing interpretable principal curve using Neural ODEs",
    "abstract": "The study of high dimensional data sets often rely on their low dimensional projections that preserve the local geometry of the original space. While numerous methods have been developed to summarize this space as variations of tree-like structures, they are usually non-parametric and \"static\" in nature. As data may come from systems that are dynamical such as a differentiating cell, a static, non-parametric characterization of the space may not be the most appropriate. Here, we developed a framework, the principal flow, that is capable of characterizing the space in a dynamical manner. The principal flow, defined using neural ODEs, directs motion of a particle through the space, where the trajectory of the particle resembles the principal curve of the dataset. We illustrate that our framework can be used to characterize shapes of various complexities, and is flexible to incorporate summaries of relaxation dynamics. ",
    "url": "https://arxiv.org/abs/2311.09274",
    "authors": [
      "Guangzheng Zhang",
      "Bingxian Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2311.09276",
    "title": "Leveraging Citizen Science for Flood Extent Detection using Machine  Learning Benchmark Dataset",
    "abstract": "Accurate detection of inundated water extents during flooding events is crucial in emergency response decisions and aids in recovery efforts. Satellite Remote Sensing data provides a global framework for detecting flooding extents. Specifically, Sentinel-1 C-Band Synthetic Aperture Radar (SAR) imagery has proven to be useful in detecting water bodies due to low backscatter of water features in both co-polarized and cross-polarized SAR imagery. However, increased backscatter can be observed in certain flooded regions such as presence of infrastructure and trees - rendering simple methods such as pixel intensity thresholding and time-series differencing inadequate. Machine Learning techniques has been leveraged to precisely capture flood extents in flooded areas with bumps in backscatter but needs high amounts of labelled data to work desirably. Hence, we created a labeled known water body extent and flooded area extents during known flooding events covering about 36,000 sq. kilometers of regions within mainland U.S and Bangladesh. Further, We also leveraged citizen science by open-sourcing the dataset and hosting an open competition based on the dataset to rapidly prototype flood extent detection using community generated models. In this paper we present the information about the dataset, the data processing pipeline, a baseline model and the details about the competition, along with discussion on winning approaches. We believe the dataset adds to already existing datasets based on Sentinel-1C SAR data and leads to more robust modeling of flood extents. We also hope the results from the competition pushes the research in flood extent detection further. ",
    "url": "https://arxiv.org/abs/2311.09276",
    "authors": [
      "Muthukumaran Ramasubramanian",
      "Iksha Gurung",
      "Shubhankar Gahlot",
      "Ronny H\u00e4nsch",
      "Andrew L. Molthan",
      "Manil Maskey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2311.09329",
    "title": "A Comparative Analysis of Machine Learning Models for Early Detection of  Hospital-Acquired Infections",
    "abstract": "As more and more infection-specific machine learning models are developed and planned for clinical deployment, simultaneously running predictions from different models may provide overlapping or even conflicting information. It is important to understand the concordance and behavior of parallel models in deployment. In this study, we focus on two models for the early detection of hospital-acquired infections (HAIs): 1) the Infection Risk Index (IRI) and 2) the Ventilator-Associated Pneumonia (VAP) prediction model. The IRI model was built to predict all HAIs, whereas the VAP model identifies patients at risk of developing ventilator-associated pneumonia. These models could make important improvements in patient outcomes and hospital management of infections through early detection of infections and in turn, enable early interventions. The two models vary in terms of infection label definition, cohort selection, and prediction schema. In this work, we present a comparative analysis between the two models to characterize concordances and confusions in predicting HAIs by these models. The learnings from this study will provide important findings for how to deploy multiple concurrent disease-specific models in the future. ",
    "url": "https://arxiv.org/abs/2311.09329",
    "authors": [
      "Ethan Harvey",
      "Junzi Dong",
      "Erina Ghosh",
      "Ali Samadani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.09333",
    "title": "Strategic Data Augmentation with CTGAN for Smart Manufacturing:  Enhancing Machine Learning Predictions of Paper Breaks in Pulp-and-Paper  Production",
    "abstract": "A significant challenge for predictive maintenance in the pulp-and-paper industry is the infrequency of paper breaks during the production process. In this article, operational data is analyzed from a paper manufacturing machine in which paper breaks are relatively rare but have a high economic impact. Utilizing a dataset comprising 18,398 instances derived from a quality assurance protocol, we address the scarcity of break events (124 cases) that pose a challenge for machine learning predictive models. With the help of Conditional Generative Adversarial Networks (CTGAN) and Synthetic Minority Oversampling Technique (SMOTE), we implement a novel data augmentation framework. This method ensures that the synthetic data mirrors the distribution of the real operational data but also seeks to enhance the performance metrics of predictive modeling. Before and after the data augmentation, we evaluate three different machine learning algorithms-Decision Trees (DT), Random Forest (RF), and Logistic Regression (LR). Utilizing the CTGAN-enhanced dataset, our study achieved significant improvements in predictive maintenance performance metrics. The efficacy of CTGAN in addressing data scarcity was evident, with the models' detection of machine breaks (Class 1) improving by over 30% for Decision Trees, 20% for Random Forest, and nearly 90% for Logistic Regression. With this methodological advancement, this study contributes to industrial quality control and maintenance scheduling by addressing rare event prediction in manufacturing processes. ",
    "url": "https://arxiv.org/abs/2311.09333",
    "authors": [
      "Hamed Khosravi",
      "Sarah Farhadpour",
      "Manikanta Grandhi",
      "Ahmed Shoyeb Raihan",
      "Srinjoy Das",
      "Imtiaz Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.09338",
    "title": "Challenges for Predictive Modeling with Neural Network Techniques using  Error-Prone Dietary Intake Data",
    "abstract": "Dietary intake data are routinely drawn upon to explore diet-health relationships. However, these data are often subject to measurement error, distorting the true relationships. Beyond measurement error, there are likely complex synergistic and sometimes antagonistic interactions between different dietary components, complicating the relationships between diet and health outcomes. Flexible models are required to capture the nuance that these complex interactions introduce. This complexity makes research on diet-health relationships an appealing candidate for the application of machine learning techniques, and in particular, neural networks. Neural networks are computational models that are able to capture highly complex, nonlinear relationships so long as sufficient data are available. While these models have been applied in many domains, the impacts of measurement error on the performance of predictive modeling has not been systematically investigated. However, dietary intake data are typically collected using self-report methods and are prone to large amounts of measurement error. In this work, we demonstrate the ways in which measurement error erodes the performance of neural networks, and illustrate the care that is required for leveraging these models in the presence of error. We demonstrate the role that sample size and replicate measurements play on model performance, indicate a motivation for the investigation of transformations to additivity, and illustrate the caution required to prevent model overfitting. While the past performance of neural networks across various domains make them an attractive candidate for examining diet-health relationships, our work demonstrates that substantial care and further methodological development are both required to observe increased predictive performance when applying these techniques, compared to more traditional statistical procedures. ",
    "url": "https://arxiv.org/abs/2311.09338",
    "authors": [
      "Dylan Spicker",
      "Amir Nazemi",
      "Joy Hutchinson",
      "Paul Fieguth",
      "Sharon I. Kirkpatrick",
      "Michael Wallace",
      "Kevin W. Dodd"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2311.09348",
    "title": "Analysis of Research Trends in Computer Science: A Network Approach",
    "abstract": "Nowadays, computer science (CS) has emerged as a dominant force in numerous research areas both within and beyond its own discipline. However, despite its significant impact on scholarly space, only a limited number of studies have been conducted to analyze the research trends and relationships within computer science. In this study, we collected information on fields and subfields from over 2,000 research articles published in the 2022 proceedings of the top Association for Computing Machinery (ACM) conferences spanning various research fields. Through a network approach, we investigated the interconnections between CS fields and subfields to evaluate their interdisciplinarity and multidisciplinarity. Our findings indicate that computing methodologies and privacy and security stand out as the most interdisciplinary fields, while human-centered computing exhibits the highest frequency among the papers. Furthermore, we discovered that machine learning emerges as the most interdisciplinary and multidisciplinary subfield within computer science. These results offer valuable insights for universities seeking to foster interdisciplinary research opportunities for their students. ",
    "url": "https://arxiv.org/abs/2311.09348",
    "authors": [
      "Ghazal Kalhor",
      "Behnam Bahrak"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.09355",
    "title": "Privacy Threats in Stable Diffusion Models",
    "abstract": "This paper introduces a novel approach to membership inference attacks (MIA) targeting stable diffusion computer vision models, specifically focusing on the highly sophisticated Stable Diffusion V2 by StabilityAI. MIAs aim to extract sensitive information about a model's training data, posing significant privacy concerns. Despite its advancements in image synthesis, our research reveals privacy vulnerabilities in the stable diffusion models' outputs. Exploiting this information, we devise a black-box MIA that only needs to query the victim model repeatedly. Our methodology involves observing the output of a stable diffusion model at different generative epochs and training a classification model to distinguish when a series of intermediates originated from a training sample or not. We propose numerous ways to measure the membership features and discuss what works best. The attack's efficacy is assessed using the ROC AUC method, demonstrating a 60\\% success rate in inferring membership information. This paper contributes to the growing body of research on privacy and security in machine learning, highlighting the need for robust defenses against MIAs. Our findings prompt a reevaluation of the privacy implications of stable diffusion models, urging practitioners and developers to implement enhanced security measures to safeguard against such attacks. ",
    "url": "https://arxiv.org/abs/2311.09355",
    "authors": [
      "Thomas Cilloni",
      "Charles Fleming",
      "Charles Walter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.09366",
    "title": "LOKE: Linked Open Knowledge Extraction for Automated Knowledge Graph  Construction",
    "abstract": "While the potential of Open Information Extraction (Open IE) for Knowledge Graph Construction (KGC) may seem promising, we find that the alignment of Open IE extraction results with existing knowledge graphs to be inadequate. The advent of Large Language Models (LLMs), especially the commercially available OpenAI models, have reset expectations for what is possible with deep learning models and have created a new field called prompt engineering. We investigate the use of GPT models and prompt engineering for knowledge graph construction with the Wikidata knowledge graph to address a similar problem to Open IE, which we call Open Knowledge Extraction (OKE) using an approach we call the Linked Open Knowledge Extractor (LOKE, pronounced like \"Loki\"). We consider the entity linking task essential to construction of real world knowledge graphs. We merge the CaRB benchmark scoring approach with data from the TekGen dataset for the LOKE task. We then show that a well engineered prompt, paired with a naive entity linking approach (which we call LOKE-GPT), outperforms AllenAI's OpenIE 4 implementation on the OKE task, although it over-generates triples compared to the reference set due to overall triple scarcity in the TekGen set. Through an analysis of entity linkability in the CaRB dataset, as well as outputs from OpenIE 4 and LOKE-GPT, we see that LOKE-GPT and the \"silver\" TekGen triples show that the task is significantly different in content from OIE, if not structure. Through this analysis and a qualitative analysis of sentence extractions via all methods, we found that LOKE-GPT extractions are of high utility for the KGC task and suitable for use in semi-automated extraction settings. ",
    "url": "https://arxiv.org/abs/2311.09366",
    "authors": [
      "Jamie McCusker"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.09367",
    "title": "A Survey on Online User Aggression: Content Detection and Behavioural  Analysis on Social Media Platforms",
    "abstract": "The rise of social media platforms has led to an increase in cyber-aggressive behavior, encompassing a broad spectrum of hostile behavior, including cyberbullying, online harassment, and the dissemination of offensive and hate speech. These behaviors have been associated with significant societal consequences, ranging from online anonymity to real-world outcomes such as depression, suicidal tendencies, and, in some instances, offline violence. Recognizing the societal risks associated with unchecked aggressive content, this paper delves into the field of Aggression Content Detection and Behavioral Analysis of Aggressive Users, aiming to bridge the gap between disparate studies. In this paper, we analyzed the diversity of definitions and proposed a unified cyber-aggression definition. We examine the comprehensive process of Aggression Content Detection, spanning from dataset creation, feature selection and extraction, and detection algorithm development. Further, we review studies on Behavioral Analysis of Aggression that explore the influencing factors, consequences, and patterns associated with cyber-aggressive behavior. This systematic literature review is a cross-examination of content detection and behavioral analysis in the realm of cyber-aggression. The integrated investigation reveals the effectiveness of incorporating sociological insights into computational techniques for preventing cyber-aggressive behavior. Finally, the paper concludes by identifying research gaps and encouraging further progress in the unified domain of socio-computational aggressive behavior analysis. ",
    "url": "https://arxiv.org/abs/2311.09367",
    "authors": [
      "Swapnil Mane",
      "Suman Kundu",
      "Rajesh Sharma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09389",
    "title": "Neural machine translation for automated feedback on children's  early-stage writing",
    "abstract": "In this work, we address the problem of assessing and constructing feedback for early-stage writing automatically using machine learning. Early-stage writing is typically vastly different from conventional writing due to phonetic spelling and lack of proper grammar, punctuation, spacing etc. Consequently, early-stage writing is highly non-trivial to analyze using common linguistic metrics. We propose to use sequence-to-sequence models for \"translating\" early-stage writing by students into \"conventional\" writing, which allows the translated text to be analyzed using linguistic metrics. Furthermore, we propose a novel robust likelihood to mitigate the effect of noise in the dataset. We investigate the proposed methods using a set of numerical experiments and demonstrate that the conventional text can be predicted with high accuracy. ",
    "url": "https://arxiv.org/abs/2311.09389",
    "authors": [
      "Jonas Vestergaard Jensen",
      "Mikkel Jordahn",
      "Michael Riis Andersen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.09393",
    "title": "Taypsi: Static Enforcement of Privacy Policies for Policy-Agnostic  Oblivious Computation",
    "abstract": "Secure multiparty computation (MPC) techniques enable multiple parties to compute joint functions over their private data without sharing that data to other parties, typically by employing powerful cryptographic protocols to protect individual's data. One challenge when writing such functions is that most MPC languages force users to intermix programmatic and privacy concerns in a single application, making it difficult to change or audit a program's underlying privacy policy. Existing policy-agnostic MPC languages rely on run-time / dynamic enforcement to decouple privacy requirements from program logic. Unfortunately, the resulting overhead makes it difficult to scale MPC applications that manipulate structured data. This work proposes to eliminate this overhead by instead transforming programs to semantically equivalent versions that statically enforce user-provided privacy policies. We have implemented this approach in a new MPC language, called Taypsi; our experimental evaluation demonstrates that the resulting system features considerable performance improvements on a variety of MPC applications involving structured data and complex privacy polices. ",
    "url": "https://arxiv.org/abs/2311.09393",
    "authors": [
      "Qianchuan Ye",
      "Benjamin Delaware"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.09394",
    "title": "GWP-ASan: Sampling-Based Detection of Memory-Safety Bugs in Production",
    "abstract": "Despite the recent advances in pre-production bug detection, heap-use-after-free and heap-buffer-overflow bugs remain the primary problem for security, reliability, and developer productivity for applications written in C or C++, across all major software ecosystems. Memory-safe languages solve this problem when they are used, but the existing code bases consisting of billions of lines of C and C++ continue to grow, and we need additional bug detection mechanisms. This paper describes a family of tools that detect these two classes of memory-safety bugs, while running in production, at near-zero overhead. These tools combine page-granular guarded allocation and low-rate sampling. In other words, we added an \"if\" statement to a 36-year-old idea and made it work at scale. We describe the basic algorithm, several of its variants and implementations, and the results of multi-year deployments across mobile, desktop, and server applications. ",
    "url": "https://arxiv.org/abs/2311.09394",
    "authors": [
      "Kostya Serebryany",
      "Chris Kennelly",
      "Mitch Phillips",
      "Matt Denton",
      "Marco Elver",
      "Alexander Potapenko",
      "Matt Morehouse",
      "Vlad Tsyrklevich",
      "Christian Holler",
      "Julian Lettner",
      "David Kilzer",
      "Lander Brandt"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2311.09406",
    "title": "Alternatives to the Scaled Dot Product for Attention in the Transformer  Neural Network Architecture",
    "abstract": "The transformer neural network architecture uses a form of attention in which the dot product of query and key is divided by the square root of the key dimension before applying softmax. This scaling of the dot product is designed to avoid the absolute value of the dot products becoming so large that applying softmax leads to vanishing gradients. In this paper, we propose some alternative scalings, including dividing the dot product instead by the sum of the key lengths before applying softmax. We use simulated keys and queries to show that in many situations this appears to be more effective at avoiding regions where applying softmax leads to vanishing gradients. ",
    "url": "https://arxiv.org/abs/2311.09406",
    "authors": [
      "James Bernhard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.09425",
    "title": "Robust and conservative dynamical low-rank methods for the Vlasov  equation via a novel macro-micro decomposition",
    "abstract": "Dynamical low-rank (DLR) approximation has gained interest in recent years as a viable solution to the curse of dimensionality in the numerical solution of kinetic equations including the Boltzmann and Vlasov equations. These methods include the projector-splitting and Basis-update & Galerkin DLR integrators, and have shown promise at greatly improving the computational efficiency of kinetic solutions. However, this often comes at the cost of conservation of charge, current and energy. In this work we show how a novel macro-micro decomposition may be used to separate the distribution function into two components, one of which carries the conserved quantities, and the other of which is orthogonal to them. We apply DLR approximation to the latter, and thereby achieve a clean and extensible approach to a conservative DLR scheme which retains the computational advantages of the base scheme. Moreover, our decomposition is compatible with the projector-splitting integrator, and can therefore access second-order accuracy in time via a Strang splitting scheme. We describe a first-order integrator which can exactly conserve charge and either current or energy, as well as a second-order accurate integrator which exactly conserves charge and energy. To highlight the flexibility of the proposed macro-micro decomposition, we implement a pair of velocity space discretizations, and verify the claimed accuracy and conservation properties on a suite of plasma benchmark problems. ",
    "url": "https://arxiv.org/abs/2311.09425",
    "authors": [
      "Jack Coughlin",
      "Jingwei Hu",
      "Uri Shumlak"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2311.09431",
    "title": "Striped Attention: Faster Ring Attention for Causal Transformers",
    "abstract": "To help address the growing demand for ever-longer sequence lengths in transformer models, Liu et al. recently proposed Ring Attention, an exact attention algorithm capable of overcoming per-device memory bottle- necks by distributing self-attention across multiple devices. In this paper, we study the performance characteristics of Ring Attention in the important special case of causal transformer models, and identify a key workload imbal- ance due to triangular structure of causal attention computations. We propose a simple extension to Ring Attention, which we call Striped Attention to fix this imbalance. Instead of devices having contiguous subsequences, each device has a subset of tokens distributed uniformly throughout the sequence, which we demonstrate leads to more even workloads. In experiments running Striped Attention on A100 GPUs and TPUv4s, we are able to achieve up to 1.45x end-to-end throughput improvements over the original Ring Attention algorithm on causal transformer training at a sequence length of 256k. Furthermore, on 16 TPUv4 chips, we were able to achieve 1.65x speedups at sequence lengths of 786k. We release the code for our experiments as open source ",
    "url": "https://arxiv.org/abs/2311.09431",
    "authors": [
      "William Brandon",
      "Aniruddha Nrusimha",
      "Kevin Qian",
      "Zachary Ankner",
      "Tian Jin",
      "Zhiye Song",
      "Jonathan Ragan-Kelley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09433",
    "title": "Backdoor Activation Attack: Attack Large Language Models using  Activation Steering for Safety-Alignment",
    "abstract": "To ensure AI safety, instruction-tuned Large Language Models (LLMs) are specifically trained to ensure alignment, which refers to making models behave in accordance with human intentions. While these models have demonstrated commendable results on various safety benchmarks, the vulnerability of their safety alignment has not been extensively studied. This is particularly troubling given the potential harm that LLMs can inflict. Existing attack methods on LLMs often rely on poisoned training data or the injection of malicious prompts. These approaches compromise the stealthiness and generalizability of the attacks, making them susceptible to detection. Additionally, these models often demand substantial computational resources for implementation, making them less practical for real-world applications. In this work, we introduce a novel attack framework, called Backdoor Activation Attack, which injects trojan steering vectors into the activation layers of LLMs. These malicious steering vectors can be triggered at inference time to steer the models toward attacker-desired behaviors by manipulating their activations. In particular, the steering vectors are generated by taking the difference between benign and malicious activations. Then, the most effective steering vector is selected and added to the forward passes of the LLMs. Our experiment results on four primary alignment tasks show that our proposed method is highly effective and adds little or no overhead to attack efficiency. Additionally, we discuss potential countermeasures against such activation attacks. Our code and data are available at https://email-haoran-for-link. Warning: this paper contains content that can be offensive or upsetting. ",
    "url": "https://arxiv.org/abs/2311.09433",
    "authors": [
      "Haoran Wang",
      "Kai Shu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09443",
    "title": "Subtle Misogyny Detection and Mitigation: An Expert-Annotated Dataset",
    "abstract": "Using novel approaches to dataset development, the Biasly dataset captures the nuance and subtlety of misogyny in ways that are unique within the literature. Built in collaboration with multi-disciplinary experts and annotators themselves, the dataset contains annotations of movie subtitles, capturing colloquial expressions of misogyny in North American film. The dataset can be used for a range of NLP tasks, including classification, severity score regression, and text generation for rewrites. In this paper, we discuss the methodology used, analyze the annotations obtained, and provide baselines using common NLP algorithms in the context of misogyny detection and mitigation. We hope this work will promote AI for social good in NLP for bias detection, explanation, and removal. ",
    "url": "https://arxiv.org/abs/2311.09443",
    "authors": [
      "Brooklyn Sheppard",
      "Anna Richter",
      "Allison Cohen",
      "Elizabeth Allyn Smith",
      "Tamara Kneese",
      "Carolyne Pelletier",
      "Ioana Baldini",
      "Yue Dong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09445",
    "title": "A Software-Hardware Co-Optimized Toolkit for Deep Reinforcement Learning  on Heterogeneous Platforms",
    "abstract": "Deep Reinforcement Learning (DRL) is vital in various AI applications. DRL algorithms comprise diverse compute kernels, which may not be simultaneously optimized using a homogeneous architecture. However, even with available heterogeneous architectures, optimizing DRL performance remains a challenge due to the complexity of hardware and programming models employed in modern data centers. To address this, we introduce PEARL, a toolkit for composing parallel DRL systems on heterogeneous platforms consisting of general-purpose processors (CPUs) and accelerators (GPUs, FPGAs). Our innovations include: 1. A general training protocol agnostic of the underlying hardware, enabling portable implementations across various processors and accelerators. 2. Incorporation of DRL-specific scheduling optimizations within the protocol, facilitating parallelized training and enhancing the overall system performance. 3. High-level API for productive development using the toolkit. 4. Automatic optimization of DRL task-to-device assignments through performance estimation, supporting various optimization metrics including throughput and power efficiency. We showcase our toolkit through experimentation with two widely used DRL algorithms, DQN and DDPG, on two diverse heterogeneous platforms. The generated implementations outperform state-of-the-art libraries for CPU-GPU platforms by throughput improvements of up to 2.1$\\times$ and power efficiency improvements of up to 3.4$\\times$. ",
    "url": "https://arxiv.org/abs/2311.09445",
    "authors": [
      "Yuan Meng",
      "Michael Kinsner",
      "Deshanand Singh",
      "Mahesh A Iyer",
      "Viktor Prasanna"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.09456",
    "title": "DeepMartNet -- A Martingale Based Deep Neural Network Learning Method  for Dirichlet BVP and Eigenvalue Problems of Elliptic PDEs",
    "abstract": "In this paper, we propose DeepMartNet - a Martingale based deep neural network learning method for solving Dirichlet boundary value problems (BVPs) and eigenvalue problems for elliptic partial differential equations (PDEs) in high dimensions. The method is based on Varadhan's Martingale problem formulation for the BVP/eigenvalue problems where a loss function enforcing the Martingale property for the PDE solution is used for efficient optimization by sampling the stochastic processes associated with elliptic operators. High dimensional numerical results for BVPs of the Poisson-Boltzmann equation and eigenvalue problems of a Fokker-Planck equation demonstrate the capability of the proposed DeepMartNet learning method for solving high dimensional PDE problems. ",
    "url": "https://arxiv.org/abs/2311.09456",
    "authors": [
      "Wei Cai",
      "Andrew He",
      "Daniel Margolis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2311.09466",
    "title": "Soft Matching Distance: A metric on neural representations that captures  single-neuron tuning",
    "abstract": "Common measures of neural representational (dis)similarity are designed to be insensitive to rotations and reflections of the neural activation space. Motivated by the premise that the tuning of individual units may be important, there has been recent interest in developing stricter notions of representational (dis)similarity that require neurons to be individually matched across networks. When two networks have the same size (i.e. same number of neurons), a distance metric can be formulated by optimizing over neuron index permutations to maximize tuning curve alignment. However, it is not clear how to generalize this metric to measure distances between networks with different sizes. Here, we leverage a connection to optimal transport theory to derive a natural generalization based on \"soft\" permutations. The resulting metric is symmetric, satisfies the triangle inequality, and can be interpreted as a Wasserstein distance between two empirical distributions. Further, our proposed metric avoids counter-intuitive outcomes suffered by alternative approaches, and captures complementary geometric insights into neural representations that are entirely missed by rotation-invariant metrics. ",
    "url": "https://arxiv.org/abs/2311.09466",
    "authors": [
      "Meenakshi Khosla",
      "Alex H. Williams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.09468",
    "title": "Carbon Dioxide Emission Minimized Virtual Machine (VM) Placement in  Cloud-Fog Network Architecture",
    "abstract": "Cloud computing has provided economies of scale, savings, and efficiency for both individual consumers and enterprises. Its key advantage is its ability to handle increasing amounts of data and provide functionality that gives users the ability to scale their computing resources, including processing, data storage, and networking capabilities. Virtual Machines (VM), enabled via virtualization technology, allow cloud service providers to deliver their services to users. This, however, results in increasing carbon dioxide emissions from increased energy use. This paper introduces a Mixed-Integer Linear Programming (MILP) model that investigates the VM placement, focusing on the British Telecom (BT) network topology, in a cloud-fog network architecture when renewable energy sources are introduced in the fog layer located near traffic-producing sources. VMs can be placed on nodes hosted on the core, metro, and access (fog) layers. We first investigate the effect of varying traffic on IP over WDM power consumption in the backbone network and the number of optical carrier signals to serve the traffic over a period of time. We later extend the model to consider the CO2-minimized optimal virtual machine placement given the sporadic traffic quantity, and the consideration of solar renewable energy sources placed in data centers located in the access (fog) layer throughout the day, imposed on the VM and the minimum workload requirement of the VM to maintain a service level agreement (SLA). ",
    "url": "https://arxiv.org/abs/2311.09468",
    "authors": [
      "Tarek Bessalah"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2311.09473",
    "title": "JAB: Joint Adversarial Prompting and Belief Augmentation",
    "abstract": "With the recent surge of language models in different applications, attention to safety and robustness of these models has gained significant importance. Here we introduce a joint framework in which we simultaneously probe and improve the robustness of a black-box target model via adversarial prompting and belief augmentation using iterative feedback loops. This framework utilizes an automated red teaming approach to probe the target model, along with a belief augmenter to generate instructions for the target model to improve its robustness to those adversarial probes. Importantly, the adversarial model and the belief generator leverage the feedback from past interactions to improve the effectiveness of the adversarial prompts and beliefs, respectively. In our experiments, we demonstrate that such a framework can reduce toxic content generation both in dynamic cases where an adversary directly interacts with a target model and static cases where we use a static benchmark dataset to evaluate our model. ",
    "url": "https://arxiv.org/abs/2311.09473",
    "authors": [
      "Ninareh Mehrabi",
      "Palash Goyal",
      "Anil Ramakrishna",
      "Jwala Dhamala",
      "Shalini Ghosh",
      "Richard Zemel",
      "Kai-Wei Chang",
      "Aram Galstyan",
      "Rahul Gupta"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09482",
    "title": "Robust Conformal Prediction for STL Runtime Verification under  Distribution Shift",
    "abstract": "Cyber-physical systems (CPS) designed in simulators behave differently in the real-world. Once they are deployed in the real-world, we would hence like to predict system failures during runtime. We propose robust predictive runtime verification (RPRV) algorithms under signal temporal logic (STL) tasks for general stochastic CPS. The RPRV problem faces several challenges: (1) there may not be sufficient data of the behavior of the deployed CPS, (2) predictive models are based on a distribution over system trajectories encountered during the design phase, i.e., there may be a distribution shift during deployment. To address these challenges, we assume to know an upper bound on the statistical distance (in terms of an f-divergence) between the distributions at deployment and design time, and we utilize techniques based on robust conformal prediction. Motivated by our results in [1], we construct an accurate and an interpretable RPRV algorithm. We use a trajectory prediction model to estimate the system behavior at runtime and robust conformal prediction to obtain probabilistic guarantees by accounting for distribution shifts. We precisely quantify the relationship between calibration data, desired confidence, and permissible distribution shift. To the best of our knowledge, these are the first statistically valid algorithms under distribution shift in this setting. We empirically validate our algorithms on a Franka manipulator within the NVIDIA Isaac sim environment. ",
    "url": "https://arxiv.org/abs/2311.09482",
    "authors": [
      "Yiqi Zhao",
      "Bardh Hoxha",
      "Georgios Fainekos",
      "Jyotirmoy V. Deshmukh",
      "Lars Lindemann"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Logic in Computer Science (cs.LO)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.09498",
    "title": "Network Wide Evacuation Traffic Prediction in a Rapidly Intensifying  Hurricane from Traffic Detectors and Facebook Movement Data: A Deep Learning  Approach",
    "abstract": "Traffic prediction during hurricane evacuation is essential for optimizing the use of transportation infrastructures. It can reduce evacuation time by providing information on future congestion in advance. However, evacuation traffic prediction can be challenging as evacuation traffic patterns is significantly different than regular period traffic. A data-driven traffic prediction model is developed in this study by utilizing traffic detector and Facebook movement data during Hurricane Ian, a rapidly intensifying hurricane. We select 766 traffic detectors from Florida's 4 major interstates to collect traffic features. Additionally, we use Facebook movement data collected during Hurricane Ian's evacuation period. The deep-learning model is first trained on regular period (May-August 2022) data to understand regular traffic patterns and then Hurricane Ian's evacuation period data is used as test data. The model achieves 95% accuracy (RMSE = 356) during regular period, but it underperforms with 55% accuracy (RMSE = 1084) during the evacuation period. Then, a transfer learning approach is adopted where a pretrained model is used with additional evacuation related features to predict evacuation period traffic. After transfer learning, the model achieves 89% accuracy (RMSE = 514). Adding Facebook movement data further reduces model's RMSE value to 393 and increases accuracy to 93%. The proposed model is capable to forecast traffic up to 6-hours in advance. Evacuation traffic management officials can use the developed traffic prediction model to anticipate future traffic congestion in advance and take proactive measures to reduce delays during evacuation. ",
    "url": "https://arxiv.org/abs/2311.09498",
    "authors": [
      "Md Mobasshir Rashid",
      "Rezaur Rahman",
      "Samiul Hasan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.09499",
    "title": "Center Focusing Network for Real-Time LiDAR Panoptic Segmentation",
    "abstract": "LiDAR panoptic segmentation facilitates an autonomous vehicle to comprehensively understand the surrounding objects and scenes and is required to run in real time. The recent proposal-free methods accelerate the algorithm, but their effectiveness and efficiency are still limited owing to the difficulty of modeling non-existent instance centers and the costly center-based clustering modules. To achieve accurate and real-time LiDAR panoptic segmentation, a novel center focusing network (CFNet) is introduced. Specifically, the center focusing feature encoding (CFFE) is proposed to explicitly understand the relationships between the original LiDAR points and virtual instance centers by shifting the LiDAR points and filling in the center points. Moreover, to leverage the redundantly detected centers, a fast center deduplication module (CDM) is proposed to select only one center for each instance. Experiments on the SemanticKITTI and nuScenes panoptic segmentation benchmarks demonstrate that our CFNet outperforms all existing methods by a large margin and is 1.6 times faster than the most efficient method. The code is available at https://github.com/GangZhang842/CFNet. ",
    "url": "https://arxiv.org/abs/2311.09499",
    "authors": [
      "Xiaoyan Li",
      "Gang Zhang",
      "Boyue Wang",
      "Yongli Hu",
      "Baocai Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.09500",
    "title": "Pseudo-keypoints RKHS Learning for Self-supervised 6DoF Pose Estimation",
    "abstract": "This paper addresses the simulation-to-real domain gap in 6DoF PE, and proposes a novel self-supervised keypoint radial voting-based 6DoF PE framework, effectively narrowing this gap using a learnable kernel in RKHS. We formulate this domain gap as a distance in high-dimensional feature space, distinct from previous iterative matching methods. We propose an adapter network, which evolves the network parameters from the source domain, which has been massively trained on synthetic data with synthetic poses, to the target domain, which is trained on real data. Importantly, the real data training only uses pseudo-poses estimated by pseudo-keypoints, and thereby requires no real groundtruth data annotations. RKHSPose achieves state-of-the-art performance on three commonly used 6DoF PE datasets including LINEMOD (+4.2%), Occlusion LINEMOD (+2%), and YCB-Video (+3%). It also compares favorably to fully supervised methods on all six applicable BOP core datasets, achieving within -10.8% to -0.3% of the top fully supervised results. ",
    "url": "https://arxiv.org/abs/2311.09500",
    "authors": [
      "Yangzheng Wu",
      "Michael Greenspan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.09505",
    "title": "SegMix: A Simple Structure-Aware Data Augmentation Method",
    "abstract": "Interpolation-based Data Augmentation (DA) methods (Mixup) linearly interpolate the inputs and labels of two or more training examples. Mixup has more recently been adapted to the field of Natural Language Processing (NLP), mainly for sequence labeling tasks. However, such a simple adoption yields mixed or unstable improvements over the baseline models. We argue that the direct-adoption methods do not account for structures in NLP tasks. To this end, we propose SegMix, a collection of interpolation-based DA algorithms that can adapt to task-specific structures. SegMix poses fewer constraints on data structures, is robust to various hyperparameter settings, applies to more task settings, and adds little computational overhead. In the algorithm's core, we apply interpolation methods on task-specific meaningful segments, in contrast to applying them on sequences as in prior work. We find SegMix to be a flexible framework that combines rule-based DA methods with interpolation-based methods, creating interesting mixtures of DA techniques. We show that SegMix consistently improves performance over strong baseline models in Named Entity Recognition (NER) and Relation Extraction (RE) tasks, especially under data-scarce settings. Furthermore, this method is easy to implement and adds negligible training overhead. ",
    "url": "https://arxiv.org/abs/2311.09505",
    "authors": [
      "Yuxin Pei",
      "Pushkar Bhuse",
      "Zhengzhong Liu",
      "Eric Xing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.09514",
    "title": "Know Thy Neighbors: A Graph Based Approach for Effective Sensor-Based  Human Activity Recognition in Smart Homes",
    "abstract": "There has been a resurgence of applications focused on Human Activity Recognition (HAR) in smart homes, especially in the field of ambient intelligence and assisted living technologies. However, such applications present numerous significant challenges to any automated analysis system operating in the real world, such as variability, sparsity, and noise in sensor measurements. Although state-of-the-art HAR systems have made considerable strides in addressing some of these challenges, they especially suffer from a practical limitation: they require successful pre-segmentation of continuous sensor data streams before automated recognition, i.e., they assume that an oracle is present during deployment, which is capable of identifying time windows of interest across discrete sensor events. To overcome this limitation, we propose a novel graph-guided neural network approach that performs activity recognition by learning explicit co-firing relationships between sensors. We accomplish this by learning a more expressive graph structure representing the sensor network in a smart home, in a data-driven manner. Our approach maps discrete input sensor measurements to a feature space through the application of attention mechanisms and hierarchical pooling of node embeddings. We demonstrate the effectiveness of our proposed approach by conducting several experiments on CASAS datasets, showing that the resulting graph-guided neural network outperforms the state-of-the-art method for HAR in smart homes across multiple datasets and by large margins. These results are promising because they push HAR for smart homes closer to real-world applications. ",
    "url": "https://arxiv.org/abs/2311.09514",
    "authors": [
      "Srivatsa P",
      "Thomas Pl\u00f6tz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.09516",
    "title": "Real-Time Adaptive Neural Network on FPGA: Enhancing Adaptability  through Dynamic Classifier Selection",
    "abstract": "This research studies an adaptive neural network with a Dynamic Classifier Selection framework on Field-Programmable Gate Arrays (FPGAs). The evaluations are conducted across three different datasets. By adjusting parameters, the architecture surpasses all models in the ensemble set in accuracy and shows an improvement of up to 8% compared to a singular neural network implementation. The research also emphasizes considerable resource savings of up to 109.28%, achieved via partial reconfiguration rather than a traditional fixed approach. Such improved efficiency suggests that the architecture is ideal for settings limited by computational capacity, like in edge computing scenarios. The collected data highlights the architecture's two main benefits: high performance and real-world application, signifying a notable input to FPGA-based ensemble learning methods. ",
    "url": "https://arxiv.org/abs/2311.09516",
    "authors": [
      "Achraf El Bouazzaoui",
      "Abdelkader Hadjoudja",
      "Omar Mouhib"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2311.09519",
    "title": "Leveraging Code to Improve In-context Learning for Semantic Parsing",
    "abstract": "In-context learning (ICL) is an appealing approach for semantic parsing due to its few-shot nature and improved generalization. However, learning to parse to rare domain-specific languages (DSLs) from just a few demonstrations is challenging, limiting the performance of even the most capable LLMs. In this work, we improve the effectiveness of ICL for semantic parsing by (1) using general-purpose programming languages such as Python instead of DSLs, and (2) augmenting prompts with a structured domain description that includes, e.g., the available classes and functions. We show that both these changes significantly improve accuracy across three popular datasets. Combined, they lead to dramatic improvements (e.g. 7.9% to 66.5% on SMCalFlow compositional split), nearly closing the performance gap between easier i.i.d.\\ and harder compositional splits when used with a strong model, and reducing the need for a large number of demonstrations. We find that the resemblance of the target parse language to general-purpose code is a more important factor than the language's popularity in pre-training corpora. Our findings provide an improved methodology for building semantic parsers in the modern context of ICL with LLMs. ",
    "url": "https://arxiv.org/abs/2311.09519",
    "authors": [
      "Ben Bogin",
      "Shivanshu Gupta",
      "Peter Clark",
      "Ashish Sabharwal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09525",
    "title": "NGEL-SLAM: Neural Implicit Representation-based Global Consistent  Low-Latency SLAM System",
    "abstract": "Neural implicit representations have emerged as a promising solution for providing dense geometry in Simultaneous Localization and Mapping (SLAM). However, existing methods in this direction fall short in terms of global consistency and low latency. This paper presents NGEL-SLAM to tackle the above challenges. To ensure global consistency, our system leverages a traditional feature-based tracking module that incorporates loop closure. Additionally, we maintain a global consistent map by representing the scene using multiple neural implicit fields, enabling quick adjustment to the loop closure. Moreover, our system allows for fast convergence through the use of octree-based implicit representations. The combination of rapid response to loop closure and fast convergence makes our system a truly low-latency system that achieves global consistency. Our system enables rendering high-fidelity RGB-D images, along with extracting dense and complete surfaces. Experiments on both synthetic and real-world datasets suggest that our system achieves state-of-the-art tracking and mapping accuracy while maintaining low latency. ",
    "url": "https://arxiv.org/abs/2311.09525",
    "authors": [
      "Yunxuan Mao",
      "Xuan Yu",
      "Kai Wang",
      "Yue Wang",
      "Rong Xiong",
      "Yiyi Liao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.09529",
    "title": "TransCrimeNet: A Transformer-Based Model for Text-Based Crime Prediction  in Criminal Networks",
    "abstract": "This paper presents TransCrimeNet, a novel transformer-based model for predicting future crimes in criminal networks from textual data. Criminal network analysis has become vital for law enforcement agencies to prevent crimes. However, existing graph-based methods fail to effectively incorporate crucial textual data like social media posts and interrogation transcripts that provide valuable insights into planned criminal activities. To address this limitation, we develop TransCrimeNet which leverages the representation learning capabilities of transformer models like BERT to extract features from unstructured text data. These text-derived features are fused with graph embeddings of the criminal network for accurate prediction of future crimes. Extensive experiments on real-world criminal network datasets demonstrate that TransCrimeNet outperforms previous state-of-the-art models by 12.7\\% in F1 score for crime prediction. The results showcase the benefits of combining textual and graph-based features for actionable insights to disrupt criminal enterprises. ",
    "url": "https://arxiv.org/abs/2311.09529",
    "authors": [
      "Chen Yang"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2311.09537",
    "title": "Future Full-Ocean Deep SSPs Prediction based on Hierarchical Long  Short-Term Memory Neural Networks",
    "abstract": "The spatial-temporal distribution of underwater sound velocity affects the propagation mode of underwater acoustic signals. Therefore, rapid estimation and prediction of underwater sound velocity distribution is crucial for providing underwater positioning, navigation and timing (PNT) services. Currently, sound speed profile (SSP) inversion methods have a faster time response rate compared to direct measurement methods, however, most SSP inversion methods focus on constructing spatial dimensional sound velocity fields and are highly dependent on sonar observation data, thus high requirements have been placed on observation data sources. To explore the distribution pattern of sound velocity in the time dimension and achieve future SSP prediction without sonar observation data, we propose a hierarchical long short-term memory (H-LSTM) neural network for SSP prediction. By our SSP prediction method, the sound speed distribution could be estimated without any on-site data measurement process, so that the time efficiency could be greatly improved. Through comparing with other state-of-the-art methods, H-LSTM has better accuracy performance on prediction of monthly average sound velocity distribution, which is less than 1 m/s in different depth layers. ",
    "url": "https://arxiv.org/abs/2311.09537",
    "authors": [
      "Jiajun Lu",
      "Hao Zhang",
      "Pengfei Wu",
      "Sijia Li",
      "Wei Huang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.09538",
    "title": "Reducing Privacy Risks in Online Self-Disclosures with Language Models",
    "abstract": "Self-disclosure, while being common and rewarding in social media interaction, also poses privacy risks. In this paper, we take the initiative to protect the user-side privacy associated with online self-disclosure through identification and abstraction. We develop a taxonomy of 19 self-disclosure categories, and curate a large corpus consisting of 4.8K annotated disclosure spans. We then fine-tune a language model for identification, achieving over 75% in Token F$_1$. We further conduct a HCI user study, with 82\\% of participants viewing the model positively, highlighting its real world applicability. Motivated by the user feedback, we introduce the task of self-disclosure abstraction. We experiment with both one-span abstraction and three-span abstraction settings, and explore multiple fine-tuning strategies. Our best model can generate diverse abstractions that moderately reduce privacy risks while maintaining high utility according to human evaluation. ",
    "url": "https://arxiv.org/abs/2311.09538",
    "authors": [
      "Yao Dou",
      "Isadora Krsek",
      "Tarek Naous",
      "Anubha Kabra",
      "Sauvik Das",
      "Alan Ritter",
      "Wei Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2311.09566",
    "title": "A Knowledge Distillation Approach for Sepsis Outcome Prediction from  Multivariate Clinical Time Series",
    "abstract": "Sepsis is a life-threatening condition triggered by an extreme infection response. Our objective is to forecast sepsis patient outcomes using their medical history and treatments, while learning interpretable state representations to assess patients' risks in developing various adverse outcomes. While neural networks excel in outcome prediction, their limited interpretability remains a key issue. In this work, we use knowledge distillation via constrained variational inference to distill the knowledge of a powerful \"teacher\" neural network model with high predictive power to train a \"student\" latent variable model to learn interpretable hidden state representations to achieve high predictive performance for sepsis outcome prediction. Using real-world data from the MIMIC-IV database, we trained an LSTM as the \"teacher\" model to predict mortality for sepsis patients, given information about their recent history of vital signs, lab values and treatments. For our student model, we use an autoregressive hidden Markov model (AR-HMM) to learn interpretable hidden states from patients' clinical time series, and use the posterior distribution of the learned state representations to predict various downstream outcomes, including hospital mortality, pulmonary edema, need for diuretics, dialysis, and mechanical ventilation. Our results show that our approach successfully incorporates the constraint to achieve high predictive power similar to the teacher model, while maintaining the generative performance. ",
    "url": "https://arxiv.org/abs/2311.09566",
    "authors": [
      "Anna Wong",
      "Shu Ge",
      "Nassim Oufattole",
      "Adam Dejl",
      "Megan Su",
      "Ardavan Saeedi",
      "Li-wei H. Lehman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.09584",
    "title": "A Dichotomy Hierarchy Characterizing Linear Time Subgraph Counting in  Bounded Degeneracy Graphs",
    "abstract": "Subgraph and homomorphism counting are fundamental algorithmic problems. Given a constant-sized pattern graph $H$ and a large input graph $G$, we wish to count the number of $H$-homomorphisms/subgraphs in $G$. Given the massive sizes of real-world graphs and the practical importance of counting problems, we focus on when (near) linear time algorithms are possible. The seminal work of Chiba-Nishizeki (SICOMP 1985) shows that for bounded degeneracy graphs $G$, clique and $4$-cycle counting can be done linear time. Recent works (Bera et al, SODA 2021, JACM 2022) show a dichotomy theorem characterizing the patterns $H$ for which $H$-homomorphism counting is possible in linear time, for bounded degeneracy inputs $G$. At the other end, Ne\\v{s}et\\v{r}il and Ossona de Mendez used their deep theory of \"sparsity\" to define bounded expansion graphs. They prove that, for all $H$, $H$-homomorphism counting can be done in linear time for bounded expansion inputs. What lies between? For a specific $H$, can we characterize input classes where $H$-homomorphism counting is possible in linear time? We discover a hierarchy of dichotomy theorems that precisely answer the above questions. We show the existence of an infinite sequence of graph classes $\\mathcal{G}_0$ $\\supseteq$ $\\mathcal{G}_1$ $\\supseteq$ ... $\\supseteq$ $\\mathcal{G}_\\infty$ where $\\mathcal{G}_0$ is the class of bounded degeneracy graphs, and $\\mathcal{G}_\\infty$ is the class of bounded expansion graphs. Fix any constant sized pattern graph $H$. Let $LICL(H)$ denote the length of the longest induced cycle in $H$. We prove the following. If $LICL(H) < 3(r+2)$, then $H$-homomorphisms can be counted in linear time for inputs in $\\mathcal{G}_r$. If $LICL(H) \\geq 3(r+2)$, then $H$-homomorphism counting on inputs from $\\mathcal{G}_r$ takes $\\Omega(m^{1+\\gamma})$ time. We prove similar dichotomy theorems for subgraph counting. ",
    "url": "https://arxiv.org/abs/2311.09584",
    "authors": [
      "Daniel Paul-Pena",
      "C. Seshadhri"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2311.09593",
    "title": "Multi-Step Dialogue Workflow Action Prediction",
    "abstract": "In task-oriented dialogue, a system often needs to follow a sequence of actions, called a workflow, that complies with a set of guidelines in order to complete a task. In this paper, we propose the novel problem of multi-step workflow action prediction, in which the system predicts multiple future workflow actions. Accurate prediction of multiple steps allows for multi-turn automation, which can free up time to focus on more complex tasks. We propose three modeling approaches that are simple to implement yet lead to more action automation: 1) fine-tuning on a training dataset, 2) few-shot in-context learning leveraging retrieval and large language model prompting, and 3) zero-shot graph traversal, which aggregates historical action sequences into a graph for prediction. We show that multi-step action prediction produces features that improve accuracy on downstream dialogue tasks like predicting task success, and can increase automation of steps by 20% without requiring as much feedback from a human overseeing the system. ",
    "url": "https://arxiv.org/abs/2311.09593",
    "authors": [
      "Ramya Ramakrishnan",
      "Ethan Elenberg",
      "Hashan Narangodage",
      "Ryan McDonald"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.09601",
    "title": "Code Models are Zero-shot Precondition Reasoners",
    "abstract": "One of the fundamental skills required for an agent acting in an environment to complete tasks is the ability to understand what actions are plausible at any given point. This work explores a novel use of code representations to reason about action preconditions for sequential decision making tasks. Code representations offer the flexibility to model procedural activities and associated constraints as well as the ability to execute and verify constraint satisfaction. Leveraging code representations, we extract action preconditions from demonstration trajectories in a zero-shot manner using pre-trained code models. Given these extracted preconditions, we propose a precondition-aware action sampling strategy that ensures actions predicted by a policy are consistent with preconditions. We demonstrate that the proposed approach enhances the performance of few-shot policy learning approaches across task-oriented dialog and embodied textworld benchmarks. ",
    "url": "https://arxiv.org/abs/2311.09601",
    "authors": [
      "Lajanugen Logeswaran",
      "Sungryull Sohn",
      "Yiwei Lyu",
      "Anthony Zhe Liu",
      "Dong-Ki Kim",
      "Dongsub Shim",
      "Moontae Lee",
      "Honglak Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.09614",
    "title": "Comprehensive Evaluation and Insights into the Use of Deep Neural  Networks to Detect and Quantify Lymphoma Lesions in PET/CT Images",
    "abstract": "This study performs comprehensive evaluation of four neural network architectures (UNet, SegResNet, DynUNet, and SwinUNETR) for lymphoma lesion segmentation from PET/CT images. These networks were trained, validated, and tested on a diverse, multi-institutional dataset of 611 cases. Internal testing (88 cases; total metabolic tumor volume (TMTV) range [0.52, 2300] ml) showed SegResNet as the top performer with a median Dice similarity coefficient (DSC) of 0.76 and median false positive volume (FPV) of 4.55 ml; all networks had a median false negative volume (FNV) of 0 ml. On the unseen external test set (145 cases with TMTV range: [0.10, 2480] ml), SegResNet achieved the best median DSC of 0.68 and FPV of 21.46 ml, while UNet had the best FNV of 0.41 ml. We assessed reproducibility of six lesion measures, calculated their prediction errors, and examined DSC performance in relation to these lesion measures, offering insights into segmentation accuracy and clinical relevance. Additionally, we introduced three lesion detection criteria, addressing the clinical need for identifying lesions, counting them, and segmenting based on metabolic characteristics. We also performed expert intra-observer variability analysis revealing the challenges in segmenting ``easy'' vs. ``hard'' cases, to assist in the development of more resilient segmentation algorithms. Finally, we performed inter-observer agreement assessment underscoring the importance of a standardized ground truth segmentation protocol involving multiple expert annotators. Code is available at: https://github.com/microsoft/lymphoma-segmentation-dnn ",
    "url": "https://arxiv.org/abs/2311.09614",
    "authors": [
      "Shadab Ahamed",
      "Yixi Xu",
      "Claire Gowdy",
      "Joo H. O",
      "Ingrid Bloise",
      "Don Wilson",
      "Patrick Martineau",
      "Fran\u00e7ois B\u00e9nard",
      "Fereshteh Yousefirizi",
      "Rahul Dodhia",
      "Juan M. Lavista",
      "William B. Weeks",
      "Carlos F. Uribe",
      "Arman Rahmim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.09615",
    "title": "On Retrieval Augmentation and the Limitations of Language Model Training",
    "abstract": "Augmenting a language model (LM) with $k$-nearest neighbors (kNN) retrieval on its training data alone can decrease its perplexity, though the underlying reasons for this remains elusive. In this work, we first rule out one previously posited possibility -- the \"softmax bottleneck.\" We further identify the MLP hurdle phenomenon, where the final MLP layer in LMs may impede LM optimization early on. We explore memorization and generalization in language models with two new datasets, where advanced model like GPT-3.5-turbo find generalizing to irrelevant information in the training data challenging. However, incorporating kNN retrieval to vanilla GPT-2 117M can consistently improve performance in this setting. ",
    "url": "https://arxiv.org/abs/2311.09615",
    "authors": [
      "Ting-Rui Chiang",
      "Xinyan Velocity Yu",
      "Joshua Robinson",
      "Ollie Liu",
      "Isabelle Lee",
      "Dani Yogatama"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09620",
    "title": "GAIA: Delving into Gradient-based Attribution Abnormality for  Out-of-distribution Detection",
    "abstract": "Detecting out-of-distribution (OOD) examples is crucial to guarantee the reliability and safety of deep neural networks in real-world settings. In this paper, we offer an innovative perspective on quantifying the disparities between in-distribution (ID) and OOD data -- analyzing the uncertainty that arises when models attempt to explain their predictive decisions. This perspective is motivated by our observation that gradient-based attribution methods encounter challenges in assigning feature importance to OOD data, thereby yielding divergent explanation patterns. Consequently, we investigate how attribution gradients lead to uncertain explanation outcomes and introduce two forms of abnormalities for OOD detection: the zero-deflation abnormality and the channel-wise average abnormality. We then propose GAIA, a simple and effective approach that incorporates Gradient Abnormality Inspection and Aggregation. The effectiveness of GAIA is validated on both commonly utilized (CIFAR) and large-scale (ImageNet-1k) benchmarks. Specifically, GAIA reduces the average FPR95 by 23.10% on CIFAR10 and by 45.41% on CIFAR100 compared to advanced post-hoc methods. ",
    "url": "https://arxiv.org/abs/2311.09620",
    "authors": [
      "Jinggang Chen",
      "Junjie Li",
      "Xiaoyang Qu",
      "Jianzong Wang",
      "Jiguang Wan",
      "Jing Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.09630",
    "title": "From Scroll to Misbelief: Modeling the Unobservable Susceptibility to  Misinformation on Social Media",
    "abstract": "Susceptibility to misinformation describes the extent to believe unverifiable claims, which is hidden in people's mental process and infeasible to observe. Existing susceptibility studies heavily rely on the self-reported beliefs, making any downstream applications on susceptability hard to scale. To address these limitations, in this work, we propose a computational model to infer users' susceptibility levels given their activities. Since user's susceptibility is a key indicator for their reposting behavior, we utilize the supervision from the observable sharing behavior to infer the underlying susceptibility tendency. The evaluation shows that our model yields estimations that are highly aligned with human judgment on users' susceptibility level comparisons. Building upon such large-scale susceptibility labeling, we further conduct a comprehensive analysis of how different social factors relate to susceptibility. We find that political leanings and psychological factors are associated with susceptibility in varying degrees. ",
    "url": "https://arxiv.org/abs/2311.09630",
    "authors": [
      "Yanchen Liu",
      "Mingyu Derek Ma",
      "Wenna Qin",
      "Azure Zhou",
      "Jiaao Chen",
      "Weiyan Shi",
      "Wei Wang",
      "Diyi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.09635",
    "title": "Evaluating In-Context Learning of Libraries for Code Generation",
    "abstract": "Contemporary Large Language Models (LLMs) exhibit a high degree of code generation and comprehension capability. A particularly promising area is their ability to interpret code modules from unfamiliar libraries for solving user-instructed tasks. Recent work has shown that large proprietary LLMs can learn novel library usage in-context from demonstrations. These results raise several open questions: whether demonstrations of library usage is required, whether smaller (and more open) models also possess such capabilities, etc. In this work, we take a broader approach by systematically evaluating a diverse array of LLMs across three scenarios reflecting varying levels of domain specialization to understand their abilities and limitations in generating code based on libraries defined in-context. Our results show that even smaller open-source LLMs like Llama-2 and StarCoder demonstrate an adept understanding of novel code libraries based on specification presented in-context. Our findings further reveal that LLMs exhibit a surprisingly high proficiency in learning novel library modules even when provided with just natural language descriptions or raw code implementations of the functions, which are often cheaper to obtain than demonstrations. Overall, our results pave the way for harnessing LLMs in more adaptable and dynamic coding environments. ",
    "url": "https://arxiv.org/abs/2311.09635",
    "authors": [
      "Arkil Patel",
      "Siva Reddy",
      "Dzmitry Bahdanau",
      "Pradeep Dasigi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09648",
    "title": "Event Causality Is Key to Computational Story Understanding",
    "abstract": "Psychological research suggests the central role of event causality in human story understanding. Further, event causality has been heavily utilized in symbolic story generation. However, few machine learning systems for story understanding employ event causality, partially due to the lack of reliable methods for identifying open-world causal event relations. Leveraging recent progress in large language models (LLMs), we present the first method for event causality identification that leads to material improvements in computational story understanding. We design specific prompts for extracting event causal relations from GPT. Against human-annotated event causal relations in the GLUCOSE dataset, our technique performs on par with supervised models, while being easily generalizable to stories of different types and lengths. The extracted causal relations lead to 5.7\\% improvements on story quality evaluation and 8.7\\% on story video-text alignment. Our findings indicate enormous untapped potential for event causality in computational story understanding. ",
    "url": "https://arxiv.org/abs/2311.09648",
    "authors": [
      "Yidan Sun",
      "Qin Chao",
      "Boyang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09662",
    "title": "AXI-REALM: A Lightweight and Modular Interconnect Extension for Traffic  Regulation and Monitoring of Heterogeneous Real-Time SoCs",
    "abstract": "The increasing demand for heterogeneous functionality in the automotive industry and the evolution of chip manufacturing processes have led to the transition from federated to integrated critical real-time embedded systems (CRTESs). This leads to higher integration challenges of conventional timing predictability techniques due to access contention on shared resources, which can be resolved by providing system-level observability and controllability in hardware. We focus on the interconnect as a shared resource and propose AXI-REALM, a lightweight, modular, and technology-independent real-time extension to industry-standard AXI4 interconnects, available open-source. AXI-REALM uses a credit-based mechanism to distribute and control the bandwidth in a multi-subordinate system on periodic time windows, proactively prevents denial of service from malicious actors in the system, and tracks each manager's access and interference statistics for optimal budget and period selection. We provide detailed performance and implementation cost assessment in a 12nm node and an end-to-end functional case study implementing AXI-REALM into an open-source Linux-capable RISC-V SoC. In a system with a general-purpose core and a hardware accelerator's DMA engine causing interference on the interconnect, AXI-REALM achieves fair bandwidth distribution among managers, allowing the core to recover 68.2 % of its performance compared to the case without contention. Moreover, near-ideal performance (above 95 %) can be achieved by distributing the available bandwidth in favor of the core, improving the worst-case memory access latency from 264 to below eight cycles. Our approach minimizes buffering compared to other solutions and introduces only 2.45 % area overhead compared to the original SoC. ",
    "url": "https://arxiv.org/abs/2311.09662",
    "authors": [
      "Thomas Benz",
      "Alessandro Ottaviano",
      "Robert Balas",
      "Angelo Garofalo",
      "Francesco Restuccia",
      "Alessandro Biondi",
      "Luca Benini"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2311.09667",
    "title": "Repetitive nonoverlapping sequential pattern mining",
    "abstract": "Sequential pattern mining (SPM) is an important branch of knowledge discovery that aims to mine frequent sub-sequences (patterns) in a sequential database. Various SPM methods have been investigated, and most of them are classical SPM methods, since these methods only consider whether or not a given pattern occurs within a sequence. Classical SPM can only find the common features of sequences, but it ignores the number of occurrences of the pattern in each sequence, i.e., the degree of interest of specific users. To solve this problem, this paper addresses the issue of repetitive nonoverlapping sequential pattern (RNP) mining and proposes the RNP-Miner algorithm. To reduce the number of candidate patterns, RNP-Miner adopts an itemset pattern join strategy. To improve the efficiency of support calculation, RNP-Miner utilizes the candidate support calculation algorithm based on the position dictionary. To validate the performance of RNP-Miner, 10 competitive algorithms and 20 sequence databases were selected. The experimental results verify that RNP-Miner outperforms the other algorithms, and using RNPs can achieve a better clustering performance than raw data and classical frequent patterns. All the algorithms were developed using the PyCharm environment and can be downloaded from https://github.com/wuc567/Pattern-Mining/tree/master/RNP-Miner. ",
    "url": "https://arxiv.org/abs/2311.09667",
    "authors": [
      "Meng Geng",
      "Youxi Wu",
      "Yan Li",
      "Jing Liu",
      "Philippe Fournier-Viger",
      "Xingquan Zhu",
      "Xindong Wu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2311.09671",
    "title": "Robust Contrastive Learning With Theory Guarantee",
    "abstract": "Contrastive learning (CL) is a self-supervised training paradigm that allows us to extract meaningful features without any label information. A typical CL framework is divided into two phases, where it first tries to learn the features from unlabelled data, and then uses those features to train a linear classifier with the labeled data. While a fair amount of existing theoretical works have analyzed how the unsupervised loss in the first phase can support the supervised loss in the second phase, none has examined the connection between the unsupervised loss and the robust supervised loss, which can shed light on how to construct an effective unsupervised loss for the first phase of CL. To fill this gap, our work develops rigorous theories to dissect and identify which components in the unsupervised loss can help improve the robust supervised loss and conduct proper experiments to verify our findings. ",
    "url": "https://arxiv.org/abs/2311.09671",
    "authors": [
      "Ngoc N. Tran",
      "Lam Tran",
      "Hoang Phan",
      "Anh Bui",
      "Tung Pham",
      "Toan Tran",
      "Dinh Phung",
      "Trung Le"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.09675",
    "title": "Where Do People Tell Stories Online? Story Detection Across Online  Communities",
    "abstract": "People share stories online for a myriad of purposes, whether as a means of self-disclosure, processing difficult personal experiences, providing needed information or entertainment, or persuading others to share their beliefs. Better understanding of online storytelling can illuminate the dynamics of social movements, sensemaking practices, persuasion strategies, and more. However, unlike other media such as books and visual content where the narrative nature of the content is often overtly signaled at the document level, studying storytelling in online communities is challenging due to the mixture of storytelling and non-storytelling behavior, which can be interspersed within documents and across diverse topics and settings. We introduce a codebook and create the Storytelling in Online Communities Corpus, an expert-annotated dataset of 502 English-language posts and comments with labeled story and event spans. Using our corpus, we train and evaluate an online story detection model, which we use to investigate the role storytelling of in different social contexts. We identify distinctive features of online storytelling, the prevalence of storytelling among different communities, and the conversational patterns of storytelling. ",
    "url": "https://arxiv.org/abs/2311.09675",
    "authors": [
      "Maria Antoniak",
      "Joel Mire",
      "Maarten Sap",
      "Elliott Ash",
      "Andrew Piper"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09690",
    "title": "CDMPP: A Device-Model Agnostic Framework for Latency Prediction of  Tensor Programs",
    "abstract": "Deep Neural Networks (DNNs) have shown excellent performance in a wide range of machine learning applications. Knowing the latency of running a DNN model or tensor program on a specific device is useful in various tasks, such as DNN graph- or tensor-level optimization and device selection. Considering the large space of DNN models and devices that impede direct profiling of all combinations, recent efforts focus on building a predictor to model the performance of DNN models on different devices. However, none of the existing attempts have achieved a cost model that can accurately predict the performance of various tensor programs while supporting both training and inference accelerators. We propose CDMPP, an efficient tensor program latency prediction framework for both cross-model and cross-device prediction. We design an informative but efficient representation of tensor programs, called compact ASTs, and a pre-order-based positional encoding method, to capture the internal structure of tensor programs. We develop a domain-adaption-inspired method to learn domain-invariant representations and devise a KMeans-based sampling algorithm, for the predictor to learn from different domains (i.e., different DNN operators and devices). Our extensive experiments on a diverse range of DNN models and devices demonstrate that CDMPP significantly outperforms state-of-the-art baselines with 14.03% and 10.85% prediction error for cross-model and cross-device prediction, respectively, and one order of magnitude higher training efficiency. The implementation and the expanded dataset are available at https://github.com/joapolarbear/cdmpp. ",
    "url": "https://arxiv.org/abs/2311.09690",
    "authors": [
      "Hanpeng Hu",
      "Junwei Su",
      "Juntao Zhao",
      "Yanghua Peng",
      "Yibo Zhu",
      "Haibin Lin",
      "Chuan Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2311.09694",
    "title": "Whispers of Doubt Amidst Echoes of Triumph in NLP Robustness",
    "abstract": "Are the longstanding robustness issues in NLP resolved by today's larger and more performant models? To address this question, we conduct a thorough investigation using 19 models of different sizes spanning different architectural choices and pretraining objectives. We conduct evaluations using (a) OOD and challenge test sets, (b) CheckLists, (c) contrast sets, and (d) adversarial inputs. Our analysis reveals that not all OOD tests provide further insight into robustness. Evaluating with CheckLists and contrast sets shows significant gaps in model performance; merely scaling models does not make them sufficiently robust. Finally, we point out that current approaches for adversarial evaluations of models are themselves problematic: they can be easily thwarted, and in their current forms, do not represent a sufficiently deep probe of model robustness. We conclude that not only is the question of robustness in NLP as yet unresolved, but even some of the approaches to measure robustness need to be reassessed. ",
    "url": "https://arxiv.org/abs/2311.09694",
    "authors": [
      "Ashim Gupta",
      "Rishanth Rajendhran",
      "Nathan Stringham",
      "Vivek Srikumar",
      "Ana Marasovi\u0107"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09708",
    "title": "A Self-enhancement Multitask Framework for Unsupervised Aspect Category  Detection",
    "abstract": "Our work addresses the problem of unsupervised Aspect Category Detection using a small set of seed words. Recent works have focused on learning embedding spaces for seed words and sentences to establish similarities between sentences and aspects. However, aspect representations are limited by the quality of initial seed words, and model performances are compromised by noise. To mitigate this limitation, we propose a simple framework that automatically enhances the quality of initial seed words and selects high-quality sentences for training instead of using the entire dataset. Our main concepts are to add a number of seed words to the initial set and to treat the task of noise resolution as a task of augmenting data for a low-resource task. In addition, we jointly train Aspect Category Detection with Aspect Term Extraction and Aspect Term Polarity to further enhance performance. This approach facilitates shared representation learning, allowing Aspect Category Detection to benefit from the additional guidance offered by other tasks. Extensive experiments demonstrate that our framework surpasses strong baselines on standard datasets. ",
    "url": "https://arxiv.org/abs/2311.09708",
    "authors": [
      "Thi-Nhung Nguyen",
      "Hoang Ngo",
      "Kiem-Hieu Nguyen",
      "Tuan-Dung Cao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09711",
    "title": "Second-order Rate Analysis of a Two-user Gaussian Interference Channel  with Heterogeneous Blocklength Constraints",
    "abstract": "We consider a two-user Gaussian interference channel with heterogeneous blocklength constraints (HB-GIC), strong interference, and two private messages. We propose to apply the successive interference cancellation with early decoding, i.e., decoding a message with a number of received symbols less than the blocklength at the receiver. We determine the necessary number of received symbols to achieve successful decoding of the longer codeword that satisfies the input power constraints and target average error probability constraints. To attain the results, we investigate the dependence testing bound analysis over an independent and identically distributed (i.i.d.) Gaussian input. Besides, we derive the second-order achievable rate region of the considered HB-GIC. By numerical results based on the rate-profile approach, we compare the derived second-order rate region to the first-order one, which shows the rate back-off of the considered model due to the impact of finite blocklength. ",
    "url": "https://arxiv.org/abs/2311.09711",
    "authors": [
      "Kailun Dong",
      "Pin-Hsun Lin",
      "Marcel Mross",
      "Eduard A. Jorswieck"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2311.09726",
    "title": "MS-Former: Memory-Supported Transformer for Weakly Supervised Change  Detection with Patch-Level Annotations",
    "abstract": "Fully supervised change detection methods have achieved significant advancements in performance, yet they depend severely on acquiring costly pixel-level labels. Considering that the patch-level annotations also contain abundant information corresponding to both changed and unchanged objects in bi-temporal images, an intuitive solution is to segment the changes with patch-level annotations. How to capture the semantic variations associated with the changed and unchanged regions from the patch-level annotations to obtain promising change results is the critical challenge for the weakly supervised change detection task. In this paper, we propose a memory-supported transformer (MS-Former), a novel framework consisting of a bi-directional attention block (BAB) and a patch-level supervision scheme (PSS) tailored for weakly supervised change detection with patch-level annotations. More specifically, the BAM captures contexts associated with the changed and unchanged regions from the temporal difference features to construct informative prototypes stored in the memory bank. On the other hand, the BAM extracts useful information from the prototypes as supplementary contexts to enhance the temporal difference features, thereby better distinguishing changed and unchanged regions. After that, the PSS guides the network learning valuable knowledge from the patch-level annotations, thus further elevating the performance. Experimental results on three benchmark datasets demonstrate the effectiveness of our proposed method in the change detection task. The demo code for our work will be publicly available at \\url{https://github.com/guanyuezhen/MS-Former}. ",
    "url": "https://arxiv.org/abs/2311.09726",
    "authors": [
      "Zhenglai Li",
      "Chang Tang",
      "Xinwang Liu",
      "Changdong Li",
      "Xianju Li",
      "Wei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.09733",
    "title": "MOKA: Moral Knowledge Augmentation for Moral Event Extraction",
    "abstract": "News media employ moral language to create memorable stories, and readers often engage with the content that align with their values. Moral theories have been applied to news analysis studying moral values in isolation, while the intricate dynamics among participating entities in shaping moral events have been overlooked. This is mainly due to the use of obscure language to conceal evident ideology and values, coupled with the insufficient moral reasoning capability in most existing NLP systems, where LLMs are no exception. To study this phenomenon, we first annotate a new dataset, MORAL EVENTS, consisting of 5,494 structured annotations on 474 news articles by diverse US media across the political spectrum. We further propose MOKA, a moral event extraction framework with MOral Knowledge Augmentation, that leverages knowledge derived from moral words and moral scenarios. Experimental results show that MOKA outperforms competitive baselines across three moral event understanding tasks. Further analyses illuminate the selective reporting of moral events by media outlets of different ideological leanings, suggesting the significance of event-level morality analysis in news. Our datasets and codebase are available at https://github.com/launchnlp/MOKA. ",
    "url": "https://arxiv.org/abs/2311.09733",
    "authors": [
      "Xinliang Frederick Zhang",
      "Winston Wu",
      "Nick Beauchamp",
      "Lu Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09756",
    "title": "FairytaleCQA: Integrating a Commonsense Knowledge Graph into Children's  Storybook Narratives",
    "abstract": "AI models (including LLM) often rely on narrative question-answering (QA) datasets to provide customized QA functionalities to support downstream children education applications; however, existing datasets only include QA pairs that are grounded within the given storybook content, but children can learn more when teachers refer the storybook content to real-world knowledge (e.g., commonsense knowledge). We introduce the FairytaleCQA dataset, which is annotated by children education experts, to supplement 278 storybook narratives with educationally appropriate commonsense knowledge. The dataset has 5,868 QA pairs that not only originate from the storybook narrative but also contain the commonsense knowledge grounded by an external knowledge graph (i.e., ConceptNet). A follow-up experiment shows that a smaller model (T5-large) fine-tuned with FairytaleCQA reliably outperforms much larger prompt-engineered LLM (e.g., GPT-4) in this new QA-pair generation task (QAG). This result suggests that: 1) our dataset brings novel challenges to existing LLMs, and 2) human experts' data annotation are still critical as they have much nuanced knowledge that LLMs do not know in the children educational domain. ",
    "url": "https://arxiv.org/abs/2311.09756",
    "authors": [
      "Jiaju Chen",
      "Yuxuan Lu",
      "Shao Zhang",
      "Bingsheng Yao",
      "Yuanzhe Dong",
      "Ying Xu",
      "Yunyao Li",
      "Qianwen Wang",
      "Dakuo Wang",
      "Yuling Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09757",
    "title": "UFPS: A unified framework for partially-annotated federated segmentation  in heterogeneous data distribution",
    "abstract": "Partially supervised segmentation is a label-saving method based on datasets with fractional classes labeled and intersectant. However, it is still far from landing on real-world medical applications due to privacy concerns and data heterogeneity. As a remedy without privacy leakage, federated partially supervised segmentation (FPSS) is formulated in this work. The main challenges for FPSS are class heterogeneity and client drift. We propose a Unified Federated Partially-labeled Segmentation (UFPS) framework to segment pixels within all classes for partially-annotated datasets by training a totipotential global model without class collision. Our framework includes Unified Label Learning and sparsed Unified Sharpness Aware Minimization for unification of class and feature space, respectively. We find that vanilla combinations for traditional methods in partially supervised segmentation and federated learning are mainly hampered by class collision through empirical study. Our comprehensive experiments on real medical datasets demonstrate better deconflicting and generalization ability of UFPS compared with modified methods. ",
    "url": "https://arxiv.org/abs/2311.09757",
    "authors": [
      "Le Jiang",
      "Li Yan Ma",
      "Tie Yong Zeng",
      "Shi Hui Ying"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.09761",
    "title": "MAFALDA: A Benchmark and Comprehensive Study of Fallacy Detection and  Classification",
    "abstract": "Fallacies can be used to spread disinformation, fake news, and propaganda, underlining the importance of their detection. Automated detection and classification of fallacies, however, remain challenging, mainly because of the innate subjectivity of the task and the need for a comprehensive, unified approach in existing research. Addressing these limitations, our study introduces a novel taxonomy of fallacies that aligns and refines previous classifications, a new annotation scheme tailored for subjective NLP tasks, and a new evaluation method designed to handle subjectivity, adapted to precision, recall, and F1-Score metrics. Using our annotation scheme, the paper introduces MAFALDA (Multi-level Annotated FALlacy DAtaset), a gold standard dataset. MAFALDA is based on examples from various previously existing fallacy datasets under our unified taxonomy across three levels of granularity. We then evaluate several language models under a zero-shot learning setting using MAFALDA to assess their fallacy detection and classification capability. Our comprehensive evaluation not only benchmarks the performance of these models but also provides valuable insights into their strengths and limitations in addressing fallacious reasoning. ",
    "url": "https://arxiv.org/abs/2311.09761",
    "authors": [
      "Chadi Helwe",
      "Tom Calamai",
      "Pierre-Henri Paris",
      "Chlo\u00e9 Clavel",
      "Fabian Suchanek"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.09763",
    "title": "Test-time Backdoor Mitigation for Black-Box Large Language Models with  Defensive Demonstrations",
    "abstract": "Existing studies in backdoor defense have predominantly focused on the training phase, overlooking the critical aspect of testing time defense. This gap becomes particularly pronounced in the context of Large Language Models (LLMs) deployed as Web Services, which typically offer only black-box access, rendering training-time defenses impractical. To bridge this gap, our work introduces defensive demonstrations, an innovative backdoor defense strategy for blackbox large language models. Our method involves identifying the task and retrieving task-relevant demonstrations from an uncontaminated pool. These demonstrations are then combined with user queries and presented to the model during testing, without requiring any modifications/tuning to the black-box model or insights into its internal mechanisms. Defensive demonstrations are designed to counteract the adverse effects of triggers, aiming to recalibrate and correct the behavior of poisoned models during test-time evaluations. Extensive experiments show that defensive demonstrations are effective in defending both instance-level and instruction-level backdoor attacks, not only rectifying the behavior of poisoned models but also surpassing existing baselines in most scenarios. ",
    "url": "https://arxiv.org/abs/2311.09763",
    "authors": [
      "Wenjie Mo",
      "Jiashu Xu",
      "Qin Liu",
      "Jiongxiao Wang",
      "Jun Yan",
      "Chaowei Xiao",
      "Muhao Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09768",
    "title": "Utilizing dataset affinity prediction in object detection to assess  training data",
    "abstract": "Data pooling offers various advantages, such as increasing the sample size, improving generalization, reducing sampling bias, and addressing data sparsity and quality, but it is not straightforward and may even be counterproductive. Assessing the effectiveness of pooling datasets in a principled manner is challenging due to the difficulty in estimating the overall information content of individual datasets. Towards this end, we propose incorporating a data source prediction module into standard object detection pipelines. The module runs with minimal overhead during inference time, providing additional information about the data source assigned to individual detections. We show the benefits of the so-called dataset affinity score by automatically selecting samples from a heterogeneous pool of vehicle datasets. The results show that object detectors can be trained on a significantly sparser set of training samples without losing detection accuracy. ",
    "url": "https://arxiv.org/abs/2311.09768",
    "authors": [
      "Stefan Becker",
      "Jens Bayer",
      "Ronny Hug",
      "Wolfgang H\u00fcbner",
      "Michael Arens"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.09770",
    "title": "DINO-VITS: Data-Efficient Noise-Robust Zero-Shot Voice Cloning via  Multi-Tasking with Self-Supervised Speaker Verification Loss",
    "abstract": "Recent progress in self-supervised representation learning has opened up new opportunities for training from unlabeled data and has been a growing trend in voice conversion. However, unsupervised training of voice cloning seems to remain a challenging task. In this paper we propose a semi-supervised zero-shot voice cloning approach that works by adapting a HuBERT-based voice conversion system to the voice cloning task and shows the robustness of such a system to noises both in training data (we add noises resulting in up to 0db signal-to-noise-ratio to 35% of training data with no significant degradation of evaluation metrics) and in the target speaker reference audio at inference. Moreover, such a method does not require any type of denoising or noise-labeling of training data. Finally, we introduce a novel multi-tasking approach by incorporating self-supervised DINO loss into joint training of a CAM++ based speaker verification system and a unit-based VITS cloning system. We show that it significantly improves the quality of generated audio over baselines, especially for noisy target speaker references. ",
    "url": "https://arxiv.org/abs/2311.09770",
    "authors": [
      "Vikentii Pankov",
      "Valeria Pronina",
      "Alexander Kuzmin",
      "Maksim Borisov",
      "Nikita Usoltsev",
      "Xingshan Zeng",
      "Alexander Golubkov",
      "Nikolai Ermolenko",
      "Aleksandra Shirshova",
      "Yulia Matveeva"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2311.09775",
    "title": "MEGA: A Memory-Efficient GNN Accelerator Exploiting Degree-Aware  Mixed-Precision Quantization",
    "abstract": "Graph Neural Networks (GNNs) are becoming a promising technique in various domains due to their excellent capabilities in modeling non-Euclidean data. Although a spectrum of accelerators has been proposed to accelerate the inference of GNNs, our analysis demonstrates that the latency and energy consumption induced by DRAM access still significantly impedes the improvement of performance and energy efficiency. To address this issue, we propose a Memory-Efficient GNN Accelerator (MEGA) through algorithm and hardware co-design in this work. Specifically, at the algorithm level, through an in-depth analysis of the node property, we observe that the data-independent quantization in previous works is not optimal in terms of accuracy and memory efficiency. This motivates us to propose the Degree-Aware mixed-precision quantization method, in which a proper bitwidth is learned and allocated to a node according to its in-degree to compress GNNs as much as possible while maintaining accuracy. At the hardware level, we employ a heterogeneous architecture design in which the aggregation and combination phases are implemented separately with different dataflows. In order to boost the performance and energy efficiency, we also present an Adaptive-Package format to alleviate the storage overhead caused by the fine-grained bitwidth and diverse sparsity, and a Condense-Edge scheduling method to enhance the data locality and further alleviate the access irregularity induced by the extremely sparse adjacency matrix in the graph. We implement our MEGA accelerator in a 28nm technology node. Extensive experiments demonstrate that MEGA can achieve an average speedup of 38.3x, 7.1x, 4.0x, 3.6x and 47.6x, 7.2x, 5.4x, 4.5x energy savings over four state-of-the-art GNN accelerators, HyGCN, GCNAX, GROW, and SGCN, respectively, while retaining task accuracy. ",
    "url": "https://arxiv.org/abs/2311.09775",
    "authors": [
      "Zeyu Zhu",
      "Fanrong Li",
      "Gang Li",
      "Zejian Liu",
      "Zitao Mo",
      "Qinghao Hu",
      "Xiaoyao Liang",
      "Jian Cheng"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.09790",
    "title": "Breaking Boundaries: Balancing Performance and Robustness in Deep  Wireless Traffic Forecasting",
    "abstract": "Balancing the trade-off between accuracy and robustness is a long-standing challenge in time series forecasting. While most of existing robust algorithms have achieved certain suboptimal performance on clean data, sustaining the same performance level in the presence of data perturbations remains extremely hard. % In this paper, we study a wide array of perturbation scenarios and propose novel defense mechanisms against adversarial attacks using real-world telecom data. We compare our strategy against two existing adversarial training algorithms under a range of maximal allowed perturbations, defined using $\\ell_{\\infty}$-norm, $\\in [0.1,0.4]$. % Our findings reveal that our hybrid strategy, which is composed of a classifier to detect adversarial examples, a denoiser to eliminate noise from the perturbed data samples, and a standard forecaster, achieves the best performance on both clean and perturbed data. % Our optimal model can retain up to $92.02\\%$ the performance of the original forecasting model in terms of Mean Squared Error (MSE) on clean data, while being more robust than the standard adversarially trained models on perturbed data. Its MSE is 2.71$\\times$ and 2.51$\\times$ lower than those of comparing methods on normal and perturbed data, respectively. In addition, the components of our models can be trained in parallel, resulting in better computational efficiency. % Our results indicate that we can optimally balance the trade-off between the performance and robustness of forecasting models by improving the classifier and denoiser, even in the presence of sophisticated and destructive poisoning attacks. ",
    "url": "https://arxiv.org/abs/2311.09790",
    "authors": [
      "Ilbert Romain",
      "V. Hoang Thai",
      "Zhang Zonghua",
      "Palpanas Themis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.09802",
    "title": "Neuro-Symbolic Integration Brings Causal and Reliable Reasoning Proofs",
    "abstract": "Though prompting LLMs with various reasoning structures produces reasoning proofs along with answers, these proofs are not ensured to be causal and reliable due to the inherent defects of LLMs. Tracking such deficiencies, we present a neuro-symbolic integration method, in which a neural LLM is used to represent the knowledge of the problem while an LLM-free symbolic solver is adopted to do deliberative reasoning using the knowledge. Specifically, our customized meta-interpreters allow the production of reasoning proofs and support flexible search strategies. These reasoning proofs are ensured to be causal and reliable because of the deterministic executing nature of the symbolic solvers. Empirically, on ProofWriter, our method surpasses the CoT baseline by nearly double in accuracy and more than triple in proof similarity. On GSM8K, our method also shows accuracy improvements and nearly doubled proof similarity. Our code is released at https://github.com/DAMO-NLP-SG/CaRing ",
    "url": "https://arxiv.org/abs/2311.09802",
    "authors": [
      "Sen Yang",
      "Xin Li",
      "Leyang Cui",
      "Lidong Bing",
      "Wai Lam"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09817",
    "title": "Neural-Logic Human-Object Interaction Detection",
    "abstract": "The interaction decoder utilized in prevalent Transformer-based HOI detectors typically accepts pre-composed human-object pairs as inputs. Though achieving remarkable performance, such paradigm lacks feasibility and cannot explore novel combinations over entities during decoding. We present L OGIC HOI, a new HOI detector that leverages neural-logic reasoning and Transformer to infer feasible interactions between entities. Specifically, we modify the self-attention mechanism in vanilla Transformer, enabling it to reason over the <human, action, object> triplet and constitute novel interactions. Meanwhile, such reasoning process is guided by two crucial properties for understanding HOI: affordances (the potential actions an object can facilitate) and proxemics (the spatial relations between humans and objects). We formulate these two properties in first-order logic and ground them into continuous space to constrain the learning process of our approach, leading to improved performance and zero-shot generalization capabilities. We evaluate L OGIC HOI on V-COCO and HICO-DET under both normal and zero-shot setups, achieving significant improvements over existing methods. ",
    "url": "https://arxiv.org/abs/2311.09817",
    "authors": [
      "Liulei Li",
      "Jianan Wei",
      "Wenguan Wang",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.09821",
    "title": "Towards Robust Temporal Reasoning of Large Language Models via a  Multi-Hop QA Dataset and Pseudo-Instruction Tuning",
    "abstract": "Knowledge in the real world is being updated constantly. However, it is costly to frequently update large language models (LLMs). Therefore, it is crucial for LLMs to understand the concept of temporal knowledge. However, prior works on temporal question answering did not emphasize multi-answer and multi-hop types of temporal reasoning. In this paper, we propose a complex temporal question-answering (QA) dataset Complex-TR that focuses on multi-answer and multi-hop temporal reasoning. Besides, we also propose a novel data augmentation strategy to improve the complex temporal reasoning capability and robustness of LLMs. We conducted experiments on multiple temporal QA datasets. Experimental results show that our method is able to improve LLMs' performance on temporal QA benchmarks by significant margins. ",
    "url": "https://arxiv.org/abs/2311.09821",
    "authors": [
      "Qingyu Tan",
      "Hwee Tou Ng",
      "Lidong Bing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09834",
    "title": "Overview of the HASOC Subtrack at FIRE 2023: Identification of Tokens  Contributing to Explicit Hate in English by Span Detection",
    "abstract": "As hate speech continues to proliferate on the web, it is becoming increasingly important to develop computational methods to mitigate it. Reactively, using black-box models to identify hateful content can perplex users as to why their posts were automatically flagged as hateful. On the other hand, proactive mitigation can be achieved by suggesting rephrasing before a post is made public. However, both mitigation techniques require information about which part of a post contains the hateful aspect, i.e., what spans within a text are responsible for conveying hate. Better detection of such spans can significantly reduce explicitly hateful content on the web. To further contribute to this research area, we organized HateNorm at HASOC-FIRE 2023, focusing on explicit span detection in English Tweets. A total of 12 teams participated in the competition, with the highest macro-F1 observed at 0.58. ",
    "url": "https://arxiv.org/abs/2311.09834",
    "authors": [
      "Sarah Masud",
      "Mohammad Aflah Khan",
      "Md. Shad Akhtar",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09841",
    "title": "Leveraging LLMs in Scholarly Knowledge Graph Question Answering",
    "abstract": "This paper presents a scholarly Knowledge Graph Question Answering (KGQA) that answers bibliographic natural language questions by leveraging a large language model (LLM) in a few-shot manner. The model initially identifies the top-n similar training questions related to a given test question via a BERT-based sentence encoder and retrieves their corresponding SPARQL. Using the top-n similar question-SPARQL pairs as an example and the test question creates a prompt. Then pass the prompt to the LLM and generate a SPARQL. Finally, runs the SPARQL against the underlying KG - ORKG (Open Research KG) endpoint and returns an answer. Our system achieves an F1 score of 99.0%, on SciQA - one of the Scholarly-QALD-23 challenge benchmarks. ",
    "url": "https://arxiv.org/abs/2311.09841",
    "authors": [
      "Tilahun Abedissa Taffa",
      "Ricardo Usbeck"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.09848",
    "title": "Diffusion-Augmented Neural Processes",
    "abstract": "Over the last few years, Neural Processes have become a useful modelling tool in many application areas, such as healthcare and climate sciences, in which data are scarce and prediction uncertainty estimates are indispensable. However, the current state of the art in the field (AR CNPs; Bruinsma et al., 2023) presents a few issues that prevent its widespread deployment. This work proposes an alternative, diffusion-based approach to NPs which, through conditioning on noised datasets, addresses many of these limitations, whilst also exceeding SOTA performance. ",
    "url": "https://arxiv.org/abs/2311.09848",
    "authors": [
      "Lorenzo Bonito",
      "James Requeima",
      "Aliaksandra Shysheya",
      "Richard E. Turner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.09849",
    "title": "Rusty Detection Using Image Processing For Maintenance Of Stations",
    "abstract": "This study addresses the challenge of accurately seg-menting rusted areas on painted construction surfaces. A method leveraging digital image processing is explored to calculate the percentage of rust present on painted coatings. The proposed segmentation approach is based on the HSV color model. To equalize luminosity and mitigate the influence of illumination, a fundamental model of single-scale Retinex is applied specifically to the saturation component. Subsequently, the image undergoes further processing, involv-ing manual color filtering. This step is crucial for refining the identification of rusted regions. To enhance precision and filter out noise, the pixel areas selected through color filtering are subjected to the DBScan algorithm. This multi-step process aims to achieve a robust segmentation of rusted areas on painted construction surfaces, providing a valuable contribution to the field of corrosion detection and analysis. ",
    "url": "https://arxiv.org/abs/2311.09849",
    "authors": [
      "Dao Duy Tung",
      "Ho Xuan Hung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.09858",
    "title": "Polynomially Over-Parameterized Convolutional Neural Networks Contain  Structured Strong Winning Lottery Tickets",
    "abstract": "The Strong Lottery Ticket Hypothesis (SLTH) states that randomly-initialised neural networks likely contain subnetworks that perform well without any training. Although unstructured pruning has been extensively studied in this context, its structured counterpart, which can deliver significant computational and memory efficiency gains, has been largely unexplored. One of the main reasons for this gap is the limitations of the underlying mathematical tools used in formal analyses of the SLTH. In this paper, we overcome these limitations: we leverage recent advances in the multidimensional generalisation of the Random Subset-Sum Problem and obtain a variant that admits the stochastic dependencies that arise when addressing structured pruning in the SLTH. We apply this result to prove, for a wide class of random Convolutional Neural Networks, the existence of structured subnetworks that can approximate any sufficiently smaller network. This result provides the first sub-exponential bound around the SLTH for structured pruning, opening up new avenues for further research on the hypothesis and contributing to the understanding of the role of over-parameterization in deep learning. ",
    "url": "https://arxiv.org/abs/2311.09858",
    "authors": [
      "Arthur da Cunha",
      "Francesco d'Amore",
      "Emanuele Natale"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2311.09862",
    "title": "Which Modality should I use -- Text, Motif, or Image? : Understanding  Graphs with Large Language Models",
    "abstract": "Large language models (LLMs) are revolutionizing various fields by leveraging large text corpora for context-aware intelligence. Due to the context size, however, encoding an entire graph with LLMs is fundamentally limited. This paper explores how to better integrate graph data with LLMs and presents a novel approach using various encoding modalities (e.g., text, image, and motif) and approximation of global connectivity of a graph using different prompting methods to enhance LLMs' effectiveness in handling complex graph structures. The study also introduces GraphTMI, a new benchmark for evaluating LLMs in graph structure analysis, focusing on factors such as homophily, motif presence, and graph difficulty. Key findings reveal that image modality, supported by advanced vision-language models like GPT-4V, is more effective than text in managing token limits while retaining critical information. The research also examines the influence of different factors on each encoding modality's performance. This study highlights the current limitations and charts future directions for LLMs in graph understanding and reasoning tasks. ",
    "url": "https://arxiv.org/abs/2311.09862",
    "authors": [
      "Debarati Das",
      "Ishaan Gupta",
      "Jaideep Srivastava",
      "Dongyeop Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.09867",
    "title": "Parallel and Sequential Resources Networks",
    "abstract": "A large number of real and abstract systems involve the transformation of some basic resource into respective products under the action of multiple processing agents, which can be understood as multiple-agent production systems (MAP). At each discrete time instant, for each agent, a fraction of the resources is assumed to be kept, forwarded to other agents, or converted into work with some efficiency. The present work describes a systematic study of nine basic MAP architectures subdivided into two main groups, namely parallel and sequential distribution of resources from a single respective source. Several types of interconnections among the involved processing agents are also considered. The resulting MAP architectures are studied in terms of the total amount of work, the dispersion of the resources (states) among the agents, and the transition times from the start of operation until the respective steady state. Several interesting results are obtained and discussed, including the observation that some of the parallel designs were able to yield maximum work and minimum state dispersion, achieved at the expense of the transition time and use of several interconnections between the source and the agents. The results obtained for the sequential designs indicate that relatively high performance can be obtained for some specific cases. ",
    "url": "https://arxiv.org/abs/2311.09867",
    "authors": [
      "Alexandre Benatti",
      "Luciano da F. Costa"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2311.09904",
    "title": "Capacitated Network Bargaining Games: Stability and Structure",
    "abstract": "Capacitated network bargaining games are popular combinatorial games that involve the structure of matchings in graphs. We show that it is always possible to stabilize unweighted instances of this problem (that is, ensure that they admit a stable outcome) via capacity-reduction and edge-removal operations, without decreasing the total value that the players can get. Furthermore, for general weighted instances, we show that computing a minimum amount of vertex-capacity to reduce to make an instance stable is a polynomial-time solvable problem. We then exploit this to give approximation results for the NP-hard problem of stabilizing a graph via edge-removal operations. Our work extends and generalizes previous results in the literature that dealt with an uncapacitated version of the problem, using several new arguments. In particular, while previous results mainly used combinatorial techniques, we here rely on polyhedral arguments and, more specifically, on the notion of circuits of a polytope. ",
    "url": "https://arxiv.org/abs/2311.09904",
    "authors": [
      "Laura Sanit\u00e0",
      "Lucy Verberk"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2311.09939",
    "title": "RED-DOT: Multimodal Fact-checking via Relevant Evidence Detection",
    "abstract": "Online misinformation is often multimodal in nature, i.e., it is caused by misleading associations between texts and accompanying images. To support the fact-checking process, researchers have been recently developing automatic multimodal methods that gather and analyze external information, evidence, related to the image-text pairs under examination. However, prior works assumed all collected evidence to be relevant. In this study, we introduce a \"Relevant Evidence Detection\" (RED) module to discern whether each piece of evidence is relevant, to support or refute the claim. Specifically, we develop the \"Relevant Evidence Detection Directed Transformer\" (RED-DOT) and explore multiple architectural variants (e.g., single or dual-stage) and mechanisms (e.g., \"guided attention\"). Extensive ablation and comparative experiments demonstrate that RED-DOT achieves significant improvements over the state-of-the-art on the VERITE benchmark by up to 28.5%. Furthermore, our evidence re-ranking and element-wise modality fusion led to RED-DOT achieving competitive and even improved performance on NewsCLIPings+, without the need for numerous evidence or multiple backbone encoders. Finally, our qualitative analysis demonstrates that the proposed \"guided attention\" module has the potential to enhance the architecture's interpretability. We release our code at: https://github.com/stevejpapad/relevant-evidence-detection ",
    "url": "https://arxiv.org/abs/2311.09939",
    "authors": [
      "Stefanos-Iordanis Papadopoulos",
      "Christos Koutlis",
      "Symeon Papadopoulos",
      "Panagiotis C. Petrantonakis"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.09941",
    "title": "Ghost Value Augmentation for $k$-ECSS and $k$-ECSM",
    "abstract": "We give a poly-time algorithm for the $k$-edge-connected spanning subgraph ($k$-ECSS) problem that returns a solution of cost no greater than the cheapest $(k+10)$-ECSS on the same graph. Our approach enhances the iterative relaxation framework with a new ingredient, which we call ghost values, that allows for high sparsity in intermediate problems. Our guarantees improve upon the best-known approximation factor of $2$ for $k$-ECSS whenever the optimal value of $(k+10)$-ECSS is close to that of $k$-ECSS. This is a property that holds for the closely related problem $k$-edge-connected spanning multi-subgraph ($k$-ECSM), which is identical to $k$-ECSS except edges can be selected multiple times at the same cost. As a consequence, we obtain a $\\left(1+O\\left(\\frac{1}{k}\\right)\\right)$-approximation for $k$-ECSM, which resolves a conjecture of Pritchard and improves upon a recent $1+O\\left(\\frac{1}{k}\\right)$ approximation of Karlin, Klein, Oveis Gharan, and Zhang. Moreover, we present a matching lower bound for $k$-ECSM, showing that our approximation ratio is tight up to the constant factor in $O\\left(\\frac{1}{k}\\right)$, unless $P=NP$. ",
    "url": "https://arxiv.org/abs/2311.09941",
    "authors": [
      "D Ellis Hershkowitz",
      "Nathan Klein",
      "Rico Zenklusen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2311.09944",
    "title": "A Physics-Informed Neural Network approach for compartmental  epidemiological models",
    "abstract": "Compartmental models provide simple and efficient tools to analyze the relevant transmission processes during an outbreak, to produce short-term forecasts or transmission scenarios, and to assess the impact of vaccination campaigns. However, their calibration is not straightforward, since many factors contribute to the rapid change of the transmission dynamics during an epidemic. For example, there might be changes in the individual awareness, the imposition of non-pharmacological interventions and the emergence of new variants. As a consequence, model parameters such as the transmission rate are doomed to change in time, making their assessment more challenging. Here, we propose to use Physics-Informed Neural Networks (PINNs) to track the temporal changes in the model parameters and provide an estimate of the model state variables. PINNs recently gained attention in many engineering applications thanks to their ability to consider both the information from data (typically uncertain) and the governing equations of the system. The ability of PINNs to identify unknown model parameters makes them particularly suitable to solve ill-posed inverse problems, such as those arising in the application of epidemiological models. Here, we develop a reduced-split approach for the implementation of PINNs to estimate the temporal changes in the state variables and transmission rate of an epidemic based on the SIR model equation and infectious data. The main idea is to split the training first on the epidemiological data, and then on the residual of the system equations. The proposed method is applied to five synthetic test cases and two real scenarios reproducing the first months of the COVID-19 Italian pandemic. Our results show that the split implementation of PINNs outperforms the standard approach in terms of accuracy (up to one order of magnitude) and computational times (speed up of 20%). ",
    "url": "https://arxiv.org/abs/2311.09944",
    "authors": [
      "Caterina Millevoi",
      "Damiano Pasetto",
      "Massimiliano Ferronato"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2311.09945",
    "title": "An Attention-Based Denoising Framework for Personality Detection in  Social Media Texts",
    "abstract": "In social media networks, users produce a large amount of text content anytime, providing researchers with a valuable approach to digging for personality-related information. Personality detection based on user-generated texts is a universal method that can be used to build user portraits. The presence of noise in social media texts hinders personality detection. However, previous studies have not fully addressed this challenge. Inspired by the scanning reading technique, we propose an attention-based information extraction mechanism (AIEM) for long texts, which is applied to quickly locate valuable pieces of information, and focus more attention on the deep semantics of key pieces. Then, we provide a novel attention-based denoising framework (ADF) for personality detection tasks and achieve state-of-the-art performance on two commonly used datasets. Notably, we obtain an average accuracy improvement of 10.2% on the gold standard Twitter-Myers-Briggs Type Indicator (Twitter-MBTI) dataset. We made our code publicly available on GitHub. We shed light on how AIEM works to magnify personality-related signals. ",
    "url": "https://arxiv.org/abs/2311.09945",
    "authors": [
      "Qirui Tang",
      "Wenkang Jiang",
      "Yihua Du",
      "Lei Lin"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09948",
    "title": "Hijacking Large Language Models via Adversarial In-Context Learning",
    "abstract": "In-context learning (ICL) has emerged as a powerful paradigm leveraging LLMs for specific tasks by utilizing labeled examples as demonstrations in the precondition prompts. Despite its promising performance, ICL suffers from instability with the choice and arrangement of examples. Additionally, crafted adversarial attacks pose a notable threat to the robustness of ICL. However, existing attacks are either easy to detect, rely on external models, or lack specificity towards ICL. To address these issues, this work introduces a novel transferable attack for ICL, aiming to hijack LLMs to generate the targeted response. The proposed LLM hijacking attack leverages a gradient-based prompt search method to learn and append imperceptible adversarial suffixes to the in-context demonstrations. Extensive experimental results on various tasks and datasets demonstrate the effectiveness of our LLM hijacking attack, resulting in a distracted attention towards adversarial tokens, consequently leading to the targeted unwanted outputs. ",
    "url": "https://arxiv.org/abs/2311.09948",
    "authors": [
      "Yao Qiang",
      "Xiangyu Zhou",
      "Dongxiao Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.09962",
    "title": "Self-supervised learning of multi-omics embeddings in the low-label,  high-data regime",
    "abstract": "Contrastive, self-supervised learning (SSL) is used to train a model that predicts cancer type from miRNA, mRNA or RPPA expression data. This model, a pretrained FT-Transformer, is shown to outperform XGBoost and CatBoost, standard benchmarks for tabular data, when labelled samples are scarce but the number of unlabelled samples is high. This is despite the fact that the datasets we use have $\\mathcal{O}(10^{1})$ classes and $\\mathcal{O}(10^{2})-\\mathcal{O}(10^{4})$ features. After demonstrating the efficacy of our chosen method of self-supervised pretraining, we investigate SSL for multi-modal models. A late-fusion model is proposed, where each omics is passed through its own sub-network, the outputs of which are averaged and passed to the pretraining or downstream objective function. Multi-modal pretraining is shown to improve predictions from a single omics, and we argue that this is useful for datasets with many unlabelled multi-modal samples, but few labelled unimodal samples. Additionally, we show that pretraining each omics-specific module individually is highly effective. This enables the application of the proposed model in a variety of contexts where a large amount of unlabelled data is available from each omics, but only a few labelled samples. ",
    "url": "https://arxiv.org/abs/2311.09962",
    "authors": [
      "Christian John Hurry",
      "Emma Slade"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2311.09965",
    "title": "SurgPLAN: Surgical Phase Localization Network for Phase Recognition",
    "abstract": "Surgical phase recognition is crucial to providing surgery understanding in smart operating rooms. Despite great progress in automatic surgical phase recognition, most existing methods are still restricted by two problems. First, these methods cannot capture discriminative visual features for each frame and motion information with simple 2D networks. Second, the frame-by-frame recognition paradigm degrades the performance due to unstable predictions within each phase, termed as phase shaking. To address these two challenges, we propose a Surgical Phase LocAlization Network, named SurgPLAN, to facilitate a more accurate and stable surgical phase recognition with the principle of temporal detection. Specifically, we first devise a Pyramid SlowFast (PSF) architecture to serve as the visual backbone to capture multi-scale spatial and temporal features by two branches with different frame sampling rates. Moreover, we propose a Temporal Phase Localization (TPL) module to generate the phase prediction based on temporal region proposals, which ensures accurate and consistent predictions within each surgical phase. Extensive experiments confirm the significant advantages of our SurgPLAN over frame-by-frame approaches in terms of both accuracy and stability. ",
    "url": "https://arxiv.org/abs/2311.09965",
    "authors": [
      "Xingjian Luo",
      "You Pang",
      "Zhen Chen",
      "Jinlin Wu",
      "Zongmin Zhang",
      "Zhen Lei",
      "Hongbin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.09974",
    "title": "From Pretext to Purpose: Batch-Adaptive Self-Supervised Learning",
    "abstract": "In recent years, self-supervised contrastive learning has emerged as a distinguished paradigm in the artificial intelligence landscape. It facilitates unsupervised feature learning through contrastive delineations at the instance level. However, crafting an effective self-supervised paradigm remains a pivotal challenge within this field. This paper delves into two crucial factors impacting self-supervised contrastive learning-bach size and pretext tasks, and from a data processing standpoint, proposes an adaptive technique of batch fusion. The proposed method, via dimensionality reduction and reconstruction of batch data, enables formerly isolated individual data to partake in intra-batch communication through the Embedding Layer. Moreover, it adaptively amplifies the self-supervised feature encoding capability as the training progresses. We conducted a linear classification test of this method based on the classic contrastive learning framework on ImageNet-1k. The empirical findings illustrate that our approach achieves state-of-the-art performance under equitable comparisons. Benefiting from its \"plug-and-play\" characteristics, we further explored other contrastive learning methods. On the ImageNet-100, compared to the original performance, the top1 has seen a maximum increase of 1.25%. We suggest that the proposed method may contribute to the advancement of data-driven self-supervised learning research, bringing a fresh perspective to this community. ",
    "url": "https://arxiv.org/abs/2311.09974",
    "authors": [
      "Jiansong Zhang",
      "Peizhong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.09999",
    "title": "TransFusion -- A Transparency-Based Diffusion Model for Anomaly  Detection",
    "abstract": "Surface anomaly detection is a vital component in manufacturing inspection. Reconstructive anomaly detection methods restore the normal appearance of an object, ideally modifying only the anomalous regions. Due to the limitations of commonly used reconstruction architectures, the produced reconstructions are often poor and either still contain anomalies or lack details in anomaly-free regions. Recent reconstructive methods adopt diffusion models, however with the standard diffusion process the problems are not adequately addressed. We propose a novel transparency-based diffusion process, where the transparency of anomalous regions is progressively increased, restoring their normal appearance accurately and maintaining the appearance of anomaly-free regions without loss of detail. We propose TRANSparency DifFUSION (TransFusion), a discriminative anomaly detection method that implements the proposed diffusion process, enabling accurate downstream anomaly detection. TransFusion achieves state-of-the-art performance on both the VisA and the MVTec AD datasets, with an image-level AUROC of 98.5% and 99.2%, respectively. ",
    "url": "https://arxiv.org/abs/2311.09999",
    "authors": [
      "Matic Fu\u010dka",
      "Vitjan Zavrtanik",
      "Danijel Sko\u010daj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.10002",
    "title": "Straggler-resilient Federated Learning: Tackling Computation  Heterogeneity with Layer-wise Partial Model Training in Mobile Edge Network",
    "abstract": "Federated Learning (FL) enables many resource-limited devices to train a model collaboratively without data sharing. However, many existing works focus on model-homogeneous FL, where the global and local models are the same size, ignoring the inherently heterogeneous computational capabilities of different devices and restricting resource-constrained devices from contributing to FL. In this paper, we consider model-heterogeneous FL and propose Federated Partial Model Training (FedPMT), where devices with smaller computational capabilities work on partial models (subsets of the global model) and contribute to the global model. Different from Dropout-based partial model generation, which removes neurons in hidden layers at random, model training in FedPMT is achieved from the back-propagation perspective. As such, all devices in FedPMT prioritize the most crucial parts of the global model. Theoretical analysis shows that the proposed partial model training design has a similar convergence rate to the widely adopted Federated Averaging (FedAvg) algorithm, $\\mathcal{O}(1/T)$, with the sub-optimality gap enlarged by a constant factor related to the model splitting design in FedPMT. Empirical results show that FedPMT significantly outperforms the existing benchmark FedDrop. Meanwhile, compared to the popular model-homogeneous benchmark, FedAvg, FedPMT reaches the learning target in a shorter completion time, thus achieving a better trade-off between learning accuracy and completion time. ",
    "url": "https://arxiv.org/abs/2311.10002",
    "authors": [
      "Hongda Wu",
      "Ping Wang",
      "C V Aswartha Narayana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.10005",
    "title": "Towards Flexibility and Robustness of LSM Trees",
    "abstract": "Log-Structured Merge trees (LSM trees) are increasingly used as part of the storage engine behind several data systems, and are frequently deployed in the cloud. As the number of applications relying on LSM-based storage backends increases, the problem of performance tuning of LSM trees receives increasing attention. We consider both nominal tunings - where workload and execution environment are accurately known a priori - and robust tunings - which consider uncertainty in the workload knowledge. This type of workload uncertainty is common in modern applications, notably in shared infrastructure environments like the public cloud. To address this problem, we introduce ENDURE, a new paradigm for tuning LSM trees in the presence of workload uncertainty. Specifically, we focus on the impact of the choice of compaction policy, size ratio, and memory allocation on the overall performance. ENDURE considers a robust formulation of the throughput maximization problem and recommends a tuning that offers near-optimal throughput when the executed workload is not the same, instead in a neighborhood of the expected workload. Additionally, we explore the robustness of flexible LSM designs by proposing a new unified design called K-LSM that encompasses existing designs. We deploy our robust tuning system, ENDURE, on a state-of-the-art key-value store, RocksDB, and demonstrate throughput improvements of up to 5x in the presence of uncertainty. Our results indicate that the tunings obtained by ENDURE are more robust than tunings obtained under our expanded LSM design space. This indicates that robustness may not be inherent to a design, instead, it is an outcome of a tuning process that explicitly accounts for uncertainty. ",
    "url": "https://arxiv.org/abs/2311.10005",
    "authors": [
      "Andy Huynh",
      "Harshal A. Chaudhari",
      "Evimaria Terzi",
      "Manos Athanassoulis"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2311.10011",
    "title": "SQLNet: Scale-Modulated Query and Localization Network for Few-Shot  Class-Agnostic Counting",
    "abstract": "The class-agnostic counting (CAC) task has recently been proposed to solve the problem of counting all objects of an arbitrary class with several exemplars given in the input image. To address this challenging task, existing leading methods all resort to density map regression, which renders them impractical for downstream tasks that require object locations and restricts their ability to well explore the scale information of exemplars for supervision. To address the limitations, we propose a novel localization-based CAC approach, termed Scale-modulated Query and Localization Network (SQLNet). It fully explores the scales of exemplars in both the query and localization stages and achieves effective counting by accurately locating each object and predicting its approximate size. Specifically, during the query stage, rich discriminative representations of the target class are acquired by the Hierarchical Exemplars Collaborative Enhancement (HECE) module from the few exemplars through multi-scale exemplar cooperation with equifrequent size prompt embedding. These representations are then fed into the Exemplars-Unified Query Correlation (EUQC) module to interact with the query features in a unified manner and produce the correlated query tensor. In the localization stage, the Scale-aware Multi-head Localization (SAML) module utilizes the query tensor to predict the confidence, location, and size of each potential object. Moreover, a scale-aware localization loss is introduced, which exploits flexible location associations and exemplar scales for supervision to optimize the model performance. Extensive experiments demonstrate that SQLNet outperforms state-of-the-art methods on popular CAC benchmarks, achieving excellent performance not only in counting accuracy but also in localization and bounding box generation. Our codes will be available at https://github.com/HCPLab-SYSU/SQLNet ",
    "url": "https://arxiv.org/abs/2311.10011",
    "authors": [
      "Hefeng Wu",
      "Yandong Chen",
      "Lingbo Liu",
      "Tianshui Chen",
      "Keze Wang",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.10025",
    "title": "A Novel Neural Network-Based Federated Learning System for Imbalanced  and Non-IID Data",
    "abstract": "With the growth of machine learning techniques, privacy of data of users has become a major concern. Most of the machine learning algorithms rely heavily on large amount of data which may be collected from various sources. Collecting these data yet maintaining privacy policies has become one of the most challenging tasks for the researchers. To combat this issue, researchers have introduced federated learning, where a prediction model is learnt by ensuring the privacy of data of clients data. However, the prevalent federated learning algorithms possess an accuracy and efficiency trade-off, especially for non-IID data. In this research, we propose a centralized, neural network-based federated learning system. The centralized algorithm incorporates micro-level parallel processing inspired by the traditional mini-batch algorithm where the client devices and the server handle the forward and backward propagation respectively. We also devise a semi-centralized version of our proposed algorithm. This algorithm takes advantage of edge computing for minimizing the load from the central server, where clients handle both the forward and backward propagation while sacrificing the overall train time to some extent. We evaluate our proposed systems on five well-known benchmark datasets and achieve satisfactory performance in a reasonable time across various data distribution settings as compared to some existing benchmark algorithms. ",
    "url": "https://arxiv.org/abs/2311.10025",
    "authors": [
      "Mahfuzur Rahman Chowdhury",
      "Muhammad Ibrahim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.10050",
    "title": "Graph models for Cybersecurity -- A Survey",
    "abstract": "Graph models are helpful means of analyzing computer networks as well as complex system architectures for security. In this paper we evaluate the current state of research for representing and analysing cyber-attack using graph models, i.e. attack graph (AG) formalisms. We propose a taxonomy on attack graph formalisms, based on 70 models, which we analysed with respect to their \\textit{graph semantic}, involved agents and analysis features. Additionally, we adress which formalisms allow for automatic attack graph generation from raw or processes data inputs. Our taxonomy is especially designed to help users and applied researchers identify a suitable AG model for their needs. A summary of the individual AG formalisms is provided as supplementary material. ",
    "url": "https://arxiv.org/abs/2311.10050",
    "authors": [
      "Jasmin Wachter"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.10051",
    "title": "Tabular Few-Shot Generalization Across Heterogeneous Feature Spaces",
    "abstract": "Despite the prevalence of tabular datasets, few-shot learning remains under-explored within this domain. Existing few-shot methods are not directly applicable to tabular datasets due to varying column relationships, meanings, and permutational invariance. To address these challenges, we propose FLAT-a novel approach to tabular few-shot learning, encompassing knowledge sharing between datasets with heterogeneous feature spaces. Utilizing an encoder inspired by Dataset2Vec, FLAT learns low-dimensional embeddings of datasets and their individual columns, which facilitate knowledge transfer and generalization to previously unseen datasets. A decoder network parametrizes the predictive target network, implemented as a Graph Attention Network, to accommodate the heterogeneous nature of tabular datasets. Experiments on a diverse collection of 118 UCI datasets demonstrate FLAT's successful generalization to new tabular datasets and a considerable improvement over the baselines. ",
    "url": "https://arxiv.org/abs/2311.10051",
    "authors": [
      "Max Zhu",
      "Katarzyna Kobalczyk",
      "Andrija Petrovic",
      "Mladen Nikolic",
      "Mihaela van der Schaar",
      "Boris Delibasic",
      "Petro Lio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.10054",
    "title": "Is \"A Helpful Assistant\" the Best Role for Large Language Models? A  Systematic Evaluation of Social Roles in System Prompts",
    "abstract": "Prompting serves as the major way humans interact with Large Language Models (LLM). Commercial AI systems commonly define the role of the LLM in system prompts. For example, ChatGPT uses \"You are a helpful assistant\" as part of the default system prompt. But is \"a helpful assistant\" the best role for LLMs? In this study, we present a systematic evaluation of how social roles in system prompts affect model performance. We curate a list of 162 roles covering 6 types of interpersonal relationships and 8 types of occupations. Through extensive analysis of 3 popular LLMs and 2457 questions, we show that adding interpersonal roles in prompts consistently improves the models' performance over a range of questions. Moreover, while we find that using gender-neutral roles and specifying the role as the audience leads to better performances, predicting which role leads to the best performance remains a challenging task, and that frequency, similarity, and perplexity do not fully explain the effect of social roles on model performances. Our results can help inform the design of system prompts for AI systems. Code and data are available at https://github.com/Jiaxin-Pei/Prompting-with-Social-Roles. ",
    "url": "https://arxiv.org/abs/2311.10054",
    "authors": [
      "Mingqian Zheng",
      "Jiaxin Pei",
      "David Jurgens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.10091",
    "title": "Adaptive Shells for Efficient Neural Radiance Field Rendering",
    "abstract": "Neural radiance fields achieve unprecedented quality for novel view synthesis, but their volumetric formulation remains expensive, requiring a huge number of samples to render high-resolution images. Volumetric encodings are essential to represent fuzzy geometry such as foliage and hair, and they are well-suited for stochastic optimization. Yet, many scenes ultimately consist largely of solid surfaces which can be accurately rendered by a single sample per pixel. Based on this insight, we propose a neural radiance formulation that smoothly transitions between volumetric- and surface-based rendering, greatly accelerating rendering speed and even improving visual fidelity. Our method constructs an explicit mesh envelope which spatially bounds a neural volumetric representation. In solid regions, the envelope nearly converges to a surface and can often be rendered with a single sample. To this end, we generalize the NeuS formulation with a learned spatially-varying kernel size which encodes the spread of the density, fitting a wide kernel to volume-like regions and a tight kernel to surface-like regions. We then extract an explicit mesh of a narrow band around the surface, with width determined by the kernel size, and fine-tune the radiance field within this band. At inference time, we cast rays against the mesh and evaluate the radiance field only within the enclosed region, greatly reducing the number of samples required. Experiments show that our approach enables efficient rendering at very high fidelity. We also demonstrate that the extracted envelope enables downstream applications such as animation and simulation. ",
    "url": "https://arxiv.org/abs/2311.10091",
    "authors": [
      "Zian Wang",
      "Tianchang Shen",
      "Merlin Nimier-David",
      "Nicholas Sharp",
      "Jun Gao",
      "Alexander Keller",
      "Sanja Fidler",
      "Thomas M\u00fcller",
      "Zan Gojcic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2311.10092",
    "title": "Traffic Video Object Detection using Motion Prior",
    "abstract": "Traffic videos inherently differ from generic videos in their stationary camera setup, thus providing a strong motion prior where objects often move in a specific direction over a short time interval. Existing works predominantly employ generic video object detection framework for traffic video object detection, which yield certain advantages such as broad applicability and robustness to diverse scenarios. However, they fail to harness the strength of motion prior to enhance detection accuracy. In this work, we propose two innovative methods to exploit the motion prior and boost the performance of both fully-supervised and semi-supervised traffic video object detection. Firstly, we introduce a new self-attention module that leverages the motion prior to guide temporal information integration in the fully-supervised setting. Secondly, we utilise the motion prior to develop a pseudo-labelling mechanism to eliminate noisy pseudo labels for the semi-supervised setting. Both of our motion-prior-centred methods consistently demonstrates superior performance, outperforming existing state-of-the-art approaches by a margin of 2% in terms of mAP. ",
    "url": "https://arxiv.org/abs/2311.10092",
    "authors": [
      "Lihao Liu",
      "Yanqi Cheng",
      "Dongdong Chen",
      "Jing He",
      "Pietro Li\u00f2",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Angelica I Aviles-Rivero"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.09261",
    "title": "Emerging Drug Interaction Prediction Enabled by Flow-based Graph Neural  Network with Biomedical Network",
    "abstract": "Accurately predicting drug-drug interactions (DDI) for emerging drugs, which offer possibilities for treating and alleviating diseases, with computational methods can improve patient care and contribute to efficient drug development. However, many existing computational methods require large amounts of known DDI information, which is scarce for emerging drugs. In this paper, we propose EmerGNN, a graph neural network (GNN) that can effectively predict interactions for emerging drugs by leveraging the rich information in biomedical networks. EmerGNN learns pairwise representations of drugs by extracting the paths between drug pairs, propagating information from one drug to the other, and incorporating the relevant biomedical concepts on the paths. The different edges on the biomedical network are weighted to indicate the relevance for the target DDI prediction. Overall, EmerGNN has higher accuracy than existing approaches in predicting interactions for emerging drugs and can identify the most relevant information on the biomedical network. ",
    "url": "https://arxiv.org/abs/2311.09261",
    "authors": [
      "Yongqi Zhang",
      "Quanming Yao",
      "Ling Yue",
      "Xian Wu",
      "Ziheng Zhang",
      "Zhenxi Lin",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.09312",
    "title": "H-Packer: Holographic Rotationally Equivariant Convolutional Neural  Network for Protein Side-Chain Packing",
    "abstract": "Accurately modeling protein 3D structure is essential for the design of functional proteins. An important sub-task of structure modeling is protein side-chain packing: predicting the conformation of side-chains (rotamers) given the protein's backbone structure and amino-acid sequence. Conventional approaches for this task rely on expensive sampling procedures over hand-crafted energy functions and rotamer libraries. Recently, several deep learning methods have been developed to tackle the problem in a data-driven way, albeit with vastly different formulations (from image-to-image translation to directly predicting atomic coordinates). Here, we frame the problem as a joint regression over the side-chains' true degrees of freedom: the dihedral $\\chi$ angles. We carefully study possible objective functions for this task, while accounting for the underlying symmetries of the task. We propose Holographic Packer (H-Packer), a novel two-stage algorithm for side-chain packing built on top of two light-weight rotationally equivariant neural networks. We evaluate our method on CASP13 and CASP14 targets. H-Packer is computationally efficient and shows favorable performance against conventional physics-based algorithms and is competitive against alternative deep learning solutions. ",
    "url": "https://arxiv.org/abs/2311.09312",
    "authors": [
      "Gian Marco Visani",
      "William Galvin",
      "Michael Neal Pun",
      "Armita Nourmohammad"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.09375",
    "title": "HypOp: Distributed Constrained Combinatorial Optimization leveraging  Hypergraph Neural Networks",
    "abstract": "Scalable addressing of high dimensional constrained combinatorial optimization problems is a challenge that arises in several science and engineering disciplines. Recent work introduced novel application of graph neural networks for solving polynomial-cost unconstrained combinatorial optimization problems. This paper proposes a new framework, called HypOp, which greatly advances the state of the art for solving combinatorial optimization problems in several aspects: (i) it generalizes the prior results to constrained optimization problems with an arbitrary cost function; (ii) it broadens the application to higher dimensional problems by leveraging a hypergraph neural network structure; (iii) it enables scalability to much larger problems by introducing a new distributed and parallel architecture for hypergraph neural network training; (iv) it demonstrates generalizability to other problem formulations by knowledge transfer from the learned experience of addressing one set of cost/constraints to another set for the same hypergraph; (v) it significantly boosts the solution accuracy compared with the prior art by suggesting a fine-tuning step using simulated annealing; (vi) HypOp shows a remarkable progress on benchmark examples, with run times improved by up to fivefold using a combination of fine-tuning and distributed training techniques. The framework allows addressing a novel set of scientific problems including hypergraph MaxCut problem, satisfiability problems (3SAT), and resource allocation. We showcase the application of HypOp in scientific discovery by solving a hypergraph MaxCut problem on the NDC drug-substance hypergraph. Through extensive experimentation on a variety of combinatorial optimization problems, HypOp demonstrates superiority over existing unsupervised learning-based solvers and generic optimization methods. ",
    "url": "https://arxiv.org/abs/2311.09375",
    "authors": [
      "Nasimeh Heydaribeni",
      "Xinrui Zhan",
      "Ruisi Zhang",
      "Tina Eliassi-Rad",
      "Farinaz Koushanfar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.09491",
    "title": "Spatial Bayesian Neural Networks",
    "abstract": "Statistical models for spatial processes play a central role in statistical analyses of spatial data. Yet, it is the simple, interpretable, and well understood models that are routinely employed even though, as is revealed through prior and posterior predictive checks, these can poorly characterise the spatial heterogeneity in the underlying process of interest. Here, we propose a new, flexible class of spatial-process models, which we refer to as spatial Bayesian neural networks (SBNNs). An SBNN leverages the representational capacity of a Bayesian neural network; it is tailored to a spatial setting by incorporating a spatial \"embedding layer\" into the network and, possibly, spatially-varying network parameters. An SBNN is calibrated by matching its finite-dimensional distribution at locations on a fine gridding of space to that of a target process of interest. That process could be easy to simulate from or we have many realisations from it. We propose several variants of SBNNs, most of which are able to match the finite-dimensional distribution of the target process at the selected grid better than conventional BNNs of similar complexity. We also show that a single SBNN can be used to represent a variety of spatial processes often used in practice, such as Gaussian processes and lognormal processes. We briefly discuss the tools that could be used to make inference with SBNNs, and we conclude with a discussion of their advantages and limitations. ",
    "url": "https://arxiv.org/abs/2311.09491",
    "authors": [
      "Andrew Zammit-Mangion",
      "Michael D. Kaminski",
      "Ba-Hien Tran",
      "Maurizio Filippone",
      "Noel Cressie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.09618",
    "title": "Simulating Opinion Dynamics with Networks of LLM-based Agents",
    "abstract": "Accurately simulating human opinion dynamics is crucial for understanding a variety of societal phenomena, including polarization and the spread of misinformation. However, the agent-based models (ABMs) commonly used for such simulations lack fidelity to human behavior. We propose a new approach to simulating opinion dynamics based on populations of Large Language Models (LLMs). Our findings reveal a strong inherent bias in LLM agents towards accurate information, leading to consensus in line with scientific reality. However, this bias limits the simulation of individuals with resistant views on issues like climate change. After inducing confirmation bias through prompt engineering, we observed opinion fragmentation in line with existing agent-based research. These insights highlight the promise and limitations of LLM agents in this domain and suggest a path forward: refining LLMs with real-world discourse to better simulate the evolution of human beliefs. ",
    "url": "https://arxiv.org/abs/2311.09618",
    "authors": [
      "Yun-Shiuan Chuang",
      "Agam Goyal",
      "Nikunj Harlalka",
      "Siddharth Suresh",
      "Robert Hawkins",
      "Sijia Yang",
      "Dhavan Shah",
      "Junjie Hu",
      "Timothy T. Rogers"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.09623",
    "title": "Apoptosis classification using attention based spatio temporal graph  convolution neural network",
    "abstract": "Accurate classification of apoptosis plays an important role in cell biology research. There are many state-of-the-art approaches which use deep CNNs to perform the apoptosis classification but these approaches do not account for the cell interaction. Our paper proposes the Attention Graph spatio-temporal graph convolutional network to classify the cell death based on the target cells in the video. This method considers the interaction of multiple target cells at each time stamp. We model the whole video sequence as a set of graphs and classify the target cell in the video as dead or alive. Our method encounters both spatial and temporal relationships. ",
    "url": "https://arxiv.org/abs/2311.09623",
    "authors": [
      "Akash Awasthi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.09642",
    "title": "Weakly Supervised Anomaly Detection for Chest X-Ray Image",
    "abstract": "Chest X-Ray (CXR) examination is a common method for assessing thoracic diseases in clinical applications. While recent advances in deep learning have enhanced the significance of visual analysis for CXR anomaly detection, current methods often miss key cues in anomaly images crucial for identifying disease regions, as they predominantly rely on unsupervised training with normal images. This letter focuses on a more practical setup in which few-shot anomaly images with only image-level labels are available during training. For this purpose, we propose WSCXR, a weakly supervised anomaly detection framework for CXR. WSCXR firstly constructs sets of normal and anomaly image features respectively. It then refines the anomaly image features by eliminating normal region features through anomaly feature mining, thus fully leveraging the scarce yet crucial features of diseased areas. Additionally, WSCXR employs a linear mixing strategy to augment the anomaly features, facilitating the training of anomaly detector with few-shot anomaly images. Experiments on two CXR datasets demonstrate the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2311.09642",
    "authors": [
      "Haoqi Ni",
      "Ximiao Zhang",
      "Min Xu",
      "Ning Lang",
      "Xiuzhuang Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.09846",
    "title": "GroupMixer: Patch-based Group Convolutional Neural Network for Breast  Cancer Detection from Histopathological Images",
    "abstract": "Diagnosis of breast cancer malignancy at the early stages is a crucial step for controlling its side effects. Histopathological analysis provides a unique opportunity for malignant breast cancer detection. However, such a task would be tedious and time-consuming for the histopathologists. Deep Neural Networks enable us to learn informative features directly from raw histopathological images without manual feature extraction. Although Convolutional Neural Networks (CNNs) have been the dominant architectures in the computer vision realm, Transformer-based architectures have shown promising results in different computer vision tasks. Although harnessing the capability of Transformer-based architectures for medical image analysis seems interesting, these architectures are large, have a significant number of trainable parameters, and require large datasets to be trained on, which are usually rare in the medical domain. It has been claimed and empirically proved that at least part of the superior performance of Transformer-based architectures in Computer Vision domain originates from patch embedding operation. In this paper, we borrowed the previously introduced idea of integrating a fully Convolutional Neural Network architecture with Patch Embedding operation and presented an efficient CNN architecture for breast cancer malignancy detection from histopathological images. Despite the number of parameters that is significantly smaller than other methods, the accuracy performance metrics achieved 97.65%, 98.92%, 99.21%, and 98.01% for 40x, 100x, 200x, and 400x magnifications respectively. We took a step forward and modified the architecture using Group Convolution and Channel Shuffling ideas and reduced the number of trainable parameters even more with a negligible decline in performance and achieved 95.42%, 98.16%, 96.05%, and 97.92% accuracy for the mentioned magnifications respectively. ",
    "url": "https://arxiv.org/abs/2311.09846",
    "authors": [
      "Ardavan Modarres",
      "Erfan Ebrahim Esfahani",
      "Mahsa Bahrami"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.09942",
    "title": "Harnessing Transformers: A Leap Forward in Lung Cancer Image Detection",
    "abstract": "This paper discusses the role of Transfer Learning (TL) and transformers in cancer detection based on image analysis. With the enormous evolution of cancer patients, the identification of cancer cells in a patient's body has emerged as a trend in the field of Artificial Intelligence (AI). This process involves analyzing medical images, such as Computed Tomography (CT) scans and Magnetic Resonance Imaging (MRIs), to identify abnormal growths that may help in cancer detection. Many techniques and methods have been realized to improve the quality and performance of cancer classification and detection, such as TL, which allows the transfer of knowledge from one task to another with the same task or domain. TL englobes many methods, particularly those used in image analysis, such as transformers and Convolutional Neural Network (CNN) models trained on the ImageNet dataset. This paper analyzes and criticizes each method of TL based on image analysis and compares the results of each method, showing that transformers have achieved the best results with an accuracy of 97.41% for colon cancer detection and 94.71% for Histopathological Lung cancer. Future directions for cancer detection based on image analysis are also discussed. ",
    "url": "https://arxiv.org/abs/2311.09942",
    "authors": [
      "Amine Bechar",
      "Youssef Elmir",
      "Rafik Medjoudj",
      "Yassine Himeur",
      "Abbes Amira"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.10023",
    "title": "Online Optimization for Network Resource Allocation and Comparison with  Reinforcement Learning Techniques",
    "abstract": "We tackle in this paper an online network resource allocation problem with job transfers. The network is composed of many servers connected by communication links. The system operates in discrete time; at each time slot, the administrator reserves resources at servers for future job requests, and a cost is incurred for the reservations made. Then, after receptions, the jobs may be transferred between the servers to best accommodate the demands. This incurs an additional transport cost. Finally, if a job request cannot be satisfied, there is a violation that engenders a cost to pay for the blocked job. We propose a randomized online algorithm based on the exponentially weighted method. We prove that our algorithm enjoys a sub-linear in time regret, which indicates that the algorithm is adapting and learning from its experiences and is becoming more efficient in its decision-making as it accumulates more data. Moreover, we test the performance of our algorithm on artificial data and compare it against a reinforcement learning method where we show that our proposed method outperforms the latter. ",
    "url": "https://arxiv.org/abs/2311.10023",
    "authors": [
      "Ahmed Sid-Ali",
      "Ioannis Lambadaris",
      "Yiqiang Q. Zhao",
      "Gennady Shaikhet",
      "Amirhossein Asgharnia"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2101.10814",
    "title": "Spread and defend infection in graphs",
    "abstract": " Comments: incomplete work. major revision required ",
    "url": "https://arxiv.org/abs/2101.10814",
    "authors": [
      "Arya Tanmay Gupta"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2102.02710",
    "title": "Matching Impatient and Heterogeneous Demand and Supply",
    "abstract": " Comments: 16 figures ",
    "url": "https://arxiv.org/abs/2102.02710",
    "authors": [
      "Angelos Aveklouris",
      "Levi DeValve",
      "Maximiliano Stock",
      "Amy R. Ward"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Performance (cs.PF)",
      "Systems and Control (eess.SY)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2104.12679",
    "title": "Impact of Spatial Frequency Based Constraints on Adversarial Robustness",
    "abstract": " Title: Impact of Spatial Frequency Based Constraints on Adversarial Robustness ",
    "url": "https://arxiv.org/abs/2104.12679",
    "authors": [
      "R\u00e9mi Bernhard",
      "Pierre-Alain Moellic",
      "Martial Mermillod",
      "Yannick Bourrier",
      "Romain Cohendet",
      "Miguel Solinas",
      "Marina Reyboz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.00292",
    "title": "Fair Data Representation for Machine Learning at the Pareto Frontier",
    "abstract": " Comments: 62 pages, 9 figures ",
    "url": "https://arxiv.org/abs/2201.00292",
    "authors": [
      "Shizhou Xu",
      "Thomas Strohmer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2205.00256",
    "title": "Heterogeneous Graph Neural Networks using Self-supervised Reciprocally  Contrastive Learning",
    "abstract": " Title: Heterogeneous Graph Neural Networks using Self-supervised Reciprocally  Contrastive Learning ",
    "url": "https://arxiv.org/abs/2205.00256",
    "authors": [
      "Cuiying Huo",
      "Dongxiao He",
      "Yawen Li",
      "Di Jin",
      "Jianwu Dang",
      "Weixiong Zhang",
      "Witold Pedrycz",
      "Lingfei Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09048",
    "title": "Global Contrast Masked Autoencoders Are Powerful Pathological  Representation Learners",
    "abstract": " Title: Global Contrast Masked Autoencoders Are Powerful Pathological  Representation Learners ",
    "url": "https://arxiv.org/abs/2205.09048",
    "authors": [
      "Hao Quan",
      "Xingyu Li",
      "Weixing Chen",
      "Qun Bai",
      "Mingchen Zou",
      "Ruijie Yang",
      "Tingting Zheng",
      "Ruiqun Qi",
      "Xinghua Gao",
      "Xiaoyu Cui"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.03403",
    "title": "On the design and analysis of near-term quantum network protocols using  Markov decision processes",
    "abstract": " Comments: v2: 19+37 pages, 17 figures; updated references; minor changes to the structure and presentation; similar to the published version ",
    "url": "https://arxiv.org/abs/2207.03403",
    "authors": [
      "Sumeet Khatri"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2207.04876",
    "title": "On the Intrinsic Structures of Spiking Neural Networks",
    "abstract": " Title: On the Intrinsic Structures of Spiking Neural Networks ",
    "url": "https://arxiv.org/abs/2207.04876",
    "authors": [
      "Shao-Qun Zhang",
      "Jia-Yi Chen",
      "Jin-Hui Wu",
      "Gao Zhang",
      "Huan Xiong",
      "Bin Gu",
      "Zhi-Hua Zhou"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.10265",
    "title": "FOCUS: Fairness via Agent-Awareness for Federated Learning on  Heterogeneous Data",
    "abstract": " Title: FOCUS: Fairness via Agent-Awareness for Federated Learning on  Heterogeneous Data ",
    "url": "https://arxiv.org/abs/2207.10265",
    "authors": [
      "Wenda Chu",
      "Chulin Xie",
      "Boxin Wang",
      "Linyi Li",
      "Lang Yin",
      "Arash Nourian",
      "Han Zhao",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2209.01473",
    "title": "Model-based Analysis and Specification of Functional Requirements and  Tests for Complex Automotive Systems",
    "abstract": " Title: Model-based Analysis and Specification of Functional Requirements and  Tests for Complex Automotive Systems ",
    "url": "https://arxiv.org/abs/2209.01473",
    "authors": [
      "Carsten Wiecher",
      "Constantin Mandel",
      "Matthias G\u00fcnther",
      "Jannik Fischbach",
      "Joel Greenyer",
      "Matthias Greinert",
      "Carsten Wolff",
      "Roman Dumitrescu",
      "Daniel Mendez",
      "Albert Albers"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2212.05197",
    "title": "Formal Model-Driven Analysis of Resilience of GossipSub to Attacks from  Misbehaving Peers",
    "abstract": " Comments: To appear in IEEE Security and Privacy 2024 (Oakland) ",
    "url": "https://arxiv.org/abs/2212.05197",
    "authors": [
      "Ankit Kumar",
      "Max von Hippel",
      "Pete Manolios",
      "Cristina Nita-Rotaru"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2302.14838",
    "title": "EvoPrompting: Language Models for Code-Level Neural Architecture Search",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2302.14838",
    "authors": [
      "Angelica Chen",
      "David M. Dohan",
      "David R. So"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.00783",
    "title": "Adversarial Examples Exist in Two-Layer ReLU Networks for Low  Dimensional Linear Subspaces",
    "abstract": " Comments: Camera ready version for NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2303.00783",
    "authors": [
      "Odelia Melamed",
      "Gilad Yehudai",
      "Gal Vardi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.04749",
    "title": "Data-Driven Robust Backward Reachable Sets for Set-Theoretic Model  Predictive Control",
    "abstract": " Comments: Preprint jointly submitted to IEEE Control Systems Letters (L-CSS) and IEEE Conference on Decision and Control (CDC) ",
    "url": "https://arxiv.org/abs/2303.04749",
    "authors": [
      "Mehran Attar",
      "Walter Lucia"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2303.06817",
    "title": "Transformation-Invariant Network for Few-Shot Object Detection in Remote  Sensing Images",
    "abstract": " Comments: Accepted by TGRS. Modified some errors from the previous version ",
    "url": "https://arxiv.org/abs/2303.06817",
    "authors": [
      "Nanqing Liu",
      "Xun Xu",
      "Turgay Celik",
      "Zongxin Gan",
      "Heng-Chao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.02816",
    "title": "Shannon meets Gray: Noise-robust, Low-sensitivity Codes with  Applications in Differential Privacy",
    "abstract": " Comments: 17 pages, SODA 2024 ",
    "url": "https://arxiv.org/abs/2305.02816",
    "authors": [
      "David Rasmussen Lolck",
      "Rasmus Pagh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2305.05400",
    "title": "Investigating the Corruption Robustness of Image Classifiers with Random  Lp-norm Corruptions",
    "abstract": " Comments: Preprint submitted to VISAPP 2024 ",
    "url": "https://arxiv.org/abs/2305.05400",
    "authors": [
      "Georg Siedel",
      "Weijia Shao",
      "Silvia Vock",
      "Andrey Morozov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.15270",
    "title": "Reversible Graph Neural Network-based Reaction Distribution Learning for  Multiple Appropriate Facial Reactions Generation",
    "abstract": " Title: Reversible Graph Neural Network-based Reaction Distribution Learning for  Multiple Appropriate Facial Reactions Generation ",
    "url": "https://arxiv.org/abs/2305.15270",
    "authors": [
      "Tong Xu",
      "Micol Spitale",
      "Hao Tang",
      "Lu Liu",
      "Hatice Gunes",
      "Siyang Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18651",
    "title": "UMD: Unsupervised Model Detection for X2X Backdoor Attacks",
    "abstract": " Comments: Proceedings of the 40th International Conference on Machine Learning ",
    "url": "https://arxiv.org/abs/2305.18651",
    "authors": [
      "Zhen Xiang",
      "Zidi Xiong",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.10532",
    "title": "Personalized Elastic Embedding Learning for On-Device Recommendation",
    "abstract": " Title: Personalized Elastic Embedding Learning for On-Device Recommendation ",
    "url": "https://arxiv.org/abs/2306.10532",
    "authors": [
      "Ruiqi Zheng",
      "Liang Qu",
      "Tong Chen",
      "Kai Zheng",
      "Yuhui Shi",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2306.12047",
    "title": "Residual-Based Error Corrector Operator to Enhance Accuracy and  Reliability of Neural Operator Surrogates of Nonlinear Variational  Boundary-Value Problems",
    "abstract": " Comments: 36 pages, 14 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2306.12047",
    "authors": [
      "Prashant K. Jha"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.12251",
    "title": "GADBench: Revisiting and Benchmarking Supervised Graph Anomaly Detection",
    "abstract": " Comments: NeurIPS 2023 Datasets and Benchmarks Track camera ready version ",
    "url": "https://arxiv.org/abs/2306.12251",
    "authors": [
      "Jianheng Tang",
      "Fengrui Hua",
      "Ziqi Gao",
      "Peilin Zhao",
      "Jia Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.12983",
    "title": "Towards More Realistic Membership Inference Attacks on Large Diffusion  Models",
    "abstract": " Comments: Accepted at WACV2024 ",
    "url": "https://arxiv.org/abs/2306.12983",
    "authors": [
      "Jan Dubi\u0144ski",
      "Antoni Kowalczuk",
      "Stanis\u0142aw Pawlak",
      "Przemys\u0142aw Rokita",
      "Tomasz Trzci\u0144ski",
      "Pawe\u0142 Morawiecki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.14670",
    "title": "Improved Bayes Risk Can Yield Reduced Social Welfare Under Competition",
    "abstract": " Comments: To appear at NeurIPS 2023; this is the full version ",
    "url": "https://arxiv.org/abs/2306.14670",
    "authors": [
      "Meena Jagadeesan",
      "Michael I. Jordan",
      "Jacob Steinhardt",
      "Nika Haghtalab"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2307.00534",
    "title": "Shared Growth of Graph Neural Networks via Prompted Free-direction  Knowledge Distillation",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2206.06561 ",
    "url": "https://arxiv.org/abs/2307.00534",
    "authors": [
      "Kaituo Feng",
      "Yikun Miao",
      "Changsheng Li",
      "Ye Yuan",
      "Guoren Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.01484",
    "title": "Robust finite element methods and solvers for the Biot--Brinkman  equations in vorticity form",
    "abstract": " Title: Robust finite element methods and solvers for the Biot--Brinkman  equations in vorticity form ",
    "url": "https://arxiv.org/abs/2307.01484",
    "authors": [
      "Ruben Caraballo",
      "Chansophea Wathanak In",
      "Alberto F. Mart\u00edn",
      "Ricardo Ruiz-Baier"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2307.07711",
    "title": "Sandpile Prediction on Structured Undirected Graphs",
    "abstract": " Comments: 62 pages, submitted to STOC24 ",
    "url": "https://arxiv.org/abs/2307.07711",
    "authors": [
      "Ruinian Chang",
      "Jingbang Chen",
      "Ian Munro",
      "Richard Peng",
      "Qingyu Shi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2307.08390",
    "title": "Correlation-aware Spatial-Temporal Graph Learning for Multivariate  Time-series Anomaly Detection",
    "abstract": " Comments: 17 pages, double columns, 10 tables, 3 figures. Accepted to IEEE Transactions on Neural Networks and Learning Systems (TNNLS) ",
    "url": "https://arxiv.org/abs/2307.08390",
    "authors": [
      "Yu Zheng",
      "Huan Yee Koh",
      "Ming Jin",
      "Lianhua Chi",
      "Khoa T. Phan",
      "Shirui Pan",
      "Yi-Ping Phoebe Chen",
      "Wei Xiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.10915",
    "title": "Revisiting Fine-Tuning Strategies for Self-supervised Medical Imaging  Analysis",
    "abstract": " Comments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2023, December 10th, 2023, New Orleans, United States, 18 pages ",
    "url": "https://arxiv.org/abs/2307.10915",
    "authors": [
      "Muhammad Osama Khan",
      "Yi Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.12327",
    "title": "End-to-end Hyperspectral Image Change Detection Network Based on Band  Selection",
    "abstract": " Title: End-to-end Hyperspectral Image Change Detection Network Based on Band  Selection ",
    "url": "https://arxiv.org/abs/2307.12327",
    "authors": [
      "Qingren Yao",
      "Yuan Zhou",
      "Chang Tang",
      "Wei Xiang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.16328",
    "title": "Debunking Disinformation: Revolutionizing Truth with NLP in Fake News  Detection",
    "abstract": " Comments: The content is not particularly relevant to the research ",
    "url": "https://arxiv.org/abs/2308.16328",
    "authors": [
      "Li He",
      "Siyi Hu",
      "Ailun Pei"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.04955",
    "title": "Information-Theoretic Bounds on The Removal of Attribute-Specific Bias  From Neural Networks",
    "abstract": " Comments: 15 pages, 4 figures, 3 tables. To appear in Algorithmic Fairness through the Lens of Time Workshop at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2310.04955",
    "authors": [
      "Jiazhi Li",
      "Mahyar Khayatkhoei",
      "Jiageng Zhu",
      "Hanchen Xie",
      "Mohamed E. Hussein",
      "Wael AbdAlmageed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.08176",
    "title": "Infinite Width Graph Neural Networks for Node Regression/ Classification",
    "abstract": " Comments: 49 Pages, 2 Figures (with subfigures), multiple tables, v2: made table of contents fit to one page and added derivatives on GAT*NTK and GAT*GP in A.4, v3: shorten parts of introduction and fixed typos, added numberings to equations and discussion section ",
    "url": "https://arxiv.org/abs/2310.08176",
    "authors": [
      "Yunus Cobanoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15015",
    "title": "Leveraging Deep Learning for Abstractive Code Summarization of  Unofficial Documentation",
    "abstract": " Title: Leveraging Deep Learning for Abstractive Code Summarization of  Unofficial Documentation ",
    "url": "https://arxiv.org/abs/2310.15015",
    "authors": [
      "AmirHossein Naghshzan",
      "Latifa Guerrouj",
      "Olga Baysal"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15808",
    "title": "Dissecting the Performance of Satellite Network Operators",
    "abstract": " Comments: Published at International Conference on emerging Networking EXperiments and Technologies (CoNEXT 2023). Please cite the CoNEXT version ",
    "url": "https://arxiv.org/abs/2310.15808",
    "authors": [
      "Aravindh Raman",
      "Matteo Varvello",
      "Hyunseok Chang",
      "Nishanth Sastry",
      "Yasir Zaki"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.18583",
    "title": "Self-Supervised Multi-Modality Learning for Multi-Label Skin Lesion  Classification",
    "abstract": " Title: Self-Supervised Multi-Modality Learning for Multi-Label Skin Lesion  Classification ",
    "url": "https://arxiv.org/abs/2310.18583",
    "authors": [
      "Hao Wang",
      "Euijoon Ahn",
      "Lei Bi",
      "Jinman Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.20522",
    "title": "Tight bounds on adjacency labels for monotone graph classes",
    "abstract": " Comments: 18 pages, 1 figure. arXiv admin note: text overlap with arXiv:2307.11225 ",
    "url": "https://arxiv.org/abs/2310.20522",
    "authors": [
      "\u00c9douard Bonnet",
      "Julien Duron",
      "John Sylvester",
      "Viktor Zamaraev",
      "Maksim Zhukovskii"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2311.00440",
    "title": "Maximum $k$- vs. $\\ell$-colourings of graphs",
    "abstract": " Comments: an extra hardness result ",
    "url": "https://arxiv.org/abs/2311.00440",
    "authors": [
      "Tamio-Vesa Nakajima",
      "Stanislav \u017divn\u00fd"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2311.01655",
    "title": "Detecting Spurious Correlations via Robust Visual Concepts in Real and  AI-Generated Image Classification",
    "abstract": " Comments: Paper accepted at 37th Conference on Neural Information Processing Systems (NeurIPS 2023), XAIA Workshop ",
    "url": "https://arxiv.org/abs/2311.01655",
    "authors": [
      "Preetam Prabhu Srikar Dammu",
      "Chirag Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.02782",
    "title": "Towards Generic Anomaly Detection and Understanding: Large-scale  Visual-linguistic Model (GPT-4V) Takes the Lead",
    "abstract": " Comments: Work in progress. Evaluated GPT-4V on 4 modalities, 9 tasks, and 15 datasets. The first three authors contribute equally ",
    "url": "https://arxiv.org/abs/2311.02782",
    "authors": [
      "Yunkang Cao",
      "Xiaohao Xu",
      "Chen Sun",
      "Xiaonan Huang",
      "Weiming Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.02869",
    "title": "Lightweight equivariant interaction graph neural network for accurate  and efficient interatomic potential and force predictions",
    "abstract": " Title: Lightweight equivariant interaction graph neural network for accurate  and efficient interatomic potential and force predictions ",
    "url": "https://arxiv.org/abs/2311.02869",
    "authors": [
      "Ziduo Yang",
      "Xian Wang",
      "Yifan Li",
      "Qiujie Lv",
      "Calvin Yu-Chian Chen",
      "Lei Shen"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2311.04950",
    "title": "Lightweight Diffusion Models with Distillation-Based Block Neural  Architecture Search",
    "abstract": " Title: Lightweight Diffusion Models with Distillation-Based Block Neural  Architecture Search ",
    "url": "https://arxiv.org/abs/2311.04950",
    "authors": [
      "Siao Tang",
      "Xin Wang",
      "Hong Chen",
      "Chaoyu Guan",
      "Yansong Tang",
      "Wenwu zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.05237",
    "title": "Widely Applicable Strong Baseline for Sports Ball Detection and Tracking",
    "abstract": " Comments: BMVC2023. Code & dataset : this https URL ",
    "url": "https://arxiv.org/abs/2311.05237",
    "authors": [
      "Shuhei Tarashima",
      "Muhammad Abdul Haq",
      "Yushan Wang",
      "Norio Tagawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.05371",
    "title": "Training Robust Deep Physiological Measurement Models with Synthetic  Video-based Data",
    "abstract": " Title: Training Robust Deep Physiological Measurement Models with Synthetic  Video-based Data ",
    "url": "https://arxiv.org/abs/2311.05371",
    "authors": [
      "Yuxuan Ou",
      "Yuzhe Zhang",
      "Yuntang Wang",
      "Shwetak Patel",
      "Daniel McDuf",
      "Yuzhe Yang",
      "Xin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.07141",
    "title": "SABAF: Removing Strong Attribute Bias from Neural Networks with  Adversarial Filtering",
    "abstract": " Comments: 35 pages, 18 figures, 32 tables. This work is an extended version of our paper (arXiv:2310.04955). Code will be released at this https URL ",
    "url": "https://arxiv.org/abs/2311.07141",
    "authors": [
      "Jiazhi Li",
      "Mahyar Khayatkhoei",
      "Jiageng Zhu",
      "Hanchen Xie",
      "Mohamed E. Hussein",
      "Wael AbdAlmageed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2311.07370",
    "title": "Classification of developmental and brain disorders via graph  convolutional aggregation",
    "abstract": " Title: Classification of developmental and brain disorders via graph  convolutional aggregation ",
    "url": "https://arxiv.org/abs/2311.07370",
    "authors": [
      "Ibrahim Salim",
      "A. Ben Hamza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.07587",
    "title": "Frontier Language Models are not Robust to Adversarial Arithmetic, or  \"What do I need to say so you agree 2+2=5?",
    "abstract": " Title: Frontier Language Models are not Robust to Adversarial Arithmetic, or  \"What do I need to say so you agree 2+2=5? ",
    "url": "https://arxiv.org/abs/2311.07587",
    "authors": [
      "C. Daniel Freeman",
      "Laura Culp",
      "Aaron Parisi",
      "Maxwell L Bileschi",
      "Gamaleldin F Elsayed",
      "Alex Rizkowsky",
      "Isabelle Simpson",
      "Alex Alemi",
      "Azade Nova",
      "Ben Adlam",
      "Bernd Bohnet",
      "Gaurav Mishra",
      "Hanie Sedghi",
      "Igor Mordatch",
      "Izzeddin Gur",
      "Jaehoon Lee",
      "JD Co-Reyes",
      "Jeffrey Pennington",
      "Kelvin Xu",
      "Kevin Swersky",
      "Kshiteej Mahajan",
      "Lechao Xiao",
      "Rosanne Liu",
      "Simon Kornblith",
      "Noah Constant",
      "Peter J. Liu",
      "Roman Novak",
      "Yundi Qian",
      "Noah Fiedel",
      "Jascha Sohl-Dickstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.08167",
    "title": "SeDe: Balancing Blockchain Privacy and Regulatory Compliance by  Selective De-Anonymization",
    "abstract": " Title: SeDe: Balancing Blockchain Privacy and Regulatory Compliance by  Selective De-Anonymization ",
    "url": "https://arxiv.org/abs/2311.08167",
    "authors": [
      "Naveen Sahu",
      "Mitul Gajera",
      "Amit Chaudhary",
      "Hamish Ivey-Law"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.09174",
    "title": "AbsPyramid: Benchmarking the Abstraction Ability of Language Models with  a Unified Entailment Graph",
    "abstract": " Comments: Work in progress ",
    "url": "https://arxiv.org/abs/2311.09174",
    "authors": [
      "Zhaowei Wang",
      "Haochen Shi",
      "Weiqi Wang",
      "Tianqing Fang",
      "Hongming Zhang",
      "Sehyun Choi",
      "Xin Liu",
      "Yangqiu Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]