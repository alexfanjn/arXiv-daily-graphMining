[
  {
    "id": "arXiv:2311.01473",
    "title": "Adversarial Examples in the Physical World: A Survey",
    "abstract": "Deep neural networks (DNNs) have demonstrated high vulnerability to adversarial examples. Besides the attacks in the digital world, the practical implications of adversarial examples in the physical world present significant challenges and safety concerns. However, current research on physical adversarial examples (PAEs) lacks a comprehensive understanding of their unique characteristics, leading to limited significance and understanding. In this paper, we address this gap by thoroughly examining the characteristics of PAEs within a practical workflow encompassing training, manufacturing, and re-sampling processes. By analyzing the links between physical adversarial attacks, we identify manufacturing and re-sampling as the primary sources of distinct attributes and particularities in PAEs. Leveraging this knowledge, we develop a comprehensive analysis and classification framework for PAEs based on their specific characteristics, covering over 100 studies on physical-world adversarial examples. Furthermore, we investigate defense strategies against PAEs and identify open challenges and opportunities for future research. We aim to provide a fresh, thorough, and systematic understanding of PAEs, thereby promoting the development of robust adversarial learning and its application in open-world scenarios. ",
    "url": "https://arxiv.org/abs/2311.01473",
    "authors": [
      "Jiakai Wang",
      "Donghua Wang",
      "Jin Hu",
      "Siyang Wu",
      "Tingsong Jiang",
      "Wen Yao",
      "Aishan Liu",
      "Xianglong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01475",
    "title": "Patch-Based Deep Unsupervised Image Segmentation using Graph Cuts",
    "abstract": "Unsupervised image segmentation aims at grouping different semantic patterns in an image without the use of human annotation. Similarly, image clustering searches for groupings of images based on their semantic content without supervision. Classically, both problems have captivated researchers as they drew from sound mathematical concepts to produce concrete applications. With the emergence of deep learning, the scientific community turned its attention to complex neural network-based solvers that achieved impressive results in those domains but rarely leveraged the advances made by classical methods. In this work, we propose a patch-based unsupervised image segmentation strategy that bridges advances in unsupervised feature extraction from deep clustering methods with the algorithmic help of classical graph-based methods. We show that a simple convolutional neural network, trained to classify image patches and iteratively regularized using graph cuts, naturally leads to a state-of-the-art fully-convolutional unsupervised pixel-level segmenter. Furthermore, we demonstrate that this is the ideal setting for leveraging the patch-level pairwise features generated by vision transformer models. Our results on real image data demonstrate the effectiveness of our proposed methodology. ",
    "url": "https://arxiv.org/abs/2311.01475",
    "authors": [
      "Isaac Wasserman",
      "Jeova Farias Sales Rocha Neto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2311.01479",
    "title": "Detecting Out-of-Distribution Through the Lens of Neural Collapse",
    "abstract": "Out-of-distribution (OOD) detection is essential for the safe deployment of AI. Particularly, OOD detectors should generalize effectively across diverse scenarios. To improve upon the generalizability of existing OOD detectors, we introduce a highly versatile OOD detector, called Neural Collapse inspired OOD detector (NC-OOD). We extend the prevalent observation that in-distribution (ID) features tend to form clusters, whereas OOD features are far away. Particularly, based on the recent observation, Neural Collapse, we further demonstrate that ID features tend to cluster in proximity to weight vectors. From our extended observation, we propose to detect OOD based on feature proximity to weight vectors. To further rule out OOD samples, we leverage the observation that OOD features tend to reside closer to the origin than ID features. Extensive experiments show that our approach enhances the generalizability of existing work and can consistently achieve state-of-the-art OOD detection performance across a wide range of OOD Benchmarks over different classification tasks, training losses, and model architectures. ",
    "url": "https://arxiv.org/abs/2311.01479",
    "authors": [
      "Litian Liu",
      "Yao Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2311.01483",
    "title": "FedSN: A General Federated Learning Framework over LEO Satellite  Networks",
    "abstract": "Recently, a large number of Low Earth Orbit (LEO) satellites have been launched and deployed successfully in space by commercial companies, such as SpaceX. Due to multimodal sensors equipped by the LEO satellites, they serve not only for communication but also for various machine learning applications, such as space modulation recognition, remote sensing image classification, etc. However, the ground station (GS) may be incapable of downloading such a large volume of raw sensing data for centralized model training due to the limited contact time with LEO satellites (e.g. 5 minutes). Therefore, federated learning (FL) has emerged as the promising solution to address this problem via on-device training. Unfortunately, to enable FL on LEO satellites, we still face three critical challenges that are i) heterogeneous computing and memory capabilities, ii) limited uplink rate, and iii) model staleness. To this end, we propose FedSN as a general FL framework to tackle the above challenges, and fully explore data diversity on LEO satellites. Specifically, we first present a novel sub-structure scheme to enable heterogeneous local model training considering different computing, memory, and communication constraints on LEO satellites. Additionally, we propose a pseudo-synchronous model aggregation strategy to dynamically schedule model aggregation for compensating model staleness. To further demonstrate the effectiveness of the FedSN, we evaluate it using space modulation recognition and remote sensing image classification tasks by leveraging the data from real-world satellite networks. Extensive experimental results demonstrate that FedSN framework achieves higher accuracy, lower computing, and communication overhead than the state-of-the-art benchmarks and the effectiveness of each components in FedSN. ",
    "url": "https://arxiv.org/abs/2311.01483",
    "authors": [
      "Zheng Lin",
      "Zhe Chen",
      "Zihan Fang",
      "Xianhao Chen",
      "Xiong Wang",
      "Yue Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.01487",
    "title": "What Makes for Good Visual Instructions? Synthesizing Complex Visual  Reasoning Instructions for Visual Instruction Tuning",
    "abstract": "Visual instruction tuning is an essential approach to improving the zero-shot generalization capability of Multi-modal Large Language Models (MLLMs). A surge of visual instruction datasets with various focuses and characteristics have been proposed recently, enabling MLLMs to achieve surprising results on evaluation benchmarks. To develop more capable MLLMs, in this paper, we aim to investigate a more fundamental question: ``what makes for good visual instructions?''. By conducting a comprehensive empirical study, we find that instructions focused on complex visual reasoning tasks are particularly effective in improving the performance of MLLMs on evaluation benchmarks. Building upon this finding, we design a systematic approach to automatically creating high-quality complex visual reasoning instructions. Our approach employs a synthesis-complication-reformulation paradigm, leveraging multiple stages to gradually increase the complexity of the instructions while guaranteeing quality. Based on this approach, we create the synthetic visual reasoning instruction dataset consisting of 32K examples, namely ComVint, and fine-tune four MLLMs on it. Experimental results demonstrate that our dataset consistently enhances the performance of all the compared MLLMs, e.g., improving the performance of MiniGPT-4 and BLIP-2 on MME-Cognition by 32.6% and 28.8%, respectively. Our code and data are publicly available at the link: https://github.com/RUCAIBox/ComVint. ",
    "url": "https://arxiv.org/abs/2311.01487",
    "authors": [
      "Yifan Du",
      "Hangyu Guo",
      "Kun Zhou",
      "Wayne Xin Zhao",
      "Jinpeng Wang",
      "Chuyuan Wang",
      "Mingchen Cai",
      "Ruihua Song",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.01490",
    "title": "The Behavior of Large Language Models When Prompted to Generate Code  Explanations",
    "abstract": "This paper systematically explores how Large Language Models (LLMs) generate explanations of code examples of the type used in intro-to-programming courses. As we show, the nature of code explanations generated by LLMs varies considerably based on the wording of the prompt, the target code examples being explained, the programming language, the temperature parameter, and the version of the LLM. Nevertheless, they are consistent in two major respects for Java and Python: the readability level, which hovers around 7-8 grade, and lexical density, i.e., the relative size of the meaningful words with respect to the total explanation size. Furthermore, the explanations score very high in correctness but less on three other metrics: completeness, conciseness, and contextualization. ",
    "url": "https://arxiv.org/abs/2311.01490",
    "authors": [
      "Priti Oli",
      "Rabin Banjade",
      "Jeevan Chapagain",
      "Vasile Rus"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.01522",
    "title": "An Efficient Detection and Control System for Underwater Docking using  Machine Learning and Realistic Simulation: A Comprehensive Approach",
    "abstract": "Underwater docking is critical to enable the persistent operation of Autonomous Underwater Vehicles (AUVs). For this, the AUV must be capable of detecting and localizing the docking station, which is complex due to the highly dynamic undersea environment. Image-based solutions offer a high acquisition rate and versatile alternative to adapt to this environment; however, the underwater environment presents challenges such as low visibility, high turbidity, and distortion. In addition to this, field experiments to validate underwater docking capabilities can be costly and dangerous due to the specialized equipment and safety considerations required to conduct the experiments. This work compares different deep-learning architectures to perform underwater docking detection and classification. The architecture with the best performance is then compressed using knowledge distillation under the teacher-student paradigm to reduce the network's memory footprint, allowing real-time implementation. To reduce the simulation-to-reality gap, a Generative Adversarial Network (GAN) is used to do image-to-image translation, converting the Gazebo simulation image into a realistic underwater-looking image. The obtained image is then processed using an underwater image formation model to simulate image attenuation over distance under different water types. The proposed method is finally evaluated according to the AUV docking success rate and compared with classical vision methods. The simulation results show an improvement of 20% in the high turbidity scenarios regardless of the underwater currents. Furthermore, we show the performance of the proposed approach by showing experimental results on the off-the-shelf AUV Iver3. ",
    "url": "https://arxiv.org/abs/2311.01522",
    "authors": [
      "Jalil Chavez-Galaviz",
      "Jianwen Li",
      "Matthew Bergman",
      "Miras Mengdibayev"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01526",
    "title": "ATGNN: Audio Tagging Graph Neural Network",
    "abstract": "Deep learning models such as CNNs and Transformers have achieved impressive performance for end-to-end audio tagging. Recent works have shown that despite stacking multiple layers, the receptive field of CNNs remains severely limited. Transformers on the other hand are able to map global context through self-attention, but treat the spectrogram as a sequence of patches which is not flexible enough to capture irregular audio objects. In this work, we treat the spectrogram in a more flexible way by considering it as graph structure and process it with a novel graph neural architecture called ATGNN. ATGNN not only combines the capability of CNNs with the global information sharing ability of Graph Neural Networks, but also maps semantic relationships between learnable class embeddings and corresponding spectrogram regions. We evaluate ATGNN on two audio tagging tasks, where it achieves 0.585 mAP on the FSD50K dataset and 0.335 mAP on the AudioSet-balanced dataset, achieving comparable results to Transformer based models with significantly lower number of learnable parameters. ",
    "url": "https://arxiv.org/abs/2311.01526",
    "authors": [
      "Shubhr Singh",
      "Christian J. Steinmetz",
      "Emmanouil Benetos",
      "Huy Phan",
      "Dan Stowell"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2311.01530",
    "title": "NOD-TAMP: Multi-Step Manipulation Planning with Neural Object  Descriptors",
    "abstract": "Developing intelligent robots for complex manipulation tasks in household and factory settings remains challenging due to long-horizon tasks, contact-rich manipulation, and the need to generalize across a wide variety of object shapes and scene layouts. While Task and Motion Planning (TAMP) offers a promising solution, its assumptions such as kinodynamic models limit applicability in novel contexts. Neural object descriptors (NODs) have shown promise in object and scene generalization but face limitations in addressing broader tasks. Our proposed TAMP-based framework, NOD-TAMP, extracts short manipulation trajectories from a handful of human demonstrations, adapts these trajectories using NOD features, and composes them to solve broad long-horizon tasks. Validated in a simulation environment, NOD-TAMP effectively tackles varied challenges and outperforms existing methods, establishing a cohesive framework for manipulation planning. For videos and other supplemental material, see the project website: https://sites.google.com/view/nod-tamp/. ",
    "url": "https://arxiv.org/abs/2311.01530",
    "authors": [
      "Shuo Cheng",
      "Caelan Garrett",
      "Ajay Mandlekar",
      "Danfei Xu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.01553",
    "title": "Total Variation Meets Differential Privacy",
    "abstract": "The framework of approximate differential privacy is considered, and augmented by introducing the notion of \"the total variation of a (privacy-preserving) mechanism\" (denoted by $\\eta$-TV). With this refinement, an exact composition result is derived, and shown to be significantly tighter than the optimal bounds for differential privacy (which do not consider the total variation). Furthermore, it is shown that $(\\varepsilon,\\delta)$-DP with $\\eta$-TV is closed under subsampling. The induced total variation of commonly used mechanisms are computed. Moreover, the notion of total variation of a mechanism is extended to the local privacy setting and privacy-utility tradeoffs are investigated. In particular, total variation distance and KL divergence are considered as utility functions and upper bounds are derived. Finally, the results are compared and connected to the (purely) locally differentially private setting. ",
    "url": "https://arxiv.org/abs/2311.01553",
    "authors": [
      "Elena Ghazi",
      "Ibrahim Issa"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2311.01559",
    "title": "The effect of disruptive events on spatial and social interactions: An  assessment of structural changes in pre-and post-COVID-19 pandemic networks",
    "abstract": "Disruptive events significantly alter spatial and social interactions among people and places. To examine the structural changes in spatial and social interaction networks in pre- and post-periods of the COVID-19 pandemic, we employ the Louvain method to algorithmically detect regions (communities) within the county-to-county networks of the SafeGraph mobility and Facebook social connectedness. We then utilize a range of partition similarity metrics, including adjusted Rand, z-Rand, Normalized Mutual Information (NMI), and Jaccard indices, to quantitatively measure the similarity of regions between the pre- and post-periods partitions of each network. Our findings reveal that in the post-pandemic period, spatial interactions led to the formation of localized geographic communities or regions characterized by higher modular activity within each region. In contrast, online social interactions shifted towards longer distance connections, resulting in the emergence of larger regions marked by strong friendship ties that often encompassed multiple states. By understanding these changes, we contribute to a better comprehension of the pandemic's impact on our interconnected physical-virtual world, providing valuable insights for future research and informing strategies to adapt to the evolving dynamics of human interactions. ",
    "url": "https://arxiv.org/abs/2311.01559",
    "authors": [
      "Caglar Koylu",
      "Maryam Torkashvand"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.01563",
    "title": "Assist Is Just as Important as the Goal: Image Resurfacing to Aid  Model's Robust Prediction",
    "abstract": "Adversarial patches threaten visual AI models in the real world. The number of patches in a patch attack is variable and determines the attack's potency in a specific environment. Most existing defenses assume a single patch in the scene, and the multiple patch scenarios are shown to overcome them. This paper presents a model-agnostic defense against patch attacks based on total variation for image resurfacing (TVR). The TVR is an image-cleansing method that processes images to remove probable adversarial regions. TVR can be utilized solely or augmented with a defended model, providing multi-level security for robust prediction. TVR nullifies the influence of patches in a single image scan with no prior assumption on the number of patches in the scene. We validate TVR on the ImageNet-Patch benchmark dataset and with real-world physical objects, demonstrating its ability to mitigate patch attack. ",
    "url": "https://arxiv.org/abs/2311.01563",
    "authors": [
      "Abhijith Sharma",
      "Phil Munz",
      "Apurva Narayan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.01573",
    "title": "Improving Fairness using Vision-Language Driven Image Augmentation",
    "abstract": "Fairness is crucial when training a deep-learning discriminative model, especially in the facial domain. Models tend to correlate specific characteristics (such as age and skin color) with unrelated attributes (downstream tasks), resulting in biases which do not correspond to reality. It is common knowledge that these correlations are present in the data and are then transferred to the models during training. This paper proposes a method to mitigate these correlations to improve fairness. To do so, we learn interpretable and meaningful paths lying in the semantic space of a pre-trained diffusion model (DiffAE) -- such paths being supervised by contrastive text dipoles. That is, we learn to edit protected characteristics (age and skin color). These paths are then applied to augment images to improve the fairness of a given dataset. We test the proposed method on CelebA-HQ and UTKFace on several downstream tasks with age and skin color as protected characteristics. As a proxy for fairness, we compute the difference in accuracy with respect to the protected characteristics. Quantitative results show how the augmented images help the model improve the overall accuracy, the aforementioned metric, and the disparity of equal opportunity. Code is available at: https://github.com/Moreno98/Vision-Language-Bias-Control. ",
    "url": "https://arxiv.org/abs/2311.01573",
    "authors": [
      "Moreno D'Inc\u00e0",
      "Christos Tzelepis",
      "Ioannis Patras",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01589",
    "title": "A Statistical Guarantee for Representation Transfer in Multitask  Imitation Learning",
    "abstract": "Transferring representation for multitask imitation learning has the potential to provide improved sample efficiency on learning new tasks, when compared to learning from scratch. In this work, we provide a statistical guarantee indicating that we can indeed achieve improved sample efficiency on the target task when a representation is trained using sufficiently diverse source tasks. Our theoretical results can be readily extended to account for commonly used neural network architectures with realistic assumptions. We conduct empirical analyses that align with our theoretical findings on four simulated environments$\\unicode{x2014}$in particular leveraging more data from source tasks can improve sample efficiency on learning in the new task. ",
    "url": "https://arxiv.org/abs/2311.01589",
    "authors": [
      "Bryan Chan",
      "Karime Pereida",
      "James Bergstra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01591",
    "title": "Better Fair than Sorry: Adversarial Missing Data Imputation for Fair  GNNs",
    "abstract": "This paper addresses the problem of learning fair Graph Neural Networks (GNNs) under missing protected attributes. GNNs have achieved state-of-the-art results in many relevant tasks where decisions might disproportionately impact specific communities. However, existing work on fair GNNs assumes that either protected attributes are fully-observed or that the missing data imputation is fair. In practice, biases in the imputation will be propagated to the model outcomes, leading them to overestimate the fairness of their predictions. We address this challenge by proposing Better Fair than Sorry (BFtS), a fair missing data imputation model for protected attributes used by fair GNNs. The key design principle behind BFtS is that imputations should approximate the worst-case scenario for the fair GNN -- i.e. when optimizing fairness is the hardest. We implement this idea using a 3-player adversarial scheme where two adversaries collaborate against the fair GNN. Experiments using synthetic and real datasets show that BFtS often achieves a better fairness $\\times$ accuracy trade-off than existing alternatives. ",
    "url": "https://arxiv.org/abs/2311.01591",
    "authors": [
      "Debolina Halder Lina",
      "Arlei Silva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01605",
    "title": "Faithful and Robust Local Interpretability for Textual Predictions",
    "abstract": "Interpretability is essential for machine learning models to be trusted and deployed in critical domains. However, existing methods for interpreting text models are often complex, lack solid mathematical foundations, and their performance is not guaranteed. In this paper, we propose FRED (Faithful and Robust Explainer for textual Documents), a novel method for interpreting predictions over text. FRED identifies key words in a document that significantly impact the prediction when removed. We establish the reliability of FRED through formal definitions and theoretical analyses on interpretable classifiers. Additionally, our empirical evaluation against state-of-the-art methods demonstrates the effectiveness of FRED in providing insights into text models. ",
    "url": "https://arxiv.org/abs/2311.01605",
    "authors": [
      "Gianluigi Lopardo",
      "Frederic Precioso",
      "Damien Garreau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.01642",
    "title": "Robust Adversarial Reinforcement Learning via Bounded Rationality  Curricula",
    "abstract": "Robustness against adversarial attacks and distribution shifts is a long-standing goal of Reinforcement Learning (RL). To this end, Robust Adversarial Reinforcement Learning (RARL) trains a protagonist against destabilizing forces exercised by an adversary in a competitive zero-sum Markov game, whose optimal solution, i.e., rational strategy, corresponds to a Nash equilibrium. However, finding Nash equilibria requires facing complex saddle point optimization problems, which can be prohibitive to solve, especially for high-dimensional control. In this paper, we propose a novel approach for adversarial RL based on entropy regularization to ease the complexity of the saddle point optimization problem. We show that the solution of this entropy-regularized problem corresponds to a Quantal Response Equilibrium (QRE), a generalization of Nash equilibria that accounts for bounded rationality, i.e., agents sometimes play random actions instead of optimal ones. Crucially, the connection between the entropy-regularized objective and QRE enables free modulation of the rationality of the agents by simply tuning the temperature coefficient. We leverage this insight to propose our novel algorithm, Quantal Adversarial RL (QARL), which gradually increases the rationality of the adversary in a curriculum fashion until it is fully rational, easing the complexity of the optimization problem while retaining robustness. We provide extensive evidence of QARL outperforming RARL and recent baselines across several MuJoCo locomotion and navigation problems in overall performance and robustness. ",
    "url": "https://arxiv.org/abs/2311.01642",
    "authors": [
      "Aryaman Reddi",
      "Maximilian T\u00f6lle",
      "Jan Peters",
      "Georgia Chalvatzaki",
      "Carlo D'Eramo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01644",
    "title": "Should Under-parameterized Student Networks Copy or Average Teacher  Weights?",
    "abstract": "Any continuous function $f^*$ can be approximated arbitrarily well by a neural network with sufficiently many neurons $k$. We consider the case when $f^*$ itself is a neural network with one hidden layer and $k$ neurons. Approximating $f^*$ with a neural network with $n< k$ neurons can thus be seen as fitting an under-parameterized \"student\" network with $n$ neurons to a \"teacher\" network with $k$ neurons. As the student has fewer neurons than the teacher, it is unclear, whether each of the $n$ student neurons should copy one of the teacher neurons or rather average a group of teacher neurons. For shallow neural networks with erf activation function and for the standard Gaussian input distribution, we prove that \"copy-average\" configurations are critical points if the teacher's incoming vectors are orthonormal and its outgoing weights are unitary. Moreover, the optimum among such configurations is reached when $n-1$ student neurons each copy one teacher neuron and the $n$-th student neuron averages the remaining $k-n+1$ teacher neurons. For the student network with $n=1$ neuron, we provide additionally a closed-form solution of the non-trivial critical point(s) for commonly used activation functions through solving an equivalent constrained optimization problem. Empirically, we find for the erf activation function that gradient flow converges either to the optimal copy-average critical point or to another point where each student neuron approximately copies a different teacher neuron. Finally, we find similar results for the ReLU activation function, suggesting that the optimal solution of underparameterized networks has a universal structure. ",
    "url": "https://arxiv.org/abs/2311.01644",
    "authors": [
      "Berfin \u015eim\u015fek",
      "Amire Bendjeddou",
      "Wulfram Gerstner",
      "Johanni Brea"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.01647",
    "title": "Calibrate and Boost Logical Expressiveness of GNN Over Multi-Relational  and Temporal Graphs",
    "abstract": "As a powerful framework for graph representation learning, Graph Neural Networks (GNNs) have garnered significant attention in recent years. However, to the best of our knowledge, there has been no formal analysis of the logical expressiveness of GNNs as Boolean node classifiers over multi-relational graphs, where each edge carries a specific relation type. In this paper, we investigate $\\mathcal{FOC}_2$, a fragment of first-order logic with two variables and counting quantifiers. On the negative side, we demonstrate that the R$^2$-GNN architecture, which extends the local message passing GNN by incorporating global readout, fails to capture $\\mathcal{FOC}_2$ classifiers in the general case. Nevertheless, on the positive side, we establish that R$^2$-GNNs models are equivalent to $\\mathcal{FOC}_2$ classifiers under certain restricted yet reasonable scenarios. To address the limitations of R$^2$-GNNs regarding expressiveness, we propose a simple graph transformation technique, akin to a preprocessing step, which can be executed in linear time. This transformation enables R$^2$-GNNs to effectively capture any $\\mathcal{FOC}_2$ classifiers when applied to the \"transformed\" input graph. Moreover, we extend our analysis of expressiveness and graph transformation to temporal graphs, exploring several temporal GNN architectures and providing an expressiveness hierarchy for them. To validate our findings, we implement R$^2$-GNNs and the graph transformation technique and conduct empirical tests in node classification tasks against various well-known GNN architectures that support multi-relational or temporal graphs. Our experimental results consistently demonstrate that R$^2$-GNN with the graph transformation outperforms the baseline methods on both synthetic and real-world datasets ",
    "url": "https://arxiv.org/abs/2311.01647",
    "authors": [
      "Yeyuan Chen",
      "Dingmin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2311.01655",
    "title": "Detecting Spurious Correlations via Robust Visual Concepts in Real and  AI-Generated Image Classification",
    "abstract": "Often machine learning models tend to automatically learn associations present in the training data without questioning their validity or appropriateness. This undesirable property is the root cause of the manifestation of spurious correlations, which render models unreliable and prone to failure in the presence of distribution shifts. Research shows that most methods attempting to remedy spurious correlations are only effective for a model's known spurious associations. Current spurious correlation detection algorithms either rely on extensive human annotations or are too restrictive in their formulation. Moreover, they rely on strict definitions of visual artifacts that may not apply to data produced by generative models, as they are known to hallucinate contents that do not conform to standard specifications. In this work, we introduce a general-purpose method that efficiently detects potential spurious correlations, and requires significantly less human interference in comparison to the prior art. Additionally, the proposed method provides intuitive explanations while eliminating the need for pixel-level annotations. We demonstrate the proposed method's tolerance to the peculiarity of AI-generated images, which is a considerably challenging task, one where most of the existing methods fall short. Consequently, our method is also suitable for detecting spurious correlations that may propagate to downstream applications originating from generative models. ",
    "url": "https://arxiv.org/abs/2311.01655",
    "authors": [
      "Preetam Prabhu Srikar Dammu",
      "Chirag Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01659",
    "title": "Efficient Cloud Pipelines for Neural Radiance Fields",
    "abstract": "Since their introduction in 2020, Neural Radiance Fields (NeRFs) have taken the computer vision community by storm. They provide a multi-view representation of a scene or object that is ideal for eXtended Reality (XR) applications and for creative endeavors such as virtual production, as well as change detection operations in geospatial analytics. The computational cost of these generative AI models is quite high, however, and the construction of cloud pipelines to generate NeRFs is neccesary to realize their potential in client applications. In this paper, we present pipelines on a high performance academic computing cluster and compare it with a pipeline implemented on Microsoft Azure. Along the way, we describe some uses of NeRFs in enabling novel user interaction scenarios. ",
    "url": "https://arxiv.org/abs/2311.01659",
    "authors": [
      "Derek Jacoby",
      "Donglin Xu",
      "Weder Ribas",
      "Minyi Xu",
      "Ting Liu",
      "Vishwanath Jayaraman",
      "Mengdi Wei",
      "Emma De Blois",
      "Yvonne Coady"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01661",
    "title": "Deep Learning-driven Community Resilience Rating based on Intertwined  Socio-Technical Systems Features",
    "abstract": "Community resilience is a complex and muti-faceted phenomenon that emerges from complex and nonlinear interactions among different socio-technical systems and their resilience properties. However, present studies on community resilience focus primarily on vulnerability assessment and utilize index-based approaches, with limited ability to capture heterogeneous features within community socio-technical systems and their nonlinear interactions in shaping robustness, redundancy, and resourcefulness components of resilience. To address this gap, this paper presents an integrated three-layer deep learning model for community resilience rating (called Resili-Net). Twelve measurable resilience features are specified and computed within community socio-technical systems (i.e., facilities, infrastructures, and society) related to three resilience components of robustness, redundancy, and resourcefulness. Using publicly accessible data from multiple metropolitan statistical areas in the United States, Resili-Net characterizes the resilience levels of spatial areas into five distinct levels. The interpretability of the model outcomes enables feature analysis for specifying the determinants of resilience in areas within each resilience level, allowing for the identification of specific resilience enhancement strategies. Changes in community resilience profiles under urban development patterns are further examined by changing the value of related socio-technical systems features. Accordingly, the outcomes provide novel perspectives for community resilience assessment by harnessing machine intelligence and heterogeneous urban big data. ",
    "url": "https://arxiv.org/abs/2311.01661",
    "authors": [
      "Kai Yin",
      "Ali Mostafavi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2311.01676",
    "title": "MineSegSAT: An automated system to evaluate mining disturbed area  extents from Sentinel-2 imagery",
    "abstract": "Assessing the environmental impact of the mineral extraction industry plays a critical role in understanding and mitigating the ecological consequences of extractive activities. This paper presents MineSegSAT, a model that presents a novel approach to predicting environmentally impacted areas of mineral extraction sites using the SegFormer deep learning segmentation architecture trained on Sentinel-2 data. The data was collected from non-overlapping regions over Western Canada in 2021 containing areas of land that have been environmentally impacted by mining activities that were identified from high-resolution satellite imagery in 2021. The SegFormer architecture, a state-of-the-art semantic segmentation framework, is employed to leverage its advanced spatial understanding capabilities for accurate land cover classification. We investigate the efficacy of loss functions including Dice, Tversky, and Lovasz loss respectively. The trained model was utilized for inference over the test region in the ensuing year to identify potential areas of expansion or contraction over these same periods. The Sentinel-2 data is made available on Amazon Web Services through a collaboration with Earth Daily Analytics which provides corrected and tiled analytics-ready data on the AWS platform. The model and ongoing API to access the data on AWS allow the creation of an automated tool to monitor the extent of disturbed areas surrounding known mining sites to ensure compliance with their environmental impact goals. ",
    "url": "https://arxiv.org/abs/2311.01676",
    "authors": [
      "Ezra MacDonald",
      "Derek Jacoby",
      "Yvonne Coady"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2311.01682",
    "title": "Flow-Based Feature Fusion for Vehicle-Infrastructure Cooperative 3D  Object Detection",
    "abstract": "Cooperatively utilizing both ego-vehicle and infrastructure sensor data can significantly enhance autonomous driving perception abilities. However, the uncertain temporal asynchrony and limited communication conditions can lead to fusion misalignment and constrain the exploitation of infrastructure data. To address these issues in vehicle-infrastructure cooperative 3D (VIC3D) object detection, we propose the Feature Flow Net (FFNet), a novel cooperative detection framework. FFNet is a flow-based feature fusion framework that uses a feature flow prediction module to predict future features and compensate for asynchrony. Instead of transmitting feature maps extracted from still-images, FFNet transmits feature flow, leveraging the temporal coherence of sequential infrastructure frames. Furthermore, we introduce a self-supervised training approach that enables FFNet to generate feature flow with feature prediction ability from raw infrastructure sequences. Experimental results demonstrate that our proposed method outperforms existing cooperative detection methods while only requiring about 1/100 of the transmission cost of raw data and covers all latency in one model on the DAIR-V2X dataset. The code is available at \\href{https://github.com/haibao-yu/FFNet-VIC3D}{https://github.com/haibao-yu/FFNet-VIC3D}. ",
    "url": "https://arxiv.org/abs/2311.01682",
    "authors": [
      "Haibao Yu",
      "Yingjuan Tang",
      "Enze Xie",
      "Jilei Mao",
      "Ping Luo",
      "Zaiqing Nie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01686",
    "title": "Disentangled Representation Learning with Transmitted Information  Bottleneck",
    "abstract": "Encoding only the task-related information from the raw data, \\ie, disentangled representation learning, can greatly contribute to the robustness and generalizability of models. Although significant advances have been made by regularizing the information in representations with information theory, two major challenges remain: 1) the representation compression inevitably leads to performance drop; 2) the disentanglement constraints on representations are in complicated optimization. To these issues, we introduce Bayesian networks with transmitted information to formulate the interaction among input and representations during disentanglement. Building upon this framework, we propose \\textbf{DisTIB} (\\textbf{T}ransmitted \\textbf{I}nformation \\textbf{B}ottleneck for \\textbf{Dis}entangled representation learning), a novel objective that navigates the balance between information compression and preservation. We employ variational inference to derive a tractable estimation for DisTIB. This estimation can be simply optimized via standard gradient descent with a reparameterization trick. Moreover, we theoretically prove that DisTIB can achieve optimal disentanglement, underscoring its superior efficacy. To solidify our claims, we conduct extensive experiments on various downstream tasks to demonstrate the appealing efficacy of DisTIB and validate our theoretical analyses. ",
    "url": "https://arxiv.org/abs/2311.01686",
    "authors": [
      "Zhuohang Dang",
      "Minnan Luo",
      "Chengyou Jia",
      "Guang Dai",
      "Jihong Wang",
      "Xiaojun Chang",
      "Jingdong Wang",
      "Qinghua Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01698",
    "title": "Adversarial Attacks on Cooperative Multi-agent Bandits",
    "abstract": "Cooperative multi-agent multi-armed bandits (CMA2B) consider the collaborative efforts of multiple agents in a shared multi-armed bandit game. We study latent vulnerabilities exposed by this collaboration and consider adversarial attacks on a few agents with the goal of influencing the decisions of the rest. More specifically, we study adversarial attacks on CMA2B in both homogeneous settings, where agents operate with the same arm set, and heterogeneous settings, where agents have distinct arm sets. In the homogeneous setting, we propose attack strategies that, by targeting just one agent, convince all agents to select a particular target arm $T-o(T)$ times while incurring $o(T)$ attack costs in $T$ rounds. In the heterogeneous setting, we prove that a target arm attack requires linear attack costs and propose attack strategies that can force a maximum number of agents to suffer linear regrets while incurring sublinear costs and only manipulating the observations of a few target agents. Numerical experiments validate the effectiveness of our proposed attack strategies. ",
    "url": "https://arxiv.org/abs/2311.01698",
    "authors": [
      "Jinhang Zuo",
      "Zhiyao Zhang",
      "Xuchuang Wang",
      "Cheng Chen",
      "Shuai Li",
      "John C.S. Lui",
      "Mohammad Hajiesmaili",
      "Adam Wierman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2311.01707",
    "title": "Distributed Multi-Robot Multi-Target Tracking Using Heterogeneous  Limited-Range Sensors",
    "abstract": "This paper presents a cooperative multi-robot multi-target tracking framework aimed at enhancing the efficiency of the heterogeneous sensor network and, consequently, improving overall target tracking accuracy. The concept of normalized unused sensing capacity is introduced to quantify the information a sensor is currently gathering relative to its theoretical maximum. This measurement can be computed using entirely local information and is applicable to various sensor models, distinguishing it from previous literature on the subject. It is then utilized to develop a distributed coverage control strategy for a heterogeneous sensor network, adaptively balancing the workload based on each sensor's current unused capacity. The algorithm is validated through a series of ROS and MATLAB simulations, demonstrating superior results compared to standard approaches that do not account for heterogeneity or current usage rates. ",
    "url": "https://arxiv.org/abs/2311.01707",
    "authors": [
      "Jun Chen",
      "Mohammed Abugurain",
      "Philip Dames",
      "Shinkyu Park"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.01708",
    "title": "Physics-Informed Generator-Encoder Adversarial Networks with Latent  Space Matching for Stochastic Differential Equations",
    "abstract": "We propose a new class of physics-informed neural networks, called Physics-Informed Generator-Encoder Adversarial Networks, to effectively address the challenges posed by forward, inverse, and mixed problems in stochastic differential equations. In these scenarios, while the governing equations are known, the available data consist of only a limited set of snapshots for system parameters. Our model consists of two key components: the generator and the encoder, both updated alternately by gradient descent. In contrast to previous approaches of directly matching the approximated solutions with real snapshots, we employ an indirect matching that operates within the lower-dimensional latent feature space. This method circumvents challenges associated with high-dimensional inputs and complex data distributions, while yielding more accurate solutions compared to existing neural network solvers. In addition, the approach also mitigates the training instability issues encountered in previous adversarial frameworks in an efficient manner. Numerical results provide compelling evidence of the effectiveness of the proposed method in solving different types of stochastic differential equations. ",
    "url": "https://arxiv.org/abs/2311.01708",
    "authors": [
      "Ruisong Gao",
      "Min Yang",
      "Jin Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2311.01713",
    "title": "An Empirical Study of Benchmarking Chinese Aspect Sentiment Quad  Prediction",
    "abstract": "Aspect sentiment quad prediction (ASQP) is a critical subtask of aspect-level sentiment analysis. Current ASQP datasets are characterized by their small size and low quadruple density, which hinders technical development. To expand capacity, we construct two large Chinese ASQP datasets crawled from multiple online platforms. The datasets hold several significant characteristics: larger size (each with 10,000+ samples) and rich aspect categories, more words per sentence, and higher density than existing ASQP datasets. Moreover, we are the first to evaluate the performance of Generative Pre-trained Transformer (GPT) series models on ASQP and exhibit potential issues. The experiments with state-of-the-art ASQP baselines underscore the need to explore additional techniques to address ASQP, as well as the importance of further investigation into methods to improve the performance of GPTs. ",
    "url": "https://arxiv.org/abs/2311.01713",
    "authors": [
      "Junxian Zhou",
      "Haiqin Yang",
      "Ye Junpeng",
      "Yuxuan He",
      "Hao Mou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.01714",
    "title": "EXIM: A Hybrid Explicit-Implicit Representation for Text-Guided 3D Shape  Generation",
    "abstract": "This paper presents a new text-guided technique for generating 3D shapes. The technique leverages a hybrid 3D shape representation, namely EXIM, combining the strengths of explicit and implicit representations. Specifically, the explicit stage controls the topology of the generated 3D shapes and enables local modifications, whereas the implicit stage refines the shape and paints it with plausible colors. Also, the hybrid approach separates the shape and color and generates color conditioned on shape to ensure shape-color consistency. Unlike the existing state-of-the-art methods, we achieve high-fidelity shape generation from natural-language descriptions without the need for time-consuming per-shape optimization or reliance on human-annotated texts during training or test-time optimization. Further, we demonstrate the applicability of our approach to generate indoor scenes with consistent styles using text-induced 3D shapes. Through extensive experiments, we demonstrate the compelling quality of our results and the high coherency of our generated shapes with the input texts, surpassing the performance of existing methods by a significant margin. Codes and models are released at https://github.com/liuzhengzhe/EXIM. ",
    "url": "https://arxiv.org/abs/2311.01714",
    "authors": [
      "Zhengzhe Liu",
      "Jingyu Hu",
      "Ka-Hei Hui",
      "Xiaojuan Qi",
      "Daniel Cohen-Or",
      "Chi-Wing Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01722",
    "title": "Heterogeneous federated collaborative filtering using FAIR: Federated  Averaging in Random Subspaces",
    "abstract": "Recommendation systems (RS) for items (e.g., movies, books) and ads are widely used to tailor content to users on various internet platforms. Traditionally, recommendation models are trained on a central server. However, due to rising concerns for data privacy and regulations like the GDPR, federated learning is an increasingly popular paradigm in which data never leaves the client device. Applying federated learning to recommendation models is non-trivial due to large embedding tables, which often exceed the memory constraints of most user devices. To include data from all devices in federated learning, we must enable collective training of embedding tables on devices with heterogeneous memory capacities. Current solutions to heterogeneous federated learning can only accommodate a small range of capacities and thus limit the number of devices that can participate in training. We present Federated Averaging in Random subspaces (FAIR), which allows arbitrary compression of embedding tables based on device capacity and ensures the participation of all devices in training. FAIR uses what we call consistent and collapsible subspaces defined by hashing-based random projections to jointly train large embedding tables while using varying amounts of compression on user devices. We evaluate FAIR on Neural Collaborative Filtering tasks with multiple datasets and verify that FAIR can gather and share information from a wide range of devices with varying capacities, allowing for seamless collaboration. We prove the convergence of FAIR in the homogeneous setting with non-i.i.d data distribution. Our code is open source at {https://github.com/apd10/FLCF} ",
    "url": "https://arxiv.org/abs/2311.01722",
    "authors": [
      "Aditya Desai",
      "Benjamin Meisburger",
      "Zichang Liu",
      "Anshumali Shrivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01723",
    "title": "Towards Calibrated Robust Fine-Tuning of Vision-Language Models",
    "abstract": "While fine-tuning unleashes the potential of a pre-trained model to a specific task, it trades off the model's generalization capability on out-of-distribution (OOD) datasets. To mitigate this, robust fine-tuning aims to ensure performance on OOD datasets as well as an in-distribution (ID) dataset for which the model is being tuned. However, another criterion for reliable machine learning (ML), confidence calibration, has been overlooked despite its increasing demand for real-world high-stakes ML applications (e.g., autonomous driving and medical diagnosis). For the first time, we raise concerns about the calibration of fine-tuned vision-language models (VLMs) under distribution shift by showing that naive fine-tuning and even state-of-the-art robust fine-tuning methods hurt the calibration of pre-trained VLMs, especially on OOD datasets. To address this, we provide a simple approach, called a calibrated robust fine-tuning (CaRot) that incentivizes the calibration and robustness on both ID and OOD datasets. Empirical results on ImageNet-1K distribution shift evaluation verify the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2311.01723",
    "authors": [
      "Changdae Oh",
      "Mijoo Kim",
      "Hyesu Lim",
      "Junhyeok Park",
      "Euiseog Jeong",
      "Zhi-Qi Cheng",
      "Kyungwoo Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.01729",
    "title": "CDGraph: Dual Conditional Social Graph Synthesizing via Diffusion Model",
    "abstract": "The social graphs synthesized by the generative models are increasingly in demand due to data scarcity and concerns over user privacy. One of the key performance criteria for generating social networks is the fidelity to specified conditionals, such as users with certain membership and financial status. While recent diffusion models have shown remarkable performance in generating images, their effectiveness in synthesizing graphs has not yet been explored in the context of conditional social graphs. In this paper, we propose the first kind of conditional diffusion model for social networks, CDGraph, which trains and synthesizes graphs based on two specified conditions. We propose the co-evolution dependency in the denoising process of CDGraph to capture the mutual dependencies between the dual conditions and further incorporate social homophily and social contagion to preserve the connectivity between nodes while satisfying the specified conditions. Moreover, we introduce a novel classifier loss, which guides the training of the diffusion process through the mutual dependency of dual conditions. We evaluate CDGraph against four existing graph generative methods, i.e., SPECTRE, GSM, EDGE, and DiGress, on four datasets. Our results show that the generated graphs from CDGraph achieve much higher dual-conditional validity and lower discrepancy in various social network metrics than the baselines, thus demonstrating its proficiency in generating dual-conditional social graphs. ",
    "url": "https://arxiv.org/abs/2311.01729",
    "authors": [
      "Jui-Yi Tsai",
      "Ya-Wen Teng",
      "Ho Chiok Yew",
      "De-Nian Yang",
      "Lydia Y. Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01734",
    "title": "MixCon3D: Synergizing Multi-View and Cross-Modal Contrastive Learning  for Enhancing 3D Representation",
    "abstract": "Contrastive learning has emerged as a promising paradigm for 3D open-world understanding, jointly with text, image, and point cloud. In this paper, we introduce MixCon3D, which combines the complementary information between 2D images and 3D point clouds to enhance contrastive learning. With the further integration of multi-view 2D images, MixCon3D enhances the traditional tri-modal representation by offering a more accurate and comprehensive depiction of real-world 3D objects and bolstering text alignment. Additionally, we pioneer the first thorough investigation of various training recipes for the 3D contrastive learning paradigm, building a solid baseline with improved performance. Extensive experiments conducted on three representative benchmarks reveal that our method renders significant improvement over the baseline, surpassing the previous state-of-the-art performance on the challenging 1,156-category Objaverse-LVIS dataset by 5.7%. We further showcase the effectiveness of our approach in more applications, including text-to-3D retrieval and point cloud captioning. The code is available at https://github.com/UCSC-VLAA/MixCon3D. ",
    "url": "https://arxiv.org/abs/2311.01734",
    "authors": [
      "Yipeng Gao",
      "Zeyu Wang",
      "Wei-Shi Zheng",
      "Cihang Xie",
      "Yuyin Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01740",
    "title": "SAC$^3$: Reliable Hallucination Detection in Black-Box Language Models  via Semantic-aware Cross-check Consistency",
    "abstract": "Hallucination detection is a critical step toward understanding the trustworthiness of modern language models (LMs). To achieve this goal, we re-examine existing detection approaches based on the self-consistency of LMs and uncover two types of hallucinations resulting from 1) question-level and 2) model-level, which cannot be effectively identified through self-consistency check alone. Building upon this discovery, we propose a novel sampling-based method, i.e., semantic-aware cross-check consistency (SAC$^3$) that expands on the principle of self-consistency checking. Our SAC$^3$ approach incorporates additional mechanisms to detect both question-level and model-level hallucinations by leveraging advances including semantically equivalent question perturbation and cross-model response consistency checking. Through extensive and systematic empirical analysis, we demonstrate that SAC$^3$ outperforms the state of the art in detecting both non-factual and factual statements across multiple question-answering and open-domain generation benchmarks. ",
    "url": "https://arxiv.org/abs/2311.01740",
    "authors": [
      "Jiaxin Zhang",
      "Zhuohang Li",
      "Kamalika Das",
      "Bradley A. Malin",
      "Sricharan Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.01752",
    "title": "Low Overhead Beam Alignment for Mobile Millimeter Channel Based on  Continuous-Time Prediction",
    "abstract": "In millimeter-wave (mmWave) communications, directional transmission based on beamforming is important to compensate for high pathloss. To maintain the desired direction transmission gain, beam scanning that involves the transmitter sending the pilot signal over all available beam directions to find the optimal beam is often considered. Alternatively, beam tracking using partial beams can save the beam training overhead through algorithms such as statistical analysis models and kalman filter (KF). Unfortunately, existing beam tracking solutions are limited to a fixed beam variation pattern. In this work, we propose a beam alignment scheme called adaptive online beam alignment (AOBA), which aims to reduce training overhead and achieve accurate beam alignment for any movement profile. The proposed AOBA periodically performs beam tracking using a small amount but carefully selected candidate beams and switches to beam scanning using all available beams based on a given switching rule. During the interval without the pilot signal, the optimal beam at an arbitrary time instant is predicted with the aid of the recently proposed ordinary differential equation (ODE)-long short-term memory (LSTM) model. Extensive simulations are conducted to evaluate the performance of the proposed AOBA in comparison with several existing beam alignment schemes. ",
    "url": "https://arxiv.org/abs/2311.01752",
    "authors": [
      "Huang-Chou Lin",
      "Kuang-Hao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.01755",
    "title": "Towards a Unified Transformer-based Framework for Scene Graph Generation  and Human-object Interaction Detection",
    "abstract": "Scene graph generation (SGG) and human-object interaction (HOI) detection are two important visual tasks aiming at localising and recognising relationships between objects, and interactions between humans and objects, respectively. Prevailing works treat these tasks as distinct tasks, leading to the development of task-specific models tailored to individual datasets. However, we posit that the presence of visual relationships can furnish crucial contextual and intricate relational cues that significantly augment the inference of human-object interactions. This motivates us to think if there is a natural intrinsic relationship between the two tasks, where scene graphs can serve as a source for inferring human-object interactions. In light of this, we introduce SG2HOI+, a unified one-step model based on the Transformer architecture. Our approach employs two interactive hierarchical Transformers to seamlessly unify the tasks of SGG and HOI detection. Concretely, we initiate a relation Transformer tasked with generating relation triples from a suite of visual features. Subsequently, we employ another transformer-based decoder to predict human-object interactions based on the generated relation triples. A comprehensive series of experiments conducted across established benchmark datasets including Visual Genome, V-COCO, and HICO-DET demonstrates the compelling performance of our SG2HOI+ model in comparison to prevalent one-stage SGG models. Remarkably, our approach achieves competitive performance when compared to state-of-the-art HOI methods. Additionally, we observe that our SG2HOI+ jointly trained on both SGG and HOI tasks in an end-to-end manner yields substantial improvements for both tasks compared to individualized training paradigms. ",
    "url": "https://arxiv.org/abs/2311.01755",
    "authors": [
      "Tao He",
      "Lianli Gao",
      "Jingkuan Song",
      "Yuan-Fang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01773",
    "title": "PDF: Point Diffusion Implicit Function for Large-scale Scene Neural  Representation",
    "abstract": "Recent advances in implicit neural representations have achieved impressive results by sampling and fusing individual points along sampling rays in the sampling space. However, due to the explosively growing sampling space, finely representing and synthesizing detailed textures remains a challenge for unbounded large-scale outdoor scenes. To alleviate the dilemma of using individual points to perceive the entire colossal space, we explore learning the surface distribution of the scene to provide structural priors and reduce the samplable space and propose a Point Diffusion implicit Function, PDF, for large-scale scene neural representation. The core of our method is a large-scale point cloud super-resolution diffusion module that enhances the sparse point cloud reconstructed from several training images into a dense point cloud as an explicit prior. Then in the rendering stage, only sampling points with prior points within the sampling radius are retained. That is, the sampling space is reduced from the unbounded space to the scene surface. Meanwhile, to fill in the background of the scene that cannot be provided by point clouds, the region sampling based on Mip-NeRF 360 is employed to model the background representation. Expensive experiments have demonstrated the effectiveness of our method for large-scale scene novel view synthesis, which outperforms relevant state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2311.01773",
    "authors": [
      "Yuhan Ding",
      "Fukun Yin",
      "Jiayuan Fan",
      "Hui Li",
      "Xin Chen",
      "Wen Liu",
      "Chongshan Lu",
      "Gang YU",
      "Tao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01796",
    "title": "Learning to Augment Distributions for Out-of-Distribution Detection",
    "abstract": "Open-world classification systems should discern out-of-distribution (OOD) data whose labels deviate from those of in-distribution (ID) cases, motivating recent studies in OOD detection. Advanced works, despite their promising progress, may still fail in the open world, owing to the lack of knowledge about unseen OOD data in advance. Although one can access auxiliary OOD data (distinct from unseen ones) for model training, it remains to analyze how such auxiliary data will work in the open world. To this end, we delve into such a problem from a learning theory perspective, finding that the distribution discrepancy between the auxiliary and the unseen real OOD data is the key to affecting the open-world detection performance. Accordingly, we propose Distributional-Augmented OOD Learning (DAL), alleviating the OOD distribution discrepancy by crafting an OOD distribution set that contains all distributions in a Wasserstein ball centered on the auxiliary OOD distribution. We justify that the predictor trained over the worst OOD data in the ball can shrink the OOD distribution discrepancy, thus improving the open-world detection performance given only the auxiliary OOD data. We conduct extensive evaluations across representative OOD detection setups, demonstrating the superiority of our DAL over its advanced counterparts. ",
    "url": "https://arxiv.org/abs/2311.01796",
    "authors": [
      "Qizhou Wang",
      "Zhen Fang",
      "Yonggang Zhang",
      "Feng Liu",
      "Yixuan Li",
      "Bo Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01807",
    "title": "Cross-modal Consistency Learning with Fine-grained Fusion Network for  Multimodal Fake News Detection",
    "abstract": "Previous studies on multimodal fake news detection have observed the mismatch between text and images in the fake news and attempted to explore the consistency of multimodal news based on global features of different modalities. However, they fail to investigate this relationship between fine-grained fragments in multimodal content. To gain public trust, fake news often includes relevant parts in the text and the image, making such multimodal content appear consistent. Using global features may suppress potential inconsistencies in irrelevant parts. Therefore, in this paper, we propose a novel Consistency-learning Fine-grained Fusion Network (CFFN) that separately explores the consistency and inconsistency from high-relevant and low-relevant word-region pairs. Specifically, for a multimodal post, we divide word-region pairs into high-relevant and low-relevant parts based on their relevance scores. For the high-relevant part, we follow the cross-modal attention mechanism to explore the consistency. For low-relevant part, we calculate inconsistency scores to capture inconsistent points. Finally, a selection module is used to choose the primary clue (consistency or inconsistency) for identifying the credibility of multimodal news. Extensive experiments on two public datasets demonstrate that our CFFN substantially outperforms all the baselines. ",
    "url": "https://arxiv.org/abs/2311.01807",
    "authors": [
      "Jun Li",
      "Yi Bin",
      "Jie Zou",
      "Jie Zou",
      "Guoqing Wang",
      "Yang Yang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.01815",
    "title": "Estimating 3D Uncertainty Field: Quantifying Uncertainty for Neural  Radiance Fields",
    "abstract": "Current methods based on Neural Radiance Fields (NeRF) significantly lack the capacity to quantify uncertainty in their predictions, particularly on the unseen space including the occluded and outside scene content. This limitation hinders their extensive applications in robotics, where the reliability of model predictions has to be considered for tasks such as robotic exploration and planning in unknown environments. To address this, we propose a novel approach to estimate a 3D Uncertainty Field based on the learned incomplete scene geometry, which explicitly identifies these unseen regions. By considering the accumulated transmittance along each camera ray, our Uncertainty Field infers 2D pixel-wise uncertainty, exhibiting high values for rays directly casting towards occluded or outside the scene content. To quantify the uncertainty on the learned surface, we model a stochastic radiance field. Our experiments demonstrate that our approach is the only one that can explicitly reason about high uncertainty both on 3D unseen regions and its involved 2D rendered pixels, compared with recent methods. Furthermore, we illustrate that our designed uncertainty field is ideally suited for real-world robotics tasks, such as next-best-view selection. ",
    "url": "https://arxiv.org/abs/2311.01815",
    "authors": [
      "Jianxiong Shen",
      "Ruijie Ren",
      "Adria Ruiz",
      "Francesc Moreno-Noguer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.01833",
    "title": "Similarity network aggregation for the analysis of glacier ecosystems",
    "abstract": "The synthesis of information deriving from complex networks is a topic receiving increasing relevance in ecology and environmental sciences. In particular, the aggregation of multilayer networks, i.e. network structures formed by multiple interacting networks (the layers), constitutes a fast-growing field. In several environmental applications, the layers of a multilayer network are modelled as a collection of similarity matrices describing how similar pairs of biological entities are, based on different types of features (e.g. biological traits). The present paper first discusses two main techniques for combining the multi-layered information into a single network (the so-called monoplex), i.e. Similarity Network Fusion (SNF) and Similarity Matrix Average (SMA). Then, the effectiveness of the two methods is tested on a real-world dataset of the relative abundance of microbial species in the ecosystems of nine glaciers (four glaciers in the Alps and five in the Andes). A preliminary clustering analysis on the monoplexes obtained with different methods shows the emergence of a tightly connected community formed by species that are typical of cryoconite holes worldwide. Moreover, the weights assigned to different layers by the SMA algorithm suggest that two large South American glaciers (Exploradores and Perito Moreno) are structurally different from the smaller glaciers in both Europe and South America. Overall, these results highlight the importance of integration methods in the discovery of the underlying organizational structure of biological entities in multilayer ecological networks. ",
    "url": "https://arxiv.org/abs/2311.01833",
    "authors": [
      "Roberto Ambrosini",
      "Federica Baccini",
      "Lucio Barabesi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2311.01840",
    "title": "Spectral Clustering of Attributed Multi-relational Graphs",
    "abstract": "Graph clustering aims at discovering a natural grouping of the nodes such that similar nodes are assigned to a common cluster. Many different algorithms have been proposed in the literature: for simple graphs, for graphs with attributes associated to nodes, and for graphs where edges represent different types of relations among nodes. However, complex data in many domains can be represented as both attributed and multi-relational networks. In this paper, we propose SpectralMix, a joint dimensionality reduction technique for multi-relational graphs with categorical node attributes. SpectralMix integrates all information available from the attributes, the different types of relations, and the graph structure to enable a sound interpretation of the clustering results. Moreover, it generalizes existing techniques: it reduces to spectral embedding and clustering when only applied to a single graph and to homogeneity analysis when applied to categorical data. Experiments conducted on several real-world datasets enable us to detect dependencies between graph structure and categorical attributes, moreover, they exhibit the superiority of SpectralMix over existing methods. ",
    "url": "https://arxiv.org/abs/2311.01840",
    "authors": [
      "Ylli Sadikaj",
      "Yllka Velaj",
      "Sahar Behzadi",
      "Claudia Plant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.01842",
    "title": "A Neural Radiance Field-Based Architecture for Intelligent Multilayered  View Synthesis",
    "abstract": "A mobile ad hoc network is made up of a number of wireless portable nodes that spontaneously come together en route for establish a transitory network with no need for any central management. A mobile ad hoc network (MANET) is made up of a sizable and reasonably dense community of mobile nodes that travel across any terrain and rely solely on wireless interfaces for communication, not on any well before centralized management. Furthermore, routing be supposed to offer a method for instantly delivering data across a network between any two nodes. Finding the best packet routing from across infrastructure is the major issue, though. The proposed protocol's major goal is to identify the least-expensive nominal capacity acquisition that assures the transportation of realistic transport that ensures its durability in the event of any node failure. This study suggests the Optimized Route Selection via Red Imported Fire Ants (RIFA) Strategy as a way to improve on-demand source routing systems. Predicting Route Failure and energy Utilization is used to pick the path during the routing phase. Proposed work assess the results of the comparisons based on performance parameters like as energy usage, packet delivery rate (PDR), and end-to-end (E2E) delay. The outcome demonstrates that the proposed strategy is preferable and increases network lifetime while lowering node energy consumption and typical E2E delay under the majority of network performance measures and factors. ",
    "url": "https://arxiv.org/abs/2311.01842",
    "authors": [
      "D. Dhinakaran",
      "S. M. Udhaya Sankar",
      "G. Elumalai",
      "N. Jagadish kumar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.01851",
    "title": "Holistic Representation Learning for Multitask Trajectory Anomaly  Detection",
    "abstract": "Video anomaly detection deals with the recognition of abnormal events in videos. Apart from the visual signal, video anomaly detection has also been addressed with the use of skeleton sequences. We propose a holistic representation of skeleton trajectories to learn expected motions across segments at different times. Our approach uses multitask learning to reconstruct any continuous unobserved temporal segment of the trajectory allowing the extrapolation of past or future segments and the interpolation of in-between segments. We use an end-to-end attention-based encoder-decoder. We encode temporally occluded trajectories, jointly learn latent representations of the occluded segments, and reconstruct trajectories based on expected motions across different temporal segments. Extensive experiments on three trajectory-based video anomaly detection datasets show the advantages and effectiveness of our approach with state-of-the-art results on anomaly detection in skeleton trajectories. ",
    "url": "https://arxiv.org/abs/2311.01851",
    "authors": [
      "Alexandros Stergiou",
      "Brent De Weerdt",
      "Nikos Deligiannis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01873",
    "title": "Efficient Black-Box Adversarial Attacks on Neural Text Detectors",
    "abstract": "Neural text detectors are models trained to detect whether a given text was generated by a language model or written by a human. In this paper, we investigate three simple and resource-efficient strategies (parameter tweaking, prompt engineering, and character-level mutations) to alter texts generated by GPT-3.5 that are unsuspicious or unnoticeable for humans but cause misclassification by neural text detectors. The results show that especially parameter tweaking and character-level mutations are effective strategies. ",
    "url": "https://arxiv.org/abs/2311.01873",
    "authors": [
      "Vitalii Fishchuk",
      "Daniel Braun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.01875",
    "title": "Enhancing Functional Data Analysis with Sequential Neural Networks:  Advantages and Comparative Study",
    "abstract": "Functional Data Analysis (FDA) is a statistical domain developed to handle functional data characterized by high dimensionality and complex data structures. Sequential Neural Networks (SNNs) are specialized neural networks capable of processing sequence data, a fundamental aspect of functional data. Despite their great flexibility in modeling functional data, SNNs have been inadequately employed in the FDA community. One notable advantage of SNNs is the ease of implementation, making them accessible to a broad audience beyond academia. Conversely, FDA-based methodologies present challenges, particularly for practitioners outside the field, due to their intricate complexity. In light of this, we propose utilizing SNNs in FDA applications and demonstrate their effectiveness through comparative analyses against popular FDA regression models based on numerical experiments and real-world data analysis. SNN architectures allow us to surpass the limitations of traditional FDA methods, offering scalability, flexibility, and improved analytical performance. Our findings highlight the potential of SNN-based methodologies as powerful tools for data applications involving functional data. ",
    "url": "https://arxiv.org/abs/2311.01875",
    "authors": [
      "J. Zhao",
      "J. Li",
      "M. Chen",
      "S. Jadhav"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.01902",
    "title": "High Precision Causal Model Evaluation with Conditional Randomization",
    "abstract": "The gold standard for causal model evaluation involves comparing model predictions with true effects estimated from randomized controlled trials (RCT). However, RCTs are not always feasible or ethical to perform. In contrast, conditionally randomized experiments based on inverse probability weighting (IPW) offer a more realistic approach but may suffer from high estimation variance. To tackle this challenge and enhance causal model evaluation in real-world conditional randomization settings, we introduce a novel low-variance estimator for causal error, dubbed as the pairs estimator. By applying the same IPW estimator to both the model and true experimental effects, our estimator effectively cancels out the variance due to IPW and achieves a smaller asymptotic variance. Empirical studies demonstrate the improved of our estimator, highlighting its potential on achieving near-RCT performance. Our method offers a simple yet powerful solution to evaluate causal inference models in conditional randomization settings without complicated modification of the IPW estimator itself, paving the way for more robust and reliable model assessments. ",
    "url": "https://arxiv.org/abs/2311.01902",
    "authors": [
      "Chao Ma",
      "Cheng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2311.01907",
    "title": "BoschAI @ PLABA 2023: Leveraging Edit Operations in End-to-End Neural  Sentence Simplification",
    "abstract": "Automatic simplification can help laypeople to comprehend complex scientific text. Language models are frequently applied to this task by translating from complex to simple language. In this paper, we describe our system based on Llama 2, which ranked first in the PLABA shared task addressing the simplification of biomedical text. We find that the large portion of shared tokens between input and output leads to weak training signals and conservatively editing models. To mitigate these issues, we propose sentence-level and token-level loss weights. They give higher weight to modified tokens, indicated by edit distance and edit operations, respectively. We conduct an empirical evaluation on the PLABA dataset and find that both approaches lead to simplifications closer to those created by human annotators (+1.8% / +3.5% SARI), simpler language (-1 / -1.1 FKGL) and more edits (1.6x / 1.8x edit distance) compared to the same model fine-tuned with standard cross entropy. We furthermore show that the hyperparameter $\\lambda$ in token-level loss weights can be used to control the edit distance and the simplicity level (FKGL). ",
    "url": "https://arxiv.org/abs/2311.01907",
    "authors": [
      "Valentin Knappich",
      "Simon Razniewski",
      "Annemarie Friedrich"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.01909",
    "title": "Version Age-Optimal Cached Status Updates in a Gossiping Network with  Energy Harvesting Sensor",
    "abstract": "In this work, we consider a real-time IoT monitoring system in which an energy harvesting sensor with a finite-size battery measures a physical process and transmits the status updates to an aggregator. The aggregator, equipped with caching capabilities, can serve the external requests of a destination network with either a stored update or a fresh update from the sensor. We assume the destination network acts as a gossiping network in which the update packets are forwarded among the nodes in a randomized setting. We utilize the Markov Decision Process framework to model and optimize the network's average Version Age of Information (AoI) and obtain the optimal policy at the aggregator. The structure of the optimal policy is analytically demonstrated and numerically verified. Numerical results highlight the effect of the system parameters on the average Version AoI. The simulations reveal the superior performance of the optimal policy compared to a set of baseline policies. ",
    "url": "https://arxiv.org/abs/2311.01909",
    "authors": [
      "Erfan Delfani",
      "Nikolaos Pappas"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2311.01928",
    "title": "Constructing Temporal Dynamic Knowledge Graphs from Interactive  Text-based Games",
    "abstract": "In natural language processing, interactive text-based games serve as a test bed for interactive AI systems. Prior work has proposed to play text-based games by acting based on discrete knowledge graphs constructed by the Discrete Graph Updater (DGU) to represent the game state from the natural language description. While DGU has shown promising results with high interpretability, it suffers from lower knowledge graph accuracy due to its lack of temporality and limited generalizability to complex environments with objects with the same label. In order to address DGU's weaknesses while preserving its high interpretability, we propose the Temporal Discrete Graph Updater (TDGU), a novel neural network model that represents dynamic knowledge graphs as a sequence of timestamped graph events and models them using a temporal point based graph neural network. Through experiments on the dataset collected from a text-based game TextWorld, we show that TDGU outperforms the baseline DGU. We further show the importance of temporal information for TDGU's performance through an ablation study and demonstrate that TDGU has the ability to generalize to more complex environments with objects with the same label. All the relevant code can be found at \\url{https://github.com/yukw777/temporal-discrete-graph-updater}. ",
    "url": "https://arxiv.org/abs/2311.01928",
    "authors": [
      "Keunwoo Peter Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.02007",
    "title": "Towards Unsupervised Object Detection From LiDAR Point Clouds",
    "abstract": "In this paper, we study the problem of unsupervised object detection from 3D point clouds in self-driving scenes. We present a simple yet effective method that exploits (i) point clustering in near-range areas where the point clouds are dense, (ii) temporal consistency to filter out noisy unsupervised detections, (iii) translation equivariance of CNNs to extend the auto-labels to long range, and (iv) self-supervision for improving on its own. Our approach, OYSTER (Object Discovery via Spatio-Temporal Refinement), does not impose constraints on data collection (such as repeated traversals of the same location), is able to detect objects in a zero-shot manner without supervised finetuning (even in sparse, distant regions), and continues to self-improve given more rounds of iterative self-training. To better measure model performance in self-driving scenarios, we propose a new planning-centric perception metric based on distance-to-collision. We demonstrate that our unsupervised object detector significantly outperforms unsupervised baselines on PandaSet and Argoverse 2 Sensor dataset, showing promise that self-supervision combined with object priors can enable object discovery in the wild. For more information, visit the project website: https://waabi.ai/research/oyster ",
    "url": "https://arxiv.org/abs/2311.02007",
    "authors": [
      "Lunjun Zhang",
      "Anqi Joyce Yang",
      "Yuwen Xiong",
      "Sergio Casas",
      "Bin Yang",
      "Mengye Ren",
      "Raquel Urtasun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.02017",
    "title": "DeliverAI: Reinforcement Learning Based Distributed Path-Sharing Network  for Food Deliveries",
    "abstract": "Delivery of items from the producer to the consumer has experienced significant growth over the past decade and has been greatly fueled by the recent pandemic. Amazon Fresh, Shopify, UberEats, InstaCart, and DoorDash are rapidly growing and are sharing the same business model of consumer items or food delivery. Existing food delivery methods are sub-optimal because each delivery is individually optimized to go directly from the producer to the consumer via the shortest time path. We observe a significant scope for reducing the costs associated with completing deliveries under the current model. We model our food delivery problem as a multi-objective optimization, where consumer satisfaction and delivery costs, both, need to be optimized. Taking inspiration from the success of ride-sharing in the taxi industry, we propose DeliverAI - a reinforcement learning-based path-sharing algorithm. Unlike previous attempts for path-sharing, DeliverAI can provide real-time, time-efficient decision-making using a Reinforcement learning-enabled agent system. Our novel agent interaction scheme leverages path-sharing among deliveries to reduce the total distance traveled while keeping the delivery completion time under check. We generate and test our methodology vigorously on a simulation setup using real data from the city of Chicago. Our results show that DeliverAI can reduce the delivery fleet size by 12\\%, the distance traveled by 13%, and achieve 50% higher fleet utilization compared to the baselines. ",
    "url": "https://arxiv.org/abs/2311.02017",
    "authors": [
      "Ashman Mehra",
      "Snehanshu Saha",
      "Vaskar Raychoudhury",
      "Archana Mathur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.02025",
    "title": "Vicinal Risk Minimization for Few-Shot Cross-lingual Transfer in Abusive  Language Detection",
    "abstract": "Cross-lingual transfer learning from high-resource to medium and low-resource languages has shown encouraging results. However, the scarcity of resources in target languages remains a challenge. In this work, we resort to data augmentation and continual pre-training for domain adaptation to improve cross-lingual abusive language detection. For data augmentation, we analyze two existing techniques based on vicinal risk minimization and propose MIXAG, a novel data augmentation method which interpolates pairs of instances based on the angle of their representations. Our experiments involve seven languages typologically distinct from English and three different domains. The results reveal that the data augmentation strategies can enhance few-shot cross-lingual abusive language detection. Specifically, we observe that consistently in all target languages, MIXAG improves significantly in multidomain and multilingual environments. Finally, we show through an error analysis how the domain adaptation can favour the class of abusive texts (reducing false negatives), but at the same time, declines the precision of the abusive language detection model. ",
    "url": "https://arxiv.org/abs/2311.02025",
    "authors": [
      "Gretel Liz De la Pe\u00f1a Sarrac\u00e9n",
      "Paolo Rosso",
      "Robert Litschko",
      "Goran Glava\u0161",
      "Simone Paolo Ponzetto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.02026",
    "title": "APRICOT: Acuity Prediction in Intensive Care Unit (ICU): Predicting  Stability, Transitions, and Life-Sustaining Therapies",
    "abstract": "The acuity state of patients in the intensive care unit (ICU) can quickly change from stable to unstable, sometimes leading to life-threatening conditions. Early detection of deteriorating conditions can result in providing more timely interventions and improved survival rates. Current approaches rely on manual daily assessments. Some data-driven approaches have been developed, that use mortality as a proxy of acuity in the ICU. However, these methods do not integrate acuity states to determine the stability of a patient or the need for life-sustaining therapies. In this study, we propose APRICOT (Acuity Prediction in Intensive Care Unit), a Transformer-based neural network to predict acuity state in real-time in ICU patients. We develop and extensively validate externally, temporally, and prospectively the APRICOT model on three large datasets: University of Florida Health (UFH), eICU Collaborative Research Database (eICU), and Medical Information Mart for Intensive Care (MIMIC)-IV. The performance of APRICOT shows comparable results to state-of-the-art mortality prediction models (external AUROC 0.93-0.93, temporal AUROC 0.96-0.98, and prospective AUROC 0.98) as well as acuity prediction models (external AUROC 0.80-0.81, temporal AUROC 0.77-0.78, and prospective AUROC 0.87). Furthermore, APRICOT can make predictions for the need for life-sustaining therapies, showing comparable results to state-of-the-art ventilation prediction models (external AUROC 0.80-0.81, temporal AUROC 0.87-0.88, and prospective AUROC 0.85), and vasopressor prediction models (external AUROC 0.82-0.83, temporal AUROC 0.73-0.75, prospective AUROC 0.87). This tool allows for real-time acuity monitoring of a patient and can provide helpful information to clinicians to make timely interventions. Furthermore, the model can suggest life-sustaining therapies that the patient might need in the next hours in the ICU. ",
    "url": "https://arxiv.org/abs/2311.02026",
    "authors": [
      "Miguel Contreras",
      "Brandon Silva",
      "Benjamin Shickel",
      "Tezcan Ozrazgat Baslanti",
      "Yuanfang Ren",
      "Ziyuan Guan",
      "Sabyasachi Bandyopadhyay",
      "Kia Khezeli",
      "Azra Bihorac",
      "Parisa Rashidi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.02044",
    "title": "Occlusion-Aware 2D and 3D Centerline Detection for Urban Driving via  Automatic Label Generation",
    "abstract": "This research work seeks to explore and identify strategies that can determine road topology information in 2D and 3D under highly dynamic urban driving scenarios. To facilitate this exploration, we introduce a substantial dataset comprising nearly one million automatically labeled data frames. A key contribution of our research lies in developing an automatic label-generation process and an occlusion handling strategy. This strategy is designed to model a wide range of occlusion scenarios, from mild disruptions to severe blockages. Furthermore, we present a comprehensive ablation study wherein multiple centerline detection methods are developed and evaluated. This analysis not only benchmarks the performance of various approaches but also provides valuable insights into the interpretability of these methods. Finally, we demonstrate the practicality of our methods and assess their adaptability across different sensor configurations, highlighting their versatility and relevance in real-world scenarios. Our dataset and experimental models are publicly available. ",
    "url": "https://arxiv.org/abs/2311.02044",
    "authors": [
      "David Paz",
      "Narayanan E. Ranganatha",
      "Srinidhi K. Srinivas",
      "Yunchao Yao",
      "Henrik I. Christensen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.02072",
    "title": "Learning Historical Status Prompt for Accurate and Robust Visual  Tracking",
    "abstract": "Most trackers perform template and search region similarity matching to find the most similar object to the template during tracking. However, they struggle to make prediction when the target appearance changes due to the limited historical information introduced by roughly cropping the current search region based on the predicted result of previous frame. In this paper, we identify that the central impediment to improving the performance of existing trackers is the incapacity to integrate abundant and effective historical information. To address this issue, we propose a Historical Information Prompter (HIP) to enhance the provision of historical information. We also build HIPTrack upon HIP module. HIP is a plug-and-play module that make full use of search region features to introduce historical appearance information. It also incorporates historical position information by constructing refined mask of the target. HIP is a lightweight module to generate historical information prompts. By integrating historical information prompts, HIPTrack significantly enhances the tracking performance without the need to retrain the backbone. Experimental results demonstrate that our method outperforms all state-of-the-art approaches on LaSOT, LaSOT ext, GOT10k and NfS. Futhermore, HIP module exhibits strong generality and can be seamlessly integrated into trackers to improve tracking performance. The source code and models will be released for further research. ",
    "url": "https://arxiv.org/abs/2311.02072",
    "authors": [
      "Wenrui Cai",
      "Qingjie Liu",
      "Yunhong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.02076",
    "title": "Universal Sharpness Dynamics in Neural Network Training: Fixed Point  Analysis, Edge of Stability, and Route to Chaos",
    "abstract": "In gradient descent dynamics of neural networks, the top eigenvalue of the Hessian of the loss (sharpness) displays a variety of robust phenomena throughout training. This includes early time regimes where the sharpness may decrease during early periods of training (sharpness reduction), and later time behavior such as progressive sharpening and edge of stability. We demonstrate that a simple $2$-layer linear network (UV model) trained on a single training example exhibits all of the essential sharpness phenomenology observed in real-world scenarios. By analyzing the structure of dynamical fixed points in function space and the vector field of function updates, we uncover the underlying mechanisms behind these sharpness trends. Our analysis reveals (i) the mechanism behind early sharpness reduction and progressive sharpening, (ii) the required conditions for edge of stability, and (iii) a period-doubling route to chaos on the edge of stability manifold as learning rate is increased. Finally, we demonstrate that various predictions from this simplified model generalize to real-world scenarios and discuss its limitations. ",
    "url": "https://arxiv.org/abs/2311.02076",
    "authors": [
      "Dayal Singh Kalra",
      "Tianyu He",
      "Maissam Barkeshli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Chaotic Dynamics (nlin.CD)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.20333",
    "title": "Semidefinite network games: multiplayer minimax and semidefinite  complementarity problems",
    "abstract": "Network games are an important class of games that model agent interactions in networked systems, where players are situated at the nodes of a graph and their payoffs depend on the actions taken by their neighbors. We extend the classical framework by considering a game model where the strategies are positive semidefinite matrices having trace one. These (continuous) games can serve as a simple model of quantum strategic interactions. We focus on the zero-sum case, where the sum of all players' payoffs is equal to zero. We establish that in this class of games, Nash equilibria can be characterized as the projection of a spectrahedron, that is, the feasible region of a semidefinite program. Furthermore, we demonstrate that determining whether a game is a semidefinite network game is equivalent to deciding if the value of a semidefinite program is zero. Beyond the zero-sum case, we characterize Nash equilibria as the solutions of a semidefinite linear complementarity problem. ",
    "url": "https://arxiv.org/abs/2310.20333",
    "authors": [
      "Constantin Ickstadt",
      "Thorsten Theobald",
      "Elias Tsigaridas",
      "Antonios Varvitsiotis"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2311.01489",
    "title": "Invariant Causal Imitation Learning for Generalizable Policies",
    "abstract": "Consider learning an imitation policy on the basis of demonstrated behavior from multiple environments, with an eye towards deployment in an unseen environment. Since the observable features from each setting may be different, directly learning individual policies as mappings from features to actions is prone to spurious correlations -- and may not generalize well. However, the expert's policy is often a function of a shared latent structure underlying those observable features that is invariant across settings. By leveraging data from multiple environments, we propose Invariant Causal Imitation Learning (ICIL), a novel technique in which we learn a feature representation that is invariant across domains, on the basis of which we learn an imitation policy that matches expert behavior. To cope with transition dynamics mismatch, ICIL learns a shared representation of causal features (for all training environments), that is disentangled from the specific representations of noise variables (for each of those environments). Moreover, to ensure that the learned policy matches the observation distribution of the expert's policy, ICIL estimates the energy of the expert's observations and uses a regularization term that minimizes the imitator policy's next state energy. Experimentally, we compare our methods against several benchmarks in control and healthcare tasks and show its effectiveness in learning imitation policies capable of generalizing to unseen environments. ",
    "url": "https://arxiv.org/abs/2311.01489",
    "authors": [
      "Ioana Bica",
      "Daniel Jarrett",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01500",
    "title": "E(2) Equivariant Neural Networks for Robust Galaxy Morphology  Classification",
    "abstract": "We propose the use of group convolutional neural network architectures (GCNNs) equivariant to the 2D Euclidean group, $E(2)$, for the task of galaxy morphology classification by utilizing symmetries of the data present in galaxy images as an inductive bias in the architecture. We conduct robustness studies by introducing artificial perturbations via Poisson noise insertion and one-pixel adversarial attacks to simulate the effects of limited observational capabilities. We train, validate, and test GCNNs equivariant to discrete subgroups of $E(2)$ - the cyclic and dihedral groups of order $N$ - on the Galaxy10 DECals dataset and find that GCNNs achieve higher classification accuracy and are consistently more robust than their non-equivariant counterparts, with an architecture equivariant to the group $D_{16}$ achieving a $95.52 \\pm 0.18\\%$ test-set accuracy. We also find that the model loses $<6\\%$ accuracy on a $50\\%$-noise dataset and all GCNNs are less susceptible to one-pixel perturbations than an identically constructed CNN. Our code is publicly available at https://github.com/snehjp2/GCNNMorphology. ",
    "url": "https://arxiv.org/abs/2311.01500",
    "authors": [
      "Sneh Pandya",
      "Purvik Patel",
      "Franc O",
      "Jonathan Blazek"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01588",
    "title": "Domain Adaptive Graph Neural Networks for Constraining Cosmological  Parameters Across Multiple Data Sets",
    "abstract": "Deep learning models have been shown to outperform methods that rely on summary statistics, like the power spectrum, in extracting information from complex cosmological data sets. However, due to differences in the subgrid physics implementation and numerical approximations across different simulation suites, models trained on data from one cosmological simulation show a drop in performance when tested on another. Similarly, models trained on any of the simulations would also likely experience a drop in performance when applied to observational data. Training on data from two different suites of the CAMELS hydrodynamic cosmological simulations, we examine the generalization capabilities of Domain Adaptive Graph Neural Networks (DA-GNNs). By utilizing GNNs, we capitalize on their capacity to capture structured scale-free cosmological information from galaxy distributions. Moreover, by including unsupervised domain adaptation via Maximum Mean Discrepancy (MMD), we enable our models to extract domain-invariant features. We demonstrate that DA-GNN achieves higher accuracy and robustness on cross-dataset tasks (up to $28\\%$ better relative error and up to almost an order of magnitude better $\\chi^2$). Using data visualizations, we show the effects of domain adaptation on proper latent space data alignment. This shows that DA-GNNs are a promising method for extracting domain-independent cosmological information, a vital step toward robust deep learning for real cosmic survey data. ",
    "url": "https://arxiv.org/abs/2311.01588",
    "authors": [
      "Andrea Roncoli",
      "Aleksandra \u0106iprijanovi\u0107",
      "Maggie Voetberg",
      "Francisco Villaescusa-Navarro",
      "Brian Nord"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01624",
    "title": "Attention based Dual-Branch Complex Feature Fusion Network for  Hyperspectral Image Classification",
    "abstract": "This research work presents a novel dual-branch model for hyperspectral image classification that combines two streams: one for processing standard hyperspectral patches using Real-Valued Neural Network (RVNN) and the other for processing their corresponding Fourier transforms using Complex-Valued Neural Network (CVNN). The proposed model is evaluated on the Pavia University and Salinas datasets. Results show that the proposed model outperforms state-of-the-art methods in terms of overall accuracy, average accuracy, and Kappa. Through the incorporation of Fourier transforms in the second stream, the model is able to extract frequency information, which complements the spatial information extracted by the first stream. The combination of these two streams improves the overall performance of the model. Furthermore, to enhance the model performance, the Squeeze and Excitation (SE) mechanism has been utilized. Experimental evidence show that SE block improves the models overall accuracy by almost 1\\%. ",
    "url": "https://arxiv.org/abs/2311.01624",
    "authors": [
      "Mohammed Q. Alkhatib",
      "Mina Al-Saad",
      "Nour Aburaed",
      "M. Sami Zitouni",
      "Hussain Al Ahmad"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01653",
    "title": "INeAT: Iterative Neural Adaptive Tomography",
    "abstract": "Computed Tomography (CT) with its remarkable capability for three-dimensional imaging from multiple projections, enjoys a broad range of applications in clinical diagnosis, scientific observation, and industrial detection. Neural Adaptive Tomography (NeAT) is a recently proposed 3D rendering method based on neural radiance field for CT, and it demonstrates superior performance compared to traditional methods. However, it still faces challenges when dealing with the substantial perturbations and pose shifts encountered in CT scanning processes. Here, we propose a neural rendering method for CT reconstruction, named Iterative Neural Adaptive Tomography (INeAT), which incorporates iterative posture optimization to effectively counteract the influence of posture perturbations in data, particularly in cases involving significant posture variations. Through the implementation of a posture feedback optimization strategy, INeAT iteratively refines the posture corresponding to the input images based on the reconstructed 3D volume. We demonstrate that INeAT achieves artifact-suppressed and resolution-enhanced reconstruction in scenarios with significant pose disturbances. Furthermore, we show that our INeAT maintains comparable reconstruction performance to stable-state acquisitions even using data from unstable-state acquisitions, which significantly reduces the time required for CT scanning and relaxes the stringent requirements on imaging hardware systems, underscoring its immense potential for applications in short-time and low-cost CT technology. ",
    "url": "https://arxiv.org/abs/2311.01653",
    "authors": [
      "Bo Xiong",
      "Changqing Su",
      "Zihan Lin",
      "You Zhou",
      "Zhaofei Yu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01727",
    "title": "Flexible Error Mitigation of Quantum Processes with Data Augmentation  Empowered Neural Model",
    "abstract": "Neural networks have shown their effectiveness in various tasks in the realm of quantum computing. However, their application in quantum error mitigation, a crucial step towards realizing practical quantum advancements, has been restricted by reliance on noise-free statistics. To tackle this critical challenge, we propose a data augmentation empowered neural model for error mitigation (DAEM). Our model does not require any prior knowledge about the specific noise type and measurement settings and can estimate noise-free statistics solely from the noisy measurement results of the target quantum process, rendering it highly suitable for practical implementation. In numerical experiments, we show the model's superior performance in mitigating various types of noise, including Markovian noise and Non-Markovian noise, compared with previous error mitigation methods. We further demonstrate its versatility by employing the model to mitigate errors in diverse types of quantum processes, including those involving large-scale quantum systems and continuous-variable quantum states. This powerful data augmentation-empowered neural model for error mitigation establishes a solid foundation for realizing more reliable and robust quantum technologies in practical applications. ",
    "url": "https://arxiv.org/abs/2311.01727",
    "authors": [
      "Manwen Liao",
      "Yan Zhu",
      "Giulio Chiribella",
      "Yuxiang Yang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01894",
    "title": "Simulation of acquisition shifts in T2 Flair MR images to stress test AI  segmentation networks",
    "abstract": "Purpose: To provide a simulation framework for routine neuroimaging test data, which allows for \"stress testing\" of deep segmentation networks against acquisition shifts that commonly occur in clinical practice for T2 weighted (T2w) fluid attenuated inversion recovery (FLAIR) Magnetic Resonance Imaging (MRI) protocols. Approach: The approach simulates \"acquisition shift derivatives\" of MR images based on MR signal equations. Experiments comprise the validation of the simulated images by real MR scans and example stress tests on state-of-the-art MS lesion segmentation networks to explore a generic model function to describe the F1 score in dependence of the contrast-affecting sequence parameters echo time (TE) and inversion time (TI). Results: The differences between real and simulated images range up to 19 % in gray and white matter for extreme parameter settings. For the segmentation networks under test the F1 score dependency on TE and TI can be well described by quadratic model functions (R^2 > 0.9). The coefficients of the model functions indicate that changes of TE have more influence on the model performance than TI. Conclusions: We show that these deviations are in the range of values as may be caused by erroneous or individual differences of relaxation times as described by literature. The coefficients of the F1 model function allow for quantitative comparison of the influences of TE and TI. Limitations arise mainly from tissues with the low baseline signal (like CSF) and when the protocol contains contrast-affecting measures that cannot be modelled due to missing information in the DICOM header. ",
    "url": "https://arxiv.org/abs/2311.01894",
    "authors": [
      "Christiane Posselt",
      "Mehmet Yigit Avci",
      "Mehmet Yigitsoy",
      "Patrick Sch\u00fcnke",
      "Christoph Kolbitsch",
      "Tobias Sch\u00e4ffter",
      "Stefanie Remmele"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01916",
    "title": "Contrast-Agnostic Groupwise Registration by Robust PCA for Quantitative  Cardiac MRI",
    "abstract": "Quantitative cardiac magnetic resonance imaging (MRI) is an increasingly important diagnostic tool for cardiovascular diseases. Yet, co-registration of all baseline images within the quantitative MRI sequence is essential for the accuracy and precision of quantitative maps. However, co-registering all baseline images from a quantitative cardiac MRI sequence remains a nontrivial task because of the simultaneous changes in intensity and contrast, in combination with cardiac and respiratory motion. To address the challenge, we propose a novel motion correction framework based on robust principle component analysis (rPCA) that decomposes quantitative cardiac MRI into low-rank and sparse components, and we integrate the groupwise CNN-based registration backbone within the rPCA framework. The low-rank component of rPCA corresponds to the quantitative mapping (i.e. limited degree of freedom in variation), while the sparse component corresponds to the residual motion, making it easier to formulate and solve the groupwise registration problem. We evaluated our proposed method on cardiac T1 mapping by the modified Look-Locker inversion recovery (MOLLI) sequence, both before and after the Gadolinium contrast agent administration. Our experiments showed that our method effectively improved registration performance over baseline methods without introducing rPCA, and reduced quantitative mapping error in both in-domain (pre-contrast MOLLI) and out-of-domain (post-contrast MOLLI) inference. The proposed rPCA framework is generic and can be integrated with other registration backbones. ",
    "url": "https://arxiv.org/abs/2311.01916",
    "authors": [
      "Xinqi Li",
      "Yi Zhang",
      "Yidong Zhao",
      "Jan van Gemert",
      "Qian Tao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01994",
    "title": "Obtaining Explainable Classification Models using Distributionally  Robust Optimization",
    "abstract": "Model explainability is crucial for human users to be able to interpret how a proposed classifier assigns labels to data based on its feature values. We study generalized linear models constructed using sets of feature value rules, which can capture nonlinear dependencies and interactions. An inherent trade-off exists between rule set sparsity and its prediction accuracy. It is computationally expensive to find the right choice of sparsity -- e.g., via cross-validation -- with existing methods. We propose a new formulation to learn an ensemble of rule sets that simultaneously addresses these competing factors. Good generalization is ensured while keeping computational costs low by utilizing distributionally robust optimization. The formulation utilizes column generation to efficiently search the space of rule sets and constructs a sparse ensemble of rule sets, in contrast with techniques like random forests or boosting and their variants. We present theoretical results that motivate and justify the use of our distributionally robust formulation. Extensive numerical experiments establish that our method improves over competing methods -- on a large set of publicly available binary classification problem instances -- with respect to one or more of the following metrics: generalization quality, computational cost, and explainability. ",
    "url": "https://arxiv.org/abs/2311.01994",
    "authors": [
      "Sanjeeb Dash",
      "Soumyadip Ghosh",
      "Joao Goncalves",
      "Mark S. Squillante"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2311.01996",
    "title": "Detection of keratoconus Diseases using deep Learning",
    "abstract": "One of the most serious corneal disorders, keratoconus is difficult to diagnose in its early stages and can result in blindness. This illness, which often appears in the second decade of life, affects people of all sexes and races. Convolutional neural networks (CNNs), one of the deep learning approaches, have recently come to light as particularly promising tools for the accurate and timely diagnosis of keratoconus. The purpose of this study was to evaluate how well different D-CNN models identified keratoconus-related diseases. To be more precise, we compared five different CNN-based deep learning architectures (DenseNet201, InceptionV3, MobileNetV2, VGG19, Xception). In our comprehensive experimental analysis, the DenseNet201-based model performed very well in keratoconus disease identification in our extensive experimental research. This model outperformed its D-CNN equivalents, with an astounding accuracy rate of 89.14% in three crucial classes: Keratoconus, Normal, and Suspect. The results demonstrate not only the stability and robustness of the model but also its practical usefulness in real-world applications for accurate and dependable keratoconus identification. In addition, D-CNN DenseNet201 performs extraordinarily well in terms of precision, recall rates, and F1 scores in addition to accuracy. These measures validate the model's usefulness as an effective diagnostic tool by highlighting its capacity to reliably detect instances of keratoconus and to reduce false positives and negatives. ",
    "url": "https://arxiv.org/abs/2311.01996",
    "authors": [
      "AKM Enzam-Ul Haque",
      "Golam Rabbany",
      "Md. Siam"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.08452",
    "title": "On minimizers and convolutional filters: theoretical connections and  applications to genome analysis",
    "abstract": " Comments: 13 pages, 4 figures, submitted to a conference ",
    "url": "https://arxiv.org/abs/2111.08452",
    "authors": [
      "Yun William Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Genomics (q-bio.GN)"
    ]
  },
  {
    "id": "arXiv:2201.09698",
    "title": "Graph Neural Diffusion Networks for Semi-supervised Learning",
    "abstract": " Comments: 7 pages ",
    "url": "https://arxiv.org/abs/2201.09698",
    "authors": [
      "Wei Ye",
      "Zexi Huang",
      "Yunqi Hong",
      "Ambuj Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.02205",
    "title": "Clustered Saliency Prediction",
    "abstract": " Comments: 12 pages, BMVC 2023 ",
    "url": "https://arxiv.org/abs/2207.02205",
    "authors": [
      "Rezvan Sherkati",
      "James J. Clark"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.06177",
    "title": "Characterizing Graph Datasets for Node Classification:  Homophily-Heterophily Dichotomy and Beyond",
    "abstract": " Title: Characterizing Graph Datasets for Node Classification:  Homophily-Heterophily Dichotomy and Beyond ",
    "url": "https://arxiv.org/abs/2209.06177",
    "authors": [
      "Oleg Platonov",
      "Denis Kuznedelev",
      "Artem Babenko",
      "Liudmila Prokhorenkova"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2211.08761",
    "title": "Separable PINN: Mitigating the Curse of Dimensionality in  Physics-Informed Neural Networks",
    "abstract": " Comments: To appear in NeurIPS 2022 Workshop on The Symbiosis of Deep Learning and Differential Equations (DLDE) - II, 12 pages, 5 figures, full paper: arXiv:2306.15969 ",
    "url": "https://arxiv.org/abs/2211.08761",
    "authors": [
      "Junwoo Cho",
      "Seungtae Nam",
      "Hyunmo Yang",
      "Seok-Bae Yun",
      "Youngjoon Hong",
      "Eunbyung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.04873",
    "title": "Multimodal Prototype-Enhanced Network for Few-Shot Action Recognition",
    "abstract": " Title: Multimodal Prototype-Enhanced Network for Few-Shot Action Recognition ",
    "url": "https://arxiv.org/abs/2212.04873",
    "authors": [
      "Xinzhe Ni",
      "Yong Liu",
      "Hao Wen",
      "Yatai Ji",
      "Jing Xiao",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.01135",
    "title": "Provably Robust Semi-Infinite Program Under Collision Constraints via  Subdivision",
    "abstract": " Title: Provably Robust Semi-Infinite Program Under Collision Constraints via  Subdivision ",
    "url": "https://arxiv.org/abs/2302.01135",
    "authors": [
      "Duo Zhang",
      "Chen Liang",
      "Xifeng Gao",
      "Kui Wu",
      "Zherong Pan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.07104",
    "title": "xASTNN: Improved Code Representations for Industrial Practice",
    "abstract": " Comments: Accepted to ESEC/FSE 2023 ",
    "url": "https://arxiv.org/abs/2303.07104",
    "authors": [
      "Zhiwei Xu",
      "Min Zhou",
      "Xibin Zhao",
      "Yang Chen",
      "Xi Cheng",
      "Hongyu Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.11143",
    "title": "Adversarial Attacks against Binary Similarity Systems",
    "abstract": " Title: Adversarial Attacks against Binary Similarity Systems ",
    "url": "https://arxiv.org/abs/2303.11143",
    "authors": [
      "Gianluca Capozzi",
      "Daniele Cono D'Elia",
      "Giuseppe Antonio Di Luna",
      "Leonardo Querzoni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10050",
    "title": "The Impact of Missing Data on Causal Discovery: A Multicentric Clinical  Study",
    "abstract": " Title: The Impact of Missing Data on Causal Discovery: A Multicentric Clinical  Study ",
    "url": "https://arxiv.org/abs/2305.10050",
    "authors": [
      "Alessio Zanga",
      "Alice Bernasconi",
      "Peter J.F. Lucas",
      "Hanny Pijnenborg",
      "Casper Reijnen",
      "Marco Scutari",
      "Fabio Stella"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.15004",
    "title": "LLMDet: A Third Party Large Language Models Generated Text Detection  Tool",
    "abstract": " Comments: Accepted to the Findings of EMNLP 2023 ",
    "url": "https://arxiv.org/abs/2305.15004",
    "authors": [
      "Kangxi Wu",
      "Liang Pang",
      "Huawei Shen",
      "Xueqi Cheng",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2306.00265",
    "title": "Doubly Robust Self-Training",
    "abstract": " Title: Doubly Robust Self-Training ",
    "url": "https://arxiv.org/abs/2306.00265",
    "authors": [
      "Banghua Zhu",
      "Mingyu Ding",
      "Philip Jacobson",
      "Ming Wu",
      "Wei Zhan",
      "Michael Jordan",
      "Jiantao Jiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.02899",
    "title": "Learning nonparametric latent causal graphs with unknown interventions",
    "abstract": " Comments: To appear at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.02899",
    "authors": [
      "Yibo Jiang",
      "Bryon Aragam"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.10763",
    "title": "Guiding Language Models of Code with Global Context using Monitors",
    "abstract": " Comments: Accepted to NeurIPS 2023 and to appear as \"Monitor-Guided Decoding of Code LMs with Static Analysis of Repository Context\" at this https URL . Contents: 11 pages, 15 additional pages of appendix, 13 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2306.10763",
    "authors": [
      "Lakshya A Agrawal",
      "Aditya Kanade",
      "Navin Goyal",
      "Shuvendu K. Lahiri",
      "Sriram K. Rajamani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2306.15136",
    "title": "What Truly Matters in Trajectory Prediction for Autonomous Driving?",
    "abstract": " Title: What Truly Matters in Trajectory Prediction for Autonomous Driving? ",
    "url": "https://arxiv.org/abs/2306.15136",
    "authors": [
      "Phong Tran",
      "Haoran Wu",
      "Cunjun Yu",
      "Panpan Cai",
      "Sifa Zheng",
      "David Hsu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.05374",
    "title": "Multi-Task Learning to Enhance Generalizability of Neural Network  Equalizers in Coherent Optical Systems",
    "abstract": " Comments: 4 pages, European Conference on Optical Communication (ECOC) ",
    "url": "https://arxiv.org/abs/2307.05374",
    "authors": [
      "Sasipim Srivallapanondh",
      "Pedro J. Freire",
      "Ashraful Alam",
      "Nelson Costa",
      "Bernhard Spinnler",
      "Antonio Napoli",
      "Egor Sedov",
      "Sergei K. Turitsyn",
      "Jaroslaw E. Prilepsky"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12936",
    "title": "Timely Target Tracking: Distributed Updating in Cognitive Radar Networks",
    "abstract": " Comments: 14 pages, double column, 14 figures ",
    "url": "https://arxiv.org/abs/2307.12936",
    "authors": [
      "William W. Howard",
      "Anthony F. Martone",
      "R. Michael Buehrer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.00180",
    "title": "General Anomaly Detection of Underwater Gliders Validated by Large-scale  Deployment Datasets",
    "abstract": " Comments: Accepted in IEEE/MTS OCEANS Gulf Coast 2023 ",
    "url": "https://arxiv.org/abs/2308.00180",
    "authors": [
      "Ruochu Yang",
      "Chad Lembke",
      "Fumin Zhang",
      "Catherine Edwards"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10685",
    "title": "Contrastive Graph Prompt-tuning for Cross-domain Recommendation",
    "abstract": " Title: Contrastive Graph Prompt-tuning for Cross-domain Recommendation ",
    "url": "https://arxiv.org/abs/2308.10685",
    "authors": [
      "Zixuan Yi",
      "Iadh Ounis",
      "Craig Macdonald"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2308.13612",
    "title": "Is Deep Learning Network Necessary for Image Generation?",
    "abstract": " Comments: This paper has been reject. I am planning to combine this paper with my another paper to make one strong paper ",
    "url": "https://arxiv.org/abs/2308.13612",
    "authors": [
      "Chenqiu Zhao",
      "Guanfang Dong",
      "Anup Basu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.01814",
    "title": "Data-Driven Computation of Robust Invariant Sets and Gain-Scheduled  Controllers for Linear Parameter-Varying Systems",
    "abstract": " Comments: 6 pages, 3 figures. Accepted for publication, IEEE Control System Letters (LCSS) 2023 ",
    "url": "https://arxiv.org/abs/2309.01814",
    "authors": [
      "Manas Mejari",
      "Ankit Gupta",
      "Dario Piga"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.04579",
    "title": "EGOFALLS: A visual-audio dataset and benchmark for fall detection using  egocentric cameras",
    "abstract": " Title: EGOFALLS: A visual-audio dataset and benchmark for fall detection using  egocentric cameras ",
    "url": "https://arxiv.org/abs/2309.04579",
    "authors": [
      "Xueyi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.14072",
    "title": "BoIR: Box-Supervised Instance Representation for Multi-Person Pose  Estimation",
    "abstract": " Comments: Accepted to BMVC 2023, 19 pages including the appendix, 6 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2309.14072",
    "authors": [
      "Uyoung Jeong",
      "Seungryul Baek",
      "Hyung Jin Chang",
      "Kwang In Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.15770",
    "title": "Generating Transferable Adversarial Simulation Scenarios for  Self-Driving via Neural Rendering",
    "abstract": " Comments: Conference paper submitted to CoRL 23 ",
    "url": "https://arxiv.org/abs/2309.15770",
    "authors": [
      "Yasasa Abeysirigoonawardena",
      "Kevin Xie",
      "Chuhan Chen",
      "Salar Hosseini",
      "Ruiting Chen",
      "Ruiqi Wang",
      "Florian Shkurti"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.08701",
    "title": "Biased news sharing and partisan polarization on social media",
    "abstract": " Title: Biased news sharing and partisan polarization on social media ",
    "url": "https://arxiv.org/abs/2310.08701",
    "authors": [
      "Sof\u00eda M del Pozo",
      "Sebasti\u00e1n Pinto",
      "Matteo Serafino",
      "Lucio Garcia",
      "Hern\u00e1n A Makse",
      "Pablo Balenzuela"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2310.08854",
    "title": "Rank-DETR for High Quality Object Detection",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2310.08854",
    "authors": [
      "Yifan Pu",
      "Weicong Liang",
      "Yiduo Hao",
      "Yuhui Yuan",
      "Yukang Yang",
      "Chao Zhang",
      "Han Hu",
      "Gao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.12701",
    "title": "Parity Games on Temporal Graphs",
    "abstract": " Title: Parity Games on Temporal Graphs ",
    "url": "https://arxiv.org/abs/2310.12701",
    "authors": [
      "Pete Austin",
      "Sougata Bose",
      "Patrick Totzke"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2310.13139",
    "title": "Graph Neural Networks with polynomial activations have limited  expressivity",
    "abstract": " Title: Graph Neural Networks with polynomial activations have limited  expressivity ",
    "url": "https://arxiv.org/abs/2310.13139",
    "authors": [
      "Sammy Khalife"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16945",
    "title": "Causal Q-Aggregation for CATE Model Selection",
    "abstract": " Comments: The main text is 10 pages, and we include the Appendix at the end (totaling 52 pages) ",
    "url": "https://arxiv.org/abs/2310.16945",
    "authors": [
      "Hui Lan",
      "Vasilis Syrgkanis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2310.17584",
    "title": "A minimax optimal control approach for robust neural ODEs",
    "abstract": " Comments: 6 pages, 2 figures and 1 table ",
    "url": "https://arxiv.org/abs/2310.17584",
    "authors": [
      "Cristina Cipriani",
      "Alessandro Scagliotti",
      "Tobias W\u00f6hrer"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.18961",
    "title": "AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly  Detection",
    "abstract": " Title: AnomalyCLIP: Object-agnostic Prompt Learning for Zero-shot Anomaly  Detection ",
    "url": "https://arxiv.org/abs/2310.18961",
    "authors": [
      "Qihang Zhou",
      "Guansong Pang",
      "Yu Tian",
      "Shibo He",
      "Jiming Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19461",
    "title": "FoodFresh: Multi-Chain Design for an Inter-Institutional Food Supply  Chain Network",
    "abstract": " Title: FoodFresh: Multi-Chain Design for an Inter-Institutional Food Supply  Chain Network ",
    "url": "https://arxiv.org/abs/2310.19461",
    "authors": [
      "Philipp Stangl",
      "Christoph P. Neumann"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.01057",
    "title": "Ultra-Efficient On-Device Object Detection on AI-Integrated Smart  Glasses with TinyissimoYOLO",
    "abstract": " Title: Ultra-Efficient On-Device Object Detection on AI-Integrated Smart  Glasses with TinyissimoYOLO ",
    "url": "https://arxiv.org/abs/2311.01057",
    "authors": [
      "Julian Moosmann",
      "Pietro Bonazzi",
      "Yawei Li",
      "Sizhen Bian",
      "Philipp Mayer",
      "Luca Benini",
      "Michele Magno"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  }
]