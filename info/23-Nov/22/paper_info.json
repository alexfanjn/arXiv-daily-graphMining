[
  {
    "id": "arXiv:2311.12041",
    "title": "Automated Detection of hidden Damages and Impurities in Aluminum Die  Casting Materials and Fibre-Metal Laminates using Low-quality X-ray  Radiography, Synthetic X-ray Data Augmentation by Simulation, and Machine  Learning",
    "abstract": "Detection and characterization of hidden defects, impurities, and damages in layered composites like Fibre laminates, e.g., Fibre Metal Laminates (FML), as well as in monolithic materials, e.g., aluminum die casting materials, is still a challenge. This work discusses methods and challenges in data-driven modeling of automated damage and defect detectors using X-ray single- and multi-projection (CT) images. Three main issues are identified: Data and feature variance, data feature labeling (for supervised machine learning), and the missing ground truth. It will be shown that only simulation of data can deliver a ground truth data set and accurate labeling. Noise has significant impact on the feature detection and will be discussed. Data-driven feature detectors are implemented with semantic pixel- or z-profile Convolutional Neural Networks and LSTM Auto-encoders. Data is measured with three different devices: A low-quality and low-cost (Low-Q), a mid- and a high-quality (micro-CT, Mid-/High-Q) device. The goals of this work are the training of robust and generalized feature detectors with synthetic data and the transition from High- and Mid-Q laboratory measuring technologies towards in-field usable technologies and methods. ",
    "url": "https://arxiv.org/abs/2311.12041",
    "authors": [
      "Stefan Bosse",
      "Dirk Lehmhus"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2311.12051",
    "title": "Boost Adversarial Transferability by Uniform Scale and Mix Mask Method",
    "abstract": "Adversarial examples generated from surrogate models often possess the ability to deceive other black-box models, a property known as transferability. Recent research has focused on enhancing adversarial transferability, with input transformation being one of the most effective approaches. However, existing input transformation methods suffer from two issues. Firstly, certain methods, such as the Scale-Invariant Method, employ exponentially decreasing scale invariant parameters that decrease the adaptability in generating effective adversarial examples across multiple scales. Secondly, most mixup methods only linearly combine candidate images with the source image, leading to reduced features blending effectiveness. To address these challenges, we propose a framework called Uniform Scale and Mix Mask Method (US-MM) for adversarial example generation. The Uniform Scale approach explores the upper and lower boundaries of perturbation with a linear factor, minimizing the negative impact of scale copies. The Mix Mask method introduces masks into the mixing process in a nonlinear manner, significantly improving the effectiveness of mixing strategies. Ablation experiments are conducted to validate the effectiveness of each component in US-MM and explore the effect of hyper-parameters. Empirical evaluations on standard ImageNet datasets demonstrate that US-MM achieves an average of 7% better transfer attack success rate compared to state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2311.12051",
    "authors": [
      "Tao Wang",
      "Zijian Ying",
      "Qianmu Li",
      "zhichao Lian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12058",
    "title": "FlashOcc: Fast and Memory-Efficient Occupancy Prediction via  Channel-to-Height Plugin",
    "abstract": "Given the capability of mitigating the long-tail deficiencies and intricate-shaped absence prevalent in 3D object detection, occupancy prediction has become a pivotal component in autonomous driving systems. However, the procession of three-dimensional voxel-level representations inevitably introduces large overhead in both memory and computation, obstructing the deployment of to-date occupancy prediction approaches. In contrast to the trend of making the model larger and more complicated, we argue that a desirable framework should be deployment-friendly to diverse chips while maintaining high precision. To this end, we propose a plug-and-play paradigm, namely FlashOCC, to consolidate rapid and memory-efficient occupancy prediction while maintaining high precision. Particularly, our FlashOCC makes two improvements based on the contemporary voxel-level occupancy prediction approaches. Firstly, the features are kept in the BEV, enabling the employment of efficient 2D convolutional layers for feature extraction. Secondly, a channel-to-height transformation is introduced to lift the output logits from the BEV into the 3D space. We apply the FlashOCC to diverse occupancy prediction baselines on the challenging Occ3D-nuScenes benchmarks and conduct extensive experiments to validate the effectiveness. The results substantiate the superiority of our plug-and-play paradigm over previous state-of-the-art methods in terms of precision, runtime efficiency, and memory costs, demonstrating its potential for deployment. The code will be made available. ",
    "url": "https://arxiv.org/abs/2311.12058",
    "authors": [
      "Zichen Yu",
      "Changyong Shu",
      "Jiajun Deng",
      "Kangjie Lu",
      "Zongdai Liu",
      "Jiangyong Yu",
      "Dawei Yang",
      "Hui Li",
      "Yan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12064",
    "title": "Security Fence Inspection at Airports Using Object Detection",
    "abstract": "To ensure the security of airports, it is essential to protect the airside from unauthorized access. For this purpose, security fences are commonly used, but they require regular inspection to detect damages. However, due to the growing shortage of human specialists and the large manual effort, there is the need for automated methods. The aim is to automatically inspect the fence for damage with the help of an autonomous robot. In this work, we explore object detection methods to address the fence inspection task and localize various types of damages. In addition to evaluating four State-of-the-Art (SOTA) object detection models, we analyze the impact of several design criteria, aiming at adapting to the task-specific challenges. This includes contrast adjustment, optimization of hyperparameters, and utilization of modern backbones. The experimental results indicate that our optimized You Only Look Once v5 (YOLOv5) model achieves the highest accuracy of the four methods with an increase of 6.9% points in Average Precision (AP) compared to the baseline. Moreover, we show the real-time capability of the model. The trained models are published on GitHub: https://github.com/N-Friederich/airport_fence_inspection. ",
    "url": "https://arxiv.org/abs/2311.12064",
    "authors": [
      "Nils Friederich",
      "Andreas Specker",
      "J\u00fcrgen Beyerer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12068",
    "title": "Enhancing Novel Object Detection via Cooperative Foundational Models",
    "abstract": "In this work, we address the challenging and emergent problem of novel object detection (NOD), focusing on the accurate detection of both known and novel object categories during inference. Traditional object detection algorithms are inherently closed-set, limiting their capability to handle NOD. We present a novel approach to transform existing closed-set detectors into open-set detectors. This transformation is achieved by leveraging the complementary strengths of pre-trained foundational models, specifically CLIP and SAM, through our cooperative mechanism. Furthermore, by integrating this mechanism with state-of-the-art open-set detectors such as GDINO, we establish new benchmarks in object detection performance. Our method achieves 17.42 mAP in novel object detection and 42.08 mAP for known objects on the challenging LVIS dataset. Adapting our approach to the COCO OVD split, we surpass the current state-of-the-art by a margin of 7.2 $ \\text{AP}_{50} $ for novel classes. Our code is available at https://github.com/rohit901/cooperative-foundational-models . ",
    "url": "https://arxiv.org/abs/2311.12068",
    "authors": [
      "Rohit Bharadwaj",
      "Muzammal Naseer",
      "Salman Khan",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.12074",
    "title": "SecureBERT and LLAMA 2 Empowered Control Area Network Intrusion  Detection and Classification",
    "abstract": "Numerous studies have proved their effective strength in detecting Control Area Network (CAN) attacks. In the realm of understanding the human semantic space, transformer-based models have demonstrated remarkable effectiveness. Leveraging pre-trained transformers has become a common strategy in various language-related tasks, enabling these models to grasp human semantics more comprehensively. To delve into the adaptability evaluation on pre-trained models for CAN intrusion detection, we have developed two distinct models: CAN-SecureBERT and CAN-LLAMA2. Notably, our CAN-LLAMA2 model surpasses the state-of-the-art models by achieving an exceptional performance 0.999993 in terms of balanced accuracy, precision detection rate, F1 score, and a remarkably low false alarm rate of 3.10e-6. Impressively, the false alarm rate is 52 times smaller than that of the leading model, MTH-IDS (Multitiered Hybrid Intrusion Detection System). Our study underscores the promise of employing a Large Language Model as the foundational model, while incorporating adapters for other cybersecurity-related tasks and maintaining the model's inherent language-related capabilities. ",
    "url": "https://arxiv.org/abs/2311.12074",
    "authors": [
      "Xuemei Li",
      "Huirong Fu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.12075",
    "title": "BadCLIP: Dual-Embedding Guided Backdoor Attack on Multimodal Contrastive  Learning",
    "abstract": "Studying backdoor attacks is valuable for model copyright protection and enhancing defenses. While existing backdoor attacks have successfully infected multimodal contrastive learning models such as CLIP, they can be easily countered by specialized backdoor defenses for MCL models. This paper reveals the threats in this practical scenario that backdoor attacks can remain effective even after defenses and introduces the \\emph{\\toolns} attack, which is resistant to backdoor detection and model fine-tuning defenses. To achieve this, we draw motivations from the perspective of the Bayesian rule and propose a dual-embedding guided framework for backdoor attacks. Specifically, we ensure that visual trigger patterns approximate the textual target semantics in the embedding space, making it challenging to detect the subtle parameter variations induced by backdoor learning on such natural trigger patterns. Additionally, we optimize the visual trigger patterns to align the poisoned samples with target vision features in order to hinder the backdoor unlearning through clean fine-tuning. Extensive experiments demonstrate that our attack significantly outperforms state-of-the-art baselines (+45.3% ASR) in the presence of SoTA backdoor defenses, rendering these mitigation and detection strategies virtually ineffective. Furthermore, our approach effectively attacks some more rigorous scenarios like downstream tasks. We believe that this paper raises awareness regarding the potential threats associated with the practical application of multimodal contrastive learning and encourages the development of more robust defense mechanisms. ",
    "url": "https://arxiv.org/abs/2311.12075",
    "authors": [
      "Siyuan Liang",
      "Mingli Zhu",
      "Aishan Liu",
      "Baoyuan Wu",
      "Xiaochun Cao",
      "Ee-Chien Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12076",
    "title": "Towards Few-shot Out-of-Distribution Detection",
    "abstract": "Out-of-distribution (OOD) detection is critical for ensuring the reliability of open-world intelligent systems. Despite the notable advancements in existing OOD detection methodologies, our study identifies a significant performance drop under the scarcity of training samples. In this context, we introduce a novel few-shot OOD detection benchmark, carefully constructed to address this gap. Our empirical analysis reveals the superiority of ParameterEfficient Fine-Tuning (PEFT) strategies, such as visual prompt tuning and visual adapter tuning, over conventional techniques, including fully fine-tuning and linear probing tuning in the few-shot OOD detection task. Recognizing some crucial information from the pre-trained model, which is pivotal for OOD detection, may be lost during the fine-tuning process, we propose a method termed DomainSpecific and General Knowledge Fusion (DSGF). This approach is designed to be compatible with diverse fine-tuning frameworks. Our experiments show that the integration of DSGF significantly enhances the few-shot OOD detection capabilities across various methods and fine-tuning methodologies, including fully fine-tuning, visual adapter tuning, and visual prompt tuning. The code will be released. ",
    "url": "https://arxiv.org/abs/2311.12076",
    "authors": [
      "Jiuqing Dong",
      "Yongbin Gao",
      "Heng Zhou",
      "Jun Cen",
      "Yifan Yao",
      "Sook Yoon",
      "Park Dong Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12077",
    "title": "Efficient Model Agnostic Approach for Implicit Neural Representation  Based Arbitrary-Scale Image Super-Resolution",
    "abstract": "Single image super-resolution (SISR) has experienced significant advancements, primarily driven by deep convolutional networks. Traditional networks, however, are limited to upscaling images to a fixed scale, leading to the utilization of implicit neural functions for generating arbitrarily scaled images. Nevertheless, these methodologies have imposed substantial computational demands as they involve querying every target pixel to a single resource-intensive decoder. In this paper, we introduce a novel and efficient framework, the Mixture of Experts Implicit Super-Resolution (MoEISR), which enables super-resolution at arbitrary scales with significantly increased computational efficiency without sacrificing reconstruction quality. MoEISR dynamically allocates the most suitable decoding expert to each pixel using a lightweight mapper module, allowing experts with varying capacities to reconstruct pixels across regions with diverse complexities. Our experiments demonstrate that MoEISR successfully reduces up to 73% in floating point operations (FLOPs) while delivering comparable or superior peak signal-to-noise ratio (PSNR). ",
    "url": "https://arxiv.org/abs/2311.12077",
    "authors": [
      "Young Jae Oh",
      "Jihun Kim",
      "Tae Hyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12084",
    "title": "ODDR: Outlier Detection & Dimension Reduction Based Defense Against  Adversarial Patches",
    "abstract": "Adversarial attacks are a major deterrent towards the reliable use of machine learning models. A powerful type of adversarial attacks is the patch-based attack, wherein the adversarial perturbations modify localized patches or specific areas within the images to deceive the trained machine learning model. In this paper, we introduce Outlier Detection and Dimension Reduction (ODDR), a holistic defense mechanism designed to effectively mitigate patch-based adversarial attacks. In our approach, we posit that input features corresponding to adversarial patches, whether naturalistic or otherwise, deviate from the inherent distribution of the remaining image sample and can be identified as outliers or anomalies. ODDR employs a three-stage pipeline: Fragmentation, Segregation, and Neutralization, providing a model-agnostic solution applicable to both image classification and object detection tasks. The Fragmentation stage parses the samples into chunks for the subsequent Segregation process. Here, outlier detection techniques identify and segregate the anomalous features associated with adversarial perturbations. The Neutralization stage utilizes dimension reduction methods on the outliers to mitigate the impact of adversarial perturbations without sacrificing pertinent information necessary for the machine learning task. Extensive testing on benchmark datasets and state-of-the-art adversarial patches demonstrates the effectiveness of ODDR. Results indicate robust accuracies matching and lying within a small range of clean accuracies (1%-3% for classification and 3%-5% for object detection), with only a marginal compromise of 1%-2% in performance on clean samples, thereby significantly outperforming other defenses. ",
    "url": "https://arxiv.org/abs/2311.12084",
    "authors": [
      "Nandish Chattopadhyay",
      "Amira Guesmi",
      "Muhammad Abdullah Hanif",
      "Bassem Ouni",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12086",
    "title": "Masked Autoencoders Are Robust Neural Architecture Search Learners",
    "abstract": "Neural Architecture Search (NAS) currently relies heavily on labeled data, which is both expensive and time-consuming to acquire. In this paper, we propose a novel NAS framework based on Masked Autoencoders (MAE) that eliminates the need for labeled data during the search process. By replacing the supervised learning objective with an image reconstruction task, our approach enables the robust discovery of network architectures without compromising performance and generalization ability. Additionally, we address the problem of performance collapse encountered in the widely-used Differentiable Architecture Search (DARTS) method in the unsupervised paradigm by introducing a multi-scale decoder. Through extensive experiments conducted on various search spaces and datasets, we demonstrate the effectiveness and robustness of the proposed method, providing empirical evidence of its superiority over baseline approaches. ",
    "url": "https://arxiv.org/abs/2311.12086",
    "authors": [
      "Yiming Hu",
      "Xiangxiang Chu",
      "Bo Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.12088",
    "title": "PhytNet -- Tailored Convolutional Neural Networks for Custom Botanical  Data",
    "abstract": "Automated disease, weed and crop classification with computer vision will be invaluable in the future of agriculture. However, existing model architectures like ResNet, EfficientNet and ConvNeXt often underperform on smaller, specialised datasets typical of such projects. We address this gap with informed data collection and the development of a new CNN architecture, PhytNet. Utilising a novel dataset of infrared cocoa tree images, we demonstrate PhytNet's development and compare its performance with existing architectures. Data collection was informed by analysis of spectroscopy data, which provided useful insights into the spectral characteristics of cocoa trees. Such information could inform future data collection and model development. Cocoa was chosen as a focal species due to the diverse pathology of its diseases, which pose significant challenges for detection. ResNet18 showed some signs of overfitting, while EfficientNet variants showed distinct signs of overfitting. By contrast, PhytNet displayed excellent attention to relevant features, no overfitting, and an exceptionally low computation cost (1.19 GFLOPS). As such PhytNet is a promising candidate for rapid disease or plant classification, or precise localisation of disease symptoms for autonomous systems. ",
    "url": "https://arxiv.org/abs/2311.12088",
    "authors": [
      "Jamie R. Sykes",
      "Katherine Denby",
      "Daniel W. Franks"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.12125",
    "title": "Mixing-Denoising Generalizable Occupancy Networks",
    "abstract": "While current state-of-the-art generalizable implicit neural shape models rely on the inductive bias of convolutions, it is still not entirely clear how properties emerging from such biases are compatible with the task of 3D reconstruction from point cloud. We explore an alternative approach to generalizability in this context. We relax the intrinsic model bias (i.e. using MLPs to encode local features as opposed to convolutions) and constrain the hypothesis space instead with an auxiliary regularization related to the reconstruction task, i.e. denoising. The resulting model is the first only-MLP locally conditioned implicit shape reconstruction from point cloud network with fast feed forward inference. Point cloud borne features and denoising offsets are predicted from an exclusively MLP-made network in a single forward pass. A decoder predicts occupancy probabilities for queries anywhere in space by pooling nearby features from the point cloud order-invariantly, guided by denoised relative positional encoding. We outperform the state-of-the-art convolutional method while using half the number of model parameters. ",
    "url": "https://arxiv.org/abs/2311.12125",
    "authors": [
      "Amine Ouasfi",
      "Adnane Boukhayma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.12136",
    "title": "Multi-view Graph Convolution for Participant Recommendation",
    "abstract": "Social networks have become essential for people's lives. The proliferation of web services further expands social networks at an unprecedented scale, leading to immeasurable commercial value for online platforms. Recently, the group buying (GB) business mode is prevalent and also becoming more popular in E-commerce. GB explicitly forms groups of users with similar interests to secure better discounts from the merchants, often operating within social networks. It is a novel way to further unlock the commercial value by explicitly utilizing the online social network in E-commerce. Participant recommendation, a fundamental problem emerging together with GB, aims to find the participants for a launched group buying process with an initiator and a target item to increase the GB success rate. This paper proposes Multi-View Graph Convolution for Participant Recommendation (MVPRec) to tackle this problem. To differentiate the roles of users (Initiator/Participant) within the GB process, we explicitly reconstruct historical GB data into initiator-view and participant-view graphs. Together with the social graph, we obtain a multi-view user representation with graph encoders. Then MVPRec fuses the GB and social representation with an attention module to obtain the user representation and learns a matching score with the initiator's social friends via a multi-head attention mechanism. Social friends with the Top-k matching score are recommended for the corresponding GB process. Experiments on three datasets justify the effectiveness of MVPRec in the emerging participant recommendation problem. ",
    "url": "https://arxiv.org/abs/2311.12136",
    "authors": [
      "Xiaolong Liu",
      "Liangwei Yang",
      "Chen Wang",
      "Mingdai Yang",
      "Zhiwei Liu",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.12179",
    "title": "Leveraging Closed-Access Multilingual Embedding for Automatic Sentence  Alignment in Low Resource Languages",
    "abstract": "The importance of qualitative parallel data in machine translation has long been determined but it has always been very difficult to obtain such in sufficient quantity for the majority of world languages, mainly because of the associated cost and also the lack of accessibility to these languages. Despite the potential for obtaining parallel datasets from online articles using automatic approaches, forensic investigations have found a lot of quality-related issues such as misalignment, and wrong language codes. In this work, we present a simple but qualitative parallel sentence aligner that carefully leveraged the closed-access Cohere multilingual embedding, a solution that ranked second in the just concluded #CoHereAIHack 2023 Challenge (see https://ai6lagos.devpost.com). The proposed approach achieved $94.96$ and $54.83$ f1 scores on FLORES and MAFAND-MT, compared to $3.64$ and $0.64$ of LASER respectively. Our method also achieved an improvement of more than 5 BLEU scores over LASER, when the resulting datasets were used with MAFAND-MT dataset to train translation models. Our code and data are available for research purposes here (https://github.com/abumafrim/Cohere-Align). ",
    "url": "https://arxiv.org/abs/2311.12179",
    "authors": [
      "Idris Abdulmumin",
      "Auwal Abubakar Khalid",
      "Shamsuddeen Hassan Muhammad",
      "Ibrahim Said Ahmad",
      "Lukman Jibril Aliyu",
      "Babangida Sani",
      "Bala Mairiga Abduljalil",
      "Sani Ahmad Hassan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.12195",
    "title": "Scaling up the formation of agents with heterogeneous sensing: mixed  distance and bearing-only",
    "abstract": "Unlike the case with identical neighboring agents whose actions are mirrored, the problem of distributed formation control design with heterogeneous sensing is not straightforward. In this paper, we consider the problem of distributed formation control where each agent can only control distances or bearings with its neighbors. We firstly develop a rigidity theory with heterogeneous sensing to ensure that the desired shape is well-posed. Secondly, we propose an iterative method that allows us to scale up the number of agents with heterogeneous sensing. Finally, numerical simulations show the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2311.12195",
    "authors": [
      "Jin Chen",
      "Bayu Jayawardhana",
      "Hector Garcia de Marina"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.12207",
    "title": "Defense semantics of argumentation: revisit",
    "abstract": "In this paper we introduce a novel semantics, called defense semantics, for Dung's abstract argumentation frameworks in terms of a notion of (partial) defence, which is a triple encoding that one argument is (partially) defended by another argument via attacking the attacker of the first argument. In terms of defense semantics, we show that defenses related to self-attacked arguments and arguments in 3-cycles are unsatifiable under any situation and therefore can be removed without affecting the defense semantics of an AF. Then, we introduce a new notion of defense equivalence of AFs, and compare defense equivalence with standard equivalence and strong equivalence, respectively. Finally, by exploiting defense semantics, we define two kinds of reasons for accepting arguments, i.e., direct reasons and root reasons, and a notion of root equivalence of AFs that can be used in argumentation summarization. ",
    "url": "https://arxiv.org/abs/2311.12207",
    "authors": [
      "Beishui Liao",
      "Leendert van der Torre"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.12211",
    "title": "DefensiveDR: Defending against Adversarial Patches using Dimensionality  Reduction",
    "abstract": "Adversarial patch-based attacks have shown to be a major deterrent towards the reliable use of machine learning models. These attacks involve the strategic modification of localized patches or specific image areas to deceive trained machine learning models. In this paper, we propose \\textit{DefensiveDR}, a practical mechanism using a dimensionality reduction technique to thwart such patch-based attacks. Our method involves projecting the sample images onto a lower-dimensional space while retaining essential information or variability for effective machine learning tasks. We perform this using two techniques, Singular Value Decomposition and t-Distributed Stochastic Neighbor Embedding. We experimentally tune the variability to be preserved for optimal performance as a hyper-parameter. This dimension reduction substantially mitigates adversarial perturbations, thereby enhancing the robustness of the given machine learning model. Our defense is model-agnostic and operates without assumptions about access to model decisions or model architectures, making it effective in both black-box and white-box settings. Furthermore, it maintains accuracy across various models and remains robust against several unseen patch-based attacks. The proposed defensive approach improves the accuracy from 38.8\\% (without defense) to 66.2\\% (with defense) when performing LaVAN and GoogleAp attacks, which supersedes that of the prominent state-of-the-art like LGS (53.86\\%) and Jujutsu (60\\%). ",
    "url": "https://arxiv.org/abs/2311.12211",
    "authors": [
      "Nandish Chattopadhyay",
      "Amira Guesmi",
      "Muhammad Abdullah Hanif",
      "Bassem Ouni",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.12224",
    "title": "Fast Inner-Product Algorithms and Architectures for Deep Neural Network  Accelerators",
    "abstract": "We introduce a new algorithm called the Free-pipeline Fast Inner Product (FFIP) and its hardware architecture that improve an under-explored fast inner-product algorithm (FIP) proposed by Winograd in 1968. Unlike the unrelated Winograd minimal filtering algorithms for convolutional layers, FIP is applicable to all machine learning (ML) model layers that can mainly decompose to matrix multiplication, including fully-connected, convolutional, recurrent, and attention/transformer layers. We implement FIP for the first time in an ML accelerator then present our FFIP algorithm and generalized architecture which inherently improve FIP's clock frequency and, as a consequence, throughput for a similar hardware cost. Finally, we contribute ML-specific optimizations for the FIP and FFIP algorithms and architectures. We show that FFIP can be seamlessly incorporated into traditional fixed-point systolic array ML accelerators to achieve the same throughput with half the number of multiply-accumulate (MAC) units, or it can double the maximum systolic array size that can fit onto devices with a fixed hardware budget. Our FFIP implementation for non-sparse ML models with 8 to 16-bit fixed-point inputs achieves higher throughput and compute efficiency than the best-in-class prior solutions on the same type of compute platform. ",
    "url": "https://arxiv.org/abs/2311.12224",
    "authors": [
      "Trevor E. Pogue",
      "Nicola Nicolici"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2311.12244",
    "title": "Provable Representation with Efficient Planning for Partially Observable  Reinforcement Learning",
    "abstract": "In real-world reinforcement learning problems, the state information is often only partially observable, which breaks the basic assumption in Markov decision processes, and thus, leads to inferior performances. Partially Observable Markov Decision Processes have been introduced to explicitly take the issue into account for learning, exploration, and planning, but presenting significant computational and statistical challenges. To address these difficulties, we exploit the representation view, which leads to a coherent design framework for a practically tractable reinforcement learning algorithm upon partial observations. We provide a theoretical analysis for justifying the statistical efficiency of the proposed algorithm. We also empirically demonstrate the proposed algorithm can surpass state-of-the-art performance with partial observations across various benchmarks, therefore, pushing reliable reinforcement learning towards more practical applications. ",
    "url": "https://arxiv.org/abs/2311.12244",
    "authors": [
      "Hongming Zhang",
      "Tongzheng Ren",
      "Chenjun Xiao",
      "Dale Schuurmans",
      "Bo Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.12245",
    "title": "Towards Accurate Loop Closure Detection in Semantic SLAM with 3D  Semantic Covisibility Graphs",
    "abstract": "Loop closure is necessary for correcting errors accumulated in simultaneous localization and mapping (SLAM) in unknown environments. However, conventional loop closure methods based on low-level geometric or image features may cause high ambiguity by not distinguishing similar scenarios. Thus, incorrect loop closures can occur. Though semantic 2D image information is considered in some literature to detect loop closures, there is little work that compares 3D scenes as an integral part of a semantic SLAM system. This paper introduces an approach, called SmSLAM+LCD, integrated into a semantic SLAM system to combine high-level 3D semantic information and low-level feature information to conduct accurate loop closure detection and effective drift reduction. The effectiveness of our approach is demonstrated in testing results. ",
    "url": "https://arxiv.org/abs/2311.12245",
    "authors": [
      "Zhentian Qian",
      "Jie Fu",
      "Jing Xiao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.12253",
    "title": "The limitation of neural nets for approximation and optimization",
    "abstract": "We are interested in assessing the use of neural networks as surrogate models to approximate and minimize objective functions in optimization problems. While neural networks are widely used for machine learning tasks such as classification and regression, their application in solving optimization problems has been limited. Our study begins by determining the best activation function for approximating the objective functions of popular nonlinear optimization test problems, and the evidence provided shows that~SiLU has the best performance. We then analyze the accuracy of function value, gradient, and Hessian approximations for such objective functions obtained through interpolation/regression models and neural networks. When compared to interpolation/regression models, neural networks can deliver competitive zero- and first-order approximations (at a high training cost) but underperform on second-order approximation. However, it is shown that combining a neural net activation function with the natural basis for quadratic interpolation/regression can waive the necessity of including cross terms in the natural basis, leading to models with fewer parameters to determine. Lastly, we provide evidence that the performance of a state-of-the-art derivative-free optimization algorithm can hardly be improved when the gradient of an objective function is approximated using any of the surrogate models considered, including neural networks. ",
    "url": "https://arxiv.org/abs/2311.12253",
    "authors": [
      "Tommaso Giovannelli",
      "Oumaima Sohab",
      "Luis Nunes Vicente"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.12255",
    "title": "Exploring Time Granularity on Temporal Graphs for Dynamic Link  Prediction in Real-world Networks",
    "abstract": "Dynamic Graph Neural Networks (DGNNs) have emerged as the predominant approach for processing dynamic graph-structured data. However, the influence of temporal information on model performance and robustness remains insufficiently explored, particularly regarding how models address prediction tasks with different time granularities. In this paper, we explore the impact of time granularity when training DGNNs on dynamic graphs through extensive experiments. We examine graphs derived from various domains and compare three different DGNNs to the baseline model across four varied time granularities. We mainly consider the interplay between time granularities, model architectures, and negative sampling strategies to obtain general conclusions. Our results reveal that a sophisticated memory mechanism and proper time granularity are crucial for a DGNN to deliver competitive and robust performance in the dynamic link prediction task. We also discuss drawbacks in considered models and datasets and propose promising directions for future research on the time granularity of temporal graphs. ",
    "url": "https://arxiv.org/abs/2311.12255",
    "authors": [
      "Xiangjian Jiang",
      "Yanyi Pu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.12267",
    "title": "Learning Causal Representations from General Environments:  Identifiability and Intrinsic Ambiguity",
    "abstract": "This paper studies causal representation learning, the task of recovering high-level latent variables and their causal relationships from low-level data that we observe, assuming access to observations generated from multiple environments. While existing works are able to prove full identifiability of the underlying data generating process, they typically assume access to single-node, hard interventions which is rather unrealistic in practice. The main contribution of this paper is characterize a notion of identifiability which is provably the best one can achieve when hard interventions are not available. First, for linear causal models, we provide identifiability guarantee for data observed from general environments without assuming any similarities between them. While the causal graph is shown to be fully recovered, the latent variables are only identified up to an effect-domination ambiguity (EDA). We then propose an algorithm, LiNGCReL which is guaranteed to recover the ground-truth model up to EDA, and we demonstrate its effectiveness via numerical experiments. Moving on to general non-parametric causal models, we prove the same idenfifiability guarantee assuming access to groups of soft interventions. Finally, we provide counterparts of our identifiability results, indicating that EDA is basically inevitable in our setting. ",
    "url": "https://arxiv.org/abs/2311.12267",
    "authors": [
      "Jikai Jin",
      "Vasilis Syrgkanis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Econometrics (econ.EM)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.12273",
    "title": "How AI-driven Digital Twins Can Empower Mobile Networks",
    "abstract": "The growing complexity of next-generation networks exacerbates the modeling and algorithmic flaws of conventional network optimization methodology. In this paper, we propose a mobile network digital twin (MNDT) architecture for 6G networks. To address the modeling and algorithmic shortcomings, the MNDT uses a simulation-optimization structure. The feedback from the network simulation engine, which serves as validation for the optimizer's decision outcomes, is used explicitly to train artificial intelligence (AI) empowered optimizers iteratively. In practice, we develop a network digital twin prototype system leveraging data-driven technology to accurately model the behaviors of mobile network elements (e.g., mobile users and base stations), wireless environments, and network performance. An AI-powered network optimizer has been developed based on the deployed MNDT prototype system for providing reliable and optimized network configurations. The results of the experiments demonstrate that the proposed MNDT infrastructure can provide practical network optimization solutions while adapting to the more complex environment. ",
    "url": "https://arxiv.org/abs/2311.12273",
    "authors": [
      "Tong Li",
      "Fenyu Jiang",
      "Qiaohong Yu",
      "Wenzhen Huang",
      "Tao Jiang",
      "Depeng Jin"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.12275",
    "title": "Enabling On-Device Large Language Model Personalization with  Self-Supervised Data Selection and Synthesis",
    "abstract": "After a large language model (LLM) is deployed on edge devices, it is desirable for these devices to learn from user-generated conversation data to generate user-specific and personalized responses in real-time. However, user-generated data usually contains sensitive and private information, and uploading such data to the cloud for annotation is not preferred if not prohibited. While it is possible to obtain annotation locally by directly asking users to provide preferred responses, such annotations have to be sparse to not affect user experience. In addition, the storage of edge devices is usually too limited to enable large-scale fine-tuning with full user-generated data. It remains an open question how to enable on-device LLM personalization, considering sparse annotation and limited on-device storage. In this paper, we propose a novel framework to select and store the most representative data online in a self-supervised way. Such data has a small memory footprint and allows infrequent requests of user annotations for further fine-tuning. To enhance fine-tuning quality, multiple semantically similar pairs of question texts and expected responses are generated using the LLM. Our experiments show that the proposed framework achieves the best user-specific content-generating capability (accuracy) and fine-tuning speed (performance) compared with vanilla baselines. To the best of our knowledge, this is the very first on-device LLM personalization framework. ",
    "url": "https://arxiv.org/abs/2311.12275",
    "authors": [
      "Ruiyang Qin",
      "Jun Xia",
      "Zhenge Jia",
      "Meng Jiang",
      "Ahmed Abbasi",
      "Peipei Zhou",
      "Jingtong Hu",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.12281",
    "title": "GPUSCAN++:eficient Structural Graph Clustering on GPUs",
    "abstract": "Structural clustering is one of the most popular graph clustering methods, which has achieved great performance improvement by utilizing GPUs. Even though, the state-of-the-art GPU-based structural clustering algorithm, GPUSCAN, still suffers from efficiency issues since lots of extra costs are introduced for parallelization. Moreover, GPUSCAN assumes that the graph is resident in the GPU memory. However, the GPU memory capacity is limited currently while many real-world graphs are big and cannot fit in the GPU memory, which makes GPUSCAN unable to handle large graphs. Motivated by this, we present a new GPU-based structural clustering algorithm, GPUSCAN++, in this paper. To address the efficiency issue, we propose a new progressive clustering method tailored for GPUs that not only avoid high parallelization costs but also fully exploits the computing resources of GPUs. To address the GPU memory limitation issue, we propose a partition-based algorithm for structural clustering that can process large graphs with limited GPU memory. We conduct experiments on real graphs, and the experimental results demonstrate that our algorithm can achieve up to 168 times speedup compared with the state-of-the-art GPU-based algorithm when the graph can be resident in the GPU memory. Moreover, our algorithm is scalable to handle large graphs. As an example, our algorithm can finish the structural clustering on a graph with 1.8 billion edges using less than 2 GB GPU memory. ",
    "url": "https://arxiv.org/abs/2311.12281",
    "authors": [
      "Long Yuan",
      "Zeyu Zhou",
      "Xuemin Lin",
      "Zi Chen",
      "Xiang Zhao",
      "Fan Zhang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2311.12307",
    "title": "Causality is all you need",
    "abstract": "In the fundamental statistics course, students are taught to remember the well-known saying: \"Correlation is not Causation\". Till now, statistics (i.e., correlation) have developed various successful frameworks, such as Transformer and Pre-training large-scale models, which have stacked multiple parallel self-attention blocks to imitate a wide range of tasks. However, in the causation community, how to build an integrated causal framework still remains an untouched domain despite its excellent intervention capabilities. In this paper, we propose the Causal Graph Routing (CGR) framework, an integrated causal scheme relying entirely on the intervention mechanisms to reveal the cause-effect forces hidden in data. Specifically, CGR is composed of a stack of causal layers. Each layer includes a set of parallel deconfounding blocks from different causal graphs. We combine these blocks via the concept of the proposed sufficient cause, which allows the model to dynamically select the suitable deconfounding methods in each layer. CGR is implemented as the stacked networks, integrating no confounder, back-door adjustment, front-door adjustment, and probability of sufficient cause. We evaluate this framework on two classical tasks of CV and NLP. Experiments show CGR can surpass the current state-of-the-art methods on both Visual Question Answer and Long Document Classification tasks. In particular, CGR has great potential in building the \"causal\" pre-training large-scale model that effectively generalizes to diverse tasks. It will improve the machines' comprehension of causal relationships within a broader semantic space. ",
    "url": "https://arxiv.org/abs/2311.12307",
    "authors": [
      "Ning Xu",
      "Yifei Gao",
      "Hongshuo Tian",
      "Yongdong Zhang",
      "An-An Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.12309",
    "title": "Power grid operational risk assessment using graph neural network  surrogates",
    "abstract": "We investigate the utility of graph neural networks (GNNs) as proxies of power grid operational decision-making algorithms (optimal power flow (OPF) and security-constrained unit commitment (SCUC)) to enable rigorous quantification of the operational risk. To conduct principled risk analysis, numerous Monte Carlo (MC) samples are drawn from the (foretasted) probability distributions of spatio-temporally correlated stochastic grid variables. The corresponding OPF and SCUC solutions, which are needed to quantify the risk, are generated using traditional OPF and SCUC solvers to generate data for training GNN model(s). The GNN model performance is evaluated in terms of the accuracy of predicting quantities of interests (QoIs) derived from the decision variables in OPF and SCUC. Specifically, we focus on thermal power generation and load shedding at system and individual zone level. We also perform reliability and risk quantification based on GNN predictions and compare with that obtained from OPF/SCUC solutions. Our results demonstrate that GNNs are capable of providing fast and accurate prediction of QoIs and thus can be good surrogate models for OPF and SCUC. The excellent accuracy of GNN-based reliability and risk assessment further suggests that GNN surrogate has the potential to be applied in real-time and hours-ahead risk quantification. ",
    "url": "https://arxiv.org/abs/2311.12309",
    "authors": [
      "Yadong Zhang",
      "Pranav M Karve",
      "Sankaran Mahadevan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.12311",
    "title": "ABFL: Angular Boundary Discontinuity Free Loss for Arbitrary Oriented  Object Detection in Aerial Images",
    "abstract": "Arbitrary oriented object detection (AOOD) in aerial images is a widely concerned and highly challenging task, and plays an important role in many scenarios. The core of AOOD involves the representation, encoding, and feature augmentation of oriented bounding-boxes (Bboxes). Existing methods lack intuitive modeling of angle difference measurement in oriented Bbox representations. Oriented Bboxes under different representations exhibit rotational symmetry with varying periods due to angle periodicity. The angular boundary discontinuity (ABD) problem at periodic boundary positions is caused by rotational symmetry in measuring angular differences. In addition, existing methods also use additional encoding-decoding structures for oriented Bboxes. In this paper, we design an angular boundary free loss (ABFL) based on the von Mises distribution. The ABFL aims to solve the ABD problem when detecting oriented objects. Specifically, ABFL proposes to treat angles as circular data rather than linear data when measuring angle differences, aiming to introduce angle periodicity to alleviate the ABD problem and improve the accuracy of angle difference measurement. In addition, ABFL provides a simple and effective solution for various periodic boundary discontinuities caused by rotational symmetry in AOOD tasks, as it does not require additional encoding-decoding structures for oriented Bboxes. Extensive experiments on the DOTA and HRSC2016 datasets show that the proposed ABFL loss outperforms some state-of-the-art methods focused on addressing the ABD problem. ",
    "url": "https://arxiv.org/abs/2311.12311",
    "authors": [
      "Zifei Zhao",
      "Shengyang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12314",
    "title": "Demystifying Graph Sparsification Algorithms in Graph Properties  Preservation",
    "abstract": "Graph sparsification is a technique that approximates a given graph by a sparse graph with a subset of vertices and/or edges. The goal of an effective sparsification algorithm is to maintain specific graph properties relevant to the downstream task while minimizing the graph's size. Graph algorithms often suffer from long execution time due to the irregularity and the large real-world graph size. Graph sparsification can be applied to greatly reduce the run time of graph algorithms by substituting the full graph with a much smaller sparsified graph, without significantly degrading the output quality. However, the interaction between numerous sparsifiers and graph properties is not widely explored, and the potential of graph sparsification is not fully understood. In this work, we cover 16 widely-used graph metrics, 12 representative graph sparsification algorithms, and 14 real-world input graphs spanning various categories, exhibiting diverse characteristics, sizes, and densities. We developed a framework to extensively assess the performance of these sparsification algorithms against graph metrics, and provide insights to the results. Our study shows that there is no one sparsifier that performs the best in preserving all graph properties, e.g. sparsifiers that preserve distance-related graph properties (eccentricity) struggle to perform well on Graph Neural Networks (GNN). This paper presents a comprehensive experimental study evaluating the performance of sparsification algorithms in preserving essential graph metrics. The insights inform future research in incorporating matching graph sparsification to graph algorithms to maximize benefits while minimizing quality degradation. Furthermore, we provide a framework to facilitate the future evaluation of evolving sparsification algorithms, graph metrics, and ever-growing graph data. ",
    "url": "https://arxiv.org/abs/2311.12314",
    "authors": [
      "Yuhan Chen",
      "Haojie Ye",
      "Sanketh Vedula",
      "Alex Bronstein",
      "Ronald Dreslinski",
      "Trevor Mudge",
      "Nishil Talati"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2311.12323",
    "title": "Modeling Political Orientation of Social Media Posts: An Extended  Analysis",
    "abstract": "Developing machine learning models to characterize political polarization on online social media presents significant challenges. These challenges mainly stem from various factors such as the lack of annotated data, presence of noise in social media datasets, and the sheer volume of data. The common research practice typically examines the biased structure of online user communities for a given topic or qualitatively measuring the impacts of polarized topics on social media. However, there is limited work focusing on analyzing polarization at the ground-level, specifically in the social media posts themselves. Such existing analysis heavily relies on annotated data, which often requires laborious human labeling, offers labels only to specific problems, and lacks the ability to determine the near-future bias state of a social media conversations. Understanding the degree of political orientation conveyed in social media posts is crucial for quantifying the bias of online user communities and investigating the spread of polarized content. In this work, we first introduce two heuristic methods that leverage on news media bias and post content to label social media posts. Next, we compare the efficacy and quality of heuristically labeled dataset with a randomly sampled human-annotated dataset. Additionally, we demonstrate that current machine learning models can exhibit improved performance in predicting political orientation of social media posts, employing both traditional supervised learning and few-shot learning setups. We conduct experiments using the proposed heuristic methods and machine learning approaches to predict the political orientation of posts collected from two social media forums with diverse political ideologies: Gab and Twitter. ",
    "url": "https://arxiv.org/abs/2311.12323",
    "authors": [
      "Sadia Kamal",
      "Brenner Little",
      "Jade Gullic",
      "Trevor Harms",
      "Kristin Olofsson",
      "Arunkumar Bagavathi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.12329",
    "title": "Graph Neural Ordinary Differential Equations-based method for  Collaborative Filtering",
    "abstract": "Graph Convolution Networks (GCNs) are widely considered state-of-the-art for collaborative filtering. Although several GCN-based methods have been proposed and achieved state-of-the-art performance in various tasks, they can be computationally expensive and time-consuming to train if too many layers are created. However, since the linear GCN model can be interpreted as a differential equation, it is possible to transfer it to an ODE problem. This inspired us to address the computational limitations of GCN-based models by designing a simple and efficient NODE-based model that can skip some GCN layers to reach the final state, thus avoiding the need to create many layers. In this work, we propose a Graph Neural Ordinary Differential Equation-based method for Collaborative Filtering (GODE-CF). This method estimates the final embedding by utilizing the information captured by one or two GCN layers. To validate our approach, we conducted experiments on multiple datasets. The results demonstrate that our model outperforms competitive baselines, including GCN-based models and other state-of-the-art CF methods. Notably, our proposed GODE-CF model has several advantages over traditional GCN-based models. It is simple, efficient, and has a fast training time, making it a practical choice for real-world situations. ",
    "url": "https://arxiv.org/abs/2311.12329",
    "authors": [
      "Ke Xu",
      "Yuanjie Zhu",
      "Weizhi Zhang",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2311.12345",
    "title": "Stable Diffusion For Aerial Object Detection",
    "abstract": "Aerial object detection is a challenging task, in which one major obstacle lies in the limitations of large-scale data collection and the long-tail distribution of certain classes. Synthetic data offers a promising solution, especially with recent advances in diffusion-based methods like stable diffusion (SD). However, the direct application of diffusion methods to aerial domains poses unique challenges: stable diffusion's optimization for rich ground-level semantics doesn't align with the sparse nature of aerial objects, and the extraction of post-synthesis object coordinates remains problematic. To address these challenges, we introduce a synthetic data augmentation framework tailored for aerial images. It encompasses sparse-to-dense region of interest (ROI) extraction to bridge the semantic gap, fine-tuning the diffusion model with low-rank adaptation (LORA) to circumvent exhaustive retraining, and finally, a Copy-Paste method to compose synthesized objects with backgrounds, providing a nuanced approach to aerial object detection through synthetic data. ",
    "url": "https://arxiv.org/abs/2311.12345",
    "authors": [
      "Yanan Jian",
      "Fuxun Yu",
      "Simranjit Singh",
      "Dimitrios Stamoulis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.12356",
    "title": "Random Linear Projections Loss for Hyperplane-Based Optimization in  Regression Neural Networks",
    "abstract": "Despite their popularity across a wide range of domains, regression neural networks are prone to overfitting complex datasets. In this work, we propose a loss function termed Random Linear Projections (RLP) loss, which is empirically shown to mitigate overfitting. With RLP loss, the distance between sets of hyperplanes connecting fixed-size subsets of the neural network's feature-prediction pairs and feature-label pairs is minimized. The intuition behind this loss derives from the notion that if two functions share the same hyperplanes connecting all subsets of feature-label pairs, then these functions must necessarily be equivalent. Our empirical studies, conducted across benchmark datasets and representative synthetic examples, demonstrate the improvements of the proposed RLP loss over mean squared error (MSE). Specifically, neural networks trained with the RLP loss achieve better performance while requiring fewer data samples and are more robust to additive noise. We provide theoretical analysis supporting our empirical findings. ",
    "url": "https://arxiv.org/abs/2311.12356",
    "authors": [
      "Shyam Venkatasubramanian",
      "Ahmed Aloui",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.12358",
    "title": "Federated Learning via Consensus Mechanism on Heterogeneous Data: A New  Perspective on Convergence",
    "abstract": "Federated learning (FL) on heterogeneous data (non-IID data) has recently received great attention. Most existing methods focus on studying the convergence guarantees for the global objective. While these methods can guarantee the decrease of the global objective in each communication round, they fail to ensure risk decrease for each client. In this paper, to address the problem,we propose FedCOME, which introduces a consensus mechanism to enforce decreased risk for each client after each training round. In particular, we allow a slight adjustment to a client's gradient on the server side, which generates an acute angle between the corrected gradient and the original ones of other clients. We theoretically show that the consensus mechanism can guarantee the convergence of the global objective. To generalize the consensus mechanism to the partial participation FL scenario, we devise a novel client sampling strategy to select the most representative clients for the global data distribution. Training on these selected clients with the consensus mechanism could empirically lead to risk decrease for clients that are not selected. Finally, we conduct extensive experiments on four benchmark datasets to show the superiority of FedCOME against other state-of-the-art methods in terms of effectiveness, efficiency and fairness. For reproducibility, we make our source code publicly available at: \\url{https://github.com/fedcome/fedcome}. ",
    "url": "https://arxiv.org/abs/2311.12358",
    "authors": [
      "Shu Zheng",
      "Tiandi Ye",
      "Xiang Li",
      "Ming Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.12372",
    "title": "Malicious URL Detection via Pretrained Language Model Guided Multi-Level  Feature Attention Network",
    "abstract": "The widespread use of the Internet has revolutionized information retrieval methods. However, this transformation has also given rise to a significant cybersecurity challenge: the rapid proliferation of malicious URLs, which serve as entry points for a wide range of cyber threats. In this study, we present an efficient pre-training model-based framework for malicious URL detection. Leveraging the subword and character-aware pre-trained model, CharBERT, as our foundation, we further develop three key modules: hierarchical feature extraction, layer-aware attention, and spatial pyramid pooling. The hierarchical feature extraction module follows the pyramid feature learning principle, extracting multi-level URL embeddings from the different Transformer layers of CharBERT. Subsequently, the layer-aware attention module autonomously learns connections among features at various hierarchical levels and allocates varying weight coefficients to each level of features. Finally, the spatial pyramid pooling module performs multiscale downsampling on the weighted multi-level feature pyramid, achieving the capture of local features as well as the aggregation of global features. The proposed method has been extensively validated on multiple public datasets, demonstrating a significant improvement over prior works, with the maximum accuracy gap reaching 8.43% compared to the previous state-of-the-art method. Additionally, we have assessed the model's generalization and robustness in scenarios such as cross-dataset evaluation and adversarial attacks. Finally, we conducted real-world case studies on the active phishing URLs. ",
    "url": "https://arxiv.org/abs/2311.12372",
    "authors": [
      "Ruitong Liu",
      "Yanbin Wang",
      "Haitao Xu",
      "Zhan Qin",
      "Yiwei Liu",
      "Zheng Cao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.12389",
    "title": "Linear-time online visibility graph transformation algorithm: for both  natural and horizontal visibility criteria",
    "abstract": "Visibility graph (VG) transformation is a technique used to convert a time series into a graph based on specific visibility criteria. It has attracted increasing interest in the fields of time series analysis, forecasting, and classification. Optimizing the VG transformation algorithm to accelerate the process is a critical aspect of VG-related research, as it enhances the applicability of VG transformation in latency-sensitive areas and conserves computational resources. In the real world, many time series are presented in the form of data streams. Despite the proposal of the concept of VG's online functionality, previous studies have not thoroughly explored the acceleration of VG transformation by leveraging the characteristics of data streams. In this paper, we propose that an efficient online VG algorithm should adhere to two criteria and develop a linear-time method, termed the LOT framework, for both natural and horizontal visibility graph transformations in data stream scenarios. Experiments are conducted on two datasets, comparing our approach with five existing methods as baselines. The results demonstrate the validity and promising computational efficiency of our framework. ",
    "url": "https://arxiv.org/abs/2311.12389",
    "authors": [
      "Yusheng Huang",
      "Yong Deng"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2311.12397",
    "title": "Rich and Poor Texture Contrast: A Simple yet Effective Approach for  AI-generated Image Detection",
    "abstract": "Recent generative models show impressive performance in generating photographic images. Humans can hardly distinguish such incredibly realistic-looking AI-generated images from real ones. AI-generated images may lead to ubiquitous disinformation dissemination. Therefore, it is of utmost urgency to develop a detector to identify AI-generated images. Most existing detectors suffer from sharp performance drops over unseen generative models. In this paper, we propose a novel AI-generated image detector capable of identifying fake images created by a wide range of generative models. Our approach leverages the inter-pixel correlation contrast between rich and poor texture regions within an image. Pixels in rich texture regions exhibit more significant fluctuations than those in poor texture regions. This discrepancy reflects that the entropy of rich texture regions is larger than that of poor ones. Consequently, synthesizing realistic rich texture regions proves to be more challenging for existing generative models. Based on this principle, we divide an image into multiple patches and reconstruct them into two images, comprising rich-texture and poor-texture patches respectively. Subsequently, we extract the inter-pixel correlation discrepancy feature between rich and poor texture regions. This feature serves as a universal fingerprint used for AI-generated image forensics across different generative models. In addition, we build a comprehensive AI-generated image detection benchmark, which includes 16 kinds of prevalent generative models, to evaluate the effectiveness of existing baselines and our approach. Our benchmark provides a leaderboard for follow-up studies. Extensive experimental results show that our approach outperforms state-of-the-art baselines by a significant margin. Our project: https://fdmas.github.io/AIGCDetect/ ",
    "url": "https://arxiv.org/abs/2311.12397",
    "authors": [
      "Nan Zhong",
      "Yiran Xu",
      "Zhenxing Qian",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12399",
    "title": "A Survey of Graph Meets Large Language Model: Progress and Future  Directions",
    "abstract": "Graph plays a significant role in representing and analyzing complex relationships in real-world applications such as citation networks, social networks, and biological data. Recently, Large Language Models (LLMs), which have achieved tremendous success in various domains, have also been leveraged in graph-related tasks to surpass traditional Graph Neural Networks (GNNs) based methods and yield state-of-the-art performance. In this survey, we first present a comprehensive review and analysis of existing methods that integrate LLMs with graphs. First of all, we propose a new taxonomy, which organizes existing methods into three categories based on the role (i.e., enhancer, predictor, and alignment component) played by LLMs in graph-related tasks. Then we systematically survey the representative methods along the three categories of the taxonomy. Finally, we discuss the remaining limitations of existing studies and highlight promising avenues for future research. The relevant papers are summarized and will be consistently updated at: https://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks. ",
    "url": "https://arxiv.org/abs/2311.12399",
    "authors": [
      "Yuhan Li",
      "Zhixun Li",
      "Peisong Wang",
      "Jia Li",
      "Xiangguo Sun",
      "Hong Cheng",
      "Jeffrey Xu Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.12401",
    "title": "CASR: Refining Action Segmentation via Magrinalizing Frame-levle Causal  Relationships",
    "abstract": "Integrating deep learning and causal discovery has increased the interpretability of Temporal Action Segmentation (TAS) tasks. However, frame-level causal relationships exist many complicated noises outside the segment-level, making it infeasible to directly express macro action semantics. Thus, we propose \\textit{\\textbf{Causal Abstraction Segmentation Refiner (CASR)}}, which can refine TAS results from various models by enhancing video causality in marginalizing frame-level casual relationships. Specifically, we define the equivalent frame-level casual model and segment-level causal model, so that the causal adjacency matrix constructed from marginalized frame-level causal relationships has the ability to represent the segmnet-level causal relationships. CASR works out by reducing the difference in the causal adjacency matrix between we constructed and pre-segmentation results of backbone models. In addition, we propose a novel evaluation metric Causal Edit Distance (CED) to evaluate the causal interpretability. Extensive experimental results on mainstream datasets indicate that CASR significantly surpasses existing various methods in action segmentation performance, as well as in causal explainability and generalization. Our code will be available soon. ",
    "url": "https://arxiv.org/abs/2311.12401",
    "authors": [
      "Keqing Du",
      "Xinyu Yang",
      "Hang Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2311.12405",
    "title": "IndoRobusta: Towards Robustness Against Diverse Code-Mixed Indonesian  Local Languages",
    "abstract": "Significant progress has been made on Indonesian NLP. Nevertheless, exploration of the code-mixing phenomenon in Indonesian is limited, despite many languages being frequently mixed with Indonesian in daily conversation. In this work, we explore code-mixing in Indonesian with four embedded languages, i.e., English, Sundanese, Javanese, and Malay; and introduce IndoRobusta, a framework to evaluate and improve the code-mixing robustness. Our analysis shows that the pre-training corpus bias affects the model's ability to better handle Indonesian-English code-mixing when compared to other local languages, despite having higher language diversity. ",
    "url": "https://arxiv.org/abs/2311.12405",
    "authors": [
      "Muhammad Farid Adilazuarda",
      "Samuel Cahyawijaya",
      "Genta Indra Winata",
      "Pascale Fung",
      "Ayu Purwarianti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.12407",
    "title": "Learning Part Motion of Articulated Objects Using Spatially Continuous  Neural Implicit Representations",
    "abstract": "Articulated objects (e.g., doors and drawers) exist everywhere in our life. Different from rigid objects, articulated objects have higher degrees of freedom and are rich in geometries, semantics, and part functions. Modeling different kinds of parts and articulations with nerual networks plays an essential role in articulated object understanding and manipulation, and will further benefit 3D vision and robotics communities. To model articulated objects, most previous works directly encode articulated objects into feature representations, without specific designs for parts, articulations and part motions. In this paper, we introduce a novel framework that explicitly disentangles the part motion of articulated objects by predicting the transformation matrix of points on the part surface, using spatially continuous neural implicit representations to model the part motion smoothly in the space. More importantly, while many methods could only model a certain kind of joint motion (such as the revolution in the clockwise order), our proposed framework is generic to different kinds of joint motions in that transformation matrix can model diverse kinds of joint motions in the space. Quantitative and qualitative results of experiments over diverse categories of articulated objects demonstrate the effectiveness of our proposed framework. ",
    "url": "https://arxiv.org/abs/2311.12407",
    "authors": [
      "Yushi Du",
      "Ruihai Wu",
      "Yan Shen",
      "Hao Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12419",
    "title": "Board-to-Board: Evaluating Moonboard Grade Prediction Generalization",
    "abstract": "Bouldering is a sport where athletes aim to climb up an obstacle using a set of defined holds called a route. Typically routes are assigned a grade to inform climbers of its difficulty and allow them to more easily track their progression. However, the variation in individual climbers technical and physical attributes and many nuances of an individual route make grading a difficult and often biased task. In this work, we apply classical and deep-learning modelling techniques to the 2016, 2017 and 2019 Moonboard datasets, achieving state of the art grade prediction performance with 0.87 MAE and 1.12 RMSE. We achieve this performance on a feature-set that does not require decomposing routes into individual moves, which is a method common in literature and introduces bias. We also demonstrate the generalization capability of this model between editions and introduce a novel vision-based method of grade prediction. While the generalization performance of these techniques is below human level performance currently, we propose these methods as a basis for future work. Such a tool could be implemented in pre-existing mobile applications and would allow climbers to better track their progress and assess new routes with reduced bias. ",
    "url": "https://arxiv.org/abs/2311.12419",
    "authors": [
      "Daniel Petashvili",
      "Matthew Rodda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12420",
    "title": "How Far Have We Gone in Vulnerability Detection Using Large Language  Models",
    "abstract": "As software becomes increasingly complex and prone to vulnerabilities, automated vulnerability detection is critically important, yet challenging. Given the significant successes of Large Language Models (LLMs) in various tasks, there is growing anticipation of their efficacy in vulnerability detection. However, a quantitative understanding of their potential in vulnerability detection is still missing. To bridge this gap, we introduce a comprehensive vulnerability benchmark VulBench. This benchmark aggregates high-quality data from a wide range of CTF (Capture-the-Flag) challenges and real-world applications, with annotations for each vulnerable function detailing the vulnerability type and its root cause. Through our experiments encompassing 16 LLMs and 6 state-of-the-art (SOTA) deep learning-based models and static analyzers, we find that several LLMs outperform traditional deep learning approaches in vulnerability detection, revealing an untapped potential in LLMs. This work contributes to the understanding and utilization of LLMs for enhanced software security. ",
    "url": "https://arxiv.org/abs/2311.12420",
    "authors": [
      "Zeyu Gao",
      "Hao Wang",
      "Yuchen Zhou",
      "Wenyu Zhu",
      "Chao Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.12430",
    "title": "AR Visualization System for Ship Detection and Recognition Based on AI",
    "abstract": "Augmented reality technology has been widely used in industrial design interaction, exhibition guide, information retrieval and other fields. The combination of artificial intelligence and augmented reality technology has also become a future development trend. This project is an AR visualization system for ship detection and recognition based on AI, which mainly includes three parts: artificial intelligence module, Unity development module and Hololens2AR module. This project is based on R3Det algorithm to complete the detection and recognition of ships in remote sensing images. The recognition rate of model detection trained on RTX 2080Ti can reach 96%. Then, the 3D model of the ship is obtained by ship categories and information and generated in the virtual scene. At the same time, voice module and UI interaction module are added. Finally, we completed the deployment of the project on Hololens2 through MRTK. The system realizes the fusion of computer vision and augmented reality technology, which maps the results of object detection to the AR field, and makes a brave step toward the future technological trend and intelligent application. ",
    "url": "https://arxiv.org/abs/2311.12430",
    "authors": [
      "Ziqi Ye",
      "Limin Huang",
      "Yongji Wu",
      "Min Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12454",
    "title": "HierSpeech++: Bridging the Gap between Semantic and Acoustic  Representation of Speech by Hierarchical Variational Inference for Zero-shot  Speech Synthesis",
    "abstract": "Large language models (LLM)-based speech synthesis has been widely adopted in zero-shot speech synthesis. However, they require a large-scale data and possess the same limitations as previous autoregressive speech models, including slow inference speed and lack of robustness. This paper proposes HierSpeech++, a fast and strong zero-shot speech synthesizer for text-to-speech (TTS) and voice conversion (VC). We verified that hierarchical speech synthesis frameworks could significantly improve the robustness and expressiveness of the synthetic speech. Furthermore, we significantly improve the naturalness and speaker similarity of synthetic speech even in zero-shot speech synthesis scenarios. For text-to-speech, we adopt the text-to-vec framework, which generates a self-supervised speech representation and an F0 representation based on text representations and prosody prompts. Then, HierSpeech++ generates speech from the generated vector, F0, and voice prompt. We further introduce a high-efficient speech super-resolution framework from 16 kHz to 48 kHz. The experimental results demonstrated that the hierarchical variational autoencoder could be a strong zero-shot speech synthesizer given that it outperforms LLM-based and diffusion-based models. Moreover, we achieved the first human-level quality zero-shot speech synthesis. Audio samples and source code are available at https://github.com/sh-lee-prml/HierSpeechpp. ",
    "url": "https://arxiv.org/abs/2311.12454",
    "authors": [
      "Sang-Hoon Lee",
      "Ha-Yeong Choi",
      "Seung-Bin Kim",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2311.12465",
    "title": "Towards a Gateway for Knowledge Graph Schemas Collection, Analysis, and  Embedding",
    "abstract": "One of the significant barriers to the training of statistical models on knowledge graphs is the difficulty that scientists have in finding the best input data to address their prediction goal. In addition to this, a key challenge is to determine how to manipulate these relational data, which are often in the form of particular triples (i.e., subject, predicate, object), to enable the learning process. Currently, many high-quality catalogs of knowledge graphs, are available. However, their primary goal is the re-usability of these resources, and their interconnection, in the context of the Semantic Web. This paper describes the LiveSchema initiative, namely, a first version of a gateway that has the main scope of leveraging the gold mine of data collected by many existing catalogs collecting relational data like ontologies and knowledge graphs. At the current state, LiveSchema contains - 1000 datasets from 4 main sources and offers some key facilities, which allow to: i) evolving LiveSchema, by aggregating other source catalogs and repositories as input sources; ii) querying all the collected resources; iii) transforming each given dataset into formal concept analysis matrices that enable analysis and visualization services; iv) generating models and tensors from each given dataset. ",
    "url": "https://arxiv.org/abs/2311.12465",
    "authors": [
      "Mattia Fumagalli",
      "Marco Boffo",
      "Daqian Shi",
      "Mayukh Bagchi",
      "Fausto Giunchiglia"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.12466",
    "title": "Robust Hole-Detection in Triangular Meshes Irrespective of the Presence  of Singular Vertices",
    "abstract": "In this work, we present a boundary and hole detection approach that traverses all the boundaries of an edge-manifold triangular mesh, irrespectively of the presence of singular vertices, and subsequently determines and labels all holes of the mesh. The proposed automated hole-detection method is valuable to the computer-aided design (CAD) community as all half-edges within the mesh are utilized and for each half-edge the algorithm guarantees both the existence and the uniqueness of the boundary associated to it. As existing hole-detection approaches assume that singular vertices are absent or may require mesh modification, these methods are ill-equipped to detect boundaries/holes in real-world meshes that contain singular vertices. We demonstrate the method in an underwater autonomous robotic application, exploiting surface reconstruction methods based on point cloud data. In such a scenario the determined holes can be interpreted as information gaps, enabling timely corrective action during the data acquisition. However, the scope of our method is not confined to these two sectors alone; it is versatile enough to be applied on any edge-manifold triangle mesh. An evaluation of the method is performed on both synthetic and real-world data (including a triangle mesh from a point cloud obtained by a multibeam sonar). The source code of our reference implementation is available: https://github.com/Mauhing/hole-detection-on-triangle-mesh. ",
    "url": "https://arxiv.org/abs/2311.12466",
    "authors": [
      "Mauhing Yip",
      "Annette Stahl",
      "Christian Schellewald"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.12472",
    "title": "Self-Supervised Deconfounding Against Spatio-Temporal Shifts: Theory and  Modeling",
    "abstract": "As an important application of spatio-temporal (ST) data, ST traffic forecasting plays a crucial role in improving urban travel efficiency and promoting sustainable development. In practice, the dynamics of traffic data frequently undergo distributional shifts attributed to external factors such as time evolution and spatial differences. This entails forecasting models to handle the out-of-distribution (OOD) issue where test data is distributed differently from training data. In this work, we first formalize the problem by constructing a causal graph of past traffic data, future traffic data, and external ST contexts. We reveal that the failure of prior arts in OOD traffic data is due to ST contexts acting as a confounder, i.e., the common cause for past data and future ones. Then, we propose a theoretical solution named Disentangled Contextual Adjustment (DCA) from a causal lens. It differentiates invariant causal correlations against variant spurious ones and deconfounds the effect of ST contexts. On top of that, we devise a Spatio-Temporal sElf-superVised dEconfounding (STEVE) framework. It first encodes traffic data into two disentangled representations for associating invariant and variant ST contexts. Then, we use representative ST contexts from three conceptually different perspectives (i.e., temporal, spatial, and semantic) as self-supervised signals to inject context information into both representations. In this way, we improve the generalization ability of the learned context-oriented representations to OOD ST traffic forecasting. Comprehensive experiments on four large-scale benchmark datasets demonstrate that our STEVE consistently outperforms the state-of-the-art baselines across various ST OOD scenarios. ",
    "url": "https://arxiv.org/abs/2311.12472",
    "authors": [
      "Jiahao Ji",
      "Wentao Zhang",
      "Jingyuan Wang",
      "Yue He",
      "Chao Huang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.12486",
    "title": "HCA-Net: Hierarchical Context Attention Network for Intervertebral Disc  Semantic Labeling",
    "abstract": "Accurate and automated segmentation of intervertebral discs (IVDs) in medical images is crucial for assessing spine-related disorders, such as osteoporosis, vertebral fractures, or IVD herniation. We present HCA-Net, a novel contextual attention network architecture for semantic labeling of IVDs, with a special focus on exploiting prior geometric information. Our approach excels at processing features across different scales and effectively consolidating them to capture the intricate spatial relationships within the spinal cord. To achieve this, HCA-Net models IVD labeling as a pose estimation problem, aiming to minimize the discrepancy between each predicted IVD location and its corresponding actual joint location. In addition, we introduce a skeletal loss term to reinforce the model's geometric dependence on the spine. This loss function is designed to constrain the model's predictions to a range that matches the general structure of the human vertebral skeleton. As a result, the network learns to reduce the occurrence of false predictions and adaptively improves the accuracy of IVD location estimation. Through extensive experimental evaluation on multi-center spine datasets, our approach consistently outperforms previous state-of-the-art methods on both MRI T1w and T2w modalities. The codebase is accessible to the public on \\href{https://github.com/xmindflow/HCA-Net}{GitHub}. ",
    "url": "https://arxiv.org/abs/2311.12486",
    "authors": [
      "Afshin Bozorgpour",
      "Bobby Azad",
      "Reza Azad",
      "Yury Velichko",
      "Ulas Bagci",
      "Dorit Merhof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12490",
    "title": "Hyb-NeRF: A Multiresolution Hybrid Encoding for Neural Radiance Fields",
    "abstract": "Recent advances in Neural radiance fields (NeRF) have enabled high-fidelity scene reconstruction for novel view synthesis. However, NeRF requires hundreds of network evaluations per pixel to approximate a volume rendering integral, making it slow to train. Caching NeRFs into explicit data structures can effectively enhance rendering speed but at the cost of higher memory usage. To address these issues, we present Hyb-NeRF, a novel neural radiance field with a multi-resolution hybrid encoding that achieves efficient neural modeling and fast rendering, which also allows for high-quality novel view synthesis. The key idea of Hyb-NeRF is to represent the scene using different encoding strategies from coarse-to-fine resolution levels. Hyb-NeRF exploits memory-efficiency learnable positional features at coarse resolutions and the fast optimization speed and local details of hash-based feature grids at fine resolutions. In addition, to further boost performance, we embed cone tracing-based features in our learnable positional encoding that eliminates encoding ambiguity and reduces aliasing artifacts. Extensive experiments on both synthetic and real-world datasets show that Hyb-NeRF achieves faster rendering speed with better rending quality and even a lower memory footprint in comparison to previous state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2311.12490",
    "authors": [
      "Yifan Wang",
      "Yi Gong",
      "Yuan Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.12526",
    "title": "Neural Network Pruning by Gradient Descent",
    "abstract": "The rapid increase in the parameters of deep learning models has led to significant costs, challenging computational efficiency and model interpretability. In this paper, we introduce a novel and straightforward neural network pruning framework that incorporates the Gumbel-Softmax technique. This framework enables the simultaneous optimization of a network's weights and topology in an end-to-end process using stochastic gradient descent. Empirical results demonstrate its exceptional compression capability, maintaining high accuracy on the MNIST dataset with only 0.15\\% of the original network parameters. Moreover, our framework enhances neural network interpretability, not only by allowing easy extraction of feature importance directly from the pruned network but also by enabling visualization of feature symmetry and the pathways of information propagation from features to outcomes. Although the pruning strategy is learned through deep learning, it is surprisingly intuitive and understandable, focusing on selecting key representative features and exploiting data patterns to achieve extreme sparse pruning. We believe our method opens a promising new avenue for deep learning pruning and the creation of interpretable machine learning systems. ",
    "url": "https://arxiv.org/abs/2311.12526",
    "authors": [
      "Zhang Zhang",
      "Ruyi Tao",
      "Jiang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.12532",
    "title": "Total Turning and Motion Range Prediction for Safe Unicycle Control",
    "abstract": "Safe and smooth motion control is essential for mobile robots when performing various automation tasks around obstacles, especially in the presence of people and other mobile robots. The total turning and space used by a mobile robot while moving towards a specified goal position play a crucial role in determining the required control effort and complexity. In this paper, we consider a standard unicycle control approach based on angular feedback linearization and provide an explicit analytical measure for determining the total turning effort during unicycle control in terms of unicycle state and control gains. We show that undesired spiral oscillatory motion around the goal position can be avoided by choosing a higher angular control gain compared to the linear control gain. Accordingly, we establish an accurate, explicit triangular motion range bound on the closed-loop unicycle trajectory using the total turning effort. The improved accuracy in motion range prediction results from a stronger dependency on the unicycle state and control parameters. To compare alternative circular, conic, and triangular motion range prediction approaches, we present an application of the proposed unicycle motion control and motion prediction methods for safe unicycle path following around obstacles in numerical simulations. ",
    "url": "https://arxiv.org/abs/2311.12532",
    "authors": [
      "Abdulla Tarshahani",
      "Aykut \u0130\u015fleyen",
      "\u00d6m\u00fcr Arslan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2311.12550",
    "title": "Explainable Anomaly Detection using Masked Latent Generative Modeling",
    "abstract": "We present a novel time series anomaly detection method that achieves excellent detection accuracy while offering a superior level of explainability. Our proposed method, TimeVQVAE-AD, leverages masked generative modeling adapted from the cutting-edge time series generation method known as TimeVQVAE. The prior model is trained on the discrete latent space of a time-frequency domain. Notably, the dimensional semantics of the time-frequency domain are preserved in the latent space, enabling us to compute anomaly scores across different frequency bands, which provides a better insight into the detected anomalies. Additionally, the generative nature of the prior model allows for sampling likely normal states for detected anomalies, enhancing the explainability of the detected anomalies through counterfactuals. Our experimental evaluation on the UCR Time Series Anomaly archive demonstrates that TimeVQVAE-AD significantly surpasses the existing methods in terms of detection accuracy and explainability. ",
    "url": "https://arxiv.org/abs/2311.12550",
    "authors": [
      "Daesoo Lee",
      "Sara Malacarne",
      "Erlend Aune"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.12560",
    "title": "Benchmarking bias: Expanding clinical AI model card to incorporate bias  reporting of social and non-social factors",
    "abstract": "Clinical AI model reporting cards should be expanded to incorporate a broad bias reporting of both social and non-social factors. Non-social factors consider the role of other factors, such as disease dependent, anatomic, or instrument factors on AI model bias, which are essential to ensure safe deployment. ",
    "url": "https://arxiv.org/abs/2311.12560",
    "authors": [
      "Carolina A. M. Heming",
      "Mohamed Abdalla",
      "Monish Ahluwalia",
      "Linglin Zhang",
      "Hari Trivedi",
      "MinJae Woo",
      "Benjamin Fine",
      "Judy Wawira Gichoya",
      "Leo Anthony Celi",
      "Laleh Seyyed-Kalantari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12561",
    "title": "Convolutional Neural Networks for Neuroimaging in Parkinson's Disease:  Is Preprocessing Needed?",
    "abstract": "Spatial and intensity normalization are nowadays a prerequisite for neuroimaging analysis. Influenced by voxel-wise and other univariate comparisons, where these corrections are key, they are commonly applied to any type of analysis and imaging modalities. Nuclear imaging modalities such as PET-FDG or FP-CIT SPECT, a common modality used in Parkinson's Disease diagnosis, are especially dependent on intensity normalization. However, these steps are computationally expensive and furthermore, they may introduce deformations in the images, altering the information contained in them. Convolutional Neural Networks (CNNs), for their part, introduce position invariance to pattern recognition, and have been proven to classify objects regardless of their orientation, size, angle, etc. Therefore, a question arises: how well can CNNs account for spatial and intensity differences when analysing nuclear brain imaging? Are spatial and intensity normalization still needed? To answer this question, we have trained four different CNN models based on well-established architectures, using or not different spatial and intensity normalization preprocessing. The results show that a sufficiently complex model such as our three-dimensional version of the ALEXNET can effectively account for spatial differences, achieving a diagnosis accuracy of 94.1% with an area under the ROC curve of 0.984. The visualization of the differences via saliency maps shows that these models are correctly finding patterns that match those found in the literature, without the need of applying any complex spatial normalization procedure. However, the intensity normalization -- and its type -- is revealed as very influential in the results and accuracy of the trained model, and therefore must be well accounted. ",
    "url": "https://arxiv.org/abs/2311.12561",
    "authors": [
      "Francisco J. Martinez-Murcia",
      "Juan M. G\u00f3rriz",
      "Javier Ram\u00edrez",
      "Andr\u00e9s Ortiz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.12568",
    "title": "The $\u03b2$ maps and the strong clustering at the complex unit circle",
    "abstract": "In this work, we study eigenvalue distribution results of a class of highly non-normal matrix-sequences, which can be viewed as a low rank perturbation depending on a parameter $\\beta>1$ of the basic Toeplitz matrix-sequence $\\{T_n(e^{\\mathbf{i}\\theta})\\}_{n\\in\\N}$, $\\mathbf{i}^2=-1$. The latter has obviously all eigenvalues equal to zero for any matrix order $n$, while for the matrix-sequence under consideration we will show a strong clustering at the range of the generating function $e^{\\mathbf{i}\\theta}$ i.e. at the complex unit circle. For $\\beta\\ge 2$ no outliers show up, while for $\\beta \\in (1,2)$ only two outliers are present, which are both real, positive and have finite limits equal to $\\beta-1$ and $(\\beta-1)^{-1}$, respectively. The problem looks mathematically innocent, but indeed it is quite challenging since all the sophisticated machinery for deducing the eigenvalue clustering is not easy to apply in the current setting and at most we may hope for weak clustering results. In the derivations, we resort to a trick already used for the spectral analysis of the Google matrix plus several tools from complex analysis. We only mention that the problem is not an academical curiosity and in fact it stems from problems in dynamical systems and number theory. Numerical experiments in high precision are provided and more results are sketched for limit case of $\\beta=1$. ",
    "url": "https://arxiv.org/abs/2311.12568",
    "authors": [
      "Alec Schiavoni Piazza",
      "David Meadon",
      "Stefano Serra-Capizzano"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2311.12574",
    "title": "IMGTB: A Framework for Machine-Generated Text Detection Benchmarking",
    "abstract": "In the era of large language models generating high quality texts, it is a necessity to develop methods for detection of machine-generated text to avoid harmful use or simply due to annotation purposes. It is, however, also important to properly evaluate and compare such developed methods. Recently, a few benchmarks have been proposed for this purpose; however, integration of newest detection methods is rather challenging, since new methods appear each month and provide slightly different evaluation pipelines. In this paper, we present the IMGTB framework, which simplifies the benchmarking of machine-generated text detection methods by easy integration of custom (new) methods and evaluation datasets. Its configurability and flexibility makes research and development of new detection methods easier, especially their comparison to the existing state-of-the-art detectors. The default set of analyses, metrics and visualizations offered by the tool follows the established practices of machine-generated text detection benchmarking found in state-of-the-art literature. ",
    "url": "https://arxiv.org/abs/2311.12574",
    "authors": [
      "Michal Spiegel",
      "Dominik Macko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.12589",
    "title": "Improving Source-Free Target Adaptation with Vision Transformers  Leveraging Domain Representation Images",
    "abstract": "Unsupervised Domain Adaptation (UDA) methods facilitate knowledge transfer from a labeled source domain to an unlabeled target domain, navigating the obstacle of domain shift. While Convolutional Neural Networks (CNNs) are a staple in UDA, the rise of Vision Transformers (ViTs) provides new avenues for domain generalization. This paper presents an innovative method to bolster ViT performance in source-free target adaptation, beginning with an evaluation of how key, query, and value elements affect ViT outcomes. Experiments indicate that altering the key component has negligible effects on Transformer performance. Leveraging this discovery, we introduce Domain Representation Images (DRIs), feeding embeddings through the key element. DRIs act as domain-specific markers, effortlessly merging with the training regimen. To assess our method, we perform target adaptation tests on the Cross Instance DRI source-only (SO) control. We measure the efficacy of target adaptation with and without DRIs, against existing benchmarks like SHOT-B* and adaptations via CDTrans. Findings demonstrate that excluding DRIs offers limited gains over SHOT-B*, while their inclusion in the key segment boosts average precision promoting superior domain generalization. This research underscores the vital role of DRIs in enhancing ViT efficiency in UDA scenarios, setting a precedent for further domain adaptation explorations. ",
    "url": "https://arxiv.org/abs/2311.12589",
    "authors": [
      "Gauransh Sawhney",
      "Daksh Dave",
      "Adeel Ahmed",
      "Jiechao Gao",
      "Khalid Saleem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.12601",
    "title": "Deep learning-based detection of morphological features associated with  hypoxia in H&E breast cancer whole slide images",
    "abstract": "Hypoxia occurs when tumour cells outgrow their blood supply, leading to regions of low oxygen levels within the tumour. Calculating hypoxia levels can be an important step in understanding the biology of tumours, their clinical progression and response to treatment. This study demonstrates a novel application of deep learning to evaluate hypoxia in the context of breast cancer histomorphology. More precisely, we show that Weakly Supervised Deep Learning (WSDL) models can accurately detect hypoxia associated features in routine Hematoxylin and Eosin (H&E) whole slide images (WSI). We trained and evaluated a deep Multiple Instance Learning model on tiles from WSI H&E tissue from breast cancer primary sites (n=240) obtaining on average an AUC of 0.87 on a left-out test set. We also showed significant differences between features of hypoxic and normoxic tissue regions as distinguished by the WSDL models. Such DL hypoxia H&E WSI detection models could potentially be extended to other tumour types and easily integrated into the pathology workflow without requiring additional costly assays. ",
    "url": "https://arxiv.org/abs/2311.12601",
    "authors": [
      "Petru Manescu",
      "Joseph Geradts",
      "Delmiro Fernandez-Reyes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Tissues and Organs (q-bio.TO)"
    ]
  },
  {
    "id": "arXiv:2311.12603",
    "title": "Surgical Temporal Action-aware Network with Sequence Regularization for  Phase Recognition",
    "abstract": "To assist surgeons in the operating theatre, surgical phase recognition is critical for developing computer-assisted surgical systems, which requires comprehensive understanding of surgical videos. Although existing studies made great progress, there are still two significant limitations worthy of improvement. First, due to the compromise of resource consumption, frame-wise visual features are extracted by 2D networks and disregard spatial and temporal knowledge of surgical actions, which hinders subsequent inter-frame modeling for phase prediction. Second, these works simply utilize ordinary classification loss with one-hot phase labels to optimize the phase predictions, and cannot fully explore surgical videos under inadequate supervision. To overcome these two limitations, we propose a Surgical Temporal Action-aware Network with sequence Regularization, named STAR-Net, to recognize surgical phases more accurately from input videos. Specifically, we propose an efficient multi-scale surgical temporal action (MS-STA) module, which integrates visual features with spatial and temporal knowledge of surgical actions at the cost of 2D networks. Moreover, we devise the dual-classifier sequence regularization (DSR) to facilitate the training of STAR-Net by the sequence guidance of an auxiliary classifier with a smaller capacity. Our STAR-Net with MS-STA and DSR can exploit visual features of surgical actions with effective regularization, thereby leading to the superior performance of surgical phase recognition. Extensive experiments on a large-scale gastrectomy surgery dataset and the public Cholec80 benchmark prove that our STAR-Net significantly outperforms state-of-the-arts of surgical phase recognition. ",
    "url": "https://arxiv.org/abs/2311.12603",
    "authors": [
      "Zhen Chen",
      "Yuhao Zhai",
      "Jun Zhang",
      "Jinqiao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12608",
    "title": "Adaptive Dense Pseudo Label Selection for Semi-supervised Oriented  Object Detection",
    "abstract": "Recently, dense pseudo-label, which directly selects pseudo labels from the original output of the teacher model without any complicated post-processing steps, has received considerable attention in semi-supervised object detection (SSOD). However, for the multi-oriented and dense objects that are common in aerial scenes, existing dense pseudo-label selection methods are inefficient and impede the performance in semi-supervised oriented object detection. Therefore, we propose Adaptive Dense Pseudo Label Selection (ADPLS) for semi-supervised oriented object detection. In ADPLS, we design a simple but effective adaptive mechanism to guide the selection of dense pseudo labels. Specifically, we propose the mean Feature-Richness Score (mFRS) to estimate the density of potential objects and use this score to adjust the number of dense pseudo labels. On the DOTA-v1.5 benchmark, the proposed method outperforms previous methods especially when labeled data are scarce. For example, it achieves 49.78 mAP given only 5% of annotated data, which surpasses previous state-of-the-art method given 10% of annotated data by 1.15 mAP. Our codes will be available soon. ",
    "url": "https://arxiv.org/abs/2311.12608",
    "authors": [
      "Tong Zhao",
      "Qiang Fang",
      "Shuohao Shi",
      "Xin Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12617",
    "title": "Leveraging Unlabeled Data for 3D Medical Image Segmentation through  Self-Supervised Contrastive Learning",
    "abstract": "Current 3D semi-supervised segmentation methods face significant challenges such as limited consideration of contextual information and the inability to generate reliable pseudo-labels for effective unsupervised data use. To address these challenges, we introduce two distinct subnetworks designed to explore and exploit the discrepancies between them, ultimately correcting the erroneous prediction results. More specifically, we identify regions of inconsistent predictions and initiate a targeted verification training process. This procedure strategically fine-tunes and harmonizes the predictions of the subnetworks, leading to enhanced utilization of contextual information. Furthermore, to adaptively fine-tune the network's representational capacity and reduce prediction uncertainty, we employ a self-supervised contrastive learning paradigm. For this, we use the network's confidence to distinguish between reliable and unreliable predictions. The model is then trained to effectively minimize unreliable predictions. Our experimental results for organ segmentation, obtained from clinical MRI and CT scans, demonstrate the effectiveness of our approach when compared to state-of-the-art methods. The codebase is accessible on \\href{https://github.com/xmindflow/SSL-contrastive}{GitHub}. ",
    "url": "https://arxiv.org/abs/2311.12617",
    "authors": [
      "Sanaz Karimijafarbigloo",
      "Reza Azad",
      "Yury Velichko",
      "Ulas Bagci",
      "Dorit Merhof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12623",
    "title": "Bridging Generalization Gaps in High Content Imaging Through Online  Self-Supervised Domain Adaptation",
    "abstract": "High Content Imaging (HCI) plays a vital role in modern drug discovery and development pipelines, facilitating various stages from hit identification to candidate drug characterization. Applying machine learning models to these datasets can prove challenging as they typically consist of multiple batches, affected by experimental variation, especially if different imaging equipment have been used. Moreover, as new data arrive, it is preferable that they are analyzed in an online fashion. To overcome this, we propose CODA, an online self-supervised domain adaptation approach. CODA divides the classifier's role into a generic feature extractor and a task-specific model. We adapt the feature extractor's weights to the new domain using cross-batch self-supervision while keeping the task-specific model unchanged. Our results demonstrate that this strategy significantly reduces the generalization gap, achieving up to a 300% improvement when applied to data from different labs utilizing different microscopes. CODA can be applied to new, unlabeled out-of-domain data sources of different sizes, from a single plate to multiple experimental batches. ",
    "url": "https://arxiv.org/abs/2311.12623",
    "authors": [
      "Johan Fredin Haslum",
      "Christos Matsoukas",
      "Karl-Johan Leuchowius",
      "Kevin Smith"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12630",
    "title": "Hierarchical Joint Graph Learning and Multivariate Time Series  Forecasting",
    "abstract": "Multivariate time series is prevalent in many scientific and industrial domains. Modeling multivariate signals is challenging due to their long-range temporal dependencies and intricate interactions--both direct and indirect. To confront these complexities, we introduce a method of representing multivariate signals as nodes in a graph with edges indicating interdependency between them. Specifically, we leverage graph neural networks (GNN) and attention mechanisms to efficiently learn the underlying relationships within the time series data. Moreover, we suggest employing hierarchical signal decompositions running over the graphs to capture multiple spatial dependencies. The effectiveness of our proposed model is evaluated across various real-world benchmark datasets designed for long-term forecasting tasks. The results consistently showcase the superiority of our model, achieving an average 23\\% reduction in mean squared error (MSE) compared to existing models. ",
    "url": "https://arxiv.org/abs/2311.12630",
    "authors": [
      "Juhyeon Kim",
      "Hyungeun Lee",
      "Seungwon Yu",
      "Ung Hwang",
      "Wooyul Jung",
      "Miseon Park",
      "Kijung Yoon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.12644",
    "title": "Careful Selection and Thoughtful Discarding: Graph Explicit Pooling  Utilizing Discarded Nodes",
    "abstract": "Graph pooling has been increasingly recognized as crucial for Graph Neural Networks (GNNs) to facilitate hierarchical graph representation learning. Existing graph pooling methods commonly consist of two stages: selecting top-ranked nodes and discarding the remaining to construct coarsened graph representations. However, this paper highlights two key issues with these methods: 1) The process of selecting nodes to discard frequently employs additional Graph Convolutional Networks or Multilayer Perceptrons, lacking a thorough evaluation of each node's impact on the final graph representation and subsequent prediction tasks. 2) Current graph pooling methods tend to directly discard the noise segment (dropped) of the graph without accounting for the latent information contained within these elements. To address the first issue, we introduce a novel Graph Explicit Pooling (GrePool) method, which selects nodes by explicitly leveraging the relationships between the nodes and final representation vectors crucial for classification. The second issue is addressed using an extended version of GrePool (i.e., GrePool+), which applies a uniform loss on the discarded nodes. This addition is designed to augment the training process and improve classification accuracy. Furthermore, we conduct comprehensive experiments across 12 widely used datasets to validate our proposed method's effectiveness, including the Open Graph Benchmark datasets. Our experimental results uniformly demonstrate that GrePool outperforms 14 baseline methods for most datasets. Likewise, implementing GrePool+ enhances GrePool's performance without incurring additional computational costs. ",
    "url": "https://arxiv.org/abs/2311.12644",
    "authors": [
      "Chuang Liu",
      "Wenhang Yu",
      "Kuang Gao",
      "Xueqi Ma",
      "Yibing Zhan",
      "Jia Wu",
      "Bo Du",
      "Wenbin Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.12651",
    "title": "Mobile-Seed: Joint Semantic Segmentation and Boundary Detection for  Mobile Robots",
    "abstract": "Precise and rapid delineation of sharp boundaries and robust semantics is essential for numerous downstream robotic tasks, such as robot grasping and manipulation, real-time semantic mapping, and online sensor calibration performed on edge computing units. Although boundary detection and semantic segmentation are complementary tasks, most studies focus on lightweight models for semantic segmentation but overlook the critical role of boundary detection. In this work, we introduce Mobile-Seed, a lightweight, dual-task framework tailored for simultaneous semantic segmentation and boundary detection. Our framework features a two-stream encoder, an active fusion decoder (AFD) and a dual-task regularization approach. The encoder is divided into two pathways: one captures category-aware semantic information, while the other discerns boundaries from multi-scale features. The AFD module dynamically adapts the fusion of semantic and boundary information by learning channel-wise relationships, allowing for precise weight assignment of each channel. Furthermore, we introduce a regularization loss to mitigate the conflicts in dual-task learning and deep diversity supervision. Compared to existing methods, the proposed Mobile-Seed offers a lightweight framework to simultaneously improve semantic segmentation performance and accurately locate object boundaries. Experiments on the Cityscapes dataset have shown that Mobile-Seed achieves notable improvement over the state-of-the-art (SOTA) baseline by 2.2 percentage points (pp) in mIoU and 4.2 pp in mF-score, while maintaining an online inference speed of 23.9 frames-per-second (FPS) with 1024x2048 resolution input on an RTX 2080 Ti GPU. Additional experiments on CamVid and PASCAL Context datasets confirm our method's generalizability. Code and additional results are publicly available at \\url{https://martin-liao.github.io/Mobile-Seed/}. ",
    "url": "https://arxiv.org/abs/2311.12651",
    "authors": [
      "Youqi Liao",
      "Shuhao Kang",
      "Jianping Li",
      "Yang Liu",
      "Yun Liu",
      "Zhen Dong",
      "Bisheng Yang",
      "Xieyuanli Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.12652",
    "title": "FedDRO: Federated Compositional Optimization for Distributionally Robust  Learning",
    "abstract": "Recently, compositional optimization (CO) has gained popularity because of its applications in distributionally robust optimization (DRO) and many other machine learning problems. Large-scale and distributed availability of data demands the development of efficient federated learning (FL) algorithms for solving CO problems. Developing FL algorithms for CO is particularly challenging because of the compositional nature of the objective. Moreover, current state-of-the-art methods to solve such problems rely on large batch gradients (depending on the solution accuracy) not feasible for most practical settings. To address these challenges, in this work, we propose efficient FedAvg-type algorithms for solving non-convex CO in the FL setting. We first establish that vanilla FedAvg is not suitable to solve distributed CO problems because of the data heterogeneity in the compositional objective at each client which leads to the amplification of bias in the local compositional gradient estimates. To this end, we propose a novel FL framework FedDRO that utilizes the DRO problem structure to design a communication strategy that allows FedAvg to control the bias in the estimation of the compositional gradient. A key novelty of our work is to develop solution accuracy-independent algorithms that do not require large batch gradients (and function evaluations) for solving federated CO problems. We establish $\\mathcal{O}(\\epsilon^{-2})$ sample and $\\mathcal{O}(\\epsilon^{-3/2})$ communication complexity in the FL setting while achieving linear speedup with the number of clients. We corroborate our theoretical findings with empirical studies on large-scale DRO problems. ",
    "url": "https://arxiv.org/abs/2311.12652",
    "authors": [
      "Prashant Khanduri",
      "Chengyin Li",
      "Rafi Ibn Sultan",
      "Yao Qiang",
      "Joerg Kliewer",
      "Dongxiao Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2311.12657",
    "title": "Carbohydrate NMR chemical shift predictions using E(3) equivariant graph  neural networks",
    "abstract": "Carbohydrates, vital components of biological systems, are well-known for their structural diversity. Nuclear Magnetic Resonance (NMR) spectroscopy plays a crucial role in understanding their intricate molecular arrangements and is essential in assessing and verifying the molecular structure of organic molecules. An important part of this process is to predict the NMR chemical shift from the molecular structure. This work introduces a novel approach that leverages E(3) equivariant graph neural networks to predict carbohydrate NMR spectra. Notably, our model achieves a substantial reduction in mean absolute error, up to threefold, compared to traditional models that rely solely on two-dimensional molecular structure. Even with limited data, the model excels, highlighting its robustness and generalization capabilities. The implications are far-reaching and go beyond an advanced understanding of carbohydrate structures and spectral interpretation. For example, it could accelerate research in pharmaceutical applications, biochemistry, and structural biology, offering a faster and more reliable analysis of molecular structures. Furthermore, our approach is a key step towards a new data-driven era in spectroscopy, potentially influencing spectroscopic techniques beyond NMR. ",
    "url": "https://arxiv.org/abs/2311.12657",
    "authors": [
      "Maria B\u00e5nkestad",
      "Keven M. Dorst",
      "G\u00f6ran Widmalm",
      "Jerk R\u00f6nnols"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2311.12666",
    "title": "SSVEP-DAN: A Data Alignment Network for SSVEP-based Brain Computer  Interfaces",
    "abstract": "Steady-state visual-evoked potential (SSVEP)-based brain-computer interfaces (BCIs) offer a non-invasive means of communication through high-speed speller systems. However, their efficiency heavily relies on individual training data obtained during time-consuming calibration sessions. To address the challenge of data insufficiency in SSVEP-based BCIs, we present SSVEP-DAN, the first dedicated neural network model designed for aligning SSVEP data across different domains, which can encompass various sessions, subjects, or devices. Our experimental results across multiple cross-domain scenarios demonstrate SSVEP-DAN's capability to transform existing source SSVEP data into supplementary calibration data, significantly enhancing SSVEP decoding accuracy in scenarios with limited calibration data. We envision SSVEP-DAN as a catalyst for practical SSVEP-based BCI applications with minimal calibration. The source codes in this work are available at: https://github.com/CECNL/SSVEP-DAN. ",
    "url": "https://arxiv.org/abs/2311.12666",
    "authors": [
      "Sung-Yu Chen",
      "Chi-Min Chang",
      "Kuan-Jung Chiang",
      "Chun-Shu Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.12679",
    "title": "BundleMoCap: Efficient, Robust and Smooth Motion Capture from Sparse  Multiview Videos",
    "abstract": "Capturing smooth motions from videos using markerless techniques typically involves complex processes such as temporal constraints, multiple stages with data-driven regression and optimization, and bundle solving over temporal windows. These processes can be inefficient and require tuning multiple objectives across stages. In contrast, BundleMoCap introduces a novel and efficient approach to this problem. It solves the motion capture task in a single stage, eliminating the need for temporal smoothness objectives while still delivering smooth motions. BundleMoCap outperforms the state-of-the-art without increasing complexity. The key concept behind BundleMoCap is manifold interpolation between latent keyframes. By relying on a local manifold smoothness assumption, we can efficiently solve a bundle of frames using a single code. Additionally, the method can be implemented as a sliding window optimization and requires only the first frame to be properly initialized, reducing the overall computational burden. BundleMoCap's strength lies in its ability to achieve high-quality motion capture results with simplicity and efficiency. More details can be found at https://moverseai.github.io/bundle/. ",
    "url": "https://arxiv.org/abs/2311.12679",
    "authors": [
      "Georgios Albanis",
      "Nikolaos Zioulis",
      "Kostas Kolomvatsos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.12684",
    "title": "Adversarial Reweighting Guided by Wasserstein Distance for Bias  Mitigation",
    "abstract": "The unequal representation of different groups in a sample population can lead to discrimination of minority groups when machine learning models make automated decisions. To address these issues, fairness-aware machine learning jointly optimizes two (or more) metrics aiming at predictive effectiveness and low unfairness. However, the inherent under-representation of minorities in the data makes the disparate treatment of subpopulations less noticeable and difficult to deal with during learning. In this paper, we propose a novel adversarial reweighting method to address such \\emph{representation bias}. To balance the data distribution between the majority and the minority groups, our approach deemphasizes samples from the majority group. To minimize empirical risk, our method prefers samples from the majority group that are close to the minority group as evaluated by the Wasserstein distance. Our theoretical analysis shows the effectiveness of our adversarial reweighting approach. Experiments demonstrate that our approach mitigates bias without sacrificing classification accuracy, outperforming related state-of-the-art methods on image and tabular benchmark datasets. ",
    "url": "https://arxiv.org/abs/2311.12684",
    "authors": [
      "Xuan Zhao",
      "Simone Fabbrizzi",
      "Paula Reyero Lobo",
      "Siamak Ghodsi",
      "Klaus Broelemann",
      "Steffen Staab",
      "Gjergji Kasneci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.12688",
    "title": "On the Out-of-Distribution Coverage of Combining Split Conformal  Prediction and Bayesian Deep Learning",
    "abstract": "Bayesian deep learning and conformal prediction are two methods that have been used to convey uncertainty and increase safety in machine learning systems. We focus on combining Bayesian deep learning with split conformal prediction and how this combination effects out-of-distribution coverage; particularly in the case of multiclass image classification. We suggest that if the model is generally underconfident on the calibration set, then the resultant conformal sets may exhibit worse out-of-distribution coverage compared to simple predictive credible sets. Conversely, if the model is overconfident on the calibration set, the use of conformal prediction may improve out-of-distribution coverage. We evaluate prediction sets as a result of combining split conformal methods and neural networks trained with (i) stochastic gradient descent, (ii) deep ensembles, and (iii) mean-field variational inference. Our results suggest that combining Bayesian deep learning models with split conformal prediction can, in some cases, cause unintended consequences such as reducing out-of-distribution coverage. ",
    "url": "https://arxiv.org/abs/2311.12688",
    "authors": [
      "Paul Scemama",
      "Ariel Kapusta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.12710",
    "title": "Short Voting Codes For Practical Code Voting",
    "abstract": "To preserve voter secrecy on untrusted voter devices we propose to use short voting codes. This ensures voting codes remain practical even if the voter is able to select multiple voting choices. We embed the mechanism in a protocol that avoids complex cryptography in both the setup and the voting phase and relies only on standard cryptographic primitives. Trusting the setup, and one out of multiple server components, the protocol provides vote secrecy, cast-as-intended, recorded-as-cast, tallied-as-recorded, eligibility and universal verifiability. ",
    "url": "https://arxiv.org/abs/2311.12710",
    "authors": [
      "Florian Moser"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.12715",
    "title": "Attacks of fairness in Federated Learning",
    "abstract": "Federated Learning is an important emerging distributed training paradigm that keeps data private on clients. It is now well understood that by controlling only a small subset of FL clients, it is possible to introduce a backdoor to a federated learning model, in the presence of certain attributes. In this paper, we present a new type of attack that compromises the fairness of the trained model. Fairness is understood to be the attribute-level performance distribution of a trained model. It is particularly salient in domains where, for example, skewed accuracy discrimination between subpopulations could have disastrous consequences. We find that by employing a threat model similar to that of a backdoor attack, an attacker is able to influence the aggregated model to have an unfair performance distribution between any given set of attributes. Furthermore, we find that this attack is possible by controlling only a single client. While combating naturally induced unfairness in FL has previously been discussed in depth, its artificially induced kind has been neglected. We show that defending against attacks on fairness should be a critical consideration in any situation where unfairness in a trained model could benefit a user who participated in its training. ",
    "url": "https://arxiv.org/abs/2311.12715",
    "authors": [
      "Joseph Rance",
      "Filip Svoboda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.12722",
    "title": "Attacking Motion Planners Using Adversarial Perception Errors",
    "abstract": "Autonomous driving (AD) systems are often built and tested in a modular fashion, where the performance of different modules is measured using task-specific metrics. These metrics should be chosen so as to capture the downstream impact of each module and the performance of the system as a whole. For example, high perception quality should enable prediction and planning to be performed safely. Even though this is true in general, we show here that it is possible to construct planner inputs that score very highly on various perception quality metrics but still lead to planning failures. In an analogy to adversarial attacks on image classifiers, we call such inputs \\textbf{adversarial perception errors} and show they can be systematically constructed using a simple boundary-attack algorithm. We demonstrate the effectiveness of this algorithm by finding attacks for two different black-box planners in several urban and highway driving scenarios using the CARLA simulator. Finally, we analyse the properties of these attacks and show that they are isolated in the input space of the planner, and discuss their implications for AD system deployment and testing. ",
    "url": "https://arxiv.org/abs/2311.12722",
    "authors": [
      "Jonathan Sadeghi",
      "Nicholas A. Lord",
      "John Redford",
      "Romain Mueller"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.12737",
    "title": "Exploring Graph Classification Techniques Under Low Data Constraints: A  Comprehensive Study",
    "abstract": "This survey paper presents a brief overview of recent research on graph data augmentation and few-shot learning. It covers various techniques for graph data augmentation, including node and edge perturbation, graph coarsening, and graph generation, as well as the latest developments in few-shot learning, such as meta-learning and model-agnostic meta-learning. The paper explores these areas in depth and delves into further sub classifications. Rule based approaches and learning based approaches are surveyed under graph augmentation techniques. Few-Shot Learning on graphs is also studied in terms of metric learning techniques and optimization-based techniques. In all, this paper provides an extensive array of techniques that can be employed in solving graph processing problems faced in low-data scenarios. ",
    "url": "https://arxiv.org/abs/2311.12737",
    "authors": [
      "Kush Kothari",
      "Bhavya Mehta",
      "Reshmika Nambiar",
      "Seema Shrawne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.12741",
    "title": "Content Augmented Graph Neural Networks",
    "abstract": "In recent years, graph neural networks (GNNs) have become a popular tool for solving various problems over graphs. In these models, the link structure of the graph is typically exploited and nodes' embeddings are iteratively updated based on adjacent nodes. Nodes' contents are used solely in the form of feature vectors, served as nodes' first-layer embeddings. However, the filters or convolutions, applied during iterations/layers to these initial embeddings lead to their impact diminish and contribute insignificantly to the final embeddings. In order to address this issue, in this paper we propose augmenting nodes' embeddings by embeddings generating from their content, at higher GNN layers. More precisely, we propose models wherein a structural embedding using a GNN and a content embedding are computed for each node. These two are combined using a combination layer to form the embedding of a node at a given layer. We suggest methods such as using an auto-encoder or building a content graph, to generate content embeddings. In the end, by conducting experiments over several real-world datasets, we demonstrate the high accuracy and performance of our models. ",
    "url": "https://arxiv.org/abs/2311.12741",
    "authors": [
      "Fatemeh Gholamzadeh Nasrabadi",
      "AmirHossein Kashani",
      "Pegah Zahedi",
      "Mostafa Haghir Chehreghani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.12745",
    "title": "Learn to Augment Network Simulators Towards Digital Network Twins",
    "abstract": "Digital network twin (DNT) is a promising paradigm to replicate real-world cellular networks toward continual assessment, proactive management, and what-if analysis. Existing discussions have been focusing on using only deep learning techniques to build DNTs, which raises widespread concerns regarding their generalization, explainability, and transparency. In this paper, we explore an alternative approach to augment network simulators with context-aware neural agents. The main challenge lies in the non-trivial simulation-to-reality (sim-to-real) discrepancy between offline simulators and real-world networks. To solve the challenge, we propose a new learn-to-bridge algorithm to cost-efficiently bridge the sim-to-real discrepancy in two alternative stages. In the first stage, we select states to query performances in real-world networks by using newly-designed cost-aware Bayesian optimization. In the second stage, we train the neural agent to learn the state context and bridge the probabilistic discrepancy based on Bayesian neural networks (BNN). In addition, we build a small-scale end-to-end network testbed based on OpenAirInterface RAN and Core with USRP B210 and a smartphone, and replicate the network in NS-3. The evaluation results show that, our proposed solution substantially outperforms existing methods, with more than 92\\% reduction in the sim-to-real discrepancy. ",
    "url": "https://arxiv.org/abs/2311.12745",
    "authors": [
      "Yuru Zhang",
      "Ming Zhao",
      "Qiang Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.12750",
    "title": "Learning to Optimise Wind Farms with Graph Transformers",
    "abstract": "This work proposes a novel data-driven model capable of providing accurate predictions for the power generation of all wind turbines in wind farms of arbitrary layout, yaw angle configurations and wind conditions. The proposed model functions by encoding a wind farm into a fully-connected graph and processing the graph representation through a graph transformer. The graph transformer surrogate is shown to generalise well and is able to uncover latent structural patterns within the graph representation of wind farms. It is demonstrated how the resulting surrogate model can be used to optimise yaw angle configurations using genetic algorithms, achieving similar levels of accuracy to industrially-standard wind farm simulation tools while only taking a fraction of the computational cost. ",
    "url": "https://arxiv.org/abs/2311.12750",
    "authors": [
      "Siyi Li",
      "Arnaud Robert",
      "A. Aldo Faisal",
      "Matthew D. Piggott"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.12754",
    "title": "SelfOcc: Self-Supervised Vision-Based 3D Occupancy Prediction",
    "abstract": "3D occupancy prediction is an important task for the robustness of vision-centric autonomous driving, which aims to predict whether each point is occupied in the surrounding 3D space. Existing methods usually require 3D occupancy labels to produce meaningful results. However, it is very laborious to annotate the occupancy status of each voxel. In this paper, we propose SelfOcc to explore a self-supervised way to learn 3D occupancy using only video sequences. We first transform the images into the 3D space (e.g., bird's eye view) to obtain 3D representation of the scene. We directly impose constraints on the 3D representations by treating them as signed distance fields. We can then render 2D images of previous and future frames as self-supervision signals to learn the 3D representations. We propose an MVS-embedded strategy to directly optimize the SDF-induced weights with multiple depth proposals. Our SelfOcc outperforms the previous best method SceneRF by 58.7% using a single frame as input on SemanticKITTI and is the first self-supervised work that produces reasonable 3D occupancy for surround cameras on Occ3D. SelfOcc produces high-quality depth and achieves state-of-the-art results on novel depth synthesis, monocular depth estimation, and surround-view depth estimation on the SemanticKITTI, KITTI-2015, and nuScenes, respectively. Code: https://github.com/huang-yh/SelfOcc. ",
    "url": "https://arxiv.org/abs/2311.12754",
    "authors": [
      "Yuanhui Huang",
      "Wenzhao Zheng",
      "Borui Zhang",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.12758",
    "title": "Estimating time of arrival of vehicle fleets with GCN based traffic  prediction",
    "abstract": "This paper presents an effective framework for estimating time of arrival of vehicles (buses) in an Intelligent Transit Management System (ITMS) having sparse position updates. Our contributions towards this is firstly in implementing a constrained optimization based road linestring segmenting framework ensuring ideal segment lengths and segments with sufficient density of vehicle position measurements which will result in valid statistics for scenarios involving sparse position measurements. Over this we propose a comprehensive approach for predicting traffic delays and estimated time of vehicle arrival addressing both the spatial and temporal dependencies of traffic. The traffic delay model is built on top of the T-GCN architecture on which we optimally augment an adjacency matrix which models a complexly connected road network considering the degree of influence between road segments, enabling the traffic delay model to look beyond physical road connectivity in predicting traffic delays and therefore producing better estimates of arrival times to points along the designated route of the vehicles. ",
    "url": "https://arxiv.org/abs/2311.12758",
    "authors": [
      "Shivika Sharma",
      "Nandini Mawane",
      "Dhruthick Gowda M",
      "Mayur Taware",
      "Chetan Kumar",
      "Yash Chandrashekhar Dixit",
      "Rakshit Ramesh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.12764",
    "title": "Investigating Weight-Perturbed Deep Neural Networks With Application in  Iris Presentation Attack Detection",
    "abstract": "Deep neural networks (DNNs) exhibit superior performance in various machine learning tasks, e.g., image classification, speech recognition, biometric recognition, object detection, etc. However, it is essential to analyze their sensitivity to parameter perturbations before deploying them in real-world applications. In this work, we assess the sensitivity of DNNs against perturbations to their weight and bias parameters. The sensitivity analysis involves three DNN architectures (VGG, ResNet, and DenseNet), three types of parameter perturbations (Gaussian noise, weight zeroing, and weight scaling), and two settings (entire network and layer-wise). We perform experiments in the context of iris presentation attack detection and evaluate on two publicly available datasets: LivDet-Iris-2017 and LivDet-Iris-2020. Based on the sensitivity analysis, we propose improved models simply by perturbing parameters of the network without undergoing training. We further combine these perturbed models at the score-level and at the parameter-level to improve the performance over the original model. The ensemble at the parameter-level shows an average improvement of 43.58% on the LivDet-Iris-2017 dataset and 9.25% on the LivDet-Iris-2020 dataset. The source code is available at \\href{https://github.com/redwankarimsony/WeightPerturbation-MSU}{https://github.com/redwankarimsony/WeightPerturbation-MSU}. ",
    "url": "https://arxiv.org/abs/2311.12764",
    "authors": [
      "Renu Sharma",
      "Redwan Sony",
      "Arun Ross"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12779",
    "title": "Finding Adversarial Inputs for Heuristics using Multi-level Optimization",
    "abstract": "Production systems use heuristics because they are faster or scale better than their optimal counterparts. Yet, practitioners are often unaware of the performance gap between a heuristic and the optimum or between two heuristics in realistic scenarios. We present MetaOpt, a system that helps analyze heuristics. Users specify the heuristic and the optimal (or another heuristic) as input, and MetaOpt automatically encodes these efficiently for a solver to find performance gaps and their corresponding adversarial inputs. Its suite of built-in optimizations helps it scale its analysis to practical problem sizes. To show it is versatile, we used MetaOpt to analyze heuristics from three domains (traffic engineering, vector bin packing, and packet scheduling). We found a production traffic engineering heuristic can require 30% more capacity than the optimal to satisfy realistic demands. Based on the patterns in the adversarial inputs MetaOpt produced, we modified the heuristic to reduce its performance gap by 12.5$\\times$. We examined adversarial inputs to a vector bin packing heuristic and proved a new lower bound on its performance. ",
    "url": "https://arxiv.org/abs/2311.12779",
    "authors": [
      "Pooria Namyar",
      "Behnaz Arzani",
      "Ryan Beckett",
      "Santiago Segarra",
      "Himanshu Raj",
      "Umesh Krishnaswamy",
      "Ramesh Govindan",
      "Srikanth Kandula"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2311.12796",
    "title": "Physics-guided Shape-from-Template: Monocular Video Perception through  Neural Surrogate Models",
    "abstract": "3D reconstruction of dynamic scenes is a long-standing problem in computer graphics and increasingly difficult the less information is available. Shape-from-Template (SfT) methods aim to reconstruct a template-based geometry from RGB images or video sequences, often leveraging just a single monocular camera without depth information, such as regular smartphone recordings. Unfortunately, existing reconstruction methods are either unphysical and noisy or slow in optimization. To solve this problem, we propose a novel SfT reconstruction algorithm for cloth using a pre-trained neural surrogate model that is fast to evaluate, stable, and produces smooth reconstructions due to a regularizing physics simulation. Differentiable rendering of the simulated mesh enables pixel-wise comparisons between the reconstruction and a target video sequence that can be used for a gradient-based optimization procedure to extract not only shape information but also physical parameters such as stretching, shearing, or bending stiffness of the cloth. This allows to retain a precise, stable, and smooth reconstructed geometry while reducing the runtime by a factor of 400-500 compared to $\\phi$-SfT, a state-of-the-art physics-based SfT approach. ",
    "url": "https://arxiv.org/abs/2311.12796",
    "authors": [
      "David Stotko",
      "Nils Wandel",
      "Reinhard Klein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.12040",
    "title": "TransCDR: a deep learning model for enhancing the generalizability of  cancer drug response prediction through transfer learning and multimodal data  fusion for drug representation",
    "abstract": "Accurate and robust drug response prediction is of utmost importance in precision medicine. Although many models have been developed to utilize the representations of drugs and cancer cell lines for predicting cancer drug responses (CDR), their performances can be improved by addressing issues such as insufficient data modality, suboptimal fusion algorithms, and poor generalizability for novel drugs or cell lines. We introduce TransCDR, which uses transfer learning to learn drug representations and fuses multi-modality features of drugs and cell lines by a self-attention mechanism, to predict the IC50 values or sensitive states of drugs on cell lines. We are the first to systematically evaluate the generalization of the CDR prediction model to novel (i.e., never-before-seen) compound scaffolds and cell line clusters. TransCDR shows better generalizability than 8 state-of-the-art models. TransCDR outperforms its 5 variants that train drug encoders (i.e., RNN and AttentiveFP) from scratch under various scenarios. The most critical contributors among multiple drug notations and omics profiles are Extended Connectivity Fingerprint and genetic mutation. Additionally, the attention-based fusion module further enhances the predictive performance of TransCDR. TransCDR, trained on the GDSC dataset, demonstrates strong predictive performance on the external testing set CCLE. It is also utilized to predict missing CDRs on GDSC. Moreover, we investigate the biological mechanisms underlying drug response by classifying 7,675 patients from TCGA into drug-sensitive or drug-resistant groups, followed by a Gene Set Enrichment Analysis. TransCDR emerges as a potent tool with significant potential in drug response prediction. The source code and data can be accessed at https://github.com/XiaoqiongXia/TransCDR. ",
    "url": "https://arxiv.org/abs/2311.12040",
    "authors": [
      "Xiaoqiong Xia",
      "Chaoyu Zhu",
      "Yuqi Shan",
      "Fan Zhong",
      "Lei Liu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.12081",
    "title": "Leveraging healthy population variability in deep learning unsupervised  anomaly detection in brain FDG PET",
    "abstract": "Unsupervised anomaly detection is a popular approach for the analysis of neuroimaging data as it allows to identify a wide variety of anomalies from unlabelled data. It relies on building a subject-specific model of healthy appearance to which a subject's image can be compared to detect anomalies. In the literature, it is common for anomaly detection to rely on analysing the residual image between the subject's image and its pseudo-healthy reconstruction. This approach however has limitations partly due to the pseudo-healthy reconstructions being imperfect and to the lack of natural thresholding mechanism. Our proposed method, inspired by Z-scores, leverages the healthy population variability to overcome these limitations. Our experiments conducted on FDG PET scans from the ADNI database demonstrate the effectiveness of our approach in accurately identifying Alzheimer's disease related anomalies. ",
    "url": "https://arxiv.org/abs/2311.12081",
    "authors": [
      "Ma\u00eblys Solal",
      "Ravi Hassanaly",
      "Ninon Burgos"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2311.12449",
    "title": "HPCNeuroNet: Advancing Neuromorphic Audio Signal Processing with  Transformer-Enhanced Spiking Neural Networks",
    "abstract": "This paper presents a novel approach to neuromorphic audio processing by integrating the strengths of Spiking Neural Networks (SNNs), Transformers, and high-performance computing (HPC) into the HPCNeuroNet architecture. Utilizing the Intel N-DNS dataset, we demonstrate the system's capability to process diverse human vocal recordings across multiple languages and noise backgrounds. The core of our approach lies in the fusion of the temporal dynamics of SNNs with the attention mechanisms of Transformers, enabling the model to capture intricate audio patterns and relationships. Our architecture, HPCNeuroNet, employs the Short-Time Fourier Transform (STFT) for time-frequency representation, Transformer embeddings for dense vector generation, and SNN encoding/decoding mechanisms for spike train conversions. The system's performance is further enhanced by leveraging the computational capabilities of NVIDIA's GeForce RTX 3060 GPU and Intel's Core i9 12900H CPU. Additionally, we introduce a hardware implementation on the Xilinx VU37P HBM FPGA platform, optimizing for energy efficiency and real-time processing. The proposed accelerator achieves a throughput of 71.11 Giga-Operations Per Second (GOP/s) with a 3.55 W on-chip power consumption at 100 MHz. The comparison results with off-the-shelf devices and recent state-of-the-art implementations illustrate that the proposed accelerator has obvious advantages in terms of energy efficiency and design flexibility. Through design-space exploration, we provide insights into optimizing core capacities for audio tasks. Our findings underscore the transformative potential of integrating SNNs, Transformers, and HPC for neuromorphic audio processing, setting a new benchmark for future research and applications. ",
    "url": "https://arxiv.org/abs/2311.12449",
    "authors": [
      "Murat Isik",
      "Hiruna Vishwamith",
      "Kayode Inadagbo",
      "I. Can Dikmen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2311.12530",
    "title": "An efficient likelihood-free Bayesian inference method based on  sequential neural posterior estimation",
    "abstract": "Sequential neural posterior estimation (SNPE) techniques have been recently proposed for dealing with simulation-based models with intractable likelihoods. Unlike approximate Bayesian computation, SNPE techniques learn the posterior from sequential simulation using neural network-based conditional density estimators. This paper reclaims SNPE-B proposed by Lueckmann et al. (2017), which suffers from inefficiency and slow inference due to inefficient utilization of simulated data and high variance of parameter updates. To address these issues, we firstly introduce a concentrated loss function based on an adaptive calibration kernel that reweights the simulated data appropriately to improve the data efficiency. Moreover, we provide a theoretical analysis of the variance of associated Monte Carlo estimators. Based on this analysis, we then propose several variance reduction techniques to further accelerate the process of learning. Numerical experiments demonstrate that our method outperforms the original method together with other existing competitors on certain tasks. ",
    "url": "https://arxiv.org/abs/2311.12530",
    "authors": [
      "Yifei Xiong",
      "Xiliang Yang",
      "Sanguo Zhang",
      "Zhijian He"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2311.12770",
    "title": "Swift Parameter-free Attention Network for Efficient Super-Resolution",
    "abstract": "Single Image Super-Resolution (SISR) is a crucial task in low-level computer vision, aiming to reconstruct high-resolution images from low-resolution counterparts. Conventional attention mechanisms have significantly improved SISR performance but often result in complex network structures and large number of parameters, leading to slow inference speed and large model size. To address this issue, we propose the Swift Parameter-free Attention Network (SPAN), a highly efficient SISR model that balances parameter count, inference speed, and image quality. SPAN employs a novel parameter-free attention mechanism, which leverages symmetric activation functions and residual connections to enhance high-contribution information and suppress redundant information. Our theoretical analysis demonstrates the effectiveness of this design in achieving the attention mechanism's purpose. We evaluate SPAN on multiple benchmarks, showing that it outperforms existing efficient super-resolution models in terms of both image quality and inference speed, achieving a significant quality-speed trade-off. This makes SPAN highly suitable for real-world applications, particularly in resource-constrained scenarios. Notably, our model attains the best PSNR of 27.09 dB, and the test runtime of our team is reduced by 7.08ms in the NTIRE 2023 efficient super-resolution challenge. Our code and models are made publicly available at \\url{https://github.com/hongyuanyu/SPAN}. ",
    "url": "https://arxiv.org/abs/2311.12770",
    "authors": [
      "Cheng Wan",
      "Hongyuan Yu",
      "Zhiqi Li",
      "Yihang Chen",
      "Yajun Zou",
      "Yuqing Liu",
      "Xuanwu Yin",
      "Kunlong Zuo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:1810.12813",
    "title": "Contextual Hourglass Network for Semantic Segmentation of High  Resolution Aerial Imagery",
    "abstract": " Comments: Accepted by ICIP 2019, this https URL ",
    "url": "https://arxiv.org/abs/1810.12813",
    "authors": [
      "Panfeng Li",
      "Youzuo Lin",
      "Emily Schultz-Fellenz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2004.07780",
    "title": "Shortcut Learning in Deep Neural Networks",
    "abstract": " Comments: perspective article published at Nature Machine Intelligence (this https URL) ",
    "url": "https://arxiv.org/abs/2004.07780",
    "authors": [
      "Robert Geirhos",
      "J\u00f6rn-Henrik Jacobsen",
      "Claudio Michaelis",
      "Richard Zemel",
      "Wieland Brendel",
      "Matthias Bethge",
      "Felix A. Wichmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2011.04923",
    "title": "Topological properties of basins of attraction and expressiveness of  width bounded neural networks",
    "abstract": " Title: Topological properties of basins of attraction and expressiveness of  width bounded neural networks ",
    "url": "https://arxiv.org/abs/2011.04923",
    "authors": [
      "Hans-Peter Beise",
      "Steve Dias Da Cruz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.00955",
    "title": "Source Free Unsupervised Graph Domain Adaptation",
    "abstract": " Comments: 12 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2112.00955",
    "authors": [
      "Haitao Mao",
      "Lun Du",
      "Yujia Zheng",
      "Qiang Fu",
      "Zelin Li",
      "Xu Chen",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.09831",
    "title": "Neural Born Iteration Method For Solving Inverse Scattering Problems: 2D  Cases",
    "abstract": " Comments: This preprint has been published in IEEE Transactions on Antennas and Propagation on 01 November 2022. Please cite the final published version as [T. Shan et al., \"Neural Born Iterative Method for Solving Inverse Scattering Problems: 2D Cases,\" in IEEE Transactions on Antennas and Propagation, vol. 71, no. 1, pp. 818-829, Jan. 2023, doi: 10.1109/TAP.2022.3217333.] ",
    "url": "https://arxiv.org/abs/2112.09831",
    "authors": [
      "Tao Shan",
      "Zhichao Lin",
      "Xiaoqian Song",
      "Maokun Li",
      "Fan Yang",
      "Zhensheng Xu"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2202.10793",
    "title": "PyTorch Geometric Signed Directed: A Software Package on Graph Neural  Networks for Signed and Directed Graphs",
    "abstract": " Comments: Accepted by LoG 2023. 27 pages in total ",
    "url": "https://arxiv.org/abs/2202.10793",
    "authors": [
      "Yixuan He",
      "Xitong Zhang",
      "Junjie Huang",
      "Benedek Rozemberczki",
      "Mihai Cucuringu",
      "Gesine Reinert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.09157",
    "title": "Multifidelity Deep Operator Networks For Data-Driven and  Physics-Informed Problems",
    "abstract": " Title: Multifidelity Deep Operator Networks For Data-Driven and  Physics-Informed Problems ",
    "url": "https://arxiv.org/abs/2204.09157",
    "authors": [
      "Amanda A. Howard",
      "Mauro Perego",
      "George E. Karniadakis",
      "Panos Stinis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.04763",
    "title": "Neural Bregman Divergences for Distance Learning",
    "abstract": " Comments: Published in ICLR 2023, more related works added ",
    "url": "https://arxiv.org/abs/2206.04763",
    "authors": [
      "Fred Lu",
      "Edward Raff",
      "Francis Ferraro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.00319",
    "title": "Robust Planning for Multi-stage Forceful Manipulation",
    "abstract": " Comments: Accepted to IJRR (International Journal of Robotics Research). Supplemental Video: this https URL ",
    "url": "https://arxiv.org/abs/2208.00319",
    "authors": [
      "Rachel Holladay",
      "Tom\u00e1s Lozano-P\u00e9rez",
      "Alberto Rodriguez"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2208.04589",
    "title": "Long-term Causal Effects Estimation via Latent Surrogates Representation  Learning",
    "abstract": " Title: Long-term Causal Effects Estimation via Latent Surrogates Representation  Learning ",
    "url": "https://arxiv.org/abs/2208.04589",
    "authors": [
      "Ruichu Cai",
      "Weilin Chen",
      "Zeqin Yang",
      "Shu Wan",
      "Chen Zheng",
      "Xiaoqing Yang",
      "Jiecheng Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.04717",
    "title": "Cascaded and Generalizable Neural Radiance Fields for Fast View  Synthesis",
    "abstract": " Comments: Accepted at IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) ",
    "url": "https://arxiv.org/abs/2208.04717",
    "authors": [
      "Phong Nguyen-Ha",
      "Lam Huynh",
      "Esa Rahtu",
      "Jiri Matas",
      "Janne Heikkila"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2211.08942",
    "title": "Differentially Private Optimizers Can Learn Adversarially Robust Models",
    "abstract": " Title: Differentially Private Optimizers Can Learn Adversarially Robust Models ",
    "url": "https://arxiv.org/abs/2211.08942",
    "authors": [
      "Yuan Zhang",
      "Zhiqi Bu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.15513",
    "title": "Composite Score for Anomaly Detection in Imbalanced Real-World  Industrial Dataset",
    "abstract": " Comments: This version of the article has been accepted for publication, after peer review and is subject to Springer Nature AM terms of use, but is not the Version of Record and does not reflect post-acceptance improvements, or any corrections. The Version of Record is available online at: this https URL ",
    "url": "https://arxiv.org/abs/2211.15513",
    "authors": [
      "Arnaud Bougaham",
      "Mohammed El Adoui",
      "Isabelle Linden",
      "Beno\u00eet Fr\u00e9nay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.02081",
    "title": "YolOOD: Utilizing Object Detection Concepts for Multi-Label  Out-of-Distribution Detection",
    "abstract": " Comments: 10 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2212.02081",
    "authors": [
      "Alon Zolfi",
      "Guy Amit",
      "Amit Baras",
      "Satoru Koda",
      "Ikuya Morikawa",
      "Yuval Elovici",
      "Asaf Shabtai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05258",
    "title": "Image augmentation with conformal mappings for a convolutional neural  network",
    "abstract": " Comments: 14 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2212.05258",
    "authors": [
      "Oona Rainio",
      "Mohamed M.S. Nasser",
      "Matti Vuorinen",
      "Riku Kl\u00e9n"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.04181",
    "title": "Attending to Graph Transformers",
    "abstract": " Title: Attending to Graph Transformers ",
    "url": "https://arxiv.org/abs/2302.04181",
    "authors": [
      "Luis M\u00fcller",
      "Mikhail Galkin",
      "Christopher Morris",
      "Ladislav Ramp\u00e1\u0161ek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2302.10396",
    "title": "Assessing Domain Gap for Continual Domain Adaptation in Object Detection",
    "abstract": " Comments: Accepted to CVIU ",
    "url": "https://arxiv.org/abs/2302.10396",
    "authors": [
      "Anh-Dzung Doan",
      "Bach Long Nguyen",
      "Surabhi Gupta",
      "Ian Reid",
      "Markus Wagner",
      "Tat-Jun Chin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.01351",
    "title": "APARATE: Adaptive Adversarial Patch for CNN-based Monocular Depth  Estimation for Autonomous Navigation",
    "abstract": " Title: APARATE: Adaptive Adversarial Patch for CNN-based Monocular Depth  Estimation for Autonomous Navigation ",
    "url": "https://arxiv.org/abs/2303.01351",
    "authors": [
      "Amira Guesmi",
      "Muhammad Abdullah Hanif",
      "Ihsen Alouani",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.02536",
    "title": "Finding Alignments Between Interpretable Causal Variables and  Distributed Neural Representations",
    "abstract": " Title: Finding Alignments Between Interpretable Causal Variables and  Distributed Neural Representations ",
    "url": "https://arxiv.org/abs/2303.02536",
    "authors": [
      "Atticus Geiger",
      "Zhengxuan Wu",
      "Christopher Potts",
      "Thomas Icard",
      "Noah D. Goodman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2303.17646",
    "title": "XPert: Peripheral Circuit & Neural Architecture Co-search for Area and  Energy-efficient Xbar-based Computing",
    "abstract": " Comments: Accepted to Design and Automation Conference (DAC) ",
    "url": "https://arxiv.org/abs/2303.17646",
    "authors": [
      "Abhishek Moitra",
      "Abhiroop Bhattacharjee",
      "Youngeun Kim",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.07647",
    "title": "LASER: A Neuro-Symbolic Framework for Learning Spatial-Temporal Scene  Graphs with Weak Supervision",
    "abstract": " Title: LASER: A Neuro-Symbolic Framework for Learning Spatial-Temporal Scene  Graphs with Weak Supervision ",
    "url": "https://arxiv.org/abs/2304.07647",
    "authors": [
      "Jiani Huang",
      "Ziyang Li",
      "Mayur Naik",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2304.07927",
    "title": "A Randomized Approach for Tight Privacy Accounting",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2304.07927",
    "authors": [
      "Jiachen T. Wang",
      "Saeed Mahloujifar",
      "Tong Wu",
      "Ruoxi Jia",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.07955",
    "title": "Heterogeneous Domain Adaptation with Positive and Unlabeled Data",
    "abstract": " Comments: Accepted by IEEE Big Data 2023 as a regular paper ",
    "url": "https://arxiv.org/abs/2304.07955",
    "authors": [
      "Junki Mori",
      "Ryo Furukawa",
      "Isamu Teranishi",
      "Jun Sakuma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.09248",
    "title": "Real-Time Helmet Violation Detection in AI City Challenge 2023 with  Genetic Algorithm-Enhanced YOLOv5",
    "abstract": " Title: Real-Time Helmet Violation Detection in AI City Challenge 2023 with  Genetic Algorithm-Enhanced YOLOv5 ",
    "url": "https://arxiv.org/abs/2304.09248",
    "authors": [
      "Elham Soltanikazemi",
      "Ashwin Dhakal",
      "Bijaya Kumar Hatuwal",
      "Imad Eddine Toubal",
      "Armstrong Aboah",
      "Kannappan Palaniappan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.09355",
    "title": "To Compress or Not to Compress- Self-Supervised Learning and Information  Theory: A Review",
    "abstract": " Title: To Compress or Not to Compress- Self-Supervised Learning and Information  Theory: A Review ",
    "url": "https://arxiv.org/abs/2304.09355",
    "authors": [
      "Ravid Shwartz-Ziv",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2304.14922",
    "title": "Supervised and Unsupervised Deep Learning Approaches for EEG Seizure  Prediction",
    "abstract": " Comments: 16 figures, 9 tables ",
    "url": "https://arxiv.org/abs/2304.14922",
    "authors": [
      "Zakary Georgis-Yap",
      "Milos R. Popovic",
      "Shehroz S. Khan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.11618",
    "title": "DAP: A Dynamic Adversarial Patch for Evading Person Detectors",
    "abstract": " Title: DAP: A Dynamic Adversarial Patch for Evading Person Detectors ",
    "url": "https://arxiv.org/abs/2305.11618",
    "authors": [
      "Amira Guesmi",
      "Ruitian Ding",
      "Muhammad Abdullah Hanif",
      "Ihsen Alouani",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.18183",
    "title": "On Counterfactual Data Augmentation Under Confounding",
    "abstract": " Title: On Counterfactual Data Augmentation Under Confounding ",
    "url": "https://arxiv.org/abs/2305.18183",
    "authors": [
      "Abbavaram Gowtham Reddy",
      "Saketh Bachu",
      "Saloni Dash",
      "Charchit Sharma",
      "Amit Sharma",
      "Vineeth N Balasubramanian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.05557",
    "title": "On Performance Discrepancies Across Local Homophily Levels in Graph  Neural Networks",
    "abstract": " Comments: 30 pages ",
    "url": "https://arxiv.org/abs/2306.05557",
    "authors": [
      "Donald Loveland",
      "Jiong Zhu",
      "Mark Heimann",
      "Benjamin Fish",
      "Michael T. Schaub",
      "Danai Koutra"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06010",
    "title": "A Large-Scale Analysis on Self-Supervised Video Representation Learning",
    "abstract": " Title: A Large-Scale Analysis on Self-Supervised Video Representation Learning ",
    "url": "https://arxiv.org/abs/2306.06010",
    "authors": [
      "Akash Kumar",
      "Ashlesha Kumar",
      "Vibhav Vineet",
      "Yogesh Singh Rawat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.12685",
    "title": "Rethinking the Backward Propagation for Adversarial Transferability",
    "abstract": " Comments: Accepted by NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.12685",
    "authors": [
      "Xiaosen Wang",
      "Kangheng Tong",
      "Kun He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.16568",
    "title": "Early warning signals for predicting cryptomarket vendor success using  dark net forum networks",
    "abstract": " Title: Early warning signals for predicting cryptomarket vendor success using  dark net forum networks ",
    "url": "https://arxiv.org/abs/2306.16568",
    "authors": [
      "Hanjo D. Boekhout",
      "Arjan A.J. Blokland",
      "Frank W. Takes"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.17103",
    "title": "LyricWhiz: Robust Multilingual Zero-shot Lyrics Transcription by  Whispering to ChatGPT",
    "abstract": " Comments: 9 pages, 2 figures, 5 tables, accepted by ISMIR 2023 ",
    "url": "https://arxiv.org/abs/2306.17103",
    "authors": [
      "Le Zhuo",
      "Ruibin Yuan",
      "Jiahao Pan",
      "Yinghao Ma",
      "Yizhi LI",
      "Ge Zhang",
      "Si Liu",
      "Roger Dannenberg",
      "Jie Fu",
      "Chenghua Lin",
      "Emmanouil Benetos",
      "Wenhu Chen",
      "Wei Xue",
      "Yike Guo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2306.17844",
    "title": "The Clock and the Pizza: Two Stories in Mechanistic Explanation of  Neural Networks",
    "abstract": " Comments: Accepted by NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.17844",
    "authors": [
      "Ziqian Zhong",
      "Ziming Liu",
      "Max Tegmark",
      "Jacob Andreas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.01452",
    "title": "Causal Reinforcement Learning: A Survey",
    "abstract": " Comments: 52 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2307.01452",
    "authors": [
      "Zhihong Deng",
      "Jing Jiang",
      "Guodong Long",
      "Chengqi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.07081",
    "title": "Kernel t-distributed stochastic neighbor embedding",
    "abstract": " Title: Kernel t-distributed stochastic neighbor embedding ",
    "url": "https://arxiv.org/abs/2307.07081",
    "authors": [
      "Denis C. Ilie-Ablachim",
      "Bogdan Dumitrescu",
      "Cristian Rusu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.09815",
    "title": "LDP: Language-driven Dual-Pixel Image Defocus Deblurring Network",
    "abstract": " Title: LDP: Language-driven Dual-Pixel Image Defocus Deblurring Network ",
    "url": "https://arxiv.org/abs/2307.09815",
    "authors": [
      "Hao Yang",
      "Liyuan Pan",
      "Yan Yang",
      "Richard Hartley",
      "Miaomiao Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.10865",
    "title": "Addressing caveats of neural persistence with deep graph persistence",
    "abstract": " Comments: Transactions on Machine Learning Research (TMLR), 2023 ",
    "url": "https://arxiv.org/abs/2307.10865",
    "authors": [
      "Leander Girrbach",
      "Anders Christensen",
      "Ole Winther",
      "Zeynep Akata",
      "A. Sophia Koepke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2308.13700",
    "title": "Multipartite Entanglement in Quantum Networks using Subgraph  Complementations",
    "abstract": " Comments: Presented as a poster paper at the 2023 IEEE International Conference on Quantum Computing and Engineering (QCE23) ",
    "url": "https://arxiv.org/abs/2308.13700",
    "authors": [
      "Aniruddha Sen",
      "Kenneth Goodenough",
      "Don Towsley"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2308.14491",
    "title": "Closeness of Some Graph Operations",
    "abstract": " Comments: 16 pages ",
    "url": "https://arxiv.org/abs/2308.14491",
    "authors": [
      "Chavdar Dangalchev"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2309.03036",
    "title": "An Efficient Temporary Deepfake Location Approach Based Embeddings for  Partially Spoofed Audio Detection",
    "abstract": " Title: An Efficient Temporary Deepfake Location Approach Based Embeddings for  Partially Spoofed Audio Detection ",
    "url": "https://arxiv.org/abs/2309.03036",
    "authors": [
      "Yuankun Xie",
      "Haonan Cheng",
      "Yutian Wang",
      "Long Ye"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2309.12190",
    "title": "Regret and Conservatism of Distributionally Robust Constrained  Stochastic Model Predictive Control",
    "abstract": " Comments: Extended version of a manuscript submitted to L-CSS with ACC option (revised version) ",
    "url": "https://arxiv.org/abs/2309.12190",
    "authors": [
      "Maik Pfefferkorn",
      "Venkatraman Renganathan",
      "Rolf Findeisen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2309.13108",
    "title": "Data is often loadable in short depth: Quantum circuits from tensor  networks for finance, images, fluids, and proteins",
    "abstract": " Comments: 10 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2309.13108",
    "authors": [
      "Raghav Jumade",
      "Nicolas PD Sawaya"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2310.08897",
    "title": "Self supervised convolutional kernel based handcrafted feature  harmonization: Enhanced left ventricle hypertension disease phenotyping on  echocardiography",
    "abstract": " Comments: 11 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2310.08897",
    "authors": [
      "Jina Lee",
      "Youngtaek Hong",
      "Dawun Jeong",
      "Yeonggul Jang",
      "Sihyeon Jeong",
      "Taekgeun Jung",
      "Yeonyee E. Yoon",
      "Inki Moon",
      "Seung-Ah Lee",
      "Hyuk-Jae Chang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09299",
    "title": "Digital Twin Assisted Deep Reinforcement Learning for Online Admission  Control in Sliced Network",
    "abstract": " Comments: 13 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2310.09299",
    "authors": [
      "Zhenyu Tao",
      "Wei Xu",
      "Xiaohu You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.10837",
    "title": "Approximating Two-Layer Feedforward Networks for Efficient Transformers",
    "abstract": " Comments: Accepted to EMNLP 2023 Findings ",
    "url": "https://arxiv.org/abs/2310.10837",
    "authors": [
      "R\u00f3bert Csord\u00e1s",
      "Kazuki Irie",
      "J\u00fcrgen Schmidhuber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.13019",
    "title": "Tailoring Adversarial Attacks on Deep Neural Networks for Targeted Class  Manipulation Using DeepFool Algorithm",
    "abstract": " Comments: 8 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2310.13019",
    "authors": [
      "S. M. Fazle Rabby Labib",
      "Joyanta Jyoti Mondal",
      "Meem Arafat Manab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.14884",
    "title": "Budgeted Embedding Table For Recommender Systems",
    "abstract": " Comments: Accepted by WSDM 2024 ",
    "url": "https://arxiv.org/abs/2310.14884",
    "authors": [
      "Yunke Qu",
      "Tong Chen",
      "Quoc Viet Hung Nguyen",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.17355",
    "title": "Exploring the Trie of Rules: a fast data structure for the  representation of association rules",
    "abstract": " Comments: 12 pages, 13 figures, preprint of journal article ",
    "url": "https://arxiv.org/abs/2310.17355",
    "authors": [
      "Mikhail Kudriavtsev",
      "Marija Bezbradica",
      "Andrew McCarren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.17949",
    "title": "Instance Segmentation under Occlusions via Location-aware Copy-Paste  Data Augmentation",
    "abstract": " Title: Instance Segmentation under Occlusions via Location-aware Copy-Paste  Data Augmentation ",
    "url": "https://arxiv.org/abs/2310.17949",
    "authors": [
      "Son Nguyen",
      "Mikel Lainsa",
      "Hung Dao",
      "Daeyoung Kim",
      "Giang Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19805",
    "title": "Sample Efficient Reward Augmentation in offline-to-online Reinforcement  Learning",
    "abstract": " Comments: 23 pages, 11 Figures, and 6 Tables ",
    "url": "https://arxiv.org/abs/2310.19805",
    "authors": [
      "Ziqi Zhang",
      "Xiao Xiong",
      "Zifeng Zhuang",
      "Jinxin Liu",
      "Donglin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.20567",
    "title": "One-shot backpropagation for multi-step prediction in physics-based  system identification -- EXTENDED VERSION",
    "abstract": " Title: One-shot backpropagation for multi-step prediction in physics-based  system identification -- EXTENDED VERSION ",
    "url": "https://arxiv.org/abs/2310.20567",
    "authors": [
      "Cesare Donati",
      "Martina Mammarella",
      "Fabrizio Dabbene",
      "Carlo Novara",
      "Constantino Lagoa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01038",
    "title": "Better with Less: A Data-Active Perspective on Pre-Training Graph Neural  Networks",
    "abstract": " Title: Better with Less: A Data-Active Perspective on Pre-Training Graph Neural  Networks ",
    "url": "https://arxiv.org/abs/2311.01038",
    "authors": [
      "Jiarong Xu",
      "Renhong Huang",
      "Xin Jiang",
      "Yuxuan Cao",
      "Carl Yang",
      "Chunping Wang",
      "Yang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.02143",
    "title": "Pairing-based graph neural network for simulating quantum materials",
    "abstract": " Title: Pairing-based graph neural network for simulating quantum materials ",
    "url": "https://arxiv.org/abs/2311.02143",
    "authors": [
      "Di Luo",
      "David D. Dai",
      "Liang Fu"
    ],
    "subjectives": [
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2311.05481",
    "title": "META4: Semantically-Aligned Generation of Metaphoric Gestures Using  Self-Supervised Text and Speech Representation",
    "abstract": " Title: META4: Semantically-Aligned Generation of Metaphoric Gestures Using  Self-Supervised Text and Speech Representation ",
    "url": "https://arxiv.org/abs/2311.05481",
    "authors": [
      "Mireille Fares",
      "Catherine Pelachaud",
      "Nicolas Obin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.06483",
    "title": "Stacked networks improve physics-informed training: applications to  neural networks and deep operator networks",
    "abstract": " Title: Stacked networks improve physics-informed training: applications to  neural networks and deep operator networks ",
    "url": "https://arxiv.org/abs/2311.06483",
    "authors": [
      "Amanda A Howard",
      "Sarah H Murphy",
      "Shady E Ahmed",
      "Panos Stinis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2311.06504",
    "title": "SCL-VI: Self-supervised Context Learning for Visual Inspection of  Industrial Defects",
    "abstract": " Title: SCL-VI: Self-supervised Context Learning for Visual Inspection of  Industrial Defects ",
    "url": "https://arxiv.org/abs/2311.06504",
    "authors": [
      "Peng Wang",
      "Haiming Yao",
      "Wenyong Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.10122",
    "title": "Video-LLaVA: Learning United Visual Representation by Alignment Before  Projection",
    "abstract": " Title: Video-LLaVA: Learning United Visual Representation by Alignment Before  Projection ",
    "url": "https://arxiv.org/abs/2311.10122",
    "authors": [
      "Bin Lin",
      "Yang Ye",
      "Bin Zhu",
      "Jiaxi Cui",
      "Munan Ning",
      "Peng Jin",
      "Li Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.10801",
    "title": "Reinforcement Learning with Maskable Stock Representation for Portfolio  Management in Customizable Stock Pools",
    "abstract": " Title: Reinforcement Learning with Maskable Stock Representation for Portfolio  Management in Customizable Stock Pools ",
    "url": "https://arxiv.org/abs/2311.10801",
    "authors": [
      "Wentao Zhang",
      "Yilei Zhao",
      "Shuo Sun",
      "Jie Ying",
      "Yonggang Xie",
      "Zitao Song",
      "Xinrun Wang",
      "Bo An"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.10869",
    "title": "Evolutionary algorithms as an alternative to backpropagation for  supervised training of Biophysical Neural Networks and Neural ODEs",
    "abstract": " Title: Evolutionary algorithms as an alternative to backpropagation for  supervised training of Biophysical Neural Networks and Neural ODEs ",
    "url": "https://arxiv.org/abs/2311.10869",
    "authors": [
      "James Hazelden",
      "Yuhan Helena Liu",
      "Eli Shlizerman",
      "Eric Shea-Brown"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.11013",
    "title": "Implicit Event-RGBD Neural SLAM",
    "abstract": " Title: Implicit Event-RGBD Neural SLAM ",
    "url": "https://arxiv.org/abs/2311.11013",
    "authors": [
      "Delin Qu",
      "Chi Yan",
      "Dong Wang",
      "Jie Yin",
      "Dan Xu",
      "Bin Zhao",
      "Xuelong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11354",
    "title": "Scale-aware competition network for palmprint recognition",
    "abstract": " Title: Scale-aware competition network for palmprint recognition ",
    "url": "https://arxiv.org/abs/2311.11354",
    "authors": [
      "Chengrui Gao",
      "Ziyuan Yang",
      "Min Zhu",
      "Andrew Beng Jin Teoh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11439",
    "title": "Improved Defect Detection and Classification Method for Advanced IC  Nodes by Using Slicing Aided Hyper Inference with Refinement Strategy",
    "abstract": " Comments: 12 pages, 9 figures, to be presented at International Conference on Machine Intelligence with Applications (ICMIA), and to be published in conference proceedings by AIP ",
    "url": "https://arxiv.org/abs/2311.11439",
    "authors": [
      "Vic De Ridder",
      "Bappaditya Dey",
      "Victor Blanco",
      "Sandip Halder",
      "Bartel Van Waeyenberge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11995",
    "title": "BrainWash: A Poisoning Attack to Forget in Continual Learning",
    "abstract": " Title: BrainWash: A Poisoning Attack to Forget in Continual Learning ",
    "url": "https://arxiv.org/abs/2311.11995",
    "authors": [
      "Ali Abbasi",
      "Parsa Nooralinejad",
      "Hamed Pirsiavash",
      "Soheil Kolouri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  }
]