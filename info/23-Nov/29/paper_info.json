[
  {
    "id": "arXiv:2311.16104",
    "title": "Data Analytics with Differential Privacy",
    "abstract": "Differential privacy is the state-of-the-art definition for privacy, guaranteeing that any analysis performed on a sensitive dataset leaks no information about the individuals whose data are contained therein. In this thesis, we develop differentially private algorithms to analyze distributed and streaming data. In the distributed model, we consider the particular problem of learning -- in a distributed fashion -- a global model of the data, that can subsequently be used for arbitrary analyses. We build upon PrivBayes, a differentially private method that approximates the high-dimensional distribution of a centralized dataset as a product of low-order distributions, utilizing a Bayesian Network model. We examine three novel approaches to learning a global Bayesian Network from distributed data, while offering the differential privacy guarantee to all local datasets. Our work includes a detailed theoretical analysis of the distributed, differentially private entropy estimator which we use in one of our algorithms, as well as a detailed experimental evaluation, using both synthetic and real-world data. In the streaming model, we focus on the problem of estimating the density of a stream of users, which expresses the fraction of all users that actually appear in the stream. We offer one of the strongest privacy guarantees for the streaming model, user-level pan-privacy, which ensures that the privacy of any user is protected, even against an adversary that observes the internal state of the algorithm. We provide a detailed analysis of an existing, sampling-based algorithm for the problem and propose two novel modifications that significantly improve it, both theoretically and experimentally, by optimally using all the allocated \"privacy budget.\" ",
    "url": "https://arxiv.org/abs/2311.16104",
    "authors": [
      "Vassilis Digalakis Jr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2311.16110",
    "title": "Community Battery Energy Storage Systems for Enhancing Distribution  System Operation: A Multi-objective Optimization Approach",
    "abstract": "The growing penetration of distributed energy resources (DERs) in distribution networks (DNs) raises new operational challenges, particularly in terms of reliability and voltage regulation. In response to these challenges, we introduce an innovative DN operation framework with multi-objective optimization, leveraging community battery energy storage systems (C-BESS). The proposed framework targets two key operational objectives: first, to minimize voltage deviation, which is a concern for a distribution network service provider (DNSP), and second, to maximize the utilization of DERs on the demand side. Recognizing the conflicting nature of these objectives, we utilize C-BESS to enhance the system's adaptability to dynamically adjust DN operations. The multi-objective optimization problem is solved using the non-dominated sorting genetic algorithm-II (NSGA-II). Case studies using real-world data are conducted to validate the effectiveness of the proposed framework. The results show significant improvements in voltage regulation and DER utilization, demonstrating the potential of C-BESS in enabling more reliable DN operation. Our findings contribute to the ongoing discourse on the role of C-BESS in DN operation enhancement and DER integration. ",
    "url": "https://arxiv.org/abs/2311.16110",
    "authors": [
      "Yunqi Wang",
      "Hao Wang",
      "Markus Wagner",
      "Ariel Liebman"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2311.16112",
    "title": "Co-learning synaptic delays, weights and adaptation in spiking neural  networks",
    "abstract": "Spiking neural networks (SNN) distinguish themselves from artificial neural networks (ANN) because of their inherent temporal processing and spike-based computations, enabling a power-efficient implementation in neuromorphic hardware. In this paper, we demonstrate that data processing with spiking neurons can be enhanced by co-learning the connection weights with two other biologically inspired neuronal features: 1) a set of parameters describing neuronal adaptation processes and 2) synaptic propagation delays. The former allows the spiking neuron to learn how to specifically react to incoming spikes based on its past. The trained adaptation parameters result in neuronal heterogeneity, which is found in the brain and also leads to a greater variety in available spike patterns. The latter enables to learn to explicitly correlate patterns that are temporally distanced. Synaptic delays reflect the time an action potential requires to travel from one neuron to another. We show that each of the co-learned features separately leads to an improvement over the baseline SNN and that the combination of both leads to state-of-the-art SNN results on all speech recognition datasets investigated with a simple 2-hidden layer feed-forward network. Our SNN outperforms the ANN on the neuromorpic datasets (Spiking Heidelberg Digits and Spiking Speech Commands), even with fewer trainable parameters. On the 35-class Google Speech Commands dataset, our SNN also outperforms a GRU of similar size. Our work presents brain-inspired improvements to SNN that enable them to excel over an equivalent ANN of similar size on tasks with rich temporal dynamics. ",
    "url": "https://arxiv.org/abs/2311.16112",
    "authors": [
      "Lucas Deckers",
      "Laurens Van Damme",
      "Ing Jyh Tsang",
      "Werner Van Leekwijck",
      "Steven Latr\u00e9"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16113",
    "title": "BAGEL: Backdoor Attacks against Federated Contrastive Learning",
    "abstract": "Federated Contrastive Learning (FCL) is an emerging privacy-preserving paradigm in distributed learning for unlabeled data. In FCL, distributed parties collaboratively learn a global encoder with unlabeled data, and the global encoder could be widely used as a feature extractor to build models for many downstream tasks. However, FCL is also vulnerable to many security threats (e.g., backdoor attacks) due to its distributed nature, which are seldom investigated in existing solutions. In this paper, we study the backdoor attack against FCL as a pioneer research, to illustrate how backdoor attacks on distributed local clients act on downstream tasks. Specifically, in our system, malicious clients can successfully inject a backdoor into the global encoder by uploading poisoned local updates, thus downstream models built with this global encoder will also inherit the backdoor. We also investigate how to inject backdoors into multiple downstream models, in terms of two different backdoor attacks, namely the \\textit{centralized attack} and the \\textit{decentralized attack}. Experiment results show that both the centralized and the decentralized attacks can inject backdoors into downstream models effectively with high attack success rates. Finally, we evaluate two defense methods against our proposed backdoor attacks in FCL, which indicates that the decentralized backdoor attack is more stealthy and harder to defend. ",
    "url": "https://arxiv.org/abs/2311.16113",
    "authors": [
      "Yao Huang",
      "Kongyang Chen",
      "Jiannong Cao",
      "Jiaxing Shen",
      "Shaowei Wang",
      "Yun Peng",
      "Weilong Peng",
      "Kechao Cai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.16114",
    "title": "Learning Noise-Robust Joint Representation for Multimodal Emotion  Recognition under Realistic Incomplete Data Scenarios",
    "abstract": "Multimodal emotion recognition (MER) in practical scenarios presents a significant challenge due to the presence of incomplete data, such as missing or noisy data. Traditional methods often discard missing data or replace it with a zero vector, neglecting the availability issue of noisy data. Consequently, these approaches are not fully applicable to realistic scenarios, where both missing and noisy data are prevalent. To address this problem, we propose a novel noise-robust MER model, named NMER, which effectively learns robust multimodal joint representations from incomplete data containing noise. Our approach incorporates two key components. First, we introduce a noise scheduler that adjusts the type and level of noise in the training data, emulating the characteristics of incomplete data in realistic scenarios. Second, we employ a Variational AutoEncoder (VAE)-based NMER model to generate robust multimodal joint representations from the noisy data, leveraging the modality invariant feature. The experimental results on the benchmark dataset IEMOCAP indicate the proposed NMER outperforms state-of-the-art MER systems. The ablation results also confirm the effectiveness of the VAE structure. We release our code at \\href{https://github.com/WooyoohL/Noise-robust_MER. ",
    "url": "https://arxiv.org/abs/2311.16114",
    "authors": [
      "Qi Fan",
      "Haolin Zuo",
      "Rui Liu",
      "Zheng Lian",
      "Guanglai Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16118",
    "title": "Imperceptible CMOS camera dazzle for adversarial attacks on deep neural  networks",
    "abstract": "Despite the outstanding performance of deep neural networks, they are vulnerable to adversarial attacks. While there are many invisible attacks in the digital domain, most physical world adversarial attacks are visible. Here we present an invisible optical adversarial attack that uses a light source to dazzle a CMOS camera with a rolling shutter. We present the photopic conditions required to keep the attacking light source completely invisible while sufficiently jamming the captured image so that a deep neural network applied to it is deceived. ",
    "url": "https://arxiv.org/abs/2311.16118",
    "authors": [
      "Zvi Stein",
      "Adrian Stern"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16121",
    "title": "Real-Time Neural Materials using Block-Compressed Features",
    "abstract": "Neural materials typically consist of a collection of neural features along with a decoder network. The main challenge in integrating such models in real-time rendering pipelines lies in the large size required to store their features in GPU memory and the complexity of evaluating the network efficiently. We present a neural material model whose features and decoder are specifically designed to be used in real-time rendering pipelines. Our framework leverages hardware-based block compression (BC) texture formats to store the learned features and trains the model to output the material information continuously in space and scale. To achieve this, we organize the features in a block-based manner and emulate BC6 decompression during training, making it possible to export them as regular BC6 textures. This structure allows us to use high resolution features while maintaining a low memory footprint. Consequently, this enhances our model's overall capability, enabling the use of a lightweight and simple decoder architecture that can be evaluated directly in a shader. Furthermore, since the learned features can be decoded continuously, it allows for random uv sampling and smooth transition between scales without needing any subsequent filtering. As a result, our neural material has a small memory footprint, can be decoded extremely fast adding a minimal computational overhead to the rendering pipeline. ",
    "url": "https://arxiv.org/abs/2311.16121",
    "authors": [
      "Cl\u00e9ment Weinreich",
      "Louis de Oliveira",
      "Antoine Houdard",
      "Georges Nader"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2311.16123",
    "title": "Exploring Multiple Neighborhood Neural Cellular Automata (MNNCA) for  Enhanced Texture Learning",
    "abstract": "Cellular Automata (CA) have long been foundational in simulating dynamical systems computationally. With recent innovations, this model class has been brought into the realm of deep learning by parameterizing the CA's update rule using an artificial neural network, termed Neural Cellular Automata (NCA). This allows NCAs to be trained via gradient descent, enabling them to evolve into specific shapes, generate textures, and mimic behaviors such as swarming. However, a limitation of traditional NCAs is their inability to exhibit sufficiently complex behaviors, restricting their potential in creative and modeling tasks. Our research explores enhancing the NCA framework by incorporating multiple neighborhoods and introducing structured noise for seed states. This approach is inspired by techniques that have historically amplified the expressiveness of classical continuous CA. All code and example videos are publicly available on https://github.com/MagnusPetersen/MNNCA. ",
    "url": "https://arxiv.org/abs/2311.16123",
    "authors": [
      "Magnus Petersen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Cellular Automata and Lattice Gases (nlin.CG)"
    ]
  },
  {
    "id": "arXiv:2311.16124",
    "title": "DiffAttack: Evasion Attacks Against Diffusion-Based Adversarial  Purification",
    "abstract": "Diffusion-based purification defenses leverage diffusion models to remove crafted perturbations of adversarial examples and achieve state-of-the-art robustness. Recent studies show that even advanced attacks cannot break such defenses effectively, since the purification process induces an extremely deep computational graph which poses the potential problem of gradient obfuscation, high memory cost, and unbounded randomness. In this paper, we propose a unified framework DiffAttack to perform effective and efficient attacks against diffusion-based purification defenses, including both DDPM and score-based approaches. In particular, we propose a deviated-reconstruction loss at intermediate diffusion steps to induce inaccurate density gradient estimation to tackle the problem of vanishing/exploding gradients. We also provide a segment-wise forwarding-backwarding algorithm, which leads to memory-efficient gradient backpropagation. We validate the attack effectiveness of DiffAttack compared with existing adaptive attacks on CIFAR-10 and ImageNet. We show that DiffAttack decreases the robust accuracy of models compared with SOTA attacks by over 20% on CIFAR-10 under $\\ell_\\infty$ attack $(\\epsilon=8/255)$, and over 10% on ImageNet under $\\ell_\\infty$ attack $(\\epsilon=4/255)$. We conduct a series of ablations studies, and we find 1) DiffAttack with the deviated-reconstruction loss added over uniformly sampled time steps is more effective than that added over only initial/final steps, and 2) diffusion-based purification with a moderate diffusion length is more robust under DiffAttack. ",
    "url": "https://arxiv.org/abs/2311.16124",
    "authors": [
      "Mintong Kang",
      "Dawn Song",
      "Bo Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.16125",
    "title": "Vision-Based Incoming Traffic Estimator Using Deep Neural Network on  General Purpose Embedded Hardware",
    "abstract": "Traffic management is a serious problem in many cities around the world. Even the suburban areas are now experiencing regular traffic congestion. Inappropriate traffic control wastes fuel, time, and the productivity of nations. Though traffic signals are used to improve traffic flow, they often cause problems due to inappropriate or obsolete timing that does not tally with the actual traffic intensity at the intersection. Traffic intensity determination based on statistical methods only gives the average intensity expected at any given time. However, to control traffic accurately, it is required to know the real-time traffic intensity. In this research, image processing and machine learning have been used to estimate actual traffic intensity in real time. General-purpose electronic hardware has been used for in-situ image processing based on the edge-detection method. A deep neural network (DNN) was trained to infer traffic intensity in each image in real time. The trained DNN estimated traffic intensity accurately in 90% of the real-time images during road tests. The electronic system was implemented on a Raspberry Pi single-board computer; hence, it is cost-effective for large-scale deployment. ",
    "url": "https://arxiv.org/abs/2311.16125",
    "authors": [
      "K. G. Zoysa",
      "S. R. Munasinghe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16131",
    "title": "Secure Arcade: A Gamified Defense Against Cyber Attacks",
    "abstract": "In modernity, we continually receive increasingly intricate technologies that allow us to increase our lives convenience and efficiency. Our technology, particularly technology available over the internet, is advancing at unprecedented speed. However, this speed of advancement allows those behind malicious attacks to have an increasingly easier time taking advantage of those who know little about computer security. Unfortunately, education in the computer security field is generally limited only to tertiary education. This research addresses this problem through a gamified web-based application that drives users to reach learning goals to help them become more vigilant internet users: 1. Learn and memorize general computer security terminology, 2. Become familiar with basic cryptography concepts, 3. Learn to recognize potential phishing scams via email quickly, and 4. Learn common attacks on servers and how to deal with them. ",
    "url": "https://arxiv.org/abs/2311.16131",
    "authors": [
      "Sean Loesch",
      "Ryan Hrastich",
      "Jordan Herbert",
      "Ben Drangstveit",
      "Jacob Weber",
      "Mounika Vanamala"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.16138",
    "title": "After-Stroke Arm Paresis Detection using Kinematic Data",
    "abstract": "This paper presents an approach for detecting unilateral arm paralysis/weakness using kinematic data. Our method employs temporal convolution networks and recurrent neural networks, guided by knowledge distillation, where we use inertial measurement units attached to the body to capture kinematic information such as acceleration, rotation, and flexion of body joints during an action. This information is then analyzed to recognize body actions and patterns. Our proposed network achieves a high paretic detection accuracy of 97.99\\%, with an action classification accuracy of 77.69\\%, through knowledge sharing. Furthermore, by incorporating causal reasoning, we can gain additional insights into the patient's condition, such as their Fugl-Meyer assessment score or impairment level based on the machine learning result. Overall, our approach demonstrates the potential of using kinematic data and machine learning for detecting arm paralysis/weakness. The results suggest that our method could be a useful tool for clinicians and healthcare professionals working with patients with this condition. ",
    "url": "https://arxiv.org/abs/2311.16138",
    "authors": [
      "Kenneth Lai",
      "Mohammed Almekhlafi",
      "Svetlana Yanushkevich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.16139",
    "title": "GNNBleed: Inference Attacks to Unveil Private Edges in Graphs with  Realistic Access to GNN Models",
    "abstract": "Graph Neural Networks (GNNs) have increasingly become an indispensable tool in learning from graph-structured data, catering to various applications including social network analysis, recommendation systems, etc. At the heart of these networks are the edges which are crucial in guiding GNN models' predictions. In many scenarios, these edges represent sensitive information, such as personal associations or financial dealings -- thus requiring privacy assurance. However, their contributions to GNN model predictions may in turn be exploited by the adversary to compromise their privacy. Motivated by these conflicting requirements, this paper investigates edge privacy in contexts where adversaries possess black-box GNN model access, restricted further by access controls, preventing direct insights into arbitrary node outputs. In this context, we introduce a series of privacy attacks grounded on the message-passing mechanism of GNNs. These strategies allow adversaries to deduce connections between two nodes not by directly analyzing the model's output for these pairs but by analyzing the output for nodes linked to them. Our evaluation with seven real-life datasets and four GNN architectures underlines a significant vulnerability: even in systems fortified with access control mechanisms, an adaptive adversary can decipher private connections between nodes, thereby revealing potentially sensitive relationships and compromising the confidentiality of the graph. ",
    "url": "https://arxiv.org/abs/2311.16139",
    "authors": [
      "Zeyu Song",
      "Ehsanul Kabir",
      "Shagufta Mehnaz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16141",
    "title": "Brain-Inspired Efficient Pruning: Exploiting Criticality in Spiking  Neural Networks",
    "abstract": "Spiking Neural Networks (SNNs) have been an attractive option for deployment on devices with limited computing resources and lower power consumption because of the event-driven computing characteristic. As such devices have limited computing and storage resources, pruning for SNNs has been widely focused recently. However, the binary and non-differentiable property of spike signals make pruning deep SNNs challenging, so existing methods require high time overhead to make pruning decisions. In this paper, inspired by critical brain hypothesis in neuroscience, we design a regeneration mechanism based on criticality to efficiently obtain the critical pruned networks. Firstly, we propose a low-cost metric for the criticality of pruning structures. Then we re-rank the pruned structures after pruning and regenerate those with higher criticality. We evaluate our method using VGG-16 and ResNet-19 for both unstructured pruning and structured pruning. Our method achieves higher performance compared to current state-of-the-art (SOTA) method with the same time overhead. We also achieve comparable performances (even better on VGG-16) compared to the SOTA method with 11.3x and 15.5x acceleration. Moreover, we investigate underlying mechanism of our method and find that it efficiently selects potential structures, learns the consistent feature representations and reduces the overfitting during the recovery phase. ",
    "url": "https://arxiv.org/abs/2311.16141",
    "authors": [
      "Shuo Chen",
      "Boxiao Liu",
      "Haihang You"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16143",
    "title": "Ransomware Detection and Classification using Machine Learning",
    "abstract": "Vicious assaults, malware, and various ransomware pose a cybersecurity threat, causing considerable damage to computer structures, servers, and mobile and web apps across various industries and businesses. These safety concerns are important and must be addressed immediately. Ransomware detection and classification are critical for guaranteeing rapid reaction and prevention. This study uses the XGBoost classifier and Random Forest (RF) algorithms to detect and classify ransomware attacks. This approach involves analyzing the behaviour of ransomware and extracting relevant features that can help distinguish between different ransomware families. The models are evaluated on a dataset of ransomware attacks and demonstrate their effectiveness in accurately detecting and classifying ransomware. The results show that the XGBoost classifier, Random Forest Classifiers, can effectively detect and classify different ransomware attacks with high accuracy, thereby providing a valuable tool for enhancing cybersecurity. ",
    "url": "https://arxiv.org/abs/2311.16143",
    "authors": [
      "Kavitha Kunku",
      "ANK Zaman",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16148",
    "title": "Univariate Radial Basis Function Layers: Brain-inspired Deep Neural  Layers for Low-Dimensional Inputs",
    "abstract": "Deep Neural Networks (DNNs) became the standard tool for function approximation with most of the introduced architectures being developed for high-dimensional input data. However, many real-world problems have low-dimensional inputs for which standard Multi-Layer Perceptrons (MLPs) are the default choice. An investigation into specialized architectures is missing. We propose a novel DNN layer called Univariate Radial Basis Function (U-RBF) layer as an alternative. Similar to sensory neurons in the brain, the U-RBF layer processes each individual input dimension with a population of neurons whose activations depend on different preferred input values. We verify its effectiveness compared to MLPs in low-dimensional function regressions and reinforcement learning tasks. The results show that the U-RBF is especially advantageous when the target function becomes complex and difficult to approximate. ",
    "url": "https://arxiv.org/abs/2311.16148",
    "authors": [
      "Basavasagar Patil",
      "Xavier Alameda-Pineda",
      "Chris Reinke"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16158",
    "title": "CarbNN: A Novel Active Transfer Learning Neural Network To Build De Novo  Metal Organic Frameworks (MOFs) for Carbon Capture",
    "abstract": "Over the past decade, climate change has become an increasing problem with one of the major contributing factors being carbon dioxide (CO2) emissions; almost 51% of total US carbon emissions are from factories. Current materials used in CO2 capture are lacking either in efficiency, sustainability, or cost. Electrocatalysis of CO2 is a new approach where CO2 can be reduced and the components used industrially as fuel, saving transportation costs, creating financial incentives. Metal Organic Frameworks (MOFs) are crystals made of organo-metals that adsorb, filter, and electrocatalyze CO2. The current available MOFs for capture & electrocatalysis are expensive to manufacture and inefficient at capture. The goal therefore is to computationally design a MOF that can adsorb CO2 and catalyze carbon monoxide & oxygen with low cost. A novel active transfer learning neural network was developed, utilizing transfer learning due to limited available data on 15 MOFs. Using the Cambridge Structural Database with 10,000 MOFs, the model used incremental mutations to fit a trained fitness hyper-heuristic function. Eventually, a Selenium MOF (C18MgO25Se11Sn20Zn5) was converged on. Through analysis of predictions & literature, the converged MOF was shown to be more effective & more synthetically accessible than existing MOFs, showing the model had an understanding of effective electrocatalytic structures in the material space. This novel network can be implemented for other gas separations and catalysis applications that have limited training accessible datasets. ",
    "url": "https://arxiv.org/abs/2311.16158",
    "authors": [
      "Neel Redkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.16167",
    "title": "MMPDE-Net and Moving Sampling Physics-informed Neural Networks Based On  Moving Mesh Method",
    "abstract": "In this work, we propose an end-to-end adaptive sampling neural network (MMPDE-Net) based on the moving mesh PDE method, which can adaptively generate new coordinates of sampling points by solving the moving mesh PDE. This model focuses on improving the efficiency of individual sampling points. Moreover, we have developed an iterative algorithm based on MMPDE-Net, which makes the sampling points more precise and controllable. Since MMPDE-Net is a framework independent of the deep learning solver, we combine it with PINN to propose MS-PINN and demonstrate its effectiveness by performing error analysis under the assumptions given in this paper. Meanwhile, we demonstrate the performance improvement of MS-PINN compared to PINN through numerical experiments on four typical examples to verify the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2311.16167",
    "authors": [
      "Yu Yang",
      "Qihong Yang",
      "Yangtao Deng",
      "Qiaolin He"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16172",
    "title": "Evolutionary Machine Learning and Games",
    "abstract": "Evolutionary machine learning (EML) has been applied to games in multiple ways, and for multiple different purposes. Importantly, AI research in games is not only about playing games; it is also about generating game content, modeling players, and many other applications. Many of these applications pose interesting problems for EML. We will structure this chapter on EML for games based on whether evolution is used to augment machine learning (ML) or ML is used to augment evolution. For completeness, we also briefly discuss the usage of ML and evolution separately in games. ",
    "url": "https://arxiv.org/abs/2311.16172",
    "authors": [
      "Julian Togelius",
      "Ahmed Khalifa",
      "Sam Earle",
      "Michael Cerny Green",
      "Lisa Soros"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16179",
    "title": "Next-gen traffic surveillance: AI-assisted mobile traffic violation  detection system",
    "abstract": "Road traffic accidents pose a significant global public health concern, leading to injuries, fatalities, and vehicle damage. Approximately 1,3 million people lose their lives daily due to traffic accidents [World Health Organization, 2022]. Addressing this issue requires accurate traffic law violation detection systems to ensure adherence to regulations. The integration of Artificial Intelligence algorithms, leveraging machine learning and computer vision, has facilitated the development of precise traffic rule enforcement. This paper illustrates how computer vision and machine learning enable the creation of robust algorithms for detecting various traffic violations. Our model, capable of identifying six common traffic infractions, detects red light violations, illegal use of breakdown lanes, violations of vehicle following distance, breaches of marked crosswalk laws, illegal parking, and parking on marked crosswalks. Utilizing online traffic footage and a self-mounted on-dash camera, we apply the YOLOv5 algorithm's detection module to identify traffic agents such as cars, pedestrians, and traffic signs, and the strongSORT algorithm for continuous interframe tracking. Six discrete algorithms analyze agents' behavior and trajectory to detect violations. Subsequently, an Identification Module extracts vehicle ID information, such as the license plate, to generate violation notices sent to relevant authorities. ",
    "url": "https://arxiv.org/abs/2311.16179",
    "authors": [
      "Dila Dede",
      "Mehmet Ali Sars\u0131l",
      "Ata Shaker",
      "Olgu Alt\u0131nta\u015f",
      "Onur Ergen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.16185",
    "title": "Enhancing Sentiment Analysis Results through Outlier Detection  Optimization",
    "abstract": "When dealing with text data containing subjective labels like speaker emotions, inaccuracies or discrepancies among labelers are not uncommon. Such discrepancies can significantly affect the performance of machine learning algorithms. This study investigates the potential of identifying and addressing outliers in text data with subjective labels, aiming to enhance classification outcomes. We utilized the Deep SVDD algorithm, a one-class classification method, to detect outliers in nine text-based emotion and sentiment analysis datasets. By employing both a small-sized language model (DistilBERT base model with 66 million parameters) and non-deep learning machine learning algorithms (decision tree, KNN, Logistic Regression, and LDA) as the classifier, our findings suggest that the removal of outliers can lead to enhanced results in most cases. Additionally, as outliers in such datasets are not necessarily unlearnable, we experienced utilizing a large language model -- DeBERTa v3 large with 131 million parameters, which can capture very complex patterns in data. We continued to observe performance enhancements across multiple datasets. ",
    "url": "https://arxiv.org/abs/2311.16185",
    "authors": [
      "Yuetian Chen",
      "Mei Si"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.16191",
    "title": "MACE: A Multi-pattern Accommodated and Efficient Anomaly Detection  Method in the Frequency Domain",
    "abstract": "Anomaly detection significantly enhances the robustness of cloud systems. While neural network-based methods have recently demonstrated strong advantages, they encounter practical challenges in cloud environments: the contradiction between the impracticality of maintaining a unique model for each service and the limited ability of dealing with diverse normal patterns by a unified model, as well as issues with handling heavy traffic in real time and short-term anomaly detection sensitivity. Thus, we propose MACE, a Multi-pattern Accommodated and efficient Anomaly detection method in the frequency domain for time series anomaly detection. There are three novel characteristics of it: (i) a pattern extraction mechanism excelling at handling diverse normal patterns, which enables the model to identify anomalies by examining the correlation between the data sample and its service normal pattern, instead of solely focusing on the data sample itself; (ii) a dualistic convolution mechanism that amplifies short-term anomalies in the time domain and hinders the reconstruction of anomalies in the frequency domain, which enlarges the reconstruction error disparity between anomaly and normality and facilitates anomaly detection; (iii) leveraging the sparsity and parallelism of frequency domain to enhance model efficiency. We theoretically and experimentally prove that using a strategically selected subset of Fourier bases can not only reduce computational overhead but is also profit to distinguish anomalies, compared to using the complete spectrum. Moreover, extensive experiments demonstrate MACE's effectiveness in handling diverse normal patterns with a unified model and it achieves state-of-the-art performance with high efficiency. \\end{abstract} ",
    "url": "https://arxiv.org/abs/2311.16191",
    "authors": [
      "Feiyi Chen",
      "Yingying zhang",
      "Zhen Qin",
      "Lunting Fan",
      "Renhe Jiang",
      "Yuxuan Liang",
      "Qingsong Wen",
      "Shuiguang Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.16192",
    "title": "Utilizing Multiple Inputs Autoregressive Models for Bearing Remaining  Useful Life Prediction",
    "abstract": "Accurate prediction of the Remaining Useful Life (RUL) of rolling bearings is crucial in industrial production, yet existing models often struggle with limited generalization capabilities due to their inability to fully process all vibration signal patterns. We introduce a novel multi-input autoregressive model to address this challenge in RUL prediction for bearings. Our approach uniquely integrates vibration signals with previously predicted Health Indicator (HI) values, employing feature fusion to output current window HI values. Through autoregressive iterations, the model attains a global receptive field, effectively overcoming the limitations in generalization. Furthermore, we innovatively incorporate a segmentation method and multiple training iterations to mitigate error accumulation in autoregressive models. Empirical evaluation on the PMH2012 dataset demonstrates that our model, compared to other backbone networks using similar autoregressive approaches, achieves significantly lower Root Mean Square Error (RMSE) and Score. Notably, it outperforms traditional autoregressive models that use label values as inputs and non-autoregressive networks, showing superior generalization abilities with a marked lead in RMSE and Score metrics. ",
    "url": "https://arxiv.org/abs/2311.16192",
    "authors": [
      "Junliang Wang",
      "Qinghua Zhang",
      "Guanhua Zhu",
      "Guoxi Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.16194",
    "title": "BadCLIP: Trigger-Aware Prompt Learning for Backdoor Attacks on CLIP",
    "abstract": "Contrastive Vision-Language Pre-training, known as CLIP, has shown promising effectiveness in addressing downstream image recognition tasks. However, recent works revealed that the CLIP model can be implanted with a downstream-oriented backdoor. On downstream tasks, one victim model performs well on clean samples but predicts a specific target class whenever a specific trigger is present. For injecting a backdoor, existing attacks depend on a large amount of additional data to maliciously fine-tune the entire pre-trained CLIP model, which makes them inapplicable to data-limited scenarios. In this work, motivated by the recent success of learnable prompts, we address this problem by injecting a backdoor into the CLIP model in the prompt learning stage. Our method named BadCLIP is built on a novel and effective mechanism in backdoor attacks on CLIP, i.e., influencing both the image and text encoders with the trigger. It consists of a learnable trigger applied to images and a trigger-aware context generator, such that the trigger can change text features via trigger-aware prompts, resulting in a powerful and generalizable attack. Extensive experiments conducted on 11 datasets verify that the clean accuracy of BadCLIP is similar to those of advanced prompt learning methods and the attack success rate is higher than 99% in most cases. BadCLIP is also generalizable to unseen classes, and shows a strong generalization capability under cross-dataset and cross-domain settings. ",
    "url": "https://arxiv.org/abs/2311.16194",
    "authors": [
      "Jiawang Bai",
      "Kuofeng Gao",
      "Shaobo Min",
      "Shu-Tao Xia",
      "Zhifeng Li",
      "Wei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16198",
    "title": "Ultra-short-term multi-step wind speed prediction for wind farms based  on adaptive noise reduction technology and temporal convolutional network",
    "abstract": "As an important clean and renewable kind of energy, wind power plays an important role in coping with energy crisis and environmental pollution. However, the volatility and intermittency of wind speed restrict the development of wind power. To improve the utilization of wind power, this study proposes a new wind speed prediction model based on data noise reduction technology, temporal convolutional network (TCN), and gated recurrent unit (GRU). Firstly, an adaptive data noise reduction algorithm P-SSA is proposed based on singular spectrum analysis (SSA) and Pearson correlation coefficient. The original wind speed is decomposed into multiple subsequences by SSA and then reconstructed. When the Pearson correlation coefficient between the reconstructed sequence and the original sequence is greater than 0.99, other noise subsequences are deleted to complete the data denoising. Then, the receptive field of the samples is expanded through the causal convolution and dilated convolution of TCN, and the characteristics of wind speed change are extracted. Then, the time feature information of the sequence is extracted by GRU, and then the wind speed is predicted to form the wind speed sequence prediction model of P-SSA-TCN-GRU. The proposed model was validated on three wind farms in Shandong Province. The experimental results show that the prediction performance of the proposed model is better than that of the traditional model and other models based on TCN, and the wind speed prediction of wind farms with high precision and strong stability is realized. The wind speed predictions of this model have the potential to become the data that support the operation and management of wind farms. The code is available at link. ",
    "url": "https://arxiv.org/abs/2311.16198",
    "authors": [
      "Haojian Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2311.16261",
    "title": "RelVAE: Generative Pretraining for few-shot Visual Relationship  Detection",
    "abstract": "Visual relations are complex, multimodal concepts that play an important role in the way humans perceive the world. As a result of their complexity, high-quality, diverse and large scale datasets for visual relations are still absent. In an attempt to overcome this data barrier, we choose to focus on the problem of few-shot Visual Relationship Detection (VRD), a setting that has been so far neglected by the community. In this work we present the first pretraining method for few-shot predicate classification that does not require any annotated relations. We achieve this by introducing a generative model that is able to capture the variation of semantic, visual and spatial information of relations inside a latent space and later exploiting its representations in order to achieve efficient few-shot classification. We construct few-shot training splits and show quantitative experiments on VG200 and VRD datasets where our model outperforms the baselines. Lastly we attempt to interpret the decisions of the model by conducting various qualitative experiments. ",
    "url": "https://arxiv.org/abs/2311.16261",
    "authors": [
      "Sotiris Karapiperis",
      "Markos Diomataris",
      "Vassilis Pitsikalis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.16272",
    "title": "Optimal Observer Design Using Reinforcement Learning and Quadratic  Neural Networks",
    "abstract": "This paper introduces an innovative approach based on policy iteration (PI), a reinforcement learning (RL) algorithm, to obtain an optimal observer with a quadratic cost function. This observer is designed for systems with a given linearized model and a stabilizing Luenberger observer gain. We utilize two-layer quadratic neural networks (QNN) for policy evaluation and derive a linear correction term using the input and output data. This correction term effectively rectifies inaccuracies introduced by the linearized model employed within the observer design. A unique feature of the proposed methodology is that the QNN is trained through convex optimization. The main advantage is that the QNN's input-output mapping has an analytical expression as a quadratic form, which can then be used to obtain a linear correction term policy. This is in stark contrast to the available techniques in the literature that must train a second neural network to obtain policy improvement. It is proven that the obtained linear correction term is optimal for linear systems, as both the value function and the QNN's input-output mapping are quadratic. The proposed method is applied to a simple pendulum, demonstrating an enhanced correction term policy compared to relying solely on the linearized model. This shows its promise for addressing nonlinear systems. ",
    "url": "https://arxiv.org/abs/2311.16272",
    "authors": [
      "Soroush Asri",
      "Luis Rodrigues"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.16277",
    "title": "A Graph Neural Network-Based QUBO-Formulated Hamiltonian-Inspired Loss  Function for Combinatorial Optimization using Reinforcement Learning",
    "abstract": "Quadratic Unconstrained Binary Optimization (QUBO) is a generic technique to model various NP-hard Combinatorial Optimization problems (CO) in the form of binary variables. Ising Hamiltonian is used to model the energy function of a system. QUBO to Ising Hamiltonian is regarded as a technique to solve various canonical optimization problems through quantum optimization algorithms. Recently, PI-GNN, a generic framework, has been proposed to address CO problems over graphs based on Graph Neural Network (GNN) architecture. They introduced a generic QUBO-formulated Hamiltonian-inspired loss function that was directly optimized using GNN. PI-GNN is highly scalable but there lies a noticeable decrease in the number of satisfied constraints when compared to problem-specific algorithms and becomes more pronounced with increased graph densities. Here, We identify a behavioral pattern related to it and devise strategies to improve its performance. Another group of literature uses Reinforcement learning (RL) to solve the aforementioned NP-hard problems using problem-specific reward functions. In this work, we also focus on creating a bridge between the RL-based solutions and the QUBO-formulated Hamiltonian. We formulate and empirically evaluate the compatibility of the QUBO-formulated Hamiltonian as the generic reward function in the RL-based paradigm in the form of rewards. Furthermore, we also introduce a novel Monty Carlo Tree Search-based strategy with GNN where we apply a guided search through manual perturbation of node labels during training. We empirically evaluated our methods and observed up to 44% improvement in the number of constraint violations compared to the PI-GNN. ",
    "url": "https://arxiv.org/abs/2311.16277",
    "authors": [
      "Redwan Ahmed Rizvee",
      "Raheeb Hasan",
      "Md. Mosaddek Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.16292",
    "title": "Student Mastery or AI Deception? Analyzing ChatGPT's Assessment  Proficiency and Evaluating Detection Strategies",
    "abstract": "Generative AI systems such as ChatGPT have a disruptive effect on learning and assessment. Computer science requires practice to develop skills in problem solving and programming that are traditionally developed using assignments. Generative AI has the capability of completing these assignments for students with high accuracy, which dramatically increases the potential for academic integrity issues and students not achieving desired learning outcomes. This work investigates the performance of ChatGPT by evaluating it across three courses (CS1,CS2,databases). ChatGPT completes almost all introductory assessments perfectly. Existing detection methods, such as MOSS and JPlag (based on similarity metrics) and GPTzero (AI detection), have mixed success in identifying AI solutions. Evaluating instructors and teaching assistants using heuristics to distinguish between student and AI code shows that their detection is not sufficiently accurate. These observations emphasize the need for adapting assessments and improved detection methods. ",
    "url": "https://arxiv.org/abs/2311.16292",
    "authors": [
      "Kevin Wang",
      "Seth Akins",
      "Abdallah Mohammed",
      "Ramon Lawrence"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.16304",
    "title": "Robust Self-calibration of Focal Lengths from the Fundamental Matrix",
    "abstract": "The problem of self-calibration of two cameras from a given fundamental matrix is one of the basic problems in geometric computer vision. Under the assumption of known principal points and square pixels, the well-known Bougnoux formula offers a means to compute the two unknown focal lengths. However, in many practical situations, the formula yields inaccurate results due to commonly occurring singularities. Moreover, the estimates are sensitive to noise in the computed fundamental matrix and to the assumed positions of the principal points. In this paper, we therefore propose an efficient and robust iterative method to estimate the focal lengths along with the principal points of the cameras given a fundamental matrix and priors for the estimated camera parameters. In addition, we study a computationally efficient check of models generated within RANSAC that improves the accuracy of the estimated models while reducing the total computational time. Extensive experiments on real and synthetic data show that our iterative method brings significant improvements in terms of the accuracy of the estimated focal lengths over the Bougnoux formula and other state-of-the-art methods, even when relying on inaccurate priors. ",
    "url": "https://arxiv.org/abs/2311.16304",
    "authors": [
      "Viktor Kocur",
      "Daniel Kyselica",
      "Zuzana K\u00fakelov\u00e1"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16312",
    "title": "Domain-Specific Deep Learning Feature Extractor for Diabetic Foot Ulcer  Detection",
    "abstract": "Diabetic Foot Ulcer (DFU) is a condition requiring constant monitoring and evaluations for treatment. DFU patient population is on the rise and will soon outpace the available health resources. Autonomous monitoring and evaluation of DFU wounds is a much-needed area in health care. In this paper, we evaluate and identify the most accurate feature extractor that is the core basis for developing a deep-learning wound detection network. For the evaluation, we used mAP and F1-score on the publicly available DFU2020 dataset. A combination of UNet and EfficientNetb3 feature extractor resulted in the best evaluation among the 14 networks compared. UNet and Efficientnetb3 can be used as the classifier in the development of a comprehensive DFU domain-specific autonomous wound detection pipeline. ",
    "url": "https://arxiv.org/abs/2311.16312",
    "authors": [
      "Reza Basiri",
      "Milos R. Popovic",
      "Shehroz S. Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16328",
    "title": "Target-Free Compound Activity Prediction via Few-Shot Learning",
    "abstract": "Predicting the activities of compounds against protein-based or phenotypic assays using only a few known compounds and their activities is a common task in target-free drug discovery. Existing few-shot learning approaches are limited to predicting binary labels (active/inactive). However, in real-world drug discovery, degrees of compound activity are highly relevant. We study Few-Shot Compound Activity Prediction (FS-CAP) and design a novel neural architecture to meta-learn continuous compound activities across large bioactivity datasets. Our model aggregates encodings generated from the known compounds and their activities to capture assay information. We also introduce a separate encoder for the unknown compound. We show that FS-CAP surpasses traditional similarity-based techniques as well as other state of the art few-shot learning methods on a variety of target-free drug discovery settings and datasets. ",
    "url": "https://arxiv.org/abs/2311.16328",
    "authors": [
      "Peter Eckmann",
      "Jake Anderson",
      "Michael K. Gilson",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2311.16334",
    "title": "Robust Basket Recommendation via Noise-tolerated Graph Contrastive  Learning",
    "abstract": "The growth of e-commerce has seen a surge in popularity of platforms like Amazon, eBay, and Taobao. This has given rise to a unique shopping behavior involving baskets - sets of items purchased together. As a less studied interaction mode in the community, the question of how should shopping basket complement personalized recommendation systems remains under-explored. While previous attempts focused on jointly modeling user purchases and baskets, the distinct semantic nature of these elements can introduce noise when directly integrated. This noise negatively impacts the model's performance, further exacerbated by significant noise within both user and basket behaviors. In order to cope with the above difficulties, we propose a novel Basket recommendation framework via Noise-tolerated Contrastive Learning, named BNCL, to handle the noise existing in the cross-behavior integration and within-behavior modeling. First, we represent the basket-item interactions as the hypergraph to model the complex basket behavior, where all items appearing in the same basket are treated as a single hyperedge. Second, cross-behavior contrastive learning is designed to suppress the noise during the fusion of diverse behaviors. Next, to further inhibit the within-behavior noise of the user and basket interactions, we propose to exploit invariant properties of the recommenders w.r.t augmentations through within-behavior contrastive learning. A novel consistency-aware augmentation approach is further designed to better identify noisy interactions with the consideration of the above two types of interactions. Our framework BNCL offers a generic training paradigm that is applicable to different backbones. Extensive experiments on three shopping transaction datasets verify the effectiveness of our proposed method. Our code is available. ",
    "url": "https://arxiv.org/abs/2311.16334",
    "authors": [
      "Xinrui He",
      "Tianxin Wei",
      "Jingrui He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2311.16344",
    "title": "Spatially Adaptive Cloth Regression with Implicit Neural Representations",
    "abstract": "The accurate representation of fine-detailed cloth wrinkles poses significant challenges in computer graphics. The inherently non-uniform structure of cloth wrinkles mandates the employment of intricate discretization strategies, which are frequently characterized by high computational demands and complex methodologies. Addressing this, the research introduced in this paper elucidates a novel anisotropic cloth regression technique that capitalizes on the potential of implicit neural representations of surfaces. Our first core contribution is an innovative mesh-free sampling approach, crafted to reduce the reliance on traditional mesh structures, thereby offering greater flexibility and accuracy in capturing fine cloth details. Our second contribution is a novel adversarial training scheme, which is designed meticulously to strike a harmonious balance between the sampling and simulation objectives. The adversarial approach ensures that the wrinkles are represented with high fidelity, while also maintaining computational efficiency. Our results showcase through various cloth-object interaction scenarios that our method, given the same memory constraints, consistently surpasses traditional discrete representations, particularly when modelling highly-detailed localized wrinkles. ",
    "url": "https://arxiv.org/abs/2311.16344",
    "authors": [
      "Lei Shu",
      "Vinicius Azevedo",
      "Barbara Solenthaler",
      "Markus Gross"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2311.16346",
    "title": "Small and Dim Target Detection in IR Imagery: A Review",
    "abstract": "While there has been significant progress in object detection using conventional image processing and machine learning algorithms, exploring small and dim target detection in the IR domain is a relatively new area of study. The majority of small and dim target detection methods are derived from conventional object detection algorithms, albeit with some alterations. The task of detecting small and dim targets in IR imagery is complex. This is because these targets often need distinct features, the background is cluttered with unclear details, and the IR signatures of the scene can change over time due to fluctuations in thermodynamics. The primary objective of this review is to highlight the progress made in this field. This is the first review in the field of small and dim target detection in infrared imagery, encompassing various methodologies ranging from conventional image processing to cutting-edge deep learning-based approaches. The authors have also introduced a taxonomy of such approaches. There are two main types of approaches: methodologies using several frames for detection, and single-frame-based detection techniques. Single frame-based detection techniques encompass a diverse range of methods, spanning from traditional image processing-based approaches to more advanced deep learning methodologies. Our findings indicate that deep learning approaches perform better than traditional image processing-based approaches. In addition, a comprehensive compilation of various available datasets has also been provided. Furthermore, this review identifies the gaps and limitations in existing techniques, paving the way for future research and development in this area. ",
    "url": "https://arxiv.org/abs/2311.16346",
    "authors": [
      "Nikhil Kumar",
      "Pravendra Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16361",
    "title": "Making Self-supervised Learning Robust to Spurious Correlation via  Learning-speed Aware Sampling",
    "abstract": "Self-supervised learning (SSL) has emerged as a powerful technique for learning rich representations from unlabeled data. The data representations are able to capture many underlying attributes of data, and be useful in downstream prediction tasks. In real-world settings, spurious correlations between some attributes (e.g. race, gender and age) and labels for downstream tasks often exist, e.g. cancer is usually more prevalent among elderly patients. In this paper, we investigate SSL in the presence of spurious correlations and show that the SSL training loss can be minimized by capturing only a subset of the conspicuous features relevant to those sensitive attributes, despite the presence of other important predictive features for the downstream tasks. To address this issue, we investigate the learning dynamics of SSL and observe that the learning is slower for samples that conflict with such correlations (e.g. elder patients without cancer). Motivated by these findings, we propose a learning-speed aware SSL (LA-SSL) approach, in which we sample each training data with a probability that is inversely related to its learning speed. We evaluate LA-SSL on three datasets that exhibit spurious correlations between different attributes, demonstrating that it improves the robustness of pretrained representations on downstream classification tasks. ",
    "url": "https://arxiv.org/abs/2311.16361",
    "authors": [
      "Weicheng Zhu",
      "Sheng Liu",
      "Carlos Fernandez-Granda",
      "Narges Razavian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16374",
    "title": "Physics-Informed Neural Network for Discovering Systems with  Unmeasurable States with Application to Lithium-Ion Batteries",
    "abstract": "Combining machine learning with physics is a trending approach for discovering unknown dynamics, and one of the most intensively studied frameworks is the physics-informed neural network (PINN). However, PINN often fails to optimize the network due to its difficulty in concurrently minimizing multiple losses originating from the system's governing equations. This problem can be more serious when the system's states are unmeasurable, like lithium-ion batteries (LiBs). In this work, we introduce a robust method for training PINN that uses fewer loss terms and thus constructs a less complex landscape for optimization. In particular, instead of having loss terms from each differential equation, this method embeds the dynamics into a loss function that quantifies the error between observed and predicted system outputs. This is accomplished by numerically integrating the predicted states from the neural network(NN) using known dynamics and transforming them to obtain a sequence of predicted outputs. Minimizing such a loss optimizes the NN to predict states consistent with observations given the physics. Further, the system's parameters can be added to the optimization targets. To demonstrate the ability of this method to perform various modeling and control tasks, we apply it to a battery model to concurrently estimate its states and parameters. ",
    "url": "https://arxiv.org/abs/2311.16374",
    "authors": [
      "Yuichi Kajiura",
      "Jorge Espin",
      "Dong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.16378",
    "title": "Bayesian Formulations for Graph Spectral Denoising",
    "abstract": "We consider noisy signals which are defined on the vertices of a graph and present smoothing algorithms for the cases of Gaussian, dropout, and uniformly distributed noise. The signals are assumed to follow a prior distribution defined in the frequency domain which favors signals which are smooth across the edges of the graph. By pairing this prior distribution with our three models of noise generation, we propose \\textit{Maximum A Posteriori} (M.A.P.) estimates of the true signal in the presence of noisy data and provide algorithms for computing the M.A.P. Finally, we demonstrate the algorithms' ability to effectively restore white noise on image data, and from severe dropout in toy \\& EHR data. ",
    "url": "https://arxiv.org/abs/2311.16378",
    "authors": [
      "Sam Leone",
      "Xingzhi Sun",
      "Michael Perlmutter",
      "Smita Krishnaswamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.16383",
    "title": "\"Do Users fall for Real Adversarial Phishing?\" Investigating the Human  response to Evasive Webpages",
    "abstract": "Phishing websites are everywhere, and countermeasures based on static blocklists cannot cope with such a threat. To address this problem, state-of-the-art solutions entail the application of machine learning (ML) to detect phishing websites by checking if they visually resemble webpages of well-known brands. These techniques have achieved promising results in research and, consequently, some security companies began to deploy them also in their phishing detection systems (PDS). However, ML methods are not perfect and some samples are bound to bypass even production-grade PDS. In this paper, we scrutinize whether 'genuine phishing websites' that evade 'commercial ML-based PDS' represent a problem \"in reality\". Although nobody likes landing on a phishing webpage, a false negative may not lead to serious consequences if the users (i.e., the actual target of phishing) can recognize that \"something is phishy\". Practically, we carry out the first user-study (N=126) wherein we assess whether unsuspecting users (having diverse backgrounds) are deceived by 'adversarial' phishing webpages that evaded a real PDS. We found that some well-crafted adversarial webpages can trick most participants (even IT experts), albeit others are easily recognized by most users. Our study is relevant for practitioners, since it allows prioritizing phishing webpages that simultaneously fool (i) machines and (ii) humans -- i.e., their intended targets. ",
    "url": "https://arxiv.org/abs/2311.16383",
    "authors": [
      "Ajka Draganovic",
      "Savino Dambra",
      "Javier Aldana Iuit",
      "Kevin Roundy",
      "Giovanni Apruzzese"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.16396",
    "title": "Toward Effective Secure Code Reviews: An Empirical Study of  Security-Related Coding Weaknesses",
    "abstract": "Identifying security issues early is encouraged to reduce the latent negative impacts on software systems. Code review is a widely-used method that allows developers to manually inspect modified code, catching security issues during a software development cycle. However, existing code review studies often focus on known vulnerabilities, neglecting coding weaknesses, which can introduce real-world security issues that are more visible through code review. The practices of code reviews in identifying such coding weaknesses are not yet fully investigated. To better understand this, we conducted an empirical case study in two large open-source projects, OpenSSL and PHP. Based on 135,560 code review comments, we found that reviewers raised security concerns in 35 out of 40 coding weakness categories. Surprisingly, some coding weaknesses related to past vulnerabilities, such as memory errors and resource management, were discussed less often than the vulnerabilities. Developers attempted to address raised security concerns in many cases (39%-41%), but a substantial portion was merely acknowledged (30%-36%), and some went unfixed due to disagreements about solutions (18%-20%). This highlights that coding weaknesses can slip through code review even when identified. Our findings suggest that reviewers can identify various coding weaknesses leading to security issues during code reviews. However, these results also reveal shortcomings in current code review practices, indicating the need for more effective mechanisms or support for increasing awareness of security issue management in code reviews. ",
    "url": "https://arxiv.org/abs/2311.16396",
    "authors": [
      "Wachiraphan Charoenwet",
      "Patanamon Thongtanunam",
      "Van-Thuan Pham",
      "Christoph Treude"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2311.16409",
    "title": "A Deep Q-Learning based, Base-Station Connectivity-Aware, Decentralized  Pheromone Mobility Model for Autonomous UAV Networks",
    "abstract": "UAV networks consisting of low SWaP (size, weight, and power), fixed-wing UAVs are used in many applications, including area monitoring, search and rescue, surveillance, and tracking. Performing these operations efficiently requires a scalable, decentralized, autonomous UAV network architecture with high network connectivity. Whereas fast area coverage is needed for quickly sensing the area, strong node degree and base station (BS) connectivity are needed for UAV control and coordination and for transmitting sensed information to the BS in real time. However, the area coverage and connectivity exhibit a fundamental trade-off: maintaining connectivity restricts the UAVs' ability to explore. In this paper, we first present a node degree and BS connectivity-aware distributed pheromone (BS-CAP) mobility model to autonomously coordinate the UAV movements in a decentralized UAV network. This model maintains a desired connectivity among 1-hop neighbors and to the BS while achieving fast area coverage. Next, we propose a deep Q-learning policy based BS-CAP model (BSCAP-DQN) to further tune and improve the coverage and connectivity trade-off. Since it is not practical to know the complete topology of such a network in real time, the proposed mobility models work online, are fully distributed, and rely on neighborhood information. Our simulations demonstrate that both proposed models achieve efficient area coverage and desired node degree and BS connectivity, improving significantly over existing schemes. ",
    "url": "https://arxiv.org/abs/2311.16409",
    "authors": [
      "Shreyas Devaraju",
      "Alexander Ihler",
      "Sunil Kumar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.16410",
    "title": "Reduced-order modeling for parameterized PDEs via implicit neural  representations",
    "abstract": "We present a new data-driven reduced-order modeling approach to efficiently solve parametrized partial differential equations (PDEs) for many-query problems. This work is inspired by the concept of implicit neural representation (INR), which models physics signals in a continuous manner and independent of spatial/temporal discretization. The proposed framework encodes PDE and utilizes a parametrized neural ODE (PNODE) to learn latent dynamics characterized by multiple PDE parameters. PNODE can be inferred by a hypernetwork to reduce the potential difficulties in learning PNODE due to a complex multilayer perceptron (MLP). The framework uses an INR to decode the latent dynamics and reconstruct accurate PDE solutions. Further, a physics-informed loss is also introduced to correct the prediction of unseen parameter instances. Incorporating the physics-informed loss also enables the model to be fine-tuned in an unsupervised manner on unseen PDE parameters. A numerical experiment is performed on a two-dimensional Burgers equation with a large variation of PDE parameters. We evaluate the proposed method at a large Reynolds number and obtain up to speedup of O(10^3) and ~1% relative error to the ground truth values. ",
    "url": "https://arxiv.org/abs/2311.16410",
    "authors": [
      "Tianshu Wen",
      "Kookjin Lee",
      "Youngsoo Choi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2311.16416",
    "title": "A Combinatorial Approach to Robust PCA",
    "abstract": "We study the problem of recovering Gaussian data under adversarial corruptions when the noises are low-rank and the corruptions are on the coordinate level. Concretely, we assume that the Gaussian noises lie in an unknown $k$-dimensional subspace $U \\subseteq \\mathbb{R}^d$, and $s$ randomly chosen coordinates of each data point fall into the control of an adversary. This setting models the scenario of learning from high-dimensional yet structured data that are transmitted through a highly-noisy channel, so that the data points are unlikely to be entirely clean. Our main result is an efficient algorithm that, when $ks^2 = O(d)$, recovers every single data point up to a nearly-optimal $\\ell_1$ error of $\\tilde O(ks/d)$ in expectation. At the core of our proof is a new analysis of the well-known Basis Pursuit (BP) method for recovering a sparse signal, which is known to succeed under additional assumptions (e.g., incoherence or the restricted isometry property) on the underlying subspace $U$. In contrast, we present a novel approach via studying a natural combinatorial problem and show that, over the randomness in the support of the sparse signal, a high-probability error bound is possible even if the subspace $U$ is arbitrary. ",
    "url": "https://arxiv.org/abs/2311.16416",
    "authors": [
      "Weihao Kong",
      "Mingda Qiao",
      "Rajat Sen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.16417",
    "title": "Challenges and Opportunities to Enable Large-Scale Computing via  Heterogeneous Chiplets",
    "abstract": "Fast-evolving artificial intelligence (AI) algorithms such as large language models have been driving the ever-increasing computing demands in today's data centers. Heterogeneous computing with domain-specific architectures (DSAs) brings many opportunities when scaling up and scaling out the computing system. In particular, heterogeneous chiplet architecture is favored to keep scaling up and scaling out the system as well as to reduce the design complexity and the cost stemming from the traditional monolithic chip design. However, how to interconnect computing resources and orchestrate heterogeneous chiplets is the key to success. In this paper, we first discuss the diversity and evolving demands of different AI workloads. We discuss how chiplet brings better cost efficiency and shorter time to market. Then we discuss the challenges in establishing chiplet interface standards, packaging, and security issues. We further discuss the software programming challenges in chiplet systems. ",
    "url": "https://arxiv.org/abs/2311.16417",
    "authors": [
      "Zhuoping Yang",
      "Shixin Ji",
      "Xingzhen Chen",
      "Jinming Zhuang",
      "Weifeng Zhang",
      "Dharmesh Jani",
      "Peipei Zhou"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2311.16420",
    "title": "Model-free Test Time Adaptation for Out-Of-Distribution Detection",
    "abstract": "Out-of-distribution (OOD) detection is essential for the reliability of ML models. Most existing methods for OOD detection learn a fixed decision criterion from a given in-distribution dataset and apply it universally to decide if a data point is OOD. Recent work~\\cite{fang2022is} shows that given only in-distribution data, it is impossible to reliably detect OOD data without extra assumptions. Motivated by the theoretical result and recent exploration of test-time adaptation methods, we propose a Non-Parametric Test Time \\textbf{Ada}ptation framework for \\textbf{O}ut-Of-\\textbf{D}istribution \\textbf{D}etection (\\abbr). Unlike conventional methods, \\abbr utilizes online test samples for model adaptation during testing, enhancing adaptability to changing data distributions. The framework incorporates detected OOD instances into decision-making, reducing false positive rates, particularly when ID and OOD distributions overlap significantly. We demonstrate the effectiveness of \\abbr through comprehensive experiments on multiple OOD detection benchmarks, extensive empirical studies show that \\abbr significantly improves the performance of OOD detection over state-of-the-art methods. Specifically, \\abbr reduces the false positive rate (FPR95) by $23.23\\%$ on the CIFAR-10 benchmarks and $38\\%$ on the ImageNet-1k benchmarks compared to the advanced methods. Lastly, we theoretically verify the effectiveness of \\abbr. ",
    "url": "https://arxiv.org/abs/2311.16420",
    "authors": [
      "YiFan Zhang",
      "Xue Wang",
      "Tian Zhou",
      "Kun Yuan",
      "Zhang Zhang",
      "Liang Wang",
      "Rong Jin",
      "Tieniu Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16431",
    "title": "An exact mathematical description of computation with transient  spatiotemporal dynamics in a complex-valued neural network",
    "abstract": "We study a complex-valued neural network (cv-NN) with linear, time-delayed interactions. We report the cv-NN displays sophisticated spatiotemporal dynamics, including partially synchronized ``chimera'' states. We then use these spatiotemporal dynamics, in combination with a nonlinear readout, for computation. The cv-NN can instantiate dynamics-based logic gates, encode short-term memories, and mediate secure message passing through a combination of interactions and time delays. The computations in this system can be fully described in an exact, closed-form mathematical expression. Finally, using direct intracellular recordings of neurons in slices from neocortex, we demonstrate that computations in the cv-NN are decodable by living biological neurons. These results demonstrate that complex-valued linear systems can perform sophisticated computations, while also being exactly solvable. Taken together, these results open future avenues for design of highly adaptable, bio-hybrid computing systems that can interface seamlessly with other neural networks. ",
    "url": "https://arxiv.org/abs/2311.16431",
    "authors": [
      "Roberto C. Budzinski",
      "Alexandra N. Busch",
      "Samuel Mestern",
      "Erwan Martin",
      "Luisa H. B. Liboni",
      "Federico W. Pasini",
      "J\u00e1n Min\u00e1\u010d",
      "Todd Coleman",
      "Wataru Inoue",
      "Lyle E. Muller"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.16445",
    "title": "CLAP: Contrastive Learning with Augmented Prompts for Robustness on  Pretrained Vision-Language Models",
    "abstract": "Contrastive vision-language models, e.g., CLIP, have garnered substantial attention for their exceptional generalization capabilities. However, their robustness to perturbations has ignited concerns. Existing strategies typically reinforce their resilience against adversarial examples by enabling the image encoder to \"see\" these perturbed examples, often necessitating a complete retraining of the image encoder on both natural and adversarial samples. In this study, we propose a new method to enhance robustness solely through text augmentation, eliminating the need for retraining the image encoder on adversarial examples. Our motivation arises from the realization that text and image data inherently occupy a shared latent space, comprising latent content variables and style variables. This insight suggests the feasibility of learning to disentangle these latent content variables using text data exclusively. To accomplish this, we introduce an effective text augmentation method that focuses on modifying the style while preserving the content in the text data. By changing the style part of the text data, we empower the text encoder to emphasize latent content variables, ultimately enhancing the robustness of vision-language models. Our experiments across various datasets demonstrate substantial improvements in the robustness of the pre-trained CLIP model. ",
    "url": "https://arxiv.org/abs/2311.16445",
    "authors": [
      "Yichao Cai",
      "Yuhang Liu",
      "Zhen Zhang",
      "Javen Qinfeng Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16446",
    "title": "Centre Stage: Centricity-based Audio-Visual Temporal Action Detection",
    "abstract": "Previous one-stage action detection approaches have modelled temporal dependencies using only the visual modality. In this paper, we explore different strategies to incorporate the audio modality, using multi-scale cross-attention to fuse the two modalities. We also demonstrate the correlation between the distance from the timestep to the action centre and the accuracy of the predicted boundaries. Thus, we propose a novel network head to estimate the closeness of timesteps to the action centre, which we call the centricity score. This leads to increased confidence for proposals that exhibit more precise boundaries. Our method can be integrated with other one-stage anchor-free architectures and we demonstrate this on three recent baselines on the EPIC-Kitchens-100 action detection benchmark where we achieve state-of-the-art performance. Detailed ablation studies showcase the benefits of fusing audio and our proposed centricity scores. Code and models for our proposed method are publicly available at https://github.com/hanielwang/Audio-Visual-TAD.git ",
    "url": "https://arxiv.org/abs/2311.16446",
    "authors": [
      "Hanyuan Wang",
      "Majid Mirmehdi",
      "Dima Damen",
      "Toby Perrett"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16450",
    "title": "Typhoon Intensity Prediction with Vision Transformer",
    "abstract": "Predicting typhoon intensity accurately across space and time is crucial for issuing timely disaster warnings and facilitating emergency response. This has vast potential for minimizing life losses and property damages as well as reducing economic and environmental impacts. Leveraging satellite imagery for scenario analysis is effective but also introduces additional challenges due to the complex relations among clouds and the highly dynamic context. Existing deep learning methods in this domain rely on convolutional neural networks (CNNs), which suffer from limited per-layer receptive fields. This limitation hinders their ability to capture long-range dependencies and global contextual knowledge during inference. In response, we introduce a novel approach, namely \"Typhoon Intensity Transformer\" (Tint), which leverages self-attention mechanisms with global receptive fields per layer. Tint adopts a sequence-to-sequence feature representation learning perspective. It begins by cutting a given satellite image into a sequence of patches and recursively employs self-attention operations to extract both local and global contextual relations between all patch pairs simultaneously, thereby enhancing per-patch feature representation learning. Extensive experiments on a publicly available typhoon benchmark validate the efficacy of Tint in comparison with both state-of-the-art deep learning and conventional meteorological methods. Our code is available at https://github.com/chen-huanxin/Tint. ",
    "url": "https://arxiv.org/abs/2311.16450",
    "authors": [
      "Huanxin Chen",
      "Pengshuai Yin",
      "Huichou Huang",
      "Qingyao Wu",
      "Ruirui Liu",
      "Xiatian Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.16456",
    "title": "Spiking Neural Networks with Dynamic Time Steps for Vision Transformers",
    "abstract": "Spiking Neural Networks (SNNs) have emerged as a popular spatio-temporal computing paradigm for complex vision tasks. Recently proposed SNN training algorithms have significantly reduced the number of time steps (down to 1) for improved latency and energy efficiency, however, they target only convolutional neural networks (CNN). These algorithms, when applied on the recently spotlighted vision transformers (ViT), either require a large number of time steps or fail to converge. Based on analysis of the histograms of the ANN and SNN activation maps, we hypothesize that each ViT block has a different sensitivity to the number of time steps. We propose a novel training framework that dynamically allocates the number of time steps to each ViT module depending on a trainable score assigned to each timestep. In particular, we generate a scalar binary time step mask that filters spikes emitted by each neuron in a leaky-integrate-and-fire (LIF) layer. The resulting SNNs have high activation sparsity and require only accumulate operations (AC), except for the input embedding layer, in contrast to expensive multiply-and-accumulates (MAC) needed in traditional ViTs. This yields significant improvements in energy efficiency. We evaluate our training framework and resulting SNNs on image recognition tasks including CIFAR10, CIFAR100, and ImageNet with different ViT architectures. We obtain a test accuracy of 95.97% with 4.97 time steps with direct encoding on CIFAR10. ",
    "url": "https://arxiv.org/abs/2311.16456",
    "authors": [
      "Gourav Datta",
      "Zeyu Liu",
      "Anni Li",
      "Peter A. Beerel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2311.16462",
    "title": "Viewport Prediction for Volumetric Video Streaming by Exploring Video  Saliency and Trajectory Information",
    "abstract": "Volumetric video, also known as hologram video, is a novel medium that portrays natural content in Virtual Reality (VR), Augmented Reality (AR), and Mixed Reality (MR). It is expected to be the next-gen video technology and a prevalent use case for 5G and beyond wireless communication. Considering that each user typically only watches a section of the volumetric video, known as the viewport, it is essential to have precise viewport prediction for optimal performance. However, research on this topic is still in its infancy. In the end, this paper presents and proposes a novel approach, named Saliency and Trajectory Viewport Prediction (STVP), which aims to improve the precision of viewport prediction in volumetric video streaming. The STVP extensively utilizes video saliency information and viewport trajectory. To our knowledge, this is the first comprehensive study of viewport prediction in volumetric video streaming. In particular, we introduce a novel sampling method, Uniform Random Sampling (URS), to reduce computational complexity while still preserving video features in an efficient manner. Then we present a saliency detection technique that incorporates both spatial and temporal information for detecting static, dynamic geometric, and color salient regions. Finally, we intelligently fuse saliency and trajectory information to achieve more accurate viewport prediction. We conduct extensive simulations to evaluate the effectiveness of our proposed viewport prediction methods using state-of-the-art volumetric video sequences. The experimental results show the superiority of the proposed method over existing schemes. The dataset and source code will be publicly accessible after acceptance. ",
    "url": "https://arxiv.org/abs/2311.16462",
    "authors": [
      "Jie Li",
      "Zhixin Li",
      "Zhi Liu",
      "Pengyuan Zhou",
      "Richang Hong",
      "Qiyue Li",
      "Han Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2311.16464",
    "title": "Bridging the Gap: A Unified Video Comprehension Framework for Moment  Retrieval and Highlight Detection",
    "abstract": "Video Moment Retrieval (MR) and Highlight Detection (HD) have attracted significant attention due to the growing demand for video analysis. Recent approaches treat MR and HD as similar video grounding problems and address them together with transformer-based architecture. However, we observe that the emphasis of MR and HD differs, with one necessitating the perception of local relationships and the other prioritizing the understanding of global contexts. Consequently, the lack of task-specific design will inevitably lead to limitations in associating the intrinsic specialty of two tasks. To tackle the issue, we propose a Unified Video COMprehension framework (UVCOM) to bridge the gap and jointly solve MR and HD effectively. By performing progressive integration on intra and inter-modality across multi-granularity, UVCOM achieves the comprehensive understanding in processing a video. Moreover, we present multi-aspect contrastive learning to consolidate the local relation modeling and global knowledge accumulation via well aligned multi-modal space. Extensive experiments on QVHighlights, Charades-STA, TACoS , YouTube Highlights and TVSum datasets demonstrate the effectiveness and rationality of UVCOM which outperforms the state-of-the-art methods by a remarkable margin. ",
    "url": "https://arxiv.org/abs/2311.16464",
    "authors": [
      "Yicheng Xiao",
      "Zhuoyan Luo",
      "Yong Liu",
      "Yue Ma",
      "Hengwei Bian",
      "Yatai Ji",
      "Yujiu Yang",
      "Xiu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.16474",
    "title": "Progressive Target-Styled Feature Augmentation for Unsupervised Domain  Adaptation on Point Clouds",
    "abstract": "Unsupervised domain adaptation is a critical challenge in the field of point cloud analysis, as models trained on one set of data often struggle to perform well in new scenarios due to domain shifts. Previous works tackle the problem by using adversarial training or self-supervised learning for feature extractor adaptation, but ensuring that features extracted from the target domain can be distinguished by the source-supervised classifier remains challenging. In this work, we propose a novel approach called progressive target-styled feature augmentation (PTSFA). Unlike previous works that focus on feature extractor adaptation, our PTSFA approach focuses on classifier adaptation. It aims to empower the classifier to recognize target-styled source features and progressively adapt to the target domain. To enhance the reliability of predictions within the PTSFA framework and encourage discriminative feature extraction, we further introduce a new intermediate domain approaching (IDA) strategy. We validate our method on the benchmark datasets, where our method achieves new state-of-the-art performance. Our code is available at https://github.com/xiaoyao3302/PTSFA. ",
    "url": "https://arxiv.org/abs/2311.16474",
    "authors": [
      "Zicheng Wang",
      "Zhen Zhao",
      "Yiming Wu",
      "Luping Zhou",
      "Dong Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16475",
    "title": "Generating Human-Centric Visual Cues for Human-Object Interaction  Detection via Large Vision-Language Models",
    "abstract": "Human-object interaction (HOI) detection aims at detecting human-object pairs and predicting their interactions. However, the complexity of human behavior and the diverse contexts in which these interactions occur make it challenging. Intuitively, human-centric visual cues, such as the involved participants, the body language, and the surrounding environment, play crucial roles in shaping these interactions. These cues are particularly vital in interpreting unseen interactions. In this paper, we propose three prompts with VLM to generate human-centric visual cues within an image from multiple perspectives of humans. To capitalize on these rich Human-Centric Visual Cues, we propose a novel approach named HCVC for HOI detection. Particularly, we develop a transformer-based multimodal fusion module with multitower architecture to integrate visual cue features into the instance and interaction decoders. Our extensive experiments and analysis validate the efficacy of leveraging the generated human-centric visual cues for HOI detection. Notably, the experimental results indicate the superiority of the proposed model over the existing state-of-the-art methods on two widely used datasets. ",
    "url": "https://arxiv.org/abs/2311.16475",
    "authors": [
      "Yu-Wei Zhan",
      "Fan Liu",
      "Xin Luo",
      "Liqiang Nie",
      "Xin-Shun Xu",
      "Mohan Kankanhalli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16476",
    "title": "LANS: A Layout-Aware Neural Solver for Plane Geometry Problem",
    "abstract": "Geometry problem solving (GPS) is a challenging mathematical reasoning task requiring multi-modal understanding, fusion and reasoning. Existing neural solvers take GPS as a vision-language task but be short in the representation of geometry diagrams which carry rich and complex layout information. In this paper, we propose a layout-aware neural solver named LANS, integrated with two new modules: multimodal layout-aware pre-trained language model (MLA-PLM) and layout-aware fusion attention (LA-FA). MLA-PLM adopts structural and semantic pre-training (SSP) to implement global relationship modeling, and point matching pre-training (PMP) to achieve alignment between visual points and textual points. LA-FA employs a layout-aware attention mask to realize point-guided cross-modal fusion for further boosting layout awareness of LANS. Extensive experiments on datasets Geometry3K and PGPS9K validate the effectiveness of the layout-aware modules and superior problem solving performance of our LANS solver, over existing symbolic solvers and neural solvers. The code will make public available soon. ",
    "url": "https://arxiv.org/abs/2311.16476",
    "authors": [
      "Ming-Liang Zhang",
      "Zhong-Zhi Li",
      "Fei Yin",
      "Cheng-Lin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.16478",
    "title": "RetouchUAA: Unconstrained Adversarial Attack via Image Retouching",
    "abstract": "Deep Neural Networks (DNNs) are susceptible to adversarial examples. Conventional attacks generate controlled noise-like perturbations that fail to reflect real-world scenarios and hard to interpretable. In contrast, recent unconstrained attacks mimic natural image transformations occurring in the real world for perceptible but inconspicuous attacks, yet compromise realism due to neglect of image post-processing and uncontrolled attack direction. In this paper, we propose RetouchUAA, an unconstrained attack that exploits a real-life perturbation: image retouching styles, highlighting its potential threat to DNNs. Compared to existing attacks, RetouchUAA offers several notable advantages. Firstly, RetouchUAA excels in generating interpretable and realistic perturbations through two key designs: the image retouching attack framework and the retouching style guidance module. The former custom-designed human-interpretability retouching framework for adversarial attack by linearizing images while modelling the local processing and retouching decision-making in human retouching behaviour, provides an explicit and reasonable pipeline for understanding the robustness of DNNs against retouching. The latter guides the adversarial image towards standard retouching styles, thereby ensuring its realism. Secondly, attributed to the design of the retouching decision regularization and the persistent attack strategy, RetouchUAA also exhibits outstanding attack capability and defense robustness, posing a heavy threat to DNNs. Experiments on ImageNet and Place365 reveal that RetouchUAA achieves nearly 100\\% white-box attack success against three DNNs, while achieving a better trade-off between image naturalness, transferability and defense robustness than baseline attacks. ",
    "url": "https://arxiv.org/abs/2311.16478",
    "authors": [
      "Mengda Xie",
      "Yiling He",
      "Meie Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16487",
    "title": "On the Robustness of Decision-Focused Learning",
    "abstract": "Decision-Focused Learning (DFL) is an emerging learning paradigm that tackles the task of training a machine learning (ML) model to predict missing parameters of an incomplete optimization problem, where the missing parameters are predicted. DFL trains an ML model in an end-to-end system, by integrating the prediction and optimization tasks, providing better alignment of the training and testing objectives. DFL has shown a lot of promise and holds the capacity to revolutionize decision-making in many real-world applications. However, very little is known about the performance of these models under adversarial attacks. We adopt ten unique DFL methods and benchmark their performance under two distinctly focused attacks adapted towards the Predict-then-Optimize problem setting. Our study proposes the hypothesis that the robustness of a model is highly correlated with its ability to find predictions that lead to optimal decisions without deviating from the ground-truth label. Furthermore, we provide insight into how to target the models that violate this condition and show how these models respond differently depending on the achieved optimality at the end of their training cycles. ",
    "url": "https://arxiv.org/abs/2311.16487",
    "authors": [
      "Yehya Farhat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2311.16492",
    "title": "VLPrompt: Vision-Language Prompting for Panoptic Scene Graph Generation",
    "abstract": "Panoptic Scene Graph Generation (PSG) aims at achieving a comprehensive image understanding by simultaneously segmenting objects and predicting relations among objects. However, the long-tail problem among relations leads to unsatisfactory results in real-world applications. Prior methods predominantly rely on vision information or utilize limited language information, such as object or relation names, thereby overlooking the utility of language information. Leveraging the recent progress in Large Language Models (LLMs), we propose to use language information to assist relation prediction, particularly for rare relations. To this end, we propose the Vision-Language Prompting (VLPrompt) model, which acquires vision information from images and language information from LLMs. Then, through a prompter network based on attention mechanism, it achieves precise relation prediction. Our extensive experiments show that VLPrompt significantly outperforms previous state-of-the-art methods on the PSG dataset, proving the effectiveness of incorporating language information and alleviating the long-tail problem of relations. ",
    "url": "https://arxiv.org/abs/2311.16492",
    "authors": [
      "Zijian Zhou",
      "Miaojing Shi",
      "Holger Caesar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16496",
    "title": "Leveraging Out-of-Domain Data for Domain-Specific Prompt Tuning in  Multi-Modal Fake News Detection",
    "abstract": "The spread of fake news using out-of-context images has become widespread and is a challenging task in this era of information overload. Since annotating huge amounts of such data requires significant time of domain experts, it is imperative to develop methods which can work in limited annotated data scenarios. In this work, we explore whether out-of-domain data can help to improve out-of-context misinformation detection (termed here as multi-modal fake news detection) of a desired domain, eg. politics, healthcare, etc. Towards this goal, we propose a novel framework termed DPOD (Domain-specific Prompt-tuning using Out-of-Domain data). First, to compute generalizable features, we modify the Vision-Language Model, CLIP to extract features that helps to align the representations of the images and corresponding text captions of both the in-domain and out-of-domain data in a label-aware manner. Further, we propose a domain-specific prompt learning technique which leverages the training samples of all the available domains based on the the extent they can be useful to the desired domain. Extensive experiments on a large-scale benchmark dataset, namely NewsClippings demonstrate that the proposed framework achieves state of-the-art performance, significantly surpassing the existing approaches for this challenging task. ",
    "url": "https://arxiv.org/abs/2311.16496",
    "authors": [
      "Debarshi Brahma",
      "Amartya Bhattacharya",
      "Suraj Nagaje Mahadev",
      "Anmol Asati",
      "Vikas Verma",
      "Soma Biswas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16497",
    "title": "GaitContour: Efficient Gait Recognition based on a Contour-Pose  Representation",
    "abstract": "Gait recognition holds the promise to robustly identify subjects based on walking patterns instead of appearance information. In recent years, this field has been dominated by learning methods based on two principal input representations: dense silhouette masks or sparse pose keypoints. In this work, we propose a novel, point-based Contour-Pose representation, which compactly expresses both body shape and body parts information. We further propose a local-to-global architecture, called GaitContour, to leverage this novel representation and efficiently compute subject embedding in two stages. The first stage consists of a local transformer that extracts features from five different body regions. The second stage then aggregates the regional features to estimate a global human gait representation. Such a design significantly reduces the complexity of the attention operation and improves efficiency and performance simultaneously. Through large scale experiments, GaitContour is shown to perform significantly better than previous point-based methods, while also being significantly more efficient than silhouette-based methods. On challenging datasets with significant distractors, GaitContour can even outperform silhouette-based methods. ",
    "url": "https://arxiv.org/abs/2311.16497",
    "authors": [
      "Yuxiang Guo",
      "Anshul Shah",
      "Jiang Liu",
      "Rama Chellappa",
      "Cheng Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16501",
    "title": "PISA: Point-cloud-based Instructed Scene Augmentation",
    "abstract": "Indoor scene augmentation has become an emerging topic in the field of computer vision with applications in augmented and virtual reality. However, existing scene augmentation methods mostly require a pre-built object database with a given position as the desired location. In this paper, we propose the first end-to-end multi-modal deep neural network that can generate point cloud objects consistent with their surroundings, conditioned on text instructions. Our model generates a seemly object in the appropriate position based on the inputs of a query and point clouds, thereby enabling the creation of new scenarios involving previously unseen layouts of objects. Database of pre-stored CAD models is no longer needed. We use Point-E as our generative model and introduce methods including quantified position prediction and Top-K estimation to mitigate the false negative problems caused by ambiguous language description. Moreover, we evaluate the ability of our model by demonstrating the diversity of generated objects, the effectiveness of instruction, and quantitative metric results, which collectively indicate that our model is capable of generating realistic in-door objects. For a more thorough evaluation, we also incorporate visual grounding as a metric to assess the quality of the scenes generated by our model. ",
    "url": "https://arxiv.org/abs/2311.16501",
    "authors": [
      "Yiyang Luo",
      "Ke Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16504",
    "title": "Rethinking Directional Integration in Neural Radiance Fields",
    "abstract": "Recent works use the Neural radiance field (NeRF) to perform multi-view 3D reconstruction, providing a significant leap in rendering photorealistic scenes. However, despite its efficacy, NeRF exhibits limited capability of learning view-dependent effects compared to light field rendering or image-based view synthesis. To that end, we introduce a modification to the NeRF rendering equation which is as simple as a few lines of code change for any NeRF variations, while greatly improving the rendering quality of view-dependent effects. By swapping the integration operator and the direction decoder network, we only integrate the positional features along the ray and move the directional terms out of the integration, resulting in a disentanglement of the view-dependent and independent components. The modified equation is equivalent to the classical volumetric rendering in ideal cases on object surfaces with Dirac densities. Furthermore, we prove that with the errors caused by network approximation and numerical integration, our rendering equation exhibits better convergence properties with lower error accumulations compared to the classical NeRF. We also show that the modified equation can be interpreted as light field rendering with learned ray embeddings. Experiments on different NeRF variations show consistent improvements in the quality of view-dependent effects with our simple modification. ",
    "url": "https://arxiv.org/abs/2311.16504",
    "authors": [
      "Congyue Deng",
      "Jiawei Yang",
      "Leonidas Guibas",
      "Yue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2311.16508",
    "title": "RandMSAugment: A Mixed-Sample Augmentation for Limited-Data Scenarios",
    "abstract": "The high costs of annotating large datasets suggests a need for effectively training CNNs with limited data, and data augmentation is a promising direction. We study foundational augmentation techniques, including Mixed Sample Data Augmentations (MSDAs) and a no-parameter variant of RandAugment termed Preset-RandAugment, in the fully supervised scenario. We observe that Preset-RandAugment excels in limited-data contexts while MSDAs are moderately effective. We show that low-level feature transforms play a pivotal role in this performance difference, postulate a new property of augmentations related to their data efficiency, and propose new ways to measure the diversity and realism of augmentations. Building on these insights, we introduce a novel augmentation technique called RandMSAugment that integrates complementary strengths of existing methods. RandMSAugment significantly outperforms the competition on CIFAR-100, STL-10, and Tiny-Imagenet. With very small training sets (4, 25, 100 samples/class), RandMSAugment achieves compelling performance gains between 4.1% and 6.75%. Even with more training data (500 samples/class) we improve performance by 1.03% to 2.47%. RandMSAugment does not require hyperparameter tuning, extra validation data, or cumbersome optimizations. ",
    "url": "https://arxiv.org/abs/2311.16508",
    "authors": [
      "Swarna Kamlam Ravindran",
      "Carlo Tomasi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16509",
    "title": "StyleCap: Automatic Speaking-Style Captioning from Speech Based on  Speech and Language Self-supervised Learning Models",
    "abstract": "We propose StyleCap, a method to generate natural language descriptions of speaking styles appearing in speech. Although most of conventional techniques for para-/non-linguistic information recognition focus on the category classification or the intensity estimation of pre-defined labels, they cannot provide the reasoning of the recognition result in an interpretable manner. As a first step towards an end-to-end method for generating speaking-style prompts from speech, i.e., automatic speaking-style captioning, StyleCap uses paired data of speech and natural language descriptions to train neural networks that predict prefix vectors fed into a large language model (LLM)-based text decoder from a speech representation vector. We explore an appropriate text decoder and speech feature representation suitable for this new task. The experimental results demonstrate that our StyleCap leveraging richer LLMs for the text decoder, speech self-supervised learning (SSL) features, and sentence rephrasing augmentation improves the accuracy and diversity of generated speaking-style captions. Samples of speaking-style captions generated by our StyleCap are publicly available. ",
    "url": "https://arxiv.org/abs/2311.16509",
    "authors": [
      "Kazuki Yamauchi",
      "Yusuke Ijima",
      "Yuki Saito"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2311.16514",
    "title": "Video Anomaly Detection via Spatio-Temporal Pseudo-Anomaly Generation :  A Unified Approach",
    "abstract": "Video Anomaly Detection (VAD) is an open-set recognition task, which is usually formulated as a one-class classification (OCC) problem, where training data is comprised of videos with normal instances while test data contains both normal and anomalous instances. Recent works have investigated the creation of pseudo-anomalies (PAs) using only the normal data and making strong assumptions about real-world anomalies with regards to abnormality of objects and speed of motion to inject prior information about anomalies in an autoencoder (AE) based reconstruction model during training. This work proposes a novel method for generating generic spatio-temporal PAs by inpainting a masked out region of an image using a pre-trained Latent Diffusion Model and further perturbing the optical flow using mixup to emulate spatio-temporal distortions in the data. In addition, we present a simple unified framework to detect real-world anomalies under the OCC setting by learning three types of anomaly indicators, namely reconstruction quality, temporal irregularity and semantic inconsistency. Extensive experiments on four VAD benchmark datasets namely Ped2, Avenue, ShanghaiTech and UBnormal demonstrate that our method performs on par with other existing state-of-the-art PAs generation and reconstruction based methods under the OCC setting. Our analysis also examines the transferability and generalisation of PAs across these datasets, offering valuable insights by identifying real-world anomalies through PAs. ",
    "url": "https://arxiv.org/abs/2311.16514",
    "authors": [
      "Ayush K. Rai",
      "Tarun Krishna",
      "Feiyan Hu",
      "Alexandru Drimbarean",
      "Kevin McGuinness",
      "Alan F. Smeaton",
      "Noel E. O'Connor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16519",
    "title": "B-LSTM-MIONet: Bayesian LSTM-based Neural Operators for Learning the  Response of Complex Dynamical Systems to Length-Variant Multiple Input  Functions",
    "abstract": "Deep Operator Network (DeepONet) is a neural network framework for learning nonlinear operators such as those from ordinary differential equations (ODEs) describing complex systems. Multiple-input deep neural operators (MIONet) extended DeepONet to allow multiple input functions in different Banach spaces. MIONet offers flexibility in training dataset grid spacing, without constraints on output location. However, it requires offline inputs and cannot handle varying sequence lengths in testing datasets, limiting its real-time application in dynamic complex systems. This work redesigns MIONet, integrating Long Short Term Memory (LSTM) to learn neural operators from time-dependent data. This approach overcomes data discretization constraints and harnesses LSTM's capability with variable-length, real-time data. Factors affecting learning performance, like algorithm extrapolation ability are presented. The framework is enhanced with uncertainty quantification through a novel Bayesian method, sampling from MIONet parameter distributions. Consequently, we develop the B-LSTM-MIONet, incorporating LSTM's temporal strengths with Bayesian robustness, resulting in a more precise and reliable model for noisy datasets. ",
    "url": "https://arxiv.org/abs/2311.16519",
    "authors": [
      "Zhihao Kong",
      "Amirhossein Mollaali",
      "Christian Moya",
      "Na Lu",
      "Guang Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2311.16522",
    "title": "Evaluation of dynamic characteristics of power grid based on GNN and  application on knowledge graph",
    "abstract": "A novel method for detecting faults in power grids using a graph neural network (GNN) has been developed, aimed at enhancing intelligent fault diagnosis in network operation and maintenance. This GNN-based approach identifies faulty nodes within the power grid through a specialized electrical feature extraction model coupled with a knowledge graph. Incorporating temporal data, the method leverages the status of nodes from preceding and subsequent time periods to aid in current fault detection. To validate the effectiveness of this GNN in extracting node features, a correlation analysis of the output features from each node within the neural network layer was conducted. The results from experiments show that this method can accurately locate fault nodes in simulated scenarios with a remarkable 99.53% accuracy. Additionally, the graph neural network's feature modeling allows for a qualitative examination of how faults spread across nodes, providing valuable insights for analyzing fault nodes. ",
    "url": "https://arxiv.org/abs/2311.16522",
    "authors": [
      "Hao Pei",
      "Si Lin",
      "Chuanfu Li",
      "Che Wang",
      "Haoming Chen",
      "Sizhe Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.16523",
    "title": "Phase Preservation of N-Port Networks under General Connections",
    "abstract": "This study first introduces the frequency-wise phases of n-port linear time-invariant networks based on recently defined phases of complex matrices. Such a phase characterization can be used to quantify the well-known notion of passivity for networks. Further, a class of matrix operations induced by fairly common n-port network connections is examined. The intrinsic phase properties of networks under such connections are preserved. Concretely, a scalable phase-preserving criterion is proposed, which involves only the phase properties of individual subnetworks, under the matrix operations featured by connections. This criterion ensures that the phase range of the integrated network can be verified effectively and that the scalability of the analyses can be maintained. In addition, the inverse operations of the considered connections, that is, network subtractions with correspondences are examined. With the known phase ranges of the integrated network and one of its subnetworks, the maximal allowable phase range of the remaining subnetwork can also be determined explicitly in a unified form for all types of subtractions. Finally, we extend the phase-preserving properties from the aforementioned connections to more general matrix operations defined using a certain indefinite inner product. ",
    "url": "https://arxiv.org/abs/2311.16523",
    "authors": [
      "Jianqi Chen",
      "Wei Chen",
      "Chao Chen",
      "Li Qiu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.16524",
    "title": "3D Teeth Reconstruction from Panoramic Radiographs using Neural Implicit  Functions",
    "abstract": "Panoramic radiography is a widely used imaging modality in dental practice and research. However, it only provides flattened 2D images, which limits the detailed assessment of dental structures. In this paper, we propose Occudent, a framework for 3D teeth reconstruction from panoramic radiographs using neural implicit functions, which, to the best of our knowledge, is the first work to do so. For a given point in 3D space, the implicit function estimates whether the point is occupied by a tooth, and thus implicitly determines the boundaries of 3D tooth shapes. Firstly, Occudent applies multi-label segmentation to the input panoramic radiograph. Next, tooth shape embeddings as well as tooth class embeddings are generated from the segmentation outputs, which are fed to the reconstruction network. A novel module called Conditional eXcitation (CX) is proposed in order to effectively incorporate the combined shape and class embeddings into the implicit function. The performance of Occudent is evaluated using both quantitative and qualitative measures. Importantly, Occudent is trained and validated with actual panoramic radiographs as input, distinct from recent works which used synthesized images. Experiments demonstrate the superiority of Occudent over state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2311.16524",
    "authors": [
      "Sihwa Park",
      "Seongjun Kim",
      "In-Seok Song",
      "Seung Jun Baek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16526",
    "title": "On robust overfitting: adversarial training induced distribution matters",
    "abstract": "Adversarial training may be regarded as standard training with a modified loss function. But its generalization error appears much larger than standard training under standard loss. This phenomenon, known as robust overfitting, has attracted significant research attention and remains largely as a mystery. In this paper, we first show empirically that robust overfitting correlates with the increasing generalization difficulty of the perturbation-induced distributions along the trajectory of adversarial training (specifically PGD-based adversarial training). We then provide a novel upper bound for generalization error with respect to the perturbation-induced distributions, in which a notion of the perturbation operator, referred to \"local dispersion\", plays an important role. ",
    "url": "https://arxiv.org/abs/2311.16526",
    "authors": [
      "Runzhi Tian",
      "Yongyi Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16533",
    "title": "Motor State Prediction and Friction Compensation based on Data-driven  Techniques",
    "abstract": "In order to provide robust, reliable, and accurate position and velocity control of motor drives, friction compensation has emerged as a key difficulty. Non-characterised friction could give rise to large position errors and vibrations which could be intensified by stick-slip motion and limit cycles. This paper presents an application of two data-driven nonlinear model identification techniques to discover the governing equations of motor dynamics that also characterise friction. Namely, the extraction of low-power data from time-delayed coordinates of motor velocity and sparse regression on nonlinear terms was applied to data acquired from a Brushless DC (BLDC) motor, to identify the underlying dynamics. The latter can be considered an extension of the conventional linear motor model commonly used in many model-based controllers. The identified nonlinear model was then contrasted with a nonlinear model that included the LuGre friction model and a linear model without friction. A nonlinear grey box model estimation method was used to calculate the optimum friction parameters for the LuGre model. The resulting nonlinear motor model with friction characteristics was then validated using a feedback friction compensation algorithm. The novel model showed more than 90% accuracy in predicting the motor states in all considered input excitation signals. In addition, the model-based friction compensation scheme showed a relative increase in performance when compared with a system without friction compensation. ",
    "url": "https://arxiv.org/abs/2311.16533",
    "authors": [
      "Nimantha Dasanayake",
      "Shehara Perera"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.16534",
    "title": "Graph Prompt Learning: A Comprehensive Survey and Beyond",
    "abstract": "Artificial General Intelligence (AGI) has revolutionized numerous fields, yet its integration with graph data, a cornerstone in our interconnected world, remains nascent. This paper presents a pioneering survey on the emerging domain of graph prompts in AGI, addressing key challenges and opportunities in harnessing graph data for AGI applications. Despite substantial advancements in AGI across natural language processing and computer vision, the application to graph data is relatively underexplored. This survey critically evaluates the current landscape of AGI in handling graph data, highlighting the distinct challenges in cross-modality, cross-domain, and cross-task applications specific to graphs. Our work is the first to propose a unified framework for understanding graph prompt learning, offering clarity on prompt tokens, token structures, and insertion patterns in the graph domain. We delve into the intrinsic properties of graph prompts, exploring their flexibility, expressiveness, and interplay with existing graph models. A comprehensive taxonomy categorizes over 100 works in this field, aligning them with pre-training tasks across node-level, edge-level, and graph-level objectives. Additionally, we present, ProG, a Python library, and an accompanying website, to support and advance research in graph prompting. The survey culminates in a discussion of current challenges and future directions, offering a roadmap for research in graph prompting within AGI. Through this comprehensive analysis, we aim to catalyze further exploration and practical applications of AGI in graph data, underlining its potential to reshape AGI fields and beyond. ProG and the website can be accessed by \\url{https://github.com/WxxShirley/Awesome-Graph-Prompt}, and \\url{https://github.com/sheldonresearch/ProG}, respectively. ",
    "url": "https://arxiv.org/abs/2311.16534",
    "authors": [
      "Xiangguo Sun",
      "Jiawen Zhang",
      "Xixi Wu",
      "Hong Cheng",
      "Yun Xiong",
      "Jia Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.16535",
    "title": "Contrastive encoder pre-training-based clustered federated learning for  heterogeneous data",
    "abstract": "Federated learning (FL) is a promising approach that enables distributed clients to collaboratively train a global model while preserving their data privacy. However, FL often suffers from data heterogeneity problems, which can significantly affect its performance. To address this, clustered federated learning (CFL) has been proposed to construct personalized models for different client clusters. One effective client clustering strategy is to allow clients to choose their own local models from a model pool based on their performance. However, without pre-trained model parameters, such a strategy is prone to clustering failure, in which all clients choose the same model. Unfortunately, collecting a large amount of labeled data for pre-training can be costly and impractical in distributed environments. To overcome this challenge, we leverage self-supervised contrastive learning to exploit unlabeled data for the pre-training of FL systems. Together, self-supervised pre-training and client clustering can be crucial components for tackling the data heterogeneity issues of FL. Leveraging these two crucial strategies, we propose contrastive pre-training-based clustered federated learning (CP-CFL) to improve the model convergence and overall performance of FL systems. In this work, we demonstrate the effectiveness of CP-CFL through extensive experiments in heterogeneous FL settings, and present various interesting observations. ",
    "url": "https://arxiv.org/abs/2311.16535",
    "authors": [
      "Ye Lin Tun",
      "Minh N.H. Nguyen",
      "Chu Myaet Thwal",
      "Jinwoo Choi",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.16536",
    "title": "Personalized Predictions of Glioblastoma Infiltration: Mathematical  Models, Physics-Informed Neural Networks and Multimodal Scans",
    "abstract": "Predicting the infiltration of Glioblastoma (GBM) from medical MRI scans is crucial for understanding tumor growth dynamics and designing personalized radiotherapy treatment plans.Mathematical models of GBM growth can complement the data in the prediction of spatial distributions of tumor cells. However, this requires estimating patient-specific parameters of the model from clinical data, which is a challenging inverse problem due to limited temporal data and the limited time between imaging and diagnosis. This work proposes a method that uses Physics-Informed Neural Networks (PINNs) to estimate patient-specific parameters of a reaction-diffusion PDE model of GBM growth from a single 3D structural MRI snapshot. PINNs embed both the data and the PDE into a loss function, thus integrating theory and data. Key innovations include the identification and estimation of characteristic non-dimensional parameters, a pre-training step that utilizes the non-dimensional parameters and a fine-tuning step to determine the patient specific parameters. Additionally, the diffuse domain method is employed to handle the complex brain geometry within the PINN framework. Our method is validated both on synthetic and patient datasets, and shows promise for real-time parametric inference in the clinical setting for personalized GBM treatment. ",
    "url": "https://arxiv.org/abs/2311.16536",
    "authors": [
      "Ray Zirui Zhang",
      "Ivan Ezhov",
      "Michal Balcerak",
      "Andy Zhu",
      "Benedikt Wiestler",
      "Bjoern Menze",
      "John Lowengrub"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2311.16540",
    "title": "Communication Efficiency Optimization of Federated Learning for  Computing and Network Convergence of 6G Networks",
    "abstract": "Federated learning effectively addresses issues such as data privacy by collaborating across participating devices to train global models. However, factors such as network topology and device computing power can affect its training or communication process in complex network environments. A new network architecture and paradigm with computing-measurable, perceptible, distributable, dispatchable, and manageable capabilities, computing and network convergence (CNC) of 6G networks can effectively support federated learning training and improve its communication efficiency. By guiding the participating devices' training in federated learning based on business requirements, resource load, network conditions, and arithmetic power of devices, CNC can reach this goal. In this paper, to improve the communication efficiency of federated learning in complex networks, we study the communication efficiency optimization of federated learning for computing and network convergence of 6G networks, methods that gives decisions on its training process for different network conditions and arithmetic power of participating devices in federated learning. The experiments address two architectures that exist for devices in federated learning and arrange devices to participate in training based on arithmetic power while achieving optimization of communication efficiency in the process of transferring model parameters. The results show that the method we proposed can (1) cope well with complex network situations (2) effectively balance the delay distribution of participating devices for local training (3) improve the communication efficiency during the transfer of model parameters (4) improve the resource utilization in the network. ",
    "url": "https://arxiv.org/abs/2311.16540",
    "authors": [
      "Yizhuo Cai",
      "Bo Lei",
      "Qianying Zhao",
      "Jing Peng",
      "Min Wei",
      "Yushun Zhang",
      "Xing Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2311.16544",
    "title": "Multi-Irreducible Spectral Synchronization for Robust Rotation Averaging",
    "abstract": "Rotation averaging (RA) is a fundamental problem in robotics and computer vision. In RA, the goal is to estimate a set of $N$ unknown orientations $R_{1}, ..., R_{N} \\in SO(3)$, given noisy measurements $R_{ij} \\sim R^{-1}_{i} R_{j}$ of a subset of their pairwise relative rotations. This problem is both nonconvex and NP-hard, and thus difficult to solve in the general case. We apply harmonic analysis on compact groups to derive a (convex) spectral relaxation constructed from truncated Fourier decompositions of the individual summands appearing in the RA objective; we then recover an estimate of the RA solution by computing a few extremal eigenpairs of this relaxation, and (approximately) solving a consensus problem. Our approach affords several notable advantages versus prior RA methods: it can be used in conjunction with \\emph{any} smooth loss function (including, but not limited to, robust M-estimators), does not require any initialization, and is implemented using only simple (and highly scalable) linear-algebraic computations and parallelizable optimizations over band-limited functions of individual rotational states. Moreover, under the (physically well-motivated) assumption of multiplicative Langevin measurement noise, we derive explicit performance guarantees for our spectral estimator (in the form of probabilistic tail bounds on the estimation error) that are parameterized in terms of graph-theoretic quantities of the underlying measurement network. By concretely linking estimator performance with properties of the underlying measurement graph, our results also indicate how to devise measurement networks that are \\emph{guaranteed} to achieve accurate estimation, enabling such downstream tasks as sensor placement, network compression, and active sensing. ",
    "url": "https://arxiv.org/abs/2311.16544",
    "authors": [
      "Owen Howell",
      "Haoen Huang",
      "David Rosen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Group Theory (math.GR)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2311.16564",
    "title": "Multi-agent statistical discriminative sub-trajectory mining and an  application to NBA basketball",
    "abstract": "Improvements in tracking technology through optical and computer vision systems have enabled a greater understanding of the movement-based behaviour of multiple agents, including in team sports. In this study, a Multi-Agent Statistically Discriminative Sub-Trajectory Mining (MA-Stat-DSM) method is proposed that takes a set of binary-labelled agent trajectory matrices as input and incorporates Hausdorff distance to identify sub-matrices that statistically significantly discriminate between the two groups of labelled trajectory matrices. Utilizing 2015/16 SportVU NBA tracking data, agent trajectory matrices representing attacks consisting of the trajectories of five agents (the ball, shooter, last passer, shooter defender, and last passer defender), were truncated to correspond to the time interval following the receipt of the ball by the last passer, and labelled as effective or ineffective based on a definition of attack effectiveness that we devise in the current study. After identifying appropriate parameters for MA-Stat-DSM by iteratively applying it to all matches involving the two top- and two bottom-placed teams from the 2015/16 NBA season, the method was then applied to selected matches and could identify and visualize the portions of plays, e.g., involving passing, on-, and/or off-the-ball movements, which were most relevant in rendering attacks effective or ineffective. ",
    "url": "https://arxiv.org/abs/2311.16564",
    "authors": [
      "Rory Bunker",
      "Vo Nguyen Le Duy",
      "Yasuo Tabei",
      "Ichiro Takeuchi",
      "Keisuke Fujii"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2311.16568",
    "title": "Active RIS Enhanced Spectrum Sensing for Cognitive Radio Networks",
    "abstract": "In opportunistic cognitive radio networks, when the primary signal is very weak compared to the background noise, the secondary user requires long sensing time to achieve a reliable spectrum sensing performance, leading to little remaining time for the secondary transmission. To tackle this issue, we propose an active reconfigurable intelligent surface (RIS) assisted spectrum sensing system, where the received signal strength from the interested primary user can be enhanced and underlying interference within the background noise can be mitigated as well. In comparison with the passive RIS, the active RIS can not only adapt the phase shift of each reflecting element but also amplify the incident signals. Notably, we study the reflecting coefficient matrix (RCM) optimization problem to improve the detection probability given a maximum tolerable false alarm probability and limited sensing time. Then, we show that the formulated problem can be equivalently transformed to a weighted mean square error minimization problem using the principle of the well-known weighted minimum mean square error (WMMSE) algorithm, and an iterative optimization approach is proposed to obtain the optimal RCM. In addition, to fairly compare passive RIS and active RIS, we study the required power budget of the RIS to achieve a target detection probability under a special case where the direct links are neglected and the RIS-related channels are line-of-sight. Via extensive simulations, the effectiveness of the WMMSE-based RCM optimization approach is demonstrated. Furthermore, the results reveal that the active RIS can outperform the passive RIS when the underlying interference within the background noise is relatively weak, whereas the passive RIS performs better in strong interference scenarios because the same power budget can support a vast number of passive reflecting elements for interference mitigation. ",
    "url": "https://arxiv.org/abs/2311.16568",
    "authors": [
      "Jungang Ge",
      "Ying-Chang Liang",
      "Sumei Sun",
      "Yonghong Zeng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.16577",
    "title": "Efficient Key-Based Adversarial Defense for ImageNet by Using  Pre-trained Model",
    "abstract": "In this paper, we propose key-based defense model proliferation by leveraging pre-trained models and utilizing recent efficient fine-tuning techniques on ImageNet-1k classification. First, we stress that deploying key-based models on edge devices is feasible with the latest model deployment advancements, such as Apple CoreML, although the mainstream enterprise edge artificial intelligence (Edge AI) has been focused on the Cloud. Then, we point out that the previous key-based defense on on-device image classification is impractical for two reasons: (1) training many classifiers from scratch is not feasible, and (2) key-based defenses still need to be thoroughly tested on large datasets like ImageNet. To this end, we propose to leverage pre-trained models and utilize efficient fine-tuning techniques to proliferate key-based models even on limited computing resources. Experiments were carried out on the ImageNet-1k dataset using adaptive and non-adaptive attacks. The results show that our proposed fine-tuned key-based models achieve a superior classification accuracy (more than 10% increase) compared to the previous key-based models on classifying clean and adversarial examples. ",
    "url": "https://arxiv.org/abs/2311.16577",
    "authors": [
      "AprilPyone MaungMaung",
      "Isao Echizen",
      "Hitoshi Kiya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16579",
    "title": "Recognizing Conditional Causal Relationships about Emotions and Their  Corresponding Conditions",
    "abstract": "The study of causal relationships between emotions and causes in texts has recently received much attention. Most works focus on extracting causally related clauses from documents. However, none of these works has considered that the causal relationships among the extracted emotion and cause clauses can only be valid under some specific context clauses. To highlight the context in such special causal relationships, we propose a new task to determine whether or not an input pair of emotion and cause has a valid causal relationship under different contexts and extract the specific context clauses that participate in the causal relationship. Since the task is new for which no existing dataset is available, we conduct manual annotation on a benchmark dataset to obtain the labels for our tasks and the annotations of each context clause's type that can also be used in some other applications. We adopt negative sampling to construct the final dataset to balance the number of documents with and without causal relationships. Based on the constructed dataset, we propose an end-to-end multi-task framework, where we design two novel and general modules to handle the two goals of our task. Specifically, we propose a context masking module to extract the context clauses participating in the causal relationships. We propose a prediction aggregation module to fine-tune the prediction results according to whether the input emotion and causes depend on specific context clauses. Results of extensive comparative experiments and ablation studies demonstrate the effectiveness and generality of our proposed framework. ",
    "url": "https://arxiv.org/abs/2311.16579",
    "authors": [
      "Xinhong Chen",
      "Zongxi Li",
      "Yaowei Wang",
      "Haoran Xie",
      "Jianping Wang",
      "Qing Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.16584",
    "title": "FedAL: Black-Box Federated Knowledge Distillation Enabled by Adversarial  Learning",
    "abstract": "Knowledge distillation (KD) can enable collaborative learning among distributed clients that have different model architectures and do not share their local data and model parameters with others. Each client updates its local model using the average model output/feature of all client models as the target, known as federated KD. However, existing federated KD methods often do not perform well when clients' local models are trained with heterogeneous local datasets. In this paper, we propose Federated knowledge distillation enabled by Adversarial Learning (FedAL) to address the data heterogeneity among clients. First, to alleviate the local model output divergence across clients caused by data heterogeneity, the server acts as a discriminator to guide clients' local model training to achieve consensus model outputs among clients through a min-max game between clients and the discriminator. Moreover, catastrophic forgetting may happen during the clients' local training and global knowledge transfer due to clients' heterogeneous local data. Towards this challenge, we design the less-forgetting regularization for both local training and global knowledge transfer to guarantee clients' ability to transfer/learn knowledge to/from others. Experimental results show that FedAL and its variants achieve higher accuracy than other federated KD baselines. ",
    "url": "https://arxiv.org/abs/2311.16584",
    "authors": [
      "Pengchao Han",
      "Xingyan Shi",
      "Jianwei Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.16589",
    "title": "Improving Lane Detection Generalization: A Novel Framework using HD Maps  for Boosting Diversity",
    "abstract": "Lane detection is a vital task for vehicles to navigate and localize their position on the road. To ensure reliable results, lane detection algorithms must have robust generalization performance in various road environments. However, despite the significant performance improvement of deep learning-based lane detection algorithms, their generalization performance in response to changes in road environments still falls short of expectations. In this paper, we present a novel framework for single-source domain generalization (SSDG) in lane detection. By decomposing data into lane structures and surroundings, we enhance diversity using High-Definition (HD) maps and generative models. Rather than expanding data volume, we strategically select a core subset of data, maximizing diversity and optimizing performance. Our extensive experiments demonstrate that our framework enhances the generalization performance of lane detection, comparable to the domain adaptation-based method. ",
    "url": "https://arxiv.org/abs/2311.16589",
    "authors": [
      "Daeun Lee",
      "Minhyeok Heo",
      "Jiwon Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.16592",
    "title": "RGBGrasp: Image-based Object Grasping by Capturing Multiple Views during  Robot Arm Movement with Neural Radiance Fields",
    "abstract": "Robotic research encounters a significant hurdle when it comes to the intricate task of grasping objects that come in various shapes, materials, and textures. Unlike many prior investigations that heavily leaned on specialized point-cloud cameras or abundant RGB visual data to gather 3D insights for object-grasping missions, this paper introduces a pioneering approach called RGBGrasp. This method depends on a limited set of RGB views to perceive the 3D surroundings containing transparent and specular objects and achieve accurate grasping. Our method utilizes pre-trained depth prediction models to establish geometry constraints, enabling precise 3D structure estimation, even under limited view conditions. Finally, we integrate hash encoding and a proposal sampler strategy to significantly accelerate the 3D reconstruction process. These innovations significantly enhance the adaptability and effectiveness of our algorithm in real-world scenarios. Through comprehensive experimental validation, we demonstrate that RGBGrasp achieves remarkable success across a wide spectrum of object-grasping scenarios, establishing it as a promising solution for real-world robotic manipulation tasks. The demo of our method can be found on: https://sites.google.com/view/rgbgrasp ",
    "url": "https://arxiv.org/abs/2311.16592",
    "authors": [
      "Chang Liu",
      "Kejian Shi",
      "Kaichen Zhou",
      "Haoxiao Wang",
      "Jiyao Zhang",
      "Hao Dong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.16594",
    "title": "Monitor Placement for Fault Localization in Deep Neural Network  Accelerators",
    "abstract": "Systolic arrays are a prominent choice for deep neural network (DNN) accelerators because they offer parallelism and efficient data reuse. Improving the reliability of DNN accelerators is crucial as hardware faults can degrade the accuracy of DNN inferencing. Systolic arrays make use of a large number of processing elements (PEs) for parallel processing, but when one PE is faulty, the error propagates and affects the outcomes of downstream PEs. Due to the large number of PEs, the cost associated with implementing hardware-based runtime monitoring of every single PE is infeasible. We present a solution to optimize the placement of hardware monitors within systolic arrays. We first prove that $2N-1$ monitors are needed to localize a single faulty PE and we also derive the monitor placement. We show that a second placement optimization problem, which minimizes the set of candidate faulty PEs for a given number of monitors, is NP-hard. Therefore, we propose a heuristic approach to balance the reliability and hardware resource utilization in DNN accelerators when number of monitors is limited. Experimental evaluation shows that to localize a single faulty PE, an area overhead of only 0.33% is incurred for a $256\\times 256$ systolic array. ",
    "url": "https://arxiv.org/abs/2311.16594",
    "authors": [
      "Wei-Kai Liu",
      "Benjamin Tan",
      "Krishnendu Chakrabarty"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.16605",
    "title": "LasTGL: An Industrial Framework for Large-Scale Temporal Graph Learning",
    "abstract": "Over the past few years, graph neural networks (GNNs) have become powerful and practical tools for learning on (static) graph-structure data. However, many real-world applications, such as social networks and e-commerce, involve temporal graphs where nodes and edges are dynamically evolving. Temporal graph neural networks (TGNNs) have progressively emerged as an extension of GNNs to address time-evolving graphs and have gradually become a trending research topic in both academics and industry. Advancing research in such an emerging field requires new tools to compose TGNN models and unify their different schemes in dealing with temporal graphs. To facilitate research and application in temporal graph learning, we introduce LasTGL, an industrial framework that integrates unified and extensible implementations of common temporal graph learning algorithms for various advanced tasks. The purpose of LasTGL is to provide the essential building blocks for solving temporal graph learning tasks, focusing on the guiding principles of user-friendliness and quick prototyping on which PyTorch is based. In particular, LasTGL provides comprehensive temporal graph datasets, TGNN models and utilities along with well-documented tutorials, making it suitable for both absolute beginners and expert deep learning practitioners alike. ",
    "url": "https://arxiv.org/abs/2311.16605",
    "authors": [
      "Jintang Li",
      "Jiawang Dan",
      "Ruofan Wu",
      "Jing Zhou",
      "Sheng Tian",
      "Yunfei Liu",
      "Baokun Wang",
      "Changhua Meng",
      "Weiqiang Wang",
      "Yuchang Zhu",
      "Liang Chen",
      "Zibin Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.16616",
    "title": "Adversarial Distribution Balancing for Counterfactual Reasoning",
    "abstract": "The development of causal prediction models is challenged by the fact that the outcome is only observable for the applied (factual) intervention and not for its alternatives (the so-called counterfactuals); in medicine we only know patients' survival for the administered drug and not for other therapeutic options. Machine learning approaches for counterfactual reasoning have to deal with both unobserved outcomes and distributional differences due to non-random treatment administration. Unsupervised domain adaptation (UDA) addresses similar issues; one has to deal with unobserved outcomes -- the labels of the target domain -- and distributional differences between source and target domain. We propose Adversarial Distribution Balancing for Counterfactual Reasoning (ADBCR), which directly uses potential outcome estimates of the counterfactuals to remove spurious causal relations. We show that ADBCR outcompetes state-of-the-art methods on three benchmark datasets, and demonstrate that ADBCR's performance can be further improved if unlabeled validation data are included in the training procedure to better adapt the model to the validation domain. ",
    "url": "https://arxiv.org/abs/2311.16616",
    "authors": [
      "Stefan Schrod",
      "Fabian Sinz",
      "Michael Altenbuchinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16618",
    "title": "Cross-level Attention with Overlapped Windows for Camouflaged Object  Detection",
    "abstract": "Camouflaged objects adaptively fit their color and texture with the environment, which makes them indistinguishable from the surroundings. Current methods revealed that high-level semantic features can highlight the differences between camouflaged objects and the backgrounds. Consequently, they integrate high-level semantic features with low-level detailed features for accurate camouflaged object detection (COD). Unlike previous designs for multi-level feature fusion, we state that enhancing low-level features is more impending for COD. In this paper, we propose an overlapped window cross-level attention (OWinCA) to achieve the low-level feature enhancement guided by the highest-level features. By sliding an aligned window pair on both the highest- and low-level feature maps, the high-level semantics are explicitly integrated into the low-level details via cross-level attention. Additionally, it employs an overlapped window partition strategy to alleviate the incoherence among windows, which prevents the loss of global information. These adoptions enable the proposed OWinCA to enhance low-level features by promoting the separability of camouflaged objects. The associated proposed OWinCANet fuses these enhanced multi-level features by simple convolution operation to achieve the final COD. Experiments conducted on three large-scale COD datasets demonstrate that our OWinCANet significantly surpasses the current state-of-the-art COD methods. ",
    "url": "https://arxiv.org/abs/2311.16618",
    "authors": [
      "Jiepan Li",
      "Fangxiao Lu",
      "Nan Xue",
      "Zhuohong Li",
      "Hongyan Zhang",
      "Wei He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16646",
    "title": "Rethinking Backdoor Attacks on Dataset Distillation: A Kernel Method  Perspective",
    "abstract": "Dataset distillation offers a potential means to enhance data efficiency in deep learning. Recent studies have shown its ability to counteract backdoor risks present in original training samples. In this study, we delve into the theoretical aspects of backdoor attacks and dataset distillation based on kernel methods. We introduce two new theory-driven trigger pattern generation methods specialized for dataset distillation. Following a comprehensive set of analyses and experiments, we show that our optimization-based trigger design framework informs effective backdoor attacks on dataset distillation. Notably, datasets poisoned by our designed trigger prove resilient against conventional backdoor attack detection and mitigation methods. Our empirical results validate that the triggers developed using our approaches are proficient at executing resilient backdoor attacks. ",
    "url": "https://arxiv.org/abs/2311.16646",
    "authors": [
      "Ming-Yu Chung",
      "Sheng-Yen Chou",
      "Chia-Mu Yu",
      "Pin-Yu Chen",
      "Sy-Yen Kuo",
      "Tsung-Yi Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.16650",
    "title": "Text2Tree: Aligning Text Representation to the Label Tree Hierarchy for  Imbalanced Medical Classification",
    "abstract": "Deep learning approaches exhibit promising performances on various text tasks. However, they are still struggling on medical text classification since samples are often extremely imbalanced and scarce. Different from existing mainstream approaches that focus on supplementary semantics with external medical information, this paper aims to rethink the data challenges in medical texts and present a novel framework-agnostic algorithm called Text2Tree that only utilizes internal label hierarchy in training deep learning models. We embed the ICD code tree structure of labels into cascade attention modules for learning hierarchy-aware label representations. Two new learning schemes, Similarity Surrogate Learning (SSL) and Dissimilarity Mixup Learning (DML), are devised to boost text classification by reusing and distinguishing samples of other labels following the label representation hierarchy, respectively. Experiments on authoritative public datasets and real-world medical records show that our approach stably achieves superior performances over classical and advanced imbalanced classification methods. ",
    "url": "https://arxiv.org/abs/2311.16650",
    "authors": [
      "Jiahuan Yan",
      "Haojun Gao",
      "Zhang Kai",
      "Weize Liu",
      "Danny Chen",
      "Jian Wu",
      "Jintai Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.16652",
    "title": "Augmenting x-ray single particle imaging reconstruction with  self-supervised machine learning",
    "abstract": "The development of X-ray Free Electron Lasers (XFELs) has opened numerous opportunities to probe atomic structure and ultrafast dynamics of various materials. Single Particle Imaging (SPI) with XFELs enables the investigation of biological particles in their natural physiological states with unparalleled temporal resolution, while circumventing the need for cryogenic conditions or crystallization. However, reconstructing real-space structures from reciprocal-space x-ray diffraction data is highly challenging due to the absence of phase and orientation information, which is further complicated by weak scattering signals and considerable fluctuations in the number of photons per pulse. In this work, we present an end-to-end, self-supervised machine learning approach to recover particle orientations and estimate reciprocal space intensities from diffraction images only. Our method demonstrates great robustness under demanding experimental conditions with significantly enhanced reconstruction capabilities compared with conventional algorithms, and signifies a paradigm shift in SPI as currently practiced at XFELs. ",
    "url": "https://arxiv.org/abs/2311.16652",
    "authors": [
      "Zhantao Chen",
      "Cong Wang",
      "Mingye Gao",
      "Chun Hong Yoon",
      "Jana B. Thayer",
      "Joshua J. Turner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Applied Physics (physics.app-ph)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2311.16657",
    "title": "SCALAR-NeRF: SCAlable LARge-scale Neural Radiance Fields for Scene  Reconstruction",
    "abstract": "In this work, we introduce SCALAR-NeRF, a novel framework tailored for scalable large-scale neural scene reconstruction. We structure the neural representation as an encoder-decoder architecture, where the encoder processes 3D point coordinates to produce encoded features, and the decoder generates geometric values that include volume densities of signed distances and colors. Our approach first trains a coarse global model on the entire image dataset. Subsequently, we partition the images into smaller blocks using KMeans with each block being modeled by a dedicated local model. We enhance the overlapping regions across different blocks by scaling up the bounding boxes of each local block. Notably, the decoder from the global model is shared across distinct blocks and therefore promoting alignment in the feature space of local encoders. We propose an effective and efficient methodology to fuse the outputs from these local models to attain the final reconstruction. Employing this refined coarse-to-fine strategy, our method outperforms state-of-the-art NeRF methods and demonstrates scalability for large-scale scene reconstruction. The code will be available on our project page at https://aibluefisher.github.io/SCALAR-NeRF/ ",
    "url": "https://arxiv.org/abs/2311.16657",
    "authors": [
      "Yu Chen",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16661",
    "title": "Cooperative Abnormal Node Detection with Adversary Resistance: A  Probabilistic Approach",
    "abstract": "This paper presents a novel probabilistic detection scheme called Cooperative Statistical Detection (CSD) for abnormal node detection while defending against adversarial attacks in cluster-tree networks. The CSD performs a two-phase process: 1) designing a likelihood ratio test (LRT) for a non-root node at its children from the perspective of packet loss; 2) making an overall decision at the root node based on the aggregated detection data of the nodes over tree branches. In most adversarial scenarios, malicious children knowing the detection policy can generate falsified data to protect the abnormal parent from being detected or frame its normal parent as an anomalous node. To resolve this issue, a modified Z-score-based falsification-resistant mechanism is presented in the CSD to remove untrustworthy information. Through theoretical analysis, we show that the LRT-based method achieves perfect detection, i.e., both the false alarm and missed detection probabilities decay exponentially to zero. Furthermore, the optimal removal threshold of the modified Z-score method is derived for falsifications with uncertain strategies and guarantees perfect detection of the CSD. As our simulation results show, the CSD approach is robust to falsifications and can rapidly reach $99\\%$ detection accuracy, even in existing adversarial scenarios, which outperforms state-of-the-art technology. ",
    "url": "https://arxiv.org/abs/2311.16661",
    "authors": [
      "Yingying Huangfu",
      "Tian Bai"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2311.16664",
    "title": "DGNR: Density-Guided Neural Point Rendering of Large Driving Scenes",
    "abstract": "Despite the recent success of Neural Radiance Field (NeRF), it is still challenging to render large-scale driving scenes with long trajectories, particularly when the rendering quality and efficiency are in high demand. Existing methods for such scenes usually involve with spatial warping, geometric supervision from zero-shot normal or depth estimation, or scene division strategies, where the synthesized views are often blurry or fail to meet the requirement of efficient rendering. To address the above challenges, this paper presents a novel framework that learns a density space from the scenes to guide the construction of a point-based renderer, dubbed as DGNR (Density-Guided Neural Rendering). In DGNR, geometric priors are no longer needed, which can be intrinsically learned from the density space through volumetric rendering. Specifically, we make use of a differentiable renderer to synthesize images from the neural density features obtained from the learned density space. A density-based fusion module and geometric regularization are proposed to optimize the density space. By conducting experiments on a widely used autonomous driving dataset, we have validated the effectiveness of DGNR in synthesizing photorealistic driving scenes and achieving real-time capable rendering. ",
    "url": "https://arxiv.org/abs/2311.16664",
    "authors": [
      "Zhuopeng Li",
      "Chenming Wu",
      "Liangjun Zhang",
      "Jianke Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16666",
    "title": "MultiModal-Learning for Predicting Molecular Properties: A Framework  Based on Image and Graph Structures",
    "abstract": "The quest for accurate prediction of drug molecule properties poses a fundamental challenge in the realm of Artificial Intelligence Drug Discovery (AIDD). An effective representation of drug molecules emerges as a pivotal component in this pursuit. Contemporary leading-edge research predominantly resorts to self-supervised learning (SSL) techniques to extract meaningful structural representations from large-scale, unlabeled molecular data, subsequently fine-tuning these representations for an array of downstream tasks. However, an inherent shortcoming of these studies lies in their singular reliance on one modality of molecular information, such as molecule image or SMILES representations, thus neglecting the potential complementarity of various molecular modalities. In response to this limitation, we propose MolIG, a novel MultiModaL molecular pre-training framework for predicting molecular properties based on Image and Graph structures. MolIG model innovatively leverages the coherence and correlation between molecule graph and molecule image to execute self-supervised tasks, effectively amalgamating the strengths of both molecular representation forms. This holistic approach allows for the capture of pivotal molecular structural characteristics and high-level semantic information. Upon completion of pre-training, Graph Neural Network (GNN) Encoder is used for the prediction of downstream tasks. In comparison to advanced baseline models, MolIG exhibits enhanced performance in downstream tasks pertaining to molecular property prediction within benchmark groups such as MoleculeNet Benchmark Group and ADMET Benchmark Group. ",
    "url": "https://arxiv.org/abs/2311.16666",
    "authors": [
      "Zhuoyuan Wang",
      "Jiacong Mi",
      "Shan Lu",
      "Jieyue He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Chemical Physics (physics.chem-ph)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2311.16668",
    "title": "LiveNVS: Neural View Synthesis on Live RGB-D Streams",
    "abstract": "Existing real-time RGB-D reconstruction approaches, like Kinect Fusion, lack real-time photo-realistic visualization. This is due to noisy, oversmoothed or incomplete geometry and blurry textures which are fused from imperfect depth maps and camera poses. Recent neural rendering methods can overcome many of such artifacts but are mostly optimized for offline usage, hindering the integration into a live reconstruction pipeline. In this paper, we present LiveNVS, a system that allows for neural novel view synthesis on a live RGB-D input stream with very low latency and real-time rendering. Based on the RGB-D input stream, novel views are rendered by projecting neural features into the target view via a densely fused depth map and aggregating the features in image-space to a target feature map. A generalizable neural network then translates the target feature map into a high-quality RGB image. LiveNVS achieves state-of-the-art neural rendering quality of unknown scenes during capturing, allowing users to virtually explore the scene and assess reconstruction quality in real-time. ",
    "url": "https://arxiv.org/abs/2311.16668",
    "authors": [
      "Laura Fink",
      "Darius R\u00fcckert",
      "Linus Franke",
      "Joachim Keinert",
      "Marc Stamminger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2311.16670",
    "title": "PyTorch Geometric High Order: A Unified Library for High Order Graph  Neural Network",
    "abstract": "We introduce PyTorch Geometric High Order (PyGHO), a library for High Order Graph Neural Networks (HOGNNs) that extends PyTorch Geometric (PyG). Unlike ordinary Message Passing Neural Networks (MPNNs) that exchange messages between nodes, HOGNNs, encompassing subgraph GNNs and k-WL GNNs, encode node tuples, a method previously lacking a standardized framework and often requiring complex coding. PyGHO's main objective is to provide an unified and user-friendly interface for various HOGNNs. It accomplishes this through streamlined data structures for node tuples, comprehensive data processing utilities, and a flexible suite of operators for high-order GNN methodologies. In this work, we present a detailed in-depth of PyGHO and compare HOGNNs implemented with PyGHO with their official implementation on real-world tasks. PyGHO achieves up to $50\\%$ acceleration and reduces the code needed for implementation by an order of magnitude. Our library is available at \\url{https://github.com/GraphPKU/PygHO}. ",
    "url": "https://arxiv.org/abs/2311.16670",
    "authors": [
      "Xiyuan Wang",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16671",
    "title": "SplitNeRF: Split Sum Approximation Neural Field for Joint Geometry,  Illumination, and Material Estimation",
    "abstract": "We present a novel approach for digitizing real-world objects by estimating their geometry, material properties, and environmental lighting from a set of posed images with fixed lighting. Our method incorporates into Neural Radiance Field (NeRF) pipelines the split sum approximation used with image-based lighting for real-time physical-based rendering. We propose modeling the scene's lighting with a single scene-specific MLP representing pre-integrated image-based lighting at arbitrary resolutions. We achieve accurate modeling of pre-integrated lighting by exploiting a novel regularizer based on efficient Monte Carlo sampling. Additionally, we propose a new method of supervising self-occlusion predictions by exploiting a similar regularizer based on Monte Carlo sampling. Experimental results demonstrate the efficiency and effectiveness of our approach in estimating scene geometry, material properties, and lighting. Our method is capable of attaining state-of-the-art relighting quality after only ${\\sim}1$ hour of training in a single NVIDIA A100 GPU. ",
    "url": "https://arxiv.org/abs/2311.16671",
    "authors": [
      "Jesus Zarzar",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2311.16683",
    "title": "Hyper-Relational Knowledge Graph Neural Network for Next POI",
    "abstract": "With the advancement of mobile technology, Point of Interest (POI) recommendation systems in Location-based Social Networks (LBSN) have brought numerous benefits to both users and companies. Many existing works employ Knowledge Graph (KG) to alleviate the data sparsity issue in LBSN. These approaches primarily focus on modeling the pair-wise relations in LBSN to enrich the semantics and thereby relieve the data sparsity issue. However, existing approaches seldom consider the hyper-relations in LBSN, such as the mobility relation (a 3-ary relation: user-POI-time). This makes the model hard to exploit the semantics accurately. In addition, prior works overlook the rich structural information inherent in KG, which consists of higher-order relations and can further alleviate the impact of data sparsity.To this end, we propose a Hyper-Relational Knowledge Graph Neural Network (HKGNN) model. In HKGNN, a Hyper-Relational Knowledge Graph (HKG) that models the LBSN data is constructed to maintain and exploit the rich semantics of hyper-relations. Then we proposed a Hypergraph Neural Network to utilize the structural information of HKG in a cohesive way. In addition, a self-attention network is used to leverage sequential information and make personalized recommendations. Furthermore, side information, essential in reducing data sparsity by providing background knowledge of POIs, is not fully utilized in current methods. In light of this, we extended the current dataset with available side information to further lessen the impact of data sparsity. Results of experiments on four real-world LBSN datasets demonstrate the effectiveness of our approach compared to existing state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2311.16683",
    "authors": [
      "Jixiao Zhang",
      "Yongkang Li",
      "Ruotong Zou",
      "Jingyuan Zhang",
      "Zipei Fan",
      "Xuan Song"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16716",
    "title": "Graph Pre-training and Prompt Learning for Recommendation",
    "abstract": "GNN-based recommenders have excelled in modeling intricate user-item interactions through multi-hop message passing. However, existing methods often overlook the dynamic nature of evolving user-item interactions, which impedes the adaption to changing user preferences and distribution shifts in newly arriving data. Thus, their scalability and performances in real-world dynamic environments are limited. In this study, we propose GraphPL, a framework that incorporates parameter-efficient and dynamic graph pre-training with prompt learning. This novel combination empowers GNNs to effectively capture both long-term user preferences and short-term behavior dynamics, enabling the delivery of accurate and timely recommendations. Our GraphPL framework addresses the challenge of evolving user preferences by seamlessly integrating a temporal prompt mechanism and a graph-structural prompt learning mechanism into the pre-trained GNN model. The temporal prompt mechanism encodes time information on user-item interaction, allowing the model to naturally capture temporal context, while the graph-structural prompt learning mechanism enables the transfer of pre-trained knowledge to adapt to behavior dynamics without the need for continuous incremental training. We further bring in a dynamic evaluation setting for recommendation to mimic real-world dynamic scenarios and bridge the offline-online gap to a better level. Our extensive experiments including a large-scale industrial deployment showcases the lightweight plug-in scalability of our GraphPL when integrated with various state-of-the-art recommenders, emphasizing the advantages of GraphPL in terms of effectiveness, robustness and efficiency. ",
    "url": "https://arxiv.org/abs/2311.16716",
    "authors": [
      "Yuhao Yang",
      "Lianghao Xia",
      "Da Luo",
      "Kangyi Lin",
      "Chao Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.16733",
    "title": "LLMs for Science: Usage for Code Generation and Data Analysis",
    "abstract": "Large language models (LLMs) have been touted to enable increased productivity in many areas of today's work life. Scientific research as an area of work is no exception: the potential of LLM-based tools to assist in the daily work of scientists has become a highly discussed topic across disciplines. However, we are only at the very onset of this subject of study. It is still unclear how the potential of LLMs will materialise in research practice. With this study, we give first empirical evidence on the use of LLMs in the research process. We have investigated a set of use cases for LLM-based tools in scientific research, and conducted a first study to assess to which degree current tools are helpful. In this paper we report specifically on use cases related to software engineering, such as generating application code and developing scripts for data analytics. While we studied seemingly simple use cases, results across tools differ significantly. Our results highlight the promise of LLM-based tools in general, yet we also observe various issues, particularly regarding the integrity of the output these tools provide. ",
    "url": "https://arxiv.org/abs/2311.16733",
    "authors": [
      "Mohamed Nejjar",
      "Luca Zacharias",
      "Fabian Stiehle",
      "Ingo Weber"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.16738",
    "title": "Riemannian Self-Attention Mechanism for SPD Networks",
    "abstract": "Symmetric positive definite (SPD) matrix has been demonstrated to be an effective feature descriptor in many scientific areas, as it can encode spatiotemporal statistics of the data adequately on a curved Riemannian manifold, i.e., SPD manifold. Although there are many different ways to design network architectures for SPD matrix nonlinear learning, very few solutions explicitly mine the geometrical dependencies of features at different layers. Motivated by the great success of self-attention mechanism in capturing long-range relationships, an SPD manifold self-attention mechanism (SMSA) is proposed in this paper using some manifold-valued geometric operations, mainly the Riemannian metric, Riemannian mean, and Riemannian optimization. Then, an SMSA-based geometric learning module (SMSA-GLM) is designed for the sake of improving the discrimination of the generated deep structured representations. Extensive experimental results achieved on three benchmarking datasets show that our modification against the baseline network further alleviates the information degradation problem and leads to improved accuracy. ",
    "url": "https://arxiv.org/abs/2311.16738",
    "authors": [
      "Rui Wang",
      "Xiao-Jun Wu",
      "Hui Li",
      "Josef Kittler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16773",
    "title": "Multi-Channel Cross Modal Detection of Synthetic Face Images",
    "abstract": "Synthetically generated face images have shown to be indistinguishable from real images by humans and as such can lead to a lack of trust in digital content as they can, for instance, be used to spread misinformation. Therefore, the need to develop algorithms for detecting entirely synthetic face images is apparent. Of interest are images generated by state-of-the-art deep learning-based models, as these exhibit a high level of visual realism. Recent works have demonstrated that detecting such synthetic face images under realistic circumstances remains difficult as new and improved generative models are proposed with rapid speed and arbitrary image post-processing can be applied. In this work, we propose a multi-channel architecture for detecting entirely synthetic face images which analyses information both in the frequency and visible spectra using Cross Modal Focal Loss. We compare the proposed architecture with several related architectures trained using Binary Cross Entropy and show in cross-model experiments that the proposed architecture supervised using Cross Modal Focal Loss, in general, achieves most competitive performance. ",
    "url": "https://arxiv.org/abs/2311.16773",
    "authors": [
      "M. Ibsen",
      "C. Rathgeb",
      "S. Marcel",
      "C. Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16804",
    "title": "Advancements in Arc Fault Detection for Electrical Distribution Systems:  A Comprehensive Review from Artificial Intelligence Perspective",
    "abstract": "This comprehensive review paper provides a thorough examination of current advancements and research in the field of arc fault detection for electrical distribution systems. The increasing demand for electricity, coupled with the increasing utilization of renewable energy sources, has necessitated vigilance in safeguarding electrical distribution systems against arc faults. Such faults could lead to catastrophic accidents, including fires, equipment damage, loss of human life, and other critical issues. To mitigate these risks, this review article focuses on the identification and early detection of arc faults, with a particular emphasis on the vital role of artificial intelligence (AI) in the detection and prediction of arc faults. The paper explores a wide range of methodologies for arc fault detection and highlights the superior performance of AI-based methods in accurately identifying arc faults when compared to other approaches. A thorough evaluation of existing methodologies is conducted by categorizing them into distinct groups, which provides a structured framework for understanding the current state of arc fault detection techniques. This categorization serves as a foundation for identifying the existing constraints and future research avenues in the domain of arc fault detection for electrical distribution systems. This review paper provides the state of the art in arc fault detection, aiming to enhance safety and reliability in electrical distribution systems and guide future research efforts. ",
    "url": "https://arxiv.org/abs/2311.16804",
    "authors": [
      "Kriti Thakur",
      "Divyanshi Dwivedi",
      "K. Victor Sam Moses Babu",
      "Alivelu Manga Parimi",
      "Pradeep Kumar Yemula",
      "Pratyush Chakraborty",
      "Mayukha Pal"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.16818",
    "title": "DI-Net : Decomposed Implicit Garment Transfer Network for Digital  Clothed 3D Human",
    "abstract": "3D virtual try-on enjoys many potential applications and hence has attracted wide attention. However, it remains a challenging task that has not been adequately solved. Existing 2D virtual try-on methods cannot be directly extended to 3D since they lack the ability to perceive the depth of each pixel. Besides, 3D virtual try-on approaches are mostly built on the fixed topological structure and with heavy computation. To deal with these problems, we propose a Decomposed Implicit garment transfer network (DI-Net), which can effortlessly reconstruct a 3D human mesh with the newly try-on result and preserve the texture from an arbitrary perspective. Specifically, DI-Net consists of two modules: 1) A complementary warping module that warps the reference image to have the same pose as the source image through dense correspondence learning and sparse flow learning; 2) A geometry-aware decomposed transfer module that decomposes the garment transfer into image layout based transfer and texture based transfer, achieving surface and texture reconstruction by constructing pixel-aligned implicit functions. Experimental results show the effectiveness and superiority of our method in the 3D virtual try-on task, which can yield more high-quality results over other existing methods. ",
    "url": "https://arxiv.org/abs/2311.16818",
    "authors": [
      "Xiaojing Zhong",
      "Yukun Su",
      "Zhonghua Wu",
      "Guosheng Lin",
      "Qingyao Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16833",
    "title": "1-Lipschitz Layers Compared: Memory, Speed, and Certifiable Robustness",
    "abstract": "The robustness of neural networks against input perturbations with bounded magnitude represents a serious concern in the deployment of deep learning models in safety-critical systems. Recently, the scientific community has focused on enhancing certifiable robustness guarantees by crafting 1-Lipschitz neural networks that leverage Lipschitz bounded dense and convolutional layers. Although different methods have been proposed in the literature to achieve this goal, understanding the performance of such methods is not straightforward, since different metrics can be relevant (e.g., training time, memory usage, accuracy, certifiable robustness) for different applications. For this reason, this work provides a thorough theoretical and empirical comparison between methods by evaluating them in terms of memory usage, speed, and certifiable robust accuracy. The paper also provides some guidelines and recommendations to support the user in selecting the methods that work best depending on the available resources. We provide code at https://github.com/berndprach/1LipschitzLayersCompared. ",
    "url": "https://arxiv.org/abs/2311.16833",
    "authors": [
      "Bernd Prach",
      "Fabio Brau",
      "Giorgio Buttazzo",
      "Christoph H. Lampert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.16834",
    "title": "Modular Neural Networks for Time Series Forecasting: Interpretability  and Feature Selection using Attention",
    "abstract": "Multivariate time series have many applications, from healthcare and meteorology to life science. Although deep learning models have shown excellent predictive performance for time series, they have been criticised for being \"black-boxes\" or non-interpretable. This paper proposes a novel modular neural network model for multivariate time series prediction that is interpretable by construction. A recurrent neural network learns the temporal dependencies in the data while an attention-based feature selection component selects the most relevant features and suppresses redundant features used in the learning of the temporal dependencies. A modular deep network is trained from the selected features independently to show the users how features influence outcomes, making the model interpretable. Experimental results show that this approach can outperform state-of-the-art interpretable Neural Additive Models (NAM) and variations thereof in both regression and classification of time series tasks, achieving a predictive performance that is comparable to the top non-interpretable methods for time series, LSTM and XGBoost. ",
    "url": "https://arxiv.org/abs/2311.16834",
    "authors": [
      "Qiqi Su",
      "Christos Kloukinas",
      "Artur d'Garcez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.16835",
    "title": "Unified-modal Salient Object Detection via Adaptive Prompt Learning",
    "abstract": "Existing single-modal and multi-modal salient object detection (SOD) methods focus on designing specific architectures tailored for their respective tasks. However, developing completely different models for different tasks leads to labor and time consumption, as well as high computational and practical deployment costs. In this paper, we make the first attempt to address both single-modal and multi-modal SOD in a unified framework called UniSOD. Nevertheless, assigning appropriate strategies to modality variable inputs is challenging. To this end, UniSOD learns modality-aware prompts with task-specific hints through adaptive prompt learning, which are plugged into the proposed pre-trained baseline SOD model to handle corresponding tasks, while only requiring few learnable parameters compared to training the entire model. Each modality-aware prompt is generated from a switchable prompt generation block, which performs structural switching solely relied on single-modal and multi-modal inputs. UniSOD achieves consistent performance improvement on 14 benchmark datasets for RGB, RGB-D, and RGB-T SOD, which demonstrates that our method effectively and efficiently unifies single-modal and multi-modal SOD tasks. ",
    "url": "https://arxiv.org/abs/2311.16835",
    "authors": [
      "Kunpeng Wang",
      "Chenglong Li",
      "Zhengzheng Tu",
      "Bin Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16856",
    "title": "Attentional Graph Neural Networks for Robust Massive Network  Localization",
    "abstract": "Graph neural networks (GNNs) have gained significant popularity for classification tasks in machine learning, yet their applications to regression problems remain limited. Concurrently, attention mechanisms have emerged as powerful tools in sequential learning tasks. In this paper, we employ GNNs and attention mechanisms to address a classical but challenging nonlinear regression problem: network localization. We propose a novel GNN-based network localization method that achieves exceptional stability and accuracy in the presence of severe non-line-of-sight (NLOS) propagations, while eliminating the need for laborious offline calibration or NLOS identification. Extensive experimental results validate the effectiveness and high accuracy of our GNN-based localization model, particularly in challenging NLOS scenarios. However, the proposed GNN-based model exhibits limited flexibility, and its accuracy is highly sensitive to a specific hyperparameter that determines the graph structure. To address the limitations and extend the applicability of the GNN-based model to real scenarios, we introduce two attentional graph neural networks (AGNNs) that offer enhanced flexibility and the ability to automatically learn the optimal hyperparameter for each node. Experimental results confirm that the AGNN models are able to enhance localization accuracy, providing a promising solution for real-world applications. We also provide some analyses of the improved performance achieved by the AGNN models from the perspectives of dynamic attention and signal denoising characteristics. ",
    "url": "https://arxiv.org/abs/2311.16856",
    "authors": [
      "Wenzhong Yan",
      "Juntao Wang",
      "Feng Yin",
      "Abdelhak M. Zoubir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.16876",
    "title": "Digital Twin-Enhanced Deep Reinforcement Learning for Resource  Management in Networks Slicing",
    "abstract": "Network slicing-based communication systems can dynamically and efficiently allocate resources for diversified services. However, due to the limitation of the network interface on channel access and the complexity of the resource allocation, it is challenging to achieve an acceptable solution in the practical system without precise prior knowledge of the dynamics probability model of the service requests. Existing work attempts to solve this problem using deep reinforcement learning (DRL), however, such methods usually require a lot of interaction with the real environment in order to achieve good results. In this paper, a framework consisting of a digital twin and reinforcement learning agents is present to handle the issue. Specifically, we propose to use the historical data and the neural networks to build a digital twin model to simulate the state variation law of the real environment. Then, we use the data generated by the network slicing environment to calibrate the digital twin so that it is in sync with the real environment. Finally, DRL for slice optimization optimizes its own performance in this virtual pre-verification environment. We conducted an exhaustive verification of the proposed digital twin framework to confirm its scalability. Specifically, we propose to use loss landscapes to visualize the generalization of DRL solutions. We explore a distillation-based optimization scheme for lightweight slicing strategies. In addition, we also extend the framework to offline reinforcement learning, where solutions can be used to obtain intelligent decisions based solely on historical data. Numerical simulation experiments show that the proposed digital twin can significantly improve the performance of the slice optimization strategy. ",
    "url": "https://arxiv.org/abs/2311.16876",
    "authors": [
      "Zhengming Zhang",
      "Yongming Huang",
      "Cheng Zhang",
      "Qingbi Zheng",
      "Luxi Yang",
      "Xiaohu You"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16878",
    "title": "Temporal Importance Factor for Loss Functions for CTR Prediction",
    "abstract": "Click-through rate (CTR) prediction is an important task for the companies to recommend products which better match user preferences. User behavior in digital advertising is dynamic and changes over time. It is crucial for the companies to capture the most recent trends to provide more accurate recommendations for users. In CTR prediction, most models use binary cross-entropy loss function. However, it does not focus on the data distribution shifts occurring over time. To address this problem, we propose a factor for the loss functions by utilizing the sequential nature of user-item interactions. This approach aims to focus on the most recent samples by penalizing them more through the loss function without forgetting the long-term information. Our solution is model-agnostic, and the temporal importance factor can be used with different loss functions. Offline experiments in both public and company datasets show that the temporal importance factor for loss functions outperforms the baseline loss functions considered. ",
    "url": "https://arxiv.org/abs/2311.16878",
    "authors": [
      "Ramazan Tar\u0131k T\u00fcrksoy",
      "Beyza T\u00fcrkmen",
      "Furkan Durmu\u015f"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2311.16883",
    "title": "Compressing the Backward Pass of Large-Scale Neural Architectures by  Structured Activation Pruning",
    "abstract": "The rise of Deep Neural Networks (DNNs) has led to an increase in model size and complexity, straining the memory capacity of GPUs. Sparsity in DNNs, characterized as structural or ephemeral, has gained attention as a solution. This work focuses on ephemeral sparsity, aiming to reduce memory consumption during training. It emphasizes the significance of activations, an often overlooked component, and their role in memory usage. This work employs structured pruning in Block Sparse Compressed Row (BSR) format in combination with a magnitude-based criterion to efficiently prune activations. We furthermore introduce efficient block-sparse operators for GPUs and showcase their effectiveness, as well as the superior compression offered by block sparsity. We report the effectiveness of activation pruning by evaluating training speed, accuracy, and memory usage of large-scale neural architectures on the example of ResMLP on image classification tasks. As a result, we observe a memory reduction of up to 32\\% while maintaining accuracy. Ultimately, our approach aims to democratize large-scale model training, reduce GPU requirements, and address ecological concerns. ",
    "url": "https://arxiv.org/abs/2311.16883",
    "authors": [
      "Daniel Barley",
      "Holger Fr\u00f6ning"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2311.16892",
    "title": "Enhancing Item-level Bundle Representation for Bundle Recommendation",
    "abstract": "Bundle recommendation approaches offer users a set of related items on a particular topic. The current state-of-the-art (SOTA) method utilizes contrastive learning to learn representations at both the bundle and item levels. However, due to the inherent difference between the bundle-level and item-level preferences, the item-level representations may not receive sufficient information from the bundle affiliations to make accurate predictions. In this paper, we propose a novel approach EBRec, short of Enhanced Bundle Recommendation, which incorporates two enhanced modules to explore inherent item-level bundle representations. First, we propose to incorporate the bundle-user-item (B-U-I) high-order correlations to explore more collaborative information, thus to enhance the previous bundle representation that solely relies on the bundle-item affiliation information. Second, we further enhance the B-U-I correlations by augmenting the observed user-item interactions with interactions generated from pre-trained models, thus improving the item-level bundle representations. We conduct extensive experiments on three public datasets, and the results justify the effectiveness of our approach as well as the two core modules. Codes and datasets are available at https://github.com/answermycode/EBRec. ",
    "url": "https://arxiv.org/abs/2311.16892",
    "authors": [
      "Xiaoyu Du",
      "Kun Qian",
      "Yunshan Ma",
      "Xinguang Xiang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2311.16894",
    "title": "Dendrogram distance: an evaluation metric for generative networks using  hierarchical clustering",
    "abstract": "We present a novel metric for generative modeling evaluation, focusing primarily on generative networks. The method uses dendrograms to represent real and fake data, allowing for the divergence between training and generated samples to be computed. This metric focus on mode collapse, targeting generators that are not able to capture all modes in the training set. To evaluate the proposed method it is introduced a validation scheme based on sampling from real datasets, therefore the metric is evaluated in a controlled environment and proves to be competitive with other state-of-the-art approaches. ",
    "url": "https://arxiv.org/abs/2311.16894",
    "authors": [
      "Gustavo Sutter Carvalho",
      "Moacir Antonelli Ponti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16905",
    "title": "Analyzing the Influence of Language Model-Generated Responses in  Mitigating Hate Speech on Social Media Directed at Ukrainian Refugees in  Poland",
    "abstract": "In the context of escalating hate speech and polarization on social media, this study investigates the potential of employing responses generated by Large Language Models (LLM), complemented with pertinent verified knowledge links, to counteract such trends. Through extensive A/B testing involving the posting of 753 automatically generated responses, the goal was to minimize the propagation of hate speech directed at Ukrainian refugees in Poland. The results indicate that deploying LLM-generated responses as replies to harmful tweets effectively diminishes user engagement, as measured by likes/impressions. When we respond to an original tweet, i.e., which is not a reply, we reduce the engagement of users by over 20\\% without increasing the number of impressions. On the other hand, our responses increase the ratio of the number of replies to a harmful tweet to impressions, especially if the harmful tweet is not original. Additionally, the study examines how generated responses influence the overall sentiment of tweets in the discussion, revealing that our intervention does not significantly alter the mean sentiment. This paper suggests the implementation of an automatic moderation system to combat hate speech on social media and provides an in-depth analysis of the A/B experiment, covering methodology, data collection, and statistical outcomes. Ethical considerations and challenges are also discussed, offering guidance for the development of discourse moderation systems leveraging the capabilities of generative AI. ",
    "url": "https://arxiv.org/abs/2311.16905",
    "authors": [
      "Jakub Podolak",
      "Szymon \u0141ukasik",
      "Pawe\u0142 Balawender",
      "Jan Ossowski",
      "Katarzyna B\u0105kowicz",
      "Piotr Sankowski"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2311.16912",
    "title": "Continuous optimization methods for the graph isomorphism problem",
    "abstract": "The graph isomorphism problem looks deceptively simple, but although polynomial-time algorithms exist for certain types of graphs such as planar graphs and graphs with bounded degree or eigenvalue multiplicity, its complexity class is still unknown. Information about potential isomorphisms between two graphs is contained in the eigenvalues and eigenvectors of their adjacency matrices. However, symmetries of graphs often lead to repeated eigenvalues so that associated eigenvectors are determined only up to basis rotations, which complicates graph isomorphism testing. We consider orthogonal and doubly stochastic relaxations of the graph isomorphism problem, analyze the geometric properties of the resulting solution spaces, and show that their complexity increases significantly if repeated eigenvalues exist. By restricting the search space to suitable subspaces, we derive an efficient Frank-Wolfe based continuous optimization approach for detecting isomorphisms. We illustrate the efficacy of the algorithm with the aid of various highly symmetric graphs. ",
    "url": "https://arxiv.org/abs/2311.16912",
    "authors": [
      "Stefan Klus",
      "Patrick Gel\u00df"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2311.16914",
    "title": "Brain-ID: Learning Robust Feature Representations for Brain Imaging",
    "abstract": "Recent learning-based approaches have made astonishing advances in calibrated medical imaging like computerized tomography, yet they struggle to generalize in uncalibrated modalities -- notoriously magnetic resonance imaging (MRI), where performance is highly sensitive to the differences in MR contrast, resolution, and orientation between the training and testing data. This prevents broad applicability to the diverse clinical acquisition protocols in the real world. We introduce Brain-ID, a robust feature representation learning strategy for brain imaging, which is contrast-agnostic, and robust to the brain anatomy of each subject regardless of the appearance of acquired images (i.e., deformation, contrast, resolution, orientation, artifacts, etc). Brain-ID is trained entirely on synthetic data, and easily adapts to downstream tasks with our proposed simple one-layer solution. We validate the robustness of Brain-ID features, and evaluate their performance in a variety of downstream applications, including both contrast-independent (anatomy reconstruction/contrast synthesis, brain segmentation), and contrast-dependent (super-resolution, bias field estimation) tasks. Extensive experiments on 6 public datasets demonstrate that Brain-ID achieves state-of-the-art performance in all tasks, and more importantly, preserves its performance when only limited training data is available. ",
    "url": "https://arxiv.org/abs/2311.16914",
    "authors": [
      "Peirong Liu",
      "Oula Puonti",
      "Xiaoling Hu",
      "Daniel C. Alexander",
      "Juan Eugenio Iglesias"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16940",
    "title": "FP-Fed: Privacy-Preserving Federated Detection of Browser Fingerprinting",
    "abstract": "Browser fingerprinting often provides an attractive alternative to third-party cookies for tracking users across the web. In fact, the increasing restrictions on third-party cookies placed by common web browsers and recent regulations like the GDPR may accelerate the transition. To counter browser fingerprinting, previous work proposed several techniques to detect its prevalence and severity. However, these rely on 1) centralized web crawls and/or 2) computationally intensive operations to extract and process signals (e.g., information-flow and static analysis). To address these limitations, we present FP-Fed, the first distributed system for browser fingerprinting detection. Using FP-Fed, users can collaboratively train on-device models based on their real browsing patterns, without sharing their training data with a central entity, by relying on Differentially Private Federated Learning (DP-FL). To demonstrate its feasibility and effectiveness, we evaluate FP-Fed's performance on a set of 18.3k popular websites with different privacy levels, numbers of participants, and features extracted from the scripts. Our experiments show that FP-Fed achieves reasonably high detection performance and can perform both training and inference efficiently, on-device, by only relying on runtime signals extracted from the execution trace, without requiring any resource-intensive operation. ",
    "url": "https://arxiv.org/abs/2311.16940",
    "authors": [
      "Meenatchi Sundaram Muthu Selva Annamalai",
      "Igor Bilogrevic",
      "Emiliano De Cristofaro"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2311.16941",
    "title": "Debiasing Multimodal Models via Causal Information Minimization",
    "abstract": "Most existing debiasing methods for multimodal models, including causal intervention and inference methods, utilize approximate heuristics to represent the biases, such as shallow features from early stages of training or unimodal features for multimodal tasks like VQA, etc., which may not be accurate. In this paper, we study bias arising from confounders in a causal graph for multimodal data and examine a novel approach that leverages causally-motivated information minimization to learn the confounder representations. Robust predictive features contain diverse information that helps a model generalize to out-of-distribution data. Hence, minimizing the information content of features obtained from a pretrained biased model helps learn the simplest predictive features that capture the underlying data distribution. We treat these features as confounder representations and use them via methods motivated by causal theory to remove bias from models. We find that the learned confounder representations indeed capture dataset biases, and the proposed debiasing methods improve out-of-distribution (OOD) performance on multiple multimodal datasets without sacrificing in-distribution performance. Additionally, we introduce a novel metric to quantify the sufficiency of spurious features in models' predictions that further demonstrates the effectiveness of our proposed methods. Our code is available at: https://github.com/Vaidehi99/CausalInfoMin ",
    "url": "https://arxiv.org/abs/2311.16941",
    "authors": [
      "Vaidehi Patil",
      "Adyasha Maharana",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2311.16943",
    "title": "Image segmentation with traveling waves in an exactly solvable recurrent  neural network",
    "abstract": "We study image segmentation using spatiotemporal dynamics in a recurrent neural network where the state of each unit is given by a complex number. We show that this network generates sophisticated spatiotemporal dynamics that can effectively divide an image into groups according to a scene's structural characteristics. Using an exact solution of the recurrent network's dynamics, we present a precise description of the mechanism underlying object segmentation in this network, providing a clear mathematical interpretation of how the network performs this task. We then demonstrate a simple algorithm for object segmentation that generalizes across inputs ranging from simple geometric objects in grayscale images to natural images. Object segmentation across all images is accomplished with one recurrent neural network that has a single, fixed set of weights. This demonstrates the expressive potential of recurrent neural networks when constructed using a mathematical approach that brings together their structure, dynamics, and computation. ",
    "url": "https://arxiv.org/abs/2311.16943",
    "authors": [
      "Luisa H. B. Liboni",
      "Roberto C. Budzinski",
      "Alexandra N. Busch",
      "Sindy L\u00f6we",
      "Thomas A. Keller",
      "Max Welling",
      "Lyle E. Muller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.16944",
    "title": "Teaching DevOps Security Education with Hands-on Labware: Automated  Detection of Security Weakness in Python",
    "abstract": "The field of DevOps security education necessitates innovative approaches to effectively address the ever-evolving challenges of cybersecurity. In adopting a student-centered ap-proach, there is the need for the design and development of a comprehensive set of hands-on learning modules. In this paper, we introduce hands-on learning modules that enable learners to be familiar with identifying known security weaknesses, based on taint tracking to accurately pinpoint vulnerable code. To cultivate an engaging and motivating learning environment, our hands-on approach includes a pre-lab, hands-on and post lab sections. They all provide introduction to specific DevOps topics and software security problems at hand, followed by practicing with real world code examples having security issues to detect them using tools. The initial evaluation results from a number of courses across multiple schools show that the hands-on modules are enhancing the interests among students on software security and cybersecurity, while preparing them to address DevOps security vulnerabilities. ",
    "url": "https://arxiv.org/abs/2311.16944",
    "authors": [
      "Mst Shapna Akter",
      "Juanjose Rodriguez-Cardenas",
      "Hossain Shahriar",
      "Akond Rahman",
      "Fan Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.16945",
    "title": "UC-NeRF: Neural Radiance Field for Under-Calibrated multi-view cameras  in autonomous driving",
    "abstract": "Multi-camera setups find widespread use across various applications, such as autonomous driving, as they greatly expand sensing capabilities. Despite the fast development of Neural radiance field (NeRF) techniques and their wide applications in both indoor and outdoor scenes, applying NeRF to multi-camera systems remains very challenging. This is primarily due to the inherent under-calibration issues in multi-camera setup, including inconsistent imaging effects stemming from separately calibrated image signal processing units in diverse cameras, and system errors arising from mechanical vibrations during driving that affect relative camera poses. In this paper, we present UC-NeRF, a novel method tailored for novel view synthesis in under-calibrated multi-view camera systems. Firstly, we propose a layer-based color correction to rectify the color inconsistency in different image regions. Second, we propose virtual warping to generate more viewpoint-diverse but color-consistent virtual views for color correction and 3D recovery. Finally, a spatiotemporally constrained pose refinement is designed for more robust and accurate pose calibration in multi-camera systems. Our method not only achieves state-of-the-art performance of novel view synthesis in multi-camera setups, but also effectively facilitates depth estimation in large-scale outdoor scenes with the synthesized novel views. ",
    "url": "https://arxiv.org/abs/2311.16945",
    "authors": [
      "Kai Cheng",
      "Xiaoxiao Long",
      "Wei Yin",
      "Jin Wang",
      "Zhiqiang Wu",
      "Yuexin Ma",
      "Kaixuan Wang",
      "Xiaozhi Chen",
      "Xuejin Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16953",
    "title": "Local certification of geometric graph classes",
    "abstract": "The goal of local certification is to locally convince the vertices of a graph $G$ that $G$ satisfies a given property. A prover assigns short certificates to the vertices of the graph, then the vertices are allowed to check their certificates and the certificates of their neighbors, and based only on this local view, they must decide whether $G$ satisfies the given property. If the graph indeed satisfies the property, all vertices must accept the instance, and otherwise at least one vertex must reject the instance (for any possible assignment of certificates). The goal is to minimize to size of the certificates. In this paper we study the local certification of geometric and topological graph classes. While it is known that in $n$-vertex graphs, planarity can be certified locally with certificates of size $O(\\log n)$, we show that several closely related graph classes require certificates of size $\\Omega(n)$. This includes penny graphs, unit-distance graphs, (induced) subgraphs of the square grid, 1-planar graphs, and unit-square graphs. For unit-disk graphs we obtain a lower bound of $\\Omega(n^{1-\\delta})$ for any $\\delta>0$ on the size of the certificates. All our results are tight up to a $n^{o(1)}$ factor, and give the first known examples of hereditary (and even monotone) graph classes for which the certificates must have polynomial size. The lower bounds are obtained by proving rigidity properties of the considered graphs, which might be of independent interest. ",
    "url": "https://arxiv.org/abs/2311.16953",
    "authors": [
      "Oscar Defrain",
      "Louis Esperet",
      "Aur\u00e9lie Lagoutte",
      "Pat Morin",
      "Jean-Florent Raymond"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.16957",
    "title": "Space-Efficient Data Structures for Polyominoes and Bar Graphs",
    "abstract": "We provide a compact data structure for representing polyominoes that supports neighborhood and visibility queries. Neighborhood queries concern reporting adjacent cells to a given cell, and visibility queries determine whether a straight line can be drawn within the polyomino that connects two specified cells. For an arbitrary small $\\epsilon >0$, our data structure can encode a polyomino with $n$ cells in $(3+\\epsilon)n + o(n)$ bits while supporting all queries in constant time. The space complexity can be improved to $3n+o(n)$, while supporting neighborhood queries in $\\mathcal{O}(1)$ and visibility queries in $\\mathcal{O}(t(n))$ for any arbitrary $t(n) \\in \\omega(1)$. Previous attempts at enumerating polyominoes have indicated that at least $2.00091n - o(n)$ bits are required to differentiate between distinct polyominoes, which shows our data structure is compact. In addition, we introduce a succinct data structure tailored for bar graphs, a specific subclass of polyominoes resembling histograms. We demonstrate that a bar graph comprising $n$ cells can be encoded using only $n + o(n)$ bits, enabling constant-time query processing. Meanwhile, $n-1$ bits are necessary to represent any bar graph, proving our data structure is succinct. ",
    "url": "https://arxiv.org/abs/2311.16957",
    "authors": [
      "Magnus Berg",
      "Shahin Kamali",
      "Katherine Ling",
      "Cooper Sigrist"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2311.16959",
    "title": "Principal-Agent Problem with Third Party: Information Design from Social  Planner's Perspective",
    "abstract": "We study the principal-agent problem with a third party that we call social planner, whose responsibility is to reconcile the conflicts of interest between the two players and induce socially optimal outcome in terms of some given social utility function. The social planner owns no contractual power but manages to control the information flow between the principal and the agent. We design a simple workflow with two stages for the social planner. In the first stage, the problem is reformulated as an optimization problem whose solution is the optimal utility profile. In the second stage, we investigate information design and show that binary-signal information structure suffices to induce the socially optimal outcome determined in the first stage. The result shows that information plays a key role in social planning in the principal-agent model. ",
    "url": "https://arxiv.org/abs/2311.16959",
    "authors": [
      "Shiyun Lin",
      "Zhihua Zhang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2311.17010",
    "title": "Node Connectivity Augmentation of Highly Connected Graphs",
    "abstract": "Node-connectivity augmentation is a fundamental network design problem. We are given a $k$-node connected graph $G$ together with an additional set of links, and the goal is to add a cheap subset of links to $G$ to make it $(k+1)$-node connected. In this work, we characterize completely the computational complexity status of the problem, by showing hardness for all values of $k$ which were not addressed previously in the literature. We then focus on $k$-node connectivity augmentation for $k=n-4$, which corresponds to the highest value of $k$ for which the problem is NP-hard. We improve over the previously best known approximation bounds for this problem, by developing a $\\frac{3}{2}$-approximation algorithm for the weighted setting, and a $\\frac{4}{3}$-approximation algorithm for the unweighted setting. ",
    "url": "https://arxiv.org/abs/2311.17010",
    "authors": [
      "Waldo Galvez",
      "Dylan Hyatt-Denesik",
      "Afrouz Jabal Ameli",
      "Laura Sanita"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2311.17022",
    "title": "Message Recovery Attack in NTRU through VFK Lattices",
    "abstract": "In the present paper, we implement a message recovery attack to all variants of the NTRU cryptosystem. Our approach involves a reduction from the NTRU-lattice to a Voronoi First Kind lattice, enabling the application of a polynomial CVP exact algorithm crucial for executing the Message Recovery. The efficacy of our attack relies on a specific oracle that permits us to approximate an unknown quantity. Furthermore, we outline the mathematical conditions under which the attack is successful. Finally, we delve into a well-established polynomial algorithm for CVP on VFK lattices and its implementation, shedding light on its efficacy in our attack. Subsequently, we present comprehensive experimental results on the NTRU-HPS and the NTRU-Prime variants of the NIST submissions and propose a method that could indicate the resistance of the NTRU cryptosystem to our attack. ",
    "url": "https://arxiv.org/abs/2311.17022",
    "authors": [
      "Eirini Poimenidou",
      "Marios Adamoudis",
      "Konstantinos A. Draziotis",
      "Kostas Tsichlas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.17042",
    "title": "Adversarial Diffusion Distillation",
    "abstract": "We introduce Adversarial Diffusion Distillation (ADD), a novel training approach that efficiently samples large-scale foundational image diffusion models in just 1-4 steps while maintaining high image quality. We use score distillation to leverage large-scale off-the-shelf image diffusion models as a teacher signal in combination with an adversarial loss to ensure high image fidelity even in the low-step regime of one or two sampling steps. Our analyses show that our model clearly outperforms existing few-step methods (GANs, Latent Consistency Models) in a single step and reaches the performance of state-of-the-art diffusion models (SDXL) in only four steps. ADD is the first method to unlock single-step, real-time image synthesis with foundation models. Code and weights available under https://github.com/Stability-AI/generative-models and https://huggingface.co/stabilityai/ . ",
    "url": "https://arxiv.org/abs/2311.17042",
    "authors": [
      "Axel Sauer",
      "Dominik Lorenz",
      "Andreas Blattmann",
      "Robin Rombach"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17055",
    "title": "No Representation Rules Them All in Category Discovery",
    "abstract": "In this paper we tackle the problem of Generalized Category Discovery (GCD). Specifically, given a dataset with labelled and unlabelled images, the task is to cluster all images in the unlabelled subset, whether or not they belong to the labelled categories. Our first contribution is to recognize that most existing GCD benchmarks only contain labels for a single clustering of the data, making it difficult to ascertain whether models are using the available labels to solve the GCD task, or simply solving an unsupervised clustering problem. As such, we present a synthetic dataset, named 'Clevr-4', for category discovery. Clevr-4 contains four equally valid partitions of the data, i.e based on object shape, texture, color or count. To solve the task, models are required to extrapolate the taxonomy specified by the labelled set, rather than simply latching onto a single natural grouping of the data. We use this dataset to demonstrate the limitations of unsupervised clustering in the GCD setting, showing that even very strong unsupervised models fail on Clevr-4. We further use Clevr-4 to examine the weaknesses of existing GCD algorithms, and propose a new method which addresses these shortcomings, leveraging consistent findings from the representation learning literature to do so. Our simple solution, which is based on 'mean teachers' and termed $\\mu$GCD, substantially outperforms implemented baselines on Clevr-4. Finally, when we transfer these findings to real data on the challenging Semantic Shift Benchmark (SSB), we find that $\\mu$GCD outperforms all prior work, setting a new state-of-the-art. For the project webpage, see https://www.robots.ox.ac.uk/~vgg/data/clevr4/ ",
    "url": "https://arxiv.org/abs/2311.17055",
    "authors": [
      "Sagar Vaze",
      "Andrea Vedaldi",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17056",
    "title": "Self-Supervised Motion Magnification by Backpropagating Through Optical  Flow",
    "abstract": "This paper presents a simple, self-supervised method for magnifying subtle motions in video: given an input video and a magnification factor, we manipulate the video such that its new optical flow is scaled by the desired amount. To train our model, we propose a loss function that estimates the optical flow of the generated video and penalizes how far if deviates from the given magnification factor. Thus, training involves differentiating through a pretrained optical flow network. Since our model is self-supervised, we can further improve its performance through test-time adaptation, by finetuning it on the input video. It can also be easily extended to magnify the motions of only user-selected objects. Our approach avoids the need for synthetic magnification datasets that have been used to train prior learning-based approaches. Instead, it leverages the existing capabilities of off-the-shelf motion estimators. We demonstrate the effectiveness of our method through evaluations of both visual quality and quantitative metrics on a range of real-world and synthetic videos, and we show our method works for both supervised and unsupervised optical flow methods. ",
    "url": "https://arxiv.org/abs/2311.17056",
    "authors": [
      "Zhaoying Pan",
      "Daniel Geng",
      "Andrew Owens"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17058",
    "title": "Panoptic Video Scene Graph Generation",
    "abstract": "Towards building comprehensive real-world visual perception systems, we propose and study a new problem called panoptic scene graph generation (PVSG). PVSG relates to the existing video scene graph generation (VidSGG) problem, which focuses on temporal interactions between humans and objects grounded with bounding boxes in videos. However, the limitation of bounding boxes in detecting non-rigid objects and backgrounds often causes VidSGG to miss key details crucial for comprehensive video understanding. In contrast, PVSG requires nodes in scene graphs to be grounded by more precise, pixel-level segmentation masks, which facilitate holistic scene understanding. To advance research in this new area, we contribute the PVSG dataset, which consists of 400 videos (289 third-person + 111 egocentric videos) with a total of 150K frames labeled with panoptic segmentation masks as well as fine, temporal scene graphs. We also provide a variety of baseline methods and share useful design practices for future work. ",
    "url": "https://arxiv.org/abs/2311.17058",
    "authors": [
      "Jingkang Yang",
      "Wenxuan Peng",
      "Xiangtai Li",
      "Zujin Guo",
      "Liangyu Chen",
      "Bo Li",
      "Zheng Ma",
      "Kaiyang Zhou",
      "Wayne Zhang",
      "Chen Change Loy",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.03688",
    "title": "Graph Parameters, Universal Obstructions, and WQO",
    "abstract": "We introduce the notion of universal obstruction of a graph parameter, with respect to some quasi-ordering relation. Universal obstructions may serve as compact characterizations of the asymptotic behavior of graph parameters. We provide order-theoretic conditions which imply that such a characterization is finite and, when this is the case, we present some algorithmic implications on the existence of fixed-parameter algorithms. ",
    "url": "https://arxiv.org/abs/2304.03688",
    "authors": [
      "Christophe Paul",
      "Evangelos Protopapas",
      "Dimitrios M. Thilikos"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2311.16111",
    "title": "Deep Explainability: Spin-Geometrical Neural Meta-Structures",
    "abstract": "We face up to the challenge of explainability in multimodal artificial intelligence. At the nexus of neuroscience-inspired and quantum computing, interpretable and transparent spin-geometrical meta-architectures for early fusion of large-scale, heterogeneous, graph-structured data are envisioned, harnessing recent evidence for relativistic quantum neural coding of (co-)behavioral states in the self-organizing brain, under competitive, multidimensional dynamics. The designs draw on a self-dual classical description - via special Clifford-Lipschitz operations - of spinorial quantum states within registers of at most 16 qubits for efficient encoding of exponentially large neural structures. Formally 'trained', Lorentz neural architectures with precisely one lateral layer of exclusively inhibitory interneurons accounting for anti-modalities, as well as their co-architectures with intra-layer connections are highlighted. In principle, the approach accommodates the fusion of up to 16 time-invariant interconnected (anti-)modalities and the explicit recognition of underlying multidimensional patterns. Comprehensive insights are expected to be gained through applications to multimodal big data, under real-world scenarios. ",
    "url": "https://arxiv.org/abs/2311.16111",
    "authors": [
      "Sofia Karamintziou",
      "Georgios Meditskos",
      "Dimos Ntioudis",
      "Thanassis Mavropoulos",
      "Stefanos Vrochidis",
      "Ioannis",
      "Kompatsiaris"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.16132",
    "title": "A novel RNA pseudouridine site prediction model using Utility Kernel and  data-driven parameters",
    "abstract": "RNA protein Interactions (RPIs) play an important role in biological systems. Recently, we have enumerated the RPIs at the residue level and have elucidated the minimum structural unit (MSU) in these interactions to be a stretch of five residues (Nucleotides/amino acids). Pseudouridine is the most frequent modification in RNA. The conversion of uridine to pseudouridine involves interactions between pseudouridine synthase and RNA. The existing models to predict the pseudouridine sites in a given RNA sequence mainly depend on user-defined features such as mono and dinucleotide composition/propensities of RNA sequences. Predicting pseudouridine sites is a non-linear classification problem with limited data points. Deep Learning models are efficient discriminators when the data set size is reasonably large and fail when there is a paucity of data ($<1000$ samples). To mitigate this problem, we propose a Support Vector Machine (SVM) Kernel based on utility theory from Economics, and using data-driven parameters (i.e. MSU) as features. For this purpose, we have used position-specific tri/quad/pentanucleotide composition/propensity (PSPC/PSPP) besides nucleotide and dineculeotide composition as features. SVMs are known to work well in small data regimes and kernels in SVM are designed to classify non-linear data. The proposed model outperforms the existing state-of-the-art models significantly (10%-15% on average). ",
    "url": "https://arxiv.org/abs/2311.16132",
    "authors": [
      "Sourabh Patil",
      "Archana Mathur",
      "Raviprasad Aduri",
      "Snehanshu Saha"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16135",
    "title": "Use of Deep Neural Networks for Uncertain Stress Functions with  Extensions to Impact Mechanics",
    "abstract": "Stress-strain curves, or more generally, stress functions, are an extremely important characterization of a material's mechanical properties. However, stress functions are often difficult to derive and are narrowly tailored to a specific material. Further, large deformations, high strain-rates, temperature sensitivity, and effect of material parameters compound modeling challenges. We propose a generalized deep neural network approach to model stress as a state function with quantile regression to capture uncertainty. We extend these models to uniaxial impact mechanics using stochastic differential equations to demonstrate a use case and provide a framework for implementing this uncertainty-aware stress function. We provide experiments benchmarking our approach against leading constitutive, machine learning, and transfer learning approaches to stress and impact mechanics modeling on publicly available and newly presented data sets. We also provide a framework to optimize material parameters given multiple competing impact scenarios. ",
    "url": "https://arxiv.org/abs/2311.16135",
    "authors": [
      "Garrett Blum",
      "Ryan Doris",
      "Diego Klabjan",
      "Horacio Espinosa",
      "Ron Szalkowski"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16160",
    "title": "Protein-ligand binding representation learning from fine-grained  interactions",
    "abstract": "The binding between proteins and ligands plays a crucial role in the realm of drug discovery. Previous deep learning approaches have shown promising results over traditional computationally intensive methods, but resulting in poor generalization due to limited supervised data. In this paper, we propose to learn protein-ligand binding representation in a self-supervised learning manner. Different from existing pre-training approaches which treat proteins and ligands individually, we emphasize to discern the intricate binding patterns from fine-grained interactions. Specifically, this self-supervised learning problem is formulated as a prediction of the conclusive binding complex structure given a pocket and ligand with a Transformer based interaction module, which naturally emulates the binding process. To ensure the representation of rich binding information, we introduce two pre-training tasks, i.e.~atomic pairwise distance map prediction and mask ligand reconstruction, which comprehensively model the fine-grained interactions from both structure and feature space. Extensive experiments have demonstrated the superiority of our method across various binding tasks, including protein-ligand affinity prediction, virtual screening and protein-ligand docking. ",
    "url": "https://arxiv.org/abs/2311.16160",
    "authors": [
      "Shikun Feng",
      "Minghao Li",
      "Yinjun Jia",
      "Weiying Ma",
      "Yanyan Lan"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16197",
    "title": "Generation of patient specific cardiac chamber models using generative  neural networks under a Bayesian framework for electroanatomical mapping",
    "abstract": "Electroanatomical mapping is a technique used in cardiology to create a detailed 3D map of the electrical activity in the heart. It is useful for diagnosis, treatment planning and real time guidance in cardiac ablation procedures to treat arrhythmias like atrial fibrillation. A probabilistic machine learning model trained on a library of CT/MRI scans of the heart can be used during electroanatomical mapping to generate a patient-specific 3D model of the chamber being mapped. The use of probabilistic machine learning models under a Bayesian framework provides a way to quantify uncertainty in results and provide a natural framework of interpretability of the model. Here we introduce a Bayesian approach to surface reconstruction of cardiac chamber models from a sparse 3D point cloud data acquired during electroanatomical mapping. We show how probabilistic graphical models trained on segmented CT/MRI data can be used to generate cardiac chamber models from few acquired locations thereby reducing procedure time and x-ray exposure. We show how they provide insight into what the neural network learns from the segmented CT/MRI images used to train the network, which provides explainability to the resulting cardiac chamber models generated by the model. ",
    "url": "https://arxiv.org/abs/2311.16197",
    "authors": [
      "Sunil Mathew",
      "Jasbir Sra",
      "Daniel B. Rowe"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16200",
    "title": "Streaming Lossless Volumetric Compression of Medical Images Using Gated  Recurrent Convolutional Neural Network",
    "abstract": "Deep learning-based lossless compression methods offer substantial advantages in compressing medical volumetric images. Nevertheless, many learning-based algorithms encounter a trade-off between practicality and compression performance. This paper introduces a hardware-friendly streaming lossless volumetric compression framework, utilizing merely one-thousandth of the model weights compared to other learning-based compression frameworks. We propose a gated recurrent convolutional neural network that combines diverse convolutional structures and fusion gate mechanisms to capture the inter-slice dependencies in volumetric images. Based on such contextual information, we can predict the pixel-by-pixel distribution for entropy coding. Guided by hardware/software co-design principles, we implement the proposed framework on Field Programmable Gate Array to achieve enhanced real-time performance. Extensive experimental results indicate that our method outperforms traditional lossless volumetric compressors and state-of-the-art learning-based lossless compression methods across various medical image benchmarks. Additionally, our method exhibits robust generalization ability and competitive compression speed ",
    "url": "https://arxiv.org/abs/2311.16200",
    "authors": [
      "Qianhao Chen",
      "Jietao Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16207",
    "title": "The Graph Convolutional Network with Multi-representation Alignment for  Drug Synergy Prediction",
    "abstract": "Drug combination refers to the use of two or more drugs to treat a specific disease at the same time. It is currently the mainstream way to treat complex diseases. Compared with single drugs, drug combinations have better efficacy and can better inhibit toxicity and drug resistance. The computational model based on deep learning concatenates the representation of multiple drugs and the corresponding cell line feature as input, and the output is whether the drug combination can have an inhibitory effect on the cell line. However, this strategy of concatenating multiple representations has the following defects: the alignment of drug representation and cell line representation is ignored, resulting in the synergistic relationship not being reflected positionally in the embedding space. Moreover, the alignment measurement function in deep learning cannot be suitable for drug synergy prediction tasks due to differences in input types. Therefore, in this work, we propose a graph convolutional network with multi-representation alignment (GCNMRA) for predicting drug synergy. In the GCNMRA model, we designed a multi-representation alignment function suitable for the drug synergy prediction task so that the positional relationship between drug representations and cell line representation is reflected in the embedding space. In addition, the vector modulus of drug representations and cell line representation is considered to improve the accuracy of calculation results and accelerate model convergence. Finally, many relevant experiments were run on multiple drug synergy datasets to verify the effectiveness of the above innovative elements and the excellence of the GCNMRA model. ",
    "url": "https://arxiv.org/abs/2311.16207",
    "authors": [
      "Xinxing Yang",
      "Genke Yang",
      "Jian Chu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16214",
    "title": "DGR: Tackling Drifted and Correlated Noise in Quantum Error Correction  via Decoding Graph Re-weighting",
    "abstract": "Quantum hardware suffers from high error rates and noise, which makes directly running applications on them ineffective. Quantum Error Correction (QEC) is a critical technique towards fault tolerance which encodes the quantum information distributively in multiple data qubits and uses syndrome qubits to check parity. Minimum-Weight-Perfect-Matching (MWPM) is a popular QEC decoder that takes the syndromes as input and finds the matchings between syndromes that infer the errors. However, there are two paramount challenges for MWPM decoders. First, as noise in real quantum systems can drift over time, there is a potential misalignment with the decoding graph's initial weights, leading to a severe performance degradation in the logical error rates. Second, while the MWPM decoder addresses independent errors, it falls short when encountering correlated errors typical on real hardware, such as those in the 2Q depolarizing channel. We propose DGR, an efficient decoding graph edge re-weighting strategy with no quantum overhead. It leverages the insight that the statistics of matchings across decoding iterations offer rich information about errors on real quantum hardware. By counting the occurrences of edges and edge pairs in decoded matchings, we can statistically estimate the up-to-date probabilities of each edge and the correlations between them. The reweighting process includes two vital steps: alignment re-weighting and correlation re-weighting. The former updates the MWPM weights based on statistics to align with actual noise, and the latter adjusts the weight considering edge correlations. Extensive evaluations on surface code and honeycomb code under various settings show that DGR reduces the logical error rate by 3.6x on average-case noise mismatch with exceeding 5000x improvement under worst-case mismatch. ",
    "url": "https://arxiv.org/abs/2311.16214",
    "authors": [
      "Hanrui Wang",
      "Pengyu Liu",
      "Yilian Liu",
      "Jiaqi Gu",
      "Jonathan Baker",
      "Frederic T. Chong",
      "Song Han"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16308",
    "title": "Compression-based inference of network motif sets",
    "abstract": "Physical and functional constraints on biological networks lead to complex topological patterns across multiple scales in their organization. A particular type of higher-order network feature that has received considerable interest is network motifs, defined as statistically regular subgraphs. These may implement fundamental logical and computational circuits and are referred as ``building blocks of complex networks''. Their well-defined structures and small sizes also enables the testing of their functions in synthetic and natural biological experiments. The statistical inference of network motifs is however fraught with difficulties, from defining and sampling the right null model to accounting for the large number of possible motifs and their potential correlations in statistical testing. Here we develop a framework for motif mining based on lossless network compression using subgraph contractions. The minimum description length principle allows us to select the most significant set of motifs as well as other prominent network features in terms of their combined compression of the network. The approach inherently accounts for multiple testing and correlations between subgraphs and does not rely on a priori specification of an appropriate null model. This provides an alternative definition of motif significance which guarantees more robust statistical inference. Our approach overcomes the common problems in classic testing-based motif analysis. We apply our methodology to perform comparative connectomics by evaluating the compressibility and the circuit motifs of a range of synaptic-resolution neural connectomes. ",
    "url": "https://arxiv.org/abs/2311.16308",
    "authors": [
      "Alexis B\u00e9nichou",
      "Jean-Baptiste Masson",
      "Christian L. Vestergaard"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2311.16333",
    "title": "From Reactive to Proactive Volatility Modeling with Hemisphere Neural  Networks",
    "abstract": "We reinvigorate maximum likelihood estimation (MLE) for macroeconomic density forecasting through a novel neural network architecture with dedicated mean and variance hemispheres. Our architecture features several key ingredients making MLE work in this context. First, the hemispheres share a common core at the entrance of the network which accommodates for various forms of time variation in the error variance. Second, we introduce a volatility emphasis constraint that breaks mean/variance indeterminacy in this class of overparametrized nonlinear models. Third, we conduct a blocked out-of-bag reality check to curb overfitting in both conditional moments. Fourth, the algorithm utilizes standard deep learning software and thus handles large data sets - both computationally and statistically. Ergo, our Hemisphere Neural Network (HNN) provides proactive volatility forecasts based on leading indicators when it can, and reactive volatility based on the magnitude of previous prediction errors when it must. We evaluate point and density forecasts with an extensive out-of-sample experiment and benchmark against a suite of models ranging from classics to more modern machine learning-based offerings. In all cases, HNN fares well by consistently providing accurate mean/variance forecasts for all targets and horizons. Studying the resulting volatility paths reveals its versatility, while probabilistic forecasting evaluation metrics showcase its enviable reliability. Finally, we also demonstrate how this machinery can be merged with other structured deep learning models by revisiting Goulet Coulombe (2022)'s Neural Phillips Curve. ",
    "url": "https://arxiv.org/abs/2311.16333",
    "authors": [
      "Philippe Goulet Coulombe",
      "Mikael Frenette",
      "Karin Klieber"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16490",
    "title": "SIRAN: Sinkhorn Distance Regularized Adversarial Network for DEM  Super-resolution using Discriminative Spatial Self-attention",
    "abstract": "Digital Elevation Model (DEM) is an essential aspect in the remote sensing domain to analyze and explore different applications related to surface elevation information. In this study, we intend to address the generation of high-resolution DEMs using high-resolution multi-spectral (MX) satellite imagery by incorporating adversarial learning. To promptly regulate this process, we utilize the notion of polarized self-attention of discriminator spatial maps as well as introduce a Densely connected Multi-Residual Block (DMRB) module to assist in efficient gradient flow. Further, we present an objective function related to optimizing Sinkhorn distance with traditional GAN to improve the stability of adversarial learning. In this regard, we provide both theoretical and empirical substantiation of better performance in terms of vanishing gradient issues and numerical convergence. We demonstrate both qualitative and quantitative outcomes with available state-of-the-art methods. Based on our experiments on DEM datasets of Shuttle Radar Topographic Mission (SRTM) and Cartosat-1, we show that the proposed model performs preferably against other learning-based state-of-the-art methods. We also generate and visualize several high-resolution DEMs covering terrains with diverse signatures to show the performance of our model. ",
    "url": "https://arxiv.org/abs/2311.16490",
    "authors": [
      "Subhajit Paul",
      "Ashutosh Gupta"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16583",
    "title": "The Inverse of the Complex Gamma Function",
    "abstract": "We consider the functional inverse of the Gamma function in the complex plane, where it is multi-valued, and define a set of suitable branches by proposing a natural extension from the real case. ",
    "url": "https://arxiv.org/abs/2311.16583",
    "authors": [
      "David J. Jeffrey",
      "Stephen M. Watt"
    ],
    "subjectives": [
      "Complex Variables (math.CV)",
      "Symbolic Computation (cs.SC)"
    ]
  },
  {
    "id": "arXiv:2311.16602",
    "title": "GSP-KalmanNet: Tracking Graph Signals via Neural-Aided Kalman Filtering",
    "abstract": "Dynamic systems of graph signals are encountered in various applications, including social networks, power grids, and transportation. While such systems can often be described as state space (SS) models, tracking graph signals via conventional tools based on the Kalman filter (KF) and its variants is typically challenging. This is due to the nonlinearity, high dimensionality, irregularity of the domain, and complex modeling associated with real-world dynamic systems of graph signals. In this work, we study the tracking of graph signals using a hybrid model-based/data-driven approach. We develop the GSP-KalmanNet, which tracks the hidden graphical states from the graphical measurements by jointly leveraging graph signal processing (GSP) tools and deep learning (DL) techniques. The derivations of the GSP-KalmanNet are based on extending the KF to exploit the inherent graph structure via graph frequency domain filtering, which considerably simplifies the computational complexity entailed in processing high-dimensional signals and increases the robustness to small topology changes. Then, we use data to learn the Kalman gain following the recently proposed KalmanNet framework, which copes with partial and approximated modeling, without forcing a specific model over the noise statistics. Our empirical results demonstrate that the proposed GSP-KalmanNet achieves enhanced accuracy and run time performance as well as improved robustness to model misspecifications compared with both model-based and data-driven benchmarks. ",
    "url": "https://arxiv.org/abs/2311.16602",
    "authors": [
      "Itay Buchnik",
      "Guy Sagi",
      "Nimrod Leinwand",
      "Yuval Loya",
      "Nir Shlezinger",
      "Tirza Routtenberg"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16628",
    "title": "Symmetry-regularized neural ordinary differential equations",
    "abstract": "Neural Ordinary Differential Equations (Neural ODEs) is a class of deep neural network models that interpret the hidden state dynamics of neural networks as an ordinary differential equation, thereby capable of capturing system dynamics in a continuous time framework. In this work, I integrate symmetry regularization into Neural ODEs. In particular, I use continuous Lie symmetry of ODEs and PDEs associated with the model to derive conservation laws and add them to the loss function, making it physics-informed. This incorporation of inherent structural properties into the loss function could significantly improve robustness and stability of the model during training. To illustrate this method, I employ a toy model that utilizes a cosine rate of change in the hidden state, showcasing the process of identifying Lie symmetries, deriving conservation laws, and constructing a new loss function. ",
    "url": "https://arxiv.org/abs/2311.16628",
    "authors": [
      "Wenbo Hao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.16707",
    "title": "Full-resolution MLPs Empower Medical Dense Prediction",
    "abstract": "Dense prediction is a fundamental requirement for many medical vision tasks such as medical image restoration, registration, and segmentation. The most popular vision model, Convolutional Neural Networks (CNNs), has reached bottlenecks due to the intrinsic locality of convolution operations. Recently, transformers have been widely adopted for dense prediction for their capability to capture long-range visual dependence. However, due to the high computational complexity and large memory consumption of self-attention operations, transformers are usually used at downsampled feature resolutions. Such usage cannot effectively leverage the tissue-level textural information available only at the full image resolution. This textural information is crucial for medical dense prediction as it can differentiate the subtle human anatomy in medical images. In this study, we hypothesize that Multi-layer Perceptrons (MLPs) are superior alternatives to transformers in medical dense prediction where tissue-level details dominate the performance, as MLPs enable long-range dependence at the full image resolution. To validate our hypothesis, we develop a full-resolution hierarchical MLP framework that uses MLPs beginning from the full image resolution. We evaluate this framework with various MLP blocks on a wide range of medical dense prediction tasks including restoration, registration, and segmentation. Extensive experiments on six public well-benchmarked datasets show that, by simply using MLPs at full resolution, our framework outperforms its CNN and transformer counterparts and achieves state-of-the-art performance on various medical dense prediction tasks. ",
    "url": "https://arxiv.org/abs/2311.16707",
    "authors": [
      "Mingyuan Meng",
      "Yuxin Xue",
      "Dagan Feng",
      "Lei Bi",
      "Jinman Kim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16848",
    "title": "Localization of a Passive Source with a Sensor Network based  Experimental Molecular Communication Platform",
    "abstract": "In a practical molecular communication scenario such as monitoring air pollutants released from an unknown source, it is essential to estimate the location of the molecular transmitter (TX). This paper presents a novel Sensor Network-based Localization Algorithm (SNCLA) for passive transmission by using a novel experimental platform which mainly comprises a clustered sensor network (SN) with $24$ sensor nodes and evaporating ethanol molecules as the passive TX. In SNCLA, a Gaussian plume model is employed to derive the location estimator. The parameters such as transmitted mass, wind velocity, detection time, and actual concentration are calculated or estimated from the measured signals via the SN to be employed as the input for the location estimator. The numerical results show that the performance of SNCLA is better for stronger winds in the medium. Our findings show that evaporated molecules do not propagate homogeneously through the SN due to the presence of the wind. In addition, our statistical analysis based on the measured experimental data shows that the sensed signals by the SN have a log-normal distribution, while the additive noise follows a Student's t-distribution in contrast to the Gaussian assumption in the literature. ",
    "url": "https://arxiv.org/abs/2311.16848",
    "authors": [
      "Fatih Gulec",
      "Damla Yagmur Koda",
      "Baris Atakan",
      "Andrew W. Eckford"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2311.16904",
    "title": "Study of BSM Inter-Packet Gap Tails in C-V2X Networks",
    "abstract": "Cellular vehicle-to-everything (C-V2X) enables safety-critical connected vehicular service by exchanging basic safety messages (BSMs) among nearby vehicular users (VUEs). Timely transmission of BSMs is crucial to avoid stale information at VUEs. However, successive packet losses can lead to large inter-packet gaps (IPGs), reducing the BSMs' reliability. This paper investigates the tail behavior of IPG and information age (IA) distributions in C-V2X mode 4, a decentralized resource allocation method based on semi-persistent scheduling (SPS). We study the improvements and trade-offs introduced by SAE one-shot transmission to decrease the number of successive BSM losses at destination VUEs. The study employs high-fidelity system-level simulations that closely follow the SPS process of CV2X mode 4 to evaluate the performance of interleaved one-shot SPS transmissions. The numerical results demonstrate significant improvement in the IPG and IA tail distributions in various simulation scenarios. Additionally, we propose an accurate analytical model to characterize the IPG tail behavior of C-V2X BSM transmissions. The proposed model is validated by comparing its results with those obtained using the system-level simulations. Our validation shows that the proposed model generates analytical results that coincide with the asymptotic slopes of IPG distribution in different BSM transmission modes. ",
    "url": "https://arxiv.org/abs/2311.16904",
    "authors": [
      "Abdurrahman Fouda",
      "Randall Berry",
      "Ivan Vukovic"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2311.16909",
    "title": "Multinomial belief networks",
    "abstract": "A Bayesian approach to machine learning is attractive when we need to quantify uncertainty, deal with missing observations, when samples are scarce, or when the data is sparse. All of these commonly apply when analysing healthcare data. To address these analytical requirements, we propose a deep generative model for multinomial count data where both the weights and hidden units of the network are Dirichlet distributed. A Gibbs sampling procedure is formulated that takes advantage of a series of augmentation relations, analogous to the Zhou-Cong-Chen model. We apply the model on small handwritten digits, and a large experimental dataset of DNA mutations in cancer, and we show how the model is able to extract biologically meaningful meta-signatures in a fully data-driven way. ",
    "url": "https://arxiv.org/abs/2311.16909",
    "authors": [
      "H. C. Donker",
      "D. Neijzen",
      "G. A. Lunter"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2311.16984",
    "title": "FedECA: A Federated External Control Arm Method for Causal Inference  with Time-To-Event Data in Distributed Settings",
    "abstract": "External control arms (ECA) can inform the early clinical development of experimental drugs and provide efficacy evidence for regulatory approval in non-randomized settings. However, the main challenge of implementing ECA lies in accessing real-world data or historical clinical trials. Indeed, data sharing is often not feasible due to privacy considerations related to data leaving the original collection centers, along with pharmaceutical companies' competitive motives. In this paper, we leverage a privacy-enhancing technology called federated learning (FL) to remove some of the barriers to data sharing. We introduce a federated learning inverse probability of treatment weighted (IPTW) method for time-to-event outcomes called FedECA which eases the implementation of ECA by limiting patients' data exposure. We show with extensive experiments that FedECA outperforms its closest competitor, matching-adjusted indirect comparison (MAIC), in terms of statistical power and ability to balance the treatment and control groups. To encourage the use of such methods, we publicly release our code which relies on Substra, an open-source FL software with proven experience in privacy-sensitive contexts. ",
    "url": "https://arxiv.org/abs/2311.16984",
    "authors": [
      "Jean Ogier du Terrail",
      "Quentin Klopfenstein",
      "Honghao Li",
      "Imke Mayer",
      "Nicolas Loiseau",
      "Mohammad Hallal",
      "F\u00e9lix Balazard",
      "Mathieu Andreux"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2007.10784",
    "title": "OccamNet: A Fast Neural Model for Symbolic Regression at Scale",
    "abstract": " Title: OccamNet: A Fast Neural Model for Symbolic Regression at Scale ",
    "url": "https://arxiv.org/abs/2007.10784",
    "authors": [
      "Owen Dugan",
      "Rumen Dangovski",
      "Allan Costa",
      "Samuel Kim",
      "Pawan Goyal",
      "Joseph Jacobson",
      "Marin Solja\u010di\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2105.08124",
    "title": "Planar Drawings with Few Slopes of Halin Graphs and Nested Pseudotrees",
    "abstract": " Comments: Extended version of \"Planar Drawings with Few Slopes of Halin Graphs and Nested Pseudotrees\" appeared in the Proceedings of the 17th Algorithms and Data Structures Symposium (WADS 2021) ",
    "url": "https://arxiv.org/abs/2105.08124",
    "authors": [
      "Steven Chaplick",
      "Giordano Da Lozzo",
      "Emilio Di Giacomo",
      "Giuseppe Liotta",
      "Fabrizio Montecchiani"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2106.14756",
    "title": "Differentially Private Algorithms for Graphs Under Continual Observation",
    "abstract": " Comments: Corrected typos in lower bounds in Table 1. Fixed missing factor $\\ell$ in statement of Theorem 45 ",
    "url": "https://arxiv.org/abs/2106.14756",
    "authors": [
      "Hendrik Fichtenberger",
      "Monika Henzinger",
      "Wolfgang Ost"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2108.04840",
    "title": "Post-hoc Interpretability for Neural NLP: A Survey",
    "abstract": " Title: Post-hoc Interpretability for Neural NLP: A Survey ",
    "url": "https://arxiv.org/abs/2108.04840",
    "authors": [
      "Andreas Madsen",
      "Siva Reddy",
      "Sarath Chandar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2111.10085",
    "title": "Mate! Are You Really Aware? An Explainability-Guided Testing Framework  for Robustness of Malware Detectors",
    "abstract": " Comments: Accepted at ESEC/FSE 2023. this https URL ",
    "url": "https://arxiv.org/abs/2111.10085",
    "authors": [
      "Ruoxi Sun",
      "Minhui Xue",
      "Gareth Tyson",
      "Tian Dong",
      "Shaofeng Li",
      "Shuo Wang",
      "Haojin Zhu",
      "Seyit Camtepe",
      "Surya Nepal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.03002",
    "title": "GraphPrompt: Graph-Based Prompt Templates for Biomedical Synonym  Prediction",
    "abstract": " Comments: 7 pages ",
    "url": "https://arxiv.org/abs/2112.03002",
    "authors": [
      "Hanwen Xu",
      "Jiayou Zhang",
      "Zhirui Wang",
      "Shizhuo Zhang",
      "Megh Manoj Bhalerao",
      "Yucong Liu",
      "Dawei Zhu",
      "Sheng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.05760",
    "title": "Big Data Analytics for Network Level Short-Term Travel Time Prediction  with Hierarchical LSTM",
    "abstract": " Title: Big Data Analytics for Network Level Short-Term Travel Time Prediction  with Hierarchical LSTM ",
    "url": "https://arxiv.org/abs/2201.05760",
    "authors": [
      "Tianya T. Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.06573",
    "title": "Speech intelligibility of simulated hearing loss sounds and its  prediction using the Gammachirp Envelope Similarity Index (GESI)",
    "abstract": " Comments: This preprint is a copy of the final version accepted for Interspeech 2022. See this https URL ",
    "url": "https://arxiv.org/abs/2206.06573",
    "authors": [
      "Toshio Irino",
      "Honoka Tamaru",
      "Ayako Yamamoto"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.08164",
    "title": "Long Range Graph Benchmark",
    "abstract": " Comments: Added reference to T\\\"onshoff et al., 2023 in Sec. 4.1; NeurIPS 2022 Track on D&B; Open-sourced at: this https URL ",
    "url": "https://arxiv.org/abs/2206.08164",
    "authors": [
      "Vijay Prakash Dwivedi",
      "Ladislav Ramp\u00e1\u0161ek",
      "Mikhail Galkin",
      "Ali Parviz",
      "Guy Wolf",
      "Anh Tuan Luu",
      "Dominique Beaini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.11792",
    "title": "Two-dimensional total absorption spectroscopy with conditional  generative adversarial networks",
    "abstract": " Title: Two-dimensional total absorption spectroscopy with conditional  generative adversarial networks ",
    "url": "https://arxiv.org/abs/2206.11792",
    "authors": [
      "Cade Dembski",
      "Michelle P. Kuchera",
      "Sean Liddick",
      "Raghu Ramanujan",
      "Artemis Spyrou"
    ],
    "subjectives": [
      "Nuclear Experiment (nucl-ex)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.13269",
    "title": "Wasserstein Distributionally Robust Estimation in High Dimensions:  Performance Analysis and Optimal Hyperparameter Tuning",
    "abstract": " Comments: This paper was previously titled \"The Performance of Wasserstein Distributionally Robust M-Estimators in High Dimensions\" ",
    "url": "https://arxiv.org/abs/2206.13269",
    "authors": [
      "Liviu Aolaritei",
      "Soroosh Shafiee",
      "Florian D\u00f6rfler"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2212.04548",
    "title": "STLGRU: Spatio-Temporal Lightweight Graph GRU for Traffic Flow  Prediction",
    "abstract": " Comments: We withdraw for now and shall further work on the manuscript and upload it again ",
    "url": "https://arxiv.org/abs/2212.04548",
    "authors": [
      "Kishor Kumar Bhaumik",
      "Fahim Faisal Niloy",
      "Saif Mahmud",
      "Simon Woo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.07221",
    "title": "On the Role of Randomization in Adversarially Robust Classification",
    "abstract": " Comments: 10 pages main paper (27 total), 2 figures in main paper. Neurips 2023 ",
    "url": "https://arxiv.org/abs/2302.07221",
    "authors": [
      "Lucas Gnecco-Heredia",
      "Yann Chevaleyre",
      "Benjamin Negrevergne",
      "Laurent Meunier",
      "Muni Sreenivas Pydi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.09554",
    "title": "Mixed Hierarchy Network for Image Restoration",
    "abstract": " Title: Mixed Hierarchy Network for Image Restoration ",
    "url": "https://arxiv.org/abs/2302.09554",
    "authors": [
      "Hu Gao",
      "Depeng Dang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.06222",
    "title": "Robust MADER: Decentralized Multiagent Trajectory Planner Robust to  Communication Delay in Dynamic Environments",
    "abstract": " Comments: 8 pagers, 10 figures,. arXiv admin note: substantial text overlap with arXiv:2209.13667 ",
    "url": "https://arxiv.org/abs/2303.06222",
    "authors": [
      "Kota Kondo",
      "Reinaldo Figueroa",
      "Juan Rached",
      "Jesus Tordesillas",
      "Parker C. Lusk",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2303.06842",
    "title": "Hierarchical Relationships: A New Perspective to Enhance Scene Graph  Generation",
    "abstract": " Comments: NeurIPS 2023 New Frontiers in Graph Learning Workshop (NeurIPS GLFrontiers 2023); NeurIPS 2023 Queer in AI Workshop ",
    "url": "https://arxiv.org/abs/2303.06842",
    "authors": [
      "Bowen Jiang",
      "Camillo J. Taylor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09373",
    "title": "MAPSeg: Unified Unsupervised Domain Adaptation for Heterogeneous Medical  Image Segmentation Based on 3D Masked Autoencoding and Pseudo-Labeling",
    "abstract": " Comments: 16 pages and 7 figures. Revised and extended to test-time and federated domain adaptation. Xuzhe Zhang and Yuhao Wu are co-first authors. Andrew F. Laine and Yun Wang are co-senior supervising authors ",
    "url": "https://arxiv.org/abs/2303.09373",
    "authors": [
      "Xuzhe Zhang",
      "Yuhao Wu",
      "Elsa Angelini",
      "Ang Li",
      "Jia Guo",
      "Jerod M. Rasmussen",
      "Thomas G. O'Connor",
      "Pathik D. Wadhwa",
      "Andrea Parolin Jackowski",
      "Hai Li",
      "Jonathan Posner",
      "Andrew F. Laine",
      "Yun Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.09656",
    "title": "Revealing complexities when adult readers engage in the credibility  evaluation of social media posts",
    "abstract": " Comments: 25 pages, 5 figures including the appendix. Accepted to Computers in Human Behavior ",
    "url": "https://arxiv.org/abs/2303.09656",
    "authors": [
      "Miikka Kuutila",
      "Carita Kiili",
      "Reijo Kupiainen",
      "Eetu Huusko",
      "Junhao Li",
      "Simo Hosio",
      "Mika M\u00e4ntyl\u00e4",
      "Julie Coiro",
      "Kristian Kiili"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2303.10276",
    "title": "Unleashing the Potential of Spiking Neural Networks by Dynamic  Confidence",
    "abstract": " Comments: Accepted by ICCV2023 ",
    "url": "https://arxiv.org/abs/2303.10276",
    "authors": [
      "Chen Li",
      "Edward Jones",
      "Steve Furber"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.08415",
    "title": "Marsellus: A Heterogeneous RISC-V AI-IoT End-Node SoC with 2-to-8b DNN  Acceleration and 30%-Boost Adaptive Body Biasing",
    "abstract": " Comments: Post-print accepted by IEEE Journal of Solid-State Circuits. Fixed metadata (was missing one co-author), added DOI of IEEE JSSC ",
    "url": "https://arxiv.org/abs/2305.08415",
    "authors": [
      "Francesco Conti",
      "Gianna Paulin",
      "Angelo Garofalo",
      "Davide Rossi",
      "Alfio Di Mauro",
      "Georg Rutishauser",
      "Gianmarco Ottavi",
      "Manuel Eggimann",
      "Hayate Okuhara",
      "Luca Benini"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10498",
    "title": "Edge Directionality Improves Learning on Heterophilic Graphs",
    "abstract": " Title: Edge Directionality Improves Learning on Heterophilic Graphs ",
    "url": "https://arxiv.org/abs/2305.10498",
    "authors": [
      "Emanuele Rossi",
      "Bertrand Charpentier",
      "Francesco Di Giovanni",
      "Fabrizio Frasca",
      "Stephan G\u00fcnnemann",
      "Michael Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.12476",
    "title": "Zero-shot Visual Relation Detection via Composite Visual Cues from Large  Language Models",
    "abstract": " Title: Zero-shot Visual Relation Detection via Composite Visual Cues from Large  Language Models ",
    "url": "https://arxiv.org/abs/2305.12476",
    "authors": [
      "Lin Li",
      "Jun Xiao",
      "Guikun Chen",
      "Jian Shao",
      "Yueting Zhuang",
      "Long Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.14561",
    "title": "Negative Feedback Training: A Novel Concept to Improve Robustness of  NVCIM DNN Accelerators",
    "abstract": " Title: Negative Feedback Training: A Novel Concept to Improve Robustness of  NVCIM DNN Accelerators ",
    "url": "https://arxiv.org/abs/2305.14561",
    "authors": [
      "Yifan Qin",
      "Zheyu Yan",
      "Wujie Wen",
      "Xiaobo Sharon Hu",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2305.18228",
    "title": "SR-OOD: Out-of-Distribution Detection via Sample Repairing",
    "abstract": " Comments: This is an updated version of the paper ",
    "url": "https://arxiv.org/abs/2305.18228",
    "authors": [
      "Rui Sun",
      "Andi Zhang",
      "Haiming Zhang",
      "Jinke Ren",
      "Yao Zhu",
      "Ruimao Zhang",
      "Shuguang Cui",
      "Zhen Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.19056",
    "title": "Drivers of social influence in the Twitter migration to Mastodon",
    "abstract": " Comments: Please refer to the accepted version of this paper on Scientific Reports. DOI: 10.1038/s41598-023-48200-7 ",
    "url": "https://arxiv.org/abs/2305.19056",
    "authors": [
      "Lucio La Cava",
      "Luca Maria Aiello",
      "Andrea Tagarelli"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2306.00544",
    "title": "Codebook Configuration for RIS-aided Systems via Implicit Neural  Representations",
    "abstract": " Title: Codebook Configuration for RIS-aided Systems via Implicit Neural  Representations ",
    "url": "https://arxiv.org/abs/2306.00544",
    "authors": [
      "Huiying Yang",
      "Rujing Xiong",
      "Yao Xiao",
      "Zhijie Fan",
      "Tiebin Mi",
      "Robert Caiming Qiu",
      "Zenan Ling"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.13029",
    "title": "Decentralized Online Federated G-Network Learning for Lightweight  Intrusion Detection",
    "abstract": " Title: Decentralized Online Federated G-Network Learning for Lightweight  Intrusion Detection ",
    "url": "https://arxiv.org/abs/2306.13029",
    "authors": [
      "Mert Nak\u0131p",
      "Baran Can G\u00fcl",
      "Erol Gelenbe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2307.06985",
    "title": "Patent Documents to Engineering Design Knowledge Graphs",
    "abstract": " Title: Patent Documents to Engineering Design Knowledge Graphs ",
    "url": "https://arxiv.org/abs/2307.06985",
    "authors": [
      "L Siddharth",
      "Jianxi Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2307.09850",
    "title": "Communication-Efficient Distribution-Free Inference Over Networks",
    "abstract": " Comments: Presented in the Asilomar Conference on Signals, Systems, and Computers (2023) ",
    "url": "https://arxiv.org/abs/2307.09850",
    "authors": [
      "Mehrdad Pournaderi",
      "Yu Xiang"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2307.12301",
    "title": "Unsupervised Image Outlier Detection using RANSAC",
    "abstract": " Title: Unsupervised Image Outlier Detection using RANSAC ",
    "url": "https://arxiv.org/abs/2307.12301",
    "authors": [
      "Chen-Han Tsai",
      "Yu-Shao Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.12689",
    "title": "Addressing the Impact of Localized Training Data in Graph Neural  Networks",
    "abstract": " Comments: 6 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2307.12689",
    "authors": [
      "Akansha A"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.00929",
    "title": "Towards Discriminative Representation with Meta-learning for  Colonoscopic Polyp Re-Identification",
    "abstract": " Title: Towards Discriminative Representation with Meta-learning for  Colonoscopic Polyp Re-Identification ",
    "url": "https://arxiv.org/abs/2308.00929",
    "authors": [
      "Suncheng Xiang",
      "Qingzhong Chen",
      "Shilun Cai",
      "Chengfeng Zhou",
      "Crystal Cai",
      "Sijia Du",
      "Zhengjie Zhang",
      "Yunshi Zhong",
      "Dahong Qian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.10099",
    "title": "Geometric instability of graph neural networks on large graphs",
    "abstract": " Title: Geometric instability of graph neural networks on large graphs ",
    "url": "https://arxiv.org/abs/2308.10099",
    "authors": [
      "Emily Morris",
      "Haotian Shen",
      "Weiling Du",
      "Muhammad Hamza Sajjad",
      "Borun Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2308.14610",
    "title": "PolarRec: Radio Interferometric Data Reconstruction with Polar  Coordinate Representation",
    "abstract": " Title: PolarRec: Radio Interferometric Data Reconstruction with Polar  Coordinate Representation ",
    "url": "https://arxiv.org/abs/2308.14610",
    "authors": [
      "Ruoqi Wang",
      "Zhuoyang Chen",
      "Jiayi Zhu",
      "Qiong Luo",
      "Feng Wang"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.15568",
    "title": "Over-Squashing in Graph Neural Networks: A Comprehensive survey",
    "abstract": " Comments: 10 pages ",
    "url": "https://arxiv.org/abs/2308.15568",
    "authors": [
      "Singh Akansha"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.01291",
    "title": "Generative Social Choice",
    "abstract": " Comments: Substantially revised with non-approval utility model, new representation axiom (balanced justified representation), and real-world case study ",
    "url": "https://arxiv.org/abs/2309.01291",
    "authors": [
      "Sara Fish",
      "Paul G\u00f6lz",
      "David C. Parkes",
      "Ariel D. Procaccia",
      "Gili Rusak",
      "Itai Shapira",
      "Manuel W\u00fcthrich"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.02705",
    "title": "Certifying LLM Safety against Adversarial Prompting",
    "abstract": " Title: Certifying LLM Safety against Adversarial Prompting ",
    "url": "https://arxiv.org/abs/2309.02705",
    "authors": [
      "Aounon Kumar",
      "Chirag Agarwal",
      "Suraj Srinivas",
      "Aaron Jiaxun Li",
      "Soheil Feizi",
      "Himabindu Lakkaraju"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.10399",
    "title": "Exploiting Causality Signals in Medical Images: A Pilot Study with  Empirical Results",
    "abstract": " Comments: Repeated analyses with new dataset, provided more visual/algorithmic insights, improved clarity, remarked significance and novelty; 17 pages, 8 figures, second round review ",
    "url": "https://arxiv.org/abs/2309.10399",
    "authors": [
      "Gianluca Carloni",
      "Sara Colantonio"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13607",
    "title": "MM-NeRF: Multimodal-Guided 3D Multi-Style Transfer of Neural Radiance  Field",
    "abstract": " Title: MM-NeRF: Multimodal-Guided 3D Multi-Style Transfer of Neural Radiance  Field ",
    "url": "https://arxiv.org/abs/2309.13607",
    "authors": [
      "Zijiang Yang",
      "Zhongwei Qiu",
      "Chang Xu",
      "Dongmei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.13620",
    "title": "PRIS: Practical robust invertible network for image steganography",
    "abstract": " Title: PRIS: Practical robust invertible network for image steganography ",
    "url": "https://arxiv.org/abs/2309.13620",
    "authors": [
      "Hang Yang",
      "Yitian Xu",
      "Xuhua Liu",
      "Xiaodong Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2309.14053",
    "title": "Revisiting LARS for Large Batch Training Generalization of Neural  Networks",
    "abstract": " Title: Revisiting LARS for Large Batch Training Generalization of Neural  Networks ",
    "url": "https://arxiv.org/abs/2309.14053",
    "authors": [
      "Khoi Do",
      "Duong Nguyen",
      "Hoa Nguyen",
      "Long Tran-Thanh",
      "Quoc-Viet Pham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.02691",
    "title": "Robust Ocean Subgrid-Scale Parameterizations Using Fourier Neural  Operators",
    "abstract": " Title: Robust Ocean Subgrid-Scale Parameterizations Using Fourier Neural  Operators ",
    "url": "https://arxiv.org/abs/2310.02691",
    "authors": [
      "Victor Mangeleer",
      "Gilles Louppe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2310.04486",
    "title": "T-Rep: Representation Learning for Time Series using Time-Embeddings",
    "abstract": " Comments: Under review at ICLR 2024 ",
    "url": "https://arxiv.org/abs/2310.04486",
    "authors": [
      "Archibald Fraikin",
      "Adrien Bennetot",
      "St\u00e9phanie Allassonni\u00e8re"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.06328",
    "title": "Antenna Response Consistency Driven Self-supervised Learning for  WIFI-based Human Activity Recognition",
    "abstract": " Title: Antenna Response Consistency Driven Self-supervised Learning for  WIFI-based Human Activity Recognition ",
    "url": "https://arxiv.org/abs/2310.06328",
    "authors": [
      "Ke Xu",
      "Jiangtao Wang",
      "Hongyuan Zhu",
      "Dingchang Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.08165",
    "title": "COVID-19 detection using ViT transformer-based approach from Computed  Tomography Images",
    "abstract": " Title: COVID-19 detection using ViT transformer-based approach from Computed  Tomography Images ",
    "url": "https://arxiv.org/abs/2310.08165",
    "authors": [
      "Kenan Morani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.08992",
    "title": "CodeChain: Towards Modular Code Generation Through Chain of  Self-revisions with Representative Sub-modules",
    "abstract": " Title: CodeChain: Towards Modular Code Generation Through Chain of  Self-revisions with Representative Sub-modules ",
    "url": "https://arxiv.org/abs/2310.08992",
    "authors": [
      "Hung Le",
      "Hailin Chen",
      "Amrita Saha",
      "Akash Gokul",
      "Doyen Sahoo",
      "Shafiq Joty"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2310.10404",
    "title": "LLM4SGG: Large Language Model for Weakly Supervised Scene Graph  Generation",
    "abstract": " Comments: 21 pages, Preprint ",
    "url": "https://arxiv.org/abs/2310.10404",
    "authors": [
      "Kibum Kim",
      "Kanghoon Yoon",
      "Jaehyeong Jeon",
      "Yeonjun In",
      "Jinyoung Moon",
      "Donghyun Kim",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.11270",
    "title": "Graph Neural Networks for Recommendation: Reproducibility, Graph  Topology, and Node Representation",
    "abstract": " Title: Graph Neural Networks for Recommendation: Reproducibility, Graph  Topology, and Node Representation ",
    "url": "https://arxiv.org/abs/2310.11270",
    "authors": [
      "Daniele Malitesta",
      "Claudio Pomo",
      "Tommaso Di Noia"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.11676",
    "title": "PREM: A Simple Yet Effective Approach for Node-Level Graph Anomaly  Detection",
    "abstract": " Comments: Accepted by IEEE International Conference of Data Mining 2023 (ICDM 2023) ",
    "url": "https://arxiv.org/abs/2310.11676",
    "authors": [
      "Junjun Pan",
      "Yixin Liu",
      "Yizhen Zheng",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.14045",
    "title": "Training Image Derivatives: Increased Accuracy and Universal Robustness",
    "abstract": " Comments: converted to two-column format, shortened abstract, improved readability, removed unnecessary graphics, fixed typos ",
    "url": "https://arxiv.org/abs/2310.14045",
    "authors": [
      "Vsevolod I. Avrutskiy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.17025",
    "title": "netFound: Foundation Model for Network Security",
    "abstract": " Title: netFound: Foundation Model for Network Security ",
    "url": "https://arxiv.org/abs/2310.17025",
    "authors": [
      "Satyandra Guthula",
      "Navya Battula",
      "Roman Beltiukov",
      "Wenbo Guo",
      "Arpit Gupta"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.01270",
    "title": "People Make Better Edits: Measuring the Efficacy of LLM-Generated  Counterfactually Augmented Data for Harmful Language Detection",
    "abstract": " Comments: Preprint of EMNLP'23 paper ",
    "url": "https://arxiv.org/abs/2311.01270",
    "authors": [
      "Indira Sen",
      "Dennis Assenmacher",
      "Mattia Samory",
      "Isabelle Augenstein",
      "Wil van der Aalst",
      "Claudia Wagner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2311.05521",
    "title": "BakedAvatar: Baking Neural Fields for Real-Time Head Avatar Synthesis",
    "abstract": " Comments: ACM Transactions on Graphics (SIGGRAPH Asia 2023). Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2311.05521",
    "authors": [
      "Hao-Bin Duan",
      "Miao Wang",
      "Jin-Chuan Shi",
      "Xu-Chuan Chen",
      "Yan-Pei Cao"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.06542",
    "title": "Generation Of Colors using Bidirectional Long Short Term Memory Networks",
    "abstract": " Comments: 8 pages ",
    "url": "https://arxiv.org/abs/2311.06542",
    "authors": [
      "A. Sinha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.06965",
    "title": "Anchor Data Augmentation",
    "abstract": " Title: Anchor Data Augmentation ",
    "url": "https://arxiv.org/abs/2311.06965",
    "authors": [
      "Nora Schneider",
      "Shirin Goshtasbpour",
      "Fernando Perez-Cruz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.07089",
    "title": "Recursive and non-recursive filters for sequential smoothing and  prediction with instantaneous phase and frequency estimation applications  (extended version)",
    "abstract": " Comments: Reduced page count from 80 down to 50 by removing page breaks between figures and reducing figure size. Added page numbers. Added (extended version) to title ",
    "url": "https://arxiv.org/abs/2311.07089",
    "authors": [
      "Hugh Lachlan Kennedy"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.07222",
    "title": "Neural General Circulation Models",
    "abstract": " Comments: 67 pages, 34 figures ",
    "url": "https://arxiv.org/abs/2311.07222",
    "authors": [
      "Dmitrii Kochkov",
      "Janni Yuval",
      "Ian Langmore",
      "Peter Norgaard",
      "Jamie Smith",
      "Griffin Mooers",
      "James Lottes",
      "Stephan Rasp",
      "Peter D\u00fcben",
      "Milan Kl\u00f6wer",
      "Sam Hatfield",
      "Peter Battaglia",
      "Alvaro Sanchez-Gonzalez",
      "Matthew Willson",
      "Michael P. Brenner",
      "Stephan Hoyer"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2311.09312",
    "title": "H-Packer: Holographic Rotationally Equivariant Convolutional Neural  Network for Protein Side-Chain Packing",
    "abstract": " Comments: Accepted as a conference paper at MLCB 2023. 8 pages main body, 20 pages with appendix. 10 figures ",
    "url": "https://arxiv.org/abs/2311.09312",
    "authors": [
      "Gian Marco Visani",
      "William Galvin",
      "Michael Neal Pun",
      "Armita Nourmohammad"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.09790",
    "title": "Breaking Boundaries: Balancing Performance and Robustness in Deep  Wireless Traffic Forecasting",
    "abstract": " Comments: Accepted for presentation at the ARTMAN workshop, part of the ACM Conference on Computer and Communications Security (CCS), 2023 ",
    "url": "https://arxiv.org/abs/2311.09790",
    "authors": [
      "Romain Ilbert",
      "Thai V. Hoang",
      "Zonghua Zhang",
      "Themis Palpanas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.11567",
    "title": "CORE-MM: Complex Open-Ended Reasoning Evaluation For Multi-Modal Large  Language Models",
    "abstract": " Title: CORE-MM: Complex Open-Ended Reasoning Evaluation For Multi-Modal Large  Language Models ",
    "url": "https://arxiv.org/abs/2311.11567",
    "authors": [
      "Xiaotian Han",
      "Quanzeng You",
      "Yongfei Liu",
      "Wentao Chen",
      "Huangjie Zheng",
      "Khalil Mrini",
      "Xudong Lin",
      "Yiqi Wang",
      "Bohan Zhai",
      "Jianbo Yuan",
      "Heng Wang",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12399",
    "title": "A Survey of Graph Meets Large Language Model: Progress and Future  Directions",
    "abstract": " Comments: Work in progress; 13 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2311.12399",
    "authors": [
      "Yuhan Li",
      "Zhixun Li",
      "Peisong Wang",
      "Jia Li",
      "Xiangguo Sun",
      "Hong Cheng",
      "Jeffrey Xu Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.12824",
    "title": "Comparative Analysis of Shear Strength Prediction Models for Reinforced  Concrete Slab-Column Connections",
    "abstract": " Comments: 34 Pages,25 Figures ",
    "url": "https://arxiv.org/abs/2311.12824",
    "authors": [
      "Sarmed Wahab",
      "Nasim Shakouri Mahmoudabadi",
      "Sarmad Waqas",
      "Nouman Herl",
      "Muhammad Iqbal",
      "Khurshid Alam",
      "Afaq Ahmad"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.15243",
    "title": "ID-like Prompt Learning for Few-Shot Out-of-Distribution Detection",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2311.15243",
    "authors": [
      "Yichen Bai",
      "Zongbo Han",
      "Changqing Zhang",
      "Bing Cao",
      "Xiaoheng Jiang",
      "Qinghua Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  }
]