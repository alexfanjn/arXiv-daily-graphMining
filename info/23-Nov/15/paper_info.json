[
  {
    "id": "arXiv:2311.07577",
    "title": "Algorithms for Object Detection in Substations",
    "abstract": "Inspection of high-voltage power equipment is an effective way to ensure power supply reliability. Object recognition, one of the key technologies in automatic power equipment inspection, attracts attention of many researchers and engineers. Although quite a few existing models have some their own advantages, object relationship between equipment which is very important in this task is scarcely considered. This paper combining object relationship modeling and Transformer Model proposes a Relation Transformer Model. It has four parts -- backbone, encoder, decoder and prediction heads. With this structure, the proposed method shows in experiments a much better performance than other three commonly used models in object recognition in substation, largely promoting the development of automatic power equipment inspection. ",
    "url": "https://arxiv.org/abs/2311.07577",
    "authors": [
      "Bingying Jin",
      "Yadong Liu",
      "Qinlin Qian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2311.07578",
    "title": "A Metacognitive Approach to Out-of-Distribution Detection for  Segmentation",
    "abstract": "Despite outstanding semantic scene segmentation in closed-worlds, deep neural networks segment novel instances poorly, which is required for autonomous agents acting in an open world. To improve out-of-distribution (OOD) detection for segmentation, we introduce a metacognitive approach in the form of a lightweight module that leverages entropy measures, segmentation predictions, and spatial context to characterize the segmentation model's uncertainty and detect pixel-wise OOD data in real-time. Additionally, our approach incorporates a novel method of generating synthetic OOD data in context with in-distribution data, which we use to fine-tune existing segmentation models with maximum entropy training. This further improves the metacognitive module's performance without requiring access to OOD data while enabling compatibility with established pre-trained models. Our resulting approach can reliably detect OOD instances in a scene, as shown by state-of-the-art performance on OOD detection for semantic segmentation benchmarks. ",
    "url": "https://arxiv.org/abs/2311.07578",
    "authors": [
      "Meghna Gummadi",
      "Cassandra Kent",
      "Karl Schmeckpeper",
      "Eric Eaton"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.07584",
    "title": "Performance Prediction of Data-Driven Knowledge summarization of High  Entropy Alloys (HEAs) literature implementing Natural Language Processing  algorithms",
    "abstract": "The ability to interpret spoken language is connected to natural language processing. It involves teaching the AI how words relate to one another, how they are meant to be used, and in what settings. The goal of natural language processing (NLP) is to get a machine intelligence to process words the same way a human brain does. This enables machine intelligence to interpret, arrange, and comprehend textual data by processing the natural language. The technology can comprehend what is communicated, whether it be through speech or writing because AI pro-cesses language more quickly than humans can. In the present study, five NLP algorithms, namely, Geneism, Sumy, Luhn, Latent Semantic Analysis (LSA), and Kull-back-Liebler (KL) al-gorithm, are implemented for the first time for the knowledge summarization purpose of the High Entropy Alloys (HEAs). The performance prediction of these algorithms is made by using the BLEU score and ROUGE score. The results showed that the Luhn algorithm has the highest accuracy score for the knowledge summarization tasks compared to the other used algorithms. ",
    "url": "https://arxiv.org/abs/2311.07584",
    "authors": [
      "Akshansh Mishra",
      "Vijaykumar S Jatti",
      "Vaishnavi More",
      "Anish Dasgupta",
      "Devarrishi Dixit",
      "Eyob Messele Sefene"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.07585",
    "title": "Input Reconstruction Attack against Vertical Federated Large Language  Models",
    "abstract": "Recently, large language models (LLMs) have drawn extensive attention from academia and the public, due to the advent of the ChatGPT. While LLMs show their astonishing ability in text generation for various tasks, privacy concerns limit their usage in real-life businesses. More specifically, either the user's inputs (the user sends the query to the model-hosting server) or the model (the user downloads the complete model) itself will be revealed during the usage. Vertical federated learning (VFL) is a promising solution to this kind of problem. It protects both the user's input and the knowledge of the model by splitting the model into a bottom part and a top part, which is maintained by the user and the model provider, respectively. However, in this paper, we demonstrate that in LLMs, VFL fails to protect the user input since it is simple and cheap to reconstruct the input from the intermediate embeddings. Experiments show that even with a commercial GPU, the input sentence can be reconstructed in only one second. We also discuss several possible solutions to enhance the privacy of vertical federated LLMs. ",
    "url": "https://arxiv.org/abs/2311.07585",
    "authors": [
      "Fei Zheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.07586",
    "title": "Event Detection on Twitter",
    "abstract": "Detecting events by using social media has been an active research problem. In this work, we investigate and compare the performance of two methods for event detection in Twitter by using Apache Storm as the stream processing infrastructure. The first event detection method is based on identifying uncommonly common words inside tweet blocks, and the second one is based on clustering tweets to detect a cluster as an event. Each of the methods has its own characteristics. Uncommonly common word based method relies on the burst of words and hence is not affected from concurrency problems in distributed environment. On the other hand, clustering based method includes a finer grained analysis, but it is sensitive to the concurrent processing. We investigate the effect of stream processing and concurrency handling support provided by Apace Storm on event detection by these methods. ",
    "url": "https://arxiv.org/abs/2311.07586",
    "authors": [
      "Ozlem Ceren Sahin",
      "Nesime Tatbul",
      "Pinar Karagoz"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.07587",
    "title": "Frontier Language Models are not Robust to Adversarial Arithmetic, or  \"What do I need to say so you agree 2+2=5?",
    "abstract": "We introduce and study the problem of adversarial arithmetic, which provides a simple yet challenging testbed for language model alignment. This problem is comprised of arithmetic questions posed in natural language, with an arbitrary adversarial string inserted before the question is complete. Even in the simple setting of 1-digit addition problems, it is easy to find adversarial prompts that make all tested models (including PaLM2, GPT4, Claude2) misbehave, and even to steer models to a particular wrong answer. We additionally provide a simple algorithm for finding successful attacks by querying those same models, which we name \"prompt inversion rejection sampling\" (PIRS). We finally show that models can be partially hardened against these attacks via reinforcement learning and via agentic constitutional loops. However, we were not able to make a language model fully robust against adversarial arithmetic attacks. ",
    "url": "https://arxiv.org/abs/2311.07587",
    "authors": [
      "C. Daniel Freeman",
      "Laura Culp",
      "Aaron Parisi",
      "Maxwell L Bileschi",
      "Gamaleldin F Elsayed",
      "Alex Rizkowsky",
      "Isabelle Simpson",
      "Alex Alemi",
      "Azade Nova",
      "Ben Adlam",
      "Bernd Bohnet",
      "Gaurav Mishra",
      "Hanie Sedghi",
      "Igor Mordatch",
      "Izzeddin Gur",
      "Jaehoon Lee",
      "JD Co-Reyes",
      "Jeffrey Pennington",
      "Kelvin Xu",
      "Kevin Swersky",
      "Kshiteej Mahajan",
      "Lechao Xiao",
      "Rosanne Liu",
      "Simon Kornblith",
      "Noah Constant",
      "Peter J. Liu",
      "Roman Novak",
      "Sharad Vikram",
      "Yundi Qian",
      "Noah Fiedel",
      "Jascha Sohl-Dickstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.07591",
    "title": "Identification of Books That are Suitable for Middle School Students  Using Artificial Neural Networks",
    "abstract": "Reading right books contributes to children's imagination and brain development, enhances their language and emotional comprehension abilities, and strengthens their relationships with others. Building upon the critical role of reading books in individual development, this paper aims to develop an algorithm that determines the suitability of books for middle school students by analyzing their structural and semantic features. Using methods described, an algorithm will be created that can be utilized by institutions and individuals responsible for children's education, such as the Ministry of National Education officials and schools. This algorithm will facilitate the selection of books to be taught at the middle school level. With the algorithm, the book selection process for the middle school curriculum can be expedited, and it will serve as a preliminary reference source for those who evaluate books by reading them. In this paper, the Python programming language was employed, utilizing natural language processing methods. Additionally, an artificial neural network (ANN) was trained using the data which had been preprocessed to construct an original dataset. To train this network, suitable books for middle school students were provided by the MEB, Oxford and Cambridge and with content assessed based on the \"R\" criterion, and inappropriate books for middle school students in terms of content were included. This trained neural network achieved a 90.06% consistency rate in determining the appropriateness of the test-provided books. Considering the obtained findings, it can be concluded that the developed software has achieved the desired objective. ",
    "url": "https://arxiv.org/abs/2311.07591",
    "authors": [
      "Alp Niksarli",
      "Sadik Ozan Gorgu",
      "Ege Gencer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.07595",
    "title": "A Decision Support System for Liver Diseases Prediction: Integrating  Batch Processing, Rule-Based Event Detection and SPARQL Query",
    "abstract": "Liver diseases pose a significant global health burden, impacting a substantial number of individuals and exerting substantial economic and social consequences. Rising liver problems are considered a fatal disease in many countries, such as Egypt, Molda, etc. The objective of this study is to construct a predictive model for liver illness using Basic Formal Ontology (BFO) and detection rules derived from a decision tree algorithm. Based on these rules, events are detected through batch processing using the Apache Jena framework. Based on the event detected, queries can be directly processed using SPARQL. To make the ontology operational, these Decision Tree (DT) rules are converted into Semantic Web Rule Language (SWRL). Using this SWRL in the ontology for predicting different types of liver disease with the help of the Pellet and Drool inference engines in Protege Tools, a total of 615 records are taken from different liver diseases. After inferring the rules, the result can be generated for the patient according to the DT rules, and other patient-related details along with different precautionary suggestions can be obtained based on these results. Combining query results of batch processing and ontology-generated results can give more accurate suggestions for disease prevention and detection. This work aims to provide a comprehensive approach that is applicable for liver disease prediction, rich knowledge graph representation, and smart querying capabilities. The results show that combining RDF data, SWRL rules, and SPARQL queries for analysing and predicting liver disease can help medical professionals to learn more about liver diseases and make a Decision Support System (DSS) for health care. ",
    "url": "https://arxiv.org/abs/2311.07595",
    "authors": [
      "Ritesh Chandra",
      "Sadhana Tiwari",
      "Satyam Rastogi",
      "Sonali Agarwal"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.07596",
    "title": "Graph GOSPA metric: a metric to measure the discrepancy between graphs  of different sizes",
    "abstract": "This paper proposes a metric to measure the dissimilarity between graphs that may have a different number of nodes. The proposed metric extends the generalised optimal subpattern assignment (GOSPA) metric, which is a metric for sets, to graphs. The proposed graph GOSPA metric includes costs associated with node attribute errors for properly assigned nodes, missed and false nodes and edge mismatches between graphs. The computation of this metric is based on finding the optimal assignments between nodes in the two graphs, with the possibility of leaving some of the nodes unassigned. We also propose a lower bound for the metric, which is also a metric for graphs and is computable in polynomial time using linear programming. The metric is first derived for undirected unweighted graphs and it is then extended to directed and weighted graphs. The properties of the metric are demonstrated via simulated and empirical datasets. ",
    "url": "https://arxiv.org/abs/2311.07596",
    "authors": [
      "Jinhao Gu",
      "\u00c1ngel F. Garc\u00eda-Fern\u00e1ndez",
      "Robert E. Firth",
      "Lennart Svensson"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.07599",
    "title": "Testing LLMs on Code Generation with Varying Levels of Prompt  Specificity",
    "abstract": "Large language models (LLMs) have demonstrated unparalleled prowess in mimicking human-like text generation and processing. Among the myriad of applications that benefit from LLMs, automated code generation is increasingly promising. The potential to transform natural language prompts into executable code promises a major shift in software development practices and paves the way for significant reductions in manual coding efforts and the likelihood of human-induced errors. This paper reports the results of a study that evaluates the performance of various LLMs, such as Bard, ChatGPT-3.5, ChatGPT-4, and Claude-2, in generating Python for coding problems. We focus on how levels of prompt specificity impact the accuracy, time efficiency, and space efficiency of the generated code. A benchmark of 104 coding problems, each with four types of prompts with varying degrees of tests and specificity, was employed to examine these aspects comprehensively. Our results indicate significant variations in performance across different LLMs and prompt types, and its key contribution is to reveal the ideal prompting strategy for creating accurate Python functions. This study lays the groundwork for further research in LLM capabilities and suggests practical implications for utilizing LLMs in automated code generation tasks and test-driven development. ",
    "url": "https://arxiv.org/abs/2311.07599",
    "authors": [
      "Lincoln Murr",
      "Morgan Grainger",
      "David Gao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.07608",
    "title": "MuST: Multimodal Spatiotemporal Graph-Transformer for Hospital  Readmission Prediction",
    "abstract": "Hospital readmission prediction is considered an essential approach to decreasing readmission rates, which is a key factor in assessing the quality and efficacy of a healthcare system. Previous studies have extensively utilized three primary modalities, namely electronic health records (EHR), medical images, and clinical notes, to predict hospital readmissions. However, the majority of these studies did not integrate information from all three modalities or utilize the spatiotemporal relationships present in the dataset. This study introduces a novel model called the Multimodal Spatiotemporal Graph-Transformer (MuST) for predicting hospital readmissions. By employing Graph Convolution Networks and temporal transformers, we can effectively capture spatial and temporal dependencies in EHR and chest radiographs. We then propose a fusion transformer to combine the spatiotemporal features from the two modalities mentioned above with the features from clinical notes extracted by a pre-trained, domain-specific transformer. We assess the effectiveness of our methods using the latest publicly available dataset, MIMIC-IV. The experimental results indicate that the inclusion of multimodal features in MuST improves its performance in comparison to unimodal methods. Furthermore, our proposed pipeline outperforms the current leading methods in the prediction of hospital readmissions. ",
    "url": "https://arxiv.org/abs/2311.07608",
    "authors": [
      "Yan Miao",
      "Lequan Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.07614",
    "title": "Application of a Dense Fusion Attention Network in Fault Diagnosis of  Centrifugal Fan",
    "abstract": "Although the deep learning recognition model has been widely used in the condition monitoring of rotating machinery. However, it is still a challenge to understand the correspondence between the structure and function of the model and the diagnosis process. Therefore, this paper discusses embedding distributed attention modules into dense connections instead of traditional dense cascading operations. It not only decouples the influence of space and channel on fault feature adaptive recalibration feature weights, but also forms a fusion attention function. The proposed dense fusion focuses on the visualization of the network diagnosis process, which increases the interpretability of model diagnosis. How to continuously and effectively integrate different functions to enhance the ability to extract fault features and the ability to resist noise is answered. Centrifugal fan fault data is used to verify this network. Experimental results show that the network has stronger diagnostic performance than other advanced fault diagnostic models. ",
    "url": "https://arxiv.org/abs/2311.07614",
    "authors": [
      "Ruijun Wang",
      "Yuan Liu",
      "Zhixia Fan",
      "Xiaogang Xu",
      "Huijie Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.07617",
    "title": "CLAMP: A Contrastive Language And Molecule Pre-training Network",
    "abstract": "This paper highlights a shift in how to approach material generation. Instead of material-to-material, we propose a language-to-material generation architecture that utilizes millions of untapped data points. Using a web scraper to collect crystal text pairs from open-source research papers, a contrastive model can be trained using a convolutional graph neural network encoder and a language encoder. This would allow unsupervised zero-shot classification which can be trained by taking advantage of linguistic structure. Without any specific training data, an ~82\\% accuracy was achieved and ~75\\% accuracy for photocatalyst prediction with an extremely small dataset. This novel network could ideally be cross-applied to any reaction that can be described via text, opening completely new methods to think about 3D chemical framework generation. In the full experiment diffusion models would likely be incorporated to fully exploit the latent space. ",
    "url": "https://arxiv.org/abs/2311.07617",
    "authors": [
      "Neel Redkar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2311.07627",
    "title": "A Consistent Diffusion-Based Algorithm for Semi-Supervised Graph  Learning",
    "abstract": "The task of semi-supervised classification aims at assigning labels to all nodes of a graph based on the labels known for a few nodes, called the seeds. One of the most popular algorithms relies on the principle of heat diffusion, where the labels of the seeds are spread by thermoconductance and the temperature of each node at equilibrium is used as a score function for each label. In this paper, we prove that this algorithm is not consistent unless the temperatures of the nodes at equilibrium are centered before scoring. This crucial step does not only make the algorithm provably consistent on a block model but brings significant performance gains on real graphs. ",
    "url": "https://arxiv.org/abs/2311.07627",
    "authors": [
      "Thomas Bonald",
      "Nathan de Lara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.07632",
    "title": "ResMGCN: Residual Message Graph Convolution Network for Fast Biomedical  Interactions Discovering",
    "abstract": "Biomedical information graphs are crucial for interaction discovering of biomedical information in modern age, such as identification of multifarious molecular interactions and drug discovery, which attracts increasing interests in biomedicine, bioinformatics, and human healthcare communities. Nowadays, more and more graph neural networks have been proposed to learn the entities of biomedical information and precisely reveal biomedical molecule interactions with state-of-the-art results. These methods remedy the fading of features from a far distance but suffer from remedying such problem at the expensive cost of redundant memory and time. In our paper, we propose a novel Residual Message Graph Convolution Network (ResMGCN) for fast and precise biomedical interaction prediction in a different idea. Specifically, instead of enhancing the message from far nodes, ResMGCN aggregates lower-order information with the next round higher information to guide the node update to obtain a more meaningful node representation. ResMGCN is able to perceive and preserve various messages from the previous layer and high-order information in the current layer with least memory and time cost to obtain informative representations of biomedical entities. We conduct experiments on four biomedical interaction network datasets, including protein-protein, drug-drug, drug-target, and gene-disease interactions, which demonstrates that ResMGCN outperforms previous state-of-the-art models while achieving superb effectiveness on both storage and time. ",
    "url": "https://arxiv.org/abs/2311.07632",
    "authors": [
      "Zecheng Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Molecular Networks (q-bio.MN)"
    ]
  },
  {
    "id": "arXiv:2311.07635",
    "title": "Past as a Guide: Leveraging Retrospective Learning for Python Code  Completion",
    "abstract": "This work presents Past as a Guide (PaG), a simple approach for Large Language Models (LLMs) to improve the coding capabilities by integrating the past history with interactive and iterative code refinements. To be specific, inspired by human cognitive processes, the proposed method enables LLMs to utilize previous programming and debugging experiences to enhance the Python code completion tasks. The framework facilitates LLMs to iteratively refine the Python code based on previous execution and debugging results and optimize learning and reasoning capabilities. The proposed methodology achieved a 92\\% pass@1 on HumanEval, demonstrating the potential to advance the field by leveraging retrospection from past experiences and interactive and iterative refinement processes without external correctness indicators. ",
    "url": "https://arxiv.org/abs/2311.07635",
    "authors": [
      "Seunggyoon Shin",
      "Seunggyu Chang",
      "Sungjoon Choi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.07705",
    "title": "Robust and Scalable Hyperdimensional Computing With Brain-Like Neural  Adaptations",
    "abstract": "The Internet of Things (IoT) has facilitated many applications utilizing edge-based machine learning (ML) methods to analyze locally collected data. Unfortunately, popular ML algorithms often require intensive computations beyond the capabilities of today's IoT devices. Brain-inspired hyperdimensional computing (HDC) has been introduced to address this issue. However, existing HDCs use static encoders, requiring extremely high dimensionality and hundreds of training iterations to achieve reasonable accuracy. This results in a huge efficiency loss, severely impeding the application of HDCs in IoT systems. We observed that a main cause is that the encoding module of existing HDCs lacks the capability to utilize and adapt to information learned during training. In contrast, neurons in human brains dynamically regenerate all the time and provide more useful functionalities when learning new information. While the goal of HDC is to exploit the high-dimensionality of randomly generated base hypervectors to represent the information as a pattern of neural activity, it remains challenging for existing HDCs to support a similar behavior as brain neural regeneration. In this work, we present dynamic HDC learning frameworks that identify and regenerate undesired dimensions to provide adequate accuracy with significantly lowered dimensionalities, thereby accelerating both the training and inference. ",
    "url": "https://arxiv.org/abs/2311.07705",
    "authors": [
      "Junyao Wang",
      "Mohammad Abdullah Al Faruque"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.07711",
    "title": "Histopathologic Cancer Detection",
    "abstract": "Early diagnosis of the cancer cells is necessary for making an effective treatment plan and for the health and safety of a patient. Nowadays, doctors usually use a histological grade that pathologists determine by performing a semi-quantitative analysis of the histopathological and cytological features of hematoxylin-eosin (HE) stained histopathological images. This research contributes a potential classification model for cancer prognosis to efficiently utilize the valuable information underlying the HE-stained histopathological images. This work uses the PatchCamelyon benchmark datasets and trains them in a multi-layer perceptron and convolution model to observe the model's performance in terms of precision, Recall, F1 Score, Accuracy, and AUC Score. The evaluation result shows that the baseline convolution model outperforms the baseline MLP model. Also, this paper introduced ResNet50 and InceptionNet models with data augmentation, where ResNet50 is able to beat the state-of-the-art model. Furthermore, the majority vote and concatenation ensemble were evaluated and provided the future direction of using transfer learning and segmentation to understand the specific features. ",
    "url": "https://arxiv.org/abs/2311.07711",
    "authors": [
      "Varan Singh Rohila",
      "Neeraj Lalwani",
      "Lochan Basyal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.07734",
    "title": "Quality-Aware Prototype Memory for Face Representation Learning",
    "abstract": "Prototype Memory is a powerful model for face representation learning. It enables the training of face recognition models using datasets of any size, with on-the-fly generation of prototypes (classifier weights) and efficient ways of their utilization. Prototype Memory demonstrated strong results in many face recognition benchmarks. However, the algorithm of prototype generation, used in it, is prone to the problems of imperfectly calculated prototypes in case of low-quality or poorly recognizable faces in the images, selected for the prototype creation. All images of the same person, presented in the mini-batch, used with equal weights, and the resulting averaged prototype could be contaminated with imperfect embeddings of such face images. It can lead to misdirected training signals and impair the performance of the trained face recognition models. In this paper, we propose a simple and effective way to improve Prototype Memory with quality-aware prototype generation. Quality-Aware Prototype Memory uses different weights for images of different quality in the process of prototype generation. With this improvement, prototypes get more valuable information from high-quality images and less hurt by low-quality ones. We propose and compare several methods of quality estimation and usage, perform extensive experiments on the different face recognition benchmarks and demonstrate the advantages of the proposed model compared to the basic version of Prototype Memory. ",
    "url": "https://arxiv.org/abs/2311.07734",
    "authors": [
      "Evgeny Smirnov",
      "Vasiliy Galyuk",
      "Evgeny Lukyanets"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.07742",
    "title": "Modeling Sequences as Star Graphs to Address Over-smoothing in  Self-attentive Sequential Recommendation",
    "abstract": "Self-attention (SA) mechanisms have been widely used in developing sequential recommendation (SR) methods, and demonstrated state-of-the-art performance. However, in this paper, we show that self-attentive SR methods substantially suffer from the over-smoothing issue that item embeddings within a sequence become increasingly similar across attention blocks. As widely demonstrated in the literature, this issue could lead to a loss of information in individual items, and significantly degrade models' scalability and performance. To address the over-smoothing issue, in this paper, we view items within a sequence constituting a star graph and develop a method, denoted as MSSG, for SR. Different from existing self-attentive methods, MSSG introduces an additional internal node to specifically capture the global information within the sequence, and does not require information propagation among items. This design fundamentally addresses the over-smoothing issue and enables MSSG a linear time complexity with respect to the sequence length. We compare MSSG with ten state-of-the-art baseline methods on six public benchmark datasets. Our experimental results demonstrate that MSSG significantly outperforms the baseline methods, with an improvement of as much as 10.10%. Our analysis shows the superior scalability of MSSG over the state-of-the-art self-attentive methods. Our complexity analysis and run-time performance comparison together show that MSSG is both theoretically and practically more efficient than self-attentive methods. Our analysis of the attention weights learned in SA-based methods indicates that on sparse recommendation data, modeling dependencies in all item pairs using the SA mechanism yields limited information gain, and thus, might not benefit the recommendation performance ",
    "url": "https://arxiv.org/abs/2311.07742",
    "authors": [
      "Bo Peng",
      "Ziqi Chen",
      "Srinivasan Parthasarathy",
      "Xia Ning"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2311.07745",
    "title": "Simplifying Complex Observation Models in Continuous POMDP Planning with  Probabilistic Guarantees and Practice",
    "abstract": "Solving partially observable Markov decision processes (POMDPs) with high dimensional and continuous observations, such as camera images, is required for many real life robotics and planning problems. Recent researches suggested machine learned probabilistic models as observation models, but their use is currently too computationally expensive for online deployment. We deal with the question of what would be the implication of using simplified observation models for planning, while retaining formal guarantees on the quality of the solution. Our main contribution is a novel probabilistic bound based on a statistical total variation distance of the simplified model. We show that it bounds the theoretical POMDP value w.r.t. original model, from the empirical planned value with the simplified model, by generalizing recent results of particle-belief MDP concentration bounds. Our calculations can be separated into offline and online parts, and we arrive at formal guarantees without having to access the costly model at all during planning, which is also a novel result. Finally, we demonstrate in simulation how to integrate the bound into the routine of an existing continuous online POMDP solver. ",
    "url": "https://arxiv.org/abs/2311.07745",
    "authors": [
      "Idan Lev-Yehudi",
      "Moran Barenboim",
      "Vadim Indelman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.07753",
    "title": "Bringing Reconfigurability to the Network Stack",
    "abstract": "Reconfiguring the network stack allows applications to specialize the implementations of communication libraries depending on where they run, the requests they serve, and the performance they need to provide. Specializing applications in this way is challenging because developers need to choose the libraries they use when writing a program and cannot easily change them at runtime. This paper introduces Bertha, which allows these choices to be changed at runtime without limiting developer flexibility in the choice of network and communication functions. Bertha allows applications to safely use optimized communication primitives (including ones with deployment limitations) without limiting deployability. Our evaluation shows cases where this results in 16x higher throughput and 63% lower latency than current portable approaches while imposing minimal overheads when compared to a hand-optimized versions that use deployment-specific communication primitives. ",
    "url": "https://arxiv.org/abs/2311.07753",
    "authors": [
      "Akshay Narayan",
      "Aurojit Panda",
      "Mohammad Alizadeh",
      "Hari Balakrishnan",
      "Arvind Krishnamurthy",
      "Scott Shenker"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2311.07758",
    "title": "Synchrophasor Data Anomaly Detection on Grid Edge by 5G Communication  and Adjacent Compute",
    "abstract": "The fifth-generation mobile communication (5G) technology offers opportunities to enhance the real-time monitoring of grids. The 5G-enabled phasor measurement units (PMUs) feature flexible positioning and cost-effective long-term maintenance without the constraints of fixing wires. This paper is the first to demonstrate the applicability of 5G in PMU communication, and the experiment was carried out at Verizon non-standalone test-bed at Pacific Northwest National Laboratory (PNNL) Advanced Wireless Communication lab. The performance of the 5G-enabled PMU communication setup is reviewed and discussed in this paper, and a generalized dynamic linear model (GDLM) based real-time synchrophasor data anomaly detection use-case is presented. Last but not least, the practicability of implementing 5G for wide-area protection strategies is explored and discussed by analyzing the experimental results. ",
    "url": "https://arxiv.org/abs/2311.07758",
    "authors": [
      "Chuan Qin",
      "Dexin Wang",
      "Kishan Prudhvi Guddanti",
      "Xiaoyuan Fan",
      "Zhangshuan Hou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.07760",
    "title": "Ransomware Detection Using Federated Learning with Imbalanced Datasets",
    "abstract": "Ransomware is a type of malware which encrypts user data and extorts payments in return for the decryption keys. This cyberthreat is one of the most serious challenges facing organizations today and has already caused immense financial damage. As a result, many researchers have been developing techniques to counter ransomware. Recently, the federated learning (FL) approach has also been applied for ransomware analysis, allowing corporations to achieve scalable, effective detection and attribution without having to share their private data. However, in reality there is much variation in the quantity and composition of ransomware data collected across multiple FL client sites/regions. This imbalance will inevitably degrade the effectiveness of any defense mechanisms. To address this concern, a modified FL scheme is proposed using a weighted cross-entropy loss function approach to mitigate dataset imbalance. A detailed performance evaluation study is then presented for the case of static analysis using the latest Windows-based ransomware families. The findings confirm improved ML classifier performance for a highly imbalanced dataset. ",
    "url": "https://arxiv.org/abs/2311.07760",
    "authors": [
      "Aldin Vehabovic",
      "Hadi Zanddizari",
      "Nasir Ghani",
      "G. Javidi",
      "S. Uluagac",
      "M. Rahouti",
      "E. Bou-Harb",
      "M. Safaei Pour"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.07780",
    "title": "Parrot-Trained Adversarial Examples: Pushing the Practicality of  Black-Box Audio Attacks against Speaker Recognition Models",
    "abstract": "Audio adversarial examples (AEs) have posed significant security challenges to real-world speaker recognition systems. Most black-box attacks still require certain information from the speaker recognition model to be effective (e.g., keeping probing and requiring the knowledge of similarity scores). This work aims to push the practicality of the black-box attacks by minimizing the attacker's knowledge about a target speaker recognition model. Although it is not feasible for an attacker to succeed with completely zero knowledge, we assume that the attacker only knows a short (or a few seconds) speech sample of a target speaker. Without any probing to gain further knowledge about the target model, we propose a new mechanism, called parrot training, to generate AEs against the target model. Motivated by recent advancements in voice conversion (VC), we propose to use the one short sentence knowledge to generate more synthetic speech samples that sound like the target speaker, called parrot speech. Then, we use these parrot speech samples to train a parrot-trained(PT) surrogate model for the attacker. Under a joint transferability and perception framework, we investigate different ways to generate AEs on the PT model (called PT-AEs) to ensure the PT-AEs can be generated with high transferability to a black-box target model with good human perceptual quality. Real-world experiments show that the resultant PT-AEs achieve the attack success rates of 45.8% - 80.8% against the open-source models in the digital-line scenario and 47.9% - 58.3% against smart devices, including Apple HomePod (Siri), Amazon Echo, and Google Home, in the over-the-air scenario. ",
    "url": "https://arxiv.org/abs/2311.07780",
    "authors": [
      "Rui Duan",
      "Zhe Qu",
      "Leah Ding",
      "Yao Liu",
      "Zhuo Lu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2311.07798",
    "title": "Probabilistic Physics-integrated Neural Differentiable Modeling for  Isothermal Chemical Vapor Infiltration Process",
    "abstract": "Chemical vapor infiltration (CVI) is a widely adopted manufacturing technique used in producing carbon-carbon and carbon-silicon carbide composites. These materials are especially valued in the aerospace and automotive industries for their robust strength and lightweight characteristics. The densification process during CVI critically influences the final performance, quality, and consistency of these composite materials. Experimentally optimizing the CVI processes is challenging due to long experimental time and large optimization space. To address these challenges, this work takes a modeling-centric approach. Due to the complexities and limited experimental data of the isothermal CVI densification process, we have developed a data-driven predictive model using the physics-integrated neural differentiable (PiNDiff) modeling framework. An uncertainty quantification feature has been embedded within the PiNDiff method, bolstering the model's reliability and robustness. Through comprehensive numerical experiments involving both synthetic and real-world manufacturing data, the proposed method showcases its capability in modeling densification during the CVI process. This research highlights the potential of the PiNDiff framework as an instrumental tool for advancing our understanding, simulation, and optimization of the CVI manufacturing process, particularly when faced with sparse data and an incomplete description of the underlying physics. ",
    "url": "https://arxiv.org/abs/2311.07798",
    "authors": [
      "Deepak Akhare",
      "Zeping Chen",
      "Richard Gulotty",
      "Tengfei Luo",
      "Jian-Xun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.07816",
    "title": "Leveraging Large Language Models to Detect Influence Campaigns in Social  Media",
    "abstract": "Social media influence campaigns pose significant challenges to public discourse and democracy. Traditional detection methods fall short due to the complexity and dynamic nature of social media. Addressing this, we propose a novel detection method using Large Language Models (LLMs) that incorporates both user metadata and network structures. By converting these elements into a text format, our approach effectively processes multilingual content and adapts to the shifting tactics of malicious campaign actors. We validate our model through rigorous testing on multiple datasets, showcasing its superior performance in identifying influence efforts. This research not only offers a powerful tool for detecting campaigns, but also sets the stage for future enhancements to keep up with the fast-paced evolution of social media-based influence tactics. ",
    "url": "https://arxiv.org/abs/2311.07816",
    "authors": [
      "Luca Luceri",
      "Eric Boniardi",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.07840",
    "title": "Enabling Decision-Support Systems through Automated Cell Tower Detection",
    "abstract": "Cell phone coverage and high-speed service gaps persist in rural areas in sub-Saharan Africa, impacting public access to mobile-based financial, educational, and humanitarian services. Improving maps of telecommunications infrastructure can help inform strategies to eliminate gaps in mobile coverage. Deep neural networks, paired with remote sensing images, can be used for object detection of cell towers and eliminate the need for inefficient and burdensome manual mapping to find objects over large geographic regions. In this study, we demonstrate a partially automated workflow to train an object detection model to locate cell towers using OpenStreetMap (OSM) features and high-resolution Maxar imagery. For model fine-tuning and evaluation, we curated a diverse dataset of over 6,000 unique images of cell towers in 26 countries in eastern, southern, and central Africa using automatically generated annotations from OSM points. Our model achieves an average precision at 50% Intersection over Union (IoU) (AP@50) of 81.2 with good performance across different geographies and out-of-sample testing. Accurate localization of cell towers can yield more accurate cell coverage maps, in turn enabling improved delivery of digital services for decision-support applications. ",
    "url": "https://arxiv.org/abs/2311.07840",
    "authors": [
      "Natasha Krell",
      "Will Gleave",
      "Daniel Nakada",
      "Justin Downes",
      "Amanda Willet",
      "Matthew Baran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.07850",
    "title": "Bring Your Own KG: Self-Supervised Program Synthesis for Zero-Shot KGQA",
    "abstract": "We present BYOKG, a universal question-answering (QA) system that can operate on any knowledge graph (KG), requires no human-annotated training data, and can be ready to use within a day -- attributes that are out-of-scope for current KGQA systems. BYOKG draws inspiration from the remarkable ability of humans to comprehend information present in an unseen KG through exploration -- starting at random nodes, inspecting the labels of adjacent nodes and edges, and combining them with their prior world knowledge. In BYOKG, exploration leverages an LLM-backed symbolic agent that generates a diverse set of query-program exemplars, which are then used to ground a retrieval-augmented reasoning procedure to predict programs for arbitrary questions. BYOKG is effective over both small- and large-scale graphs, showing dramatic gains in QA accuracy over a zero-shot baseline of 27.89 and 58.02 F1 on GrailQA and MetaQA, respectively. On GrailQA, we further show that our unsupervised BYOKG outperforms a supervised in-context learning method, demonstrating the effectiveness of exploration. Lastly, we find that performance of BYOKG reliably improves with continued exploration as well as improvements in the base LLM, notably outperforming a state-of-the-art fine-tuned model by 7.08 F1 on a sub-sampled zero-shot split of GrailQA. ",
    "url": "https://arxiv.org/abs/2311.07850",
    "authors": [
      "Dhruv Agarwal",
      "Rajarshi Das",
      "Sopan Khosla",
      "Rashmi Gangadharaiah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.07864",
    "title": "Probing clustering in neural network representations",
    "abstract": "Neural network representations contain structure beyond what was present in the training labels. For instance, representations of images that are visually or semantically similar tend to lie closer to each other than to dissimilar images, regardless of their labels. Clustering these representations can thus provide insights into dataset properties as well as the network internals. In this work, we study how the many design choices involved in neural network training affect the clusters formed in the hidden representations. To do so, we establish an evaluation setup based on the BREEDS hierarchy, for the task of subclass clustering after training models with only superclass information. We isolate the training dataset and architecture as important factors affecting clusterability. Datasets with labeled classes consisting of unrelated subclasses yield much better clusterability than those following a natural hierarchy. When using pretrained models to cluster representations on downstream datasets, models pretrained on subclass labels provide better clusterability than models pretrained on superclass labels, but only when there is a high degree of domain overlap between the pretraining and downstream data. Architecturally, we find that normalization strategies affect which layers yield the best clustering performance, and, surprisingly, Vision Transformers attain lower subclass clusterability than ResNets. ",
    "url": "https://arxiv.org/abs/2311.07864",
    "authors": [
      "Thao Nguyen",
      "Simon Kornblith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.07867",
    "title": "Mixture of Coupled HMMs for Robust Modeling of Multivariate Healthcare  Time Series",
    "abstract": "Analysis of multivariate healthcare time series data is inherently challenging: irregular sampling, noisy and missing values, and heterogeneous patient groups with different dynamics violating exchangeability. In addition, interpretability and quantification of uncertainty are critically important. Here, we propose a novel class of models, a mixture of coupled hidden Markov models (M-CHMM), and demonstrate how it elegantly overcomes these challenges. To make the model learning feasible, we derive two algorithms to sample the sequences of the latent variables in the CHMM: samplers based on (i) particle filtering and (ii) factorized approximation. Compared to existing inference methods, our algorithms are computationally tractable, improve mixing, and allow for likelihood estimation, which is necessary to learn the mixture model. Experiments on challenging real-world epidemiological and semi-synthetic data demonstrate the advantages of the M-CHMM: improved data fit, capacity to efficiently handle missing and noisy measurements, improved prediction accuracy, and ability to identify interpretable subsets in the data. ",
    "url": "https://arxiv.org/abs/2311.07867",
    "authors": [
      "Onur Poyraz",
      "Pekka Marttinen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.07871",
    "title": "Dual-channel Prototype Network for few-shot Classification of  Pathological Images",
    "abstract": "In pathology, the rarity of certain diseases and the complexity in annotating pathological images significantly hinder the creation of extensive, high-quality datasets. This limitation impedes the progress of deep learning-assisted diagnostic systems in pathology. Consequently, it becomes imperative to devise a technology that can discern new disease categories from a minimal number of annotated examples. Such a technology would substantially advance deep learning models for rare diseases. Addressing this need, we introduce the Dual-channel Prototype Network (DCPN), rooted in the few-shot learning paradigm, to tackle the challenge of classifying pathological images with limited samples. DCPN augments the Pyramid Vision Transformer (PVT) framework for few-shot classification via self-supervised learning and integrates it with convolutional neural networks. This combination forms a dual-channel architecture that extracts multi-scale, highly precise pathological features. The approach enhances the versatility of prototype representations and elevates the efficacy of prototype networks in few-shot pathological image classification tasks. We evaluated DCPN using three publicly available pathological datasets, configuring small-sample classification tasks that mirror varying degrees of clinical scenario domain shifts. Our experimental findings robustly affirm DCPN's superiority in few-shot pathological image classification, particularly in tasks within the same domain, where it achieves the benchmarks of supervised learning. ",
    "url": "https://arxiv.org/abs/2311.07871",
    "authors": [
      "Hao Quan",
      "Xinjia Li",
      "Dayu Hu",
      "Tianhang Nan",
      "Xiaoyu Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.07872",
    "title": "Cost-Efficient Computation Offloading and Service Chain Caching in LEO  Satellite Networks",
    "abstract": "The ever-increasing demand for ubiquitous, continuous, and high-quality services poses a great challenge to the traditional terrestrial network. To mitigate this problem, the mobile-edge-computing-enhanced low earth orbit (LEO) satellite network, which provides both communication connectivity and on-board processing services, has emerged as an effective method. The main issue in LEO satellites includes finding the optimal locations to host network functions (NFs) and then making offloading decisions. In this article, we jointly consider the problem of service chain caching and computation offloading to minimize the overall cost, which consists of task latency and energy consumption. In particular, the collaboration among satellites, the network resource limitations, and the specific operation order of NFs in service chains are taken into account. Then, the problem is formulated and linearized as an integer linear programming model. Moreover, to accelerate the solution, we provide a greedy algorithm with cubic time complexity. Numerical investigations demonstrate the effectiveness of the proposed scheme, which can reduce the overall cost by around 20% compared to the nominal case where NFs are served in data centers. ",
    "url": "https://arxiv.org/abs/2311.07872",
    "authors": [
      "Yantong Wang",
      "Chuanfen Feng",
      "Jiande Sun"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.07876",
    "title": "Learning Adversarial Low-rank Markov Decision Processes with Unknown  Transition and Full-information Feedback",
    "abstract": "In this work, we study the low-rank MDPs with adversarially changed losses in the full-information feedback setting. In particular, the unknown transition probability kernel admits a low-rank matrix decomposition \\citep{REPUCB22}, and the loss functions may change adversarially but are revealed to the learner at the end of each episode. We propose a policy optimization-based algorithm POLO, and we prove that it attains the $\\widetilde{O}(K^{\\frac{5}{6}}A^{\\frac{1}{2}}d\\ln(1+M)/(1-\\gamma)^2)$ regret guarantee, where $d$ is rank of the transition kernel (and hence the dimension of the unknown representations), $A$ is the cardinality of the action space, $M$ is the cardinality of the model class, and $\\gamma$ is the discounted factor. Notably, our algorithm is oracle-efficient and has a regret guarantee with no dependence on the size of potentially arbitrarily large state space. Furthermore, we also prove an $\\Omega(\\frac{\\gamma^2}{1-\\gamma} \\sqrt{d A K})$ regret lower bound for this problem, showing that low-rank MDPs are statistically more difficult to learn than linear MDPs in the regret minimization setting. To the best of our knowledge, we present the first algorithm that interleaves representation learning, exploration, and exploitation to achieve the sublinear regret guarantee for RL with nonlinear function approximation and adversarial losses. ",
    "url": "https://arxiv.org/abs/2311.07876",
    "authors": [
      "Canzhe Zhao",
      "Ruofeng Yang",
      "Baoxiang Wang",
      "Xuezhou Zhang",
      "Shuai Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.07879",
    "title": "Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting  Volunteer Content Moderators",
    "abstract": "Extensive efforts in automated approaches for content moderation have been focused on developing models to identify toxic, offensive, and hateful content -- with the aim of lightening the load for moderators. Yet, it remains uncertain whether improvements on those tasks truly address the needs that moderators have in accomplishing their work. In this paper, we surface the gaps between past research efforts that have aimed to provide automation for aspects of the content moderation task, and the needs of volunteer content moderators. To do so, we conduct a model review on Hugging Face to reveal the availability of models to cover various moderation rules and guidelines. We further put state-of-the-art LLMs to the test (GPT-4 and Llama-2), evaluating how well these models perform in flagging violations of platform rules. Overall, we observe a non-trivial gap, as missing developed models and LLMs exhibit low recall on a significant portion of the rules. ",
    "url": "https://arxiv.org/abs/2311.07879",
    "authors": [
      "Yang Trista Cao",
      "Lovely-Frances Domingo",
      "Sarah Ann Gilbert",
      "Michelle Mazurek",
      "Katie Shilton",
      "Hal Daum\u00e9 III"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.07880",
    "title": "VegaEdge: Edge AI Confluence Anomaly Detection for Real-Time Highway  IoT-Applications",
    "abstract": "Vehicle anomaly detection plays a vital role in highway safety applications such as accident prevention, rapid response, traffic flow optimization, and work zone safety. With the surge of the Internet of Things (IoT) in recent years, there has arisen a pressing demand for Artificial Intelligence (AI) based anomaly detection methods designed to meet the requirements of IoT devices. Catering to this futuristic vision, we introduce a lightweight approach to vehicle anomaly detection by utilizing the power of trajectory prediction. Our proposed design identifies vehicles deviating from expected paths, indicating highway risks from different camera-viewing angles from real-world highway datasets. On top of that, we present VegaEdge - a sophisticated AI confluence designed for real-time security and surveillance applications in modern highway settings through edge-centric IoT-embedded platforms equipped with our anomaly detection approach. Extensive testing across multiple platforms and traffic scenarios showcases the versatility and effectiveness of VegaEdge. This work also presents the Carolinas Anomaly Dataset (CAD), to bridge the existing gap in datasets tailored for highway anomalies. In real-world scenarios, our anomaly detection approach achieves an AUC-ROC of 0.94, and our proposed VegaEdge design, on an embedded IoT platform, processes 738 trajectories per second in a typical highway setting. The dataset is available at https://github.com/TeCSAR-UNCC/Carolinas_Dataset#chd-anomaly-test-set . ",
    "url": "https://arxiv.org/abs/2311.07880",
    "authors": [
      "Vinit Katariya",
      "Fatema-E- Jannat",
      "Armin Danesh Pazho",
      "Ghazal Alinezhad Noghre",
      "Hamed Tabkhi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.07912",
    "title": "Detection of Small Targets in Sea Clutter Based on RepVGG and Continuous  Wavelet Transform",
    "abstract": "Constructing a high-performance target detector under the background of sea clutter is always necessary and important. In this work, we propose a RepVGGA0-CWT detector, where RepVGG is a residual network that gains a high detection accuracy. Different from traditional residual networks, RepVGG keeps an acceptable calculation speed. Giving consideration to both accuracy and speed, the RepVGGA0 is selected among all the variants of RepVGG. Also, continuous wavelet transform (CWT) is employed to extract the radar echoes' time-frequency feature effectively. In the tests, other networks (ResNet50, ResNet18 and AlexNet) and feature extraction methods (short-time Fourier transform (STFT), CWT) are combined to build detectors for comparison. The result of different datasets shows that the RepVGGA0-CWT detector performs better than those detectors in terms of low controllable false alarm rate, high training speed, high inference speed and low memory usage. This RepVGGA0-CWT detector is hardware-friendly and can be applied in real-time scenes for its high inference speed in detection. ",
    "url": "https://arxiv.org/abs/2311.07912",
    "authors": [
      "Jingchen Ni",
      "Haoru Li",
      "Lilin Xu",
      "Jing Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.07914",
    "title": "Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey",
    "abstract": "The contemporary LLMs are prone to producing hallucinations, stemming mainly from the knowledge gaps within the models. To address this critical limitation, researchers employ diverse strategies to augment the LLMs by incorporating external knowledge, aiming to reduce hallucinations and enhance reasoning accuracy. Among these strategies, leveraging knowledge graphs as a source of external information has demonstrated promising results. In this survey, we conduct a comprehensive review of these knowledge-graph-based knowledge augmentation techniques in LLMs, focusing on their efficacy in mitigating hallucinations. We systematically categorize these methods into three overarching groups, offering both methodological comparisons and empirical evaluations of their performance. Lastly, the paper explores the challenges associated with these techniques and outlines potential avenues for future research in this emerging field. ",
    "url": "https://arxiv.org/abs/2311.07914",
    "authors": [
      "Garima Agrawal",
      "Tharindu Kumarage",
      "Zeyad Alghami",
      "Huan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.07925",
    "title": "Brain-Driven Representation Learning Based on Diffusion Model",
    "abstract": "Interpreting EEG signals linked to spoken language presents a complex challenge, given the data's intricate temporal and spatial attributes, as well as the various noise factors. Denoising diffusion probabilistic models (DDPMs), which have recently gained prominence in diverse areas for their capabilities in representation learning, are explored in our research as a means to address this issue. Using DDPMs in conjunction with a conditional autoencoder, our new approach considerably outperforms traditional machine learning algorithms and established baseline models in accuracy. Our results highlight the potential of DDPMs as a sophisticated computational method for the analysis of speech-related EEG signals. This could lead to significant advances in brain-computer interfaces tailored for spoken communication. ",
    "url": "https://arxiv.org/abs/2311.07925",
    "authors": [
      "Soowon Kim",
      "Seo-Hyun Lee",
      "Young-Eun Lee",
      "Ji-Won Lee",
      "Ji-Ha Park",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.07928",
    "title": "Towards Improving Robustness Against Common Corruptions in Object  Detectors Using Adversarial Contrastive Learning",
    "abstract": "Neural networks have revolutionized various domains, exhibiting remarkable accuracy in tasks like natural language processing and computer vision. However, their vulnerability to slight alterations in input samples poses challenges, particularly in safety-critical applications like autonomous driving. Current approaches, such as introducing distortions during training, fall short in addressing unforeseen corruptions. This paper proposes an innovative adversarial contrastive learning framework to enhance neural network robustness simultaneously against adversarial attacks and common corruptions. By generating instance-wise adversarial examples and optimizing contrastive loss, our method fosters representations that resist adversarial perturbations and remain robust in real-world scenarios. Subsequent contrastive learning then strengthens the similarity between clean samples and their adversarial counterparts, fostering representations resistant to both adversarial attacks and common distortions. By focusing on improving performance under adversarial and real-world conditions, our approach aims to bolster the robustness of neural networks in safety-critical applications, such as autonomous vehicles navigating unpredictable weather conditions. We anticipate that this framework will contribute to advancing the reliability of neural networks in challenging environments, facilitating their widespread adoption in mission-critical scenarios. ",
    "url": "https://arxiv.org/abs/2311.07928",
    "authors": [
      "Shashank Kotyan",
      "Danilo Vasconcellos Vargas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.07929",
    "title": "Self-supervised Heterogeneous Graph Variational Autoencoders",
    "abstract": "Heterogeneous Information Networks (HINs), which consist of various types of nodes and edges, have recently demonstrated excellent performance in graph mining. However, most existing heterogeneous graph neural networks (HGNNs) ignore the problems of missing attributes, inaccurate attributes and scarce labels for nodes, which limits their expressiveness. In this paper, we propose a generative self-supervised model SHAVA to address these issues simultaneously. Specifically, SHAVA first initializes all the nodes in the graph with a low-dimensional representation matrix. After that, based on the variational graph autoencoder framework, SHAVA learns both node-level and attribute-level embeddings in the encoder, which can provide fine-grained semantic information to construct node attributes. In the decoder, SHAVA reconstructs both links and attributes. Instead of directly reconstructing raw features for attributed nodes, SHAVA generates the initial low-dimensional representation matrix for all the nodes, based on which raw features of attributed nodes are further reconstructed to leverage accurate attributes. In this way, SHAVA can not only complete informative features for non-attributed nodes, but rectify inaccurate ones for attributed nodes. Finally, we conduct extensive experiments to show the superiority of SHAVA in tackling HINs with missing and inaccurate attributes. ",
    "url": "https://arxiv.org/abs/2311.07929",
    "authors": [
      "Yige Zhao",
      "Jianxiang Yu",
      "Yao Cheng",
      "Chengcheng Yu",
      "Yiding Liu",
      "Xiang Li",
      "Shuaiqiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.07930",
    "title": "It's All Relative! -- A Synthetic Query Generation Approach for  Improving Zero-Shot Relevance Prediction",
    "abstract": "Recent developments in large language models (LLMs) have shown promise in their ability to generate synthetic query-document pairs by prompting with as few as 8 demonstrations. This has enabled building better IR models, especially for tasks with no training data readily available. Typically, such synthetic query generation (QGen) approaches condition on an input context (e.g. a text document) and generate a query relevant to that context, or condition the QGen model additionally on the relevance label (e.g. relevant vs irrelevant) to generate queries across relevance buckets. However, we find that such QGen approaches are sub-optimal as they require the model to reason about the desired label and the input from a handful of examples. In this work, we propose to reduce this burden of LLMs by generating queries simultaneously for different labels. We hypothesize that instead of asking the model to generate, say, an irrelevant query given an input context, asking the model to generate an irrelevant query relative to a relevant query is a much simpler task setup for the model to reason about. Extensive experimentation across seven IR datasets shows that synthetic queries generated in such a fashion translates to a better downstream performance, suggesting that the generated queries are indeed of higher quality. ",
    "url": "https://arxiv.org/abs/2311.07930",
    "authors": [
      "Aditi Chaudhary",
      "Karthik Raman",
      "Michael Bendersky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.07932",
    "title": "Cross-subject dual-domain fusion network with task-related and  task-discriminant component analysis enhancing one-shot SSVEP classification",
    "abstract": "This study addresses the significant challenge of developing efficient decoding algorithms for classifying steady-state visual evoked potentials (SSVEPs) in scenarios characterized by extreme scarcity of calibration data, where only one calibration is available for each stimulus target. To tackle this problem, we introduce a novel cross-subject dual-domain fusion network (CSDuDoFN) incorporating task-related and task-discriminant component analysis (TRCA and TDCA) for one-shot SSVEP classification. The CSDuDoFN framework is designed to comprehensively transfer information from source subjects, while TRCA and TDCA are employed to exploit the single available calibration of the target subject. Specifically, we develop multi-reference least-squares transformation (MLST) to map data from both source subjects and the target subject into the domain of sine-cosine templates, thereby mitigating inter-individual variability and benefiting transfer learning. Subsequently, the transformed data in the sine-cosine templates domain and the original domain data are separately utilized to train a convolutional neural network (CNN) model, with the adequate fusion of their feature maps occurring at distinct network layers. To further capitalize on the calibration of the target subject, source aliasing matrix estimation (SAME) data augmentation is incorporated into the training process of the ensemble TRCA (eTRCA) and TDCA models. Ultimately, the outputs of the CSDuDoFN, eTRCA, and TDCA are combined for SSVEP classification. The effectiveness of our proposed approach is comprehensively evaluated on three publicly available SSVEP datasets, achieving the best performance on two datasets and competitive performance on one. This underscores the potential for integrating brain-computer interface (BCI) into daily life. ",
    "url": "https://arxiv.org/abs/2311.07932",
    "authors": [
      "Yang Deng",
      "Zhiwei Ji",
      "Yijun Wang",
      "S.Kevin Zhou"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2311.07946",
    "title": "The Impact of Adversarial Node Placement in Decentralized Federated  Learning Networks",
    "abstract": "As Federated Learning (FL) grows in popularity, new decentralized frameworks are becoming widespread. These frameworks leverage the benefits of decentralized environments to enable fast and energy-efficient inter-device communication. However, this growing popularity also intensifies the need for robust security measures. While existing research has explored various aspects of FL security, the role of adversarial node placement in decentralized networks remains largely unexplored. This paper addresses this gap by analyzing the performance of decentralized FL for various adversarial placement strategies when adversaries can jointly coordinate their placement within a network. We establish two baseline strategies for placing adversarial node: random placement and network centrality-based placement. Building on this foundation, we propose a novel attack algorithm that prioritizes adversarial spread over adversarial centrality by maximizing the average network distance between adversaries. We show that the new attack algorithm significantly impacts key performance metrics such as testing accuracy, outperforming the baseline frameworks by between 9% and 66.5% for the considered setups. Our findings provide valuable insights into the vulnerabilities of decentralized FL systems, setting the stage for future research aimed at developing more secure and robust decentralized FL frameworks. ",
    "url": "https://arxiv.org/abs/2311.07946",
    "authors": [
      "Adam Piaseczny",
      "Eric Ruzomberka",
      "Rohit Parasnis",
      "Christopher G. Brinton"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2311.07955",
    "title": "Deep Learning-Based Object Detection in Maritime Unmanned Aerial Vehicle  Imagery: Review and Experimental Comparisons",
    "abstract": "With the advancement of maritime unmanned aerial vehicles (UAVs) and deep learning technologies, the application of UAV-based object detection has become increasingly significant in the fields of maritime industry and ocean engineering. Endowed with intelligent sensing capabilities, the maritime UAVs enable effective and efficient maritime surveillance. To further promote the development of maritime UAV-based object detection, this paper provides a comprehensive review of challenges, relative methods, and UAV aerial datasets. Specifically, in this work, we first briefly summarize four challenges for object detection on maritime UAVs, i.e., object feature diversity, device limitation, maritime environment variability, and dataset scarcity. We then focus on computational methods to improve maritime UAV-based object detection performance in terms of scale-aware, small object detection, view-aware, rotated object detection, lightweight methods, and others. Next, we review the UAV aerial image/video datasets and propose a maritime UAV aerial dataset named MS2ship for ship detection. Furthermore, we conduct a series of experiments to present the performance evaluation and robustness analysis of object detection methods on maritime datasets. Eventually, we give the discussion and outlook on future works for maritime UAV-based object detection. The MS2ship dataset is available at \\href{https://github.com/zcj234/MS2ship}{https://github.com/zcj234/MS2ship}. ",
    "url": "https://arxiv.org/abs/2311.07955",
    "authors": [
      "Chenjie Zhao",
      "Ryan Wen Liu",
      "Jingxiang Qu",
      "Ruobin Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.07965",
    "title": "DQR-TTS: Semi-supervised Text-to-speech Synthesis with Dynamic Quantized  Representation",
    "abstract": "Most existing neural-based text-to-speech methods rely on extensive datasets and face challenges under low-resource condition. In this paper, we introduce a novel semi-supervised text-to-speech synthesis model that learns from both paired and unpaired data to address this challenge. The key component of the proposed model is a dynamic quantized representation module, which is integrated into a sequential autoencoder. When given paired data, the module incorporates a trainable codebook that learns quantized representations under the supervision of the paired data. However, due to the limited paired data in low-resource scenario, these paired data are difficult to cover all phonemes. Then unpaired data is fed to expand the dynamic codebook by adding quantized representation vectors that are sufficiently distant from the existing ones during training. Experiments show that with less than 120 minutes of paired data, the proposed method outperforms existing methods in both subjective and objective metrics. ",
    "url": "https://arxiv.org/abs/2311.07965",
    "authors": [
      "Jiangzong Wang",
      "Pengcheng Li",
      "Xulong Zhang",
      "Ning Cheng",
      "Jing Xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2311.07966",
    "title": "Higher-Order Expander Graph Propagation",
    "abstract": "Graph neural networks operate on graph-structured data via exchanging messages along edges. One limitation of this message passing paradigm is the over-squashing problem. Over-squashing occurs when messages from a node's expanded receptive field are compressed into fixed-size vectors, potentially causing information loss. To address this issue, recent works have explored using expander graphs, which are highly-connected sparse graphs with low diameters, to perform message passing. However, current methods on expander graph propagation only consider pair-wise interactions, ignoring higher-order structures in complex data. To explore the benefits of capturing these higher-order correlations while still leveraging expander graphs, we introduce higher-order expander graph propagation. We propose two methods for constructing bipartite expanders and evaluate their performance on both synthetic and real-world datasets. ",
    "url": "https://arxiv.org/abs/2311.07966",
    "authors": [
      "Thomas Christie",
      "Yu He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.07985",
    "title": "Configurable convolutional neural networks for real-time  pedestrian-level wind prediction in urban environments",
    "abstract": "Urbanization has underscored the importance of understanding the pedestrian wind environment in urban and architectural design contexts. Pedestrian Wind Comfort (PWC) focuses on the effects of wind on the safety and comfort of pedestrians and cyclists, given the influence of urban structures on the local microclimate. Traditional Computational Fluid Dynamics (CFD) methods used for PWC analysis have limitations in computation, cost, and time. Deep-learning models have the potential to significantly speed up this process. The prevailing state-of-the-art methodologies largely rely on GAN-based models, such as pix2pix, which have exhibited training instability issues. In contrast, our work introduces a convolutional neural network (CNN) approach based on the U-Net architecture, offering a more stable and streamlined solution. The process of generating a wind flow prediction at pedestrian level is reformulated from a 3D CFD simulation into a 2D image-to-image translation task, using the projected building heights as input. Testing on standard consumer hardware shows that our model can efficiently predict wind velocities in urban settings in real time. Further tests on different configurations of the model, combined with a Pareto front analysis, helped identify the trade-off between accuracy and computational efficiency. This CNN-based approach provides a fast and efficient method for PWC analysis, potentially aiding in more efficient urban design processes. ",
    "url": "https://arxiv.org/abs/2311.07985",
    "authors": [
      "Alfredo Vicente Clemente",
      "Knut Erik Teigen Giljarhus",
      "Luca Oggiano",
      "Massimiliano Ruocco"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2311.07989",
    "title": "A Survey on Language Models for Code",
    "abstract": "In this work we systematically review the recent advancements in code processing with language models, covering 50+ models, 30+ evaluation tasks, and 500 related works. We break down code processing models into general language models represented by the GPT family and specialized models that are specifically pretrained on code, often with tailored objectives. We discuss the relations and differences between these models, and highlight the historical transition of code modeling from statistical models and RNNs to pretrained Transformers and LLMs, which is exactly the same course that had been taken by NLP. We also discuss code-specific features such as AST, CFG, and unit tests, along with their application in training code language models, and identify key challenges and potential future directions in this domain. We keep the survey open and updated on github repository at https://github.com/codefuse-ai/Awesome-Code-LLM. ",
    "url": "https://arxiv.org/abs/2311.07989",
    "authors": [
      "Ziyin Zhang",
      "Chaoyu Chen",
      "Bingchang Liu",
      "Cong Liao",
      "Zi Gong",
      "Hang Yu",
      "Jianguo Li",
      "Rui Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2311.07993",
    "title": "Explicit Change Relation Learning for Change Detection in VHR Remote  Sensing Images",
    "abstract": "Change detection has always been a concerned task in the interpretation of remote sensing images. It is essentially a unique binary classification task with two inputs, and there is a change relationship between these two inputs. At present, the mining of change relationship features is usually implicit in the network architectures that contain single-branch or two-branch encoders. However, due to the lack of artificial prior design for change relationship features, these networks cannot learn enough change semantic information and lose more accurate change detection performance. So we propose a network architecture NAME for the explicit mining of change relation features. In our opinion, the change features of change detection should be divided into pre-changed image features, post-changed image features and change relation features. In order to fully mine these three kinds of change features, we propose the triple branch network combining the transformer and convolutional neural network (CNN) to extract and fuse these change features from two perspectives of global information and local information, respectively. In addition, we design the continuous change relation (CCR) branch to further obtain the continuous and detail change relation features to improve the change discrimination capability of the model. The experimental results show that our network performs better, in terms of F1, IoU, and OA, than those of the existing advanced networks for change detection on four public very high-resolution (VHR) remote sensing datasets. Our source code is available at https://github.com/DalongZ/NAME. ",
    "url": "https://arxiv.org/abs/2311.07993",
    "authors": [
      "Dalong Zheng",
      "Zebin Wu",
      "Jia Liu",
      "Chih-Cheng Hung",
      "Zhihui Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.07996",
    "title": "How Well Do Text Embedding Models Understand Syntax?",
    "abstract": "Text embedding models have significantly contributed to advancements in natural language processing by adeptly capturing semantic properties of textual data. However, the ability of these models to generalize across a wide range of syntactic contexts remains under-explored. In this paper, we first develop an evaluation set, named \\textbf{SR}, to scrutinize the capability for syntax understanding of text embedding models from two crucial syntactic aspects: Structural heuristics, and Relational understanding among concepts, as revealed by the performance gaps in previous studies. Our findings reveal that existing text embedding models have not sufficiently addressed these syntactic understanding challenges, and such ineffectiveness becomes even more apparent when evaluated against existing benchmark datasets. Furthermore, we conduct rigorous analysis to unearth factors that lead to such limitations and examine why previous evaluations fail to detect such ineffectiveness. Lastly, we propose strategies to augment the generalization ability of text embedding models in diverse syntactic scenarios. This study serves to highlight the hurdles associated with syntactic generalization and provides pragmatic guidance for boosting model performance across varied syntactic contexts. ",
    "url": "https://arxiv.org/abs/2311.07996",
    "authors": [
      "Yan Zhang",
      "Zhaopeng Feng",
      "Zhiyang Teng",
      "Zuozhu Liu",
      "Haizhou Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.08000",
    "title": "LiPar: A Lightweight Parallel Learning Model for Practical In-Vehicle  Network Intrusion Detection",
    "abstract": "With the development of intelligent transportation systems, vehicles are exposed to a complex network environment. As the main network of in-vehicle networks, the controller area network (CAN) has many potential security hazards, resulting in higher requirements for intrusion detection systems to ensure safety. Among intrusion detection technologies, methods based on deep learning work best without prior expert knowledge. However, they all have a large model size and rely on cloud computing, and are therefore not suitable to be installed on the in-vehicle network. Therefore, we propose a lightweight parallel neural network structure, LiPar, to allocate task loads to multiple electronic control units (ECU). The LiPar model consists of multi-dimensional branch convolution networks, spatial and temporal feature fusion learning, and a resource adaptation algorithm. Through experiments, we prove that LiPar has great detection performance, running efficiency, and lightweight model size, which can be well adapted to the in-vehicle environment practically and protect the in-vehicle CAN bus security. ",
    "url": "https://arxiv.org/abs/2311.08000",
    "authors": [
      "Aiheng Zhang",
      "Kai Wang",
      "Bailing Wang",
      "Yulei Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.08001",
    "title": "A Comparative Analysis of the COVID-19 Infodemic in English and Chinese:  Insights from Social Media Textual Data",
    "abstract": "The COVID-19 infodemic, characterized by the rapid spread of misinformation and unverified claims related to the pandemic, presents a significant challenge. This paper presents a comparative analysis of the COVID-19 infodemic in the English and Chinese languages, utilizing textual data extracted from social media platforms. To ensure a balanced representation, two infodemic datasets were created by augmenting previously collected social media textual data. Through word frequency analysis, the thirty-five most frequently occurring infodemic words are identified, shedding light on prevalent discussions surrounding the infodemic. Moreover, topic clustering analysis uncovers thematic structures and provides a deeper understanding of primary topics within each language context. Additionally, sentiment analysis enables comprehension of the emotional tone associated with COVID-19 information on social media platforms in English and Chinese. This research contributes to a better understanding of the COVID-19 infodemic phenomenon and can guide the development of strategies to combat misinformation during public health crises across different languages. ",
    "url": "https://arxiv.org/abs/2311.08001",
    "authors": [
      "Jia Luo",
      "Daiyun Peng",
      "Lei Shi",
      "Didier El Baz",
      "Xinran Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2311.08009",
    "title": "From Human to Robot Interactions: A Circular Approach towards  Trustworthy Social Robots",
    "abstract": "Human trust research uncovered important catalysts for trust building between interaction partners such as appearance or cognitive factors. The introduction of robots into social interactions calls for a reevaluation of these findings and also brings new challenges and opportunities. In this paper, we suggest approaching trust research in a circular way by drawing from human trust findings, validating them and conceptualizing them for robots, and finally using the precise manipulability of robots to explore previously less-explored areas of trust formation to generate new hypotheses for trust building between agents. ",
    "url": "https://arxiv.org/abs/2311.08009",
    "authors": [
      "Anna L. Lange",
      "Murat Kirtay",
      "Verena V. Hafner"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.08013",
    "title": "CP-SLAM: Collaborative Neural Point-based SLAM System",
    "abstract": "This paper presents a collaborative implicit neural simultaneous localization and mapping (SLAM) system with RGB-D image sequences, which consists of complete front-end and back-end modules including odometry, loop detection, sub-map fusion, and global refinement. In order to enable all these modules in a unified framework, we propose a novel neural point based 3D scene representation in which each point maintains a learnable neural feature for scene encoding and is associated with a certain keyframe. Moreover, a distributed-to-centralized learning strategy is proposed for the collaborative implicit SLAM to improve consistency and cooperation. A novel global optimization framework is also proposed to improve the system accuracy like traditional bundle adjustment. Experiments on various datasets demonstrate the superiority of the proposed method in both camera tracking and mapping. ",
    "url": "https://arxiv.org/abs/2311.08013",
    "authors": [
      "Jiarui Hu",
      "Mao Mao",
      "Hujun Bao",
      "Guofeng Zhang",
      "Zhaopeng Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.08027",
    "title": "A practical key-recovery attack on LWE-based key-encapsulation mechanism  schemes using Rowhammer",
    "abstract": "Physical attacks are serious threats to cryptosystems deployed in the real world. In this work, we propose a microarchitectural end-to-end attack methodology on generic lattice-based post-quantum key encapsulation mechanisms to recover the long-term secret key. Our attack targets a critical component of a Fujisaki-Okamoto transform that is used in the construction of almost all lattice-based key encapsulation mechanisms. We demonstrate our attack model on practical schemes such as Kyber and Saber by using Rowhammer. We show that our attack is highly practical and imposes little preconditions on the attacker to succeed. As an additional contribution, we propose an improved version of the plaintext checking oracle, which is used by almost all physical attack strategies on lattice-based key-encapsulation mechanisms. Our improvement reduces the number of queries to the plaintext checking oracle by as much as $39\\%$ for Saber and approximately $23\\%$ for Kyber768. This can be of independent interest and can also be used to reduce the complexity of other attacks. ",
    "url": "https://arxiv.org/abs/2311.08027",
    "authors": [
      "Puja Mondal",
      "Suparna Kundu",
      "Sarani Bhattacharya",
      "Angshuman Karmakar",
      "Ingrid Verbauwhede"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.08035",
    "title": "Data-driven building energy efficiency prediction based on envelope heat  losses using physics-informed neural networks",
    "abstract": "The analytical prediction of building energy performance in residential buildings based on the heat losses of its individual envelope components is a challenging task. It is worth noting that this field is still in its infancy, with relatively limited research conducted in this specific area to date, especially when it comes for data-driven approaches. In this paper we introduce a novel physics-informed neural network model for addressing this problem. Through the employment of unexposed datasets that encompass general building information, audited characteristics, and heating energy consumption, we feed the deep learning model with general building information, while the model's output consists of the structural components and several thermal properties that are in fact the basic elements of an energy performance certificate (EPC). On top of this neural network, a function, based on physics equations, calculates the energy consumption of the building based on heat losses and enhances the loss function of the deep learning model. This methodology is tested on a real case study for 256 buildings located in Riga, Latvia. Our investigation comes up with promising results in terms of prediction accuracy, paving the way for automated, and data-driven energy efficiency performance prediction based on basic properties of the building, contrary to exhaustive energy efficiency audits led by humans, which are the current status quo. ",
    "url": "https://arxiv.org/abs/2311.08035",
    "authors": [
      "Vasilis Michalakopoulos",
      "Sotiris Pelekis",
      "Giorgos Kormpakis",
      "Vagelis Karakolis",
      "Spiros Mouzakitis",
      "Dimitris Askounis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2311.08042",
    "title": "Quantum Algorithms for Graph Coloring and other Partitioning, Covering,  and Packing Problems",
    "abstract": "Let U be a universe on n elements, let k be a positive integer, and let F be a family of (implicitly defined) subsets of U. We consider the problems of partitioning U into k sets from F, covering U with k sets from F, and packing k non-intersecting sets from F into U. Classically, these problems can be solved via inclusion-exclusion in O*(2^n) time [BjorklundHK09]. Quantumly, there are faster algorithms for graph coloring with running time O(1.9140^n) [ShimizuM22] and for Set Cover with a small number of sets with running time O(1.7274^n |F|^O(1)) [AmbainisBIKPV19]. In this paper, we give a quantum speedup for Set Partition, Set Cover, and Set Packing whenever there is a classical enumeration algorithm that lends itself to a quadratic quantum speedup, which, for any subinstance on a subset X of U, enumerates at least one member of a k-partition, k-cover, or k-packing (if one exists) restricted to (or projected onto, in the case of k-cover) the set X in O*(c^{|X|}) time with c<2. Our bounded-error quantum algorithm runs in O*((2+c)^(n/2)) for Set Partition, Set Cover, and Set Packing. When c<=1.147899, our algorithm is slightly faster than O*((2+c)^(n/2)); when c approaches 1, it matches the running time of [AmbainisBIKPV19] for Set Cover when |F| is subexponential in n. For Graph Coloring, we further improve the running time to O(1.7956^n) by leveraging faster algorithms for coloring with a small number of colors to better balance our divide-and-conquer steps. For Domatic Number, we obtain a O((2-\\epsilon)^n) running time for some \\epsilon>0. ",
    "url": "https://arxiv.org/abs/2311.08042",
    "authors": [
      "Serge Gaspers",
      "Jerry Zirui Li"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2311.08045",
    "title": "Adversarial Preference Optimization",
    "abstract": "Human preference alignment is a crucial training step to improve the interaction quality of large language models (LLMs). Existing aligning methods depend on manually annotated preference data to guide the LLM optimization directions. However, in practice, continuously updating LLMs raises a distribution gap between model-generated samples and human-preferred responses, which hinders model fine-tuning efficiency. To mitigate this issue, previous methods require additional preference annotation on generated samples to adapt the shifted distribution, which consumes a large amount of annotation resources. Targeting more efficient human preference optimization, we propose an adversarial preference optimization (APO) framework, where the LLM agent and the preference model update alternatively via a min-max game. Without additional annotation, our APO method can make a self-adaption to the generation distribution gap through the adversarial learning process. In experiments, we empirically verify the effectiveness of APO in improving LLM's helpfulness and harmlessness compared with rejection sampling baselines. ",
    "url": "https://arxiv.org/abs/2311.08045",
    "authors": [
      "Pengyu Cheng",
      "Yifan Yang",
      "Jian Li",
      "Yong Dai",
      "Nan Du"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.08046",
    "title": "Chat-UniVi: Unified Visual Representation Empowers Large Language Models  with Image and Video Understanding",
    "abstract": "Large language models have demonstrated impressive universal capabilities across a wide range of open-ended tasks and have extended their utility to encompass multimodal conversations. However, existing methods encounter challenges in effectively handling both image and video understanding, particularly with limited visual tokens. In this work, we introduce Chat-UniVi, a unified vision-language model capable of comprehending and engaging in conversations involving images and videos through a unified visual representation. Specifically, we employ a set of dynamic visual tokens to uniformly represent images and videos. This representation framework empowers the model to efficiently utilize a limited number of visual tokens to simultaneously capture the spatial details necessary for images and the comprehensive temporal relationship required for videos. Moreover, we leverage a multi-scale representation, enabling the model to perceive both high-level semantic concepts and low-level visual details. Notably, Chat-UniVi is trained on a mixed dataset containing both images and videos, allowing direct application to tasks involving both mediums without requiring any modifications. Extensive experimental results demonstrate that Chat-UniVi, as a unified model, consistently outperforms even existing methods exclusively designed for either images or videos. ",
    "url": "https://arxiv.org/abs/2311.08046",
    "authors": [
      "Peng Jin",
      "Ryuichi Takanobu",
      "Caiwan Zhang",
      "Xiaochun Cao",
      "Li Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.08057",
    "title": "Data and models for stance and premise detection in COVID-19 tweets:  insights from the Social Media Mining for Health (SMM4H) 2022 shared task",
    "abstract": "The COVID-19 pandemic has sparked numerous discussions on social media platforms, with users sharing their views on topics such as mask-wearing and vaccination. To facilitate the evaluation of neural models for stance detection and premise classification, we organized the Social Media Mining for Health (SMM4H) 2022 Shared Task 2. This competition utilized manually annotated posts on three COVID-19-related topics: school closures, stay-at-home orders, and wearing masks. In this paper, we extend the previous work and present newly collected data on vaccination from Twitter to assess the performance of models on a different topic. To enhance the accuracy and effectiveness of our evaluation, we employed various strategies to aggregate tweet texts with claims, including models with feature-level (early) fusion and dual-view architectures from SMM4H 2022 leaderboard. Our primary objective was to create a valuable dataset and perform an extensive experimental evaluation to support future research in argument mining in the health domain. ",
    "url": "https://arxiv.org/abs/2311.08057",
    "authors": [
      "Vera Davydova",
      "Huabin Yang",
      "Elena Tutubalina"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.08066",
    "title": "How to get better embeddings with code pre-trained models? An empirical  study",
    "abstract": "Pre-trained language models have demonstrated powerful capabilities in the field of natural language processing (NLP). Recently, code pre-trained model (PTM), which draw from the experiences of the NLP field, have also achieved state-of-the-art results in many software engineering (SE) downstream tasks. These code PTMs take into account the differences between programming languages and natural languages during pre-training and make adjustments to pre-training tasks and input data. However, researchers in the SE community still inherit habits from the NLP field when using these code PTMs to generate embeddings for SE downstream classification tasks, such as generating semantic embeddings for code snippets through special tokens and inputting code and text information in the same way as pre-training the PTMs. In this paper, we empirically study five different PTMs (i.e. CodeBERT, CodeT5, PLBART, CodeGPT and CodeGen) with three different architectures (i.e. encoder-only, decoder-only and encoder-decoder) on four SE downstream classification tasks (i.e. code vulnerability detection, code clone detection, just-in-time defect prediction and function docstring mismatch detection) with respect to the two aforementioned aspects. Our experimental results indicate that (1) regardless of the architecture of the code PTMs used, embeddings obtained through special tokens do not sufficiently aggregate the semantic information of the entire code snippet; (2) the quality of code embeddings obtained by combing code data and text data in the same way as pre-training the PTMs is poor and cannot guarantee richer semantic information; (3) using the method that aggregates the vector representations of all code tokens, the decoder-only PTMs can obtain code embeddings with semantics as rich as or even better quality than those obtained from the encoder-only and encoder-decoder PTMs. ",
    "url": "https://arxiv.org/abs/2311.08066",
    "authors": [
      "Yu Zhao",
      "Lina Gong",
      "Haoxiang Zhang",
      "Yaoshen Yu",
      "Zhiqiu Huang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2311.08083",
    "title": "Solving ARC visual analogies with neural embeddings and vector  arithmetic: A generalized method",
    "abstract": "Analogical reasoning derives information from known relations and generalizes this information to similar yet unfamiliar situations. One of the first generalized ways in which deep learning models were able to solve verbal analogies was through vector arithmetic of word embeddings, essentially relating words that were mapped to a vector space (e.g., king - man + woman = __?). In comparison, most attempts to solve visual analogies are still predominantly task-specific and less generalizable. This project focuses on visual analogical reasoning and applies the initial generalized mechanism used to solve verbal analogies to the visual realm. Taking the Abstraction and Reasoning Corpus (ARC) as an example to investigate visual analogy solving, we use a variational autoencoder (VAE) to transform ARC items into low-dimensional latent vectors, analogous to the word embeddings used in the verbal approaches. Through simple vector arithmetic, underlying rules of ARC items are discovered and used to solve them. Results indicate that the approach works well on simple items with fewer dimensions (i.e., few colors used, uniform shapes), similar input-to-output examples, and high reconstruction accuracy on the VAE. Predictions on more complex items showed stronger deviations from expected outputs, although, predictions still often approximated parts of the item's rule set. Error patterns indicated that the model works as intended. On the official ARC paradigm, the model achieved a score of 2% (cf. current world record is 21%) and on ConceptARC it scored 8.8%. Although the methodology proposed involves basic dimensionality reduction techniques and standard vector arithmetic, this approach demonstrates promising outcomes on ARC and can easily be generalized to other abstract visual reasoning tasks. ",
    "url": "https://arxiv.org/abs/2311.08083",
    "authors": [
      "Luca H. Thoms",
      "Karel A. Veldkamp",
      "Hannes Rosenbusch",
      "Claire E. Stevenson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.08086",
    "title": "CPSOR-GCN: A Vehicle Trajectory Prediction Method Powered by Emotion and  Cognitive Theory",
    "abstract": "Active safety systems on vehicles often face problems with false alarms. Most active safety systems predict the driver's trajectory with the assumption that the driver is always in a normal emotion, and then infer risks. However, the driver's trajectory uncertainty increases under abnormal emotions. This paper proposes a new trajectory prediction model: CPSOR-GCN, which predicts vehicle trajectories under abnormal emotions. At the physical level, the interaction features between vehicles are extracted by the physical GCN module. At the cognitive level, SOR cognitive theory is used as prior knowledge to build a Dynamic Bayesian Network (DBN) structure. The conditional probability and state transition probability of nodes from the calibrated SOR-DBN quantify the causal relationship between cognitive factors, which is embedded into the cognitive GCN module to extract the characteristics of the influence mechanism of emotions on driving behavior. The CARLA-SUMO joint driving simulation platform was built to develop dangerous pre-crash scenarios. Methods of recreating traffic scenes were used to naturally induce abnormal emotions. The experiment collected data from 26 participants to verify the proposed model. Compared with the model that only considers physical motion features, the prediction accuracy of the proposed model is increased by 68.70%. Furthermore,considering the SOR-DBN reduces the prediction error of the trajectory by 15.93%. Compared with other advanced trajectory prediction models, the results of CPSOR-GCN also have lower errors. This model can be integrated into active safety systems to better adapt to the driver's emotions, which could effectively reduce false alarms. ",
    "url": "https://arxiv.org/abs/2311.08086",
    "authors": [
      "L. Tang",
      "Y. Li",
      "J. Yuan",
      "A. Fu",
      "J. Sun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.08094",
    "title": "Act-VIT: A Representationally Robust Attention Architecture for Skeleton  Based Action Recognition Using Vision Transformer",
    "abstract": "Skeleton-based action recognition receives the attention of many researchers as it is robust to viewpoint and illumination changes, and its processing is much more efficient than video frames. With the emergence of deep learning models, it has become very popular to represent the skeleton data in pseudo-image form and apply Convolutional Neural Networks for action recognition. Thereafter, studies concentrated on finding effective methods for forming pseudo-images. Recently, attention networks, more specifically transformers have provided promising results in various vision problems. In this study, the effectiveness of vision transformers for skeleton-based action recognition is examined and its robustness on the pseudo-image representation scheme is investigated. To this end, a three-level architecture, Act-VIT is proposed, which forms a set of pseudo images apply a classifier on each of the representation and combine their results to find the final action class. The classifiers of Act-VIT are first realized by CNNs and then by VITs and their performances are compared. Experimental studies reveal that the vision transformer is less sensitive to the initial pseudo-image representation compared to CNN. Nevertheless, even with the vision transformer, the recognition performance can be further improved by consensus of classifiers. ",
    "url": "https://arxiv.org/abs/2311.08094",
    "authors": [
      "Ozge Oztimur Karadag"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.08103",
    "title": "Exploring Semi-supervised Hierarchical Stacked Encoder for Legal  Judgement Prediction",
    "abstract": "Predicting the judgment of a legal case from its unannotated case facts is a challenging task. The lengthy and non-uniform document structure poses an even greater challenge in extracting information for decision prediction. In this work, we explore and propose a two-level classification mechanism; both supervised and unsupervised; by using domain-specific pre-trained BERT to extract information from long documents in terms of sentence embeddings further processing with transformer encoder layer and use unsupervised clustering to extract hidden labels from these embeddings to better predict a judgment of a legal case. We conduct several experiments with this mechanism and see higher performance gains than the previously proposed methods on the ILDC dataset. Our experimental results also show the importance of domain-specific pre-training of Transformer Encoders in legal information processing. ",
    "url": "https://arxiv.org/abs/2311.08103",
    "authors": [
      "Nishchal Prasad",
      "Mohand Boughanem",
      "Taoufiq Dkaki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2311.08107",
    "title": "SAIE Framework: Support Alone Isn't Enough -- Advancing LLM Training  with Adversarial Remarks",
    "abstract": "Large Language Models (LLMs) can justify or criticize their predictions through discussion with other models or humans, thereby enhancing their intrinsic understanding of instances. While proactive discussions enhance performance, this approach is currently limited to the inference phase. In this context, we posit a hypothesis: learning interactive discussions during training can improve understanding for the instances in the training step and proficiency in logical/critical thinking ability and verbalized expression of the model in the inference step. Our proposed SAIE training method involves both supportive and adversarial discussions between the learner and partner models. The learner model receives a remark from the partner through the discussion, and the parameters of the learner model are then updated based on this remark. That is, the teacher signal dynamically adjusts in response to the evolving model output throughout the training step. By bolstering the capacity for discussion and comprehension of instances, our experiments across datasets, including GSM8K, CommonsenseQA, and MMLU, reveal that models fine-tuned with our method consistently surpass those trained with standard fine-tuning techniques. Moreover, our approach demonstrates superior performance in multi-agent inference scenarios, boosting the models' reasoning abilities at the inference step. ",
    "url": "https://arxiv.org/abs/2311.08107",
    "authors": [
      "Mengsay Loem",
      "Masahiro Kaneko",
      "Naoaki Okazaki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.08110",
    "title": "Improving hateful memes detection via learning hatefulness-aware  embedding space through retrieval-guided contrastive learning",
    "abstract": "Hateful memes have emerged as a significant concern on the Internet. These memes, which are a combination of image and text, often convey messages vastly different from their individual meanings. Thus, detecting hateful memes requires the system to jointly understand the visual and textual modalities. However, our investigation reveals that the embedding space of existing CLIP-based systems lacks sensitivity to subtle differences in memes that are vital for correct hatefulness classification. To address this issue, we propose constructing a hatefulness-aware embedding space through retrieval-guided contrastive training. Specifically, we add an auxiliary loss that utilizes hard negative and pseudo-gold samples to train the embedding space. Our approach achieves state-of-the-art performance on the HatefulMemes dataset with an AUROC of 86.7. Notably, our approach outperforms much larger fine-tuned Large Multimodal Models like Flamingo and LLaVA. Finally, we demonstrate a retrieval-based hateful memes detection system, which is capable of making hatefulness classification based on data unseen in training from a database. This allows developers to update the hateful memes detection system by simply adding new data without retraining, a desirable feature for real services in the constantly-evolving landscape of hateful memes on the Internet. ",
    "url": "https://arxiv.org/abs/2311.08110",
    "authors": [
      "Jingbiao Mei",
      "Jinghong Chen",
      "Weizhe Lin",
      "Bill Byrne",
      "Marcus Tomalin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.08118",
    "title": "Evaluating Neighbor Explainability for Graph Neural Networks",
    "abstract": "Explainability in Graph Neural Networks (GNNs) is a new field growing in the last few years. In this publication we address the problem of determining how important is each neighbor for the GNN when classifying a node and how to measure the performance for this specific task. To do this, various known explainability methods are reformulated to get the neighbor importance and four new metrics are presented. Our results show that there is almost no difference between the explanations provided by gradient-based techniques in the GNN domain. In addition, many explainability techniques failed to identify important neighbors when GNNs without self-loops are used. ",
    "url": "https://arxiv.org/abs/2311.08118",
    "authors": [
      "Oscar Llorente",
      "P\u00e9ter Vaderna",
      "S\u00e1ndor Laki",
      "Roland Kotrocz\u00f3",
      "Rita Csoma",
      "J\u00e1nos M\u00e1rk Szalai-Gindl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.08125",
    "title": "Lite it fly: An All-Deformable-Butterfly Network",
    "abstract": "Most deep neural networks (DNNs) consist fundamentally of convolutional and/or fully connected layers, wherein the linear transform can be cast as the product between a filter matrix and a data matrix obtained by arranging feature tensors into columns. The lately proposed deformable butterfly (DeBut) decomposes the filter matrix into generalized, butterflylike factors, thus achieving network compression orthogonal to the traditional ways of pruning or low-rank decomposition. This work reveals an intimate link between DeBut and a systematic hierarchy of depthwise and pointwise convolutions, which explains the empirically good performance of DeBut layers. By developing an automated DeBut chain generator, we show for the first time the viability of homogenizing a DNN into all DeBut layers, thus achieving an extreme sparsity and compression. Various examples and hardware benchmarks verify the advantages of All-DeBut networks. In particular, we show it is possible to compress a PointNet to < 5% parameters with < 5% accuracy drop, a record not achievable by other compression schemes. ",
    "url": "https://arxiv.org/abs/2311.08125",
    "authors": [
      "Rui Lin",
      "Jason Chun Lok Li",
      "Jiajun Zhou",
      "Binxiao Huang",
      "Jie Ran",
      "Ngai Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.08141",
    "title": "GMTR: Graph Matching Transformers",
    "abstract": "Vision transformers (ViTs) have recently been used for visual matching beyond object detection and segmentation. However, the original grid dividing strategy of ViTs neglects the spatial information of the keypoints, limiting the sensitivity to local information. Therefore, we propose \\textbf{QueryTrans} (Query Transformer), which adopts a cross-attention module and keypoints-based center crop strategy for better spatial information extraction. We further integrate the graph attention module and devise a transformer-based graph matching approach \\textbf{GMTR} (Graph Matching TRansformers) whereby the combinatorial nature of GM is addressed by a graph transformer neural GM solver. On standard GM benchmarks, GMTR shows competitive performance against the SOTA frameworks. Specifically, on Pascal VOC, GMTR achieves $\\mathbf{83.6\\%}$ accuracy, $\\mathbf{0.9\\%}$ higher than the SOTA framework. On Spair-71k, GMTR shows great potential and outperforms most of the previous works. Meanwhile, on Pascal VOC, QueryTrans improves the accuracy of NGMv2 from $80.1\\%$ to $\\mathbf{83.3\\%}$, and BBGM from $79.0\\%$ to $\\mathbf{84.5\\%}$. On Spair-71k, QueryTrans improves NGMv2 from $80.6\\%$ to $\\mathbf{82.5\\%}$, and BBGM from $82.1\\%$ to $\\mathbf{83.9\\%}$. Source code will be made publicly available. ",
    "url": "https://arxiv.org/abs/2311.08141",
    "authors": [
      "Jinpei Guo",
      "Shaofeng Zhang",
      "Runzhong Wang",
      "Chang Liu",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.08147",
    "title": "RECALL: A Benchmark for LLMs Robustness against External Counterfactual  Knowledge",
    "abstract": "LLMs and AI chatbots have improved people's efficiency in various fields. However, the necessary knowledge for answering the question may be beyond the models' knowledge boundaries. To mitigate this issue, many researchers try to introduce external knowledge, such as knowledge graphs and Internet contents, into LLMs for up-to-date information. However, the external information from the Internet may include counterfactual information that will confuse the model and lead to an incorrect response. Thus there is a pressing need for LLMs to possess the ability to distinguish reliable information from external knowledge. Therefore, to evaluate the ability of LLMs to discern the reliability of external knowledge, we create a benchmark from existing knowledge bases. Our benchmark consists of two tasks, Question Answering and Text Generation, and for each task, we provide models with a context containing counterfactual information. Evaluation results show that existing LLMs are susceptible to interference from unreliable external knowledge with counterfactual information, and simple intervention methods make limited contributions to the alleviation of this issue. ",
    "url": "https://arxiv.org/abs/2311.08147",
    "authors": [
      "Yi Liu",
      "Lianzhe Huang",
      "Shicheng Li",
      "Sishuo Chen",
      "Hao Zhou",
      "Fandong Meng",
      "Jie Zhou",
      "Xu Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.08149",
    "title": "Modeling Complex Disease Trajectories using Deep Generative Models with  Semi-Supervised Latent Processes",
    "abstract": "In this paper, we propose a deep generative time series approach using latent temporal processes for modeling and holistically analyzing complex disease trajectories. We aim to find meaningful temporal latent representations of an underlying generative process that explain the observed disease trajectories in an interpretable and comprehensive way. To enhance the interpretability of these latent temporal processes, we develop a semi-supervised approach for disentangling the latent space using established medical concepts. By combining the generative approach with medical knowledge, we leverage the ability to discover novel aspects of the disease while integrating medical concepts into the model. We show that the learned temporal latent processes can be utilized for further data analysis and clinical hypothesis testing, including finding similar patients and clustering the disease into new sub-types. Moreover, our method enables personalized online monitoring and prediction of multivariate time series including uncertainty quantification. We demonstrate the effectiveness of our approach in modeling systemic sclerosis, showcasing the potential of our machine learning model to capture complex disease trajectories and acquire new medical knowledge. ",
    "url": "https://arxiv.org/abs/2311.08149",
    "authors": [
      "C\u00e9cile Trottet",
      "Manuel Sch\u00fcrch",
      "Ahmed Allam",
      "Imon Barua",
      "Liubov Petelytska",
      "Oliver Distler",
      "Anna-Maria Hoffmann-Vold",
      "Michael Krauthammer",
      "EUSTAR collaborators"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.08153",
    "title": "When Mining Electric Locomotives Meet Reinforcement Learning",
    "abstract": "As the most important auxiliary transportation equipment in coal mines, mining electric locomotives are mostly operated manually at present. However, due to the complex and ever-changing coal mine environment, electric locomotive safety accidents occur frequently these years. A mining electric locomotive control method that can adapt to different complex mining environments is needed. Reinforcement Learning (RL) is concerned with how artificial agents ought to take actions in an environment so as to maximize reward, which can help achieve automatic control of mining electric locomotive. In this paper, we present how to apply RL to the autonomous control of mining electric locomotives. To achieve more precise control, we further propose an improved epsilon-greedy (IEG) algorithm which can better balance the exploration and exploitation. To verify the effectiveness of this method, a co-simulation platform for autonomous control of mining electric locomotives is built which can complete closed-loop simulation of the vehicles. The simulation results show that this method ensures the locomotives following the front vehicle safely and responding promptly in the event of sudden obstacles on the road when the vehicle in complex and uncertain coal mine environments. ",
    "url": "https://arxiv.org/abs/2311.08153",
    "authors": [
      "Ying Li",
      "Zhencai Zhu",
      "Xiaoqiang Li",
      "Chunyu Yang",
      "Hao Lu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.08157",
    "title": "TransformCode: A Contrastive Learning Framework for Code Embedding via  Subtree transformation",
    "abstract": "Large-scale language models have made great progress in the field of software engineering in recent years. They can be used for many code-related tasks such as code clone detection, code-to-code search, and method name prediction. However, these large-scale language models based on each code token have several drawbacks: They are usually large in scale, heavily dependent on labels, and require a lot of computing power and time to fine-tune new datasets.Furthermore, code embedding should be performed on the entire code snippet rather than encoding each code token. The main reason for this is that encoding each code token would cause model parameter inflation, resulting in a lot of parameters storing information that we are not very concerned about. In this paper, we propose a novel framework, called TransformCode, that learns about code embeddings in a contrastive learning manner. The framework uses the Transformer encoder as an integral part of the model. We also introduce a novel data augmentation technique called abstract syntax tree transformation: This technique applies syntactic and semantic transformations to the original code snippets to generate more diverse and robust anchor samples. Our proposed framework is both flexible and adaptable: It can be easily extended to other downstream tasks that require code representation such as code clone detection and classification. The framework is also very efficient and scalable: It does not require a large model or a large amount of training data, and can support any programming language.Finally, our framework is not limited to unsupervised learning, but can also be applied to some supervised learning tasks by incorporating task-specific labels or objectives. To explore the effectiveness of our framework, we conducted extensive experiments on different software engineering tasks using different programming languages and multiple datasets. ",
    "url": "https://arxiv.org/abs/2311.08157",
    "authors": [
      "Zixiang Xian",
      "Rubing Huang",
      "Dave Towey",
      "Chunrong Fang",
      "Zhenyu Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.08159",
    "title": "DynamicSurf: Dynamic Neural RGB-D Surface Reconstruction with an  Optimizable Feature Grid",
    "abstract": "We propose DynamicSurf, a model-free neural implicit surface reconstruction method for high-fidelity 3D modelling of non-rigid surfaces from monocular RGB-D video. To cope with the lack of multi-view cues in monocular sequences of deforming surfaces, one of the most challenging settings for 3D reconstruction, DynamicSurf exploits depth, surface normals, and RGB losses to improve reconstruction fidelity and optimisation time. DynamicSurf learns a neural deformation field that maps a canonical representation of the surface geometry to the current frame. We depart from current neural non-rigid surface reconstruction models by designing the canonical representation as a learned feature grid which leads to faster and more accurate surface reconstruction than competing approaches that use a single MLP. We demonstrate DynamicSurf on public datasets and show that it can optimize sequences of varying frames with $6\\times$ speedup over pure MLP-based approaches while achieving comparable results to the state-of-the-art methods. Project is available at https://mirgahney.github.io//DynamicSurf.io/. ",
    "url": "https://arxiv.org/abs/2311.08159",
    "authors": [
      "Mirgahney Mohamed",
      "Lourdes Agapito"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.08167",
    "title": "SeDe: Balancing Blockchain Privacy and Regulatory Compliance by  Selective De-Anonymization",
    "abstract": "Privacy is one of the essential pillars for the widespread adoption of blockchains, but public blockchains are transparent by nature. Modern analytics techniques can easily subdue the pseudonymity feature of a blockchain user. Some applications have been able to provide practical privacy protections using privacy-preserving cryptography techniques. However, malicious actors have abused them illicitly, discouraging honest actors from using privacy-preserving applications as \"mixing\" user interactions and funds with anonymous bad actors, causing compliance and regulatory concerns. In this paper, we propose a framework that balances privacy-preserving features by establishing a regulatory and compliant framework called Selective De-Anonymization (SeDe). The adoption of this framework allows privacy-preserving applications on blockchains to de-anonymize illicit transactions by recursive traversal of subgraphs of linked transactions. Our technique achieves this without leaving de-anonymization decisions or control in the hands of a single entity but distributing it among multiple entities while holding them accountable for their respective actions. To instantiate, our framework uses threshold encryption schemes and Zero-Knowledge Proofs (ZKPs). ",
    "url": "https://arxiv.org/abs/2311.08167",
    "authors": [
      "Naveen Sahu",
      "Mitul Gajera",
      "Amit Chaudhary",
      "Hamish Ivey-Law"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.08170",
    "title": "Neural Lattice Reduction: A Self-Supervised Geometric Deep Learning  Approach",
    "abstract": "Lattice reduction is a combinatorial optimization problem aimed at finding the most orthogonal basis in a given lattice. In this work, we address lattice reduction via deep learning methods. We design a deep neural model outputting factorized unimodular matrices and train it in a self-supervised manner by penalizing non-orthogonal lattice bases. We incorporate the symmetries of lattice reduction into the model by making it invariant and equivariant with respect to appropriate continuous and discrete groups. ",
    "url": "https://arxiv.org/abs/2311.08170",
    "authors": [
      "Giovanni Luca Marchetti",
      "Gabriele Cesa",
      "Kumar Pratik",
      "Arash Behboodi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2311.08207",
    "title": "Online Data-driven Control Against False Data Injection Attacks",
    "abstract": "The rise of cyber-security concerns has brought significant attention to the analysis and design of cyber-physical systems (CPSs). Among the various types of cyberattacks, denial-of-service (DoS) attacks and false data injection (FDI) attacks can be easily launched and have become prominent threats. While resilient control against DoS attacks has received substantial research efforts, countermeasures developed against FDI attacks have been relatively limited, particularly when explicit system models are not available. To address this gap, the present paper focuses on the design of data-driven controllers for unknown linear systems subject to FDI attacks on the actuators, utilizing input-state data. To this end, a general FDI attack model is presented, which imposes minimally constraints on the switching frequency of attack channels and the magnitude of attack matrices. A dynamic state feedback control law is designed based on offline and online input-state data, which adapts to the channel switching of FDI attacks. This is achieved by solving two data-based semi-definite programs (SDPs) on-the-fly to yield a tight approximation of the set of subsystems consistent with both offline clean data and online attack-corrupted data. It is shown that under mild conditions on the attack, the proposed SDPs are recursively feasible and controller achieves exponential stability. Numerical examples showcase its effectiveness in mitigating the impact of FDI attacks. ",
    "url": "https://arxiv.org/abs/2311.08207",
    "authors": [
      "Wenjie Liu",
      "Lidong Li",
      "Jian Sun",
      "Fang Deng",
      "Gang Wang",
      "Jie Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.08227",
    "title": "Prediction of inter packet arrival times for enhanced NR-V2X sidelink  scheduling",
    "abstract": "A significant limitation of the LTE-V2X and NR-V2X sidelink scheduling mechanisms is their difficulty coping with variations in inter packet arrival times, also known as aperiodic packets. This conflicts with the fundamental characteristics of most V2X services which are triggered based on an event. e.g. ETSI Cooperative Awareness Messages (CAMs) - vehicle kinematics, Cooperative Perception Messages (CPMs) - object sensing and Decentralised Event Notification Messages (DENMs) - event occurrences. Furthermore, network management techniques such as congestion control mechanisms can result in varied inter packet arrival times. To combat this, NR-V2X introduced a dynamic grant mechanism, which we show is ineffective unless there is background periodic traffic to stabilise the sensing history upon which the scheduler makes it decisions. The characteristics of V2X services make it implausible that such periodic application traffic will exist. To overcome this significant drawback, we demonstrate that the standardised scheduling algorithms can be made effective if the event triggered arrival rate of packets can be accurately predicted. These predictions can be used to tune the Resource Reservation Interval (RRI) parameter of the MAC scheduler to negate the negative impact of aperiodicity. Such an approach allows the scheduler to achieve comparable performance to a scenario where packets arrive periodically. To demonstrate the effectiveness of our approach, an ML model has been devised for the prediction of cooperative awareness messages, but the same principle can be abstracted to other V2X service types. ",
    "url": "https://arxiv.org/abs/2311.08227",
    "authors": [
      "Brian McCarthy",
      "Aisling O'Driscoll"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2311.08255",
    "title": "Neural Dynamics of Delayed Feedback in Robot Teleoperation: Insights  from fNIRS Analysis",
    "abstract": "As robot teleoperation increasingly becomes integral in executing tasks in distant, hazardous, or inaccessible environments, the challenge of operational delays remains a significant obstacle. These delays are inherent in signal transmission and processing and can adversely affect the operators performance, particularly in tasks requiring precision and timeliness. While current research has made strides in mitigating these delays through advanced control strategies and training methods, a crucial gap persists in understanding the neurofunctional impacts of these delays and the efficacy of countermeasures from a cognitive perspective. Our study narrows this gap by leveraging functional Near-Infrared Spectroscopy (fNIRS) to examine the neurofunctional implications of simulated haptic feedback on cognitive activity and motor coordination under delayed conditions. In a human-subject experiment (N=41), we manipulated sensory feedback to observe its influences on various brain regions of interest (ROIs) response during teleoperation tasks. The fNIRS data provided a detailed assessment of cerebral activity, particularly in ROIs implicated in time perception and the execution of precise movements. Our results reveal that certain conditions, which provided immediate simulated haptic feedback, significantly optimized neural functions related to time perception and motor coordination, and improved motor performance. These findings provide empirical evidence about the neurofunctional basis of the enhanced motor performance with simulated synthetic force feedback in the presence of teleoperation delays. ",
    "url": "https://arxiv.org/abs/2311.08255",
    "authors": [
      "Tianyu Zhou",
      "Yang Ye",
      "Qi Zhu",
      "William Vann",
      "Jing Du"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2311.08265",
    "title": "On The Relationship Between Universal Adversarial Attacks And Sparse  Representations",
    "abstract": "The prominent success of neural networks, mainly in computer vision tasks, is increasingly shadowed by their sensitivity to small, barely perceivable adversarial perturbations in image input. In this work, we aim at explaining this vulnerability through the framework of sparsity. We show the connection between adversarial attacks and sparse representations, with a focus on explaining the universality and transferability of adversarial examples in neural networks. To this end, we show that sparse coding algorithms, and the neural network-based learned iterative shrinkage thresholding algorithm (LISTA) among them, suffer from this sensitivity, and that common attacks on neural networks can be expressed as attacks on the sparse representation of the input image. The phenomenon that we observe holds true also when the network is agnostic to the sparse representation and dictionary, and thus can provide a possible explanation for the universality and transferability of adversarial attacks. The code is available at https://github.com/danawr/adversarial_attacks_and_sparse_representations. ",
    "url": "https://arxiv.org/abs/2311.08265",
    "authors": [
      "Dana Weitzner",
      "Raja Giryes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.08271",
    "title": "Mobility-Induced Graph Learning for WiFi Positioning",
    "abstract": "A smartphone-based user mobility tracking could be effective in finding his/her location, while the unpredictable error therein due to low specification of built-in inertial measurement units (IMUs) rejects its standalone usage but demands the integration to another positioning technique like WiFi positioning. This paper aims to propose a novel integration technique using a graph neural network called Mobility-INduced Graph LEarning (MINGLE), which is designed based on two types of graphs made by capturing different user mobility features. Specifically, considering sequential measurement points (MPs) as nodes, a user's regular mobility pattern allows us to connect neighbor MPs as edges, called time-driven mobility graph (TMG). Second, a user's relatively straight transition at a constant pace when moving from one position to another can be captured by connecting the nodes on each path, called a direction-driven mobility graph (DMG). Then, we can design graph convolution network (GCN)-based cross-graph learning, where two different GCN models for TMG and DMG are jointly trained by feeding different input features created by WiFi RTTs yet sharing their weights. Besides, the loss function includes a mobility regularization term such that the differences between adjacent location estimates should be less variant due to the user's stable moving pace. Noting that the regularization term does not require ground-truth location, MINGLE can be designed under semi- and self-supervised learning frameworks. The proposed MINGLE's effectiveness is extensively verified through field experiments, showing a better positioning accuracy than benchmarks, say root mean square errors (RMSEs) being 1.398 (m) and 1.073 (m) for self- and semi-supervised learning cases, respectively. ",
    "url": "https://arxiv.org/abs/2311.08271",
    "authors": [
      "Kyuwon Han",
      "Seung Min Yu",
      "Seong-Lyun Kim",
      "Seung-Woo Ko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.08272",
    "title": "Mixed Attention Network for Cross-domain Sequential Recommendation",
    "abstract": "In modern recommender systems, sequential recommendation leverages chronological user behaviors to make effective next-item suggestions, which suffers from data sparsity issues, especially for new users. One promising line of work is the cross-domain recommendation, which trains models with data across multiple domains to improve the performance in data-scarce domains. Recent proposed cross-domain sequential recommendation models such as PiNet and DASL have a common drawback relying heavily on overlapped users in different domains, which limits their usage in practical recommender systems. In this paper, we propose a Mixed Attention Network (MAN) with local and global attention modules to extract the domain-specific and cross-domain information. Firstly, we propose a local/global encoding layer to capture the domain-specific/cross-domain sequential pattern. Then we propose a mixed attention layer with item similarity attention, sequence-fusion attention, and group-prototype attention to capture the local/global item similarity, fuse the local/global item sequence, and extract the user groups across different domains, respectively. Finally, we propose a local/global prediction layer to further evolve and combine the domain-specific and cross-domain interests. Experimental results on two real-world datasets (each with two domains) demonstrate the superiority of our proposed model. Further study also illustrates that our proposed method and components are model-agnostic and effective, respectively. The code and data are available at https://github.com/Guanyu-Lin/MAN. ",
    "url": "https://arxiv.org/abs/2311.08272",
    "authors": [
      "Guanyu Lin",
      "Chen Gao",
      "Yu Zheng",
      "Jianxin Chang",
      "Yanan Niu",
      "Yang Song",
      "Kun Gai",
      "Zhiheng Li",
      "Depeng Jin",
      "Yong Li",
      "Meng Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.08314",
    "title": "Convolutional Neural Networks Exploiting Attributes of Biological  Neurons",
    "abstract": "In this era of artificial intelligence, deep neural networks like Convolutional Neural Networks (CNNs) have emerged as front-runners, often surpassing human capabilities. These deep networks are often perceived as the panacea for all challenges. Unfortunately, a common downside of these networks is their ''black-box'' character, which does not necessarily mirror the operation of biological neural systems. Some even have millions/billions of learnable (tunable) parameters, and their training demands extensive data and time. Here, we integrate the principles of biological neurons in certain layer(s) of CNNs. Specifically, we explore the use of neuro-science-inspired computational models of the Lateral Geniculate Nucleus (LGN) and simple cells of the primary visual cortex. By leveraging such models, we aim to extract image features to use as input to CNNs, hoping to enhance training efficiency and achieve better accuracy. We aspire to enable shallow networks with a Push-Pull Combination of Receptive Fields (PP-CORF) model of simple cells as the foundation layer of CNNs to enhance their learning process and performance. To achieve this, we propose a two-tower CNN, one shallow tower and the other as ResNet 18. Rather than extracting the features blindly, it seeks to mimic how the brain perceives and extracts features. The proposed system exhibits a noticeable improvement in the performance (on an average of $5\\%-10\\%$) on CIFAR-10, CIFAR-100, and ImageNet-100 datasets compared to ResNet-18. We also check the efficiency of only the Push-Pull tower of the network. ",
    "url": "https://arxiv.org/abs/2311.08314",
    "authors": [
      "Neeraj Kumar Singh",
      "Nikhil R. Pal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.08325",
    "title": "Protecting the Future of Information: LOCO Coding With Error Detection  for DNA Data Storage",
    "abstract": "DNA strands serve as a storage medium for $4$-ary data over the alphabet $\\{A,T,G,C\\}$. DNA data storage promises formidable information density, long-term durability, and ease of replicability. However, information in this intriguing storage technology might be corrupted. Experiments have revealed that DNA sequences with long homopolymers and/or with low $GC$-content are notably more subject to errors upon storage. This paper investigates the utilization of the recently-introduced method for designing lexicographically-ordered constrained (LOCO) codes in DNA data storage. This paper introduces DNA LOCO (D-LOCO) codes, over the alphabet $\\{A,T,G,C\\}$ with limited runs of identical symbols. These codes come with an encoding-decoding rule we derive, which provides affordable encoding-decoding algorithms. In terms of storage overhead, the proposed encoding-decoding algorithms outperform those in the existing literature. Our algorithms are readily reconfigurable. D-LOCO codes are intrinsically balanced, which allows us to achieve balancing over the entire DNA strand with minimal rate penalty. Moreover, we propose four schemes to bridge consecutive codewords, three of which guarantee single substitution error detection per codeword. We examine the probability of undetecting errors. We also show that D-LOCO codes are capacity-achieving and that they offer remarkably high rates at moderate lengths. ",
    "url": "https://arxiv.org/abs/2311.08325",
    "authors": [
      "Canberk \u0130rima\u011fz\u0131",
      "Yusuf Uslan",
      "Ahmed Hareedy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.08349",
    "title": "Artificial Text Boundary Detection with Topological Data Analysis and  Sliding Window Techniques",
    "abstract": "Due to the rapid development of text generation models, people increasingly often encounter texts that may start out as written by a human but then continue as machine-generated results of large language models. Detecting the boundary between human-written and machine-generated parts of such texts is a very challenging problem that has not received much attention in literature. In this work, we consider and compare a number of different approaches for this artificial text boundary detection problem, comparing several predictors over features of different nature. We show that supervised fine-tuning of the RoBERTa model works well for this task in general but fails to generalize in important cross-domain and cross-generator settings, demonstrating a tendency to overfit to spurious properties of the data. Then, we propose novel approaches based on features extracted from a frozen language model's embeddings that are able to outperform both the human accuracy level and previously considered baselines on the Real or Fake Text benchmark. Moreover, we adapt perplexity-based approaches for the boundary detection task and analyze their behaviour. We analyze the robustness of all proposed classifiers in cross-domain and cross-model settings, discovering important properties of the data that can negatively influence the performance of artificial text boundary detection algorithms. ",
    "url": "https://arxiv.org/abs/2311.08349",
    "authors": [
      "Laida Kushnareva",
      "Tatiana Gaintseva",
      "German Magai",
      "Serguei Barannikov",
      "Dmitry Abulkhanov",
      "Kristian Kuznetsov",
      "Irina Piontkovskaya",
      "Sergey Nikolenko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.08357",
    "title": "Sparsity-Preserving Differentially Private Training of Large Embedding  Models",
    "abstract": "As the use of large embedding models in recommendation systems and language applications increases, concerns over user data privacy have also risen. DP-SGD, a training algorithm that combines differential privacy with stochastic gradient descent, has been the workhorse in protecting user privacy without compromising model accuracy by much. However, applying DP-SGD naively to embedding models can destroy gradient sparsity, leading to reduced training efficiency. To address this issue, we present two new algorithms, DP-FEST and DP-AdaFEST, that preserve gradient sparsity during private training of large embedding models. Our algorithms achieve substantial reductions ($10^6 \\times$) in gradient size, while maintaining comparable levels of accuracy, on benchmark real-world datasets. ",
    "url": "https://arxiv.org/abs/2311.08357",
    "authors": [
      "Badih Ghazi",
      "Yangsibo Huang",
      "Pritish Kamath",
      "Ravi Kumar",
      "Pasin Manurangsi",
      "Amer Sinha",
      "Chiyuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.08359",
    "title": "Rotation-Agnostic Image Representation Learning for Digital Pathology",
    "abstract": "This paper addresses complex challenges in histopathological image analysis through three key contributions. Firstly, it introduces a fast patch selection method, FPS, for whole-slide image (WSI) analysis, significantly reducing computational cost while maintaining accuracy. Secondly, it presents PathDino, a lightweight histopathology feature extractor with a minimal configuration of five Transformer blocks and only 9 million parameters, markedly fewer than alternatives. Thirdly, it introduces a rotation-agnostic representation learning paradigm using self-supervised learning, effectively mitigating overfitting. We also show that our compact model outperforms existing state-of-the-art histopathology-specific vision transformers on 12 diverse datasets, including both internal datasets spanning four sites (breast, liver, skin, and colorectal) and seven public datasets (PANDA, CAMELYON16, BRACS, DigestPath, Kather, PanNuke, and WSSS4LUAD). Notably, even with a training dataset of 6 million histopathology patches from The Cancer Genome Atlas (TCGA), our approach demonstrates an average 8.5% improvement in patch-level majority vote performance. These contributions provide a robust framework for enhancing image analysis in digital pathology, rigorously validated through extensive evaluation. Project Page: https://rhazeslab.github.io/PathDino-Page/ ",
    "url": "https://arxiv.org/abs/2311.08359",
    "authors": [
      "Saghir Alfasly",
      "Abubakr Shafique",
      "Peyman Nejat",
      "Jibran Khan",
      "Areej Alsaafin",
      "Ghazal Alabtah",
      "H.R. Tizhoosh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.08369",
    "title": "How You Prompt Matters! Even Task-Oriented Constraints in Instructions  Affect LLM-Generated Text Detection",
    "abstract": "Against the misuse (e.g., plagiarism or spreading misinformation) of Large Language Models (LLMs), many recent works have presented LLM-generated-text detectors with promising detection performance. Spotlighting a situation where users instruct LLMs to generate texts (e.g., essay writing), there are various ways to write the instruction (e.g., what task-oriented constraint to include). In this paper, we discover that even a task-oriented constraint in instruction can cause the inconsistent performance of current detectors to the generated texts. Specifically, we focus on student essay writing as a realistic domain and manually create the task-oriented constraint for each factor on essay quality by Ke and Ng (2019). Our experiment shows that the detection performance variance of the current detector on texts generated by instruction with each task-oriented constraint is up to 20 times larger than the variance caused by generating texts multiple times and paraphrasing the instruction. Our finding calls for further research on developing robust detectors that can detect such distributional shifts caused by a task-oriented constraint in the instruction. ",
    "url": "https://arxiv.org/abs/2311.08369",
    "authors": [
      "Ryuto Koike",
      "Masahiro Kaneko",
      "Naoaki Okazaki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.08380",
    "title": "Direct Preference Optimization for Neural Machine Translation with  Minimum Bayes Risk Decoding",
    "abstract": "Minimum Bayes Risk (MBR) decoding can significantly improve translation performance of Multilingual Large Language Models (MLLMs). However, MBR decoding is computationally expensive and in this paper, we show how recently developed Reinforcement Learning (RL) technique, Direct Preference Optimization (DPO) can be used to fine-tune MLLMs so that we get the gains from MBR without the additional computation in inference. Our fine-tuned models have significantly improved performance on multiple NMT test sets compared to base MLLMs without preference optimization. Our method boosts the translation performance of MLLMs using relatively small monolingual fine-tuning sets. ",
    "url": "https://arxiv.org/abs/2311.08380",
    "authors": [
      "Guangyu Yang",
      "Jinghong Chen",
      "Weizhe Lin",
      "Bill Byrne"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.08392",
    "title": "Iterative Network Pricing for Ridesharing Platforms",
    "abstract": "Ridesharing platforms match riders and drivers, using dynamic pricing to balance supply and demand. The origin-based \"surge pricing\", however, does not take into consideration market conditions at trip destinations, leading to inefficient driver flows in space and incentivizes drivers to strategize. In this work, we introduce the Iterative Network Pricing mechanism, addressing a main challenge in the practical implementation of optimal origin-destination (OD) based prices, that the model for rider demand is hard to estimate. Assuming that the platform's surge algorithm clears the market for each origin in real-time, our mechanism updates the OD-based price adjustments week-over-week, using only information immediately observable during the same time window in the prior weeks. For stationary market conditions, we prove that our mechanism converges to an outcome that is approximately welfare-optimal. Using data from the City of Chicago, we illustrate (via simulation) the iterative updates under our mechanism for morning rush hours, demonstrating substantial welfare improvements despite significant fluctuations of market conditions from early 2019 through the end of 2020. ",
    "url": "https://arxiv.org/abs/2311.08392",
    "authors": [
      "Chenkai Yu",
      "Hongyao Ma"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2311.08393",
    "title": "MVSA-Net: Multi-View State-Action Recognition for Robust and Deployable  Trajectory Generation",
    "abstract": "The learn-from-observation (LfO) paradigm is a human-inspired mode for a robot to learn to perform a task simply by watching it being performed. LfO can facilitate robot integration on factory floors by minimizing disruption and reducing tedious programming. A key component of the LfO pipeline is a transformation of the depth camera frames to the corresponding task state and action pairs, which are then relayed to learning techniques such as imitation or inverse reinforcement learning for understanding the task parameters. While several existing computer vision models analyze videos for activity recognition, SA-Net specifically targets robotic LfO from RGB-D data. However, SA-Net and many other models analyze frame data captured from a single viewpoint. Their analysis is therefore highly sensitive to occlusions of the observed task, which are frequent in deployments. An obvious way of reducing occlusions is to simultaneously observe the task from multiple viewpoints and synchronously fuse the multiple streams in the model. Toward this, we present multi-view SA-Net, which generalizes the SA-Net model to allow the perception of multiple viewpoints of the task activity, integrate them, and better recognize the state and action in each frame. Performance evaluations on two distinct domains establish that MVSA-Net recognizes the state-action pairs under occlusion more accurately compared to single-view MVSA-Net and other baselines. Our ablation studies further evaluate its performance under different ambient conditions and establish the contribution of the architecture components. As such, MVSA-Net offers a significantly more robust and deployable state-action trajectory generation compared to previous methods. ",
    "url": "https://arxiv.org/abs/2311.08393",
    "authors": [
      "Ehsan Asali",
      "Prashant Doshi",
      "Jin Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.07636",
    "title": "Attention-based Multi-task Learning for Base Editor Outcome Prediction",
    "abstract": "Human genetic diseases often arise from point mutations, emphasizing the critical need for precise genome editing techniques. Among these, base editing stands out as it allows targeted alterations at the single nucleotide level. However, its clinical application is hindered by low editing efficiency and unintended mutations, necessitating extensive trial-and-error experimentation in the laboratory. To speed up this process, we present an attention-based two-stage machine learning model that learns to predict the likelihood of all possible editing outcomes for a given genomic target sequence. We further propose a multi-task learning schema to jointly learn multiple base editors (i.e. variants) at once. Our model's predictions consistently demonstrated a strong correlation with the actual experimental results on multiple datasets and base editor variants. These results provide further validation for the models' capacity to enhance and accelerate the process of refining base editing designs. ",
    "url": "https://arxiv.org/abs/2311.07636",
    "authors": [
      "Amina Mollaysa",
      "Ahmed Allam",
      "Michael Krauthamme"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.07787",
    "title": "Hybrid Synaptic Structure for Spiking Neural Network Realization",
    "abstract": "Neural networks and neuromorphic computing play pivotal roles in deep learning and machine vision. Due to their dissipative nature and inherent limitations, traditional semiconductor-based circuits face challenges in realizing ultra-fast and low-power neural networks. However, the spiking behavior characteristic of single flux quantum (SFQ) circuits positions them as promising candidates for spiking neural networks (SNNs). Our previous work showcased a JJ-Soma design capable of operating at tens of gigahertz while consuming only a fraction of the power compared to traditional circuits, as documented in [1]. This paper introduces a compact SFQ-based synapse design that applies positive and negative weighted inputs to the JJ-Soma. Using an RSFQ synapse empowers us to replicate the functionality of a biological neuron, a crucial step in realizing a complete SNN. The JJ-Synapse can operate at ultra-high frequencies, exhibits orders of magnitude lower power consumption than CMOS counterparts, and can be conveniently fabricated using commercial Nb processes. Furthermore, the network's flexibility enables modifications by incorporating cryo-CMOS circuits for weight value adjustments. In our endeavor, we have successfully designed, fabricated, and partially tested the JJ-Synapse within our cryocooler system. Integration with the JJ-Soma further facilitates the realization of a high-speed inference SNN. ",
    "url": "https://arxiv.org/abs/2311.07787",
    "authors": [
      "Sasan Razmkhah",
      "Mustafa Altay Karamuftuoglu",
      "Ali Bozbey"
    ],
    "subjectives": [
      "Superconductivity (cond-mat.supr-con)",
      "Hardware Architecture (cs.AR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.07956",
    "title": "Robust Learning Based Condition Diagnosis Method for Distribution  Network Switchgear",
    "abstract": "This paper introduces a robust, learning-based method for diagnosing the state of distribution network switchgear, which is crucial for maintaining the power quality for end users. Traditional diagnostic models often rely heavily on expert knowledge and lack robustness. To address this, our method incorporates an expanded feature vector that includes environmental data, temperature readings, switch position, motor operation, insulation conditions, and local discharge information. We tackle the issue of high dimensionality through feature mapping. The method introduces a decision radius to categorize unlabeled samples and updates the model parameters using a combination of supervised and unsupervised loss, along with a consistency regularization function. This approach ensures robust learning even with a limited number of labeled samples. Comparative analysis demonstrates that this method significantly outperforms existing models in both accuracy and robustness. ",
    "url": "https://arxiv.org/abs/2311.07956",
    "authors": [
      "Wenxi Zhang",
      "Zhe Li",
      "Weixi Li",
      "Weisi Ma",
      "Xinyi Chen",
      "Sizhe Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.07995",
    "title": "EPPA numbers of graphs",
    "abstract": "If $G$ is a graph, $A,B$ its induced subgraphs and $f\\colon A\\to B$ an isomorphism, we say that $f$ is a partial automorphism of $G$. In 1992, Hrushovski proved that graphs have the extension property for partial automorphisms (EPPA, also called the Hrushovski property), that is, for every finite graph $G$ there is a finite graph $H$, its EPPA-witness, such that $G$ is an induced subgraph of $H$ and every partial automorphism of $G$ extends to an automorphism of $H$. The EPPA number of a graph $G$, denoted by $\\mathop{\\mathrm{eppa}}\\nolimits(G)$, is the smallest number of vertices of an EPPA-witness for $G$, and we put $\\mathop{\\mathrm{eppa}}\\nolimits(n) = \\max\\{\\mathop{\\mathrm{eppa}}\\nolimits(G) : \\lvert G\\rvert = n\\}$. In this note we review the state of the area, improve some lower bounds (in particular, we show that $\\mathop{\\mathrm{eppa}}\\nolimits(n)\\geq \\frac{2^n}{\\sqrt{n}}$, thereby identifying the correct base of the exponential) and pose several open questions. We also briefly discuss EPPA numbers of hypergraphs and directed graphs. ",
    "url": "https://arxiv.org/abs/2311.07995",
    "authors": [
      "David Bradley-Williams",
      "Peter J. Cameron",
      "Jan Hubi\u010dka",
      "Mat\u011bj Kone\u010dn\u00fd"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2311.08059",
    "title": "FS-Net: Full Scale Network and Adaptive Threshold for Improving  Extraction of Micro-Retinal Vessel Structures",
    "abstract": "Retinal vascular segmentation, is a widely researched subject in biomedical image processing, aims to relieve ophthalmologists' workload when treating and detecting retinal disorders. However, segmenting retinal vessels has its own set of challenges, with prior techniques failing to generate adequate results when segmenting branches and microvascular structures. The neural network approaches used recently are characterized by the inability to keep local and global properties together and the failure to capture tiny end vessels make it challenging to attain the desired result. To reduce this retinal vessel segmentation problem, we propose a full-scale micro-vessel extraction mechanism based on an encoder-decoder neural network architecture, sigmoid smoothing, and an adaptive threshold method. The network consists of of residual, encoder booster, bottleneck enhancement, squeeze, and excitation building blocks. All of these blocks together help to improve the feature extraction and prediction of the segmentation map. The proposed solution has been evaluated using the DRIVE, CHASE-DB1, and STARE datasets, and competitive results are obtained when compared with previous studies. The AUC and accuracy on the DRIVE dataset are 0.9884 and 0.9702, respectively. On the CHASE-DB1 dataset, the scores are 0.9903 and 0.9755, respectively. On the STARE dataset, the scores are 0.9916 and 0.9750, respectively. The performance achieved is one step ahead of what has been done in previous studies, and this results in a higher chance of having this solution in real-life diagnostic centers that seek ophthalmologists attention. ",
    "url": "https://arxiv.org/abs/2311.08059",
    "authors": [
      "Melaku N. Getahun",
      "Oleg Y. Rogov",
      "Dmitry V. Dylov",
      "Andrey Somov",
      "Ahmed Bouridane",
      "Rifat Hamoudi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.08075",
    "title": "GlanceSeg: Real-time microaneurysm lesion segmentation with  gaze-map-guided foundation model for early detection of diabetic retinopathy",
    "abstract": "Early-stage diabetic retinopathy (DR) presents challenges in clinical diagnosis due to inconspicuous and minute microangioma lesions, resulting in limited research in this area. Additionally, the potential of emerging foundation models, such as the segment anything model (SAM), in medical scenarios remains rarely explored. In this work, we propose a human-in-the-loop, label-free early DR diagnosis framework called GlanceSeg, based on SAM. GlanceSeg enables real-time segmentation of microangioma lesions as ophthalmologists review fundus images. Our human-in-the-loop framework integrates the ophthalmologist's gaze map, allowing for rough localization of minute lesions in fundus images. Subsequently, a saliency map is generated based on the located region of interest, which provides prompt points to assist the foundation model in efficiently segmenting microangioma lesions. Finally, a domain knowledge filter refines the segmentation of minute lesions. We conducted experiments on two newly-built public datasets, i.e., IDRiD and Retinal-Lesions, and validated the feasibility and superiority of GlanceSeg through visualized illustrations and quantitative measures. Additionally, we demonstrated that GlanceSeg improves annotation efficiency for clinicians and enhances segmentation performance through fine-tuning using annotations. This study highlights the potential of GlanceSeg-based annotations for self-model optimization, leading to enduring performance advancements through continual learning. ",
    "url": "https://arxiv.org/abs/2311.08075",
    "authors": [
      "Hongyang Jiang",
      "Mengdi Gao",
      "Zirong Liu",
      "Chen Tang",
      "Xiaoqing Zhang",
      "Shuai Jiang",
      "Wu Yuan",
      "Jiang Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2311.08080",
    "title": "Identifying Light-curve Signals with a Deep Learning Based Object  Detection Algorithm. II. A General Light Curve Classification Framework",
    "abstract": "Vast amounts of astronomical photometric data are generated from various projects, requiring significant efforts to identify variable stars and other object classes. In light of this, a general, widely applicable classification framework would simplify the task of designing custom classifiers. We present a novel deep learning framework for classifying light curves using a weakly supervised object detection model. Our framework identifies the optimal windows for both light curves and power spectra automatically, and zooms in on their corresponding data. This allows for automatic feature extraction from both time and frequency domains, enabling our model to handle data across different scales and sampling intervals. We train our model on datasets obtained from both space-based and ground-based multi-band observations of variable stars and transients. We achieve an accuracy of 87% for combined variables and transient events, which is comparable to the performance of previous feature-based models. Our trained model can be utilized directly to other missions, such as ASAS-SN, without requiring any retraining or fine-tuning. To address known issues with miscalibrated predictive probabilities, we apply conformal prediction to generate robust predictive sets that guarantee true label coverage with a given probability. Additionally, we incorporate various anomaly detection algorithms to empower our model with the ability to identify out-of-distribution objects. Our framework is implemented in the Deep-LC toolkit, which is an open-source Python package hosted on Github and PyPI. ",
    "url": "https://arxiv.org/abs/2311.08080",
    "authors": [
      "Kaiming Cui",
      "D. J. Armstrong",
      "Fabo Feng"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.08179",
    "title": "Semi-Supervised Learning via Swapped Prediction for Communication Signal  Recognition",
    "abstract": "Deep neural networks have been widely used in communication signal recognition and achieved remarkable performance, but this superiority typically depends on using massive examples for supervised learning, whereas training a deep neural network on small datasets with few labels generally falls into overfitting, resulting in degenerated performance. To this end, we develop a semi-supervised learning (SSL) method that effectively utilizes a large collection of more readily available unlabeled signal data to improve generalization. The proposed method relies largely on a novel implementation of consistency-based regularization, termed Swapped Prediction, which leverages strong data augmentation to perturb an unlabeled sample and then encourage its corresponding model prediction to be close to its original, optimized with a scaled cross-entropy loss with swapped symmetry. Extensive experiments indicate that our proposed method can achieve a promising result for deep SSL of communication signal recognition. ",
    "url": "https://arxiv.org/abs/2311.08179",
    "authors": [
      "Weidong Wang",
      "Hongshu Liao",
      "Lu Gan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.08330",
    "title": "Generative De-Quantization for Neural Speech Codec via Latent Diffusion",
    "abstract": "In low-bitrate speech coding, end-to-end speech coding networks aim to learn compact yet expressive features and a powerful decoder in a single network. A challenging problem as such results in unwelcome complexity increase and inferior speech quality. In this paper, we propose to separate the representation learning and information reconstruction tasks. We leverage an end-to-end codec for learning low-dimensional discrete tokens and employ a latent diffusion model to de-quantize coded features into a high-dimensional continuous space, relieving the decoder's burden of de-quantizing and upsampling. To mitigate the issue of over-smooth generation, we introduce midway-infilling with less noise reduction and stronger conditioning. In ablation studies, we investigate the hyperparameters for midway-infilling and latent diffusion space with different dimensions. Subjective listening tests show that our model outperforms the state-of-the-art at two low bitrates, 1.5 and 3 kbps. Codes and samples of this work are available on our webpage. ",
    "url": "https://arxiv.org/abs/2311.08330",
    "authors": [
      "Haici Yang",
      "Inseon Jang",
      "Minje Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:1907.04585",
    "title": "Quasi-polynomial time approximation schemes for the Maximum Weight  Independent Set Problem in H-free graphs",
    "abstract": " Comments: v2: added results on subexponential algorithms, v3: revision after reviewers' remarks, v4: final version accepted at SICOMP ",
    "url": "https://arxiv.org/abs/1907.04585",
    "authors": [
      "Maria Chudnovsky",
      "Marcin Pilipczuk",
      "Micha\u0142 Pilipczuk",
      "St\u00e9phan Thomass\u00e9"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2104.13881",
    "title": "Large Scale Prediction with Decision Trees",
    "abstract": " Title: Large Scale Prediction with Decision Trees ",
    "url": "https://arxiv.org/abs/2104.13881",
    "authors": [
      "Jason M. Klusowski",
      "Peter M. Tian"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2106.05544",
    "title": "CogAlign: Learning to Align Textual Neural Representations to Cognitive  Language Processing Signals",
    "abstract": " Title: CogAlign: Learning to Align Textual Neural Representations to Cognitive  Language Processing Signals ",
    "url": "https://arxiv.org/abs/2106.05544",
    "authors": [
      "Yuqi Ren",
      "Deyi Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2106.06854",
    "title": "A Deep Reinforcement Learning Approach to Marginalized Importance  Sampling with the Successor Representation",
    "abstract": " Comments: ICML 2021 ",
    "url": "https://arxiv.org/abs/2106.06854",
    "authors": [
      "Scott Fujimoto",
      "David Meger",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2201.10859",
    "title": "Visualizing the Diversity of Representations Learned by Bayesian Neural  Networks",
    "abstract": " Comments: 16 pages, 18 figures ",
    "url": "https://arxiv.org/abs/2201.10859",
    "authors": [
      "Dennis Grinwald",
      "Kirill Bykov",
      "Shinichi Nakajima",
      "Marina M.-C. H\u00f6hne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.03359",
    "title": "An efficient semi-supervised quality control system trained using  physics-based MRI-artefact generators and adversarial training",
    "abstract": " Title: An efficient semi-supervised quality control system trained using  physics-based MRI-artefact generators and adversarial training ",
    "url": "https://arxiv.org/abs/2206.03359",
    "authors": [
      "Daniele Ravi",
      "Frederik Barkhof",
      "Daniel C. Alexander",
      "Lemuel Puglisi",
      "Geoffrey JM Parker",
      "Arman Eshaghi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.01473",
    "title": "Model-based Analysis and Specification of Functional Requirements and  Tests for Complex Automotive Systems",
    "abstract": " Title: Model-based Analysis and Specification of Functional Requirements and  Tests for Complex Automotive Systems ",
    "url": "https://arxiv.org/abs/2209.01473",
    "authors": [
      "Carsten Wiecher",
      "Constantin Mandel",
      "Matthias G\u00fcnther",
      "Jannik Fischbach",
      "Joel Greenyer",
      "Matthias Greinert",
      "Carsten Wolff",
      "Roman Dumitrescu",
      "Daniel Mendez",
      "Albert Albers"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.07410",
    "title": "Identification of quantum entanglement with Siamese convolutional neural  networks and semi-supervised learning",
    "abstract": " Comments: Updated version with improved models; 11 pages, 5 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2210.07410",
    "authors": [
      "Jaros\u0142aw Paw\u0142owski",
      "Mateusz Krawczyk"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2211.02914",
    "title": "Robust Reflection Removal with Flash-only Cues in the Wild",
    "abstract": " Comments: Extension of CVPR 2021 paper [arXiv:2103.04273], submitted to TPAMI. Our source code and dataset are publicly available at this http URL ",
    "url": "https://arxiv.org/abs/2211.02914",
    "authors": [
      "Chenyang Lei",
      "Xudong Jiang",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2211.10627",
    "title": "EGRC-Net: Embedding-induced Graph Refinement Clustering Network",
    "abstract": " Comments: This paper has been accepted by IEEE Transactions on Image Processing ",
    "url": "https://arxiv.org/abs/2211.10627",
    "authors": [
      "Zhihao Peng",
      "Hui Liu",
      "Yuheng Jia",
      "Junhui Hou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2301.12309",
    "title": "On the Lipschitz Constant of Deep Networks and Double Descent",
    "abstract": " Title: On the Lipschitz Constant of Deep Networks and Double Descent ",
    "url": "https://arxiv.org/abs/2301.12309",
    "authors": [
      "Matteo Gamba",
      "Hossein Azizpour",
      "M\u00e5rten Bj\u00f6rkman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.08942",
    "title": "PAC-Bayesian Generalization Bounds for Adversarial Generative Models",
    "abstract": " Comments: Published at ICML 2023 ",
    "url": "https://arxiv.org/abs/2302.08942",
    "authors": [
      "Sokhna Diarra Mbacke",
      "Florence Clerc",
      "Pascal Germain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.02867",
    "title": "Boundary-semantic collaborative guidance network with dual-stream  feedback mechanism for salient object detection in optical remote sensing  imagery",
    "abstract": " Comments: Accepted by TGRS ",
    "url": "https://arxiv.org/abs/2303.02867",
    "authors": [
      "Dejun Feng",
      "Hongyu Chen",
      "Suning Liu",
      "Ziyang Liao",
      "Xingyu Shen",
      "Yakun Xie",
      "Jun Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2303.04749",
    "title": "Data-Driven Robust Backward Reachable Sets for Set-Theoretic Model  Predictive Control",
    "abstract": " Comments: Preprint jointly submitted to IEEE Control Systems Letters (L-CSS) and IEEE Conference on Decision and Control (CDC) ",
    "url": "https://arxiv.org/abs/2303.04749",
    "authors": [
      "Mehran Attar",
      "Walter Lucia"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2304.05071",
    "title": "Fracture Detection in Pediatric Wrist Trauma X-ray Images Using YOLOv8  Algorithm",
    "abstract": " Comments: Scientific Reports ",
    "url": "https://arxiv.org/abs/2304.05071",
    "authors": [
      "Rui-Yang Ju",
      "Weiming Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.15738",
    "title": "Maximum Weight Independent Set in Graphs with no Long Claws in  Quasi-Polynomial Time",
    "abstract": " Comments: 58 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2305.15738",
    "authors": [
      "Peter Gartland",
      "Daniel Lokshtanov",
      "Tom\u00e1\u0161 Masa\u0159\u00edk",
      "Marcin Pilipczuk",
      "Micha\u0142 Pilipczuk",
      "Pawe\u0142 Rz\u0105\u017cewski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2305.17479",
    "title": "Inferring Causal Effects Under Heterogeneous Peer Influence",
    "abstract": " Title: Inferring Causal Effects Under Heterogeneous Peer Influence ",
    "url": "https://arxiv.org/abs/2305.17479",
    "authors": [
      "Shishir Adhikari",
      "Elena Zheleva"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.00041",
    "title": "Causal Intervention for Measuring Confidence in Drug-Target Interaction  Prediction",
    "abstract": " Title: Causal Intervention for Measuring Confidence in Drug-Target Interaction  Prediction ",
    "url": "https://arxiv.org/abs/2306.00041",
    "authors": [
      "Wenting Ye",
      "Chen Li",
      "Yang Xie",
      "Wen Zhang",
      "Hong-Yu Zhang",
      "Bowen Wang",
      "Debo Cheng",
      "Zaiwen Feng"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.11797",
    "title": "Towards a robust and reliable deep learning approach for detection of  compact binary mergers in gravitational wave data",
    "abstract": " Comments: 22 pages, 22 figures ",
    "url": "https://arxiv.org/abs/2306.11797",
    "authors": [
      "Shreejit Jadhav",
      "Mihir Shrivastava",
      "Sanjit Mitra"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.13508",
    "title": "The effect of distant connections on node anonymity in complex networks",
    "abstract": " Comments: New version. Updated title, and results added to Supplementary information ",
    "url": "https://arxiv.org/abs/2306.13508",
    "authors": [
      "Rachel G. de Jong",
      "Mark P. J. van der Loo",
      "Frank W. Takes"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.13724",
    "title": "Review of compressed embedding layers and their applications for  recommender systems",
    "abstract": " Comments: 10 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2306.13724",
    "authors": [
      "Tamas Hajgato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.00754",
    "title": "ImDiffusion: Imputed Diffusion Models for Multivariate Time Series  Anomaly Detection",
    "abstract": " Comments: To appear in VLDB 2024.Code: this https URL ",
    "url": "https://arxiv.org/abs/2307.00754",
    "authors": [
      "Yuhang Chen",
      "Chaoyun Zhang",
      "Minghua Ma",
      "Yudong Liu",
      "Ruomeng Ding",
      "Bowen Li",
      "Shilin He",
      "Saravan Rajmohan",
      "Qingwei Lin",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.09444",
    "title": "No distributed quantum advantage for approximate graph coloring",
    "abstract": " Title: No distributed quantum advantage for approximate graph coloring ",
    "url": "https://arxiv.org/abs/2307.09444",
    "authors": [
      "Xavier Coiteux-Roy",
      "Francesco d'Amore",
      "Rishikesh Gajjala",
      "Fabian Kuhn",
      "Fran\u00e7ois Le Gall",
      "Henrik Lievonen",
      "Augusto Modanese",
      "Marc-Olivier Renou",
      "Gustav Schmid",
      "Jukka Suomela"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Emerging Technologies (cs.ET)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2307.12540",
    "title": "UniFormaly: Towards Task-Agnostic Unified Framework for Visual Anomaly  Detection",
    "abstract": " Comments: 23 pages, 13 figures. Codes are available at this https URL ",
    "url": "https://arxiv.org/abs/2307.12540",
    "authors": [
      "Yujin Lee",
      "Harin Lim",
      "Seoyoon Jang",
      "Hyunsoo Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.15807",
    "title": "Anomaly Detection in Industrial Machinery using IoT Devices and Machine  Learning: a Systematic Mapping",
    "abstract": " Title: Anomaly Detection in Industrial Machinery using IoT Devices and Machine  Learning: a Systematic Mapping ",
    "url": "https://arxiv.org/abs/2307.15807",
    "authors": [
      "S\u00e9rgio F. Chevtchenko",
      "Elisson da Silva Rocha",
      "Monalisa Cristina Moura Dos Santos",
      "Ricardo Lins Mota",
      "Diego Moura Vieira",
      "Ermeson Carneiro de Andrade",
      "Danilo Ricardo Barbosa de Ara\u00fajo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10874",
    "title": "Analyzing Transformer Dynamics as Movement through Embedding Space",
    "abstract": " Comments: V2. Rewrote abstract. Rewrote / re-organized the entire paper into a more formal proposition/argument/result format. To shorten main paper length: Wrote more compact text in general, moved \"negative self bias\" and \"encoder v/s decoder walks\" sections to the appendix and packed figures. Styled as TMLR ",
    "url": "https://arxiv.org/abs/2308.10874",
    "authors": [
      "Sumeet S. Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2308.13816",
    "title": "Homological Convolutional Neural Networks",
    "abstract": " Comments: 26 pages, 5 figures, 11 tables, 1 equation, 1 algorithm ",
    "url": "https://arxiv.org/abs/2308.13816",
    "authors": [
      "Antonio Briola",
      "Yuanrong Wang",
      "Silvia Bartolucci",
      "Tomaso Aste"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2309.00305",
    "title": "Efficient Surrogate Models for Materials Science Simulations: Machine  Learning-based Prediction of Microstructure Properties",
    "abstract": " Title: Efficient Surrogate Models for Materials Science Simulations: Machine  Learning-based Prediction of Microstructure Properties ",
    "url": "https://arxiv.org/abs/2309.00305",
    "authors": [
      "Binh Duong Nguyen",
      "Pavlo Potapenko",
      "Aytekin Dermici",
      "Kishan Govind",
      "S\u00e9bastien Bompas",
      "Stefan Sandfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08652",
    "title": "Quantifying Credit Portfolio sensitivity to asset correlations with  interpretable generative neural networks",
    "abstract": " Title: Quantifying Credit Portfolio sensitivity to asset correlations with  interpretable generative neural networks ",
    "url": "https://arxiv.org/abs/2309.08652",
    "authors": [
      "Sergio Caprioli",
      "Emanuele Cagliero",
      "Riccardo Crupi"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.10462",
    "title": "Computing the Weight Distribution of the Binary Reed-Muller Code  ${\\mathcal R} (4,9)$",
    "abstract": " Comments: typos corrected, reference added, revised arguments in section 3, results unchanged ",
    "url": "https://arxiv.org/abs/2309.10462",
    "authors": [
      "Miroslav Markov",
      "Yuri Borissov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2309.14610",
    "title": "Unsupervised Graph Deep Learning Reveals Emergent Flood Risk Profile of  Urban Areas",
    "abstract": " Comments: 24 pages ",
    "url": "https://arxiv.org/abs/2309.14610",
    "authors": [
      "Kai Yin",
      "Ali Mostafavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2310.01113",
    "title": "HyperGraphDis: Leveraging Hypergraphs for Contextual and Social-Based  Disinformation Detection",
    "abstract": " Comments: We have updated the paper to include additional references ",
    "url": "https://arxiv.org/abs/2310.01113",
    "authors": [
      "Nikos Salamanos",
      "Pantelitsa Leonidou",
      "Nikolaos Laoutaris",
      "Michael Sirivianos",
      "Maria Aspri",
      "Marius Paraschiv"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.07793",
    "title": "GenTKG: Generative Forecasting on Temporal Knowledge Graph",
    "abstract": " Comments: 8 pages, accepted to Temporal Graph Learning @ NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2310.07793",
    "authors": [
      "Ruotong Liao",
      "Xu Jia",
      "Yunpu Ma",
      "Volker Tresp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.11755",
    "title": "RGM: A Robust Generalist Matching Model",
    "abstract": " Comments: 17 pages. Fixed typo in the first two equations. Code is available at: this https URL ",
    "url": "https://arxiv.org/abs/2310.11755",
    "authors": [
      "Songyan Zhang",
      "Xinyu Sun",
      "Hao Chen",
      "Bo Li",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.12334",
    "title": "Improving Representation Learning for Histopathologic Images with  Cluster Constraints",
    "abstract": " Comments: Accepted by ICCV2023 ",
    "url": "https://arxiv.org/abs/2310.12334",
    "authors": [
      "Weiyi Wu",
      "Chongyang Gao",
      "Joseph DiPalma",
      "Soroush Vosoughi",
      "Saeed Hassanpour"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.14421",
    "title": "On existence, uniqueness and scalability of adversarial robustness  measures for AI classifiers",
    "abstract": " Comments: 16 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2310.14421",
    "authors": [
      "Illia Horenko"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18801",
    "title": "Integrated Relative-Measurement-Based Network Localization and Formation  Maneuver Control (Extended Version)",
    "abstract": " Comments: 12 pages; 7 figures, title corrected, DOI added ",
    "url": "https://arxiv.org/abs/2310.18801",
    "authors": [
      "Xu Fang",
      "Lihua Xie",
      "Xiaolei Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.03402",
    "title": "CycleCL: Self-supervised Learning for Periodic Videos",
    "abstract": " Comments: Accepted at WACV 2024 ",
    "url": "https://arxiv.org/abs/2311.03402",
    "authors": [
      "Matteo Destro",
      "Michael Gygli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.05410",
    "title": "Linear Gaussian Bounding Box Representation and Ring-Shaped Rotated  Convolution for Oriented Object Detection",
    "abstract": " Title: Linear Gaussian Bounding Box Representation and Ring-Shaped Rotated  Convolution for Oriented Object Detection ",
    "url": "https://arxiv.org/abs/2311.05410",
    "authors": [
      "Zhen Zhou",
      "Yunkai Ma",
      "Junfeng Fan",
      "Zhaoyang Liu",
      "Fengshui Jing",
      "Min Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.05808",
    "title": "Scale-MIA: A Scalable Model Inversion Attack against Secure Federated  Learning via Latent Space Reconstruction",
    "abstract": " Title: Scale-MIA: A Scalable Model Inversion Attack against Secure Federated  Learning via Latent Space Reconstruction ",
    "url": "https://arxiv.org/abs/2311.05808",
    "authors": [
      "Shanghao Shi",
      "Ning Wang",
      "Yang Xiao",
      "Chaoyu Zhang",
      "Yi Shi",
      "Y.Thomas Hou",
      "Wenjing Lou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.06429",
    "title": "The Impact of Load Altering Attacks on Distribution Systems with ZIP  Loads",
    "abstract": " Title: The Impact of Load Altering Attacks on Distribution Systems with ZIP  Loads ",
    "url": "https://arxiv.org/abs/2311.06429",
    "authors": [
      "Sajjad Maleki",
      "Shijie Pan",
      "E. Veronica Belmega",
      "Charalambos Konstantinou",
      "Subhash Lakshminarayana"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.07089",
    "title": "Recursive and non-recursive filters for sequential smoothing and  prediction with instantaneous phase and frequency estimation applications",
    "abstract": " Comments: Added 3 more refs. Added extra para to discussion on generic low-pass filtering applications. Added arXiv ID to header ",
    "url": "https://arxiv.org/abs/2311.07089",
    "authors": [
      "Hugh Lachlan Kennedy"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.07247",
    "title": "Simultaneous Clutter Detection and Semantic Segmentation of Moving  Objects for Automotive Radar Data",
    "abstract": " Comments: Published at IEEE International Conference on Intelligent Transportation Systems (ITSC), Bilbao, ESP, 2023 ",
    "url": "https://arxiv.org/abs/2311.07247",
    "authors": [
      "Johannes Kopp",
      "Dominik Kellner",
      "Aldi Piroli",
      "Vinzenz Dallabetta",
      "Klaus Dietmayer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  }
]