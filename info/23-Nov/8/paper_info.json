[
  {
    "id": "arXiv:2311.03358",
    "title": "Towards Understanding and Analyzing Rationale in Commit Messages using a  Knowledge Graph Approach",
    "abstract": "Extracting rationale information from commit messages allows developers to better understand a system and its past development. Here we present our ongoing work on the Kantara end-to-end rationale reconstruction pipeline to a) structure rationale information in an ontologically-based knowledge graph, b) extract and classify this information from commits, and c) produce analysis reports and visualizations for developers. We also present our work on creating a labelled dataset for our running example of the Out-of-Memory component of the Linux kernel. This dataset is used as ground truth for our evaluation of NLP classification techniques which show promising results, especially the multi-classification technique XGBoost. ",
    "url": "https://arxiv.org/abs/2311.03358",
    "authors": [
      "Mouna Dhaouadi",
      "Bentley James Oakes",
      "Michalis Famelis"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2311.03366",
    "title": "Neural Rankers for Code Generation via Inter-Cluster Modeling",
    "abstract": "Code Large Language Models (CodeLLMs) have ushered in a new era of code generation advancements. However, selecting the best solutions from among all possible CodeLLM solutions remains a challenge. Previous methods frequently overlooked the intricate functional similarities and interactions between clusters, resulting in suboptimal results. In this work, we introduce \\textit{SRank}, a novel reranking strategy for selecting the best solution from code generation that focuses on modeling inter-cluster relationship. By quantifying the functional overlap between clusters, our approach provides a better ranking strategy of code solutions. Empirical results show that our method achieves a remarkable results on pass@1 score. For instance, on the Human-Eval benchmark, we achieve 69.66\\% in pass@1 with Codex002, 75.31\\% for WizardCoder, 53.99\\% for StarCoder and 60.55\\% for CodeGen, which surpass the state-of-the-arts solution ranking methods, such as CodeT and Coder-Reviewer on the same CodeLLM with significant margin ($\\approx 6.1\\%$ improvement on average). Comparing to the random sampling method, we can achieve an average improvement of $\\approx 23.07\\%$ on Human-Eval and 17.64\\% on MBPP. Even in scenarios with limited test inputs, our approach demonstrates robustness and superiority, marking a new state-of-the-arts in code generation reranking. ",
    "url": "https://arxiv.org/abs/2311.03366",
    "authors": [
      "Hung Quoc To",
      "Minh Huynh Nguyen",
      "Nghi D. Q. Bui"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.03373",
    "title": "Unscrambling the Rectification of Adversarial Attacks Transferability  across Computer Networks",
    "abstract": "Convolutional neural networks (CNNs) models play a vital role in achieving state-of-the-art performances in various technological fields. CNNs are not limited to Natural Language Processing (NLP) or Computer Vision (CV) but also have substantial applications in other technological domains, particularly in cybersecurity. The reliability of CNN's models can be compromised because of their susceptibility to adversarial attacks, which can be generated effortlessly, easily applied, and transferred in real-world scenarios. In this paper, we present a novel and comprehensive method to improve the strength of attacks and assess the transferability of adversarial examples in CNNs when such strength changes, as well as whether the transferability property issue exists in computer network applications. In the context of our study, we initially examined six distinct modes of attack: the Carlini and Wagner (C&W), Fast Gradient Sign Method (FGSM), Iterative Fast Gradient Sign Method (I-FGSM), Jacobian-based Saliency Map (JSMA), Limited-memory Broyden fletcher Goldfarb Shanno (L-BFGS), and Projected Gradient Descent (PGD) attack. We applied these attack techniques on two popular datasets: the CIC and UNSW datasets. The outcomes of our experiment demonstrate that an improvement in transferability occurs in the targeted scenarios for FGSM, JSMA, LBFGS, and other attacks. Our findings further indicate that the threats to security posed by adversarial examples, even in computer network applications, necessitate the development of novel defense mechanisms to enhance the security of DL-based techniques. ",
    "url": "https://arxiv.org/abs/2311.03373",
    "authors": [
      "Ehsan Nowroozi",
      "Samaneh Ghelichkhani",
      "Imran Haider",
      "Ali Dehghantanha"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.03375",
    "title": "Edge AI Inference in Heterogeneous Constrained Computing: Feasibility  and Opportunities",
    "abstract": "The network edge's role in Artificial Intelligence (AI) inference processing is rapidly expanding, driven by a plethora of applications seeking computational advantages. These applications strive for data-driven efficiency, leveraging robust AI capabilities and prioritizing real-time responsiveness. However, as demand grows, so does system complexity. The proliferation of AI inference accelerators showcases innovation but also underscores challenges, particularly the varied software and hardware configurations of these devices. This diversity, while advantageous for certain tasks, introduces hurdles in device integration and coordination. In this paper, our objectives are three-fold. Firstly, we outline the requirements and components of a framework that accommodates hardware diversity. Next, we assess the impact of device heterogeneity on AI inference performance, identifying strategies to optimize outcomes without compromising service quality. Lastly, we shed light on the prevailing challenges and opportunities in this domain, offering insights for both the research community and industry stakeholders. ",
    "url": "https://arxiv.org/abs/2311.03375",
    "authors": [
      "Roberto Morabito",
      "Mallik Tatipamula",
      "Sasu Tarkoma",
      "Mung Chiang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2311.03382",
    "title": "Causal Structure Representation Learning of Confounders in Latent Space  for Recommendation",
    "abstract": "Inferring user preferences from the historical feedback of users is a valuable problem in recommender systems. Conventional approaches often rely on the assumption that user preferences in the feedback data are equivalent to the real user preferences without additional noise, which simplifies the problem modeling. However, there are various confounders during user-item interactions, such as weather and even the recommendation system itself. Therefore, neglecting the influence of confounders will result in inaccurate user preferences and suboptimal performance of the model. Furthermore, the unobservability of confounders poses a challenge in further addressing the problem. To address these issues, we refine the problem and propose a more rational solution. Specifically, we consider the influence of confounders, disentangle them from user preferences in the latent space, and employ causal graphs to model their interdependencies without specific labels. By cleverly combining local and global causal graphs, we capture the user-specificity of confounders on user preferences. We theoretically demonstrate the identifiability of the obtained causal graph. Finally, we propose our model based on Variational Autoencoders, named Causal Structure representation learning of Confounders in latent space (CSC). We conducted extensive experiments on one synthetic dataset and five real-world datasets, demonstrating the superiority of our model. Furthermore, we demonstrate that the learned causal representations of confounders are controllable, potentially offering users fine-grained control over the objectives of their recommendation lists with the learned causal graphs. ",
    "url": "https://arxiv.org/abs/2311.03382",
    "authors": [
      "Hangtong Xu",
      "Yuanbo Xu",
      "Yongjian Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2311.03387",
    "title": "Determination of droplet size from wide-angle light scattering image  data using convolutional neural networks",
    "abstract": "Wide-angle light scattering (WALS) offers the possibility of a highly temporally and spatially resolved measurement of droplets in spray-based methods for nanoparticle synthesis. The size of these droplets is a critical variable affecting the final properties of synthesized materials such as hetero-aggregates. However, conventional methods for determining droplet sizes from WALS image data are labor-intensive and may introduce biases, particularly when applied to complex systems like spray flame synthesis (SFS). To address these challenges, we introduce a fully automatic machine learning-based approach that employs convolutional neural networks (CNNs) in order to streamline the droplet sizing process. This CNN-based methodology offers further advantages: it requires few manual labels and can utilize transfer learning, making it a promising alternative to conventional methods, specifically with respect to efficiency. To evaluate the performance of our machine learning models, we consider WALS data from an ethanol spray flame process at various heights above the burner surface (HABs), where the models are trained and cross-validated on a large dataset comprising nearly 35000 WALS images. ",
    "url": "https://arxiv.org/abs/2311.03387",
    "authors": [
      "Tom Kirstein",
      "Simon A\u00dfmann",
      "Orkun Furat",
      "Stefan Will",
      "Volker Schmidt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.03388",
    "title": "Attention-based Models for Snow-Water Equivalent Prediction",
    "abstract": "Snow Water-Equivalent (SWE) -- the amount of water available if snowpack is melted -- is a key decision variable used by water management agencies to make irrigation, flood control, power generation and drought management decisions. SWE values vary spatiotemporally -- affected by weather, topography and other environmental factors. While daily SWE can be measured by Snow Telemetry (SNOTEL) stations with requisite instrumentation, such stations are spatially sparse requiring interpolation techniques to create spatiotemporally complete data. While recent efforts have explored machine learning (ML) for SWE prediction, a number of recent ML advances have yet to be considered. The main contribution of this paper is to explore one such ML advance, attention mechanisms, for SWE prediction. Our hypothesis is that attention has a unique ability to capture and exploit correlations that may exist across locations or the temporal spectrum (or both). We present a generic attention-based modeling framework for SWE prediction and adapt it to capture spatial attention and temporal attention. Our experimental results on 323 SNOTEL stations in the Western U.S. demonstrate that our attention-based models outperform other machine learning approaches. We also provide key results highlighting the differences between spatial and temporal attention in this context and a roadmap toward deployment for generating spatially-complete SWE maps. ",
    "url": "https://arxiv.org/abs/2311.03388",
    "authors": [
      "Krishu K. Thapa",
      "Bhupinderjeet Singh",
      "Supriya Savalkar",
      "Alan Fern",
      "Kirti Rajagopalan",
      "Ananth Kalyanaraman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2311.03393",
    "title": "Sketching Multidimensional Time Series for Fast Discord Mining",
    "abstract": "Time series discords are a useful primitive for time series anomaly detection, and the matrix profile is capable of capturing discord effectively. There exist many research efforts to improve the scalability of discord discovery with respect to the length of time series. However, there is surprisingly little work focused on reducing the time complexity of matrix profile computation associated with dimensionality of a multidimensional time series. In this work, we propose a sketch for discord mining among multi-dimensional time series. After an initial pre-processing of the sketch as fast as reading the data, the discord mining has runtime independent of the dimensionality of the original data. On several real world examples from water treatment and transportation, the proposed algorithm improves the throughput by at least an order of magnitude (50X) and only has minimal impact on the quality of the approximated solution. Additionally, the proposed method can handle the dynamic addition or deletion of dimensions inconsequential overhead. This allows a data analyst to consider \"what-if\" scenarios in real time while exploring the data. ",
    "url": "https://arxiv.org/abs/2311.03393",
    "authors": [
      "Chin-Chia Michael Yeh",
      "Yan Zheng",
      "Menghai Pan",
      "Huiyuan Chen",
      "Zhongfang Zhuang",
      "Junpeng Wang",
      "Liang Wang",
      "Wei Zhang",
      "Jeff M. Phillips",
      "Eamonn Keogh"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.03396",
    "title": "Differentially Private Pre-Trained Model Fusion using Decentralized  Federated Graph Matching",
    "abstract": "Model fusion is becoming a crucial component in the context of model-as-a-service scenarios, enabling the delivery of high-quality model services to local users. However, this approach introduces privacy risks and imposes certain limitations on its applications. Ensuring secure model exchange and knowledge fusion among users becomes a significant challenge in this setting. To tackle this issue, we propose PrivFusion, a novel architecture that preserves privacy while facilitating model fusion under the constraints of local differential privacy. PrivFusion leverages a graph-based structure, enabling the fusion of models from multiple parties without necessitating retraining. By employing randomized mechanisms, PrivFusion ensures privacy guarantees throughout the fusion process. To enhance model privacy, our approach incorporates a hybrid local differentially private mechanism and decentralized federated graph matching, effectively protecting both activation values and weights. Additionally, we introduce a perturbation filter adapter to alleviate the impact of randomized noise, thereby preserving the utility of the fused model. Through extensive experiments conducted on diverse image datasets and real-world healthcare applications, we provide empirical evidence showcasing the effectiveness of PrivFusion in maintaining model performance while preserving privacy. Our contributions offer valuable insights and practical solutions for secure and collaborative data analysis within the domain of privacy-preserving model fusion. ",
    "url": "https://arxiv.org/abs/2311.03396",
    "authors": [
      "Qian Chen",
      "Yiqiang Chen",
      "Xinlong Jiang",
      "Teng Zhang",
      "Weiwei Dai",
      "Wuliang Huang",
      "Zhen Yan",
      "Bo Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.03402",
    "title": "CycleCL: Self-supervised Learning for Periodic Videos",
    "abstract": "Analyzing periodic video sequences is a key topic in applications such as automatic production systems, remote sensing, medical applications, or physical training. An example is counting repetitions of a physical exercise. Due to the distinct characteristics of periodic data, self-supervised methods designed for standard image datasets do not capture changes relevant to the progression of the cycle and fail to ignore unrelated noise. They thus do not work well on periodic data. In this paper, we propose CycleCL, a self-supervised learning method specifically designed to work with periodic data. We start from the insight that a good visual representation for periodic data should be sensitive to the phase of a cycle, but be invariant to the exact repetition, i.e. it should generate identical representations for a specific phase throughout all repetitions. We exploit the repetitions in videos to design a novel contrastive learning method based on a triplet loss that optimizes for these desired properties. Our method uses pre-trained features to sample pairs of frames from approximately the same phase and negative pairs of frames from different phases. Then, we iterate between optimizing a feature encoder and resampling triplets, until convergence. By optimizing a model this way, we are able to learn features that have the mentioned desired properties. We evaluate CycleCL on an industrial and multiple human actions datasets, where it significantly outperforms previous video-based self-supervised learning methods on all tasks. ",
    "url": "https://arxiv.org/abs/2311.03402",
    "authors": [
      "Matteo Destro",
      "Michael Gygli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.03408",
    "title": "Training Multi-layer Neural Networks on Ising Machine",
    "abstract": "As a dedicated quantum device, Ising machines could solve large-scale binary optimization problems in milliseconds. There is emerging interest in utilizing Ising machines to train feedforward neural networks due to the prosperity of generative artificial intelligence. However, existing methods can only train single-layer feedforward networks because of the complex nonlinear network topology. This paper proposes an Ising learning algorithm to train quantized neural network (QNN), by incorporating two essential techinques, namely binary representation of topological network and order reduction of loss function. As far as we know, this is the first algorithm to train multi-layer feedforward networks on Ising machines, providing an alternative to gradient-based backpropagation. Firstly, training QNN is formulated as a quadratic constrained binary optimization (QCBO) problem by representing neuron connection and activation function as equality constraints. All quantized variables are encoded by binary bits based on binary encoding protocol. Secondly, QCBO is converted to a quadratic unconstrained binary optimization (QUBO) problem, that can be efficiently solved on Ising machines. The conversion leverages both penalty function and Rosenberg order reduction, who together eliminate equality constraints and reduce high-order loss function into a quadratic one. With some assumptions, theoretical analysis shows the space complexity of our algorithm is $\\mathcal{O}(H^2L + HLN\\log H)$, quantifying the required number of Ising spins. Finally, the algorithm effectiveness is validated with a simulated Ising machine on MNIST dataset. After annealing 700 ms, the classification accuracy achieves 98.3%. Among 100 runs, the success probability of finding the optimal solution is 72%. Along with the increasing number of spins on Ising machine, our algorithm has the potential to train deeper neural networks. ",
    "url": "https://arxiv.org/abs/2311.03408",
    "authors": [
      "Xujie Song",
      "Tong Liu",
      "Shengbo Eben Li",
      "Jingliang Duan",
      "Wenxuan Wang",
      "Keqiang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2311.03410",
    "title": "DP-DCAN: Differentially Private Deep Contrastive Autoencoder Network for  Single-cell Clustering",
    "abstract": "Single-cell RNA sequencing (scRNA-seq) is important to transcriptomic analysis of gene expression. Recently, deep learning has facilitated the analysis of high-dimensional single-cell data. Unfortunately, deep learning models may leak sensitive information about users. As a result, Differential Privacy (DP) is increasingly used to protect privacy. However, existing DP methods usually perturb whole neural networks to achieve differential privacy, and hence result in great performance overheads. To address this challenge, in this paper, we take advantage of the uniqueness of the autoencoder that it outputs only the dimension-reduced vector in the middle of the network, and design a Differentially Private Deep Contrastive Autoencoder Network (DP-DCAN) by partial network perturbation for single-cell clustering. Since only partial network is added with noise, the performance improvement is obvious and twofold: one part of network is trained with less noise due to a bigger privacy budget, and the other part is trained without any noise. Experimental results of six datasets have verified that DP-DCAN is superior to the traditional DP scheme with whole network perturbation. Moreover, DP-DCAN demonstrates strong robustness to adversarial attacks. The code is available at https://github.com/LFD-byte/DP-DCAN. ",
    "url": "https://arxiv.org/abs/2311.03410",
    "authors": [
      "Huifa Li",
      "Jie Fu",
      "Zhili Chen",
      "Xiaomin Yang",
      "Haitao Liu",
      "Xinpeng Ling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Genomics (q-bio.GN)"
    ]
  },
  {
    "id": "arXiv:2311.03414",
    "title": "A Generative Neural Network Approach for 3D Multi-Criteria Design  Generation and Optimization of an Engine Mount for an Unmanned Air Vehicle",
    "abstract": "One of the most promising developments in computer vision in recent years is the use of generative neural networks for functionality condition-based 3D design reconstruction and generation. Here, neural networks learn dependencies between functionalities and a geometry in a very effective way. For a neural network the functionalities are translated in conditions to a certain geometry. But the more conditions the design generation needs to reflect, the more difficult it is to learn clear dependencies. This leads to a multi criteria design problem due various conditions, which are not considered in the neural network structure so far. In this paper, we address this multi-criteria challenge for a 3D design use case related to an unmanned aerial vehicle (UAV) motor mount. We generate 10,000 abstract 3D designs and subject them all to simulations for three physical disciplines: mechanics, thermodynamics, and aerodynamics. Then, we train a Conditional Variational Autoencoder (CVAE) using the geometry and corresponding multicriteria functional constraints as input. We use our trained CVAE as well as the Marching cubes algorithm to generate meshes for simulation based evaluation. The results are then evaluated with the generated UAV designs. Subsequently, we demonstrate the ability to generate optimized designs under self-defined functionality conditions using the trained neural network. ",
    "url": "https://arxiv.org/abs/2311.03414",
    "authors": [
      "Christoph Petroll",
      "Sebastian Eilermann",
      "Philipp Hoefer",
      "Oliver Niggemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.03470",
    "title": "Orion: A Fully Homomorphic Encryption Compiler for Private Deep Neural  Network Inference",
    "abstract": "Fully Homomorphic Encryption (FHE) has the potential to substantially improve privacy and security by enabling computation on encrypted data. This is especially true with deep learning, as today many popular user services are powered by neural networks. One of the major challenges facing wide-scale deployment of FHE-secured neural inference is effectively mapping them to the FHE domain. FHE poses many programming challenges including packing large vectors, handling expensive rotations, and correctly implementing complex strided convolutions. This makes programming FHE inferences prone to poor performance and errors. In this paper we overcome these challenges with Orion, an automated optimizing FHE compiler for neural inference. Orion automatically maps PyTorch-specified networks to FHE, handling common layer types and arbitrary tensor shapes and strides. Moreover, we develop novel optimizations that balance dense FHE vector packing, efficient rotations, and minimize operations to improve performance. We have implemented Orion, which will be open sourced, and evaluated it on common benchmarks used by the FHE deep learning community. We compare Orion to multiple state-of-the-art solutions and report iso-accuracy speedups ranging from 2.7$\\times$ to 20.5$\\times$. ",
    "url": "https://arxiv.org/abs/2311.03470",
    "authors": [
      "Austin Ebel",
      "Karthik Garimella",
      "Brandon Reagen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.03509",
    "title": "MFAAN: Unveiling Audio Deepfakes with a Multi-Feature Authenticity  Network",
    "abstract": "In the contemporary digital age, the proliferation of deepfakes presents a formidable challenge to the sanctity of information dissemination. Audio deepfakes, in particular, can be deceptively realistic, posing significant risks in misinformation campaigns. To address this threat, we introduce the Multi-Feature Audio Authenticity Network (MFAAN), an advanced architecture tailored for the detection of fabricated audio content. MFAAN incorporates multiple parallel paths designed to harness the strengths of different audio representations, including Mel-frequency cepstral coefficients (MFCC), linear-frequency cepstral coefficients (LFCC), and Chroma Short Time Fourier Transform (Chroma-STFT). By synergistically fusing these features, MFAAN achieves a nuanced understanding of audio content, facilitating robust differentiation between genuine and manipulated recordings. Preliminary evaluations of MFAAN on two benchmark datasets, 'In-the-Wild' Audio Deepfake Data and The Fake-or-Real Dataset, demonstrate its superior performance, achieving accuracies of 98.93% and 94.47% respectively. Such results not only underscore the efficacy of MFAAN but also highlight its potential as a pivotal tool in the ongoing battle against deepfake audio content. ",
    "url": "https://arxiv.org/abs/2311.03509",
    "authors": [
      "Karthik Sivarama Krishnan",
      "Koushik Sivarama Krishnan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2311.03520",
    "title": "Brain Networks and Intelligence: A Graph Neural Network Based Approach  to Resting State fMRI Data",
    "abstract": "Resting-state functional magnetic resonance imaging (rsfMRI) is a powerful tool for investigating the relationship between brain function and cognitive processes as it allows for the functional organization of the brain to be captured without relying on a specific task or stimuli. In this paper, we present a novel modeling architecture called BrainRGIN for predicting intelligence (fluid, crystallized, and total intelligence) using graph neural networks on rsfMRI derived static functional network connectivity matrices. Extending from the existing graph convolution networks, our approach incorporates a clustering-based embedding and graph isomorphism network in the graph convolutional layer to reflect the nature of the brain sub-network organization and efficient network expression, in combination with TopK pooling and attention-based readout functions. We evaluated our proposed architecture on a large dataset, specifically the Adolescent Brain Cognitive Development Dataset, and demonstrated its effectiveness in predicting individual differences in intelligence. Our model achieved lower mean squared errors and higher correlation scores than existing relevant graph architectures and other traditional machine learning models for all of the intelligence prediction tasks. The middle frontal gyrus exhibited a significant contribution to both fluid and crystallized intelligence, suggesting their pivotal role in these cognitive processes. Total composite scores identified a diverse set of brain regions to be relevant which underscores the complex nature of total intelligence. ",
    "url": "https://arxiv.org/abs/2311.03520",
    "authors": [
      "Bishal Thapaliya",
      "Esra Akbas",
      "Jiayu Chen",
      "Raam Sapkota",
      "Bhaskar Ray",
      "Pranav Suresh",
      "Vince Calhoun",
      "Jingyu Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2311.03532",
    "title": "The Fairness Stitch: Unveiling the Potential of Model Stitching in  Neural Network De-Biasing",
    "abstract": "The pursuit of fairness in machine learning models has emerged as a critical research challenge in different applications ranging from bank loan approval to face detection. Despite the widespread adoption of artificial intelligence algorithms across various domains, concerns persist regarding the presence of biases and discrimination within these models. To address this pressing issue, this study introduces a novel method called \"The Fairness Stitch (TFS)\" to enhance fairness in deep learning models. This method combines model stitching and training jointly, while incorporating fairness constraints. In this research, we assess the effectiveness of our proposed method by conducting a comprehensive evaluation of two well-known datasets, CelebA and UTKFace. We systematically compare the performance of our approach with the existing baseline method. Our findings reveal a notable improvement in achieving a balanced trade-off between fairness and performance, highlighting the promising potential of our method to address bias-related challenges and foster equitable outcomes in machine learning models. This paper poses a challenge to the conventional wisdom of the effectiveness of the last layer in deep learning models for de-biasing. ",
    "url": "https://arxiv.org/abs/2311.03532",
    "authors": [
      "Modar Sulaiman",
      "Kallol Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2311.03542",
    "title": "Indexing Techniques for Graph Reachability Queries",
    "abstract": "We survey graph reachability indexing techniques for efficient processing of graph reachability queries in two types of popular graph models: plain graphs and edge-labeled graphs. Reachability queries are fundamental in graph processing, and reachability indexes are specialized data structures tailored for speeding up such queries. Work on this topic goes back four decades -- we include 33 of the proposed techniques. Plain graphs contain only vertices and edges, with reachability queries checking path existence between a source and target vertex. Edge-labeled graphs, in contrast, augment plain graphs by adding edge labels. Reachability queries in edge-labeled graphs incorporate path constraints based on edge labels, assessing both path existence and compliance with constraints. We categorize techniques in both plain and edge-labeled graphs and discuss the approaches according to this classification, using existing techniques as exemplars. We discuss the main challenges within each class and how these might be addressed in other approaches. We conclude with a discussion of the open research challenges and future research directions, along the lines of integrating reachability indexes into graph data management systems. This survey serves as a comprehensive resource for researchers and practitioners interested in the advancements, techniques, and challenges on reachability indexing in graph analytics. ",
    "url": "https://arxiv.org/abs/2311.03542",
    "authors": [
      "Chao Zhang",
      "Angela Bonifati",
      "M. Tamer \u00d6zsu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2311.03543",
    "title": "Enabling Dynamic Selection of Implementation Variants in Component-Based  Parallel Programming for Heterogeneous Systems",
    "abstract": "Heterogeneous systems, consisting of CPUs and GPUs, offer the capability to address the demands of compute- and data-intensive applications. However, programming such systems is challenging, requiring knowledge of various parallel programming frameworks. This paper introduces COMPAR, a component-based parallel programming framework that enables the exposure and selection of multiple implementation variants of components at runtime. The framework leverages compiler directive-based language extensions to annotate the source code and generate the necessary glue code for the StarPU runtime system. COMPAR provides a unified view of implementation variants and allows for intelligent selection based on runtime context. Our evaluation demonstrates the effectiveness of COMPAR through benchmark applications. The proposed approach simplifies heterogeneous parallel programming and promotes code reuse while achieving optimal performance. ",
    "url": "https://arxiv.org/abs/2311.03543",
    "authors": [
      "Suejb Memeti"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2311.03552",
    "title": "Modeling and Control of Diesel Engine Emissions using Multi-layer Neural  Networks and Economic Model Predictive Control",
    "abstract": "This paper presents the results of developing a multi-layer Neural Network (NN) to represent diesel engine emissions and integrating this NN into control design. Firstly, a NN is trained and validated to simultaneously predict oxides of nitrogen (N Ox) and Soot using both transient and steady-state data. Based on the input-output correlation analysis, inputs to NN with the highest influence on the emissions are selected while keeping the NN structure simple. Secondly, a co-simulation framework is implemented to integrate the NN emissions model with a model of a diesel engine airpath system built in GT-Power and used to identify a low-order linear parameter-varying (LPV) model for emissions prediction. Finally, an economic supervisory model predictive controller (MPC) is developed using the LPV emissions model to adjust setpoints to an inner-loop airpath tracking MPC. Simulation results are reported illustrating the capability of the resulting controller to reduce N Ox, meet the target Soot limit, and track the adjusted intake manifold pressure and exhaust gas recirculation (EGR) rate targets. ",
    "url": "https://arxiv.org/abs/2311.03552",
    "authors": [
      "Jiadi Zhang",
      "Xiao Li",
      "Mohammad Reza Amini",
      "Ilya Kolmanovsky",
      "Munechika Tsutsumi",
      "Hayato Nakada"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.03555",
    "title": "Model Predictive Control of Diesel Engine Emissions Based on Neural  Network Modeling",
    "abstract": "This paper addresses the control of diesel engine nitrogen oxides (NOx) and Soot emissions through the application of Model Predictive Control (MPC). The developments described in the paper are based on a high-fidelity model of the engine airpath and torque response in GT-Power, which is extended with a feedforward neural network (FNN)-based model of engine out (feedgas) emissions identified from experimental engine data to enable the controller co-simulation and performance verification. A Recurrent Neural Network (RNN) is then identified for use as a prediction model in the implementation of a nonlinear economic MPC that adjusts intake manifold pressure and EGR rate set-points to the inner loop airpath controller as well as the engine fueling rate. Based on GT-Power engine model and FNN emissions model, the closed-loop simulations of the control system and the plant model, over different driving cycles, demonstrate the capability to shape engine out emissions response by adjusting weights and constraints in economic MPC formulation. ",
    "url": "https://arxiv.org/abs/2311.03555",
    "authors": [
      "Jiadi Zhang",
      "Xiao Li",
      "Ilya Kolmanovsky",
      "Munechika Tsutsumi",
      "Hayato Nakada"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.03562",
    "title": "From Bits to Insights: Exploring Network Traffic, Traffic Matrices, and  Heavy-Tailed Data",
    "abstract": "With the Internet a central component of modern society, entire industries and fields have developed both in support and against cybersecurity. For cyber operators to best understand their networks, they must conduct detailed traffic analyses. A growing recognition is the ubiquity of heavy-tailed characteristics in network traffic. However, a thorough analysis of cybersecurity programs suggests little statistics educational background, worsened by the observation that college-level statistics courses largely lack heavy-tailed content, meaning cyber operators are both ill-equipped to appropriately analyze their network traffic and unable to easily access resources that could help. In response, we developed an accessible Jupyter Notebook module that guides individuals--regardless of statistical background--through traffic matrix creation, heavy-tailed data identification, data visualization, and distribution fitting. Such content empowers cyber operators, improving analyses and design. ",
    "url": "https://arxiv.org/abs/2311.03562",
    "authors": [
      "Christopher Howard",
      "Hayden Jananthan",
      "Jeremy Kepner"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.03565",
    "title": "MIRAGE: Multi-Binary Image Risk Assessment with Attack Graph Employment",
    "abstract": "Attackers can exploit known vulnerabilities to infiltrate a device's firmware and the communication between firmware binaries, in order to pass between them. To improve cybersecurity, organizations must identify and mitigate the risks of the firmware they use. An attack graph (AG) can be used to assess and visually display firmware's risks by organizing the identified vulnerabilities into attack paths composed of sequences of actions attackers may perform to compromise firmware images. In this paper, we utilize AGs for firmware risk assessment. We propose MIRAGE (Multi-binary Image Risk Assessment with Attack Graph Employment), a framework for identifying potential attack vectors and vulnerable interactions between firmware binaries; MIRAGE accomplishes this by generating AGs for firmware inter-binary communication. The use cases of the proposed firmware AG generation framework include the identification of risky external interactions, supply chain risk assessment, and security analysis with digital twins. To evaluate the MIRAGE framework, we collected a dataset of 703 firmware images. We also propose a model for examining the risks of firmware binaries, demonstrate the model's implementation on the dataset of firmware images, and list the riskiest binaries. ",
    "url": "https://arxiv.org/abs/2311.03565",
    "authors": [
      "David Tayouri",
      "Telem Nachum",
      "Asaf Shabtai"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.03566",
    "title": "Measuring Adversarial Datasets",
    "abstract": "In the era of widespread public use of AI systems across various domains, ensuring adversarial robustness has become increasingly vital to maintain safety and prevent undesirable errors. Researchers have curated various adversarial datasets (through perturbations) for capturing model deficiencies that cannot be revealed in standard benchmark datasets. However, little is known about how these adversarial examples differ from the original data points, and there is still no methodology to measure the intended and unintended consequences of those adversarial transformations. In this research, we conducted a systematic survey of existing quantifiable metrics that describe text instances in NLP tasks, among dimensions of difficulty, diversity, and disagreement. We selected several current adversarial effect datasets and compared the distributions between the original and their adversarial counterparts. The results provide valuable insights into what makes these datasets more challenging from a metrics perspective and whether they align with underlying assumptions. ",
    "url": "https://arxiv.org/abs/2311.03566",
    "authors": [
      "Yuanchen Bai",
      "Raoyi Huang",
      "Vijay Viswanathan",
      "Tzu-Sheng Kuo",
      "Tongshuang Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2311.03570",
    "title": "Cal-DETR: Calibrated Detection Transformer",
    "abstract": "Albeit revealing impressive predictive performance for several computer vision tasks, deep neural networks (DNNs) are prone to making overconfident predictions. This limits the adoption and wider utilization of DNNs in many safety-critical applications. There have been recent efforts toward calibrating DNNs, however, almost all of them focus on the classification task. Surprisingly, very little attention has been devoted to calibrating modern DNN-based object detectors, especially detection transformers, which have recently demonstrated promising detection performance and are influential in many decision-making systems. In this work, we address the problem by proposing a mechanism for calibrated detection transformers (Cal-DETR), particularly for Deformable-DETR, UP-DETR and DINO. We pursue the train-time calibration route and make the following contributions. First, we propose a simple yet effective approach for quantifying uncertainty in transformer-based object detectors. Second, we develop an uncertainty-guided logit modulation mechanism that leverages the uncertainty to modulate the class logits. Third, we develop a logit mixing approach that acts as a regularizer with detection-specific losses and is also complementary to the uncertainty-guided logit modulation technique to further improve the calibration performance. Lastly, we conduct extensive experiments across three in-domain and four out-domain scenarios. Results corroborate the effectiveness of Cal-DETR against the competing train-time methods in calibrating both in-domain and out-domain detections while maintaining or even improving the detection performance. Our codebase and pre-trained models can be accessed at \\url{https://github.com/akhtarvision/cal-detr}. ",
    "url": "https://arxiv.org/abs/2311.03570",
    "authors": [
      "Muhammad Akhtar Munir",
      "Salman Khan",
      "Muhammad Haris Khan",
      "Mohsen Ali",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.03572",
    "title": "Unsupervised Region-Growing Network for Object Segmentation in  Atmospheric Turbulence",
    "abstract": "In this paper, we present a two-stage unsupervised foreground object segmentation network tailored for dynamic scenes affected by atmospheric turbulence. In the first stage, we utilize averaged optical flow from turbulence-distorted image sequences to feed a novel region-growing algorithm, crafting preliminary masks for each moving object in the video. In the second stage, we employ a U-Net architecture with consistency and grouping losses to further refine these masks optimizing their spatio-temporal alignment. Our approach does not require labeled training data and works across varied turbulence strengths for long-range video. Furthermore, we release the first moving object segmentation dataset of turbulence-affected videos, complete with manually annotated ground truth masks. Our method, evaluated on this new dataset, demonstrates superior segmentation accuracy and robustness as compared to current state-of-the-art unsupervised methods. ",
    "url": "https://arxiv.org/abs/2311.03572",
    "authors": [
      "Dehao Qin",
      "Ripon Saha",
      "Suren Jayasuriya",
      "Jinwei Ye",
      "Nianyi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.03583",
    "title": "Finding Increasingly Large Extremal Graphs with AlphaZero and Tabu  Search",
    "abstract": "This work studies a central extremal graph theory problem inspired by a 1975 conjecture of Erd\\H{o}s, which aims to find graphs with a given size (number of nodes) that maximize the number of edges without having 3- or 4-cycles. We formulate this problem as a sequential decision-making problem and compare AlphaZero, a neural network-guided tree search, with tabu search, a heuristic local search method. Using either method, by introducing a curriculum -- jump-starting the search for larger graphs using good graphs found at smaller sizes -- we improve the state-of-the-art lower bounds for several sizes. We also propose a flexible graph-generation environment and a permutation-invariant network architecture for learning to search in the space of graphs. ",
    "url": "https://arxiv.org/abs/2311.03583",
    "authors": [
      "Abbas Mehrabian",
      "Ankit Anand",
      "Hyunjik Kim",
      "Nicolas Sonnerat",
      "Matej Balog",
      "Gheorghe Comanici",
      "Tudor Berariu",
      "Andrew Lee",
      "Anian Ruoss",
      "Anna Bulanova",
      "Daniel Toyama",
      "Sam Blackwell",
      "Bernardino Romera Paredes",
      "Petar Veli\u010dkovi\u0107",
      "Laurent Orseau",
      "Joonkyung Lee",
      "Anurag Murty Naredla",
      "Doina Precup",
      "Adam Zsolt Wagner"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.03606",
    "title": "Multimodal Stress Detection Using Facial Landmarks and Biometric Signals",
    "abstract": "The development of various sensing technologies is improving measurements of stress and the well-being of individuals. Although progress has been made with single signal modalities like wearables and facial emotion recognition, integrating multiple modalities provides a more comprehensive understanding of stress, given that stress manifests differently across different people. Multi-modal learning aims to capitalize on the strength of each modality rather than relying on a single signal. Given the complexity of processing and integrating high-dimensional data from limited subjects, more research is needed. Numerous research efforts have been focused on fusing stress and emotion signals at an early stage, e.g., feature-level fusion using basic machine learning methods and 1D-CNN Methods. This paper proposes a multi-modal learning approach for stress detection that integrates facial landmarks and biometric signals. We test this multi-modal integration with various early-fusion and late-fusion techniques to integrate the 1D-CNN model from biometric signals and 2-D CNN using facial landmarks. We evaluate these architectures using a rigorous test of models' generalizability using the leave-one-subject-out mechanism, i.e., all samples related to a single subject are left out to train the model. Our findings show that late-fusion achieved 94.39\\% accuracy, and early-fusion surpassed it with a 98.38\\% accuracy rate. This research contributes valuable insights into enhancing stress detection through a multi-modal approach. The proposed research offers important knowledge in improving stress detection using a multi-modal approach. ",
    "url": "https://arxiv.org/abs/2311.03606",
    "authors": [
      "Majid Hosseini",
      "Morteza Bodaghi",
      "Ravi Teja Bhupatiraju",
      "Anthony Maida",
      "Raju Gottumukkala"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.03620",
    "title": "FusionViT: Hierarchical 3D Object Detection via LiDAR-Camera Vision  Transformer Fusion",
    "abstract": "For 3D object detection, both camera and lidar have been demonstrated to be useful sensory devices for providing complementary information about the same scenery with data representations in different modalities, e.g., 2D RGB image vs 3D point cloud. An effective representation learning and fusion of such multi-modal sensor data is necessary and critical for better 3D object detection performance. To solve the problem, in this paper, we will introduce a novel vision transformer-based 3D object detection model, namely FusionViT. Different from the existing 3D object detection approaches, FusionViT is a pure-ViT based framework, which adopts a hierarchical architecture by extending the transformer model to embed both images and point clouds for effective representation learning. Such multi-modal data embedding representations will be further fused together via a fusion vision transformer model prior to feeding the learned features to the object detection head for both detection and localization of the 3D objects in the input scenery. To demonstrate the effectiveness of FusionViT, extensive experiments have been done on real-world traffic object detection benchmark datasets KITTI and Waymo Open. Notably, our FusionViT model can achieve state-of-the-art performance and outperforms not only the existing baseline methods that merely rely on camera images or lidar point clouds, but also the latest multi-modal image-point cloud deep fusion approaches. ",
    "url": "https://arxiv.org/abs/2311.03620",
    "authors": [
      "Xinhao Xiang",
      "Jiawei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.03626",
    "title": "PINNs-TF2: Fast and User-Friendly Physics-Informed Neural Networks in  TensorFlow V2",
    "abstract": "Physics-informed neural networks (PINNs) have gained prominence for their capability to tackle supervised learning tasks that conform to physical laws, notably nonlinear partial differential equations (PDEs). This paper presents \"PINNs-TF2\", a Python package built on the TensorFlow V2 framework. It not only accelerates PINNs implementation but also simplifies user interactions by abstracting complex PDE challenges. We underscore the pivotal role of compilers in PINNs, highlighting their ability to boost performance by up to 119x. Across eight diverse examples, our package, integrated with XLA compilers, demonstrated its flexibility and achieved an average speed-up of 18.12 times over TensorFlow V1. Moreover, a real-world case study is implemented to underscore the compilers' potential to handle many trainable parameters and large batch sizes. For community engagement and future enhancements, our package's source code is openly available at: https://github.com/rezaakb/pinns-tf2. ",
    "url": "https://arxiv.org/abs/2311.03626",
    "authors": [
      "Reza Akbarian Bafghi",
      "Maziar Raissi"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2311.03629",
    "title": "Random Field Augmentations for Self-Supervised Representation Learning",
    "abstract": "Self-supervised representation learning is heavily dependent on data augmentations to specify the invariances encoded in representations. Previous work has shown that applying diverse data augmentations is crucial to downstream performance, but augmentation techniques remain under-explored. In this work, we propose a new family of local transformations based on Gaussian random fields to generate image augmentations for self-supervised representation learning. These transformations generalize the well-established affine and color transformations (translation, rotation, color jitter, etc.) and greatly increase the space of augmentations by allowing transformation parameter values to vary from pixel to pixel. The parameters are treated as continuous functions of spatial coordinates, and modeled as independent Gaussian random fields. Empirical results show the effectiveness of the new transformations for self-supervised representation learning. Specifically, we achieve a 1.7% top-1 accuracy improvement over baseline on ImageNet downstream classification, and a 3.6% improvement on out-of-distribution iNaturalist downstream classification. However, due to the flexibility of the new transformations, learned representations are sensitive to hyperparameters. While mild transformations improve representations, we observe that strong transformations can degrade the structure of an image, indicating that balancing the diversity and strength of augmentations is important for improving generalization of learned representations. ",
    "url": "https://arxiv.org/abs/2311.03629",
    "authors": [
      "Philip Andrew Mansfield",
      "Arash Afkanpour",
      "Warren Richard Morningstar",
      "Karan Singhal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.03630",
    "title": "Counterfactual Data Augmentation with Contrastive Learning",
    "abstract": "Statistical disparity between distinct treatment groups is one of the most significant challenges for estimating Conditional Average Treatment Effects (CATE). To address this, we introduce a model-agnostic data augmentation method that imputes the counterfactual outcomes for a selected subset of individuals. Specifically, we utilize contrastive learning to learn a representation space and a similarity measure such that in the learned representation space close individuals identified by the learned similarity measure have similar potential outcomes. This property ensures reliable imputation of counterfactual outcomes for the individuals with close neighbors from the alternative treatment group. By augmenting the original dataset with these reliable imputations, we can effectively reduce the discrepancy between different treatment groups, while inducing minimal imputation error. The augmented dataset is subsequently employed to train CATE estimation models. Theoretical analysis and experimental studies on synthetic and semi-synthetic benchmarks demonstrate that our method achieves significant improvements in both performance and robustness to overfitting across state-of-the-art models. ",
    "url": "https://arxiv.org/abs/2311.03630",
    "authors": [
      "Ahmed Aloui",
      "Juncheng Dong",
      "Cat P. Le",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.03631",
    "title": "Novel data structures for label based queries specifically efficient for  billion+ property graph networks using Kinetica-Graph",
    "abstract": "This paper discusses a novel data structure that efficiently implements label based graph queries particularly for very large graphs. The major issues in large graph databases is the memory foot-print of label based property associations to graph entities and subsequent query speeds. To this end, unlike the available graph databases, that use key-value pairs using map like associative containers, we have devised a novel data structure that is superior in its memory foot-print as well as its fast search characteristics without any compromise on the number of labels that can be associated to graph nodes and edges. We will demonstrate the power of this novel unconventional data structure over billion plus graphs within the context. ",
    "url": "https://arxiv.org/abs/2311.03631",
    "authors": [
      "Bilge Kaan Karamete",
      "Eli Glaser"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2311.03650",
    "title": "Image Generation and Learning Strategy for Deep Document Forgery  Detection",
    "abstract": "In recent years, document processing has flourished and brought numerous benefits. However, there has been a significant rise in reported cases of forged document images. Specifically, recent advancements in deep neural network (DNN) methods for generative tasks may amplify the threat of document forgery. Traditional approaches for forged document images created by prevalent copy-move methods are unsuitable against those created by DNN-based methods, as we have verified. To address this issue, we construct a training dataset of document forgery images, named FD-VIED, by emulating possible attacks, such as text addition, removal, and replacement with recent DNN-methods. Additionally, we introduce an effective pre-training approach through self-supervised learning with both natural images and document images. In our experiments, we demonstrate that our approach enhances detection performance. ",
    "url": "https://arxiv.org/abs/2311.03650",
    "authors": [
      "Yamato Okamoto",
      "Osada Genki",
      "Iu Yahiro",
      "Rintaro Hasegawa",
      "Peifei Zhu",
      "Hirokatsu Kataoka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.03651",
    "title": "SeRO: Self-Supervised Reinforcement Learning for Recovery from  Out-of-Distribution Situations",
    "abstract": "Robotic agents trained using reinforcement learning have the problem of taking unreliable actions in an out-of-distribution (OOD) state. Agents can easily become OOD in real-world environments because it is almost impossible for them to visit and learn the entire state space during training. Unfortunately, unreliable actions do not ensure that agents perform their original tasks successfully. Therefore, agents should be able to recognize whether they are in OOD states and learn how to return to the learned state distribution rather than continue to take unreliable actions. In this study, we propose a novel method for retraining agents to recover from OOD situations in a self-supervised manner when they fall into OOD states. Our in-depth experimental results demonstrate that our method substantially improves the agent's ability to recover from OOD situations in terms of sample efficiency and restoration of the performance for the original tasks. Moreover, we show that our method can retrain the agent to recover from OOD situations even when in-distribution states are difficult to visit through exploration. ",
    "url": "https://arxiv.org/abs/2311.03651",
    "authors": [
      "Chan Kim",
      "Jaekyung Cho",
      "Christophe Bobda",
      "Seung-Woo Seo",
      "Seong-Woo Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.03653",
    "title": "On the Performance of LoRa Empowered Communication for Wireless Body  Area Networks",
    "abstract": "To remotely monitor the physiological status of the human body, long range (LoRa) communication has been considered as an eminently suitable candidate for wireless body area networks (WBANs). Typically, a Rayleigh-lognormal fading channel is encountered by the LoRa links of the WBAN. In this context, we characterize the performance of the LoRa system in WBAN scenarios with an emphasis on the physical (PHY) layer and medium access control (MAC) layer in the face of Rayleigh-lognormal fading channels and the same spreading factor interference. Specifically, closed-form approximate bit error probability (BEP) expressions are derived for the LoRa system. The results show that increasing the SF and reducing the interference efficiently mitigate the shadowing effects. Moreover, in the quest for the most suitable MAC protocol for LoRa based WBANs, three MAC protocols are critically appraised, namely the pure ALOHA, slotted ALOHA, and carrier-sense multiple access. The coverage probability, energy efficiency, throughput, and system delay of the three MAC protocols are analyzed in Rayleigh-lognormal fading channel. Furthermore, the performance of the equal-interval-based and equal-area-based schemes is analyzed to guide the choice of the SF. Our simulation results confirm the accuracy of the mathematical analysis and provide some useful insights for the future design of LoRa based WBANs. ",
    "url": "https://arxiv.org/abs/2311.03653",
    "authors": [
      "Minling Zhang",
      "Guofa Cai",
      "Zhiping Xu",
      "Jiguang He",
      "Markku Juntti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.03658",
    "title": "The Linear Representation Hypothesis and the Geometry of Large Language  Models",
    "abstract": "Informally, the 'linear representation hypothesis' is the idea that high-level concepts are represented linearly as directions in some representation space. In this paper, we address two closely related questions: What does \"linear representation\" actually mean? And, how do we make sense of geometric notions (e.g., cosine similarity or projection) in the representation space? To answer these, we use the language of counterfactuals to give two formalizations of \"linear representation\", one in the output (word) representation space, and one in the input (sentence) space. We then prove these connect to linear probing and model steering, respectively. To make sense of geometric notions, we use the formalization to identify a particular (non-Euclidean) inner product that respects language structure in a sense we make precise. Using this causal inner product, we show how to unify all notions of linear representation. In particular, this allows the construction of probes and steering vectors using counterfactual pairs. Experiments with LLaMA-2 demonstrate the existence of linear representations of concepts, the connection to interpretation and control, and the fundamental role of the choice of inner product. ",
    "url": "https://arxiv.org/abs/2311.03658",
    "authors": [
      "Kiho Park",
      "Yo Joong Choe",
      "Victor Veitch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.03659",
    "title": "GNN-Based Beamforming for Sum-Rate Maximization in MU-MISO Networks",
    "abstract": "The advantages of graph neural networks (GNNs) in leveraging the graph topology of wireless networks have drawn increasing attentions. This paper studies the GNN-based learning approach for the sum-rate maximization in multiple-user multiple-input single-output (MU-MISO) networks subject to the users' individual data rate requirements and the power budget of the base station. By modeling the MU-MISO network as a graph, a GNN-based architecture named CRGAT is proposed to directly map the channel state information to the beamforming vectors. The attention-enabled aggregation and the residual-assisted combination are adopted to enhance the learning capability and avoid the oversmoothing issue. Furthermore, a novel activation function is proposed for the constraint due to the limited power budget at the base station. The CRGAT is trained in an unsupervised learning manner with two proposed loss functions. An evaluation method is proposed for the learning-based approach, based on which the effectiveness of the proposed CRGAT is validated in comparison with several convex optimization and learning based approaches. Numerical results are provided to reveal the advantages of the CRGAT including the millisecond-level response with limited optimality performance loss, the scalability to different number of users and power budgets, and the adaptability to different system settings. ",
    "url": "https://arxiv.org/abs/2311.03659",
    "authors": [
      "Yuhang Li",
      "Yang Lu",
      "Bo Ai",
      "Octavia A. Dobre",
      "Zhiguo Ding",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.03661",
    "title": "Graph Neural Networks for Power Grid Operational Risk Assessment",
    "abstract": "In this article, the utility of graph neural network (GNN) surrogates for Monte Carlo (MC) sampling-based risk quantification in daily operations of power grid is investigated. The MC simulation process necessitates solving a large number of optimal power flow (OPF) problems corresponding to the sample values of stochastic grid variables (power demand and renewable generation), which is computationally prohibitive. Computationally inexpensive surrogates of the OPF problem provide an attractive alternative for expedited MC simulation. GNN surrogates are especially suitable due to their superior ability to handle graph-structured data. Therefore, GNN surrogates of OPF problem are trained using supervised learning. They are then used to obtain Monte Carlo (MC) samples of the quantities of interest (operating reserve, transmission line flow) given the (hours-ahead) probabilistic wind generation and load forecast. The utility of GNN surrogates is evaluated by comparing OPF-based and GNN-based grid reliability and risk for IEEE Case118 synthetic grid. It is shown that the GNN surrogates are sufficiently accurate for predicting the (bus-level, branch-level and system-level) grid state and enable fast as well as accurate operational risk quantification for power grids. The article thus develops various tools for fast reliability and risk quantification for real-world power grids using GNNs. ",
    "url": "https://arxiv.org/abs/2311.03661",
    "authors": [
      "Yadong Zhang",
      "Pranav M Karve",
      "Sankaran Mahadevan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.03665",
    "title": "Faster Algorithms for Cycle Hitting Problems on Disk Graphs",
    "abstract": "In this paper, we consider three hitting problems on a disk intersection graph: Triangle Hitting Set, Feedback Vertex Set, and Odd Cycle Transversal. Given a disk intersection graph $G$, our goal is to compute a set of vertices hitting all triangles, all cycles, or all odd cycles, respectively. Our algorithms run in time $2^{\\tilde O(k^{4/5})}n^{O(1)}$, $2^{\\tilde O(k^{9/10})}n^{O(1)}$, and $2^{\\tilde O(k^{19/20})}n^{O(1)}$, respectively, where $n$ denotes the number of vertices of $G$. These do not require a geometric representation of a disk graph. If a geometric representation of a disk graph is given as input, we can solve these problems more efficiently. In this way, we improve the algorithms for those three problem by Lokshtanov et al. [SODA 2022]. ",
    "url": "https://arxiv.org/abs/2311.03665",
    "authors": [
      "Shinwoo An",
      "Kyungjin Cho",
      "Eunjin Oh"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2311.03679",
    "title": "Unsupervised convolutional neural network fusion approach for change  detection in remote sensing images",
    "abstract": "With the rapid development of deep learning, a variety of change detection methods based on deep learning have emerged in recent years. However, these methods usually require a large number of training samples to train the network model, so it is very expensive. In this paper, we introduce a completely unsupervised shallow convolutional neural network (USCNN) fusion approach for change detection. Firstly, the bi-temporal images are transformed into different feature spaces by using convolution kernels of different sizes to extract multi-scale information of the images. Secondly, the output features of bi-temporal images at the same convolution kernels are subtracted to obtain the corresponding difference images, and the difference feature images at the same scale are fused into one feature image by using 1 * 1 convolution layer. Finally, the output features of different scales are concatenated and a 1 * 1 convolution layer is used to fuse the multi-scale information of the image. The model parameters are obtained by a redesigned sparse function. Our model has three features: the entire training process is conducted in an unsupervised manner, the network architecture is shallow, and the objective function is sparse. Thus, it can be seen as a kind of lightweight network model. Experimental results on four real remote sensing datasets indicate the feasibility and effectiveness of the proposed approach. ",
    "url": "https://arxiv.org/abs/2311.03679",
    "authors": [
      "Weidong Yan",
      "Pei Yan",
      "Li Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2311.03682",
    "title": "Incentive Design for Eco-driving in Urban Transportation Networks",
    "abstract": "Eco-driving emerges as a cost-effective and efficient strategy to mitigate greenhouse gas emissions in urban transportation networks. Acknowledging the persuasive influence of incentives in shaping driver behavior, this paper presents the `eco-planner,' a digital platform devised to promote eco-driving practices in urban transportation. At the outset of their trips, users provide the platform with their trip details and travel time preferences, enabling the eco-planner to formulate personalized eco-driving recommendations and corresponding incentives, while adhering to its budgetary constraints. Upon trip completion, incentives are transferred to users who comply with the recommendations and effectively reduce their emissions. By comparing our proposed incentive mechanism with a baseline scheme that offers uniform incentives to all users, we demonstrate that our approach achieves superior emission reductions and increased user compliance with a smaller budget. ",
    "url": "https://arxiv.org/abs/2311.03682",
    "authors": [
      "M. Umar B. Niazi",
      "Jung-Hoon Cho",
      "Munther A. Dahleh",
      "Roy Dong",
      "Cathy Wu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Social and Information Networks (cs.SI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2311.03683",
    "title": "Preventing Arbitrarily High Confidence on Far-Away Data in  Point-Estimated Discriminative Neural Networks",
    "abstract": "Discriminatively trained, deterministic neural networks are the de facto choice for classification problems. However, even though they achieve state-of-the-art results on in-domain test sets, they tend to be overconfident on out-of-distribution (OOD) data. For instance, ReLU networks -- a popular class of neural network architectures -- have been shown to almost always yield high confidence predictions when the test data are far away from the training set, even when they are trained with OOD data. We overcome this problem by adding a term to the output of the neural network that corresponds to the logit of an extra class, that we design to dominate the logits of the original classes as we move away from the training data.This technique provably prevents arbitrarily high confidence on far-away test data while maintaining a simple discriminative point-estimate training. Evaluation on various benchmarks demonstrates strong performance against competitive baselines on both far-away and realistic OOD data. ",
    "url": "https://arxiv.org/abs/2311.03683",
    "authors": [
      "Ahmad Rashid",
      "Serena Hacker",
      "Guojun Zhang",
      "Agustinus Kristiadi",
      "Pascal Poupart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.03696",
    "title": "Bilingual Corpus Mining and Multistage Fine-Tuning for Improving Machine  Translation of Lecture Transcripts",
    "abstract": "Lecture transcript translation helps learners understand online courses, however, building a high-quality lecture machine translation system lacks publicly available parallel corpora. To address this, we examine a framework for parallel corpus mining, which provides a quick and effective way to mine a parallel corpus from publicly available lectures on Coursera. To create the parallel corpora, we propose a dynamic programming based sentence alignment algorithm which leverages the cosine similarity of machine-translated sentences. The sentence alignment F1 score reaches 96%, which is higher than using the BERTScore, LASER, or sentBERT methods. For both English--Japanese and English--Chinese lecture translations, we extracted parallel corpora of approximately 50,000 lines and created development and test sets through manual filtering for benchmarking translation performance. Through machine translation experiments, we show that the mined corpora enhance the quality of lecture transcript translation when used in conjunction with out-of-domain parallel corpora via multistage fine-tuning. Furthermore, this study also suggests guidelines for gathering and cleaning corpora, mining parallel sentences, cleaning noise in the mined data, and creating high-quality evaluation splits. For the sake of reproducibility, we have released the corpora as well as the code to create them. The dataset is available at https://github.com/shyyhs/CourseraParallelCorpusMining. ",
    "url": "https://arxiv.org/abs/2311.03696",
    "authors": [
      "Haiyue Song",
      "Raj Dabre",
      "Chenhui Chu",
      "Atsushi Fujita",
      "Sadao Kurohashi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.03701",
    "title": "Hypothesis Network Planned Exploration for Rapid Meta-Reinforcement  Learning Adaptation",
    "abstract": "Meta Reinforcement Learning (Meta RL) trains agents that adapt to fast-changing environments and tasks. Current strategies often lose adaption efficiency due to the passive nature of model exploration, causing delayed understanding of new transition dynamics. This results in particularly fast-evolving tasks being impossible to solve. We propose a novel approach, Hypothesis Network Planned Exploration (HyPE), that integrates an active and planned exploration process via the hypothesis network to optimize adaptation speed. HyPE uses a generative hypothesis network to form potential models of state transition dynamics, then eliminates incorrect models through strategically devised experiments. Evaluated on a symbolic version of the Alchemy game, HyPE outpaces baseline methods in adaptation speed and model accuracy, validating its potential in enhancing reinforcement learning adaptation in rapidly evolving settings. ",
    "url": "https://arxiv.org/abs/2311.03701",
    "authors": [
      "Maxwell Joseph Jacobson",
      "Yexiang Xue"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.03707",
    "title": "The NeurIPS 2022 Neural MMO Challenge: A Massively Multiagent  Competition with Specialization and Trade",
    "abstract": "In this paper, we present the results of the NeurIPS-2022 Neural MMO Challenge, which attracted 500 participants and received over 1,600 submissions. Like the previous IJCAI-2022 Neural MMO Challenge, it involved agents from 16 populations surviving in procedurally generated worlds by collecting resources and defeating opponents. This year's competition runs on the latest v1.6 Neural MMO, which introduces new equipment, combat, trading, and a better scoring system. These elements combine to pose additional robustness and generalization challenges not present in previous competitions. This paper summarizes the design and results of the challenge, explores the potential of this environment as a benchmark for learning methods, and presents some practical reinforcement learning training approaches for complex tasks with sparse rewards. Additionally, we have open-sourced our baselines, including environment wrappers, benchmarks, and visualization tools for future research. ",
    "url": "https://arxiv.org/abs/2311.03707",
    "authors": [
      "Enhong Liu",
      "Joseph Suarez",
      "Chenhui You",
      "Bo Wu",
      "Bingcheng Chen",
      "Jun Hu",
      "Jiaxin Chen",
      "Xiaolong Zhu",
      "Clare Zhu",
      "Julian Togelius",
      "Sharada Mohanty",
      "Weijun Hong",
      "Rui Du",
      "Yibing Zhang",
      "Qinwen Wang",
      "Xinhang Li",
      "Zheng Yuan",
      "Xiang Li",
      "Yuejia Huang",
      "Kun Zhang",
      "Hanhui Yang",
      "Shiqi Tang",
      "Phillip Isola"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2311.03725",
    "title": "DeepInspect: An AI-Powered Defect Detection for Manufacturing Industries",
    "abstract": "Utilizing Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Generative Adversarial Networks (GANs), our system introduces an innovative approach to defect detection in manufacturing. This technology excels in precisely identifying faults by extracting intricate details from product photographs, utilizing RNNs to detect evolving errors and generating synthetic defect data to bolster the model's robustness and adaptability across various defect scenarios. The project leverages a deep learning framework to automate real-time flaw detection in the manufacturing process. It harnesses extensive datasets of annotated images to discern complex defect patterns. This integrated system seamlessly fits into production workflows, thereby boosting efficiency and elevating product quality. As a result, it reduces waste and operational costs, ultimately enhancing market competitiveness. ",
    "url": "https://arxiv.org/abs/2311.03725",
    "authors": [
      "Arti Kumbhar",
      "Amruta Chougale",
      "Priya Lokhande",
      "Saloni Navaghane",
      "Aditi Burud",
      "Saee Nimbalkar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2311.03733",
    "title": "Improved weight initialization for deep and narrow feedforward neural  network",
    "abstract": "Appropriate weight initialization settings, along with the ReLU activation function, have been a cornerstone of modern deep learning, making it possible to train and deploy highly effective and efficient neural network models across diverse artificial intelligence. The problem of dying ReLU, where ReLU neurons become inactive and yield zero output, presents a significant challenge in the training of deep neural networks with ReLU activation function. Theoretical research and various methods have been introduced to address the problem. However, even with these methods and research, training remains challenging for extremely deep and narrow feedforward networks with ReLU activation function. In this paper, we propose a new weight initialization method to address this issue. We prove the properties of the proposed initial weight matrix and demonstrate how these properties facilitate the effective propagation of signal vectors. Through a series of experiments and comparisons with existing methods, we demonstrate the effectiveness of the new initialization method. ",
    "url": "https://arxiv.org/abs/2311.03733",
    "authors": [
      "Hyunwoo Lee",
      "Yunho Kim",
      "Seungyeop Yang",
      "Hayoung Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.03736",
    "title": "Neural MMO 2.0: A Massively Multi-task Addition to Massively Multi-agent  Learning",
    "abstract": "Neural MMO 2.0 is a massively multi-agent environment for reinforcement learning research. The key feature of this new version is a flexible task system that allows users to define a broad range of objectives and reward signals. We challenge researchers to train agents capable of generalizing to tasks, maps, and opponents never seen during training. Neural MMO features procedurally generated maps with 128 agents in the standard setting and support for up to. Version 2.0 is a complete rewrite of its predecessor with three-fold improved performance and compatibility with CleanRL. We release the platform as free and open-source software with comprehensive documentation available at neuralmmo.github.io and an active community Discord. To spark initial research on this new platform, we are concurrently running a competition at NeurIPS 2023. ",
    "url": "https://arxiv.org/abs/2311.03736",
    "authors": [
      "Joseph Su\u00e1rez",
      "Phillip Isola",
      "Kyoung Whan Choe",
      "David Bloomin",
      "Hao Xiang Li",
      "Nikhil Pinnaparaju",
      "Nishaanth Kanna",
      "Daniel Scott",
      "Ryan Sullivan",
      "Rose S. Shuman",
      "Lucas de Alc\u00e2ntara",
      "Herbie Bradley",
      "Louis Castricato",
      "Kirsty You",
      "Yuhao Jiang",
      "Qimai Li",
      "Jiaxin Chen",
      "Xiaolong Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2311.03742",
    "title": "3DifFusionDet: Diffusion Model for 3D Object Detection with Robust  LiDAR-Camera Fusion",
    "abstract": "Good 3D object detection performance from LiDAR-Camera sensors demands seamless feature alignment and fusion strategies. We propose the 3DifFusionDet framework in this paper, which structures 3D object detection as a denoising diffusion process from noisy 3D boxes to target boxes. In this framework, ground truth boxes diffuse in a random distribution for training, and the model learns to reverse the noising process. During inference, the model gradually refines a set of boxes that were generated at random to the outcomes. Under the feature align strategy, the progressive refinement method could make a significant contribution to robust LiDAR-Camera fusion. The iterative refinement process could also demonstrate great adaptability by applying the framework to various detecting circumstances where varying levels of accuracy and speed are required. Extensive experiments on KITTI, a benchmark for real-world traffic object identification, revealed that 3DifFusionDet is able to perform favorably in comparison to earlier, well-respected detectors. ",
    "url": "https://arxiv.org/abs/2311.03742",
    "authors": [
      "Xinhao Xiang",
      "Simon Dr\u00e4ger",
      "Jiawei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.03746",
    "title": "Enhanced physics-informed neural networks with domain scaling and  residual correction methods for multi-frequency elliptic problems",
    "abstract": "In this paper, neural network approximation methods are developed for elliptic partial differential equations with multi-frequency solutions. Neural network work approximation methods have advantages over classical approaches in that they can be applied without much concerns on the form of the differential equations or the shape or dimension of the problem domain. When applied to problems with multi-frequency solutions, the performance and accuracy of neural network approximation methods are strongly affected by the contrast of the high- and low-frequency parts in the solutions. To address this issue, domain scaling and residual correction methods are proposed. The efficiency and accuracy of the proposed methods are demonstrated for multi-frequency model problems. ",
    "url": "https://arxiv.org/abs/2311.03746",
    "authors": [
      "Deok-Kyu Jang",
      "Hyea Hyun Kim",
      "Kyungsoo Kim"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2311.03747",
    "title": "SBCFormer: Lightweight Network Capable of Full-size ImageNet  Classification at 1 FPS on Single Board Computers",
    "abstract": "Computer vision has become increasingly prevalent in solving real-world problems across diverse domains, including smart agriculture, fishery, and livestock management. These applications may not require processing many image frames per second, leading practitioners to use single board computers (SBCs). Although many lightweight networks have been developed for mobile/edge devices, they primarily target smartphones with more powerful processors and not SBCs with the low-end CPUs. This paper introduces a CNN-ViT hybrid network called SBCFormer, which achieves high accuracy and fast computation on such low-end CPUs. The hardware constraints of these CPUs make the Transformer's attention mechanism preferable to convolution. However, using attention on low-end CPUs presents a challenge: high-resolution internal feature maps demand excessive computational resources, but reducing their resolution results in the loss of local image details. SBCFormer introduces an architectural design to address this issue. As a result, SBCFormer achieves the highest trade-off between accuracy and speed on a Raspberry Pi 4 Model B with an ARM-Cortex A72 CPU. For the first time, it achieves an ImageNet-1K top-1 accuracy of around 80% at a speed of 1.0 frame/sec on the SBC. Code is available at https://github.com/xyongLu/SBCFormer. ",
    "url": "https://arxiv.org/abs/2311.03747",
    "authors": [
      "Xiangyong Lu",
      "Masanori Suganuma",
      "Takayuki Okatani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.03756",
    "title": "Learning Decentralized Traffic Signal Controllers with Multi-Agent Graph  Reinforcement Learning",
    "abstract": "This paper considers optimal traffic signal control in smart cities, which has been taken as a complex networked system control problem. Given the interacting dynamics among traffic lights and road networks, attaining controller adaptivity and scalability stands out as a primary challenge. Capturing the spatial-temporal correlation among traffic lights under the framework of Multi-Agent Reinforcement Learning (MARL) is a promising solution. Nevertheless, existing MARL algorithms ignore effective information aggregation which is fundamental for improving the learning capacity of decentralized agents. In this paper, we design a new decentralized control architecture with improved environmental observability to capture the spatial-temporal correlation. Specifically, we first develop a topology-aware information aggregation strategy to extract correlation-related information from unstructured data gathered in the road network. Particularly, we transfer the road network topology into a graph shift operator by forming a diffusion process on the topology, which subsequently facilitates the construction of graph signals. A diffusion convolution module is developed, forming a new MARL algorithm, which endows agents with the capabilities of graph learning. Extensive experiments based on both synthetic and real-world datasets verify that our proposal outperforms existing decentralized algorithms. ",
    "url": "https://arxiv.org/abs/2311.03756",
    "authors": [
      "Yao Zhang",
      "Zhiwen Yu",
      "Jun Zhang",
      "Liang Wang",
      "Tom H. Luan",
      "Bin Guo",
      "Chau Yuen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.03762",
    "title": "Image change detection with only a few samples",
    "abstract": "This paper considers image change detection with only a small number of samples, which is a significant problem in terms of a few annotations available. A major impediment of image change detection task is the lack of large annotated datasets covering a wide variety of scenes. Change detection models trained on insufficient datasets have shown poor generalization capability. To address the poor generalization issue, we propose using simple image processing methods for generating synthetic but informative datasets, and design an early fusion network based on object detection which could outperform the siamese neural network. Our key insight is that the synthetic data enables the trained model to have good generalization ability for various scenarios. We compare the model trained on the synthetic data with that on the real-world data captured from a challenging dataset, CDNet, using six different test sets. The results demonstrate that the synthetic data is informative enough to achieve higher generalization ability than the insufficient real-world data. Besides, the experiment shows that utilizing a few (often tens of) samples to fine-tune the model trained on the synthetic data will achieve excellent results. ",
    "url": "https://arxiv.org/abs/2311.03762",
    "authors": [
      "Ke Liu",
      "Zhaoyi Song",
      "Haoyue Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.03780",
    "title": "Ensembling Textual and Structure-Based Models for Knowledge Graph  Completion",
    "abstract": "We consider two popular approaches to Knowledge Graph Completion (KGC): textual models that rely on textual entity descriptions, and structure-based models that exploit the connectivity structure of the Knowledge Graph (KG). Preliminary experiments show that these approaches have complementary strengths: structure-based models perform well when the gold answer is easily reachable from the query head in the KG, while textual models exploit descriptions to give good performance even when the gold answer is not reachable. In response, we explore ensembling as a way of combining the best of both approaches. We propose a novel method for learning query-dependent ensemble weights by using the distributions of scores assigned by individual models to all candidate entities. Our ensemble baseline achieves state-of-the-art results on three standard KGC datasets, with up to 6.8 pt MRR and 8.3 pt Hits@1 gains over best individual models. ",
    "url": "https://arxiv.org/abs/2311.03780",
    "authors": [
      "Ananjan Nandi",
      "Navdeep Kaur",
      "Parag Singla",
      "Mausam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.03783",
    "title": "Scene-Driven Multimodal Knowledge Graph Construction for Embodied AI",
    "abstract": "Embodied AI is one of the most popular studies in artificial intelligence and robotics, which can effectively improve the intelligence of real-world agents (i.e. robots) serving human beings. Scene knowledge is important for an agent to understand the surroundings and make correct decisions in the varied open world. Currently, knowledge base for embodied tasks is missing and most existing work use general knowledge base or pre-trained models to enhance the intelligence of an agent. For conventional knowledge base, it is sparse, insufficient in capacity and cost in data collection. For pre-trained models, they face the uncertainty of knowledge and hard maintenance. To overcome the challenges of scene knowledge, we propose a scene-driven multimodal knowledge graph (Scene-MMKG) construction method combining conventional knowledge engineering and large language models. A unified scene knowledge injection framework is introduced for knowledge representation. To evaluate the advantages of our proposed method, we instantiate Scene-MMKG considering typical indoor robotic functionalities (Manipulation and Mobility), named ManipMob-MMKG. Comparisons in characteristics indicate our instantiated ManipMob-MMKG has broad superiority in data-collection efficiency and knowledge quality. Experimental results on typical embodied tasks show that knowledge-enhanced methods using our instantiated ManipMob-MMKG can improve the performance obviously without re-designing model structures complexly. Our project can be found at https://sites.google.com/view/manipmob-mmkg ",
    "url": "https://arxiv.org/abs/2311.03783",
    "authors": [
      "Song Yaoxian",
      "Sun Penglei",
      "Liu Haoyu",
      "Li Zhixu",
      "Song Wei",
      "Xiao Yanghua",
      "Zhou Xiaofang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Symbolic Computation (cs.SC)"
    ]
  },
  {
    "id": "arXiv:2311.03784",
    "title": "UP-NeRF: Unconstrained Pose-Prior-Free Neural Radiance Fields",
    "abstract": "Neural Radiance Field (NeRF) has enabled novel view synthesis with high fidelity given images and camera poses. Subsequent works even succeeded in eliminating the necessity of pose priors by jointly optimizing NeRF and camera pose. However, these works are limited to relatively simple settings such as photometrically consistent and occluder-free image collections or a sequence of images from a video. So they have difficulty handling unconstrained images with varying illumination and transient occluders. In this paper, we propose \\textbf{UP-NeRF} (\\textbf{U}nconstrained \\textbf{P}ose-prior-free \\textbf{Ne}ural \\textbf{R}adiance \\textbf{F}ields) to optimize NeRF with unconstrained image collections without camera pose prior. We tackle these challenges with surrogate tasks that optimize color-insensitive feature fields and a separate module for transient occluders to block their influence on pose estimation. In addition, we introduce a candidate head to enable more robust pose estimation and transient-aware depth supervision to minimize the effect of incorrect prior. Our experiments verify the superior performance of our method compared to the baselines including BARF and its variants in a challenging internet photo collection, \\textit{Phototourism} dataset. The code of UP-NeRF is available at \\url{https://github.com/mlvlab/UP-NeRF}. ",
    "url": "https://arxiv.org/abs/2311.03784",
    "authors": [
      "Injae Kim",
      "Minhyuk Choi",
      "Hyunwoo J. Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.03785",
    "title": "Self-MI: Efficient Multimodal Fusion via Self-Supervised Multi-Task  Learning with Auxiliary Mutual Information Maximization",
    "abstract": "Multimodal representation learning poses significant challenges in capturing informative and distinct features from multiple modalities. Existing methods often struggle to exploit the unique characteristics of each modality due to unified multimodal annotations. In this study, we propose Self-MI in the self-supervised learning fashion, which also leverage Contrastive Predictive Coding (CPC) as an auxiliary technique to maximize the Mutual Information (MI) between unimodal input pairs and the multimodal fusion result with unimodal inputs. Moreover, we design a label generation module, $ULG_{MI}$ for short, that enables us to create meaningful and informative labels for each modality in a self-supervised manner. By maximizing the Mutual Information, we encourage better alignment between the multimodal fusion and the individual modalities, facilitating improved multimodal fusion. Extensive experiments on three benchmark datasets including CMU-MOSI, CMU-MOSEI, and SIMS, demonstrate the effectiveness of Self-MI in enhancing the multimodal fusion task. ",
    "url": "https://arxiv.org/abs/2311.03785",
    "authors": [
      "Cam-Van Thi Nguyen",
      "Ngoc-Hoa Thi Nguyen",
      "Duc-Trong Le",
      "Quang-Thuy Ha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2311.03788",
    "title": "Language Representation Projection: Can We Transfer Factual Knowledge  across Languages in Multilingual Language Models?",
    "abstract": "Multilingual pretrained language models serve as repositories of multilingual factual knowledge. Nevertheless, a substantial performance gap of factual knowledge probing exists between high-resource languages and low-resource languages, suggesting limited implicit factual knowledge transfer across languages in multilingual pretrained language models. This paper investigates the feasibility of explicitly transferring relatively rich factual knowledge from English to non-English languages. To accomplish this, we propose two parameter-free $\\textbf{L}$anguage $\\textbf{R}$epresentation $\\textbf{P}$rojection modules (LRP2). The first module converts non-English representations into English-like equivalents, while the second module reverts English-like representations back into representations of the corresponding non-English language. Experimental results on the mLAMA dataset demonstrate that LRP2 significantly improves factual knowledge retrieval accuracy and facilitates knowledge transferability across diverse non-English languages. We further investigate the working mechanism of LRP2 from the perspectives of representation space and cross-lingual knowledge neuron. ",
    "url": "https://arxiv.org/abs/2311.03788",
    "authors": [
      "Shaoyang Xu",
      "Junzhuo Li",
      "Deyi Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.03863",
    "title": "An Explainable Framework for Machine learning-Based Reactive Power  Optimization of Distribution Network",
    "abstract": "To reduce the heavy computational burden of reactive power optimization of distribution networks, machine learning models are receiving increasing attention. However, most machine learning models (e.g., neural networks) are usually considered as black boxes, making it challenging for power system operators to identify and comprehend potential biases or errors in the decision-making process of machine learning models. To address this issue, an explainable machine-learning framework is proposed to optimize the reactive power in distribution networks. Firstly, a Shapley additive explanation framework is presented to measure the contribution of each input feature to the solution of reactive power optimizations generated from machine learning models. Secondly, a model-agnostic approximation method is developed to estimate Shapley values, so as to avoid the heavy computational burden associated with direct calculations of Shapley values. The simulation results show that the proposed explainable framework can accurately explain the solution of the machine learning model-based reactive power optimization by using visual analytics, from both global and instance perspectives. Moreover, the proposed explainable framework is model-agnostic, and thus applicable to various models (e.g., neural networks). ",
    "url": "https://arxiv.org/abs/2311.03863",
    "authors": [
      "Wenlong Liao",
      "Benjamin Sch\u00e4fer",
      "Dalin Qin",
      "Gonghao Zhang",
      "Zhixian Wang",
      "Zhe Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.03865",
    "title": "FD-MIA: Efficient Attacks on Fairness-enhanced Models",
    "abstract": "Previous studies have developed fairness methods for biased models that exhibit discriminatory behaviors towards specific subgroups. While these models have shown promise in achieving fair predictions, recent research has identified their potential vulnerability to score-based membership inference attacks (MIAs). In these attacks, adversaries can infer whether a particular data sample was used during training by analyzing the model's prediction scores. However, our investigations reveal that these score-based MIAs are ineffective when targeting fairness-enhanced models in binary classifications. The attack models trained to launch the MIAs degrade into simplistic threshold models, resulting in lower attack performance. Meanwhile, we observe that fairness methods often lead to prediction performance degradation for the majority subgroups of the training data. This raises the barrier to successful attacks and widens the prediction gaps between member and non-member data. Building upon these insights, we propose an efficient MIA method against fairness-enhanced models based on fairness discrepancy results (FD-MIA). It leverages the difference in the predictions from both the original and fairness-enhanced models and exploits the observed prediction gaps as attack clues. We also explore potential strategies for mitigating privacy leakages. Extensive experiments validate our findings and demonstrate the efficacy of the proposed method. ",
    "url": "https://arxiv.org/abs/2311.03865",
    "authors": [
      "Huan Tian",
      "Guangsheng Zhang",
      "Bo Liu",
      "Tianqing Zhu",
      "Ming Ding",
      "Wanlei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.03866",
    "title": "SCONE-GAN: Semantic Contrastive learning-based Generative Adversarial  Network for an end-to-end image translation",
    "abstract": "SCONE-GAN presents an end-to-end image translation, which is shown to be effective for learning to generate realistic and diverse scenery images. Most current image-to-image translation approaches are devised as two mappings: a translation from the source to target domain and another to represent its inverse. While successful in many applications, these approaches may suffer from generating trivial solutions with limited diversity. That is because these methods learn more frequent associations rather than the scene structures. To mitigate the problem, we propose SCONE-GAN that utilises graph convolutional networks to learn the objects dependencies, maintain the image structure and preserve its semantics while transferring images into the target domain. For more realistic and diverse image generation we introduce style reference image. We enforce the model to maximize the mutual information between the style image and output. The proposed method explicitly maximizes the mutual information between the related patches, thus encouraging the generator to produce more diverse images. We validate the proposed algorithm for image-to-image translation and stylizing outdoor images. Both qualitative and quantitative results demonstrate the effectiveness of our approach on four dataset. ",
    "url": "https://arxiv.org/abs/2311.03866",
    "authors": [
      "Iman Abbasnejad",
      "Fabio Zambetta",
      "Flora Salim",
      "Timothy Wiley",
      "Jeffrey Chan",
      "Russell Gallagher",
      "Ehsan Abbasnejad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.03897",
    "title": "Temporal Graph Representation Learning with Adaptive Augmentation  Contrastive",
    "abstract": "Temporal graph representation learning aims to generate low-dimensional dynamic node embeddings to capture temporal information as well as structural and property information. Current representation learning methods for temporal networks often focus on capturing fine-grained information, which may lead to the model capturing random noise instead of essential semantic information. While graph contrastive learning has shown promise in dealing with noise, it only applies to static graphs or snapshots and may not be suitable for handling time-dependent noise. To alleviate the above challenge, we propose a novel Temporal Graph representation learning with Adaptive augmentation Contrastive (TGAC) model. The adaptive augmentation on the temporal graph is made by combining prior knowledge with temporal information, and the contrastive objective function is constructed by defining the augmented inter-view contrast and intra-view contrast. To complement TGAC, we propose three adaptive augmentation strategies that modify topological features to reduce noise from the network. Our extensive experiments on various real networks demonstrate that the proposed model outperforms other temporal graph representation learning methods. ",
    "url": "https://arxiv.org/abs/2311.03897",
    "authors": [
      "Hongjiang Chen",
      "Pengfei Jiao",
      "Huijun Tang",
      "Huaming Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.03904",
    "title": "RobustMat: Neural Diffusion for Street Landmark Patch Matching under  Challenging Environments",
    "abstract": "For autonomous vehicles (AVs), visual perception techniques based on sensors like cameras play crucial roles in information acquisition and processing. In various computer perception tasks for AVs, it may be helpful to match landmark patches taken by an onboard camera with other landmark patches captured at a different time or saved in a street scene image database. To perform matching under challenging driving environments caused by changing seasons, weather, and illumination, we utilize the spatial neighborhood information of each patch. We propose an approach, named RobustMat, which derives its robustness to perturbations from neural differential equations. A convolutional neural ODE diffusion module is used to learn the feature representation for the landmark patches. A graph neural PDE diffusion module then aggregates information from neighboring landmark patches in the street scene. Finally, feature similarity learning outputs the final matching score. Our approach is evaluated on several street scene datasets and demonstrated to achieve state-of-the-art matching results under environmental perturbations. ",
    "url": "https://arxiv.org/abs/2311.03904",
    "authors": [
      "Rui She",
      "Qiyu Kang",
      "Sijie Wang",
      "Yuan-Rui Yang",
      "Kai Zhao",
      "Yang Song",
      "Wee Peng Tay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.03919",
    "title": "Unveiling the Invisible: Detection and Evaluation of Prototype Pollution  Gadgets with Dynamic Taint Analysis",
    "abstract": "For better or worse, JavaScript is the cornerstone of modern Web. Prototype-based languages like JavaScript are susceptible to prototype pollution vulnerabilities, enabling an attacker to inject arbitrary properties into an object's prototype. The attacker can subsequently capitalize on the injected properties by executing otherwise benign pieces of code, so-called gadgets, that perform security-sensitive operations. The success of an attack largely depends on the presence of gadgets, leading to high-profile exploits such as privilege escalation and arbitrary code execution (ACE). This paper proposes Dasty, the first semi-automated pipeline to help developers identify gadgets in their applications' software supply chain. Dasty targets server-side Node.js applications and relies on an enhancement of dynamic taint analysis which we implement with the dynamic AST-level instrumentation. Moreover, Dasty provides support for visualization of code flows with an IDE, thus facilitating the subsequent manual analysis for building proof-of-concept exploits. To illustrate the danger of gadgets, we use Dasty in a study of the most dependent-upon NPM packages to analyze the presence of gadgets leading to ACE. Dasty identifies 1,269 server-side packages, of which 631 have code flows that may reach dangerous sinks. We manually prioritize and verify the candidate flows to build proof-of-concept exploits for 49 NPM packages, including popular packages such as ejs, nodemailer and workerpool. To investigate how Dasty integrates with existing tools to find end-to-end exploits, we conduct an in-depth analysis of a popular data visualization dashboard to find one high-severity CVE-2023-31415 leading to remote code execution. For the first time, our results systematically demonstrate the dangers of server-side gadgets and call for further research to solve the problem. ",
    "url": "https://arxiv.org/abs/2311.03919",
    "authors": [
      "Mikhail Shcherbakov",
      "Paul Moosbrugger",
      "Musard Balliu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2311.03923",
    "title": "Hardware Aware Evolutionary Neural Architecture Search using  Representation Similarity Metric",
    "abstract": "Hardware-aware Neural Architecture Search (HW-NAS) is a technique used to automatically design the architecture of a neural network for a specific task and target hardware. However, evaluating the performance of candidate architectures is a key challenge in HW-NAS, as it requires significant computational resources. To address this challenge, we propose an efficient hardware-aware evolution-based NAS approach called HW-EvRSNAS. Our approach re-frames the neural architecture search problem as finding an architecture with performance similar to that of a reference model for a target hardware, while adhering to a cost constraint for that hardware. This is achieved through a representation similarity metric known as Representation Mutual Information (RMI) employed as a proxy performance evaluator. It measures the mutual information between the hidden layer representations of a reference model and those of sampled architectures using a single training batch. We also use a penalty term that penalizes the search process in proportion to how far an architecture's hardware cost is from the desired hardware cost threshold. This resulted in a significantly reduced search time compared to the literature that reached up to 8000x speedups resulting in lower CO2 emissions. The proposed approach is evaluated on two different search spaces while using lower computational resources. Furthermore, our approach is thoroughly examined on six different edge devices under various hardware cost constraints. ",
    "url": "https://arxiv.org/abs/2311.03923",
    "authors": [
      "Nilotpal Sinha",
      "Abd El Rahman Shabayek",
      "Anis Kacem",
      "Peyman Rostami",
      "Carl Shneider",
      "Djamila Aouada"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.03932",
    "title": "TempoGRAPHer: Aggregation Based Temporal Graph Exploration",
    "abstract": "Graphs offer a generic abstraction for modeling entities, and the interactions and relationships between them. Most real world graphs, such as social and cooperation networks evolve over time, and exploring their evolution may reveal important information. In this paper, we present TempoGRAPHer, a system for visualizing and analyzing the evolution of a temporal attributed graph. TempoGRAPHer supports both temporal and attribute aggregation. It also allows graph exploration by identifying periods of significant growth, shrinkage, or stability. Temporal exploration is supported by two complementary strategies, namely skyline and interaction-based exploration. Skyline-based exploration provides insights on the overall trends in the evolution, while interaction-based exploration offers a closer look at specific parts of the graph evolution history where significant changes appeared. We showcase the usefulness of TempoGRAPHer in understanding graph evolution by presenting a detailed scenario that explores the evolution of a contact network between primary school students. ",
    "url": "https://arxiv.org/abs/2311.03932",
    "authors": [
      "Evangelia Tsoukanara",
      "Georgia Koloniari",
      "Evaggelia Pitoura"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.03963",
    "title": "An Expectation-Realization Model for Metaphor Detection",
    "abstract": "We propose a metaphor detection architecture that is structured around two main modules: an expectation component that estimates representations of literal word expectations given a context, and a realization component that computes representations of actual word meanings in context. The overall architecture is trained to learn expectation-realization (ER) patterns that characterize metaphorical uses of words. When evaluated on three metaphor datasets for within distribution, out of distribution, and novel metaphor generalization, the proposed method is shown to obtain results that are competitive or better than state-of-the art. Further increases in metaphor detection accuracy are obtained through ensembling of ER models. ",
    "url": "https://arxiv.org/abs/2311.03963",
    "authors": [
      "Oseremen O. Uduehi",
      "Razvan C. Bunescu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.03964",
    "title": "Enhancing Multimodal Compositional Reasoning of Visual Language Models  with Generative Negative Mining",
    "abstract": "Contemporary large-scale visual language models (VLMs) exhibit strong representation capacities, making them ubiquitous for enhancing image and text understanding tasks. They are often trained in a contrastive manner on a large and diverse corpus of images and corresponding text captions scraped from the internet. Despite this, VLMs often struggle with compositional reasoning tasks which require a fine-grained understanding of the complex interactions of objects and their attributes. This failure can be attributed to two main factors: 1) Contrastive approaches have traditionally focused on mining negative examples from existing datasets. However, the mined negative examples might not be difficult for the model to discriminate from the positive. An alternative to mining would be negative sample generation 2) But existing generative approaches primarily focus on generating hard negative texts associated with a given image. Mining in the other direction, i.e., generating negative image samples associated with a given text has been ignored. To overcome both these limitations, we propose a framework that not only mines in both directions but also generates challenging negative samples in both modalities, i.e., images and texts. Leveraging these generative hard negative samples, we significantly enhance VLMs' performance in tasks involving multimodal compositional reasoning. Our code and dataset are released at https://ugorsahin.github.io/enhancing-multimodal-compositional-reasoning-of-vlm.html. ",
    "url": "https://arxiv.org/abs/2311.03964",
    "authors": [
      "Ugur Sahin",
      "Hang Li",
      "Qadeer Khan",
      "Daniel Cremers",
      "Volker Tresp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.03967",
    "title": "CeCNN: Copula-enhanced convolutional neural networks in joint prediction  of refraction error and axial length based on ultra-widefield fundus images",
    "abstract": "Ultra-widefield (UWF) fundus images are replacing traditional fundus images in screening, detection, prediction, and treatment of complications related to myopia because their much broader visual range is advantageous for highly myopic eyes. Spherical equivalent (SE) is extensively used as the main myopia outcome measure, and axial length (AL) has drawn increasing interest as an important ocular component for assessing myopia. Cutting-edge studies show that SE and AL are strongly correlated. Using the joint information from SE and AL is potentially better than using either separately. In the deep learning community, though there is research on multiple-response tasks with a 3D image biomarker, dependence among responses is only sporadically taken into consideration. Inspired by the spirit that information extracted from the data by statistical methods can improve the prediction accuracy of deep learning models, we formulate a class of multivariate response regression models with a higher-order tensor biomarker, for the bivariate tasks of regression-classification and regression-regression. Specifically, we propose a copula-enhanced convolutional neural network (CeCNN) framework that incorporates the dependence between responses through a Gaussian copula (with parameters estimated from a warm-up CNN) and uses the induced copula-likelihood loss with the backbone CNNs. We establish the statistical framework and algorithms for the aforementioned two bivariate tasks. We show that the CeCNN has better prediction accuracy after adding the dependency information to the backbone models. The modeling and the proposed CeCNN algorithm are applicable beyond the UWF scenario and can be effective with other backbones beyond ResNet and LeNet. ",
    "url": "https://arxiv.org/abs/2311.03967",
    "authors": [
      "Chong Zhong",
      "Yang Li",
      "Danjuan Yang",
      "Meiyan Li",
      "Xingyao Zhou",
      "Bo Fu",
      "Catherine C. Liu",
      "A.H. Welsh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.03969",
    "title": "Factoring Hate Speech: A New Annotation Framework to Study Hate Speech  in Social Media",
    "abstract": "In this work we propose a novel annotation scheme which factors hate speech into five separate discursive categories. To evaluate our scheme, we construct a corpus of over 2.9M Twitter posts containing hateful expressions directed at Jews, and annotate a sample dataset of 1,050 tweets. We present a statistical analysis of the annotated dataset as well as discuss annotation examples, and conclude by discussing promising directions for future work. ",
    "url": "https://arxiv.org/abs/2311.03969",
    "authors": [
      "Gal Ron",
      "Effi Levi",
      "Odelia Oshri",
      "Shaul R. Shenhav"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.03975",
    "title": "Adaptive 3D Geometry-based Stochastic Channel Prediction for 3D DL  Selection",
    "abstract": "This paper addresses the challenges of mobile user requirements in shadowing and multi-fading environments, focusing on the Downlink (DL) radio node selection based on Uplink (UL) channel estimation. One of the key issues tackled in this research is the prediction performance in scenarios where estimated channels are integrated. An adaptive deep learning approach is proposed to improve performance, offering a compelling alternative to traditional interpolation techniques for air-to-ground link selection on demand. Moreover, our study considers a 3D channel model, which provides a more realistic and accurate representation than 2D models, particularly in the context of 3D network node distributions. This consideration becomes crucial in addressing the complex multipath fading effects within geometric stochastic 3D 3GPP channel models in urban environments. Furthermore, our research emphasises the need for adaptive prediction mechanisms that carefully balance the trade-off between DL link forecasted frequency response accuracy and the complexity requirements associated with estimation and prediction. This paper contributes to advancing 3D radio resource management by addressing these challenges, enabling more efficient and reliable communication for energy-constrained flying network nodes in dynamic environments. ",
    "url": "https://arxiv.org/abs/2311.03975",
    "authors": [
      "Mervat Zarour",
      "Qiuheng Zhou",
      "Sergiy Melnyk",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2311.03976",
    "title": "Its All Graph To Me: Foundational Topology Models with Contrastive  Learning on Multiple Domains",
    "abstract": "Representations and embeddings of graph data have been essential in many domains of research. The principle benefit of learning such representations is that the pre-trained model can be fine-tuned on smaller datasets where data or labels are scarse. Existing models, however, are domain specific; for example a model trained on molecular graphs is fine-tuned on other molecular graphs. This means that in many application cases the choice of pre-trained model can be arbitrary, and novel domains may lack an appropriate pre-trained model. This is of particular issue where data is scarse, precluding traditional supervised methods. In this work we use adversarial contrastive learning to present a \\method, a model pre-trained on many graph domains. We train the model only on topologies but include node labels in evaluation. We evaluate the efficacy of its learnt representations on various downstream tasks. Against baseline models pre-trained on single domains, as well as un-trained models and non-transferred models, we show that performance is equal or better using our single model. This includes when node labels are used in evaluation, where performance is consistently superior to single-domain or non-pre-trained models. ",
    "url": "https://arxiv.org/abs/2311.03976",
    "authors": [
      "Alex O. Davies",
      "Riku W. Green",
      "Nirav S. Ajmeri",
      "Telmo M. Silva Filho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.03985",
    "title": "Quadrotor Experimental Dynamic Identification with Comprehensive NARX  Neural Networks",
    "abstract": "This research paper delves into the field of quadrotor dynamics, which are famous by their nonlinearity, under-actuation, and multivariable nature. Due to the critical need for precise modeling and control in this context we explore the capabilities of NARX (Nonlinear AutoRegressive with eXogenous inputs) Neural Networks (NN). These networks are employed for comprehensive and accurate modeling of quadrotor behaviors, take advantage of their ability to capture the hided dynamics. Our research encompasses a rigorous experimental setup, including the use of PRBS (Pseudo-random binary sequence) signals for excitation, to validate the efficacy of NARX-NN in predicting and controlling quadrotor dynamics. The results reveal exceptional accuracy, with fit percentages exceeding 99% on both estimation and validation data. Moreover, we identified the quadrotor dynamics using different NARX NN structures, including the NARX model with a sigmoid NN, NARX feedforward NN, and cascade NN. In summary, our study positions NARX-NN as a transformative tool for quadrotor applications, ranging from autonomous navigation to aerial robotics, thanks to their accurate and comprehensive modeling capabilities. ",
    "url": "https://arxiv.org/abs/2311.03985",
    "authors": [
      "Khaled Telli",
      "Okba Kraa",
      "Yassine Himeur",
      "Mohamed Boumehraz",
      "Shadi Atalla",
      "Wathiq Mansoor",
      "Abdelmalik Ouamane"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2311.03989",
    "title": "Learned Causal Method Prediction",
    "abstract": "For a given causal question, it is important to efficiently decide which causal inference method to use for a given dataset. This is challenging because causal methods typically rely on complex and difficult-to-verify assumptions, and cross-validation is not applicable since ground truth causal quantities are unobserved.In this work, we propose CAusal Method Predictor (CAMP), a framework for predicting the best method for a given dataset. To this end, we generate datasets from a diverse set of synthetic causal models, score the candidate methods, and train a model to directly predict the highest-scoring method for that dataset. Next, by formulating a self-supervised pre-training objective centered on dataset assumptions relevant for causal inference, we significantly reduce the need for costly labeled data and enhance training efficiency. Our strategy learns to map implicit dataset properties to the best method in a data-driven manner. In our experiments, we focus on method prediction for causal discovery. CAMP outperforms selecting any individual candidate method and demonstrates promising generalization to unseen semi-synthetic and real-world benchmarks. ",
    "url": "https://arxiv.org/abs/2311.03989",
    "authors": [
      "Shantanu Gupta",
      "Cheng Zhang",
      "Agrin Hilmkil"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2311.03996",
    "title": "An Initialization Schema for Neuronal Networks on Tabular Data",
    "abstract": "Nowadays, many modern applications require heterogeneous tabular data, which is still a challenging task in terms of regression and classification. Many approaches have been proposed to adapt neural networks for this task, but still, boosting and bagging of decision trees are the best-performing methods for this task. In this paper, we show that a binomial initialized neural network can be used effectively on tabular data. The proposed approach shows a simple but effective approach for initializing the first hidden layer in neural networks. We also show that this initializing schema can be used to jointly train ensembles by adding gradient masking to batch entries and using the binomial initialization for the last layer in a neural network. For this purpose, we modified the hinge binary loss and the soft max loss to make them applicable for joint ensemble training. We evaluate our approach on multiple public datasets and showcase the improved performance compared to other neural network-based approaches. In addition, we discuss the limitations and possible further research of our approach for improving the applicability of neural networks to tabular data. Link: https://es-cloud.cs.uni-tuebingen.de/d/8e2ab8c3fdd444e1a135/?p=%2FInitializationNeuronalNetworksTabularData&mode=list ",
    "url": "https://arxiv.org/abs/2311.03996",
    "authors": [
      "Wolfgang Fuhl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.04007",
    "title": "The Energy Prediction Smart-Meter Dataset: Analysis of Previous  Competitions and Beyond",
    "abstract": "This paper presents the real-world smart-meter dataset and offers an analysis of solutions derived from the Energy Prediction Technical Challenges, focusing primarily on two key competitions: the IEEE Computational Intelligence Society (IEEE-CIS) Technical Challenge on Energy Prediction from Smart Meter data in 2020 (named EP) and its follow-up challenge at the IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) in 2021 (named as XEP). These competitions focus on accurate energy consumption forecasting and the importance of interpretability in understanding the underlying factors. The challenge aims to predict monthly and yearly estimated consumption for households, addressing the accurate billing problem with limited historical smart meter data. The dataset comprises 3,248 smart meters, with varying data availability ranging from a minimum of one month to a year. This paper delves into the challenges, solutions and analysing issues related to the provided real-world smart meter data, developing accurate predictions at the household level, and introducing evaluation criteria for assessing interpretability. Additionally, this paper discusses aspects beyond the competitions: opportunities for energy disaggregation and pattern detection applications at the household level, significance of communicating energy-driven factors for optimised billing, and emphasising the importance of responsible AI and data privacy considerations. These aspects provide insights into the broader implications and potential advancements in energy consumption prediction. Overall, these competitions provide a dataset for residential energy research and serve as a catalyst for exploring accurate forecasting, enhancing interpretability, and driving progress towards the discussion of various aspects such as energy disaggregation, demand response programs or behavioural interventions. ",
    "url": "https://arxiv.org/abs/2311.04007",
    "authors": [
      "Direnc Pekaslan",
      "Jose Maria Alonso-Moral",
      "Kasun Bandara",
      "Christoph Bergmeir",
      "Juan Bernabe-Moreno",
      "Robert Eigenmann",
      "Nils Einecke",
      "Selvi Ergen",
      "Rakshitha Godahewa",
      "Hansika Hewamalage",
      "Jesus Lago",
      "Steffen Limmer",
      "Sven Rebhan",
      "Boris Rabinovich",
      "Dilini Rajapasksha",
      "Heda Song",
      "Christian Wagner",
      "Wenlong Wu",
      "Luis Magdalena",
      "Isaac Triguero"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.04009",
    "title": "AGNES: Abstraction-guided Framework for Deep Neural Networks Security",
    "abstract": "Deep Neural Networks (DNNs) are becoming widespread, particularly in safety-critical areas. One prominent application is image recognition in autonomous driving, where the correct classification of objects, such as traffic signs, is essential for safe driving. Unfortunately, DNNs are prone to backdoors, meaning that they concentrate on attributes of the image that should be irrelevant for their correct classification. Backdoors are integrated into a DNN during training, either with malicious intent (such as a manipulated training process, because of which a yellow sticker always leads to a traffic sign being recognised as a stop sign) or unintentional (such as a rural background leading to any traffic sign being recognised as animal crossing, because of biased training data). In this paper, we introduce AGNES, a tool to detect backdoors in DNNs for image recognition. We discuss the principle approach on which AGNES is based. Afterwards, we show that our tool performs better than many state-of-the-art methods for multiple relevant case studies. ",
    "url": "https://arxiv.org/abs/2311.04009",
    "authors": [
      "Akshay Dhonthi",
      "Marcello Eiermann",
      "Ernst Moritz Hahn",
      "Vahid Hashemi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.04037",
    "title": "Causal Discovery Under Local Privacy",
    "abstract": "Differential privacy is a widely adopted framework designed to safeguard the sensitive information of data providers within a data set. It is based on the application of controlled noise at the interface between the server that stores and processes the data, and the data consumers. Local differential privacy is a variant that allows data providers to apply the privatization mechanism themselves on their data individually. Therefore it provides protection also in contexts in which the server, or even the data collector, cannot be trusted. The introduction of noise, however, inevitably affects the utility of the data, particularly by distorting the correlations between individual data components. This distortion can prove detrimental to tasks such as causal discovery. In this paper, we consider various well-known locally differentially private mechanisms and compare the trade-off between the privacy they provide, and the accuracy of the causal structure produced by algorithms for causal learning when applied to data obfuscated by these mechanisms. Our analysis yields valuable insights for selecting appropriate local differentially private protocols for causal discovery tasks. We foresee that our findings will aid researchers and practitioners in conducting locally private causal discovery. ",
    "url": "https://arxiv.org/abs/2311.04037",
    "authors": [
      "R\u016bta Binkyt\u0117",
      "Carlos Pinz\u00f3n",
      "Szilvia Lesty\u00e1n",
      "Kangsoo Jung",
      "H\u00e9ber H. Arcolezi",
      "Catuscia Palamidessi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2311.04040",
    "title": "Data exploitation: multi-task learning of object detection and semantic  segmentation on partially annotated data",
    "abstract": "Multi-task partially annotated data where each data point is annotated for only a single task are potentially helpful for data scarcity if a network can leverage the inter-task relationship. In this paper, we study the joint learning of object detection and semantic segmentation, the two most popular vision problems, from multi-task data with partial annotations. Extensive experiments are performed to evaluate each task performance and explore their complementarity when a multi-task network cannot optimize both tasks simultaneously. We propose employing knowledge distillation to leverage joint-task optimization. The experimental results show favorable results for multi-task learning and knowledge distillation over single-task learning and even full supervision scenario. All code and data splits are available at https://github.com/lhoangan/multas ",
    "url": "https://arxiv.org/abs/2311.04040",
    "authors": [
      "Ho\u00e0ng-\u00c2n L\u00ea",
      "Minh-Tan Pham"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.04044",
    "title": "P-Bench: A Multi-level Privacy Evaluation Benchmark for Language Models",
    "abstract": "The rapid development of language models (LMs) brings unprecedented accessibility and usage for both models and users. On the one hand, powerful LMs, trained with massive textual data, achieve state-of-the-art performance over numerous downstream NLP tasks. On the other hand, more and more attention is paid to unrestricted model accesses that may bring malicious privacy risks of data leakage. To address these issues, many recent works propose privacy-preserving language models (PPLMs) with differential privacy (DP). Unfortunately, different DP implementations make it challenging for a fair comparison among existing PPLMs. In this paper, we present P-Bench, a multi-perspective privacy evaluation benchmark to empirically and intuitively quantify the privacy leakage of LMs. Instead of only protecting and measuring the privacy of protected data with DP parameters, P-Bench sheds light on the neglected inference data privacy during actual usage. P-Bench first clearly defines multi-faceted privacy objectives during private fine-tuning. Then, P-Bench constructs a unified pipeline to perform private fine-tuning. Lastly, P-Bench performs existing privacy attacks on LMs with pre-defined privacy objectives as the empirical evaluation results. The empirical attack results are used to fairly and intuitively evaluate the privacy leakage of various PPLMs. We conduct extensive experiments on three datasets of GLUE for mainstream LMs. ",
    "url": "https://arxiv.org/abs/2311.04044",
    "authors": [
      "Haoran Li",
      "Dadi Guo",
      "Donghao Li",
      "Wei Fan",
      "Qi Hu",
      "Xin Liu",
      "Chunkit Chan",
      "Duanyi Yao",
      "Yangqiu Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.04056",
    "title": "Multi-View Causal Representation Learning with Partial Observability",
    "abstract": "We present a unified framework for studying the identifiability of representations learned from simultaneously observed views, such as different data modalities. We allow a partially observed setting in which each view constitutes a nonlinear mixture of a subset of underlying latent variables, which can be causally related. We prove that the information shared across all subsets of any number of views can be learned up to a smooth bijection using contrastive learning and a single encoder per view. We also provide graphical criteria indicating which latent variables can be identified through a simple set of rules, which we refer to as identifiability algebra. Our general framework and theoretical results unify and extend several previous works on multi-view nonlinear ICA, disentanglement, and causal representation learning. We experimentally validate our claims on numerical, image, and multi-modal data sets. Further, we demonstrate that the performance of prior methods is recovered in different special cases of our setup. Overall, we find that access to multiple partial views enables us to identify a more fine-grained representation, under the generally milder assumption of partial observability. ",
    "url": "https://arxiv.org/abs/2311.04056",
    "authors": [
      "Dingling Yao",
      "Danru Xu",
      "S\u00e9bastien Lachapelle",
      "Sara Magliacane",
      "Perouz Taslakian",
      "Georg Martius",
      "Julius von K\u00fcgelgen",
      "Francesco Locatello"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.04058",
    "title": "mmFUSION: Multimodal Fusion for 3D Objects Detection",
    "abstract": "Multi-sensor fusion is essential for accurate 3D object detection in self-driving systems. Camera and LiDAR are the most commonly used sensors, and usually, their fusion happens at the early or late stages of 3D detectors with the help of regions of interest (RoIs). On the other hand, fusion at the intermediate level is more adaptive because it does not need RoIs from modalities but is complex as the features of both modalities are presented from different points of view. In this paper, we propose a new intermediate-level multi-modal fusion (mmFUSION) approach to overcome these challenges. First, the mmFUSION uses separate encoders for each modality to compute features at a desired lower space volume. Second, these features are fused through cross-modality and multi-modality attention mechanisms proposed in mmFUSION. The mmFUSION framework preserves multi-modal information and learns to complement modalities' deficiencies through attention weights. The strong multi-modal features from the mmFUSION framework are fed to a simple 3D detection head for 3D predictions. We evaluate mmFUSION on the KITTI and NuScenes dataset where it performs better than available early, intermediate, late, and even two-stage based fusion schemes. The code with the mmdetection3D project plugin will be publicly available soon. ",
    "url": "https://arxiv.org/abs/2311.04058",
    "authors": [
      "Javed Ahmad",
      "Alessio Del Bue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.04060",
    "title": "Estimator-Coupled Reinforcement Learning for Robust Purely Tactile  In-Hand Manipulation",
    "abstract": "This paper identifies and addresses the problems with naively combining (reinforcement) learning-based controllers and state estimators for robotic in-hand manipulation. Specifically, we tackle the challenging task of purely tactile, goal-conditioned, dextrous in-hand reorientation with the hand pointing downwards. Due to the limited sensing available, many control strategies that are feasible in simulation when having full knowledge of the object's state do not allow for accurate state estimation. Hence, separately training the controller and the estimator and combining the two at test time leads to poor performance. We solve this problem by coupling the control policy to the state estimator already during training in simulation. This approach leads to more robust state estimation and overall higher performance on the task while maintaining an interpretability advantage over end-to-end policy learning. With our GPU-accelerated implementation, learning from scratch takes a median training time of only 6.5 hours on a single, low-cost GPU. In simulation experiments with the DLR-Hand II and for four significantly different object shapes, we provide an in-depth analysis of the performance of our approach. We demonstrate the successful sim2real transfer by rotating the four objects to all 24 orientations in the $\\pi/2$ discretization of SO(3), which has never been achieved for such a diverse set of shapes. Finally, our method can reorient a cube consecutively to nine goals (median), which was beyond the reach of previous methods in this challenging setting. ",
    "url": "https://arxiv.org/abs/2311.04060",
    "authors": [
      "Lennart R\u00f6stel",
      "Johannes Pitz",
      "Leon Sievers",
      "Berthold B\u00e4uml"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.04061",
    "title": "Neural Yarn-Level Appearance Model for Cloth Rendering",
    "abstract": "The realistic rendering of woven and knitted fabrics has posed significant challenges throughout many years. Previously, fiber-based micro-appearance models have achieved considerable success in attaining high levels of realism. However, rendering such models remains complex due to the intricate internal scatterings of hundreds or thousands of fibers within a yarn, requiring vast amounts of memory and time to render. In this paper, we introduce a novel framework to capture yarn-level appearance by tracing and aggregating many light paths through the underlying fiber geometry. We then employ lightweight neural networks to accurately model the aggregated BSDF, which allows for the precise modeling of a diverse array of materials while offering substantial improvements in speed and reductions in memory. Furthermore, we introduce a novel importance sampling scheme to further speed up the rate of convergence. We validate the efficacy and versatility of our framework through comparisons with preceding fiber-based shading models and by replicating various real-world fabrics. Our proposed model's enhanced performance and adaptability make it especially beneficial for film and video game production applications. ",
    "url": "https://arxiv.org/abs/2311.04061",
    "authors": [
      "Guan Yu Soh",
      "Zahra Montazeri"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2311.04069",
    "title": "LISBET: a self-supervised Transformer model for the automatic  segmentation of social behavior motifs",
    "abstract": "Social behavior, defined as the process by which individuals act and react in response to others, is crucial for the function of societies and holds profound implications for mental health. To fully grasp the intricacies of social behavior and identify potential therapeutic targets for addressing social deficits, it is essential to understand its core principles. Although machine learning algorithms have made it easier to study specific aspects of complex behavior, current methodologies tend to focus primarily on single-animal behavior. In this study, we introduce LISBET (seLf-supervIsed Social BEhavioral Transformer), a model designed to detect and segment social interactions. Our model eliminates the need for feature selection and extensive human annotation by using self-supervised learning to detect and quantify social behaviors from dynamic body parts tracking data. LISBET can be used in hypothesis-driven mode to automate behavior classification using supervised finetuning, and in discovery-driven mode to segment social behavior motifs using unsupervised learning. We found that motifs recognized using the discovery-driven approach not only closely match the human annotations but also correlate with the electrophysiological activity of dopaminergic neurons in the Ventral Tegmental Area (VTA). We hope LISBET will help the community improve our understanding of social behaviors and their neural underpinnings. ",
    "url": "https://arxiv.org/abs/2311.04069",
    "authors": [
      "Giuseppe Chindemi",
      "Benoit Girard",
      "Camilla Bellone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.04077",
    "title": "Deep Neural Network based Optimal Control of Greenhouses",
    "abstract": "Automatic control of greenhouse crop production is of great interest owing to the increasing energy and labor costs. Hierarchical Model Predictive Control (HMPC) is a multi-level control strategy for regulating environmental conditions in a greenhouse through energy-efficient operation and resource utilization. We suggest in this work to use two-level HMPC, where the upper level generates suitable reference trajectories based on day-ahead predictions. These references are tracked down in the lower level using Nonlinear Model Predictive Control (NMPC). In order to apply HMPC, a model of the crop dynamics is essential. However, the complex nature of the underlying model including discontinuities and nonlinearities results in intractable computational complexity and long sampling times. In this paper, we propose to use NMPC as a data generator to learn the tracking control policy using deep neural networks. Then, the references are tracked using the trained Deep Neural Network (DNN) to reduce the computational burden. The efficiency of our approach under real-time disturbances is demonstrated by means of a simulation study. ",
    "url": "https://arxiv.org/abs/2311.04077",
    "authors": [
      "Kiran Kumar Sathyanarayanan",
      "Philipp Sauerteig",
      "Stefan Streif"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.04095",
    "title": "Image-Pointcloud Fusion based Anomaly Detection using PD-REAL Dataset",
    "abstract": "We present PD-REAL, a novel large-scale dataset for unsupervised anomaly detection (AD) in the 3D domain. It is motivated by the fact that 2D-only representations in the AD task may fail to capture the geometric structures of anomalies due to uncertainty in lighting conditions or shooting angles. PD-REAL consists entirely of Play-Doh models for 15 object categories and focuses on the analysis of potential benefits from 3D information in a controlled environment. Specifically, objects are first created with six types of anomalies, such as dent, crack, or perforation, and then photographed under different lighting conditions to mimic real-world inspection scenarios. To demonstrate the usefulness of 3D information, we use a commercially available RealSense camera to capture RGB and depth images. Compared to the existing 3D dataset for AD tasks, the data acquisition of PD-REAL is significantly cheaper, easily scalable and easier to control variables. Extensive evaluations with state-of-the-art AD algorithms on our dataset demonstrate the benefits as well as challenges of using 3D information. Our dataset can be downloaded from https://github.com/Andy-cs008/PD-REAL ",
    "url": "https://arxiv.org/abs/2311.04095",
    "authors": [
      "Jianjian Qin",
      "Chunzhi Gu",
      "Jun Yu",
      "Chao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.04107",
    "title": "Interactive Semantic Map Representation for Skill-based Visual Object  Navigation",
    "abstract": "Visual object navigation using learning methods is one of the key tasks in mobile robotics. This paper introduces a new representation of a scene semantic map formed during the embodied agent interaction with the indoor environment. It is based on a neural network method that adjusts the weights of the segmentation model with backpropagation of the predicted fusion loss values during inference on a regular (backward) or delayed (forward) image sequence. We have implemented this representation into a full-fledged navigation approach called SkillTron, which can select robot skills from end-to-end policies based on reinforcement learning and classic map-based planning methods. The proposed approach makes it possible to form both intermediate goals for robot exploration and the final goal for object navigation. We conducted intensive experiments with the proposed approach in the Habitat environment, which showed a significant superiority in navigation quality metrics compared to state-of-the-art approaches. The developed code and used custom datasets are publicly available at github.com/AIRI-Institute/skill-fusion. ",
    "url": "https://arxiv.org/abs/2311.04107",
    "authors": [
      "Tatiana Zemskova",
      "Aleksei Staroverov",
      "Kirill Muravyev",
      "Dmitry Yudin",
      "Aleksandr Panov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.04109",
    "title": "Do Language Models Learn Semantics of Code? A Case Study in  Vulnerability Detection",
    "abstract": "Recently, pretrained language models have shown state-of-the-art performance on the vulnerability detection task. These models are pretrained on a large corpus of source code, then fine-tuned on a smaller supervised vulnerability dataset. Due to the different training objectives and the performance of the models, it is interesting to consider whether the models have learned the semantics of code relevant to vulnerability detection, namely bug semantics, and if so, how the alignment to bug semantics relates to model performance. In this paper, we analyze the models using three distinct methods: interpretability tools, attention analysis, and interaction matrix analysis. We compare the models' influential feature sets with the bug semantic features which define the causes of bugs, including buggy paths and Potentially Vulnerable Statements (PVS). We find that (1) better-performing models also aligned better with PVS, (2) the models failed to align strongly to PVS, and (3) the models failed to align at all to buggy paths. Based on our analysis, we developed two annotation methods which highlight the bug semantics inside the model's inputs. We evaluated our approach on four distinct transformer models and four vulnerability datasets and found that our annotations improved the models' performance in the majority of settings - 11 out of 16, with up to 9.57 points improvement in F1 score compared to conventional fine-tuning. We further found that with our annotations, the models aligned up to 232% better to potentially vulnerable statements. Our findings indicate that it is helpful to provide the model with information of the bug semantics, that the model can attend to it, and motivate future work in learning more complex path-based bug semantics. Our code and data are available at https://figshare.com/s/4a16a528d6874aad51a0. ",
    "url": "https://arxiv.org/abs/2311.04109",
    "authors": [
      "Benjamin Steenhoek",
      "Md Mahbubur Rahman",
      "Shaila Sharmin",
      "Wei Le"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.04133",
    "title": "Simple Bundles of Complex Networks",
    "abstract": "Complex networks can be used to represent and model an ample diversity of abstract and real-world systems and structures. A good deal of the research on these structures has focused on specific topological properties, including node degree, shortest paths, and modularity. In the present work, we develop an approach aimed at identifying and characterizing simple bundles of interconnections between pairs of nodes (source and destination) in complex networks. More specifically, simple bundles can be understood as corresponding to the bundle of paths obtained while traveling through successive neighborhoods after departing from a given source node. Because no node appears more than once along a given bundle, these structures have been said to be simple, in analogy to the concept of a simple path. In addition to describing simple bundles and providing a possible methodology for their identification, we also consider how their respective effective width can be estimated in terms of diffusion flow and exponential entropy of transition probabilities. The potential of the concepts and methods described in this work is then illustrated respectively to the characterization and analysis of model-theoretic networks, with several interesting results. ",
    "url": "https://arxiv.org/abs/2311.04133",
    "authors": [
      "Alexandre Benatti",
      "Luciano da F. Costa"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.04139",
    "title": "Modelling Sentiment Analysis: LLMs and data augmentation techniques",
    "abstract": "This paper provides different approaches for a binary sentiment classification on a small training dataset. LLMs that provided state-of-the-art results in sentiment analysis and similar domains are being used, such as BERT, RoBERTa and XLNet. ",
    "url": "https://arxiv.org/abs/2311.04139",
    "authors": [
      "Guillem Senabre Prades"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.04149",
    "title": "HyperS2V: A Framework for Structural Representation of Nodes in Hyper  Networks",
    "abstract": "In contrast to regular (simple) networks, hyper networks possess the ability to depict more complex relationships among nodes and store extensive information. Such networks are commonly found in real-world applications, such as in social interactions. Learning embedded representations for nodes involves a process that translates network structures into more simplified spaces, thereby enabling the application of machine learning approaches designed for vector data to be extended to network data. Nevertheless, there remains a need to delve into methods for learning embedded representations that prioritize structural aspects. This research introduces HyperS2V, a node embedding approach that centers on the structural similarity within hyper networks. Initially, we establish the concept of hyper-degrees to capture the structural properties of nodes within hyper networks. Subsequently, a novel function is formulated to measure the structural similarity between different hyper-degree values. Lastly, we generate structural embeddings utilizing a multi-scale random walk framework. Moreover, a series of experiments, both intrinsic and extrinsic, are performed on both toy and real networks. The results underscore the superior performance of HyperS2V in terms of both interpretability and applicability to downstream tasks. ",
    "url": "https://arxiv.org/abs/2311.04149",
    "authors": [
      "Shu Liu",
      "Cameron Lai",
      "Fujio Toriumi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.04154",
    "title": "High-fidelity 3D Reconstruction of Plants using Neural Radiance Field",
    "abstract": "Accurate reconstruction of plant phenotypes plays a key role in optimising sustainable farming practices in the field of Precision Agriculture (PA). Currently, optical sensor-based approaches dominate the field, but the need for high-fidelity 3D reconstruction of crops and plants in unstructured agricultural environments remains challenging. Recently, a promising development has emerged in the form of Neural Radiance Field (NeRF), a novel method that utilises neural density fields. This technique has shown impressive performance in various novel vision synthesis tasks, but has remained relatively unexplored in the agricultural context. In our study, we focus on two fundamental tasks within plant phenotyping: (1) the synthesis of 2D novel-view images and (2) the 3D reconstruction of crop and plant models. We explore the world of neural radiance fields, in particular two SOTA methods: Instant-NGP, which excels in generating high-quality images with impressive training and inference speed, and Instant-NSR, which improves the reconstructed geometry by incorporating the Signed Distance Function (SDF) during training. In particular, we present a novel plant phenotype dataset comprising real plant images from production environments. This dataset is a first-of-its-kind initiative aimed at comprehensively exploring the advantages and limitations of NeRF in agricultural contexts. Our experimental results show that NeRF demonstrates commendable performance in the synthesis of novel-view images and is able to achieve reconstruction results that are competitive with Reality Capture, a leading commercial software for 3D Multi-View Stereo (MVS)-based reconstruction. However, our study also highlights certain drawbacks of NeRF, including relatively slow training speeds, performance limitations in cases of insufficient sampling, and challenges in obtaining geometry quality in complex setups. ",
    "url": "https://arxiv.org/abs/2311.04154",
    "authors": [
      "Kewei Hu",
      "Ying Wei",
      "Yaoqiang Pan",
      "Hanwen Kang",
      "Chao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.04163",
    "title": "Outliers with Opposing Signals Have an Outsized Effect on Neural Network  Optimization",
    "abstract": "We identify a new phenomenon in neural network optimization which arises from the interaction of depth and a particular heavy-tailed structure in natural data. Our result offers intuitive explanations for several previously reported observations about network training dynamics. In particular, it implies a conceptually new cause for progressive sharpening and the edge of stability; we also highlight connections to other concepts in optimization and generalization including grokking, simplicity bias, and Sharpness-Aware Minimization. Experimentally, we demonstrate the significant influence of paired groups of outliers in the training data with strong opposing signals: consistent, large magnitude features which dominate the network output throughout training and provide gradients which point in opposite directions. Due to these outliers, early optimization enters a narrow valley which carefully balances the opposing groups; subsequent sharpening causes their loss to rise rapidly, oscillating between high on one group and then the other, until the overall loss spikes. We describe how to identify these groups, explore what sets them apart, and carefully study their effect on the network's optimization and behavior. We complement these experiments with a mechanistic explanation on a toy example of opposing signals and a theoretical analysis of a two-layer linear network on a simple model. Our finding enables new qualitative predictions of training behavior which we confirm experimentally. It also provides a new lens through which to study and improve modern training practices for stochastic optimization, which we highlight via a case study of Adam versus SGD. ",
    "url": "https://arxiv.org/abs/2311.04163",
    "authors": [
      "Elan Rosenfeld",
      "Andrej Risteski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.04164",
    "title": "Models towards Risk Behavior Prediction and Analysis: A Netherlands Case  study",
    "abstract": "In many countries financial service providers have to elicit their customers risk preferences, when offering products and services. For instance, in the Netherlands pension funds will be legally obliged to factor in their clients risk preferences when devising their investment strategies. Therefore, assessing and measuring the risk preferences of individuals is critical for the analysis of individuals' behavior and policy prescriptions. In the psychology and economics, a number of methods to elicit risk preferences have been developed using hypothetical scenarios and economic experiments. These methods of eliciting individual risk preferences are usually applied to small samples because they are expensive and the implementation can be complex and not suitable when large cohorts need to be measured. A large number of supervised learning models ranging from linear regression to support vector machines are used to predict risk preference measures using socio-economic register data such as age, gender, migration background and other demographic variables in combination with data on income, wealth, pension fund contributions, and other financial data. The employed machine learning models cover a range of assumptions and properties as well as a diverse set of regression metrics. The optimum model is selected using the metrics and interpretability of the model. The optimal models are lasso regression and gradient boosting machines with mean average percentage error of about 30%. This is important as it helps to estimate risk attitudes without actually measuring them. It should be noted that with the current accuracy the tested models are not ready for deployment for applications that require high accuracy. However, the results do indicate which models should be used in situations that do not require the most accurate predictions such as augmentation data for pensions' recommendation. ",
    "url": "https://arxiv.org/abs/2311.04164",
    "authors": [
      "Onaopepo Adekunle",
      "Arno Riedl",
      "Michel Dumontier"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2311.04171",
    "title": "HADES: Fast Singularity Detection with Local Measure Comparison",
    "abstract": "We introduce Hades, an unsupervised algorithm to detect singularities in data. This algorithm employs a kernel goodness-of-fit test, and as a consequence it is much faster and far more scaleable than the existing topology-based alternatives. Using tools from differential geometry and optimal transport theory, we prove that Hades correctly detects singularities with high probability when the data sample lives on a transverse intersection of equidimensional manifolds. In computational experiments, Hades recovers singularities in synthetically generated data, branching points in road network data, intersection rings in molecular conformation space, and anomalies in image data. ",
    "url": "https://arxiv.org/abs/2311.04171",
    "authors": [
      "Uzu Lim",
      "Harald Oberhauser",
      "Vidit Nanda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Algebraic Topology (math.AT)",
      "Differential Geometry (math.DG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2311.04190",
    "title": "Spatio-Temporal Anomaly Detection with Graph Networks for Data Quality  Monitoring of the Hadron Calorimeter",
    "abstract": "The compact muon solenoid (CMS) experiment is a general-purpose detector for high-energy collision at the large hadron collider (LHC) at CERN. It employs an online data quality monitoring (DQM) system to promptly spot and diagnose particle data acquisition problems to avoid data quality loss. In this study, we present semi-supervised spatio-temporal anomaly detection (AD) monitoring for the physics particle reading channels of the hadronic calorimeter (HCAL) of the CMS using three-dimensional digi-occupancy map data of the DQM. We propose the GraphSTAD system, which employs convolutional and graph neural networks to learn local spatial characteristics induced by particles traversing the detector, and global behavior owing to shared backend circuit connections and housing boxes of the channels, respectively. Recurrent neural networks capture the temporal evolution of the extracted spatial features. We have validated the accuracy of the proposed AD system in capturing diverse channel fault types using the LHC Run-2 collision data sets. The GraphSTAD system has achieved production-level accuracy and is being integrated into the CMS core production system--for real-time monitoring of the HCAL. We have also provided a quantitative performance comparison with alternative benchmark models to demonstrate the promising leverage of the presented system. ",
    "url": "https://arxiv.org/abs/2311.04190",
    "authors": [
      "Mulugeta Weldezgina Asres",
      "Christian Walter Omlin",
      "Long Wang",
      "David Yu",
      "Pavel Parygin",
      "Jay Dittmann",
      "Georgia Karapostoli",
      "Markus Seidel",
      "Rosamaria Venditti",
      "Luka Lambrecht",
      "Emanuele Usai",
      "Muhammad Ahmad",
      "Javier Fernandez Menendez",
      "Kaori Maeshima",
      "CMS-HCAL Collaboration"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.04194",
    "title": "Quantization-aware Neural Architectural Search for Intrusion Detection",
    "abstract": "Deploying machine learning-based intrusion detection systems (IDSs) on hardware devices is challenging due to their limited computational resources, power consumption, and network connectivity. Hence, there is a significant need for robust, deep learning models specifically designed with such constraints in mind. In this paper, we present a design methodology that automatically trains and evolves quantized neural network (NN) models that are a thousand times smaller than state-of-the-art NNs but can efficiently analyze network data for intrusion at high accuracy. In this regard, the number of LUTs utilized by this network when deployed to an FPGA is between 2.3x and 8.5x smaller with performance comparable to prior work. ",
    "url": "https://arxiv.org/abs/2311.04194",
    "authors": [
      "Rabin Yu Acharya",
      "Laurens Le Jeune",
      "Nele Mentens",
      "Fatemeh Ganji",
      "Domenic Forte"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.04196",
    "title": "JPAVE: A Generation and Classification-based Model for Joint Product  Attribute Prediction and Value Extraction",
    "abstract": "Product attribute value extraction is an important task in e-Commerce which can help several downstream applications such as product search and recommendation. Most previous models handle this task using sequence labeling or question answering method which rely on the sequential position information of values in the product text and are vulnerable to data discrepancy between training and testing. This limits their generalization ability to real-world scenario in which each product can have multiple descriptions across various shopping platforms with different composition of text and style. They also have limited zero-shot ability to new values. In this paper, we propose a multi-task learning model with value generation/classification and attribute prediction called JPAVE to predict values without the necessity of position information of values in the text. Furthermore, the copy mechanism in value generator and the value attention module in value classifier help our model address the data discrepancy issue by only focusing on the relevant part of input text and ignoring other information which causes the discrepancy issue such as sentence structure in the text. Besides, two variants of our model are designed for open-world and closed-world scenarios. In addition, copy mechanism introduced in the first variant based on value generation can improve its zero-shot ability for identifying unseen values. Experimental results on a public dataset demonstrate the superiority of our model compared with strong baselines and its generalization ability of predicting new values. ",
    "url": "https://arxiv.org/abs/2311.04196",
    "authors": [
      "Zhongfen Deng",
      "Hao Peng",
      "Tao Zhang",
      "Shuaiqi Liu",
      "Wenting Zhao",
      "Yibo Wang",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.04215",
    "title": "Wearable data from subjects playing Super Mario, sitting university  exams, or performing physical exercise help detect acute mood episodes via  self-supervised learning",
    "abstract": "Personal sensing, leveraging data passively and near-continuously collected with wearables from patients in their ecological environment, is a promising paradigm to monitor mood disorders (MDs), a major determinant of worldwide disease burden. However, collecting and annotating wearable data is very resource-intensive. Studies of this kind can thus typically afford to recruit only a couple dozens of patients. This constitutes one of the major obstacles to applying modern supervised machine learning techniques to MDs detection. In this paper, we overcome this data bottleneck and advance the detection of MDs acute episode vs stable state from wearables data on the back of recent advances in self-supervised learning (SSL). This leverages unlabelled data to learn representations during pre-training, subsequently exploited for a supervised task. First, we collected open-access datasets recording with an Empatica E4 spanning different, unrelated to MD monitoring, personal sensing tasks -- from emotion recognition in Super Mario players to stress detection in undergraduates -- and devised a pre-processing pipeline performing on-/off-body detection, sleep-wake detection, segmentation, and (optionally) feature extraction. With 161 E4-recorded subjects, we introduce E4SelfLearning, the largest to date open access collection, and its pre-processing pipeline. Second, we show that SSL confidently outperforms fully-supervised pipelines using either our novel E4-tailored Transformer architecture (E4mer) or classical baseline XGBoost: 81.23% against 75.35% (E4mer) and 72.02% (XGBoost) correctly classified recording segments from 64 (half acute, half stable) patients. Lastly, we illustrate that SSL performance is strongly associated with the specific surrogate task employed for pre-training as well as with unlabelled data availability. ",
    "url": "https://arxiv.org/abs/2311.04215",
    "authors": [
      "Filippo Corponi",
      "Bryan M. Li",
      "Gerard Anmella",
      "Cl\u00e0udia Valenzuela-Pascual",
      "Ariadna Mas",
      "Isabella Pacchiarotti",
      "Marc Valent\u00ed",
      "Iria Grande",
      "Antonio Benabarre",
      "Marina Garriga",
      "Eduard Vieta",
      "Allan H Young",
      "Stephen M. Lawrie",
      "Heather C. Whalley",
      "Diego Hidalgo-Mazzei",
      "Antonio Vergari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.03409",
    "title": "Visualizing DNA reaction trajectories with deep graph embedding  approaches",
    "abstract": "Synthetic biologists and molecular programmers design novel nucleic acid reactions, with many potential applications. Good visualization tools are needed to help domain experts make sense of the complex outputs of folding pathway simulations of such reactions. Here we present ViDa, a new approach for visualizing DNA reaction folding trajectories over the energy landscape of secondary structures. We integrate a deep graph embedding model with common dimensionality reduction approaches, to map high-dimensional data onto 2D Euclidean space. We assess ViDa on two well-studied and contrasting DNA hybridization reactions. Our preliminary results suggest that ViDa's visualization successfully separates trajectories with different folding mechanisms, thereby providing useful insight to users, and is a big improvement over the current state-of-the-art in DNA kinetics visualization. ",
    "url": "https://arxiv.org/abs/2311.03409",
    "authors": [
      "Chenwei Zhang",
      "Khanh Dao Duc",
      "Anne Condon"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.03411",
    "title": "ViDa: Visualizing DNA hybridization trajectories with  biophysics-informed deep graph embeddings",
    "abstract": "Visualization tools can help synthetic biologists and molecular programmers understand the complex reactive pathways of nucleic acid reactions, which can be designed for many potential applications and can be modelled using a continuous-time Markov chain (CTMC). Here we present ViDa, a new visualization approach for DNA reaction trajectories that uses a 2D embedding of the secondary structure state space underlying the CTMC model. To this end, we integrate a scattering transform of the secondary structure adjacency, a variational autoencoder, and a nonlinear dimensionality reduction method. We augment the training loss with domain-specific supervised terms that capture both thermodynamic and kinetic features. We assess ViDa on two well-studied DNA hybridization reactions. Our results demonstrate that the domain-specific features lead to significant quality improvements over the state-of-the-art in DNA state space visualization, successfully separating different folding pathways and thus providing useful insights into dominant reaction mechanisms. ",
    "url": "https://arxiv.org/abs/2311.03411",
    "authors": [
      "Chenwei Zhang",
      "Jordan Lovrod",
      "Boyan Beronov",
      "Khanh Dao Duc",
      "Anne Condon"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2311.03421",
    "title": "Hopfield-Enhanced Deep Neural Networks for Artifact-Resilient Brain  State Decoding",
    "abstract": "The study of brain states, ranging from highly synchronous to asynchronous neuronal patterns like the sleep-wake cycle, is fundamental for assessing the brain's spatiotemporal dynamics and their close connection to behavior. However, the development of new techniques to accurately identify them still remains a challenge, as these are often compromised by the presence of noise, artifacts, and suboptimal recording quality. In this study, we propose a two-stage computational framework combining Hopfield Networks for artifact data preprocessing with Convolutional Neural Networks (CNNs) for classification of brain states in rat neural recordings under different levels of anesthesia. To evaluate the robustness of our framework, we deliberately introduced noise artifacts into the neural recordings. We evaluated our hybrid Hopfield-CNN pipeline by benchmarking it against two comparative models: a standalone CNN handling the same noisy inputs, and another CNN trained and tested on artifact-free data. Performance across various levels of data compression and noise intensities showed that our framework can effectively mitigate artifacts, allowing the model to reach parity with the clean-data CNN at lower noise levels. Although this study mainly benefits small-scale experiments, the findings highlight the necessity for advanced deep learning and Hopfield Network models to improve scalability and robustness in diverse real-world settings. ",
    "url": "https://arxiv.org/abs/2311.03421",
    "authors": [
      "Arnau Marin-Llobet",
      "Arnau Manasanch",
      "Maria V. Sanchez-Vives"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.03508",
    "title": "Astrocytes as a mechanism for meta-plasticity and contextually-guided  network function",
    "abstract": "Astrocytes are a highly expressed and highly enigmatic cell-type in the mammalian brain. Traditionally viewed as a mediator of basic physiological sustenance, it is increasingly recognized that astrocytes may play a more direct role in neural computation. A conceptual challenge to this idea is the fact that astrocytic activity takes a very different form than that of neurons, and in particular, occurs at orders-of-magnitude slower time-scales. In the current paper, we engage how such time-scale separation may endow astrocytes with the capability to enable learning in context-dependent settings, where fluctuations in task parameters may occur much more slowly than within-task requirements. This idea is based on the recent supposition that astrocytes, owing to their sensitivity to a host of physiological covariates, may be particularly well poised to modulate the dynamics of neural circuits in functionally salient ways. We pose a general model of neural-synaptic-astrocyte interaction and use formal analysis to characterize how astrocytic modulation may constitute a form of meta-plasticity, altering the ways in which synapses and neurons adapt as a function of time. We then embed this model in a bandit-based reinforcement learning task environment, and show how the presence of time-scale separated astrocytic modulation enables learning over multiple fluctuating contexts. Indeed, these networks learn far more reliably versus dynamically homogenous networks and conventional non-network-based bandit algorithms. Our results indicate how the presence of neural-astrocyte interaction in the brain may benefit learning over different time-scale and the conveyance of task relevant contextual information onto circuit dynamics. ",
    "url": "https://arxiv.org/abs/2311.03508",
    "authors": [
      "Lulu Gong",
      "Fabio Pasqualetti",
      "Thomas Papouin",
      "ShiNung Ching"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.03666",
    "title": "Stochastic Control with Distributionally Robust Constraints for  Cyber-Physical Systems Vulnerable to Attacks",
    "abstract": "In this paper, we investigate the control of a cyber-physical system (CPS) while accounting for its vulnerability to external attacks. We formulate a constrained stochastic problem with a robust constraint to ensure robust operation against potential attacks. We seek to minimize the expected cost subject to a constraint limiting the worst-case expected damage an attacker can impose on the CPS. We present a dynamic programming decomposition to compute the optimal control strategy in this robust-constrained formulation and prove its recursive feasibility. We also illustrate the utility of our results by applying them to a numerical simulation. ",
    "url": "https://arxiv.org/abs/2311.03666",
    "authors": [
      "Nishanth Venkatesh",
      "Aditya Dave",
      "Ioannis Faros",
      "Andreas A. Malikopoulos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.03713",
    "title": "Multimodal deep representation learning for quantum cross-platform  verification",
    "abstract": "Cross-platform verification, a critical undertaking in the realm of early-stage quantum computing, endeavors to characterize the similarity of two imperfect quantum devices executing identical algorithms, utilizing minimal measurements. While the random measurement approach has been instrumental in this context, the quasi-exponential computational demand with increasing qubit count hurdles its feasibility in large-qubit scenarios. To bridge this knowledge gap, here we introduce an innovative multimodal learning approach, recognizing that the formalism of data in this task embodies two distinct modalities: measurement outcomes and classical description of compiled circuits on explored quantum devices, both enriched with unique information. Building upon this insight, we devise a multimodal neural network to independently extract knowledge from these modalities, followed by a fusion operation to create a comprehensive data representation. The learned representation can effectively characterize the similarity between the explored quantum devices when executing new quantum algorithms not present in the training data. We evaluate our proposal on platforms featuring diverse noise models, encompassing system sizes up to 50 qubits. The achieved results demonstrate a three-orders-of-magnitude improvement in prediction accuracy compared to the random measurements and offer compelling evidence of the complementary roles played by each modality in cross-platform verification. These findings pave the way for harnessing the power of multimodal learning to overcome challenges in wider quantum system learning tasks. ",
    "url": "https://arxiv.org/abs/2311.03713",
    "authors": [
      "Yang Qian",
      "Yuxuan Du",
      "Zhenliang He",
      "Min-hsiu Hsieh",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.03821",
    "title": "Positive Competitive Networks for Sparse Reconstruction",
    "abstract": "We propose, and analyze, a continuous-time firing-rate neural network, the positive firing-rate competitive network (PFCN), to tackle sparse reconstruction problems with non-negativity constraints. These problems, which involve approximating a given input stimulus from a dictionary using a set of sparse (active) neurons, play a key role in a wide range of domains spanning e.g., neuroscience, signal processing, and machine learning. First, by leveraging the theory of proximal operators, we introduce a result relating the equilibria of a family of continuous-time firing-rate neural networks to the optimal solutions of sparse reconstruction problems. Then, we give rigorous conditions for the convergence of the PFCN to the equilibrium. Specifically, we show that the convergence: (i) only depends on a property of the dictionary; (ii) is linear-exponential, in the sense that initially the convergence rate is at most linear and then, after a transient, it becomes exponential. To obtain our main theorem, we also prove a number of technical results to assess certain contractivity properties of the dynamics of our interest. Finally, we validate the effectiveness of our approach via a numerical example. ",
    "url": "https://arxiv.org/abs/2311.03821",
    "authors": [
      "Veronica Centorrino",
      "Anand Gokhale",
      "Alexander Davydov",
      "Giovanni Russo",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2311.04049",
    "title": "3D EAGAN: 3D edge-aware attention generative adversarial network for  prostate segmentation in transrectal ultrasound images",
    "abstract": "Automatic prostate segmentation in TRUS images has always been a challenging problem, since prostates in TRUS images have ambiguous boundaries and inhomogeneous intensity distribution. Although many prostate segmentation methods have been proposed, they still need to be improved due to the lack of sensibility to edge information. Consequently, the objective of this study is to devise a highly effective prostate segmentation method that overcomes these limitations and achieves accurate segmentation of prostates in TRUS images. A 3D edge-aware attention generative adversarial network (3D EAGAN)-based prostate segmentation method is proposed in this paper, which consists of an edge-aware segmentation network (EASNet) that performs the prostate segmentation and a discriminator network that distinguishes predicted prostates from real prostates. The proposed EASNet is composed of an encoder-decoder-based U-Net backbone network, a detail compensation module, four 3D spatial and channel attention modules, an edge enhance module, and a global feature extractor. The detail compensation module is proposed to compensate for the loss of detailed information caused by the down-sampling process of the encoder. The features of the detail compensation module are selectively enhanced by the 3D spatial and channel attention module. Furthermore, an edge enhance module is proposed to guide shallow layers in the EASNet to focus on contour and edge information in prostates. Finally, features from shallow layers and hierarchical features from the decoder module are fused through the global feature extractor to predict the segmentation prostates. ",
    "url": "https://arxiv.org/abs/2311.04049",
    "authors": [
      "Mengqing Liu",
      "Xiao Shao",
      "Liping Jiang",
      "Kaizhi Wu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2012.04634",
    "title": "Accurate 3D Object Detection using Energy-Based Models",
    "abstract": " Comments: CVPR Workshops 2021. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2012.04634",
    "authors": [
      "Fredrik K. Gustafsson",
      "Martin Danelljan",
      "Thomas B. Sch\u00f6n"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2101.02320",
    "title": "Scale-free tree network with an ultra-large diameter",
    "abstract": " Title: Scale-free tree network with an ultra-large diameter ",
    "url": "https://arxiv.org/abs/2101.02320",
    "authors": [
      "Fei Ma",
      "Ping Wang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2203.03897",
    "title": "Geodesic Multi-Modal Mixup for Robust Fine-Tuning",
    "abstract": " Comments: To appear at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2203.03897",
    "authors": [
      "Changdae Oh",
      "Junhyuk So",
      "Hoyoon Byun",
      "YongTaek Lim",
      "Minchul Shin",
      "Jong-June Jeon",
      "Kyungwoo Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.10581",
    "title": "FAIR4Cov: Fused Audio Instance and Representation for COVID-19 Detection",
    "abstract": " Title: FAIR4Cov: Fused Audio Instance and Representation for COVID-19 Detection ",
    "url": "https://arxiv.org/abs/2204.10581",
    "authors": [
      "Tuan Truong",
      "Matthias Lenga",
      "Antoine Serrurier",
      "Sadegh Mohammadi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.04507",
    "title": "Software Mitigation of RISC-V Spectre Attacks",
    "abstract": " Title: Software Mitigation of RISC-V Spectre Attacks ",
    "url": "https://arxiv.org/abs/2206.04507",
    "authors": [
      "Ruxandra B\u0103lucea",
      "Paul Irofti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Operating Systems (cs.OS)"
    ]
  },
  {
    "id": "arXiv:2206.08171",
    "title": "K-Radar: 4D Radar Object Detection for Autonomous Driving in Various  Weather Conditions",
    "abstract": " Comments: Accepted at NeurIPS 2022 Datasets and Benchmarks Track ",
    "url": "https://arxiv.org/abs/2206.08171",
    "authors": [
      "Dong-Hee Paek",
      "Seung-Hyun Kong",
      "Kevin Tirta Wijaya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.09798",
    "title": "Using Sum-Product Networks to Assess Uncertainty in Deep Active Learning",
    "abstract": " Comments: 15 pages,9 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2206.09798",
    "authors": [
      "Mohamadsadegh Khosravani",
      "Sandra Zilles"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2207.09429",
    "title": "Prior-Independent Auctions for Heterogeneous Bidders",
    "abstract": " Comments: Full version of a paper in the Proceedings of the 2024 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA) ",
    "url": "https://arxiv.org/abs/2207.09429",
    "authors": [
      "Guru Guruganesh",
      "Aranyak Mehta",
      "Di Wang",
      "Kangning Wang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2208.06318",
    "title": "Towards Code Summarization of APIs Based on Unofficial Documentation  Using NLP Techniques",
    "abstract": " Title: Towards Code Summarization of APIs Based on Unofficial Documentation  Using NLP Techniques ",
    "url": "https://arxiv.org/abs/2208.06318",
    "authors": [
      "AmirHossein Naghshzan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.06579",
    "title": "C^2:Co-design of Robots via Concurrent Networks Coupling Online and  Offline Reinforcement Learning",
    "abstract": " Title: C^2:Co-design of Robots via Concurrent Networks Coupling Online and  Offline Reinforcement Learning ",
    "url": "https://arxiv.org/abs/2209.06579",
    "authors": [
      "Ci Chen",
      "Pingyu Xiang",
      "Haojian Lu",
      "Yue Wang",
      "Rong Xiong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.09326",
    "title": "Sparse Interaction Additive Networks via Feature Interaction Detection  and Sparse Selection",
    "abstract": " Title: Sparse Interaction Additive Networks via Feature Interaction Detection  and Sparse Selection ",
    "url": "https://arxiv.org/abs/2209.09326",
    "authors": [
      "James Enouen",
      "Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.15042",
    "title": "Generalizability of Adversarial Robustness Under Distribution Shifts",
    "abstract": " Comments: TMLR 2023 (Featured Certification) ",
    "url": "https://arxiv.org/abs/2209.15042",
    "authors": [
      "Kumail Alhamoud",
      "Hasan Abed Al Kader Hammoud",
      "Motasem Alfarra",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.09364",
    "title": "Probabilistic Categorical Adversarial Attack & Adversarial Training",
    "abstract": " Title: Probabilistic Categorical Adversarial Attack & Adversarial Training ",
    "url": "https://arxiv.org/abs/2210.09364",
    "authors": [
      "Han Xu",
      "Pengfei He",
      "Jie Ren",
      "Yuxuan Wan",
      "Zitao Liu",
      "Hui Liu",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.09721",
    "title": "An incremental input-to-state stability condition for a generic class of  recurrent neural networks",
    "abstract": " Title: An incremental input-to-state stability condition for a generic class of  recurrent neural networks ",
    "url": "https://arxiv.org/abs/2210.09721",
    "authors": [
      "William D'Amico",
      "Alessio La Bella",
      "Marcello Farina"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.12040",
    "title": "Neuro-Symbolic Causal Reasoning Meets Signaling Game for Emergent  Semantic Communications",
    "abstract": " Title: Neuro-Symbolic Causal Reasoning Meets Signaling Game for Emergent  Semantic Communications ",
    "url": "https://arxiv.org/abs/2210.12040",
    "authors": [
      "Christo Kurisummoottil Thomas",
      "Walid Saad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.03392",
    "title": "A tight upper bound on the number of non-zero weights of a quasi-cyclic  code",
    "abstract": " Title: A tight upper bound on the number of non-zero weights of a quasi-cyclic  code ",
    "url": "https://arxiv.org/abs/2211.03392",
    "authors": [
      "Xiaoxiao Li",
      "Minjia Shi",
      "San Ling"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.10955",
    "title": "When Noisy Labels Meet Long Tail Dilemmas: A Representation Calibration  Method",
    "abstract": " Comments: Accepted as an ICCV 2023 oral paper ",
    "url": "https://arxiv.org/abs/2211.10955",
    "authors": [
      "Manyi Zhang",
      "Xuyang Zhao",
      "Jun Yao",
      "Chun Yuan",
      "Weiran Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2211.16412",
    "title": "Procedural Image Programs for Representation Learning",
    "abstract": " Comments: 29 pages, Accepted in the Conference on Neural Information Processing Systems 2022 (NeurIPS 2022) ",
    "url": "https://arxiv.org/abs/2211.16412",
    "authors": [
      "Manel Baradad",
      "Chun-Fu Chen",
      "Jonas Wulff",
      "Tongzhou Wang",
      "Rogerio Feris",
      "Antonio Torralba",
      "Phillip Isola"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.01545",
    "title": "A Generalized Scalarization Method for Evolutionary Multi-Objective  Optimization",
    "abstract": " Comments: Correct some typos. (Accepted for presentation at Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI-23)) ",
    "url": "https://arxiv.org/abs/2212.01545",
    "authors": [
      "Ruihao Zheng",
      "Zhenkun Wang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2212.04922",
    "title": "Doubly Robust Kernel Statistics for Testing Distributional Treatment  Effects",
    "abstract": " Comments: 10 pages, Preprint ",
    "url": "https://arxiv.org/abs/2212.04922",
    "authors": [
      "Jake Fawkes",
      "Robert Hu",
      "Robin J. Evans",
      "Dino Sejdinovic"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.05404",
    "title": "Cap2Aug: Caption guided Image to Image data Augmentation",
    "abstract": " Title: Cap2Aug: Caption guided Image to Image data Augmentation ",
    "url": "https://arxiv.org/abs/2212.05404",
    "authors": [
      "Aniket Roy",
      "Anshul Shah",
      "Ketul Shah",
      "Anirban Roy",
      "Rama Chellappa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.12317",
    "title": "Matching Cuts in Graphs of High Girth and H-Free Graphs",
    "abstract": " Title: Matching Cuts in Graphs of High Girth and H-Free Graphs ",
    "url": "https://arxiv.org/abs/2212.12317",
    "authors": [
      "Carl Feghali",
      "Felicia Lucke",
      "Daniel Paulusma",
      "Bernard Ries"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2301.10884",
    "title": "Break It Down: Evidence for Structural Compositionality in Neural  Networks",
    "abstract": " Title: Break It Down: Evidence for Structural Compositionality in Neural  Networks ",
    "url": "https://arxiv.org/abs/2301.10884",
    "authors": [
      "Michael A. Lepori",
      "Thomas Serre",
      "Ellie Pavlick"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.04178",
    "title": "DynGFN: Towards Bayesian Inference of Gene Regulatory Networks with  GFlowNets",
    "abstract": " Title: DynGFN: Towards Bayesian Inference of Gene Regulatory Networks with  GFlowNets ",
    "url": "https://arxiv.org/abs/2302.04178",
    "authors": [
      "Lazar Atanackovic",
      "Alexander Tong",
      "Bo Wang",
      "Leo J. Lee",
      "Yoshua Bengio",
      "Jason Hartford"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2302.07025",
    "title": "Optimal Transport for Change Detection on LiDAR Point Clouds",
    "abstract": " Comments: This project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No101027956 ",
    "url": "https://arxiv.org/abs/2302.07025",
    "authors": [
      "Marco Fiorucci",
      "Peter Naylor",
      "Makoto Yamada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2302.09043",
    "title": "Self-Supervised Representation Learning from Temporal Ordering of  Automated Driving Sequences",
    "abstract": " Comments: 12 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2302.09043",
    "authors": [
      "Christopher Lang",
      "Alexander Braun",
      "Lars Schillingmann",
      "Karsten Haug",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.12000",
    "title": "Graph Construction using Principal Axis Trees for Simple Graph  Convolution",
    "abstract": " Title: Graph Construction using Principal Axis Trees for Simple Graph  Convolution ",
    "url": "https://arxiv.org/abs/2302.12000",
    "authors": [
      "Mashaan Alshammari",
      "John Stavrakakis",
      "Adel F. Ahmed",
      "Masahiro Takatsuka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2303.10093",
    "title": "Investigating the Role of Attribute Context in Vision-Language Models  for Object Recognition and Detection",
    "abstract": " Comments: Accepted at Winter Conference on Applications of Computer Vision (WACV), 2024 ",
    "url": "https://arxiv.org/abs/2303.10093",
    "authors": [
      "Kyle Buettner",
      "Adriana Kovashka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.13764",
    "title": "GQE-Net: A Graph-based Quality Enhancement Network for Point Cloud Color  Attribute",
    "abstract": " Comments: Accepted by IEEE TIP (DOI: 10.1109/TIP.2023.3330086) ",
    "url": "https://arxiv.org/abs/2303.13764",
    "authors": [
      "Jinrui Xing",
      "Hui Yuan",
      "Raouf Hamzaoui",
      "Hao Liu",
      "Junhui Hou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.01834",
    "title": "Neural Field Convolutions by Repeated Differentiation",
    "abstract": " Title: Neural Field Convolutions by Repeated Differentiation ",
    "url": "https://arxiv.org/abs/2304.01834",
    "authors": [
      "Ntumba Elie Nsampi",
      "Adarsh Djeacoumar",
      "Hans-Peter Seidel",
      "Tobias Ritschel",
      "Thomas Leimk\u00fchler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2304.03408",
    "title": "Dynamics of Finite Width Kernel and Prediction Fluctuations in Mean  Field Neural Networks",
    "abstract": " Comments: Advances in Neural Information Processing Systems 36 (2023) Camera Ready ",
    "url": "https://arxiv.org/abs/2304.03408",
    "authors": [
      "Blake Bordelon",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.10749",
    "title": "Multi-scale Evolutionary Neural Architecture Search for Deep Spiking  Neural Networks",
    "abstract": " Title: Multi-scale Evolutionary Neural Architecture Search for Deep Spiking  Neural Networks ",
    "url": "https://arxiv.org/abs/2304.10749",
    "authors": [
      "Wenxuan Pan",
      "Feifei Zhao",
      "Guobin Shen",
      "Yi Zeng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.13105",
    "title": "Attention-Enhanced Deep Learning for Device-Free Through-the-Wall  Presence Detection Using Indoor WiFi System",
    "abstract": " Title: Attention-Enhanced Deep Learning for Device-Free Through-the-Wall  Presence Detection Using Indoor WiFi System ",
    "url": "https://arxiv.org/abs/2304.13105",
    "authors": [
      "Li-Hsiang Shen",
      "Kuan-I Lu",
      "An-Hung Hsiao",
      "Kai-Ten Feng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.02646",
    "title": "Design and Detection of Unitary Constellations in Non-Coherent SIMO  Systems for Short Packet Communications",
    "abstract": " Comments: 13 pages, 10 figures, in preparation to submit to IEEE Transactions on Wireless Communications ",
    "url": "https://arxiv.org/abs/2305.02646",
    "authors": [
      "Son T. Duong",
      "Ha H. Nguyen",
      "Ebrahim Bedeer",
      "Robert Barton"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2305.08573",
    "title": "A graph convolutional autoencoder approach to model order reduction for  parametrized PDEs",
    "abstract": " Comments: this https URL ",
    "url": "https://arxiv.org/abs/2305.08573",
    "authors": [
      "Federico Pichi",
      "Beatriz Moya",
      "Jan S. Hesthaven"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.09850",
    "title": "MINT: Multiplier-less INTeger Quantization for Energy Efficient Spiking  Neural Networks",
    "abstract": " Comments: 6 pages. Accepted to 29th Asia and South Pacific Design Automation Conference (ASP-DAC 2024), nominated for best paper award ",
    "url": "https://arxiv.org/abs/2305.09850",
    "authors": [
      "Ruokai Yin",
      "Yuhang Li",
      "Abhishek Moitra",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2305.14517",
    "title": "CongFu: Conditional Graph Fusion for Drug Synergy Prediction",
    "abstract": " Title: CongFu: Conditional Graph Fusion for Drug Synergy Prediction ",
    "url": "https://arxiv.org/abs/2305.14517",
    "authors": [
      "Oleksii Tsepa",
      "Bohdan Naida",
      "Anna Goldenberg",
      "Bo Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2305.17134",
    "title": "NeuManifold: Neural Watertight Manifold Reconstruction with Efficient  and High-Quality Rendering Support",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2305.17134",
    "authors": [
      "Xinyue Wei",
      "Fanbo Xiang",
      "Sai Bi",
      "Anpei Chen",
      "Kalyan Sunkavalli",
      "Zexiang Xu",
      "Hao Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.04061",
    "title": "Deploying a Robust Active Preference Elicitation Algorithm on MTurk:  Experiment Design, Interface, and Evaluation for COVID-19 Patient  Prioritization",
    "abstract": " Comments: 10 pages, 5 figures, 1 table ",
    "url": "https://arxiv.org/abs/2306.04061",
    "authors": [
      "Caroline M. Johnston",
      "Patrick Vossler",
      "Simon Blessenohl",
      "Phebe Vayanos"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.04096",
    "title": "An enrichment approach for enhancing the expressivity of neural  operators with applications to seismology",
    "abstract": " Title: An enrichment approach for enhancing the expressivity of neural  operators with applications to seismology ",
    "url": "https://arxiv.org/abs/2306.04096",
    "authors": [
      "Ehsan Haghighat",
      "Umair bin Waheed",
      "George Karniadakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2306.04186",
    "title": "Self-supervised Audio Teacher-Student Transformer for Both Clip-level  and Frame-level Tasks",
    "abstract": " Comments: Submitted to IEEE TASLP. arXiv admin note: text overlap with arXiv:2204.12076 ",
    "url": "https://arxiv.org/abs/2306.04186",
    "authors": [
      "Xian Li",
      "Nian Shao",
      "Xiaofei Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.07716",
    "title": "Dynamically Masked Discriminator for Generative Adversarial Networks",
    "abstract": " Comments: Updated v2 -- NeurIPS 2023 camera ready version ",
    "url": "https://arxiv.org/abs/2306.07716",
    "authors": [
      "Wentian Zhang",
      "Haozhe Liu",
      "Bing Li",
      "Jinheng Xie",
      "Yawen Huang",
      "Yuexiang Li",
      "Yefeng Zheng",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.09858",
    "title": "Prototype Learning for Explainable Brain Age Prediction",
    "abstract": " Comments: Accepted for presentation at WCAV 2024 ",
    "url": "https://arxiv.org/abs/2306.09858",
    "authors": [
      "Linde S. Hesse",
      "Nicola K. Dinsdale",
      "Ana I. L. Namburete"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.10280",
    "title": "OpenGSL: A Comprehensive Benchmark for Graph Structure Learning",
    "abstract": " Comments: 9 pages, 4 figures. Accepted by NeurIPS Datasets and Benchmarks Track 2023 ",
    "url": "https://arxiv.org/abs/2306.10280",
    "authors": [
      "Zhiyao Zhou",
      "Sheng Zhou",
      "Bochao Mao",
      "Xuanyi Zhou",
      "Jiawei Chen",
      "Qiaoyu Tan",
      "Daochen Zha",
      "Yan Feng",
      "Chun Chen",
      "Can Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.11412",
    "title": "Size Matters: Large Graph Generation with HiGGs",
    "abstract": " Comments: Presented at the NeurIPS 2023 Synthetic Data Generation with Generative AI workshop ",
    "url": "https://arxiv.org/abs/2306.11412",
    "authors": [
      "Alex O. Davies",
      "Nirav S. Ajmeri",
      "Telmo M. Silva Filho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.14351",
    "title": "Comparing Causal Frameworks: Potential Outcomes, Structural Models,  Graphs, and Abstractions",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.14351",
    "authors": [
      "Duligur Ibeling",
      "Thomas Icard"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.14770",
    "title": "ProtoDiff: Learning to Learn Prototypical Networks by Task-Guided  Diffusion",
    "abstract": " Comments: Accepted by NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.14770",
    "authors": [
      "Yingjun Du",
      "Zehao Xiao",
      "Shengcai Liao",
      "Cees Snoek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.16819",
    "title": "Graph Denoising Diffusion for Inverse Protein Folding",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.16819",
    "authors": [
      "Kai Yi",
      "Bingxin Zhou",
      "Yiqing Shen",
      "Pietro Li\u00f2",
      "Yu Guang Wang"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.17466",
    "title": "MedAugment: Universal Automatic Data Augmentation Plug-in for Medical  Image Analysis",
    "abstract": " Comments: 26 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2306.17466",
    "authors": [
      "Zhaoshan Liu",
      "Qiujie Lv",
      "Yifan Li",
      "Ziduo Yang",
      "Lei Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07187",
    "title": "Erasing, Transforming, and Noising Defense Network for Occluded Person  Re-Identification",
    "abstract": " Title: Erasing, Transforming, and Noising Defense Network for Occluded Person  Re-Identification ",
    "url": "https://arxiv.org/abs/2307.07187",
    "authors": [
      "Neng Dong",
      "Liyan Zhang",
      "Shuanglin Yan",
      "Hao Tang",
      "Jinhui Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07697",
    "title": "Think-on-Graph: Deep and Responsible Reasoning of Large Language Model  on Knowledge Graph",
    "abstract": " Comments: 30 pages, 13 figures, 20 tables ",
    "url": "https://arxiv.org/abs/2307.07697",
    "authors": [
      "Jiashuo Sun",
      "Chengjin Xu",
      "Lumingyuan Tang",
      "Saizhuo Wang",
      "Chen Lin",
      "Yeyun Gong",
      "Lionel M. Ni",
      "Heung-Yeung Shum",
      "Jian Guo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2307.13214",
    "title": "FedMEKT: Distillation-based Embedding Knowledge Transfer for Multimodal  Federated Learning",
    "abstract": " Title: FedMEKT: Distillation-based Embedding Knowledge Transfer for Multimodal  Federated Learning ",
    "url": "https://arxiv.org/abs/2307.13214",
    "authors": [
      "Huy Q. Le",
      "Minh N. H. Nguyen",
      "Chu Myaet Thwal",
      "Yu Qiao",
      "Chaoning Zhang",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.00987",
    "title": "Percolation in higher order networks via mapping to chygraphs",
    "abstract": " Comments: 8 pages, 4 figures, ref to github repository ",
    "url": "https://arxiv.org/abs/2308.00987",
    "authors": [
      "Alexei Vazquez"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Data Structures and Algorithms (cs.DS)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2308.11110",
    "title": "A novel analysis of utility in privacy pipelines, using Kronecker  products and quantitative information flow",
    "abstract": " Title: A novel analysis of utility in privacy pipelines, using Kronecker  products and quantitative information flow ",
    "url": "https://arxiv.org/abs/2308.11110",
    "authors": [
      "M\u00e1rio S. Alvim",
      "Natasha Fernandes",
      "Annabelle McIver",
      "Carroll Morgan",
      "Gabriel H. Nunes"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.14132",
    "title": "Detecting Language Model Attacks with Perplexity",
    "abstract": " Title: Detecting Language Model Attacks with Perplexity ",
    "url": "https://arxiv.org/abs/2308.14132",
    "authors": [
      "Gabriel Alon",
      "Michael Kamfonas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.00317",
    "title": "A Text-based Approach For Link Prediction on Wikipedia Articles",
    "abstract": " Comments: Accepted by DSAA 2023 Conference in the DSAA Student Competition Section ",
    "url": "https://arxiv.org/abs/2309.00317",
    "authors": [
      "Anh Hoang Tran",
      "Tam Minh Nguyen",
      "Son T. Luu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.00543",
    "title": "Curating Naturally Adversarial Datasets for Learning-Enabled Medical  Cyber-Physical Systems",
    "abstract": " Title: Curating Naturally Adversarial Datasets for Learning-Enabled Medical  Cyber-Physical Systems ",
    "url": "https://arxiv.org/abs/2309.00543",
    "authors": [
      "Sydney Pugh",
      "Ivan Ruchkin",
      "Insup Lee",
      "James Weimer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.02422",
    "title": "Maximum Mean Discrepancy Meets Neural Networks: The  Radon-Kolmogorov-Smirnov Test",
    "abstract": " Title: Maximum Mean Discrepancy Meets Neural Networks: The  Radon-Kolmogorov-Smirnov Test ",
    "url": "https://arxiv.org/abs/2309.02422",
    "authors": [
      "Seunghoon Paik",
      "Michael Celentano",
      "Alden Green",
      "Ryan J. Tibshirani"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2309.03783",
    "title": "Not your private t\u00eate-\u00e0-t\u00eate: leveraging the power of higher-order  networks to study animal communication",
    "abstract": " Title: Not your private t\u00eate-\u00e0-t\u00eate: leveraging the power of higher-order  networks to study animal communication ",
    "url": "https://arxiv.org/abs/2309.03783",
    "authors": [
      "Iacopo Iacopini",
      "Jennifer R Foote",
      "Nina H Fefferman",
      "Elizabeth P Derryberry",
      "Matthew J Silk"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Social and Information Networks (cs.SI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2309.04037",
    "title": "SRN-SZ: Deep Leaning-Based Scientific Error-bounded Lossy Compression  with Super-resolution Neural Networks",
    "abstract": " Title: SRN-SZ: Deep Leaning-Based Scientific Error-bounded Lossy Compression  with Super-resolution Neural Networks ",
    "url": "https://arxiv.org/abs/2309.04037",
    "authors": [
      "Jinyang Liu",
      "Sheng Di",
      "Sian Jin",
      "Kai Zhao",
      "Xin Liang",
      "Zizhong Chen",
      "Franck Cappello"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2309.04190",
    "title": "SegmentAnything helps microscopy images based automatic and quantitative  organoid detection and analysis",
    "abstract": " Comments: submitted to SPIE: Medical Imaging 2024 ",
    "url": "https://arxiv.org/abs/2309.04190",
    "authors": [
      "Xiaodan Xing",
      "Chunling Tang",
      "Yunzhe Guo",
      "Nicholas Kurniawan",
      "Guang Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2309.05139",
    "title": "A Skeleton-based Approach For Rock Crack Detection Towards A Climbing  Robot Application",
    "abstract": " Title: A Skeleton-based Approach For Rock Crack Detection Towards A Climbing  Robot Application ",
    "url": "https://arxiv.org/abs/2309.05139",
    "authors": [
      "Josselin Somerville Roberts",
      "Paul-Emile Giacomelli",
      "Yoni Gozlan",
      "Julia Di"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2309.06782",
    "title": "Improved particle-flow event reconstruction with scalable neural  networks for current and future particle detectors",
    "abstract": " Comments: 19 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2309.06782",
    "authors": [
      "Joosep Pata",
      "Eric Wulff",
      "Farouk Mokhtar",
      "David Southwick",
      "Mengke Zhang",
      "Maria Girone",
      "Javier Duarte"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Instrumentation and Detectors (physics.ins-det)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2309.07289",
    "title": "User Training with Error Augmentation for Electromyogram-based Gesture  Classification",
    "abstract": " Comments: 10 pages, 10 figures. V2: Fix latex characters in author name ",
    "url": "https://arxiv.org/abs/2309.07289",
    "authors": [
      "Yunus Bicer",
      "Niklas Smedemark-Margulies",
      "Basak Celik",
      "Elifnur Sunger",
      "Ryan Orendorff",
      "Stephanie Naufel",
      "Tales Imbiriba",
      "Deniz Erdo\u011fmu\u015f",
      "Eugene Tunik",
      "Mathew Yarossi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.11523",
    "title": "RMT: Retentive Networks Meet Vision Transformers",
    "abstract": " Comments: Fix the bug in the UperNet. Code will be released at this https URL ",
    "url": "https://arxiv.org/abs/2309.11523",
    "authors": [
      "Qihang Fan",
      "Huaibo Huang",
      "Mingrui Chen",
      "Hongmin Liu",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.15601",
    "title": "A Study on Tiny YOLO for Resource Constrained Xray Threat Detection",
    "abstract": " Comments: Paper Accepted in AI-ML Systems '23, SAI4E Workshop, Bangalore ",
    "url": "https://arxiv.org/abs/2309.15601",
    "authors": [
      "Raghav Ambati",
      "Ayon Borthakur"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.00496",
    "title": "The Sparsity Roofline: Understanding the Hardware Limits of Sparse  Neural Networks",
    "abstract": " Title: The Sparsity Roofline: Understanding the Hardware Limits of Sparse  Neural Networks ",
    "url": "https://arxiv.org/abs/2310.00496",
    "authors": [
      "Cameron Shinn",
      "Collin McCarthy",
      "Saurav Muralidharan",
      "Muhammad Osama",
      "John D. Owens"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.01258",
    "title": "MobileNVC: Real-time 1080p Neural Video Compression on a Mobile Device",
    "abstract": " Comments: Matches version published at WACV 2024 ",
    "url": "https://arxiv.org/abs/2310.01258",
    "authors": [
      "Ties van Rozendaal",
      "Tushar Singhal",
      "Hoang Le",
      "Guillaume Sautiere",
      "Amir Said",
      "Krishna Buska",
      "Anjuman Raha",
      "Dimitris Kalatzis",
      "Hitarth Mehta",
      "Frank Mayer",
      "Liang Zhang",
      "Markus Nagel",
      "Auke Wiggers"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.02641",
    "title": "Deformation-Invariant Neural Network and Its Applications in Distorted  Image Restoration and Analysis",
    "abstract": " Title: Deformation-Invariant Neural Network and Its Applications in Distorted  Image Restoration and Analysis ",
    "url": "https://arxiv.org/abs/2310.02641",
    "authors": [
      "Han Zhang",
      "Qiguang Chen",
      "Lok Ming Lui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2310.11807",
    "title": "Learning Global Quantum Properties from Local Measurements with Neural  Networks",
    "abstract": " Title: Learning Global Quantum Properties from Local Measurements with Neural  Networks ",
    "url": "https://arxiv.org/abs/2310.11807",
    "authors": [
      "Ya-Dong Wu",
      "Yan Zhu",
      "Yuexuan Wang",
      "Giulio Chiribella"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.15015",
    "title": "Leveraging Deep Learning for Abstractive Code Summarization of  Unofficial Documentation",
    "abstract": " Title: Leveraging Deep Learning for Abstractive Code Summarization of  Unofficial Documentation ",
    "url": "https://arxiv.org/abs/2310.15015",
    "authors": [
      "AmirHossein Naghshzan",
      "Latifa Guerrouj",
      "Olga Baysal"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16858",
    "title": "4D-Editor: Interactive Object-level Editing in Dynamic Neural Radiance  Fields via Semantic Distillation",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2310.16858",
    "authors": [
      "Dadong Jiang",
      "Zhihui Ke",
      "Xiaobo Zhou",
      "Xidong Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18620",
    "title": "ODM3D: Alleviating Foreground Sparsity for Semi-Supervised Monocular 3D  Object Detection",
    "abstract": " Comments: Accepted by WACV 2024 ",
    "url": "https://arxiv.org/abs/2310.18620",
    "authors": [
      "Weijia Zhang",
      "Dongnan Liu",
      "Chao Ma",
      "Weidong Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18651",
    "title": "LG-Self: Local-Global Self-Supervised Visual Representation Learning",
    "abstract": " Comments: 14 pages ",
    "url": "https://arxiv.org/abs/2310.18651",
    "authors": [
      "Ali Javidani",
      "Mohammad Amin Sadeghi",
      "Babak Nadjar Araabi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.18725",
    "title": "The Evolution of the Interplay Between Input Distributions and Linear  Regions in Networks",
    "abstract": " Comments: Under review ",
    "url": "https://arxiv.org/abs/2310.18725",
    "authors": [
      "Xuan Qi",
      "Yi Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.19005",
    "title": "Kernel-based Joint Multiple Graph Learning and Clustering of Graph  Signals",
    "abstract": " Comments: 6 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2310.19005",
    "authors": [
      "Mohamad H. Alizade",
      "Aref Einizade",
      "Jhony H. Giraldo"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19253",
    "title": "Flow-based distributionally robust optimization",
    "abstract": " Title: Flow-based distributionally robust optimization ",
    "url": "https://arxiv.org/abs/2310.19253",
    "authors": [
      "Chen Xu",
      "Jonghyeok Lee",
      "Xiuyuan Cheng",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.19685",
    "title": "DGFN: Double Generative Flow Networks",
    "abstract": " Comments: Accepted to NeurIPS 2023 Workshop ",
    "url": "https://arxiv.org/abs/2310.19685",
    "authors": [
      "Elaine Lau",
      "Nikhil Vemgal",
      "Doina Precup",
      "Emmanuel Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2311.00660",
    "title": "TPSeNCE: Towards Artifact-Free Realistic Rain Generation for Deraining  and Object Detection in Rain",
    "abstract": " Comments: WACV 2024 ",
    "url": "https://arxiv.org/abs/2311.00660",
    "authors": [
      "Shen Zheng",
      "Changjie Lu",
      "Srinivasa G. Narasimhan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.00729",
    "title": "ZEETAD: Adapting Pretrained Vision-Language Model for Zero-Shot  End-to-End Temporal Action Detection",
    "abstract": " Title: ZEETAD: Adapting Pretrained Vision-Language Model for Zero-Shot  End-to-End Temporal Action Detection ",
    "url": "https://arxiv.org/abs/2311.00729",
    "authors": [
      "Thinh Phan",
      "Khoa Vo",
      "Duy Le",
      "Gianfranco Doretto",
      "Donald Adjeroh",
      "Ngan Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.00814",
    "title": "Investigating Self-Supervised Deep Representations for EEG-based  Auditory Attention Decoding",
    "abstract": " Comments: Submitted to ICASSP 2024 ",
    "url": "https://arxiv.org/abs/2311.00814",
    "authors": [
      "Karan Thakkar",
      "Jiarui Hai",
      "Mounya Elhilali"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2311.00975",
    "title": "Autonomous Learning of Generative Models with Chemical Reaction Network  Ensembles",
    "abstract": " Title: Autonomous Learning of Generative Models with Chemical Reaction Network  Ensembles ",
    "url": "https://arxiv.org/abs/2311.00975",
    "authors": [
      "William Poole",
      "Thomas E. Ouldridge",
      "Manoj Gopalkrishnan"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)",
      "Biological Physics (physics.bio-ph)"
    ]
  },
  {
    "id": "arXiv:2311.01479",
    "title": "Detecting Out-of-Distribution Through the Lens of Neural Collapse",
    "abstract": " Title: Detecting Out-of-Distribution Through the Lens of Neural Collapse ",
    "url": "https://arxiv.org/abs/2311.01479",
    "authors": [
      "Litian Liu",
      "Yao Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2311.01522",
    "title": "An Efficient Detection and Control System for Underwater Docking using  Machine Learning and Realistic Simulation: A Comprehensive Approach",
    "abstract": " Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible ",
    "url": "https://arxiv.org/abs/2311.01522",
    "authors": [
      "Jalil Chavez-Galaviz",
      "Jianwen Li",
      "Matthew Bergman",
      "Miras Mengdibayev",
      "Nina Mahmoudian"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.02117",
    "title": "Cooperative Network Learning for Large-Scale and Decentralized Graphs",
    "abstract": " Title: Cooperative Network Learning for Large-Scale and Decentralized Graphs ",
    "url": "https://arxiv.org/abs/2311.02117",
    "authors": [
      "Qiang Wu",
      "Yiming Huang",
      "Yujie Zeng",
      "Yijie Teng",
      "Fang Zhou",
      "Linyuan L\u00fc"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.02747",
    "title": "Attention Modules Improve Image-Level Anomaly Detection for Industrial  Inspection: A DifferNet Case Study",
    "abstract": " Comments: Accepted at WACV 2024 ",
    "url": "https://arxiv.org/abs/2311.02747",
    "authors": [
      "Andr\u00e9 Luiz Buarque Vieira e Silva",
      "Francisco Sim\u00f5es",
      "Danny Kowerko",
      "Tobias Schlosser",
      "Felipe Battisti",
      "Veronica Teichrieb"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.02831",
    "title": "SemanticTopoLoop: Semantic Loop Closure With 3D Topological Graph Based  on Quadric-Level Object Map",
    "abstract": " Title: SemanticTopoLoop: Semantic Loop Closure With 3D Topological Graph Based  on Quadric-Level Object Map ",
    "url": "https://arxiv.org/abs/2311.02831",
    "authors": [
      "Zhenzhong Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.03071",
    "title": "OrthoNets: Orthogonal Channel Attention Networks",
    "abstract": " Comments: IEEE BigData 2023 ",
    "url": "https://arxiv.org/abs/2311.03071",
    "authors": [
      "Hadi Salman",
      "Caleb Parks",
      "Matthew Swan",
      "John Gauch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.03076",
    "title": "SugarViT -- Multi-objective Regression of UAV Images with Vision  Transformers and Deep Label Distribution Learning Demonstrated on Disease  Severity Prediction in Sugar Beet",
    "abstract": " Comments: submitted to Computers and Electronics in Agriculture ",
    "url": "https://arxiv.org/abs/2311.03076",
    "authors": [
      "Maurice G\u00fcnder",
      "Facundo Ram\u00f3n Ispizua Yamati",
      "Abel Andree Barreto Alc\u00e1ntara",
      "Anne-Katrin Mahlein",
      "Rafet Sifa",
      "Christian Bauckhage"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]