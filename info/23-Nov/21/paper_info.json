[
  {
    "id": "arXiv:2311.10721",
    "title": "Deep Neuromorphic Networks with Superconducting Single Flux Quanta",
    "abstract": "Conventional semiconductor-based integrated circuits are gradually approaching fundamental scaling limits. Many prospective solutions have recently emerged to supplement or replace both the technology on which basic devices are built and the architecture of data processing. Neuromorphic circuits are a promising approach to computing where techniques used by the brain to achieve high efficiency are exploited. Many existing neuromorphic circuits rely on unconventional and useful properties of novel technologies to better mimic the operation of the brain. One such technology is single flux quantum (SFQ) logic -- a cryogenic superconductive technology in which the data are represented by quanta of magnetic flux (fluxons) produced and processed by Josephson junctions embedded within inductive loops. The movement of a fluxon within a circuit produces a quantized voltage pulse (SFQ pulse), resembling a neuronal spiking event. These circuits routinely operate at clock frequencies of tens to hundreds of gigahertz, making SFQ a natural technology for processing high frequency pulse trains. Prior proposals for SFQ neural networks often require energy-expensive fluxon conversions, involve heterogeneous technologies, or exclusively focus on device level behavior. In this paper, a design methodology for deep single flux quantum neuromorphic networks is presented. Synaptic and neuronal circuits based on SFQ technology are presented and characterized. Based on these primitives, a deep neuromorphic XOR network is evaluated as a case study, both at the architectural and circuit levels, achieving wide classification margins. The proposed methodology does not employ unconventional superconductive devices or semiconductor transistors. The resulting networks are tunable by an external current, making this proposed system an effective approach for scalable cryogenic neuromorphic computing. ",
    "url": "https://arxiv.org/abs/2311.10721",
    "authors": [
      "Gleb Krylov",
      "Alexander J. Edwards",
      "Joseph S. Friedman",
      "Eby G. Friedman"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.10725",
    "title": "Should they? Mobile Biometrics and Technopolicy meet Queer Community  Considerations",
    "abstract": "Smartphones are integral to our daily lives and activities, providing us with basic functions like texting and phone calls to more complex motion-based functionalities like navigation, mobile gaming, and fitness-tracking. To facilitate these functionalities, smartphones rely on integrated sensors like accelerometers and gyroscopes. These sensors provide personalized measurements that, in turn, contribute to tasks such as analyzing biometric data for mobile health purposes. In addition to benefiting smartphone users, biometric data holds significant value for researchers engaged in biometric identification research. Nonetheless, utilizing this user data for biometric identification tasks, such as gait and gender recognition, raises serious privacy, normative, and ethical concerns, particularly within the queer community. Concerns of algorithmic bias and algorithmically-driven dysphoria surface from a historical backdrop of marginalization, surveillance, harassment, discrimination, and violence against the queer community. In this position paper, we contribute to the timely discourse on safeguarding human rights within AI-driven systems by providing a sense of challenges, tensions, and opportunities for new data protections and biometric collection practices in a way that grapples with the sociotechnical realities of the queer community. ",
    "url": "https://arxiv.org/abs/2311.10725",
    "authors": [
      "Anaelia Ovalle",
      "Davi Liang",
      "Alicia Boyd"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.10733",
    "title": "Proceedings of the 3rd International Workshop on Mining and Learning in  the Legal Domain (MLLD-23)",
    "abstract": "This is the Proceedings of the 3rd International Workshop on Mining and Learning in the Legal Domain (MLLD-23) which took place in conjunction with the 32nd ACM International Conference on Information and Knowledge Management (CIKM-2023) at the University of Birmingham, Birmingham, UK on Sunday 22nd October 2023. ",
    "url": "https://arxiv.org/abs/2311.10733",
    "authors": [
      "Masoud Makrehchi",
      "Dell Zhang",
      "Alina Petrova",
      "John Armour"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2311.10736",
    "title": "Systematic Evaluation of Applying Space-Filling Curves to Automotive  Maneuver Detection",
    "abstract": "Identifying driving maneuvers plays an essential role on-board vehicles to monitor driving and driver states, as well as off-board to train and evaluate machine learning algorithms for automated driving for example. Maneuvers can be characterized by vehicle kinematics or data from its surroundings including other traffic participants. Extracting relevant maneuvers therefore requires analyzing time-series of (i) structured, multi-dimensional kinematic data, and (ii) unstructured, large data samples for video, radar, or LiDAR sensors. However, such data analysis requires scalable and computationally efficient approaches, especially for non-annotated data. In this paper, we are presenting a maneuver detection approach based on two variants of space-filling curves (Z-order and Hilbert) to detect maneuvers when passing roundabouts that do not use GPS data. We systematically evaluate their respective performance by including permutations of selections of kinematic signals at varying frequencies and compare them with two alternative baselines: All manually identified roundabouts, and roundabouts that are marked by geofences. We find that encoding just longitudinal and lateral accelerations sampled at 10Hz using a Hilbert space-filling curve is already successfully identifying roundabout maneuvers, which allows to avoid the use of potentially sensitive signals such as GPS locations to comply with data protection and privacy regulations like GDPR. ",
    "url": "https://arxiv.org/abs/2311.10736",
    "authors": [
      "Christian Berger",
      "Beatriz Cabrero-Daniel",
      "M. Cagri Kaya",
      "Maryam Esmaeili Darestani",
      "Hannah Shiels"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.10745",
    "title": "\"Just a little bit on the outside for the whole time\": Social belonging  confidence and the persistence of Machine Learning and Artificial  Intelligence students",
    "abstract": "The growing field of machine learning (ML) and artificial intelligence (AI) presents a unique and unexplored case within persistence research, meaning it is unclear how past findings from engineering will apply to this developing field. We conduct an exploratory study to gain an initial understanding of persistence in this field and identify fruitful directions for future work. One factor that has been shown to predict persistence in engineering is belonging; we study belonging through the lens of confidence, and discuss how attention to social belonging confidence may help to increase diversity in the profession. In this research paper, we conduct a small set of interviews with students in ML/AI courses. Thematic analysis of these interviews revealed initial differences in how students see a career in ML/AI, which diverge based on interest and programming confidence. We identified how exposure and initiation, the interpretation of ML and AI field boundaries, and beliefs of the skills required to succeed might influence students' intentions to persist. We discuss differences in how students describe being motivated by social belonging and the importance of close mentorship. We motivate further persistence research in ML/AI with particular focus on social belonging and close mentorship, the role of intersectional identity, and introductory ML/AI courses. ",
    "url": "https://arxiv.org/abs/2311.10745",
    "authors": [
      "Katherine Mao",
      "Sharon Ferguson",
      "James Magarian",
      "Alison Olechowski"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Other Computer Science (cs.OH)"
    ]
  },
  {
    "id": "arXiv:2311.10747",
    "title": "Safety-aware Causal Representation for Trustworthy Reinforcement  Learning in Autonomous Driving",
    "abstract": "In the domain of autonomous driving, the Learning from Demonstration (LfD) paradigm has exhibited notable efficacy in addressing sequential decision-making problems. However, consistently achieving safety in varying traffic contexts, especially in safety-critical scenarios, poses a significant challenge due to the long-tailed and unforeseen scenarios absent from offline datasets. In this paper, we introduce the saFety-aware strUctured Scenario representatION (FUSION), a pioneering methodology conceived to facilitate the learning of an adaptive end-to-end driving policy by leveraging structured scenario information. FUSION capitalizes on the causal relationships between decomposed reward, cost, state, and action space, constructing a framework for structured sequential reasoning under dynamic traffic environments. We conduct rigorous evaluations in two typical real-world settings of distribution shift in autonomous vehicles, demonstrating the good balance between safety cost and utility reward of FUSION compared to contemporary state-of-the-art safety-aware LfD baselines. Empirical evidence under diverse driving scenarios attests that FUSION significantly enhances the safety and generalizability of autonomous driving agents, even in the face of challenging and unseen environments. Furthermore, our ablation studies reveal noticeable improvements in the integration of causal representation into the safe offline RL problem. ",
    "url": "https://arxiv.org/abs/2311.10747",
    "authors": [
      "Haohong Lin",
      "Wenhao Ding",
      "Zuxin Liu",
      "Yaru Niu",
      "Jiacheng Zhu",
      "Yuming Niu",
      "Ding Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.10753",
    "title": "Automating Source Code Refactoring in the Classroom",
    "abstract": "Refactoring is the practice of improving software quality without altering its external behavior. Developers intuitively refactor their code for multiple purposes, such as improving program comprehension, reducing code complexity, dealing with technical debt, and removing code smells. However, no prior studies have exposed the students to an experience of the process of antipatterns detection and refactoring correction, and provided students with toolset to practice it. To understand and increase the awareness of refactoring concepts, in this paper, we aim to reflect on our experience with teaching refactoring and how it helps students become more aware of bad programming practices and the importance of correcting them via refactoring. This paper discusses the results of an experiment in the classroom that involved carrying out various refactoring activities for the purpose of removing antipatterns using JDeodorant, an Eclipse plugin that supports antipatterns detection and refactoring. The results of the quantitative and qualitative analysis with 171 students show that students tend to appreciate the idea of learning refactoring and are satisfied with various aspects of the JDeodorant plugin's operation. Through this experiment, refactoring can turn into a vital part of the computing educational plan. We envision our findings enabling educators to support students with refactoring tools tuned towards safer and trustworthy refactoring. ",
    "url": "https://arxiv.org/abs/2311.10753",
    "authors": [
      "Eman Abdullah AlOmar",
      "Mohamed Wiem Mkaouer",
      "Ali Ouni"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2311.10764",
    "title": "Deep Group Interest Modeling of Full Lifelong User Behaviors for CTR  Prediction",
    "abstract": "Extracting users' interests from their lifelong behavior sequence is crucial for predicting Click-Through Rate (CTR). Most current methods employ a two-stage process for efficiency: they first select historical behaviors related to the candidate item and then deduce the user's interest from this narrowed-down behavior sub-sequence. This two-stage paradigm, though effective, leads to information loss. Solely using users' lifelong click behaviors doesn't provide a complete picture of their interests, leading to suboptimal performance. In our research, we introduce the Deep Group Interest Network (DGIN), an end-to-end method to model the user's entire behavior history. This includes all post-registration actions, such as clicks, cart additions, purchases, and more, providing a nuanced user understanding. We start by grouping the full range of behaviors using a relevant key (like item_id) to enhance efficiency. This process reduces the behavior length significantly, from O(10^4) to O(10^2). To mitigate the potential loss of information due to grouping, we incorporate two categories of group attributes. Within each group, we calculate statistical information on various heterogeneous behaviors (like behavior counts) and employ self-attention mechanisms to highlight unique behavior characteristics (like behavior type). Based on this reorganized behavior data, the user's interests are derived using the Transformer technique. Additionally, we identify a subset of behaviors that share the same item_id with the candidate item from the lifelong behavior sequence. The insights from this subset reveal the user's decision-making process related to the candidate item, improving prediction accuracy. Our comprehensive evaluation, both on industrial and public datasets, validates DGIN's efficacy and efficiency. ",
    "url": "https://arxiv.org/abs/2311.10764",
    "authors": [
      "Qi Liu",
      "Xuyang Hou",
      "Haoran Jin",
      "jin Chen",
      "Zhe Wang",
      "Defu Lian",
      "Tan Qu",
      "Jia Cheng",
      "Jun Lei"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.10780",
    "title": "Extending Neural Network Verification to a Larger Family of Piece-wise  Linear Activation Functions",
    "abstract": "In this paper, we extend an available neural network verification technique to support a wider class of piece-wise linear activation functions. Furthermore, we extend the algorithms, which provide in their original form exact respectively over-approximative results for bounded input sets represented as start sets, to allow also unbounded input set. We implemented our algorithms and demonstrated their effectiveness in some case studies. ",
    "url": "https://arxiv.org/abs/2311.10780",
    "authors": [
      "L\u00e1szl\u00f3 Antal",
      "Hana Masara",
      "Erika \u00c1brah\u00e1m"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2311.10784",
    "title": "ExFake: Towards an Explainable Fake News Detection Based on Content and  Social Context Information",
    "abstract": "ExFake is an explainable fake news detection system based on content and context-level information. It is concerned with the veracity analysis of online posts based on their content, social context (i.e., online users' credibility and historical behaviour), and data coming from trusted entities such as fact-checking websites and named entities. Unlike state-of-the-art systems, an Explainable AI (XAI) assistant is also adopted to help online social networks (OSN) users develop good reflexes when faced with any doubted information that spreads on social networks. The trustworthiness of OSN users is also addressed by assigning a credibility score to OSN users, as OSN users are one of the main culprits for spreading fake news. Experimental analysis on a real-world dataset demonstrates that ExFake significantly outperforms other baseline methods for fake news detection. ",
    "url": "https://arxiv.org/abs/2311.10784",
    "authors": [
      "Sabrine Amri",
      "Henri-Cedric Mputu Boleilanga",
      "Esma A\u00efmeur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.10788",
    "title": "Efficient Temporally-Aware DeepFake Detection using H.264 Motion Vectors",
    "abstract": "Video DeepFakes are fake media created with Deep Learning (DL) that manipulate a person's expression or identity. Most current DeepFake detection methods analyze each frame independently, ignoring inconsistencies and unnatural movements between frames. Some newer methods employ optical flow models to capture this temporal aspect, but they are computationally expensive. In contrast, we propose using the related but often ignored Motion Vectors (MVs) and Information Masks (IMs) from the H.264 video codec, to detect temporal inconsistencies in DeepFakes. Our experiments show that this approach is effective and has minimal computational costs, compared with per-frame RGB-only methods. This could lead to new, real-time temporally-aware DeepFake detection methods for video calls and streaming. ",
    "url": "https://arxiv.org/abs/2311.10788",
    "authors": [
      "Peter Gr\u00f6nquist",
      "Yufan Ren",
      "Qingyi He",
      "Alessio Verardo",
      "Sabine S\u00fcsstrunk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.10789",
    "title": "Stratified-NMF for Heterogeneous Data",
    "abstract": "Non-negative matrix factorization (NMF) is an important technique for obtaining low dimensional representations of datasets. However, classical NMF does not take into account data that is collected at different times or in different locations, which may exhibit heterogeneity. We resolve this problem by solving a modified NMF objective, Stratified-NMF, that simultaneously learns strata-dependent statistics and a shared topics matrix. We develop multiplicative update rules for this novel objective and prove convergence of the objective. Then, we experiment on synthetic data to demonstrate the efficiency and accuracy of the method. Lastly, we apply our method to three real world datasets and empirically investigate their learned features. ",
    "url": "https://arxiv.org/abs/2311.10789",
    "authors": [
      "James Chapman",
      "Yotam Yaniv",
      "Deanna Needell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2311.10802",
    "title": "Is Conventional SNN Really Efficient? A Perspective from Network  Quantization",
    "abstract": "Spiking Neural Networks (SNNs) have been widely praised for their high energy efficiency and immense potential. However, comprehensive research that critically contrasts and correlates SNNs with quantized Artificial Neural Networks (ANNs) remains scant, often leading to skewed comparisons lacking fairness towards ANNs. This paper introduces a unified perspective, illustrating that the time steps in SNNs and quantized bit-widths of activation values present analogous representations. Building on this, we present a more pragmatic and rational approach to estimating the energy consumption of SNNs. Diverging from the conventional Synaptic Operations (SynOps), we champion the \"Bit Budget\" concept. This notion permits an intricate discourse on strategically allocating computational and storage resources between weights, activation values, and temporal steps under stringent hardware constraints. Guided by the Bit Budget paradigm, we discern that pivoting efforts towards spike patterns and weight quantization, rather than temporal attributes, elicits profound implications for model performance. Utilizing the Bit Budget for holistic design consideration of SNNs elevates model performance across diverse data types, encompassing static imagery and neuromorphic datasets. Our revelations bridge the theoretical chasm between SNNs and quantized ANNs and illuminate a pragmatic trajectory for future endeavors in energy-efficient neural computations. ",
    "url": "https://arxiv.org/abs/2311.10802",
    "authors": [
      "Guobin Shen",
      "Dongcheng Zhao",
      "Tenglong Li",
      "Jindong Li",
      "Yi Zeng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.10803",
    "title": "Robustness Enhancement in Neural Networks with Alpha-Stable Training  Noise",
    "abstract": "With the increasing use of deep learning on data collected by non-perfect sensors and in non-perfect environments, the robustness of deep learning systems has become an important issue. A common approach for obtaining robustness to noise has been to train deep learning systems with data augmented with Gaussian noise. In this work, we challenge the common choice of Gaussian noise and explore the possibility of stronger robustness for non-Gaussian impulsive noise, specifically alpha-stable noise. Justified by the Generalized Central Limit Theorem and evidenced by observations in various application areas, alpha-stable noise is widely present in nature. By comparing the testing accuracy of models trained with Gaussian noise and alpha-stable noise on data corrupted by different noise, we find that training with alpha-stable noise is more effective than Gaussian noise, especially when the dataset is corrupted by impulsive noise, thus improving the robustness of the model. The generality of this conclusion is validated through experiments conducted on various deep learning models with image and time series datasets, and other benchmark corrupted datasets. Consequently, we propose a novel data augmentation method that replaces Gaussian noise, which is typically added to the training data, with alpha-stable noise. ",
    "url": "https://arxiv.org/abs/2311.10803",
    "authors": [
      "Xueqiong Yuan",
      "Jipeng Li",
      "Ercan Engin Kuruo\u011flu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.10825",
    "title": "Pudding: Private User Discovery in Anonymity Networks",
    "abstract": "Anonymity networks allow messaging with metadata privacy, providing better privacy than popular encrypted messaging applications. However, contacting a user on an anonymity network currently requires knowing their public key or similar high-entropy information, as these systems lack a privacy-preserving mechanism for contacting a user via a short, human-readable username. Previous research suggests that this is a barrier to widespread adoption. In this paper we propose Pudding, a novel private user discovery protocol that allows a user to be contacted on an anonymity network knowing only their email address. Our protocol hides contact relationships between users, prevents impersonation, and conceals which usernames are registered on the network. Pudding is Byzantine fault tolerant, remaining available and secure as long as less than one third of servers are crashed, unavailable, or malicious. It can be deployed on Loopix and Nym without changes to the underlying anonymity network protocol, and it supports mobile devices with intermittent network connectivity. We demonstrate the practicality of Pudding with a prototype using the Nym anonymity network. We also formally define the security and privacy goals of our protocol and conduct a thorough analysis to assess its compliance with these definitions. ",
    "url": "https://arxiv.org/abs/2311.10825",
    "authors": [
      "Ceren Kocao\u011fullar",
      "Daniel Hugenroth",
      "Martin Kleppmann",
      "Alastair R. Beresford"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.10833",
    "title": "Generative AI has lowered the barriers to computational social sciences",
    "abstract": "Generative artificial intelligence (AI) has revolutionized the field of computational social science, unleashing new possibilities for analyzing multimodal data, especially for scholars who may not have extensive programming expertise. This breakthrough carries profound implications for the realm of social sciences. Firstly, generative AI can significantly enhance the productivity of social scientists by automating the generation, annotation, and debugging of code. Secondly, it empowers researchers to delve into sophisticated data analysis through the innovative use of prompt engineering. Lastly, the educational sphere of computational social science stands to benefit immensely from these tools, given their exceptional ability to annotate and elucidate complex codes for learners, thereby simplifying the learning process and making the technology more accessible. ",
    "url": "https://arxiv.org/abs/2311.10833",
    "authors": [
      "Yongjun Zhang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2311.10837",
    "title": "The hidden dimension of information diffusion: A latent space  representation of Social Media News Sharing behavior",
    "abstract": "In times marked by an abundance of news sources and the widespread use of social media for staying informed, acquiring accurate data faces increasing challenges. Today, access to information plays a crucial role in shaping public opinion and is significantly influenced by interactions on social media. Therefore, studying the dissemination of news on these platforms is vital for understanding how individuals stay informed. In this paper, we study emergent properties of media outlet sharing behavior by users in social media. We quantify this behavior in terms of coordinates in a latent space proposing a metric called Media Sharing Index (MSI). We observe that the MSI shows a bimodal distribution in this latent dimension, reflecting the preference of large groups of users for specific groups of media outlets. This methodology allows the study of the extent to which communities of interacting users are permeable to different sources of information. Additionally, it facilitates the analysis of the relationship between users' media outlet preferences, their political leanings, and the political leanings of the media outlets. ",
    "url": "https://arxiv.org/abs/2311.10837",
    "authors": [
      "Sof\u00eda M del Pozo",
      "Sebasti\u00e1n Pinto",
      "Matteo Serafino",
      "Federico Moss",
      "Tom\u00e1s Cicchini",
      "Hern\u00e1n A Makse",
      "Pablo Balenzuela"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2311.10845",
    "title": "Domain Generalization of 3D Object Detection by Density-Resampling",
    "abstract": "Point-cloud-based 3D object detection suffers from performance degradation when encountering data with novel domain gaps. To tackle it, the single-domain generalization (SDG) aims to generalize the detection model trained in a limited single source domain to perform robustly on unexplored domains. In this paper, we propose an SDG method to improve the generalizability of 3D object detection to unseen target domains. Unlike prior SDG works for 3D object detection solely focusing on data augmentation, our work introduces a novel data augmentation method and contributes a new multi-task learning strategy in the methodology. Specifically, from the perspective of data augmentation, we design a universal physical-aware density-based data augmentation (PDDA) method to mitigate the performance loss stemming from diverse point densities. From the learning methodology viewpoint, we develop a multi-task learning for 3D object detection: during source training, besides the main standard detection task, we leverage an auxiliary self-supervised 3D scene restoration task to enhance the comprehension of the encoder on background and foreground details for better recognition and detection of objects. Furthermore, based on the auxiliary self-supervised task, we propose the first test-time adaptation method for domain generalization of 3D object detection, which efficiently adjusts the encoder's parameters to adapt to unseen target domains during testing time, to further bridge domain gaps. Extensive cross-dataset experiments covering \"Car\", \"Pedestrian\", and \"Cyclist\" detections, demonstrate our method outperforms state-of-the-art SDG methods and even overpass unsupervised domain adaptation methods under some circumstances. The code will be made publicly available. ",
    "url": "https://arxiv.org/abs/2311.10845",
    "authors": [
      "Shuangzhi Li",
      "Lei Ma",
      "Xingyu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.10873",
    "title": "Multi-entity Video Transformers for Fine-Grained Video Representation  Learning",
    "abstract": "The area of temporally fine-grained video representation learning aims to generate frame-by-frame representations for temporally dense tasks. In this work, we advance the state-of-the-art for this area by re-examining the design of transformer architectures for video representation learning. A salient aspect of our self-supervised method is the improved integration of spatial information in the temporal pipeline by representing multiple entities per frame. Prior works use late fusion architectures that reduce frames to a single dimensional vector before any cross-frame information is shared, while our method represents each frame as a group of entities or tokens. Our Multi-entity Video Transformer (MV-Former) architecture achieves state-of-the-art results on multiple fine-grained video benchmarks. MV-Former leverages image features from self-supervised ViTs, and employs several strategies to maximize the utility of the extracted features while also avoiding the need to fine-tune the complex ViT backbone. This includes a Learnable Spatial Token Pooling strategy, which is used to identify and extract features for multiple salient regions per frame. Our experiments show that MV-Former not only outperforms previous self-supervised methods, but also surpasses some prior works that use additional supervision or training data. When combined with additional pre-training data from Kinetics-400, MV-Former achieves a further performance boost. The code for MV-Former is available at https://github.com/facebookresearch/video_rep_learning. ",
    "url": "https://arxiv.org/abs/2311.10873",
    "authors": [
      "Matthew Walmer",
      "Rose Kanjirathinkal",
      "Kai Sheng Tai",
      "Keyur Muzumdar",
      "Taipeng Tian",
      "Abhinav Shrivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.10887",
    "title": "Point Cloud Self-supervised Learning via 3D to Multi-view Masked  Autoencoder",
    "abstract": "In recent years, the field of 3D self-supervised learning has witnessed significant progress, resulting in the emergence of Multi-Modality Masked AutoEncoders (MAE) methods that leverage both 2D images and 3D point clouds for pre-training. However, a notable limitation of these approaches is that they do not fully utilize the multi-view attributes inherent in 3D point clouds, which is crucial for a deeper understanding of 3D structures. Building upon this insight, we introduce a novel approach employing a 3D to multi-view masked autoencoder to fully harness the multi-modal attributes of 3D point clouds. To be specific, our method uses the encoded tokens from 3D masked point clouds to generate original point clouds and multi-view depth images across various poses. This approach not only enriches the model's comprehension of geometric structures but also leverages the inherent multi-modal properties of point clouds. Our experiments illustrate the effectiveness of the proposed method for different tasks and under different settings. Remarkably, our method outperforms state-of-the-art counterparts by a large margin in a variety of downstream tasks, including 3D object classification, few-shot learning, part segmentation, and 3D object detection. Code will be available at: https://github.com/Zhimin-C/Multiview-MAE ",
    "url": "https://arxiv.org/abs/2311.10887",
    "authors": [
      "Zhimin Chen",
      "Yingwei Li",
      "Longlong Jing",
      "Liang Yang",
      "Bing Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.10898",
    "title": "On Functional Activations in Deep Neural Networks",
    "abstract": "Background: Deep neural networks have proven to be powerful computational tools for modeling, prediction, and generation. However, the workings of these models have generally been opaque. Recent work has shown that the performance of some models are modulated by overlapping functional networks of connections within the models. Here the techniques of functional neuroimaging are applied to an exemplary large language model to probe its functional structure. Methods: A series of block-designed task-based prompt sequences were generated to probe the Facebook Galactica-125M model. Tasks included prompts relating to political science, medical imaging, paleontology, archeology, pathology, and random strings presented in an off/on/off pattern with prompts about other random topics. For the generation of each output token, all layer output values were saved to create an effective time series. General linear models were fit to the data to identify layer output values which were active with the tasks. Results: Distinct, overlapping networks were identified with each task. Most overlap was observed between medical imaging and pathology networks. These networks were repeatable across repeated performance of related tasks, and correspondence of identified functional networks and activation in tasks not used to define the functional networks was shown to accurately identify the presented task. Conclusion: The techniques of functional neuroimaging can be applied to deep neural networks as a means to probe their workings. Identified functional networks hold the potential for use in model alignment, modulation of model output, and identifying weights to target in fine-tuning. ",
    "url": "https://arxiv.org/abs/2311.10898",
    "authors": [
      "Andrew S. Nencka",
      "L. Tugan Muftuler",
      "Peter LaViolette",
      "Kevin M. Koch"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.10908",
    "title": "Equivariant Neural Operator Learning with Graphon Convolution",
    "abstract": "We propose a general architecture that combines the coefficient learning scheme with a residual operator layer for learning mappings between continuous functions in the 3D Euclidean space. Our proposed model is guaranteed to achieve SE(3)-equivariance by design. From the graph spectrum view, our method can be interpreted as convolution on graphons (dense graphs with infinitely many nodes), which we term InfGCN. By leveraging both the continuous graphon structure and the discrete graph structure of the input data, our model can effectively capture the geometric information while preserving equivariance. Through extensive experiments on large-scale electron density datasets, we observed that our model significantly outperformed the current state-of-the-art architectures. Multiple ablation studies were also carried out to demonstrate the effectiveness of the proposed architecture. ",
    "url": "https://arxiv.org/abs/2311.10908",
    "authors": [
      "Chaoran Cheng",
      "Jian Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.10919",
    "title": "PACOL: Poisoning Attacks Against Continual Learners",
    "abstract": "Continual learning algorithms are typically exposed to untrusted sources that contain training data inserted by adversaries and bad actors. An adversary can insert a small number of poisoned samples, such as mislabeled samples from previously learned tasks, or intentional adversarial perturbed samples, into the training datasets, which can drastically reduce the model's performance. In this work, we demonstrate that continual learning systems can be manipulated by malicious misinformation and present a new category of data poisoning attacks specific for continual learners, which we refer to as {\\em Poisoning Attacks Against Continual Learners} (PACOL). The effectiveness of labeling flipping attacks inspires PACOL; however, PACOL produces attack samples that do not change the sample's label and produce an attack that causes catastrophic forgetting. A comprehensive set of experiments shows the vulnerability of commonly used generative replay and regularization-based continual learning approaches against attack methods. We evaluate the ability of label-flipping and a new adversarial poison attack, namely PACOL proposed in this work, to force the continual learning system to forget the knowledge of a learned task(s). More specifically, we compared the performance degradation of continual learning systems trained on benchmark data streams with and without poisoning attacks. Moreover, we discuss the stealthiness of the attacks in which we test the success rate of data sanitization defense and other outlier detection-based defenses for filtering out adversarial samples. ",
    "url": "https://arxiv.org/abs/2311.10919",
    "authors": [
      "Huayu Li",
      "Gregory Ditzler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.10924",
    "title": "Faster Streaming and Scalable Algorithms for Finding Directed Dense  Subgraphs in Large Graphs",
    "abstract": "Finding dense subgraphs is a fundamental algorithmic tool in data mining, community detection, and clustering. In this problem, one aims to find an induced subgraph whose edge-to-vertex ratio is maximized. We study the directed case of this question in the context of semi-streaming and massively parallel algorithms. In particular, we show that it is possible to find a $(2+\\epsilon)$ approximation on randomized streams even in a single pass by using $O(n \\cdot {\\rm poly} \\log n)$ memory on $n$-vertex graphs. Our result improves over prior works, which were designed for arbitrary-ordered streams: the algorithm by Bahmani et al. (VLDB 2012) which uses $O(\\log n)$ passes, and the work by Esfandiari et al. (2015) which makes one pass but uses $O(n^{3/2})$ memory. Moreover, our techniques extend to the Massively Parallel Computation model yielding $O(1)$ rounds in the super-linear and $O(\\sqrt{\\log n})$ rounds in the nearly-linear memory regime. This constitutes a quadratic improvement over state-of-the-art bounds by Bahmani et al. (VLDB 2012 and WAW 2014), which require $O(\\log n)$ rounds even in the super-linear memory regime. Finally, we empirically evaluate our single-pass semi-streaming algorithm on $6$ benchmarks and show that, even on non-randomly ordered streams, the quality of its output is essentially the same as that of Bahmani et al. (VLDB 2012) while it is $2$ times faster on large graphs. ",
    "url": "https://arxiv.org/abs/2311.10924",
    "authors": [
      "Slobodan Mitrovi\u0107",
      "Theodore Pan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2311.10944",
    "title": "Deception Detection from Linguistic and Physiological Data Streams Using  Bimodal Convolutional Neural Networks",
    "abstract": "Deception detection is gaining increasing interest due to ethical and security concerns. This paper explores the application of convolutional neural networks for the purpose of multimodal deception detection. We use a dataset built by interviewing 104 subjects about two topics, with one truthful and one falsified response from each subject about each topic. In particular, we make three main contributions. First, we extract linguistic and physiological features from this data to train and construct the neural network models. Second, we propose a fused convolutional neural network model using both modalities in order to achieve an improved overall performance. Third, we compare our new approach with earlier methods designed for multimodal deception detection. We find that our system outperforms regular classification methods; our results indicate the feasibility of using neural networks for deception detection even in the presence of limited amounts of data. ",
    "url": "https://arxiv.org/abs/2311.10944",
    "authors": [
      "Panfeng Li",
      "Mohamed Abouelenien",
      "Rada Mihalcea"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.10952",
    "title": "NAS-ASDet: An Adaptive Design Method for Surface Defect Detection  Network using Neural Architecture Search",
    "abstract": "Deep convolutional neural networks (CNNs) have been widely used in surface defect detection. However, no CNN architecture is suitable for all detection tasks and designing effective task-specific requires considerable effort. The neural architecture search (NAS) technology makes it possible to automatically generate adaptive data-driven networks. Here, we propose a new method called NAS-ASDet to adaptively design network for surface defect detection. First, a refined and industry-appropriate search space that can adaptively adjust the feature distribution is designed, which consists of repeatedly stacked basic novel cells with searchable attention operations. Then, a progressive search strategy with a deep supervision mechanism is used to explore the search space faster and better. This method can design high-performance and lightweight defect detection networks with data scarcity in industrial scenarios. The experimental results on four datasets demonstrate that the proposed method achieves superior performance and a relatively lighter model size compared to other competitive methods, including both manual and NAS-based approaches. ",
    "url": "https://arxiv.org/abs/2311.10952",
    "authors": [
      "Zhenrong Wang",
      "Bin Li",
      "Weifeng Li",
      "Shuanlong Niu",
      "Wang Miao",
      "Tongzhi Niu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.10972",
    "title": "Polynomial-Time Solutions for ReLU Network Training: A Complexity  Classification via Max-Cut and Zonotopes",
    "abstract": "We investigate the complexity of training a two-layer ReLU neural network with weight decay regularization. Previous research has shown that the optimal solution of this problem can be found by solving a standard cone-constrained convex program. Using this convex formulation, we prove that the hardness of approximation of ReLU networks not only mirrors the complexity of the Max-Cut problem but also, in certain special cases, exactly corresponds to it. In particular, when $\\epsilon\\leq\\sqrt{84/83}-1\\approx 0.006$, we show that it is NP-hard to find an approximate global optimizer of the ReLU network objective with relative error $\\epsilon$ with respect to the objective value. Moreover, we develop a randomized algorithm which mirrors the Goemans-Williamson rounding of semidefinite Max-Cut relaxations. To provide polynomial-time approximations, we classify training datasets into three categories: (i) For orthogonal separable datasets, a precise solution can be obtained in polynomial-time. (ii) When there is a negative correlation between samples of different classes, we give a polynomial-time approximation with relative error $\\sqrt{\\pi/2}-1\\approx 0.253$. (iii) For general datasets, the degree to which the problem can be approximated in polynomial-time is governed by a geometric factor that controls the diameter of two zonotopes intrinsic to the dataset. To our knowledge, these results present the first polynomial-time approximation guarantees along with first hardness of approximation results for regularized ReLU networks. ",
    "url": "https://arxiv.org/abs/2311.10972",
    "authors": [
      "Yifei Wang",
      "Mert Pilanci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.10975",
    "title": "Engage Wider Audience or Facilitate Quality Answers? a Mixed-methods  Analysis of Questioning Strategies for Research Sensemaking on a Community  Q&A Site",
    "abstract": "Discussing research-sensemaking questions on Community Question and Answering (CQA) platforms has been an increasingly common practice for the public to participate in science communication. Nonetheless, how users strategically craft research-sensemaking questions to engage public participation and facilitate knowledge construction is a significant yet less understood problem. To fill this gap, we collected 837 science-related questions and 157,684 answers from Zhihu, and conducted a mixed-methods study to explore user-developed strategies in proposing research-sensemaking questions, and their potential effects on public engagement and knowledge construction. Through open coding, we captured a comprehensive taxonomy of question-crafting strategies, such as eyecatching narratives with counter-intuitive claims and rigorous descriptions with data use. Regression analysis indicated that these strategies correlated with user engagement and answer construction in different ways (e.g., emotional questions attracted more views and answers), yet there existed a general divergence between wide participation and quality knowledge establishment, when most questioning strategies could not ensure both. Based on log analysis, we further found that collaborative editing afforded unique values in refining research-sensemaking questions regarding accuracy, rigor, comprehensiveness and attractiveness. We propose design implications to facilitate accessible, accurate and engaging science communication on CQA platforms. ",
    "url": "https://arxiv.org/abs/2311.10975",
    "authors": [
      "Changyang He",
      "Yue Deng",
      "Lu He",
      "Qingyu Guo",
      "Yu Zhang",
      "Zhicong Lu",
      "Bo Li"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2311.10977",
    "title": "Images Connect Us Together: Navigating a COVID-19 Local Outbreak in  China Through Social Media Images",
    "abstract": "Social media images, curated or casual, have become a crucial component of communicating situational information and emotions during health crises. Despite its prevalence and significance in informational dissemination and emotional connection, there lacks a comprehensive understanding of visual crisis communication in the aftermath of a pandemic which is characterized by uncertain local situations and emotional fatigue. To fill this gap, this work collected 345,423 crisis-related posts and 65,376 original images during the Xi'an COVID-19 local outbreak in China, and adopted a mixed-methods approach to understanding themes, goals, and strategies of crisis imagery. Image clustering captured the diversity of visual themes during the outbreak, such as text images embedding authoritative guidelines and ``visual diaries'' recording and sharing the quarantine life. Through text classification of the post that visuals were situated in, we found that different visual themes highly correlated with the informational and emotional goals of the post text, such as adopting text images to convey the latest policies and sharing food images to express anxiety. We further unpacked nuanced strategies of crisis image use through inductive coding, such as signifying authority and triggering empathy. We discuss the opportunities and challenges of crisis imagery and provide design implications to facilitate effective visual crisis communication. ",
    "url": "https://arxiv.org/abs/2311.10977",
    "authors": [
      "Changyang He",
      "Lu He",
      "Wenjie Yang",
      "Bo Li"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.10984",
    "title": "Black Hole Search in Dynamic Cactus Graph",
    "abstract": "We study the problem of black hole search by a set of mobile agents, where the underlying graph is a dynamic cactus. A black hole is a dangerous vertex in the graph that eliminates any visiting agent without leaving any trace behind. Key parameters that dictate the complexity of finding the black hole include: the number of agents required (termed as \\textit{size}), the number of moves performed by the agents in order to determine the black hole location (termed as \\textit{move}) and the \\textit{time} (or round) taken to terminate. This problem has already been studied where the underlying graph is a dynamic ring \\cite{di2021black}. In this paper, we extend the same problem to a dynamic cactus. We introduce two categories of dynamicity, but still the underlying graph needs to be connected: first, we examine the scenario where, at most, one dynamic edge can disappear or reappear at any round. Secondly, we consider the problem for at most $k$ dynamic edges. In both scenarios, we establish lower and upper bounds for the necessary number of agents, moves and rounds. ",
    "url": "https://arxiv.org/abs/2311.10984",
    "authors": [
      "Adri Bhattacharya",
      "Giuseppe F. Italiano",
      "Partha Sarathi Mandal"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.10988",
    "title": "Expanding Scene Graph Boundaries: Fully Open-vocabulary Scene Graph  Generation via Visual-Concept Alignment and Retention",
    "abstract": "Scene Graph Generation (SGG) offers a structured representation critical in many computer vision applications. Traditional SGG approaches, however, are limited by a closed-set assumption, restricting their ability to recognize only predefined object and relation categories. To overcome this, we categorize SGG scenarios into four distinct settings based on the node and edge: Closed-set SGG, Open Vocabulary (object) Detection-based SGG (OvD-SGG), Open Vocabulary Relation-based SGG (OvR-SGG), and Open Vocabulary Detection + Relation-based SGG (OvD+R-SGG). While object-centric open vocabulary SGG has been studied recently, the more challenging problem of relation-involved open-vocabulary SGG remains relatively unexplored. To fill this gap, we propose a unified framework named OvSGTR towards fully open vocabulary SGG from a holistic view. The proposed framework is an end-toend transformer architecture, which learns a visual-concept alignment for both nodes and edges, enabling the model to recognize unseen categories. For the more challenging settings of relation-involved open vocabulary SGG, the proposed approach integrates relation-aware pre-training utilizing image-caption data and retains visual-concept alignment through knowledge distillation. Comprehensive experimental results on the Visual Genome benchmark demonstrate the effectiveness and superiority of the proposed framework. ",
    "url": "https://arxiv.org/abs/2311.10988",
    "authors": [
      "Zuyao Chen",
      "Jinlin Wu",
      "Zhen Lei",
      "Zhaoxiang Zhang",
      "Changwen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.10992",
    "title": "Towards Robust and Accurate Visual Prompting",
    "abstract": "Visual prompting, an efficient method for transfer learning, has shown its potential in vision tasks. However, previous works focus exclusively on VP from standard source models, it is still unknown how it performs under the scenario of a robust source model: Whether a visual prompt derived from a robust model can inherit the robustness while suffering from the generalization performance decline, albeit for a downstream dataset that is different from the source dataset? In this work, we get an affirmative answer of the above question and give an explanation on the visual representation level. Moreover, we introduce a novel technique named Prompt Boundary Loose (PBL) to effectively mitigates the suboptimal results of visual prompt on standard accuracy without losing (or even significantly improving) its adversarial robustness when using a robust model as source model. Extensive experiments across various datasets show that our findings are universal and demonstrate the significant benefits of our proposed method. ",
    "url": "https://arxiv.org/abs/2311.10992",
    "authors": [
      "Qi Li",
      "Liangzhi Li",
      "Zhouqiang Jiang",
      "Bowen Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11001",
    "title": "Gendec: A Machine Learning-based Framework for Gender Detection from  Japanese Names",
    "abstract": "Every human has their own name, a fundamental aspect of their identity and cultural heritage. The name often conveys a wealth of information, including details about an individual's background, ethnicity, and, especially, their gender. By detecting gender through the analysis of names, researchers can unlock valuable insights into linguistic patterns and cultural norms, which can be applied to practical applications. Hence, this work presents a novel dataset for Japanese name gender detection comprising 64,139 full names in romaji, hiragana, and kanji forms, along with their biological genders. Moreover, we propose Gendec, a framework for gender detection from Japanese names that leverages diverse approaches, including traditional machine learning techniques or cutting-edge transfer learning models, to predict the gender associated with Japanese names accurately. Through a thorough investigation, the proposed framework is expected to be effective and serve potential applications in various domains. ",
    "url": "https://arxiv.org/abs/2311.11001",
    "authors": [
      "Duong Tien Pham",
      "Luan Thanh Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.11009",
    "title": "Joyful: Joint Modality Fusion and Graph Contrastive Learning for  Multimodal Emotion Recognition",
    "abstract": "Multimodal emotion recognition aims to recognize emotions for each utterance of multiple modalities, which has received increasing attention for its application in human-machine interaction. Current graph-based methods fail to simultaneously depict global contextual features and local diverse uni-modal features in a dialogue. Furthermore, with the number of graph layers increasing, they easily fall into over-smoothing. In this paper, we propose a method for joint modality fusion and graph contrastive learning for multimodal emotion recognition (Joyful), where multimodality fusion, contrastive learning, and emotion recognition are jointly optimized. Specifically, we first design a new multimodal fusion mechanism that can provide deep interaction and fusion between the global contextual and uni-modal specific features. Then, we introduce a graph contrastive learning framework with inter-view and intra-view contrastive losses to learn more distinguishable representations for samples with different sentiments. Extensive experiments on three benchmark datasets indicate that Joyful achieved state-of-the-art (SOTA) performance compared to all baselines. ",
    "url": "https://arxiv.org/abs/2311.11009",
    "authors": [
      "Dongyuan Li",
      "Yusong Wang",
      "Kotaro Funakoshi",
      "Manabu Okumura"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.11012",
    "title": "Bit Cipher -- A Simple yet Powerful Word Representation System that  Integrates Efficiently with Language Models",
    "abstract": "While Large Language Models (LLMs) become ever more dominant, classic pre-trained word embeddings sustain their relevance through computational efficiency and nuanced linguistic interpretation. Drawing from recent studies demonstrating that the convergence of GloVe and word2vec optimizations all tend towards log-co-occurrence matrix variants, we construct a novel word representation system called Bit-cipher that eliminates the need of backpropagation while leveraging contextual information and hyper-efficient dimensionality reduction techniques based on unigram frequency, providing strong interpretability, alongside efficiency. We use the bit-cipher algorithm to train word vectors via a two-step process that critically relies on a hyperparameter -- bits -- that controls the vector dimension. While the first step trains the bit-cipher, the second utilizes it under two different aggregation modes -- summation or concatenation -- to produce contextually rich representations from word co-occurrences. We extend our investigation into bit-cipher's efficacy, performing probing experiments on part-of-speech (POS) tagging and named entity recognition (NER) to assess its competitiveness with classic embeddings like word2vec and GloVe. Additionally, we explore its applicability in LM training and fine-tuning. By replacing embedding layers with cipher embeddings, our experiments illustrate the notable efficiency of cipher in accelerating the training process and attaining better optima compared to conventional training paradigms. Experiments on the integration of bit-cipher embedding layers with Roberta, T5, and OPT, prior to or as a substitute for fine-tuning, showcase a promising enhancement to transfer learning, allowing rapid model convergence while preserving competitive performance. ",
    "url": "https://arxiv.org/abs/2311.11012",
    "authors": [
      "Haoran Zhao",
      "Jake Ryland Williams"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.11013",
    "title": "Implicit Event-RGBD Neural SLAM",
    "abstract": "Implicit neural SLAM has achieved remarkable progress recently. Nevertheless, existing methods face significant challenges in non-ideal scenarios, such as motion blur or lighting variation, which often leads to issues like convergence failures, localization drifts, and distorted mapping. To address these challenges, we propose $\\textbf{EN-SLAM}$, the first event-RGBD implicit neural SLAM framework, which effectively leverages the high rate and high dynamic range advantages of event data for tracking and mapping. Specifically, EN-SLAM proposes a differentiable CRF (Camera Response Function) rendering technique to generate distinct RGB and event camera data via a shared radiance field, which is optimized by learning a unified implicit representation with the captured event and RGBD supervision. Moreover, based on the temporal difference property of events, we propose a temporal aggregating optimization strategy for the event joint tracking and global bundle adjustment, capitalizing on the consecutive difference constraints of events, significantly enhancing tracking accuracy and robustness. Finally, we construct the simulated dataset $\\textbf{DEV-Indoors}$ and real captured dataset $\\textbf{DEV-Reals}$ containing 6 scenes, 17 sequences with practical motion blur and lighting changes for evaluations. Experimental results show that our method outperforms the SOTA methods in both tracking ATE and mapping ACC with a real-time $17$ FPS in various challenging environments. The code and dataset will be released upon the paper publication. ",
    "url": "https://arxiv.org/abs/2311.11013",
    "authors": [
      "Delin Qu",
      "Chi Yan",
      "Dong Wang",
      "Jie Yin",
      "Dan Xu",
      "Bin Zhao",
      "Xuelong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11014",
    "title": "Lesion Search with Self-supervised Learning",
    "abstract": "Content-based image retrieval (CBIR) with self-supervised learning (SSL) accelerates clinicians' interpretation of similar images without manual annotations. We develop a CBIR from the contrastive learning SimCLR and incorporate a generalized-mean (GeM) pooling followed by L2 normalization to classify lesion types and retrieve similar images before clinicians' analysis. Results have shown improved performance. We additionally build an open-source application for image analysis and retrieval. The application is easy to integrate, relieving manual efforts and suggesting the potential to support clinicians' everyday activities. ",
    "url": "https://arxiv.org/abs/2311.11014",
    "authors": [
      "Kristin Qi",
      "Jiali Cheng",
      "Daniel Haehn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11016",
    "title": "SNI-SLAM: Semantic Neural Implicit SLAM",
    "abstract": "We propose SNI-SLAM, a semantic SLAM system utilizing neural implicit representation, that simultaneously performs accurate semantic mapping, high-quality surface reconstruction, and robust camera tracking. In this system, we introduce hierarchical semantic representation to allow multi-level semantic comprehension for top-down structured semantic mapping of the scene. In addition, to fully utilize the correlation between multiple attributes of the environment, we integrate appearance, geometry and semantic features through cross-attention for feature collaboration. This strategy enables a more multifaceted understanding of the environment, thereby allowing SNI-SLAM to remain robust even when single attribute is defective. Then, we design an internal fusion-based decoder to obtain semantic, RGB, Truncated Signed Distance Field (TSDF) values from multi-level features for accurate decoding. Furthermore, we propose a feature loss to update the scene representation at the feature level. Compared with low-level losses such as RGB loss and depth loss, our feature loss is capable of guiding the network optimization on a higher-level. Our SNI-SLAM method demonstrates superior performance over all recent NeRF-based SLAM methods in terms of mapping and tracking accuracy on Replica and ScanNet datasets, while also showing excellent capabilities in accurate semantic segmentation and real-time semantic mapping. ",
    "url": "https://arxiv.org/abs/2311.11016",
    "authors": [
      "Siting Zhu",
      "Guangming Wang",
      "Hermann Blum",
      "Jiuming Liu",
      "Liang Song",
      "Marc Pollefeys",
      "Hesheng Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.11017",
    "title": "Improving Adversarial Transferability by Stable Diffusion",
    "abstract": "Deep neural networks (DNNs) are susceptible to adversarial examples, which introduce imperceptible perturbations to benign samples, deceiving DNN predictions. While some attack methods excel in the white-box setting, they often struggle in the black-box scenario, particularly against models fortified with defense mechanisms. Various techniques have emerged to enhance the transferability of adversarial attacks for the black-box scenario. Among these, input transformation-based attacks have demonstrated their effectiveness. In this paper, we explore the potential of leveraging data generated by Stable Diffusion to boost adversarial transferability. This approach draws inspiration from recent research that harnessed synthetic data generated by Stable Diffusion to enhance model generalization. In particular, previous work has highlighted the correlation between the presence of both real and synthetic data and improved model generalization. Building upon this insight, we introduce a novel attack method called Stable Diffusion Attack Method (SDAM), which incorporates samples generated by Stable Diffusion to augment input images. Furthermore, we propose a fast variant of SDAM to reduce computational overhead while preserving high adversarial transferability. Our extensive experimental results demonstrate that our method outperforms state-of-the-art baselines by a substantial margin. Moreover, our approach is compatible with existing transfer-based attacks to further enhance adversarial transferability. ",
    "url": "https://arxiv.org/abs/2311.11017",
    "authors": [
      "Jiayang Liu",
      "Siyu Zhu",
      "Siyuan Liang",
      "Jie Zhang",
      "Han Fang",
      "Weiming Zhang",
      "Ee-Chien Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11018",
    "title": "SORTAD: Self-Supervised Optimized Random Transformations for Anomaly  Detection in Tabular Data",
    "abstract": "We consider a self-supervised approach to anomaly detection in tabular data. Random transformations are applied to the data, and then each transformation is identified based on its output. These predicted transformations are used to identify anomalies. In tabular data this approach faces many challenges that are related to the uncorrelated nature of the data. These challenges affect the transformations that should be used, as well as the use of their predictions. To this end, we propose SORTAD, a novel algorithm that is tailor-made to solve these challenges. SORTAD optimally chooses random transformations that help the classification process, and have a scoring function that is more sensitive to the changes in the transformations classification prediction encountered in tabular data. SORTAD achieved state-of-the-art results on multiple commonly used anomaly detection data sets, as well as in the overall results across all data sets tested. ",
    "url": "https://arxiv.org/abs/2311.11018",
    "authors": [
      "Guy Hay",
      "Pablo Liberman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.11055",
    "title": "Designing Interpretable ML System to Enhance Trustworthy AI in  Healthcare: A Systematic Review of the Last Decade to A Proposed Robust  Framework",
    "abstract": "AI-based medical technologies, including wearables, telemedicine, LLMs, and digital care twins, significantly impact healthcare. Ensuring AI results are accurate and interpretable is crucial, especially for clinicians. This paper reviews processes and challenges of interpretable ML (IML) and explainable AI (XAI) in healthcare. Objectives include reviewing XAI processes, methods, applications, and challenges, with a focus on quality control. The IML process is classified into data pre-processing interpretability, interpretable modeling, and post-processing interpretability. The paper aims to establish the importance of robust interpretability in healthcare through experimental results, providing insights for creating communicable clinician-AI tools. Research questions, eligibility criteria, and goals were identified following PRISMA and PICO methods. PubMed, Scopus, and Web of Science were systematically searched using specific strings. The survey introduces a step-by-step roadmap for implementing XAI in clinical applications, addressing existing gaps and acknowledging XAI model limitations. ",
    "url": "https://arxiv.org/abs/2311.11055",
    "authors": [
      "Elham Nasarian",
      "Roohallah Alizadehsani",
      "U. Rajendra Acharyac",
      "d Kwok-Leung Tsui"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.11063",
    "title": "Hierarchical Cut Labelling -- Scaling Up Distance Queries on Road  Networks",
    "abstract": "Answering the shortest-path distance between two arbitrary locations is a fundamental problem in road networks. Labelling-based solutions are the current state-of-the-arts to render fast response time, which can generally be categorised into hub-based labellings, highway-based labellings, and tree decomposition labellings. Hub-based and highway-based labellings exploit hierarchical structures of road networks with the aim to reduce labelling size for improving query efficiency. However, these solutions still result in large search spaces on distance labels at query time, particularly when road networks are large. Tree decomposition labellings leverage a hierarchy of vertices to reduce search spaces over distance labels at query time, but such a hierarchy is generated using tree decomposition techniques, which may yield very large labelling sizes and slow querying. In this paper, we propose a novel solution \\emph{hierarchical cut 2-hop labelling (HC2L)} to address the drawbacks of the existing works. Our solution combines the benefits of hierarchical structures from both perspectives - reduce the size of a distance labelling at preprocessing time and further reduce the search space on a distance labelling at query time. At its core, we propose a new hierarchy, \\emph{balanced tree hierarchy}, which enables a fast, efficient data structure to reduce the size of distance labelling and to select a very small subset of labels to compute the shortest-path distance at query time. To speed up the construction process of HC2L, we further propose a parallel variant of our method, namely HC2L$^p$. We have evaluated our solution on 10 large real-world road networks through extensive experiments. ",
    "url": "https://arxiv.org/abs/2311.11063",
    "authors": [
      "Muhammad Farhan",
      "Henning Koehler",
      "Robert Ohms",
      "Qing Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2311.11073",
    "title": "Community-Aware Efficient Graph Contrastive Learning via Personalized  Self-Training",
    "abstract": "In recent years, graph contrastive learning (GCL) has emerged as one of the optimal solutions for various supervised tasks at the node level. However, for unsupervised and structure-related tasks such as community detection, current GCL algorithms face difficulties in acquiring the necessary community-level information, resulting in poor performance. In addition, general contrastive learning algorithms improve the performance of downstream tasks by increasing the number of negative samples, which leads to severe class collision and unfairness of community detection. To address above issues, we propose a novel Community-aware Efficient Graph Contrastive Learning Framework (CEGCL) to jointly learn community partition and node representations in an end-to-end manner. Specifically, we first design a personalized self-training (PeST) strategy for unsupervised scenarios, which enables our model to capture precise community-level personalized information in a graph. With the benefit of the PeST, we alleviate class collision and unfairness without sacrificing the overall model performance. Furthermore, the aligned graph clustering (AlGC) is employed to obtain the community partition. In this module, we align the clustering space of our downstream task with that in PeST to achieve more consistent node embeddings. Finally, we demonstrate the effectiveness of our model for community detection both theoretically and experimentally. Extensive experimental results also show that our CEGCL exhibits state-of-the-art performance on three benchmark datasets with different scales. ",
    "url": "https://arxiv.org/abs/2311.11073",
    "authors": [
      "Yuecheng Li",
      "Yanming Hu",
      "Lele Fu",
      "Chuan Chen",
      "Lei Yang",
      "Zibin Zheng"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.11080",
    "title": "DSCom: A Data-Driven Self-Adaptive Community-Based Framework for  Influence Maximization in Social Networks",
    "abstract": "Influence maximization aims to find a subset of seeds that maximize the influence spread under a given budget. In this paper, we mainly address the data-driven version of this problem, where the diffusion model is not given but needs to be inferred from the history cascades. Several previous works have addressed this topic in a statistical way and provided efficient algorithms with theoretical guarantee. However, in their settings, though the diffusion parameters are inferred, they still need users to preset the diffusion model, which can be an intractable problem in real-world practices. In this paper, we reformulate the problem on the attributed network and leverage the node attributes to estimate the closeness between the connected nodes. Specifically, we propose a machine learning-based framework, named DSCom, to address this problem in a heuristic way. Under this framework, we first infer the users' relationship from the diffusion dataset through attention mechanism and then leverage spectral clustering to overcome the influence overlap problem in the lack of exact diffusion formula. Compared to the previous theoretical works, we carefully designed empirical experiments with parameterized diffusion models based on real-world social networks, which prove the efficiency and effectiveness of our algorithm. ",
    "url": "https://arxiv.org/abs/2311.11080",
    "authors": [
      "Yuxin Zuo",
      "Haojia Sun",
      "Yongyi Hu",
      "Jianxiong Guo",
      "Xiaofeng Gao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11085",
    "title": "Compositional Fusion of Signals in Data Embedding",
    "abstract": "Embeddings in AI convert symbolic structures into fixed-dimensional vectors, effectively fusing multiple signals. However, the nature of this fusion in real-world data is often unclear. To address this, we introduce two methods: (1) Correlation-based Fusion Detection, measuring correlation between known attributes and embeddings, and (2) Additive Fusion Detection, viewing embeddings as sums of individual vectors representing attributes. Applying these methods, word embeddings were found to combine semantic and morphological signals. BERT sentence embeddings were decomposed into individual word vectors of subject, verb and object. In the knowledge graph-based recommender system, user embeddings, even without training on demographic data, exhibited signals of demographics like age and gender. This study highlights that embeddings are fusions of multiple signals, from Word2Vec components to demographic hints in graph embeddings. ",
    "url": "https://arxiv.org/abs/2311.11085",
    "authors": [
      "Zhijin Guo",
      "Zhaozhen Xu",
      "Martha Lewis",
      "Nello Cristianini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.11091",
    "title": "Deep Tensor Network",
    "abstract": "In this paper, we delve into the foundational principles of tensor categories, harnessing the universal property of the tensor product to pioneer novel methodologies in deep network architectures. Our primary contribution is the introduction of the Tensor Attention and Tensor Interaction Mechanism, a groundbreaking approach that leverages the tensor category to enhance the computational efficiency and the expressiveness of deep networks, and can even be generalized into the quantum realm. ",
    "url": "https://arxiv.org/abs/2311.11091",
    "authors": [
      "Yifan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2311.11106",
    "title": "ShapeMaker: Self-Supervised Joint Shape Canonicalization, Segmentation,  Retrieval and Deformation",
    "abstract": "In this paper, we present ShapeMaker, a unified self-supervised learning framework for joint shape canonicalization, segmentation, retrieval and deformation. Given a partially-observed object in an arbitrary pose, we first canonicalize the object by extracting point-wise affine-invariant features, disentangling inherent structure of the object with its pose and size. These learned features are then leveraged to predict semantically consistent part segmentation and corresponding part centers. Next, our lightweight retrieval module aggregates the features within each part as its retrieval token and compare all the tokens with source shapes from a pre-established database to identify the most geometrically similar shape. Finally, we deform the retrieved shape in the deformation module to tightly fit the input object by harnessing part center guided neural cage deformation. The key insight of ShapeMaker is the simultaneous training of the four highly-associated processes: canonicalization, segmentation, retrieval, and deformation, leveraging cross-task consistency losses for mutual supervision. Extensive experiments on synthetic datasets PartNet, ComplementMe, and real-world dataset Scan2CAD demonstrate that ShapeMaker surpasses competitors by a large margin. Codes will be released soon. ",
    "url": "https://arxiv.org/abs/2311.11106",
    "authors": [
      "Yan Di",
      "Chenyangguang Zhang",
      "Chaowei Wang",
      "Ruida Zhang",
      "Guangyao Zhai",
      "Yanyan Li",
      "Bowen Fu",
      "Xiangyang Ji",
      "Shan Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11114",
    "title": "Environment-Aware Dynamic Graph Learning for Out-of-Distribution  Generalization",
    "abstract": "Dynamic graph neural networks (DGNNs) are increasingly pervasive in exploiting spatio-temporal patterns on dynamic graphs. However, existing works fail to generalize under distribution shifts, which are common in real-world scenarios. As the generation of dynamic graphs is heavily influenced by latent environments, investigating their impacts on the out-of-distribution (OOD) generalization is critical. However, it remains unexplored with the following two major challenges: (1) How to properly model and infer the complex environments on dynamic graphs with distribution shifts? (2) How to discover invariant patterns given inferred spatio-temporal environments? To solve these challenges, we propose a novel Environment-Aware dynamic Graph LEarning (EAGLE) framework for OOD generalization by modeling complex coupled environments and exploiting spatio-temporal invariant patterns. Specifically, we first design the environment-aware EA-DGNN to model environments by multi-channel environments disentangling. Then, we propose an environment instantiation mechanism for environment diversification with inferred distributions. Finally, we discriminate spatio-temporal invariant patterns for out-of-distribution prediction by the invariant pattern recognition mechanism and perform fine-grained causal interventions node-wisely with a mixture of instantiated environment samples. Experiments on real-world and synthetic dynamic graph datasets demonstrate the superiority of our method against state-of-the-art baselines under distribution shifts. To the best of our knowledge, we are the first to study OOD generalization on dynamic graphs from the environment learning perspective. ",
    "url": "https://arxiv.org/abs/2311.11114",
    "authors": [
      "Haonan Yuan",
      "Qingyun Sun",
      "Xingcheng Fu",
      "Ziwei Zhang",
      "Cheng Ji",
      "Hao Peng",
      "Jianxin Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11120",
    "title": "An Improved Neural Network Model Based On CNN Using For Fruit Sugar  Degree Detection",
    "abstract": "Artificial Intelligence(AI) widely applies in Image Classification and Recognition, Text Understanding and Natural Language Processing, which makes great progress. In this paper, we introduced AI into the fruit quality detection field. We designed a fruit sugar degree regression model using an Artificial Neural Network based on spectra of fruits within the visible/near-infrared(V/NIR)range. After analysis of fruit spectra, we innovatively proposed a new neural network structure: low layers consist of a Multilayer Perceptron(MLP), a middle layer is a 2-dimensional correlation matrix layer, and high layers consist of several Convolutional Neural Network(CNN) layers. In this study, we used fruit sugar value as a detection target, collecting two fruits called Gan Nan Navel and Tian Shan Pear as samples, doing experiments respectively, and comparing their results. We used Analysis of Variance(ANOVA) to evaluate the reliability of the dataset we collected. Then, we tried multiple strategies to process spectrum data, evaluating their effects. In this paper, we tried to add Wavelet Decomposition(WD) to reduce feature dimensions and a Genetic Algorithm(GA) to find excellent features. Then, we compared Neural Network models with traditional Partial Least Squares(PLS) based models. We also compared the neural network structure we designed(MLP-CNN) with other traditional neural network structures. In this paper, we proposed a new evaluation standard derived from dataset standard deviation(STD) for evaluating detection performance, validating the viability of using an artificial neural network model to do fruit sugar degree nondestructive detection. ",
    "url": "https://arxiv.org/abs/2311.11120",
    "authors": [
      "Boyang Deng",
      "Xin Wen",
      "Zhan Gao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11126",
    "title": "Bayesian Neural Networks: A Min-Max Game Framework",
    "abstract": "Bayesian neural networks use random variables to describe the neural networks rather than deterministic neural networks and are mostly trained by variational inference which updates the mean and variance at the same time. Here, we formulate the Bayesian neural networks as a minimax game problem. We do the experiments on the MNIST data set and the primary result is comparable to the existing closed-loop transcription neural network. Finally, we reveal the connections between Bayesian neural networks and closed-loop transcription neural networks, and show our framework is rather practical, and provide another view of Bayesian neural networks. ",
    "url": "https://arxiv.org/abs/2311.11126",
    "authors": [
      "Junping Hong",
      "Ercan Engin Kuruoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11147",
    "title": "Toward A Generic Vehicular Cloud Network Architecture: A Case of Virtual  Vehicle As A Service",
    "abstract": "In recent years, cloud computing has gained more and more popularity. The motivation towards implementing cloud computing in vehicular networks is due to the availability of communication, storage, and computing resources represented by communication, vehicles, roadside units (RSUs), and central servers. These resources can be utilized and provided to vehicles, drivers on the road, travellers, and customers on the internet. Intelligent Transportation System (ITS) applications can utilize vehicular cloud computing to provide efficient real-time services, as well as to improve transportation safety, mobility, and comfort levels for drivers. In this paper, all possible vehicular cloud models are presented. Each vehicular cloud model offers different services. Integrating all vehicular cloud models into one integrated system will provide all services and serve internet users, passengers, and vehicles. Therefore, a generic vehicular cloud model is proposed. After that, a new service called Virtual Vehicle is proposed in vehicular cloud computing. The virtual vehicle is a virtual machine that migrates from one physical vehicle to another. It provides the same services as the physical vehicle according to the consumer's requirements. ",
    "url": "https://arxiv.org/abs/2311.11147",
    "authors": [
      "Fekri M. Abduljalil"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2311.11157",
    "title": "Contextualizing Internet Memes Across Social Media Platforms",
    "abstract": "Internet memes have emerged as a novel format for communication and expressing ideas on the web. Their fluidity and creative nature are reflected in their widespread use, often across platforms and occasionally for unethical or harmful purposes. While computational work has already analyzed their high-level virality over time and developed specialized classifiers for hate speech detection, there have been no efforts to date that aim to holistically track, identify, and map internet memes posted on social media. To bridge this gap, we investigate whether internet memes across social media platforms can be contextualized by using a semantic repository of knowledge, namely, a knowledge graph. We collect thousands of potential internet meme posts from two social media platforms, namely Reddit and Discord, and perform an extract-transform-load procedure to create a data lake with candidate meme posts. By using vision transformer-based similarity, we match these candidates against the memes cataloged in a recently released knowledge graph of internet memes, IMKG. We provide evidence that memes published online can be identified by mapping them to IMKG. We leverage this grounding to study the prevalence of memes on different platforms, discover popular memes, and select common meme channels and subreddits. Finally, we illustrate how the grounding can enable users to get context about memes on social media thanks to their link to the knowledge graph. ",
    "url": "https://arxiv.org/abs/2311.11157",
    "authors": [
      "Saurav Joshi",
      "Filip Ilievski",
      "Luca Luceri"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2311.11161",
    "title": "Experts-in-the-Loop: Establishing an Effective Workflow in Crafting  Privacy Q&A",
    "abstract": "Privacy policies play a vital role in safeguarding user privacy as legal jurisdictions worldwide emphasize the need for transparent data processing. While the suitability of privacy policies to enhance transparency has been critically discussed, employing conversational AI systems presents unique challenges in informing users effectively. In this position paper, we propose a dynamic workflow for transforming privacy policies into privacy question-and-answer (Q&A) pairs to make privacy policies easily accessible through conversational AI. Thereby, we facilitate interdisciplinary collaboration among legal experts and conversation designers, while also considering the utilization of large language models' generative capabilities and addressing associated challenges. Our proposed workflow underscores continuous improvement and monitoring throughout the construction of privacy Q&As, advocating for comprehensive review and refinement through an experts-in-the-loop approach. ",
    "url": "https://arxiv.org/abs/2311.11161",
    "authors": [
      "Zahra Kolagar",
      "Anna Katharina Leschanowsky",
      "Birgit Popp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.11172",
    "title": "Low-Precision Floating-Point for Efficient On-Board Deep Neural Network  Processing",
    "abstract": "One of the major bottlenecks in high-resolution Earth Observation (EO) space systems is the downlink between the satellite and the ground. Due to hardware limitations, on-board power limitations or ground-station operation costs, there is a strong need to reduce the amount of data transmitted. Various processing methods can be used to compress the data. One of them is the use of on-board deep learning to extract relevant information in the data. However, most ground-based deep neural network parameters and computations are performed using single-precision floating-point arithmetic, which is not adapted to the context of on-board processing. We propose to rely on quantized neural networks and study how to combine low precision (mini) floating-point arithmetic with a Quantization-Aware Training methodology. We evaluate our approach with a semantic segmentation task for ship detection using satellite images from the Airbus Ship dataset. Our results show that 6-bit floating-point quantization for both weights and activations can compete with single-precision without significant accuracy degradation. Using a Thin U-Net 32 model, only a 0.3% accuracy degradation is observed with 6-bit minifloat quantization (a 6-bit equivalent integer-based approach leads to a 0.5% degradation). An initial hardware study also confirms the potential impact of such low-precision floating-point designs, but further investigation at the scale of a full inference accelerator is needed before concluding whether they are relevant in a practical on-board scenario. ",
    "url": "https://arxiv.org/abs/2311.11172",
    "authors": [
      "C\u00e9dric Gernigon",
      "Silviu-Ioan Filip",
      "Olivier Sentieys",
      "Cl\u00e9ment Coggiola",
      "Micka\u00ebl Bruno"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.11177",
    "title": "Assessing the Security of GitHub Copilot Generated Code -- A Targeted  Replication Study",
    "abstract": "AI-powered code generation models have been developing rapidly, allowing developers to expedite code generation and thus improve their productivity. These models are trained on large corpora of code (primarily sourced from public repositories), which may contain bugs and vulnerabilities. Several concerns have been raised about the security of the code generated by these models. Recent studies have investigated security issues in AI-powered code generation tools such as GitHub Copilot and Amazon CodeWhisperer, revealing several security weaknesses in the code generated by these tools. As these tools evolve, it is expected that they will improve their security protocols to prevent the suggestion of insecure code to developers. This paper replicates the study of Pearce et al., which investigated security weaknesses in Copilot and uncovered several weaknesses in the code suggested by Copilot across diverse scenarios and languages (Python, C and Verilog). Our replication examines Copilot security weaknesses using newer versions of Copilot and CodeQL (the security analysis framework). The replication focused on the presence of security vulnerabilities in Python code. Our results indicate that, even with the improvements in newer versions of Copilot, the percentage of vulnerable code suggestions has reduced from 36.54% to 27.25%. Nonetheless, it remains evident that the model still suggests insecure code. ",
    "url": "https://arxiv.org/abs/2311.11177",
    "authors": [
      "Vahid Majdinasab",
      "Michael Joshua Bishop",
      "Shawn Rasheed",
      "Arghavan Moradidakhel",
      "Amjed Tahir",
      "Foutse Khomh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2311.11184",
    "title": "Diverse Shape Completion via Style Modulated Generative Adversarial  Networks",
    "abstract": "Shape completion aims to recover the full 3D geometry of an object from a partial observation. This problem is inherently multi-modal since there can be many ways to plausibly complete the missing regions of a shape. Such diversity would be indicative of the underlying uncertainty of the shape and could be preferable for downstream tasks such as planning. In this paper, we propose a novel conditional generative adversarial network that can produce many diverse plausible completions of a partially observed point cloud. To enable our network to produce multiple completions for the same partial input, we introduce stochasticity into our network via style modulation. By extracting style codes from complete shapes during training, and learning a distribution over them, our style codes can explicitly carry shape category information leading to better completions. We further introduce diversity penalties and discriminators at multiple scales to prevent conditional mode collapse and to train without the need for multiple ground truth completions for each partial input. Evaluations across several synthetic and real datasets demonstrate that our method achieves significant improvements in respecting the partial observations while obtaining greater diversity in completions. ",
    "url": "https://arxiv.org/abs/2311.11184",
    "authors": [
      "Wesley Khademi",
      "Li Fuxin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11191",
    "title": "Attention-Based Real-Time Defenses for Physical Adversarial Attacks in  Vision Applications",
    "abstract": "Deep neural networks exhibit excellent performance in computer vision tasks, but their vulnerability to real-world adversarial attacks, achieved through physical objects that can corrupt their predictions, raises serious security concerns for their application in safety-critical domains. Existing defense methods focus on single-frame analysis and are characterized by high computational costs that limit their applicability in multi-frame scenarios, where real-time decisions are crucial. To address this problem, this paper proposes an efficient attention-based defense mechanism that exploits adversarial channel-attention to quickly identify and track malicious objects in shallow network layers and mask their adversarial effects in a multi-frame setting. This work advances the state of the art by enhancing existing over-activation techniques for real-world adversarial attacks to make them usable in real-time applications. It also introduces an efficient multi-frame defense framework, validating its efficacy through extensive experiments aimed at evaluating both defense performance and computational cost. ",
    "url": "https://arxiv.org/abs/2311.11191",
    "authors": [
      "Giulio Rossolini",
      "Alessandro Biondi",
      "Giorgio Buttazzo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11198",
    "title": "Self-Supervised Versus Supervised Training for Segmentation of Organoid  Images",
    "abstract": "The process of annotating relevant data in the field of digital microscopy can be both time-consuming and especially expensive due to the required technical skills and human-expert knowledge. Consequently, large amounts of microscopic image data sets remain unlabeled, preventing their effective exploitation using deep-learning algorithms. In recent years it has been shown that a lot of relevant information can be drawn from unlabeled data. Self-supervised learning (SSL) is a promising solution based on learning intrinsic features under a pretext task that is similar to the main task without requiring labels. The trained result is transferred to the main task - image segmentation in our case. A ResNet50 U-Net was first trained to restore images of liver progenitor organoids from augmented images using the Structural Similarity Index Metric (SSIM), alone, and using SSIM combined with L1 loss. Both the encoder and decoder were trained in tandem. The weights were transferred to another U-Net model designed for segmentation with frozen encoder weights, using Binary Cross Entropy, Dice, and Intersection over Union (IoU) losses. For comparison, we used the same U-Net architecture to train two supervised models, one utilizing the ResNet50 encoder as well as a simple CNN. Results showed that self-supervised learning models using a 25\\% pixel drop or image blurring augmentation performed better than the other augmentation techniques using the IoU loss. When trained on only 114 images for the main task, the self-supervised learning approach outperforms the supervised method achieving an F1-score of 0.85, with higher stability, in contrast to an F1=0.78 scored by the supervised method. Furthermore, when trained with larger data sets (1,000 images), self-supervised learning is still able to perform better, achieving an F1-score of 0.92, contrasting to a score of 0.85 for the supervised method. ",
    "url": "https://arxiv.org/abs/2311.11198",
    "authors": [
      "Asmaa Haja",
      "Eric Brouwer",
      "Lambert Schomaker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.11206",
    "title": "Robust Network Slicing: Multi-Agent Policies, Adversarial Attacks, and  Defensive Strategies",
    "abstract": "In this paper, we present a multi-agent deep reinforcement learning (deep RL) framework for network slicing in a dynamic environment with multiple base stations and multiple users. In particular, we propose a novel deep RL framework with multiple actors and centralized critic (MACC) in which actors are implemented as pointer networks to fit the varying dimension of input. We evaluate the performance of the proposed deep RL algorithm via simulations to demonstrate its effectiveness. Subsequently, we develop a deep RL based jammer with limited prior information and limited power budget. The goal of the jammer is to minimize the transmission rates achieved with network slicing and thus degrade the network slicing agents' performance. We design a jammer with both listening and jamming phases and address jamming location optimization as well as jamming channel optimization via deep RL. We evaluate the jammer at the optimized location, generating interference attacks in the optimized set of channels by switching between the jamming phase and listening phase. We show that the proposed jammer can significantly reduce the victims' performance without direct feedback or prior knowledge on the network slicing policies. Finally, we devise a Nash-equilibrium-supervised policy ensemble mixed strategy profile for network slicing (as a defensive measure) and jamming. We evaluate the performance of the proposed policy ensemble algorithm by applying on the network slicing agents and the jammer agent in simulations to show its effectiveness. ",
    "url": "https://arxiv.org/abs/2311.11206",
    "authors": [
      "Feng Wang",
      "M. Cenk Gursoy",
      "Senem Velipasalar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2311.11208",
    "title": "LogicNet: A Logical Consistency Embedded Face Attribute Learning Network",
    "abstract": "Ensuring logical consistency in predictions is a crucial yet overlooked aspect in multi-attribute classification. We explore the potential reasons for this oversight and introduce two pressing challenges to the field: 1) How can we ensure that a model, when trained with data checked for logical consistency, yields predictions that are logically consistent? 2) How can we achieve the same with data that hasn't undergone logical consistency checks? Minimizing manual effort is also essential for enhancing automation. To address these challenges, we introduce two datasets, FH41K and CelebA-logic, and propose LogicNet, an adversarial training framework that learns the logical relationships between attributes. Accuracy of LogicNet surpasses that of the next-best approach by 23.05%, 9.96%, and 1.71% on FH37K, FH41K, and CelebA-logic, respectively. In real-world case analysis, our approach can achieve a reduction of more than 50% in the average number of failed cases compared to other methods. ",
    "url": "https://arxiv.org/abs/2311.11208",
    "authors": [
      "Haiyu Wu",
      "Sicong Tian",
      "Huayu Li",
      "Kevin W. Bowyer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11210",
    "title": "HiH: A Multi-modal Hierarchy in Hierarchy Network for Unconstrained Gait  Recognition",
    "abstract": "Gait recognition has achieved promising advances in controlled settings, yet it significantly struggles in unconstrained environments due to challenges such as view changes, occlusions, and varying walking speeds. Additionally, efforts to fuse multiple modalities often face limited improvements because of cross-modality incompatibility, particularly in outdoor scenarios. To address these issues, we present a multi-modal Hierarchy in Hierarchy network (HiH) that integrates silhouette and pose sequences for robust gait recognition. HiH features a main branch that utilizes Hierarchical Gait Decomposer (HGD) modules for depth-wise and intra-module hierarchical examination of general gait patterns from silhouette data. This approach captures motion hierarchies from overall body dynamics to detailed limb movements, facilitating the representation of gait attributes across multiple spatial resolutions. Complementing this, an auxiliary branch, based on 2D joint sequences, enriches the spatial and temporal aspects of gait analysis. It employs a Deformable Spatial Enhancement (DSE) module for pose-guided spatial attention and a Deformable Temporal Alignment (DTA) module for aligning motion dynamics through learned temporal offsets. Extensive evaluations across diverse indoor and outdoor datasets demonstrate HiH's state-of-the-art performance, affirming a well-balanced trade-off between accuracy and efficiency. ",
    "url": "https://arxiv.org/abs/2311.11210",
    "authors": [
      "Lei Wang",
      "Yinchi Ma",
      "Peng Luan",
      "Wei Yao",
      "Congcong Li",
      "Bo Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11212",
    "title": "Can We Utilize Pre-trained Language Models within Causal Discovery  Algorithms?",
    "abstract": "Scaling laws have allowed Pre-trained Language Models (PLMs) into the field of causal reasoning. Causal reasoning of PLM relies solely on text-based descriptions, in contrast to causal discovery which aims to determine the causal relationships between variables utilizing data. Recently, there has been current research regarding a method that mimics causal discovery by aggregating the outcomes of repetitive causal reasoning, achieved through specifically designed prompts. It highlights the usefulness of PLMs in discovering cause and effect, which is often limited by a lack of data, especially when dealing with multiple variables. Conversely, the characteristics of PLMs which are that PLMs do not analyze data and they are highly dependent on prompt design leads to a crucial limitation for directly using PLMs in causal discovery. Accordingly, PLM-based causal reasoning deeply depends on the prompt design and carries out the risk of overconfidence and false predictions in determining causal relationships. In this paper, we empirically demonstrate the aforementioned limitations of PLM-based causal reasoning through experiments on physics-inspired synthetic data. Then, we propose a new framework that integrates prior knowledge obtained from PLM with a causal discovery algorithm. This is accomplished by initializing an adjacency matrix for causal discovery and incorporating regularization using prior knowledge. Our proposed framework not only demonstrates improved performance through the integration of PLM and causal discovery but also suggests how to leverage PLM-extracted prior knowledge with existing causal discovery algorithms. ",
    "url": "https://arxiv.org/abs/2311.11212",
    "authors": [
      "Chanhui Lee",
      "Juhyeon Kim",
      "Yongjun Jeong",
      "Juhyun Lyu",
      "Junghee Kim",
      "Sangmin Lee",
      "Sangjun Han",
      "Hyeokjun Choe",
      "Soyeon Park",
      "Woohyung Lim",
      "Sungbin Lim",
      "Sanghack Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.11225",
    "title": "TextGuard: Provable Defense against Backdoor Attacks on Text  Classification",
    "abstract": "Backdoor attacks have become a major security threat for deploying machine learning models in security-critical applications. Existing research endeavors have proposed many defenses against backdoor attacks. Despite demonstrating certain empirical defense efficacy, none of these techniques could provide a formal and provable security guarantee against arbitrary attacks. As a result, they can be easily broken by strong adaptive attacks, as shown in our evaluation. In this work, we propose TextGuard, the first provable defense against backdoor attacks on text classification. In particular, TextGuard first divides the (backdoored) training data into sub-training sets, achieved by splitting each training sentence into sub-sentences. This partitioning ensures that a majority of the sub-training sets do not contain the backdoor trigger. Subsequently, a base classifier is trained from each sub-training set, and their ensemble provides the final prediction. We theoretically prove that when the length of the backdoor trigger falls within a certain threshold, TextGuard guarantees that its prediction will remain unaffected by the presence of the triggers in training and testing inputs. In our evaluation, we demonstrate the effectiveness of TextGuard on three benchmark text classification tasks, surpassing the certification accuracy of existing certified defenses against backdoor attacks. Furthermore, we propose additional strategies to enhance the empirical performance of TextGuard. Comparisons with state-of-the-art empirical defenses validate the superiority of TextGuard in countering multiple backdoor attacks. Our code and data are available at https://github.com/AI-secure/TextGuard. ",
    "url": "https://arxiv.org/abs/2311.11225",
    "authors": [
      "Hengzhi Pei",
      "Jinyuan Jia",
      "Wenbo Guo",
      "Bo Li",
      "Dawn Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.11227",
    "title": "FedRA: A Random Allocation Strategy for Federated Tuning to Unleash the  Power of Heterogeneous Clients",
    "abstract": "With the increasing availability of Foundation Models, federated tuning has garnered attention in the field of federated learning, utilizing data and computation resources from multiple clients to collaboratively fine-tune foundation models. However, in real-world federated scenarios, there often exist a multitude of heterogeneous clients with varying computation and communication resources, rendering them incapable of supporting the entire model fine-tuning process. In response to this challenge, we propose a novel federated tuning algorithm, FedRA. The implementation of FedRA is straightforward and can be seamlessly integrated into any transformer-based model without the need for further modification to the original model. Specifically, in each communication round, FedRA randomly generates an allocation matrix. For resource-constrained clients, it reorganizes a small number of layers from the original model based on the allocation matrix and fine-tunes using LoRA. Subsequently, the server aggregates the updated LoRA parameters from the clients according to the current allocation matrix into the corresponding layers of the original model. It is worth noting that FedRA also supports scenarios where none of the clients can support the entire global model, which is an impressive advantage. We conduct experiments on two large-scale image datasets, DomainNet and NICO++, under various non-iid settings. The results demonstrate that FedRA outperforms the compared methods significantly. The source code is available at \\url{https://github.com/leondada/FedRA}. ",
    "url": "https://arxiv.org/abs/2311.11227",
    "authors": [
      "Shangchao Su",
      "Bin Li",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.11229",
    "title": "Causal ATE Mitigates Unintended Bias in Controlled Text Generation",
    "abstract": "We study attribute control in language models through the method of Causal Average Treatment Effect (Causal ATE). Existing methods for the attribute control task in Language Models (LMs) check for the co-occurrence of words in a sentence with the attribute of interest, and control for them. However, spurious correlation of the words with the attribute in the training dataset, can cause models to hallucinate the presence of the attribute when presented with the spurious correlate during inference. We show that the simple perturbation-based method of Causal ATE removes this unintended effect. Additionally, we offer a theoretical foundation for investigating Causal ATE in the classification task, and prove that it reduces the number of false positives -- thereby mitigating the issue of unintended bias. Specifically, we ground it in the problem of toxicity mitigation, where a significant challenge lies in the inadvertent bias that often emerges towards protected groups post detoxification. We show that this unintended bias can be solved by the use of the Causal ATE metric. ",
    "url": "https://arxiv.org/abs/2311.11229",
    "authors": [
      "Rahul Madhavan",
      "Kahini Wadhawan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.11235",
    "title": "Unraveling the `Anomaly' in Time Series Anomaly Detection: A  Self-supervised Tri-domain Solution",
    "abstract": "The ongoing challenges in time series anomaly detection (TSAD), notably the scarcity of anomaly labels and the variability in anomaly lengths and shapes, have led to the need for a more efficient solution. As limited anomaly labels hinder traditional supervised models in TSAD, various SOTA deep learning techniques, such as self-supervised learning, have been introduced to tackle this issue. However, they encounter difficulties handling variations in anomaly lengths and shapes, limiting their adaptability to diverse anomalies. Additionally, many benchmark datasets suffer from the problem of having explicit anomalies that even random functions can detect. This problem is exacerbated by ill-posed evaluation metrics, known as point adjustment (PA), which can result in inflated model performance. In this context, we propose a novel self-supervised learning based Tri-domain Anomaly Detector (TriAD), which addresses these challenges by modeling features across three data domains - temporal, frequency, and residual domains - without relying on anomaly labels. Unlike traditional contrastive learning methods, TriAD employs both inter-domain and intra-domain contrastive loss to learn common attributes among normal data and differentiate them from anomalies. Additionally, our approach can detect anomalies of varying lengths by integrating with a discord discovery algorithm. It is worth noting that this study is the first to reevaluate the deep learning potential in TSAD, utilizing both rigorously designed datasets (i.e., UCR Archive) and evaluation metrics (i.e., PA%K and affiliation). Through experimental results on the UCR dataset, TriAD achieves an impressive three-fold increase in PA%K based F1 scores over SOTA deep learning models, and 50% increase of accuracy as compared to SOTA discord discovery algorithms. ",
    "url": "https://arxiv.org/abs/2311.11235",
    "authors": [
      "Yuting Sun",
      "Guansong Pang",
      "Guanhua Ye",
      "Tong Chen",
      "Xia Hu",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11249",
    "title": "Open Set Dandelion Network for IoT Intrusion Detection",
    "abstract": "As IoT devices become widely, it is crucial to protect them from malicious intrusions. However, the data scarcity of IoT limits the applicability of traditional intrusion detection methods, which are highly data-dependent. To address this, in this paper we propose the Open-Set Dandelion Network (OSDN) based on unsupervised heterogeneous domain adaptation in an open-set manner. The OSDN model performs intrusion knowledge transfer from the knowledge-rich source network intrusion domain to facilitate more accurate intrusion detection for the data-scarce target IoT intrusion domain. Under the open-set setting, it can also detect newly-emerged target domain intrusions that are not observed in the source domain. To achieve this, the OSDN model forms the source domain into a dandelion-like feature space in which each intrusion category is compactly grouped and different intrusion categories are separated, i.e., simultaneously emphasising inter-category separability and intra-category compactness. The dandelion-based target membership mechanism then forms the target dandelion. Then, the dandelion angular separation mechanism achieves better inter-category separability, and the dandelion embedding alignment mechanism further aligns both dandelions in a finer manner. To promote intra-category compactness, the discriminating sampled dandelion mechanism is used. Assisted by the intrusion classifier trained using both known and generated unknown intrusion knowledge, a semantic dandelion correction mechanism emphasises easily-confused categories and guides better inter-category separability. Holistically, these mechanisms form the OSDN model that effectively performs intrusion knowledge transfer to benefit IoT intrusion detection. Comprehensive experiments on several intrusion datasets verify the effectiveness of the OSDN model, outperforming three state-of-the-art baseline methods by 16.9%. ",
    "url": "https://arxiv.org/abs/2311.11249",
    "authors": [
      "Jiashu Wu",
      "Hao Dai",
      "Kenneth B. Kent",
      "Jerome Yen",
      "Chengzhong Xu",
      "Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.11261",
    "title": "Adversarial Prompt Tuning for Vision-Language Models",
    "abstract": "With the rapid advancement of multimodal learning, pre-trained Vision-Language Models (VLMs) such as CLIP have demonstrated remarkable capacities in bridging the gap between visual and language modalities. However, these models remain vulnerable to adversarial attacks, particularly in the image modality, presenting considerable security risks. This paper introduces Adversarial Prompt Tuning (AdvPT), a novel technique to enhance the adversarial robustness of image encoders in VLMs. AdvPT innovatively leverages learnable text prompts and aligns them with adversarial image embeddings, to address the vulnerabilities inherent in VLMs without the need for extensive parameter training or modification of the model architecture. We demonstrate that AdvPT improves resistance against white-box and black-box adversarial attacks and exhibits a synergistic effect when combined with existing image-processing-based defense techniques, further boosting defensive capabilities. Comprehensive experimental analyses provide insights into adversarial prompt tuning, a novel paradigm devoted to improving resistance to adversarial images through textual input modifications, paving the way for future robust multimodal learning research. These findings open up new possibilities for enhancing the security of VLMs. Our code will be available upon publication of the paper. ",
    "url": "https://arxiv.org/abs/2311.11261",
    "authors": [
      "Jiaming Zhang",
      "Xingjun Ma",
      "Xin Wang",
      "Lingyu Qiu",
      "Jiaqi Wang",
      "Yu-Gang Jiang",
      "Jitao Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11262",
    "title": "Uncertainty quantification for noisy inputs-outputs in physics-informed  neural networks and neural operators",
    "abstract": "Uncertainty quantification (UQ) in scientific machine learning (SciML) becomes increasingly critical as neural networks (NNs) are being widely adopted in addressing complex problems across various scientific disciplines. Representative SciML models are physics-informed neural networks (PINNs) and neural operators (NOs). While UQ in SciML has been increasingly investigated in recent years, very few works have focused on addressing the uncertainty caused by the noisy inputs, such as spatial-temporal coordinates in PINNs and input functions in NOs. The presence of noise in the inputs of the models can pose significantly more challenges compared to noise in the outputs of the models, primarily due to the inherent nonlinearity of most SciML algorithms. As a result, UQ for noisy inputs becomes a crucial factor for reliable and trustworthy deployment of these models in applications involving physical knowledge. To this end, we introduce a Bayesian approach to quantify uncertainty arising from noisy inputs-outputs in PINNs and NOs. We show that this approach can be seamlessly integrated into PINNs and NOs, when they are employed to encode the physical information. PINNs incorporate physics by including physics-informed terms via automatic differentiation, either in the loss function or the likelihood, and often take as input the spatial-temporal coordinate. Therefore, the present method equips PINNs with the capability to address problems where the observed coordinate is subject to noise. On the other hand, pretrained NOs are also commonly employed as equation-free surrogates in solving differential equations and Bayesian inverse problems, in which they take functions as inputs. The proposed approach enables them to handle noisy measurements for both input and output functions with UQ. ",
    "url": "https://arxiv.org/abs/2311.11262",
    "authors": [
      "Zongren Zou",
      "Xuhui Meng",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2311.11278",
    "title": "Transcending Forgery Specificity with Latent Space Augmentation for  Generalizable Deepfake Detection",
    "abstract": "Deepfake detection faces a critical generalization hurdle, with performance deteriorating when there is a mismatch between the distributions of training and testing data. A broadly received explanation is the tendency of these detectors to be overfitted to forgery-specific artifacts, rather than learning features that are widely applicable across various forgeries. To address this issue, we propose a simple yet effective detector called LSDA (\\underline{L}atent \\underline{S}pace \\underline{D}ata \\underline{A}ugmentation), which is based on a heuristic idea: representations with a wider variety of forgeries should be able to learn a more generalizable decision boundary, thereby mitigating the overfitting of method-specific features (see Figure. 1). Following this idea, we propose to enlarge the forgery space by constructing and simulating variations within and across forgery features in the latent space. This approach encompasses the acquisition of enriched, domain-specific features and the facilitation of smoother transitions between different forgery types, effectively bridging domain gaps. Our approach culminates in refining a binary classifier that leverages the distilled knowledge from the enhanced features, striving for a generalizable deepfake detector. Comprehensive experiments show that our proposed method is surprisingly effective and transcends state-of-the-art detectors across several widely used benchmarks. ",
    "url": "https://arxiv.org/abs/2311.11278",
    "authors": [
      "Zhiyuan Yan",
      "Yuhao Luo",
      "Siwei Lyu",
      "Qingshan Liu",
      "Baoyuan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11289",
    "title": "Pair-wise Layer Attention with Spatial Masking for Video Prediction",
    "abstract": "Video prediction yields future frames by employing the historical frames and has exhibited its great potential in many applications, e.g., meteorological prediction, and autonomous driving. Previous works often decode the ultimate high-level semantic features to future frames without texture details, which deteriorates the prediction quality. Motivated by this, we develop a Pair-wise Layer Attention (PLA) module to enhance the layer-wise semantic dependency of the feature maps derived from the U-shape structure in Translator, by coupling low-level visual cues and high-level features. Hence, the texture details of predicted frames are enriched. Moreover, most existing methods capture the spatiotemporal dynamics by Translator, but fail to sufficiently utilize the spatial features of Encoder. This inspires us to design a Spatial Masking (SM) module to mask partial encoding features during pretraining, which adds the visibility of remaining feature pixels by Decoder. To this end, we present a Pair-wise Layer Attention with Spatial Masking (PLA-SM) framework for video prediction to capture the spatiotemporal dynamics, which reflect the motion trend. Extensive experiments and rigorous ablation studies on five benchmarks demonstrate the advantages of the proposed approach. The code is available at GitHub. ",
    "url": "https://arxiv.org/abs/2311.11289",
    "authors": [
      "Ping Li",
      "Chenhan Zhang",
      "Zheng Yang",
      "Xianghua Xu",
      "Mingli Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11300",
    "title": "Robust Control of Unknown Switched Linear Systems from Noisy Data",
    "abstract": "This paper investigates the problem of data-driven stabilization for linear discrete-time switched systems with unknown switching dynamics. In the absence of noise, a data-based state feedback stabilizing controller can be obtained by solving a semi-definite program (SDP) on-the-fly, which automatically adapts to the changes of switching dynamics. However, when noise is present, the persistency of excitation condition based on the closed-loop data may be undermined, rendering the SDP infeasible. To address this issue, an auxiliary function-based switching control law is proposed, which only requires intermittent SDP solutions when its feasibility is guaranteed. By analyzing the relationship between the controller and the system switching times, it is shown that the proposed controller guarantees input-to-state practical stability (ISpS) of the closed-loop switched linear system, provided that the noise is bounded and the dynamics switches slowly enough. Two numerical examples are presented to verify the effectiveness of the proposed controller. ",
    "url": "https://arxiv.org/abs/2311.11300",
    "authors": [
      "Wenjie Liu",
      "Yifei Li",
      "Jian Sun",
      "Gang Wang",
      "Jie Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.11302",
    "title": "Exchanging Dual Encoder-Decoder: A New Strategy for Change Detection  with Semantic Guidance and Spatial Localization",
    "abstract": "Change detection is a critical task in earth observation applications. Recently, deep learning-based methods have shown promising performance and are quickly adopted in change detection. However, the widely used multiple encoder and single decoder (MESD) as well as dual encoder-decoder (DED) architectures still struggle to effectively handle change detection well. The former has problems of bitemporal feature interference in the feature-level fusion, while the latter is inapplicable to intraclass change detection and multiview building change detection. To solve these problems, we propose a new strategy with an exchanging dual encoder-decoder structure for binary change detection with semantic guidance and spatial localization. The proposed strategy solves the problems of bitemporal feature inference in MESD by fusing bitemporal features in the decision level and the inapplicability in DED by determining changed areas using bitemporal semantic features. We build a binary change detection model based on this strategy, and then validate and compare it with 18 state-of-the-art change detection methods on six datasets in three scenarios, including intraclass change detection datasets (CDD, SYSU), single-view building change detection datasets (WHU, LEVIR-CD, LEVIR-CD+) and a multiview building change detection dataset (NJDS). The experimental results demonstrate that our model achieves superior performance with high efficiency and outperforms all benchmark methods with F1-scores of 97.77%, 83.07%, 94.86%, 92.33%, 91.39%, 74.35% on CDD, SYSU, WHU, LEVIR-CD, LEVIR- CD+, and NJDS datasets, respectively. The code of this work will be available at https://github.com/NJU-LHRS/official-SGSLN. ",
    "url": "https://arxiv.org/abs/2311.11302",
    "authors": [
      "Sijie Zhao",
      "Xueliang Zhang",
      "Pengfeng Xiao",
      "Guangjun He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11334",
    "title": "Using Causal Threads to Explain Changes in a Dynamic System",
    "abstract": "We explore developing rich semantic models of systems. Specifically, we consider structured causal explanations about state changes in those systems. Essentially, we are developing process-based dynamic knowledge graphs. As an example, we construct a model of the causal threads for geological changes proposed by the Snowball Earth theory. Further, we describe an early prototype of a graphical interface to present the explanations. Unlike statistical approaches to summarization and explanation such as Large Language Models (LLMs), our approach of direct representation can be inspected and verified directly. ",
    "url": "https://arxiv.org/abs/2311.11334",
    "authors": [
      "Robert B. Allen"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11335",
    "title": "Self-Distilled Representation Learning for Time Series",
    "abstract": "Self-supervised learning for time-series data holds potential similar to that recently unleashed in Natural Language Processing and Computer Vision. While most existing works in this area focus on contrastive learning, we propose a conceptually simple yet powerful non-contrastive approach, based on the data2vec self-distillation framework. The core of our method is a student-teacher scheme that predicts the latent representation of an input time series from masked views of the same time series. This strategy avoids strong modality-specific assumptions and biases typically introduced by the design of contrastive sample pairs. We demonstrate the competitiveness of our approach for classification and forecasting as downstream tasks, comparing with state-of-the-art self-supervised learning methods on the UCR and UEA archives as well as the ETT and Electricity datasets. ",
    "url": "https://arxiv.org/abs/2311.11335",
    "authors": [
      "Felix Pieper",
      "Konstantin Ditschuneit",
      "Martin Genzel",
      "Alexandra Lindt",
      "Johannes Otterbach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.11337",
    "title": "H2 suboptimal containment control of homogeneous and heterogeneous  multi-agent systems",
    "abstract": "This paper deals with the H2 suboptimal state containment control problem for homogeneous linear multi-agent systems and the H2 suboptimal output containment control problem for heterogeneous linear multi-agent systems. For both problems, given multiple autonomous leaders and a number of followers, we introduce suitable performance outputs and an associated H2 cost functional, respectively. The aim is to design a distributed protocol by dynamic output feedback that achieves state/output containment control while the associated H2 cost is smaller than an a priori given upper bound. To this end, we first show that the H2 suboptimal state/output containment control problem can be equivalently transformed into H2 suboptimal control problems for a set of independent systems. Based on this, design methods are then provided to compute such distributed dynamic output feedback protocols. Simulation examples are provided to illustrate the performance of our proposed protocols. ",
    "url": "https://arxiv.org/abs/2311.11337",
    "authors": [
      "Yuan Gao",
      "Junjie Jiao",
      "Zhongkui Li",
      "Sandra Hirche"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2311.11340",
    "title": "RflyMAD: A Dataset for Multicopter Fault Detection and Health Assessment",
    "abstract": "This paper presents an open-source dataset RflyMAD, a Multicopter Abnomal Dataset developed by Reliable Flight Control (Rfly) Group aiming to promote the development of research fields like fault detection and isolation (FDI) or health assessment (HA). The entire 114 GB dataset includes 11 types of faults under 6 flight statuses which are adapted from ADS-33 file to cover more occasions in which the multicopters have different mobility levels when faults occur. In the total 5629 flight cases, the fault time is up to 3283 minutes, and there are 2566 cases for software-in-the-loop (SIL) simulation, 2566 cases for hardware-in-the-loop (HIL) simulation and 497 cases for real flight. As it contains simulation data based on RflySim and real flight data, it is possible to improve the quantity while increasing the data quality. In each case, there are ULog, Telemetry log, Flight information and processed files for researchers to use and check. The RflyMAD dataset could be used as a benchmark for fault diagnosis methods and the support relationship between simulation data and real flight is verified through transfer learning methods. More methods as a baseline will be presented in the future, and RflyMAD will be updated with more data and types. In addition, the dataset and related toolkit can be accessed through https://rfly-openha.github.io/documents/4_resources/dataset.html. ",
    "url": "https://arxiv.org/abs/2311.11340",
    "authors": [
      "Xiangli Le",
      "Bo Jin",
      "Gen Cui",
      "Xunhua Dai",
      "Quan Quan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.11343",
    "title": "A Generative Model for Accelerated Inverse Modelling Using a Novel  Embedding for Continuous Variables",
    "abstract": "In materials science, the challenge of rapid prototyping materials with desired properties often involves extensive experimentation to find suitable microstructures. Additionally, finding microstructures for given properties is typically an ill-posed problem where multiple solutions may exist. Using generative machine learning models can be a viable solution which also reduces the computational cost. This comes with new challenges because, e.g., a continuous property variable as conditioning input to the model is required. We investigate the shortcomings of an existing method and compare this to a novel embedding strategy for generative models that is based on the binary representation of floating point numbers. This eliminates the need for normalization, preserves information, and creates a versatile embedding space for conditioning the generative model. This technique can be applied to condition a network on any number, to provide fine control over generated microstructure images, thereby contributing to accelerated materials design. ",
    "url": "https://arxiv.org/abs/2311.11343",
    "authors": [
      "S\u00e9bastien Bompas abd Stefan Sandfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)"
    ]
  },
  {
    "id": "arXiv:2311.11348",
    "title": "p-adaptive discontinuous Galerkin method for the shallow water equations  on heterogeneous computing architectures",
    "abstract": "Heterogeneous computing and exploiting integrated CPU-GPU architectures has become a clear current trend since the flattening of Moore's Law. In this work, we propose a numerical and algorithmic re-design of a p-adaptive quadrature-free discontinuous Galerkin method (DG) for the shallow water equations (SWE). Our new approach separates the computations of the non-adaptive (lower-order) and adaptive (higher-order) parts of the discretization form each other. Thereby, we can overlap computations of the lower-order and the higher-order DG solution components. Furthermore, we investigate execution times of main computational kernels and use automatic code generation to optimize their distribution between the CPU and GPU. Several setups, including a prototype of a tsunami simulation in a tide-driven flow scenario, are investigated, and the results show that significant performance improvements can be achieved in suitable setups. ",
    "url": "https://arxiv.org/abs/2311.11348",
    "authors": [
      "Sara Faghih-Naini",
      "Vadym Aizinger",
      "Sebastian Kuckuk",
      "Richard Angersbach",
      "Harald K\u00f6stler"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.11354",
    "title": "Scale-aware competition network for palmprint recognition",
    "abstract": "Palmprint biometrics garner heightened attention in palm-scanning payment and social security due to their distinctive attributes. However, prevailing methodologies singularly prioritize texture orientation, neglecting the significant texture scale dimension. We design an innovative network for concurrently extracting intra-scale and inter-scale features to redress this limitation. This paper proposes a scale-aware competitive network (SAC-Net), which includes the Inner-Scale Competition Module (ISCM) and the Across-Scale Competition Module (ASCM) to capture texture characteristics related to orientation and scale. ISCM efficiently integrates learnable Gabor filters and a self-attention mechanism to extract rich orientation data and discern textures with long-range discriminative properties. Subsequently, ASCM leverages a competitive strategy across various scales to effectively encapsulate the competitive texture scale elements. By synergizing ISCM and ASCM, our method adeptly characterizes palmprint features. Rigorous experimentation across three benchmark datasets unequivocally demonstrates our proposed approach's exceptional recognition performance and resilience relative to state-of-the-art alternatives. ",
    "url": "https://arxiv.org/abs/2311.11354",
    "authors": [
      "Chengrui Gao",
      "Ziyuan Yang",
      "Min Zhu",
      "Andrew Beng Jin Teo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11368",
    "title": "Self-Supervised Pretraining for Heterogeneous Hypergraph Neural Networks",
    "abstract": "Recently, pretraining methods for the Graph Neural Networks (GNNs) have been successful at learning effective representations from unlabeled graph data. However, most of these methods rely on pairwise relations in the graph and do not capture the underling higher-order relations between entities. Hypergraphs are versatile and expressive structures that can effectively model higher-order relationships among entities in the data. Despite the efforts to adapt GNNs to hypergraphs (HyperGNN), there are currently no fully self-supervised pretraining methods for HyperGNN on heterogeneous hypergraphs. In this paper, we present SPHH, a novel self-supervised pretraining framework for heterogeneous HyperGNNs. Our method is able to effectively capture higher-order relations among entities in the data in a self-supervised manner. SPHH is consist of two self-supervised pretraining tasks that aim to simultaneously learn both local and global representations of the entities in the hypergraph by using informative representations derived from the hypergraph structure. Overall, our work presents a significant advancement in the field of self-supervised pretraining of HyperGNNs, and has the potential to improve the performance of various graph-based downstream tasks such as node classification and link prediction tasks which are mapped to hypergraph configuration. Our experiments on two real-world benchmarks using four different HyperGNN models show that our proposed SPHH framework consistently outperforms state-of-the-art baselines in various downstream tasks. The results demonstrate that SPHH is able to improve the performance of various HyperGNN models in various downstream tasks, regardless of their architecture or complexity, which highlights the robustness of our framework. ",
    "url": "https://arxiv.org/abs/2311.11368",
    "authors": [
      "Abdalgader Abubaker",
      "Takanori Maehara",
      "Madhav Nimishakavi",
      "Vassilis Plachouras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.11371",
    "title": "SOccDPT: Semi-Supervised 3D Semantic Occupancy from Dense Prediction  Transformers trained under memory constraints",
    "abstract": "We present SOccDPT, a memory-efficient approach for 3D semantic occupancy prediction from monocular image input using dense prediction transformers. To address the limitations of existing methods trained on structured traffic datasets, we train our model on unstructured datasets including the Indian Driving Dataset and Bengaluru Driving Dataset. Our semi-supervised training pipeline allows SOccDPT to learn from datasets with limited labels by reducing the requirement for manual labelling by substituting it with pseudo-ground truth labels to produce our Bengaluru Semantic Occupancy Dataset. This broader training enhances our model's ability to handle unstructured traffic scenarios effectively. To overcome memory limitations during training, we introduce patch-wise training where we select a subset of parameters to train each epoch, reducing memory usage during auto-grad graph construction. In the context of unstructured traffic and memory-constrained training and inference, SOccDPT outperforms existing disparity estimation approaches as shown by the RMSE score of 9.1473, achieves a semantic segmentation IoU score of 46.02% and operates at a competitive frequency of 69.47 Hz. We make our code and semantic occupancy dataset public. ",
    "url": "https://arxiv.org/abs/2311.11371",
    "authors": [
      "Aditya Nalgunda Ganesh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11375",
    "title": "ML-LMCL: Mutual Learning and Large-Margin Contrastive Learning for  Improving ASR Robustness in Spoken Language Understanding",
    "abstract": "Spoken language understanding (SLU) is a fundamental task in the task-oriented dialogue systems. However, the inevitable errors from automatic speech recognition (ASR) usually impair the understanding performance and lead to error propagation. Although there are some attempts to address this problem through contrastive learning, they (1) treat clean manual transcripts and ASR transcripts equally without discrimination in fine-tuning; (2) neglect the fact that the semantically similar pairs are still pushed away when applying contrastive learning; (3) suffer from the problem of Kullback-Leibler (KL) vanishing. In this paper, we propose Mutual Learning and Large-Margin Contrastive Learning (ML-LMCL), a novel framework for improving ASR robustness in SLU. Specifically, in fine-tuning, we apply mutual learning and train two SLU models on the manual transcripts and the ASR transcripts, respectively, aiming to iteratively share knowledge between these two models. We also introduce a distance polarization regularizer to avoid pushing away the intra-cluster pairs as much as possible. Moreover, we use a cyclical annealing schedule to mitigate KL vanishing issue. Experiments on three datasets show that ML-LMCL outperforms existing models and achieves new state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2311.11375",
    "authors": [
      "Xuxin Cheng",
      "Bowen Cao",
      "Qichen Ye",
      "Zhihong Zhu",
      "Hongxiang Li",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.11423",
    "title": "Offline Reinforcement Learning for Wireless Network Optimization with  Mixture Datasets",
    "abstract": "The recent development of reinforcement learning (RL) has boosted the adoption of online RL for wireless radio resource management (RRM). However, online RL algorithms require direct interactions with the environment, which may be undesirable given the potential performance loss due to the unavoidable exploration in RL. In this work, we first investigate the use of \\emph{offline} RL algorithms in solving the RRM problem. We evaluate several state-of-the-art offline RL algorithms, including behavior constrained Q-learning (BCQ), conservative Q-learning (CQL), and implicit Q-learning (IQL), for a specific RRM problem that aims at maximizing a linear combination {of sum and} 5-percentile rates via user scheduling. We observe that the performance of offline RL for the RRM problem depends critically on the behavior policy used for data collection, and further propose a novel offline RL solution that leverages heterogeneous datasets collected by different behavior policies. We show that with a proper mixture of the datasets, offline RL can produce a near-optimal RL policy even when all involved behavior policies are highly suboptimal. ",
    "url": "https://arxiv.org/abs/2311.11423",
    "authors": [
      "Kun Yang",
      "Cong Shen",
      "Jing Yang",
      "Shu-ping Yeh",
      "Jerry Sydir"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.11427",
    "title": "Appearance Codes using Joint Embedding Learning of Multiple Modalities",
    "abstract": "The use of appearance codes in recent work on generative modeling has enabled novel view renders with variable appearance and illumination, such as day-time and night-time renders of a scene. A major limitation of this technique is the need to re-train new appearance codes for every scene on inference, so in this work we address this problem proposing a framework that learns a joint embedding space for the appearance and structure of the scene by enforcing a contrastive loss constraint between different modalities. We apply our framework to a simple Variational Auto-Encoder model on the RADIATE dataset \\cite{sheeny2021radiate} and qualitatively demonstrate that we can generate new renders of night-time photos using day-time appearance codes without additional optimization iterations. Additionally, we compare our model to a baseline VAE that uses the standard per-image appearance code technique and show that our approach achieves generations of similar quality without learning appearance codes for any unseen images on inference. ",
    "url": "https://arxiv.org/abs/2311.11427",
    "authors": [
      "Alex Zhang",
      "Evan Dogariu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11429",
    "title": "Fast Heavy Inner Product Identification Between Weights and Inputs in  Neural Network Training",
    "abstract": "In this paper, we consider a heavy inner product identification problem, which generalizes the Light Bulb problem~(\\cite{prr89}): Given two sets $A \\subset \\{-1,+1\\}^d$ and $B \\subset \\{-1,+1\\}^d$ with $|A|=|B| = n$, if there are exact $k$ pairs whose inner product passes a certain threshold, i.e., $\\{(a_1, b_1), \\cdots, (a_k, b_k)\\} \\subset A \\times B$ such that $\\forall i \\in [k], \\langle a_i,b_i \\rangle \\geq \\rho \\cdot d$, for a threshold $\\rho \\in (0,1)$, the goal is to identify those $k$ heavy inner products. We provide an algorithm that runs in $O(n^{2 \\omega / 3+ o(1)})$ time to find the $k$ inner product pairs that surpass $\\rho \\cdot d$ threshold with high probability, where $\\omega$ is the current matrix multiplication exponent. By solving this problem, our method speed up the training of neural networks with ReLU activation function. ",
    "url": "https://arxiv.org/abs/2311.11429",
    "authors": [
      "Lianke Qin",
      "Saayan Mitra",
      "Zhao Song",
      "Yuanyuan Yang",
      "Tianyi Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.11439",
    "title": "Improved Defect Detection and Classification Method for Advanced IC  Nodes by Using Slicing Aided Hyper Inference with Refinement Strategy",
    "abstract": "In semiconductor manufacturing, lithography has often been the manufacturing step defining the smallest possible pattern dimensions. In recent years, progress has been made towards high-NA (Numerical Aperture) EUVL (Extreme-Ultraviolet-Lithography) paradigm, which promises to advance pattern shrinking (2 nm node and beyond). However, a significant increase in stochastic defects and the complexity of defect detection becomes more pronounced with high-NA. Present defect inspection techniques (both non-machine learning and machine learning based), fail to achieve satisfactory performance at high-NA dimensions. In this work, we investigate the use of the Slicing Aided Hyper Inference (SAHI) framework for improving upon current techniques. Using SAHI, inference is performed on size-increased slices of the SEM images. This leads to the object detector's receptive field being more effective in capturing small defect instances. First, the performance on previously investigated semiconductor datasets is benchmarked across various configurations, and the SAHI approach is demonstrated to substantially enhance the detection of small defects, by approx. 2x. Afterwards, we also demonstrated application of SAHI leads to flawless detection rates on a new test dataset, with scenarios not encountered during training, whereas previous trained models failed. Finally, we formulate an extension of SAHI that does not significantly reduce true-positive predictions while eliminating false-positive predictions. ",
    "url": "https://arxiv.org/abs/2311.11439",
    "authors": [
      "Vic De Ridder",
      "Bappaditya Dey",
      "Victor Blanco",
      "Sandip Halder",
      "Bartel Van Waeyenberge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11452",
    "title": "Physics-Enhanced TinyML for Real-Time Detection of Ground Magnetic  Anomalies",
    "abstract": "Space weather phenomena like geomagnetic disturbances (GMDs) and geomagnetically induced currents (GICs) pose significant risks to critical technological infrastructure. While traditional predictive models, grounded in simulation, hold theoretical robustness, they grapple with challenges, notably the assimilation of imprecise data and extensive computational complexities. In recent years, Tiny Machine Learning (TinyML) has been adopted to develop Machine Learning (ML)-enabled magnetometer systems for predicting real-time terrestrial magnetic perturbations as a proxy measure for GIC. While TinyML offers efficient, real-time data processing, its intrinsic limitations prevent the utilization of robust methods with high computational needs. This paper developed a physics-guided TinyML framework to address the above challenges. This framework integrates physics-based regularization at the stages of model training and compression, thereby augmenting the reliability of predictions. The developed pruning scheme within the framework harnesses the inherent physical characteristics of the domain, striking a balance between model size and robustness. The study presents empirical results, drawing a comprehensive comparison between the accuracy and reliability of the developed framework and its traditional counterpart. Such a comparative analysis underscores the prospective applicability of the developed framework in conceptualizing robust, ML-enabled magnetometer systems for real-time space weather forecasting. ",
    "url": "https://arxiv.org/abs/2311.11452",
    "authors": [
      "Talha Siddique",
      "MD Shaad Mahmud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.11485",
    "title": "An NMF-Based Building Block for Interpretable Neural Networks With  Continual Learning",
    "abstract": "Existing learning methods often struggle to balance interpretability and predictive performance. While models like nearest neighbors and non-negative matrix factorization (NMF) offer high interpretability, their predictive performance on supervised learning tasks is often limited. In contrast, neural networks based on the multi-layer perceptron (MLP) support the modular construction of expressive architectures and tend to have better recognition accuracy but are often regarded as black boxes in terms of interpretability. Our approach aims to strike a better balance between these two aspects through the use of a building block based on NMF that incorporates supervised neural network training methods to achieve high predictive performance while retaining the desirable interpretability properties of NMF. We evaluate our Predictive Factorized Coupling (PFC) block on small datasets and show that it achieves competitive predictive performance with MLPs while also offering improved interpretability. We demonstrate the benefits of this approach in various scenarios, such as continual learning, training on non-i.i.d. data, and knowledge removal after training. Additionally, we show examples of using the PFC block to build more expressive architectures, including a fully-connected residual network as well as a factorized recurrent neural network (RNN) that performs competitively with vanilla RNNs while providing improved interpretability. The PFC block uses an iterative inference algorithm that converges to a fixed point, making it possible to trade off accuracy vs computation after training but also currently preventing its use as a general MLP replacement in some scenarios such as training on very large datasets. We provide source code at https://github.com/bkvogel/pfc ",
    "url": "https://arxiv.org/abs/2311.11485",
    "authors": [
      "Brian K. Vogel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.11486",
    "title": "Perspectives on Privacy in the Post-Roe Era: A Mixed-Methods of Machine  Learning and Qualitative Analyses of Tweets",
    "abstract": "Abortion is a controversial topic that has long been debated in the US. With the recent Supreme Court decision to overturn Roe v. Wade, access to safe and legal reproductive care is once again in the national spotlight. A key issue central to this debate is patient privacy, as in the post-HITECH Act era it has become easier for medical records to be electronically accessed and shared. This study analyzed a large Twitter dataset from May to December 2022 to examine the public's reactions to Roe v. Wade's overruling and its implications for privacy. Using a mixed-methods approach consisting of computational and qualitative content analysis, we found a wide range of concerns voiced from the confidentiality of patient-physician information exchange to medical records being shared without patient consent. These findings may inform policy making and healthcare industry practices concerning medical privacy related to reproductive rights and women's health. ",
    "url": "https://arxiv.org/abs/2311.11486",
    "authors": [
      "Yawen Guo",
      "Rachael Zehrung",
      "Katie Genuario",
      "Xuan Lu",
      "Qiaozhu Mei",
      "Yunan Chen",
      "Kai Zheng"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2311.11500",
    "title": "Multi-component Predictions of Transient Solution Fields with Sequential  Deep Operator Network",
    "abstract": "The Deep Operator Network (DeepONet) structure has shown great potential in approximating complex solution operators with low generalization errors. Recently, a sequential DeepONet (S-DeepONet) was proposed to use sequential learning models in the branch of DeepONet to predict final solutions given time-dependent inputs. In this novel work, the S-DeepONet architecture is further extended by modifying the information combination mechanism between the branch and trunk networks to simultaneously predict vector solutions with multiple components at multiple time steps of the evolution history. Two example problems, one on transient fluid flow and the other on path-dependent plastic loading were shown to demonstrate the capabilities of the model to handle different physics problems. The use of a trained S-DeepONet model in inverse parameter identification via the genetic algorithm is shown to demonstrate the application of the model. In almost all cases, the trained model achieved an $R^2$ value of above 0.99 and relative $L_2$ error of less than 10\\% with only 3200 training data points, indicating superior accuracy. The vector S-DeepONet model, having only 0.4\\% more parameters than a scalar model, can predict two output components simultaneously at an accuracy similar to the two independently trained scalar models with a 20.8\\% faster training time. The S-DeepONet inference is at least three orders of magnitude faster than direct numerical simulations, and inverse parameter identifications using the trained model is highly efficient and accurate. ",
    "url": "https://arxiv.org/abs/2311.11500",
    "authors": [
      "Junyan He",
      "Shashank Kushwaha",
      "Jaewan Park",
      "Seid Koric",
      "Diab Abueidda",
      "Iwona Jasiuk"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2311.11509",
    "title": "Token-Level Adversarial Prompt Detection Based on Perplexity Measures  and Contextual Information",
    "abstract": "In recent years, Large Language Models (LLM) have emerged as pivotal tools in various applications. However, these models are susceptible to adversarial prompt attacks, where attackers can carefully curate input strings that lead to undesirable outputs. The inherent vulnerability of LLMs stems from their input-output mechanisms, especially when presented with intensely out-of-distribution (OOD) inputs. This paper proposes a token-level detection method to identify adversarial prompts, leveraging the LLM's capability to predict the next token's probability. We measure the degree of the model's perplexity and incorporate neighboring token information to encourage the detection of contiguous adversarial prompt sequences. As a result, we propose two methods: one that identifies each token as either being part of an adversarial prompt or not, and another that estimates the probability of each token being part of an adversarial prompt. ",
    "url": "https://arxiv.org/abs/2311.11509",
    "authors": [
      "Zhengmian Hu",
      "Gang Wu",
      "Saayan Mitra",
      "Ruiyi Zhang",
      "Tong Sun",
      "Heng Huang",
      "Vishy Swaminathan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.11513",
    "title": "Distributionally Robust Evaluation for Real-Time Flexibility of Electric  Vehicles Considering Uncertain Departure Behavior and State-of-Charge",
    "abstract": "Accurately evaluating the real-time flexibility of electric vehicles (EVs) is necessary for EV aggregators to offer ancillary services. However, regulation-caused uncertain state-of-charge and random departure behavior complicate the evaluation and badly impact the evaluation accuracy. To resolve this issue, this letter proposes a distributionally robust real-time flexibility evaluation model that formulates the uncertain departure behavior and state-of-charge of EVs in an online updating pattern. Thanks to dualization, this model can be efficiently solved via off-the-shelf solvers. Case studies validate the superiority of the proposed method and its scalability regarding EV numbers. ",
    "url": "https://arxiv.org/abs/2311.11513",
    "authors": [
      "Yixin Li",
      "Zhengshuo Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.11514",
    "title": "HexGen: Generative Inference of Foundation Model over Heterogeneous  Decentralized Environment",
    "abstract": "Serving foundation model inference is a pivotal component of contemporary AI applications, where this service is usually hosted in a centralized data center on a group of homogeneous high-performance GPUs. In this paper, we explore how to deploy such a service in a heterogeneous environment in terms of both computation capacity and network connection as an alternative to reduce the high inference cost. We propose HexGen, a distributed inference engine that supports asymmetric partitioning of the inference computation according to tensor model parallelism and pipeline parallelism. HexGen can be deployed with a set of different GPUs connected by a fully heterogeneous network, where the key technique contribution is a scheduling algorithm that allocates the asymmetric inference tasklets among these GPUs connected by different networks. We define the scheduling problem as a constrained optimization problem and further propose an efficient evolutionary algorithm to find the optimal allocation strategy. We conduct an extensive empirical study to evaluate the efficiency of HexGen by serving the state-of-the-art Llama-2 (70B) model. The experimental results suggest that HexGen can choose to achieve up to 2.3 times lower latency deadlines or tolerate up to 4 times more traffic request rates compared with the homogeneous baseline given the same budget. Our implementation is available at https://github.com/Relaxed-System-Lab/HexGen. ",
    "url": "https://arxiv.org/abs/2311.11514",
    "authors": [
      "Youhe Jiang",
      "Ran Yan",
      "Xiaozhe Yao",
      "Beidi Chen",
      "Binhang Yuan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.11542",
    "title": "Data-driven project planning: An integrated network learning and  constraint relaxation approach in favor of scheduling",
    "abstract": "Our focus is on projects, i.e., business processes, which are emerging as the economic drivers of our times. Differently from day-to-day operational processes that do not require detailed planning, a project requires planning and resource-constrained scheduling for coordinating resources across sub- or related projects and organizations. A planner in charge of project planning has to select a set of activities to perform, determine their precedence constraints, and schedule them according to temporal project constraints. We suggest a data-driven project planning approach for classes of projects such as infrastructure building and information systems development projects. A project network is first learned from historical records. The discovered network relaxes temporal constraints embedded in individual projects, thus uncovering where planning and scheduling flexibility can be exploited for greater benefit. Then, the network, which contains multiple project plan variations, from which one has to be selected, is enriched by identifying decision rules and frequent paths. The planner can rely on the project network for: 1) decoding a project variation such that it forms a new project plan, and 2) applying resource-constrained project scheduling procedures to determine the project's schedule and resource allocation. Using two real-world project datasets, we show that the suggested approach may provide the planner with significant flexibility (up to a 26% reduction of the critical path of a real project) to adjust the project plan and schedule. We believe that the proposed approach can play an important part in supporting decision making towards automated data-driven project planning. ",
    "url": "https://arxiv.org/abs/2311.11542",
    "authors": [
      "Izack Cohen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11544",
    "title": "Understanding Variation in Subpopulation Susceptibility to Poisoning  Attacks",
    "abstract": "Machine learning is susceptible to poisoning attacks, in which an attacker controls a small fraction of the training data and chooses that data with the goal of inducing some behavior unintended by the model developer in the trained model. We consider a realistic setting in which the adversary with the ability to insert a limited number of data points attempts to control the model's behavior on a specific subpopulation. Inspired by previous observations on disparate effectiveness of random label-flipping attacks on different subpopulations, we investigate the properties that can impact the effectiveness of state-of-the-art poisoning attacks against different subpopulations. For a family of 2-dimensional synthetic datasets, we empirically find that dataset separability plays a dominant role in subpopulation vulnerability for less separable datasets. However, well-separated datasets exhibit more dependence on individual subpopulation properties. We further discover that a crucial subpopulation property is captured by the difference in loss on the clean dataset between the clean model and a target model that misclassifies the subpopulation, and a subpopulation is much easier to attack if the loss difference is small. This property also generalizes to high-dimensional benchmark datasets. For the Adult benchmark dataset, we show that we can find semantically-meaningful subpopulation properties that are related to the susceptibilities of a selected group of subpopulations. The results in this paper are accompanied by a fully interactive web-based visualization of subpopulation poisoning attacks found at https://uvasrg.github.io/visualizing-poisoning ",
    "url": "https://arxiv.org/abs/2311.11544",
    "authors": [
      "Evan Rose",
      "Fnu Suya",
      "David Evans"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.11549",
    "title": "Unearthing Common Inconsistency for Generalisable Deepfake Detection",
    "abstract": "Deepfake has emerged for several years, yet efficient detection techniques could generalize over different manipulation methods require further research. While current image-level detection method fails to generalize to unseen domains, owing to the domain-shift phenomenon brought by CNN's strong inductive bias towards Deepfake texture, video-level one shows its potential to have both generalization across multiple domains and robustness to compression. We argue that although distinct face manipulation tools have different inherent bias, they all disrupt the consistency between frames, which is a natural characteristic shared by authentic videos. Inspired by this, we proposed a detection approach by capturing frame inconsistency that broadly exists in different forgery techniques, termed unearthing-common-inconsistency (UCI). Concretely, the UCI network based on self-supervised contrastive learning can better distinguish temporal consistency between real and fake videos from multiple domains. We introduced a temporally-preserved module method to introduce spatial noise perturbations, directing the model's attention towards temporal information. Subsequently, leveraging a multi-view cross-correlation learning module, we extensively learn the disparities in temporal representations between genuine and fake samples. Extensive experiments demonstrate the generalization ability of our method on unseen Deepfake domains. ",
    "url": "https://arxiv.org/abs/2311.11549",
    "authors": [
      "Beilin Chu",
      "Xuan Xu",
      "Weike You",
      "Linna Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11550",
    "title": "Abnormal traffic detection system in SDN based on deep learning hybrid  models",
    "abstract": "Software defined network (SDN) provides technical support for network construction in smart cities, However, the openness of SDN is also prone to more network attacks. Traditional abnormal traffic detection methods have complex algorithms and find it difficult to detect abnormalities in the network promptly, which cannot meet the demand for abnormal detection in the SDN environment. Therefore, we propose an abnormal traffic detection system based on deep learning hybrid model. The system adopts a hierarchical detection technique, which first achieves rough detection of abnormal traffic based on port information. Then it uses wavelet transform and deep learning techniques for fine detection of all traffic data flowing through suspicious switches. The experimental results show that the proposed detection method based on port information can quickly complete the approximate localization of the source of abnormal traffic. the accuracy, precision, and recall of the fine detection are significantly improved compared with the traditional method of abnormal traffic detection in SDN. ",
    "url": "https://arxiv.org/abs/2311.11550",
    "authors": [
      "Kun Wang",
      "Yu Fua",
      "Xueyuan Duan",
      "Taotao Liu",
      "Jianqiao Xu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2311.11555",
    "title": "NePF: Neural Photon Field for Single-Stage Inverse Rendering",
    "abstract": "We present a novel single-stage framework, Neural Photon Field (NePF), to address the ill-posed inverse rendering from multi-view images. Contrary to previous methods that recover the geometry, material, and illumination in multiple stages and extract the properties from various multi-layer perceptrons across different neural fields, we question such complexities and introduce our method - a single-stage framework that uniformly recovers all properties. NePF achieves this unification by fully utilizing the physical implication behind the weight function of neural implicit surfaces and the view-dependent radiance. Moreover, we introduce an innovative coordinate-based illumination model for rapid volume physically-based rendering. To regularize this illumination, we implement the subsurface scattering model for diffuse estimation. We evaluate our method on both real and synthetic datasets. The results demonstrate the superiority of our approach in recovering high-fidelity geometry and visual-plausible material attributes. ",
    "url": "https://arxiv.org/abs/2311.11555",
    "authors": [
      "Tuen-Yue Tsui",
      "Qin Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2311.11566",
    "title": "Does complimentary information from multispectral imaging improve face  presentation attack detection?",
    "abstract": "Presentation Attack Detection (PAD) has been extensively studied, particularly in the visible spectrum. With the advancement of sensing technology beyond the visible range, multispectral imaging has gained significant attention in this direction. We present PAD based on multispectral images constructed for eight different presentation artifacts resulted from three different artifact species. In this work, we introduce Face Presentation Attack Multispectral (FPAMS) database to demonstrate the significance of employing multispectral imaging. The goal of this work is to study complementary information that can be combined in two different ways (image fusion and score fusion) from multispectral imaging to improve the face PAD. The experimental evaluation results present an extensive qualitative analysis of 61650 sample multispectral images collected for bonafide and artifacts. The PAD based on the score fusion and image fusion method presents superior performance, demonstrating the significance of employing multispectral imaging to detect presentation artifacts. ",
    "url": "https://arxiv.org/abs/2311.11566",
    "authors": [
      "Narayan Vetrekar",
      "Raghavendra Ramachandra",
      "Sushma Venkatesh",
      "Jyoti D. Pawar",
      "R. S. Gad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11567",
    "title": "CORE-MM: Complex Open-Ended Reasoning Evaluation For Multi-Modal Large  Language Models",
    "abstract": "Multi-modal Large Language Models (MLLMs) are increasingly prominent in the field of artificial intelligence. These models not only excel in traditional vision-language tasks but also demonstrate impressive performance in contemporary multi-modal benchmarks. Although many of these benchmarks attempt to holistically evaluate MLLMs, they typically concentrate on basic reasoning tasks, often yielding only simple yes/no or multi-choice responses. These methods naturally lead to confusion and difficulties in conclusively determining the reasoning capabilities of MLLMs. To mitigate this issue, we manually curate a benchmark dataset specifically designed for MLLMs, with a focus on complex reasoning tasks. Our benchmark comprises three key reasoning categories: deductive, abductive, and analogical reasoning. The queries in our dataset are intentionally constructed to engage the reasoning capabilities of MLLMs in the process of generating answers. For a fair comparison across various MLLMs, we incorporate intermediate reasoning steps into our evaluation criteria. In instances where an MLLM is unable to produce a definitive answer, its reasoning ability is evaluated by requesting intermediate reasoning steps. If these steps align with our manual annotations, appropriate scores are assigned. This evaluation scheme resembles methods commonly used in human assessments, such as exams or assignments, and represents what we consider a more effective assessment technique compared with existing benchmarks. We evaluate a selection of representative MLLMs using this rigorously developed open-ended multi-step elaborate reasoning benchmark, designed to challenge and accurately measure their reasoning capabilities. The code and data will be released at https://core-mm.github.io/ ",
    "url": "https://arxiv.org/abs/2311.11567",
    "authors": [
      "Xiaotian Han",
      "Quanzeng You",
      "Yongfei Liu",
      "Wentao Chen",
      "Huangjie Zheng",
      "Khalil Mrini",
      "Xudong Lin",
      "Yiqi Wang",
      "Bohan Zhai",
      "Jianbo Yuan",
      "Heng Wang",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11570",
    "title": "Decoupled DETR For Few-shot Object Detection",
    "abstract": "Few-shot object detection (FSOD), an efficient method for addressing the severe data-hungry problem, has been extensively discussed. Current works have significantly advanced the problem in terms of model and data. However, the overall performance of most FSOD methods still does not fulfill the desired accuracy. In this paper we improve the FSOD model to address the severe issue of sample imbalance and weak feature propagation. To alleviate modeling bias from data-sufficient base classes, we examine the effect of decoupling the parameters for classes with sufficient data and classes with few samples in various ways. We design a base-novel categories decoupled DETR (DeDETR) for FSOD. We also explore various types of skip connection between the encoder and decoder for DETR. Besides, we notice that the best outputs could come from the intermediate layer of the decoder instead of the last layer; therefore, we build a unified decoder module that could dynamically fuse the decoder layers as the output feature. We evaluate our model on commonly used datasets such as PASCAL VOC and MSCOCO. Our results indicate that our proposed module could achieve stable improvements of 5% to 10% in both fine-tuning and meta-learning paradigms and has outperformed the highest score in recent works. ",
    "url": "https://arxiv.org/abs/2311.11570",
    "authors": [
      "Zeyu Shangguan",
      "Lian Huai",
      "Tong Liu",
      "Xingqun Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11574",
    "title": "A Framework on Complex Matrix Derivatives with Special Structure  Constraints for Wireless Systems",
    "abstract": "Matrix-variate optimization plays a central role in advanced wireless system designs. In this paper, we aim to explore optimal solutions of matrix variables under two special structure constraints using complex matrix derivatives, including diagonal structure constraints and constant modulus constraints, both of which are closely related to the state-of-the-art wireless applications. Specifically, for diagonal structure constraints mostly considered in the uplink multi-user single-input multiple-output (MU-SIMO) system and the amplitude-adjustable intelligent reflecting surface (IRS)-aided multiple-input multiple-output (MIMO) system, the capacity maximization problem, the mean-squared error (MSE) minimization problem and their variants are rigorously investigated. By leveraging complex matrix derivatives, the optimal solutions of these problems are directly obtained in closed forms. Nevertheless, for constant modulus constraints with the intrinsic nature of element-wise decomposability, which are often seen in the hybrid analog-digital MIMO system and the fully-passive IRS-aided MIMO system, we firstly explore inherent structures of the element-wise phase derivatives associated with different optimization problems. Then, we propose a novel alternating optimization (AO) algorithm with the aid of several arbitrary feasible solutions, which avoids the complicated matrix inversion and matrix factorization involved in conventional element-wise iterative algorithms. Numerical simulations reveal that the proposed algorithm can dramatically reduce the computational complexity without loss of system performance. ",
    "url": "https://arxiv.org/abs/2311.11574",
    "authors": [
      "Xin Ju",
      "Shiqi Gong",
      "Nan Zhao",
      "Chengwen Xing",
      "Arumugam Nallanathan",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2311.11580",
    "title": "SeaDSC: A video-based unsupervised method for dynamic scene change  detection in unmanned surface vehicles",
    "abstract": "Recently, there has been an upsurge in the research on maritime vision, where a lot of works are influenced by the application of computer vision for Unmanned Surface Vehicles (USVs). Various sensor modalities such as camera, radar, and lidar have been used to perform tasks such as object detection, segmentation, object tracking, and motion planning. A large subset of this research is focused on the video analysis, since most of the current vessel fleets contain the camera's onboard for various surveillance tasks. Due to the vast abundance of the video data, video scene change detection is an initial and crucial stage for scene understanding of USVs. This paper outlines our approach to detect dynamic scene changes in USVs. To the best of our understanding, this work represents the first investigation of scene change detection in the maritime vision application. Our objective is to identify significant changes in the dynamic scenes of maritime video data, particularly those scenes that exhibit a high degree of resemblance. In our system for dynamic scene change detection, we propose completely unsupervised learning method. In contrast to earlier studies, we utilize a modified cutting-edge generative picture model called VQ-VAE-2 to train on multiple marine datasets, aiming to enhance the feature extraction. Next, we introduce our innovative similarity scoring technique for directly calculating the level of similarity in a sequence of consecutive frames by utilizing grid calculation on retrieved features. The experiments were conducted using a nautical video dataset called RoboWhaler to showcase the efficient performance of our technique. ",
    "url": "https://arxiv.org/abs/2311.11580",
    "authors": [
      "Linh Trinh",
      "Ali Anwar",
      "Siegfried Mercelis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11587",
    "title": "AKConv: Convolutional Kernel with Arbitrary Sampled Shapes and Arbitrary  Number of Parameters",
    "abstract": "Neural networks based on convolutional operations have achieved remarkable results in the field of deep learning, but there are two inherent flaws in standard convolutional operations. On the one hand, the convolution operation be confined to a local window and cannot capture information from other locations, and its sampled shapes is fixed. On the other hand, the size of the convolutional kernel is fixed to k $\\times$ k, which is a fixed square shape, and the number of parameters tends to grow squarely with size. It is obvious that the shape and size of targets are various in different datasets and at different locations. Convolutional kernels with fixed sample shapes and squares do not adapt well to changing targets. In response to the above questions, the Alterable Kernel Convolution (AKConv) is explored in this work, which gives the convolution kernel an arbitrary number of parameters and arbitrary sampled shapes to provide richer options for the trade-off between network overhead and performance. In AKConv, we define initial positions for convolutional kernels of arbitrary size by means of a new coordinate generation algorithm. To adapt to changes for targets, we introduce offsets to adjust the shape of the samples at each position. Moreover, we explore the effect of the neural network by using the AKConv with the same size and different initial sampled shapes. AKConv completes the process of efficient feature extraction by irregular convolutional operations and brings more exploration options for convolutional sampling shapes. Object detection experiments on representative datasets COCO2017, VOC 7+12 and VisDrone-DET2021 fully demonstrate the advantages of AKConv. AKConv can be used as a plug-and-play convolutional operation to replace convolutional operations to improve network performance. The code for the relevant tasks can be found at https://github.com/CV-ZhangXin/AKConv. ",
    "url": "https://arxiv.org/abs/2311.11587",
    "authors": [
      "Xin Zhang",
      "Yingze Song",
      "Tingting Song",
      "Degang Yang",
      "Yichen Ye",
      "Jie Zhou",
      "Liming Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11601",
    "title": "Addressing the Length Bias Problem in Document-Level Neural Machine  Translation",
    "abstract": "Document-level neural machine translation (DNMT) has shown promising results by incorporating more context information. However, this approach also introduces a length bias problem, whereby DNMT suffers from significant translation quality degradation when decoding documents that are much shorter or longer than the maximum sequence length during training. %i.e., the length bias problem. To solve the length bias problem, we propose to improve the DNMT model in training method, attention mechanism, and decoding strategy. Firstly, we propose to sample the training data dynamically to ensure a more uniform distribution across different sequence lengths. Then, we introduce a length-normalized attention mechanism to aid the model in focusing on target information, mitigating the issue of attention divergence when processing longer sequences. Lastly, we propose a sliding window strategy during decoding that integrates as much context information as possible without exceeding the maximum sequence length. The experimental results indicate that our method can bring significant improvements on several open datasets, and further analysis shows that our method can significantly alleviate the length bias problem. ",
    "url": "https://arxiv.org/abs/2311.11601",
    "authors": [
      "Zhuocheng Zhang",
      "Shuhao Gu",
      "Min Zhang",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.11602",
    "title": "A Multi-In-Single-Out Network for Video Frame Interpolation without  Optical Flow",
    "abstract": "In general, deep learning-based video frame interpolation (VFI) methods have predominantly focused on estimating motion vectors between two input frames and warping them to the target time. While this approach has shown impressive performance for linear motion between two input frames, it exhibits limitations when dealing with occlusions and nonlinear movements. Recently, generative models have been applied to VFI to address these issues. However, as VFI is not a task focused on generating plausible images, but rather on predicting accurate intermediate frames between two given frames, performance limitations still persist. In this paper, we propose a multi-in-single-out (MISO) based VFI method that does not rely on motion vector estimation, allowing it to effectively model occlusions and nonlinear motion. Additionally, we introduce a novel motion perceptual loss that enables MISO-VFI to better capture the spatio-temporal correlations within the video frames. Our MISO-VFI method achieves state-of-the-art results on VFI benchmarks Vimeo90K, Middlebury, and UCF101, with a significant performance gap compared to existing approaches. ",
    "url": "https://arxiv.org/abs/2311.11602",
    "authors": [
      "Jaemin Lee",
      "Minseok Seo",
      "Sangwoo Lee",
      "Hyobin Park",
      "Dong-Geol Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11605",
    "title": "Machine learning-based malware detection for IoT devices using  control-flow data",
    "abstract": "Embedded devices are specialised devices designed for one or only a few purposes. They are often part of a larger system, through wired or wireless connection. Those embedded devices that are connected to other computers or embedded systems through the Internet are called Internet of Things (IoT for short) devices. With their widespread usage and their insufficient protection, these devices are increasingly becoming the target of malware attacks. Companies often cut corners to save manufacturing costs or misconfigure when producing these devices. This can be lack of software updates, ports left open or security defects by design. Although these devices may not be as powerful as a regular computer, their large number makes them suitable candidates for botnets. Other types of IoT devices can even cause health problems since there are even pacemakers connected to the Internet. This means, that without sufficient defence, even directed assaults are possible against people. The goal of this thesis project is to provide better security for these devices with the help of machine learning algorithms and reverse engineering tools. Specifically, I study the applicability of control-flow related data of executables for malware detection. I present a malware detection method with two phases. The first phase extracts control-flow related data using static binary analysis. The second phase classifies binary executables as either malicious or benign using a neural network model. I train the model using a dataset of malicious and benign ARM applications. ",
    "url": "https://arxiv.org/abs/2311.11605",
    "authors": [
      "Gergely Hevesi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.11626",
    "title": "A novel transformer-based approach for soil temperature prediction",
    "abstract": "Soil temperature is one of the most significant parameters that plays a crucial role in glacier energy, dynamics of mass balance, processes of surface hydrological, coaction of glacier-atmosphere, nutrient cycling, ecological stability, the management of soil, water, and field crop. In this work, we introduce a novel approach using transformer models for the purpose of forecasting soil temperature prediction. To the best of our knowledge, the usage of transformer models in this work is the very first attempt to predict soil temperature. Experiments are carried out using six different FLUXNET stations by modeling them with five different transformer models, namely, Vanilla Transformer, Informer, Autoformer, Reformer, and ETSformer. To demonstrate the effectiveness of the proposed model, experiment results are compared with both deep learning approaches and literature studies. Experiment results show that the utilization of transformer models ensures a significant contribution to the literature, thence determining the new state-of-the-art. ",
    "url": "https://arxiv.org/abs/2311.11626",
    "authors": [
      "Muhammet Mucahit Enes Yurtsever",
      "Ayhan Kucukmanisa",
      "Zeynep Hilal Kilimci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2311.11644",
    "title": "Unraveling the Control Engineer's Craft with Neural Networks",
    "abstract": "Many industrial processes require suitable controllers to meet their performance requirements. More often, a sophisticated digital twin is available, which is a highly complex model that is a virtual representation of a given physical process, whose parameters may not be properly tuned to capture the variations in the physical process. In this paper, we present a sim2real, direct data-driven controller tuning approach, where the digital twin is used to generate input-output data and suitable controllers for several perturbations in its parameters. State-of-the art neural-network architectures are then used to learn the controller tuning rule that maps input-output data onto the controller parameters, based on artificially generated data from perturbed versions of the digital twin. In this way, as far as we are aware, we tackle for the first time the problem of re-calibrating the controller by meta-learning the tuning rule directly from data, thus practically replacing the control engineer with a machine learning model. The benefits of this methodology are illustrated via numerical simulations for several choices of neural-network architectures. ",
    "url": "https://arxiv.org/abs/2311.11644",
    "authors": [
      "Braghadeesh Lakshminarayanan",
      "Federico Dett\u00f9",
      "Cristian R. Rojas",
      "Simone Formentin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.11646",
    "title": "CastDet: Toward Open Vocabulary Aerial Object Detection with  CLIP-Activated Student-Teacher Learning",
    "abstract": "Object detection in aerial images is a pivotal task for various earth observation applications, whereas current algorithms learn to detect only a pre-defined set of object categories demanding sufficient bounding-box annotated training samples and fail to detect novel object categories. In this paper, we consider open-vocabulary object detection (OVD) in aerial images that enables the characterization of new objects beyond training categories on the earth surface without annotating training images for these new categories. The performance of OVD depends on the quality of class-agnostic region proposals and pseudo-labels that can generalize well to novel object categories. To simultaneously generate high-quality proposals and pseudo-labels, we propose CastDet, a CLIP-activated student-teacher open-vocabulary object Detection framework. Our end-to-end framework within the student-teacher mechanism employs the CLIP model as an extra omniscient teacher of rich knowledge into the student-teacher self-learning process. By doing so, our approach boosts novel object proposals and classification. Furthermore, we design a dynamic label queue technique to maintain high-quality pseudo labels during batch training and mitigate label imbalance. We conduct extensive experiments on multiple existing aerial object detection datasets, which are set up for the OVD task. Experimental results demonstrate our CastDet achieving superior open-vocabulary detection performance, e.g., reaching 40.0 HM (Harmonic Mean), which outperforms previous methods Detic/ViLD by 26.9/21.1 on the VisDroneZSD dataset. ",
    "url": "https://arxiv.org/abs/2311.11646",
    "authors": [
      "Yan Li",
      "Weiwei Guo",
      "Dunyun He",
      "Jiaqi Zhou",
      "Yuze Gao",
      "Wenxian Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11659",
    "title": "MGCT: Mutual-Guided Cross-Modality Transformer for Survival Outcome  Prediction using Integrative Histopathology-Genomic Features",
    "abstract": "The rapidly emerging field of deep learning-based computational pathology has shown promising results in utilizing whole slide images (WSIs) to objectively prognosticate cancer patients. However, most prognostic methods are currently limited to either histopathology or genomics alone, which inevitably reduces their potential to accurately predict patient prognosis. Whereas integrating WSIs and genomic features presents three main challenges: (1) the enormous heterogeneity of gigapixel WSIs which can reach sizes as large as 150,000x150,000 pixels; (2) the absence of a spatially corresponding relationship between histopathology images and genomic molecular data; and (3) the existing early, late, and intermediate multimodal feature fusion strategies struggle to capture the explicit interactions between WSIs and genomics. To ameliorate these issues, we propose the Mutual-Guided Cross-Modality Transformer (MGCT), a weakly-supervised, attention-based multimodal learning framework that can combine histology features and genomic features to model the genotype-phenotype interactions within the tumor microenvironment. To validate the effectiveness of MGCT, we conduct experiments using nearly 3,600 gigapixel WSIs across five different cancer types sourced from The Cancer Genome Atlas (TCGA). Extensive experimental results consistently emphasize that MGCT outperforms the state-of-the-art (SOTA) methods. ",
    "url": "https://arxiv.org/abs/2311.11659",
    "authors": [
      "Mingxin Liu",
      "Yunzan Liu",
      "Hui Cui",
      "Chunquan Li",
      "Jiquan Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11662",
    "title": "Enhanced Spatio-Temporal Context for Temporally Consistent Robust 3D  Human Motion Recovery from Monocular Videos",
    "abstract": "Recovering temporally consistent 3D human body pose, shape and motion from a monocular video is a challenging task due to (self-)occlusions, poor lighting conditions, complex articulated body poses, depth ambiguity, and limited availability of annotated data. Further, doing a simple perframe estimation is insufficient as it leads to jittery and implausible results. In this paper, we propose a novel method for temporally consistent motion estimation from a monocular video. Instead of using generic ResNet-like features, our method uses a body-aware feature representation and an independent per-frame pose and camera initialization over a temporal window followed by a novel spatio-temporal feature aggregation by using a combination of self-similarity and self-attention over the body-aware features and the perframe initialization. Together, they yield enhanced spatiotemporal context for every frame by considering remaining past and future frames. These features are used to predict the pose and shape parameters of the human body model, which are further refined using an LSTM. Experimental results on the publicly available benchmark data show that our method attains significantly lower acceleration error and outperforms the existing state-of-the-art methods over all key quantitative evaluation metrics, including complex scenarios like partial occlusion, complex poses and even relatively low illumination. ",
    "url": "https://arxiv.org/abs/2311.11662",
    "authors": [
      "Sushovan Chanda",
      "Amogh Tiwari",
      "Lokender Tiwari",
      "Brojeshwar Bhowmick",
      "Avinash Sharma",
      "Hrishav Barua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11683",
    "title": "ViP-Mixer: A Convolutional Mixer for Video Prediction",
    "abstract": "Video prediction aims to predict future frames from a video's previous content. Existing methods mainly process video data where the time dimension mingles with the space and channel dimensions from three distinct angles: as a sequence of individual frames, as a 3D volume in spatiotemporal coordinates, or as a stacked image where frames are treated as separate channels. Most of them generally focus on one of these perspectives and may fail to fully exploit the relationships across different dimensions. To address this issue, this paper introduces a convolutional mixer for video prediction, termed ViP-Mixer, to model the spatiotemporal evolution in the latent space of an autoencoder. The ViP-Mixers are stacked sequentially and interleave feature mixing at three levels: frames, channels, and locations. Extensive experiments demonstrate that our proposed method achieves new state-of-the-art prediction performance on three benchmark video datasets covering both synthetic and real-world scenarios. ",
    "url": "https://arxiv.org/abs/2311.11683",
    "authors": [
      "Xin Zheng",
      "Ziang Peng",
      "Yuan Cao",
      "Hongming Shan",
      "Junping Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11689",
    "title": "Causal Structure Learning Supervised by Large Language Model",
    "abstract": "Causal discovery from observational data is pivotal for deciphering complex relationships. Causal Structure Learning (CSL), which focuses on deriving causal Directed Acyclic Graphs (DAGs) from data, faces challenges due to vast DAG spaces and data sparsity. The integration of Large Language Models (LLMs), recognized for their causal reasoning capabilities, offers a promising direction to enhance CSL by infusing it with knowledge-based causal inferences. However, existing approaches utilizing LLMs for CSL have encountered issues, including unreliable constraints from imperfect LLM inferences and the computational intensity of full pairwise variable analyses. In response, we introduce the Iterative LLM Supervised CSL (ILS-CSL) framework. ILS-CSL innovatively integrates LLM-based causal inference with CSL in an iterative process, refining the causal DAG using feedback from LLMs. This method not only utilizes LLM resources more efficiently but also generates more robust and high-quality structural constraints compared to previous methodologies. Our comprehensive evaluation across eight real-world datasets demonstrates ILS-CSL's superior performance, setting a new standard in CSL efficacy and showcasing its potential to significantly advance the field of causal discovery. The codes are available at \\url{https://github.com/tyMadara/ILS-CSL}. ",
    "url": "https://arxiv.org/abs/2311.11689",
    "authors": [
      "Taiyu Ban",
      "Lyuzhou Chen",
      "Derui Lyu",
      "Xiangyu Wang",
      "Huanhuan Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11691",
    "title": "Towards Robust Text Retrieval with Progressive Learning",
    "abstract": "Retrieval augmentation has become an effective solution to empower large language models (LLMs) with external and verified knowledge sources from the database, which overcomes the limitations and hallucinations of LLMs in handling up-to-date and domain-specific information. However, existing embedding models for text retrieval usually have three non-negligible limitations. First, the number and diversity of samples in a batch are too restricted to supervise the modeling of textual nuances at scale. Second, the high proportional noise are detrimental to the semantic correctness and consistency of embeddings. Third, the equal treatment to easy and difficult samples would cause sub-optimum convergence of embeddings with poorer generalization. In this paper, we propose the PEG, a progressively learned embeddings for robust text retrieval. Specifically, we increase the training in-batch negative samples to 80,000, and for each query, we extracted five hard negatives. Concurrently, we incorporated a progressive learning mechanism, enabling the model to dynamically modulate its attention to the samples throughout the entire training process. Additionally, PEG is trained on more than 100 million data, encompassing a wide range of domains (e.g., finance, medicine, and tourism) and covering various tasks (e.g., question-answering, machine reading comprehension, and similarity matching). Extensive experiments conducted on C-MTEB and DuReader demonstrate that PEG surpasses state-of-the-art embeddings in retrieving true positives, highlighting its significant potential for applications in LLMs. Our model is publicly available at https://huggingface.co/TownsWu/PEG. ",
    "url": "https://arxiv.org/abs/2311.11691",
    "authors": [
      "Tong Wu",
      "Yulei Qin",
      "Enwei Zhang",
      "Zihan Xu",
      "Yuting Gao",
      "Ke Li",
      "Xing Sun"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11704",
    "title": "Demonstrating Almost Linear Time Complexity of Bus Admittance  Matrix-Based Distribution Network Power Flow: An Empirical Approach",
    "abstract": "The bus admittance matrix is central to many power system simulation algorithms, but the link between problem size and computation time (i.e., the time complexity) using modern sparse solvers is not fully understood. It has recently been suggested that some popular algorithms used in distribution system power flow analysis have cubic complexity, based on properties of dense matrix numerical algorithms; a tighter theoretical estimate of complexity using sparse solvers is not immediately forthcoming due to these solvers' problem-dependent behaviour. To address this, the time complexity of admittance matrix-based distribution power flow is considered empirically across a library of 75 networks, ranging in size from 50 to 300,000 nodes. Results across four admittance matrix-based methods suggest complexity coefficient values between 1.04 and 1.12, indicating complexity that is instead almost linear. The proposed empirical approach is suggested as a convenient and practical way of benchmarking the scalability of power flow algorithms. ",
    "url": "https://arxiv.org/abs/2311.11704",
    "authors": [
      "Matthew Deakin",
      "Davis Montenegro"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.11707",
    "title": "Configuring an heterogeneous smartgrid network: complexity and  approximations for tree topologies",
    "abstract": "We address the problem of configuring a power distribution network with reliability and resilience objectives by satisfying the demands of the consumers and saturating each production source as little as possible. We consider power distribution networks containing source nodes producing electricity, nodes representing electricity consumers and switches between them. Configuring this network consists in deciding the orientation of the links between the nodes of the network. The electric flow is a direct consequence of the chosen configuration and can be computed in polynomial time. It is valid if it satisfies the demand of each consumer and capacity constraints on the network. In such a case, we study the problem of determining a feasible solution that balances the loads of the sources, that is their production rates. We use three metrics to measure the quality of a solution: minimizing the maximum load, maximizing the minimum load and minimizing the difference of the maximum and the minimum loads. This defines optimization problems called respectively min-M, max-m and min-R. In the case where the graph of the network is a tree, it is known that the problem of building a valid configuration is polynomial. We show the three optimization variants have distinct properties regarding the theoretical complexity and the approximability. Particularly, we show that min-M is polynomial, that max-m is NP-Hard but belongs to the class FPTAS and that min-R is NP-Hard, cannot 1 be approximated to within any exponential relative ratio but, for any $\\epsilon$ > 0, there exists an algorithm for which the value of the returned solution equals the value of an optimal solution shifted by at most $\\epsilon$. ",
    "url": "https://arxiv.org/abs/2311.11707",
    "authors": [
      "Dominique Barth",
      "Thierry Mautor",
      "Dimitri Watel",
      "Marc-Antoine Weisser"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2311.11714",
    "title": "On the Importance of Large Objects in CNN Based Object Detection  Algorithms",
    "abstract": "Object detection models, a prominent class of machine learning algorithms, aim to identify and precisely locate objects in images or videos. However, this task might yield uneven performances sometimes caused by the objects sizes and the quality of the images and labels used for training. In this paper, we highlight the importance of large objects in learning features that are critical for all sizes. Given these findings, we propose to introduce a weighting term into the training loss. This term is a function of the object area size. We show that giving more weight to large objects leads to improved detection scores across all object sizes and so an overall improvement in Object Detectors performances (+2 p.p. of mAP on small objects, +2 p.p. on medium and +4 p.p. on large on COCO val 2017 with InternImage-T). Additional experiments and ablation studies with different models and on a different dataset further confirm the robustness of our findings. ",
    "url": "https://arxiv.org/abs/2311.11714",
    "authors": [
      "Ahmed Ben Saad",
      "Gabriele Facciolo",
      "Axel Davy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11717",
    "title": "Can we infer the presence of Differential Privacy in Deep Learning  models' weights? Towards more secure Deep Learning",
    "abstract": "Differential Privacy (DP) is a key property to protect data and models from integrity attacks. In the Deep Learning (DL) field, it is commonly implemented through the Differentially Private Stochastic Gradient Descent (DP-SGD). However, when a model is shared or released, there is no way to check whether it is differentially private, that is, it required to trust the model provider. This situation poses a problem when data privacy is mandatory, specially with current data regulations, as the presence of DP can not be certificated consistently by any third party. Thus, we face the challenge of determining whether a DL model has been trained with DP, according to the title question: Can we infer the presence of Differential Privacy in Deep Learning models' weights? Since the DP-SGD significantly changes the training process of a DL model, we hypothesize that DP leaves an imprint in the weights of a DL model, which can be used to predict whether a model has been trained with DP regardless of its architecture and the training dataset. In this paper, we propose to employ the imprint in model weights of using DP to infer the presence of DP training in a DL model. To substantiate our hypothesis, we developed an experimental methodology based on two datasets of weights of DL models, each with models with and without DP training and a meta-classifier to infer whether DP was used in the training process of a DL model, by accessing its weights. We accomplish both, the removal of the requirement of a trusted model provider and a strong foundation for this interesting line of research. Thus, our contribution is an additional layer of security on top of the strict private requirements of DP training in DL models, towards to DL models. ",
    "url": "https://arxiv.org/abs/2311.11717",
    "authors": [
      "Jim\u00e9nez-L\u00f3pez",
      "Daniel",
      "Rodr\u00edguez-Barroso",
      "Nuria",
      "Luz\u00f3n",
      "M. Victoria",
      "Herrera",
      "Francisco"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.11722",
    "title": "Sparse4D v3: Advancing End-to-End 3D Detection and Tracking",
    "abstract": "In autonomous driving perception systems, 3D detection and tracking are the two fundamental tasks. This paper delves deeper into this field, building upon the Sparse4D framework. We introduce two auxiliary training tasks (Temporal Instance Denoising and Quality Estimation) and propose decoupled attention to make structural improvements, leading to significant enhancements in detection performance. Additionally, we extend the detector into a tracker using a straightforward approach that assigns instance ID during inference, further highlighting the advantages of query-based algorithms. Extensive experiments conducted on the nuScenes benchmark validate the effectiveness of the proposed improvements. With ResNet50 as the backbone, we witnessed enhancements of 3.0\\%, 2.2\\%, and 7.6\\% in mAP, NDS, and AMOTA, achieving 46.9\\%, 56.1\\%, and 49.0\\%, respectively. Our best model achieved 71.9\\% NDS and 67.7\\% AMOTA on the nuScenes test set. Code will be released at \\url{https://github.com/linxuewu/Sparse4D}. ",
    "url": "https://arxiv.org/abs/2311.11722",
    "authors": [
      "Xuewu Lin",
      "Zixiang Pei",
      "Tianwei Lin",
      "Lichao Huang",
      "Zhizhong Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.11753",
    "title": "AdvGen: Physical Adversarial Attack on Face Presentation Attack  Detection Systems",
    "abstract": "Evaluating the risk level of adversarial images is essential for safely deploying face authentication models in the real world. Popular approaches for physical-world attacks, such as print or replay attacks, suffer from some limitations, like including physical and geometrical artifacts. Recently, adversarial attacks have gained attraction, which try to digitally deceive the learning strategy of a recognition system using slight modifications to the captured image. While most previous research assumes that the adversarial image could be digitally fed into the authentication systems, this is not always the case for systems deployed in the real world. This paper demonstrates the vulnerability of face authentication systems to adversarial images in physical world scenarios. We propose AdvGen, an automated Generative Adversarial Network, to simulate print and replay attacks and generate adversarial images that can fool state-of-the-art PADs in a physical domain attack setting. Using this attack strategy, the attack success rate goes up to 82.01%. We test AdvGen extensively on four datasets and ten state-of-the-art PADs. We also demonstrate the effectiveness of our attack by conducting experiments in a realistic, physical environment. ",
    "url": "https://arxiv.org/abs/2311.11753",
    "authors": [
      "Sai Amrit Patnaik",
      "Shivali Chansoriya",
      "Anil K. Jain",
      "Anoop M. Namboodiri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11754",
    "title": "A Large-Scale Car Parts (LSCP) Dataset for Lightweight Fine-Grained  Detection",
    "abstract": "Automotive related datasets have previously been used for training autonomous driving systems or vehicle classification tasks. However, there is a lack of datasets in the field of automotive AI for car parts detection, and most available datasets are limited in size and scope, struggling to cover diverse scenarios. To address this gap, this paper presents a large-scale and fine-grained automotive dataset consisting of 84,162 images for detecting 12 different types of car parts. This dataset was collected from natural cameras and online websites which covers various car brands, scenarios, and shooting angles. To alleviate the burden of manual annotation, we propose a novel semi-supervised auto-labeling method that leverages state-of-the-art pre-trained detectors. Moreover, we study the limitations of the Grounding DINO approach for zero-shot labeling. Finally, we evaluate the effectiveness of our proposed dataset through fine-grained car parts detection by training several lightweight YOLO-series detectors. ",
    "url": "https://arxiv.org/abs/2311.11754",
    "authors": [
      "Wang Jie",
      "Zhong Yilin",
      "Cao Qianqian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11756",
    "title": "LSTM-CNN: An efficient diagnostic network for Parkinson's disease  utilizing dynamic handwriting analysis",
    "abstract": "Background and objectives: Dynamic handwriting analysis, due to its non-invasive and readily accessible nature, has recently emerged as a vital adjunctive method for the early diagnosis of Parkinson's disease. In this study, we design a compact and efficient network architecture to analyse the distinctive handwriting patterns of patients' dynamic handwriting signals, thereby providing an objective identification for the Parkinson's disease diagnosis. Methods: The proposed network is based on a hybrid deep learning approach that fully leverages the advantages of both long short-term memory (LSTM) and convolutional neural networks (CNNs). Specifically, the LSTM block is adopted to extract the time-varying features, while the CNN-based block is implemented using one-dimensional convolution for low computational cost. Moreover, the hybrid model architecture is continuously refined under ablation studies for superior performance. Finally, we evaluate the proposed method with its generalization under a five-fold cross-validation, which validates its efficiency and robustness. Results: The proposed network demonstrates its versatility by achieving impressive classification accuracies on both our new DraWritePD dataset ($96.2\\%$) and the well-established PaHaW dataset ($90.7\\%$). Moreover, the network architecture also stands out for its excellent lightweight design, occupying a mere $0.084$M of parameters, with a total of only $0.59$M floating-point operations. It also exhibits near real-time CPU inference performance, with inference times ranging from $0.106$ to $0.220$s. Conclusions: We present a series of experiments with extensive analysis, which systematically demonstrate the effectiveness and efficiency of the proposed hybrid neural network in extracting distinctive handwriting patterns for precise diagnosis of Parkinson's disease. ",
    "url": "https://arxiv.org/abs/2311.11756",
    "authors": [
      "Xuechao Wang",
      "Junqing Huang",
      "Sven Nomm",
      "Marianna Chatzakou",
      "Kadri Medijainen",
      "Aaro Toomela",
      "Michael Ruzhansky"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11759",
    "title": "Unveiling the Unseen Potential of Graph Learning through MLPs: Effective  Graph Learners Using Propagation-Embracing MLPs",
    "abstract": "Recent studies attempted to utilize multilayer perceptrons (MLPs) to solve semi-supervised node classification on graphs, by training a student MLP by knowledge distillation (KD) from a teacher graph neural network (GNN). While previous studies have focused mostly on training the student MLP by matching the output probability distributions between the teacher and student models during KD, it has not been systematically studied how to inject the structural information in an explicit and interpretable manner. Inspired by GNNs that separate feature transformation $T$ and propagation $\\Pi$, we re-frame the KD process as enabling the student MLP to explicitly learn both $T$ and $\\Pi$. Although this can be achieved by applying the inverse propagation $\\Pi^{-1}$ before distillation from the teacher GNN, it still comes with a high computational cost from large matrix multiplications during training. To solve this problem, we propose Propagate & Distill (P&D), which propagates the output of the teacher GNN before KD and can be interpreted as an approximate process of the inverse propagation $\\Pi^{-1}$. Through comprehensive evaluations using real-world benchmark datasets, we demonstrate the effectiveness of P&D by showing further performance boost of the student MLP. ",
    "url": "https://arxiv.org/abs/2311.11759",
    "authors": [
      "Yong-Min Shin",
      "Won-Yong Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.11778",
    "title": "Preliminary Report: On Information Hiding in Multi-Hop Radio Networks",
    "abstract": "In this paper, we consider the problem of an adversary aiming to learn information about the network topology or the executed algorithm from some signals obtained during the algorithm's execution. The problem is defined in a very general form. However, it is mainly motivated by multi-hop ad hoc radio networks. In contrast to previous work concentrated on single-hop radio networks, this model is critically more complex due to the number of possible settings that need to be taken into account when considering different combinations of topologies and communication models. Moreover, the definition of the adversary is also ambiguous, and the adequate approach needs to depend on the adversary's aims and capabilities. This preliminary report presents a general theoretical background and some basic algorithms. We also propose some general taxonomy as a framework for future research. ",
    "url": "https://arxiv.org/abs/2311.11778",
    "authors": [
      "Marek Klonowski",
      "Mateusz Marciniak"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.11796",
    "title": "Beyond Boundaries: A Comprehensive Survey of Transferable Attacks on AI  Systems",
    "abstract": "Artificial Intelligence (AI) systems such as autonomous vehicles, facial recognition, and speech recognition systems are increasingly integrated into our daily lives. However, despite their utility, these AI systems are vulnerable to a wide range of attacks such as adversarial, backdoor, data poisoning, membership inference, model inversion, and model stealing attacks. In particular, numerous attacks are designed to target a particular model or system, yet their effects can spread to additional targets, referred to as transferable attacks. Although considerable efforts have been directed toward developing transferable attacks, a holistic understanding of the advancements in transferable attacks remains elusive. In this paper, we comprehensively explore learning-based attacks from the perspective of transferability, particularly within the context of cyber-physical security. We delve into different domains -- the image, text, graph, audio, and video domains -- to highlight the ubiquitous and pervasive nature of transferable attacks. This paper categorizes and reviews the architecture of existing attacks from various viewpoints: data, process, model, and system. We further examine the implications of transferable attacks in practical scenarios such as autonomous driving, speech recognition, and large language models (LLMs). Additionally, we outline the potential research directions to encourage efforts in exploring the landscape of transferable attacks. This survey offers a holistic understanding of the prevailing transferable attacks and their impacts across different domains. ",
    "url": "https://arxiv.org/abs/2311.11796",
    "authors": [
      "Guangjing Wang",
      "Ce Zhou",
      "Yuanda Wang",
      "Bocheng Chen",
      "Hanqing Guo",
      "Qiben Yan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11812",
    "title": "Improving Real Estate Appraisal with POI Integration and Areal Embedding",
    "abstract": "Despite advancements in real estate appraisal methods, this study primarily focuses on two pivotal challenges. Firstly, we explore the often-underestimated impact of Points of Interest (POI) on property values, emphasizing the necessity for a comprehensive, data-driven approach to feature selection. Secondly, we integrate road-network-based Areal Embedding to enhance spatial understanding for real estate appraisal. We first propose a revised method for POI feature extraction, and discuss the impact of each POI for house price appraisal. Then we present the Areal embedding-enabled Masked Multihead Attention-based Spatial Interpolation for House Price Prediction (AMMASI) model, an improvement upon the existing ASI model, which leverages masked multi-head attention on geographic neighbor houses and similar-featured houses. Our model outperforms current baselines and also offers promising avenues for future optimization in real estate appraisal methodologies. ",
    "url": "https://arxiv.org/abs/2311.11812",
    "authors": [
      "Sumin Han",
      "Youngjun Park",
      "Sonia Sabir",
      "Jisun An",
      "Dongman Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11815",
    "title": "CrackCLF: Automatic Pavement Crack Detection based on Closed-Loop  Feedback",
    "abstract": "Automatic pavement crack detection is an important task to ensure the functional performances of pavements during their service life. Inspired by deep learning (DL), the encoder-decoder framework is a powerful tool for crack detection. However, these models are usually open-loop (OL) systems that tend to treat thin cracks as the background. Meanwhile, these models can not automatically correct errors in the prediction, nor can it adapt to the changes of the environment to automatically extract and detect thin cracks. To tackle this problem, we embed closed-loop feedback (CLF) into the neural network so that the model could learn to correct errors on its own, based on generative adversarial networks (GAN). The resulting model is called CrackCLF and includes the front and back ends, i.e. segmentation and adversarial network. The front end with U-shape framework is employed to generate crack maps, and the back end with a multi-scale loss function is used to correct higher-order inconsistencies between labels and crack maps (generated by the front end) to address open-loop system issues. Empirical results show that the proposed CrackCLF outperforms others methods on three public datasets. Moreover, the proposed CLF can be defined as a plug and play module, which can be embedded into different neural network models to improve their performances. ",
    "url": "https://arxiv.org/abs/2311.11815",
    "authors": [
      "Chong Li",
      "Zhun Fan",
      "Ying Chen",
      "Huibiao Lin",
      "Laura Moretti",
      "Giuseppe Loprencipe",
      "Weihua Sheng",
      "Kelvin C. P. Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2311.11821",
    "title": "Cross-View Graph Consistency Learning for Invariant Graph  Representations",
    "abstract": "Graph representation learning is fundamental for analyzing graph-structured data. Exploring invariant graph representations remains a challenge for most existing graph representation learning methods. In this paper, we propose a cross-view graph consistency learning (CGCL) method that learns invariant graph representations for link prediction. First, two complementary augmented views are derived from an incomplete graph structure through a bidirectional graph structure augmentation scheme. This augmentation scheme mitigates the potential information loss that is commonly associated with various data augmentation techniques involving raw graph data, such as edge perturbation, node removal, and attribute masking. Second, we propose a CGCL model that can learn invariant graph representations. A cross-view training scheme is proposed to train the proposed CGCL model. This scheme attempts to maximize the consistency information between one augmented view and the graph structure reconstructed from the other augmented view. Furthermore, we offer a comprehensive theoretical CGCL analysis. This paper empirically and experimentally demonstrates the effectiveness of the proposed CGCL method, achieving competitive results on graph datasets in comparisons with several state-of-the-art algorithms. ",
    "url": "https://arxiv.org/abs/2311.11821",
    "authors": [
      "Jie Chen",
      "Zhiming Li",
      "Hua Mao",
      "Wai Lok Woo",
      "Xi Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11822",
    "title": "Zero redundancy distributed learning with differential privacy",
    "abstract": "Deep learning using large models have achieved great success in a wide range of domains. However, training these models on billions of parameters is very challenging in terms of the training speed, memory cost, and communication efficiency, especially under the privacy-preserving regime with differential privacy (DP). On the one hand, DP optimization has comparable efficiency to the standard non-private optimization on a single GPU, but on multiple GPUs, existing DP distributed learning (such as pipeline parallel) has suffered from significantly worse efficiency. On the other hand, the Zero Redundancy Optimizer (ZeRO) is a state-of-the-art solution to the standard distributed learning, exhibiting excellent training efficiency on large models, but to work compatibly with DP is technically complicated. In this work, we develop a new systematic solution, DP-ZeRO, (I) to scale up the trainable DP model size, e.g. to GPT-100B, (II) to obtain the same computation and communication efficiency as the standard ZeRO, and (III) to enable mixed-precision DP training. Our DP-ZeRO, like the standard ZeRO, has the potential to train models with arbitrary size and is evaluated on the world's largest DP models in terms of the number of trainable parameters. ",
    "url": "https://arxiv.org/abs/2311.11822",
    "authors": [
      "Zhiqi Bu",
      "Justin Chiu",
      "Ruixuan Liu",
      "Sheng Zha",
      "George Karypis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.11824",
    "title": "Graph Variational Embedding Collaborative Filtering",
    "abstract": "The customization of recommended content to users holds significant importance in enhancing user experiences across a wide spectrum of applications such as e-commerce, music, and shopping. Graph-based methods have achieved considerable performance by capturing user-item interactions. However, these methods tend to utilize randomly constructed embeddings in the dataset used for training the recommender, which lacks any user preferences. Here, we propose the concept of variational embeddings as a means of pre-training the recommender system to improve the feature propagation through the layers of graph convolutional networks (GCNs). The graph variational embedding collaborative filtering (GVECF) is introduced as a novel framework to incorporate representations learned through a variational graph auto-encoder which are embedded into a GCN-based collaborative filtering. This approach effectively transforms latent high-order user-item interactions into more trainable vectors, ultimately resulting in better performance in terms of recall and normalized discounted cumulative gain(NDCG) metrics. The experiments conducted on benchmark datasets demonstrate that our proposed method achieves up to 13.78% improvement in the recall over the test data. ",
    "url": "https://arxiv.org/abs/2311.11824",
    "authors": [
      "Narges Sadat Fazeli Dehkordi",
      "Hadi Zare",
      "Parham Moradi",
      "Mahdi Jalili"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11825",
    "title": "Holistic Inverse Rendering of Complex Facade via Aerial 3D Scanning",
    "abstract": "In this work, we use multi-view aerial images to reconstruct the geometry, lighting, and material of facades using neural signed distance fields (SDFs). Without the requirement of complex equipment, our method only takes simple RGB images captured by a drone as inputs to enable physically based and photorealistic novel-view rendering, relighting, and editing. However, a real-world facade usually has complex appearances ranging from diffuse rocks with subtle details to large-area glass windows with specular reflections, making it hard to attend to everything. As a result, previous methods can preserve the geometry details but fail to reconstruct smooth glass windows or verse vise. In order to address this challenge, we introduce three spatial- and semantic-adaptive optimization strategies, including a semantic regularization approach based on zero-shot segmentation techniques to improve material consistency, a frequency-aware geometry regularization to balance surface smoothness and details in different surfaces, and a visibility probe-based scheme to enable efficient modeling of the local lighting in large-scale outdoor environments. In addition, we capture a real-world facade aerial 3D scanning image set and corresponding point clouds for training and benchmarking. The experiment demonstrates the superior quality of our method on facade holistic inverse rendering, novel view synthesis, and scene editing compared to state-of-the-art baselines. ",
    "url": "https://arxiv.org/abs/2311.11825",
    "authors": [
      "Zixuan Xie",
      "Rengan Xie",
      "Rong Li",
      "Kai Huang",
      "Pengju Qiao",
      "Jingsen Zhu",
      "Xu Yin",
      "Qi Ye",
      "Wei Hua",
      "Yuchi Huo",
      "Hujun Bao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2311.11845",
    "title": "Entangled View-Epipolar Information Aggregation for Generalizable Neural  Radiance Fields",
    "abstract": "Generalizable NeRF can directly synthesize novel views across new scenes, eliminating the need for scene-specific retraining in vanilla NeRF. A critical enabling factor in these approaches is the extraction of a generalizable 3D representation by aggregating source-view features. In this paper, we propose an Entangled View-Epipolar Information Aggregation method dubbed EVE-NeRF. Different from existing methods that consider cross-view and along-epipolar information independently, EVE-NeRF conducts the view-epipolar feature aggregation in an entangled manner by injecting the scene-invariant appearance continuity and geometry consistency priors to the aggregation process. Our approach effectively mitigates the potential lack of inherent geometric and appearance constraint resulting from one-dimensional interactions, thus further boosting the 3D representation generalizablity. EVE-NeRF attains state-of-the-art performance across various evaluation scenarios. Extensive experiments demonstate that, compared to prevailing single-dimensional aggregation, the entangled network excels in the accuracy of 3D scene geometry and appearance reconstruction.Our project page is https://github.com/tatakai1/EVENeRF. ",
    "url": "https://arxiv.org/abs/2311.11845",
    "authors": [
      "Zhiyuan Min",
      "Yawei Luo",
      "Wei Yang",
      "Yuesong Wang",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11849",
    "title": "Multilayer Quantile Graph for Multivariate Time Series Analysis and  Dimensionality Reduction",
    "abstract": "In recent years, there has been a surge in the prevalence of high- and multi-dimensional temporal data across various scientific disciplines. These datasets are characterized by their vast size and challenging potential for analysis. Such data typically exhibit serial and cross-dependency and possess high dimensionality, thereby introducing additional complexities to conventional time series analysis methods. To address these challenges, a recent and complementary approach has emerged, known as network-based analysis methods for multivariate time series. In univariate settings, Quantile Graphs have been employed to capture temporal transition properties and reduce data dimensionality by mapping observations to a smaller set of sample quantiles. To confront the increasingly prominent issue of high dimensionality, we propose an extension of Quantile Graphs into a multivariate variant, which we term \"Multilayer Quantile Graphs\". In this innovative mapping, each time series is transformed into a Quantile Graph, and inter-layer connections are established to link contemporaneous quantiles of pairwise series. This enables the analysis of dynamic transitions across multiple dimensions. In this study, we demonstrate the effectiveness of this new mapping using a synthetic multivariate time series dataset. We delve into the resulting network's topological structures, extract network features, and employ these features for original dataset analysis. Furthermore, we compare our results with a recent method from the literature. The resulting multilayer network offers a significant reduction in the dimensionality of the original data while capturing serial and cross-dimensional transitions. This approach facilitates the characterization and analysis of large multivariate time series datasets through network analysis techniques. ",
    "url": "https://arxiv.org/abs/2311.11849",
    "authors": [
      "Vanessa Freitas Silva",
      "Maria Eduarda Silva",
      "Pedro Ribeiro",
      "Fernando Silva"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.11853",
    "title": "Asynchronous Bioplausible Neuron for Spiking Neural Networks for  Event-Based Vision",
    "abstract": "Spiking Neural Networks (SNNs) offer a biologically inspired approach to computer vision that can lead to more efficient processing of visual data with reduced energy consumption. However, maintaining homeostasis within these networks is challenging, as it requires continuous adjustment of neural responses to preserve equilibrium and optimal processing efficiency amidst diverse and often unpredictable input signals. In response to these challenges, we propose the Asynchronous Bioplausible Neuron (ABN), a dynamic spike firing mechanism to auto-adjust the variations in the input signal. Comprehensive evaluation across various datasets demonstrates ABN's enhanced performance in image classification and segmentation, maintenance of neural equilibrium, and energy efficiency. ",
    "url": "https://arxiv.org/abs/2311.11853",
    "authors": [
      "Sanket Kachole",
      "Hussain Sajwani",
      "Fariborz Baghaei Naeini",
      "Dimitrios Makris",
      "Yahya Zweiri"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2311.11861",
    "title": "Generating Valid and Natural Adversarial Examples with Large Language  Models",
    "abstract": "Deep learning-based natural language processing (NLP) models, particularly pre-trained language models (PLMs), have been revealed to be vulnerable to adversarial attacks. However, the adversarial examples generated by many mainstream word-level adversarial attack models are neither valid nor natural, leading to the loss of semantic maintenance, grammaticality, and human imperceptibility. Based on the exceptional capacity of language understanding and generation of large language models (LLMs), we propose LLM-Attack, which aims at generating both valid and natural adversarial examples with LLMs. The method consists of two stages: word importance ranking (which searches for the most vulnerable words) and word synonym replacement (which substitutes them with their synonyms obtained from LLMs). Experimental results on the Movie Review (MR), IMDB, and Yelp Review Polarity datasets against the baseline adversarial attack models illustrate the effectiveness of LLM-Attack, and it outperforms the baselines in human and GPT-4 evaluation by a significant margin. The model can generate adversarial examples that are typically valid and natural, with the preservation of semantic meaning, grammaticality, and human imperceptibility. ",
    "url": "https://arxiv.org/abs/2311.11861",
    "authors": [
      "Zimu Wang",
      "Wei Wang",
      "Qi Chen",
      "Qiufeng Wang",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.11864",
    "title": "Secure Data Transmission over Insecure Radio Channel in Wireless of  Things (WoT) Network",
    "abstract": "Potential capacity of processors is enhancing rapidly which leads to the increase of computational ability of the adversary. As a result, the required key size for conventional encryption techniques is growing everyday for complex unbreakable security communication systems. The Public Key Cryptography (PKC) techniques which use larger keys cannot be fitted in tiny resource constrained Wireless of Things (WoT) devices. Some Symmetric Key Cryptosystems (SKC) use smaller keys, which can be fitted in the tiny devices. But in large networks where the number of nodes is in the order of 103, the memory constraint does not allow the system to do so. The existing secure data communication in insecure medium uses various conventional encryption methods like Public Key Cryptography (PKC) and Symmetric Key Cryptosystems (SKC). Generally, modern encryption methods need huge processing power, memory and time. Also in some cases, Key Pre-distribution System (KPS) is used among different communicating devices. With the growing need for larger key size in the conventional secure communication system, the existing resources in the communicating devices suffer from resource starvation. Hence, the need of a novel mechanism for secure communication is inevitable. But the existing secure communication mechanisms like PKC, SKC or KPS do not ensure elimination of resource starvation issue in tiny devices during communication. In these existing conventional mechanisms, the plain text is generally converted into cipher text with greater size than the plain text at the device level, which leads to resource starvation. At the time of transmission, the cipher text at the device end requires more bandwidth than the plain text which puts bandwidth overhead on the broadcast channel (BC). ",
    "url": "https://arxiv.org/abs/2311.11864",
    "authors": [
      "Prokash Barman",
      "Banani Saha"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.11891",
    "title": "AMES: A Differentiable Embedding Space Selection Framework for Latent  Graph Inference",
    "abstract": "In real-world scenarios, although data entities may possess inherent relationships, the specific graph illustrating their connections might not be directly accessible. Latent graph inference addresses this issue by enabling Graph Neural Networks (GNNs) to operate on point cloud data, dynamically learning the necessary graph structure. These graphs are often derived from a latent embedding space, which can be modeled using Euclidean, hyperbolic, spherical, or product spaces. However, currently, there is no principled differentiable method for determining the optimal embedding space. In this work, we introduce the Attentional Multi-Embedding Selection (AMES) framework, a differentiable method for selecting the best embedding space for latent graph inference through backpropagation, considering a downstream task. Our framework consistently achieves comparable or superior results compared to previous methods for latent graph inference across five benchmark datasets. Importantly, our approach eliminates the need for conducting multiple experiments to identify the optimal embedding space. Furthermore, we explore interpretability techniques that track the gradient contributions of different latent graphs, shedding light on how our attention-based, fully differentiable approach learns to choose the appropriate latent space. In line with previous works, our experiments emphasize the advantages of hyperbolic spaces in enhancing performance. More importantly, our interpretability framework provides a general approach for quantitatively comparing embedding spaces across different tasks based on their contributions, a dimension that has been overlooked in previous literature on latent graph inference. ",
    "url": "https://arxiv.org/abs/2311.11891",
    "authors": [
      "Yuan Lu",
      "Haitz S\u00e1ez de Oc\u00e1riz Borde",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.11893",
    "title": "Towards Proactive Safe Human-Robot Collaborations via Data-Efficient  Conditional Behavior Prediction",
    "abstract": "We focus on the problem of how we can enable a robot to collaborate seamlessly with a human partner, specifically in scenarios like collaborative manufacturing where prexisting data is sparse. Much prior work in human-robot collaboration uses observational models of humans (i.e. models that treat the robot purely as an observer) to choose the robot's behavior, but such models do not account for the influence the robot has on the human's actions, which may lead to inefficient interactions. We instead formulate the problem of optimally choosing a collaborative robot's behavior based on a conditional model of the human that depends on the robot's future behavior. First, we propose a novel model-based formulation of conditional behavior prediction that allows the robot to infer the human's intentions based on its future plan in data-sparse environments. We then show how to utilize a conditional model for proactive goal selection and path generation around human collaborators. Finally, we use our proposed proactive controller in a collaborative task with real users to show that it can improve users' interactions with a robot collaborator quantitatively and qualitatively. ",
    "url": "https://arxiv.org/abs/2311.11893",
    "authors": [
      "Ravi Pandya",
      "Zhuoyuan Wang",
      "Yorie Nakahira",
      "Changliu Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.11905",
    "title": "Real-Time Surface-to-Air Missile Engagement Zone Prediction Using  Simulation and Machine Learning",
    "abstract": "Surface-to-Air Missiles (SAMs) are crucial in modern air defense systems. A critical aspect of their effectiveness is the Engagement Zone (EZ), the spatial region within which a SAM can effectively engage and neutralize a target. Notably, the EZ is intrinsically related to the missile's maximum range; it defines the furthest distance at which a missile can intercept a target. The accurate computation of this EZ is essential but challenging due to the dynamic and complex factors involved, which often lead to high computational costs and extended processing times when using conventional simulation methods. In light of these challenges, our study investigates the potential of machine learning techniques, proposing an approach that integrates machine learning with a custom-designed simulation tool to train supervised algorithms. We leverage a comprehensive dataset of pre-computed SAM EZ simulations, enabling our model to accurately predict the SAM EZ for new input parameters. It accelerates SAM EZ simulations, enhances air defense strategic planning, and provides real-time insights, improving SAM system performance. The study also includes a comparative analysis of machine learning algorithms, illuminating their capabilities and performance metrics and suggesting areas for future research, highlighting the transformative potential of machine learning in SAM EZ simulations. ",
    "url": "https://arxiv.org/abs/2311.11905",
    "authors": [
      "Joao P. A. Dantas",
      "Diego Geraldo",
      "Felipe L. L. Medeiros",
      "Marcos R. O. A. Maximo",
      "Takashi Yoneyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.11913",
    "title": "Deep Calibration of Market Simulations using Neural Density Estimators  and Embedding Networks",
    "abstract": "The ability to construct a realistic simulator of financial exchanges, including reproducing the dynamics of the limit order book, can give insight into many counterfactual scenarios, such as a flash crash, a margin call, or changes in macroeconomic outlook. In recent years, agent-based models have been developed that reproduce many features of an exchange, as summarised by a set of stylised facts and statistics. However, the ability to calibrate simulators to a specific period of trading remains an open challenge. In this work, we develop a novel approach to the calibration of market simulators by leveraging recent advances in deep learning, specifically using neural density estimators and embedding networks. We demonstrate that our approach is able to correctly identify high probability parameter sets, both when applied to synthetic and historical data, and without reliance on manually selected or weighted ensembles of stylised facts. ",
    "url": "https://arxiv.org/abs/2311.11913",
    "authors": [
      "Namid R. Stillman",
      "Rory Baggott",
      "Justin Lyon",
      "Jianfei Zhang",
      "Dingqiu Zhu",
      "Tao Chen",
      "Perukrishnen Vytelingum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.11961",
    "title": "NNG-Mix: Improving Semi-supervised Anomaly Detection with Pseudo-anomaly  Generation",
    "abstract": "Anomaly detection (AD) is essential in identifying rare and often critical events in complex systems, finding applications in fields such as network intrusion detection, financial fraud detection, and fault detection in infrastructure and industrial systems. While AD is typically treated as an unsupervised learning task due to the high cost of label annotation, it is more practical to assume access to a small set of labeled anomaly samples from domain experts, as is the case for semi-supervised anomaly detection. Semi-supervised and supervised approaches can leverage such labeled data, resulting in improved performance. In this paper, rather than proposing a new semi-supervised or supervised approach for AD, we introduce a novel algorithm for generating additional pseudo-anomalies on the basis of the limited labeled anomalies and a large volume of unlabeled data. This serves as an augmentation to facilitate the detection of new anomalies. Our proposed algorithm, named Nearest Neighbor Gaussian Mixup (NNG-Mix), efficiently integrates information from both labeled and unlabeled data to generate pseudo-anomalies. We compare the performance of this novel algorithm with commonly applied augmentation techniques, such as Mixup and Cutout. We evaluate NNG-Mix by training various existing semi-supervised and supervised anomaly detection algorithms on the original training data along with the generated pseudo-anomalies. Through extensive experiments on 57 benchmark datasets in ADBench, reflecting different data types, we demonstrate that NNG-Mix outperforms other data augmentation methods. It yields significant performance improvements compared to the baselines trained exclusively on the original training data. Notably, NNG-Mix yields up to 16.4%, 8.8%, and 8.0% improvements on Classical, CV, and NLP datasets in ADBench. Our source code will be available at https://github.com/donghao51/NNG-Mix. ",
    "url": "https://arxiv.org/abs/2311.11961",
    "authors": [
      "Hao Dong",
      "Ga\u00ebtan Frusque",
      "Yue Zhao",
      "Eleni Chatzi",
      "Olga Fink"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11976",
    "title": "Context-aware Neural Machine Translation for English-Japanese Business  Scene Dialogues",
    "abstract": "Despite the remarkable advancements in machine translation, the current sentence-level paradigm faces challenges when dealing with highly-contextual languages like Japanese. In this paper, we explore how context-awareness can improve the performance of the current Neural Machine Translation (NMT) models for English-Japanese business dialogues translation, and what kind of context provides meaningful information to improve translation. As business dialogue involves complex discourse phenomena but offers scarce training resources, we adapted a pretrained mBART model, finetuning on multi-sentence dialogue data, which allows us to experiment with different contexts. We investigate the impact of larger context sizes and propose novel context tokens encoding extra-sentential information, such as speaker turn and scene type. We make use of Conditional Cross-Mutual Information (CXMI) to explore how much of the context the model uses and generalise CXMI to study the impact of the extra-sentential context. Overall, we find that models leverage both preceding sentences and extra-sentential context (with CXMI increasing with context size) and we provide a more focused analysis on honorifics translation. Regarding translation quality, increased source-side context paired with scene and speaker information improves the model performance compared to previous work and our context-agnostic baselines, measured in BLEU and COMET metrics. ",
    "url": "https://arxiv.org/abs/2311.11976",
    "authors": [
      "Sumire Honda",
      "Patrick Fernandes",
      "Chrysoula Zerva"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.11995",
    "title": "BrainWash: A Poisoning Attack to Forget in Continual Learning",
    "abstract": "Continual learning has gained substantial attention within the deep learning community, offering promising solutions to the challenging problem of sequential learning. Yet, a largely unexplored facet of this paradigm is its susceptibility to adversarial attacks, especially with the aim of inducing forgetting. In this paper, we introduce \"BrainWash,\" a novel data poisoning method tailored to impose forgetting on a continual learner. By adding the BrainWash noise to a variety of baselines, we demonstrate how a trained continual learner can be induced to forget its previously learned tasks catastrophically, even when using these continual learning baselines. An important feature of our approach is that the attacker requires no access to previous tasks' data and is armed merely with the model's current parameters and the data belonging to the most recent task. Our extensive experiments highlight the efficacy of BrainWash, showcasing degradation in performance across various regularization-based continual learning methods. ",
    "url": "https://arxiv.org/abs/2311.11995",
    "authors": [
      "Ali Abbasi",
      "Parsa Nooralinejad",
      "Hamed Pirsiavash",
      "Soheil Kolouri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.11997",
    "title": "Smart Energy Network Digital Twins: Findings from a UK-Based  Demonstrator Project",
    "abstract": "Digital Twins promise to deliver a step-change in distribution system operations and planning, but there are few real-world examples that explore the challenges of combining imperfect model and measurement data, and then use these as the basis for subsequent analysis. In this work we propose a Digital Twin framework for electrical distribution systems and implement that framework on the Smart Energy Network Demonstrator microgrid in the UK. The data and software implementation are made available open-source, and consist of a network model, power meter measurements, and unbalanced power flow-based algorithms. Measurement and network uncertainties are shown to have a substantial impact on the quality of Digital Twin outputs. The potential benefits of a dynamic export limit and voltage control are estimated using the Digital Twin, using simulated measurements to address data quality challenges, with results showing curtailment for an exemplar day could be reduced by 56%. Power meter data and a network model are shown to be necessary for developing algorithms that enable decision-making that is robust to real-world uncertainties, with possibilities and challenges of Digital Twin development clearly demonstrated. ",
    "url": "https://arxiv.org/abs/2311.11997",
    "authors": [
      "Matthew Deakin",
      "Marta Vanin",
      "Zhong Fan",
      "Dirk Van Hertem"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.12024",
    "title": "PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape  Prediction",
    "abstract": "We propose a Pose-Free Large Reconstruction Model (PF-LRM) for reconstructing a 3D object from a few unposed images even with little visual overlap, while simultaneously estimating the relative camera poses in ~1.3 seconds on a single A100 GPU. PF-LRM is a highly scalable method utilizing the self-attention blocks to exchange information between 3D object tokens and 2D image tokens; we predict a coarse point cloud for each view, and then use a differentiable Perspective-n-Point (PnP) solver to obtain camera poses. When trained on a huge amount of multi-view posed data of ~1M objects, PF-LRM shows strong cross-dataset generalization ability, and outperforms baseline methods by a large margin in terms of pose prediction accuracy and 3D reconstruction quality on various unseen evaluation datasets. We also demonstrate our model's applicability in downstream text/image-to-3D task with fast feed-forward inference. Our project website is at: https://totoro97.github.io/pf-lrm . ",
    "url": "https://arxiv.org/abs/2311.12024",
    "authors": [
      "Peng Wang",
      "Hao Tan",
      "Sai Bi",
      "Yinghao Xu",
      "Fujun Luan",
      "Kalyan Sunkavalli",
      "Wenping Wang",
      "Zexiang Xu",
      "Kai Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.12026",
    "title": "Rate-Independent Gradient Crystal Plasticity Theory -- Robust  Algorithmic Formulations based on Incremental Energy Minimization",
    "abstract": "Numerically robust algorithmic formulations suitable for rate-independent crystal plasticity are presented. They cover classic local models as well as gradient-enhanced theories in which the gradients of the plastic slips are incorporated by means of the micromorphic approach. The elaborated algorithmic formulations rely on the underlying variational structure of (associative) crystal plasticity. To be more precise and in line with so-called variational constitutive updates or incremental energy minimization principles, an incrementally defined energy derived from the underlying time-continuous constitutive model represents the starting point of the novel numerically robust algorithmic formulations. This incrementally defined potential allows to compute all variables jointly as minimizers of this energy. While such discrete variational constitutive updates are not new in general, they are considered here in order to employ powerful techniques from non-linear constrained optimization theory in order to compute robustly the aforementioned minimizers. The analyzed prototype models are based on (1) nonlinear complementarity problem (NCP) functions as well as on (2) the augmented Lagrangian formulation. Numerical experiments show the numerical robustness of the resulting algorithmic formulations. Furthermore, it is shown that the novel algorithmic ideas can also be integrated into classic, non-variational, return-mapping schemes. ",
    "url": "https://arxiv.org/abs/2311.12026",
    "authors": [
      "Volker Fohrmeister",
      "J\u00f6rn Mosler"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2311.10754",
    "title": "A Recent Survey of the Advancements in Deep Learning Techniques for  Monkeypox Disease Detection",
    "abstract": "Monkeypox is a zoonotic infectious disease induced by the Monkeypox virus, part of the poxviridae orthopoxvirus group initially discovered in Africa and gained global attention in mid-2022 with cases reported outside endemic areas. Symptoms include headaches, chills, fever, smallpox, measles, and chickenpox-like skin manifestations and the WHO officially announced monkeypox as a global public health pandemic, in July-2022. Timely diagnosis is imperative for assessing disease severity, conducting clinical evaluations, and determining suitable treatment plans. Traditionally, PCR testing of skin lesions is considered a benchmark for the primary diagnosis by WHO, with symptom management as the primary treatment and antiviral drugs like tecovirimat for severe cases. However, manual analysis within hospitals poses a substantial challenge during public health emergencies, particularly in the case of epidemics and pandemics. Therefore, this survey paper provides an extensive and efficient analysis of deep learning (DL) methods for the automatic detection of MP in skin lesion images. These DL techniques are broadly grouped into categories, including deep CNN, Deep CNNs ensemble, deep hybrid learning, the newly developed, and Vision transformer for diagnosing MP. Additionally, the paper addresses benchmark datasets and their collection from various authentic sources, pre-processing techniques, and evaluation metrics. The survey also briefly delves into emerging concepts, identifies research gaps, limitations, and applications, and outlines challenges in the diagnosis process. This survey furnishes valuable insights into the prospective areas of DL study and is anticipated to serve as a path for researchers. ",
    "url": "https://arxiv.org/abs/2311.10754",
    "authors": [
      "Saddam Hussain Khan",
      "Rashid Iqbal",
      "Saeeda Naz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.10756",
    "title": "Earnings Prediction Using Recurrent Neural Networks",
    "abstract": "Firm disclosures about future prospects are crucial for corporate valuation and compliance with global regulations, such as the EU's MAR and the US's SEC Rule 10b-5 and RegFD. To comply with disclosure obligations, issuers must identify nonpublic information with potential material impact on security prices as only new, relevant and unexpected information materially affects prices in efficient markets. Financial analysts, assumed to represent public knowledge on firms' earnings prospects, face limitations in offering comprehensive coverage and unbiased estimates. This study develops a neural network to forecast future firm earnings, using four decades of financial data, addressing analysts' coverage gaps and potentially revealing hidden insights. The model avoids selectivity and survivorship biases as it allows for missing data. Furthermore, the model is able to produce both fiscal-year-end and quarterly earnings predictions. Its performance surpasses benchmark models from the academic literature by a wide margin and outperforms analysts' forecasts for fiscal-year-end earnings predictions. ",
    "url": "https://arxiv.org/abs/2311.10756",
    "authors": [
      "Moritz Scherrmann",
      "Ralf Elsas"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.10801",
    "title": "Reinforcement Learning with Maskable Stock Representation for Portfolio  Management in Customizable Stock Pools",
    "abstract": "Portfolio management (PM) is a fundamental financial trading task, which explores the optimal periodical reallocation of capitals into different stocks to pursue long-term profits. Reinforcement learning (RL) has recently shown its potential to train profitable agents for PM through interacting with financial markets. However, existing work mostly focuses on fixed stock pools, which is inconsistent with investors' practical demand. Specifically, the target stock pool of different investors varies dramatically due to their discrepancy on market states and individual investors may temporally adjust stocks they desire to trade (e.g., adding one popular stocks), which lead to customizable stock pools (CSPs). Existing RL methods require to retrain RL agents even with a tiny change of the stock pool, which leads to high computational cost and unstable performance. To tackle this challenge, we propose EarnMore, a rEinforcement leARNing framework with Maskable stOck REpresentation to handle PM with CSPs through one-shot training in a global stock pool (GSP). Specifically, we first introduce a mechanism to mask out the representation of the stocks outside the target pool. Second, we learn meaningful stock representations through a self-supervised masking and reconstruction process. Third, a re-weighting mechanism is designed to make the portfolio concentrate on favorable stocks and neglect the stocks outside the target pool. Through extensive experiments on 8 subset stock pools of the US stock market, we demonstrate that EarnMore significantly outperforms 14 state-of-the-art baselines in terms of 6 popular financial metrics with over 40% improvement on profit. ",
    "url": "https://arxiv.org/abs/2311.10801",
    "authors": [
      "Wentao Zhang"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.10808",
    "title": "Multiparameter Persistent Homology for Molecular Property Prediction",
    "abstract": "In this study, we present a novel molecular fingerprint generation method based on multiparameter persistent homology. This approach reveals the latent structures and relationships within molecular geometry, and detects topological features that exhibit persistence across multiple scales along multiple parameters, such as atomic mass, partial charge, and bond type, and can be further enhanced by incorporating additional parameters like ionization energy, electron affinity, chirality and orbital hybridization. The proposed fingerprinting method provides fresh perspectives on molecular structure that are not easily discernible from single-parameter or single-scale analysis. Besides, in comparison with traditional graph neural networks, multiparameter persistent homology has the advantage of providing a more comprehensive and interpretable characterization of the topology of the molecular data. We have established theoretical stability guarantees for multiparameter persistent homology, and have conducted extensive experiments on the Lipophilicity, FreeSolv, and ESOL datasets to demonstrate its effectiveness in predicting molecular properties. ",
    "url": "https://arxiv.org/abs/2311.10808",
    "authors": [
      "Andac Demir",
      "Bulent Kiziltan"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2311.10857",
    "title": "WATUNet: A Deep Neural Network for Segmentation of Volumetric Sweep  Imaging Ultrasound",
    "abstract": "Objective. Limited access to breast cancer diagnosis globally leads to delayed treatment. Ultrasound, an effective yet underutilized method, requires specialized training for sonographers, which hinders its widespread use. Approach. Volume sweep imaging (VSI) is an innovative approach that enables untrained operators to capture high-quality ultrasound images. Combined with deep learning, like convolutional neural networks (CNNs), it can potentially transform breast cancer diagnosis, enhancing accuracy, saving time and costs, and improving patient outcomes. The widely used UNet architecture, known for medical image segmentation, has limitations, such as vanishing gradients and a lack of multi-scale feature extraction and selective region attention. In this study, we present a novel segmentation model known as Wavelet_Attention_UNet (WATUNet). In this model, we incorporate wavelet gates (WGs) and attention gates (AGs) between the encoder and decoder instead of a simple connection to overcome the limitations mentioned, thereby improving model performance. Main results. Two datasets are utilized for the analysis. The public \"Breast Ultrasound Images\" (BUSI) dataset of 780 images and a VSI dataset of 3818 images. Both datasets contained segmented lesions categorized into three types: no mass, benign mass, and malignant mass. Our segmentation results show superior performance compared to other deep networks. The proposed algorithm attained a Dice coefficient of 0.94 and an F1 score of 0.94 on the VSI dataset and scored 0.93 and 0.94 on the public dataset, respectively. ",
    "url": "https://arxiv.org/abs/2311.10857",
    "authors": [
      "Donya Khaledyan",
      "Thomas J. Marini",
      "Avice OConnell",
      "Steven Meng",
      "Jonah Kan",
      "Galen Brennan",
      "Yu Zhao",
      "Timothy M.Baran",
      "Kevin J. Parker"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.10869",
    "title": "Evolutionary algorithms as an alternative to backpropagation for  supervised training of Biophysical Neural Networks and Neural ODEs",
    "abstract": "Training networks consisting of biophysically accurate neuron models could allow for new insights into how brain circuits can organize and solve tasks. We begin by analyzing the extent to which the central algorithm for neural network learning -- stochastic gradient descent through backpropagation (BP) -- can be used to train such networks. We find that properties of biophysically based neural network models needed for accurate modelling such as stiffness, high nonlinearity and long evaluation timeframes relative to spike times makes BP unstable and divergent in a variety of cases. To address these instabilities and inspired by recent work, we investigate the use of \"gradient-estimating\" evolutionary algorithms (EAs) for training biophysically based neural networks. We find that EAs have several advantages making them desirable over direct BP, including being forward-pass only, robust to noisy and rigid losses, allowing for discrete loss formulations, and potentially facilitating a more global exploration of parameters. We apply our method to train a recurrent network of Morris-Lecar neuron models on a stimulus integration and working memory task, and show how it can succeed in cases where direct BP is inapplicable. To expand on the viability of EAs in general, we apply them to a general neural ODE problem and a stiff neural ODE benchmark and find again that EAs can out-perform direct BP here, especially for the over-parameterized regime. Our findings suggest that biophysical neurons could provide useful benchmarks for testing the limits of BP-adjacent methods, and demonstrate the viability of EAs for training networks with complex components. ",
    "url": "https://arxiv.org/abs/2311.10869",
    "authors": [
      "James Hazelden",
      "Yuhan Helena Liu",
      "Eli Shlizerman",
      "Eric Shea-Brown"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.10954",
    "title": "Taxonomic analysis of asteroids with artificial neural networks",
    "abstract": "We study the surface composition of asteroids with visible and/or infrared spectroscopy. For example, asteroid taxonomy is based on the spectral features or multiple color indices in visible and near-infrared wavelengths. The composition of asteroids gives key information to understand their origin and evolution. However, we lack compositional information for faint asteroids due to limits of ground-based observational instruments. In the near future, the Chinese Space Survey telescope (CSST) will provide multiple colors and spectroscopic data for asteroids of apparent magnitude brighter than 25 mag and 23 mag, respectively. For the aim of analysis of the CSST spectroscopic data, we applied an algorithm using artificial neural networks (ANNs) to establish a preliminary classification model for asteroid taxonomy according to the design of the survey module of CSST. Using the SMASS II spectra and the Bus-Binzel taxonomy system, our ANN classification tool composed of 5 individual ANNs is constructed, and the accuracy of this classification system is higher than 92 %. As the first application of our ANN tool, 64 spectra of 42 asteroids obtained in 2006 and 2007 by us with the 2.16-m telescope in the Xinglong station (Observatory Code 327) of National Astronomical Observatory of China are analyzed. The predicted labels of these spectra using our ANN tool are found to be reasonable when compared to their known taxonomic labels. Considering the accuracy and stability, our ANN tool can be applied to analyse the CSST asteroid spectra in the future. ",
    "url": "https://arxiv.org/abs/2311.10954",
    "authors": [
      "Nanping Luo",
      "Xiaobin Wang",
      "Shenghong Gu",
      "Antti Penttil\u00e4",
      "Karri Muinonen",
      "Yisi Liu"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.11096",
    "title": "On the Out of Distribution Robustness of Foundation Models in Medical  Image Segmentation",
    "abstract": "Constructing a robust model that can effectively generalize to test samples under distribution shifts remains a significant challenge in the field of medical imaging. The foundational models for vision and language, pre-trained on extensive sets of natural image and text data, have emerged as a promising approach. It showcases impressive learning abilities across different tasks with the need for only a limited amount of annotated samples. While numerous techniques have focused on developing better fine-tuning strategies to adapt these models for specific domains, we instead examine their robustness to domain shifts in the medical image segmentation task. To this end, we compare the generalization performance to unseen domains of various pre-trained models after being fine-tuned on the same in-distribution dataset and show that foundation-based models enjoy better robustness than other architectures. From here, we further developed a new Bayesian uncertainty estimation for frozen models and used them as an indicator to characterize the model's performance on out-of-distribution (OOD) data, proving particularly beneficial for real-world applications. Our experiments not only reveal the limitations of current indicators like accuracy on the line or agreement on the line commonly used in natural image applications but also emphasize the promise of the introduced Bayesian uncertainty. Specifically, lower uncertainty predictions usually tend to higher out-of-distribution (OOD) performance. ",
    "url": "https://arxiv.org/abs/2311.11096",
    "authors": [
      "Duy Minh Ho Nguyen",
      "Tan Ngoc Pham",
      "Nghiem Tuong Diep",
      "Nghi Quoc Phan",
      "Quang Pham",
      "Vinh Tong",
      "Binh T. Nguyen",
      "Ngan Hoang Le",
      "Nhat Ho",
      "Pengtao Xie",
      "Daniel Sonntag",
      "Mathias Niepert"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11128",
    "title": "Evolutionary game selection creates cooperative environments",
    "abstract": "The emergence of collective cooperation in competitive environments is a well-known phenomenon in biology, economics and social systems. While most evolutionary game models focus on the evolution of strategies for a fixed game, how strategic decisions co-evolve with the environment has so far mostly been overlooked. Here, we consider a game selection model where not only the strategies but also the game can change over time following evolutionary principles. Our results show that co-evolutionary dynamics of games and strategies can induce novel collective phenomena, fostering the emergence of cooperative environments. When the model is taken on structured populations the architecture of the interaction network can significantly amplify pro-social behaviour, with a critical role played by network heterogeneity and the presence of clustered groups, distinctive features observed in real-world populations. By unveiling the link between the evolution of strategies and games for different structured populations, our model sheds new light on the origin of social dilemmas ubiquitously observed in real-world social systems. ",
    "url": "https://arxiv.org/abs/2311.11128",
    "authors": [
      "Onkar Sadekar",
      "Andrea Civilini",
      "Jes\u00fas G\u00f3mez-Garde\u00f1es",
      "Vito Latora",
      "Federico Battiston"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computer Science and Game Theory (cs.GT)",
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Populations and Evolution (q-bio.PE)"
    ]
  },
  {
    "id": "arXiv:2311.11187",
    "title": "Link Streams as a Generalization of Graphs and Time Series",
    "abstract": "A link stream is a set of possibly weighted triplets (t, u, v) modeling that u and v interacted at time t. Link streams offer an effective model for datasets containing both temporal and relational information, making their proper analysis crucial in many applications. They are commonly regarded as sequences of graphs or collections of time series. Yet, a recent seminal work demonstrated that link streams are more general objects of which graphs are only particular cases. It therefore started the construction of a dedicated formalism for link streams by extending graph theory. In this work, we contribute to the development of this formalism by showing that link streams also generalize time series. In particular, we show that a link stream corresponds to a time-series extended to a relational dimension, which opens the door to also extend the framework of signal processing to link streams. We therefore develop extensions of numerous signal concepts to link streams: from elementary ones like energy, correlation, and differentiation, to more advanced ones like Fourier transform and filters. ",
    "url": "https://arxiv.org/abs/2311.11187",
    "authors": [
      "Esteban Bautista",
      "Matthieu Latapy"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.11234",
    "title": "Enhancing Radiology Diagnosis through Convolutional Neural Networks for  Computer Vision in Healthcare",
    "abstract": "The transformative power of Convolutional Neural Networks (CNNs) in radiology diagnostics is examined in this study, with a focus on interpretability, effectiveness, and ethical issues. With an altered DenseNet architecture, the CNN performs admirably in terms of particularity, sensitivity, as well as accuracy. Its superiority over conventional methods is validated by comparative analyses, which highlight efficiency gains. Nonetheless, interpretability issues highlight the necessity of sophisticated methods in addition to continuous model improvement. Integration issues like interoperability and radiologists' training lead to suggestions for teamwork. Systematic consideration of the ethical implications is carried out, necessitating extensive frameworks. Refinement of architectures, interpretability, alongside ethical considerations need to be prioritized in future work for responsible CNN deployment in radiology diagnostics. ",
    "url": "https://arxiv.org/abs/2311.11234",
    "authors": [
      "Keshav Kumar K.",
      "Dr N V S L Narasimham"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.11258",
    "title": "Tensor networks for interpretable and efficient quantum-inspired machine  learning",
    "abstract": "It is a critical challenge to simultaneously gain high interpretability and efficiency with the current schemes of deep machine learning (ML). Tensor network (TN), which is a well-established mathematical tool originating from quantum mechanics, has shown its unique advantages on developing efficient ``white-box'' ML schemes. Here, we give a brief review on the inspiring progresses made in TN-based ML. On one hand, interpretability of TN ML is accommodated with the solid theoretical foundation based on quantum information and many-body physics. On the other hand, high efficiency can be rendered from the powerful TN representations and the advanced computational techniques developed in quantum many-body physics. With the fast development on quantum computers, TN is expected to conceive novel schemes runnable on quantum hardware, heading towards the ``quantum artificial intelligence'' in the forthcoming future. ",
    "url": "https://arxiv.org/abs/2311.11258",
    "authors": [
      "Shi-Ju Ran",
      "Gang Su"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.11412",
    "title": "Neural Quantum Embedding: Pushing the Limits of Quantum Supervised  Learning",
    "abstract": "Quantum embedding is indispensable for applying quantum machine learning techniques to classical data, and has substantial impacts on performance outcomes. In this study, we present Neural Quantum Embedding (NQE), a method that efficiently optimizes quantum embedding by leveraging classical deep learning techniques. NQE enhances the lower bound of the empirical risk, leading to substantial improvements in classification performance. Moreover, NQE improves robustness against noise. To validate the effectiveness of NQE, we conduct experiments on IBM quantum devices for image data classification, resulting in a remarkable accuracy enhancement from 0.52 to 0.96. Numerical analysis of the local effective dimension highlights that NQE improves the trainability and generalization performance of quantum neural networks. Furthermore, NQE achieves improved generalization in the quantum kernel method, as evidenced by a reduction in the upper bound of the expected risk. ",
    "url": "https://arxiv.org/abs/2311.11412",
    "authors": [
      "Tak Hur",
      "Israel F. Araujo",
      "Daniel K. Park"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ]
  },
  {
    "id": "arXiv:2311.11436",
    "title": "Duality of Bures and Shape Distances with Implications for Comparing  Neural Representations",
    "abstract": "A multitude of (dis)similarity measures between neural network representations have been proposed, resulting in a fragmented research landscape. Most of these measures fall into one of two categories. First, measures such as linear regression, canonical correlations analysis (CCA), and shape distances, all learn explicit mappings between neural units to quantify similarity while accounting for expected invariances. Second, measures such as representational similarity analysis (RSA), centered kernel alignment (CKA), and normalized Bures similarity (NBS) all quantify similarity in summary statistics, such as stimulus-by-stimulus kernel matrices, which are already invariant to expected symmetries. Here, we take steps towards unifying these two broad categories of methods by observing that the cosine of the Riemannian shape distance (from category 1) is equal to NBS (from category 2). We explore how this connection leads to new interpretations of shape distances and NBS, and draw contrasts of these measures with CKA, a popular similarity measure in the deep learning literature. ",
    "url": "https://arxiv.org/abs/2311.11436",
    "authors": [
      "Sarah E. Harvey",
      "Brett W. Larsen",
      "Alex H. Williams"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.11520",
    "title": "Liver Tumor Prediction with Advanced Attention Mechanisms Integrated  into a Depth-Based Variant Search Algorithm",
    "abstract": "In recent days, Deep Learning (DL) techniques have become an emerging transformation in the field of machine learning, artificial intelligence, computer vision, and so on. Subsequently, researchers and industries have been highly endorsed in the medical field, predicting and controlling diverse diseases at specific intervals. Liver tumor prediction is a vital chore in analyzing and treating liver diseases. This paper proposes a novel approach for predicting liver tumors using Convolutional Neural Networks (CNN) and a depth-based variant search algorithm with advanced attention mechanisms (CNN-DS-AM). The proposed work aims to improve accuracy and robustness in diagnosing and treating liver diseases. The anticipated model is assessed on a Computed Tomography (CT) scan dataset containing both benign and malignant liver tumors. The proposed approach achieved high accuracy in predicting liver tumors, outperforming other state-of-the-art methods. Additionally, advanced attention mechanisms were incorporated into the CNN model to enable the identification and highlighting of regions of the CT scans most relevant to predicting liver tumors. The results suggest that incorporating attention mechanisms and a depth-based variant search algorithm into the CNN model is a promising approach for improving the accuracy and robustness of liver tumor prediction. It can assist radiologists in their diagnosis and treatment planning. The proposed system achieved a high accuracy of 95.5% in predicting liver tumors, outperforming other state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2311.11520",
    "authors": [
      "P. Kalaiselvi",
      "S. Anusuya"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.11749",
    "title": "Revealing behavioral impact on mobility prediction networks through  causal interventions",
    "abstract": "Deep neural networks are increasingly utilized in mobility prediction tasks, yet their intricate internal workings pose challenges for interpretability, especially in comprehending how various aspects of mobility behavior affect predictions. In this study, we introduce a causal intervention framework to assess the impact of mobility-related factors on neural networks designed for next location prediction -- a task focusing on predicting the immediate next location of an individual. To achieve this, we employ individual mobility models to generate synthetic location visit sequences and control behavior dynamics by intervening in their data generation process. We evaluate the interventional location sequences using mobility metrics and input them into well-trained networks to analyze performance variations. The results demonstrate the effectiveness in producing location sequences with distinct mobility behaviors, thus facilitating the simulation of diverse spatial and temporal changes. These changes result in performance fluctuations in next location prediction networks, revealing impacts of critical mobility behavior factors, including sequential patterns in location transitions, proclivity for exploring new locations, and preferences in location choices at population and individual levels. The gained insights hold significant value for the real-world application of mobility prediction networks, and the framework is expected to promote the use of causal inference for enhancing the interpretability and robustness of neural networks in mobility applications. ",
    "url": "https://arxiv.org/abs/2311.11749",
    "authors": [
      "Ye Hong",
      "Yanan Xin",
      "Simon Dirmeier",
      "Fernando Perez-Cruz",
      "Martin Raubal"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.11782",
    "title": "Robust Tumor Segmentation with Hyperspectral Imaging and Graph Neural  Networks",
    "abstract": "Segmenting the boundary between tumor and healthy tissue during surgical cancer resection poses a significant challenge. In recent years, Hyperspectral Imaging (HSI) combined with Machine Learning (ML) has emerged as a promising solution. However, due to the extensive information contained within the spectral domain, most ML approaches primarily classify individual HSI (super-)pixels, or tiles, without taking into account their spatial context. In this paper, we propose an improved methodology that leverages the spatial context of tiles for more robust and smoother segmentation. To address the irregular shapes of tiles, we utilize Graph Neural Networks (GNNs) to propagate context information across neighboring regions. The features for each tile within the graph are extracted using a Convolutional Neural Network (CNN), which is trained simultaneously with the subsequent GNN. Moreover, we incorporate local image quality metrics into the loss function to enhance the training procedure's robustness against low-quality regions in the training images. We demonstrate the superiority of our proposed method using a clinical ex vivo dataset consisting of 51 HSI images from 30 patients. Despite the limited dataset, the GNN-based model significantly outperforms context-agnostic approaches, accurately distinguishing between healthy and tumor tissues, even in images from previously unseen patients. Furthermore, we show that our carefully designed loss function, accounting for local image quality, results in additional improvements. Our findings demonstrate that context-aware GNN algorithms can robustly find tumor demarcations on HSI images, ultimately contributing to better surgery success and patient outcome. ",
    "url": "https://arxiv.org/abs/2311.11782",
    "authors": [
      "Mayar Lotfy",
      "Anna Alperovich",
      "Tommaso Giannantonio",
      "Bjorn Barz",
      "Xiaohan Zhang",
      "Felix Holm",
      "Nassir Navab",
      "Felix Boehm",
      "Carolin Schwamborn",
      "Thomas K. Hoffmann",
      "Patrick J. Schuler"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.11804",
    "title": "Robust Multidimentional Chinese Remainder Theorem for Integer Vector  Reconstruction",
    "abstract": "The problem of robustly reconstructing an integer vector from its erroneous remainders appears in many applications in the field of multidimensional (MD) signal processing. To address this problem, a robust MD Chinese remainder theorem (CRT) was recently proposed for a special class of moduli, where the remaining integer matrices left-divided by a greatest common left divisor (gcld) of all the moduli are pairwise commutative and coprime. The strict constraint on the moduli limits the usefulness of the robust MD-CRT in practice. In this paper, we investigate the robust MD-CRT for a general set of moduli. We first introduce a necessary and sufficient condition on the difference between paired remainder errors, followed by a simple sufficient condition on the remainder error bound, for the robust MD-CRT for general moduli, where the conditions are associated with (the minimum distances of) these lattices generated by gcld's of paired moduli, and a closed-form reconstruction algorithm is presented. We then generalize the above results of the robust MD-CRT from integer vectors/matrices to real ones. Finally, we validate the robust MD-CRT for general moduli by employing numerical simulations, and apply it to MD sinusoidal frequency estimation based on multiple sub-Nyquist samplers. ",
    "url": "https://arxiv.org/abs/2311.11804",
    "authors": [
      "Li Xiao",
      "Haiye Huo",
      "Xiang-Gen Xia"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2311.11871",
    "title": "Training robust and generalizable quantum models",
    "abstract": "Adversarial robustness and generalization are both crucial properties of reliable machine learning models. In this paper, we study these properties in the context of quantum machine learning based on Lipschitz bounds. We derive tailored, parameter-dependent Lipschitz bounds for quantum models with trainable encoding, showing that the norm of the data encoding has a crucial impact on the robustness against perturbations in the input data. Further, we derive a bound on the generalization error which explicitly depends on the parameters of the data encoding. Our theoretical findings give rise to a practical strategy for training robust and generalizable quantum models by regularizing the Lipschitz bound in the cost. Further, we show that, for fixed and non-trainable encodings as frequently employed in quantum machine learning, the Lipschitz bound cannot be influenced by tuning the parameters. Thus, trainable encodings are crucial for systematically adapting robustness and generalization during training. With numerical results, we demonstrate that, indeed, Lipschitz bound regularization leads to substantially more robust and generalizable quantum models. ",
    "url": "https://arxiv.org/abs/2311.11871",
    "authors": [
      "Julian Berberich",
      "Daniel Fink",
      "Daniel Pranji\u0107",
      "Christian Tutschku",
      "Christian Holm"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2311.11883",
    "title": "Efficient Neural Networks for Tiny Machine Learning: A Comprehensive  Review",
    "abstract": "The field of Tiny Machine Learning (TinyML) has gained significant attention due to its potential to enable intelligent applications on resource-constrained devices. This review provides an in-depth analysis of the advancements in efficient neural networks and the deployment of deep learning models on ultra-low power microcontrollers (MCUs) for TinyML applications. It begins by introducing neural networks and discussing their architectures and resource requirements. It then explores MEMS-based applications on ultra-low power MCUs, highlighting their potential for enabling TinyML on resource-constrained devices. The core of the review centres on efficient neural networks for TinyML. It covers techniques such as model compression, quantization, and low-rank factorization, which optimize neural network architectures for minimal resource utilization on MCUs. The paper then delves into the deployment of deep learning models on ultra-low power MCUs, addressing challenges such as limited computational capabilities and memory resources. Techniques like model pruning, hardware acceleration, and algorithm-architecture co-design are discussed as strategies to enable efficient deployment. Lastly, the review provides an overview of current limitations in the field, including the trade-off between model complexity and resource constraints. Overall, this review paper presents a comprehensive analysis of efficient neural networks and deployment strategies for TinyML on ultra-low-power MCUs. It identifies future research directions for unlocking the full potential of TinyML applications on resource-constrained devices. ",
    "url": "https://arxiv.org/abs/2311.11883",
    "authors": [
      "Minh Tri L\u00ea",
      "Pierre Wolinski",
      "Julyan Arbel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ]
  },
  {
    "id": "arXiv:2009.07448",
    "title": "Question Directed Graph Attention Network for Numerical Reasoning over  Text",
    "abstract": " Comments: Accepted at EMNLP 2020 ",
    "url": "https://arxiv.org/abs/2009.07448",
    "authors": [
      "Kunlong Chen",
      "Weidi Xu",
      "Xingyi Cheng",
      "Zou Xiaochuan",
      "Yuyu Zhang",
      "Le Song",
      "Taifeng Wang",
      "Yuan Qi",
      "Wei Chu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2011.00789",
    "title": "Role Taxonomy of Units in Deep Neural Networks",
    "abstract": " Title: Role Taxonomy of Units in Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2011.00789",
    "authors": [
      "Yang Zhao",
      "Hao Zhang",
      "Xiuyuan Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2012.02785",
    "title": "Unsupervised embedding of trajectories captures the latent structure of  scientific migration",
    "abstract": " Comments: 44 pages (main text), 102 pages total. 5 figures (main text), 32 figures in supporting information ",
    "url": "https://arxiv.org/abs/2012.02785",
    "authors": [
      "Dakota Murray",
      "Jisung Yoon",
      "Sadamori Kojaku",
      "Rodrigo Costas",
      "Woo-Sung Jung",
      "Sta\u0161a Milojevi\u0107",
      "Yong-Yeol Ahn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2104.00851",
    "title": "Estimating the Generalization in Deep Neural Networks via Sparsity",
    "abstract": " Title: Estimating the Generalization in Deep Neural Networks via Sparsity ",
    "url": "https://arxiv.org/abs/2104.00851",
    "authors": [
      "Yang Zhao",
      "Hao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2104.11122",
    "title": "From Target Tracking to Targeting Track: A Data-Driven Yet Analytical  Approach to Joint Target Detection and Tracking",
    "abstract": " Title: From Target Tracking to Targeting Track: A Data-Driven Yet Analytical  Approach to Joint Target Detection and Tracking ",
    "url": "https://arxiv.org/abs/2104.11122",
    "authors": [
      "Tiancheng Li",
      "Yan Song",
      "Hongqi Fan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2112.14265",
    "title": "Learning in Repeated Interactions on Networks",
    "abstract": " Comments: 28 pages ",
    "url": "https://arxiv.org/abs/2112.14265",
    "authors": [
      "Wanying Huang",
      "Philipp Strack",
      "Omer Tamuz"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2202.05562",
    "title": "Edge-coloured graphs with only monochromatic perfect matchings and their  connection to quantum physics",
    "abstract": " Comments: 18 pages and 7 figures ",
    "url": "https://arxiv.org/abs/2202.05562",
    "authors": [
      "L. Sunil Chandran",
      "Rishikesh Gajjala"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2204.09369",
    "title": "A Variational Autoencoder for Heterogeneous Temporal and Longitudinal  Data",
    "abstract": " Title: A Variational Autoencoder for Heterogeneous Temporal and Longitudinal  Data ",
    "url": "https://arxiv.org/abs/2204.09369",
    "authors": [
      "Mine \u00d6\u011fretir",
      "Siddharth Ramchandran",
      "Dimitrios Papatheodorou",
      "Harri L\u00e4hdesm\u00e4ki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.06661",
    "title": "FLAD: Adaptive Federated Learning for DDoS Attack Detection",
    "abstract": " Title: FLAD: Adaptive Federated Learning for DDoS Attack Detection ",
    "url": "https://arxiv.org/abs/2205.06661",
    "authors": [
      "Roberto Doriguzzi-Corin",
      "Domenico Siracusa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.02789",
    "title": "Efficient and Accurate Physics-aware Multiplex Graph Neural Networks for  3D Small Molecules and Macromolecule Complexes",
    "abstract": " Comments: An enhanced version of this preprint has been published in Scientific Reports (DOI: 10.1038/s41598-023-46382-8) ",
    "url": "https://arxiv.org/abs/2206.02789",
    "authors": [
      "Shuo Zhang",
      "Yang Liu",
      "Lei Xie"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.11303",
    "title": "Community Recovery in the Geometric Block Model",
    "abstract": " Comments: 53 pages, 18 figures. Accepted at the Journal of Machine Learning Research (JMLR). Shorter versions accepted in AAAI 2018 (see arXiv:1709.05510) and RANDOM 2019 (see arXiv:1804.05013). arXiv admin note: text overlap with arXiv:1804.05013 ",
    "url": "https://arxiv.org/abs/2206.11303",
    "authors": [
      "Sainyam Galhotra",
      "Arya Mazumdar",
      "Soumyabrata Pal",
      "Barna Saha"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Discrete Mathematics (cs.DM)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.11828",
    "title": "On the Complexity of Problems on Tree-structured Graphs",
    "abstract": " Title: On the Complexity of Problems on Tree-structured Graphs ",
    "url": "https://arxiv.org/abs/2206.11828",
    "authors": [
      "Hans L. Bodlaender",
      "Carla Groenland",
      "Hugo Jacob",
      "Marcin Pilipczuk",
      "Micha\u0142 Pilipczuk"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2208.14989",
    "title": "Learning Multiscale Non-stationary Causal Structures",
    "abstract": " Title: Learning Multiscale Non-stationary Causal Structures ",
    "url": "https://arxiv.org/abs/2208.14989",
    "authors": [
      "Gabriele D'Acunto",
      "Gianmarco De Francisci Morales",
      "Paolo Bajardi",
      "Francesco Bonchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.07067",
    "title": "Efficient learning of nonlinear prediction models with time-series  privileged information",
    "abstract": " Title: Efficient learning of nonlinear prediction models with time-series  privileged information ",
    "url": "https://arxiv.org/abs/2209.07067",
    "authors": [
      "Bastian Jung",
      "Fredrik D Johansson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.04574",
    "title": "ARUBA: An Architecture-Agnostic Balanced Loss for Aerial Object  Detection",
    "abstract": " Comments: Accepted to WACV 2023 ",
    "url": "https://arxiv.org/abs/2210.04574",
    "authors": [
      "Rebbapragada V C Sairam",
      "Monish Keswani",
      "Uttaran Sinha",
      "Nishit Shah",
      "Vineeth N Balasubramanian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11479",
    "title": "Exploitation of material consolidation trade-offs in multi-tier complex  supply networks",
    "abstract": " Comments: accepted to Supply Chain Analytics ",
    "url": "https://arxiv.org/abs/2210.11479",
    "authors": [
      "Vinod Kumar Chauhan",
      "Muhannad Alomari",
      "James Arney",
      "Ajith Kumar Parlikad",
      "Alexandra Brintrup"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2210.16028",
    "title": "Laugh Betrays You? Learning Robust Speaker Representation From Speech  Containing Non-Verbal Fragments",
    "abstract": " Comments: see 2308.07056 which is a newer version of this work ",
    "url": "https://arxiv.org/abs/2210.16028",
    "authors": [
      "Yuke Lin",
      "Xiaoyi Qin",
      "Huahua Cui",
      "Zhenyi Zhu",
      "Ming Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2211.10890",
    "title": "Single-Pass Contrastive Learning Can Work for Both Homophilic and  Heterophilic Graph",
    "abstract": " Comments: This article has been accepted for publication by the Transactions on Machine Learning Research. OpenReview at: this https URL ",
    "url": "https://arxiv.org/abs/2211.10890",
    "authors": [
      "Haonan Wang",
      "Jieyu Zhang",
      "Qi Zhu",
      "Wei Huang",
      "Kenji Kawaguchi",
      "Xiaokui Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2211.11077",
    "title": "Unifying Tracking and Image-Video Object Detection",
    "abstract": " Title: Unifying Tracking and Image-Video Object Detection ",
    "url": "https://arxiv.org/abs/2211.11077",
    "authors": [
      "Peirong Liu",
      "Rui Wang",
      "Pengchuan Zhang",
      "Omid Poursaeed",
      "Yipin Zhou",
      "Xuefei Cao",
      "Sreya Dutta Roy",
      "Ashish Shah",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2212.08966",
    "title": "Graph Learning and Its Advancements on Large Language Models: A Holistic  Survey",
    "abstract": " Comments: 24 pages, 9 figures, 4 tables ",
    "url": "https://arxiv.org/abs/2212.08966",
    "authors": [
      "Shaopeng Wei",
      "Yu Zhao",
      "Xingyan Chen",
      "Qing Li",
      "Fuzhen Zhuang",
      "Ji Liu",
      "Fuji Ren",
      "Gang Kou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2301.01333",
    "title": "oneDNN Graph Compiler: A Hybrid Approach for High-Performance Deep  Learning Compilation",
    "abstract": " Comments: 10 pages excluding reference, 9 figures, 1 table ",
    "url": "https://arxiv.org/abs/2301.01333",
    "authors": [
      "Jianhui Li",
      "Zhennan Qin",
      "Yijie Mei",
      "Jingze Cui",
      "Yunfei Song",
      "Ciyong Chen",
      "Yifei Zhang",
      "Longsheng Du",
      "Xianhang Cheng",
      "Baihui Jin",
      "Yan Zhang",
      "Igor Safonov",
      "Jason Ye",
      "Eric Lin",
      "Dan Lavery"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2301.11290",
    "title": "Graph Encoder Ensemble for Simultaneous Vertex Embedding and Community  Detection",
    "abstract": " Comments: 8 pages ",
    "url": "https://arxiv.org/abs/2301.11290",
    "authors": [
      "Cencheng Shen",
      "Youngser Park",
      "Carey E. Priebe"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2302.06494",
    "title": "Explicit3D: Graph Network with Spatial Inference for Single Image 3D  Object Detection",
    "abstract": " Title: Explicit3D: Graph Network with Spatial Inference for Single Image 3D  Object Detection ",
    "url": "https://arxiv.org/abs/2302.06494",
    "authors": [
      "Yanjun Liu",
      "Wenming Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2303.05621",
    "title": "Transformation of social relationships in COVID-19 America: Remote  communication may amplify political echo chambers",
    "abstract": " Title: Transformation of social relationships in COVID-19 America: Remote  communication may amplify political echo chambers ",
    "url": "https://arxiv.org/abs/2303.05621",
    "authors": [
      "Byungkyu Lee",
      "Kangsan Lee",
      "Benjamin Hartmann"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2303.06982",
    "title": "Analysing the Masked predictive coding training criterion for  pre-training a Speech Representation Model",
    "abstract": " Title: Analysing the Masked predictive coding training criterion for  pre-training a Speech Representation Model ",
    "url": "https://arxiv.org/abs/2303.06982",
    "authors": [
      "Hemant Yadav",
      "Sunayana Sitaram",
      "Rajiv Ratn Shah"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2304.05735",
    "title": "RO-MAP: Real-Time Multi-Object Mapping with Neural Radiance Fields",
    "abstract": " Comments: The code and dataset are available at: this https URL ",
    "url": "https://arxiv.org/abs/2304.05735",
    "authors": [
      "Xiao Han",
      "Houxuan Liu",
      "Yunchao Ding",
      "Lu Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.04022",
    "title": "Asynchronous multi-class traffic management in wide area networks",
    "abstract": " Title: Asynchronous multi-class traffic management in wide area networks ",
    "url": "https://arxiv.org/abs/2305.04022",
    "authors": [
      "Hao Wu",
      "Jian Yan",
      "Linling Kuang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2305.06657",
    "title": "On Practical Robust Reinforcement Learning: Practical Uncertainty Set  and Double-Agent Algorithm",
    "abstract": " Title: On Practical Robust Reinforcement Learning: Practical Uncertainty Set  and Double-Agent Algorithm ",
    "url": "https://arxiv.org/abs/2305.06657",
    "authors": [
      "Ukjo Hwang",
      "Songnam Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.11162",
    "title": "The Graph Database Interface: Scaling Online Transactional and  Analytical Graph Workloads to Hundreds of Thousands of Cores",
    "abstract": " Comments: Best Paper Finalist at ACM Supercomputing '23 (SC '23) ",
    "url": "https://arxiv.org/abs/2305.11162",
    "authors": [
      "Maciej Besta",
      "Robert Gerstenberger",
      "Marc Fischer",
      "Micha\u0142 Podstawski",
      "Nils Blach",
      "Berke Egeli",
      "Georgy Mitenkov",
      "Wojciech Chlapek",
      "Marek Michalewicz",
      "Hubert Niewiadomski",
      "J\u00fcrgen M\u00fcller",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2305.12457",
    "title": "Unsupervised Multi-view Pedestrian Detection",
    "abstract": " Title: Unsupervised Multi-view Pedestrian Detection ",
    "url": "https://arxiv.org/abs/2305.12457",
    "authors": [
      "Mengyin Liu",
      "Chao Zhu",
      "Shiqi Ren",
      "Xu-Cheng Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2305.13302",
    "title": "Language-Agnostic Bias Detection in Language Models with Bias Probing",
    "abstract": " Comments: EMNLP 2023 Findings ",
    "url": "https://arxiv.org/abs/2305.13302",
    "authors": [
      "Abdullatif K\u00f6ksal",
      "Omer Faruk Yalcin",
      "Ahmet Akbiyik",
      "M. Tahir Kilavuz",
      "Anna Korhonen",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.17010",
    "title": "Let the Flows Tell: Solving Graph Combinatorial Optimization Problems  with GFlowNets",
    "abstract": " Comments: Accepted by NeurIPS 2023 as spotlight ",
    "url": "https://arxiv.org/abs/2305.17010",
    "authors": [
      "Dinghuai Zhang",
      "Hanjun Dai",
      "Nikolay Malkin",
      "Aaron Courville",
      "Yoshua Bengio",
      "Ling Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.02080",
    "title": "Benchmarking Robustness of Adaptation Methods on Pre-trained  Vision-Language Models",
    "abstract": " Comments: Accepted at NeurIPS 2023 Datasets and Benchmarks Track; 9 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2306.02080",
    "authors": [
      "Shuo Chen",
      "Jindong Gu",
      "Zhen Han",
      "Yunpu Ma",
      "Philip Torr",
      "Volker Tresp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.04987",
    "title": "Convolutional Recurrent Neural Network with Attention for 3D Speech  Enhancement",
    "abstract": " Comments: Published on IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC 2023) ",
    "url": "https://arxiv.org/abs/2306.04987",
    "authors": [
      "Han Yin",
      "Jisheng Bai",
      "Mou Wang",
      "Siwei Huang",
      "Yafei Jia",
      "Jianfeng Chen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2306.05693",
    "title": "Robust Active and Passive Beamforming for RIS-Assisted Full-Duplex  Systems under Imperfect CSI",
    "abstract": " Comments: some errors found ",
    "url": "https://arxiv.org/abs/2306.05693",
    "authors": [
      "Li-Hsiang Shen",
      "Chia-Jou Ku",
      "Kai-Ten Feng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.06064",
    "title": "Neural Algorithmic Reasoning for Combinatorial Optimisation",
    "abstract": " Title: Neural Algorithmic Reasoning for Combinatorial Optimisation ",
    "url": "https://arxiv.org/abs/2306.06064",
    "authors": [
      "Dobrik Georgiev",
      "Danilo Numeroso",
      "Davide Bacciu",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.06146",
    "title": "Hidden Classification Layers: Enhancing linear separability between  classes in neural networks layers",
    "abstract": " Comments: Paper accepted on Pattern Recognition Letters journal in Open Access with doi this https URL . Please refer to the published version ",
    "url": "https://arxiv.org/abs/2306.06146",
    "authors": [
      "Andrea Apicella",
      "Francesco Isgr\u00f2",
      "Roberto Prevete"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.07613",
    "title": "Revisiting and Advancing Adversarial Training Through A Simple Baseline",
    "abstract": " Comments: 11 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2306.07613",
    "authors": [
      "Hong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.07691",
    "title": "StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion  and Adversarial Training with Large Speech Language Models",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.07691",
    "authors": [
      "Yinghao Aaron Li",
      "Cong Han",
      "Vinay S. Raghavan",
      "Gavin Mischler",
      "Nima Mesgarani"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2306.08744",
    "title": "High-performance deep spiking neural networks with 0.3 spikes per neuron",
    "abstract": " Title: High-performance deep spiking neural networks with 0.3 spikes per neuron ",
    "url": "https://arxiv.org/abs/2306.08744",
    "authors": [
      "Ana Stanojevic",
      "Stanis\u0142aw Wo\u017aniak",
      "Guillaume Bellec",
      "Giovanni Cherubini",
      "Angeliki Pantazi",
      "Wulfram Gerstner"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.10453",
    "title": "Evaluating Graph Neural Networks for Link Prediction: Current Pitfalls  and New Benchmarking",
    "abstract": " Title: Evaluating Graph Neural Networks for Link Prediction: Current Pitfalls  and New Benchmarking ",
    "url": "https://arxiv.org/abs/2306.10453",
    "authors": [
      "Juanhui Li",
      "Harry Shomer",
      "Haitao Mao",
      "Shenglai Zeng",
      "Yao Ma",
      "Neil Shah",
      "Jiliang Tang",
      "Dawei Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2306.11925",
    "title": "LVM-Med: Learning Large-Scale Self-Supervised Vision Models for Medical  Imaging via Second-order Graph Matching",
    "abstract": " Comments: Accepted at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.11925",
    "authors": [
      "Duy M. H. Nguyen",
      "Hoang Nguyen",
      "Nghiem T. Diep",
      "Tan N. Pham",
      "Tri Cao",
      "Binh T. Nguyen",
      "Paul Swoboda",
      "Nhat Ho",
      "Shadi Albarqouni",
      "Pengtao Xie",
      "Daniel Sonntag",
      "Mathias Niepert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.12045",
    "title": "Temporal Conditioning Spiking Latent Variable Models of the Neural  Response to Natural Visual Scenes",
    "abstract": " Comments: Accepted at NeurIPS 2023. 22 pages, 7 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2306.12045",
    "authors": [
      "Gehua Ma",
      "Runhao Jiang",
      "Rui Yan",
      "Huajin Tang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2306.12685",
    "title": "Rethinking the Backward Propagation for Adversarial Transferability",
    "abstract": " Comments: Accepted by NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.12685",
    "authors": [
      "Xiaosen Wang",
      "Kangheng Tong",
      "Kun He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.00583",
    "title": "A region and category confidence-based multi-task network for carotid  ultrasound image segmentation and classification",
    "abstract": " Title: A region and category confidence-based multi-task network for carotid  ultrasound image segmentation and classification ",
    "url": "https://arxiv.org/abs/2307.00583",
    "authors": [
      "Haitao Gan",
      "Ran Zhou",
      "Yanghan Ou",
      "Furong Wang",
      "Xinyao Cheng",
      "Aaron Fenster"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.02500",
    "title": "Interpretable Computer Vision Models through Adversarial Training:  Unveiling the Robustness-Interpretability Connection",
    "abstract": " Comments: 13 pages, 19 figures, 6 tables ",
    "url": "https://arxiv.org/abs/2307.02500",
    "authors": [
      "Delyan Boychev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.04962",
    "title": "Intrinsically motivated graph exploration using network theories of  human curiosity",
    "abstract": " Comments: 15 pages, 5 figures in main text, and 18 pages, 9 figures in supplement ",
    "url": "https://arxiv.org/abs/2307.04962",
    "authors": [
      "Shubhankar P. Patankar",
      "Mathieu Ouellet",
      "Juan Cervino",
      "Alejandro Ribeiro",
      "Kieran A. Murphy",
      "Dani S. Bassett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2307.15244",
    "title": "BOURNE: Bootstrapped Self-supervised Learning Framework for Unified  Graph Anomaly Detection",
    "abstract": " Title: BOURNE: Bootstrapped Self-supervised Learning Framework for Unified  Graph Anomaly Detection ",
    "url": "https://arxiv.org/abs/2307.15244",
    "authors": [
      "Jie Liu",
      "Mengting He",
      "Xuequn Shang",
      "Jieming Shi",
      "Bin Cui",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2308.05958",
    "title": "Traceability of Water Pollution: An Inversion Scheme Via Dynamic Complex  Geometrical Optics Solutions",
    "abstract": " Title: Traceability of Water Pollution: An Inversion Scheme Via Dynamic Complex  Geometrical Optics Solutions ",
    "url": "https://arxiv.org/abs/2308.05958",
    "authors": [
      "Lingyun Qiu",
      "Zhongjing Wang",
      "Hui Yu",
      "Shenwen Yu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2308.06377",
    "title": "CATS v2: Hybrid encoders for robust medical segmentation",
    "abstract": " Comments: updated acknowledgements ",
    "url": "https://arxiv.org/abs/2308.06377",
    "authors": [
      "Hao Li",
      "Han Liu",
      "Dewei Hu",
      "Xing Yao",
      "Jiacheng Wang",
      "Ipek Oguz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.09952",
    "title": "Finding emergence in data: causal emergence inspired dynamics learning",
    "abstract": " Title: Finding emergence in data: causal emergence inspired dynamics learning ",
    "url": "https://arxiv.org/abs/2308.09952",
    "authors": [
      "Mingzhe Yang",
      "Zhipeng Wang",
      "Kaiwei Liu",
      "Yingqi Rong",
      "Bing Yuan",
      "Jiang Zhang"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.13779",
    "title": "Zero-Shot Edge Detection with SCESAME: Spectral Clustering-based  Ensemble for Segment Anything Model Estimation",
    "abstract": " Comments: 11 pages, accepted to WACV 2024 Workshop ",
    "url": "https://arxiv.org/abs/2308.13779",
    "authors": [
      "Hiroaki Yamagiwa",
      "Yusuke Takase",
      "Hiroyuki Kambe",
      "Ryosuke Nakamoto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.08387",
    "title": "Efficient Graphics Representation with Differentiable Indirection",
    "abstract": " Comments: Project website: this https URL ",
    "url": "https://arxiv.org/abs/2309.08387",
    "authors": [
      "Sayantan Datta",
      "Carl Marshall",
      "Derek Nowrouzezahrai",
      "Zhao Dong",
      "Zhengqin Li"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.16661",
    "title": "SA2-Net: Scale-aware Attention Network for Microscopic Image  Segmentation",
    "abstract": " Comments: BMVC 2023 accepted as oral ",
    "url": "https://arxiv.org/abs/2309.16661",
    "authors": [
      "Mustansar Fiaz",
      "Moein Heidari",
      "Rao Muhammad Anwer",
      "Hisham Cholakkal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.17113",
    "title": "Meta-Path Learning for Multi-relational Graph Neural Networks",
    "abstract": " Title: Meta-Path Learning for Multi-relational Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2309.17113",
    "authors": [
      "Francesco Ferrini",
      "Antonio Longa",
      "Andrea Passerini",
      "Manfred Jaeger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.00238",
    "title": "Feasibility-Guaranteed Safety Critical Control with Applications to  Heterogeneous Platoons",
    "abstract": " Comments: 9 pages, 3 figures. arXiv admin note: text overlap with arXiv:2304.00372 ",
    "url": "https://arxiv.org/abs/2310.00238",
    "authors": [
      "Shuo Liu",
      "Wei Xiao",
      "Calin A. Belta"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.03358",
    "title": "Enhancing Robust Representation in Adversarial Training: Alignment and  Exclusion Criteria",
    "abstract": " Comments: 10 pages, 9 figures, Submitted to TIFS ",
    "url": "https://arxiv.org/abs/2310.03358",
    "authors": [
      "Nuoyan Zhou",
      "Nannan Wang",
      "Decheng Liu",
      "Dawei Zhou",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.04918",
    "title": "Robust Network Pruning With Sparse Entropic Wasserstein Regression",
    "abstract": " Comments: submitted to ICLR 2024 ",
    "url": "https://arxiv.org/abs/2310.04918",
    "authors": [
      "Lei You",
      "Hei Victor Cheng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.08176",
    "title": "Infinite Width Graph Neural Networks for Node Regression/ Classification",
    "abstract": " Comments: 49 Pages, 2 Figures (with subfigures), multiple tables, v2: made table of contents fit to one page and added derivatives on GAT*NTK and GAT*GP in A.4, v3: shorten parts of introduction and fixed typos, added numberings to equations and discussion section, v4: fix two missing citations on page 10 ",
    "url": "https://arxiv.org/abs/2310.08176",
    "authors": [
      "Yunus Cobanoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.08365",
    "title": "From Large Language Models to Knowledge Graphs for Biomarker Discovery  in Cancer",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2302.04737 ",
    "url": "https://arxiv.org/abs/2310.08365",
    "authors": [
      "Md. Rezaul Karim",
      "Lina Molinas Comet",
      "Md Shajalal",
      "Oya Deniz Beyan",
      "Dietrich Rebholz-Schuhmann",
      "Stefan Decker"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.10861",
    "title": "SoybeanNet: Transformer-Based Convolutional Neural Network for Soybean  Pod Counting from Unmanned Aerial Vehicle (UAV) Images",
    "abstract": " Comments: 12 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2310.10861",
    "authors": [
      "Jiajia Li",
      "Raju Thada Magar",
      "Dong Chen",
      "Feng Lin",
      "Dechun Wang",
      "Xiang Yin",
      "Weichao Zhuang",
      "Zhaojian Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.13849",
    "title": "A Dual-Stream Neural Network Explains the Functional Segregation of  Dorsal and Ventral Visual Pathways in Human Brains",
    "abstract": " Title: A Dual-Stream Neural Network Explains the Functional Segregation of  Dorsal and Ventral Visual Pathways in Human Brains ",
    "url": "https://arxiv.org/abs/2310.13849",
    "authors": [
      "Minkyu Choi",
      "Kuan Han",
      "Xiaokai Wang",
      "Yizhen Zhang",
      "Zhongming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.15516",
    "title": "Graph Attention-based Deep Reinforcement Learning for solving the  Chinese Postman Problem with Load-dependent costs",
    "abstract": " Title: Graph Attention-based Deep Reinforcement Learning for solving the  Chinese Postman Problem with Load-dependent costs ",
    "url": "https://arxiv.org/abs/2310.15516",
    "authors": [
      "Truong Son Hy",
      "Cong Dao Tran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15543",
    "title": "Symmetry-preserving graph attention network to solve routing problems at  multiple resolutions",
    "abstract": " Title: Symmetry-preserving graph attention network to solve routing problems at  multiple resolutions ",
    "url": "https://arxiv.org/abs/2310.15543",
    "authors": [
      "Cong Dao Tran",
      "Thong Bach",
      "Truong Son Hy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.15778",
    "title": "Preserving Patient Privacy in MRI Scans: A Comprehensive Approach with  3D Masked Autoencoders",
    "abstract": " Title: Preserving Patient Privacy in MRI Scans: A Comprehensive Approach with  3D Masked Autoencoders ",
    "url": "https://arxiv.org/abs/2310.15778",
    "authors": [
      "Lennart Alexander Van der Goten",
      "Kevin Smith"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.16125",
    "title": "Online Two-stage Thermal History Prediction Method for Metal Additive  Manufacturing of Thin Walls",
    "abstract": " Comments: 30 pages, 21 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2310.16125",
    "authors": [
      "Yifan Tang",
      "M. Rahmani Dehaghani",
      "Pouyan Sajadi",
      "Shahriar Bakrani Balani",
      "Akshay Dhalpe",
      "Suraj Panicker",
      "Di Wu",
      "Eric Coatanea",
      "G. Gary Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.16597",
    "title": "Beyond IID weights: sparse and low-rank deep Neural Networks are also  Gaussian Processes",
    "abstract": " Title: Beyond IID weights: sparse and low-rank deep Neural Networks are also  Gaussian Processes ",
    "url": "https://arxiv.org/abs/2310.16597",
    "authors": [
      "Thiziri Nait-Saada",
      "Alireza Naderi",
      "Jared Tanner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18936",
    "title": "Adversarial Examples Are Not Real Features",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2310.18936",
    "authors": [
      "Ang Li",
      "Yifei Wang",
      "Yiwen Guo",
      "Yisen Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.20192",
    "title": "Shaping Opinions in Social Networks with Shadow Banning",
    "abstract": " Title: Shaping Opinions in Social Networks with Shadow Banning ",
    "url": "https://arxiv.org/abs/2310.20192",
    "authors": [
      "Yen-Shao Chen",
      "Tauhid Zaman"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.01372",
    "title": "Data-Augmented and Retrieval-Augmented Context Enrichment in Chinese  Media Bias Detection",
    "abstract": " Title: Data-Augmented and Retrieval-Augmented Context Enrichment in Chinese  Media Bias Detection ",
    "url": "https://arxiv.org/abs/2311.01372",
    "authors": [
      "Luyang Lin",
      "Jing Li",
      "Kam-Fai Wong"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2311.06212",
    "title": "Differentiable VQ-VAE's for Robust White Matter Streamline Encodings",
    "abstract": " Comments: 5 pages, 4 figures, 1 table ",
    "url": "https://arxiv.org/abs/2311.06212",
    "authors": [
      "Andrew Lizarraga",
      "Brandon Taraku",
      "Edouardo Honig",
      "Ying Nian Wu",
      "Shantanu H. Joshi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2311.06310",
    "title": "$\\textit{Labor Space}$: A Unifying Representation of the Labor Market  via Large Language Models",
    "abstract": " Comments: 12 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2311.06310",
    "authors": [
      "Seongwoon Kim",
      "Yong-Yeol Ahn",
      "Jaehyuk Park"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.07127",
    "title": "Untargeted Black-box Attacks for Social Recommendations",
    "abstract": " Comments: Preprint. Under review ",
    "url": "https://arxiv.org/abs/2311.07127",
    "authors": [
      "Wenqi Fan",
      "Shijie Wang",
      "Xiao-yong Wei",
      "Xiaowei Mei",
      "Qing Li"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.07355",
    "title": "ADAMM: Anomaly Detection of Attributed Multi-graphs with Metadata: A  Unified Neural Network Approach",
    "abstract": " Comments: Accepted at IEEE BigData 2023 ",
    "url": "https://arxiv.org/abs/2311.07355",
    "authors": [
      "Konstantinos Sotiropoulos",
      "Lingxiao Zhao",
      "Pierre Jinghong Liang",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.07780",
    "title": "Parrot-Trained Adversarial Examples: Pushing the Practicality of  Black-Box Audio Attacks against Speaker Recognition Models",
    "abstract": " Title: Parrot-Trained Adversarial Examples: Pushing the Practicality of  Black-Box Audio Attacks against Speaker Recognition Models ",
    "url": "https://arxiv.org/abs/2311.07780",
    "authors": [
      "Rui Duan",
      "Zhe Qu",
      "Leah Ding",
      "Yao Liu",
      "Zhuo Lu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2311.07989",
    "title": "A Survey on Language Models for Code",
    "abstract": " Comments: Repo is available at this https URL V2 adds several new tasks, and collates dozens more benchmarks ",
    "url": "https://arxiv.org/abs/2311.07989",
    "authors": [
      "Ziyin Zhang",
      "Chaoyu Chen",
      "Bingchang Liu",
      "Cong Liao",
      "Zi Gong",
      "Hang Yu",
      "Jianguo Li",
      "Rui Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2311.08059",
    "title": "FS-Net: Full Scale Network and Adaptive Threshold for Improving  Extraction of Micro-Retinal Vessel Structures",
    "abstract": " Comments: 7 pages, 2 figures ",
    "url": "https://arxiv.org/abs/2311.08059",
    "authors": [
      "Melaku N. Getahun",
      "Oleg Y. Rogov",
      "Dmitry V. Dylov",
      "Andrey Somov",
      "Ahmed Bouridane",
      "Rifat Hamoudi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.08393",
    "title": "MVSA-Net: Multi-View State-Action Recognition for Robust and Deployable  Trajectory Generation",
    "abstract": " Comments: Accepted at the 'Towards Reliable and Deployable Learning-Based Robotic Systems' workshop, Conference on Robot Learning (CoRL) 2023 ",
    "url": "https://arxiv.org/abs/2311.08393",
    "authors": [
      "Ehsan Asali",
      "Prashant Doshi",
      "Jin Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.08427",
    "title": "Towards a Transportable Causal Network Model Based on Observational  Healthcare Data",
    "abstract": " Title: Towards a Transportable Causal Network Model Based on Observational  Healthcare Data ",
    "url": "https://arxiv.org/abs/2311.08427",
    "authors": [
      "Alice Bernasconi",
      "Alessio Zanga",
      "Peter J.F. Lucas",
      "Marco Scutari",
      "Fabio Stella"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2311.08778",
    "title": "Gitor: Scalable Code Clone Detection by Building Global Sample Graph",
    "abstract": " Comments: 12 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2311.08778",
    "authors": [
      "Junjie Shan",
      "Shihan Dou",
      "Yueming Wu",
      "Hairu Wu",
      "Yang Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2311.08835",
    "title": "Correlation-guided Query-Dependency Calibration in Video Representation  Learning for Temporal Grounding",
    "abstract": " Comments: 20 pages, 14 figures, 14 tables, Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2311.08835",
    "authors": [
      "WonJun Moon",
      "Sangeek Hyun",
      "SuBeen Lee",
      "Jae-Pil Heo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.09115",
    "title": "HEALNet -- Hybrid Multi-Modal Fusion for Heterogeneous Biomedical Data",
    "abstract": " Comments: 7 pages body, 5 pages appendix ",
    "url": "https://arxiv.org/abs/2311.09115",
    "authors": [
      "Konstantin Hemker",
      "Nikola Simidjievski",
      "Mateja Jamnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.09500",
    "title": "Pseudo-keypoint RKHS Learning for Self-supervised 6DoF Pose Estimation",
    "abstract": " Title: Pseudo-keypoint RKHS Learning for Self-supervised 6DoF Pose Estimation ",
    "url": "https://arxiv.org/abs/2311.09500",
    "authors": [
      "Yangzheng Wu",
      "Michael Greenspan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.09642",
    "title": "Weakly Supervised Anomaly Detection for Chest X-Ray Image",
    "abstract": " Title: Weakly Supervised Anomaly Detection for Chest X-Ray Image ",
    "url": "https://arxiv.org/abs/2311.09642",
    "authors": [
      "Haoqi Ni",
      "Ximiao Zhang",
      "Min Xu",
      "Ning Lang",
      "Xiuzhuang Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.09941",
    "title": "Ghost Value Augmentation for $k$-ECSS and $k$-ECSM",
    "abstract": " Title: Ghost Value Augmentation for $k$-ECSS and $k$-ECSM ",
    "url": "https://arxiv.org/abs/2311.09941",
    "authors": [
      "D Ellis Hershkowitz",
      "Nathan Klein",
      "Rico Zenklusen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2311.10542",
    "title": "A Tale of Unrealized Hope: Hardware Performance Counter Against Cache  Attacks",
    "abstract": " Comments: 26 pages, Security, Side Channel, Cache Attacks ",
    "url": "https://arxiv.org/abs/2311.10542",
    "authors": [
      "William Kosasih"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  }
]