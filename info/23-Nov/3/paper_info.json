[
  {
    "id": "arXiv:2311.00721",
    "title": "Empathy Detection Using Machine Learning on Text, Audiovisual, Audio or  Physiological Signals",
    "abstract": "Empathy is a social skill that indicates an individual's ability to understand others. Over the past few years, empathy has drawn attention from various disciplines, including but not limited to Affective Computing, Cognitive Science and Psychology. Empathy is a context-dependent term; thus, detecting or recognising empathy has potential applications in society, healthcare and education. Despite being a broad and overlapping topic, the avenue of empathy detection studies leveraging Machine Learning remains underexplored from a holistic literature perspective. To this end, we systematically collect and screen 801 papers from 10 well-known databases and analyse the selected 54 papers. We group the papers based on input modalities of empathy detection systems, i.e., text, audiovisual, audio and physiological signals. We examine modality-specific pre-processing and network architecture design protocols, popular dataset descriptions and availability details, and evaluation protocols. We further discuss the potential applications, deployment challenges and research gaps in the Affective Computing-based empathy domain, which can facilitate new avenues of exploration. We believe that our work is a stepping stone to developing a privacy-preserving and unbiased empathic system inclusive of culture, diversity and multilingualism that can be deployed in practice to enhance the overall well-being of human life. ",
    "url": "https://arxiv.org/abs/2311.00721",
    "authors": [
      "Md Rakibul Hasan",
      "Md Zakir Hossain",
      "Shreya Ghosh",
      "Susannah Soon",
      "Tom Gedeon"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.00729",
    "title": "ZEETAD: Adapting Pretrained Vision-Language Model for Zero-Shot  End-to-End Temporal Action Detection",
    "abstract": "Temporal action detection (TAD) involves the localization and classification of action instances within untrimmed videos. While standard TAD follows fully supervised learning with closed-set setting on large training data, recent zero-shot TAD methods showcase the promising of open-set setting by leveraging large-scale contrastive visual-language (ViL) pretrained models. However, existing zero-shot TAD methods have limitations on how to properly construct the strong relationships between two interdependent tasks of localization and classification and adapt ViL model to video understanding. In this work, we present ZEETAD, featuring two modules: dual-localization and zero-shot proposal classification. The former is a Transformer-based module that detects action events while selectively collecting crucial semantic embeddings for later recognition. The latter one, CLIP-based module, generates semantic embeddings from text and frame inputs for each temporal unit. Additionally, we enhance discriminative capability on unseen classes by minimally updating the frozen CLIP encoder with lightweight adapters. Extensive experiments on THUMOS14 and ActivityNet-1.3 datasets demonstrate our approach's superior performance in zero-shot TAD and effective knowledge transfer from ViL models to unseen action categories. ",
    "url": "https://arxiv.org/abs/2311.00729",
    "authors": [
      "Thinh Phan",
      "Khoa Vo",
      "Duy Le",
      "Gianfranco Doretto",
      "Donald Adjeroh",
      "Ngan Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.00735",
    "title": "PET Tracer Conversion among Brain PET via Variable Augmented Invertible  Network",
    "abstract": "Positron emission tomography (PET), as an imaging technique with high biochemical sensitivity, has been widely used in diagnosis of encephalopathy and brain science research used in brain disease diagnosis and brain science research. Since different tracers present different effects on the same focal area, the choice of tracers is getting more significant for PET imaging. Nowadays, with the wide application of PET imaging in neuropsychiatric treatment, 6-18F-fluoro-3, 4-dihydroxy-L-phenylalanine (DOPA) has been found to be more effective than 18F-labeled fluorine-2-deoxyglucose (FDG) in this field. However, due to the complexity of its preparation and other limitations, DOPA is far less widely used than FDG. To address this issue, a tracer conversion invertible neural network (TC-INN) for image projection is developed to map FDG images to DOPA images through deep learning. More diagnostic information is obtained by generating PET images from FDG to DOPA. Specifically, the proposed TC-INN consists of two separate phases, one for training the traceable data, the other for re-building the new data. The reference DOPA PET image is used as the learning target for the corresponding network during the training process of tracer conversion. Mean-while, the invertible network iteratively estimates the resultant DOPA PET data and compares it to the reference DOPA PET data. Notably, the reversible model employed variable enhancement techniques to achieve better power generation. Moreover, image registration needs to be performed before training due to the angular deviation of the acquired FDG and DOPA data information. Experimental results show generative ability in mapping be-tween FDG images and DOPA images. It demonstrates great potential for PET image conversion in the case of limited tracer applications. ",
    "url": "https://arxiv.org/abs/2311.00735",
    "authors": [
      "Bohui Shen",
      "Wei Zhang",
      "Xubiao Liu",
      "Pengfei Yu",
      "Shirui Jiang",
      "Xinchong Shi",
      "Xiangsong Zhang",
      "Xiaoyu Zhou",
      "Weirui Zhang",
      "Bingxuan Li",
      "Qiegen Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.00774",
    "title": "Conformalized Deep Splines for Optimal and Efficient Prediction Sets",
    "abstract": "Uncertainty estimation is critical in high-stakes machine learning applications. One effective way to estimate uncertainty is conformal prediction, which can provide predictive inference with statistical coverage guarantees. We present a new conformal regression method, Spline Prediction Intervals via Conformal Estimation (SPICE), that estimates the conditional density using neural-network-parameterized splines. We prove universal approximation and optimality results for SPICE, which are empirically validated by our experiments. SPICE is compatible with two different efficient-to-compute conformal scores, one oracle-optimal for marginal coverage (SPICE-ND) and the other asymptotically optimal for conditional coverage (SPICE-HPD). Results on benchmark datasets demonstrate SPICE-ND models achieve the smallest average prediction set sizes, including average size reductions of nearly 50% for some datasets compared to the next best baseline. SPICE-HPD models achieve the best conditional coverage compared to baselines. The SPICE implementation is made available. ",
    "url": "https://arxiv.org/abs/2311.00774",
    "authors": [
      "Nathaniel Diamant",
      "Ehsan Hajiramezanali",
      "Tommaso Biancalani",
      "Gabriele Scalia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.00778",
    "title": "Convergence of Heterogeneous Learning Dynamics in Zero-sum Stochastic  Games",
    "abstract": "This paper presents new families of algorithms for the repeated play of two-agent (near) zero-sum games and two-agent zero-sum stochastic games. For example, the family includes fictitious play and its variants as members. Commonly, the algorithms in this family are all uncoupled, rational, and convergent even in heterogeneous cases, e.g., where the dynamics may differ in terms of learning rates, full, none or temporal access to opponent actions, and model-based vs model-free learning. The convergence of heterogeneous dynamics is of practical interest especially in competitive environments since agents may have no means or interests in following the same dynamic with the same parameters. We prove that any mixture of such asymmetries does not impact the algorithms' convergence to equilibrium (or near equilibrium if there is experimentation) in zero-sum games with repeated play and in zero-sum (irreducible) stochastic games with sufficiently small discount factors. ",
    "url": "https://arxiv.org/abs/2311.00778",
    "authors": [
      "Yuksel Arslantas",
      "Ege Yuceel",
      "Yigit Yalin",
      "Muhammed O. Sayin"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2311.00788",
    "title": "Code Sparsification and its Applications",
    "abstract": "We introduce a notion of code sparsification that generalizes the notion of cut sparsification in graphs. For a (linear) code $\\mathcal{C} \\subseteq \\mathbb{F}_q^n$ of dimension $k$ a $(1 \\pm \\epsilon)$-sparsification of size $s$ is given by a weighted set $S \\subseteq [n]$ with $|S| \\leq s$ such that for every codeword $c \\in \\mathcal{C}$ the projection $c|_S$ of $c$ to the set $S$ has (weighted) hamming weight which is a $(1 \\pm \\epsilon)$ approximation of the hamming weight of $c$. We show that for every code there exists a $(1 \\pm \\epsilon)$-sparsification of size $s = \\widetilde{O}(k \\log (q) / \\epsilon^2)$. This immediately implies known results on graph and hypergraph cut sparsification up to polylogarithmic factors (with a simple unified proof). One application of our result is near-linear size sparsifiers for constraint satisfaction problems (CSPs) over $\\mathbb{F}_p$-valued variables whose unsatisfying assignments can be expressed as the zeros of a linear equation modulo a prime $p$. Building on this, we obtain a complete characterization of ternary Boolean CSPs that admit near-linear size sparsification. Finally, by connections between the eigenvalues of the Laplacians of Cayley graphs over $\\mathbb{F}_2^k$ to the weights of codewords, we also give the first proof of the existence of spectral Cayley graph sparsifiers over $\\mathbb{F}_2^k$ by Cayley graphs, i.e., where we sparsify the set of generators to nearly-optimal size. ",
    "url": "https://arxiv.org/abs/2311.00788",
    "authors": [
      "Sanjeev Khanna",
      "Aaron L Putterman",
      "Madhu Sudan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2311.00796",
    "title": "Automatic counting of planting microsites via local visual detection and  global count estimation",
    "abstract": "In forest industry, mechanical site preparation by mounding is widely used prior to planting operations. One of the main problems when planning planting operations is the difficulty in estimating the number of mounds present on a planting block, as their number may greatly vary depending on site characteristics. This estimation is often carried out through field surveys by several forestry workers. However, this procedure is prone to error and slowness. Motivated by recent advances in UAV imagery and artificial intelligence, we propose a fully automated framework to estimate the number of mounds on a planting block. Using computer vision and machine learning, we formulate the counting task as a supervised learning problem using two prediction models. A local detection model is firstly used to detect visible mounds based on deep features, while a global prediction function is subsequently applied to provide a final estimation based on block-level features. To evaluate the proposed method, we constructed a challenging UAV dataset representing several plantation blocks with different characteristics. The performed experiments demonstrated the robustness of the proposed method, which outperforms manual methods in precision, while significantly reducing time and cost. ",
    "url": "https://arxiv.org/abs/2311.00796",
    "authors": [
      "Ahmed Zgaren",
      "Wassim Bouachir",
      "Nizar Bouguila"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.00800",
    "title": "Beyond Still Images: Robust Multi-Stream Spatiotemporal Networks",
    "abstract": "A defining characteristic of natural vision is its ability to withstand a variety of input alterations, resulting in the creation of an invariant representation of the surroundings. While convolutional neural networks exhibit resilience to certain forms of spatial input variation, modifications in the spatial and temporal aspects can significantly affect the representations of video content in deep neural networks. Inspired by the resilience of natural vision to input variations, we employ a simple multi-stream model to explore its potential to address spatiotemporal changes by including temporal features. Our primary goal is to introduce a video-trained model and evaluate its robustness to diverse image and video inputs, with a particular focus on exploring the role of temporal features in invariant recognition. Results show that including videos and the temporal stream during training mitigates the decline in accuracy and mAP in image and video understanding tasks by 1.36% and 3.14%, respectively. ",
    "url": "https://arxiv.org/abs/2311.00800",
    "authors": [
      "AmirHosein Fadaei",
      "Mohammad-Reza A. Dehaqani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.00802",
    "title": "Neural Field Dynamics Model for Granular Object Piles Manipulation",
    "abstract": "We present a learning-based dynamics model for granular material manipulation. Inspired by the Eulerian approach commonly used in fluid dynamics, our method adopts a fully convolutional neural network that operates on a density field-based representation of object piles and pushers, allowing it to exploit the spatial locality of inter-object interactions as well as the translation equivariance through convolution operations. Furthermore, our differentiable action rendering module makes the model fully differentiable and can be directly integrated with a gradient-based trajectory optimization algorithm. We evaluate our model with a wide array of piles manipulation tasks both in simulation and real-world experiments and demonstrate that it significantly exceeds existing latent or particle-based methods in both accuracy and computation efficiency, and exhibits zero-shot generalization capabilities across various environments and tasks. ",
    "url": "https://arxiv.org/abs/2311.00802",
    "authors": [
      "Shangjie Xue",
      "Shuo Cheng",
      "Pujith Kachana",
      "Danfei Xu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.00808",
    "title": "Mahalanobis-Aware Training for Out-of-Distribution Detection",
    "abstract": "While deep learning models have seen widespread success in controlled environments, there are still barriers to their adoption in open-world settings. One critical task for safe deployment is the detection of anomalous or out-of-distribution samples that may require human intervention. In this work, we present a novel loss function and recipe for training networks with improved density-based out-of-distribution sensitivity. We demonstrate the effectiveness of our method on CIFAR-10, notably reducing the false-positive rate of the relative Mahalanobis distance method on far-OOD tasks by over 50%. ",
    "url": "https://arxiv.org/abs/2311.00808",
    "authors": [
      "Connor Mclaughlin",
      "Jason Matterer",
      "Michael Yee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.00810",
    "title": "A Call to Arms: AI Should be Critical for Social Media Analysis of  Conflict Zones",
    "abstract": "The massive proliferation of social media data represents a transformative moment in conflict studies. This data can provide unique insights into the spread and use of weaponry, but the scale and types of data are problematic for traditional open-source intelligence. This paper presents preliminary, transdisciplinary work using computer vision to identify specific weapon systems and the insignias of the armed groups using them. There is potential to not only track how weapons are distributed through networks of armed units but also to track which types of weapons are being used by the different types of state and non-state military actors in Ukraine. Such a system could ultimately be used to understand conflicts in real-time, including where humanitarian and medical aid is most needed. We believe that using AI to help automate such processes should be a high-priority goal for our community, with near-term real-world payoffs. ",
    "url": "https://arxiv.org/abs/2311.00810",
    "authors": [
      "Afia Abedin",
      "Abdul Bais",
      "Cody Buntain",
      "Laura Courchesne",
      "Brian McQuinn",
      "Matthew E. Taylor",
      "Muhib Ullah"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2311.00814",
    "title": "Investigating Self-Supervised Deep Representations for EEG-based  Auditory Attention Decoding",
    "abstract": "Auditory Attention Decoding (AAD) algorithms play a crucial role in isolating desired sound sources within challenging acoustic environments directly from brain activity. Although recent research has shown promise in AAD using shallow representations such as auditory envelope and spectrogram, there has been limited exploration of deep Self-Supervised (SS) representations on a larger scale. In this study, we undertake a comprehensive investigation into the performance of linear decoders across 12 deep and 2 shallow representations, applied to EEG data from multiple studies spanning 57 subjects and multiple languages. Our experimental results consistently reveal the superiority of deep features for AAD at decoding background speakers, regardless of the datasets and analysis windows. This result indicates possible nonlinear encoding of unattended signals in the brain that are revealed using deep nonlinear features. Additionally, we analyze the impact of different layers of SS representations and window sizes on AAD performance. These findings underscore the potential for enhancing EEG-based AAD systems through the integration of deep feature representations. ",
    "url": "https://arxiv.org/abs/2311.00814",
    "authors": [
      "Karan Thakkar",
      "Jiarui Hai",
      "Mounya Elhilali"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2311.00815",
    "title": "PIAug -- Physics Informed Augmentation for Learning Vehicle Dynamics for  Off-Road Navigation",
    "abstract": "Modeling the precise dynamics of off-road vehicles is a complex yet essential task due to the challenging terrain they encounter and the need for optimal performance and safety. Recently, there has been a focus on integrating nominal physics-based models alongside data-driven neural networks using Physics Informed Neural Networks. These approaches often assume the availability of a well-distributed dataset; however, this assumption may not hold due to regions in the physical distribution that are hard to collect, such as high-speed motions and rare terrains. Therefore, we introduce a physics-informed data augmentation methodology called PIAug. We show an example use case of the same by modeling high-speed and aggressive motion predictions, given a dataset with only low-speed data. During the training phase, we leverage the nominal model for generating target domain (medium and high velocity) data using the available source data (low velocity). Subsequently, we employ a physics-inspired loss function with this augmented dataset to incorporate prior knowledge of physics into the neural network. Our methodology results in up to 67% less mean error in trajectory prediction in comparison to a standalone nominal model, especially during aggressive maneuvers at speeds outside the training domain. In real-life navigation experiments, our model succeeds in 4x tighter waypoint tracking constraints than the Kinematic Bicycle Model (KBM) at out-of-domain velocities. ",
    "url": "https://arxiv.org/abs/2311.00815",
    "authors": [
      "Parv Maheshwari",
      "Wenshan Wang",
      "Samuel Triest",
      "Matthew Sivaprakasam",
      "Shubhra Aich",
      "John G. Rogers III",
      "Jason M. Gregory",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.00848",
    "title": "ABCD: Algorithm for Balanced Component Discovery in Signed Networks",
    "abstract": "The most significant balanced element in signed graphs plays a vital role in helping researchers understand the fundamental structure of the graph, as it reveals valuable information about the complex relationships between vertices in the network. The challenge is an NP-hard problem; there is no current baseline to evaluate state-of-the-art signed graphs derived from real networks. In this paper, we propose a scalable state-of-the-art approach for the maximum balanced sub-graph detection in the network of \\emph{any} size. However, it is still bounded by computational capability. The proposed approach builds on the graph characteristics and a scalable fundamental cycle discovery method to minimize the number of vertices discarded. We evaluate the proposed approach against state-of-the-art and demonstrate over two times higher graph size regarding the number of vertices selected of the discovered subset on an extensive signed network with millions of vertices and edges over the state-of-art in the same time frame. ",
    "url": "https://arxiv.org/abs/2311.00848",
    "authors": [
      "Muhieddine Shebaro",
      "Jelena Te\u0161i\u0107"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2311.00858",
    "title": "SmoothHess: ReLU Network Feature Interactions via Stein's Lemma",
    "abstract": "Several recent methods for interpretability model feature interactions by looking at the Hessian of a neural network. This poses a challenge for ReLU networks, which are piecewise-linear and thus have a zero Hessian almost everywhere. We propose SmoothHess, a method of estimating second-order interactions through Stein's Lemma. In particular, we estimate the Hessian of the network convolved with a Gaussian through an efficient sampling algorithm, requiring only network gradient calls. SmoothHess is applied post-hoc, requires no modifications to the ReLU network architecture, and the extent of smoothing can be controlled explicitly. We provide a non-asymptotic bound on the sample complexity of our estimation procedure. We validate the superior ability of SmoothHess to capture interactions on benchmark datasets and a real-world medical spirometry dataset. ",
    "url": "https://arxiv.org/abs/2311.00858",
    "authors": [
      "Max Torop",
      "Aria Masoomi",
      "Davin Hill",
      "Kivanc Kose",
      "Stratis Ioannidis",
      "Jennifer Dy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.00859",
    "title": "Optimal Cost Constrained Adversarial Attacks For Multiple Agent Systems",
    "abstract": "Finding optimal adversarial attack strategies is an important topic in reinforcement learning and the Markov decision process. Previous studies usually assume one all-knowing coordinator (attacker) for whom attacking different recipient (victim) agents incurs uniform costs. However, in reality, instead of using one limitless central attacker, the attacks often need to be performed by distributed attack agents. We formulate the problem of performing optimal adversarial agent-to-agent attacks using distributed attack agents, in which we impose distinct cost constraints on each different attacker-victim pair. We propose an optimal method integrating within-step static constrained attack-resource allocation optimization and between-step dynamic programming to achieve the optimal adversarial attack in a multi-agent system. Our numerical results show that the proposed attacks can significantly reduce the rewards received by the attacked agents. ",
    "url": "https://arxiv.org/abs/2311.00859",
    "authors": [
      "Ziqing Lu",
      "Guanlin Liu",
      "Lifeng Cai",
      "Weiyu Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2311.00869",
    "title": "Scaling Frustration Index and Corresponding Balanced State Discovery for  Real Signed Graphs",
    "abstract": "Structural balance modeling for signed graph networks presents how to model the sources of conflicts. The state-of-the-art has focused on computing the frustration index of a signed graph as a critical step toward solving problems in social and sensor networks and for scientific modeling. However, the proposed approaches do not scale to modern large, sparse signed networks. Also, they do not address that there is more than one way in some networks to reach a consensus with the minimum number of edge-sign switches needed. We propose an efficient balanced state discovery algorithm and a network frustration computation that will discover the nearest balanced state for the \\emph{any} size of the graph network and compute the frustration of the network. The speedup of the proposed method is around 300 times faster than the state-of-the-art for signed graphs with hundreds of thousands of edges. The technique successfully scales to find the balanced states and frustration of the networks with millions of nodes and edges in real time where state-of-the-art fails. ",
    "url": "https://arxiv.org/abs/2311.00869",
    "authors": [
      "Muhieddine Shebaro",
      "Jelena Te\u0161i\u0107"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2311.00886",
    "title": "COSTAR: Improved Temporal Counterfactual Estimation with Self-Supervised  Learning",
    "abstract": "Estimation of temporal counterfactual outcomes from observed history is crucial for decision-making in many domains such as healthcare and e-commerce, particularly when randomized controlled trials (RCTs) suffer from high cost or impracticality. For real-world datasets, modeling time-dependent confounders is challenging due to complex dynamics, long-range dependencies and both past treatments and covariates affecting the future outcomes. In this paper, we introduce COunterfactual Self-supervised TrAnsformeR (COSTAR), a novel approach that integrates self-supervised learning for improved historical representations. The proposed framework combines temporal and feature-wise attention with a component-wise contrastive loss tailored for temporal treatment outcome observations, yielding superior performance in estimation accuracy and generalization to out-of-distribution data compared to existing models, as validated by empirical results on both synthetic and real-world datasets. ",
    "url": "https://arxiv.org/abs/2311.00886",
    "authors": [
      "Chuizheng Meng",
      "Yihe Dong",
      "Sercan \u00d6. Ar\u0131k",
      "Yan Liu",
      "Tomas Pfister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.00888",
    "title": "Robust inter-patient comparison and analysis of blood vessels through  the univocal definition of point coordinates",
    "abstract": "The availability of digital twins for the cardiovascular system will enable insightful computational tools both for research and clinical practice. This, however, demands robust and well defined methods for the different steps involved in the process. We present a vessel coordinate system (VCS) that enables the unanbiguous definition of locations in a vessel section, by adapting the idea of cylindrical coordinates to the vessel geometry. Using the VCS, point correspondence can be defined among different samples of a cohort, allowing data transfer, quantitative comparison, shape coregistration or population analysis. We provide the technical details for coordinates computation and discuss the assumptions taken to guarantee that they are well defined. The VCS is tested in a series of applications. We present a robust, low dimensional, patient specific vascular model and use it to study phenotype variability analysis of the thoracic aorta within a cohort of patients. Point correspondence is exploited to build an haemodynamics atlas of the aorta for the same cohort. Across the paper, we also show how VCS can be used for visualization of different types of data on the anatomy. ",
    "url": "https://arxiv.org/abs/2311.00888",
    "authors": [
      "Pau Romero",
      "Abel Pedr\u00f3s",
      "Rafael Sebastian",
      "Miguel Lozano",
      "Ignacio Garc\u00eda-Fern\u00e1ndez"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2311.00889",
    "title": "Generate and Pray: Using SALLMS to Evaluate the Security of LLM  Generated Code",
    "abstract": "With the growing popularity of Large Language Models (e.g. GitHub Copilot, ChatGPT, etc.) in software engineers' daily practices, it is important to ensure that the code generated by these tools is not only functionally correct but also free of vulnerabilities. Although LLMs can help developers to be more productive, prior empirical studies have shown that LLMs can generate insecure code. There are two contributing factors to the insecure code generation. First, existing datasets used to evaluate Large Language Models (LLMs) do not adequately represent genuine software engineering tasks sensitive to security. Instead, they are often based on competitive programming challenges or classroom-type coding tasks. In real-world applications, the code produced is integrated into larger codebases, introducing potential security risks. There's a clear absence of benchmarks that focus on evaluating the security of the generated code. Second, existing evaluation metrics primarily focus on the functional correctness of the generated code while ignoring security considerations. Metrics such as pass@k gauge the probability of obtaining the correct code in the top k suggestions. Other popular metrics like BLEU, CodeBLEU, ROUGE, and METEOR similarly emphasize functional accuracy, neglecting security implications. In light of these research gaps, in this paper, we described SALLM, a framework to benchmark LLMs' abilities to generate secure code systematically. This framework has three major components: a novel dataset of security-centric Python prompts, an evaluation environment to test the generated code, and novel metrics to evaluate the models' performance from the perspective of secure code generation. ",
    "url": "https://arxiv.org/abs/2311.00889",
    "authors": [
      "Mohammed Latif Siddiq",
      "Joanna C. S. Santos"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.00917",
    "title": "RPCANet: Deep Unfolding RPCA Based Infrared Small Target Detection",
    "abstract": "Deep learning (DL) networks have achieved remarkable performance in infrared small target detection (ISTD). However, these structures exhibit a deficiency in interpretability and are widely regarded as black boxes, as they disregard domain knowledge in ISTD. To alleviate this issue, this work proposes an interpretable deep network for detecting infrared dim targets, dubbed RPCANet. Specifically, our approach formulates the ISTD task as sparse target extraction, low-rank background estimation, and image reconstruction in a relaxed Robust Principle Component Analysis (RPCA) model. By unfolding the iterative optimization updating steps into a deep-learning framework, time-consuming and complex matrix calculations are replaced by theory-guided neural networks. RPCANet detects targets with clear interpretability and preserves the intrinsic image feature, instead of directly transforming the detection task into a matrix decomposition problem. Extensive experiments substantiate the effectiveness of our deep unfolding framework and demonstrate its trustworthy results, surpassing baseline methods in both qualitative and quantitative evaluations. ",
    "url": "https://arxiv.org/abs/2311.00917",
    "authors": [
      "Fengyi Wu",
      "Tianfang Zhang",
      "Lei Li",
      "Yian Huang",
      "Zhenming Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.00919",
    "title": "MIST: Defending Against Membership Inference Attacks Through  Membership-Invariant Subspace Training",
    "abstract": "In Member Inference (MI) attacks, the adversary try to determine whether an instance is used to train a machine learning (ML) model. MI attacks are a major privacy concern when using private data to train ML models. Most MI attacks in the literature take advantage of the fact that ML models are trained to fit the training data well, and thus have very low loss on training instances. Most defenses against MI attacks therefore try to make the model fit the training data less well. Doing so, however, generally results in lower accuracy. We observe that training instances have different degrees of vulnerability to MI attacks. Most instances will have low loss even when not included in training. For these instances, the model can fit them well without concerns of MI attacks. An effective defense only needs to (possibly implicitly) identify instances that are vulnerable to MI attacks and avoids overfitting them. A major challenge is how to achieve such an effect in an efficient training process. Leveraging two distinct recent advancements in representation learning: counterfactually-invariant representations and subspace learning methods, we introduce a novel Membership-Invariant Subspace Training (MIST) method to defend against MI attacks. MIST avoids overfitting the vulnerable instances without significant impact on other instances. We have conducted extensive experimental studies, comparing MIST with various other state-of-the-art (SOTA) MI defenses against several SOTA MI attacks. We find that MIST outperforms other defenses while resulting in minimal reduction in testing accuracy. ",
    "url": "https://arxiv.org/abs/2311.00919",
    "authors": [
      "Jiacheng Li",
      "Ninghui Li",
      "Bruno Ribeiro"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.00922",
    "title": "Research Team Identification Based on Representation Learning of  Academic Heterogeneous Information Network",
    "abstract": "Academic networks in the real world can usually be described by heterogeneous information networks composed of multi-type nodes and relationships. Some existing research on representation learning for homogeneous information networks lacks the ability to explore heterogeneous information networks in heterogeneous information networks. It cannot be applied to heterogeneous information networks. Aiming at the practical needs of effectively identifying and discovering scientific research teams from the academic heterogeneous information network composed of massive and complex scientific and technological big data, this paper proposes a scientific research team identification method based on representation learning of academic heterogeneous information networks. The attention mechanism at node level and meta-path level learns low-dimensional, dense and real-valued vector representations on the basis of retaining the rich topological information of nodes in the network and the semantic information based on meta-paths, and realizes effective identification and discovery of scientific research teams and important team members in academic heterogeneous information networks based on maximizing node influence. Experimental results show that our proposed method outperforms the comparative methods. ",
    "url": "https://arxiv.org/abs/2311.00922",
    "authors": [
      "Junfu Wang",
      "Yawen Li",
      "Zhe Xue",
      "Ang Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2311.00923",
    "title": "A Review and Roadmap of Deep Causal Model from Different Causal  Structures and Representations",
    "abstract": "The fusion of causal models with deep learning introducing increasingly intricate data sets, such as the causal associations within images or between textual components, has surfaced as a focal research area. Nonetheless, the broadening of original causal concepts and theories to such complex, non-statistical data has been met with serious challenges. In response, our study proposes redefinitions of causal data into three distinct categories from the standpoint of causal structure and representation: definite data, semi-definite data, and indefinite data. Definite data chiefly pertains to statistical data used in conventional causal scenarios, while semi-definite data refers to a spectrum of data formats germane to deep learning, including time-series, images, text, and others. Indefinite data is an emergent research sphere inferred from the progression of data forms by us. To comprehensively present these three data paradigms, we elaborate on their formal definitions, differences manifested in datasets, resolution pathways, and development of research. We summarize key tasks and achievements pertaining to definite and semi-definite data from myriad research undertakings, present a roadmap for indefinite data, beginning with its current research conundrums. Lastly, we classify and scrutinize the key datasets presently utilized within these three paradigms. ",
    "url": "https://arxiv.org/abs/2311.00923",
    "authors": [
      "Hang Chen",
      "Keqing Du",
      "Chenguang Li",
      "Xinyu Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2311.00928",
    "title": "Quatro++: Robust Global Registration Exploiting Ground Segmentation for  Loop Closing in LiDAR SLAM",
    "abstract": "Global registration is a fundamental task that estimates the relative pose between two viewpoints of 3D point clouds. However, there are two issues that degrade the performance of global registration in LiDAR SLAM: one is the sparsity issue and the other is degeneracy. The sparsity issue is caused by the sparse characteristics of the 3D point cloud measurements in a mechanically spinning LiDAR sensor. The degeneracy issue sometimes occurs because the outlier-rejection methods reject too many correspondences, leaving less than three inliers. These two issues have become more severe as the pose discrepancy between the two viewpoints of 3D point clouds becomes greater. To tackle these problems, we propose a robust global registration framework, called \\textit{Quatro++}. Extending our previous work that solely focused on the global registration itself, we address the robust global registration in terms of the loop closing in LiDAR SLAM. To this end, ground segmentation is exploited to achieve robust global registration. Through the experiments, we demonstrate that our proposed method shows a higher success rate than the state-of-the-art global registration methods, overcoming the sparsity and degeneracy issues. In addition, we show that ground segmentation significantly helps to increase the success rate for the ground vehicles. Finally, we apply our proposed method to the loop closing module in LiDAR SLAM and confirm that the quality of the loop constraints is improved, showing more precise mapping results. Therefore, the experimental evidence corroborated the suitability of our method as an initial alignment in the loop closing. Our code is available at https://quatro-plusplus.github.io. ",
    "url": "https://arxiv.org/abs/2311.00928",
    "authors": [
      "Hyungtae Lim",
      "Beomsoo Kim",
      "Daebeom Kim",
      "Eungchang Mason Lee",
      "Hyun Myung"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.00931",
    "title": "Learning Defect Prediction from Unrealistic Data",
    "abstract": "Pretrained models of code, such as CodeBERT and CodeT5, have become popular choices for code understanding and generation tasks. Such models tend to be large and require commensurate volumes of training data, which are rarely available for downstream tasks. Instead, it has become popular to train models with far larger but less realistic datasets, such as functions with artificially injected bugs. Models trained on such data, however, tend to only perform well on similar data, while underperforming on real world programs. In this paper, we conjecture that this discrepancy stems from the presence of distracting samples that steer the model away from the real-world task distribution. To investigate this conjecture, we propose an approach for identifying the subsets of these large yet unrealistic datasets that are most similar to examples in real-world datasets based on their learned representations. Our approach extracts high-dimensional embeddings of both real-world and artificial programs using a neural model and scores artificial samples based on their distance to the nearest real-world sample. We show that training on only the nearest, representationally most similar samples while discarding samples that are not at all similar in representations yields consistent improvements across two popular pretrained models of code on two code understanding tasks. Our results are promising, in that they show that training models on a representative subset of an unrealistic dataset can help us harness the power of large-scale synthetic data generation while preserving downstream task performance. Finally, we highlight the limitations of applying AI models for predicting vulnerabilities and bugs in real-world applications ",
    "url": "https://arxiv.org/abs/2311.00931",
    "authors": [
      "Kamel Alrashedy",
      "Vincent J. Hellendoorn",
      "Alessandro Orso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.00940",
    "title": "Dynamic Uploading Scheduling in mmWave-Based Sensor Networks via Mobile  Blocker Detection",
    "abstract": "The freshness of information, measured as Age of Information (AoI), is critical for many applications in next-generation wireless sensor networks (WSNs). Due to its high bandwidth, millimeter wave (mmWave) communication is seen to be frequently exploited in WSNs to facilitate the deployment of bandwidth-demanding applications. However, the vulnerability of mmWave to user mobility typically results in link blockage and thus postponed real-time communications. In this paper, joint sampling and uploading scheduling in an AoI-oriented WSN working in mmWave band is considered, where a single human blocker is moving randomly and signal propagation paths may be blocked. The locations of signal reflectors and the real-time position of the blocker can be detected via wireless sensing technologies. With the knowledge of blocker motion pattern, the statistics of future wireless channels can be predicted. As a result, the AoI degradation arising from link blockage can be forecast and mitigated. Specifically, we formulate the long-term sampling, uplink transmission time and power allocation as an infinite-horizon Markov decision process (MDP) with discounted cost. Due to the curse of dimensionality, the optimal solution is infeasible. A novel low-complexity solution framework with guaranteed performance in the worst case is proposed where the forecast of link blockage is exploited in a value function approximation. Simulations show that compared with several heuristic benchmarks, our proposed policy, benefiting from the awareness of link blockage, can reduce average cost up to 49.6%. ",
    "url": "https://arxiv.org/abs/2311.00940",
    "authors": [
      "Yifei Sun",
      "Bojie Lv",
      "Rui Wang",
      "Haisheng Tan",
      "Francis C. M. Lau"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.00943",
    "title": "Sound Call Graph Construction for Java Object Deserialization",
    "abstract": "Object serialization and deserialization is widely used for storing and preserving objects in files, memory, or database as well as for transporting them across machines, enabling remote interaction among processes and many more. This mechanism relies on reflection, a dynamic language that introduces serious challenges for static analyses. Current state-of-the-art call graph construction algorithms does not fully support object serialization/deserialization, i.e., they are unable to uncover the callback methods that are invoked when objects are serialized and deserialized. Since call graphs are a core data structure for multiple type of analysis (e.g., vulnerability detection), an appropriate analysis cannot be performed since the call graph does not capture hidden (vulnerable) paths that occur via callback methods. In this paper, we present Seneca, an approach for handling serialization with improved soundness in the context of call graph construction. Our approach relies on taint analysis and API modeling to construct sound call graphs. We evaluated our approach with respect to soundness, precision, performance, and usefulness in detecting untrusted object deserialization vulnerabilities. Our results show that Seneca can create sound call graphs with respect to serialization features. The resulting call graphs do not incur significant overhead and were shown to be useful for performing identification of vulnerable paths caused by untrusted object deserialization. ",
    "url": "https://arxiv.org/abs/2311.00943",
    "authors": [
      "Joanna C. S. Santos",
      "Mehdi Mirakhorli",
      "Ali Shokri"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2311.00973",
    "title": "Federated Linear Bandits with Finite Adversarial Actions",
    "abstract": "We study a federated linear bandits model, where $M$ clients communicate with a central server to solve a linear contextual bandits problem with finite adversarial action sets that may be different across clients. To address the unique challenges of adversarial finite action sets, we propose the FedSupLinUCB algorithm, which extends the principles of SupLinUCB and OFUL algorithms in linear contextual bandits. We prove that FedSupLinUCB achieves a total regret of $\\tilde{O}(\\sqrt{d T})$, where $T$ is the total number of arm pulls from all clients, and $d$ is the ambient dimension of the linear model. This matches the minimax lower bound and thus is order-optimal (up to polylog terms). We study both asynchronous and synchronous cases and show that the communication cost can be controlled as $O(d M^2 \\log(d)\\log(T))$ and $O(\\sqrt{d^3 M^3} \\log(d))$, respectively. The FedSupLinUCB design is further extended to two scenarios: (1) variance-adaptive, where a total regret of $\\tilde{O} (\\sqrt{d \\sum \\nolimits_{t=1}^{T} \\sigma_t^2})$ can be achieved with $\\sigma_t^2$ being the noise variance of round $t$; and (2) adversarial corruption, where a total regret of $\\tilde{O}(\\sqrt{dT} + d C_p)$ can be achieved with $C_p$ being the total corruption budget. Experiment results corroborate the theoretical analysis and demonstrate the effectiveness of FedSupLinUCB on both synthetic and real-world datasets. ",
    "url": "https://arxiv.org/abs/2311.00973",
    "authors": [
      "Li Fan",
      "Ruida Zhou",
      "Chao Tian",
      "Cong Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.00974",
    "title": "CloudSim Express: A Novel Framework for Rapid Low Code Simulation of  Cloud Computing Environments",
    "abstract": "Cloud computing environment simulators enable cost-effective experimentation of novel infrastructure designs and management approaches by avoiding significant costs incurred from repetitive deployments in real Cloud platforms. However, widely used Cloud environment simulators compromise on usability due to complexities in design and configuration, along with the added overhead of programming language expertise. Existing approaches attempting to reduce this overhead, such as script-based simulators and Graphical User Interface (GUI) based simulators, often compromise on the extensibility of the simulator. Simulator extensibility allows for customization at a fine-grained level, thus reducing it significantly affects flexibility in creating simulations. To address these challenges, we propose an architectural framework to enable human-readable script-based simulations in existing Cloud environment simulators while minimizing the impact on simulator extensibility. We implement the proposed framework for the widely used Cloud environment simulator, the CloudSim toolkit, and compare it against state-of-the-art baselines using a practical use case. The resulting framework, called CloudSim Express, achieves extensible simulations while surpassing baselines with over a 71.43% reduction in code complexity and an 89.42% reduction in lines of code. ",
    "url": "https://arxiv.org/abs/2311.00974",
    "authors": [
      "Tharindu B. Hewage",
      "Shashikant Ilager",
      "Maria A. Rodriguez",
      "Rajkumar Buyya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.00983",
    "title": "Optimizing Inventory Routing: A Decision-Focused Learning Approach using  Neural Networks",
    "abstract": "Inventory Routing Problem (IRP) is a crucial challenge in supply chain management as it involves optimizing efficient route selection while considering the uncertainty of inventory demand planning. To solve IRPs, usually a two-stage approach is employed, where demand is predicted using machine learning techniques first, and then an optimization algorithm is used to minimize routing costs. Our experiment shows machine learning models fall short of achieving perfect accuracy because inventory levels are influenced by the dynamic business environment, which, in turn, affects the optimization problem in the next stage, resulting in sub-optimal decisions. In this paper, we formulate and propose a decision-focused learning-based approach to solving real-world IRPs. This approach directly integrates inventory prediction and routing optimization within an end-to-end system potentially ensuring a robust supply chain strategy. ",
    "url": "https://arxiv.org/abs/2311.00983",
    "authors": [
      "MD Shafikul Islam",
      "Azmine Toushik Wasi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2311.00986",
    "title": "M&M3D: Multi-Dataset Training and Efficient Network for Multi-view 3D  Object Detection",
    "abstract": "In this research, I proposed a network structure for multi-view 3D object detection using camera-only data and a Bird's-Eye-View map. My work is based on a current key challenge domain adaptation and visual data transfer. Although many excellent camera-only 3D object detection has been continuously proposed, many research work risk dramatic performance drop when the networks are trained on the source domain but tested on a different target domain. Then I found it is very surprising that predictions on bounding boxes and classes are still replied to on 2D networks. Based on the domain gap assumption on various 3D datasets, I found they still shared a similar data extraction on the same BEV map size and camera data transfer. Therefore, to analyze the domain gap influence on the current method and to make good use of 3D space information among the dataset and the real world, I proposed a transfer learning method and Transformer construction to study the 3D object detection on NuScenes-mini and Lyft. Through multi-dataset training and a detection head from the Transformer, the network demonstrated good data migration performance and efficient detection performance by using 3D anchor query and 3D positional information. Relying on only a small amount of source data and the existing large model pre-training weights, the efficient network manages to achieve competitive results on the new target domain. Moreover, my study utilizes 3D information as available semantic information and 2D multi-view image features blending into the visual-language transfer design. In the final 3D anchor box prediction and object classification, my network achieved good results on standard metrics of 3D object detection, which differs from dataset-specific models on each training domain without any fine-tuning. ",
    "url": "https://arxiv.org/abs/2311.00986",
    "authors": [
      "Hang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.00995",
    "title": "A Chronological Survey of Theoretical Advancements in Generative  Adversarial Networks for Computer Vision",
    "abstract": "Generative Adversarial Networks (GANs) have been workhorse generative models for last many years, especially in the research field of computer vision. Accordingly, there have been many significant advancements in the theory and application of GAN models, which are notoriously hard to train, but produce good results if trained well. There have been many a surveys on GANs, organizing the vast GAN literature from various focus and perspectives. However, none of the surveys brings out the important chronological aspect: how the multiple challenges of employing GAN models were solved one-by-one over time, across multiple landmark research works. This survey intends to bridge that gap and present some of the landmark research works on the theory and application of GANs, in chronological order. ",
    "url": "https://arxiv.org/abs/2311.00995",
    "authors": [
      "Hrishikesh Sharma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2311.00998",
    "title": "Replicable Benchmarking of Neural Machine Translation (NMT) on  Low-Resource Local Languages in Indonesia",
    "abstract": "Neural machine translation (NMT) for low-resource local languages in Indonesia faces significant challenges, including the need for a representative benchmark and limited data availability. This work addresses these challenges by comprehensively analyzing training NMT systems for four low-resource local languages in Indonesia: Javanese, Sundanese, Minangkabau, and Balinese. Our study encompasses various training approaches, paradigms, data sizes, and a preliminary study into using large language models for synthetic low-resource languages parallel data generation. We reveal specific trends and insights into practical strategies for low-resource language translation. Our research demonstrates that despite limited computational resources and textual data, several of our NMT systems achieve competitive performances, rivaling the translation quality of zero-shot gpt-3.5-turbo. These findings significantly advance NMT for low-resource languages, offering valuable guidance for researchers in similar contexts. ",
    "url": "https://arxiv.org/abs/2311.00998",
    "authors": [
      "Lucky Susanto",
      "Ryandito Diandaru",
      "Adila Krisnadhi",
      "Ayu Purwarianti",
      "Derry Wijaya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.01002",
    "title": "Robust Data Pruning under Label Noise via Maximizing Re-labeling  Accuracy",
    "abstract": "Data pruning, which aims to downsize a large training set into a small informative subset, is crucial for reducing the enormous computational costs of modern deep learning. Though large-scale data collections invariably contain annotation noise and numerous robust learning methods have been developed, data pruning for the noise-robust learning scenario has received little attention. With state-of-the-art Re-labeling methods that self-correct erroneous labels while training, it is challenging to identify which subset induces the most accurate re-labeling of erroneous labels in the entire training set. In this paper, we formalize the problem of data pruning with re-labeling. We first show that the likelihood of a training example being correctly re-labeled is proportional to the prediction confidence of its neighborhood in the subset. Therefore, we propose a novel data pruning algorithm, Prune4Rel, that finds a subset maximizing the total neighborhood confidence of all training examples, thereby maximizing the re-labeling accuracy and generalization performance. Extensive experiments on four real and one synthetic noisy datasets show that \\algname{} outperforms the baselines with Re-labeling models by up to 9.1% as well as those with a standard model by up to 21.6%. ",
    "url": "https://arxiv.org/abs/2311.01002",
    "authors": [
      "Dongmin Park",
      "Seola Choi",
      "Doyoung Kim",
      "Hwanjun Song",
      "Jae-Gil Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.01011",
    "title": "Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game",
    "abstract": "While Large Language Models (LLMs) are increasingly being used in real-world applications, they remain vulnerable to prompt injection attacks: malicious third party prompts that subvert the intent of the system designer. To help researchers study this problem, we present a dataset of over 126,000 prompt injection attacks and 46,000 prompt-based \"defenses\" against prompt injection, all created by players of an online game called Tensor Trust. To the best of our knowledge, this is currently the largest dataset of human-generated adversarial examples for instruction-following LLMs. The attacks in our dataset have a lot of easily interpretable stucture, and shed light on the weaknesses of LLMs. We also use the dataset to create a benchmark for resistance to two types of prompt injection, which we refer to as prompt extraction and prompt hijacking. Our benchmark results show that many models are vulnerable to the attack strategies in the Tensor Trust dataset. Furthermore, we show that some attack strategies from the dataset generalize to deployed LLM-based applications, even though they have a very different set of constraints to the game. We release all data and source code at https://tensortrust.ai/paper ",
    "url": "https://arxiv.org/abs/2311.01011",
    "authors": [
      "Sam Toyer",
      "Olivia Watkins",
      "Ethan Adrian Mendes",
      "Justin Svegliato",
      "Luke Bailey",
      "Tiffany Wang",
      "Isaac Ong",
      "Karim Elmaaroufi",
      "Pieter Abbeel",
      "Trevor Darrell",
      "Alan Ritter",
      "Stuart Russell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.01015",
    "title": "Act As You Wish: Fine-Grained Control of Motion Diffusion Model with  Hierarchical Semantic Graphs",
    "abstract": "Most text-driven human motion generation methods employ sequential modeling approaches, e.g., transformer, to extract sentence-level text representations automatically and implicitly for human motion synthesis. However, these compact text representations may overemphasize the action names at the expense of other important properties and lack fine-grained details to guide the synthesis of subtly distinct motion. In this paper, we propose hierarchical semantic graphs for fine-grained control over motion generation. Specifically, we disentangle motion descriptions into hierarchical semantic graphs including three levels of motions, actions, and specifics. Such global-to-local structures facilitate a comprehensive understanding of motion description and fine-grained control of motion generation. Correspondingly, to leverage the coarse-to-fine topology of hierarchical semantic graphs, we decompose the text-to-motion diffusion process into three semantic levels, which correspond to capturing the overall motion, local actions, and action specifics. Extensive experiments on two benchmark human motion datasets, including HumanML3D and KIT, with superior performances, justify the efficacy of our method. More encouragingly, by modifying the edge weights of hierarchical semantic graphs, our method can continuously refine the generated motion, which may have a far-reaching impact on the community. Code and pre-training weights are available at https://github.com/jpthu17/GraphMotion. ",
    "url": "https://arxiv.org/abs/2311.01015",
    "authors": [
      "Peng Jin",
      "Yang Wu",
      "Yanbo Fan",
      "Zhongqian Sun",
      "Yang Wei",
      "Li Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01022",
    "title": "NeuroWrite: Predictive Handwritten Digit Classification using Deep  Neural Networks",
    "abstract": "The rapid evolution of deep neural networks has revolutionized the field of machine learning, enabling remarkable advancements in various domains. In this article, we introduce NeuroWrite, a unique method for predicting the categorization of handwritten digits using deep neural networks. Our model exhibits outstanding accuracy in identifying and categorising handwritten digits by utilising the strength of convolutional neural networks (CNNs) and recurrent neural networks (RNNs).In this article, we give a thorough examination of the data preparation methods, network design, and training methods used in NeuroWrite. By implementing state-of-the-art techniques, we showcase how NeuroWrite can achieve high classification accuracy and robust generalization on handwritten digit datasets, such as MNIST. Furthermore, we explore the model's potential for real-world applications, including digit recognition in digitized documents, signature verification, and automated postal code recognition. NeuroWrite is a useful tool for computer vision and pattern recognition because of its performance and adaptability.The architecture, training procedure, and evaluation metrics of NeuroWrite are covered in detail in this study, illustrating how it can improve a number of applications that call for handwritten digit classification. The outcomes show that NeuroWrite is a promising method for raising the bar for deep neural network-based handwritten digit recognition. ",
    "url": "https://arxiv.org/abs/2311.01022",
    "authors": [
      "Kottakota Asish",
      "P. Sarath Teja",
      "R. Kishan Chander",
      "Dr. D. Deva Hema"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.01023",
    "title": "Augmentation is AUtO-Net: Augmentation-Driven Contrastive Multiview  Learning for Medical Image Segmentation",
    "abstract": "The utilisation of deep learning segmentation algorithms that learn complex organs and tissue patterns and extract essential regions of interest from the noisy background to improve the visual ability for medical image diagnosis has achieved impressive results in Medical Image Computing (MIC). This thesis focuses on retinal blood vessel segmentation tasks, providing an extensive literature review of deep learning-based medical image segmentation approaches while comparing the methodologies and empirical performances. The work also examines the limitations of current state-of-the-art methods by pointing out the two significant existing limitations: data size constraints and the dependency on high computational resources. To address such problems, this work proposes a novel efficient, simple multiview learning framework that contrastively learns invariant vessel feature representation by comparing with multiple augmented views by various transformations to overcome data shortage and improve generalisation ability. Moreover, the hybrid network architecture integrates the attention mechanism into a Convolutional Neural Network to further capture complex continuous curvilinear vessel structures. The result demonstrates the proposed method validated on the CHASE-DB1 dataset, attaining the highest F1 score of 83.46% and the highest Intersection over Union (IOU) score of 71.62% with UNet structure, surpassing existing benchmark UNet-based methods by 1.95% and 2.8%, respectively. The combination of the metrics indicates the model detects the vessel object accurately with a highly coincidental location with the ground truth. Moreover, the proposed approach could be trained within 30 minutes by consuming less than 3 GB GPU RAM, and such characteristics support the efficient implementation for real-world applications and deployments. ",
    "url": "https://arxiv.org/abs/2311.01023",
    "authors": [
      "Yanming Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.01024",
    "title": "Distance-Based Propagation for Efficient Knowledge Graph Reasoning",
    "abstract": "Knowledge graph completion (KGC) aims to predict unseen edges in knowledge graphs (KGs), resulting in the discovery of new facts. A new class of methods have been proposed to tackle this problem by aggregating path information. These methods have shown tremendous ability in the task of KGC. However they are plagued by efficiency issues. Though there are a few recent attempts to address this through learnable path pruning, they often sacrifice the performance to gain efficiency. In this work, we identify two intrinsic limitations of these methods that affect the efficiency and representation quality. To address the limitations, we introduce a new method, TAGNet, which is able to efficiently propagate information. This is achieved by only aggregating paths in a fixed window for each source-target pair. We demonstrate that the complexity of TAGNet is independent of the number of layers. Extensive experiments demonstrate that TAGNet can cut down on the number of propagated messages by as much as 90% while achieving competitive performance on multiple KG datasets. The code is available at https://github.com/HarryShomer/TAGNet. ",
    "url": "https://arxiv.org/abs/2311.01024",
    "authors": [
      "Harry Shomer",
      "Yao Ma",
      "Juanhui Li",
      "Bo Wu",
      "Charu C. Aggarwal",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.01025",
    "title": "Incorporating Language-Driven Appearance Knowledge Units with Visual  Cues in Pedestrian Detection",
    "abstract": "Large language models (LLMs) have shown their capability in understanding contextual and semantic information regarding appearance knowledge of instances. In this paper, we introduce a novel approach to utilize the strength of an LLM in understanding contextual appearance variations and to leverage its knowledge into a vision model (here, pedestrian detection). While pedestrian detection is considered one of crucial tasks directly related with our safety (e.g., intelligent driving system), it is challenging because of varying appearances and poses in diverse scenes. Therefore, we propose to formulate language-driven appearance knowledge units and incorporate them with visual cues in pedestrian detection. To this end, we establish description corpus which includes numerous narratives describing various appearances of pedestrians and others. By feeding them through an LLM, we extract appearance knowledge sets that contain the representations of appearance variations. After that, we perform a task-prompting process to obtain appearance knowledge units which are representative appearance knowledge guided to be relevant to a downstream pedestrian detection task. Finally, we provide plentiful appearance information by integrating the language-driven knowledge units with visual cues. Through comprehensive experiments with various pedestrian detectors, we verify the effectiveness of our method showing noticeable performance gains and achieving state-of-the-art detection performance. ",
    "url": "https://arxiv.org/abs/2311.01025",
    "authors": [
      "Sungjune Park",
      "Hyunjun Kim",
      "Yong Man Ro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01026",
    "title": "A Constant Factor Approximation for Directed Feedback Vertex Set in  Graphs of Bounded Genus",
    "abstract": "The minimum directed feedback vertex set problem consists in finding the minimum set of vertices that should be removed in order to make a directed graph acyclic. This is a well-known NP-hard optimization problem with applications in various fields, such as VLSI chip design, bioinformatics and transaction processing deadlock prevention and node-weighted network design. We show a constant factor approximation for the directed feedback vertex set problem in graphs of bounded genus. ",
    "url": "https://arxiv.org/abs/2311.01026",
    "authors": [
      "Hao Sun"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2311.01032",
    "title": "Decentralized Generalized Approximate Message-Passing for  Tree-Structured Networks",
    "abstract": "Decentralized generalized approximate message-passing (GAMP) is proposed for compressed sensing from distributed generalized linear measurements in a tree-structured network. Consensus propagation is used to realize average consensus required in GAMP via local communications between adjacent nodes. Decentralized GAMP is applicable to all tree-structured networks that do not necessarily have central nodes connected to all other nodes. State evolution is used to analyze the asymptotic dynamics of decentralized GAMP for zero-mean independent and identically distributed Gaussian sensing matrices. The state evolution recursion for decentralized GAMP is proved to have the same fixed points as that for centralized GAMP when homogeneous measurements with an identical dimension in all nodes are considered. Furthermore, existing long-memory proof strategy is used to prove that the state evolution recursion for decentralized GAMP with the Bayes-optimal denoisers converges to a fixed point. These results imply that the state evolution recursion for decentralized GAMP with the Bayes-optimal denoisers converges to the Bayes-optimal fixed point for the homogeneous measurements when the fixed point is unique. Numerical results for decentralized GAMP are presented in the cases of linear measurements and clipping. As examples of tree-structured networks, a one-dimensional chain and a tree with no central nodes are considered. ",
    "url": "https://arxiv.org/abs/2311.01032",
    "authors": [
      "Keigo Takeuchi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2311.01033",
    "title": "Non-Autoregressive Diffusion-based Temporal Point Processes for  Continuous-Time Long-Term Event Prediction",
    "abstract": "Continuous-time long-term event prediction plays an important role in many application scenarios. Most existing works rely on autoregressive frameworks to predict event sequences, which suffer from error accumulation, thus compromising prediction quality. Inspired by the success of denoising diffusion probabilistic models, we propose a diffusion-based non-autoregressive temporal point process model for long-term event prediction in continuous time. Instead of generating events one at a time in an autoregressive way, our model predicts the future event sequence entirely as a whole. In order to perform diffusion processes on event sequences, we develop a bidirectional map between target event sequences and the Euclidean vector space. Furthermore, we design a novel denoising network to capture both sequential and contextual features for better sample quality. Extensive experiments are conducted to prove the superiority of our proposed model over state-of-the-art methods on long-term event prediction in continuous time. To the best of our knowledge, this is the first work to apply diffusion methods to long-term event prediction problems. ",
    "url": "https://arxiv.org/abs/2311.01033",
    "authors": [
      "Wang-Tao Zhou",
      "Zhao Kang",
      "Ling Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.01038",
    "title": "Better with Less: A Data-Active Perspective on Pre-Training Graph Neural  Networks",
    "abstract": "Pre-training on graph neural networks (GNNs) aims to learn transferable knowledge for downstream tasks with unlabeled data, and it has recently become an active research area. The success of graph pre-training models is often attributed to the massive amount of input data. In this paper, however, we identify the curse of big data phenomenon in graph pre-training: more training data do not necessarily lead to better downstream performance. Motivated by this observation, we propose a better-with-less framework for graph pre-training: fewer, but carefully chosen data are fed into a GNN model to enhance pre-training. The proposed pre-training pipeline is called the data-active graph pre-training (APT) framework, and is composed of a graph selector and a pre-training model. The graph selector chooses the most representative and instructive data points based on the inherent properties of graphs as well as predictive uncertainty. The proposed predictive uncertainty, as feedback from the pre-training model, measures the confidence level of the model in the data. When fed with the chosen data, on the other hand, the pre-training model grasps an initial understanding of the new, unseen data, and at the same time attempts to remember the knowledge learned from previous data. Therefore, the integration and interaction between these two components form a unified framework (APT), in which graph pre-training is performed in a progressive and iterative way. Experiment results show that the proposed APT is able to obtain an efficient pre-training model with fewer training data and better downstream performance. ",
    "url": "https://arxiv.org/abs/2311.01038",
    "authors": [
      "Jiarong Xu",
      "Renhong Huang",
      "Xin Jiang",
      "Yuxuan Cao",
      "Carl Yang",
      "Chunping Wang",
      "Yang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.01047",
    "title": "Improving Robustness via Tilted Exponential Layer: A  Communication-Theoretic Perspective",
    "abstract": "State-of-the-art techniques for enhancing robustness of deep networks mostly rely on empirical risk minimization with suitable data augmentation. In this paper, we propose a complementary approach motivated by communication theory, aimed at enhancing the signal-to-noise ratio at the output of a neural network layer via neural competition during learning and inference. In addition to minimization of a standard end-to-end cost, neurons compete to sparsely represent layer inputs by maximization of a tilted exponential (TEXP) objective function for the layer. TEXP learning can be interpreted as maximum likelihood estimation of matched filters under a Gaussian model for data noise. Inference in a TEXP layer is accomplished by replacing batch norm by a tilted softmax, which can be interpreted as computation of posterior probabilities for the competing signaling hypotheses represented by each neuron. After providing insights via simplified models, we show, by experimentation on standard image datasets, that TEXP learning and inference enhances robustness against noise and other common corruptions, without requiring data augmentation. Further cumulative gains in robustness against this array of distortions can be obtained by appropriately combining TEXP with data augmentation techniques. ",
    "url": "https://arxiv.org/abs/2311.01047",
    "authors": [
      "Bhagyashree Puranik",
      "Ahmad Beirami",
      "Yao Qin",
      "Upamanyu Madhow"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.01050",
    "title": "Application and Energy-Aware Data Aggregation using Vector  Synchronization in Distributed Battery-less IoT Networks",
    "abstract": "The battery-less Internet of Things (IoT) devices are a key element in the sustainable green initiative for the next-generation wireless networks. These battery-free devices use the ambient energy, harvested from the environment. The energy harvesting environment is dynamic and causes intermittent task execution. The harvested energy is stored in small capacitors and it is challenging to assure the application task execution. The main goal is to provide a mechanism to aggregate the sensor data and provide a sustainable application support in the distributed battery-less IoT network. We model the distributed IoT network system consisting of many battery-free IoT sensor hardware modules and heterogeneous IoT applications that are being supported in the device-edge-cloud continuum. The applications require sensor data from a distributed set of battery-less hardware modules and there is provision of joint control over the module actuators. We propose an application-aware task and energy manager (ATEM) for the IoT devices and a vector-synchronization based data aggregator (VSDA). The ATEM is supported by device-level federated energy harvesting and system-level energy-aware heterogeneous application management. In our proposed framework the data aggregator forecasts the available power from the ambient energy harvester using long-short-term-memory (LSTM) model and sets the device profile as well as the application task rates accordingly. Our proposed scheme meets the heterogeneous application requirements with negligible overhead; reduces the data loss and packet delay; increases the hardware component availability; and makes the components available sooner as compared to the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2311.01050",
    "authors": [
      "Chetna Singhal",
      "Subhrajit Barick",
      "Rishabh Sonkar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01055",
    "title": "From 5G to 6G: Revolutionizing Satellite Networks through TRANTOR  Foundation",
    "abstract": "5G technology will drastically change the way satellite internet providers deliver services by offering higher data speeds, massive network capacity, reduced latency, improved reliability and increased availability. A standardised 5G ecosystem will enable adapting 5G to satellite needs. The EU-funded TRANTOR project will seek to develop novel and secure satellite network management solutions that allow scaling up heterogeneous satellite traffic demands and capacities in a cost-effective and highly dynamic way. Researchers also target the development of flexible 6G non-terrestrial access architectures. The focus will be on the design of a multi-orbit and multi-band antenna for satellite user equipment (UE), as well as the development of gNodeB (gNB) and UE 5G non-terrestrial network equipment to support multi-connectivity. ",
    "url": "https://arxiv.org/abs/2311.01055",
    "authors": [
      "Pol Henarejos",
      "Xavier Artiga",
      "Miguel A. V\u00e1zquez",
      "M\u00e0rius Caus",
      "Musbah Shaat",
      "Joan Bas",
      "Llu\u00eds Blanco",
      "Ana I. P\u00e9rez-Neira"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.01057",
    "title": "Ultra-Efficient On-Device Object Detection on AI-Integrated Smart  Glasses with TinyissimoYOLO",
    "abstract": "Smart glasses are rapidly gaining advanced functionality thanks to cutting-edge computing technologies, accelerated hardware architectures, and tiny AI algorithms. Integrating AI into smart glasses featuring a small form factor and limited battery capacity is still challenging when targeting full-day usage for a satisfactory user experience. This paper illustrates the design and implementation of tiny machine-learning algorithms exploiting novel low-power processors to enable prolonged continuous operation in smart glasses. We explore the energy- and latency-efficient of smart glasses in the case of real-time object detection. To this goal, we designed a smart glasses prototype as a research platform featuring two microcontrollers, including a novel milliwatt-power RISC-V parallel processor with a hardware accelerator for visual AI, and a Bluetooth low-power module for communication. The smart glasses integrate power cycling mechanisms, including image and audio sensing interfaces. Furthermore, we developed a family of novel tiny deep-learning models based on YOLO with sub-million parameters customized for microcontroller-based inference dubbed TinyissimoYOLO v1.3, v5, and v8, aiming at benchmarking object detection with smart glasses for energy and latency. Evaluations on the prototype of the smart glasses demonstrate TinyissimoYOLO's 17ms inference latency and 1.59mJ energy consumption per inference while ensuring acceptable detection accuracy. Further evaluation reveals an end-to-end latency from image capturing to the algorithm's prediction of 56ms or equivalently 18 fps, with a total power consumption of 62.9mW, equivalent to a 9.3 hours of continuous run time on a 154mAh battery. These results outperform MCUNet (TinyNAS+TinyEngine), which runs a simpler task (image classification) at just 7.3 fps per second. ",
    "url": "https://arxiv.org/abs/2311.01057",
    "authors": [
      "Julian Moosmann",
      "Pietro Bonazzi",
      "Yawei Li",
      "Sizhen Bian",
      "Philipp Mayer",
      "Luca Benini",
      "Michele Magno"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.01060",
    "title": "Reputation Systems for Supply Chains: The Challenge of Achieving Privacy  Preservation",
    "abstract": "Consumers frequently interact with reputation systems to rate products, services, and deliveries. While past research extensively studied different conceptual approaches to realize such systems securely and privacy-preservingly, these concepts are not yet in use in business-to-business environments. In this paper, (1) we thus outline which specific challenges privacy-cautious stakeholders in volatile supply chain networks introduce, (2) give an overview of the diverse landscape of privacy-preserving reputation systems and their properties, and (3) based on well-established concepts from supply chain information systems and cryptography, we further propose an initial concept that accounts for the aforementioned challenges by utilizing fully homomorphic encryption. For future work, we identify the need of evaluating whether novel systems address the supply chain-specific privacy and confidentiality needs. ",
    "url": "https://arxiv.org/abs/2311.01060",
    "authors": [
      "Lennart Bader",
      "Jan Pennekamp",
      "Emildeon Thevaraj",
      "Maria Spi\u00df",
      "Salil S. Kanhere",
      "Klaus Wehrle"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.01061",
    "title": "Deep Learning for real-time neural decoding of grasp",
    "abstract": "Neural decoding involves correlating signals acquired from the brain to variables in the physical world like limb movement or robot control in Brain Machine Interfaces. In this context, this work starts from a specific pre-existing dataset of neural recordings from monkey motor cortex and presents a Deep Learning-based approach to the decoding of neural signals for grasp type classification. Specifically, we propose here an approach that exploits LSTM networks to classify time series containing neural data (i.e., spike trains) into classes representing the object being grasped. The main goal of the presented approach is to improve over state-of-the-art decoding accuracy without relying on any prior neuroscience knowledge, and leveraging only the capability of deep learning models to extract correlations from data. The paper presents the results achieved for the considered dataset and compares them with previous works on the same dataset, showing a significant improvement in classification accuracy, even if considering simulated real-time decoding. ",
    "url": "https://arxiv.org/abs/2311.01061",
    "authors": [
      "Paolo Viviani",
      "Ilaria Gesmundo",
      "Elios Ghinato",
      "Andres Agudelo-Toro",
      "Chiara Vercellino",
      "Giacomo Vitali",
      "Letizia Bergamasco",
      "Alberto Scionti",
      "Marco Ghislieri",
      "Valentina Agostini",
      "Olivier Terzo",
      "Hansj\u00f6rg Scherberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2311.01073",
    "title": "Fourier Analysis of Signals on Directed Acyclic Graphs (DAG) Using Graph  Zero-Padding",
    "abstract": "Directed acyclic graphs (DAGs) are used for modeling causal relationships, dependencies, and flows in various systems. However, spectral analysis becomes impractical in this setting because the eigendecomposition of the adjacency matrix yields all eigenvalues equal to zero. This inherent property of DAGs results in an inability to differentiate between frequency components of signals on such graphs. This problem can be addressed by adding edges in DAG. However, this approach changes the physics of the considered problem. To address this limitation, we propose a graph zero-padding approach. This approach involves augmenting the original DAG with additional vertices that are connected to the existing structure. The added vertices are characterized by signal values set to zero. The proposed technique enables the spectral evaluation of system outputs on DAGs, that is the computation of vertex-domain convolution without the adverse effects of aliasing due to changes in graph structure. ",
    "url": "https://arxiv.org/abs/2311.01073",
    "authors": [
      "Ljubisa Stankovic",
      "Milos Dakovic",
      "Ali Bagheri Bardi",
      "Milos Brajovic",
      "Isidora Stankovic"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.01094",
    "title": "Max $s,t$-Flow Oracles and Negative Cycle Detection in Planar Digraphs",
    "abstract": "We study the maximum $s,t$-flow oracle problem on planar directed graphs where the goal is to design a data structure answering max $s,t$-flow value (or equivalently, min $s,t$-cut value) queries for arbitrary source-target pairs $(s,t)$. For the case of polynomially bounded integer edge capacities, we describe an exact max $s,t$-flow oracle with truly subquadratic space and preprocessing, and sublinear query time. Moreover, if $(1-\\epsilon)$-approximate answers are acceptable, we obtain a static oracle with near-linear preprocessing and $\\tilde{O}(n^{3/4})$ query time and a dynamic oracle supporting edge capacity updates and queries in $\\tilde{O}(n^{6/7})$ worst-case time. To the best of our knowledge, for directed planar graphs, no (approximate) max $s,t$-flow oracles have been described even in the unweighted case, and only trivial tradeoffs involving either no preprocessing or precomputing all the $n^2$ possible answers have been known. One key technical tool we develop on the way is a sublinear (in the number of edges) algorithm for finding a negative cycle in so-called dense distance graphs. By plugging it in earlier frameworks, we obtain improved bounds for other fundamental problems on planar digraphs. In particular, we show: (1) a deterministic $O(n\\log(nC))$ time algorithm for negatively-weighted SSSP in planar digraphs with integer edge weights at least $-C$. This improves upon the previously known bounds in the important case of weights polynomial in $n$, and (2) an improved $O(n\\log{n})$ bound on finding a perfect matching in a bipartite planar graph. ",
    "url": "https://arxiv.org/abs/2311.01094",
    "authors": [
      "Adam Karczmarz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2311.01106",
    "title": "In Defense of Softmax Parametrization for Calibrated and Consistent  Learning to Defer",
    "abstract": "Enabling machine learning classifiers to defer their decision to a downstream expert when the expert is more accurate will ensure improved safety and performance. This objective can be achieved with the learning-to-defer framework which aims to jointly learn how to classify and how to defer to the expert. In recent studies, it has been theoretically shown that popular estimators for learning to defer parameterized with softmax provide unbounded estimates for the likelihood of deferring which makes them uncalibrated. However, it remains unknown whether this is due to the widely used softmax parameterization and if we can find a softmax-based estimator that is both statistically consistent and possesses a valid probability estimator. In this work, we first show that the cause of the miscalibrated and unbounded estimator in prior literature is due to the symmetric nature of the surrogate losses used and not due to softmax. We then propose a novel statistically consistent asymmetric softmax-based surrogate loss that can produce valid estimates without the issue of unboundedness. We further analyze the non-asymptotic properties of our method and empirically validate its performance and calibration on benchmark datasets. ",
    "url": "https://arxiv.org/abs/2311.01106",
    "authors": [
      "Yuzhou Cao",
      "Hussein Mozannar",
      "Lei Feng",
      "Hongxin Wei",
      "Bo An"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01111",
    "title": "H-NeXt: The next step towards roto-translation invariant networks",
    "abstract": "The widespread popularity of equivariant networks underscores the significance of parameter efficient models and effective use of training data. At a time when robustness to unseen deformations is becoming increasingly important, we present H-NeXt, which bridges the gap between equivariance and invariance. H-NeXt is a parameter-efficient roto-translation invariant network that is trained without a single augmented image in the training set. Our network comprises three components: an equivariant backbone for learning roto-translation independent features, an invariant pooling layer for discarding roto-translation information, and a classification layer. H-NeXt outperforms the state of the art in classification on unaugmented training sets and augmented test sets of MNIST and CIFAR-10. ",
    "url": "https://arxiv.org/abs/2311.01111",
    "authors": [
      "Tomas Karella",
      "Filip Sroubek",
      "Jan Flusser",
      "Jan Blazek",
      "Vasek Kosik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01117",
    "title": "Cheating Depth: Enhancing 3D Surface Anomaly Detection via Depth  Simulation",
    "abstract": "RGB-based surface anomaly detection methods have advanced significantly. However, certain surface anomalies remain practically invisible in RGB alone, necessitating the incorporation of 3D information. Existing approaches that employ point-cloud backbones suffer from suboptimal representations and reduced applicability due to slow processing. Re-training RGB backbones, designed for faster dense input processing, on industrial depth datasets is hindered by the limited availability of sufficiently large datasets. We make several contributions to address these challenges. (i) We propose a novel Depth-Aware Discrete Autoencoder (DADA) architecture, that enables learning a general discrete latent space that jointly models RGB and 3D data for 3D surface anomaly detection. (ii) We tackle the lack of diverse industrial depth datasets by introducing a simulation process for learning informative depth features in the depth encoder. (iii) We propose a new surface anomaly detection method 3DSR, which outperforms all existing state-of-the-art on the challenging MVTec3D anomaly detection benchmark, both in terms of accuracy and processing speed. The experimental results validate the effectiveness and efficiency of our approach, highlighting the potential of utilizing depth information for improved surface anomaly detection. ",
    "url": "https://arxiv.org/abs/2311.01117",
    "authors": [
      "Vitjan Zavrtanik",
      "Matej Kristan",
      "Danijel Sko\u010daj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01125",
    "title": "Bi-Preference Learning Heterogeneous Hypergraph Networks for  Session-based Recommendation",
    "abstract": "Session-based recommendation intends to predict next purchased items based on anonymous behavior sequences. Numerous economic studies have revealed that item price is a key factor influencing user purchase decisions. Unfortunately, existing methods for session-based recommendation only aim at capturing user interest preference, while ignoring user price preference. Actually, there are primarily two challenges preventing us from accessing price preference. Firstly, the price preference is highly associated to various item features (i.e., category and brand), which asks us to mine price preference from heterogeneous information. Secondly, price preference and interest preference are interdependent and collectively determine user choice, necessitating that we jointly consider both price and interest preference for intent modeling. To handle above challenges, we propose a novel approach Bi-Preference Learning Heterogeneous Hypergraph Networks (BiPNet) for session-based recommendation. Specifically, the customized heterogeneous hypergraph networks with a triple-level convolution are devised to capture user price and interest preference from heterogeneous features of items. Besides, we develop a Bi-Preference Learning schema to explore mutual relations between price and interest preference and collectively learn these two preferences under the multi-task learning architecture. Extensive experiments on multiple public datasets confirm the superiority of BiPNet over competitive baselines. Additional research also supports the notion that the price is crucial for the task. ",
    "url": "https://arxiv.org/abs/2311.01125",
    "authors": [
      "Xiaokun Zhang",
      "Bo Xu",
      "Fenglong Ma",
      "Chenliang Li",
      "Yuan Lin",
      "Hongfei Lin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2311.01146",
    "title": "Building for Speech: Designing the Next Generation of Social Robots for  Audio Interaction",
    "abstract": "There have been incredible advancements in robotics and spoken dialogue systems (SDSs) over the past few years, yet we still don't find social robots in public spaces like train stations, shopping malls, or hospital waiting rooms. In this paper, we argue that early-stage collaboration between robot designers and SDS researchers is crucial to create social robots that can legitimately be used in real-world environments. We draw from our experiences running experiments with social robots, and the surrounding literature, to highlight recurring issues. Robots need more speakers, more microphones, quieter motors, and quieter fans to enable human-robot spoken interaction in the wild and improve accessibility. More robust robot joints are also needed to limit potential harm to older adults and other more vulnerable groups. ",
    "url": "https://arxiv.org/abs/2311.01146",
    "authors": [
      "Angus Addlesee",
      "Ioannis Papaioannou",
      "Oliver Lemon"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2311.01180",
    "title": "Automatic Configuration of Multi-Agent Model Predictive Controllers  based on Semantic Graph World Models",
    "abstract": "We propose a shared semantic map architecture to construct and configure Model Predictive Controllers (MPC) dynamically, that solve navigation problems for multiple robotic agents sharing parts of the same environment. The navigation task is represented as a sequence of semantically labeled areas in the map, that must be traversed sequentially, i.e. a route. Each semantic label represents one or more constraints on the robots' motion behaviour in that area. The advantages of this approach are: (i) an MPC-based motion controller in each individual robot can be (re-)configured, at runtime, with the locally and temporally relevant parameters; (ii) the application can influence, also at runtime, the navigation behaviour of the robots, just by adapting the semantic labels; and (iii) the robots can reason about their need for coordination, through analyzing over which horizon in time and space their routes overlap. The paper provides simulations of various representative situations, showing that the approach of runtime configuration of the MPC drastically decreases computation time, while retaining task execution performance similar to an approach in which each robot always includes all other robots in its MPC computations. ",
    "url": "https://arxiv.org/abs/2311.01180",
    "authors": [
      "K. de Vos",
      "E. Torta",
      "H. Bruyninckx",
      "C.A. Lopez Martinez",
      "M.J.G. van de Molengraft"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.01188",
    "title": "Terrain-Informed Self-Supervised Learning: Enhancing Building Footprint  Extraction from LiDAR Data with Limited Annotations",
    "abstract": "Estimating building footprint maps from geospatial data is of paramount importance in urban planning, development, disaster management, and various other applications. Deep learning methodologies have gained prominence in building segmentation maps, offering the promise of precise footprint extraction without extensive post-processing. However, these methods face challenges in generalization and label efficiency, particularly in remote sensing, where obtaining accurate labels can be both expensive and time-consuming. To address these challenges, we propose terrain-aware self-supervised learning, tailored to remote sensing, using digital elevation models from LiDAR data. We propose to learn a model to differentiate between bare Earth and superimposed structures enabling the network to implicitly learn domain-relevant features without the need for extensive pixel-level annotations. We test the effectiveness of our approach by evaluating building segmentation performance on test datasets with varying label fractions. Remarkably, with only 1% of the labels (equivalent to 25 labeled examples), our method improves over ImageNet pre-training, showing the advantage of leveraging unlabeled data for feature extraction in the domain of remote sensing. The performance improvement is more pronounced in few-shot scenarios and gradually closes the gap with ImageNet pre-training as the label fraction increases. We test on a dataset characterized by substantial distribution shifts and labeling errors to demonstrate the generalizability of our approach. When compared to other baselines, including ImageNet pretraining and more complex architectures, our approach consistently performs better, demonstrating the efficiency and effectiveness of self-supervised terrain-aware feature learning. ",
    "url": "https://arxiv.org/abs/2311.01188",
    "authors": [
      "Anuja Vats",
      "David V\u00f6lgyes",
      "Martijn Vermeer",
      "Marius Pedersen",
      "Kiran Raja",
      "Daniele S.M.Fantin",
      "Jacob Alexander Hay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01191",
    "title": "VIGraph: Self-supervised Learning for Class-Imbalanced Node  Classification",
    "abstract": "Class imbalance in graph data poses significant challenges for node classification. Existing methods, represented by SMOTE-based approaches, partially alleviate this issue but still exhibit limitations during imbalanced scenario construction. Self-supervised learning (SSL) offers a promising solution by synthesizing minority nodes from the data itself, yet its potential remains unexplored. In this paper, we analyze the limitations of SMOTE-based approaches and introduce VIGraph, a novel SSL model based on the self-supervised Variational Graph Auto-Encoder (VGAE) that leverages Variational Inference (VI) to generate minority nodes. Specifically, VIGraph strictly adheres to the concept of imbalance when constructing imbalanced graphs and utilizes the generative VGAE to generate minority nodes. Moreover, VIGraph introduces a novel Siamese contrastive strategy at the decoding phase to improve the overall quality of generated nodes. VIGraph can generate high-quality nodes without reintegrating them into the original graph, eliminating the \"Generating, Reintegrating, and Retraining\" process found in SMOTE-based methods. Experiments on multiple real-world datasets demonstrate that VIGraph achieves promising results for class-imbalanced node classification tasks. ",
    "url": "https://arxiv.org/abs/2311.01191",
    "authors": [
      "Yulan Hu",
      "Sheng Ouyang",
      "Zhirui Yang",
      "Yong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.01192",
    "title": "Semantic Scene Graph Generation Based on an Edge Dual Scene Graph and  Message Passing Neural Network",
    "abstract": "Along with generative AI, interest in scene graph generation (SGG), which comprehensively captures the relationships and interactions between objects in an image and creates a structured graph-based representation, has significantly increased in recent years. However, relying on object-centric and dichotomous relationships, existing SGG methods have a limited ability to accurately predict detailed relationships. To solve these problems, a new approach to the modeling multiobject relationships, called edge dual scene graph generation (EdgeSGG), is proposed herein. EdgeSGG is based on a edge dual scene graph and Dual Message Passing Neural Network (DualMPNN), which can capture rich contextual interactions between unconstrained objects. To facilitate the learning of edge dual scene graphs with a symmetric graph structure, the proposed DualMPNN learns both object- and relation-centric features for more accurately predicting relation-aware contexts and allows fine-grained relational updates between objects. A comparative experiment with state-of-the-art (SoTA) methods was conducted using two public datasets for SGG operations and six metrics for three subtasks. Compared with SoTA approaches, the proposed model exhibited substantial performance improvements across all SGG subtasks. Furthermore, experiment on long-tail distributions revealed that incorporating the relationships between objects effectively mitigates existing long-tail problems. ",
    "url": "https://arxiv.org/abs/2311.01192",
    "authors": [
      "Hyeongjin Kim",
      "Sangwon Kim",
      "Jong Taek Lee",
      "Byoung Chul Ko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01196",
    "title": "Combating Bilateral Edge Noise for Robust Link Prediction",
    "abstract": "Although link prediction on graphs has achieved great success with the development of graph neural networks (GNNs), the potential robustness under the edge noise is still less investigated. To close this gap, we first conduct an empirical study to disclose that the edge noise bilaterally perturbs both input topology and target label, yielding severe performance degradation and representation collapse. To address this dilemma, we propose an information-theory-guided principle, Robust Graph Information Bottleneck (RGIB), to extract reliable supervision signals and avoid representation collapse. Different from the basic information bottleneck, RGIB further decouples and balances the mutual dependence among graph topology, target labels, and representation, building new learning objectives for robust representation against the bilateral noise. Two instantiations, RGIB-SSL and RGIB-REP, are explored to leverage the merits of different methodologies, i.e., self-supervised learning and data reparameterization, for implicit and explicit data denoising, respectively. Extensive experiments on six datasets and three GNNs with diverse noisy scenarios verify the effectiveness of our RGIB instantiations. The code is publicly available at: https://github.com/tmlr-group/RGIB. ",
    "url": "https://arxiv.org/abs/2311.01196",
    "authors": [
      "Zhanke Zhou",
      "Jiangchao Yao",
      "Jiaxu Liu",
      "Xiawei Guo",
      "Quanming Yao",
      "Li He",
      "Liang Wang",
      "Bo Zheng",
      "Bo Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.01197",
    "title": "AiluRus: A Scalable ViT Framework for Dense Prediction",
    "abstract": "Vision transformers (ViTs) have emerged as a prevalent architecture for vision tasks owing to their impressive performance. However, when it comes to handling long token sequences, especially in dense prediction tasks that require high-resolution input, the complexity of ViTs increases significantly. Notably, dense prediction tasks, such as semantic segmentation or object detection, emphasize more on the contours or shapes of objects, while the texture inside objects is less informative. Motivated by this observation, we propose to apply adaptive resolution for different regions in the image according to their importance. Specifically, at the intermediate layer of the ViT, we utilize a spatial-aware density-based clustering algorithm to select representative tokens from the token sequence. Once the representative tokens are determined, we proceed to merge other tokens into their closest representative token. Consequently, semantic similar tokens are merged together to form low-resolution regions, while semantic irrelevant tokens are preserved independently as high-resolution regions. This strategy effectively reduces the number of tokens, allowing subsequent layers to handle a reduced token sequence and achieve acceleration. We evaluate our proposed method on three different datasets and observe promising performance. For example, the \"Segmenter ViT-L\" model can be accelerated by 48% FPS without fine-tuning, while maintaining the performance. Additionally, our method can be applied to accelerate fine-tuning as well. Experimental results demonstrate that we can save 52% training time while accelerating 2.46 times FPS with only a 0.09% performance drop. The code is available at https://github.com/caddyless/ailurus/tree/main. ",
    "url": "https://arxiv.org/abs/2311.01197",
    "authors": [
      "Jin Li",
      "Yaoming Wang",
      "Xiaopeng Zhang",
      "Bowen Shi",
      "Dongsheng Jiang",
      "Chenglin Li",
      "Wenrui Dai",
      "Hongkai Xiong",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.01202",
    "title": "Cross-Modal Information-Guided Network using Contrastive Learning for  Point Cloud Registration",
    "abstract": "The majority of point cloud registration methods currently rely on extracting features from points. However, these methods are limited by their dependence on information obtained from a single modality of points, which can result in deficiencies such as inadequate perception of global features and a lack of texture information. Actually, humans can employ visual information learned from 2D images to comprehend the 3D world. Based on this fact, we present a novel Cross-Modal Information-Guided Network (CMIGNet), which obtains global shape perception through cross-modal information to achieve precise and robust point cloud registration. Specifically, we first incorporate the projected images from the point clouds and fuse the cross-modal features using the attention mechanism. Furthermore, we employ two contrastive learning strategies, namely overlapping contrastive learning and cross-modal contrastive learning. The former focuses on features in overlapping regions, while the latter emphasizes the correspondences between 2D and 3D features. Finally, we propose a mask prediction module to identify keypoints in the point clouds. Extensive experiments on several benchmark datasets demonstrate that our network achieves superior registration performance. ",
    "url": "https://arxiv.org/abs/2311.01202",
    "authors": [
      "Yifan Xie",
      "Jihua Zhu",
      "Shiqi Li",
      "Pengcheng Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.01205",
    "title": "Attacking Graph Neural Networks with Bit Flips: Weisfeiler and Lehman Go  Indifferent",
    "abstract": "Prior attacks on graph neural networks have mostly focused on graph poisoning and evasion, neglecting the network's weights and biases. Traditional weight-based fault injection attacks, such as bit flip attacks used for convolutional neural networks, do not consider the unique properties of graph neural networks. We propose the Injectivity Bit Flip Attack, the first bit flip attack designed specifically for graph neural networks. Our attack targets the learnable neighborhood aggregation functions in quantized message passing neural networks, degrading their ability to distinguish graph structures and losing the expressivity of the Weisfeiler-Lehman test. Our findings suggest that exploiting mathematical properties specific to certain graph neural network architectures can significantly increase their vulnerability to bit flip attacks. Injectivity Bit Flip Attacks can degrade the maximal expressive Graph Isomorphism Networks trained on various graph property prediction datasets to random output by flipping only a small fraction of the network's bits, demonstrating its higher destructive power compared to a bit flip attack transferred from convolutional neural networks. Our attack is transparent and motivated by theoretical insights which are confirmed by extensive empirical results. ",
    "url": "https://arxiv.org/abs/2311.01205",
    "authors": [
      "Lorenz Kummer",
      "Samir Moustafa",
      "Nils N. Kriege",
      "Wilfried N. Gansterer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.01227",
    "title": "Robust Feature Learning and Global Variance-Driven Classifier Alignment  for Long-Tail Class Incremental Learning",
    "abstract": "This paper introduces a two-stage framework designed to enhance long-tail class incremental learning, enabling the model to progressively learn new classes, while mitigating catastrophic forgetting in the context of long-tailed data distributions. Addressing the challenge posed by the under-representation of tail classes in long-tail class incremental learning, our approach achieves classifier alignment by leveraging global variance as an informative measure and class prototypes in the second stage. This process effectively captures class properties and eliminates the need for data balancing or additional layer tuning. Alongside traditional class incremental learning losses in the first stage, the proposed approach incorporates mixup classes to learn robust feature representations, ensuring smoother boundaries. The proposed framework can seamlessly integrate as a module with any class incremental learning method to effectively handle long-tail class incremental learning scenarios. Extensive experimentation on the CIFAR-100 and ImageNet-Subset datasets validates the approach's efficacy, showcasing its superiority over state-of-the-art techniques across various long-tail CIL settings. ",
    "url": "https://arxiv.org/abs/2311.01227",
    "authors": [
      "Jayateja Kalla",
      "Soma Biswas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01235",
    "title": "Navigating Complex Search Tasks with AI Copilots",
    "abstract": "As many of us in the information retrieval (IR) research community know and appreciate, search is far from being a solved problem. Millions of people struggle with tasks on search engines every day. Often, their struggles relate to the intrinsic complexity of their task and the failure of search systems to fully understand the task and serve relevant results. The task motivates the search, creating the gap/problematic situation that searchers attempt to bridge/resolve and drives search behavior as they work through different task facets. Complex search tasks require more than support for rudimentary fact finding or re-finding. Research on methods to support complex tasks includes work on generating query and website suggestions, personalizing and contextualizing search, and developing new search experiences, including those that span time and space. The recent emergence of generative artificial intelligence (AI) and the arrival of assistive agents, or copilots, based on this technology, has the potential to offer further assistance to searchers, especially those engaged in complex tasks. There are profound implications from these advances for the design of intelligent systems and for the future of search itself. This article, based on a keynote by the author at the 2023 ACM SIGIR Conference, explores these issues and charts a course toward new horizons in information access guided by AI copilots. ",
    "url": "https://arxiv.org/abs/2311.01235",
    "authors": [
      "Ryen W. White"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.01245",
    "title": "Robustness for Free: Quality-Diversity Driven Discovery of Agile Soft  Robotic Gaits",
    "abstract": "Soft robotics aims to develop robots able to adapt their behavior across a wide range of unstructured and unknown environments. A critical challenge of soft robotic control is that nonlinear dynamics often result in complex behaviors hard to model and predict. Typically behaviors for mobile soft robots are discovered through empirical trial and error and hand-tuning. More recently, optimization algorithms such as Genetic Algorithms (GA) have been used to discover gaits, but these behaviors are often optimized for a single environment or terrain, and can be brittle to unplanned changes to terrain. In this paper we demonstrate how Quality Diversity Algorithms, which search of a range of high-performing behaviors, can produce repertoires of gaits that are robust to changing terrains. This robustness significantly out-performs that of gaits produced by a single objective optimization algorithm. ",
    "url": "https://arxiv.org/abs/2311.01245",
    "authors": [
      "John Daly",
      "Daniel Casper",
      "Muhammad Farooq",
      "Andrew James",
      "Ali Khan",
      "Phoenix Mulgrew",
      "Daniel Tyebkhan",
      "Bao Vo",
      "John Rieffel"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2311.01263",
    "title": "Efficient Neural Ranking using Forward Indexes and Lightweight Encoders",
    "abstract": "Dual-encoder-based dense retrieval models have become the standard in IR. They employ large Transformer-based language models, which are notoriously inefficient in terms of resources and latency. We propose Fast-Forward indexes -- vector forward indexes which exploit the semantic matching capabilities of dual-encoder models for efficient and effective re-ranking. Our framework enables re-ranking at very high retrieval depths and combines the merits of both lexical and semantic matching via score interpolation. Furthermore, in order to mitigate the limitations of dual-encoders, we tackle two main challenges: Firstly, we improve computational efficiency by either pre-computing representations, avoiding unnecessary computations altogether, or reducing the complexity of encoders. This allows us to considerably improve ranking efficiency and latency. Secondly, we optimize the memory footprint and maintenance cost of indexes; we propose two complementary techniques to reduce the index size and show that, by dynamically dropping irrelevant document tokens, the index maintenance efficiency can be improved substantially. We perform evaluation to show the effectiveness and efficiency of Fast-Forward indexes -- our method has low latency and achieves competitive results without the need for hardware acceleration, such as GPUs. ",
    "url": "https://arxiv.org/abs/2311.01263",
    "authors": [
      "Jurek Leonhardt",
      "Henrik M\u00fcller",
      "Koustav Rudra",
      "Megha Khosla",
      "Abhijit Anand",
      "Avishek Anand"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2311.01270",
    "title": "People Make Better Edits: Measuring the Efficacy of LLM-Generated  Counterfactually Augmented Data for Harmful Language Detection",
    "abstract": "NLP models are used in a variety of critical social computing tasks, such as detecting sexist, racist, or otherwise hateful content. Therefore, it is imperative that these models are robust to spurious features. Past work has attempted to tackle such spurious features using training data augmentation, including Counterfactually Augmented Data (CADs). CADs introduce minimal changes to existing training data points and flip their labels; training on them may reduce model dependency on spurious features. However, manually generating CADs can be time-consuming and expensive. Hence in this work, we assess if this task can be automated using generative NLP models. We automatically generate CADs using Polyjuice, ChatGPT, and Flan-T5, and evaluate their usefulness in improving model robustness compared to manually-generated CADs. By testing both model performance on multiple out-of-domain test sets and individual data point efficacy, our results show that while manual CADs are still the most effective, CADs generated by ChatGPT come a close second. One key reason for the lower performance of automated methods is that the changes they introduce are often insufficient to flip the original label. ",
    "url": "https://arxiv.org/abs/2311.01270",
    "authors": [
      "Indira Sen",
      "Dennis Assenmacher",
      "Mattia Samory",
      "Isabelle Augenstein",
      "Wil van der Aalst",
      "Claudia Wagne"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2311.01276",
    "title": "Long-Range Neural Atom Learning for Molecular Graphs",
    "abstract": "Graph Neural Networks (GNNs) have been widely adopted for drug discovery with molecular graphs. Nevertheless, current GNNs are mainly good at leveraging short-range interactions (SRI) but struggle to capture long-range interactions (LRI), both of which are crucial for determining molecular properties. To tackle this issue, we propose a method that implicitly projects all original atoms into a few Neural Atoms, which abstracts the collective information of atomic groups within a molecule. Specifically, we explicitly exchange the information among neural atoms and project them back to the atoms' representations as an enhancement. With this mechanism, neural atoms establish the communication channels among distant nodes, effectively reducing the interaction scope of arbitrary node pairs into a single hop. To provide an inspection of our method from a physical perspective, we reveal its connection with the traditional LRI calculation method, Ewald Summation. We conduct extensive experiments on three long-range graph benchmarks, covering both graph-level and link-level tasks on molecular graphs. We empirically justify that our method can be equipped with an arbitrary GNN and help to capture LRI. ",
    "url": "https://arxiv.org/abs/2311.01276",
    "authors": [
      "Xuan Li",
      "Zhanke Zhou",
      "Jiangchao Yao",
      "Yu Rong",
      "Lu Zhang",
      "Bo Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2311.01295",
    "title": "DP-Mix: Mixup-based Data Augmentation for Differentially Private  Learning",
    "abstract": "Data augmentation techniques, such as simple image transformations and combinations, are highly effective at improving the generalization of computer vision models, especially when training data is limited. However, such techniques are fundamentally incompatible with differentially private learning approaches, due to the latter's built-in assumption that each training image's contribution to the learned model is bounded. In this paper, we investigate why naive applications of multi-sample data augmentation techniques, such as mixup, fail to achieve good performance and propose two novel data augmentation techniques specifically designed for the constraints of differentially private learning. Our first technique, DP-Mix_Self, achieves SoTA classification performance across a range of datasets and settings by performing mixup on self-augmented data. Our second technique, DP-Mix_Diff, further improves performance by incorporating synthetic data from a pre-trained diffusion model into the mixup process. We open-source the code at https://github.com/wenxuan-Bao/DP-Mix. ",
    "url": "https://arxiv.org/abs/2311.01295",
    "authors": [
      "Wenxuan Bao",
      "Francesco Pittaluga",
      "Vijay Kumar B G",
      "Vincent Bindschaedler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01301",
    "title": "TRIALSCOPE A Unifying Causal Framework for Scaling Real-World Evidence  Generation with Biomedical Language Models",
    "abstract": "The rapid digitization of real-world data offers an unprecedented opportunity for optimizing healthcare delivery and accelerating biomedical discovery. In practice, however, such data is most abundantly available in unstructured forms, such as clinical notes in electronic medical records (EMRs), and it is generally plagued by confounders. In this paper, we present TRIALSCOPE, a unifying framework for distilling real-world evidence from population-level observational data. TRIALSCOPE leverages biomedical language models to structure clinical text at scale, employs advanced probabilistic modeling for denoising and imputation, and incorporates state-of-the-art causal inference techniques to combat common confounders. Using clinical trial specification as generic representation, TRIALSCOPE provides a turn-key solution to generate and reason with clinical hypotheses using observational data. In extensive experiments and analyses on a large-scale real-world dataset with over one million cancer patients from a large US healthcare network, we show that TRIALSCOPE can produce high-quality structuring of real-world data and generates comparable results to marquee cancer trials. In addition to facilitating in-silicon clinical trial design and optimization, TRIALSCOPE may be used to empower synthetic controls, pragmatic trials, post-market surveillance, as well as support fine-grained patient-like-me reasoning in precision diagnosis and treatment. ",
    "url": "https://arxiv.org/abs/2311.01301",
    "authors": [
      "Javier Gonz\u00e1lez",
      "Cliff Wong",
      "Zelalem Gero",
      "Jass Bagga",
      "Risa Ueno",
      "Isabel Chien",
      "Eduard Orakvin",
      "Emre Kiciman",
      "Aditya Nori",
      "Roshanthi Weerasinghe",
      "Rom S. Leidner",
      "Brian Piening",
      "Tristan Naumann",
      "Carlo Bifulco",
      "Hoifung Poon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2311.01307",
    "title": "The Effect of Scaling, Retrieval Augmentation and Form on the Factual  Consistency of Language Models",
    "abstract": "Large Language Models (LLMs) make natural interfaces to factual knowledge, but their usefulness is limited by their tendency to deliver inconsistent answers to semantically equivalent questions. For example, a model might predict both \"Anne Redpath passed away in Edinburgh.\" and \"Anne Redpath's life ended in London.\" In this work, we identify potential causes of inconsistency and evaluate the effectiveness of two mitigation strategies: up-scaling and augmenting the LM with a retrieval corpus. Our results on the LLaMA and Atlas models show that both strategies reduce inconsistency while retrieval augmentation is considerably more efficient. We further consider and disentangle the consistency contributions of different components of Atlas. For all LMs evaluated we find that syntactical form and other evaluation task artifacts impact consistency. Taken together, our results provide a better understanding of the factors affecting the factual consistency of language models. ",
    "url": "https://arxiv.org/abs/2311.01307",
    "authors": [
      "Lovisa Hagstr\u00f6m",
      "Denitsa Saynova",
      "Tobias Norlund",
      "Moa Johansson",
      "Richard Johansson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.01323",
    "title": "Towards Evaluating Transfer-based Attacks Systematically, Practically,  and Fairly",
    "abstract": "The adversarial vulnerability of deep neural networks (DNNs) has drawn great attention due to the security risk of applying these models in real-world applications. Based on transferability of adversarial examples, an increasing number of transfer-based methods have been developed to fool black-box DNN models whose architecture and parameters are inaccessible. Although tremendous effort has been exerted, there still lacks a standardized benchmark that could be taken advantage of to compare these methods systematically, fairly, and practically. Our investigation shows that the evaluation of some methods needs to be more reasonable and more thorough to verify their effectiveness, to avoid, for example, unfair comparison and insufficient consideration of possible substitute/victim models. Therefore, we establish a transfer-based attack benchmark (TA-Bench) which implements 30+ methods. In this paper, we evaluate and compare them comprehensively on 25 popular substitute/victim models on ImageNet. New insights about the effectiveness of these methods are gained and guidelines for future evaluations are provided. Code at: https://github.com/qizhangli/TA-Bench. ",
    "url": "https://arxiv.org/abs/2311.01323",
    "authors": [
      "Qizhang Li",
      "Yiwen Guo",
      "Wangmeng Zuo",
      "Hao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01326",
    "title": "Better Together: Enhancing Generative Knowledge Graph Completion with  Language Models and Neighborhood Information",
    "abstract": "Real-world Knowledge Graphs (KGs) often suffer from incompleteness, which limits their potential performance. Knowledge Graph Completion (KGC) techniques aim to address this issue. However, traditional KGC methods are computationally intensive and impractical for large-scale KGs, necessitating the learning of dense node embeddings and computing pairwise distances. Generative transformer-based language models (e.g., T5 and recent KGT5) offer a promising solution as they can predict the tail nodes directly. In this study, we propose to include node neighborhoods as additional information to improve KGC methods based on language models. We examine the effects of this imputation and show that, on both inductive and transductive Wikidata subsets, our method outperforms KGT5 and conventional KGC approaches. We also provide an extensive analysis of the impact of neighborhood on model prediction and show its importance. Furthermore, we point the way to significantly improve KGC through more effective neighborhood selection. ",
    "url": "https://arxiv.org/abs/2311.01326",
    "authors": [
      "Alla Chepurova",
      "Aydar Bulatov",
      "Yuri Kuratov",
      "Mikhail Burtsev"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.01344",
    "title": "Like an Open Book? Read Neural Network Architecture with Simple Power  Analysis on 32-bit Microcontrollers",
    "abstract": "Model extraction is a growing concern for the security of AI systems. For deep neural network models, the architecture is the most important information an adversary aims to recover. Being a sequence of repeated computation blocks, neural network models deployed on edge-devices will generate distinctive side-channel leakages. The latter can be exploited to extract critical information when targeted platforms are physically accessible. By combining theoretical knowledge about deep learning practices and analysis of a widespread implementation library (ARM CMSIS-NN), our purpose is to answer this critical question: how far can we extract architecture information by simply examining an EM side-channel trace? For the first time, we propose an extraction methodology for traditional MLP and CNN models running on a high-end 32-bit microcontroller (Cortex-M7) that relies only on simple pattern recognition analysis. Despite few challenging cases, we claim that, contrary to parameters extraction, the complexity of the attack is relatively low and we highlight the urgent need for practicable protections that could fit the strong memory and latency requirements of such platforms. ",
    "url": "https://arxiv.org/abs/2311.01344",
    "authors": [
      "Raphael Joud",
      "Pierre-Alain Moellic",
      "Simon Pontie",
      "Jean-Baptiste Rigaud"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01357",
    "title": "Robust Identity Perceptual Watermark Against Deepfake Face Swapping",
    "abstract": "Notwithstanding offering convenience and entertainment to society, Deepfake face swapping has caused critical privacy issues with the rapid development of deep generative models. Due to imperceptible artifacts in high-quality synthetic images, passive detection models against face swapping in recent years usually suffer performance damping regarding the generalizability issue. Therefore, several studies have been attempted to proactively protect the original images against malicious manipulations by inserting invisible signals in advance. However, the existing proactive defense approaches demonstrate unsatisfactory results with respect to visual quality, detection accuracy, and source tracing ability. In this study, we propose the first robust identity perceptual watermarking framework that concurrently performs detection and source tracing against Deepfake face swapping proactively. We assign identity semantics regarding the image contents to the watermarks and devise an unpredictable and unreversible chaotic encryption system to ensure watermark confidentiality. The watermarks are encoded and recovered by jointly training an encoder-decoder framework along with adversarial image manipulations. Extensive experiments demonstrate state-of-the-art performance against Deepfake face swapping under both cross-dataset and cross-manipulation settings. ",
    "url": "https://arxiv.org/abs/2311.01357",
    "authors": [
      "Tianyi Wang",
      "Mengxiao Huang",
      "Harry Cheng",
      "Bin Ma",
      "Yinglong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01372",
    "title": "Data-Augmented and Retrieval-Augmented Context Enrichment in Chinese  Media Bias Detection",
    "abstract": "With the increasing pursuit of objective reports, automatically understanding media bias has drawn more attention in recent research. However, most of the previous work examines media bias from Western ideology, such as the left and right in the political spectrum, which is not applicable to Chinese outlets. Based on the previous lexical bias and informational bias structure, we refine it from the Chinese perspective and go one step further to craft data with 7 fine-grained labels. To be specific, we first construct a dataset with Chinese news reports about COVID-19 which is annotated by our newly designed system, and then conduct substantial experiments on it to detect media bias. However, the scale of the annotated data is not enough for the latest deep-learning technology, and the cost of human annotation in media bias, which needs a lot of professional knowledge, is too expensive. Thus, we explore some context enrichment methods to automatically improve these problems. In Data-Augmented Context Enrichment (DACE), we enlarge the training data; while in Retrieval-Augmented Context Enrichment (RACE), we improve information retrieval methods to select valuable information and integrate it into our models to better understand bias. Extensive experiments are conducted on both our dataset and an English dataset BASIL. Our results show that both methods outperform our baselines, while the RACE methods are more efficient and have more potential. ",
    "url": "https://arxiv.org/abs/2311.01372",
    "authors": [
      "Luyang Lin",
      "Jing Li",
      "Kam-Fai Wong"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2311.01375",
    "title": "Monotone Generative Modeling via a Gromov-Monge Embedding",
    "abstract": "Generative Adversarial Networks (GANs) are powerful tools for creating new content, but they face challenges such as sensitivity to starting conditions and mode collapse. To address these issues, we propose a deep generative model that utilizes the Gromov-Monge embedding (GME). It helps identify the low-dimensional structure of the underlying measure of the data and then maps it, while preserving its geometry, into a measure in a low-dimensional latent space, which is then optimally transported to the reference measure. We guarantee the preservation of the underlying geometry by the GME and $c$-cyclical monotonicity of the generative map, where $c$ is an intrinsic embedding cost employed by the GME. The latter property is a first step in guaranteeing better robustness to initialization of parameters and mode collapse. Numerical experiments demonstrate the effectiveness of our approach in generating high-quality images, avoiding mode collapse, and exhibiting robustness to different starting conditions. ",
    "url": "https://arxiv.org/abs/2311.01375",
    "authors": [
      "Wonjun Lee",
      "Yifei Yang",
      "Dongmian Zou",
      "Gilad Lerman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2311.01406",
    "title": "Analysis of Information Propagation in Ethereum Network Using Combined  Graph Attention Network and Reinforcement Learning to Optimize Network  Efficiency and Scalability",
    "abstract": "Blockchain technology has revolutionized the way information is propagated in decentralized networks. Ethereum plays a pivotal role in facilitating smart contracts and decentralized applications. Understanding information propagation dynamics in Ethereum is crucial for ensuring network efficiency, security, and scalability. In this study, we propose an innovative approach that utilizes Graph Convolutional Networks (GCNs) to analyze the information propagation patterns in the Ethereum network. The first phase of our research involves data collection from the Ethereum blockchain, consisting of blocks, transactions, and node degrees. We construct a transaction graph representation using adjacency matrices to capture the node embeddings; while our major contribution is to develop a combined Graph Attention Network (GAT) and Reinforcement Learning (RL) model to optimize the network efficiency and scalability. It learns the best actions to take in various network states, ultimately leading to improved network efficiency, throughput, and optimize gas limits for block processing. In the experimental evaluation, we analyze the performance of our model on a large-scale Ethereum dataset. We investigate effectively aggregating information from neighboring nodes capturing graph structure and updating node embeddings using GCN with the objective of transaction pattern prediction, accounting for varying network loads and number of blocks. Not only we design a gas limit optimization model and provide the algorithm, but also to address scalability, we demonstrate the use and implementation of sparse matrices in GraphConv, GraphSAGE, and GAT. The results indicate that our designed GAT-RL model achieves superior results compared to other GCN models in terms of performance. It effectively propagates information across the network, optimizing gas limits for block processing and improving network efficiency. ",
    "url": "https://arxiv.org/abs/2311.01406",
    "authors": [
      "Stefan Kambiz Behfar",
      "Jon Crowcroft"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.01412",
    "title": "Castor: Causal Temporal Regime Structure Learning",
    "abstract": "The task of uncovering causal relationships among multivariate time series data stands as an essential and challenging objective that cuts across a broad array of disciplines ranging from climate science to healthcare. Such data entails linear or non-linear relationships, and usually follow multiple a priori unknown regimes. Existing causal discovery methods can infer summary causal graphs from heterogeneous data with known regimes, but they fall short in comprehensively learning both regimes and the corresponding causal graph. In this paper, we introduce CASTOR, a novel framework designed to learn causal relationships in heterogeneous time series data composed of various regimes, each governed by a distinct causal graph. Through the maximization of a score function via the EM algorithm, CASTOR infers the number of regimes and learns linear or non-linear causal relationships in each regime. We demonstrate the robust convergence properties of CASTOR, specifically highlighting its proficiency in accurately identifying unique regimes. Empirical evidence, garnered from exhaustive synthetic experiments and two real-world benchmarks, confirm CASTOR's superior performance in causal discovery compared to baseline methods. By learning a full temporal causal graph for each regime, CASTOR establishes itself as a distinctly interpretable method for causal discovery in heterogeneous time series. ",
    "url": "https://arxiv.org/abs/2311.01412",
    "authors": [
      "Abdellah Rahmani",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2311.01423",
    "title": "CenterRadarNet: Joint 3D Object Detection and Tracking Framework using  4D FMCW Radar",
    "abstract": "Robust perception is a vital component for ensuring safe autonomous and assisted driving. Automotive radar (77 to 81 GHz), which offers weather-resilient sensing, provides a complementary capability to the vision- or LiDAR-based autonomous driving systems. Raw radio-frequency (RF) radar tensors contain rich spatiotemporal semantics besides 3D location information. The majority of previous methods take in 3D (Doppler-range-azimuth) RF radar tensors, allowing prediction of an object's location, heading angle, and size in bird's-eye-view (BEV). However, they lack the ability to at the same time infer objects' size, orientation, and identity in the 3D space. To overcome this limitation, we propose an efficient joint architecture called CenterRadarNet, designed to facilitate high-resolution representation learning from 4D (Doppler-range-azimuth-elevation) radar data for 3D object detection and re-identification (re-ID) tasks. As a single-stage 3D object detector, CenterRadarNet directly infers the BEV object distribution confidence maps, corresponding 3D bounding box attributes, and appearance embedding for each pixel. Moreover, we build an online tracker utilizing the learned appearance embedding for re-ID. CenterRadarNet achieves the state-of-the-art result on the K-Radar 3D object detection benchmark. In addition, we present the first 3D object-tracking result using radar on the K-Radar dataset V2. In diverse driving scenarios, CenterRadarNet shows consistent, robust performance, emphasizing its wide applicability. ",
    "url": "https://arxiv.org/abs/2311.01423",
    "authors": [
      "Jen-Hao Cheng",
      "Sheng-Yao Kuan",
      "Hugo Latapie",
      "Gaowen Liu",
      "Jenq-Neng Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01429",
    "title": "Efficient Vision Transformer for Accurate Traffic Sign Detection",
    "abstract": "This research paper addresses the challenges associated with traffic sign detection in self-driving vehicles and driver assistance systems. The development of reliable and highly accurate algorithms is crucial for the widespread adoption of traffic sign recognition and detection (TSRD) in diverse real-life scenarios. However, this task is complicated by suboptimal traffic images affected by factors such as camera movement, adverse weather conditions, and inadequate lighting. This study specifically focuses on traffic sign detection methods and introduces the application of the Transformer model, particularly the Vision Transformer variants, to tackle this task. The Transformer's attention mechanism, originally designed for natural language processing, offers improved parallel efficiency. Vision Transformers have demonstrated success in various domains, including autonomous driving, object detection, healthcare, and defense-related applications. To enhance the efficiency of the Transformer model, the research proposes a novel strategy that integrates a locality inductive bias and a transformer module. This includes the introduction of the Efficient Convolution Block and the Local Transformer Block, which effectively capture short-term and long-term dependency information, thereby improving both detection speed and accuracy. Experimental evaluations demonstrate the significant advancements achieved by this approach, particularly when applied to the GTSDB dataset. ",
    "url": "https://arxiv.org/abs/2311.01429",
    "authors": [
      "Javad Mirzapour Kaleybar",
      "Hooman Khaloo",
      "Avaz Naghipour"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01441",
    "title": "Distilling Out-of-Distribution Robustness from Vision-Language  Foundation Models",
    "abstract": "We propose a conceptually simple and lightweight framework for improving the robustness of vision models through the combination of knowledge distillation and data augmentation. We address the conjecture that larger models do not make for better teachers by showing strong gains in out-of-distribution robustness when distilling from pretrained foundation models. Following this finding, we propose Discrete Adversarial Distillation (DAD), which leverages a robust teacher to generate adversarial examples and a VQGAN to discretize them, creating more informative samples than standard data augmentation techniques. We provide a theoretical framework for the use of a robust teacher in the knowledge distillation with data augmentation setting and demonstrate strong gains in out-of-distribution robustness and clean accuracy across different student architectures. Notably, our method adds minor computational overhead compared to similar techniques and can be easily combined with other data augmentations for further improvements. ",
    "url": "https://arxiv.org/abs/2311.01441",
    "authors": [
      "Andy Zhou",
      "Jindong Wang",
      "Yu-Xiong Wang",
      "Haohan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.01447",
    "title": "CADSim: Robust and Scalable in-the-wild 3D Reconstruction for  Controllable Sensor Simulation",
    "abstract": "Realistic simulation is key to enabling safe and scalable development of % self-driving vehicles. A core component is simulating the sensors so that the entire autonomy system can be tested in simulation. Sensor simulation involves modeling traffic participants, such as vehicles, with high quality appearance and articulated geometry, and rendering them in real time. The self-driving industry has typically employed artists to build these assets. However, this is expensive, slow, and may not reflect reality. Instead, reconstructing assets automatically from sensor data collected in the wild would provide a better path to generating a diverse and large set with good real-world coverage. Nevertheless, current reconstruction approaches struggle on in-the-wild sensor data, due to its sparsity and noise. To tackle these issues, we present CADSim, which combines part-aware object-class priors via a small set of CAD models with differentiable rendering to automatically reconstruct vehicle geometry, including articulated wheels, with high-quality appearance. Our experiments show our method recovers more accurate shapes from sparse data compared to existing approaches. Importantly, it also trains and renders efficiently. We demonstrate our reconstructed vehicles in several applications, including accurate testing of autonomy perception systems. ",
    "url": "https://arxiv.org/abs/2311.01447",
    "authors": [
      "Jingkang Wang",
      "Sivabalan Manivasagam",
      "Yun Chen",
      "Ze Yang",
      "Ioan Andrei B\u00e2rsan",
      "Anqi Joyce Yang",
      "Wei-Chiu Ma",
      "Raquel Urtasun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.01452",
    "title": "Time Series Anomaly Detection using Diffusion-based Models",
    "abstract": "Diffusion models have been recently used for anomaly detection (AD) in images. In this paper we investigate whether they can also be leveraged for AD on multivariate time series (MTS). We test two diffusion-based models and compare them to several strong neural baselines. We also extend the PA%K protocol, by computing a ROCK-AUC metric, which is agnostic to both the detection threshold and the ratio K of correctly detected points. Our models outperform the baselines on synthetic datasets and are competitive on real-world datasets, illustrating the potential of diffusion-based methods for AD in multivariate time series. ",
    "url": "https://arxiv.org/abs/2311.01452",
    "authors": [
      "Ioana Pintilie",
      "Andrei Manolache",
      "Florin Brad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.01454",
    "title": "NOIR: Neural Signal Operated Intelligent Robots for Everyday Activities",
    "abstract": "We present Neural Signal Operated Intelligent Robots (NOIR), a general-purpose, intelligent brain-robot interface system that enables humans to command robots to perform everyday activities through brain signals. Through this interface, humans communicate their intended objects of interest and actions to the robots using electroencephalography (EEG). Our novel system demonstrates success in an expansive array of 20 challenging, everyday household activities, including cooking, cleaning, personal care, and entertainment. The effectiveness of the system is improved by its synergistic integration of robot learning algorithms, allowing for NOIR to adapt to individual users and predict their intentions. Our work enhances the way humans interact with robots, replacing traditional channels of interaction with direct, neural communication. Project website: https://noir-corl.github.io/. ",
    "url": "https://arxiv.org/abs/2311.01454",
    "authors": [
      "Ruohan Zhang",
      "Sharon Lee",
      "Minjune Hwang",
      "Ayano Hiranaka",
      "Chen Wang",
      "Wensi Ai",
      "Jin Jie Ryan Tan",
      "Shreya Gupta",
      "Yilun Hao",
      "Gabrael Levine",
      "Ruohan Gao",
      "Anthony Norcia",
      "Li Fei-Fei",
      "Jiajun Wu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.01462",
    "title": "Idempotent Generative Network",
    "abstract": "We propose a new approach for generative modeling based on training a neural network to be idempotent. An idempotent operator is one that can be applied sequentially without changing the result beyond the initial application, namely $f(f(z))=f(z)$. The proposed model $f$ is trained to map a source distribution (e.g, Gaussian noise) to a target distribution (e.g. realistic images) using the following objectives: (1) Instances from the target distribution should map to themselves, namely $f(x)=x$. We define the target manifold as the set of all instances that $f$ maps to themselves. (2) Instances that form the source distribution should map onto the defined target manifold. This is achieved by optimizing the idempotence term, $f(f(z))=f(z)$ which encourages the range of $f(z)$ to be on the target manifold. Under ideal assumptions such a process provably converges to the target distribution. This strategy results in a model capable of generating an output in one step, maintaining a consistent latent space, while also allowing sequential applications for refinement. Additionally, we find that by processing inputs from both target and source distributions, the model adeptly projects corrupted or modified data back to the target manifold. This work is a first step towards a ``global projector'' that enables projecting any input into a target data distribution. ",
    "url": "https://arxiv.org/abs/2311.01462",
    "authors": [
      "Assaf Shocher",
      "Amil Dravid",
      "Yossi Gandelsman",
      "Inbar Mosseri",
      "Michael Rubinstein",
      "Alexei A. Efros"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.14691",
    "title": "Identifiability of total effects from abstractions of time series causal  graphs",
    "abstract": "We study the problem of identifiability of the total effect of an intervention from observational time series only given an abstraction of the causal graph of the system. Specifically, we consider two types of abstractions: the extended summary causal graph which conflates all lagged causal relations but distinguishes between lagged and instantaneous relations; and the summary causal graph which does not give any indication about the lag between causal relations. We show that the total effect is always identifiable in extended summary causal graphs and we provide necessary and sufficient graphical conditions for identifiability in summary causal graphs. Furthermore, we provide adjustment sets allowing to estimate the total effect whenever it is identifiable. ",
    "url": "https://arxiv.org/abs/2310.14691",
    "authors": [
      "Charles K. Assaad",
      "Emilie Devijver",
      "Eric Gaussier",
      "Gregor G\u00f6ssler",
      "Anouar Meynaoui"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.00867",
    "title": "Automatic Disfluency Detection from Untranscribed Speech",
    "abstract": "Speech disfluencies, such as filled pauses or repetitions, are disruptions in the typical flow of speech. Stuttering is a speech disorder characterized by a high rate of disfluencies, but all individuals speak with some disfluencies and the rates of disfluencies may by increased by factors such as cognitive load. Clinically, automatic disfluency detection may help in treatment planning for individuals who stutter. Outside of the clinic, automatic disfluency detection may serve as a pre-processing step to improve natural language understanding in downstream applications. With this wide range of applications in mind, we investigate language, acoustic, and multimodal methods for frame-level automatic disfluency detection and categorization. Each of these methods relies on audio as an input. First, we evaluate several automatic speech recognition (ASR) systems in terms of their ability to transcribe disfluencies, measured using disfluency error rates. We then use these ASR transcripts as input to a language-based disfluency detection model. We find that disfluency detection performance is largely limited by the quality of transcripts and alignments. We find that an acoustic-based approach that does not require transcription as an intermediate step outperforms the ASR language approach. Finally, we present multimodal architectures which we find improve disfluency detection performance over the unimodal approaches. Ultimately, this work introduces novel approaches for automatic frame-level disfluency and categorization. In the long term, this will help researchers incorporate automatic disfluency detection into a range of applications. ",
    "url": "https://arxiv.org/abs/2311.00867",
    "authors": [
      "Amrit Romana",
      "Kazuhito Koishida",
      "Emily Mower Provost"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.00927",
    "title": "Scalable Counterfactual Distribution Estimation in Multivariate Causal  Models",
    "abstract": "We consider the problem of estimating the counterfactual joint distribution of multiple quantities of interests (e.g., outcomes) in a multivariate causal model extended from the classical difference-in-difference design. Existing methods for this task either ignore the correlation structures among dimensions of the multivariate outcome by considering univariate causal models on each dimension separately and hence produce incorrect counterfactual distributions, or poorly scale even for moderate-size datasets when directly dealing with such multivariate causal model. We propose a method that alleviates both issues simultaneously by leveraging a robust latent one-dimensional subspace of the original high-dimension space and exploiting the efficient estimation from the univariate causal model on such space. Since the construction of the one-dimensional subspace uses information from all the dimensions, our method can capture the correlation structures and produce good estimates of the counterfactual distribution. We demonstrate the advantages of our approach over existing methods on both synthetic and real-world data. ",
    "url": "https://arxiv.org/abs/2311.00927",
    "authors": [
      "Thong Pham",
      "Shohei Shimizu",
      "Hideitsu Hino",
      "Tam Le"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2311.00970",
    "title": "Lightweight super resolution network for point cloud geometry  compression",
    "abstract": "This paper presents an approach for compressing point cloud geometry by leveraging a lightweight super-resolution network. The proposed method involves decomposing a point cloud into a base point cloud and the interpolation patterns for reconstructing the original point cloud. While the base point cloud can be efficiently compressed using any lossless codec, such as Geometry-based Point Cloud Compression, a distinct strategy is employed for handling the interpolation patterns. Rather than directly compressing the interpolation patterns, a lightweight super-resolution network is utilized to learn this information through overfitting. Subsequently, the network parameter is transmitted to assist in point cloud reconstruction at the decoder side. Notably, our approach differentiates itself from lookup table-based methods, allowing us to obtain more accurate interpolation patterns by accessing a broader range of neighboring voxels at an acceptable computational cost. Experiments on MPEG Cat1 (Solid) and Cat2 datasets demonstrate the remarkable compression performance achieved by our method. ",
    "url": "https://arxiv.org/abs/2311.00970",
    "authors": [
      "Wei Zhang",
      "Dingquan Li",
      "Ge Li",
      "Wen Gao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2311.00975",
    "title": "Autonomous Learning of Generative Models with Chemical Reaction Network  Ensembles",
    "abstract": "Can a micron sized sack of interacting molecules autonomously learn an internal model of a complex and fluctuating environment? We draw insights from control theory, machine learning theory, chemical reaction network theory, and statistical physics to develop a general architecture whereby a broad class of chemical systems can autonomously learn complex distributions. Our construction takes the form of a chemical implementation of machine learning's optimization workhorse: gradient descent on the relative entropy cost function. We show how this method can be applied to optimize any detailed balanced chemical reaction network and that the construction is capable of using hidden units to learn complex distributions. This result is then recast as a form of integral feedback control. Finally, due to our use of an explicit physical model of learning, we are able to derive thermodynamic costs and trade-offs associated to this process. ",
    "url": "https://arxiv.org/abs/2311.00975",
    "authors": [
      "William Poole",
      "Thomas E. Ouldridge",
      "Manoj Gopalkrishnan"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)",
      "Biological Physics (physics.bio-ph)"
    ]
  },
  {
    "id": "arXiv:2311.01356",
    "title": "On the Lipschitz constant of random neural networks",
    "abstract": "Empirical studies have widely demonstrated that neural networks are highly sensitive to small, adversarial perturbations of the input. The worst-case robustness against these so-called adversarial examples can be quantified by the Lipschitz constant of the neural network. However, only few theoretical results regarding this quantity exist in the literature. In this paper, we initiate the study of the Lipschitz constant of random ReLU neural networks, i.e., neural networks whose weights are chosen at random and which employ the ReLU activation function. For shallow neural networks, we characterize the Lipschitz constant up to an absolute numerical constant. Moreover, we extend our analysis to deep neural networks of sufficiently large width where we prove upper and lower bounds for the Lipschitz constant. These bounds match up to a logarithmic factor that depends on the depth. ",
    "url": "https://arxiv.org/abs/2311.01356",
    "authors": [
      "Paul Geuchen",
      "Thomas Heindl",
      "Dominik St\u00f6ger",
      "Felix Voigtlaender"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2311.01367",
    "title": "Respiratory Anomaly Detection using Reflected Infrared Light-wave  Signals",
    "abstract": "In this study, we present a non-contact respiratory anomaly detection method using incoherent light-wave signals reflected from the chest of a mechanical robot that can breathe like human beings. In comparison to existing radar and camera-based sensing systems for vitals monitoring, this technology uses only a low-cost ubiquitous light source (e.g., infrared light emitting diode) and sensor (e.g., photodetector). This light-wave sensing (LWS) system recognizes different breathing anomalies from the variations of light intensity reflected from the chest of the robot within a 0.5m-1.5m range. The anomaly detection model demonstrates up to 96.6% average accuracy in classifying 7 different types of breathing data using machine learning. The model can also detect faulty data collected by the system that does not contain breathing information. The developed system can be utilized at home or healthcare facilities as a smart, non-contact and discreet respiration monitoring method. ",
    "url": "https://arxiv.org/abs/2311.01367",
    "authors": [
      "Md Zobaer Islam",
      "Brenden Martin",
      "Carly Gotcher",
      "Tyler Martinez",
      "John F. O'Hara",
      "Sabit Ekin"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.01404",
    "title": "Normalizing flows as approximations of optimal transport maps via  linear-control neural ODEs",
    "abstract": "The term \"Normalizing Flows\" is related to the task of constructing invertible transport maps between probability measures by means of deep neural networks. In this paper, we consider the problem of recovering the $W_2$-optimal transport map $T$ between absolutely continuous measures $\\mu,\\nu\\in\\mathcal{P}(\\mathbb{R}^n)$ as the flow of a linear-control neural ODE. We first show that, under suitable assumptions on $\\mu,\\nu$ and on the controlled vector fields, the optimal transport map is contained in the $C^0_c$-closure of the flows generated by the system. Assuming that discrete approximations $\\mu_N,\\nu_N$ of the original measures $\\mu,\\nu$ are available, we use a discrete optimal coupling $\\gamma_N$ to define an optimal control problem. With a $\\Gamma$-convergence argument, we prove that its solutions correspond to flows that approximate the optimal transport map $T$. Finally, taking advantage of the Pontryagin Maximum Principle, we propose an iterative numerical scheme for the resolution of the optimal control problem, resulting in an algorithm for the practical computation of the approximated optimal transport map. ",
    "url": "https://arxiv.org/abs/2311.01404",
    "authors": [
      "Alessandro Scagliotti",
      "Sara Farinelli"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1005.0513",
    "title": "Local algorithms for the maximum flow and minimum cut in bounded-degree  networks",
    "abstract": " Title: Local algorithms for the maximum flow and minimum cut in bounded-degree  networks ",
    "url": "https://arxiv.org/abs/1005.0513",
    "authors": [
      "Endre Cs\u00f3ka",
      "Andr\u00e1s Pongr\u00e1cz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:1202.1565",
    "title": "Variants of local algorithms on sparse graphs",
    "abstract": " Title: Variants of local algorithms on sparse graphs ",
    "url": "https://arxiv.org/abs/1202.1565",
    "authors": [
      "Endre Cs\u00f3ka"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2002.07897",
    "title": "LocoGAN -- Locally Convolutional GAN",
    "abstract": " Title: LocoGAN -- Locally Convolutional GAN ",
    "url": "https://arxiv.org/abs/2002.07897",
    "authors": [
      "\u0141ukasz Struski",
      "Szymon Knop",
      "Jacek Tabor",
      "Wiktor Daniec",
      "Przemys\u0142aw Spurek"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2105.06943",
    "title": "Efficient Spiking Neural Networks with Radix Encoding",
    "abstract": " Title: Efficient Spiking Neural Networks with Radix Encoding ",
    "url": "https://arxiv.org/abs/2105.06943",
    "authors": [
      "Zhehui Wang",
      "Xiaozhe Gu",
      "Rick Goh",
      "Joey Tianyi Zhou",
      "Tao Luo"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2105.10381",
    "title": "Entropy-based Discovery of Summary Causal Graphs in Time Series",
    "abstract": " Comments: Published in Entropy (2022) ",
    "url": "https://arxiv.org/abs/2105.10381",
    "authors": [
      "Charles K. Assaad",
      "Emilie Devijver",
      "Eric Gaussier"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.08907",
    "title": "Releasing Graph Neural Networks with Differential Privacy Guarantees",
    "abstract": " Comments: Published in TMLR 2023 ",
    "url": "https://arxiv.org/abs/2109.08907",
    "authors": [
      "Iyiola E. Olatunji",
      "Thorben Funke",
      "Megha Khosla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2112.13398",
    "title": "Long Story Short: Omitted Variable Bias in Causal Machine Learning",
    "abstract": " Comments: This is an extended version of the paper was prepared for the NeurIPS-2021 Workshop \"Causal Inference & Machine Learning: Why now?\"; 55 pages; 10 figures ",
    "url": "https://arxiv.org/abs/2112.13398",
    "authors": [
      "Victor Chernozhukov",
      "Carlos Cinelli",
      "Whitney Newey",
      "Amit Sharma",
      "Vasilis Syrgkanis"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2112.14822",
    "title": "UCoDe: Unified Community Detection with Graph Convolutional Networks",
    "abstract": " Title: UCoDe: Unified Community Detection with Graph Convolutional Networks ",
    "url": "https://arxiv.org/abs/2112.14822",
    "authors": [
      "Atefeh Moradan",
      "Andrew Draganov",
      "Davide Mottin",
      "Ira Assent"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2204.01209",
    "title": "EResFD: Rediscovery of the Effectiveness of Standard Convolution for  Lightweight Face Detection",
    "abstract": " Comments: Accepted by WACV 2024 ",
    "url": "https://arxiv.org/abs/2204.01209",
    "authors": [
      "Joonhyun Jeong",
      "Beomyoung Kim",
      "Joonsang Yu",
      "Youngjoon Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.14724",
    "title": "Private Graph Extraction via Feature Explanations",
    "abstract": " Comments: Accepted at PETS 2023 ",
    "url": "https://arxiv.org/abs/2206.14724",
    "authors": [
      "Iyiola E. Olatunji",
      "Mandeep Rathee",
      "Thorben Funke",
      "Megha Khosla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2208.08879",
    "title": "SensorSCAN: Self-Supervised Learning and Deep Clustering for Fault  Diagnosis in Chemical Processes",
    "abstract": " Title: SensorSCAN: Self-Supervised Learning and Deep Clustering for Fault  Diagnosis in Chemical Processes ",
    "url": "https://arxiv.org/abs/2208.08879",
    "authors": [
      "Maksim Golyadkin",
      "Vitaliy Pozdnyakov",
      "Leonid Zhukov",
      "Ilya Makarov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04366",
    "title": "KP-RNN: A Deep Learning Pipeline for Human Motion Prediction and  Synthesis of Performance Art",
    "abstract": " Comments: To appear in Proceedings of AIVR 2023, 11 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2210.04366",
    "authors": [
      "Patrick Perrine",
      "Trevor Kirkby"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2212.09663",
    "title": "Norm of Word Embedding Encodes Information Gain",
    "abstract": " Comments: 23 pages, EMNLP 2023 ",
    "url": "https://arxiv.org/abs/2212.09663",
    "authors": [
      "Momose Oyama",
      "Sho Yokoi",
      "Hidetoshi Shimodaira"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2212.10649",
    "title": "Inversion of Bayesian Networks",
    "abstract": " Title: Inversion of Bayesian Networks ",
    "url": "https://arxiv.org/abs/2212.10649",
    "authors": [
      "Jesse van Oostrum",
      "Peter van Hintum",
      "Nihat Ay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2301.07210",
    "title": "Causal Falsification of Digital Twins",
    "abstract": " Title: Causal Falsification of Digital Twins ",
    "url": "https://arxiv.org/abs/2301.07210",
    "authors": [
      "Rob Cornish",
      "Muhammad Faaiz Taufiq",
      "Arnaud Doucet",
      "Chris Holmes"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2301.12874",
    "title": "Extremal Domain Translation with Neural Optimal Transport",
    "abstract": " Title: Extremal Domain Translation with Neural Optimal Transport ",
    "url": "https://arxiv.org/abs/2301.12874",
    "authors": [
      "Milena Gazdieva",
      "Alexander Korotin",
      "Daniil Selikhanovych",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.12145",
    "title": "Efficient Feature Distillation for Zero-shot Annotation Object Detection",
    "abstract": " Comments: WACV2024 accepted paper ",
    "url": "https://arxiv.org/abs/2303.12145",
    "authors": [
      "Zhuoming Liu",
      "Xuefeng Hu",
      "Ram Nevatia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.12783",
    "title": "Conformal Prediction for Time Series with Modern Hopfield Networks",
    "abstract": " Comments: presented at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2303.12783",
    "authors": [
      "Andreas Auer",
      "Martin Gauch",
      "Daniel Klotz",
      "Sepp Hochreiter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.17835",
    "title": "Improved Difference Images for Change Detection Classifiers in SAR  Imagery Using Deep Learning",
    "abstract": " Title: Improved Difference Images for Change Detection Classifiers in SAR  Imagery Using Deep Learning ",
    "url": "https://arxiv.org/abs/2303.17835",
    "authors": [
      "Janne Alatalo",
      "Tuomo Sipola",
      "Mika Rantonen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2304.07238",
    "title": "Robustness of community structure under edge addition",
    "abstract": " Comments: 17 pages, 30 figures ",
    "url": "https://arxiv.org/abs/2304.07238",
    "authors": [
      "Moyi Tian",
      "Pablo Moriano"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2304.13410",
    "title": "Improving Adversarial Transferability via Intermediate-level  Perturbation Decay",
    "abstract": " Comments: Accepted by NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2304.13410",
    "authors": [
      "Qizhang Li",
      "Yiwen Guo",
      "Wangmeng Zuo",
      "Hao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2304.14274",
    "title": "When Do Graph Neural Networks Help with Node Classification?  Investigating the Impact of Homophily Principle on Node Distinguishability",
    "abstract": " Comments: Accepted by 37th Conference on Neural Information Processing Systems (NeurIPS 2023) ",
    "url": "https://arxiv.org/abs/2304.14274",
    "authors": [
      "Sitao Luan",
      "Chenqing Hua",
      "Minkai Xu",
      "Qincheng Lu",
      "Jiaqi Zhu",
      "Xiao-Wen Chang",
      "Jie Fu",
      "Jure Leskovec",
      "Doina Precup"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.01638",
    "title": "Sequence Modeling with Multiresolution Convolutional Memory",
    "abstract": " Comments: ICML 2023, Source code: this https URL ",
    "url": "https://arxiv.org/abs/2305.01638",
    "authors": [
      "Jiaxin Shi",
      "Ke Alexander Wang",
      "Emily B. Fox"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.03619",
    "title": "Uncertainty Quantification for Fisher-Kolmogorov Equation on Graphs with  Application to Patient-Specific Alzheimer Disease",
    "abstract": " Title: Uncertainty Quantification for Fisher-Kolmogorov Equation on Graphs with  Application to Patient-Specific Alzheimer Disease ",
    "url": "https://arxiv.org/abs/2305.03619",
    "authors": [
      "Mattia Corti",
      "Francesca Bonizzoni",
      "Paola F. Antonietti",
      "Alfio M. Quarteroni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2305.07828",
    "title": "Description and Discussion on DCASE 2023 Challenge Task 2: First-Shot  Unsupervised Anomalous Sound Detection for Machine Condition Monitoring",
    "abstract": " Comments: anomaly detection, acoustic condition monitoring, domain shift, first-shot problem, DCASE Challenge, Accepted in DCASE2023 Workshop ",
    "url": "https://arxiv.org/abs/2305.07828",
    "authors": [
      "Kota Dohi",
      "Keisuke Imoto",
      "Noboru Harada",
      "Daisuke Niizumi",
      "Yuma Koizumi",
      "Tomoya Nishida",
      "Harsh Purohit",
      "Ryo Tanabe",
      "Takashi Endo",
      "Yohei Kawaguchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2305.08776",
    "title": "Bridging the Domain Gap: Self-Supervised 3D Scene Understanding with  Foundation Models",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2305.08776",
    "authors": [
      "Zhimin Chen",
      "Longlong Jing",
      "Yingwei Li",
      "Bing Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.09194",
    "title": "Characterizing network circuity among heterogeneous urban amenities",
    "abstract": " Title: Characterizing network circuity among heterogeneous urban amenities ",
    "url": "https://arxiv.org/abs/2305.09194",
    "authors": [
      "Bibandhan Poudyal",
      "Gourab Ghoshal",
      "Alec Kirkley"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2305.13677",
    "title": "Towards Legally Enforceable Hate Speech Detection for Public Forums",
    "abstract": " Comments: 8 pages; Accepted to the Findings of EMNLP 2023 ",
    "url": "https://arxiv.org/abs/2305.13677",
    "authors": [
      "Chu Fei Luo",
      "Rohan Bhambhoria",
      "Xiaodan Zhu",
      "Samuel Dahan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14764",
    "title": "Detection of Non-uniformity in Parameters for Magnetic Domain Pattern  Generation by Machine Learning",
    "abstract": " Comments: 32 pages, 14 figures ",
    "url": "https://arxiv.org/abs/2305.14764",
    "authors": [
      "Naoya Mamada",
      "Masaichiro Mizumaki",
      "Ichiro Akai",
      "Toru Aonishi"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.16744",
    "title": "Demo2Code: From Summarizing Demonstrations to Synthesizing Code via  Extended Chain-of-Thought",
    "abstract": " Comments: 10 pages (not including references and appendix), 14 figures (7 in main paper, 7 in appendix); (v3) camera-ready version ",
    "url": "https://arxiv.org/abs/2305.16744",
    "authors": [
      "Huaxiaoyue Wang",
      "Gonzalo Gonzalez-Pumariega",
      "Yash Sharma",
      "Sanjiban Choudhury"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2305.18497",
    "title": "Collaborative Learning via Prediction Consensus",
    "abstract": " Comments: Accepted to the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) ",
    "url": "https://arxiv.org/abs/2305.18497",
    "authors": [
      "Dongyang Fan",
      "Celestine Mendler-D\u00fcnner",
      "Martin Jaggi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.18832",
    "title": "ReTR: Modeling Rendering Via Transformer for Generalizable Neural  Surface Reconstruction",
    "abstract": " Comments: 18 pages, 11 Figures, Our code will be released at this https URL ",
    "url": "https://arxiv.org/abs/2305.18832",
    "authors": [
      "Yixun Liang",
      "Hao He",
      "Ying-cong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.19913",
    "title": "Representation Equivalent Neural Operators: a Framework for Alias-free  Operator Learning",
    "abstract": " Comments: 28 pages ",
    "url": "https://arxiv.org/abs/2305.19913",
    "authors": [
      "Francesca Bartolucci",
      "Emmanuel de B\u00e9zenac",
      "Bogdan Raoni\u0107",
      "Roberto Molinaro",
      "Siddhartha Mishra",
      "Rima Alaifari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2306.03698",
    "title": "Fine-grained Expressivity of Graph Neural Networks",
    "abstract": " Comments: Accepted at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.03698",
    "authors": [
      "Jan B\u00f6ker",
      "Ron Levie",
      "Ningyuan Huang",
      "Soledad Villar",
      "Christopher Morris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Discrete Mathematics (cs.DM)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2306.04699",
    "title": "DiViNeT: 3D Reconstruction from Disparate Views via Neural Template  Regularization",
    "abstract": " Comments: To be presented at NeurIPS, 2023 ",
    "url": "https://arxiv.org/abs/2306.04699",
    "authors": [
      "Aditya Vora",
      "Akshay Gadi Patil",
      "Hao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.05225",
    "title": "Boosting Adversarial Transferability by Achieving Flat Local Maxima",
    "abstract": " Comments: Accepted by the Neural Information Processing Systems (NeurIPS 2023) ",
    "url": "https://arxiv.org/abs/2306.05225",
    "authors": [
      "Zhijin Ge",
      "Hongying Liu",
      "Xiaosen Wang",
      "Fanhua Shang",
      "Yuanyuan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.10681",
    "title": "VNVC: A Versatile Neural Video Coding Framework for Efficient  Human-Machine Vision",
    "abstract": " Title: VNVC: A Versatile Neural Video Coding Framework for Efficient  Human-Machine Vision ",
    "url": "https://arxiv.org/abs/2306.10681",
    "authors": [
      "Xihua Sheng",
      "Li Li",
      "Dong Liu",
      "Houqiang Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.15111",
    "title": "Self-Supervised Image Captioning with CLIP",
    "abstract": " Comments: NeurIPS 2023 Self-Supervised Learning Workshop ",
    "url": "https://arxiv.org/abs/2306.15111",
    "authors": [
      "Chuanyang Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.16180",
    "title": "Pseudo-Bag Mixup Augmentation for Multiple Instance Learning-Based Whole  Slide Image Classification",
    "abstract": " Comments: 12 pages, 6 figures, 10 tables ",
    "url": "https://arxiv.org/abs/2306.16180",
    "authors": [
      "Pei Liu",
      "Luping Ji",
      "Xinyu Zhang",
      "Feng Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2307.07439",
    "title": "Atlas-Based Interpretable Age Prediction In Whole-Body MR Images",
    "abstract": " Title: Atlas-Based Interpretable Age Prediction In Whole-Body MR Images ",
    "url": "https://arxiv.org/abs/2307.07439",
    "authors": [
      "Sophie Starck",
      "Yadunandan Vivekanand Kini",
      "Jessica Johanna Maria Ritter",
      "Rickmer Braren",
      "Daniel Rueckert",
      "Tamara Mueller"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2307.14837",
    "title": "DNN-MG: A Hybrid Neural Network/Finite Element Method with Applications  to 3D Simulations of the Navier-Stokes Equations",
    "abstract": " Comments: 40 pages, 24 figures, 11 tables. Submitted to Computer Methods in Applied Mechanics and Engineering ",
    "url": "https://arxiv.org/abs/2307.14837",
    "authors": [
      "Nils Margenberg",
      "Robert Jendersie",
      "Christian Lessig",
      "Thomas Richter"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2308.03900",
    "title": "Developability Approximation for Neural Implicits through Rank  Minimization",
    "abstract": " Comments: Accepted-3DV(2024) ",
    "url": "https://arxiv.org/abs/2308.03900",
    "authors": [
      "Pratheba Selvaraju"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2308.06534",
    "title": "Self-Supervised Pre-Training with Contrastive and Masked Autoencoder  Methods for Dealing with Small Datasets in Deep Learning for Medical Imaging",
    "abstract": " Comments: Accepted in Nature Scientific Reports ",
    "url": "https://arxiv.org/abs/2308.06534",
    "authors": [
      "Daniel Wolf",
      "Tristan Payer",
      "Catharina Silvia Lisson",
      "Christoph Gerhard Lisson",
      "Meinrad Beer",
      "Michael G\u00f6tz",
      "Timo Ropinski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.11809",
    "title": "Expressive probabilistic sampling in recurrent neural networks",
    "abstract": " Title: Expressive probabilistic sampling in recurrent neural networks ",
    "url": "https://arxiv.org/abs/2308.11809",
    "authors": [
      "Shirui Chen",
      "Linxin Preston Jiang",
      "Rajesh P. N. Rao",
      "Eric Shea-Brown"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2309.00174",
    "title": "Typing on Any Surface: A Deep Learning-based Method for Real-Time  Keystroke Detection in Augmented Reality",
    "abstract": " Title: Typing on Any Surface: A Deep Learning-based Method for Real-Time  Keystroke Detection in Augmented Reality ",
    "url": "https://arxiv.org/abs/2309.00174",
    "authors": [
      "Xingyu Fu",
      "Mingze Xi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2309.01456",
    "title": "LLM and Infrastructure as a Code use case",
    "abstract": " Title: LLM and Infrastructure as a Code use case ",
    "url": "https://arxiv.org/abs/2309.01456",
    "authors": [
      "Thibault Chanus",
      "Michael Aubertin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.01632",
    "title": "Representing Edge Flows on Graphs via Sparse Cell Complexes",
    "abstract": " Comments: 9 pages, 6 figures (plus appendix). For evaluation code, see this https URL ",
    "url": "https://arxiv.org/abs/2309.01632",
    "authors": [
      "Josef Hoppe",
      "Michael T. Schaub"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.04037",
    "title": "SRN-SZ: Deep Leaning-Based Scientific Error-bounded Lossy Compression  with Super-resolution Neural Networks",
    "abstract": " Title: SRN-SZ: Deep Leaning-Based Scientific Error-bounded Lossy Compression  with Super-resolution Neural Networks ",
    "url": "https://arxiv.org/abs/2309.04037",
    "authors": [
      "Jinyang Liu",
      "Sheng Di",
      "Sian Jin",
      "Kai Zhao",
      "Xin Liang",
      "Zizhong Chen",
      "Franck Cappello"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2309.12148",
    "title": "Neural Modelling of Dynamic Systems with Time Delays Based on an  Adjusted NEAT Algorithm",
    "abstract": " Comments: Conference paper ",
    "url": "https://arxiv.org/abs/2309.12148",
    "authors": [
      "Krzysztof Laddach",
      "Rafa\u0142 \u0141angowski"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2309.15631",
    "title": "Design and Optimization of Residual Neural Network Accelerators for  Low-Power FPGAs Using High-Level Synthesis",
    "abstract": " Title: Design and Optimization of Residual Neural Network Accelerators for  Low-Power FPGAs Using High-Level Synthesis ",
    "url": "https://arxiv.org/abs/2309.15631",
    "authors": [
      "Filippo Minnella",
      "Teodoro Urso",
      "Mihai T. Lazarescu",
      "Luciano Lavagno"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.00402",
    "title": "DiskANN++: Efficient Page-based Search over Isomorphic Mapped Graph  Index using Query-sensitivity Entry Vertex",
    "abstract": " Comments: 14 pages including references, 9 figures ",
    "url": "https://arxiv.org/abs/2310.00402",
    "authors": [
      "Jiongkang Ni",
      "Xiaoliang Xu",
      "Yuxiang Wang",
      "Can Li",
      "Jiajie Yao",
      "Shihai Xiao",
      "Xuecang Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2310.06403",
    "title": "Boundary Discretization and Reliable Classification Network for Temporal  Action Detection",
    "abstract": " Comments: 12 pages ",
    "url": "https://arxiv.org/abs/2310.06403",
    "authors": [
      "Zhenying Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.10702",
    "title": "Transparent Anomaly Detection via Concept-based Explanations",
    "abstract": " Comments: Accepted at Neurips XAI in Action workshop ",
    "url": "https://arxiv.org/abs/2310.10702",
    "authors": [
      "Laya Rafiee Sevyeri",
      "Ivaxi Sheth",
      "Farhood Farahnak",
      "Samira Ebrahimi Kahou",
      "Shirin Abbasinejad Enger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.17341",
    "title": "De-novo Chemical Reaction Generation by Means of Temporal Convolutional  Neural Networks",
    "abstract": " Title: De-novo Chemical Reaction Generation by Means of Temporal Convolutional  Neural Networks ",
    "url": "https://arxiv.org/abs/2310.17341",
    "authors": [
      "Andrei Buin",
      "Hung Yi Chiang",
      "S. Andrew Gadsden",
      "Faraz A. Alderson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.17364",
    "title": "Distributed Adaptive Control for Uncertain Networks",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2210.00081 ",
    "url": "https://arxiv.org/abs/2310.17364",
    "authors": [
      "Venkatraman Renganathan",
      "Anders Rantzer",
      "Olle Kjellqvist"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.17403",
    "title": "Detection Defenses: An Empty Promise against Adversarial Patch Attacks  on Optical Flow",
    "abstract": " Comments: Accepted to WACV 2024 ",
    "url": "https://arxiv.org/abs/2310.17403",
    "authors": [
      "Erik Scheurer",
      "Jenny Schmalfuss",
      "Alexander Lis",
      "Andr\u00e9s Bruhn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18477",
    "title": "Understanding and Improving Ensemble Adversarial Defense",
    "abstract": " Title: Understanding and Improving Ensemble Adversarial Defense ",
    "url": "https://arxiv.org/abs/2310.18477",
    "authors": [
      "Yian Deng",
      "Tingting Mu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19385",
    "title": "Gradient-free online learning of subgrid-scale dynamics with neural  emulators",
    "abstract": " Comments: 14 pages, 6 figures, submitted for publication in Journal of Computational Physics ",
    "url": "https://arxiv.org/abs/2310.19385",
    "authors": [
      "Hugo Frezat",
      "Ronan Fablet",
      "Guillaume Balarac",
      "Julien Le Sommer"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2311.00279",
    "title": "Accelerating Maximal Clique Enumeration via Graph Reduction",
    "abstract": " Comments: 12pages ",
    "url": "https://arxiv.org/abs/2311.00279",
    "authors": [
      "Wen Deng",
      "Weiguo Zheng",
      "Hong Cheng"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2311.00489",
    "title": "Deep Neural Networks for Automatic Speaker Recognition Do Not Learn  Supra-Segmental Temporal Features",
    "abstract": " Comments: 7 pages, 2 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2311.00489",
    "authors": [
      "Daniel Neururer",
      "Volker Dellwo",
      "Thilo Stadelmann"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  }
]