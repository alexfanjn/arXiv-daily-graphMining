[
  {
    "id": "arXiv:2311.17068",
    "title": "Deep convolutional encoder-decoder hierarchical neural networks for  conjugate heat transfer surrogate modeling",
    "abstract": "Conjugate heat transfer (CHT) models are vital for the design of many engineering systems. However, high-fidelity CHT models are computationally intensive, which limits their use in applications such as design optimization, where hundreds to thousands of model evaluations are required. In this work, we develop a modular deep convolutional encoder-decoder hierarchical (DeepEDH) neural network, a novel deep-learning-based surrogate modeling methodology for computationally intensive CHT models. Leveraging convective temperature dependencies, we propose a two-stage temperature prediction architecture that couples velocity and temperature models. The proposed DeepEDH methodology is demonstrated by modeling the pressure, velocity, and temperature fields for a liquid-cooled cold-plate-based battery thermal management system with variable channel geometry. A computational model of the cold plate is developed and solved using the finite element method (FEM), generating a dataset of 1,500 simulations. The FEM results are transformed and scaled from unstructured to structured, image-like meshes to create training and test datasets. The DeepEDH methodology's performance is examined in relation to data scaling, training dataset size, and network depth. Our performance analysis covers the impact of the novel architecture, separate field models, output geometry masks, multi-stage temperature models, and optimizations of the hyperparameters and architecture. Furthermore, we quantify the influence of the CHT thermal boundary condition on surrogate model performance, highlighting improved temperature model performance with higher heat fluxes. Compared to other deep learning neural network surrogate models, such as U-Net and DenseED, the proposed DeepEDH methodology for CHT models exhibits up to a 65% enhancement in the coefficient of determination ($R^{2}$). ",
    "url": "https://arxiv.org/abs/2311.17068",
    "authors": [
      "Takiah Ebbs-Picken",
      "David A. Romero",
      "Carlos M. Da Silva",
      "Cristina H. Amon"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17073",
    "title": "Practical Layout-Aware Analog/Mixed-Signal Design Automation with  Bayesian Neural Networks",
    "abstract": "The high simulation cost has been a bottleneck of practical analog/mixed-signal design automation. Many learning-based algorithms require thousands of simulated data points, which is impractical for expensive to simulate circuits. We propose a learning-based algorithm that can be trained using a small amount of data and, therefore, scalable to tasks with expensive simulations. Our efficient algorithm solves the post-layout performance optimization problem where simulations are known to be expensive. Our comprehensive study also solves the schematic-level sizing problem. For efficient optimization, we utilize Bayesian Neural Networks as a regression model to approximate circuit performance. For layout-aware optimization, we handle the problem as a multi-fidelity optimization problem and improve efficiency by exploiting the correlations from cheaper evaluations. We present three test cases to demonstrate the efficiency of our algorithms. Our tests prove that the proposed approach is more efficient than conventional baselines and state-of-the-art algorithms. ",
    "url": "https://arxiv.org/abs/2311.17073",
    "authors": [
      "Ahmet F. Budak",
      "Keren Zhu",
      "David Z. Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2311.17074",
    "title": "Self-Supervised Learning of Whole and Component-Based Semantic  Representations for Person Re-Identification",
    "abstract": "Interactive Segmentation Models (ISMs) like the Segment Anything Model have significantly improved various computer vision tasks, yet their application to Person Re-identification (ReID) remains limited. On the other hand, existing semantic pre-training models for ReID often have limitations like predefined parsing ranges or coarse semantics. Additionally, ReID and Clothes-Changing ReID (CC-ReID) are usually treated separately due to their different domains. This paper investigates whether utilizing precise human-centric semantic representation can boost the ReID performance and improve the generalization among various ReID tasks. We propose SemReID, a self-supervised ReID model that leverages ISMs for adaptive part-based semantic extraction, contributing to the improvement of ReID performance. SemReID additionally refines its semantic representation through techniques such as image masking and KoLeo regularization. Evaluation across three types of ReID datasets -- standard ReID, CC-ReID, and unconstrained ReID -- demonstrates superior performance compared to state-of-the-art methods. In addition, recognizing the scarcity of large person datasets with fine-grained semantics, we introduce the novel LUPerson-Part dataset to assist ReID methods in acquiring the fine-grained part semantics for robust performance. ",
    "url": "https://arxiv.org/abs/2311.17074",
    "authors": [
      "Siyuan Huang",
      "Yifan Zhou",
      "Ram Prabhakar Kathirvel",
      "Rama Chellappa",
      "Chun Pong Lau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17087",
    "title": "Rethinking Mixup for Improving the Adversarial Transferability",
    "abstract": "Mixup augmentation has been widely integrated to generate adversarial examples with superior adversarial transferability when immigrating from a surrogate model to other models. However, the underlying mechanism influencing the mixup's effect on transferability remains unexplored. In this work, we posit that the adversarial examples located at the convergence of decision boundaries across various categories exhibit better transferability and identify that Admix tends to steer the adversarial examples towards such regions. However, we find the constraint on the added image in Admix decays its capability, resulting in limited transferability. To address such an issue, we propose a new input transformation-based attack called Mixing the Image but Separating the gradienT (MIST). Specifically, MIST randomly mixes the input image with a randomly shifted image and separates the gradient of each loss item for each mixed image. To counteract the imprecise gradient, MIST calculates the gradient on several mixed images for each input sample. Extensive experimental results on the ImageNet dataset demonstrate that MIST outperforms existing SOTA input transformation-based attacks with a clear margin on both Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) w/wo defense mechanisms, supporting MIST's high effectiveness and generality. ",
    "url": "https://arxiv.org/abs/2311.17087",
    "authors": [
      "Xiaosen Wang",
      "Zeyuan Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17088",
    "title": "Unsupervised Multimodal Deepfake Detection Using Intra- and Cross-Modal  Inconsistencies",
    "abstract": "Deepfake videos present an increasing threat to society with potentially negative impact on criminal justice, democracy, and personal safety and privacy. Meanwhile, detecting deepfakes, at scale, remains a very challenging tasks that often requires labeled training data from existing deepfake generation methods. Further, even the most accurate supervised learning, deepfake detection methods do not generalize to deepfakes generated using new generation methods. In this paper, we introduce a novel unsupervised approach for detecting deepfake videos by measuring of intra- and cross-modal consistency among multimodal features; specifically visual, audio, and identity features. The fundamental hypothesis behind the proposed detection method is that since deepfake generation attempts to transfer the facial motion of one identity to another, these methods will eventually encounter a trade-off between motion and identity that enviably leads to detectable inconsistencies. We validate our method through extensive experimentation, demonstrating the existence of significant intra- and cross- modal inconsistencies in deepfake videos, which can be effectively utilized to detect them with high accuracy. Our proposed method is scalable because it does not require pristine samples at inference, generalizable because it is trained only on real data, and is explainable since it can pinpoint the exact location of modality inconsistencies which are then verifiable by a human expert. ",
    "url": "https://arxiv.org/abs/2311.17088",
    "authors": [
      "Mulin Tian",
      "Mahyar Khayatkhoei",
      "Joe Mathai",
      "Wael AbdAlmageed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17094",
    "title": "In Search of a Data Transformation That Accelerates Neural Field  Training",
    "abstract": "Neural field is an emerging paradigm in data representation that trains a neural network to approximate the given signal. A key obstacle that prevents its widespread adoption is the encoding speed-generating neural fields requires an overfitting of a neural network, which can take a significant number of SGD steps to reach the desired fidelity level. In this paper, we delve into the impacts of data transformations on the speed of neural field training, specifically focusing on how permuting pixel locations affect the convergence speed of SGD. Counterintuitively, we find that randomly permuting the pixel locations can considerably accelerate the training. To explain this phenomenon, we examine the neural field training through the lens of PSNR curves, loss landscapes, and error patterns. Our analyses suggest that the random pixel permutations remove the easy-to-fit patterns, which facilitate easy optimization in the early stage but hinder capturing fine details of the signal. ",
    "url": "https://arxiv.org/abs/2311.17094",
    "authors": [
      "Junwon Seo",
      "Sangyoon Lee",
      "Kwang In Kim",
      "Jaeho Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17096",
    "title": "Robust Transductive Few-shot Learning via Joint Message Passing and  Prototype-based Soft-label Propagation",
    "abstract": "Few-shot learning (FSL) aims to develop a learning model with the ability to generalize to new classes using a few support samples. For transductive FSL tasks, prototype learning and label propagation methods are commonly employed. Prototype methods generally first learn the representative prototypes from the support set and then determine the labels of queries based on the metric between query samples and prototypes. Label propagation methods try to propagate the labels of support samples on the constructed graph encoding the relationships between both support and query samples. This paper aims to integrate these two principles together and develop an efficient and robust transductive FSL approach, termed Prototype-based Soft-label Propagation (PSLP). Specifically, we first estimate the soft-label presentation for each query sample by leveraging prototypes. Then, we conduct soft-label propagation on our learned query-support graph. Both steps are conducted progressively to boost their respective performance. Moreover, to learn effective prototypes for soft-label estimation as well as the desirable query-support graph for soft-label propagation, we design a new joint message passing scheme to learn sample presentation and relational graph jointly. Our PSLP method is parameter-free and can be implemented very efficiently. On four popular datasets, our method achieves competitive results on both balanced and imbalanced settings compared to the state-of-the-art methods. The code will be released upon acceptance. ",
    "url": "https://arxiv.org/abs/2311.17096",
    "authors": [
      "Jiahui Wang",
      "Qin Xu",
      "Bo Jiang",
      "Bin Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17097",
    "title": "Anonymous Jamming Detection in 5G with Bayesian Network Model Based  Inference Analysis",
    "abstract": "Jamming and intrusion detection are critical in 5G research, aiming to maintain reliability, prevent user experience degradation, and avoid infrastructure failure. This paper introduces an anonymous jamming detection model for 5G based on signal parameters from the protocol stacks. The system uses supervised and unsupervised learning for real-time, high-accuracy detection of jamming, including unknown types. Supervised models reach an AUC of 0.964 to 1, compared to LSTM models with an AUC of 0.923 to 1. However, the need for data annotation limits the supervised approach. To address this, an unsupervised auto-encoder-based anomaly detection is presented with an AUC of 0.987. The approach is resistant to adversarial training samples. For transparency and domain knowledge injection, a Bayesian network-based causation analysis is introduced. ",
    "url": "https://arxiv.org/abs/2311.17097",
    "authors": [
      "Ying Wang",
      "Shashank Jere",
      "Soumya Banerjee",
      "Lingjia Liu",
      "Sachin Shetty",
      "Shehadi Dayekh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2311.17098",
    "title": "DyRA: Dynamic Resolution Adjustment for Scale-robust Object Detection",
    "abstract": "In object detection, achieving constant accuracy is challenging due to the variability of object sizes. One possible solution to this problem is to optimize the input resolution, known as a multi-resolution strategy. Previous approaches for optimizing resolution are often based on pre-defined resolutions or a dynamic neural network, but there is a lack of study for run-time resolution optimization for existing architecture. In this paper, we propose an adaptive resolution scaling network called DyRA, which comprises convolutions and transformer encoder blocks, for existing detectors. Our DyRA returns a scale factor from an input image, which enables instance-specific scaling. This network is jointly trained with detectors with specially designed loss functions, namely ParetoScaleLoss and BalanceLoss. The ParetoScaleLoss produces an adaptive scale factor from the image, while the BalanceLoss optimizes the scale factor according to localization power for the dataset. The loss function is designed to minimize accuracy drop about the contrasting objective of small and large objects. Our experiments on COCO, RetinaNet, Faster-RCNN, FCOS, and Mask-RCNN achieved 1.3%, 1.1%, 1.3%, and 0.8% accuracy improvement than a multi-resolution baseline with solely resolution adjustment. The code is available at https://github.com/DaEunFullGrace/DyRA.git. ",
    "url": "https://arxiv.org/abs/2311.17098",
    "authors": [
      "Daeun Seo",
      "Hoeseok Yang",
      "Hyungshin Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.17101",
    "title": "Robust Diffusion GAN using Semi-Unbalanced Optimal Transport",
    "abstract": "Diffusion models, a type of generative model, have demonstrated great potential for synthesizing highly detailed images. By integrating with GAN, advanced diffusion models like DDGAN \\citep{xiao2022DDGAN} could approach real-time performance for expansive practical applications. While DDGAN has effectively addressed the challenges of generative modeling, namely producing high-quality samples, covering different data modes, and achieving faster sampling, it remains susceptible to performance drops caused by datasets that are corrupted with outlier samples. This work introduces a robust training technique based on semi-unbalanced optimal transport to mitigate the impact of outliers effectively. Through comprehensive evaluations, we demonstrate that our robust diffusion GAN (RDGAN) outperforms vanilla DDGAN in terms of the aforementioned generative modeling criteria, i.e., image quality, mode coverage of distribution, and inference speed, and exhibits improved robustness when dealing with both clean and corrupted datasets. ",
    "url": "https://arxiv.org/abs/2311.17101",
    "authors": [
      "Quan Dao",
      "Binh Ta",
      "Tung Pham",
      "Anh Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17109",
    "title": "Neural Texture Puppeteer: A Framework for Neural Geometry and Texture  Rendering of Articulated Shapes, Enabling Re-Identification at Interactive  Speed",
    "abstract": "In this paper, we present a neural rendering pipeline for textured articulated shapes that we call Neural Texture Puppeteer. Our method separates geometry and texture encoding. The geometry pipeline learns to capture spatial relationships on the surface of the articulated shape from ground truth data that provides this geometric information. A texture auto-encoder makes use of this information to encode textured images into a global latent code. This global texture embedding can be efficiently trained separately from the geometry, and used in a downstream task to identify individuals. The neural texture rendering and the identification of individuals run at interactive speeds. To the best of our knowledge, we are the first to offer a promising alternative to CNN- or transformer-based approaches for re-identification of articulated individuals based on neural rendering. Realistic looking novel view and pose synthesis for different synthetic cow textures further demonstrate the quality of our method. Restricted by the availability of ground truth data for the articulated shape's geometry, the quality for real-world data synthesis is reduced. We further demonstrate the flexibility of our model for real-world data by applying a synthetic to real-world texture domain shift where we reconstruct the texture from a real-world 2D RGB image. Thus, our method can be applied to endangered species where data is limited. Our novel synthetic texture dataset NePuMoo is publicly available to inspire further development in the field of neural rendering-based re-identification. ",
    "url": "https://arxiv.org/abs/2311.17109",
    "authors": [
      "Urs Waldmann",
      "Ole Johannsen",
      "Bastian Goldluecke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17115",
    "title": "Time- and Communication-Efficient Overlay Network Construction via  Gossip",
    "abstract": "We focus on the well-studied problem of distributed overlay network construction. We consider a synchronous gossip-based communication model where in each round a node can send a message of small size to another node whose identifier it knows. The network is assumed to be reconfigurable, i.e., a node can add new connections (edges) to other nodes whose identifier it knows or drop existing connections. Each node initially has only knowledge of its own identifier and the identifiers of its neighbors. The overlay construction problem is, given an arbitrary (connected) graph, to reconfigure it to obtain a bounded-degree expander graph as efficiently as possible. The overlay construction problem is relevant to building real-world peer-to-peer network topologies that have desirable properties such as low diameter, high conductance, robustness to adversarial deletions, etc. Our main result is that we show that starting from any arbitrary (connected) graph $G$ on $n$ nodes and $m$ edges, we can construct an overlay network that is a constant-degree expander in polylog $n$ rounds using only $\\tilde{O}(n)$ messages. Our time and message bounds are both essentially optimal (up to polylogarithmic factors). Our distributed overlay construction protocol is very lightweight as it uses gossip (each node communicates with only one neighbor in each round) and also scalable as it uses only $\\tilde{O}(n)$ messages, which is sublinear in $m$ (even when $m$ is moderately dense). To the best of our knowledge, this is the first result that achieves overlay network construction in polylog $n$ rounds and $o(m)$ messages. Our protocol uses graph sketches in a novel way to construct an expander overlay that is both time and communication efficient. A consequence of our overlay construction protocol is that distributed computation can be performed very efficiently in this model. ",
    "url": "https://arxiv.org/abs/2311.17115",
    "authors": [
      "Fabien Dufoulon",
      "Michael Moorman",
      "William K. Moses Jr.",
      "Gopal Pandurangan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.17116",
    "title": "REF$^2$-NeRF: Reflection and Refraction aware Neural Radiance Field",
    "abstract": "Recently, significant progress has been made in the study of methods for 3D reconstruction from multiple images using implicit neural representations, exemplified by the neural radiance field (NeRF) method. Such methods, which are based on volume rendering, can model various light phenomena, and various extended methods have been proposed to accommodate different scenes and situations. However, when handling scenes with multiple glass objects, e.g., objects in a glass showcase, modeling the target scene accurately has been challenging due to the presence of multiple reflection and refraction effects. Thus, this paper proposes a NeRF-based modeling method for scenes containing a glass case. In the proposed method, refraction and reflection are modeled using elements that are dependent and independent of the viewer's perspective. This approach allows us to estimate the surfaces where refraction occurs, i.e., glass surfaces, and enables the separation and modeling of both direct and reflected light components. Compared to existing methods, the proposed method enables more accurate modeling of both glass refraction and the overall scene. ",
    "url": "https://arxiv.org/abs/2311.17116",
    "authors": [
      "Wooseok Kim",
      "Taiki Fukiage",
      "Takeshi Oishi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17119",
    "title": "Continuous Pose for Monocular Cameras in Neural Implicit Representation",
    "abstract": "In this paper, we showcase the effectiveness of optimizing monocular camera poses as a continuous function of time. The camera poses are represented using an implicit neural function which maps the given time to the corresponding camera pose. The mapped camera poses are then used for the downstream tasks where joint camera pose optimization is also required. While doing so, the network parameters -- that implicitly represent camera poses -- are optimized. We exploit the proposed method in four diverse experimental settings, namely, (1) NeRF from noisy poses; (2) NeRF from asynchronous Events; (3) Visual Simultaneous Localization and Mapping (vSLAM); and (4) vSLAM with IMUs. In all four settings, the proposed method performs significantly better than the compared baselines and the state-of-the-art methods. Additionally, using the assumption of continuous motion, changes in pose may actually live in a manifold that has lower than 6 degrees of freedom (DOF) is also realized. We call this low DOF motion representation as the \\emph{intrinsic motion} and use the approach in vSLAM settings, showing impressive camera tracking performance. ",
    "url": "https://arxiv.org/abs/2311.17119",
    "authors": [
      "Qi Ma",
      "Danda Pani Paudel",
      "Ajad Chhatkuli",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17121",
    "title": "Generative Data Augmentation Improves Scribble-supervised Semantic  Segmentation",
    "abstract": "Recent advances in generative models, such as diffusion models, have made generating high-quality synthetic images widely accessible. Prior works have shown that training on synthetic images improves many perception tasks, such as image classification, object detection, and semantic segmentation. We are the first to explore generative data augmentations for scribble-supervised semantic segmentation. We propose a generative data augmentation method that leverages a ControlNet diffusion model conditioned on semantic scribbles to produce high-quality training data. However, naive implementations of generative data augmentations may inadvertently harm the performance of the downstream segmentor rather than improve it. We leverage classifier-free diffusion guidance to enforce class consistency and introduce encode ratios to trade off data diversity for data realism. Using the guidance scale and encode ratio, we are able to generate a spectrum of high-quality training images. We propose multiple augmentation schemes and find that these schemes significantly impact model performance, especially in the low-data regime. Our framework further reduces the gap between the performance of scribble-supervised segmentation and that of fully-supervised segmentation. We also show that our framework significantly improves segmentation performance on small datasets, even surpassing fully-supervised segmentation. ",
    "url": "https://arxiv.org/abs/2311.17121",
    "authors": [
      "Jacob Schnell",
      "Jieke Wang",
      "Lu Qi",
      "Vincent Tao Hu",
      "Meng Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17122",
    "title": "Large Model Based Referring Camouflaged Object Detection",
    "abstract": "Referring camouflaged object detection (Ref-COD) is a recently-proposed problem aiming to segment out specified camouflaged objects matched with a textual or visual reference. This task involves two major challenges: the COD domain-specific perception and multimodal reference-image alignment. Our motivation is to make full use of the semantic intelligence and intrinsic knowledge of recent Multimodal Large Language Models (MLLMs) to decompose this complex task in a human-like way. As language is highly condensed and inductive, linguistic expression is the main media of human knowledge learning, and the transmission of knowledge information follows a multi-level progression from simplicity to complexity. In this paper, we propose a large-model-based Multi-Level Knowledge-Guided multimodal method for Ref-COD termed MLKG, where multi-level knowledge descriptions from MLLM are organized to guide the large vision model of segmentation to perceive the camouflage-targets and camouflage-scene progressively and meanwhile deeply align the textual references with camouflaged photos. To our knowledge, our contributions mainly include: (1) This is the first time that the MLLM knowledge is studied for Ref-COD and COD. (2) We, for the first time, propose decomposing Ref-COD into two main perspectives of perceiving the target and scene by integrating MLLM knowledge, and contribute a multi-level knowledge-guided method. (3) Our method achieves the state-of-the-art on the Ref-COD benchmark outperforming numerous strong competitors. Moreover, thanks to the injected rich knowledge, it demonstrates zero-shot generalization ability on uni-modal COD datasets. We will release our code soon. ",
    "url": "https://arxiv.org/abs/2311.17122",
    "authors": [
      "Shupeng Cheng",
      "Ge-Peng Ji",
      "Pengda Qin",
      "Deng-Ping Fan",
      "Bowen Zhou",
      "Peng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17128",
    "title": "Vulnerability Analysis of Transformer-based Optical Character  Recognition to Adversarial Attacks",
    "abstract": "Recent advancements in Optical Character Recognition (OCR) have been driven by transformer-based models. OCR systems are critical in numerous high-stakes domains, yet their vulnerability to adversarial attack remains largely uncharted territory, raising concerns about security and compliance with emerging AI regulations. In this work we present a novel framework to assess the resilience of Transformer-based OCR (TrOCR) models. We develop and assess algorithms for both targeted and untargeted attacks. For the untargeted case, we measure the Character Error Rate (CER), while for the targeted case we use the success ratio. We find that TrOCR is highly vulnerable to untargeted attacks and somewhat less vulnerable to targeted attacks. On a benchmark handwriting data set, untargeted attacks can cause a CER of more than 1 without being noticeable to the eye. With a similar perturbation size, targeted attacks can lead to success rates of around $25\\%$ -- here we attacked single tokens, requiring TrOCR to output the tenth most likely token from a large vocabulary. ",
    "url": "https://arxiv.org/abs/2311.17128",
    "authors": [
      "Lucas Beerens",
      "Desmond J. Higham"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.17129",
    "title": "Feedback RoI Features Improve Aerial Object Detection",
    "abstract": "Neuroscience studies have shown that the human visual system utilizes high-level feedback information to guide lower-level perception, enabling adaptation to signals of different characteristics. In light of this, we propose Feedback multi-Level feature Extractor (Flex) to incorporate a similar mechanism for object detection. Flex refines feature selection based on image-wise and instance-level feedback information in response to image quality variation and classification uncertainty. Experimental results show that Flex offers consistent improvement to a range of existing SOTA methods on the challenging aerial object detection datasets including DOTA-v1.0, DOTA-v1.5, and HRSC2016. Although the design originates in aerial image detection, further experiments on MS COCO also reveal our module's efficacy in general detection models. Quantitative and qualitative analyses indicate that the improvements are closely related to image qualities, which match our motivation. ",
    "url": "https://arxiv.org/abs/2311.17129",
    "authors": [
      "Botao Ren",
      "Botian Xu",
      "Tengyu Liu",
      "Jingyi Wang",
      "Zhidong Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17132",
    "title": "TransNeXt: Robust Foveal Visual Perception for Vision Transformers",
    "abstract": "Due to the depth degradation effect in residual connections, many efficient Vision Transformers models that rely on stacking layers for information exchange often fail to form sufficient information mixing, leading to unnatural visual perception. To address this issue, in this paper, we propose Aggregated Attention, a biomimetic design-based token mixer that simulates biological foveal vision and continuous eye movement while enabling each token on the feature map to have a global perception. Furthermore, we incorporate learnable tokens that interact with conventional queries and keys, which further diversifies the generation of affinity matrices beyond merely relying on the similarity between queries and keys. Our approach does not rely on stacking for information exchange, thus effectively avoiding depth degradation and achieving natural visual perception. Additionally, we propose Convolutional GLU, a channel mixer that bridges the gap between GLU and SE mechanism, which empowers each token to have channel attention based on its nearest neighbor image features, enhancing local modeling capability and model robustness. We combine aggregated attention and convolutional GLU to create a new visual backbone called TransNeXt. Extensive experiments demonstrate that our TransNeXt achieves state-of-the-art performance across multiple model sizes. At a resolution of $224^2$, TransNeXt-Tiny attains an ImageNet accuracy of 84.0%, surpassing ConvNeXt-B with 69% fewer parameters. Our TransNeXt-Base achieves an ImageNet accuracy of 86.2% and an ImageNet-A accuracy of 61.6% at a resolution of $384^2$, a COCO object detection mAP of 57.1, and an ADE20K semantic segmentation mIoU of 54.7. ",
    "url": "https://arxiv.org/abs/2311.17132",
    "authors": [
      "Dai Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.17133",
    "title": "Deployment of a Robust and Explainable Mortality Prediction Model: The  COVID-19 Pandemic and Beyond",
    "abstract": "This study investigated the performance, explainability, and robustness of deployed artificial intelligence (AI) models in predicting mortality during the COVID-19 pandemic and beyond. The first study of its kind, we found that Bayesian Neural Networks (BNNs) and intelligent training techniques allowed our models to maintain performance amidst significant data shifts. Our results emphasize the importance of developing robust AI models capable of matching or surpassing clinician predictions, even under challenging conditions. Our exploration of model explainability revealed that stochastic models generate more diverse and personalized explanations thereby highlighting the need for AI models that provide detailed and individualized insights in real-world clinical settings. Furthermore, we underscored the importance of quantifying uncertainty in AI models which enables clinicians to make better-informed decisions based on reliable predictions. Our study advocates for prioritizing implementation science in AI research for healthcare and ensuring that AI solutions are practical, beneficial, and sustainable in real-world clinical environments. By addressing unique challenges and complexities in healthcare settings, researchers can develop AI models that effectively improve clinical practice and patient outcomes. ",
    "url": "https://arxiv.org/abs/2311.17133",
    "authors": [
      "Jacob R. Epifano",
      "Stephen Glass",
      "Ravi P. Ramachandran",
      "Sharad Patel",
      "Aaron J. Masino",
      "Ghulam Rasool"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.17134",
    "title": "\\texttt{GlycoNMR}: Dataset and benchmarks for NMR chemical shift  prediction of carbohydrates with graph neural networks",
    "abstract": "Molecular representation learning (MRL) is a powerful tool for bridging the gap between machine learning and chemical sciences, as it converts molecules into numerical representations while preserving their chemical features. These encoded representations serve as a foundation for various downstream biochemical studies, including property prediction and drug design. MRL has had great success with proteins and general biomolecule datasets. Yet, in the growing sub-field of glycoscience (the study of carbohydrates, where longer carbohydrates are also called glycans), MRL methods have been barely explored. This under-exploration can be primarily attributed to the limited availability of comprehensive and well-curated carbohydrate-specific datasets and a lack of Machine learning (ML) pipelines specifically tailored to meet the unique problems presented by carbohydrate data. Since interpreting and annotating carbohydrate-specific data is generally more complicated than protein data, domain experts are usually required to get involved. The existing MRL methods, predominately optimized for proteins and small biomolecules, also cannot be directly used in carbohydrate applications without special modifications. To address this challenge, accelerate progress in glycoscience, and enrich the data resources of the MRL community, we introduce GlycoNMR. GlycoNMR contains two laboriously curated datasets with 2,609 carbohydrate structures and 211,543 annotated nuclear magnetic resonance (NMR) chemical shifts for precise atomic-level prediction. We tailored carbohydrate-specific features and adapted existing MRL models to tackle this problem effectively. For illustration, we benchmark four modified MRL models on our new datasets. ",
    "url": "https://arxiv.org/abs/2311.17134",
    "authors": [
      "Zizhang Chen",
      "Ryan Paul Badman",
      "Lachele Foley",
      "Robert Woods",
      "Pengyu Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2311.17218",
    "title": "BIM: Block-Wise Self-Supervised Learning with Masked Image Modeling",
    "abstract": "Like masked language modeling (MLM) in natural language processing, masked image modeling (MIM) aims to extract valuable insights from image patches to enhance the feature extraction capabilities of the underlying deep neural network (DNN). Contrasted with other training paradigms like supervised learning and unsupervised contrastive learning, masked image modeling (MIM) pretraining typically demands significant computational resources in order to manage large training data batches (e.g., 4096). The significant memory and computation requirements pose a considerable challenge to its broad adoption. To mitigate this, we introduce a novel learning framework, termed~\\textit{Block-Wise Masked Image Modeling} (BIM). This framework involves decomposing the MIM tasks into several sub-tasks with independent computation patterns, resulting in block-wise back-propagation operations instead of the traditional end-to-end approach. Our proposed BIM maintains superior performance compared to conventional MIM while greatly reducing peak memory consumption. Moreover, BIM naturally enables the concurrent training of numerous DNN backbones of varying depths. This leads to the creation of multiple trained DNN backbones, each tailored to different hardware platforms with distinct computing capabilities. This approach significantly reduces computational costs in comparison with training each DNN backbone individually. Our framework offers a promising solution for resource constrained training of MIM. ",
    "url": "https://arxiv.org/abs/2311.17218",
    "authors": [
      "Yixuan Luo",
      "Mengye Ren",
      "Sai Qian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17232",
    "title": "ReWaRD: Retinal Waves for Pre-Training Artificial Neural Networks  Mimicking Real Prenatal Development",
    "abstract": "Computational models trained on a large amount of natural images are the state-of-the-art to study human vision - usually adult vision. Computational models of infant vision and its further development are gaining more and more attention in the community. In this work we aim at the very beginning of our visual experience - pre- and post-natal retinal waves which suggest to be a pre-training mechanism for the primate visual system at a very early stage of development. We see this approach as an instance of biologically plausible data driven inductive bias through pre-training. We built a computational model that mimics this development mechanism by pre-training different artificial convolutional neural networks with simulated retinal wave images. The resulting features of this biologically plausible pre-training closely match the V1 features of the primate visual system. We show that the performance gain by pre-training with retinal waves is similar to a state-of-the art pre-training pipeline. Our framework contains the retinal wave generator, as well as a training strategy, which can be a first step in a curriculum learning based training diet for various models of development. We release code, data and trained networks to build the basis for future work on visual development and based on a curriculum learning approach including prenatal development to support studies of innate vs. learned properties of the primate visual system. An additional benefit of our pre-trained networks for neuroscience or computer vision applications is the absence of biases inherited from datasets like ImageNet. ",
    "url": "https://arxiv.org/abs/2311.17232",
    "authors": [
      "Benjamin Cappell",
      "Andreas Stoll",
      "Williams Chukwudi Umah",
      "Bernhard Egger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.17241",
    "title": "End-to-End Temporal Action Detection with 1B Parameters Across 1000  Frames",
    "abstract": "Recently, temporal action detection (TAD) has seen significant performance improvement with end-to-end training. However, due to the memory bottleneck, only models with limited scales and limited data volumes can afford end-to-end training, which inevitably restricts TAD performance. In this paper, we reduce the memory consumption for end-to-end training, and manage to scale up the TAD backbone to 1 billion parameters and the input video to 1,536 frames, leading to significant detection performance. The key to our approach lies in our proposed temporal-informative adapter (TIA), which is a novel lightweight module that reduces training memory. Using TIA, we free the humongous backbone from learning to adapt to the TAD task by only updating the parameters in TIA. TIA also leads to better TAD representation by temporally aggregating context from adjacent frames throughout the backbone. We evaluate our model across four representative datasets. Owing to our efficient design, we are able to train end-to-end on VideoMAEv2-giant and achieve 75.4% mAP on THUMOS14, being the first end-to-end model to outperform the best feature-based methods. ",
    "url": "https://arxiv.org/abs/2311.17241",
    "authors": [
      "Shuming Liu",
      "Chen-Lin Zhang",
      "Chen Zhao",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17250",
    "title": "Fourier Neural Differential Equations for learning Quantum Field  Theories",
    "abstract": "A Quantum Field Theory is defined by its interaction Hamiltonian, and linked to experimental data by the scattering matrix. The scattering matrix is calculated as a perturbative series, and represented succinctly as a first order differential equation in time. Neural Differential Equations (NDEs) learn the time derivative of a residual network's hidden state, and have proven efficacy in learning differential equations with physical constraints. Hence using an NDE to learn particle scattering matrices presents a possible experiment-theory phenomenological connection. In this paper, NDE models are used to learn $\\phi^4$ theory, Scalar-Yukawa theory and Scalar Quantum Electrodynamics. A new NDE architecture is also introduced, the Fourier Neural Differential Equation (FNDE), which combines NDE integration and Fourier network convolution. The FNDE model demonstrates better generalisability than the non-integrated equivalent FNO model. It is also shown that by training on scattering data, the interaction Hamiltonian of a theory can be extracted from network parameters. ",
    "url": "https://arxiv.org/abs/2311.17250",
    "authors": [
      "Isaac Brant",
      "Alexander Norcliffe",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2311.17259",
    "title": "SoUnD Framework: Analyzing (So)cial Representation in (Un)structured  (D)ata",
    "abstract": "The unstructured nature of data used in foundation model development is a challenge to systematic analyses for making data use and documentation decisions. From a Responsible AI perspective, these decisions often rely upon understanding how people are represented in data. We propose a framework designed to guide analysis of human representation in unstructured data and identify downstream risks. We apply the framework in two toy examples using the Common Crawl web text corpus (C4) and LAION-400M. We also propose a set of hypothetical action steps in service of dataset use, development, and documentation. ",
    "url": "https://arxiv.org/abs/2311.17259",
    "authors": [
      "Mark D\u00edaz",
      "Sunipa Dev",
      "Emily Reif",
      "Remi Denton",
      "Vinodkumar Prabhakaran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2311.17279",
    "title": "LiveTune: Dynamic Parameter Tuning for Training Deep Neural Networks",
    "abstract": "Traditional machine learning training is a static process that lacks real-time adaptability of hyperparameters. Popular tuning solutions during runtime involve checkpoints and schedulers. Adjusting hyper-parameters usually require the program to be restarted, wasting utilization and time, while placing unnecessary strain on memory and processors. We present LiveTune, a new framework allowing real-time parameter tuning during training through LiveVariables. Live Variables allow for a continuous training session by storing parameters on designated ports on the system, allowing them to be dynamically adjusted. Extensive evaluations of our framework show saving up to 60 seconds and 5.4 Kilojoules of energy per hyperparameter change. ",
    "url": "https://arxiv.org/abs/2311.17279",
    "authors": [
      "Soheil Zibakhsh Shabgahi",
      "Nojan Sheybani",
      "Aiden Tabrizi",
      "Farinaz Koushanfar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2311.17286",
    "title": "LEOD: Label-Efficient Object Detection for Event Cameras",
    "abstract": "Object detection with event cameras enjoys the property of low latency and high dynamic range, making it suitable for safety-critical scenarios such as self-driving. However, labeling event streams with high temporal resolutions for supervised training is costly. We address this issue with LEOD, the first framework for label-efficient event-based detection. Our method unifies weakly- and semi-supervised object detection with a self-training mechanism. We first utilize a detector pre-trained on limited labels to produce pseudo ground truth on unlabeled events, and then re-train the detector with both real and generated labels. Leveraging the temporal consistency of events, we run bi-directional inference and apply tracking-based post-processing to enhance the quality of pseudo labels. To stabilize training, we further design a soft anchor assignment strategy to mitigate the noise in labels. We introduce new experimental protocols to evaluate the task of label-efficient event-based detection on Gen1 and 1Mpx datasets. LEOD consistently outperforms supervised baselines across various labeling ratios. For example, on Gen1, it improves mAP by 8.6% and 7.8% for RVT-S trained with 1% and 2% labels. On 1Mpx, RVT-S with 10% labels even surpasses its fully-supervised counterpart using 100% labels. LEOD maintains its effectiveness even when all labeled data are available, reaching new state-of-the-art results. Finally, we show that our method readily scales to improve larger detectors as well. ",
    "url": "https://arxiv.org/abs/2311.17286",
    "authors": [
      "Ziyi Wu",
      "Mathias Gehrig",
      "Qing Lyu",
      "Xudong Liu",
      "Igor Gilitschenski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17295",
    "title": "Elo Uncovered: Robustness and Best Practices in Language Model  Evaluation",
    "abstract": "In Natural Language Processing (NLP), the Elo rating system, originally designed for ranking players in dynamic games such as chess, is increasingly being used to evaluate Large Language Models (LLMs) through \"A vs B\" paired comparisons. However, while popular, the system's suitability for assessing entities with constant skill levels, such as LLMs, remains relatively unexplored. We study two fundamental axioms that evaluation methods should adhere to: reliability and transitivity. We conduct extensive evaluation of Elo behaviour, illustrating that individual Elo computations exhibit volatility and delving into the impact of varying the Elo rating system's hyperparameters. We show that these axioms are not always satisfied raising questions about the reliability of current comparative evaluations of LLMs. If the current use of Elo scores is intended to substitute the costly head-to-head comparison of LLMs, it is crucial to ensure the ranking is as robust as possible. Guided by the axioms, our findings offer concrete guidelines for enhancing the reliability of LLM evaluation methods, suggesting a need for reassessment of existing comparative approaches. ",
    "url": "https://arxiv.org/abs/2311.17295",
    "authors": [
      "Meriem Boubdir",
      "Edward Kim",
      "Beyza Ermis",
      "Sara Hooker",
      "Marzieh Fadaee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.17303",
    "title": "Enhancing the Performance of Neural Networks Through Causal Discovery  and Integration of Domain Knowledge",
    "abstract": "In this paper, we develop a generic methodology to encode hierarchical causality structure among observed variables into a neural network in order to improve its predictive performance. The proposed methodology, called causality-informed neural network (CINN), leverages three coherent steps to systematically map the structural causal knowledge into the layer-to-layer design of neural network while strictly preserving the orientation of every causal relationship. In the first step, CINN discovers causal relationships from observational data via directed acyclic graph (DAG) learning, where causal discovery is recast as a continuous optimization problem to avoid the combinatorial nature. In the second step, the discovered hierarchical causality structure among observed variables is systematically encoded into neural network through a dedicated architecture and customized loss function. By categorizing variables in the causal DAG as root, intermediate, and leaf nodes, the hierarchical causal DAG is translated into CINN with a one-to-one correspondence between nodes in the causal DAG and units in the CINN while maintaining the relative order among these nodes. Regarding the loss function, both intermediate and leaf nodes in the DAG graph are treated as target outputs during CINN training so as to drive co-learning of causal relationships among different types of nodes. As multiple loss components emerge in CINN, we leverage the projection of conflicting gradients to mitigate gradient interference among the multiple learning tasks. Computational experiments across a broad spectrum of UCI data sets demonstrate substantial advantages of CINN in predictive performance over other state-of-the-art methods. In addition, an ablation study underscores the value of integrating structural and quantitative causal knowledge in enhancing the neural network's predictive performance incrementally. ",
    "url": "https://arxiv.org/abs/2311.17303",
    "authors": [
      "Xiaoge Zhang",
      "Xiao-Lin Wang",
      "Fenglei Fan",
      "Yiu-Ming Cheung",
      "Indranil Bose"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2311.17324",
    "title": "Control of complex systems with generalized embedding and empirical  dynamic modeling",
    "abstract": "Feedback control is ubiquitous in complex systems. Effective control requires knowledge of the dynamics informing feedback compensation to guide the system toward desired states. In many control applications this knowledge is expressed mathematically or through data-driven models, however, as complexity grows obtaining a satisfactory mathematical representation is increasingly difficult. Further, many data-driven approaches consist of abstract internal representations that may have no obvious connection to the underlying dynamics and control, or, require a-priori specification of functions to represent the dynamics. To remove these constraints we demonstrate that generalized state space embedding and prediction can provide data-driven process model representation for control of complex systems. Generalized embedding naturally encompasses multivariate dynamics enabling state space variable cross mapping for direct assessment of multivariate contributions to the dynamics. Further, state space kernel regression allows inspection of intervariable dependencies. To illustrate this an agent based model is used to generate nonlinear dynamics which are then modeled by generalized state space embedding providing state predictions to a controller regulating the system dynamics. The method is generally applicable to any dynamic system representable in a state space. ",
    "url": "https://arxiv.org/abs/2311.17324",
    "authors": [
      "Joseph Park",
      "George Sugihara",
      "Gerald Pao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.17327",
    "title": "Improving Self-supervised Molecular Representation Learning using  Persistent Homology",
    "abstract": "Self-supervised learning (SSL) has great potential for molecular representation learning given the complexity of molecular graphs, the large amounts of unlabelled data available, the considerable cost of obtaining labels experimentally, and the hence often only small training datasets. The importance of the topic is reflected in the variety of paradigms and architectures that have been investigated recently. Yet the differences in performance seem often minor and are barely understood to date. In this paper, we study SSL based on persistent homology (PH), a mathematical tool for modeling topological features of data that persist across multiple scales. It has several unique features which particularly suit SSL, naturally offering: different views of the data, stability in terms of distance preservation, and the opportunity to flexibly incorporate domain knowledge. We (1) investigate an autoencoder, which shows the general representational power of PH, and (2) propose a contrastive loss that complements existing approaches. We rigorously evaluate our approach for molecular property prediction and demonstrate its particular features in improving the embedding space: after SSL, the representations are better and offer considerably more predictive power than the baselines over different probing tasks; our loss increases baseline performance, sometimes largely; and we often obtain substantial improvements over very small datasets, a common scenario in practice. ",
    "url": "https://arxiv.org/abs/2311.17327",
    "authors": [
      "Yuankai Luo",
      "Lei Shi",
      "Veronika Thost"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17332",
    "title": "NeRFTAP: Enhancing Transferability of Adversarial Patches on Face  Recognition using Neural Radiance Fields",
    "abstract": "Face recognition (FR) technology plays a crucial role in various applications, but its vulnerability to adversarial attacks poses significant security concerns. Existing research primarily focuses on transferability to different FR models, overlooking the direct transferability to victim's face images, which is a practical threat in real-world scenarios. In this study, we propose a novel adversarial attack method that considers both the transferability to the FR model and the victim's face image, called NeRFTAP. Leveraging NeRF-based 3D-GAN, we generate new view face images for the source and target subjects to enhance transferability of adversarial patches. We introduce a style consistency loss to ensure the visual similarity between the adversarial UV map and the target UV map under a 0-1 mask, enhancing the effectiveness and naturalness of the generated adversarial face images. Extensive experiments and evaluations on various FR models demonstrate the superiority of our approach over existing attack techniques. Our work provides valuable insights for enhancing the robustness of FR systems in practical adversarial settings. ",
    "url": "https://arxiv.org/abs/2311.17332",
    "authors": [
      "Xiaoliang Liu",
      "Furao Shen",
      "Feng Han",
      "Jian Zhao",
      "Changhai Nie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.17336",
    "title": "Incremental Neural Controlled Differential Equations for Modeling of  Path-dependent Materials",
    "abstract": "Data-driven surrogate modeling or metamodeling has emerged as a promising approach for reducing computational expenses of multiscale simulations. Recurrent Neural Network (RNN) is a common choice for modeling of path-dependent behavior. However, previous studies have shown that RNNs fail to make predictions that are consistent with perturbation in the input strain, leading to potential oscillations and lack of convergence when implemented within finite element simulations. In this work, we leverage neural differential equations which have recently emerged to model time series in a continuous manner and show their robustness in modeling elasto-plastic path-dependent material behavior. We develop a new sequential model called Incremental Neural Controlled Differential Equation (INCDE) for general time-variant dynamical systems, including path-dependent constitutive models. INCDE is formulated and analyzed in terms of stability and convergence. A surrogate model based on INCDE is subsequently trained and tested for J2 plasticity. The surrogate model is implemented for material point simulations and boundary value problems solved using the finite element method with various cyclic and monotonic loading protocols to demonstrate the robustness, consistency and accuracy of the proposed approach. ",
    "url": "https://arxiv.org/abs/2311.17336",
    "authors": [
      "Yangzi He",
      "Shabnam J. Semnani"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2311.17339",
    "title": "RADAP: A Robust and Adaptive Defense Against Diverse Adversarial Patches  on Face Recognition",
    "abstract": "Face recognition (FR) systems powered by deep learning have become widely used in various applications. However, they are vulnerable to adversarial attacks, especially those based on local adversarial patches that can be physically applied to real-world objects. In this paper, we propose RADAP, a robust and adaptive defense mechanism against diverse adversarial patches in both closed-set and open-set FR systems. RADAP employs innovative techniques, such as FCutout and F-patch, which use Fourier space sampling masks to improve the occlusion robustness of the FR model and the performance of the patch segmenter. Moreover, we introduce an edge-aware binary cross-entropy (EBCE) loss function to enhance the accuracy of patch detection. We also present the split and fill (SAF) strategy, which is designed to counter the vulnerability of the patch segmenter to complete white-box adaptive attacks. We conduct comprehensive experiments to validate the effectiveness of RADAP, which shows significant improvements in defense performance against various adversarial patches, while maintaining clean accuracy higher than that of the undefended Vanilla model. ",
    "url": "https://arxiv.org/abs/2311.17339",
    "authors": [
      "Xiaoliang Liu",
      "Furao Shen",
      "Jian Zhao",
      "Changhai Nie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.17347",
    "title": "Data-driven Bandwidth Adaptation for Radio Access Network Slices",
    "abstract": "We develop a Bandwidth Demand Estimator (BDE); a network function that periodically monitors the traffic of a Network Slice (NS) and adapts the bandwidth at the base station to efficiently meet its packet delay requirements. We design the BDE based on a data-driven approach that utilizes QoS feedback. Given the traffic of the NS, the BDE needs to learn the bandwidth required to satisfy the QoS. However, it also needs to consider the future effects of its actions since low bandwidths may create large packet queues that hinder the allocation process later on. For this reason, we propose a reinforcement learning approach. The action is the allocated bandwidth. The state describes the traffic, the wireless channel and the packet queue of the NS. The cost is a weighted sum of the bandwidth and of a binary variable that equals 1 if the QoS is violated. We periodically estimate the transition matrix of the system and perform value iteration to find the optimal policy. To speed up the estimation process, we initialize our algorithm with multi-armed bandits and exploit the monotonicity of the cost w.r.t. the action. The overall approach can be viewed as a data-driven version of receding horizon control. We implement our BDE on a 3GPP compliant testbed developed by Amarisoft. Experimental results show that the BDE reduces both the average allocated bandwidth and the QoS violations in the NS when compared to baseline schemes. The BDE can also satisfy per user tail packet delay requirements. ",
    "url": "https://arxiv.org/abs/2311.17347",
    "authors": [
      "Panagiotis Nikolaidis",
      "Asim Zoulkarni",
      "John Baras"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2311.17351",
    "title": "Exploring Large Language Models for Human Mobility Prediction under  Public Events",
    "abstract": "Public events, such as concerts and sports games, can be major attractors for large crowds, leading to irregular surges in travel demand. Accurate human mobility prediction for public events is thus crucial for event planning as well as traffic or crowd management. While rich textual descriptions about public events are commonly available from online sources, it is challenging to encode such information in statistical or machine learning models. Existing methods are generally limited in incorporating textual information, handling data sparsity, or providing rationales for their predictions. To address these challenges, we introduce a framework for human mobility prediction under public events (LLM-MPE) based on Large Language Models (LLMs), leveraging their unprecedented ability to process textual data, learn from minimal examples, and generate human-readable explanations. Specifically, LLM-MPE first transforms raw, unstructured event descriptions from online sources into a standardized format, and then segments historical mobility data into regular and event-related components. A prompting strategy is designed to direct LLMs in making and rationalizing demand predictions considering historical mobility and event features. A case study is conducted for Barclays Center in New York City, based on publicly available event information and taxi trip data. Results show that LLM-MPE surpasses traditional models, particularly on event days, with textual data significantly enhancing its accuracy. Furthermore, LLM-MPE offers interpretable insights into its predictions. Despite the great potential of LLMs, we also identify key challenges including misinformation and high costs that remain barriers to their broader adoption in large-scale human mobility analysis. ",
    "url": "https://arxiv.org/abs/2311.17351",
    "authors": [
      "Yuebing Liang",
      "Yichao Liu",
      "Xiaohan Wang",
      "Zhan Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.17361",
    "title": "How does spatial structure affect psychological restoration? A method  based on Graph Neural Networks and Street View Imagery",
    "abstract": "The Attention Restoration Theory (ART) presents a theoretical framework with four essential indicators (being away, extent, fascinating, and compatibility) for comprehending urban and natural restoration quality. However, previous studies relied on non-sequential data and non-spatial dependent methods, which overlooks the impact of spatial structure defined here as the positional relationships between scene entities on restoration quality. The past methods also make it challenging to measure restoration quality on an urban scale. In this work, a spatial-dependent graph neural networks (GNNs) approach is proposed to reveal the relation between spatial structure and restoration quality on an urban scale. Specifically, we constructed two different types of graphs at the street and city levels. The street-level graphs, using sequential street view images (SVIs) of road segments to capture position relationships between entities, were used to represent spatial structure. The city-level graph, modeling the topological relationships of roads as non-Euclidean data structures and embedding urban features (including Perception-features, Spatial-features, and Socioeconomic-features), was used to measure restoration quality. The results demonstrate that: 1) spatial-dependent GNNs model outperforms traditional methods (Acc = 0.735, F1 = 0.732); 2) spatial structure portrayed through sequential SVIs data significantly influences restoration quality; 3) spaces with the same restoration quality exhibited distinct spatial structures patterns. This study clarifies the association between spatial structure and restoration quality, providing a new perspective to improve urban well-being in the future. ",
    "url": "https://arxiv.org/abs/2311.17361",
    "authors": [
      "Haoran Ma",
      "Yan Zhang",
      "Pengyuan Liu",
      "Fan Zhang",
      "Pengyu Zhua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17366",
    "title": "Generative Hierarchical Temporal Transformer for Hand Action Recognition  and Motion Prediction",
    "abstract": "We present a novel framework that concurrently tackles hand action recognition and 3D future hand motion prediction. While previous works focus on either recognition or prediction, we propose a generative Transformer VAE architecture to jointly capture both aspects, facilitating realistic motion prediction by leveraging the short-term hand motion and long-term action consistency observed across timestamps.To ensure faithful representation of the semantic dependency and different temporal granularity of hand pose and action, our framework is decomposed into two cascaded VAE blocks. The lower pose block models short-span poses, while the upper action block models long-span action. These are connected by a mid-level feature that represents sub-second series of hand poses.Our framework is trained across multiple datasets, where pose and action blocks are trained separately to fully utilize pose-action annotations of different qualities. Evaluations show that on multiple datasets, the joint modeling of recognition and prediction improves over separate solutions, and the semantic and temporal hierarchy enables long-term pose and action modeling. ",
    "url": "https://arxiv.org/abs/2311.17366",
    "authors": [
      "Yilin Wen",
      "Hao Pan",
      "Takehiko Ohkawa",
      "Lei Yang",
      "Jia Pan",
      "Yoichi Sato",
      "Taku Komura",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17373",
    "title": "The Devil is in the Data: Learning Fair Graph Neural Networks via  Partial Knowledge Distillation",
    "abstract": "Graph neural networks (GNNs) are being increasingly used in many high-stakes tasks, and as a result, there is growing attention on their fairness recently. GNNs have been shown to be unfair as they tend to make discriminatory decisions toward certain demographic groups, divided by sensitive attributes such as gender and race. While recent works have been devoted to improving their fairness performance, they often require accessible demographic information. This greatly limits their applicability in real-world scenarios due to legal restrictions. To address this problem, we present a demographic-agnostic method to learn fair GNNs via knowledge distillation, namely FairGKD. Our work is motivated by the empirical observation that training GNNs on partial data (i.e., only node attributes or topology data) can improve their fairness, albeit at the cost of utility. To make a balanced trade-off between fairness and utility performance, we employ a set of fairness experts (i.e., GNNs trained on different partial data) to construct the synthetic teacher, which distills fairer and informative knowledge to guide the learning of the GNN student. Experiments on several benchmark datasets demonstrate that FairGKD, which does not require access to demographic information, significantly improves the fairness of GNNs by a large margin while maintaining their utility. ",
    "url": "https://arxiv.org/abs/2311.17373",
    "authors": [
      "Yuchang Zhu",
      "Jintang Li",
      "Liang Chen",
      "Zibin Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.17374",
    "title": "Attribute Simulation for Item Embedding Enhancement in Multi-interest  Recommendation",
    "abstract": "Although multi-interest recommenders have achieved significant progress in the matching stage, our research reveals that existing models tend to exhibit an under-clustered item embedding space, which leads to a low discernibility between items and hampers item retrieval. This highlights the necessity for item embedding enhancement. However, item attributes, which serve as effective and straightforward side information for enhancement, are either unavailable or incomplete in many public datasets due to the labor-intensive nature of manual annotation tasks. This dilemma raises two meaningful questions: 1. Can we bypass manual annotation and directly simulate complete attribute information from the interaction data? And 2. If feasible, how to simulate attributes with high accuracy and low complexity in the matching stage? In this paper, we first establish an inspiring theoretical feasibility that the item-attribute correlation matrix can be approximated through elementary transformations on the item co-occurrence matrix. Then based on formula derivation, we propose a simple yet effective module, SimEmb (Item Embedding Enhancement via Simulated Attribute), in the multi-interest recommendation of the matching stage to implement our findings. By simulating attributes with the co-occurrence matrix, SimEmb discards the item ID-based embedding and employs the attribute-weighted summation for item embedding enhancement. Comprehensive experiments on four benchmark datasets demonstrate that our approach notably enhances the clustering of item embedding and significantly outperforms SOTA models with an average improvement of 25.59% on Recall@20. ",
    "url": "https://arxiv.org/abs/2311.17374",
    "authors": [
      "Yaokun Liu",
      "Xiaowang Zhang",
      "Minghui Zou",
      "Zhiyong Feng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2311.17400",
    "title": "Improving the Robustness of Transformer-based Large Language Models with  Dynamic Attention",
    "abstract": "Transformer-based models, such as BERT and GPT, have been widely adopted in natural language processing (NLP) due to their exceptional performance. However, recent studies show their vulnerability to textual adversarial attacks where the model's output can be misled by intentionally manipulating the text inputs. Despite various methods that have been proposed to enhance the model's robustness and mitigate this vulnerability, many require heavy consumption resources (e.g., adversarial training) or only provide limited protection (e.g., defensive dropout). In this paper, we propose a novel method called dynamic attention, tailored for the transformer architecture, to enhance the inherent robustness of the model itself against various adversarial attacks. Our method requires no downstream task knowledge and does not incur additional costs. The proposed dynamic attention consists of two modules: (I) attention rectification, which masks or weakens the attention value of the chosen tokens, and (ii) dynamic modeling, which dynamically builds the set of candidate tokens. Extensive experiments demonstrate that dynamic attention significantly mitigates the impact of adversarial attacks, improving up to 33\\% better performance than previous methods against widely-used adversarial attacks. The model-level design of dynamic attention enables it to be easily combined with other defense methods (e.g., adversarial training) to further enhance the model's robustness. Furthermore, we demonstrate that dynamic attention preserves the state-of-the-art robustness space of the original model compared to other dynamic modeling methods. ",
    "url": "https://arxiv.org/abs/2311.17400",
    "authors": [
      "Lujia Shen",
      "Yuwen Pu",
      "Shouling Ji",
      "Changjiang Li",
      "Xuhong Zhang",
      "Chunpeng Ge",
      "Ting Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17406",
    "title": "LLM-State: Expandable State Representation for Long-horizon Task  Planning in the Open World",
    "abstract": "This work addresses the problem of long-horizon task planning with the Large Language Model (LLM) in an open-world household environment. Existing works fail to explicitly track key objects and attributes, leading to erroneous decisions in long-horizon tasks, or rely on highly engineered state features and feedback, which is not generalizable. We propose a novel, expandable state representation that provides continuous expansion and updating of object attributes from the LLM's inherent capabilities for context understanding and historical action reasoning. Our proposed representation maintains a comprehensive record of an object's attributes and changes, enabling robust retrospective summary of the sequence of actions leading to the current state. This allows enhanced context understanding for decision-making in task planning. We validate our model through experiments across simulated and real-world task planning scenarios, demonstrating significant improvements over baseline methods in a variety of tasks requiring long-horizon state tracking and reasoning. ",
    "url": "https://arxiv.org/abs/2311.17406",
    "authors": [
      "Siwei Chen",
      "Anxing Xiao",
      "David Hsu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.17408",
    "title": "Dynamic Dense Graph Convolutional Network for Skeleton-based Human  Motion Prediction",
    "abstract": "Graph Convolutional Networks (GCN) which typically follows a neural message passing framework to model dependencies among skeletal joints has achieved high success in skeleton-based human motion prediction task. Nevertheless, how to construct a graph from a skeleton sequence and how to perform message passing on the graph are still open problems, which severely affect the performance of GCN. To solve both problems, this paper presents a Dynamic Dense Graph Convolutional Network (DD-GCN), which constructs a dense graph and implements an integrated dynamic message passing. More specifically, we construct a dense graph with 4D adjacency modeling as a comprehensive representation of motion sequence at different levels of abstraction. Based on the dense graph, we propose a dynamic message passing framework that learns dynamically from data to generate distinctive messages reflecting sample-specific relevance among nodes in the graph. Extensive experiments on benchmark Human 3.6M and CMU Mocap datasets verify the effectiveness of our DD-GCN which obviously outperforms state-of-the-art GCN-based methods, especially when using long-term and our proposed extremely long-term protocol. ",
    "url": "https://arxiv.org/abs/2311.17408",
    "authors": [
      "Xinshun Wang",
      "Wanying Zhang",
      "Can Wang",
      "Yuan Gao",
      "Mengyuan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17410",
    "title": "GNNFlow: A Distributed Framework for Continuous Temporal GNN Learning on  Dynamic Graphs",
    "abstract": "Graph Neural Networks (GNNs) play a crucial role in various fields. However, most existing deep graph learning frameworks assume pre-stored static graphs and do not support training on graph streams. In contrast, many real-world graphs are dynamic and contain time domain information. We introduce GNNFlow, a distributed framework that enables efficient continuous temporal graph representation learning on dynamic graphs on multi-GPU machines. GNNFlow introduces an adaptive time-indexed block-based data structure that effectively balances memory usage with graph update and sampling operation efficiency. It features a hybrid GPU-CPU graph data placement for rapid GPU-based temporal neighborhood sampling and kernel optimizations for enhanced sampling processes. A dynamic GPU cache for node and edge features is developed to maximize cache hit rates through reuse and restoration strategies. GNNFlow supports distributed training across multiple machines with static scheduling to ensure load balance. We implement GNNFlow based on DGL and PyTorch. Our experimental results show that GNNFlow provides up to 21.1x faster continuous learning than existing systems. ",
    "url": "https://arxiv.org/abs/2311.17410",
    "authors": [
      "Yuchen Zhong",
      "Guangming Sheng",
      "Tianzuo Qin",
      "Minjie Wang",
      "Quan Gan",
      "Chuan Wu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17429",
    "title": "TARGET: Template-Transferable Backdoor Attack Against Prompt-based NLP  Models via GPT4",
    "abstract": "Prompt-based learning has been widely applied in many low-resource NLP tasks such as few-shot scenarios. However, this paradigm has been shown to be vulnerable to backdoor attacks. Most of the existing attack methods focus on inserting manually predefined templates as triggers in the pre-training phase to train the victim model and utilize the same triggers in the downstream task to perform inference, which tends to ignore the transferability and stealthiness of the templates. In this work, we propose a novel approach of TARGET (Template-trAnsfeRable backdoor attack aGainst prompt-basEd NLP models via GPT4), which is a data-independent attack method. Specifically, we first utilize GPT4 to reformulate manual templates to generate tone-strong and normal templates, and the former are injected into the model as a backdoor trigger in the pre-training phase. Then, we not only directly employ the above templates in the downstream task, but also use GPT4 to generate templates with similar tone to the above templates to carry out transferable attacks. Finally we have conducted extensive experiments on five NLP datasets and three BERT series models, with experimental results justifying that our TARGET method has better attack performance and stealthiness compared to the two-external baseline methods on direct attacks, and in addition achieves satisfactory attack capability in the unseen tone-similar templates. ",
    "url": "https://arxiv.org/abs/2311.17429",
    "authors": [
      "Zihao Tan",
      "Qingliang Chen",
      "Yongjian Huang",
      "Chen Liang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.17434",
    "title": "Group-wise Sparse and Explainable Adversarial Attacks",
    "abstract": "Sparse adversarial attacks fool deep neural networks (DNNs) through minimal pixel perturbations, typically regularized by the $\\ell_0$ norm. Recent efforts have replaced this norm with a structural sparsity regularizer, such as the nuclear group norm, to craft group-wise sparse adversarial attacks. The resulting perturbations are thus explainable and hold significant practical relevance, shedding light on an even greater vulnerability of DNNs than previously anticipated. However, crafting such attacks poses an optimization challenge, as it involves computing norms for groups of pixels within a non-convex objective. In this paper, we tackle this challenge by presenting an algorithm that simultaneously generates group-wise sparse attacks within semantically meaningful areas of an image. In each iteration, the core operation of our algorithm involves the optimization of a quasinorm adversarial loss. This optimization is achieved by employing the $1/2$-quasinorm proximal operator for some iterations, a method tailored for nonconvex programming. Subsequently, the algorithm transitions to a projected Nesterov's accelerated gradient descent with $2$-norm regularization applied to perturbation magnitudes. We rigorously evaluate the efficacy of our novel attack in both targeted and non-targeted attack scenarios, on CIFAR-10 and ImageNet datasets. When compared to state-of-the-art methods, our attack consistently results in a remarkable increase in group-wise sparsity, e.g., an increase of $48.12\\%$ on CIFAR-10 and $40.78\\%$ on ImageNet (average case, targeted attack), all while maintaining lower perturbation magnitudes. Notably, this performance is complemented by a significantly faster computation time and a $100\\%$ attack success rate. ",
    "url": "https://arxiv.org/abs/2311.17434",
    "authors": [
      "Shpresim Sadiku",
      "Moritz Wagner",
      "Sebastian Pokutta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2311.17449",
    "title": "Weakly-semi-supervised object detection in remotely sensed imagery",
    "abstract": "Deep learning for detecting objects in remotely sensed imagery can enable new technologies for important applications including mitigating climate change. However, these models often require large datasets labeled with bounding box annotations which are expensive to curate, prohibiting the development of models for new tasks and geographies. To address this challenge, we develop weakly-semi-supervised object detection (WSSOD) models on remotely sensed imagery which can leverage a small amount of bounding boxes together with a large amount of point labels that are easy to acquire at scale in geospatial data. We train WSSOD models which use large amounts of point-labeled images with varying fractions of bounding box labeled images in FAIR1M and a wind turbine detection dataset, and demonstrate that they substantially outperform fully supervised models trained with the same amount of bounding box labeled images on both datasets. Furthermore, we find that the WSSOD models trained with 2-10x fewer bounding box labeled images can perform similarly to or outperform fully supervised models trained on the full set of bounding-box labeled images. We believe that the approach can be extended to other remote sensing tasks to reduce reliance on bounding box labels and increase development of models for impactful applications. ",
    "url": "https://arxiv.org/abs/2311.17449",
    "authors": [
      "Ji Hun Wang",
      "Jeremy Irvin",
      "Beri Kohen Behar",
      "Ha Tran",
      "Raghav Samavedam",
      "Quentin Hsu",
      "Andrew Y. Ng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17451",
    "title": "Wireless Network Digital Twin for 6G: Generative AI as A Key Enabler",
    "abstract": "Digital twin, which enables emulation, evaluation, and optimization of physical entities through synchronized digital replicas, has gained increasingly attention as a promising technology for intricate wireless networks. For 6G, numerous innovative wireless technologies and network architectures have posed new challenges in establishing wireless network digital twins. To tackle these challenges, artificial intelligence (AI), particularly the flourishing generative AI, emerges as a potential solution. In this article, we discuss emerging prerequisites for wireless network digital twins considering the complicated network architecture, tremendous network scale, extensive coverage, and diversified application scenarios in the 6G era. We further explore the applications of generative AI, such as transformer and diffusion model, to empower the 6G digital twin from multiple perspectives including implementation, physical-digital synchronization, and slicing capability. Subsequently, we propose a hierarchical generative AI-enabled wireless network digital twin at both the message-level and policy-level, and provide a typical use case with numerical results to validate the effectiveness and efficiency. Finally, open research issues for wireless network digital twins in the 6G era are discussed. ",
    "url": "https://arxiv.org/abs/2311.17451",
    "authors": [
      "Zhenyu Tao",
      "Wei Xu",
      "Yongming Huang",
      "Xiaoyun Wang",
      "Xiaohu You"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17453",
    "title": "Privacy Measurement in Tabular Synthetic Data: State of the Art and  Future Research Directions",
    "abstract": "Synthetic data (SD) have garnered attention as a privacy enhancing technology. Unfortunately, there is no standard for quantifying their degree of privacy protection. In this paper, we discuss proposed quantification approaches. This contributes to the development of SD privacy standards; stimulates multi-disciplinary discussion; and helps SD researchers make informed modeling and evaluation decisions. ",
    "url": "https://arxiv.org/abs/2311.17453",
    "authors": [
      "Alexander Boudewijn",
      "Andrea Filippo Ferraris",
      "Daniele Panfilo",
      "Vanessa Cocca",
      "Sabrina Zinutti",
      "Karel De Schepper",
      "Carlo Rossi Chauvenet"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.17456",
    "title": "DifFlow3D: Toward Robust Uncertainty-Aware Scene Flow Estimation with  Diffusion Model",
    "abstract": "Scene flow estimation, which aims to predict per-point 3D displacements of dynamic scenes, is a fundamental task in the computer vision field. However, previous works commonly suffer from unreliable correlation caused by locally constrained searching ranges, and struggle with accumulated inaccuracy arising from the coarse-to-fine structure. To alleviate these problems, we propose a novel uncertainty-aware scene flow estimation network (DifFlow3D) with the diffusion probabilistic model. Iterative diffusion-based refinement is designed to enhance the correlation robustness and resilience to challenging cases, e.g., dynamics, noisy inputs, repetitive patterns, etc. To restrain the generation diversity, three key flow-related features are leveraged as conditions in our diffusion model. Furthermore, we also develop an uncertainty estimation module within diffusion to evaluate the reliability of estimated scene flow. Our DifFlow3D achieves state-of-the-art performance, with 6.7\\% and 19.1\\% EPE3D reduction respectively on FlyingThings3D and KITTI 2015 datasets. Notably, our method achieves an unprecedented millimeter-level accuracy (0.0089m in EPE3D) on the KITTI dataset. Additionally, our diffusion-based refinement paradigm can be readily integrated as a plug-and-play module into existing scene flow networks, significantly increasing their estimation accuracy. Codes will be released later. ",
    "url": "https://arxiv.org/abs/2311.17456",
    "authors": [
      "Jiuming Liu",
      "Guangming Wang",
      "Weicai Ye",
      "Chaokang Jiang",
      "Jinru Han",
      "Zhe Liu",
      "Guofeng Zhang",
      "Dalong Du",
      "Hesheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17473",
    "title": "Exploring Multi-Reader Buffers and Channel Placement during Dataflow  Network Mapping to Heterogeneous Many-core Systems",
    "abstract": "This paper presents an approach for reducing the memory requirements of dataflow applications, while minimizing the execution period when deployed on a many-core target. Often, straightforward implementations of dataflow applications suffer from data duplication if identical data has to be processed by multiple actors. In fact, multi-cast actors can produce huge memory overheads when storing and communicating copies of the same data. As a remedy, so-called Multi-Reader Buffers (MRBs) can be utilized to forward identical data to multiple actors in a FIFO manner while storing each data item only once. However, MRBs may increase the achievable period due to communication contention when accessing the shared data. A novel multi-objective design space exploration approach is proposed that selectively replaces multi-cast actors with MRBs and explores actor and FIFO channel mappings to find trade-offs between the objectives of period, memory footprint, and core cost. Our approach considers (i) memory-size constraints, (ii) hierarchical memories to implement the buffers, (iii) supports heterogeneous many-core platforms, and (iv) optimizes the buffer placement and overall scheduling to minimize the execution period by proposing a novel combined actor and communications scheduling heuristic for period minimization called CAPS-HMS. Our results show that the explored Pareto fronts improve a hypervolume indicator over a reference approach by up to 66 % for small to mid-size applications and 90 % for large applications. Moreover, selectively replacing multi-cast actors with corresponding MRBs proves to be always superior to never or always replacing them. Finally, it is shown that the quality of the explored Pareto fronts does not degrade when replacing the efficient scheduling heuristic CAPS-HMS by an exact integer linear programming (ILP) solver. ",
    "url": "https://arxiv.org/abs/2311.17473",
    "authors": [
      "Martin Letras",
      "Joachim Falk",
      "J\u00fcrgen Teich"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.17479",
    "title": "CrimeGNN: Harnessing the Power of Graph Neural Networks for Community  Detection in Criminal Networks",
    "abstract": "In this paper, we introduce CrimeGNN, a novel application of Graph Neural Networks (GNNs) specifically designed to uncover hidden communities within criminal networks. As criminal activities increasingly rely on complex network structures, traditional methods of network analysis often fall short in detecting the intricate and dynamic communities within these networks. Leveraging the power of GNNs, CrimeGNN provides an advanced and specialized solution to this problem. The model ingests a graph structure of a criminal network, where vertices represent individuals and edges represent relationships between them. CrimeGNN aims to identify a partition of the vertex set, such that each subset represents a distinct community within the network, maximizing the modularity function. Experimental results on several benchmark datasets demonstrate the effectiveness of CrimeGNN, outperforming existing methods in terms of both accuracy and computational efficiency. The proposed framework offers significant potential for aiding law enforcement agencies in proactive policing and crime prevention measures by providing a more in-depth understanding of the structure and operation of criminal networks. ",
    "url": "https://arxiv.org/abs/2311.17479",
    "authors": [
      "Chen Yang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.17491",
    "title": "Spherical Frustum Sparse Convolution Network for LiDAR Point Cloud  Semantic Segmentation",
    "abstract": "LiDAR point cloud semantic segmentation enables the robots to obtain fine-grained semantic information of the surrounding environment. Recently, many works project the point cloud onto the 2D image and adopt the 2D Convolutional Neural Networks (CNNs) or vision transformer for LiDAR point cloud semantic segmentation. However, since more than one point can be projected onto the same 2D position but only one point can be preserved, the previous 2D image-based segmentation methods suffer from inevitable quantized information loss. To avoid quantized information loss, in this paper, we propose a novel spherical frustum structure. The points projected onto the same 2D position are preserved in the spherical frustums. Moreover, we propose a memory-efficient hash-based representation of spherical frustums. Through the hash-based representation, we propose the Spherical Frustum sparse Convolution (SFC) and Frustum Fast Point Sampling (F2PS) to convolve and sample the points stored in spherical frustums respectively. Finally, we present the Spherical Frustum sparse Convolution Network (SFCNet) to adopt 2D CNNs for LiDAR point cloud semantic segmentation without quantized information loss. Extensive experiments on the SemanticKITTI and nuScenes datasets demonstrate that our SFCNet outperforms the 2D image-based semantic segmentation methods based on conventional spherical projection. The source code will be released later. ",
    "url": "https://arxiv.org/abs/2311.17491",
    "authors": [
      "Yu Zheng",
      "Guangming Wang",
      "Jiuming Liu",
      "Marc Pollefeys",
      "Hesheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17493",
    "title": "Towards Higher Ranks via Adversarial Weight Pruning",
    "abstract": "Convolutional Neural Networks (CNNs) are hard to deploy on edge devices due to its high computation and storage complexities. As a common practice for model compression, network pruning consists of two major categories: unstructured and structured pruning, where unstructured pruning constantly performs better. However, unstructured pruning presents a structured pattern at high pruning rates, which limits its performance. To this end, we propose a Rank-based PruninG (RPG) method to maintain the ranks of sparse weights in an adversarial manner. In each step, we minimize the low-rank approximation error for the weight matrices using singular value decomposition, and maximize their distance by pushing the weight matrices away from its low rank approximation. This rank-based optimization objective guides sparse weights towards a high-rank topology. The proposed method is conducted in a gradual pruning fashion to stabilize the change of rank during training. Experimental results on various datasets and different tasks demonstrate the effectiveness of our algorithm in high sparsity. The proposed RPG outperforms the state-of-the-art performance by 1.13% top-1 accuracy on ImageNet in ResNet-50 with 98% sparsity. The codes are available at https://github.com/huawei-noah/Efficient-Computing/tree/master/Pruning/RPG and https://gitee.com/mindspore/models/tree/master/research/cv/RPG. ",
    "url": "https://arxiv.org/abs/2311.17493",
    "authors": [
      "Yuchuan Tian",
      "Hanting Chen",
      "Tianyu Guo",
      "Chao Xu",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17502",
    "title": "Enhancing Answer Selection in Community Question Answering with  Pre-trained and Large Language Models",
    "abstract": "Community Question Answering (CQA) becomes increasingly prevalent in recent years. However, there are a large number of answers, which is difficult for users to select the relevant answers. Therefore, answer selection is a very significant subtask of CQA. In this paper, we first propose the Question-Answer cross attention networks (QAN) with pre-trained models for answer selection and utilize large language model (LLM) to perform answer selection with knowledge augmentation. Specifically, we apply the BERT model as the encoder layer to do pre-training for question subjects, question bodies and answers, respectively, then the cross attention mechanism selects the most relevant answer for different questions. Experiments show that the QAN model achieves state-of-the-art performance on two datasets, SemEval2015 and SemEval2017. Moreover, we use the LLM to generate external knowledge from questions and correct answers to achieve knowledge augmentation for the answer selection task by LLM, while optimizing the prompt of LLM in different aspects. The results show that the introduction of external knowledge can improve the correct answer selection rate of LLM on datasets SemEval2015 and SemEval2017. Meanwhile, LLM can also select the correct answer on more questions by optimized prompt. ",
    "url": "https://arxiv.org/abs/2311.17502",
    "authors": [
      "Xinghang Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2311.17504",
    "title": "PViT-6D: Overclocking Vision Transformers for 6D Pose Estimation with  Confidence-Level Prediction and Pose Tokens",
    "abstract": "In the current state of 6D pose estimation, top-performing techniques depend on complex intermediate correspondences, specialized architectures, and non-end-to-end algorithms. In contrast, our research reframes the problem as a straightforward regression task by exploring the capabilities of Vision Transformers for direct 6D pose estimation through a tailored use of classification tokens. We also introduce a simple method for determining pose confidence, which can be readily integrated into most 6D pose estimation frameworks. This involves modifying the transformer architecture by decreasing the number of query elements based on the network's assessment of the scene complexity. Our method that we call Pose Vision Transformer or PViT-6D provides the benefits of simple implementation and being end-to-end learnable while outperforming current state-of-the-art methods by +0.3% ADD(-S) on Linemod-Occlusion and +2.7% ADD(-S) on the YCB-V dataset. Moreover, our method enhances both the model's interpretability and the reliability of its performance during inference. ",
    "url": "https://arxiv.org/abs/2311.17504",
    "authors": [
      "Sebastian Stapf",
      "Tobias Bauernfeind",
      "Marco Riboldi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17508",
    "title": "Model Performance Prediction for Hyperparameter Optimization of Deep  Learning Models Using High Performance Computing and Quantum Annealing",
    "abstract": "Hyperparameter Optimization (HPO) of Deep Learning-based models tends to be a compute resource intensive process as it usually requires to train the target model with many different hyperparameter configurations. We show that integrating model performance prediction with early stopping methods holds great potential to speed up the HPO process of deep learning models. Moreover, we propose a novel algorithm called Swift-Hyperband that can use either classical or quantum support vector regression for performance prediction and benefit from distributed High Performance Computing environments. This algorithm is tested not only for the Machine-Learned Particle Flow model used in High Energy Physics, but also for a wider range of target models from domains such as computer vision and natural language processing. Swift-Hyperband is shown to find comparable (or better) hyperparameters as well as using less computational resources in all test cases. ",
    "url": "https://arxiv.org/abs/2311.17508",
    "authors": [
      "Juan Pablo Garc\u00eda Amboage",
      "Eric Wulff",
      "Maria Girone",
      "Tom\u00e1s F. Pena"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2311.17516",
    "title": "MMA-Diffusion: MultiModal Attack on Diffusion Models",
    "abstract": "In recent years, Text-to-Image (T2I) models have seen remarkable advancements, gaining widespread adoption. However, this progress has inadvertently opened avenues for potential misuse, particularly in generating inappropriate or Not-Safe-For-Work (NSFW) content. Our work introduces MMA-Diffusion, a framework that presents a significant and realistic threat to the security of T2I models by effectively circumventing current defensive measures in both open-source models and commercial online services. Unlike previous approaches, MMA-Diffusion leverages both textual and visual modalities to bypass safeguards like prompt filters and post-hoc safety checkers, thus exposing and highlighting the vulnerabilities in existing defense mechanisms. ",
    "url": "https://arxiv.org/abs/2311.17516",
    "authors": [
      "Yijun Yang",
      "Ruiyuan Gao",
      "Xiaosen Wang",
      "Nan Xu",
      "Qiang Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17552",
    "title": "An Efficient Illumination Invariant Tiger Detection Framework for  Wildlife Surveillance",
    "abstract": "Tiger conservation necessitates the strategic deployment of multifaceted initiatives encompassing the preservation of ecological habitats, anti-poaching measures, and community involvement for sustainable growth in the tiger population. With the advent of artificial intelligence, tiger surveillance can be automated using object detection. In this paper, an accurate illumination invariant framework is proposed based on EnlightenGAN and YOLOv8 for tiger detection. The fine-tuned YOLOv8 model achieves a mAP score of 61% without illumination enhancement. The illumination enhancement improves the mAP by 0.7%. The approaches elevate the state-of-the-art performance on the ATRW dataset by approximately 6% to 7%. ",
    "url": "https://arxiv.org/abs/2311.17552",
    "authors": [
      "Gaurav Pendharkar",
      "A.Ancy Micheal",
      "Jason Misquitta",
      "Ranjeesh Kaippada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17567",
    "title": "Network characteristics of financial networks",
    "abstract": "We embrace a fresh perspective to auditing by analyzing a large set of companies as complex financial networks rather than static aggregates of balance sheet data. Preliminary analyses show that network centrality measures within these networks could significantly enhance auditors' insights into financial structures. Utilizing data from over 300 diverse companies, we examine the structure of financial statement networks through bipartite graph analysis, exploring their scale-freeness by comparing degree distributions to power-law and exponential models. Our findings indicate heavy-tailed degree distribution for financial account nodes, networks that grow with the same diameter, and the presence of influential hubs. This study lays the groundwork for future auditing methodologies where baseline network statistics could serve as indicators for anomaly detection, marking a substantial advancement in audit research and network science. ",
    "url": "https://arxiv.org/abs/2311.17567",
    "authors": [
      "M. Boersma",
      "S. Sourabh",
      "L.A. Hoogduin",
      "D. Kandhai"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2311.17571",
    "title": "LGFCTR: Local and Global Feature Convolutional Transformer for Image  Matching",
    "abstract": "Image matching that finding robust and accurate correspondences across images is a challenging task under extreme conditions. Capturing local and global features simultaneously is an important way to mitigate such an issue but recent transformer-based decoders were still stuck in the issues that CNN-based encoders only extract local features and the transformers lack locality. Inspired by the locality and implicit positional encoding of convolutions, a novel convolutional transformer is proposed to capture both local contexts and global structures more sufficiently for detector-free matching. Firstly, a universal FPN-like framework captures global structures in self-encoder as well as cross-decoder by transformers and compensates local contexts as well as implicit positional encoding by convolutions. Secondly, a novel convolutional transformer module explores multi-scale long range dependencies by a novel multi-scale attention and further aggregates local information inside dependencies for enhancing locality. Finally, a novel regression-based sub-pixel refinement module exploits the whole fine-grained window features for fine-level positional deviation regression. The proposed method achieves superior performances on a wide range of benchmarks. The code will be available on https://github.com/zwh0527/LGFCTR. ",
    "url": "https://arxiv.org/abs/2311.17571",
    "authors": [
      "Wenhao Zhong",
      "Jie Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17583",
    "title": "CLIPC8: Face liveness detection algorithm based on image-text pairs and  contrastive learning",
    "abstract": "Face recognition technology is widely used in the financial field, and various types of liveness attack behaviors need to be addressed. Existing liveness detection algorithms are trained on specific training datasets and tested on testing datasets, but their performance and robustness in transferring to unseen datasets are relatively poor. To tackle this issue, we propose a face liveness detection method based on image-text pairs and contrastive learning, dividing liveness attack problems in the financial field into eight categories and using text information to describe the images of these eight types of attacks. The text encoder and image encoder are used to extract feature vector representations for the classification description text and face images, respectively. By maximizing the similarity of positive samples and minimizing the similarity of negative samples, the model learns shared representations between images and texts. The proposed method is capable of effectively detecting specific liveness attack behaviors in certain scenarios, such as those occurring in dark environments or involving the tampering of ID card photos. Additionally, it is also effective in detecting traditional liveness attack methods, such as printing photo attacks and screen remake attacks. The zero-shot capabilities of face liveness detection on five public datasets, including NUAA, CASIA-FASD, Replay-Attack, OULU-NPU and MSU-MFSD also reaches the level of commercial algorithms. The detection capability of proposed algorithm was verified on 5 types of testing datasets, and the results show that the method outperformed commercial algorithms, and the detection rates reached 100% on multiple datasets. Demonstrating the effectiveness and robustness of introducing image-text pairs and contrastive learning into liveness detection tasks as proposed in this paper. ",
    "url": "https://arxiv.org/abs/2311.17583",
    "authors": [
      "Xu Liu",
      "Shu Zhou",
      "Yurong Song",
      "Wenzhe Luo",
      "Xin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17587",
    "title": "Deep Reinforcement Learning Graphs: Feedback Motion Planning via Neural  Lyapunov Verification",
    "abstract": "Recent advancements in model-free deep reinforcement learning have enabled efficient agent training. However, challenges arise when determining the region of attraction for these controllers, especially if the region does not fully cover the desired area. This paper addresses this issue by introducing a feedback motion control algorithm that utilizes data-driven techniques and neural networks. The algorithm constructs a graph of connected reinforcement-learning based controllers, each with its own defined region of attraction. This incremental approach effectively covers a bounded region of interest, creating a trajectory of interconnected nodes that guide the system from an initial state to the goal. Two approaches are presented for connecting nodes within the algorithm. The first is a tree-structured method, facilitating \"point-to-point\" control by constructing a tree connecting the initial state to the goal state. The second is a graph-structured method, enabling \"space-to-space\" control by building a graph within a bounded region. This approach allows for control from arbitrary initial and goal states. The proposed method's performance is evaluated on a first-order dynamic system, considering scenarios both with and without obstacles. The results demonstrate the effectiveness of the proposed algorithm in achieving the desired control objectives. ",
    "url": "https://arxiv.org/abs/2311.17587",
    "authors": [
      "Armin Ghanbarzadeh",
      "Esmaeil Najafi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.17592",
    "title": "Robust Correlated Equilibrium: Definition and Computation",
    "abstract": "We study N-player finite games with costs perturbed due to time-varying disturbances in the underlying system and to that end we propose the concept of Robust Correlated Equilibrium that generalizes the definition of Correlated Equilibrium. Conditions under which the Robust Correlated Equilibrium exists are specified and a decentralized algorithm for learning strategies that are optimal in the sense of Robust Correlated Equilibrium is proposed. The primary contribution of the paper is the convergence analysis of the algorithm and to that end, we propose an extension of the celebrated Blackwell's Approachability theorem to games with costs that are not just time-average as in the original Blackwell's Approachability Theorem but also include time-average of previous algorithm iterates. The designed algorithm is applied to a practical water distribution network with pumps being the controllers and their costs being perturbed by uncertain consumption by consumers. Simulation results show that each controller achieves no regret and empirical distributions converge to the Robust Correlated Equilibrium. ",
    "url": "https://arxiv.org/abs/2311.17592",
    "authors": [
      "Rahul Misra",
      "Rafa\u0142 Wisniewski",
      "Carsten Skovmose Kalles\u00f8e",
      "Manuela L. Bujorianu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2311.17597",
    "title": "Continual Self-supervised Learning: Towards Universal Multi-modal  Medical Data Representation Learning",
    "abstract": "Self-supervised learning is an efficient pre-training method for medical image analysis. However, current research is mostly confined to specific-modality data pre-training, consuming considerable time and resources without achieving universality across different modalities. A straightforward solution is combining all modality data for joint self-supervised pre-training, which poses practical challenges. Firstly, our experiments reveal conflicts in representation learning as the number of modalities increases. Secondly, multi-modal data collected in advance cannot cover all real-world scenarios. In this paper, we reconsider versatile self-supervised learning from the perspective of continual learning and propose MedCoSS, a continuous self-supervised learning approach for multi-modal medical data. Unlike joint self-supervised learning, MedCoSS assigns different modality data to different training stages, forming a multi-stage pre-training process. To balance modal conflicts and prevent catastrophic forgetting, we propose a rehearsal-based continual learning method. We introduce the k-means sampling strategy to retain data from previous modalities and rehearse it when learning new modalities. Instead of executing the pretext task on buffer data, a feature distillation strategy and an intra-modal mixup strategy are applied to these data for knowledge retention. We conduct continuous self-supervised pre-training on a large-scale multi-modal unlabeled dataset, including clinical reports, X-rays, CT scans, MRI scans, and pathological images. Experimental results demonstrate MedCoSS's exceptional generalization ability across nine downstream datasets and its significant scalability in integrating new modality data. Code and pre-trained weight are available at https://github.com/yeerwen/MedCoSS. ",
    "url": "https://arxiv.org/abs/2311.17597",
    "authors": [
      "Yiwen Ye",
      "Yutong Xie",
      "Jianpeng Zhang",
      "Ziyang Chen",
      "Qi Wu",
      "Yong Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17598",
    "title": "Improving embedding of graphs with missing data by soft manifolds",
    "abstract": "Embedding graphs in continous spaces is a key factor in designing and developing algorithms for automatic information extraction to be applied in diverse tasks (e.g., learning, inferring, predicting). The reliability of graph embeddings directly depends on how much the geometry of the continuous space matches the graph structure. Manifolds are mathematical structure that can enable to incorporate in their topological spaces the graph characteristics, and in particular nodes distances. State-of-the-art of manifold-based graph embedding algorithms take advantage of the assumption that the projection on a tangential space of each point in the manifold (corresponding to a node in the graph) would locally resemble a Euclidean space. Although this condition helps in achieving efficient analytical solutions to the embedding problem, it does not represent an adequate set-up to work with modern real life graphs, that are characterized by weighted connections across nodes often computed over sparse datasets with missing records. In this work, we introduce a new class of manifold, named soft manifold, that can solve this situation. In particular, soft manifolds are mathematical structures with spherical symmetry where the tangent spaces to each point are hypocycloids whose shape is defined according to the velocity of information propagation across the data points. Using soft manifolds for graph embedding, we can provide continuous spaces to pursue any task in data analysis over complex datasets. Experimental results on reconstruction tasks on synthetic and real datasets show how the proposed approach enable more accurate and reliable characterization of graphs in continuous spaces with respect to the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2311.17598",
    "authors": [
      "Andrea Marinoni",
      "Pietro Lio'",
      "Alessandro Barp",
      "Christian Jutten",
      "Mark Girolami"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2311.17603",
    "title": "sec-certs: Examining the security certification practice for better  vulnerability mitigation",
    "abstract": "Products certified under security certification frameworks such as Common Criteria undergo significant scrutiny during the costly certification process. Yet, critical vulnerabilities, including private key recovery (ROCA, Minerva, TPM-Fail...), get discovered in certified products with high assurance levels. Furthermore, assessing which certified products are impacted by such vulnerabilities is complicated due to the large amount of unstructured certification-related data and unclear relationships between the certificates. To address these problems, we conducted a large-scale automated analysis of Common Criteria and FIPS 140 certificates. We trained unsupervised models to learn which vulnerabilities from NIST's National Vulnerability Database impact existing certified products and how certified products reference each other. Our tooling automates the analysis of tens of thousands of certification-related documents, extracting machine-readable features where manual analysis is unattainable. Further, we identify the security requirements that are associated with products being affected by fewer and less severe vulnerabilities (on average). This indicates which aspects of certification correlate with higher security. We demonstrate how our tool can be used for better vulnerability mitigation on four case studies of known, high-profile vulnerabilities. All tools and continuously updated results are available at https://seccerts.org. ",
    "url": "https://arxiv.org/abs/2311.17603",
    "authors": [
      "Adam Janovsky",
      "Jan Jancar",
      "Petr Svenda",
      "\u0141ukasz Chmielewski",
      "Jiri Michalik",
      "Vashek Matyas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.17607",
    "title": "Topology-Preserving Adversarial Training",
    "abstract": "Despite the effectiveness in improving the robustness of neural networks, adversarial training has suffered from the natural accuracy degradation problem, i.e., accuracy on natural samples has reduced significantly. In this study, we reveal that natural accuracy degradation is highly related to the disruption of the natural sample topology in the representation space by quantitative and qualitative experiments. Based on this observation, we propose Topology-pReserving Adversarial traINing (TRAIN) to alleviate the problem by preserving the topology structure of natural samples from a standard model trained only on natural samples during adversarial training. As an additional regularization, our method can easily be combined with various popular adversarial training algorithms in a plug-and-play manner, taking advantage of both sides. Extensive experiments on CIFAR-10, CIFAR-100, and Tiny ImageNet show that our proposed method achieves consistent and significant improvements over various strong baselines in most cases. Specifically, without additional data, our proposed method achieves up to 8.78% improvement in natural accuracy and 4.50% improvement in robust accuracy. ",
    "url": "https://arxiv.org/abs/2311.17607",
    "authors": [
      "Xiaoyue Mi",
      "Fan Tang",
      "Yepeng Weng",
      "Danding Wang",
      "Juan Cao",
      "Sheng Tang",
      "Peng Li",
      "Yang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17608",
    "title": "Adversarial Robust Memory-Based Continual Learner",
    "abstract": "Despite the remarkable advances that have been made in continual learning, the adversarial vulnerability of such methods has not been fully discussed. We delve into the adversarial robustness of memory-based continual learning algorithms and observe limited robustness improvement by directly applying adversarial training techniques. Preliminary studies reveal the twin challenges for building adversarial robust continual learners: accelerated forgetting in continual learning and gradient obfuscation in adversarial robustness. In this study, we put forward a novel adversarial robust memory-based continual learner that adjusts data logits to mitigate the forgetting of pasts caused by adversarial samples. Furthermore, we devise a gradient-based data selection mechanism to overcome the gradient obfuscation caused by limited stored data. The proposed approach can widely integrate with existing memory-based continual learning as well as adversarial training algorithms in a plug-and-play way. Extensive experiments on Split-CIFAR10/100 and Split-Tiny-ImageNet demonstrate the effectiveness of our approach, achieving up to 8.13% higher accuracy for adversarial data. ",
    "url": "https://arxiv.org/abs/2311.17608",
    "authors": [
      "Xiaoyue Mi",
      "Fan Tang",
      "Zonghan Yang",
      "Danding Wang",
      "Juan Cao",
      "Peng Li",
      "Yang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17626",
    "title": "Focus on Query: Adversarial Mining Transformer for Few-Shot Segmentation",
    "abstract": "Few-shot segmentation (FSS) aims to segment objects of new categories given only a handful of annotated samples. Previous works focus their efforts on exploring the support information while paying less attention to the mining of the critical query branch. In this paper, we rethink the importance of support information and propose a new query-centric FSS model Adversarial Mining Transformer (AMFormer), which achieves accurate query image segmentation with only rough support guidance or even weak support labels. The proposed AMFormer enjoys several merits. First, we design an object mining transformer (G) that can achieve the expansion of incomplete region activated by support clue, and a detail mining transformer (D) to discriminate the detailed local difference between the expanded mask and the ground truth. Second, we propose to train G and D via an adversarial process, where G is optimized to generate more accurate masks approaching ground truth to fool D. We conduct extensive experiments on commonly used Pascal-5i and COCO-20i benchmarks and achieve state-of-the-art results across all settings. In addition, the decent performance with weak support labels in our query-centric paradigm may inspire the development of more general FSS models. Code will be available at https://github.com/Wyxdm/AMNet. ",
    "url": "https://arxiv.org/abs/2311.17626",
    "authors": [
      "Yuan Wang",
      "Naisong Luo",
      "Tianzhu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17629",
    "title": "Efficient Decoder for End-to-End Oriented Object Detection in Remote  Sensing Images",
    "abstract": "Object instances in remote sensing images often distribute with multi-orientations, varying scales, and dense distribution. These issues bring challenges to end-to-end oriented object detectors including multi-scale features alignment and a large number of queries. To address these limitations, we propose an end-to-end oriented detector equipped with an efficient decoder, which incorporates two technologies, Rotated RoI attention (RRoI attention) and Selective Distinct Queries (SDQ). Specifically, RRoI attention effectively focuses on oriented regions of interest through a cross-attention mechanism and aligns multi-scale features. SDQ collects queries from intermediate decoder layers and then filters similar queries to obtain distinct queries. The proposed SDQ can facilitate the optimization of one-to-one label assignment, without introducing redundant initial queries or extra auxiliary branches. Extensive experiments on five datasets demonstrate the effectiveness of our method. Notably, our method achieves state-of-the-art performance on DIOR-R (67.31% mAP), DOTA-v1.5 (67.43% mAP), and DOTA-v2.0 (53.28% mAP) with the ResNet50 backbone. ",
    "url": "https://arxiv.org/abs/2311.17629",
    "authors": [
      "Jiaqi Zhao",
      "Zeyu Ding",
      "Yong Zhou",
      "Hancheng Zhu",
      "Wenliang Du",
      "Rui Yao",
      "Abdulmotaleb El Saddik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17631",
    "title": "Q-learning Based Optimal False Data Injection Attack on Probabilistic  Boolean Control Networks",
    "abstract": "In this paper, we present a reinforcement learning (RL) method for solving optimal false data injection attack problems in probabilistic Boolean control networks (PBCNs) where the attacker lacks knowledge of the system model. Specifically, we employ a Q-learning (QL) algorithm to address this problem. We then propose an improved QL algorithm that not only enhances learning efficiency but also obtains optimal attack strategies for large-scale PBCNs that the standard QL algorithm cannot handle. Finally, we verify the effectiveness of our proposed approach by considering two attacked PBCNs, including a 10-node network and a 28-node network. ",
    "url": "https://arxiv.org/abs/2311.17631",
    "authors": [
      "Xianlun Peng",
      "Yang Tang",
      "Fangfei Li",
      "Yang Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17643",
    "title": "Neural Fields with Thermal Activations for Arbitrary-Scale  Super-Resolution",
    "abstract": "Recent approaches for arbitrary-scale single image super-resolution (ASSR) have used local neural fields to represent continuous signals that can be sampled at different rates. However, in such formulation, the point-wise query of field values does not naturally match the point spread function (PSF) of a given pixel. In this work we present a novel way to design neural fields such that points can be queried with a Gaussian PSF, which serves as anti-aliasing when moving across resolutions for ASSR. We achieve this using a novel activation function derived from Fourier theory and the heat equation. This comes at no additional cost: querying a point with a Gaussian PSF in our framework does not affect computational cost, unlike filtering in the image domain. Coupled with a hypernetwork, our method not only provides theoretically guaranteed anti-aliasing, but also sets a new bar for ASSR while also being more parameter-efficient than previous methods. ",
    "url": "https://arxiv.org/abs/2311.17643",
    "authors": [
      "Alexander Becker",
      "Rodrigo Caye Daudt",
      "Nando Metzger",
      "Jan Dirk Wegner",
      "Konrad Schindler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17655",
    "title": "Vulnerability of Automatic Identity Recognition to Audio-Visual  Deepfakes",
    "abstract": "The task of deepfakes detection is far from being solved by speech or vision researchers. Several publicly available databases of fake synthetic video and speech were built to aid the development of detection methods. However, existing databases typically focus on visual or voice modalities and provide no proof that their deepfakes can in fact impersonate any real person. In this paper, we present the first realistic audio-visual database of deepfakes SWAN-DF, where lips and speech are well synchronized and video have high visual and audio qualities. We took the publicly available SWAN dataset of real videos with different identities to create audio-visual deepfakes using several models from DeepFaceLab and blending techniques for face swapping and HiFiVC, DiffVC, YourTTS, and FreeVC models for voice conversion. From the publicly available speech dataset LibriTTS, we also created a separate database of only audio deepfakes LibriTTS-DF using several latest text to speech methods: YourTTS, Adaspeech, and TorToiSe. We demonstrate the vulnerability of a state of the art speaker recognition system, such as ECAPA-TDNN-based model from SpeechBrain, to the synthetic voices. Similarly, we tested face recognition system based on the MobileFaceNet architecture to several variants of our visual deepfakes. The vulnerability assessment show that by tuning the existing pretrained deepfake models to specific identities, one can successfully spoof the face and speaker recognition systems in more than 90% of the time and achieve a very realistic looking and sounding fake video of a given person. ",
    "url": "https://arxiv.org/abs/2311.17655",
    "authors": [
      "Pavel Korshunov",
      "Haolin Chen",
      "Philip N. Garner",
      "Sebastien Marcel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2311.17668",
    "title": "RACED: Routing in Payment Channel Networks Using Distributed Hash Tables",
    "abstract": "The Bitcoin scalability problem has led to the development of off-chain financial mechanisms such as payment channel networks (PCNs) which help users process transactions of varying amounts, including micro-payment transactions, without writing each transaction to the blockchain. Since PCNs only allow path-based transactions, effective, secure routing protocols that find a path between a sender and receiver are fundamental to PCN operations. In this paper, we propose RACED, a routing protocol that leverages the idea of Distributed Hash Tables (DHTs) to route transactions in PCNs in a fast and secure way. Our experiments on real-world transaction datasets show that RACED gives an average transaction success ratio of 98.74%, an average pathfinding time of 31.242 seconds, which is $1.65*10^3$, $1.8*10^3$, and $4*10^2$ times faster than three other recent routing protocols that offer comparable security/privacy properties. We rigorously analyze and prove the security of RACED in the Universal Composability framework. ",
    "url": "https://arxiv.org/abs/2311.17668",
    "authors": [
      "Kartick Kolachala",
      "Mohammed Ababneh",
      "Roopa Vishwanathan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.17676",
    "title": "Improving Minority Stress Detection with Emotions",
    "abstract": "Psychological stress detection is an important task for mental healthcare research, but there has been little prior work investigating the effectiveness of psychological stress models on minority individuals, who are especially vulnerable to poor mental health outcomes. In this work, we use the related task of minority stress detection to evaluate the ability of psychological stress models to understand the language of sexual and gender minorities. We find that traditional psychological stress models underperform on minority stress detection, and we propose using emotion-infused models to reduce that performance disparity. We further demonstrate that multi-task psychological stress models outperform the current state-of-the-art for minority stress detection without directly training on minority stress data. We provide explanatory analysis showing that minority communities have different distributions of emotions than the general population and that emotion-infused models improve the performance of stress models on underrepresented groups because of their effectiveness in low-data environments, and we propose that integrating emotions may benefit underrepresented groups in other mental health detection tasks. ",
    "url": "https://arxiv.org/abs/2311.17676",
    "authors": [
      "Jonathan Ivey",
      "Susan Gauch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.17684",
    "title": "Who can help me? Reconstructing users' psychological journeys in  depression-related social media interactions",
    "abstract": "Social media are increasingly being used as self-help boards, where individuals can disclose personal experiences and feelings and look for support from peers or experts. Here we investigate several popular mental health-related Reddit boards about depression while proposing a novel psycho-social framework. We reconstruct users' psychological/linguistic profiles together with their social interactions. We cover a total of 303,016 users, engaging in 378,483 posts and 1,475,044 comments from 01/05/2018 to 01/05/2020. After identifying a network of users' interactions, e.g., who replied to whom, we open an unprecedented window over psycholinguistic, cognitive, and affective digital traces with relevance for mental health research. Through user-generated content, we identify four categories or archetypes of users in agreement with the Patient Health Engagement model: the emotionally turbulent/under blackout, the aroused, the adherent-yet-conflicted, and the eudaimonically hopeful. Analyzing users' transitions over time through conditional Markov processes, we show how these four archetypes are not consecutive stages. We do not find a linear progression or sequential patient journey, where users evolve from struggling to serenity through feelings of conflict. Instead, we find online users to follow spirals towards both negative and positive archetypal stages. Through psychological/linguistic and social network modelling, we can provide compelling quantitative pieces of evidence on how such a complex path unfolds through positive, negative, and conflicting online contexts. Our approach opens the way to data-informed understandings of psychological coping with mental health issues through social media. ",
    "url": "https://arxiv.org/abs/2311.17684",
    "authors": [
      "Virginia Morini",
      "Salvatore Citraro",
      "Elena Sajno",
      "Maria Sansoni",
      "Giuseppe Riva",
      "Massimo Stella",
      "Giulio Rossetti"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2311.17697",
    "title": "Swarm Synergy: A Silent Way of Forming Community",
    "abstract": "In this paper, we introduce a novel swarm application, swarm synergy, where robots in a swarm intend to form communities. Each robot is considered to make independent decisions without any communication capability (silent agent). The proposed algorithm is based on parameters local to individual robots. Engaging scenarios are studied where the silent robots form communities without the preset conditions on the number of communities, community size, goal location of each community, and specific members in the community. Our approach allows silent robots to achieve this self-organized swarm behavior using only sensory inputs from the environment. The algorithm facilitates the formation of multiple swarm communities at arbitrary locations with unspecified goal locations. We further infer the behavior of swarm synergy to ensure the anonymity/untraceability of both robots and communities. The robots intend to form a community by sensing the neighbors, creating synergy in a bounded environment. The time to achieve synergy depends on the environment boundary and the onboard sensor's field of view. Compared to the state-of-art with similar objectives, the proposed communication-free swarm synergy shows comparative time to synergize with untraceability features. ",
    "url": "https://arxiv.org/abs/2311.17697",
    "authors": [
      "Sweksha Jain",
      "Rugved Katole",
      "Leena Vachhani"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2311.17705",
    "title": "Q-PAC: Automated Detection of Quantum Bug-Fix Patterns",
    "abstract": "Context: Bug-fix pattern detection has been investigated in the past in the context of classical software. However, while quantum software is developing rapidly, the literature still lacks automated methods and tools to identify, analyze, and detect bug-fix patterns. To the best of our knowledge, our work previously published in SEKE'23 was the first to leverage classical techniques to detect bug-fix patterns in quantum code. Objective: To extend our previous effort, we present a research agenda (Q-Repair), including a series of testing and debugging methodologies, to improve the quality of quantum software. The ultimate goal is to utilize machine learning techniques to automatically predict fix patterns for existing quantum bugs. Method: As part of the first stage of the agenda, we extend our initial study and propose a more comprehensive automated framework, called Q-PAC, for detecting bug-fix patterns in IBM Qiskit quantum code. In the framework, we develop seven bug-fix pattern detectors using abstract syntax trees, syntactic filters, and semantic checks. Results: To demonstrate our method, we run Q-PAC on a variety of quantum bug-fix patterns using both real-world and handcrafted examples of bugs and fixes. The experimental results show that Q-PAC can effectively identify bug-fix patterns in IBM Qiskit. Conclusion: We hope our initial study on quantum bug-fix detection can bring awareness of quantum software engineering to both researchers and practitioners. Thus, we also publish Q-PAC as an open-source software on GitHub. We would like to encourage other researchers to work on research directions (such as Q-Repair) to improve the quality of the quantum programming. ",
    "url": "https://arxiv.org/abs/2311.17705",
    "authors": [
      "Pranav K. Nayak",
      "Krishn V. Kher",
      "M. Bharat Chandra",
      "M. V. Panduranga Rao",
      "Lei Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2311.17722",
    "title": "SenTest: Evaluating Robustness of Sentence Encoders",
    "abstract": "Contrastive learning has proven to be an effective method for pre-training models using weakly labeled data in the vision domain. Sentence transformers are the NLP counterparts to this architecture, and have been growing in popularity due to their rich and effective sentence representations. Having effective sentence representations is paramount in multiple tasks, such as information retrieval, retrieval augmented generation (RAG), and sentence comparison. Keeping in mind the deployability factor of transformers, evaluating the robustness of sentence transformers is of utmost importance. This work focuses on evaluating the robustness of the sentence encoders. We employ several adversarial attacks to evaluate its robustness. This system uses character-level attacks in the form of random character substitution, word-level attacks in the form of synonym replacement, and sentence-level attacks in the form of intra-sentence word order shuffling. The results of the experiments strongly undermine the robustness of sentence encoders. The models produce significantly different predictions as well as embeddings on perturbed datasets. The accuracy of the models can fall up to 15 percent on perturbed datasets as compared to unperturbed datasets. Furthermore, the experiments demonstrate that these embeddings does capture the semantic and syntactic structure (sentence order) of sentences. However, existing supervised classification strategies fail to leverage this information, and merely function as n-gram detectors. ",
    "url": "https://arxiv.org/abs/2311.17722",
    "authors": [
      "Tanmay Chavan",
      "Shantanu Patankar",
      "Aditya Kane",
      "Omkar Gokhale",
      "Geetanjali Kale",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17742",
    "title": "Robust Localization and Tracking of UAVs in OTFS-based Networks",
    "abstract": "We consider the problem of accurately localizing N unmanned aerial vehicles (UAV) in 3D space where the UAVs are part of a swarm and communicate with each other through orthogonal time-frequency space (OTFS) modulated signals. Each receiving UAV estimates the multipath wireless channel on each link formed by the line-of-sight (LoS) transmission and by the single reflections from the remaining N-2 UAVs. The estimated power delay profiles are communicated to an edge server, which is in charge of computing the exact location and speed of the UAVs. To obtain the UAVs locations and velocities, we propose an iterative algorithm, named Turbo Iterative Positioning (TIP), which, using a belief-propagation approach, effectively exploits the time difference of arrival (TDoA) measurements between the LoS and the non-LoS paths. Enabling a full cold start (no prior knowledge), our solution first maps each TDoA's profile element to a specific ID of the reflecting UAV's. The Doppler shifts measured by the OTFS receivers associated with each path are also used to estimate the UAV's velocities. The localization of the N UAVs is then derived via gradient descent optimization, with the aid of turbo-like iterations that can progressively correct some of the residual errors in the initial ID mapping operation. Our numerical results, obtained also using real-world traces, show how the multipath links are beneficial to achieving very accurate localization and speed of all UAVs, even with a limited delay-Doppler resolution. Robustness of our scheme is proven by its performance approaching the Cramer-Rao bound. ",
    "url": "https://arxiv.org/abs/2311.17742",
    "authors": [
      "Alessandro Nordio",
      "Carla Fabiana Chiasserini",
      "Emanuele Viterbo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2311.17750",
    "title": "Addressing Membership Inference Attack in Federated Learning with Model  Compression",
    "abstract": "Federated Learning (FL) has been proposed as a privacy-preserving solution for machine learning. However, recent works have shown that Federated Learning can leak private client data through membership attacks. In this paper, we show that the effectiveness of these attacks on the clients negatively correlates with the size of the client datasets and model complexity. Based on this finding, we propose model-agnostic Federated Learning as a privacy-enhancing solution because it enables the use of models of varying complexity in the clients. To this end, we present $\\texttt{MaPP-FL}$, a novel privacy-aware FL approach that leverages model compression on the clients while keeping a full model on the server. We compare the performance of $\\texttt{MaPP-FL}$ against state-of-the-art model-agnostic FL methods on the CIFAR-10, CIFAR-100, and FEMNIST vision datasets. Our experiments show the effectiveness of $\\texttt{MaPP-FL}$ in preserving the clients' and the server's privacy while achieving competitive classification accuracies. ",
    "url": "https://arxiv.org/abs/2311.17750",
    "authors": [
      "Gergely D\u00e1niel N\u00e9meth",
      "Miguel \u00c1ngel Lozano",
      "Novi Quadrianto",
      "Nuria Oliver"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2311.17752",
    "title": "BAND-2k: Banding Artifact Noticeable Database for Banding Detection and  Quality Assessment",
    "abstract": "Banding, also known as staircase-like contours, frequently occurs in flat areas of images/videos processed by the compression or quantization algorithms. As undesirable artifacts, banding destroys the original image structure, thus degrading users' quality of experience (QoE). In this paper, we systematically investigate the banding image quality assessment (IQA) problem, aiming to detect the image banding artifacts and evaluate their perceptual visual quality. Considering that the existing image banding databases only contain limited content sources and banding generation methods, and lack perceptual quality labels (i.e. mean opinion scores), we first build the largest banding IQA database so far, named Banding Artifact Noticeable Database (BAND-2k), which consists of 2,000 banding images generated by 15 compression and quantization schemes. A total of 23 workers participated in the subjective IQA experiment, yielding over 214,000 patch-level banding class labels and 44,371 reliable image-level quality ratings. Subsequently, we develop an effective no-reference (NR) banding evaluator for banding detection and quality assessment by leveraging frequency characteristics of banding artifacts. A dual convolutional neural network is employed to concurrently learn the feature representation from the high-frequency and low-frequency maps, thereby enhancing the ability to discern banding artifacts. The quality score of a banding image is generated by pooling the banding detection maps masked by the spatial frequency filters. Experiments demonstrate that our banding evaluator achieves a remarkably high accuracy in banding detection and also exhibits high SRCC and PLCC results with the perceptual quality labels. These findings unveil the strong correlations between the intensity of banding artifacts and the perceptual visual quality, thus validating the necessity of banding quality assessment. ",
    "url": "https://arxiv.org/abs/2311.17752",
    "authors": [
      "Zijian Chen",
      "Wei Sun",
      "Jun Jia",
      "Fangfang Lu",
      "Zicheng Zhang",
      "Jing Liu",
      "Ru Huang",
      "Xiongkuo Min",
      "Guangtao Zhai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Databases (cs.DB)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2311.17757",
    "title": "Robust Scheduling in Cloud Environment Based on Heuristic Optimization  Algorithm",
    "abstract": "Aiming at analyzing performance in cloud computing, some unpredictable perturbations which may lead to performance downgrade are essential factors that should not be neglected. To avoid performance downgrade in cloud computing system, it is reasonable to measure the impact of the perturbations, and further propose a robust scheduling strategy to maintain the performance of the system at an acceptable level. In this paper, we first describe the supply-demand relationship of service between cloud service providers and customers, in which the profit and waiting time are objectives they most concerned. Then, on the basis of introducing the lowest acceptable profit and longest acceptable waiting time for cloud service providers and customers respectively, we define a robustness metric method to declare that the number and speed of servers should be adequately configured in a feasible region, such that the performance of cloud computing system can stay at an acceptable level when it is subject to the perturbations. Subsequently, we discuss the robustness metric method in several cases, and propose heuristic optimization algorithm to enhance the robustness of the system as much as possible. At last, the performances of the proposed algorithm are validated by comparing with DE and PSO algorithm, the results show the superiority of the proposed algorithm. ",
    "url": "https://arxiv.org/abs/2311.17757",
    "authors": [
      "Jiaxin Zhou",
      "Siyi Chen",
      "Haiyang Kuang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.17766",
    "title": "Robustness Approaches for the Examination Timetabling Problem under Data  Uncertainty",
    "abstract": "In the literature the examination timetabling problem (ETTP) is often considered a post-enrollment problem (PE-ETTP). In the real world, universities often schedule their exams before students register using information from previous terms. A direct consequence of this approach is the uncertainty present in the resulting models. In this work we discuss several approaches available in the robust optimization literature. We consider the implications of each approach in respect to the examination timetabling problem and present how the most favorable approaches can be applied to the ETTP. Afterwards we analyze the impact of some possible implementations of the given robustness approaches on two real world instances and several random instances generated by our instance generation framework which we introduce in this work. ",
    "url": "https://arxiv.org/abs/2311.17766",
    "authors": [
      "Bernd Bassimir",
      "Rolf Wanka"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.17770",
    "title": "PillarNeSt: Embracing Backbone Scaling and Pretraining for Pillar-based  3D Object Detection",
    "abstract": "This paper shows the effectiveness of 2D backbone scaling and pretraining for pillar-based 3D object detectors. Pillar-based methods mainly employ randomly initialized 2D convolution neural network (ConvNet) for feature extraction and fail to enjoy the benefits from the backbone scaling and pretraining in the image domain. To show the scaling-up capacity in point clouds, we introduce the dense ConvNet pretrained on large-scale image datasets (e.g., ImageNet) as the 2D backbone of pillar-based detectors. The ConvNets are adaptively designed based on the model size according to the specific features of point clouds, such as sparsity and irregularity. Equipped with the pretrained ConvNets, our proposed pillar-based detector, termed PillarNeSt, outperforms the existing 3D object detectors by a large margin on the nuScenes and Argoversev2 datasets. Our code shall be released upon acceptance. ",
    "url": "https://arxiv.org/abs/2311.17770",
    "authors": [
      "Weixin Mao",
      "Tiancai Wang",
      "Diankun Zhang",
      "Junjie Yan",
      "Osamu Yoshie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2311.17781",
    "title": "Propagate & Distill: Towards Effective Graph Learners Using  Propagation-Embracing MLPs",
    "abstract": "Recent studies attempted to utilize multilayer perceptrons (MLPs) to solve semisupervised node classification on graphs, by training a student MLP by knowledge distillation from a teacher graph neural network (GNN). While previous studies have focused mostly on training the student MLP by matching the output probability distributions between the teacher and student models during distillation, it has not been systematically studied how to inject the structural information in an explicit and interpretable manner. Inspired by GNNs that separate feature transformation $T$ and propagation $\\Pi$, we re-frame the distillation process as making the student MLP learn both $T$ and $\\Pi$. Although this can be achieved by applying the inverse propagation $\\Pi^{-1}$ before distillation from the teacher, it still comes with a high computational cost from large matrix multiplications during training. To solve this problem, we propose Propagate & Distill (P&D), which propagates the output of the teacher before distillation, which can be interpreted as an approximate process of the inverse propagation. We demonstrate that P&D can readily improve the performance of the student MLP. ",
    "url": "https://arxiv.org/abs/2311.17781",
    "authors": [
      "Yong-Min Shin",
      "Won-Yong Shin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.17783",
    "title": "Identifying Dynamic Regulation with Adversarial Surrogates",
    "abstract": "Homeostasis, the ability to maintain a stable internal environment in the face of perturbations, is essential for the functioning of living systems. Given observations of a system, or even a detailed model of one, it is both valuable and extremely challenging to extract the control objectives of the homeostatic mechanisms. Lacking a clear separation between plant and controller, frameworks such as inverse optimal control and inverse reinforcement learning are unable to identify the homeostatic mechanisms. A recently developed data-driven algorithm, Identifying Regulation with Adversarial Surrogates (IRAS), detects highly regulated or conserved quantities as the solution of a min-max optimization scheme that automates classical surrogate data methods. Yet, the definition of homeostasis as regulation within narrow limits is too strict for biological systems which show sustained oscillations such as circadian rhythms. In this work, we introduce Identifying Dynamic Regulation with Adversarial Surrogates (IDRAS), a generalization of the IRAS algorithm, capable of identifying control objectives that are regulated with respect to a dynamical reference value. We test the algorithm on simulation data from realistic biological models and benchmark physical systems, demonstrating excellent empirical results. ",
    "url": "https://arxiv.org/abs/2311.17783",
    "authors": [
      "Ron Teichner",
      "Naama Brenner",
      "Ron Meir"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2311.17789",
    "title": "The Symmetric alpha-Stable Privacy Mechanism",
    "abstract": "With the rapid growth of digital platforms, there is increasing apprehension about how personal data is being collected, stored, and used by various entities. These concerns range from data breaches and cyber-attacks to potential misuse of personal information for targeted advertising and surveillance. As a result, differential privacy (DP) has emerged as a prominent tool for quantifying a system's level of protection. The Gaussian mechanism is commonly used because the Gaussian density is closed under convolution, a common method utilized when aggregating datasets. However, the Gaussian mechanism only satisfies approximate differential privacy. In this work, we present novel analysis of the Symmetric alpha-Stable (SaS) mechanism. We prove that the mechanism is purely differentially private while remaining closed under convolution. From our analysis, we believe the SaS Mechanism is an appealing choice for privacy focused applications. ",
    "url": "https://arxiv.org/abs/2311.17789",
    "authors": [
      "Christopher Zawacki",
      "Eyad Abed"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2311.17790",
    "title": "FAT-HuBERT: Front-end Adaptive Training of Hidden-unit BERT for  Distortion-Invariant Robust Speech Recognition",
    "abstract": "Advancements in monaural speech enhancement (SE) techniques have greatly improved the perceptual quality of speech. However, integrating these techniques into automatic speech recognition (ASR) systems has not yielded the expected performance gains, primarily due to the introduction of distortions during the SE process. In this paper, we propose a novel approach called FAT-HuBERT, which leverages distortion-invariant self-supervised learning (SSL) to enhance the robustness of ASR. To address the distortions introduced by the SE frontends, we introduce layer-wise fusion modules that incorporate features extracted from both observed noisy signals and enhanced signals. During training, the SE frontend is randomly selected from a pool of models. We evaluate the performance of FAT-HuBERT on simulated noisy speech generated from LibriSpeech as well as real-world noisy speech from the CHiME-4 1-channel dataset. The experimental results demonstrate a significant relative reduction in word error rate (WER). ",
    "url": "https://arxiv.org/abs/2311.17790",
    "authors": [
      "Dongning Yang",
      "Wei Wang",
      "Yanmin Qian"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2311.17810",
    "title": "Coloring the Past: Neural Historical Buildings Reconstruction from  Archival Photography",
    "abstract": "Historical buildings are a treasure and milestone of human cultural heritage. Reconstructing the 3D models of these building hold significant value. The rapid development of neural rendering methods makes it possible to recover the 3D shape only based on archival photographs. However, this task presents considerable challenges due to the limitations of such datasets. Historical photographs are often limited in number and the scenes in these photos might have altered over time. The radiometric quality of these images is also often sub-optimal. To address these challenges, we introduce an approach to reconstruct the geometry of historical buildings, employing volumetric rendering techniques. We leverage dense point clouds as a geometric prior and introduce a color appearance embedding loss to recover the color of the building given limited available color images. We aim for our work to spark increased interest and focus on preserving historical buildings. Thus, we also introduce a new historical dataset of the Hungarian National Theater, providing a new benchmark for the reconstruction method. ",
    "url": "https://arxiv.org/abs/2311.17810",
    "authors": [
      "David Komorowicz",
      "Lu Sang",
      "Ferdinand Maiwald",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17815",
    "title": "A Survey on Design Methodologies for Accelerating Deep Learning on  Heterogeneous Architectures",
    "abstract": "In recent years, the field of Deep Learning has seen many disruptive and impactful advancements. Given the increasing complexity of deep neural networks, the need for efficient hardware accelerators has become more and more pressing to design heterogeneous HPC platforms. The design of Deep Learning accelerators requires a multidisciplinary approach, combining expertise from several areas, spanning from computer architecture to approximate computing, computational models, and machine learning algorithms. Several methodologies and tools have been proposed to design accelerators for Deep Learning, including hardware-software co-design approaches, high-level synthesis methods, specific customized compilers, and methodologies for design space exploration, modeling, and simulation. These methodologies aim to maximize the exploitable parallelism and minimize data movement to achieve high performance and energy efficiency. This survey provides a holistic review of the most influential design methodologies and EDA tools proposed in recent years to implement Deep Learning accelerators, offering the reader a wide perspective in this rapidly evolving field. In particular, this work complements the previous survey proposed by the same authors in [203], which focuses on Deep Learning hardware accelerators for heterogeneous HPC platforms. ",
    "url": "https://arxiv.org/abs/2311.17815",
    "authors": [
      "Fabrizio Ferrandi",
      "Serena Curzel",
      "Leandro Fiorin",
      "Daniele Ielmini",
      "Cristina Silvano",
      "Francesco Conti",
      "Alessio Burrello",
      "Francesco Barchi",
      "Luca Benini",
      "Luciano Lavagno",
      "Teodoro Urso",
      "Enrico Calore",
      "Sebastiano Fabio Schifano",
      "Cristian Zambelli",
      "Maurizio Palesi",
      "Giuseppe Ascia",
      "Enrico Russo",
      "Nicola Petra",
      "Davide De Caro",
      "Gennaro Di Meo",
      "Valeria Cardellini",
      "Salvatore Filippone",
      "Francesco Lo Presti",
      "Francesco Silvestri",
      "Paolo Palazzari",
      "Stefania Perri"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.17822",
    "title": "Anomalous Behavior Detection in Trajectory Data of Older Drivers",
    "abstract": "Given a road network and a set of trajectory data, the anomalous behavior detection (ABD) problem is to identify drivers that show significant directional deviations, hardbrakings, and accelerations in their trips. The ABD problem is important in many societal applications, including Mild Cognitive Impairment (MCI) detection and safe route recommendations for older drivers. The ABD problem is computationally challenging due to the large size of temporally-detailed trajectories dataset. In this paper, we propose an Edge-Attributed Matrix that can represent the key properties of temporally-detailed trajectory datasets and identify abnormal driving behaviors. Experiments using real-world datasets demonstrated that our approach identifies abnormal driving behaviors. ",
    "url": "https://arxiv.org/abs/2311.17822",
    "authors": [
      "Seyedeh Gol Ara Ghoreishi",
      "Sonia Moshfeghi",
      "Muhammad Tanveer Jan",
      "Joshua Conniff",
      "KwangSoo Yang",
      "Jinwoo Jang",
      "Borko Furht",
      "Ruth Tappen",
      "David Newman",
      "Monica Rosselli",
      "Jiannan Zhai"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.17836",
    "title": "On Scaling Robust Feedback Control and State Estimation Problems in  Power Networks",
    "abstract": "Many mainstream robust control/estimation algorithms for power networks are designed using the Lyapunov theory as it provides performance guarantees for linear/nonlinear models of uncertain power networks but comes at the expense of scalability and sensitivity. In particular, Lyapunov-based approaches rely on forming semi-definite programs (SDPs) that are (i) not scalable and (ii) extremely sensitive to the choice of the bounding scalar that ensures the strict feasibility of the linear matrix inequalities (LMIs). This paper addresses these two issues by employing a celebrated non-Lyapunov approach (NLA) from the control theory literature. In lieu of linearized models of power grids, we focus on (the more representative) nonlinear differential algebraic equation (DAE) models and showcase the simplicity, scalability, and parameter-resiliency of NLA. For some power systems, the approach is nearly fifty times faster than solving SDPs via standard solvers with almost no impact on the performance. The case studies also demonstrate that NLA can be applied to more realistic scenarios in which (i) only partial state data is available and (ii) sparsity structures are imposed on the feedback gain. The paper also showcases that virtually no degradation in state estimation quality is experienced when applying NLA. ",
    "url": "https://arxiv.org/abs/2311.17836",
    "authors": [
      "MirSaleh Bahavarnia",
      "Muhammad Nadeem",
      "Ahmad F. Taha"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2311.17847",
    "title": "FastSample: Accelerating Distributed Graph Neural Network Training for  Billion-Scale Graphs",
    "abstract": "Training Graph Neural Networks(GNNs) on a large monolithic graph presents unique challenges as the graph cannot fit within a single machine and it cannot be decomposed into smaller disconnected components. Distributed sampling-based training distributes the graph across multiple machines and trains the GNN on small parts of the graph that are randomly sampled every training iteration. We show that in a distributed environment, the sampling overhead is a significant component of the training time for large-scale graphs. We propose FastSample which is composed of two synergistic techniques that greatly reduce the distributed sampling time: 1)a new graph partitioning method that eliminates most of the communication rounds in distributed sampling , 2)a novel highly optimized sampling kernel that reduces memory movement during sampling. We test FastSample on large-scale graph benchmarks and show that FastSample speeds up distributed sampling-based GNN training by up to 2x with no loss in accuracy. ",
    "url": "https://arxiv.org/abs/2311.17847",
    "authors": [
      "Hesham Mostafa",
      "Adam Grabowski",
      "Md Asadullah Turja",
      "Juan Cervino",
      "Alejandro Ribeiro",
      "Nageen Himayat"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.17852",
    "title": "A Computing-in-Memory-based One-Class Hyperdimensional Computing Model  for Outlier Detection",
    "abstract": "In this work, we present ODHD, an algorithm for outlier detection based on hyperdimensional computing (HDC), a non-classical learning paradigm. Along with the HDC-based algorithm, we propose IM-ODHD, a computing-in-memory (CiM) implementation based on hardware/software (HW/SW) codesign for improved latency and energy efficiency. The training and testing phases of ODHD may be performed with conventional CPU/GPU hardware or our IM-ODHD, SRAM-based CiM architecture using the proposed HW/SW codesign techniques. We evaluate the performance of ODHD on six datasets from different application domains using three metrics, namely accuracy, F1 score, and ROC-AUC, and compare it with multiple baseline methods such as OCSVM, isolation forest, and autoencoder. The experimental results indicate that ODHD outperforms all the baseline methods in terms of these three metrics on every dataset for both CPU/GPU and CiM implementations. Furthermore, we perform an extensive design space exploration to demonstrate the tradeoff between delay, energy efficiency, and performance of ODHD. We demonstrate that the HW/SW codesign implementation of the outlier detection on IM-ODHD is able to outperform the GPU-based implementation of ODHD by at least 293x/419x in terms of training/testing latency (and on average 16.0x/15.9x in terms of training/testing energy consumption). ",
    "url": "https://arxiv.org/abs/2311.17852",
    "authors": [
      "Ruixuan Wang",
      "Sabrina Hassan Moon",
      "Xiaobo Sharon Hu",
      "Xun Jiao",
      "Dayane Reis"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2311.17853",
    "title": "On the Adversarial Robustness of Graph Contrastive Learning Methods",
    "abstract": "Contrastive learning (CL) has emerged as a powerful framework for learning representations of images and text in a self-supervised manner while enhancing model robustness against adversarial attacks. More recently, researchers have extended the principles of contrastive learning to graph-structured data, giving birth to the field of graph contrastive learning (GCL). However, whether GCL methods can deliver the same advantages in adversarial robustness as their counterparts in the image and text domains remains an open question. In this paper, we introduce a comprehensive robustness evaluation protocol tailored to assess the robustness of GCL models. We subject these models to adaptive adversarial attacks targeting the graph structure, specifically in the evasion scenario. We evaluate node and graph classification tasks using diverse real-world datasets and attack strategies. With our work, we aim to offer insights into the robustness of GCL methods and hope to open avenues for potential future research directions. ",
    "url": "https://arxiv.org/abs/2311.17853",
    "authors": [
      "Filippo Guerranti",
      "Zinuo Yi",
      "Anna Starovoit",
      "Rafiq Kamel",
      "Simon Geisler",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17856",
    "title": "Leveraging Graph Diffusion Models for Network Refinement Tasks",
    "abstract": "Most real-world networks are noisy and incomplete samples from an unknown target distribution. Refining them by correcting corruptions or inferring unobserved regions typically improves downstream performance. Inspired by the impressive generative capabilities that have been used to correct corruptions in images, and the similarities between \"in-painting\" and filling in missing nodes and edges conditioned on the observed graph, we propose a novel graph generative framework, SGDM, which is based on subgraph diffusion. Our framework not only improves the scalability and fidelity of graph diffusion models, but also leverages the reverse process to perform novel, conditional generation tasks. In particular, through extensive empirical analysis and a set of novel metrics, we demonstrate that our proposed model effectively supports the following refinement tasks for partially observable networks: T1: denoising extraneous subgraphs, T2: expanding existing subgraphs and T3: performing \"style\" transfer by regenerating a particular subgraph to match the characteristics of a different node or subgraph. ",
    "url": "https://arxiv.org/abs/2311.17856",
    "authors": [
      "Puja Trivedi",
      "Ryan Rossi",
      "David Arbour",
      "Tong Yu",
      "Franck Dernoncourt",
      "Sungchul Kim",
      "Nedim Lipka",
      "Namyong Park",
      "Nesreen K. Ahmed",
      "Danai Koutra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.17872",
    "title": "Assessing the reliability of multistate flow networks considering  distance constraints",
    "abstract": "Evaluating the reliability of complex technical networks, such as those in energy distribution, logistics, and transportation systems, is of paramount importance. These networks are often represented as multistate flow networks (MFNs). While there has been considerable research on assessing MFN reliability, many studies still need to pay more attention to a critical factor: transmission distance constraints. These constraints are typical in real-world applications, such as Internet infrastructure, where controlling the distances between data centers, network nodes, and end-users is vital for ensuring low latency and efficient data transmission. This paper addresses the evaluation of MFN reliability under distance constraints. Specifically, it focuses on determining the probability that a minimum of $d$ flow units can be transmitted successfully from a source node to a sink node, using only paths with lengths not exceeding a predefined distance limit of $\\lambda $. We introduce an effective algorithm to tackle this challenge, provide a benchmark example to illustrate its application and analyze its computational complexity. ",
    "url": "https://arxiv.org/abs/2311.17872",
    "authors": [
      "Majid Forghani-elahabad"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2311.17878",
    "title": "TSDF-Sampling: Efficient Sampling for Neural Surface Field using  Truncated Signed Distance Field",
    "abstract": "Multi-view neural surface reconstruction has exhibited impressive results. However, a notable limitation is the prohibitively slow inference time when compared to traditional techniques, primarily attributed to the dense sampling, required to maintain the rendering quality. This paper introduces a novel approach that substantially reduces the number of samplings by incorporating the Truncated Signed Distance Field (TSDF) of the scene. While prior works have proposed importance sampling, their dependence on initial uniform samples over the entire space makes them unable to avoid performance degradation when trying to use less number of samples. In contrast, our method leverages the TSDF volume generated only by the trained views, and it proves to provide a reasonable bound on the sampling from upcoming novel views. As a result, we achieve high rendering quality by fully exploiting the continuous neural SDF estimation within the bounds given by the TSDF volume. Notably, our method is the first approach that can be robustly plug-and-play into a diverse array of neural surface field models, as long as they use the volume rendering technique. Our empirical results show an 11-fold increase in inference speed without compromising performance. The result videos are available at our project page: https://tsdf-sampling.github.io/ ",
    "url": "https://arxiv.org/abs/2311.17878",
    "authors": [
      "Chaerin Min",
      "Sehyun Cha",
      "Changhee Won",
      "Jongwoo Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17893",
    "title": "Betrayed by Attention: A Simple yet Effective Approach for  Self-supervised Video Object Segmentation",
    "abstract": "In this paper, we propose a simple yet effective approach for self-supervised video object segmentation (VOS). Our key insight is that the inherent structural dependencies present in DINO-pretrained Transformers can be leveraged to establish robust spatio-temporal correspondences in videos. Furthermore, simple clustering on this correspondence cue is sufficient to yield competitive segmentation results. Previous self-supervised VOS techniques majorly resort to auxiliary modalities or utilize iterative slot attention to assist in object discovery, which restricts their general applicability and imposes higher computational requirements. To deal with these challenges, we develop a simplified architecture that capitalizes on the emerging objectness from DINO-pretrained Transformers, bypassing the need for additional modalities or slot attention. Specifically, we first introduce a single spatio-temporal Transformer block to process the frame-wise DINO features and establish spatio-temporal dependencies in the form of self-attention. Subsequently, utilizing these attention maps, we implement hierarchical clustering to generate object segmentation masks. To train the spatio-temporal block in a fully self-supervised manner, we employ semantic and dynamic motion consistency coupled with entropy normalization. Our method demonstrates state-of-the-art performance across multiple unsupervised VOS benchmarks and particularly excels in complex real-world multi-object video segmentation tasks such as DAVIS-17-Unsupervised and YouTube-VIS-19. The code and model checkpoints will be released at https://github.com/shvdiwnkozbw/SSL-UVOS. ",
    "url": "https://arxiv.org/abs/2311.17893",
    "authors": [
      "Shuangrui Ding",
      "Rui Qian",
      "Haohang Xu",
      "Dahua Lin",
      "Hongkai Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.17901",
    "title": "SODA: Bottleneck Diffusion Models for Representation Learning",
    "abstract": "We introduce SODA, a self-supervised diffusion model, designed for representation learning. The model incorporates an image encoder, which distills a source view into a compact representation, that, in turn, guides the generation of related novel views. We show that by imposing a tight bottleneck between the encoder and a denoising decoder, and leveraging novel view synthesis as a self-supervised objective, we can turn diffusion models into strong representation learners, capable of capturing visual semantics in an unsupervised manner. To the best of our knowledge, SODA is the first diffusion model to succeed at ImageNet linear-probe classification, and, at the same time, it accomplishes reconstruction, editing and synthesis tasks across a wide range of datasets. Further investigation reveals the disentangled nature of its emergent latent space, that serves as an effective interface to control and manipulate the model's produced images. All in all, we aim to shed light on the exciting and promising potential of diffusion models, not only for image generation, but also for learning rich and robust representations. ",
    "url": "https://arxiv.org/abs/2311.17901",
    "authors": [
      "Drew A. Hudson",
      "Daniel Zoran",
      "Mateusz Malinowski",
      "Andrew K. Lampinen",
      "Andrew Jaegle",
      "James L. McClelland",
      "Loic Matthey",
      "Felix Hill",
      "Alexander Lerchner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17902",
    "title": "Language-conditioned Detection Transformer",
    "abstract": "We present a new open-vocabulary detection framework. Our framework uses both image-level labels and detailed detection annotations when available. Our framework proceeds in three steps. We first train a language-conditioned object detector on fully-supervised detection data. This detector gets to see the presence or absence of ground truth classes during training, and conditions prediction on the set of present classes. We use this detector to pseudo-label images with image-level labels. Our detector provides much more accurate pseudo-labels than prior approaches with its conditioning mechanism. Finally, we train an unconditioned open-vocabulary detector on the pseudo-annotated images. The resulting detector, named DECOLA, shows strong zero-shot performance in open-vocabulary LVIS benchmark as well as direct zero-shot transfer benchmarks on LVIS, COCO, Object365, and OpenImages. DECOLA outperforms the prior arts by 17.1 AP-rare and 9.4 mAP on zero-shot LVIS benchmark. DECOLA achieves state-of-the-art results in various model sizes, architectures, and datasets by only training on open-sourced data and academic-scale computing. Code is available at https://github.com/janghyuncho/DECOLA. ",
    "url": "https://arxiv.org/abs/2311.17902",
    "authors": [
      "Jang Hyun Cho",
      "Philipp Kr\u00e4henb\u00fchl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16410",
    "title": "Reduced-order modeling for parameterized PDEs via implicit neural  representations",
    "abstract": "We present a new data-driven reduced-order modeling approach to efficiently solve parametrized partial differential equations (PDEs) for many-query problems. This work is inspired by the concept of implicit neural representation (INR), which models physics signals in a continuous manner and independent of spatial/temporal discretization. The proposed framework encodes PDE and utilizes a parametrized neural ODE (PNODE) to learn latent dynamics characterized by multiple PDE parameters. PNODE can be inferred by a hypernetwork to reduce the potential difficulties in learning PNODE due to a complex multilayer perceptron (MLP). The framework uses an INR to decode the latent dynamics and reconstruct accurate PDE solutions. Further, a physics-informed loss is also introduced to correct the prediction of unseen parameter instances. Incorporating the physics-informed loss also enables the model to be fine-tuned in an unsupervised manner on unseen PDE parameters. A numerical experiment is performed on a two-dimensional Burgers equation with a large variation of PDE parameters. We evaluate the proposed method at a large Reynolds number and obtain up to speedup of O(10^3) and ~1% relative error to the ground truth values. ",
    "url": "https://arxiv.org/abs/2311.16410",
    "authors": [
      "Tianshu Wen",
      "Kookjin Lee",
      "Youngsoo Choi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2311.16457",
    "title": "Fixation dynamics on multilayer networks",
    "abstract": "Network structure has a large impact on constant-selection evolutionary dynamics, with which multiple types of different fitnesses (i.e., strengths) compete on the network. Here we study constant-selection dynamics on two-layer networks in which the fitness of a node in one layer affects that in the other layer, under birth-death processes and uniform initialization, which are commonly assumed. We show mathematically and numerically that two-layer networks are suppressors of selection, which suppresses the effects of the different fitness values between the different types on final outcomes of the evolutionary dynamics (called fixation probability), relative to the constituent one-layer networks. In fact, many two-layer networks are suppressors of selection relative to the most basic baseline, the Moran process. This result is in stark contrast with the results for conventional one-layer networks for which most networks are amplifiers of selection. ",
    "url": "https://arxiv.org/abs/2311.16457",
    "authors": [
      "Ruodan Liu",
      "Naoki Masuda"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2311.17103",
    "title": "Single-cell Multi-view Clustering via Community Detection with Unknown  Number of Clusters",
    "abstract": "Single-cell multi-view clustering enables the exploration of cellular heterogeneity within the same cell from different views. Despite the development of several multi-view clustering methods, two primary challenges persist. Firstly, most existing methods treat the information from both single-cell RNA (scRNA) and single-cell Assay of Transposase Accessible Chromatin (scATAC) views as equally significant, overlooking the substantial disparity in data richness between the two views. This oversight frequently leads to a degradation in overall performance. Additionally, the majority of clustering methods necessitate manual specification of the number of clusters by users. However, for biologists dealing with cell data, precisely determining the number of distinct cell types poses a formidable challenge. To this end, we introduce scUNC, an innovative multi-view clustering approach tailored for single-cell data, which seamlessly integrates information from different views without the need for a predefined number of clusters. The scUNC method comprises several steps: initially, it employs a cross-view fusion network to create an effective embedding, which is then utilized to generate initial clusters via community detection. Subsequently, the clusters are automatically merged and optimized until no further clusters can be merged. We conducted a comprehensive evaluation of scUNC using three distinct single-cell datasets. The results underscored that scUNC outperforms the other baseline methods. ",
    "url": "https://arxiv.org/abs/2311.17103",
    "authors": [
      "Dayu Hu",
      "Zhibin Dong",
      "Ke Liang",
      "Jun Wang",
      "Siwei Wang",
      "Xinwang Liu"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17162",
    "title": "Fast Particle-based Anomaly Detection Algorithm with Variational  Autoencoder",
    "abstract": "Model-agnostic anomaly detection is one of the promising approaches in the search for new beyond the standard model physics. In this paper, we present Set-VAE, a particle-based variational autoencoder (VAE) anomaly detection algorithm. We demonstrate a 2x signal efficiency gain compared with traditional subjettiness-based jet selection. Furthermore, with an eye to the future deployment to trigger systems, we propose the CLIP-VAE, which reduces the inference-time cost of anomaly detection by using the KL-divergence loss as the anomaly score, resulting in a 2x acceleration in latency and reducing the caching requirement. ",
    "url": "https://arxiv.org/abs/2311.17162",
    "authors": [
      "Ryan Liu",
      "Abhijith Gandrakota",
      "Jennifer Ngadiuba",
      "Maria Spiropulu",
      "Jean-Roch Vlimant"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.17248",
    "title": "Deep Regularized Compound Gaussian Network for Solving Linear Inverse  Problems",
    "abstract": "Incorporating prior information into inverse problems, e.g. via maximum-a-posteriori estimation, is an important technique for facilitating robust inverse problem solutions. In this paper, we devise two novel approaches for linear inverse problems that permit problem-specific statistical prior selections within the compound Gaussian (CG) class of distributions. The CG class subsumes many commonly used priors in signal and image reconstruction methods including those of sparsity-based approaches. The first method developed is an iterative algorithm, called generalized compound Gaussian least squares (G-CG-LS), that minimizes a regularized least squares objective function where the regularization enforces a CG prior. G-CG-LS is then unrolled, or unfolded, to furnish our second method, which is a novel deep regularized (DR) neural network, called DR-CG-Net, that learns the prior information. A detailed computational theory on convergence properties of G-CG-LS and thorough numerical experiments for DR-CG-Net are provided. Due to the comprehensive nature of the CG prior, these experiments show that our unrolled DR-CG-Net outperforms competitive prior art methods in tomographic imaging and compressive sensing, especially in challenging low-training scenarios. ",
    "url": "https://arxiv.org/abs/2311.17248",
    "authors": [
      "Carter Lyons",
      "Raghu G. Raj",
      "Margaret Cheney"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2311.17284",
    "title": "Discrete-to-continuum limits of optimal transport with linear growth on  periodic graphs",
    "abstract": "We prove discrete-to-continuum convergence for dynamical optimal transport on $\\mathbb{Z}^d$-periodic graphs with energy density having linear growth at infinity. This result provides an answer to a problem left open by Gladbach, Kopfer, Maas, and Portinale (Calc Var Partial Differential Equations 62(5), 2023), where the convergence behaviour of discrete boundary-value dynamical transport problems is proved under the stronger assumption of superlinear growth. Our result extends the known literature to some important classes of examples, such as scaling limits of 1-Wasserstein transport problems. Similarly to what happens in the quadratic case, the geometry of the graph plays a crucial role in the structure of the limit cost function, as we discuss in the final part of this work, which includes some visual representations. ",
    "url": "https://arxiv.org/abs/2311.17284",
    "authors": [
      "Lorenzo Portinale",
      "Filippo Quattrocchi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2311.17383",
    "title": "Dynamical manifold dimensionality as characterization measure of chimera  states in bursting neuronal networks",
    "abstract": "Methods that distinguish dynamical regimes in networks of active elements make it possible to design the dynamics of models of realistic networks. A particularly salient example is partial synchronization, which may play a pivotal role in elucidating the dynamics of biological neural networks. Such emergent partial synchronization in structurally homogeneous networks is commonly denoted as chimera states. While several methods for detecting chimeras in networks of spiking neurons have been proposed, these are less effective when applied to networks of bursting neurons. Here we introduce the correlation dimension as a novel approach to identifying dynamic network states. To assess the viability of this new method, we study a network of intrinsically Hindmarsh-Rose neurons with non-local connections. In comparison to other measures of chimera states, the correlation dimension effectively characterizes chimeras in burst neurons, whether the incoherence arises in spikes or bursts. The generality of dimensionality measures inherent in the correlation dimension renders this approach applicable to any dynamic system, facilitating the comparison of simulated and experimental data. We anticipate that this methodology will enable the tuning and simulation of when modelling intricate network processes, contributing to a deeper understanding of neural dynamics. ",
    "url": "https://arxiv.org/abs/2311.17383",
    "authors": [
      "Olesia Dogonasheva",
      "Daniil Radushev",
      "Boris Gutkin",
      "Denis Zakharov"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2311.17458",
    "title": "Quantum Neural Networks under Depolarization Noise: Exploring White-Box  Attacks and Defenses",
    "abstract": "Leveraging the unique properties of quantum mechanics, Quantum Machine Learning (QML) promises computational breakthroughs and enriched perspectives where traditional systems reach their boundaries. However, similarly to classical machine learning, QML is not immune to adversarial attacks. Quantum adversarial machine learning has become instrumental in highlighting the weak points of QML models when faced with adversarial crafted feature vectors. Diving deep into this domain, our exploration shines light on the interplay between depolarization noise and adversarial robustness. While previous results enhanced robustness from adversarial threats through depolarization noise, our findings paint a different picture. Interestingly, adding depolarization noise discontinued the effect of providing further robustness for a multi-class classification scenario. Consolidating our findings, we conducted experiments with a multi-class classifier adversarially trained on gate-based quantum simulators, further elucidating this unexpected behavior. ",
    "url": "https://arxiv.org/abs/2311.17458",
    "authors": [
      "David Winderl",
      "Nicola Franco",
      "Jeanette Miriam Lorenz"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.17490",
    "title": "Multithreaded parallelism for heterogeneous clusters of QPUs",
    "abstract": "In this work, we present MILQ, a quantum unrelated parallel machines scheduler and cutter. The setting of unrelated parallel machines considers independent hardware backends, each distinguished by differing setup and processing times. MILQ optimizes the total execution time of a batch of circuits scheduled on multiple quantum devices. It leverages state-of-the-art circuit-cutting techniques to fit circuits onto the devices and schedules them based on a mixed-integer linear program. Our results show a total improvement of up to 26 % compared to a baseline approach. ",
    "url": "https://arxiv.org/abs/2311.17490",
    "authors": [
      "Philipp Seitz",
      "Manuel Geiger",
      "Christian B. Mendl"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2311.17521",
    "title": "Spinal Muscle Atrophy Disease Modelling as Bayesian Network",
    "abstract": "We investigate the molecular gene expressions studies and public databases for disease modelling using Probabilistic Graphical Models and Bayesian Inference. A case study on Spinal Muscle Atrophy Genome-Wide Association Study results is modelled and analyzed. The genes up and down-regulated in two stages of the disease development are linked to prior knowledge published in the public domain and co-expressions network is created and analyzed. The Molecular Pathways triggered by these genes are identified. The Bayesian inference posteriors distributions are estimated using a variational analytical algorithm and a Markov chain Monte Carlo sampling algorithm. Assumptions, limitations and possible future work are concluded. ",
    "url": "https://arxiv.org/abs/2311.17521",
    "authors": [
      "Mohammed Ezzat Helal",
      "Manal Ezzat Helal",
      "Sherif Fadel Fahmy"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2102.07737",
    "title": "Zero-Shot Self-Supervised Learning for MRI Reconstruction",
    "abstract": " Title: Zero-Shot Self-Supervised Learning for MRI Reconstruction ",
    "url": "https://arxiv.org/abs/2102.07737",
    "authors": [
      "Burhaneddin Yaman",
      "Seyed Amir Hossein Hosseini",
      "Mehmet Ak\u00e7akaya"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2110.04442",
    "title": "A Primer on Deep Learning for Causal Inference",
    "abstract": " Comments: Forthcoming in Sociological Methods and Research ",
    "url": "https://arxiv.org/abs/2110.04442",
    "authors": [
      "Bernard Koch",
      "Tim Sainburg",
      "Pablo Geraldo",
      "Song Jiang",
      "Yizhou Sun",
      "Jacob Gates Foster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2111.12971",
    "title": "Natural & Adversarial Bokeh Rendering via Circle-of-Confusion Predictive  Network",
    "abstract": " Comments: 11 pages, accepted by TMM ",
    "url": "https://arxiv.org/abs/2111.12971",
    "authors": [
      "Yihao Huang",
      "Felix Juefei-Xu",
      "Qing Guo",
      "Geguang Pu",
      "Yang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.00948",
    "title": "CD-GAN: a robust fusion-based generative adversarial network for  unsupervised remote sensing change detection with heterogeneous sensors",
    "abstract": " Title: CD-GAN: a robust fusion-based generative adversarial network for  unsupervised remote sensing change detection with heterogeneous sensors ",
    "url": "https://arxiv.org/abs/2203.00948",
    "authors": [
      "Jin-Ju Wang",
      "Nicolas Dobigeon",
      "Marie Chabert",
      "Ding-Cheng Wang",
      "Ting-Zhu Huang",
      "Jie Huang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04502",
    "title": "Building Open Knowledge Graph for Metal-Organic Frameworks (MOF-KG):  Challenges and Case Studies",
    "abstract": " Comments: Accepted by the International Workshop on Knowledge Graphs and Open Knowledge Network (OKN'22) Co-located with the 28th ACM SIGKDD Conference ",
    "url": "https://arxiv.org/abs/2207.04502",
    "authors": [
      "Yuan An",
      "Jane Greenberg",
      "Xintong Zhao",
      "Xiaohua Hu",
      "Scott McCLellan",
      "Alex Kalinowski",
      "Fernando J. Uribe-Romo",
      "Kyle Langlois",
      "Jacob Furst",
      "Diego A. G\u00f3mez-Gualdr\u00f3n",
      "Fernando Fajardo-Rojas",
      "Katherine Ardila"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.04869",
    "title": "Graph-based Molecular Representation Learning",
    "abstract": " Title: Graph-based Molecular Representation Learning ",
    "url": "https://arxiv.org/abs/2207.04869",
    "authors": [
      "Zhichun Guo",
      "Kehan Guo",
      "Bozhao Nan",
      "Yijun Tian",
      "Roshni G. Iyer",
      "Yihong Ma",
      "Olaf Wiest",
      "Xiangliang Zhang",
      "Wei Wang",
      "Chuxu Zhang",
      "Nitesh V. Chawla"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.15787",
    "title": "Convolutional Codes with Optimum Bidirectional Distance Profile",
    "abstract": " Title: Convolutional Codes with Optimum Bidirectional Distance Profile ",
    "url": "https://arxiv.org/abs/2210.15787",
    "authors": [
      "Ivan Stanojevi\u0107",
      "Vojin \u0160enk"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2211.03803",
    "title": "Quantum-probabilistic Hamiltonian learning for generative modelling &  anomaly detection",
    "abstract": " Comments: 14 pages, 7 figures. Accepted version for publication ",
    "url": "https://arxiv.org/abs/2211.03803",
    "authors": [
      "Jack Y. Araz",
      "Michael Spannowsky"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2211.05368",
    "title": "A Comprehensive Survey on Distributed Training of Graph Neural Networks",
    "abstract": " Comments: To Appear in Proceedings of the IEEE ",
    "url": "https://arxiv.org/abs/2211.05368",
    "authors": [
      "Haiyang Lin",
      "Mingyu Yan",
      "Xiaochun Ye",
      "Dongrui Fan",
      "Shirui Pan",
      "Wenguang Chen",
      "Yuan Xie"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.06842",
    "title": "Hierarchical Relationships: A New Perspective to Enhance Scene Graph  Generation",
    "abstract": " Comments: NeurIPS 2023 New Frontiers in Graph Learning Workshop (NeurIPS GLFrontiers 2023); NeurIPS 2023 Queer in AI Workshop. This paper is a preliminary work of the full paper available at arXiv:2311.12889 ",
    "url": "https://arxiv.org/abs/2303.06842",
    "authors": [
      "Bowen Jiang",
      "Camillo J. Taylor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.05062",
    "title": "A Feasibility Study on Indoor Localization and Multi-person Tracking  Using Sparsely Distributed Camera Network with Edge Computing",
    "abstract": " Title: A Feasibility Study on Indoor Localization and Multi-person Tracking  Using Sparsely Distributed Camera Network with Edge Computing ",
    "url": "https://arxiv.org/abs/2305.05062",
    "authors": [
      "Hyeokhyen Kwon",
      "Chaitra Hegde",
      "Yashar Kiarashi",
      "Venkata Siva Krishna Madala",
      "Ratan Singh",
      "ArjunSinh Nakum",
      "Robert Tweedy",
      "Leandro Miletto Tonetto",
      "Craig M. Zimring",
      "Matthew Doiron",
      "Amy D. Rodriguez",
      "Allan I. Levey",
      "Gari D. Clifford"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2305.07598",
    "title": "Hausdorff Distance Matching with Adaptive Query Denoising for Rotated  Detection Transformer",
    "abstract": " Comments: Under review, 16 pages, 12 tables, 8 figures ",
    "url": "https://arxiv.org/abs/2305.07598",
    "authors": [
      "Hakjin Lee",
      "Minki Song",
      "Jamyoung Koo",
      "Junghoon Seo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.10361",
    "title": "Human Choice Prediction in Language-based Non-Cooperative Games:  Simulation-based Off-Policy Evaluation",
    "abstract": " Title: Human Choice Prediction in Language-based Non-Cooperative Games:  Simulation-based Off-Policy Evaluation ",
    "url": "https://arxiv.org/abs/2305.10361",
    "authors": [
      "Eilam Shapira",
      "Reut Apel",
      "Moshe Tennenholtz",
      "Roi Reichart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2305.10579",
    "title": "MultiPlaneNeRF: Neural Radiance Field with Non-Trainable Representation",
    "abstract": " Title: MultiPlaneNeRF: Neural Radiance Field with Non-Trainable Representation ",
    "url": "https://arxiv.org/abs/2305.10579",
    "authors": [
      "Dominik Zimny",
      "Artur Kasymov",
      "Adam Kania",
      "Jacek Tabor",
      "Maciej Zi\u0119ba",
      "Przemys\u0142aw Spurek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.10665",
    "title": "Content-based Unrestricted Adversarial Attack",
    "abstract": " Title: Content-based Unrestricted Adversarial Attack ",
    "url": "https://arxiv.org/abs/2305.10665",
    "authors": [
      "Zhaoyu Chen",
      "Bo Li",
      "Shuang Wu",
      "Kaixun Jiang",
      "Shouhong Ding",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2305.11120",
    "title": "A Compound Gaussian Least Squares Algorithm and Unrolled Network for  Linear Inverse Problems",
    "abstract": " Comments: Paper and supplementary material published in IEEE TSP. 16 pages, 9 figures, 6 tables; references updated ",
    "url": "https://arxiv.org/abs/2305.11120",
    "authors": [
      "Carter Lyons",
      "Raghu G. Raj",
      "Margaret Cheney"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2305.14912",
    "title": "SVDinsTN: A Tensor Network Paradigm for Efficient Structure Search from  Regularized Modeling Perspective",
    "abstract": " Title: SVDinsTN: A Tensor Network Paradigm for Efficient Structure Search from  Regularized Modeling Perspective ",
    "url": "https://arxiv.org/abs/2305.14912",
    "authors": [
      "Yu-Bang Zheng",
      "Xi-Le Zhao",
      "Junhua Zeng",
      "Chao Li",
      "Qibin Zhao",
      "Heng-Chao Li",
      "Ting-Zhu Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.19103",
    "title": "Does Conceptual Representation Require Embodiment? Insights From Large  Language Models",
    "abstract": " Title: Does Conceptual Representation Require Embodiment? Insights From Large  Language Models ",
    "url": "https://arxiv.org/abs/2305.19103",
    "authors": [
      "Qihui Xu",
      "Yingying Peng",
      "Minghua Wu",
      "Feng Xiao",
      "Martin Chodorow",
      "Ping Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.19487",
    "title": "SPGNN-API: A Transferable Graph Neural Network for Attack Paths  Identification and Autonomous Mitigation",
    "abstract": " Comments: IEEE Transactions on Information Forensics & Security (TIFS) ",
    "url": "https://arxiv.org/abs/2305.19487",
    "authors": [
      "Houssem Jmal",
      "Firas Ben Hmida",
      "Nardine Basta",
      "Muhammad Ikram",
      "Mohamed Ali Kaafar",
      "Andy Walker"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2306.02027",
    "title": "Evolving Knowledge Mining for Class Incremental Segmentation",
    "abstract": " Comments: Technical report ",
    "url": "https://arxiv.org/abs/2306.02027",
    "authors": [
      "Zhihe Lu",
      "Shuicheng Yan",
      "Xinchao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.10720",
    "title": "Exploring the Relationship between Samples and Masks for Robust Defect  Localization",
    "abstract": " Title: Exploring the Relationship between Samples and Masks for Robust Defect  Localization ",
    "url": "https://arxiv.org/abs/2306.10720",
    "authors": [
      "Jiang Lin",
      "Yaping Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2306.16741",
    "title": "Foundation Model for Endoscopy Video Analysis via Large-scale  Self-supervised Pre-train",
    "abstract": " Comments: MICCAI 2023 camera-ready version ",
    "url": "https://arxiv.org/abs/2306.16741",
    "authors": [
      "Zhao Wang",
      "Chang Liu",
      "Shaoting Zhang",
      "Qi Dou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.01766",
    "title": "Neural Poisson Surface Reconstruction: Resolution-Agnostic Shape  Reconstruction from Point Clouds",
    "abstract": " Title: Neural Poisson Surface Reconstruction: Resolution-Agnostic Shape  Reconstruction from Point Clouds ",
    "url": "https://arxiv.org/abs/2308.01766",
    "authors": [
      "Hector Andrade-Loarca",
      "Julius Hege",
      "Daniel Cremers",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2308.04638",
    "title": "GeoAdapt: Self-Supervised Test-Time Adaptation in LiDAR Place  Recognition Using Geometric Priors",
    "abstract": " Comments: Accepted to IEEE Robotics and Automation Letters (RA-L) November 2023 ",
    "url": "https://arxiv.org/abs/2308.04638",
    "authors": [
      "Joshua Knights",
      "Stephen Hausler",
      "Sridha Sridharan",
      "Clinton Fookes",
      "Peyman Moghadam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06107",
    "title": "Test-Time Backdoor Defense via Detecting and Repairing",
    "abstract": " Title: Test-Time Backdoor Defense via Detecting and Repairing ",
    "url": "https://arxiv.org/abs/2308.06107",
    "authors": [
      "Jiyang Guan",
      "Jian Liang",
      "Ran He"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.06703",
    "title": "Understanding the robustness difference between stochastic gradient  descent and adaptive gradient methods",
    "abstract": " Comments: Accepted at TMLR (Featured Certification). Code: see this https URL ",
    "url": "https://arxiv.org/abs/2308.06703",
    "authors": [
      "Avery Ma",
      "Yangchen Pan",
      "Amir-massoud Farahmand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2308.10743",
    "title": "Enhancing Adversarial Attacks: The Similar Target Method",
    "abstract": " Title: Enhancing Adversarial Attacks: The Similar Target Method ",
    "url": "https://arxiv.org/abs/2308.10743",
    "authors": [
      "Shuo Zhang",
      "Ziruo Wang",
      "Zikai Zhou",
      "Huanran Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2308.15068",
    "title": "A Comprehensive Augmentation Framework for Anomaly Detection",
    "abstract": " Title: A Comprehensive Augmentation Framework for Anomaly Detection ",
    "url": "https://arxiv.org/abs/2308.15068",
    "authors": [
      "Jiang Lin",
      "Yaping Yan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.15131",
    "title": "Robust Transceiver Design for Covert Integrated Sensing and  Communications With Imperfect CSI",
    "abstract": " Comments: This work has been submitted to IEEE journal for publication ",
    "url": "https://arxiv.org/abs/2308.15131",
    "authors": [
      "Yuchen Zhang",
      "Wanli Ni",
      "Jianquan Wang",
      "Wanbin Tang",
      "Min Jia",
      "Yonina C. Eldar",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2309.06800",
    "title": "Uncertainty-aware Traffic Prediction under Missing Data",
    "abstract": " Comments: 11 pages, 3 figures, a short version of this paper is accepted by ICDM 2023 ",
    "url": "https://arxiv.org/abs/2309.06800",
    "authors": [
      "Hao Mei",
      "Junxian Li",
      "Zhiming Liang",
      "Guanjie Zheng",
      "Bin Shi",
      "Hua Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2309.12931",
    "title": "On Separate Normalization in Self-supervised Transformers",
    "abstract": " Comments: NIPS 2023 ",
    "url": "https://arxiv.org/abs/2309.12931",
    "authors": [
      "Xiaohui Chen",
      "Yinkai Wang",
      "Yuanqi Du",
      "Soha Hassoun",
      "Li-Ping Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2309.14327",
    "title": "DeepSpeed-VisualChat: Multi-Round Multi-Image Interleave Chat via  Multi-Modal Causal Attention",
    "abstract": " Title: DeepSpeed-VisualChat: Multi-Round Multi-Image Interleave Chat via  Multi-Modal Causal Attention ",
    "url": "https://arxiv.org/abs/2309.14327",
    "authors": [
      "Zhewei Yao",
      "Xiaoxia Wu",
      "Conglong Li",
      "Minjia Zhang",
      "Heyang Qin",
      "Olatunji Ruwase",
      "Ammar Ahmad Awan",
      "Samyam Rajbhandari",
      "Yuxiong He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.00402",
    "title": "DiskANN++: Efficient Page-based Search over Isomorphic Mapped Graph  Index using Query-sensitivity Entry Vertex",
    "abstract": " Comments: 15 pages including references ",
    "url": "https://arxiv.org/abs/2310.00402",
    "authors": [
      "Jiongkang Ni",
      "Xiaoliang Xu",
      "Yuxiang Wang",
      "Can Li",
      "Jiajie Yao",
      "Shihai Xiao",
      "Xuecang Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2310.00965",
    "title": "Effective Learning with Node Perturbation in Deep Neural Networks",
    "abstract": " Title: Effective Learning with Node Perturbation in Deep Neural Networks ",
    "url": "https://arxiv.org/abs/2310.00965",
    "authors": [
      "Sander Dalm",
      "Marcel van Gerven",
      "Nasir Ahmad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.03605",
    "title": "FASER: Binary Code Similarity Search through the use of Intermediate  Representations",
    "abstract": " Comments: 10 pages, Proceedings of the Conference on Applied Machine Learning in Information Security (CAMLIS) ",
    "url": "https://arxiv.org/abs/2310.03605",
    "authors": [
      "Josh Collyer",
      "Tim Watson",
      "Iain Phillips"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.03684",
    "title": "SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks",
    "abstract": " Title: SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks ",
    "url": "https://arxiv.org/abs/2310.03684",
    "authors": [
      "Alexander Robey",
      "Eric Wong",
      "Hamed Hassani",
      "George J. Pappas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.05989",
    "title": "DynamicBEV: Leveraging Dynamic Queries and Temporal Context for 3D  Object Detection",
    "abstract": " Title: DynamicBEV: Leveraging Dynamic Queries and Temporal Context for 3D  Object Detection ",
    "url": "https://arxiv.org/abs/2310.05989",
    "authors": [
      "Jiawei Yao",
      "Yingxin Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.06530",
    "title": "Refining Decompiled C Code with Large Language Models",
    "abstract": " Title: Refining Decompiled C Code with Large Language Models ",
    "url": "https://arxiv.org/abs/2310.06530",
    "authors": [
      "Wai Kin Wong",
      "Huaijin Wang",
      "Zongjie Li",
      "Zhibo Liu",
      "Shuai Wang",
      "Qiyi Tang",
      "Sen Nie",
      "Shi Wu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.09932",
    "title": "\"Reading Between the Heat\": Co-Teaching Body Thermal Signatures for  Non-intrusive Stress Detection",
    "abstract": " Comments: 29 pages ",
    "url": "https://arxiv.org/abs/2310.09932",
    "authors": [
      "Yi Xiao",
      "Harshit Sharma",
      "Zhongyang Zhang",
      "Dessa Bergen-Cico",
      "Tauhidur Rahman",
      "Asif Salekin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.09949",
    "title": "Chameleon: a heterogeneous and disaggregated accelerator system for  retrieval-augmented language models",
    "abstract": " Title: Chameleon: a heterogeneous and disaggregated accelerator system for  retrieval-augmented language models ",
    "url": "https://arxiv.org/abs/2310.09949",
    "authors": [
      "Wenqi Jiang",
      "Marco Zeller",
      "Roger Waleffe",
      "Torsten Hoefler",
      "Gustavo Alonso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.16267",
    "title": "Student Classroom Behavior Detection based on Spatio-Temporal Network  and Multi-Model Fusion",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2310.02522; text overlap with arXiv:2306.03318 ",
    "url": "https://arxiv.org/abs/2310.16267",
    "authors": [
      "Fan Yang",
      "Xiaofei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.20208",
    "title": "ZoomNeXt: A Unified Collaborative Pyramid Network for Camouflaged Object  Detection",
    "abstract": " Comments: Extensions to the conference version: arXiv:2203.02688; Fixed some word errors ",
    "url": "https://arxiv.org/abs/2310.20208",
    "authors": [
      "Youwei Pang",
      "Xiaoqi Zhao",
      "Tian-Zhu Xiang",
      "Lihe Zhang",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.00423",
    "title": "LLMRec: Large Language Models with Graph Augmentation for Recommendation",
    "abstract": " Comments: WSDM 2024 Oral Presentation ",
    "url": "https://arxiv.org/abs/2311.00423",
    "authors": [
      "Wei Wei",
      "Xubin Ren",
      "Jiabin Tang",
      "Qinyong Wang",
      "Lixin Su",
      "Suqi Cheng",
      "Junfeng Wang",
      "Dawei Yin",
      "Chao Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2311.07965",
    "title": "DQR-TTS: Semi-supervised Text-to-speech Synthesis with Dynamic Quantized  Representation",
    "abstract": " Comments: Accepted by the 21st IEEE International Symposium on Parallel and Distributed Processing with Applications (IEEE ISPA 2023) ",
    "url": "https://arxiv.org/abs/2311.07965",
    "authors": [
      "Jiangzong Wang",
      "Pengcheng Li",
      "Xulong Zhang",
      "Ning Cheng",
      "Jing Xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2311.10642",
    "title": "Rethinking Attention: Exploring Shallow Feed-Forward Neural Networks as  an Alternative to Attention Layers in Transformers",
    "abstract": " Comments: Accepted at AAAI24(this https URL) ",
    "url": "https://arxiv.org/abs/2311.10642",
    "authors": [
      "Vukasin Bozic",
      "Danilo Dordevic",
      "Daniele Coppola",
      "Joseph Thommes",
      "Sidak Pal Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.12754",
    "title": "SelfOcc: Self-Supervised Vision-Based 3D Occupancy Prediction",
    "abstract": " Comments: Code is available at: this https URL ",
    "url": "https://arxiv.org/abs/2311.12754",
    "authors": [
      "Yuanhui Huang",
      "Wenzhao Zheng",
      "Borui Zhang",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2311.13010",
    "title": "Beyond Catoni: Sharper Rates for Heavy-Tailed and Robust Mean Estimation",
    "abstract": " Comments: Error in proof of Theorem 1.1 ",
    "url": "https://arxiv.org/abs/2311.13010",
    "authors": [
      "Shivam Gupta",
      "Samuel B. Hopkins",
      "Eric Price"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2311.13187",
    "title": "NeISF: Neural Incident Stokes Field for Geometry and Material Estimation",
    "abstract": " Title: NeISF: Neural Incident Stokes Field for Geometry and Material Estimation ",
    "url": "https://arxiv.org/abs/2311.13187",
    "authors": [
      "Chenhao Li",
      "Taishi Ono",
      "Takeshi Uemori",
      "Hajime Mihara",
      "Alexander Gatto",
      "Hajime Nagahara",
      "Yusuke Moriuchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.14706",
    "title": "Social AI Improves Well-Being Among Female Young Adults",
    "abstract": " Title: Social AI Improves Well-Being Among Female Young Adults ",
    "url": "https://arxiv.org/abs/2311.14706",
    "authors": [
      "Ebony Zhang",
      "Xiaoding Lu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2311.14897",
    "title": "Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via  3D Anomaly Synthesis and A Self-Supervised Learning Network",
    "abstract": " Title: Towards Scalable 3D Anomaly Detection and Localization: A Benchmark via  3D Anomaly Synthesis and A Self-Supervised Learning Network ",
    "url": "https://arxiv.org/abs/2311.14897",
    "authors": [
      "Wenqiao Li",
      "Xiaohao Xu",
      "Yao Gu",
      "Bozhong Zheng",
      "Shenghua Gao",
      "Yingna Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.15940",
    "title": "Physics-informed neural networks for transformed geometries and  manifolds",
    "abstract": " Title: Physics-informed neural networks for transformed geometries and  manifolds ",
    "url": "https://arxiv.org/abs/2311.15940",
    "authors": [
      "Samuel Burbulla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2311.15994",
    "title": "Adversarial Doodles: Interpretable and Human-drawable Attacks Provide  Describable Insights",
    "abstract": " Title: Adversarial Doodles: Interpretable and Human-drawable Attacks Provide  Describable Insights ",
    "url": "https://arxiv.org/abs/2311.15994",
    "authors": [
      "Ryoya Nara",
      "Yusuke Matsui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16519",
    "title": "B-LSTM-MIONet: Bayesian LSTM-based Neural Operators for Learning the  Response of Complex Dynamical Systems to Length-Variant Multiple Input  Functions",
    "abstract": " Title: B-LSTM-MIONet: Bayesian LSTM-based Neural Operators for Learning the  Response of Complex Dynamical Systems to Length-Variant Multiple Input  Functions ",
    "url": "https://arxiv.org/abs/2311.16519",
    "authors": [
      "Zhihao Kong",
      "Amirhossein Mollaali",
      "Christian Moya",
      "Na Lu",
      "Guang Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2311.16668",
    "title": "LiveNVS: Neural View Synthesis on Live RGB-D Streams",
    "abstract": " Comments: main paper: 8 pages, total number of pages: 15, 13 figures, to be published in SIGGRAPH Asia 2023 Conference Papers; edits: link was fixed ",
    "url": "https://arxiv.org/abs/2311.16668",
    "authors": [
      "Laura Fink",
      "Darius R\u00fcckert",
      "Linus Franke",
      "Joachim Keinert",
      "Marc Stamminger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2311.16834",
    "title": "Modular Neural Networks for Time Series Forecasting: Interpretability  and Feature Selection using Attention",
    "abstract": " Title: Modular Neural Networks for Time Series Forecasting: Interpretability  and Feature Selection using Attention ",
    "url": "https://arxiv.org/abs/2311.16834",
    "authors": [
      "Qiqi Su",
      "Christos Kloukinas",
      "Artur d'Avila Garcez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2311.16835",
    "title": "Unified-modal Salient Object Detection via Adaptive Prompt Learning",
    "abstract": " Comments: 15 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2311.16835",
    "authors": [
      "Kunpeng Wang",
      "Chenglong Li",
      "Zhengzheng Tu",
      "Bin Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2311.16883",
    "title": "Compressing the Backward Pass of Large-Scale Neural Architectures by  Structured Activation Pruning",
    "abstract": " Comments: 8 pages, 11 figures, submitted to the 6th AccML workshop at HiPEAC conference 2024 ",
    "url": "https://arxiv.org/abs/2311.16883",
    "authors": [
      "Daniel Barley",
      "Holger Fr\u00f6ning"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2311.16953",
    "title": "Local certification of geometric graph classes",
    "abstract": " Comments: 36 pages, 16 figures; v2: new reference added ",
    "url": "https://arxiv.org/abs/2311.16953",
    "authors": [
      "Oscar Defrain",
      "Louis Esperet",
      "Aur\u00e9lie Lagoutte",
      "Pat Morin",
      "Jean-Florent Raymond"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  }
]