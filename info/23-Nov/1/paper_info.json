[
  {
    "id": "arXiv:2310.19801",
    "title": "SyMPox: An Automated Monkeypox Detection System Based on Symptoms Using  XGBoost",
    "abstract": "Monkeypox is a zoonotic disease. About 87000 cases of monkeypox were confirmed by the World Health Organization until 10th June 2023. The most prevalent methods for identifying this disease are image-based recognition techniques. Still, they are not too fast and could only be available to a few individuals. This study presents an independent application named SyMPox, developed to diagnose Monkeypox cases based on symptoms. SyMPox utilizes the robust XGBoost algorithm to analyze symptom patterns and provide accurate assessments. Developed using the Gradio framework, SyMPox offers a user-friendly platform for individuals to assess their symptoms and obtain reliable Monkeypox diagnoses. ",
    "url": "https://arxiv.org/abs/2310.19801",
    "authors": [
      "Alireza Farzipour",
      "Roya Elmi",
      "Hamid Nasiri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.19805",
    "title": "SERA:Sample Efficient Reward Augmentation in offline-to-online  Reinforcement Learning",
    "abstract": "A prospective application of offline reinforcement learning (RL) involves initializing a pre-trained policy using existing static datasets for subsequent online fine-tuning. However, direct fine-tuning of the offline pre-trained policy often results in sub-optimal performance. A primary reason is that offline conservative methods diminish the agent's capability of exploration, thereby impacting online fine-tuning performance. To enhance exploration during online fine-tuning and thus enhance the overall online fine-tuning performance, we introduce a generalized reward augmentation framework called Sample Efficient Reward Augmentation (SERA). SERA aims to improve the performance of online fine-tuning by designing intrinsic rewards that encourage the agent to explore. Specifically, it implicitly implements State Marginal Matching (SMM) and penalizes out-of-distribution (OOD) state actions, thus encouraging agents to cover the target state density, and achieving better online fine-tuning results. Additionally, SERA can be effortlessly plugged into various RL algorithms to improve online fine-tuning and ensure sustained asymptotic improvement, showing the versatility as well as the effectiveness of SERA. Moreover, extensive experimental results will demonstrate that when conducting offline-to-online problems, SERA consistently and effectively enhances the performance of various offline algorithms. ",
    "url": "https://arxiv.org/abs/2310.19805",
    "authors": [
      "Ziqi Zhang",
      "Xiao Xiong",
      "Zifeng Zhuang",
      "Jinxin Liu",
      "Donglin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.19815",
    "title": "Training binary neural networks without floating point precision",
    "abstract": "The main goal of this work is to improve the efficiency of training binary neural networks, which are low latency and low energy networks. The main contribution of this work is the proposal of two solutions comprised of topology changes and strategy training that allow the network to achieve near the state-of-the-art performance and efficient training. The time required for training and the memory required in the process are two factors that contribute to efficient training. ",
    "url": "https://arxiv.org/abs/2310.19815",
    "authors": [
      "Federico Fontana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.19819",
    "title": "Machine Learning and Knowledge: Why Robustness Matters",
    "abstract": "Trusting machine learning algorithms requires having confidence in their outputs. Confidence is typically interpreted in terms of model reliability, where a model is reliable if it produces a high proportion of correct outputs. However, model reliability does not address concerns about the robustness of machine learning models, such as models relying on the wrong features or variations in performance based on context. I argue that the epistemic dimension of trust can instead be understood through the concept of knowledge, where the trustworthiness of an algorithm depends on whether its users are in the position to know that its outputs are correct. Knowledge requires beliefs to be formed for the right reasons and to be robust to error, so machine learning algorithms can only provide knowledge if they work well across counterfactual scenarios and if they make decisions based on the right features. This, I argue, can explain why we should care about model properties like interpretability, causal shortcut independence, and distribution shift robustness even if such properties are not required for model reliability. ",
    "url": "https://arxiv.org/abs/2310.19819",
    "authors": [
      "Jonathan Vandenburgh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.19845",
    "title": "Modified Genetic Algorithm for Feature Selection and Hyper Parameter  Optimization: Case of XGBoost in Spam Prediction",
    "abstract": "Recently, spam on online social networks has attracted attention in the research and business world. Twitter has become the preferred medium to spread spam content. Many research efforts attempted to encounter social networks spam. Twitter brought extra challenges represented by the feature space size, and imbalanced data distributions. Usually, the related research works focus on part of these main challenges or produce black-box models. In this paper, we propose a modified genetic algorithm for simultaneous dimensionality reduction and hyper parameter optimization over imbalanced datasets. The algorithm initialized an eXtreme Gradient Boosting classifier and reduced the features space of tweets dataset; to generate a spam prediction model. The model is validated using a 50 times repeated 10-fold stratified cross-validation, and analyzed using nonparametric statistical tests. The resulted prediction model attains on average 82.32\\% and 92.67\\% in terms of geometric mean and accuracy respectively, utilizing less than 10\\% of the total feature space. The empirical results show that the modified genetic algorithm outperforms $Chi^2$ and $PCA$ feature selection methods. In addition, eXtreme Gradient Boosting outperforms many machine learning algorithms, including BERT-based deep learning model, in spam prediction. Furthermore, the proposed approach is applied to SMS spam modeling and compared to related works. ",
    "url": "https://arxiv.org/abs/2310.19845",
    "authors": [
      "Nazeeh Ghatasheh",
      "Ismail Altaharwa",
      "Khaled Aldebei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.19898",
    "title": "MIST: Medical Image Segmentation Transformer with Convolutional  Attention Mixing (CAM) Decoder",
    "abstract": "One of the common and promising deep learning approaches used for medical image segmentation is transformers, as they can capture long-range dependencies among the pixels by utilizing self-attention. Despite being successful in medical image segmentation, transformers face limitations in capturing local contexts of pixels in multimodal dimensions. We propose a Medical Image Segmentation Transformer (MIST) incorporating a novel Convolutional Attention Mixing (CAM) decoder to address this issue. MIST has two parts: a pre-trained multi-axis vision transformer (MaxViT) is used as an encoder, and the encoded feature representation is passed through the CAM decoder for segmenting the images. In the CAM decoder, an attention-mixer combining multi-head self-attention, spatial attention, and squeeze and excitation attention modules is introduced to capture long-range dependencies in all spatial dimensions. Moreover, to enhance spatial information gain, deep and shallow convolutions are used for feature extraction and receptive field expansion, respectively. The integration of low-level and high-level features from different network stages is enabled by skip connections, allowing MIST to suppress unnecessary information. The experiments show that our MIST transformer with CAM decoder outperforms the state-of-the-art models specifically designed for medical image segmentation on the ACDC and Synapse datasets. Our results also demonstrate that adding the CAM decoder with a hierarchical transformer improves segmentation performance significantly. Our model with data and code is publicly available on GitHub. ",
    "url": "https://arxiv.org/abs/2310.19898",
    "authors": [
      "Md Motiur Rahman",
      "Shiva Shokouhmand",
      "Smriti Bhatt",
      "Miad Faezipour"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19903",
    "title": "A Multi-agent Reinforcement Learning Study of Emergence of Social  Classes out of Arbitrary Governance: The Role of Environment",
    "abstract": "There are several theories in economics regarding the roots or causes of prosperity in a society. One of these theories or hypotheses -- named geography hypothesis -- mentions that the reason why some countries are prosperous and some others are poor is the geographical location of the countries in the world as makes their climate and environment favorable or unfavorable regarding natural resources. Another competing hypothesis states that man-made institutions particularly inclusive political institutions are the reasons why some countries are prosperous and some others are poor. On the other hand, there is a specific political theory developed for the long-term social development in Iran -- named Arbitrary Rule and Aridisolatic Society which particularly emphasizes on the role of aridity to shape arbitrary political and economical institutions in Iran, without any functional social classes in the society. In this paper, by extending the AI-Economist -- a recently developed two-level multi-agent reinforcement learning environment -- I show that when the central planner is ruling the environment by arbitrary rules, the society evolves through different paths in different environments. In the environment having band-like vertical isolated patches of natural resources, all mobile agents are equally exploited by the central planner and the central planner is also not gaining any income, while in the society having more uniformly distributed natural resources, the productivity and Maximin are higher and the society generates a heterogeneous stratified social structure. All these findings provide a partial answer to the above debate and reconcile the role of geography and political institutions on the long-term development in a region. ",
    "url": "https://arxiv.org/abs/2310.19903",
    "authors": [
      "Aslan S. Dizaji"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2310.19906",
    "title": "Interpretable Prototype-based Graph Information Bottleneck",
    "abstract": "The success of Graph Neural Networks (GNNs) has led to a need for understanding their decision-making process and providing explanations for their predictions, which has given rise to explainable AI (XAI) that offers transparent explanations for black-box models. Recently, the use of prototypes has successfully improved the explainability of models by learning prototypes to imply training graphs that affect the prediction. However, these approaches tend to provide prototypes with excessive information from the entire graph, leading to the exclusion of key substructures or the inclusion of irrelevant substructures, which can limit both the interpretability and the performance of the model in downstream tasks. In this work, we propose a novel framework of explainable GNNs, called interpretable Prototype-based Graph Information Bottleneck (PGIB) that incorporates prototype learning within the information bottleneck framework to provide prototypes with the key subgraph from the input graph that is important for the model prediction. This is the first work that incorporates prototype learning into the process of identifying the key subgraphs that have a critical impact on the prediction performance. Extensive experiments, including qualitative analysis, demonstrate that PGIB outperforms state-of-the-art methods in terms of both prediction performance and explainability. ",
    "url": "https://arxiv.org/abs/2310.19906",
    "authors": [
      "Sangwoo Seo",
      "Sungwon Kim",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.19917",
    "title": "Unmasking Bias and Inequities: A Systematic Review of Bias Detection and  Mitigation in Healthcare Artificial Intelligence Using Electronic Health  Records",
    "abstract": "Objectives: Artificial intelligence (AI) applications utilizing electronic health records (EHRs) have gained popularity, but they also introduce various types of bias. This study aims to systematically review the literature that address bias in AI research utilizing EHR data. Methods: A systematic review was conducted following the Preferred Reporting Items for Systematic Reviews and Meta-analyses (PRISMA) guideline. We retrieved articles published between January 1, 2010, and October 31, 2022, from PubMed, Web of Science, and the Institute of Electrical and Electronics Engineers. We defined six major types of bias and summarized the existing approaches in bias handling. Results: Out of the 252 retrieved articles, 20 met the inclusion criteria for the final review. Five out of six bias were covered in this review: eight studies analyzed selection bias; six on implicit bias; five on confounding bias; four on measurement bias; two on algorithmic bias. For bias handling approaches, ten studies identified bias during model development, while seventeen presented methods to mitigate the bias. Discussion: Bias may infiltrate the AI application development process at various stages. Although this review discusses methods for addressing bias at different development stages, there is room for implementing additional effective approaches. Conclusion: Despite growing attention to bias in healthcare AI, research using EHR data on this topic is still limited. Detecting and mitigating AI bias with EHR data continues to pose challenges. Further research is needed to raise a standardized method that is generalizable and interpretable to detect, mitigate and evaluate bias in medical AI. ",
    "url": "https://arxiv.org/abs/2310.19917",
    "authors": [
      "Feng Chen",
      "Liqin Wang",
      "Julie Hong",
      "Jiaqi Jiang",
      "Li Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2310.19919",
    "title": "Meta-Learning Strategies through Value Maximization in Neural Networks",
    "abstract": "Biological and artificial learning agents face numerous choices about how to learn, ranging from hyperparameter selection to aspects of task distributions like curricula. Understanding how to make these meta-learning choices could offer normative accounts of cognitive control functions in biological learners and improve engineered systems. Yet optimal strategies remain challenging to compute in modern deep networks due to the complexity of optimizing through the entire learning process. Here we theoretically investigate optimal strategies in a tractable setting. We present a learning effort framework capable of efficiently optimizing control signals on a fully normative objective: discounted cumulative performance throughout learning. We obtain computational tractability by using average dynamical equations for gradient descent, available for simple neural network architectures. Our framework accommodates a range of meta-learning and automatic curriculum learning methods in a unified normative setting. We apply this framework to investigate the effect of approximations in common meta-learning algorithms; infer aspects of optimal curricula; and compute optimal neuronal resource allocation in a continual learning setting. Across settings, we find that control effort is most beneficial when applied to easier aspects of a task early in learning; followed by sustained effort on harder aspects. Overall, the learning effort framework provides a tractable theoretical test bed to study normative benefits of interventions in a variety of learning systems, as well as a formal account of optimal cognitive control strategies over learning trajectories posited by established theories in cognitive neuroscience. ",
    "url": "https://arxiv.org/abs/2310.19919",
    "authors": [
      "Rodrigo Carrasco-Davis",
      "Javier Mas\u00eds",
      "Andrew M. Saxe"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2310.19932",
    "title": "Sim2Real for Environmental Neural Processes",
    "abstract": "Machine learning (ML)-based weather models have recently undergone rapid improvements. These models are typically trained on gridded reanalysis data from numerical data assimilation systems. However, reanalysis data comes with limitations, such as assumptions about physical laws and low spatiotemporal resolution. The gap between reanalysis and reality has sparked growing interest in training ML models directly on observations such as weather stations. Modelling scattered and sparse environmental observations requires scalable and flexible ML architectures, one of which is the convolutional conditional neural process (ConvCNP). ConvCNPs can learn to condition on both gridded and off-the-grid context data to make uncertainty-aware predictions at target locations. However, the sparsity of real observations presents a challenge for data-hungry deep learning models like the ConvCNP. One potential solution is 'Sim2Real': pre-training on reanalysis and fine-tuning on observational data. We analyse Sim2Real with a ConvCNP trained to interpolate surface air temperature over Germany, using varying numbers of weather stations for fine-tuning. On held-out weather stations, Sim2Real training substantially outperforms the same model architecture trained only with reanalysis data or only with station data, showing that reanalysis data can serve as a stepping stone for learning from real observations. Sim2Real could thus enable more accurate models for weather prediction and climate monitoring. ",
    "url": "https://arxiv.org/abs/2310.19932",
    "authors": [
      "Jonas Scholz",
      "Tom R. Andersson",
      "Anna Vaughan",
      "James Requeima",
      "Richard E. Turner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2310.19938",
    "title": "Lyapunov-Based Dropout Deep Neural Network (Lb-DDNN) Controller",
    "abstract": "Deep neural network (DNN)-based adaptive controllers can be used to compensate for unstructured uncertainties in nonlinear dynamic systems. However, DNNs are also very susceptible to overfitting and co-adaptation. Dropout regularization is an approach where nodes are randomly dropped during training to alleviate issues such as overfitting and co-adaptation. In this paper, a dropout DNN-based adaptive controller is developed. The developed dropout technique allows the deactivation of weights that are stochastically selected for each individual layer within the DNN. Simultaneously, a Lyapunov-based real-time weight adaptation law is introduced to update the weights of all layers of the DNN for online unsupervised learning. A non-smooth Lyapunov-based stability analysis is performed to ensure asymptotic convergence of the tracking error. Simulation results of the developed dropout DNN-based adaptive controller indicate a 38.32% improvement in the tracking error, a 53.67% improvement in the function approximation error, and 50.44% lower control effort when compared to a baseline adaptive DNN-based controller without dropout regularization. ",
    "url": "https://arxiv.org/abs/2310.19938",
    "authors": [
      "Saiedeh Akbari",
      "Emily J. Griffis",
      "Omkar Sudhir Patil",
      "Warren E. Dixon"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19943",
    "title": "The Acquisition of Physical Knowledge in Generative Neural Networks",
    "abstract": "As children grow older, they develop an intuitive understanding of the physical processes around them. Their physical understanding develops in stages, moving along developmental trajectories which have been mapped out extensively in previous empirical research. Here, we investigate how the learning trajectories of deep generative neural networks compare to children's developmental trajectories using physical understanding as a testbed. We outline an approach that allows us to examine two distinct hypotheses of human development - stochastic optimization and complexity increase. We find that while our models are able to accurately predict a number of physical processes, their learning trajectories under both hypotheses do not follow the developmental trajectories of children. ",
    "url": "https://arxiv.org/abs/2310.19943",
    "authors": [
      "Luca M. Schulze Buschoff",
      "Eric Schulz",
      "Marcel Binz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2310.19944",
    "title": "Conditional Unscented Autoencoders for Trajectory Prediction",
    "abstract": "The \\ac{CVAE} is one of the most widely-used models in trajectory prediction for \\ac{AD}. It captures the interplay between a driving context and its ground-truth future into a probabilistic latent space and uses it to produce predictions. In this paper, we challenge key components of the CVAE. We leverage recent advances in the space of the VAE, the foundation of the CVAE, which show that a simple change in the sampling procedure can greatly benefit performance. We find that unscented sampling, which draws samples from any learned distribution in a deterministic manner, can naturally be better suited to trajectory prediction than potentially dangerous random sampling. We go further and offer additional improvements, including a more structured mixture latent space, as well as a novel, potentially more expressive way to do inference with CVAEs. We show wide applicability of our models by evaluating them on the INTERACTION prediction dataset, outperforming the state of the art, as well as at the task of image modeling on the CelebA dataset, outperforming the baseline vanilla CVAE. Code is available at https://github.com/boschresearch/cuae-prediction. ",
    "url": "https://arxiv.org/abs/2310.19944",
    "authors": [
      "Faris Janjo\u0161",
      "Marcel Hallgarten",
      "Anthony Knittel",
      "Maxim Dolgov",
      "Andreas Zell",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19958",
    "title": "PriPrune: Quantifying and Preserving Privacy in Pruned Federated  Learning",
    "abstract": "Federated learning (FL) is a paradigm that allows several client devices and a server to collaboratively train a global model, by exchanging only model updates, without the devices sharing their local training data. These devices are often constrained in terms of communication and computation resources, and can further benefit from model pruning -- a paradigm that is widely used to reduce the size and complexity of models. Intuitively, by making local models coarser, pruning is expected to also provide some protection against privacy attacks in the context of FL. However this protection has not been previously characterized, formally or experimentally, and it is unclear if it is sufficient against state-of-the-art attacks. In this paper, we perform the first investigation of privacy guarantees for model pruning in FL. We derive information-theoretic upper bounds on the amount of information leaked by pruned FL models. We complement and validate these theoretical findings, with comprehensive experiments that involve state-of-the-art privacy attacks, on several state-of-the-art FL pruning schemes, using benchmark datasets. This evaluation provides valuable insights into the choices and parameters that can affect the privacy protection provided by pruning. Based on these insights, we introduce PriPrune -- a privacy-aware algorithm for local model pruning, which uses a personalized per-client defense mask and adapts the defense pruning rate so as to jointly optimize privacy and model performance. PriPrune is universal in that can be applied after any pruned FL scheme on the client, without modification, and protects against any inversion attack by the server. Our empirical evaluation demonstrates that PriPrune significantly improves the privacy-accuracy tradeoff compared to state-of-the-art pruned FL schemes that do not take privacy into account. ",
    "url": "https://arxiv.org/abs/2310.19958",
    "authors": [
      "Tianyue Chu",
      "Mengwei Yang",
      "Nikolaos Laoutaris",
      "Athina Markopoulou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2310.19967",
    "title": "Early detection of inflammatory arthritis to improve referrals using  multimodal machine learning from blood testing, semi-structured and  unstructured patient records",
    "abstract": "Early detection of inflammatory arthritis (IA) is critical to efficient and accurate hospital referral triage for timely treatment and preventing the deterioration of the IA disease course, especially under limited healthcare resources. The manual assessment process is the most common approach in practice for the early detection of IA, but it is extremely labor-intensive and inefficient. A large amount of clinical information needs to be assessed for every referral from General Practice (GP) to the hospitals. Machine learning shows great potential in automating repetitive assessment tasks and providing decision support for the early detection of IA. However, most machine learning-based methods for IA detection rely on blood testing results. But in practice, blood testing data is not always available at the point of referrals, so we need methods to leverage multimodal data such as semi-structured and unstructured data for early detection of IA. In this research, we present fusion and ensemble learning-based methods using multimodal data to assist decision-making in the early detection of IA. To the best of our knowledge, our study is the first attempt to utilize multimodal data to support the early detection of IA from GP referrals. ",
    "url": "https://arxiv.org/abs/2310.19967",
    "authors": [
      "Bing Wang",
      "Weizi Li",
      "Anthony Bradlow",
      "Antoni T.Y. Chan",
      "Eghosa Bazuaye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19991",
    "title": "PolyThrottle: Energy-efficient Neural Network Inference on Edge Devices",
    "abstract": "As neural networks (NN) are deployed across diverse sectors, their energy demand correspondingly grows. While several prior works have focused on reducing energy consumption during training, the continuous operation of ML-powered systems leads to significant energy use during inference. This paper investigates how the configuration of on-device hardware-elements such as GPU, memory, and CPU frequency, often neglected in prior studies, affects energy consumption for NN inference with regular fine-tuning. We propose PolyThrottle, a solution that optimizes configurations across individual hardware components using Constrained Bayesian Optimization in an energy-conserving manner. Our empirical evaluation uncovers novel facets of the energy-performance equilibrium showing that we can save up to 36 percent of energy for popular models. We also validate that PolyThrottle can quickly converge towards near-optimal settings while satisfying application constraints. ",
    "url": "https://arxiv.org/abs/2310.19991",
    "authors": [
      "Minghao Yan",
      "Hongyi Wang",
      "Shivaram Venkataraman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2310.19998",
    "title": "Generative retrieval-augmented ontologic graph and multi-agent  strategies for interpretive large language model-based materials design",
    "abstract": "Transformer neural networks show promising capabilities, in particular for uses in materials analysis, design and manufacturing, including their capacity to work effectively with both human language, symbols, code, and numerical data. Here we explore the use of large language models (LLMs) as a tool that can support engineering analysis of materials, applied to retrieving key information about subject areas, developing research hypotheses, discovery of mechanistic relationships across disparate areas of knowledge, and writing and executing simulation codes for active knowledge generation based on physical ground truths. When used as sets of AI agents with specific features, capabilities, and instructions, LLMs can provide powerful problem solution strategies for applications in analysis and design problems. Our experiments focus on using a fine-tuned model, MechGPT, developed based on training data in the mechanics of materials domain. We first affirm how finetuning endows LLMs with reasonable understanding of domain knowledge. However, when queried outside the context of learned matter, LLMs can have difficulty to recall correct information. We show how this can be addressed using retrieval-augmented Ontological Knowledge Graph strategies that discern how the model understands what concepts are important and how they are related. Illustrated for a use case of relating distinct areas of knowledge - here, music and proteins - such strategies can also provide an interpretable graph structure with rich information at the node, edge and subgraph level. We discuss nonlinear sampling strategies and agent-based modeling applied to complex question answering, code generation and execution in the context of automated force field development from actively learned Density Functional Theory (DFT) modeling, and data analysis. ",
    "url": "https://arxiv.org/abs/2310.19998",
    "authors": [
      "Markus J. Buehler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Applied Physics (physics.app-ph)"
    ]
  },
  {
    "id": "arXiv:2310.20003",
    "title": "Early Detection of Depression and Eating Disorders in Spanish: UNSL at  MentalRiskES 2023",
    "abstract": "MentalRiskES is a novel challenge that proposes to solve problems related to early risk detection for the Spanish language. The objective is to detect, as soon as possible, Telegram users who show signs of mental disorders considering different tasks. Task 1 involved the users' detection of eating disorders, Task 2 focused on depression detection, and Task 3 aimed at detecting an unknown disorder. These tasks were divided into subtasks, each one defining a resolution approach. Our research group participated in subtask A for Tasks 1 and 2: a binary classification problem that evaluated whether the users were positive or negative. To solve these tasks, we proposed models based on Transformers followed by a decision policy according to criteria defined by an early detection framework. One of the models presented an extended vocabulary with important words for each task to be solved. In addition, we applied a decision policy based on the history of predictions that the model performs during user evaluation. For Tasks 1 and 2, we obtained the second-best performance according to rankings based on classification and latency, demonstrating the effectiveness and consistency of our approaches for solving early detection problems in the Spanish language. ",
    "url": "https://arxiv.org/abs/2310.20003",
    "authors": [
      "Horacio Thompson",
      "Marcelo Errecalde"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.20008",
    "title": "Evolutionary Tabletop Game Design: A Case Study in the Risk Game",
    "abstract": "Creating and evaluating games manually is an arduous and laborious task. Procedural content generation can aid by creating game artifacts, but usually not an entire game. Evolutionary game design, which combines evolutionary algorithms with automated playtesting, has been used to create novel board games with simple equipment; however, the original approach does not include complex tabletop games with dice, cards, and maps. This work proposes an extension of the approach for tabletop games, evaluating the process by generating variants of Risk, a military strategy game where players must conquer map territories to win. We achieved this using a genetic algorithm to evolve the chosen parameters, as well as a rules-based agent to test the games and a variety of quality criteria to evaluate the new variations generated. Our results show the creation of new variations of the original game with smaller maps, resulting in shorter matches. Also, the variants produce more balanced matches, maintaining the usual drama. We also identified limitations in the process, where, in many cases, where the objective function was correctly pursued, but the generated games were nearly trivial. This work paves the way towards promising research regarding the use of evolutionary game design beyond classic board games. ",
    "url": "https://arxiv.org/abs/2310.20008",
    "authors": [
      "Lana Bertoldo Rossato",
      "Leonardo Boaventura Bombardelli",
      "Anderson Rocha Tavares"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.20024",
    "title": "Topology Recoverability Prediction for Ad-Hoc Robot Networks: A  Data-Driven Fault-Tolerant Approach",
    "abstract": "Faults occurring in ad-hoc robot networks may fatally perturb their topologies leading to disconnection of subsets of those networks. Optimal topology synthesis is generally resource-intensive and time-consuming to be done in real time for large ad-hoc robot networks. One should only perform topology re-computations if the probability of topology recoverability after the occurrence of any fault surpasses that of its irrecoverability. We formulate this problem as a binary classification problem. Then, we develop a two-pathway data-driven model based on Bayesian Gaussian mixture models that predicts the solution to a typical problem by two different pre-fault and post-fault prediction pathways. The results, obtained by the integration of the predictions of those pathways, clearly indicate the success of our model in solving the topology (ir)recoverability prediction problem compared to the best of current strategies found in the literature. ",
    "url": "https://arxiv.org/abs/2310.20024",
    "authors": [
      "Matin Macktoobian",
      "Zhan Shu",
      "Qing Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2310.20052",
    "title": "Look At Me, No Replay! SurpriseNet: Anomaly Detection Inspired Class  Incremental Learning",
    "abstract": "Continual learning aims to create artificial neural networks capable of accumulating knowledge and skills through incremental training on a sequence of tasks. The main challenge of continual learning is catastrophic interference, wherein new knowledge overrides or interferes with past knowledge, leading to forgetting. An associated issue is the problem of learning \"cross-task knowledge,\" where models fail to acquire and retain knowledge that helps differentiate classes across task boundaries. A common solution to both problems is \"replay,\" where a limited buffer of past instances is utilized to learn cross-task knowledge and mitigate catastrophic interference. However, a notable drawback of these methods is their tendency to overfit the limited replay buffer. In contrast, our proposed solution, SurpriseNet, addresses catastrophic interference by employing a parameter isolation method and learning cross-task knowledge using an auto-encoder inspired by anomaly detection. SurpriseNet is applicable to both structured and unstructured data, as it does not rely on image-specific inductive biases. We have conducted empirical experiments demonstrating the strengths of SurpriseNet on various traditional vision continual-learning benchmarks, as well as on structured data datasets. Source code made available at https://doi.org/10.5281/zenodo.8247906 and https://github.com/tachyonicClock/SurpriseNet-CIKM-23 ",
    "url": "https://arxiv.org/abs/2310.20052",
    "authors": [
      "Anton Lee",
      "Yaqian Zhang",
      "Heitor Murilo Gomes",
      "Albert Bifet",
      "Bernhard Pfahringer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.20067",
    "title": "Vignat: Vulnerability identification by learning code semantics via  graph attention networks",
    "abstract": "Vulnerability identification is crucial to protect software systems from attacks for cyber-security. However, huge projects have more than millions of lines of code, and the complex dependencies make it hard to carry out traditional static and dynamic methods. Furthermore, the semantic structure of various types of vulnerabilities differs greatly and may occur simultaneously, making general rule-based methods difficult to extend. In this paper, we propose \\textit{Vignat}, a novel attention-based framework for identifying vulnerabilities by learning graph-level semantic representations of code. We represent codes with code property graphs (CPGs) in fine grain and use graph attention networks (GATs) for vulnerability detection. The results show that Vignat is able to achieve $57.38\\%$ accuracy on reliable datasets derived from popular C libraries. Furthermore, the interpretability of our GATs provides valuable insights into vulnerability patterns. ",
    "url": "https://arxiv.org/abs/2310.20067",
    "authors": [
      "Shuo Liu",
      "Gail Kaiser"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.20075",
    "title": "Meek Separators and Their Applications in Targeted Causal Discovery",
    "abstract": "Learning causal structures from interventional data is a fundamental problem with broad applications across various fields. While many previous works have focused on recovering the entire causal graph, in practice, there are scenarios where learning only part of the causal graph suffices. This is called $targeted$ causal discovery. In our work, we focus on two such well-motivated problems: subset search and causal matching. We aim to minimize the number of interventions in both cases. Towards this, we introduce the $Meek~separator$, which is a subset of vertices that, when intervened, decomposes the remaining unoriented edges into smaller connected components. We then present an efficient algorithm to find Meek separators that are of small sizes. Such a procedure is helpful in designing various divide-and-conquer-based approaches. In particular, we propose two randomized algorithms that achieve logarithmic approximation for subset search and causal matching, respectively. Our results provide the first known average-case provable guarantees for both problems. We believe that this opens up possibilities to design near-optimal methods for many other targeted causal structure learning problems arising from various applications. ",
    "url": "https://arxiv.org/abs/2310.20075",
    "authors": [
      "Kirankumar Shiragur",
      "Jiaqi Zhang",
      "Caroline Uhler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Discrete Mathematics (cs.DM)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.20091",
    "title": "Density-based User Representation through Gaussian Process Regression  for Multi-interest Personalized Retrieval",
    "abstract": "Accurate modeling of the diverse and dynamic interests of users remains a significant challenge in the design of personalized recommender systems. Existing user modeling methods, like single-point and multi-point representations, have limitations w.r.t. accuracy, diversity, computational cost, and adaptability. To overcome these deficiencies, we introduce density-based user representations (DURs), a novel model that leverages Gaussian process regression for effective multi-interest recommendation and retrieval. Our approach, GPR4DUR, exploits DURs to capture user interest variability without manual tuning, incorporates uncertainty-awareness, and scales well to large numbers of users. Experiments using real-world offline datasets confirm the adaptability and efficiency of GPR4DUR, while online experiments with simulated users demonstrate its ability to address the exploration-exploitation trade-off by effectively utilizing model uncertainty. ",
    "url": "https://arxiv.org/abs/2310.20091",
    "authors": [
      "Haolun Wu",
      "Ofer Mesh",
      "Masrour Zogh",
      "Fernando Diaz",
      "Craig Boutilier",
      "Maryam Karimzadehgan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.20093",
    "title": "Evaluating Neural Language Models as Cognitive Models of Language  Acquisition",
    "abstract": "The success of neural language models (LMs) on many technological tasks has brought about their potential relevance as scientific theories of language despite some clear differences between LM training and child language acquisition. In this paper we argue that some of the most prominent benchmarks for evaluating the syntactic capacities of LMs may not be sufficiently rigorous. In particular, we show that the template-based benchmarks lack the structural diversity commonly found in the theoretical and psychological studies of language. When trained on small-scale data modeling child language acquisition, the LMs can be readily matched by simple baseline models. We advocate for the use of the readily available, carefully curated datasets that have been evaluated for gradient acceptability by large pools of native speakers and are designed to probe the structural basis of grammar specifically. On one such dataset, the LI-Adger dataset, LMs evaluate sentences in a way inconsistent with human language users. We conclude with suggestions for better connecting LMs with the empirical study of child language acquisition. ",
    "url": "https://arxiv.org/abs/2310.20093",
    "authors": [
      "H\u00e9ctor Javier V\u00e1zquez Mart\u00ednez",
      "Annika Lea Heuser",
      "Charles Yang",
      "Jordan Kodner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.20098",
    "title": "Robust Learning for Smoothed Online Convex Optimization with Feedback  Delay",
    "abstract": "We study a challenging form of Smoothed Online Convex Optimization, a.k.a. SOCO, including multi-step nonlinear switching costs and feedback delay. We propose a novel machine learning (ML) augmented online algorithm, Robustness-Constrained Learning (RCL), which combines untrusted ML predictions with a trusted expert online algorithm via constrained projection to robustify the ML prediction. Specifically,we prove that RCL is able to guarantee$(1+\\lambda)$-competitiveness against any given expert for any$\\lambda>0$, while also explicitly training the ML model in a robustification-aware manner to improve the average-case performance. Importantly,RCL is the first ML-augmented algorithm with a provable robustness guarantee in the case of multi-step switching cost and feedback delay.We demonstrate the improvement of RCL in both robustness and average performance using battery management for electrifying transportationas a case study. ",
    "url": "https://arxiv.org/abs/2310.20098",
    "authors": [
      "Pengfei Li",
      "Jianyi Yang",
      "Adam Wierman",
      "Shaolei Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2310.20138",
    "title": "DEPN: Detecting and Editing Privacy Neurons in Pretrained Language  Models",
    "abstract": "Large language models pretrained on a huge amount of data capture rich knowledge and information in the training data. The ability of data memorization and regurgitation in pretrained language models, revealed in previous studies, brings the risk of data leakage. In order to effectively reduce these risks, we propose a framework DEPN to Detect and Edit Privacy Neurons in pretrained language models, partially inspired by knowledge neurons and model editing. In DEPN, we introduce a novel method, termed as privacy neuron detector, to locate neurons associated with private information, and then edit these detected privacy neurons by setting their activations to zero. Furthermore, we propose a privacy neuron aggregator dememorize private information in a batch processing manner. Experimental results show that our method can significantly and efficiently reduce the exposure of private data leakage without deteriorating the performance of the model. Additionally, we empirically demonstrate the relationship between model memorization and privacy neurons, from multiple perspectives, including model size, training time, prompts, privacy neuron distribution, illustrating the robustness of our approach. ",
    "url": "https://arxiv.org/abs/2310.20138",
    "authors": [
      "Xinwei Wu",
      "Junzhuo Li",
      "Minghui Xu",
      "Weilong Dong",
      "Shuangzhi Wu",
      "Chao Bian",
      "Deyi Xiong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.20145",
    "title": "Efficient Robust Bayesian Optimization for Arbitrary Uncertain inputs",
    "abstract": "Bayesian Optimization (BO) is a sample-efficient optimization algorithm widely employed across various applications. In some challenging BO tasks, input uncertainty arises due to the inevitable randomness in the optimization process, such as machining errors, execution noise, or contextual variability. This uncertainty deviates the input from the intended value before evaluation, resulting in significant performance fluctuations in the final result. In this paper, we introduce a novel robust Bayesian Optimization algorithm, AIRBO, which can effectively identify a robust optimum that performs consistently well under arbitrary input uncertainty. Our method directly models the uncertain inputs of arbitrary distributions by empowering the Gaussian Process with the Maximum Mean Discrepancy (MMD) and further accelerates the posterior inference via Nystrom approximation. Rigorous theoretical regret bound is established under MMD estimation error and extensive experiments on synthetic functions and real problems demonstrate that our approach can handle various input uncertainties and achieve state-of-the-art performance. ",
    "url": "https://arxiv.org/abs/2310.20145",
    "authors": [
      "Lin Yang",
      "Junlong Lyu",
      "Wenlong Lyu",
      "Zhitang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.20148",
    "title": "Decision-Making for Autonomous Vehicles with Interaction-Aware  Behavioral Prediction and Social-Attention Neural Network",
    "abstract": "Autonomous vehicles need to accomplish their tasks while interacting with human drivers in traffic. It is thus crucial to equip autonomous vehicles with artificial reasoning to better comprehend the intentions of the surrounding traffic, thereby facilitating the accomplishments of the tasks. In this work, we propose a behavioral model that encodes drivers' interacting intentions into latent social-psychological parameters. Leveraging a Bayesian filter, we develop a receding-horizon optimization-based controller for autonomous vehicle decision-making which accounts for the uncertainties in the interacting drivers' intentions. For online deployment, we design a neural network architecture based on the attention mechanism which imitates the behavioral model with online estimated parameter priors. We also propose a decision tree search algorithm to solve the decision-making problem online. The proposed behavioral model is then evaluated in terms of its capabilities for real-world trajectory prediction. We further conduct extensive evaluations of the proposed decision-making module, in forced highway merging scenarios, using both simulated environments and real-world traffic datasets. The results demonstrate that our algorithms can complete the forced merging tasks in various traffic conditions while ensuring driving safety. ",
    "url": "https://arxiv.org/abs/2310.20148",
    "authors": [
      "Xiao Li",
      "Kaiwen Liu",
      "H. Eric Tseng",
      "Anouck Girard",
      "Ilya Kolmanovsky"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.20160",
    "title": "On the Relationship between Code Verifiability and Understandability",
    "abstract": "Proponents of software verification have argued that simpler code is easier to verify: that is, that verification tools issue fewer false positives and require less human intervention when analyzing simpler code. We empirically validate this assumption by comparing the number of warnings produced by four state-of-the-art verification tools on 211 snippets of Java code with 20 metrics of code comprehensibility from human subjects in six prior studies. Our experiments, based on a statistical (meta-)analysis, show that, in aggregate, there is a small correlation (r = 0.23) between understandability and verifiability. The results support the claim that easy-to-verify code is often easier to understand than code that requires more effort to verify. Our work has implications for the users and designers of verification tools and for future attempts to automatically measure code comprehensibility: verification tools may have ancillary benefits to understandability, and measuring understandability may require reasoning about semantic, not just syntactic, code properties. ",
    "url": "https://arxiv.org/abs/2310.20160",
    "authors": [
      "Kobi Feldman",
      "Martin Kellogg",
      "Oscar Chaparro"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.20162",
    "title": "Is Robustness Transferable across Languages in Multilingual Neural  Machine Translation?",
    "abstract": "Robustness, the ability of models to maintain performance in the face of perturbations, is critical for developing reliable NLP systems. Recent studies have shown promising results in improving the robustness of models through adversarial training and data augmentation. However, in machine translation, most of these studies have focused on bilingual machine translation with a single translation direction. In this paper, we investigate the transferability of robustness across different languages in multilingual neural machine translation. We propose a robustness transfer analysis protocol and conduct a series of experiments. In particular, we use character-, word-, and multi-level noises to attack the specific translation direction of the multilingual neural machine translation model and evaluate the robustness of other translation directions. Our findings demonstrate that the robustness gained in one translation direction can indeed transfer to other translation directions. Additionally, we empirically find scenarios where robustness to character-level noise and word-level noise is more likely to transfer. ",
    "url": "https://arxiv.org/abs/2310.20162",
    "authors": [
      "Leiyu Pan",
      "Supryadi",
      "Deyi Xiong"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.20163",
    "title": "A Perturbative Solution to the Linear Influence/Network Autocorrelation  Model Under Network Dynamics",
    "abstract": "Known by many names and arising in many settings, the forced linear diffusion model is central to the modeling of power and influence within social networks (while also serving as the mechanistic justification for the widely used spatial/network autocorrelation models). The standard equilibrium solution to the diffusion model depends on strict timescale separation between network dynamics and attribute dynamics, such that the diffusion network can be considered fixed with respect to the diffusion process. Here, we consider a relaxation of this assumption, in which the network changes only slowly relative to the diffusion dynamics. In this case, we show that one can obtain a perturbative solution to the diffusion model, which depends on knowledge of past states in only a minimal way. ",
    "url": "https://arxiv.org/abs/2310.20163",
    "authors": [
      "Carter T. Butts"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2310.20175",
    "title": "LFAA: Crafting Transferable Targeted Adversarial Examples with  Low-Frequency Perturbations",
    "abstract": "Deep neural networks are susceptible to adversarial attacks, which pose a significant threat to their security and reliability in real-world applications. The most notable adversarial attacks are transfer-based attacks, where an adversary crafts an adversarial example to fool one model, which can also fool other models. While previous research has made progress in improving the transferability of untargeted adversarial examples, the generation of targeted adversarial examples that can transfer between models remains a challenging task. In this work, we present a novel approach to generate transferable targeted adversarial examples by exploiting the vulnerability of deep neural networks to perturbations on high-frequency components of images. We observe that replacing the high-frequency component of an image with that of another image can mislead deep models, motivating us to craft perturbations containing high-frequency information to achieve targeted attacks. To this end, we propose a method called Low-Frequency Adversarial Attack (\\name), which trains a conditional generator to generate targeted adversarial perturbations that are then added to the low-frequency component of the image. Extensive experiments on ImageNet demonstrate that our proposed approach significantly outperforms state-of-the-art methods, improving targeted attack success rates by a margin from 3.2\\% to 15.5\\%. ",
    "url": "https://arxiv.org/abs/2310.20175",
    "authors": [
      "Kunyu Wang",
      "Juluan Shi",
      "Wenxuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.20187",
    "title": "Self-supervised Pre-training for Precipitation Post-processor",
    "abstract": "Securing sufficient forecast lead time for local precipitation is essential for preventing hazardous weather events. Nonetheless, global warming-induced climate change is adding to the challenge of accurately predicting severe precipitation events, such as heavy rainfall. In this work, we propose a deep learning-based precipitation post-processor approach to numerical weather prediction (NWP) models. The precipitation post-processor consists of (i) self-supervised pre-training, where parameters of encoder are pre-trained on the reconstruction of masked variables of the atmospheric physics domain, and (ii) transfer learning on precipitation segmentation tasks (target domain) from the pre-trained encoder. We also introduce a heuristic labeling approach for effectively training class-imbalanced datasets. Our experiment results in precipitation correction for regional NWP show that the proposed method outperforms other approaches. ",
    "url": "https://arxiv.org/abs/2310.20187",
    "authors": [
      "Sojung An",
      "Junha Lee",
      "Jiyeon Jang",
      "Inchae Na",
      "Wooyeon Park",
      "Sujeong You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.20189",
    "title": "LFG: A Generative Network for Real-Time Recommendation",
    "abstract": "Recommender systems are essential information technologies today, and recommendation algorithms combined with deep learning have become a research hotspot in this field. The recommendation model known as LFM (Latent Factor Model), which captures latent features through matrix factorization and gradient descent to fit user preferences, has given rise to various recommendation algorithms that bring new improvements in recommendation accuracy. However, collaborative filtering recommendation models based on LFM lack flexibility and has shortcomings for real-time recommendations, as they need to redo the matrix factorization and retrain using gradient descent when new users arrive. In response to this, this paper innovatively proposes a Latent Factor Generator (LFG) network, and set the movie recommendation as research theme. The LFG dynamically generates user latent factors through deep neural networks without the need for re-factorization or retrain. Experimental results indicate that the LFG recommendation model outperforms traditional matrix factorization algorithms in recommendation accuracy, providing an effective solution to the challenges of real-time recommendations with LFM. ",
    "url": "https://arxiv.org/abs/2310.20189",
    "authors": [
      "Junyi Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.20192",
    "title": "Shaping Opinions in Social Networks with Shadow Banning",
    "abstract": "The proliferation of harmful content and misinformation on social networks necessitates content moderation policies to maintain platform health. One such policy is shadow banning, which limits content visibility. The danger of shadow banning is that it can be misused by social media platforms to manipulate opinions. Here we present an optimization based approach to shadow banning that can shape opinions into a desired distribution and scale to large networks. Simulations on real network topologies show that our shadow banning policies can shift opinions and increase or decrease opinion polarization. We find that if one shadow bans with the aim of shifting opinions in a certain direction, the resulting shadow banning policy can appear neutral. This shows the potential for social media platforms to misuse shadow banning without being detected. Our results demonstrate the power and danger of shadow banning for opinion manipulation in social networks. ",
    "url": "https://arxiv.org/abs/2310.20192",
    "authors": [
      "Yen-Shao Chen",
      "Tauhid Zaman"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.20193",
    "title": "FedRec+: Enhancing Privacy and Addressing Heterogeneity in Federated  Recommendation Systems",
    "abstract": "Preserving privacy and reducing communication costs for edge users pose significant challenges in recommendation systems. Although federated learning has proven effective in protecting privacy by avoiding data exchange between clients and servers, it has been shown that the server can infer user ratings based on updated non-zero gradients obtained from two consecutive rounds of user-uploaded gradients. Moreover, federated recommendation systems (FRS) face the challenge of heterogeneity, leading to decreased recommendation performance. In this paper, we propose FedRec+, an ensemble framework for FRS that enhances privacy while addressing the heterogeneity challenge. FedRec+ employs optimal subset selection based on feature similarity to generate near-optimal virtual ratings for pseudo items, utilizing only the user's local information. This approach reduces noise without incurring additional communication costs. Furthermore, we utilize the Wasserstein distance to estimate the heterogeneity and contribution of each client, and derive optimal aggregation weights by solving a defined optimization problem. Experimental results demonstrate the state-of-the-art performance of FedRec+ across various reference datasets. ",
    "url": "https://arxiv.org/abs/2310.20193",
    "authors": [
      "Lin Wang",
      "Zhichao Wang",
      "Xi Leng",
      "Xiaoying Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.20203",
    "title": "Importance Estimation with Random Gradient for Neural Network Pruning",
    "abstract": "Global Neuron Importance Estimation is used to prune neural networks for efficiency reasons. To determine the global importance of each neuron or convolutional kernel, most of the existing methods either use activation or gradient information or both, which demands abundant labelled examples. In this work, we use heuristics to derive importance estimation similar to Taylor First Order (TaylorFO) approximation based methods. We name our methods TaylorFO-abs and TaylorFO-sq. We propose two additional methods to improve these importance estimation methods. Firstly, we propagate random gradients from the last layer of a network, thus avoiding the need for labelled examples. Secondly, we normalize the gradient magnitude of the last layer output before propagating, which allows all examples to contribute similarly to the importance score. Our methods with additional techniques perform better than previous methods when tested on ResNet and VGG architectures on CIFAR-100 and STL-10 datasets. Furthermore, our method also complements the existing methods and improves their performances when combined with them. ",
    "url": "https://arxiv.org/abs/2310.20203",
    "authors": [
      "Suman Sapkota",
      "Binod Bhattarai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.20204",
    "title": "General-Purpose Retrieval-Enhanced Medical Prediction Model Using  Near-Infinite History",
    "abstract": "Developing clinical prediction models (e.g., mortality prediction) based on electronic health records (EHRs) typically relies on expert opinion for feature selection and adjusting observation window size. This burdens experts and creates a bottleneck in the development process. We propose Retrieval-Enhanced Medical prediction model (REMed) to address such challenges. REMed can essentially evaluate an unlimited number of clinical events, select the relevant ones, and make predictions. This approach effectively eliminates the need for manual feature selection and enables an unrestricted observation window. We verified these properties through experiments on 27 clinical tasks and two independent cohorts from publicly available EHR datasets, where REMed outperformed other contemporary architectures that aim to handle as many events as possible. Notably, we found that the preferences of REMed align closely with those of medical experts. We expect our approach to significantly expedite the development of EHR prediction models by minimizing clinicians' need for manual involvement. ",
    "url": "https://arxiv.org/abs/2310.20204",
    "authors": [
      "Junu Kim",
      "Chaeeun Shim",
      "Bosco Seong Kyu Yang",
      "Chami Im",
      "Sung Yoon Lim",
      "Han-Gil Jeong",
      "Edward Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.20208",
    "title": "ZoomNeXt: A Unified Collaborative Pyramid Network for Camouflaged Object  Detection",
    "abstract": "Recent camouflaged object detection (COD) attempts to segment objects visually blended into their surroundings, which is extremely complex and difficult in real-world scenarios. Apart from the high intrinsic similarity between camouflaged objects and their background, objects are usually diverse in scale, fuzzy in appearance, and even severely occluded. To this end, we propose an effective unified collaborative pyramid network which mimics human behavior when observing vague images and videos, \\textit{i.e.}, zooming in and out. Specifically, our approach employs the zooming strategy to learn discriminative mixed-scale semantics by the multi-head scale integration and rich granularity perception units, which are designed to fully explore imperceptible clues between candidate objects and background surroundings. The former's intrinsic multi-head aggregation provides more diverse visual patterns. The latter's routing mechanism can effectively propagate inter-frame difference in spatiotemporal scenarios and adaptively ignore static representations. They provides a solid foundation for realizing a unified architecture for static and dynamic COD. Moreover, considering the uncertainty and ambiguity derived from indistinguishable textures, we construct a simple yet effective regularization, uncertainty awareness loss, to encourage predictions with higher confidence in candidate regions. Our highly task-friendly framework consistently outperforms existing state-of-the-art methods in image and video COD benchmarks. The code will be available at \\url{https://github.com/lartpang/ZoomNeXt}. ",
    "url": "https://arxiv.org/abs/2310.20208",
    "authors": [
      "Youwei Pang",
      "Xiaoqi Zhao",
      "Tian-Zhu Xiang",
      "Lihe Zhang",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.20209",
    "title": "Network Contention-Aware Cluster Scheduling with Reinforcement Learning",
    "abstract": "With continuous advances in deep learning, distributed training is becoming common in GPU clusters. Specifically, for emerging workloads with diverse amounts, ratios, and patterns of communication, we observe that network contention can significantly degrade training throughput. However, widely used scheduling policies often face limitations as they are agnostic to network contention between jobs. In this paper, we present a new approach to mitigate network contention in GPU clusters using reinforcement learning. We formulate GPU cluster scheduling as a reinforcement learning problem and opt to learn a network contention-aware scheduling policy that efficiently captures contention sensitivities and dynamically adapts scheduling decisions through continuous evaluation and improvement. We show that compared to widely used scheduling policies, our approach reduces average job completion time by up to 18.2\\% and effectively cuts the tail job completion time by up to 20.7\\% while allowing a preferable trade-off between average job completion time and resource utilization. ",
    "url": "https://arxiv.org/abs/2310.20209",
    "authors": [
      "Junyeol Ryu",
      "Jeongyoon Eo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.20223",
    "title": "STDA-Meta: A Meta-Learning Framework for Few-Shot Traffic Prediction",
    "abstract": "As the development of cities, traffic congestion becomes an increasingly pressing issue, and traffic prediction is a classic method to relieve that issue. Traffic prediction is one specific application of spatio-temporal prediction learning, like taxi scheduling, weather prediction, and ship trajectory prediction. Against these problems, classical spatio-temporal prediction learning methods including deep learning, require large amounts of training data. In reality, some newly developed cities with insufficient sensors would not hold that assumption, and the data scarcity makes predictive performance worse. In such situation, the learning method on insufficient data is known as few-shot learning (FSL), and the FSL of traffic prediction remains challenges. On the one hand, graph structures' irregularity and dynamic nature of graphs cannot hold the performance of spatio-temporal learning method. On the other hand, conventional domain adaptation methods cannot work well on insufficient training data, when transferring knowledge from different domains to the intended target domain.To address these challenges, we propose a novel spatio-temporal domain adaptation (STDA) method that learns transferable spatio-temporal meta-knowledge from data-sufficient cities in an adversarial manner. This learned meta-knowledge can improve the prediction performance of data-scarce cities. Specifically, we train the STDA model using a Model-Agnostic Meta-Learning (MAML) based episode learning process, which is a model-agnostic meta-learning framework that enables the model to solve new learning tasks using only a small number of training samples. We conduct numerous experiments on four traffic prediction datasets, and our results show that the prediction performance of our model has improved by 7\\% compared to baseline models on the two metrics of MAE and RMSE. ",
    "url": "https://arxiv.org/abs/2310.20223",
    "authors": [
      "Maoxiang Sun",
      "Weilong Ding",
      "Tianpu Zhang",
      "Zijian Liu",
      "Mengda Xing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.20227",
    "title": "Achieving Scalable Capacity in Wireless Mesh Networks",
    "abstract": "Wireless mesh networks play a critical role in enabling key networking scenarios in beyond-5G (B5G) and 6G networks, including integrated access and backhaul (IAB), multi-hop sidelinks, and V2X. However, it still poses a challenge to deliver scalable per-node throughput via mesh networking, which significantly limits the potential of large-scale deployment of wireless mesh networks. Existing research has achieved $O(1)$ per-node throughput in a dense network, but how to achieve scalability remains an unresolved issue for an extended wireless network where the network size increases with a constant node density. This issue prevents a wireless mesh network from large-scale deployment. To this end, this paper aims to develop a theoretical approach to achieving scalable per-node throughput in wireless mesh networks. First, the key factors that limit the per-node throughput of wireless mesh networks are analyzed, through which two major ones are identified, i.e., link sharing and interference. Next, a multi-tier hierarchical architecture is proposed to overcome the link-sharing issue. The inter-tier interference under this architecture is then mitigated by utilizing orthogonal frequency allocation between adjacent tiers, while the intra-tier interference is reduced by considering two specific transmission schemes, one is MIMO spatial multiplexing with time-division, the other is MIMO beamforming. Theoretical analysis shows that the multi-tier mesh networking architecture can achieve a per-node throughput of $\\Theta(1)$ in both schemes, as long as certain conditions on network parameters including bandwidth, antenna numbers, and node numbers of each tier are satisfied. A case study on a realistic deployment of 10,000 nodes is then carried out, which demonstrates that a scalable throughput of $\\Theta(1)$ is achievable with a reasonable assumption on bandwidth and antenna numbers. ",
    "url": "https://arxiv.org/abs/2310.20227",
    "authors": [
      "Lei Lei",
      "Aimin Tang",
      "Xudong Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2310.20234",
    "title": "HEDNet: A Hierarchical Encoder-Decoder Network for 3D Object Detection  in Point Clouds",
    "abstract": "3D object detection in point clouds is important for autonomous driving systems. A primary challenge in 3D object detection stems from the sparse distribution of points within the 3D scene. Existing high-performance methods typically employ 3D sparse convolutional neural networks with small kernels to extract features. To reduce computational costs, these methods resort to submanifold sparse convolutions, which prevent the information exchange among spatially disconnected features. Some recent approaches have attempted to address this problem by introducing large-kernel convolutions or self-attention mechanisms, but they either achieve limited accuracy improvements or incur excessive computational costs. We propose HEDNet, a hierarchical encoder-decoder network for 3D object detection, which leverages encoder-decoder blocks to capture long-range dependencies among features in the spatial space, particularly for large and distant objects. We conducted extensive experiments on the Waymo Open and nuScenes datasets. HEDNet achieved superior detection accuracy on both datasets than previous state-of-the-art methods with competitive efficiency. The code is available at https://github.com/zhanggang001/HEDNet. ",
    "url": "https://arxiv.org/abs/2310.20234",
    "authors": [
      "Gang Zhang",
      "Junnan Chen",
      "Guohuan Gao",
      "Jianmin Li",
      "Xiaolin Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.20242",
    "title": "Intelligent-Reflecting-Surface-Assisted UAV Communications for 6G  Networks",
    "abstract": "In 6th-Generation (6G) mobile networks, Intelligent Reflective Surfaces (IRSs) and Unmanned Aerial Vehicles (UAVs) have emerged as promising technologies to address the coverage difficulties and resource constraints faced by terrestrial networks. UAVs, with their mobility and low costs, offer diverse connectivity options for mobile users and a novel deployment paradigm for 6G networks. However, the limited battery capacity of UAVs, dynamic and unpredictable channel environments, and communication resource constraints result in poor performance of traditional UAV-based networks. IRSs can not only reconstruct the wireless environment in a unique way, but also achieve wireless network relay in a cost-effective manner. Hence, it receives significant attention as a promising solution to solve the above challenges. In this article, we conduct a comprehensive survey on IRS-assisted UAV communications for 6G networks. First, primary issues, key technologies, and application scenarios of IRS-assisted UAV communications for 6G networks are introduced. Then, we put forward specific solutions to the issues of IRS-assisted UAV communications. Finally, we discuss some open issues and future research directions to guide researchers in related fields. ",
    "url": "https://arxiv.org/abs/2310.20242",
    "authors": [
      "Zhaolong Ning",
      "Tengfeng Li",
      "Yu Wu",
      "Xiaojie Wang",
      "Qingqing Wu",
      "Fei Richard Yu",
      "Song Guo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2310.20250",
    "title": "Diversified Node Sampling based Hierarchical Transformer Pooling for  Graph Representation Learning",
    "abstract": "Graph pooling methods have been widely used on downsampling graphs, achieving impressive results on multiple graph-level tasks like graph classification and graph generation. An important line called node dropping pooling aims at exploiting learnable scoring functions to drop nodes with comparatively lower significance scores. However, existing node dropping methods suffer from two limitations: (1) for each pooled node, these models struggle to capture long-range dependencies since they mainly take GNNs as the backbones; (2) pooling only the highest-scoring nodes tends to preserve similar nodes, thus discarding the affluent information of low-scoring nodes. To address these issues, we propose a Graph Transformer Pooling method termed GTPool, which introduces Transformer to node dropping pooling to efficiently capture long-range pairwise interactions and meanwhile sample nodes diversely. Specifically, we design a scoring module based on the self-attention mechanism that takes both global context and local context into consideration, measuring the importance of nodes more comprehensively. GTPool further utilizes a diversified sampling method named Roulette Wheel Sampling (RWS) that is able to flexibly preserve nodes across different scoring intervals instead of only higher scoring nodes. In this way, GTPool could effectively obtain long-range information and select more representative nodes. Extensive experiments on 11 benchmark datasets demonstrate the superiority of GTPool over existing popular graph pooling methods. ",
    "url": "https://arxiv.org/abs/2310.20250",
    "authors": [
      "Gaichao Li",
      "Jinsong Chen",
      "John E. Hopcroft",
      "Kun He"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.20256",
    "title": "PsyCoT: Psychological Questionnaire as Powerful Chain-of-Thought for  Personality Detection",
    "abstract": "Recent advances in large language models (LLMs), such as ChatGPT, have showcased remarkable zero-shot performance across various NLP tasks. However, the potential of LLMs in personality detection, which involves identifying an individual's personality from their written texts, remains largely unexplored. Drawing inspiration from Psychological Questionnaires, which are carefully designed by psychologists to evaluate individual personality traits through a series of targeted items, we argue that these items can be regarded as a collection of well-structured chain-of-thought (CoT) processes. By incorporating these processes, LLMs can enhance their capabilities to make more reasonable inferences on personality from textual input. In light of this, we propose a novel personality detection method, called PsyCoT, which mimics the way individuals complete psychological questionnaires in a multi-turn dialogue manner. In particular, we employ a LLM as an AI assistant with a specialization in text analysis. We prompt the assistant to rate individual items at each turn and leverage the historical rating results to derive a conclusive personality preference. Our experiments demonstrate that PsyCoT significantly improves the performance and robustness of GPT-3.5 in personality detection, achieving an average F1 score improvement of 4.23/10.63 points on two benchmark datasets compared to the standard prompting method. Our code is available at https://github.com/TaoYang225/PsyCoT. ",
    "url": "https://arxiv.org/abs/2310.20256",
    "authors": [
      "Tao Yang",
      "Tianyuan Shi",
      "Fanqi Wan",
      "Xiaojun Quan",
      "Qifan Wang",
      "Bingzhe Wu",
      "Jiaxiang Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.20268",
    "title": "Constructing Sample-to-Class Graph for Few-Shot Class-Incremental  Learning",
    "abstract": "Few-shot class-incremental learning (FSCIL) aims to build machine learning model that can continually learn new concepts from a few data samples, without forgetting knowledge of old classes. The challenges of FSCIL lies in the limited data of new classes, which not only lead to significant overfitting issues but also exacerbates the notorious catastrophic forgetting problems. As proved in early studies, building sample relationships is beneficial for learning from few-shot samples. In this paper, we promote the idea to the incremental scenario, and propose a Sample-to-Class (S2C) graph learning method for FSCIL. Specifically, we propose a Sample-level Graph Network (SGN) that focuses on analyzing sample relationships within a single session. This network helps aggregate similar samples, ultimately leading to the extraction of more refined class-level features. Then, we present a Class-level Graph Network (CGN) that establishes connections across class-level features of both new and old classes. This network plays a crucial role in linking the knowledge between different sessions and helps improve overall learning in the FSCIL scenario. Moreover, we design a multi-stage strategy for training S2C model, which mitigates the training challenges posed by limited data in the incremental process. The multi-stage training strategy is designed to build S2C graph from base to few-shot stages, and improve the capacity via an extra pseudo-incremental stage. Experiments on three popular benchmark datasets show that our method clearly outperforms the baselines and sets new state-of-the-art results in FSCIL. ",
    "url": "https://arxiv.org/abs/2310.20268",
    "authors": [
      "Fuyuan Hu",
      "Jian Zhang",
      "Fan Lyu",
      "Linyan Li",
      "Fenglei Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.20299",
    "title": "Verification of Neural Networks Local Differential Classification  Privacy",
    "abstract": "Neural networks are susceptible to privacy attacks. To date, no verifier can reason about the privacy of individuals participating in the training set. We propose a new privacy property, called local differential classification privacy (LDCP), extending local robustness to a differential privacy setting suitable for black-box classifiers. Given a neighborhood of inputs, a classifier is LDCP if it classifies all inputs the same regardless of whether it is trained with the full dataset or whether any single entry is omitted. A naive algorithm is highly impractical because it involves training a very large number of networks and verifying local robustness of the given neighborhood separately for every network. We propose Sphynx, an algorithm that computes an abstraction of all networks, with a high probability, from a small set of networks, and verifies LDCP directly on the abstract network. The challenge is twofold: network parameters do not adhere to a known distribution probability, making it difficult to predict an abstraction, and predicting too large abstraction harms the verification. Our key idea is to transform the parameters into a distribution given by KDE, allowing to keep the over-approximation error small. To verify LDCP, we extend a MILP verifier to analyze an abstract network. Experimental results show that by training only 7% of the networks, Sphynx predicts an abstract network obtaining 93% verification accuracy and reducing the analysis time by $1.7\\cdot10^4$x. ",
    "url": "https://arxiv.org/abs/2310.20299",
    "authors": [
      "Roie Reshef",
      "Anan Kabaha",
      "Olga Seleznova",
      "Dana Drachsler-Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2310.20305",
    "title": "Bilateral Network with Residual U-blocks and Dual-Guided Attention for  Real-time Semantic Segmentation",
    "abstract": "When some application scenarios need to use semantic segmentation technology, like automatic driving, the primary concern comes to real-time performance rather than extremely high segmentation accuracy. To achieve a good trade-off between speed and accuracy, two-branch architecture has been proposed in recent years. It treats spatial information and semantics information separately which allows the model to be composed of two networks both not heavy. However, the process of fusing features with two different scales becomes a performance bottleneck for many nowaday two-branch models. In this research, we design a new fusion mechanism for two-branch architecture which is guided by attention computation. To be precise, we use the Dual-Guided Attention (DGA) module we proposed to replace some multi-scale transformations with the calculation of attention which means we only use several attention layers of near linear complexity to achieve performance comparable to frequently-used multi-layer fusion. To ensure that our module can be effective, we use Residual U-blocks (RSU) to build one of the two branches in our networks which aims to obtain better multi-scale features. Extensive experiments on Cityscapes and CamVid dataset show the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2310.20305",
    "authors": [
      "Liang Liao",
      "Liang Wan",
      "Mingsheng Liu",
      "Shusheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.20307",
    "title": "Causal Interpretation of Self-Attention in Pre-Trained Transformers",
    "abstract": "We propose a causal interpretation of self-attention in the Transformer neural network architecture. We interpret self-attention as a mechanism that estimates a structural equation model for a given input sequence of symbols (tokens). The structural equation model can be interpreted, in turn, as a causal structure over the input symbols under the specific context of the input sequence. Importantly, this interpretation remains valid in the presence of latent confounders. Following this interpretation, we estimate conditional independence relations between input symbols by calculating partial correlations between their corresponding representations in the deepest attention layer. This enables learning the causal structure over an input sequence using existing constraint-based algorithms. In this sense, existing pre-trained Transformers can be utilized for zero-shot causal-discovery. We demonstrate this method by providing causal explanations for the outcomes of Transformers in two tasks: sentiment classification (NLP) and recommendation. ",
    "url": "https://arxiv.org/abs/2310.20307",
    "authors": [
      "Raanan Y. Rohekar",
      "Yaniv Gurwicz",
      "Shami Nisimov"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.20325",
    "title": "A polynomial-time $\\text{OPT}^\u03b5$-approximation algorithm for  maximum independent set of connected subgraphs in a planar graph",
    "abstract": "In the Maximum Independent Set of Objects problem, we are given an $n$-vertex planar graph $G$ and a family $\\mathcal{D}$ of $N$ objects, where each object is a connected subgraph of $G$. The task is to find a subfamily $\\mathcal{F} \\subseteq \\mathcal{D}$ of maximum cardinality that consists of pairwise disjoint objects. This problem is $\\mathsf{NP}$-hard and is equivalent to the problem of finding the maximum number of pairwise disjoint polygons in a given family of polygons in the plane. As shown by Adamaszek et al. (J. ACM '19), the problem admits a \\emph{quasi-polynomial time approximation scheme} (QPTAS): a $(1-\\varepsilon)$-approximation algorithm whose running time is bounded by $2^{\\mathrm{poly}(\\log(N),1/\\epsilon)} \\cdot n^{\\mathcal{O}(1)}$. Nevertheless, to the best of our knowledge, in the polynomial-time regime only the trivial $\\mathcal{O}(N)$-approximation is known for the problem in full generality. In the restricted setting where the objects are pseudolines in the plane, Fox and Pach (SODA '11) gave an $N^{\\varepsilon}$-approximation algorithm with running time $N^{2^{\\tilde{\\mathcal{O}}(1/\\varepsilon)}}$, for any $\\varepsilon>0$. In this work, we present an $\\text{OPT}^{\\varepsilon}$-approximation algorithm for the problem that runs in time $N^{\\tilde{\\mathcal{O}}(1/\\varepsilon^2)} n^{\\mathcal{O}(1)}$, for any $\\varepsilon>0$, thus improving upon the result of Fox and Pach both in terms of generality and in terms of the running time. Our approach combines the methodology of Voronoi separators, introduced by Marx and Pilipczuk (TALG '22), with a new analysis of the approximation factor. ",
    "url": "https://arxiv.org/abs/2310.20325",
    "authors": [
      "Jana Cslovjecsek",
      "Micha\u0142 Pilipczuk",
      "Karol W\u0119grzycki"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2310.20329",
    "title": "InstructCoder: Empowering Language Models for Code Editing",
    "abstract": "Code editing encompasses a variety of pragmatic tasks that developers deal with daily. Despite its relevance and practical usefulness, automatic code editing remains an underexplored area in the evolution of deep learning models, partly due to data scarcity. In this work, we explore the use of large language models (LLMs) to edit code based on user instructions, covering a broad range of implicit tasks such as comment insertion, code optimization, and code refactoring. To facilitate this, we introduce InstructCoder, the first dataset designed to adapt LLMs for general-purpose code editing, containing highdiversity code-editing tasks. It consists of over 114,000 instruction-input-output triplets and covers multiple distinct code editing scenarios. The dataset is systematically expanded through an iterative process that commences with code editing data sourced from GitHub commits as seed tasks. Seed and generated tasks are used subsequently to prompt ChatGPT for more task data. Our experiments demonstrate that open-source LLMs fine-tuned on InstructCoder can edit code correctly based on users' instructions most of the time, exhibiting unprecedented code-editing performance levels. Such results suggest that proficient instruction-finetuning can lead to significant amelioration in code editing abilities. The dataset and the source code are available at https://github.com/qishenghu/CodeInstruct. ",
    "url": "https://arxiv.org/abs/2310.20329",
    "authors": [
      "Qisheng Hu",
      "Kaixin Li",
      "Xu Zhao",
      "Yuxi Xie",
      "Tiedong Liu",
      "Hui Chen",
      "Qizhe Xie",
      "Junxian He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.20349",
    "title": "A Low-cost Strategic Monitoring Approach for Scalable and Interpretable  Error Detection in Deep Neural Networks",
    "abstract": "We present a highly compact run-time monitoring approach for deep computer vision networks that extracts selected knowledge from only a few (down to merely two) hidden layers, yet can efficiently detect silent data corruption originating from both hardware memory and input faults. Building on the insight that critical faults typically manifest as peak or bulk shifts in the activation distribution of the affected network layers, we use strategically placed quantile markers to make accurate estimates about the anomaly of the current inference as a whole. Importantly, the detector component itself is kept algorithmically transparent to render the categorization of regular and abnormal behavior interpretable to a human. Our technique achieves up to ~96% precision and ~98% recall of detection. Compared to state-of-the-art anomaly detection techniques, this approach requires minimal compute overhead (as little as 0.3% with respect to non-supervised inference time) and contributes to the explainability of the model. ",
    "url": "https://arxiv.org/abs/2310.20349",
    "authors": [
      "Florian Geissler",
      "Syed Qutub",
      "Michael Paulitsch",
      "Karthik Pattabiraman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.20350",
    "title": "Combining Shape Completion and Grasp Prediction for Fast and Versatile  Grasping with a Multi-Fingered Hand",
    "abstract": "Grasping objects with limited or no prior knowledge about them is a highly relevant skill in assistive robotics. Still, in this general setting, it has remained an open problem, especially when it comes to only partial observability and versatile grasping with multi-fingered hands. We present a novel, fast, and high fidelity deep learning pipeline consisting of a shape completion module that is based on a single depth image, and followed by a grasp predictor that is based on the predicted object shape. The shape completion network is based on VQDIF and predicts spatial occupancy values at arbitrary query points. As grasp predictor, we use our two-stage architecture that first generates hand poses using an autoregressive model and then regresses finger joint configurations per pose. Critical factors turn out to be sufficient data realism and augmentation, as well as special attention to difficult cases during training. Experiments on a physical robot platform demonstrate successful grasping of a wide range of household objects based on a depth image from a single viewpoint. The whole pipeline is fast, taking only about 1 s for completing the object's shape (0.7 s) and generating 1000 grasps (0.3 s). ",
    "url": "https://arxiv.org/abs/2310.20350",
    "authors": [
      "Matthias Humt",
      "Dominik Winkelbauer",
      "Ulrich Hillenbrand",
      "Berthold B\u00e4uml"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.20354",
    "title": "Statistical Complexity of Heterogeneous Geometric Networks",
    "abstract": "Heterogeneity and geometry are key explanatory components underlying the structure of real-world networks. The relationship between these components and the statistical complexity of networks is not well understood. We introduce a parsimonious normalised measure of statistical complexity for networks -- normalised hierarchical complexity. The measure is trivially 0 in regular graphs and we prove that this measure tends to 0 in Erd\\\"os-R\\'enyi random graphs in the thermodynamic limit. We go on to demonstrate that greater complexity arises from the combination of hierarchical and geometric components to the network structure than either on their own. Further, the levels of complexity achieved are similar to those found in many real-world networks. We also find that real world networks establish connections in a way which increases hierarchical complexity and which our null models and a range of attachment mechanisms fail to explain. This underlines the non-trivial nature of statistical complexity in real-world networks and provides foundations for the comparative analysis of network complexity within and across disciplines. ",
    "url": "https://arxiv.org/abs/2310.20354",
    "authors": [
      "Keith Malcolm Smith",
      "Jason P. Smith"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2310.20407",
    "title": "Unsupervised detection of coordinated fake-follower campaigns on social  media",
    "abstract": "Automated social media accounts, known as bots, are increasingly recognized as key tools for manipulative online activities. These activities can stem from coordination among several accounts and these automated campaigns can manipulate social network structure by following other accounts, amplifying their content, and posting messages to spam online discourse. In this study, we present a novel unsupervised detection method designed to target a specific category of malicious accounts designed to manipulate user metrics such as online popularity. Our framework identifies anomalous following patterns among all the followers of a social media account. Through the analysis of a large number of accounts on the Twitter platform (rebranded as Twitter after the acquisition of Elon Musk), we demonstrate that irregular following patterns are prevalent and are indicative of automated fake accounts. Notably, we find that these detected groups of anomalous followers exhibit consistent behavior across multiple accounts. This observation, combined with the computational efficiency of our proposed approach, makes it a valuable tool for investigating large-scale coordinated manipulation campaigns on social media platforms. ",
    "url": "https://arxiv.org/abs/2310.20407",
    "authors": [
      "Yasser Zouzou",
      "Onur Varol"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2310.20412",
    "title": "Thermal-Infrared Remote Target Detection System for Maritime Rescue  based on Data Augmentation with 3D Synthetic Data",
    "abstract": "This paper proposes a thermal-infrared (TIR) remote target detection system for maritime rescue using deep learning and data augmentation. We established a self-collected TIR dataset consisting of multiple scenes imitating human rescue situations using a TIR camera (FLIR). Additionally, to address dataset scarcity and improve model robustness, a synthetic dataset from a 3D game (ARMA3) to augment the data is further collected. However, a significant domain gap exists between synthetic TIR and real TIR images. Hence, a proper domain adaptation algorithm is essential to overcome the gap. Therefore, we suggest a domain adaptation algorithm in a target-background separated manner from 3D game-to-real, based on a generative model, to address this issue. Furthermore, a segmentation network with fixed-weight kernels at the head is proposed to improve the signal-to-noise ratio (SNR) and provide weak attention, as remote TIR targets inherently suffer from unclear boundaries. Experiment results reveal that the network trained on augmented data consisting of translated synthetic and real TIR data outperforms that trained on only real TIR data by a large margin. Furthermore, the proposed segmentation model surpasses the performance of state-of-the-art segmentation methods. ",
    "url": "https://arxiv.org/abs/2310.20412",
    "authors": [
      "Sungjin Cheong",
      "Wonho Jung",
      "Yoon Seop Lim",
      "Yong-Hwa Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.20426",
    "title": "Evolutionary Pareto Set Learning with Structure Constraints",
    "abstract": "The multiobjective evolutionary optimization algorithm (MOEA) is a powerful approach for tackling multiobjective optimization problems (MOPs), which can find a finite set of approximate Pareto solutions in a single run. However, under mild regularity conditions, the Pareto optimal set of a continuous MOP could be a low dimensional continuous manifold that contains infinite solutions. In addition, structure constraints on the whole optimal solution set, which characterize the patterns shared among all solutions, could be required in many real-life applications. It is very challenging for existing finite population based MOEAs to handle these structure constraints properly. In this work, we propose the first model-based algorithmic framework to learn the whole solution set with structure constraints for multiobjective optimization. In our approach, the Pareto optimality can be traded off with a preferred structure among the whole solution set, which could be crucial for many real-world problems. We also develop an efficient evolutionary learning method to train the set model with structure constraints. Experimental studies on benchmark test suites and real-world application problems demonstrate the promising performance of our proposed framework. ",
    "url": "https://arxiv.org/abs/2310.20426",
    "authors": [
      "Xi Lin",
      "Xiaoyuan Zhang",
      "Zhiyuan Yang",
      "Qingfu Zhang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2310.20447",
    "title": "Efficient Bayesian Learning Curve Extrapolation using Prior-Data Fitted  Networks",
    "abstract": "Learning curve extrapolation aims to predict model performance in later epochs of training, based on the performance in earlier epochs. In this work, we argue that, while the inherent uncertainty in the extrapolation of learning curves warrants a Bayesian approach, existing methods are (i) overly restrictive, and/or (ii) computationally expensive. We describe the first application of prior-data fitted neural networks (PFNs) in this context. A PFN is a transformer, pre-trained on data generated from a prior, to perform approximate Bayesian inference in a single forward pass. We propose LC-PFN, a PFN trained to extrapolate 10 million artificial right-censored learning curves generated from a parametric prior proposed in prior art using MCMC. We demonstrate that LC-PFN can approximate the posterior predictive distribution more accurately than MCMC, while being over 10 000 times faster. We also show that the same LC-PFN achieves competitive performance extrapolating a total of 20 000 real learning curves from four learning curve benchmarks (LCBench, NAS-Bench-201, Taskset, and PD1) that stem from training a wide range of model architectures (MLPs, CNNs, RNNs, and Transformers) on 53 different datasets with varying input modalities (tabular, image, text, and protein data). Finally, we investigate its potential in the context of model selection and find that a simple LC-PFN based predictive early stopping criterion obtains 2 - 6x speed-ups on 45 of these datasets, at virtually no overhead. ",
    "url": "https://arxiv.org/abs/2310.20447",
    "authors": [
      "Steven Adriaensen",
      "Herilalaina Rakotoarison",
      "Samuel M\u00fcller",
      "Frank Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.20457",
    "title": "FlexTrain: A Dynamic Training Framework for Heterogeneous Devices  Environments",
    "abstract": "As deep learning models become increasingly large, they pose significant challenges in heterogeneous devices environments. The size of deep learning models makes it difficult to deploy them on low-power or resource-constrained devices, leading to long inference times and high energy consumption. To address these challenges, we propose FlexTrain, a framework that accommodates the diverse storage and computational resources available on different devices during the training phase. FlexTrain enables efficient deployment of deep learning models, while respecting device constraints, minimizing communication costs, and ensuring seamless integration with diverse devices. We demonstrate the effectiveness of FlexTrain on the CIFAR-100 dataset, where a single global model trained with FlexTrain can be easily deployed on heterogeneous devices, saving training time and energy consumption. We also extend FlexTrain to the federated learning setting, showing that our approach outperforms standard federated learning benchmarks on both CIFAR-10 and CIFAR-100 datasets. ",
    "url": "https://arxiv.org/abs/2310.20457",
    "authors": [
      "Mert Unsal",
      "Ali Maatouk",
      "Antonio De Domenico",
      "Nicola Piovesan",
      "Fadhel Ayed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.20463",
    "title": "Interpretable Neural PDE Solvers using Symbolic Frameworks",
    "abstract": "Partial differential equations (PDEs) are ubiquitous in the world around us, modelling phenomena from heat and sound to quantum systems. Recent advances in deep learning have resulted in the development of powerful neural solvers; however, while these methods have demonstrated state-of-the-art performance in both accuracy and computational efficiency, a significant challenge remains in their interpretability. Most existing methodologies prioritize predictive accuracy over clarity in the underlying mechanisms driving the model's decisions. Interpretability is crucial for trustworthiness and broader applicability, especially in scientific and engineering domains where neural PDE solvers might see the most impact. In this context, a notable gap in current research is the integration of symbolic frameworks (such as symbolic regression) into these solvers. Symbolic frameworks have the potential to distill complex neural operations into human-readable mathematical expressions, bridging the divide between black-box predictions and solutions. ",
    "url": "https://arxiv.org/abs/2310.20463",
    "authors": [
      "Yolanne Yi Ran Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.20468",
    "title": "An Introduction to Causal Inference Methods for Observational  Human-Robot Interaction Research",
    "abstract": "Quantitative methods in Human-Robot Interaction (HRI) research have primarily relied upon randomized, controlled experiments in laboratory settings. However, such experiments are not always feasible when external validity, ethical constraints, and ease of data collection are of concern. Furthermore, as consumer robots become increasingly available, increasing amounts of real-world data will be available to HRI researchers, which prompts the need for quantative approaches tailored to the analysis of observational data. In this article, we present an alternate approach towards quantitative research for HRI researchers using methods from causal inference that can enable researchers to identify causal relationships in observational settings where randomized, controlled experiments cannot be run. We highlight different scenarios that HRI research with consumer household robots may involve to contextualize how methods from causal inference can be applied to observational HRI research. We then provide a tutorial summarizing key concepts from causal inference using a graphical model perspective and link to code examples throughout the article, which are available at https://gitlab.com/causal/causal_hri. Our work paves the way for further discussion on new approaches towards observational HRI research while providing a starting point for HRI researchers to add causal inference techniques to their analytical toolbox. ",
    "url": "https://arxiv.org/abs/2310.20468",
    "authors": [
      "Jaron J. R. Lee",
      "Gopika Ajaykumar",
      "Ilya Shpitser",
      "Chien-Ming Huang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.20469",
    "title": "Amoeba: Circumventing ML-supported Network Censorship via Adversarial  Reinforcement Learning",
    "abstract": "Embedding covert streams into a cover channel is a common approach to circumventing Internet censorship, due to censors' inability to examine encrypted information in otherwise permitted protocols (Skype, HTTPS, etc.). However, recent advances in machine learning (ML) enable detecting a range of anti-censorship systems by learning distinct statistical patterns hidden in traffic flows. Therefore, designing obfuscation solutions able to generate traffic that is statistically similar to innocuous network activity, in order to deceive ML-based classifiers at line speed, is difficult. In this paper, we formulate a practical adversarial attack strategy against flow classifiers as a method for circumventing censorship. Specifically, we cast the problem of finding adversarial flows that will be misclassified as a sequence generation task, which we solve with Amoeba, a novel reinforcement learning algorithm that we design. Amoeba works by interacting with censoring classifiers without any knowledge of their model structure, but by crafting packets and observing the classifiers' decisions, in order to guide the sequence generation process. Our experiments using data collected from two popular anti-censorship systems demonstrate that Amoeba can effectively shape adversarial flows that have on average 94% attack success rate against a range of ML algorithms. In addition, we show that these adversarial flows are robust in different network environments and possess transferability across various ML models, meaning that once trained against one, our agent can subvert other censoring classifiers without retraining. ",
    "url": "https://arxiv.org/abs/2310.20469",
    "authors": [
      "Haoyu Liu",
      "Alec F. Diallo",
      "Paul Patras"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.20475",
    "title": "Linked Papers With Code: The Latest in Machine Learning as an RDF  Knowledge Graph",
    "abstract": "In this paper, we introduce Linked Papers With Code (LPWC), an RDF knowledge graph that provides comprehensive, current information about almost 400,000 machine learning publications. This includes the tasks addressed, the datasets utilized, the methods implemented, and the evaluations conducted, along with their results. Compared to its non-RDF-based counterpart Papers With Code, LPWC not only translates the latest advancements in machine learning into RDF format, but also enables novel ways for scientific impact quantification and scholarly key content recommendation. LPWC is openly accessible at https://linkedpaperswithcode.com and is licensed under CC-BY-SA 4.0. As a knowledge graph in the Linked Open Data cloud, we offer LPWC in multiple formats, from RDF dump files to a SPARQL endpoint for direct web queries, as well as a data source with resolvable URIs and links to the data sources SemOpenAlex, Wikidata, and DBLP. Additionally, we supply knowledge graph embeddings, enabling LPWC to be readily applied in machine learning applications. ",
    "url": "https://arxiv.org/abs/2310.20475",
    "authors": [
      "Michael F\u00e4rber",
      "David Lamprecht"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.20486",
    "title": "Optimal Binary Differential Privacy via Graphs",
    "abstract": "We present the notion of \\emph{reasonable utility} for binary mechanisms, which applies to all utility functions in the literature. This notion induces a partial ordering on the performance of all binary differentially private (DP) mechanisms. DP mechanisms that are maximal elements of this ordering are optimal DP mechanisms for every reasonable utility. By looking at differential privacy as a randomized graph coloring, we characterize these optimal DP in terms of their behavior on a certain subset of the boundary datasets we call a boundary hitting set. In the process of establishing our results, we also introduce a useful notion that generalizes DP conditions for binary-valued queries, which we coin as suitable pairs. Suitable pairs abstract away the algebraic roles of $\\varepsilon,\\delta$ in the DP framework, making the derivations and understanding of our proofs simpler. Additionally, the notion of a suitable pair can potentially capture privacy conditions in frameworks other than DP and may be of independent interest. ",
    "url": "https://arxiv.org/abs/2310.20486",
    "authors": [
      "Sahel Torkamani",
      "Javad B. Ebrahimi",
      "Parastoo Sadeghi",
      "Rafael G. L. D'Oliveira",
      "Muriel M\u00e9dard"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2310.20491",
    "title": "Collaborative Decision-Making Using Spatiotemporal Graphs in Connected  Autonomy",
    "abstract": "Collaborative decision-making is an essential capability for multi-robot systems, such as connected vehicles, to collaboratively control autonomous vehicles in accident-prone scenarios. Under limited communication bandwidth, capturing comprehensive situational awareness by integrating connected agents' observation is very challenging. In this paper, we propose a novel collaborative decision-making method that efficiently and effectively integrates collaborators' representations to control the ego vehicle in accident-prone scenarios. Our approach formulates collaborative decision-making as a classification problem. We first represent sequences of raw observations as spatiotemporal graphs, which significantly reduce the package size to share among connected vehicles. Then we design a novel spatiotemporal graph neural network based on heterogeneous graph learning, which analyzes spatial and temporal connections of objects in a unified way for collaborative decision-making. We evaluate our approach using a high-fidelity simulator that considers realistic traffic, communication bandwidth, and vehicle sensing among connected autonomous vehicles. The experimental results show that our representation achieves over 100x reduction in the shared data size that meets the requirements of communication bandwidth for connected autonomous driving. In addition, our approach achieves over 30% improvements in driving safety. ",
    "url": "https://arxiv.org/abs/2310.20491",
    "authors": [
      "Peng Gao",
      "Yu Shen",
      "Ming C. Lin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2310.20492",
    "title": "Log-based Anomaly Detection of Enterprise Software: An Empirical Study",
    "abstract": "Most enterprise applications use logging as a mechanism to diagnose anomalies, which could help with reducing system downtime. Anomaly detection using software execution logs has been explored in several prior studies, using both classical and deep neural network-based machine learning models. In recent years, the research has largely focused in using variations of sequence-based deep neural networks (e.g., Long-Short Term Memory and Transformer-based models) for log-based anomaly detection on open-source data. However, they have not been applied in industrial datasets, as often. In addition, the studied open-source datasets are typically very large in size with logging statements that do not change much over time, which may not be the case with a dataset from an industrial service that is relatively new. In this paper, we evaluate several state-of-the-art anomaly detection models on an industrial dataset from our research partner, which is much smaller and loosely structured than most large scale open-source benchmark datasets. Results show that while all models are capable of detecting anomalies, certain models are better suited for less-structured datasets. We also see that model effectiveness changes when a common data leak associated with a random train-test split in some prior work is removed. A qualitative study of the defects' characteristics identified by the developers on the industrial dataset further shows strengths and weaknesses of the models in detecting different types of anomalies. Finally, we explore the effect of limited training data by gradually increasing the training set size, to evaluate if the model effectiveness does depend on the training set size. ",
    "url": "https://arxiv.org/abs/2310.20492",
    "authors": [
      "Nadun Wijesinghe",
      "Hadi Hemmati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2310.20497",
    "title": "On the matrix code of quadratic relationships for a Goppa code",
    "abstract": "In this article, we continue the analysis started in \\cite{CMT23} for the matrix code of quadratic relationships associated with a Goppa code. We provide new sparse and low-rank elements in the matrix code and categorize them according to their shape. Thanks to this description, we prove that the set of rank 2 matrices in the matrix codes associated with square-free binary Goppa codes, i.e. those used in Classic McEiece, is much larger than what is expected, at least in the case where the Goppa polynomial degree is 2. We build upon the algebraic determinantal modeling introduced in \\cite{CMT23} to derive a structural attack on these instances. Our method can break in just a few seconds some recent challenges about key-recovery attacks on the McEliece cryptosystem, consistently reducing their estimated security level. We also provide a general method, valid for any Goppa polynomial degree, to transform a generic pair of support and multiplier into a pair of support and Goppa polynomial. ",
    "url": "https://arxiv.org/abs/2310.20497",
    "authors": [
      "Rocco Mora"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.20498",
    "title": "Generative Learning of Continuous Data by Tensor Networks",
    "abstract": "Beyond their origin in modeling many-body quantum systems, tensor networks have emerged as a promising class of models for solving machine learning problems, notably in unsupervised generative learning. While possessing many desirable features arising from their quantum-inspired nature, tensor network generative models have previously been largely restricted to binary or categorical data, limiting their utility in real-world modeling problems. We overcome this by introducing a new family of tensor network generative models for continuous data, which are capable of learning from distributions containing continuous random variables. We develop our method in the setting of matrix product states, first deriving a universal expressivity theorem proving the ability of this model family to approximate any reasonably smooth probability density function with arbitrary precision. We then benchmark the performance of this model on several synthetic and real-world datasets, finding that the model learns and generalizes well on distributions of continuous and discrete variables. We develop methods for modeling different data domains, and introduce a trainable compression layer which is found to increase model performance given limited memory or computational resources. Overall, our methods give important theoretical and empirical evidence of the efficacy of quantum-inspired methods for the rapidly growing field of generative learning. ",
    "url": "https://arxiv.org/abs/2310.20498",
    "authors": [
      "Alex Meiburg",
      "Jing Chen",
      "Jacob Miller",
      "Rapha\u00eblle Tihon",
      "Guillaume Rabusseau",
      "Alejandro Perdomo-Ortiz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Quantum Physics (quant-ph)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.20501",
    "title": "LLMs may Dominate Information Access: Neural Retrievers are Biased  Towards LLM-Generated Texts",
    "abstract": "Recently, the emergence of large language models (LLMs) has revolutionized the paradigm of information retrieval (IR) applications, especially in web search. With their remarkable capabilities in generating human-like texts, LLMs have created enormous texts on the Internet. As a result, IR systems in the LLMs era are facing a new challenge: the indexed documents now are not only written by human beings but also automatically generated by the LLMs. How these LLM-generated documents influence the IR systems is a pressing and still unexplored question. In this work, we conduct a quantitative evaluation of different IR models in scenarios where both human-written and LLM-generated texts are involved. Surprisingly, our findings indicate that neural retrieval models tend to rank LLM-generated documents higher.We refer to this category of biases in neural retrieval models towards the LLM-generated text as the \\textbf{source bias}. Moreover, we discover that this bias is not confined to the first-stage neural retrievers, but extends to the second-stage neural re-rankers. Then, we provide an in-depth analysis from the perspective of text compression and observe that neural models can better understand the semantic information of LLM-generated text, which is further substantiated by our theoretical analysis.We also discuss the potential server concerns stemming from the observed source bias and hope our findings can serve as a critical wake-up call to the IR community and beyond. To facilitate future explorations of IR in the LLM era, the constructed two new benchmarks and codes will later be available at \\url{https://github.com/KID-22/LLM4IR-Bias}. ",
    "url": "https://arxiv.org/abs/2310.20501",
    "authors": [
      "Sunhao Dai",
      "Yuqi Zhou",
      "Liang Pang",
      "Weihao Liu",
      "Xiaolin Hu",
      "Yong Liu",
      "Xiao Zhang",
      "Jun Xu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2310.20515",
    "title": "LoRa Multi-Hop Networks for Monitoring Underground Mining Environments",
    "abstract": "Internet of Things applications have gained widespread recognition for their efficacy in typical scenarios, such as smart cities and smart healthcare. Nonetheless, there exist numerous unconventional situations where IoT technologies have not yet been massively applied, though they can be extremely useful. One of such domains is the underground mining sector, where enhancing automation monitoring through wireless communications is of essential significance. In this paper, we focus on the development, implementation, and evaluation of a LoRa-based multi-hop network tailored specifically for monitoring underground mining environments, where data traffic is sporadic, but energy efficiency is of paramount importance. We hence define a synchronization framework that makes it possible for the nodes to sleep for most of the time, waking up only when they need to exchange traffic. Notably, our network achieves a sub 40us proven synchronization accuracy between parent-child pairs with minimum overhead for diverse topologies, rendering it highly viable for subterranean operations. Furthermore, for proper network dimensioning, we model the interplay between network's throughput, frame size, and sampling periods of potential applications. Moreover, we propose a model to estimate devices' duty cycle based on their position within the multi-hop network, along with empirical observations for its validation. The proposed models make it possible to optimize the network's performance to meet the specific demands that can arise from the different subterranean use cases, in which robustness, low power operation, and compliance with radio-frequency regulations are key requirements that must be met. ",
    "url": "https://arxiv.org/abs/2310.20515",
    "authors": [
      "Luca Scalambrin",
      "Andrea Zanella",
      "Xavier Vilajosana"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2310.20524",
    "title": "Group-Feature (Sensor) Selection With Controlled Redundancy Using Neural  Networks",
    "abstract": "In this paper, we present a novel embedded feature selection method based on a Multi-layer Perceptron (MLP) network and generalize it for group-feature or sensor selection problems, which can control the level of redundancy among the selected features or groups. Additionally, we have generalized the group lasso penalty for feature selection to encompass a mechanism for selecting valuable group features while simultaneously maintaining a control over redundancy. We establish the monotonicity and convergence of the proposed algorithm, with a smoothed version of the penalty terms, under suitable assumptions. Experimental results on several benchmark datasets demonstrate the promising performance of the proposed methodology for both feature selection and group feature selection over some state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2310.20524",
    "authors": [
      "Aytijhya Saha",
      "Nikhil R. Pal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.20552",
    "title": "Privacy-preserving design of graph neural networks with applications to  vertical federated learning",
    "abstract": "The paradigm of vertical federated learning (VFL), where institutions collaboratively train machine learning models via combining each other's local feature or label information, has achieved great success in applications to financial risk management (FRM). The surging developments of graph representation learning (GRL) have opened up new opportunities for FRM applications under FL via efficiently utilizing the graph-structured data generated from underlying transaction networks. Meanwhile, transaction information is often considered highly sensitive. To prevent data leakage during training, it is critical to develop FL protocols with formal privacy guarantees. In this paper, we present an end-to-end GRL framework in the VFL setting called VESPER, which is built upon a general privatization scheme termed perturbed message passing (PMP) that allows the privatization of many popular graph neural architectures.Based on PMP, we discuss the strengths and weaknesses of specific design choices of concrete graph neural architectures and provide solutions and improvements for both dense and sparse graphs. Extensive empirical evaluations over both public datasets and an industry dataset demonstrate that VESPER is capable of training high-performance GNN models over both sparse and dense graphs under reasonable privacy budgets. ",
    "url": "https://arxiv.org/abs/2310.20552",
    "authors": [
      "Ruofan Wu",
      "Mingyang Zhang",
      "Lingjuan Lyu",
      "Xiaolong Xu",
      "Xiuquan Hao",
      "Xinyi Fu",
      "Tengfei Liu",
      "Tianyi Zhang",
      "Weiqiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.20567",
    "title": "One-shot backpropagation for multi-step prediction in physics-based  system identification",
    "abstract": "The aim of this paper is to present a novel general framework for the identification of possibly interconnected systems, while preserving their physical properties and providing accuracy in multi-step prediction. An analytical and recursive algorithm for the gradient computation of the multi-step loss function based on backpropagation is introduced, providing physical and structural insight directly into the learning algorithm. As a case study, the proposed approach is tested for estimating the inertia matrix of a space debris starting from state observations. ",
    "url": "https://arxiv.org/abs/2310.20567",
    "authors": [
      "Cesare Donati",
      "Martina Mammarella",
      "Fabrizio Dabbene",
      "Carlo Novara",
      "Constantino Lagoa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.20588",
    "title": "Zero-Shot Medical Information Retrieval via Knowledge Graph Embedding",
    "abstract": "In the era of the Internet of Things (IoT), the retrieval of relevant medical information has become essential for efficient clinical decision-making. This paper introduces MedFusionRank, a novel approach to zero-shot medical information retrieval (MIR) that combines the strengths of pre-trained language models and statistical methods while addressing their limitations. The proposed approach leverages a pre-trained BERT-style model to extract compact yet informative keywords. These keywords are then enriched with domain knowledge by linking them to conceptual entities within a medical knowledge graph. Experimental evaluations on medical datasets demonstrate MedFusion Rank's superior performance over existing methods, with promising results with a variety of evaluation metrics. MedFusionRank demonstrates efficacy in retrieving relevant information, even from short or single-term queries. ",
    "url": "https://arxiv.org/abs/2310.20588",
    "authors": [
      "Yuqi Wang",
      "Zeqiang Wang",
      "Wei Wang",
      "Qi Chen",
      "Kaizhu Huang",
      "Anh Nguyen",
      "Suparna De"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2310.20598",
    "title": "Online Conversion with Switching Costs: Robust and Learning-Augmented  Algorithms",
    "abstract": "We introduce and study online conversion with switching costs, a family of online problems that capture emerging problems at the intersection of energy and sustainability. In this problem, an online player attempts to purchase (alternatively, sell) fractional shares of an asset during a fixed time horizon with length $T$. At each time step, a cost function (alternatively, price function) is revealed, and the player must irrevocably decide an amount of asset to convert. The player also incurs a switching cost whenever their decision changes in consecutive time steps, i.e., when they increase or decrease their purchasing amount. We introduce competitive (robust) threshold-based algorithms for both the minimization and maximization variants of this problem, and show they are optimal among deterministic online algorithms. We then propose learning-augmented algorithms that take advantage of untrusted black-box advice (such as predictions from a machine learning model) to achieve significantly better average-case performance without sacrificing worst-case competitive guarantees. Finally, we empirically evaluate our proposed algorithms using a carbon-aware EV charging case study, showing that our algorithms substantially improve on baseline methods for this problem. ",
    "url": "https://arxiv.org/abs/2310.20598",
    "authors": [
      "Adam Lechowicz",
      "Nicolas Christianson",
      "Bo Sun",
      "Noman Bashir",
      "Mohammad Hajiesmaili",
      "Adam Wierman",
      "Prashant Shenoy"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.20620",
    "title": "The Unreasonable Effectiveness of Random Target Embeddings for  Continuous-Output Neural Machine Translation",
    "abstract": "Continuous-output neural machine translation (CoNMT) replaces the discrete next-word prediction problem with an embedding prediction. The semantic structure of the target embedding space (i.e., closeness of related words) is intuitively believed to be crucial. We challenge this assumption and show that completely random output embeddings can outperform laboriously pretrained ones, especially on larger datasets. Further investigation shows this surprising effect is strongest for rare words, due to the geometry of their embeddings. We shed further light on this finding by designing a mixed strategy that combines random and pre-trained embeddings for different tokens. ",
    "url": "https://arxiv.org/abs/2310.20620",
    "authors": [
      "Evgeniia Tokarchuk",
      "Vlad Niculae"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.20621",
    "title": "Deepfake detection by exploiting surface anomalies: the SurFake approach",
    "abstract": "The ever-increasing use of synthetically generated content in different sectors of our everyday life, one for all media information, poses a strong need for deepfake detection tools in order to avoid the proliferation of altered messages. The process to identify manipulated content, in particular images and videos, is basically performed by looking for the presence of some inconsistencies and/or anomalies specifically due to the fake generation process. Different techniques exist in the scientific literature that exploit diverse ad-hoc features in order to highlight possible modifications. In this paper, we propose to investigate how deepfake creation can impact on the characteristics that the whole scene had at the time of the acquisition. In particular, when an image (video) is captured the overall geometry of the scene (e.g. surfaces) and the acquisition process (e.g. illumination) determine a univocal environment that is directly represented by the image pixel values; all these intrinsic relations are possibly changed by the deepfake generation process. By resorting to the analysis of the characteristics of the surfaces depicted in the image it is possible to obtain a descriptor usable to train a CNN for deepfake detection: we refer to such an approach as SurFake. Experimental results carried out on the FF++ dataset for different kinds of deepfake forgeries and diverse deep learning models confirm that such a feature can be adopted to discriminate between pristine and altered images; furthermore, experiments witness that it can also be combined with visual data to provide a certain improvement in terms of detection accuracy. ",
    "url": "https://arxiv.org/abs/2310.20621",
    "authors": [
      "Andrea Ciamarra",
      "Roberto Caldelli",
      "Federico Becattini",
      "Lorenzo Seidenari",
      "Alberto Del Bimbo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.20623",
    "title": "Fully dynamic approximation schemes on planar and apex-minor-free graphs",
    "abstract": "The classic technique of Baker [J. ACM '94] is the most fundamental approach for designing approximation schemes on planar, or more generally topologically-constrained graphs, and it has been applied in a myriad of different variants and settings throughout the last 30 years. In this work we propose a dynamic variant of Baker's technique, where instead of finding an approximate solution in a given static graph, the task is to design a data structure for maintaining an approximate solution in a fully dynamic graph, that is, a graph that is changing over time by edge deletions and edge insertions. Specifically, we address the two most basic problems -- Maximum Weight Independent Set and Minimum Weight Dominating Set -- and we prove the following: for a fully dynamic $n$-vertex planar graph $G$, one can: * maintain a $(1-\\varepsilon)$-approximation of the maximum weight of an independent set in $G$ with amortized update time $f(\\varepsilon)\\cdot n^{o(1)}$; and, * under the additional assumption that the maximum degree of the graph is bounded at all times by a constant, also maintain a $(1+\\varepsilon)$-approximation of the minimum weight of a dominating set in $G$ with amortized update time $f(\\varepsilon)\\cdot n^{o(1)}$. In both cases, $f(\\varepsilon)$ is doubly-exponential in $\\mathrm{poly}(1/\\varepsilon)$ and the data structure can be initialized in time $f(\\varepsilon)\\cdot n^{1+o(1)}$. All our results in fact hold in the larger generality of any graph class that excludes a fixed apex-graph as a minor. ",
    "url": "https://arxiv.org/abs/2310.20623",
    "authors": [
      "Tuukka Korhonen",
      "Wojciech Nadara",
      "Micha\u0142 Pilipczuk",
      "Marek Soko\u0142owski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2310.20649",
    "title": "Dynamic Batch Norm Statistics Update for Natural Robustness",
    "abstract": "DNNs trained on natural clean samples have been shown to perform poorly on corrupted samples, such as noisy or blurry images. Various data augmentation methods have been recently proposed to improve DNN's robustness against common corruptions. Despite their success, they require computationally expensive training and cannot be applied to off-the-shelf trained models. Recently, it has been shown that updating BatchNorm (BN) statistics of an off-the-shelf model on a single corruption improves its accuracy on that corruption significantly. However, adopting the idea at inference time when the type of corruption is unknown and changing decreases the effectiveness of this method. In this paper, we harness the Fourier domain to detect the corruption type, a challenging task in the image domain. We propose a unified framework consisting of a corruption-detection model and BN statistics update that improves the corruption accuracy of any off-the-shelf trained model. We benchmark our framework on different models and datasets. Our results demonstrate about 8% and 4% accuracy improvement on CIFAR10-C and ImageNet-C, respectively. Furthermore, our framework can further improve the accuracy of state-of-the-art robust models, such as AugMix and DeepAug. ",
    "url": "https://arxiv.org/abs/2310.20649",
    "authors": [
      "Shahbaz Rezaei",
      "Mohammad Sadegh Norouzzadeh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.20679",
    "title": "Latent Field Discovery In Interacting Dynamical Systems With Neural  Fields",
    "abstract": "Systems of interacting objects often evolve under the influence of field effects that govern their dynamics, yet previous works have abstracted away from such effects, and assume that systems evolve in a vacuum. In this work, we focus on discovering these fields, and infer them from the observed dynamics alone, without directly observing them. We theorize the presence of latent force fields, and propose neural fields to learn them. Since the observed dynamics constitute the net effect of local object interactions and global field effects, recently popularized equivariant networks are inapplicable, as they fail to capture global information. To address this, we propose to disentangle local object interactions -- which are $\\mathrm{SE}(n)$ equivariant and depend on relative states -- from external global field effects -- which depend on absolute states. We model interactions with equivariant graph networks, and combine them with neural fields in a novel graph network that integrates field forces. Our experiments show that we can accurately discover the underlying fields in charged particles settings, traffic scenes, and gravitational n-body problems, and effectively use them to learn the system and forecast future trajectories. ",
    "url": "https://arxiv.org/abs/2310.20679",
    "authors": [
      "Miltiadis Kofinas",
      "Erik J. Bekkers",
      "Naveen Shankar Nagaraja",
      "Efstratios Gavves"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2310.20697",
    "title": "Text-Transport: Toward Learning Causal Effects of Natural Language",
    "abstract": "As language technologies gain prominence in real-world settings, it is important to understand how changes to language affect reader perceptions. This can be formalized as the causal effect of varying a linguistic attribute (e.g., sentiment) on a reader's response to the text. In this paper, we introduce Text-Transport, a method for estimation of causal effects from natural language under any text distribution. Current approaches for valid causal effect estimation require strong assumptions about the data, meaning the data from which one can estimate valid causal effects often is not representative of the actual target domain of interest. To address this issue, we leverage the notion of distribution shift to describe an estimator that transports causal effects between domains, bypassing the need for strong assumptions in the target domain. We derive statistical guarantees on the uncertainty of this estimator, and we report empirical results and analyses that support the validity of Text-Transport across data settings. Finally, we use Text-Transport to study a realistic setting--hate speech on social media--in which causal effects do shift significantly between text domains, demonstrating the necessity of transport when conducting causal inference on natural language. ",
    "url": "https://arxiv.org/abs/2310.20697",
    "authors": [
      "Victoria Lin",
      "Louis-Philippe Morency",
      "Eli Ben-Michael"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2310.20700",
    "title": "SEINE: Short-to-Long Video Diffusion Model for Generative Transition and  Prediction",
    "abstract": "Recently video generation has achieved substantial progress with realistic results. Nevertheless, existing AI-generated videos are usually very short clips (\"shot-level\") depicting a single scene. To deliver a coherent long video (\"story-level\"), it is desirable to have creative transition and prediction effects across different clips. This paper presents a short-to-long video diffusion model, SEINE, that focuses on generative transition and prediction. The goal is to generate high-quality long videos with smooth and creative transitions between scenes and varying lengths of shot-level videos. Specifically, we propose a random-mask video diffusion model to automatically generate transitions based on textual descriptions. By providing the images of different scenes as inputs, combined with text-based control, our model generates transition videos that ensure coherence and visual quality. Furthermore, the model can be readily extended to various tasks such as image-to-video animation and autoregressive video prediction. To conduct a comprehensive evaluation of this new generative task, we propose three assessing criteria for smooth and creative transition: temporal consistency, semantic similarity, and video-text semantic alignment. Extensive experiments validate the effectiveness of our approach over existing methods for generative transition and prediction, enabling the creation of story-level long videos. Project page: https://vchitect.github.io/SEINE-project/ . ",
    "url": "https://arxiv.org/abs/2310.20700",
    "authors": [
      "Xinyuan Chen",
      "Yaohui Wang",
      "Lingjun Zhang",
      "Shaobin Zhuang",
      "Xin Ma",
      "Jiashuo Yu",
      "Yali Wang",
      "Dahua Lin",
      "Yu Qiao",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.20710",
    "title": "FPO++: Efficient Encoding and Rendering of Dynamic Neural Radiance  Fields by Analyzing and Enhancing Fourier PlenOctrees",
    "abstract": "Fourier PlenOctrees have shown to be an efficient representation for real-time rendering of dynamic Neural Radiance Fields (NeRF). Despite its many advantages, this method suffers from artifacts introduced by the involved compression when combining it with recent state-of-the-art techniques for training the static per-frame NeRF models. In this paper, we perform an in-depth analysis of these artifacts and leverage the resulting insights to propose an improved representation. In particular, we present a novel density encoding that adapts the Fourier-based compression to the characteristics of the transfer function used by the underlying volume rendering procedure and leads to a substantial reduction of artifacts in the dynamic model. Furthermore, we show an augmentation of the training data that relaxes the periodicity assumption of the compression. We demonstrate the effectiveness of our enhanced Fourier PlenOctrees in the scope of quantitative and qualitative evaluations on synthetic and real-world scenes. ",
    "url": "https://arxiv.org/abs/2310.20710",
    "authors": [
      "Saskia Rabich",
      "Patrick Stotko",
      "Reinhard Klein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2305.15499",
    "title": "Neural network reconstruction of cosmology using the Pantheon  compilation",
    "abstract": "In this work, we reconstruct the Hubble diagram using various data sets, including correlated ones, in Artificial Neural Networks (ANN). Using ReFANN, that was built for data sets with independent uncertainties, we expand it to include non-Guassian data points, as well as data sets with covariance matrices among others. Furthermore, we compare our results with the existing ones derived from Gaussian processes and we also perform null tests in order to test the validity of the concordance model of cosmology. ",
    "url": "https://arxiv.org/abs/2305.15499",
    "authors": [
      "Konstantinos F. Dialektopoulos",
      "Purba Mukherjee",
      "Jackson Levi Said",
      "Jurgen Mifsud"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19005",
    "title": "Kernel-based Joint Multiple Graph Learning and Clustering of Graph  Signals",
    "abstract": "Within the context of Graph Signal Processing (GSP), Graph Learning (GL) is concerned with the inference of a graph's topology from nodal observations, i.e., graph signals. However, data is often in mixed form, relating to different underlying structures. This heterogeneity necessitates the joint clustering and learning of multiple graphs. In many real-life applications, there are available node-side covariates (i.e., kernels) that imperatively should be incorporated, which has not been addressed by the rare graph signal clustering approaches. To this end and inspired by the rich K-means framework, we propose a novel kernel-based algorithm to incorporate this node-side information as we jointly partition the signals and learn a graph for each cluster. Numerical experiments demonstrate its effectiveness over the state-of-the-art. ",
    "url": "https://arxiv.org/abs/2310.19005",
    "authors": [
      "Mohamad H. Alizade",
      "Aref Einizade"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.19817",
    "title": "Intelligibility prediction with a pretrained noise-robust automatic  speech recognition model",
    "abstract": "This paper describes two intelligibility prediction systems derived from a pretrained noise-robust automatic speech recognition (ASR) model for the second Clarity Prediction Challenge (CPC2). One system is intrusive and leverages the hidden representations of the ASR model. The other system is non-intrusive and makes predictions with derived ASR uncertainty. The ASR model is only pretrained with a simulated noisy speech corpus and does not take advantage of the CPC2 data. For that reason, the intelligibility prediction systems are robust to unseen scenarios given the accurate prediction performance on the CPC2 evaluation. ",
    "url": "https://arxiv.org/abs/2310.19817",
    "authors": [
      "Zehai Tu",
      "Ning Ma",
      "Jon Barker"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2310.19844",
    "title": "Design and Analysis of Robust Ballistic Landings on the Secondary of a  Binary Asteroid",
    "abstract": "ESA's Hera mission aims to visit binary asteroid Didymos in late 2026, investigating its physical characteristics and the result of NASA's impact by the DART spacecraft in more detail. Two CubeSats on-board Hera plan to perform a ballistic landing on the secondary of the system, called Dimorphos. For these types of landings the translational state during descent is not controlled, reducing the spacecrafts complexity but also increasing its sensitivity to deployment maneuver errors and dynamical uncertainties. This paper introduces a novel methodology to analyse the effect of these uncertainties on the dynamics of the lander and design a trajectory that is robust against them. This methodology consists of propagating the uncertain state of the lander using the non-intrusive Chebyshev interpolation (NCI) technique, which approximates the uncertain dynamics using a polynomial expansion, and analysing the results using the pseudo-diffusion indicator, derived from the coefficients of the polynomial expansion, which quantifies the rate of growth of the set of possible states of the spacecraft over time. This indicator is used here to constrain the impact velocity and angle to values which allow for successful settling on the surface. This information is then used to optimize the landing trajectory by applying the NCI technique inside the transcription of the problem. The resulting trajectory increases the robustness of the trajectory compared to a conventional method, improving the landing success by 20 percent and significantly reducing the landing footprint. ",
    "url": "https://arxiv.org/abs/2310.19844",
    "authors": [
      "Iosto Fodde",
      "Jinglang Feng",
      "Massimiliano Vasile",
      "Jes\u00fas Gil-Fern\u00e1ndez"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2310.19870",
    "title": "Metric Flows with Neural Networks",
    "abstract": "We develop a theory of flows in the space of Riemannian metrics induced by neural network gradient descent. This is motivated in part by recent advances in approximating Calabi-Yau metrics with neural networks and is enabled by recent advances in understanding flows in the space of neural networks. We derive the corresponding metric flow equations, which are governed by a metric neural tangent kernel, a complicated, non-local object that evolves in time. However, many architectures admit an infinite-width limit in which the kernel becomes fixed and the dynamics simplify. Additional assumptions can induce locality in the flow, which allows for the realization of Perelman's formulation of Ricci flow that was used to resolve the 3d Poincar\\'e conjecture. We apply these ideas to numerical Calabi-Yau metrics, including a discussion on the importance of feature learning. ",
    "url": "https://arxiv.org/abs/2310.19870",
    "authors": [
      "James Halverson",
      "Fabian Ruehle"
    ],
    "subjectives": [
      "High Energy Physics - Theory (hep-th)",
      "Machine Learning (cs.LG)",
      "Differential Geometry (math.DG)"
    ]
  },
  {
    "id": "arXiv:2310.19973",
    "title": "Unified Enhancement of Privacy Bounds for Mixture Mechanisms via  $f$-Differential Privacy",
    "abstract": "Differentially private (DP) machine learning algorithms incur many sources of randomness, such as random initialization, random batch subsampling, and shuffling. However, such randomness is difficult to take into account when proving differential privacy bounds because it induces mixture distributions for the algorithm's output that are difficult to analyze. This paper focuses on improving privacy bounds for shuffling models and one-iteration differentially private gradient descent (DP-GD) with random initializations using $f$-DP. We derive a closed-form expression of the trade-off function for shuffling models that outperforms the most up-to-date results based on $(\\epsilon,\\delta)$-DP. Moreover, we investigate the effects of random initialization on the privacy of one-iteration DP-GD. Our numerical computations of the trade-off function indicate that random initialization can enhance the privacy of DP-GD. Our analysis of $f$-DP guarantees for these mixture mechanisms relies on an inequality for trade-off functions introduced in this paper. This inequality implies the joint convexity of $F$-divergences. Finally, we study an $f$-DP analog of the advanced joint convexity of the hockey-stick divergence related to $(\\epsilon,\\delta)$-DP and apply it to analyze the privacy of mixture mechanisms. ",
    "url": "https://arxiv.org/abs/2310.19973",
    "authors": [
      "Chendi Wang",
      "Buxin Su",
      "Jiayuan Ye",
      "Reza Shokri",
      "Weijie J. Su"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2310.20079",
    "title": "Hybridizing Physics and Neural ODEs for Predicting Plasma Inductance  Dynamics in Tokamak Fusion Reactors",
    "abstract": "While fusion reactors known as tokamaks hold promise as a firm energy source, advances in plasma control, and handling of events where control of plasmas is lost, are needed for them to be economical. A significant bottleneck towards applying more advanced control algorithms is the need for better plasma simulation, where both physics-based and data-driven approaches currently fall short. The former is bottle-necked by both computational cost and the difficulty of modelling plasmas, and the latter is bottle-necked by the relative paucity of data. To address this issue, this work applies the neural ordinary differential equations (ODE) framework to the problem of predicting a subset of plasma dynamics, namely the coupled plasma current and internal inductance dynamics. As the neural ODE framework allows for the natural inclusion of physics-based inductive biases, we train both physics-based and neural network models on data from the Alcator C-Mod fusion reactor and find that a model that combines physics-based equations with a neural ODE performs better than both existing physics-motivated ODEs and a pure neural ODE model. ",
    "url": "https://arxiv.org/abs/2310.20079",
    "authors": [
      "Allen M. Wang",
      "Darren T. Garnier",
      "Cristina Rea"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.20224",
    "title": "Choose A Table: Tensor Dirichlet Process Multinomial Mixture Model with  Graphs for Passenger Trajectory Clustering",
    "abstract": "Passenger clustering based on trajectory records is essential for transportation operators. However, existing methods cannot easily cluster the passengers due to the hierarchical structure of the passenger trip information, including multiple trips within each passenger and multi-dimensional information about each trip. Furthermore, existing approaches rely on an accurate specification of the clustering number to start. Finally, existing methods do not consider spatial semantic graphs such as geographical proximity and functional similarity between the locations. In this paper, we propose a novel tensor Dirichlet Process Multinomial Mixture model with graphs, which can preserve the hierarchical structure of the multi-dimensional trip information and cluster them in a unified one-step manner with the ability to determine the number of clusters automatically. The spatial graphs are utilized in community detection to link the semantic neighbors. We further propose a tensor version of Collapsed Gibbs Sampling method with a minimum cluster size requirement. A case study based on Hong Kong metro passenger data is conducted to demonstrate the automatic process of cluster amount evolution and better cluster quality measured by within-cluster compactness and cross-cluster separateness. The code is available at https://github.com/bonaldli/TensorDPMM-G. ",
    "url": "https://arxiv.org/abs/2310.20224",
    "authors": [
      "Ziyue Li",
      "Hao Yan",
      "Chen Zhang",
      "Lijun Sun",
      "Wolfgang Ketter",
      "Fugee Tsung"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2310.20365",
    "title": "Physical-layer key distribution using synchronous complex dynamics of  DBR semiconductor lasers",
    "abstract": "Common-signal-induced synchronization of semiconductor lasers with optical feedback inspired a promising physical key distribution with information-theoretic security and potential in high rate. A significant challenge is the requirement to shorten the synchronization recovery time for increasing key rate without sacrificing operation parameter space for security. Here, open-loop synchronization of wavelength-tunable multi-section distributed Bragg reflector (DBR) lasers is proposed as a solution for physical-layer key distribution. Experiments show that the synchronization is sensitive to two operation parameters, i.e., currents of grating section and phase section. Furthermore, fast wavelength-shift keying synchronization can be achieved by direct modulation on one of the two currents. The synchronization recovery time is shortened by one order of magnitude compared to close-loop synchronization. An experimental implementation is demonstrated with a final key rate of 5.98 Mbit/s over 160 km optical fiber distance. It is thus believed that fast-tunable multi-section semiconductor lasers opens a new avenue of high-rate physical-layer key distribution using laser synchronization. ",
    "url": "https://arxiv.org/abs/2310.20365",
    "authors": [
      "Anbang Wang",
      "Yicheng Du",
      "Qingtian Li",
      "Longsheng Wang",
      "Zhiwei Jia",
      "Yuwen Qin",
      "Yuncai Wang"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.20398",
    "title": "A hybrid approach for solving the gravitational N-body problem with  Artificial Neural Networks",
    "abstract": "Simulating the evolution of the gravitational N-body problem becomes extremely computationally expensive as N increases since the problem complexity scales quadratically with the number of bodies. We study the use of Artificial Neural Networks (ANNs) to replace expensive parts of the integration of planetary systems. Neural networks that include physical knowledge have grown in popularity in the last few years, although few attempts have been made to use them to speed up the simulation of the motion of celestial bodies. We study the advantages and limitations of using Hamiltonian Neural Networks to replace computationally expensive parts of the numerical simulation. We compare the results of the numerical integration of a planetary system with asteroids with those obtained by a Hamiltonian Neural Network and a conventional Deep Neural Network, with special attention to understanding the challenges of this problem. Due to the non-linear nature of the gravitational equations of motion, errors in the integration propagate. To increase the robustness of a method that uses neural networks, we propose a hybrid integrator that evaluates the prediction of the network and replaces it with the numerical solution if considered inaccurate. Hamiltonian Neural Networks can make predictions that resemble the behavior of symplectic integrators but are challenging to train and in our case fail when the inputs differ ~7 orders of magnitude. In contrast, Deep Neural Networks are easy to train but fail to conserve energy, leading to fast divergence from the reference solution. The hybrid integrator designed to include the neural networks increases the reliability of the method and prevents large energy errors without increasing the computing cost significantly. For this problem, the use of neural networks results in faster simulations when the number of asteroids is >70. ",
    "url": "https://arxiv.org/abs/2310.20398",
    "authors": [
      "Veronica Saz Ulibarrena",
      "Philipp Horn",
      "Simon Portegies Zwart",
      "Elena Sellentin",
      "Barry Koren",
      "Maxwell X. Cai"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2310.20427",
    "title": "Assessing and Enhancing Robustness of Deep Learning Models with  Corruption Emulation in Digital Pathology",
    "abstract": "Deep learning in digital pathology brings intelligence and automation as substantial enhancements to pathological analysis, the gold standard of clinical diagnosis. However, multiple steps from tissue preparation to slide imaging introduce various image corruptions, making it difficult for deep neural network (DNN) models to achieve stable diagnostic results for clinical use. In order to assess and further enhance the robustness of the models, we analyze the physical causes of the full-stack corruptions throughout the pathological life-cycle and propose an Omni-Corruption Emulation (OmniCE) method to reproduce 21 types of corruptions quantified with 5-level severity. We then construct three OmniCE-corrupted benchmark datasets at both patch level and slide level and assess the robustness of popular DNNs in classification and segmentation tasks. Further, we explore to use the OmniCE-corrupted datasets as augmentation data for training and experiments to verify that the generalization ability of the models has been significantly enhanced. ",
    "url": "https://arxiv.org/abs/2310.20427",
    "authors": [
      "Peixiang Huang",
      "Songtao Zhang",
      "Yulu Gan",
      "Rui Xu",
      "Rongqi Zhu",
      "Wenkang Qin",
      "Limei Guo",
      "Shan Jiang",
      "Lin Luo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.20522",
    "title": "Tight bounds on adjacency labels for monotone graph classes",
    "abstract": "A class of graphs admits an adjacency labeling scheme of size $f(n)$, if the vertices of any $n$-vertex graph $G$ in the class can be assigned binary strings (aka labels) of length $f(n)$ so that the adjacency between each pair of vertices in $G$ can be determined only from their labels. The Implicit Graph Conjecture (IGC) claimed that any graph class which is hereditary (i.e. closed under taking induced subgraphs) and factorial (i.e. containing $2^{\\Theta(n \\log n)}$ graphs on $n$ vertices) admits an adjacency labeling scheme of order optimal size $O(\\log n)$. After thirty years open, the IGC was recently disproved [Hatami and Hatami, FOCS 2022]. In this work we show that the IGC does not hold even for monotone graph classes, i.e. classes closed under taking subgraphs. More specifically, we show that there are monotone factorial graph classes for which the size of any adjacency labeling scheme is $\\Omega(\\log^2 n)$. Moreover, this is best possible, as any monotone factorial class admits an adjacency labeling scheme of size $O(\\log^2 n)$. This is a consequence of our general result that establishes tight bounds on the size of adjacency labeling schemes for monotone graph classes: for any function $f: \\mathbb{R}_{\\geq 0} \\rightarrow \\mathbb{R}_{\\geq 0}$ with $\\log x \\leq f(x) \\leq x^{1-\\delta}$ for some constant $\\delta > 0$, that satisfies some natural conditions, there exist monotone graph classes, in which the number of $n$-vertex graphs grows as $2^{O(nf(n))}$ and that do not admit adjacency labels of size at most $f(n) \\log n$. On the other hand any such class admits adjacency labels of size $O(f(n)\\log n)$, which is a factor of $\\log n$ away from the order optimal bound $O(f(n))$. This is the first example of tight bounds on adjacency labels for graph classes that do not admit order optimal adjacency labeling schemes. ",
    "url": "https://arxiv.org/abs/2310.20522",
    "authors": [
      "\u00c9douard Bonnet",
      "Julien Duron",
      "John Sylvester",
      "Viktor Zamaraev",
      "Maksim Zhukovskii"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2310.20544",
    "title": "Information-theoretic causality and applications to turbulence: energy  cascade and inner/outer layer interactions",
    "abstract": "We introduce an information-theoretic method for quantifying causality in chaotic systems. The approach, referred to as IT-causality, quantifies causality by measuring the information gained about future events conditioned on the knowledge of past events. The causal interactions are classified into redundant, unique, and synergistic contributions depending on their nature. The formulation is non-intrusive, invariance under invertible transformations of the variables, and provides the missing causality due to unobserved variables. The method only requires pairs of past-future events of the quantities of interest, making it convenient for both computational simulations and experimental investigations. IT-causality is validated in four scenarios representing basic causal interactions among variables: mediator, confounder, redundant collider, and synergistic collider. The approach is leveraged to address two questions relevant to turbulence research: i) the scale locality of the energy cascade in isotropic turbulence, and ii) the interactions between inner and outer layer flow motions in wall-bounded turbulence. In the former case, we demonstrate that causality in the energy cascade flows sequentially from larger to smaller scales without requiring intermediate scales. Conversely, the flow of information from small to large scales is shown to be redundant. In the second problem, we observe a unidirectional causality flow, with causality predominantly originating from the outer layer and propagating towards the inner layer, but not vice versa. The decomposition of IT-causality into intensities also reveals that the causality is primarily associated with high-velocity streaks. ",
    "url": "https://arxiv.org/abs/2310.20544",
    "authors": [
      "Adri\u00e1n Lozano-Dur\u00e1n",
      "Gonzalo Arranz",
      "Yuenong Ling"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Information Theory (cs.IT)",
      "Chaotic Dynamics (nlin.CD)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2310.20579",
    "title": "Initialization Matters: Privacy-Utility Analysis of Overparameterized  Neural Networks",
    "abstract": "We analytically investigate how over-parameterization of models in randomized machine learning algorithms impacts the information leakage about their training data. Specifically, we prove a privacy bound for the KL divergence between model distributions on worst-case neighboring datasets, and explore its dependence on the initialization, width, and depth of fully connected neural networks. We find that this KL privacy bound is largely determined by the expected squared gradient norm relative to model parameters during training. Notably, for the special setting of linearized network, our analysis indicates that the squared gradient norm (and therefore the escalation of privacy loss) is tied directly to the per-layer variance of the initialization distribution. By using this analysis, we demonstrate that privacy bound improves with increasing depth under certain initializations (LeCun and Xavier), while degrades with increasing depth under other initializations (He and NTK). Our work reveals a complex interplay between privacy and depth that depends on the chosen initialization distribution. We further prove excess empirical risk bounds under a fixed KL privacy budget, and show that the interplay between privacy utility trade-off and depth is similarly affected by the initialization. ",
    "url": "https://arxiv.org/abs/2310.20579",
    "authors": [
      "Jiayuan Ye",
      "Zhenyu Zhu",
      "Fanghui Liu",
      "Reza Shokri",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.20582",
    "title": "The serotonergic psychedelic N,N-dipropyltryptamine alters  information-processing dynamics in cortical neural circuits",
    "abstract": "Most of the recent work in psychedelic neuroscience has been done using non-invasive neuroimaging, with data recorded from the brains of adult volunteers under the influence of a variety of drugs. While this data provides holistic insights into the effects of psychedelics on whole-brain dynamics, the effects of psychedelics on the meso-scale dynamics of cortical circuits remains much less explored. Here, we report the effects of the serotonergic psychedelic N,N-diproptyltryptamine (DPT) on information-processing dynamics in a sample of in vitro organotypic cultures made from rat cortical tissue. Three hours of spontaneous activity were recorded: an hour of pre-drug control, and hour of exposure to 10$\\mu$M DPT solution, and a final hour of washout, once again under control conditions. We found that DPT reversibly alters information dynamics in multiple ways: first, the DPT condition was associated with higher entropy of spontaneous firing activity and reduced the amount of time information was stored in individual neurons. Second, DPT also reduced the reversibility of neural activity, increasing the entropy produced and suggesting a drive away from equilibrium. Third, DPT altered the structure of neuronal circuits, decreasing the overall information flow coming into each neuron, but increasing the number of weak connections, creating a dynamic that combines elements of integration and disintegration. Finally, DPT decreased the higher-order statistical synergy present in sets of three neurons. Collectively, these results paint a complex picture of how psychedelics regulate information processing in meso-scale cortical tissue. Implications for existing hypotheses of psychedelic action, such as the Entropic Brain Hypothesis, are discussed. ",
    "url": "https://arxiv.org/abs/2310.20582",
    "authors": [
      "Thomas F. Varley",
      "Daniel Havert",
      "Leandro Fosque",
      "Abolfazl Alipour",
      "Naruepon Weerawongphrom",
      "Hiroki Naganobori",
      "Lily O'Shea",
      "Maria Pope",
      "John Beggs"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Information Theory (cs.IT)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ]
  },
  {
    "id": "arXiv:2310.20601",
    "title": "Functional connectivity modules in recurrent neural networks: function,  origin and dynamics",
    "abstract": "Understanding the ubiquitous phenomenon of neural synchronization across species and organizational levels is crucial for decoding brain function. Despite its prevalence, the specific functional role, origin, and dynamical implication of modular structures in correlation-based networks remains ambiguous. Using recurrent neural networks trained on systems neuroscience tasks, this study investigates these important characteristics of modularity in correlation networks. We demonstrate that modules are functionally coherent units that contribute to specialized information processing. We show that modules form spontaneously from asymmetries in the sign and weight of projections from the input layer to the recurrent layer. Moreover, we show that modules define connections with similar roles in governing system behavior and dynamics. Collectively, our findings clarify the function, formation, and operational significance of functional connectivity modules, offering insights into cortical function and laying the groundwork for further studies on brain function, development, and dynamics. ",
    "url": "https://arxiv.org/abs/2310.20601",
    "authors": [
      "Jacob Tanner",
      "Sina Mansour L.",
      "Ludovico Coletta",
      "Alessandro Gozzi",
      "Richard F. Betzel"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.20609",
    "title": "Graph Matching via convex relaxation to the simplex",
    "abstract": "This paper addresses the Graph Matching problem, which consists of finding the best possible alignment between two input graphs, and has many applications in computer vision, network deanonymization and protein alignment. A common approach to tackle this problem is through convex relaxations of the NP-hard \\emph{Quadratic Assignment Problem} (QAP). Here, we introduce a new convex relaxation onto the unit simplex and develop an efficient mirror descent scheme with closed-form iterations for solving this problem. Under the correlated Gaussian Wigner model, we show that the simplex relaxation admits a unique solution with high probability. In the noiseless case, this is shown to imply exact recovery of the ground truth permutation. Additionally, we establish a novel sufficiency condition for the input matrix in standard greedy rounding methods, which is less restrictive than the commonly used `diagonal dominance' condition. We use this condition to show exact one-step recovery of the ground truth (holding almost surely) via the mirror descent scheme, in the noiseless setting. We also use this condition to obtain significantly improved conditions for the GRAMPA algorithm [Fan et al. 2019] in the noiseless setting. ",
    "url": "https://arxiv.org/abs/2310.20609",
    "authors": [
      "Ernesto Araya Valdivia",
      "Hemant Tyagi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2310.20630",
    "title": "Projecting basis functions with tensor networks for Gaussian process  regression",
    "abstract": "This paper presents a method for approximate Gaussian process (GP) regression with tensor networks (TNs). A parametric approximation of a GP uses a linear combination of basis functions, where the accuracy of the approximation depends on the total number of basis functions $M$. We develop an approach that allows us to use an exponential amount of basis functions without the corresponding exponential computational complexity. The key idea to enable this is using low-rank TNs. We first find a suitable low-dimensional subspace from the data, described by a low-rank TN. In this low-dimensional subspace, we then infer the weights of our model by solving a Bayesian inference problem. Finally, we project the resulting weights back to the original space to make GP predictions. The benefit of our approach comes from the projection to a smaller subspace: It modifies the shape of the basis functions in a way that it sees fit based on the given data, and it allows for efficient computations in the smaller subspace. In an experiment with an 18-dimensional benchmark data set, we show the applicability of our method to an inverse dynamics problem. ",
    "url": "https://arxiv.org/abs/2310.20630",
    "authors": [
      "Clara Menzen",
      "Eva Memmel",
      "Kim Batselier",
      "Manon Kok"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.20671",
    "title": "Density Matrix Emulation of Quantum Recurrent Neural Networks for  Multivariate Time Series Prediction",
    "abstract": "Quantum Recurrent Neural Networks (QRNNs) are robust candidates to model and predict future values in multivariate time series. However, the effective implementation of some QRNN models is limited by the need of mid-circuit measurements. Those increase the requirements for quantum hardware, which in the current NISQ era does not allow reliable computations. Emulation arises as the main near-term alternative to explore the potential of QRNNs, but existing quantum emulators are not dedicated to circuits with multiple intermediate measurements. In this context, we design a specific emulation method that relies on density matrix formalism. The mathematical development is explicitly provided as a compact formulation by using tensor notation. It allows us to show how the present and past information from a time series is transmitted through the circuit, and how to reduce the computational cost in every time step of the emulated network. In addition, we derive the analytical gradient and the Hessian of the network outputs with respect to its trainable parameters, with an eye on gradient-based training and noisy outputs that would appear when using real quantum processors. We finally test the presented methods using a novel hardware-efficient ansatz and three diverse datasets that include univariate and multivariate time series. Our results show how QRNNs can make accurate predictions of future values by capturing non-trivial patterns of input series with different complexities. ",
    "url": "https://arxiv.org/abs/2310.20671",
    "authors": [
      "Jos\u00e9 Daniel Viqueira",
      "Daniel Fa\u00edlde",
      "Mariamo M. Juane",
      "Andr\u00e9s G\u00f3mez",
      "David Mera"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.07158",
    "title": "Hop-Spanners for Geometric Intersection Graphs",
    "abstract": " Comments: 36 pages, 24 figures, full version of an extended abstract in the Proceedings of SoCG 2022 ",
    "url": "https://arxiv.org/abs/2112.07158",
    "authors": [
      "Jonathan B. Conroy",
      "Csaba D. T\u00f3th"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2203.15009",
    "title": "DAMNETS: A Deep Autoregressive Model for Generating Markovian Network  Time Series",
    "abstract": " Title: DAMNETS: A Deep Autoregressive Model for Generating Markovian Network  Time Series ",
    "url": "https://arxiv.org/abs/2203.15009",
    "authors": [
      "Jase Clarkson",
      "Mihai Cucuringu",
      "Andrew Elliott",
      "Gesine Reinert"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistical Finance (q-fin.ST)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2203.15446",
    "title": "A framework for minimal hereditary classes of graphs of unbounded  clique-width",
    "abstract": " Comments: 33 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2203.15446",
    "authors": [
      "Robert Brignall",
      "Daniel Cocks"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2204.08663",
    "title": "Pre-training of Equivariant Graph Matching Networks with Conformation  Flexibility for Drug Binding",
    "abstract": " Title: Pre-training of Equivariant Graph Matching Networks with Conformation  Flexibility for Drug Binding ",
    "url": "https://arxiv.org/abs/2204.08663",
    "authors": [
      "Fang Wu",
      "Shuting Jin",
      "Yinghui Jiang",
      "Xurui Jin",
      "Bowen Tang",
      "Zhangming Niu",
      "Xiangrong Liu",
      "Qiang Zhang",
      "Xiangxiang Zeng",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2206.05927",
    "title": "LinK3D: Linear Keypoints Representation for 3D LiDAR Point Cloud",
    "abstract": " Title: LinK3D: Linear Keypoints Representation for 3D LiDAR Point Cloud ",
    "url": "https://arxiv.org/abs/2206.05927",
    "authors": [
      "Yunge Cui",
      "Yinlong Zhang",
      "Jiahua Dong",
      "Haibo Sun",
      "Xieyuanli Chen",
      "Feng Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.15381",
    "title": "How direct is the link between words and images?",
    "abstract": " Comments: Accepted in the Mental Lexicon Journal: this https URL ",
    "url": "https://arxiv.org/abs/2206.15381",
    "authors": [
      "Hassan Shahmohammadi",
      "Maria Heitmeier",
      "Elnaz Shafaei-Bajestan",
      "Hendrik P. A. Lensch",
      "Harald Baayen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.02016",
    "title": "Robust Reinforcement Learning in Continuous Control Tasks with  Uncertainty Set Regularization",
    "abstract": " Title: Robust Reinforcement Learning in Continuous Control Tasks with  Uncertainty Set Regularization ",
    "url": "https://arxiv.org/abs/2207.02016",
    "authors": [
      "Yuan Zhang",
      "Jianhong Wang",
      "Joschka Boedecker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2208.04591",
    "title": "Stronger Privacy Amplification by Shuffling for R\u00e9nyi and Approximate  Differential Privacy",
    "abstract": " Comments: Errata added. 14 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2208.04591",
    "authors": [
      "Vitaly Feldman",
      "Audra McMillan",
      "Kunal Talwar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.02564",
    "title": "Progressive Domain Adaptation with Contrastive Learning for Object  Detection in the Satellite Imagery",
    "abstract": " Title: Progressive Domain Adaptation with Contrastive Learning for Object  Detection in the Satellite Imagery ",
    "url": "https://arxiv.org/abs/2209.02564",
    "authors": [
      "Debojyoti Biswas",
      "Jelena Te\u0161i\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2210.09809",
    "title": "Analysis of Convolutions, Non-linearity and Depth in Graph Neural  Networks using Neural Tangent Kernel",
    "abstract": " Comments: 39 pages, 24 figures. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2210.09809",
    "authors": [
      "Mahalakshmi Sabanayagam",
      "Pascal Esser",
      "Debarghya Ghoshdastidar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2301.07261",
    "title": "A Note on the $k$-colored Crossing Ratio of Dense Geometric Graphs",
    "abstract": " Title: A Note on the $k$-colored Crossing Ratio of Dense Geometric Graphs ",
    "url": "https://arxiv.org/abs/2301.07261",
    "authors": [
      "Ruy Fabila-Monroy"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2302.05527",
    "title": "CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code",
    "abstract": " Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code ",
    "url": "https://arxiv.org/abs/2302.05527",
    "authors": [
      "Shuyan Zhou",
      "Uri Alon",
      "Sumit Agarwal",
      "Graham Neubig"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2302.06052",
    "title": "CEDNet: A Cascade Encoder-Decoder Network for Dense Prediction",
    "abstract": " Comments: Technical report; Code: this https URL ",
    "url": "https://arxiv.org/abs/2302.06052",
    "authors": [
      "Gang Zhang",
      "Ziyi Li",
      "Chufeng Tang",
      "Jianmin Li",
      "Xiaolin Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2302.06896",
    "title": "Message Passing Meets Graph Neural Networks: A New Paradigm for Massive  MIMO Systems",
    "abstract": " Comments: 30 Pages, 7 Figures, and 4 Tables. This paper has been accepted by the IEEE Transactions on Wireless Communications. The code is available at: this https URL ",
    "url": "https://arxiv.org/abs/2302.06896",
    "authors": [
      "Hengtao He",
      "Xianghao Yu",
      "Jun Zhang",
      "Shenghui Song",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2302.06960",
    "title": "Data pruning and neural scaling laws: fundamental limitations of  score-based algorithms",
    "abstract": " Title: Data pruning and neural scaling laws: fundamental limitations of  score-based algorithms ",
    "url": "https://arxiv.org/abs/2302.06960",
    "authors": [
      "Fadhel Ayed",
      "Soufiane Hayou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2302.07491",
    "title": "Self-Supervised Temporal Graph learning with Temporal and Structural  Intensity Alignment",
    "abstract": " Title: Self-Supervised Temporal Graph learning with Temporal and Structural  Intensity Alignment ",
    "url": "https://arxiv.org/abs/2302.07491",
    "authors": [
      "Meng Liu",
      "Ke Liang",
      "Yawei Zhao",
      "Wenxuan Tu",
      "Sihang Zhou",
      "Xinwang Liu",
      "Kunlun He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2303.01456",
    "title": "The Double-Edged Sword of Implicit Bias: Generalization vs. Robustness  in ReLU Networks",
    "abstract": " Comments: 42 pages; NeurIPS 2023 camera ready ",
    "url": "https://arxiv.org/abs/2303.01456",
    "authors": [
      "Spencer Frei",
      "Gal Vardi",
      "Peter L. Bartlett",
      "Nathan Srebro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2303.03012",
    "title": "On Extracting Specialized Code Abilities from Large Language Models: A  Feasibility Study",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2303.03012",
    "authors": [
      "Zongjie Li",
      "Chaozheng Wang",
      "Pingchuan Ma",
      "Chaowei Liu",
      "Shuai Wang",
      "Daoyuan Wu",
      "Cuiyun Gao",
      "Yang Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2303.03432",
    "title": "A polar prediction model for learning to represent visual  transformations",
    "abstract": " Title: A polar prediction model for learning to represent visual  transformations ",
    "url": "https://arxiv.org/abs/2303.03432",
    "authors": [
      "Pierre-\u00c9tienne H. Fiquet",
      "Eero P. Simoncelli"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2303.04178",
    "title": "SALSA PICANTE: a machine learning attack on LWE with binary secrets",
    "abstract": " Comments: 15 pages, 6 figures, 17 tables; accepted to CCS 2023 ",
    "url": "https://arxiv.org/abs/2303.04178",
    "authors": [
      "Cathy Li",
      "Jana Sot\u00e1kov\u00e1",
      "Emily Wenger",
      "Mohamed Malhou",
      "Evrard Garcelon",
      "Francois Charton",
      "Kristin Lauter"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2303.08240",
    "title": "Parametric Surface Constrained Upsampler Network for Point Cloud",
    "abstract": " Comments: Update Supplementary Files ",
    "url": "https://arxiv.org/abs/2303.08240",
    "authors": [
      "Pingping Cai",
      "Zhenyao Wu",
      "Xinyi Wu",
      "Song Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2303.09093",
    "title": "GLEN: General-Purpose Event Detection for Thousands of Types",
    "abstract": " Comments: Accepted to EMNLP 2023. The first two authors contributed equally. (16 pages) ",
    "url": "https://arxiv.org/abs/2303.09093",
    "authors": [
      "Qiusi Zhan",
      "Sha Li",
      "Kathryn Conger",
      "Martha Palmer",
      "Heng Ji",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2303.18138",
    "title": "BERT4ETH: A Pre-trained Transformer for Ethereum Fraud Detection",
    "abstract": " Comments: The ACM Web conference (WWW) 2023 ",
    "url": "https://arxiv.org/abs/2303.18138",
    "authors": [
      "Sihao Hu",
      "Zhen Zhang",
      "Bingqiao Luo",
      "Shengliang Lu",
      "Bingsheng He",
      "Ling Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2304.03216",
    "title": "On the Pareto Front of Multilingual Neural Machine Translation",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2304.03216",
    "authors": [
      "Liang Chen",
      "Shuming Ma",
      "Dongdong Zhang",
      "Furu Wei",
      "Baobao Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2304.14990",
    "title": "Robust Stackelberg Equilibria",
    "abstract": " Title: Robust Stackelberg Equilibria ",
    "url": "https://arxiv.org/abs/2304.14990",
    "authors": [
      "Jiarui Gan",
      "Minbiao Han",
      "Jibang Wu",
      "Haifeng Xu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)",
      "Theoretical Economics (econ.TH)"
    ]
  },
  {
    "id": "arXiv:2305.01210",
    "title": "Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of  Large Language Models for Code Generation",
    "abstract": " Title: Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of  Large Language Models for Code Generation ",
    "url": "https://arxiv.org/abs/2305.01210",
    "authors": [
      "Jiawei Liu",
      "Chunqiu Steven Xia",
      "Yuyao Wang",
      "Lingming Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.02997",
    "title": "When Do Neural Nets Outperform Boosted Trees on Tabular Data?",
    "abstract": " Comments: NeurIPS Datasets and Benchmarks Track 2023 ",
    "url": "https://arxiv.org/abs/2305.02997",
    "authors": [
      "Duncan McElfresh",
      "Sujay Khandagale",
      "Jonathan Valverde",
      "Vishak Prasad C",
      "Benjamin Feuer",
      "Chinmay Hegde",
      "Ganesh Ramakrishnan",
      "Micah Goldblum",
      "Colin White"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.03971",
    "title": "Adaptive loose optimization for robust question answering",
    "abstract": " Comments: 13 pages,8 figures ",
    "url": "https://arxiv.org/abs/2305.03971",
    "authors": [
      "Jie Ma",
      "Pinghui Wang",
      "Zewei Wang",
      "Dechen Kong",
      "Min Hu",
      "Ting Han",
      "Jun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.05276",
    "title": "Causal Discovery from Subsampled Time Series with Proxy Variables",
    "abstract": " Comments: Accepted to NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2305.05276",
    "authors": [
      "Mingzhou Liu",
      "Xinwei Sun",
      "Lingjing Hu",
      "Yizhou Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2305.06773",
    "title": "Towards a Better Understanding of the Computer Vision Research Community  in Africa",
    "abstract": " Comments: Published in EAAMO'23 under ACM License. This work is part of our African computer vision grassroots research in Ro'ya - CV4Africa, this https URL ",
    "url": "https://arxiv.org/abs/2305.06773",
    "authors": [
      "Abdul-Hakeem Omotayo",
      "Mai Gamal",
      "Eman Ehab",
      "Gbetondji Dovonon",
      "Zainab Akinjobi",
      "Ismaila Lukman",
      "Houcemeddine Turki",
      "Mahmod Abdien",
      "Idriss Tondji",
      "Abigail Oppong",
      "Yvan Pimi",
      "Karim Gamal",
      "Ro'ya-CV4Africa",
      "Mennatullah Siam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2305.06986",
    "title": "Provable Guarantees for Nonlinear Feature Learning in Three-Layer Neural  Networks",
    "abstract": " Comments: v2: NeurIPS 2023 camera ready ",
    "url": "https://arxiv.org/abs/2305.06986",
    "authors": [
      "Eshaan Nichani",
      "Alex Damian",
      "Jason D. Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.09181",
    "title": "Push-LSVRG-UP: Distributed Stochastic Optimization over Unbalanced  Directed Networks with Uncoordinated Triggered Probabilities",
    "abstract": " Comments: 16 pages, 30 figures ",
    "url": "https://arxiv.org/abs/2305.09181",
    "authors": [
      "Jinhui Hu",
      "Guo Chen",
      "Huaqing Li",
      "Zixiang Shen",
      "Weidong Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.11469",
    "title": "The Barzilai-Borwein Method for Distributed Optimization over Unbalanced  Directed Networks",
    "abstract": " Comments: 33 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2305.11469",
    "authors": [
      "Jinhui Hu",
      "Xin Chen",
      "Lifeng Zheng",
      "Ling Zhang",
      "Huaqing Li"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2305.12162",
    "title": "A Scalable Neural Network for DSIC Affine Maximizer Auction Design",
    "abstract": " Comments: NeurIPS 2023 (spotlight) ",
    "url": "https://arxiv.org/abs/2305.12162",
    "authors": [
      "Zhijian Duan",
      "Haoran Sun",
      "Yurong Chen",
      "Xiaotie Deng"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2305.13084",
    "title": "A Fractional Graph Laplacian Approach to Oversmoothing",
    "abstract": " Comments: First two authors contributed equally. 37 pages, 8 images ",
    "url": "https://arxiv.org/abs/2305.13084",
    "authors": [
      "Sohir Maskey",
      "Raffaele Paolino",
      "Aras Bacho",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2305.14083",
    "title": "Counterfactual Augmentation for Multimodal Learning Under Presentation  Bias",
    "abstract": " Comments: Accepted to Findings of EMNLP 2023 ",
    "url": "https://arxiv.org/abs/2305.14083",
    "authors": [
      "Victoria Lin",
      "Louis-Philippe Morency",
      "Dimitrios Dimitriadis",
      "Srinagesh Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2305.14535",
    "title": "Uncertainty Quantification over Graph with Conformalized Graph Neural  Networks",
    "abstract": " Comments: Published at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2305.14535",
    "authors": [
      "Kexin Huang",
      "Ying Jin",
      "Emmanuel Cand\u00e8s",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2305.19065",
    "title": "Template-free Articulated Neural Point Clouds for Reposable View  Synthesis",
    "abstract": " Title: Template-free Articulated Neural Point Clouds for Reposable View  Synthesis ",
    "url": "https://arxiv.org/abs/2305.19065",
    "authors": [
      "Lukas Uzolas",
      "Elmar Eisemann",
      "Petr Kellnhofer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2306.01930",
    "title": "Structural Similarities Between Language Models and Neural Response  Measurements",
    "abstract": " Comments: NeurReps@NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.01930",
    "authors": [
      "Jiaang Li",
      "Antonia Karamolegkou",
      "Yova Kementchedjhieva",
      "Mostafa Abdou",
      "Sune Lehmann",
      "Anders S\u00f8gaard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2306.04746",
    "title": "Using Imperfect Surrogates for Downstream Inference: Design-based  Supervised Learning for Social Science Applications of Large Language Models",
    "abstract": " Comments: 37th Conference on Neural Information Processing Systems (NeurIPS 2023) ",
    "url": "https://arxiv.org/abs/2306.04746",
    "authors": [
      "Naoki Egami",
      "Musashi Hinck",
      "Brandon M. Stewart",
      "Hanying Wei"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.06723",
    "title": "Counting Distinct Elements in the Turnstile Model with Differential  Privacy under Continual Observation",
    "abstract": " Title: Counting Distinct Elements in the Turnstile Model with Differential  Privacy under Continual Observation ",
    "url": "https://arxiv.org/abs/2306.06723",
    "authors": [
      "Palak Jain",
      "Iden Kalemaj",
      "Sofya Raskhodnikova",
      "Satchit Sivakumar",
      "Adam Smith"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2306.06815",
    "title": "TrojLLM: A Black-box Trojan Prompt Attack on Large Language Models",
    "abstract": " Comments: Accepted by NeurIPS'23 ",
    "url": "https://arxiv.org/abs/2306.06815",
    "authors": [
      "Jiaqi Xue",
      "Mengxin Zheng",
      "Ting Hua",
      "Yilin Shen",
      "Yepeng Liu",
      "Ladislau Boloni",
      "Qian Lou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.07462",
    "title": "On the Robustness of Removal-Based Feature Attributions",
    "abstract": " Comments: NeurIPS camera-ready version ",
    "url": "https://arxiv.org/abs/2306.07462",
    "authors": [
      "Chris Lin",
      "Ian Covert",
      "Su-In Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.09549",
    "title": "QH9: A Quantum Hamiltonian Prediction Benchmark for QM9 Molecules",
    "abstract": " Comments: Accepted by NeurIPS 2023, Track on Datasets and Benchmarks ",
    "url": "https://arxiv.org/abs/2306.09549",
    "authors": [
      "Haiyang Yu",
      "Meng Liu",
      "Youzhi Luo",
      "Alex Strasser",
      "Xiaofeng Qian",
      "Xiaoning Qian",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2306.09739",
    "title": "Stabilized Neural Differential Equations for Learning Dynamics with  Explicit Constraints",
    "abstract": " Comments: 22 pages, 8 figures. Accepted at NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2306.09739",
    "authors": [
      "Alistair White",
      "Niki Kilbertus",
      "Maximilian Gelbrecht",
      "Niklas Boers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2306.15969",
    "title": "Separable Physics-Informed Neural Networks",
    "abstract": " Comments: To appear in NeurIPS 2023 (28 pages, 13 figures). workshop paper: arXiv:2211.08761 ",
    "url": "https://arxiv.org/abs/2306.15969",
    "authors": [
      "Junwoo Cho",
      "Seungtae Nam",
      "Hyunmo Yang",
      "Seok-Bae Yun",
      "Youngjoon Hong",
      "Eunbyung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.01187",
    "title": "SAMAug: Point Prompt Augmentation for Segment Anything Model",
    "abstract": " Title: SAMAug: Point Prompt Augmentation for Segment Anything Model ",
    "url": "https://arxiv.org/abs/2307.01187",
    "authors": [
      "Haixing Dai",
      "Chong Ma",
      "Zhengliang Liu",
      "Yiwei Li",
      "Peng Shu",
      "Xiaozheng Wei",
      "Lin Zhao",
      "Zihao Wu",
      "Fang Zeng",
      "Dajiang Zhu",
      "Wei Liu",
      "Quanzheng Li",
      "Tianming Liu",
      "Xiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2307.12750",
    "title": "DawnIK: Decentralized Collision-Aware Inverse Kinematics Solver for  Heterogeneous Multi-Arm Systems",
    "abstract": " Comments: Salih Marangoz and Rohit Menon have equal authorship. Publication to appear in IEEE RAS Intl Conference on Humanoid Robotics (Humanoids), 2023 ",
    "url": "https://arxiv.org/abs/2307.12750",
    "authors": [
      "Salih Marangoz",
      "Rohit Menon",
      "Nils Dengler",
      "Maren Bennewitz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2308.02493",
    "title": "Body Fat Estimation from Surface Meshes using Graph Neural Networks",
    "abstract": " Title: Body Fat Estimation from Surface Meshes using Graph Neural Networks ",
    "url": "https://arxiv.org/abs/2308.02493",
    "authors": [
      "Tamara T. Mueller",
      "Siyu Zhou",
      "Sophie Starck",
      "Friederike Jungmann",
      "Alexander Ziller",
      "Orhun Aksoy",
      "Danylo Movchan",
      "Rickmer Braren",
      "Georgios Kaissis",
      "Daniel Rueckert"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2308.06629",
    "title": "Optimal FIFO grouping in public transit networks",
    "abstract": " Comments: 1 page, 0 figures ",
    "url": "https://arxiv.org/abs/2308.06629",
    "authors": [
      "Patrick Steil"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2309.01886",
    "title": "Reconstruction of Unstable Heavy Particles Using Deep  Symmetry-Preserving Attention Networks",
    "abstract": " Comments: Submitted to Nature Communications ",
    "url": "https://arxiv.org/abs/2309.01886",
    "authors": [
      "Michael James Fenton",
      "Alexander Shmakov",
      "Hideki Okawa",
      "Yuji Li",
      "Ko-Yang Hsiao",
      "Shih-Chieh Hsu",
      "Daniel Whiteson",
      "Pierre Baldi"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ]
  },
  {
    "id": "arXiv:2309.07084",
    "title": "SupFusion: Supervised LiDAR-Camera Fusion for 3D Object Detection",
    "abstract": " Comments: Accepted to ICCV2023 ",
    "url": "https://arxiv.org/abs/2309.07084",
    "authors": [
      "Yiran Qin",
      "Chaoqun Wang",
      "Zijian Kang",
      "Ningning Ma",
      "Zhen Li",
      "Ruimao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2309.13391",
    "title": "D-Separation for Causal Self-Explanation",
    "abstract": " Comments: NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2309.13391",
    "authors": [
      "Wei Liu",
      "Jun Wang",
      "Haozhao Wang",
      "Ruixuan Li",
      "Zhiying Deng",
      "YuanKai Zhang",
      "Yang Qiu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2309.16645",
    "title": "Reusability report: Prostate cancer stratification with diverse  biologically-informed neural architectures",
    "abstract": " Comments: 9 pages, 3 figures. Submitted to Nature Machine Intelligence ",
    "url": "https://arxiv.org/abs/2309.16645",
    "authors": [
      "Christian Pedersen",
      "Tiberiu Tesileanu",
      "Tinghui Wu",
      "Siavash Golkar",
      "Miles Cranmer",
      "Zijun Zhang",
      "Shirley Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.00747",
    "title": "NoxTrader: LSTM-Based Stock Return Momentum Prediction for Quantitative  Trading",
    "abstract": " Comments: 5 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2310.00747",
    "authors": [
      "Hsiang-Hui Liu",
      "Han-Jay Shu",
      "Wei-Ning Chiu"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.01210",
    "title": "Towards Robust Cardiac Segmentation using Graph Convolutional Networks",
    "abstract": " Title: Towards Robust Cardiac Segmentation using Graph Convolutional Networks ",
    "url": "https://arxiv.org/abs/2310.01210",
    "authors": [
      "Gilles Van De Vyver",
      "Sarina Thomas",
      "Guy Ben-Yosef",
      "Sindre Hellum Olaisen",
      "H\u00e5vard Dalen",
      "Lasse L\u00f8vstakken",
      "Erik Smistad"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.03320",
    "title": "BioBridge: Bridging Biomedical Foundation Models via Knowledge Graphs",
    "abstract": " Title: BioBridge: Bridging Biomedical Foundation Models via Knowledge Graphs ",
    "url": "https://arxiv.org/abs/2310.03320",
    "authors": [
      "Zifeng Wang",
      "Zichen Wang",
      "Balasubramaniam Srinivasan",
      "Vassilis N. Ioannidis",
      "Huzefa Rangwala",
      "Rishita Anubhai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.05027",
    "title": "Rigid Clumps in the MercuryDPM Particle Dynamics Code",
    "abstract": " Title: Rigid Clumps in the MercuryDPM Particle Dynamics Code ",
    "url": "https://arxiv.org/abs/2310.05027",
    "authors": [
      "Igor Ostanin",
      "Vasileios Angelidakis",
      "Timo Plath",
      "Sahar Pourandi",
      "Anthony Thornton",
      "Thomas Weinhart"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ]
  },
  {
    "id": "arXiv:2310.05446",
    "title": "RetSeg: Retention-based Colorectal Polyps Segmentation Network",
    "abstract": " Comments: Updated PDF ",
    "url": "https://arxiv.org/abs/2310.05446",
    "authors": [
      "Khaled ELKarazle",
      "Valliappan Raman",
      "Caslon Chua",
      "Patrick Then"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.08748",
    "title": "Evolutionary Dynamic Optimization and Machine Learning",
    "abstract": " Title: Evolutionary Dynamic Optimization and Machine Learning ",
    "url": "https://arxiv.org/abs/2310.08748",
    "authors": [
      "Abdennour Boulesnane"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.09833",
    "title": "MIR2: Towards Provably Robust Multi-Agent Reinforcement Learning by  Mutual Information Regularization",
    "abstract": " Title: MIR2: Towards Provably Robust Multi-Agent Reinforcement Learning by  Mutual Information Regularization ",
    "url": "https://arxiv.org/abs/2310.09833",
    "authors": [
      "Simin Li",
      "Ruixiao Xu",
      "Jun Guo",
      "Pu Feng",
      "Jiakai Wang",
      "Aishan Liu",
      "Yaodong Yang",
      "Xianglong Liu",
      "Weifeng Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.10385",
    "title": "Towards a Better Understanding of Variations in Zero-Shot Neural Machine  Translation Performance",
    "abstract": " Comments: This paper is accepted by the EMNLP 2023 Main Conference ",
    "url": "https://arxiv.org/abs/2310.10385",
    "authors": [
      "Shaomu Tan",
      "Christof Monz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.14336",
    "title": "Learning Interpretable Rules for Scalable Data Representation and  Classification",
    "abstract": " Comments: Accepted by IEEE TPAMI in October 2023; Interpretable ML; Neuro-Symbolic AI; Preliminary conference version (NeurIPS 2021) available at arXiv:2109.15103 ",
    "url": "https://arxiv.org/abs/2310.14336",
    "authors": [
      "Zhuo Wang",
      "Wei Zhang",
      "Ning Liu",
      "Jianyong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2310.14767",
    "title": "Predicting COVID-19 Infections Using Multi-layer Centrality Measures in  Population-scale Networks",
    "abstract": " Comments: Updated Acknowledgement section ",
    "url": "https://arxiv.org/abs/2310.14767",
    "authors": [
      "Christine Hedde-von Westernhagen",
      "Javier Garcia-Bernardo",
      "Ayoub Bagheri"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2310.16475",
    "title": "Efficient Serverless Function Scheduling at the Network Edge",
    "abstract": " Title: Efficient Serverless Function Scheduling at the Network Edge ",
    "url": "https://arxiv.org/abs/2310.16475",
    "authors": [
      "Jiong Lou",
      "Zhiqing Tang",
      "Shijing Yuan",
      "Jie Li",
      "Chengtao Wu",
      "Weijia Jia"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2310.16945",
    "title": "Causal Q-Aggregation for CATE Model Selection",
    "abstract": " Comments: The main text is 10 pages, and we include the Appendix at the end (totaling 51 pages) ",
    "url": "https://arxiv.org/abs/2310.16945",
    "authors": [
      "Hui Lan",
      "Vasilis Syrgkanis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2310.17158",
    "title": "CosmosDSR -- a methodology for automated detection and tracking of  orbital debris using the Unscented Kalman Filter",
    "abstract": " Comments: 7 figures, 15 pages inc refs ",
    "url": "https://arxiv.org/abs/2310.17158",
    "authors": [
      "Daniel S. Roll",
      "Zeyneb Kurt",
      "Wai Lok Woo"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.17680",
    "title": "CodeFusion: A Pre-trained Diffusion Model for Code Generation",
    "abstract": " Comments: There are some errors in the paper and we need to retract it ",
    "url": "https://arxiv.org/abs/2310.17680",
    "authors": [
      "Mukul Singh",
      "Jos\u00e9 Cambronero",
      "Sumit Gulwani",
      "Vu Le",
      "Carina Negreanu",
      "Gust Verbruggen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2310.18068",
    "title": "Simple and Robust Dynamic Two-Dimensional Convex Hull",
    "abstract": " Comments: Accepted for ALENEX24 ",
    "url": "https://arxiv.org/abs/2310.18068",
    "authors": [
      "Emil Toftegaard G\u00e6de",
      "Inge Li G\u00f8rtz",
      "Ivor van der Hoog",
      "Christoffer Krogh",
      "Eva Rotenberg"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2310.18346",
    "title": "Data-Free Distillation Improves Efficiency and Privacy in Federated  Thorax Disease Analysis",
    "abstract": " Comments: Accepted by the IEEE EMBS International Conference on Data Science and Engineering in Healthcare, Medicine & Biology ",
    "url": "https://arxiv.org/abs/2310.18346",
    "authors": [
      "Ming Li",
      "Guang Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2310.18351",
    "title": "BioImage.IO Chatbot: A Personalized Assistant for BioImage Analysis  Augmented by Community Knowledge Base",
    "abstract": " Comments: 6 pages, 1 figure ",
    "url": "https://arxiv.org/abs/2310.18351",
    "authors": [
      "Wanlu Lei",
      "Caterina Fuster-Barcel\u00f3",
      "Arrate Mu\u00f1oz-Barrutia",
      "Wei Ouyang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2310.18518",
    "title": "Reconfiguration of plane trees in convex geometric graphs",
    "abstract": " Title: Reconfiguration of plane trees in convex geometric graphs ",
    "url": "https://arxiv.org/abs/2310.18518",
    "authors": [
      "Nicolas Bousquet",
      "Lucas De Meyer",
      "Th\u00e9o Pierron",
      "Alexandra Wesolek"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2310.18891",
    "title": "Social Interaction-Aware Dynamical Models and Decision Making for  Autonomous Vehicles",
    "abstract": " Title: Social Interaction-Aware Dynamical Models and Decision Making for  Autonomous Vehicles ",
    "url": "https://arxiv.org/abs/2310.18891",
    "authors": [
      "Luca Crosato",
      "Kai Tian",
      "Hubert P. H Shum",
      "Edmond S. L. Ho",
      "Yafei Wang",
      "Chongfeng Wei"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2310.18999",
    "title": "DynPoint: Dynamic Neural Point For View Synthesis",
    "abstract": " Title: DynPoint: Dynamic Neural Point For View Synthesis ",
    "url": "https://arxiv.org/abs/2310.18999",
    "authors": [
      "Kaichen Zhou",
      "Jia-Xing Zhong",
      "Sangyun Shin",
      "Kai Lu",
      "Yiyuan Yang",
      "Andrew Markham",
      "Niki Trigoni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19152",
    "title": "BERT Lost Patience Won't Be Robust to Adversarial Slowdown",
    "abstract": " Comments: Accepted to NeurIPS 2023 [Poster] ",
    "url": "https://arxiv.org/abs/2310.19152",
    "authors": [
      "Zachary Coalson",
      "Gabriel Ritter",
      "Rakesh Bobba",
      "Sanghyun Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2310.19582",
    "title": "Human-interpretable and deep features for image privacy classification",
    "abstract": " Title: Human-interpretable and deep features for image privacy classification ",
    "url": "https://arxiv.org/abs/2310.19582",
    "authors": [
      "Darya Baranouskaya",
      "Andrea Cavallaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2310.19677",
    "title": "MoCa: Measuring Human-Language Model Alignment on Causal and Moral  Judgment Tasks",
    "abstract": " Comments: 34 pages, 7 figures. NeurIPS 2023 ",
    "url": "https://arxiv.org/abs/2310.19677",
    "authors": [
      "Allen Nie",
      "Yuhui Zhang",
      "Atharva Amdekar",
      "Chris Piech",
      "Tatsunori Hashimoto",
      "Tobias Gerstenberg"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  }
]