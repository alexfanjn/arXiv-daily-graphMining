[
  {
    "id": "arXiv:2210.07269",
    "title": "SODAPOP: Open-Ended Discovery of Social Biases in Social Commonsense  Reasoning Models",
    "abstract": "A common limitation of diagnostic tests for detecting social biases in NLP models is that they may only detect stereotypic associations that are pre-specified by the designer of the test. Since enumerating all possible problematic associations is infeasible, it is likely these tests fail to detect biases that are present in a model but not pre-specified by the designer. To address this limitation, we propose SODAPOP (SOcial bias Discovery from Answers about PeOPle) in social commonsense question-answering. Our pipeline generates modified instances from the Social IQa dataset (Sap et al., 2019) by (1) substituting names associated with different demographic groups, and (2) generating many distractor answers from a masked language model. By using a social commonsense model to score the generated distractors, we are able to uncover the model's stereotypic associations between demographic groups and an open set of words. We also test SODAPOP on debiased models and show the limitations of multiple state-of-the-art debiasing algorithms. ",
    "url": "https://arxiv.org/abs/2210.07269",
    "authors": [
      "Haozhe An",
      "Zongxia Li",
      "Jieyu Zhao",
      "Rachel Rudinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.07271",
    "title": "BLOX: Macro Neural Architecture Search Benchmark and Algorithms",
    "abstract": "Neural architecture search (NAS) has been successfully used to design numerous high-performance neural networks. However, NAS is typically compute-intensive, so most existing approaches restrict the search to decide the operations and topological structure of a single block only, then the same block is stacked repeatedly to form an end-to-end model. Although such an approach reduces the size of search space, recent studies show that a macro search space, which allows blocks in a model to be different, can lead to better performance. To provide a systematic study of the performance of NAS algorithms on a macro search space, we release Blox - a benchmark that consists of 91k unique models trained on the CIFAR-100 dataset. The dataset also includes runtime measurements of all the models on a diverse set of hardware platforms. We perform extensive experiments to compare existing algorithms that are well studied on cell-based search spaces, with the emerging blockwise approaches that aim to make NAS scalable to much larger macro search spaces. The benchmark and code are available at https://github.com/SamsungLabs/blox. ",
    "url": "https://arxiv.org/abs/2210.07271",
    "authors": [
      "Thomas Chun Pong Chau",
      "\u0141ukasz Dudziak",
      "Hongkai Wen",
      "Nicholas Donald Lane",
      "Mohamed S Abdelfattah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07277",
    "title": "The Hidden Uniform Cluster Prior in Self-Supervised Learning",
    "abstract": "A successful paradigm in representation learning is to perform self-supervised pretraining using tasks based on mini-batch statistics (e.g., SimCLR, VICReg, SwAV, MSN). We show that in the formulation of all these methods is an overlooked prior to learn features that enable uniform clustering of the data. While this prior has led to remarkably semantic representations when pretraining on class-balanced data, such as ImageNet, we demonstrate that it can hamper performance when pretraining on class-imbalanced data. By moving away from conventional uniformity priors and instead preferring power-law distributed feature clusters, we show that one can improve the quality of the learned representations on real-world class-imbalanced datasets. To demonstrate this, we develop an extension of the Masked Siamese Networks (MSN) method to support the use of arbitrary features priors. ",
    "url": "https://arxiv.org/abs/2210.07277",
    "authors": [
      "Mahmoud Assran",
      "Randall Balestriero",
      "Quentin Duval",
      "Florian Bordes",
      "Ishan Misra",
      "Piotr Bojanowski",
      "Pascal Vincent",
      "Michael Rabbat",
      "Nicolas Ballas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07302",
    "title": "Deep Reinforcement Learning-based Rebalancing Policies for Profit  Maximization of Relay Nodes in Payment Channel Networks",
    "abstract": "Payment channel networks (PCNs) are a layer-2 blockchain scalability solution, with its main entity, the payment channel, enabling transactions between pairs of nodes \"off-chain,\" thus reducing the burden on the layer-1 network. Nodes with multiple channels can serve as relays for multihop payments over a path of channels: they relay payments of others by providing the liquidity of their channels, in exchange for part of the amount withheld as a fee. Relay nodes might after a while end up with one or more unbalanced channels, and thus need to trigger a rebalancing operation. In this paper, we study how a relay node can maximize its profits from fees by using the rebalancing method of submarine swaps. We introduce a stochastic model to capture the dynamics of a relay node observing random transaction arrivals and performing occasional rebalancing operations, and express the system evolution as a Markov Decision Process. We formulate the problem of the maximization of the node's fortune over time over all rebalancing policies, and approximate the optimal solution by designing a Deep Reinforcement Learning (DRL)-based rebalancing policy. We build a discrete event simulator of the system and use it to demonstrate the DRL policy's superior performance under most conditions by conducting a comparative study of different policies and parameterizations. In all, our approach aims to be the first to introduce DRL for network optimization in the complex world of PCNs. ",
    "url": "https://arxiv.org/abs/2210.07302",
    "authors": [
      "Nikolaos Papadis",
      "Leandros Tassiulas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.07309",
    "title": "SHINE: SubHypergraph Inductive Neural nEtwork",
    "abstract": "Hypergraph neural networks can model multi-way connections among nodes of the graphs, which are common in real-world applications such as genetic medicine. In particular, genetic pathways or gene sets encode molecular functions driven by multiple genes, naturally represented as hyperedges. Thus, hypergraph-guided embedding can capture functional relations in learned representations. Existing hypergraph neural network models often focus on node-level or graph-level inference. There is an unmet need in learning powerful representations of subgraphs of hypergraphs in real-world applications. For example, a cancer patient can be viewed as a subgraph of genes harboring mutations in the patient, while all the genes are connected by hyperedges that correspond to pathways representing specific molecular functions. For accurate inductive subgraph prediction, we propose SubHypergraph Inductive Neural nEtwork (SHINE). SHINE uses informative genetic pathways that encode molecular functions as hyperedges to connect genes as nodes. SHINE jointly optimizes the objectives of end-to-end subgraph classification and hypergraph nodes' similarity regularization. SHINE simultaneously learns representations for both genes and pathways using strongly dual attention message passing. The learned representations are aggregated via a subgraph attention layer and used to train a multilayer perceptron for inductive subgraph inferencing. We evaluated SHINE against a wide array of state-of-the-art (hyper)graph neural networks, XGBoost, NMF and polygenic risk score models, using large scale NGS and curated datasets. SHINE outperformed all comparison models significantly, and yielded interpretable disease models with functional insights. ",
    "url": "https://arxiv.org/abs/2210.07309",
    "authors": [
      "Yuan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Genomics (q-bio.GN)",
      "Molecular Networks (q-bio.MN)"
    ]
  },
  {
    "id": "arXiv:2210.07311",
    "title": "Linker Code Size Optimization for Native Mobile Applications",
    "abstract": "Modern mobile applications have grown rapidly in binary size, which restricts user growth and updates for existing users. Thus, reducing the binary size is important for application developers. Recent studies have shown the possibility of using link-time code size optimizations by re-invoking certain compiler optimizations on the linked intermediate representation of the program. However, such methods often incur significant build time overhead and require intrusive changes to the existing build pipeline. In this paper, we propose several novel optimization techniques that do not require significant customization to the build pipeline and reduce binary size with low build time overhead. As opposed to re-invoking the compiler during link time, we perform true linker optimization directly as optimization passes within the linker. This enables more optimization opportunities such as pre-compiled libraries that prior work often could not optimize. We evaluate our techniques on several open-source and commercial iOS applications including NewsFeedApp, ShortVideoApp, and CollaborationSuiteApp, each with hundreds of millions of daily active users. Our technique on average achieves 12.6% binary size reduction across the three commercial applications without any user-perceivable performance degradations. ",
    "url": "https://arxiv.org/abs/2210.07311",
    "authors": [
      "Gai Liu",
      "Umar Farooq",
      "Chengyan Zhao",
      "Xia Liu",
      "Nian Sun"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2210.07316",
    "title": "MTEB: Massive Text Embedding Benchmark",
    "abstract": "Text embeddings are commonly evaluated on a small set of datasets from a single task not covering their possible applications to other tasks. It is unclear whether state-of-the-art embeddings on semantic textual similarity (STS) can be equally well applied to other tasks like clustering or reranking. This makes progress in the field difficult to track, as various models are constantly being proposed without proper evaluation. To solve this problem, we introduce the Massive Text Embedding Benchmark (MTEB). MTEB spans 8 embedding tasks covering a total of 56 datasets and 112 languages. Through the benchmarking of 33 models on MTEB, we establish the most comprehensive benchmark of text embeddings to date. We find that no particular text embedding method dominates across all tasks. This suggests that the field has yet to converge on a universal text embedding method and scale it up sufficiently to provide state-of-the-art results on all embedding tasks. MTEB comes with open-source code and a public leaderboard at https://huggingface.co/spaces/mteb/leaderboard. ",
    "url": "https://arxiv.org/abs/2210.07316",
    "authors": [
      "Niklas Muennighoff",
      "Nouamane Tazi",
      "Lo\u00efc Magne",
      "Nils Reimers"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07321",
    "title": "Machine Generated Text: A Comprehensive Survey of Threat Models and  Detection Methods",
    "abstract": "Advances in natural language generation (NLG) have resulted in machine generated text that is increasingly difficult to distinguish from human authored text. Powerful open-source models are freely available, and user-friendly tools democratizing access to generative models are proliferating. The great potential of state-of-the-art NLG systems is tempered by the multitude of avenues for abuse. Detection of machine generated text is a key countermeasure for reducing abuse of NLG models, with significant technical challenges and numerous open problems. We provide a survey that includes both 1) an extensive analysis of threat models posed by contemporary NLG systems, and 2) the most complete review of machine generated text detection methods to date. This survey places machine generated text within its cybersecurity and social context, and provides strong guidance for future work addressing the most critical threat models, and ensuring detection systems themselves demonstrate trustworthiness through fairness, robustness, and accountability. ",
    "url": "https://arxiv.org/abs/2210.07321",
    "authors": [
      "Evan Crothers",
      "Nathalie Japkowicz",
      "Herna Viktor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07323",
    "title": "HuBERT-TR: Reviving Turkish Automatic Speech Recognition with  Self-supervised Speech Representation Learning",
    "abstract": "While the Turkish language is listed among low-resource languages, literature on Turkish automatic speech recognition (ASR) is relatively old. In this paper, we present HuBERT-TR, a speech representation model for Turkish based on HuBERT. HuBERT-TR achieves state-of-the-art results on several Turkish ASR datasets. We investigate pre-training HuBERT for Turkish with large-scale data curated from online resources. We pre-train HuBERT-TR using over 6,500 hours of speech data curated from YouTube that includes extensive variability in terms of quality and genre. We show that pre-trained models within a multi-lingual setup are inferior to language-specific models, where our Turkish model HuBERT-TR base performs better than its x10 times larger multi-lingual counterpart XLS-R-1B. Moreover, we study the effect of scaling on ASR performance by scaling our models up to 1B parameters. Our best model yields a state-of-the-art word error rate of 4.97% on the Turkish Broadcast News dataset. Models are available at huggingface.co/asafaya . ",
    "url": "https://arxiv.org/abs/2210.07323",
    "authors": [
      "Ali Safaya",
      "Engin Erzin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.07327",
    "title": "Machine Learning vs. Deep Learning in 5G Networks -- A Comparison of  Scientific Impact",
    "abstract": "Introduction of fifth generation (5G) wireless network technology has matched the crucial need for high capacity and speed needs of the new generation mobile applications. Recent advances in Artificial Intelligence (AI) also empowered 5G cellular networks with two mainstreams as machine learning (ML) and deep learning (DL) techniques. Our study aims to uncover the differences in scientific impact for these two techniques by the means of statistical bibliometrics. The performed analysis includes citation performance with respect to indexing types, funding availability, journal or conference publishing options together with distributions of these metrics along years to evaluate the popularity trends in a detailed manner. Web of Science (WoS) database host 2245 papers for ML and 1407 papers for DL-related studies. DL studies, starting with 9% rate in 2013, has reached to 45% rate in 2022 among all DL and ML-related studies. Results related to scientific impact indicate that DL studies get slightly more average normalized citation (2.256) compared to ML studies (2.118) in 5G, while SCI-Expanded indexed papers in both sides tend to have similar citation performance (3.165 and 3.162 respectively). ML-related studies those are indexed in ESCI show twice citation performance compared to DL. Conference papers in DL domain and journal papers in ML domain are superior in scientific interest to their counterparts with minor differences. Highest citation performance for ML studies is achieved for year 2014, while this peak is observed for 2017 for DL studies. We can conclude that both publication and citation rate for DL-related papers tend to increase and outperform ML-based studies in 5G domain by the means of citation metrics. ",
    "url": "https://arxiv.org/abs/2210.07327",
    "authors": [
      "Ilker Turker",
      "Serhat Orkun Tan"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.07342",
    "title": "Cognitive-Driven Development Helps Software Teams to Keep Code Units  Under the Limit!",
    "abstract": "Software design techniques are undoubtedly crucial in the process of designing good software. Over the years, a large number of design techniques have been proposed by both researchers and practitioners. Unfortunately, despite their uniqueness, it is not uncommon to find software products that make subpar design decisions, leading to design degradation challenges. One potential reason for this behavior is that developers do not have a clear vision of how much a code unit could grow; without this vision, a code unit can grow endlessly, even when developers are equipped with an arsenal of design practices. Different than other design techniques, Cognitive Driven Development (CDD for short) focuses on 1) defining and 2) limiting the number of coding elements that developers could use at a given code unit. In this paper, we report on the experiences of a software development team in using CDD for building from scratch a learning management tool at Zup Innovation, a Brazilian tech company. By curating commit traces left in the repositories, combined with the developers' perception, we organized a set of findings and lessons that could be useful for those interested in adopting CDD. For instance, we noticed that by using CDD, despite the evolution of the product, developers were able to keep the code units under a small amount of size (in terms of size). Furthermore, although limiting the complexity is at the heart of CDD, we also discovered that developers tend to relax this notion of limit so that they can cope with the different complexities of the software. Still, we noticed that CDD could also influence testing practices; limiting the code units' size makes testing easier to perform. ",
    "url": "https://arxiv.org/abs/2210.07342",
    "authors": [
      "Gustavo Pinto",
      "Alberto de Souza"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.07346",
    "title": "Demystifying Self-supervised Trojan Attacks",
    "abstract": "As an emerging machine learning paradigm, self-supervised learning (SSL) is able to learn high-quality representations for complex data without data labels. Prior work shows that, besides obviating the reliance on labeling, SSL also benefits adversarial robustness by making it more challenging for the adversary to manipulate model prediction. However, whether this robustness benefit generalizes to other types of attacks remains an open question. We explore this question in the context of trojan attacks by showing that SSL is comparably vulnerable as supervised learning to trojan attacks. Specifically, we design and evaluate CTRL, an extremely simple self-supervised trojan attack. By polluting a tiny fraction of training data (less than 1%) with indistinguishable poisoning samples, CTRL causes any trigger-embedded input to be misclassified to the adversary's desired class with a high probability (over 99%) at inference. More importantly, through the lens of CTRL, we study the mechanisms underlying self-supervised trojan attacks. With both empirical and analytical evidence, we reveal that the representation invariance property of SSL, which benefits adversarial robustness, may also be the very reason making SSL highly vulnerable to trojan attacks. We further discuss the fundamental challenges to defending against self-supervised trojan attacks, pointing to promising directions for future research. ",
    "url": "https://arxiv.org/abs/2210.07346",
    "authors": [
      "Changjiang Li",
      "Ren Pang",
      "Zhaohan Xi",
      "Tianyu Du",
      "Shouling Ji",
      "Yuan Yao",
      "Ting Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07372",
    "title": "SWFormer: Sparse Window Transformer for 3D Object Detection in Point  Clouds",
    "abstract": "3D object detection in point clouds is a core component for modern robotics and autonomous driving systems. A key challenge in 3D object detection comes from the inherent sparse nature of point occupancy within the 3D scene. In this paper, we propose Sparse Window Transformer (SWFormer ), a scalable and accurate model for 3D object detection, which can take full advantage of the sparsity of point clouds. Built upon the idea of window-based Transformers, SWFormer converts 3D points into sparse voxels and windows, and then processes these variable-length sparse windows efficiently using a bucketing scheme. In addition to self-attention within each spatial window, our SWFormer also captures cross-window correlation with multi-scale feature fusion and window shifting operations. To further address the unique challenge of detecting 3D objects accurately from sparse features, we propose a new voxel diffusion technique. Experimental results on the Waymo Open Dataset show our SWFormer achieves state-of-the-art 73.36 L2 mAPH on vehicle and pedestrian for 3D object detection on the official test set, outperforming all previous single-stage and two-stage models, while being much more efficient. ",
    "url": "https://arxiv.org/abs/2210.07372",
    "authors": [
      "Pei Sun",
      "Mingxing Tan",
      "Weiyue Wang",
      "Chenxi Liu",
      "Fei Xia",
      "Zhaoqi Leng",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07373",
    "title": "Mind the Labels: Describing Relations in Knowledge Graphs With  Pretrained Models",
    "abstract": "Pretrained language models (PLMs) for data-to-text (D2T) generation can use human-readable data labels such as column headings, keys, or relation names to generalize to out-of-domain examples. However, the models are well-known in producing semantically inaccurate outputs if these labels are ambiguous or incomplete, which is often the case in D2T datasets. In this paper, we expose this issue on the task of descibing a relation between two entities. For our experiments, we collect a novel dataset for verbalizing a diverse set of 1,522 unique relations from three large-scale knowledge graphs (Wikidata, DBPedia, YAGO). We find that although PLMs for D2T generation expectedly fail on unclear cases, models trained with a large variety of relation labels are surprisingly robust in verbalizing novel, unseen relations. We argue that using data with a diverse set of clear and meaningful labels is key to training D2T generation systems capable of generalizing to novel domains. ",
    "url": "https://arxiv.org/abs/2210.07373",
    "authors": [
      "Zden\u011bk Kasner",
      "Ioannis Konstas",
      "Ond\u0159ej Du\u0161ek"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.07385",
    "title": "Synthesis of Proactive Sensor Placement In Probabilistic Attack Graphs",
    "abstract": "This paper studies the deployment of joint moving target defense (MTD) and deception against multi-stage cyberattacks. Given the system equipped with MTD that randomizes between different configurations, we investigate how to allocate a bounded number of sensors in each configuration to optimize the attack detection rate before the attacker achieves its objective. Specifically, two types of sensors are considered: intrusion detectors that are observable by the attacker and stealthy sensors that are not observable to the attacker. We propose a two-step optimization-based approach for allocating intrusion detectors and stealthy sensors: Firstly, the defender allocates intrusion detectors assuming the attacker will best respond to evade detection by intrusion detectors. Secondly, the defender will allocate stealthy sensors, given the best response attack strategy computed in the first step, to further reduce the attacker's chance of success. We illustrate the effectiveness of the proposed methods using a cyber defense example. ",
    "url": "https://arxiv.org/abs/2210.07385",
    "authors": [
      "Lening Li",
      "Haoxiang Ma",
      "Shuo Han",
      "Jie Fu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.07387",
    "title": "Amortized Inference for Heterogeneous Reconstruction in Cryo-EM",
    "abstract": "Cryo-electron microscopy (cryo-EM) is an imaging modality that provides unique insights into the dynamics of proteins and other building blocks of life. The algorithmic challenge of jointly estimating the poses, 3D structure, and conformational heterogeneity of a biomolecule from millions of noisy and randomly oriented 2D projections in a computationally efficient manner, however, remains unsolved. Our method, cryoFIRE, performs ab initio heterogeneous reconstruction with unknown poses in an amortized framework, thereby avoiding the computationally expensive step of pose search while enabling the analysis of conformational heterogeneity. Poses and conformation are jointly estimated by an encoder while a physics-based decoder aggregates the images into an implicit neural representation of the conformational space. We show that our method can provide one order of magnitude speedup on datasets containing millions of images without any loss of accuracy. We validate that the joint estimation of poses and conformations can be amortized over the size of the dataset. For the first time, we prove that an amortized method can extract interpretable dynamic information from experimental datasets. ",
    "url": "https://arxiv.org/abs/2210.07387",
    "authors": [
      "Axel Levy",
      "Gordon Wetzstein",
      "Julien Martel",
      "Frederic Poitevin",
      "Ellen D. Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2210.07394",
    "title": "Efficiently Computing Local Lipschitz Constants of Neural Networks via  Bound Propagation",
    "abstract": "Lipschitz constants are connected to many properties of neural networks, such as robustness, fairness, and generalization. Existing methods for computing Lipschitz constants either produce relatively loose upper bounds or are limited to small networks. In this paper, we develop an efficient framework for computing the $\\ell_\\infty$ local Lipschitz constant of a neural network by tightly upper bounding the norm of Clarke Jacobian via linear bound propagation. We formulate the computation of local Lipschitz constants with a linear bound propagation process on a high-order backward graph induced by the chain rule of Clarke Jacobian. To enable linear bound propagation, we derive tight linear relaxations for specific nonlinearities in Clarke Jacobian. This formulate unifies existing ad-hoc approaches such as RecurJac, which can be seen as a special case of ours with weaker relaxations. The bound propagation framework also allows us to easily borrow the popular Branch-and-Bound (BaB) approach from neural network verification to further tighten Lipschitz constants. Experiments show that on tiny models, our method produces comparable bounds compared to exact methods that cannot scale to slightly larger models; on larger models, our method efficiently produces tighter results than existing relaxed or naive methods, and our method scales to much larger practical models that previous works could not handle. We also demonstrate an application on provable monotonicity analysis. Code is available at https://github.com/shizhouxing/Local-Lipschitz-Constants. ",
    "url": "https://arxiv.org/abs/2210.07394",
    "authors": [
      "Zhouxing Shi",
      "Yihan Wang",
      "Huan Zhang",
      "Zico Kolter",
      "Cho-Jui Hsieh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07396",
    "title": "Caption supervision enables robust learners",
    "abstract": "Vision language models like CLIP are robust to natural distribution shifts, in part because CLIP learns on unstructured data using a technique called caption supervision; the model inteprets image-linked texts as ground-truth labels. In a carefully controlled comparison study, we show that CNNs trained on a standard cross-entropy loss can also benefit from caption supervision, in some cases even more than VL models, on the same data. To facilitate future experiments with high-accuracy caption-supervised models, we introduce CaptionNet (https://github.com/penfever/CaptionNet/), which includes a class-balanced, fully supervised dataset with over 50,000 new human-labeled ImageNet-compliant samples which includes web-scraped captions. In a series of experiments on CaptionNet, we show how the choice of loss function, data filtration and supervision strategy enable robust computer vision. We also provide the codebase necessary to reproduce our experiments at https://github.com/penfever/vlhub/ ",
    "url": "https://arxiv.org/abs/2210.07396",
    "authors": [
      "Benjamin Feuer",
      "Ameya Joshi",
      "Chinmay Hegde"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07401",
    "title": "Estimation of the Sample Frechet Mean: A Convolutional Neural Network  Approach",
    "abstract": "This work addresses the rising demand for novel tools in statistical and machine learning for \"graph-valued random variables\" by proposing a fast algorithm to compute the sample Frechet mean, which replaces the concept of sample mean for graphs (or networks). We use convolutional neural networks to learn the morphology of the graphs in a set of graphs. Our experiments on several ensembles of random graphs demonstrate that our method can reliably recover the sample Frechet mean. ",
    "url": "https://arxiv.org/abs/2210.07401",
    "authors": [
      "Adam Sanchez",
      "Fran\u00e7ois G. Meyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.07407",
    "title": "Anomaly detection in dynamic networks",
    "abstract": "Detecting anomalies from a series of temporal networks has many applications, including road accidents in transport networks and suspicious events in social networks. While there are many methods for network anomaly detection, statistical methods are under utilised in this space even though they have a long history and proven capability in handling temporal dependencies. In this paper, we introduce \\textit{oddnet}, a feature-based network anomaly detection method that uses time series methods to model temporal dependencies. We demonstrate the effectiveness of oddnet on synthetic and real-world datasets. The R package oddnet implements this algorithm. ",
    "url": "https://arxiv.org/abs/2210.07407",
    "authors": [
      "Sevvandi Kandanaarachchi",
      "Rob J Hyndman"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.07411",
    "title": "A Novel Supervised Contrastive Regression Framework for Prediction of  Neurocognitive Measures Using Multi-Site Harmonized Diffusion MRI  Tractography",
    "abstract": "Neuroimaging-based prediction of neurocognitive measures is valuable for studying how the brain's structure relates to cognitive function. However, the accuracy of prediction using popular linear regression models is relatively low. We propose Supervised Contrastive Regression (SCR), a simple yet effective method that allows full supervision for contrastive learning in regression tasks. SCR performs supervised contrastive representation learning by using the absolute difference between continuous regression labels (i.e. neurocognitive scores) to determine positive and negative pairs. We apply SCR to analyze a large-scale dataset including multi-site harmonized diffusion MRI and neurocognitive data from 8735 participants in the Adolescent Brain Cognitive Development (ABCD) Study. We extract white matter microstructural measures using a fine parcellation of white matter tractography into fiber clusters. We predict three scores related to domains of higher-order cognition (general cognitive ability, executive function, and learning/memory). To identify important fiber clusters for prediction of these neurocognitive scores, we propose a permutation feature importance method for high-dimensional data. We find that SCR improves the accuracy of neurocognitive score prediction compared to other state-of-the-art methods. We find that the most predictive fiber clusters are predominantly located within the superficial white matter and projection tracts, particularly the superficial frontal white matter and striato-frontal connections. Overall, our results demonstrate the utility of contrastive representation learning methods for regression, and in particular for improving neuroimaging-based prediction of higher-order cognitive abilities. ",
    "url": "https://arxiv.org/abs/2210.07411",
    "authors": [
      "Tengfei Xue",
      "Fan Zhang",
      "Leo R. Zekelman",
      "Chaoyi Zhang",
      "Yuqian Chen",
      "Suheyla Cetin-Karayumak",
      "Steve Pieper",
      "William M. Wells",
      "Yogesh Rathi",
      "Nikos Makris",
      "Weidong Cai",
      "Lauren J. O'Donnell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07414",
    "title": "Human interaction networks reveal that large cities facilitate  segregation",
    "abstract": "A long-standing expectation is that large, dense, and cosmopolitan areas will support diverse interactions and socioeconomic mixing. It has been difficult to assess this hypothesis because past approaches to measuring socioeconomic mixing have relied on static residential housing data rather than real-life interactions among people meeting at work, in places of leisure, and in home neighborhoods. Here we develop a new measure of interaction segegation (IS) that captures the economic diversity of the set of people that a given person meets in their everyday life. Leveraging cell phone mobility data to represent 1.6 billion interactions among 9.6 million people in the United States, we measure interaction segregation across 382 Metropolitan Statistical Areas (MSAs) and 2829 counties. When averaged across all MSAs, interaction segregation is 38% lower than a conventional static estimate, which means that people meet diverse others mostly when outside their home neighborhoods. But, we also find that interaction segregation is 67% higher in the 10 largest Metropolitan Statistical Areas (MSAs) than in small MSAs with fewer than 100,000 residents. We find evidence that because large cities can offer a greater choice of differentiated spaces targeted to specific socioeconomic groups, they end up promoting -- rather than reducing -- everyday economic segregation. We also discover that this segregation-increasing effect is countered when hubs of interaction (e.g. shopping malls) are positioned to bridge diverse neighborhoods and thus attract people of all socioeconomic statuses. Overall, our findings challenge a long-standing conjecture in human geography and urban design, and highlight how built environment can both prevent and facilitate diverse human interactions. ",
    "url": "https://arxiv.org/abs/2210.07414",
    "authors": [
      "Hamed Nilforoshan",
      "Wenli Looi",
      "Emma Pierson",
      "Blanca Villanueva",
      "Nic Fishman",
      "Yiling Chen",
      "John Sholar",
      "Beth Redbird",
      "David Grusky",
      "Jure Leskovec"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ]
  },
  {
    "id": "arXiv:2210.07416",
    "title": "GLACIAL: Granger and Learning-based Causality Analysis for Longitudinal  Studies",
    "abstract": "The Granger framework is widely used for discovering causal relationships based on time-varying signals. Implementations of Granger causality (GC) are mostly developed for densely sampled timeseries data. A substantially different setting, particularly common in population health applications, is the longitudinal study design, where multiple individuals are followed and sparsely observed for a limited number of times. Longitudinal studies commonly track many variables, which are likely governed by nonlinear dynamics that might have individual-specific idiosyncrasies and exhibit both direct and indirect causes. Furthermore, real-world longitudinal data often suffer from widespread missingness. GC methods are not well-suited to handle these issues. In this paper, we intend to fill this methodological gap. We propose to marry the GC framework with a machine learning based prediction model. We call our approach GLACIAL, which stands for \"Granger and LeArning-based CausalIty Analysis for Longitudinal studies.\" GLACIAL treats individuals as independent samples and uses average prediction accuracy on hold-out individuals to test for effects of causal relationships. GLACIAL employs a multi-task neural network trained with input feature dropout to efficiently learn nonlinear dynamic relationships between a large number of variables, handle missing values, and probe causal links. Extensive experiments on synthetic and real data demonstrate the utility of GLACIAL and how it can outperform competitive baselines. ",
    "url": "https://arxiv.org/abs/2210.07416",
    "authors": [
      "Minh Nguyen",
      "Gia H. Ngo",
      "Mert R. Sabuncu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2210.07420",
    "title": "Learning to Efficiently Plan Robust Frictional Multi-Object Grasps",
    "abstract": "We consider a decluttering problem where multiple rigid convex polygonal objects rest in randomly placed positions and orientations on a planar surface and must be efficiently transported to a packing box using both single and multi-object grasps. Prior work considered frictionless multi-object grasping. In this paper, we introduce friction to increase picks per hour. We train a neural network using real examples to plan robust multi-object grasps. In physical experiments, we find an 11.7% increase in success rates, a 1.7x increase in picks per hour, and an 8.2x decrease in grasp planning time compared to prior work on multi-object grasping. Videos are available at https://youtu.be/pEZpHX5FZIs. ",
    "url": "https://arxiv.org/abs/2210.07420",
    "authors": [
      "Wisdom C. Agboh",
      "Satvik Sharma",
      "Kishore Srinivas",
      "Mallika Parulekar",
      "Gaurav Datta",
      "Tianshuang Qiu",
      "Jeffrey Ichnowski",
      "Eugen Solowjow",
      "Mehmet Dogar",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07424",
    "title": "Autoregressive Uncertainty Modeling for 3D Bounding Box Prediction",
    "abstract": "3D bounding boxes are a widespread intermediate representation in many computer vision applications. However, predicting them is a challenging task, largely due to partial observability, which motivates the need for a strong sense of uncertainty. While many recent methods have explored better architectures for consuming sparse and unstructured point cloud data, we hypothesize that there is room for improvement in the modeling of the output distribution and explore how this can be achieved using an autoregressive prediction head. Additionally, we release a simulated dataset, COB-3D, which highlights new types of ambiguity that arise in real-world robotics applications, where 3D bounding box prediction has largely been underexplored. We propose methods for leveraging our autoregressive model to make high confidence predictions and meaningful uncertainty measures, achieving strong results on SUN-RGBD, Scannet, KITTI, and our new dataset. ",
    "url": "https://arxiv.org/abs/2210.07424",
    "authors": [
      "YuXuan Liu",
      "Nikhil Mishra",
      "Maximilian Sieb",
      "Yide Shentu",
      "Pieter Abbeel",
      "Xi Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07428",
    "title": "A comparative study of the performance of different search algorithms on  FOON graphs",
    "abstract": "A robot finds it really hard to learn creatively and adapt to the new unseen challenges. This is mainly because of the very limited information it has access or experience towards. Paulius et al. \\cite{b4} presented a way to construct functional graphs which can encapsulate. Sakib et al. \\cite{b1} further expanded FOON objects for robotic cooking. This paper presents a comparative study of Breadth First Search (BFS), Greedy Breadth First search (GBFS) with two heuristic functions, and Iterative Depth First Search (IDFS) and provides the comparison of their performance. ",
    "url": "https://arxiv.org/abs/2210.07428",
    "authors": [
      "Kumar Shashwat"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.07439",
    "title": "Risk-Awareness in Learning Neural Controllers for Temporal Logic  Objectives",
    "abstract": "In this paper, we consider the problem of synthesizing a controller in the presence of uncertainty such that the resulting closed-loop system satisfies certain hard constraints while optimizing certain (soft) performance objectives. We assume that the hard constraints encoding safety or mission-critical task objectives are expressed using Signal Temporal Logic (STL), while performance is quantified using standard cost functions on system trajectories. In order to prioritize the satisfaction of the hard STL constraints, we utilize the framework of control barrier functions (CBFs) and algorithmically obtain CBFs for STL objectives. We assume that the controllers are modeled using neural networks (NNs) and provide an optimization algorithm to learn the optimal parameters for the NN controller that optimize the performance at a user-specified robustness margin for the safety specifications. We use the formalism of risk measures to evaluate the risk incurred by the trade-off between robustness margin of the system and its performance. We demonstrate the efficacy of our approach on well-known difficult examples for nonlinear control such as a quad-rotor and a unicycle, where the mission objectives for each system include hard timing constraints and safety objectives. ",
    "url": "https://arxiv.org/abs/2210.07439",
    "authors": [
      "Navid Hashemi",
      "Xin Qin",
      "Jyotirmoy V. Deshmukh",
      "Georgios Fainekos",
      "Bardh Hoxha",
      "Danil Prokhorov",
      "Tomoya Yamaguchi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)"
    ]
  },
  {
    "id": "arXiv:2210.07441",
    "title": "Characterizing the Influence of Graph Elements",
    "abstract": "Influence function, a method from robust statistics, measures the changes of model parameters or some functions about model parameters concerning the removal or modification of training instances. It is an efficient and useful post-hoc method for studying the interpretability of machine learning models without the need for expensive model re-training. Recently, graph convolution networks (GCNs), which operate on graph data, have attracted a great deal of attention. However, there is no preceding research on the influence functions of GCNs to shed light on the effects of removing training nodes/edges from an input graph. Since the nodes/edges in a graph are interdependent in GCNs, it is challenging to derive influence functions for GCNs. To fill this gap, we started with the simple graph convolution (SGC) model that operates on an attributed graph and formulated an influence function to approximate the changes in model parameters when a node or an edge is removed from an attributed graph. Moreover, we theoretically analyzed the error bound of the estimated influence of removing an edge. We experimentally validated the accuracy and effectiveness of our influence estimation function. In addition, we showed that the influence function of an SGC model could be used to estimate the impact of removing training nodes/edges on the test performance of the SGC without re-training the model. Finally, we demonstrated how to use influence functions to guide the adversarial attacks on GCNs effectively. ",
    "url": "https://arxiv.org/abs/2210.07441",
    "authors": [
      "Zizhang Chen",
      "Peizhao Li",
      "Hongfu Liu",
      "Pengyu Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07443",
    "title": "MEGCF: Multimodal Entity Graph Collaborative Filtering for Personalized  Recommendation",
    "abstract": "In most E-commerce platforms, whether the displayed items trigger the user's interest largely depends on their most eye-catching multimodal content. Consequently, increasing efforts focus on modeling multimodal user preference, and the pressing paradigm is to incorporate complete multimodal deep features of the items into the recommendation module. However, the existing studies ignore the mismatch problem between multimodal feature extraction (MFE) and user interest modeling (UIM). That is, MFE and UIM have different emphases. Specifically, MFE is migrated from and adapted to upstream tasks such as image classification. In addition, it is mainly a content-oriented and non-personalized process, while UIM, with its greater focus on understanding user interaction, is essentially a user-oriented and personalized process. Therefore, the direct incorporation of MFE into UIM for purely user-oriented tasks, tends to introduce a large number of preference-independent multimodal noise and contaminate the embedding representations in UIM. This paper aims at solving the mismatch problem between MFE and UIM, so as to generate high-quality embedding representations and better model multimodal user preferences. Towards this end, we develop a novel model, MEGCF. The UIM of the proposed model captures the semantic correlation between interactions and the features obtained from MFE, thus making a better match between MFE and UIM. More precisely, semantic-rich entities are first extracted from the multimodal data, since they are more relevant to user preferences than other multimodal information. These entities are then integrated into the user-item interaction graph. Afterwards, a symmetric linear Graph Convolution Network (GCN) module is constructed to perform message propagation over the graph, in order to capture both high-order semantic correlation and collaborative filtering signals. ",
    "url": "https://arxiv.org/abs/2210.07443",
    "authors": [
      "Kang Liu",
      "Feng Xue",
      "Dan Guo",
      "Le Wu",
      "Shujie Li",
      "Richang Hong"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.07447",
    "title": "Multilingual Word Sense Disambiguation with Unified Sense Representation",
    "abstract": "As a key natural language processing (NLP) task, word sense disambiguation (WSD) evaluates how well NLP models can understand the lexical semantics of words under specific contexts. Benefited from the large-scale annotation, current WSD systems have achieved impressive performances in English by combining supervised learning with lexical knowledge. However, such success is hard to be replicated in other languages, where we only have limited annotations.In this paper, based on the multilingual lexicon BabelNet describing the same set of concepts across languages, we propose building knowledge and supervised-based Multilingual Word Sense Disambiguation (MWSD) systems. We build unified sense representations for multiple languages and address the annotation scarcity problem for MWSD by transferring annotations from rich-sourced languages to poorer ones. With the unified sense representations, annotations from multiple languages can be jointly trained to benefit the MWSD tasks. Evaluations of SemEval-13 and SemEval-15 datasets demonstrate the effectiveness of our methodology. ",
    "url": "https://arxiv.org/abs/2210.07447",
    "authors": [
      "Ying Su",
      "Hongming Zhang",
      "Yangqiu Song",
      "Tong Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.07449",
    "title": "G2A2: An Automated Graph Generator with Attributes and Anomalies",
    "abstract": "Many data-mining applications use dynamic attributed graphs to represent relational information; but due to security and privacy concerns, there is a dearth of available datasets that can be represented as dynamic attributed graphs. Even when such datasets are available, they do not have ground truth that can be used to train deep-learning models. Thus, we present G2A2, an automated graph generator with attributes and anomalies, which encompasses (1) probabilistic models to generate a dynamic bipartite graph, representing time-evolving connections between two independent sets of entities, (2) realistic injection of anomalies using a novel algorithm that captures the general properties of graph anomalies across domains, and (3) a deep generative model to produce realistic attributes, learned from an existing real-world dataset. Using the maximum mean discrepancy (MMD) metric to evaluate the realism of a G2A2-generated graph against three real-world graphs, G2A2 outperforms Kronecker graph generation by reducing the MMD distance by up to six-fold (6x). ",
    "url": "https://arxiv.org/abs/2210.07449",
    "authors": [
      "Saikat Dey",
      "Sonal Jha",
      "Wu-chun Feng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.07450",
    "title": "ExAug: Robot-Conditioned Navigation Policies via Geometric Experience  Augmentation",
    "abstract": "Machine learning techniques rely on large and diverse datasets for generalization. Computer vision, natural language processing, and other applications can often reuse public datasets to train many different models. However, due to differences in physical configurations, it is challenging to leverage public datasets for training robotic control policies on new robot platforms or for new tasks. In this work, we propose a novel framework, ExAug to augment the experiences of different robot platforms from multiple datasets in diverse environments. ExAug leverages a simple principle: by extracting 3D information in the form of a point cloud, we can create much more complex and structured augmentations, utilizing both generating synthetic images and geometric-aware penalization that would have been suitable in the same situation for a different robot, with different size, turning radius, and camera placement. The trained policy is evaluated on two new robot platforms with three different cameras in indoor and outdoor environments with obstacles. ",
    "url": "https://arxiv.org/abs/2210.07450",
    "authors": [
      "Noriaki Hirose",
      "Dhruv Shah",
      "Ajay Sridhar",
      "Sergey Levine"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07451",
    "title": "Neural Network Compression by Joint Sparsity Promotion and Redundancy  Reduction",
    "abstract": "Compression of convolutional neural network models has recently been dominated by pruning approaches. A class of previous works focuses solely on pruning the unimportant filters to achieve network compression. Another important direction is the design of sparsity-inducing constraints which has also been explored in isolation. This paper presents a novel training scheme based on composite constraints that prune redundant filters and minimize their effect on overall network learning via sparsity promotion. Also, as opposed to prior works that employ pseudo-norm-based sparsity-inducing constraints, we propose a sparse scheme based on gradient counting in our framework. Our tests on several pixel-wise segmentation benchmarks show that the number of neurons and the memory footprint of networks in the test phase are significantly reduced without affecting performance. MobileNetV3 and UNet, two well-known architectures, are used to test the proposed scheme. Our network compression method not only results in reduced parameters but also achieves improved performance compared to MobileNetv3, which is an already optimized architecture. ",
    "url": "https://arxiv.org/abs/2210.07451",
    "authors": [
      "Tariq M. Khan",
      "Syed S. Naqvi",
      "Antonio Robles-Kelly",
      "Erik Meijering"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07453",
    "title": "Using Graph Algorithms to Pretrain Graph Completion Transformers",
    "abstract": "Recent work on Graph Neural Networks has demonstrated that self-supervised pretraining can further enhance performance on downstream graph, link, and node classification tasks. However, the efficacy of pretraining tasks has not been fully investigated for downstream large knowledge graph completion tasks. Using a contextualized knowledge graph embedding approach, we investigate five different pretraining signals, constructed using several graph algorithms and no external data, as well as their combination. We leverage the versatility of our Transformer-based model to explore graph structure generation pretraining tasks, typically inapplicable to most graph embedding methods. We further propose a new path-finding algorithm guided by information gain and find that it is the best-performing pretraining task across three downstream knowledge graph completion datasets. In a multitask setting that combines all pretraining tasks, our method surpasses some of the latest and strong performing knowledge graph embedding methods on all metrics for FB15K-237, on MRR and Hit@1 for WN18RR and on MRR and hit@10 for JF17K (a knowledge hypergraph dataset). ",
    "url": "https://arxiv.org/abs/2210.07453",
    "authors": [
      "Jonathan Pilault",
      "Michael Galkin",
      "Bahare Fatemi",
      "Perouz Taslakian",
      "David Vasquez",
      "Christopher Pal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07454",
    "title": "Communication-Efficient Adam-Type Algorithms for Distributed Data Mining",
    "abstract": "Distributed data mining is an emerging research topic to effectively and efficiently address hard data mining tasks using big data, which are partitioned and computed on different worker nodes, instead of one centralized server. Nevertheless, distributed learning methods often suffer from the communication bottleneck when the network bandwidth is limited or the size of model is large. To solve this critical issue, many gradient compression methods have been proposed recently to reduce the communication cost for multiple optimization algorithms. However, the current applications of gradient compression to adaptive gradient method, which is widely adopted because of its excellent performance to train DNNs, do not achieve the same ideal compression rate or convergence rate as Sketched-SGD. To address this limitation, in this paper, we propose a class of novel distributed Adam-type algorithms (\\emph{i.e.}, SketchedAMSGrad) utilizing sketching, which is a promising compression technique that reduces the communication cost from $O(d)$ to $O(\\log(d))$ where $d$ is the parameter dimension. In our theoretical analysis, we prove that our new algorithm achieves a fast convergence rate of $O(\\frac{1}{\\sqrt{nT}} + \\frac{1}{(k/d)^2 T})$ with the communication cost of $O(k \\log(d))$ at each iteration. Compared with single-machine AMSGrad, our algorithm can achieve the linear speedup with respect to the number of workers $n$. The experimental results on training various DNNs in distributed paradigm validate the efficiency of our algorithms. ",
    "url": "https://arxiv.org/abs/2210.07454",
    "authors": [
      "Wenhan Xian",
      "Feihu Huang",
      "Heng Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.07472",
    "title": "Robust Candidate Generation for Entity Linking on Short Social Media  Texts",
    "abstract": "Entity Linking (EL) is the gateway into Knowledge Bases. Recent advances in EL utilize dense retrieval approaches for Candidate Generation, which addresses some of the shortcomings of the Lookup based approach of matching NER mentions against pre-computed dictionaries. In this work, we show that in the domain of Tweets, such methods suffer as users often include informal spelling, limited context, and lack of specificity, among other issues. We investigate these challenges on a large and recent Tweets benchmark for EL, empirically evaluate lookup and dense retrieval approaches, and demonstrate a hybrid solution using long contextual representation from Wikipedia is necessary to achieve considerable gains over previous work, achieving 0.93 recall. ",
    "url": "https://arxiv.org/abs/2210.07472",
    "authors": [
      "Liam Hebert",
      "Raheleh Makki",
      "Shubhanshu Mishra",
      "Hamidreza Saghir",
      "Anusha Kamath",
      "Yuval Merhav"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07480",
    "title": "Real-time computational powered landing guidance using convex  optimization and neural networks",
    "abstract": "Computational guidance is an emerging and accelerating trend in aerospace guidance and control. Combining machine learning and convex optimization, this paper presents a real-time computational guidance method for the 6-degrees-of-freedom powered landing guidance problem. The powered landing guidance problem is formulated as an optimal control problem, which is then transformed into a convex optimization problem. Instead of brutally using the neural networks as the controller, we use neural networks to improve the state-of-the-art sequential convex programming (SCP) algorithm. Based on the deep neural network, an initial trajectory generator is designed to provide a satisfactory initial guess for the SCP algorithm. Benefitting from designing the initial trajectory generator as a sequence model predictor, the proposed data-driven SCP architecture is capable of improving the performance of any state-of-the-art SCP algorithm in various applications, not just powered landing guidance. The simulation results show that the proposed method can precisely guide the vehicle to the landing site. Moreover, through Monte Carlo tests, the proposed method can averagely save 40.8% of the computation time compared with the SCP method, while ensuring higher terminal states accuracy. The proposed computational guidance scheme is suitable for real-time applications. ",
    "url": "https://arxiv.org/abs/2210.07480",
    "authors": [
      "Zhipeng Shen",
      "Shiyu Zhou",
      "Jianglong Yu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.07482",
    "title": "Cargo Ecosystem Dependency-Vulnerability Knowledge Graph Construction  and Vulnerability Propagation Study",
    "abstract": "Currently, little is known about the structure of the Cargo ecosystem and the potential for vulnerability propagation. Many empirical studies generalize third-party dependency governance strategies from a single software ecosystem to other ecosystems but ignore the differences in the technical structures of different software ecosystems, making it difficult to directly generalize security governance strategies from other ecosystems to the Cargo ecosystem. To fill the gap in this area, this paper constructs a knowledge graph of dependency vulnerabilities for the Cargo ecosystem using techniques related to knowledge graphs to address this challenge. This paper is the first large-scale empirical study in a related research area to address vulnerability propagation in the Cargo ecosystem. This paper proposes a dependency-vulnerability knowledge graph parsing algorithm to determine the vulnerability propagation path and propagation range and empirically studies the characteristics of vulnerabilities in the Cargo ecosystem, the propagation range, and the factors that cause vulnerability propagation. Our research has found that the Cargo ecosystem's security vulnerabilities are primarily memory-related. 18% of the libraries affected by the vulnerability is still affected by the vulnerability in the latest version of the library. The number of versions affected by the propagation of the vulnerabilities is 19.78% in the entire Cargo ecosystem. This paper looks at the characteristics and propagation factors triggering vulnerabilities in the Cargo ecosystem. It provides some practical resolution strategies for administrators of the Cargo community, developers who use Cargo to manage third-party libraries, and library owners. This paper provides new ideas for improving the overall security of the Cargo ecosystem. ",
    "url": "https://arxiv.org/abs/2210.07482",
    "authors": [
      "Peiyang Jia",
      "Chengwei Liu",
      "Hongyu Sun",
      "Chengyi Sun",
      "Mianxue Gu",
      "Yang Liu",
      "Yuqing Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.07485",
    "title": "Holistic Sentence Embeddings for Better Out-of-Distribution Detection",
    "abstract": "Detecting out-of-distribution (OOD) instances is significant for the safe deployment of NLP models. Among recent textual OOD detection works based on pretrained language models (PLMs), distance-based methods have shown superior performance. However, they estimate sample distance scores in the last-layer CLS embedding space and thus do not make full use of linguistic information underlying in PLMs. To address the issue, we propose to boost OOD detection by deriving more holistic sentence embeddings. On the basis of the observations that token averaging and layer combination contribute to improving OOD detection, we propose a simple embedding approach named Avg-Avg, which averages all token representations from each intermediate layer as the sentence embedding and significantly surpasses the state-of-the-art on a comprehensive suite of benchmarks by a 9.33% FAR95 margin. Furthermore, our analysis demonstrates that it indeed helps preserve general linguistic knowledge in fine-tuned PLMs and substantially benefits detecting background shifts. The simple yet effective embedding method can be applied to fine-tuned PLMs with negligible extra costs, providing a free gain in OOD detection. Our code is available at https://github.com/lancopku/Avg-Avg. ",
    "url": "https://arxiv.org/abs/2210.07485",
    "authors": [
      "Sishuo Chen",
      "Xiaohan Bi",
      "Rundong Gao",
      "Xu Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.07488",
    "title": "MetaFill: Text Infilling for Meta-Path Generation on Heterogeneous  Information Networks",
    "abstract": "Heterogeneous Information Network (HIN) is essential to study complicated networks containing multiple edge types and node types. Meta-path, a sequence of node types and edge types, is the core technique to embed HINs. Since manually curating meta-paths is time-consuming, there is a pressing need to develop automated meta-path generation approaches. Existing meta-path generation approaches cannot fully exploit the rich textual information in HINs, such as node names and edge type names. To address this problem, we propose MetaFill, a text-infilling-based approach for meta-path generation. The key idea of MetaFill is to formulate meta-path identification problem as a word sequence infilling problem, which can be advanced by Pretrained Language Models (PLMs). We observed the superior performance of MetaFill against existing meta-path generation methods and graph embedding methods that do not leverage meta-paths in both link prediction and node classification on two real-world HIN datasets. We further demonstrated how MetaFill can accurately classify edges in the zero-shot setting, where existing approaches cannot generate any meta-paths. MetaFill exploits PLMs to generate meta-paths for graph embedding, opening up new avenues for language model applications in graph analysis. ",
    "url": "https://arxiv.org/abs/2210.07488",
    "authors": [
      "Zequn Liu",
      "Kefei Duan",
      "Junwei Yang",
      "Hanwen Xu",
      "Ming Zhang",
      "Sheng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.07494",
    "title": "A Comprehensive Study on Large-Scale Graph Training: Benchmarking and  Rethinking",
    "abstract": "Large-scale graph training is a notoriously challenging problem for graph neural networks (GNNs). Due to the nature of evolving graph structures into the training process, vanilla GNNs usually fail to scale up, limited by the GPU memory space. Up to now, though numerous scalable GNN architectures have been proposed, we still lack a comprehensive survey and fair benchmark of this reservoir to find the rationale for designing scalable GNNs. To this end, we first systematically formulate the representative methods of large-scale graph training into several branches and further establish a fair and consistent benchmark for them by a greedy hyperparameter searching. In addition, regarding efficiency, we theoretically evaluate the time and space complexity of various branches and empirically compare them w.r.t GPU memory usage, throughput, and convergence. Furthermore, We analyze the pros and cons for various branches of scalable GNNs and then present a new ensembling training manner, named EnGCN, to address the existing issues. Remarkably, our proposed method has achieved new state-of-the-art (SOTA) performance on large-scale datasets. Our code is available at https://github.com/VITA-Group/Large_Scale_GCN_Benchmarking. ",
    "url": "https://arxiv.org/abs/2210.07494",
    "authors": [
      "Keyu Duan",
      "Zirui Liu",
      "Peihao Wang",
      "Wenqing Zheng",
      "Kaixiong Zhou",
      "Tianlong Chen",
      "Xia Hu",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.07508",
    "title": "Hierarchical Diffusion Models for Singing Voice Neural Vocoder",
    "abstract": "Recent progress in deep generative models has improved the quality of neural vocoders in speech domain. However, it remains challenging to generate high-quality singing voice due to a wider variety of musical expressions in pitch, loudness, and pronunciations. In this work, we propose a hierarchical diffusion model for singing voice neural vocoders. The proposed method consists of multiple diffusion models operating in different sampling rates; the model at the lowest sampling rate focuses on generating accurate low frequency components such as pitch, and other models progressively generate the waveform at the higher sampling rates based on the data at the lower sampling rate and acoustic features. Experimental results show that the proposed method produces high-quality singing voice for multiple singers, outperforming state-of-the-art neural vocoders with a similar range of computational costs. ",
    "url": "https://arxiv.org/abs/2210.07508",
    "authors": [
      "Naoya Takahashi",
      "Mayank Kumar",
      "Singh",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.07518",
    "title": "Counterfactual Neural Temporal Point Process for Estimating Causal  Influence of Misinformation on Social Media",
    "abstract": "Recent years have witnessed the rise of misinformation campaigns that spread specific narratives on social media to manipulate public opinions on different areas, such as politics and healthcare. Consequently, an effective and efficient automatic methodology to estimate the influence of the misinformation on user beliefs and activities is needed. However, existing works on misinformation impact estimation either rely on small-scale psychological experiments or can only discover the correlation between user behaviour and misinformation. To address these issues, in this paper, we build up a causal framework that model the causal effect of misinformation from the perspective of temporal point process. To adapt the large-scale data, we design an efficient yet precise way to estimate the Individual Treatment Effect(ITE) via neural temporal point process and gaussian mixture models. Extensive experiments on synthetic dataset verify the effectiveness and efficiency of our model. We further apply our model on a real-world dataset of social media posts and engagements about COVID-19 vaccines. The experimental results indicate that our model recognized identifiable causal effect of misinformation that hurts people's subjective emotions toward the vaccines. ",
    "url": "https://arxiv.org/abs/2210.07518",
    "authors": [
      "Yizhou Zhang",
      "Defu Cao",
      "Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.07519",
    "title": "Can Language Representation Models Think in Bets?",
    "abstract": "In recent years, transformer-based language representation models (LRMs) have achieved state-of-the-art results on difficult natural language understanding problems, such as question answering and text summarization. As these models are integrated into real-world applications, evaluating their ability to make rational decisions is an important research agenda, with practical ramifications. This article investigates LRMs' rational decision-making ability through a carefully designed set of decision-making benchmarks and experiments. Inspired by classic work in cognitive science, we model the decision-making problem as a bet. We then investigate an LRM's ability to choose outcomes that have optimal, or at minimum, positive expected gain. Through a robust body of experiments on four established LRMs, we show that a model is only able to `think in bets' if it is first fine-tuned on bet questions with an identical structure. Modifying the bet question's structure, while still retaining its fundamental characteristics, decreases an LRM's performance by more than 25\\%, on average, although absolute performance remains well above random. LRMs are also found to be more rational when selecting outcomes with non-negative expected gain, rather than optimal or strictly positive expected gain. Our results suggest that LRMs could potentially be applied to tasks that rely on cognitive decision-making skills, but that more research is necessary before they can robustly make rational decisions. ",
    "url": "https://arxiv.org/abs/2210.07519",
    "authors": [
      "Zhisheng Tang",
      "Mayank Kejriwal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.07535",
    "title": "AutoMoE: Neural Architecture Search for Efficient Sparsely Activated  Transformers",
    "abstract": "Neural architecture search (NAS) has demonstrated promising results on identifying efficient Transformer architectures which outperform manually designed ones for natural language tasks like neural machine translation (NMT). Existing NAS methods operate on a space of dense architectures, where all of the sub-architecture weights are activated for every input. Motivated by the recent advances in sparsely activated models like the Mixture-of-Experts (MoE) model, we introduce sparse architectures with conditional computation into the NAS search space. Given this expressive search space which subsumes prior densely activated architectures, we develop a new framework AutoMoE to search for efficient sparsely activated sub-Transformers. AutoMoE-generated sparse models obtain (i) 3x FLOPs reduction over manually designed dense Transformers and (ii) 23% FLOPs reduction over state-of-the-art NAS-generated dense sub-Transformers with parity in BLEU score on benchmark datasets for NMT. AutoMoE consists of three training phases: (a) Heterogeneous search space design with dense and sparsely activated Transformer modules (e.g., how many experts? where to place them? what should be their sizes?); (b) SuperNet training that jointly trains several subnetworks sampled from the large search space by weight-sharing; (c) Evolutionary search for the architecture with the optimal trade-off between task performance and computational constraint like FLOPs and latency. AutoMoE code, data and trained models are available at https://github.com/microsoft/AutoMoE. ",
    "url": "https://arxiv.org/abs/2210.07535",
    "authors": [
      "Ganesh Jawahar",
      "Subhabrata Mukherjee",
      "Xiaodong Liu",
      "Young Jin Kim",
      "Muhammad Abdul-Mageed",
      "Laks V. S. Lakshmanan",
      "Ahmed Hassan Awadallah",
      "Sebastien Bubeck",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07539",
    "title": "Superpixel Perception Graph Neural Network for Intelligent Defect  Detection",
    "abstract": "Aero-engine is the core component of aircraft and other spacecraft. The high-speed rotating blades provide power by sucking in air and fully combusting, and various defects will inevitably occur, threatening the operation safety of aero-engine. Therefore, regular inspections are essential for such a complex system. However, existing traditional technology which is borescope inspection is labor-intensive, time-consuming, and experience-dependent. To endow this technology with intelligence, a novel superpixel perception graph neural network (SPGNN) is proposed by utilizing a multi-stage graph convolutional network (MSGCN) for feature extraction and superpixel perception region proposal network (SPRPN) for region proposal. First, to capture complex and irregular textures, the images are transformed into a series of patches, to obtain their graph representations. Then, MSGCN composed of several GCN blocks extracts graph structure features and performs graph information processing at graph level. Last but not least, the SPRPN is proposed to generate perceptual bounding boxes by fusing graph representation features and superpixel perception features. Therefore, the proposed SPGNN always implements feature extraction and information transmission at the graph level in the whole SPGNN pipeline, and SPRPN and MSGNN mutually benefit from each other. To verify the effectiveness of SPGNN, we meticulously construct a simulated blade dataset with 3000 images. A public aluminum dataset is also used to validate the performances of different methods. The experimental results demonstrate that the proposed SPGNN has superior performance compared with the state-of-the-art methods. The source code will be available at https://github.com/githbshang/SPGNN. ",
    "url": "https://arxiv.org/abs/2210.07539",
    "authors": [
      "Hongbing Shang",
      "Qixiu Yang",
      "Chuang Sun",
      "Xuefeng Chen",
      "Ruqiang Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.07540",
    "title": "When Adversarial Training Meets Vision Transformers: Recipes from  Training to Architecture",
    "abstract": "Vision Transformers (ViTs) have recently achieved competitive performance in broad vision tasks. Unfortunately, on popular threat models, naturally trained ViTs are shown to provide no more adversarial robustness than convolutional neural networks (CNNs). Adversarial training is still required for ViTs to defend against such adversarial attacks. In this paper, we provide the first and comprehensive study on the adversarial training recipe of ViTs via extensive evaluation of various training techniques across benchmark datasets. We find that pre-training and SGD optimizer are necessary for ViTs' adversarial training. Further considering ViT as a new type of model architecture, we investigate its adversarial robustness from the perspective of its unique architectural components. We find, when randomly masking gradients from some attention blocks or masking perturbations on some patches during adversarial training, the adversarial robustness of ViTs can be remarkably improved, which may potentially open up a line of work to explore the architectural information inside the newly designed models like ViTs. Our code is available at https://github.com/mo666666/When-Adversarial-Training-Meets-Vision-Transformers. ",
    "url": "https://arxiv.org/abs/2210.07540",
    "authors": [
      "Yichuan Mo",
      "Dongxian Wu",
      "Yifei Wang",
      "Yiwen Guo",
      "Yisen Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07547",
    "title": "Kernel-Whitening: Overcome Dataset Bias with Isotropic Sentence  Embedding",
    "abstract": "Dataset bias has attracted increasing attention recently for its detrimental effect on the generalization ability of fine-tuned models. The current mainstream solution is designing an additional shallow model to pre-identify biased instances. However, such two-stage methods scale up the computational complexity of training process and obstruct valid feature information while mitigating bias. To address this issue, we utilize the representation normalization method which aims at disentangling the correlations between features of encoded sentences. We find it also promising in eliminating the bias problem by providing isotropic data distribution. We further propose Kernel-Whitening, a Nystrom kernel approximation method to achieve more thorough debiasing on nonlinear spurious correlations. Our framework is end-to-end with similar time consumption to fine-tuning. Experiments show that Kernel-Whitening significantly improves the performance of BERT on out-of-distribution datasets while maintaining in-distribution accuracy. ",
    "url": "https://arxiv.org/abs/2210.07547",
    "authors": [
      "Songyang Gao",
      "Shihan Dou",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07548",
    "title": "Reconstructed Student-Teacher and Discriminative Networks for Anomaly  Detection",
    "abstract": "Anomaly detection is an important problem in computer vision; however, the scarcity of anomalous samples makes this task difficult. Thus, recent anomaly detection methods have used only normal images with no abnormal areas for training. In this work, a powerful anomaly detection method is proposed based on student-teacher feature pyramid matching (STPM), which consists of a student and teacher network. Generative models are another approach to anomaly detection. They reconstruct normal images from an input and compute the difference between the predicted normal and the input. Unfortunately, STPM does not have the ability to generate normal images. To improve the accuracy of STPM, this work uses a student network, as in generative models, to reconstruct normal features. This improves the accuracy; however, the anomaly maps for normal images are not clean because STPM does not use anomaly images for training, which decreases the accuracy of the image-level anomaly detection. To further improve accuracy, a discriminative network trained with pseudo-anomalies from anomaly maps is used in our method, which consists of two pairs of student-teacher networks and a discriminative network. The method displayed high accuracy on the MVTec anomaly detection dataset. ",
    "url": "https://arxiv.org/abs/2210.07548",
    "authors": [
      "Shinji Yamada",
      "Satoshi Kamiya",
      "Kazuhiro Hotta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07562",
    "title": "TokenMixup: Efficient Attention-guided Token-level Data Augmentation for  Transformers",
    "abstract": "Mixup is a commonly adopted data augmentation technique for image classification. Recent advances in mixup methods primarily focus on mixing based on saliency. However, many saliency detectors require intense computation and are especially burdensome for parameter-heavy transformer models. To this end, we propose TokenMixup, an efficient attention-guided token-level data augmentation method that aims to maximize the saliency of a mixed set of tokens. TokenMixup provides x15 faster saliency-aware data augmentation compared to gradient-based methods. Moreover, we introduce a variant of TokenMixup which mixes tokens within a single instance, thereby enabling multi-scale feature augmentation. Experiments show that our methods significantly improve the baseline models' performance on CIFAR and ImageNet-1K, while being more efficient than previous methods. We also reach state-of-the-art performance on CIFAR-100 among from-scratch transformer models. Code is available at https://github.com/mlvlab/TokenMixup. ",
    "url": "https://arxiv.org/abs/2210.07562",
    "authors": [
      "Hyeong Kyu Choi",
      "Joonmyung Choi",
      "Hyunwoo J. Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07570",
    "title": "MICO: A Multi-alternative Contrastive Learning Framework for Commonsense  Knowledge Representation",
    "abstract": "Commonsense reasoning tasks such as commonsense knowledge graph completion and commonsense question answering require powerful representation learning. In this paper, we propose to learn commonsense knowledge representation by MICO, a Multi-alternative contrastve learning framework on COmmonsense knowledge graphs (MICO). MICO generates the commonsense knowledge representation by contextual interaction between entity nodes and relations with multi-alternative contrastive learning. In MICO, the head and tail entities in an $(h,r,t)$ knowledge triple are converted to two relation-aware sequence pairs (a premise and an alternative) in the form of natural language. Semantic representations generated by MICO can benefit the following two tasks by simply comparing the distance score between the representations: 1) zero-shot commonsense question answering task; 2) inductive commonsense knowledge graph completion task. Extensive experiments show the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2210.07570",
    "authors": [
      "Ying Su",
      "Zihao Wang",
      "Tianqing Fang",
      "Hongming Zhang",
      "Yangqiu Song",
      "Tong Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.07577",
    "title": "MonoDVPS: A Self-Supervised Monocular Depth Estimation Approach to  Depth-aware Video Panoptic Segmentation",
    "abstract": "Depth-aware video panoptic segmentation tackles the inverse projection problem of restoring panoptic 3D point clouds from video sequences, where the 3D points are augmented with semantic classes and temporally consistent instance identifiers. We propose a novel solution with a multi-task network that performs monocular depth estimation and video panoptic segmentation. Since acquiring ground truth labels for both depth and image segmentation has a relatively large cost, we leverage the power of unlabeled video sequences with self-supervised monocular depth estimation and semi-supervised learning from pseudo-labels for video panoptic segmentation. To further improve the depth prediction, we introduce panoptic-guided depth losses and a novel panoptic masking scheme for moving objects to avoid corrupting the training signal. Extensive experiments on the Cityscapes-DVPS and SemKITTI-DVPS datasets demonstrate that our model with the proposed improvements achieves competitive results and fast inference speed. ",
    "url": "https://arxiv.org/abs/2210.07577",
    "authors": [
      "Andra Petrovai",
      "Sergiu Nedevschi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07588",
    "title": "Distributed Distributionally Robust Optimization with Non-Convex  Objectives",
    "abstract": "Distributionally Robust Optimization (DRO), which aims to find an optimal decision that minimizes the worst case cost over the ambiguity set of probability distribution, has been widely applied in diverse applications, e.g., network behavior analysis, risk management, etc. However, existing DRO techniques face three key challenges: 1) how to deal with the asynchronous updating in a distributed environment; 2) how to leverage the prior distribution effectively; 3) how to properly adjust the degree of robustness according to different scenarios. To this end, we propose an asynchronous distributed algorithm, named Asynchronous Single-looP alternatIve gRadient projEction (ASPIRE) algorithm with the itErative Active SEt method (EASE) to tackle the distributed distributionally robust optimization (DDRO) problem. Furthermore, a new uncertainty set, i.e., constrained D-norm uncertainty set, is developed to effectively leverage the prior distribution and flexibly control the degree of robustness. Finally, our theoretical analysis elucidates that the proposed algorithm is guaranteed to converge and the iteration complexity is also analyzed. Extensive empirical studies on real-world datasets demonstrate that the proposed method can not only achieve fast convergence, and remain robust against data heterogeneity as well as malicious attacks, but also tradeoff robustness with performance. ",
    "url": "https://arxiv.org/abs/2210.07588",
    "authors": [
      "Yang Jiao",
      "Kai Yang",
      "Dongjin Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.07600",
    "title": "Identification of Common Trends in Political Speech in Social Media  using Sentiment Analysis",
    "abstract": "Social Media have been extensively used for commercial and political communication, besides their initial scope of providing an easy-to-use outlet to produce and consume user-generated content. Besides being a popular medium, Social Media have definitely changed the way we express ourselves or where we look for emerging news and commentary, especially during troubled times. In this paper, we examine a corpus assembled from the Twitter accounts of politicians in the United States and annotated with respect to their audience and the sentiment they convey with each post. Our purpose is to examine whether there are stylistic differences among representatives of different political ideologies, directed to different audiences or with dissimilar agendas. Our findings verify existing knowledge from conventional written communication and can be used to evaluate the quality and depth of political expression and dialogue, especially during the period leading to an election. ",
    "url": "https://arxiv.org/abs/2210.07600",
    "authors": [
      "Kostas Karpouzis",
      "Stavros Kaperonis",
      "Yannis Skarpelos"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.07601",
    "title": "MCTNet: A Multi-Scale CNN-Transformer Network for Change Detection in  Optical Remote Sensing Images",
    "abstract": "For the task of change detection (CD) in remote sensing images, deep convolution neural networks (CNNs)-based methods have recently aggregated transformer modules to improve the capability of global feature extraction. However, they suffer degraded CD performance on small changed areas due to the simple single-scale integration of deep CNNs and transformer modules. To address this issue, we propose a hybrid network based on multi-scale CNN-transformer structure, termed MCTNet, where the multi-scale global and local information are exploited to enhance the robustness of the CD performance on changed areas with different sizes. Especially, we design the ConvTrans block to adaptively aggregate global features from transformer modules and local features from CNN layers, which provides abundant global-local features with different scales. Experimental results demonstrate that our MCTNet achieves better detection performance than existing state-of-the-art CD methods. ",
    "url": "https://arxiv.org/abs/2210.07601",
    "authors": [
      "Weiming Li",
      "Lihui Xue",
      "Xueqian Wang",
      "Gang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07606",
    "title": "Revisiting Heterophily For Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) extend basic Neural Networks (NNs) by using graph structures based on the relational inductive bias (homophily assumption). While GNNs have been commonly believed to outperform NNs in real-world tasks, recent work has identified a non-trivial set of datasets where their performance compared to NNs is not satisfactory. Heterophily has been considered the main cause of this empirical observation and numerous works have been put forward to address it. In this paper, we first revisit the widely used homophily metrics and point out that their consideration of only graph-label consistency is a shortcoming. Then, we study heterophily from the perspective of post-aggregation node similarity and define new homophily metrics, which are potentially advantageous compared to existing ones. Based on this investigation, we prove that some harmful cases of heterophily can be effectively addressed by local diversification operation. Then, we propose the Adaptive Channel Mixing (ACM), a framework to adaptively exploit aggregation, diversification and identity channels node-wisely to extract richer localized information for diverse node heterophily situations. ACM is more powerful than the commonly used uni-channel framework for node classification tasks on heterophilic graphs and is easy to be implemented in baseline GNN layers. When evaluated on 10 benchmark node classification tasks, ACM-augmented baselines consistently achieve significant performance gain, exceeding state-of-the-art GNNs on most tasks without incurring significant computational burden. ",
    "url": "https://arxiv.org/abs/2210.07606",
    "authors": [
      "Sitao Luan",
      "Chenqing Hua",
      "Qincheng Lu",
      "Jiaqi Zhu",
      "Mingde Zhao",
      "Shuyuan Zhang",
      "Xiao-Wen Chang",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.07621",
    "title": "Dense-ATOMIC: Construction of Densely-connected and Multi-hop  Commonsense Knowledge Graph upon ATOMIC",
    "abstract": "ATOMIC is a large-scale commonsense knowledge graph (CSKG) containing everyday if-then knowledge triplets, i.e., {head event, relation, tail event}. The one-hop annotation manner made ATOMIC a set of independent bipartite graphs, which ignored the numerous missing links between events in different bipartite graphs and consequently caused shortcomings in knowledge coverage and multi-hop reasoning. To address these issues, we propose a CSKG completion approach by training a relation prediction model based on a set of existing triplets, and infer the missing links on ATOMIC. On this basis, we construct Dense-ATOMIC, a densely-connected and multi-hop commonsense knowledge graph. The experimental results on an annotated dense subgraph demonstrate the effectiveness of our CSKG completion approach upon ATOMIC. The evaluation on a downstream commonsense reasoning task also proves the advantage of Dense-ATOMIC against conventional ATOMIC. ",
    "url": "https://arxiv.org/abs/2210.07621",
    "authors": [
      "Xiangqing Shen",
      "Siwei Wu",
      "Rui Xia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.07626",
    "title": "BERTScore is Unfair: On Social Bias in Language Model-Based Metrics for  Text Generation",
    "abstract": "Automatic evaluation metrics are crucial to the development of generative systems. In recent years, pre-trained language model (PLM) based metrics, such as BERTScore, have been commonly adopted in various generation tasks. However, it has been demonstrated that PLMs encode a range of stereotypical societal biases, leading to a concern on the fairness of PLMs as metrics. To that end, this work presents the first systematic study on the social bias in PLM-based metrics. We demonstrate that popular PLM-based metrics exhibit significantly higher social bias than traditional metrics on 6 sensitive attributes, namely race, gender, religion, physical appearance, age, and socioeconomic status. In-depth analysis suggests that choosing paradigms (matching, regression, or generation) of the metric has a greater impact on fairness than choosing PLMs. In addition, we develop debiasing adapters that are injected into PLM layers, mitigating bias in PLM-based metrics while retaining high performance for evaluating text generation. ",
    "url": "https://arxiv.org/abs/2210.07626",
    "authors": [
      "Tianxiang Sun",
      "Junliang He",
      "Xipeng Qiu",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.07632",
    "title": "Stability of Decentralized Queueing Networks Beyond Complete Bipartite  Cases",
    "abstract": "Gaitonde and Tardos recently studied a model of queueing networks where queues compete for servers and re-send returned packets in future rounds. They quantify the amount of additional processing power that guarantees a decentralized system's stability, both when the queues adapt their strategies from round to round using no-regret learning algorithms, and when they are patient and evaluate the utility of a strategy over long periods of time. In this paper, we generalize Gaitonde and Tardos's model and consider scenarios where not all servers can serve all queues (i.e., the underlying graph is an incomplete bipartite graphs) and, further, when packets need to go through more than one layer of servers before their completions (i.e., when the underlying graph is a DAG). For the bipartite case, we obtain bounds comparable to those by Gaitonde and Tardos, with the factor slightly worse in the patient queueing model. For the more general multi-layer systems, we show that straightforward generalizations of the utility function and servers' priority rules in Gaitonde and Tardos's model may lead to unbounded gaps between centralized and decentralized systems when the queues use no regret strategies. We define a new utility and a service priority rule that are aware of the queue lengths, and show that these suffice to restore the bounded gap between centralized and decentralized systems observed in bipartite graphs. ",
    "url": "https://arxiv.org/abs/2210.07632",
    "authors": [
      "Hu Fu",
      "Qun Hu",
      "Jia'nan Lin"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2210.07634",
    "title": "Pareto-aware Neural Architecture Generation for Diverse Computational  Budgets",
    "abstract": "Designing feasible and effective architectures under diverse computational budgets, incurred by different applications/devices, is essential for deploying deep models in real-world applications. To achieve this goal, existing methods often perform an independent architecture search process for each target budget, which is very inefficient yet unnecessary. More critically, these independent search processes cannot share their learned knowledge (i.e., the distribution of good architectures) with each other and thus often result in limited search results. To address these issues, we propose a Pareto-aware Neural Architecture Generator (PNAG) which only needs to be trained once and dynamically produces the Pareto optimal architecture for any given budget via inference. To train our PNAG, we learn the whole Pareto frontier by jointly finding multiple Pareto optimal architectures under diverse budgets. Such a joint search algorithm not only greatly reduces the overall search cost but also improves the search results. Extensive experiments on three hardware platforms (i.e., mobile device, CPU, and GPU) show the superiority of our method over existing methods. ",
    "url": "https://arxiv.org/abs/2210.07634",
    "authors": [
      "Yong Guo",
      "Yaofo Chen",
      "Yin Zheng",
      "Qi Chen",
      "Peilin Zhao",
      "Jian Chen",
      "Junzhou Huang",
      "Mingkui Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07659",
    "title": "Automated dysgraphia detection by deep learning with SensoGrip",
    "abstract": "Dysgraphia, a handwriting learning disability, has a serious negative impact on children's academic results, daily life and overall wellbeing. Early detection of dysgraphia allows for an early start of a targeted intervention. Several studies have investigated dysgraphia detection by machine learning algorithms using a digital tablet. However, these studies deployed classical machine learning algorithms with manual feature extraction and selection as well as binary classification: either dysgraphia or no dysgraphia. In this work, we investigated fine grading of handwriting capabilities by predicting SEMS score (between 0 and 12) with deep learning. Our approach provide accuracy more than 99% and root mean square error lower than one, with automatic instead of manual feature extraction and selection. Furthermore, we used smart pen called SensoGrip, a pen equipped with sensors to capture handwriting dynamics, instead of a tablet, enabling writing evaluation in more realistic scenarios. ",
    "url": "https://arxiv.org/abs/2210.07659",
    "authors": [
      "Mugdim Bublin",
      "Franz Werner",
      "Andrea Kerschbaumer",
      "Gernot Korak",
      "Sebastian Geyer",
      "Lena Rettinger",
      "Erna Schoenthaler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2210.07660",
    "title": "MV-HAN: A Hybrid Attentive Networks based Multi-View Learning Model for  Large-scale Contents Recommendation",
    "abstract": "Industrial recommender systems usually employ multi-source data to improve the recommendation quality, while effectively sharing information between different data sources remain a challenge. In this paper, we introduce a novel Multi-View Approach with Hybrid Attentive Networks (MV-HAN) for contents retrieval at the matching stage of recommender systems. The proposed model enables high-order feature interaction from various input features while effectively transferring knowledge between different types. By employing a well-placed parameters sharing strategy, the MV-HAN substantially improves the retrieval performance in sparse types. The designed MV-HAN inherits the efficiency advantages in the online service from the two-tower model, by mapping users and contents of different types into the same features space. This enables fast retrieval of similar contents with an approximate nearest neighbor algorithm. We conduct offline experiments on several industrial datasets, demonstrating that the proposed MV-HAN significantly outperforms baselines on the content retrieval tasks. Importantly, the MV-HAN is deployed in a real-world matching system. Online A/B test results show that the proposed method can significantly improve the quality of recommendations. ",
    "url": "https://arxiv.org/abs/2210.07660",
    "authors": [
      "Ge Fan",
      "Chaoyun Zhang",
      "Kai Wang",
      "Junyang Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.07663",
    "title": "Pretrained Transformers Do not Always Improve Robustness",
    "abstract": "Pretrained Transformers (PT) have been shown to improve Out of Distribution (OOD) robustness than traditional models such as Bag of Words (BOW), LSTMs, Convolutional Neural Networks (CNN) powered by Word2Vec and Glove embeddings. How does the robustness comparison hold in a real world setting where some part of the dataset can be noisy? Do PT also provide more robust representation than traditional models on exposure to noisy data? We perform a comparative study on 10 models and find an empirical evidence that PT provide less robust representation than traditional models on exposure to noisy data. We investigate further and augment PT with an adversarial filtering (AF) mechanism that has been shown to improve OOD generalization. However, increase in generalization does not necessarily increase robustness, as we find that noisy data fools the AF method powered by PT. ",
    "url": "https://arxiv.org/abs/2210.07663",
    "authors": [
      "Swaroop Mishra",
      "Bhavdeep Singh Sachdeva",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07697",
    "title": "Multi-Task Learning based Video Anomaly Detection with Attention",
    "abstract": "Multi-task learning based video anomaly detection methods combine multiple proxy tasks in different branches to detect video anomalies in different situations. Most existing methods either do not combine complementary tasks to effectively cover all motion patterns, or the class of the objects is not explicitly considered. To address the aforementioned shortcomings, we propose a novel multi-task learning based method that combines complementary proxy tasks to better consider the motion and appearance features. We combine the semantic segmentation and future frame prediction tasks in a single branch to learn the object class and consistent motion patterns, and to detect respective anomalies simultaneously. In the second branch, we added several attention mechanisms to detect motion anomalies with attention to object parts, the direction of motion, and the distance of the objects from the camera. Our qualitative results show that the proposed method considers the object class effectively and learns motion with attention to the aforementioned important factors which results in a precise motion modeling and a better motion anomaly detection. Additionally, quantitative results show the superiority of our method compared with state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2210.07697",
    "authors": [
      "Mohammad Baradaran",
      "Robert Bergevin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.07699",
    "title": "s-Club Cluster Vertex Deletion on Interval and Well-Partitioned Chordal  Graphs",
    "abstract": "In this paper, we study the computational complexity of \\textsc{$s$-Club Cluster Vertex Deletion}. Given a graph, \\textsc{$s$-Club Cluster Vertex Deletion ($s$-CVD)} aims to delete the minimum number of vertices from the graph so that each connected component of the resulting graph has a diameter at most $s$. When $s=1$, the corresponding problem is popularly known as \\sloppy \\textsc{Cluster Vertex Deletion (CVD)}. We provide a faster algorithm for \\textsc{$s$-CVD} on \\emph{interval graphs}. For each $s\\geq 1$, we give an $O(n(n+m))$-time algorithm for \\textsc{$s$-CVD} on interval graphs with $n$ vertices and $m$ edges. In the case of $s=1$, our algorithm is a slight improvement over the $O(n^3)$-time algorithm of Cao \\etal (Theor. Comput. Sci., 2018) and for $s \\geq 2$, it significantly improves the state-of-the-art running time $\\left(O\\left(n^4\\right)\\right)$. We also give a polynomial-time algorithm to solve \\textsc{CVD} on \\emph{well-partitioned chordal graphs}, a graph class introduced by Ahn \\etal (\\textsc{WG 2020}) as a tool for narrowing down complexity gaps for problems that are hard on chordal graphs, and easy on split graphs. Our algorithm relies on a characterisation of the optimal solution and on solving polynomially many instances of the \\textsc{Weighted Bipartite Vertex Cover}. This generalises a result of Cao \\etal (Theor. Comput. Sci., 2018) on split graphs. We also show that for any even integer $s\\geq 2$, \\textsc{$s$-CVD} is NP-hard on well-partitioned chordal graphs. ",
    "url": "https://arxiv.org/abs/2210.07699",
    "authors": [
      "Dibyayan Chakraborty",
      "L. Sunil Chandran",
      "Sajith Padinhatteeri",
      "Raji. R. Pillai"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2210.07707",
    "title": "Generative Adversarial Learning for Trusted and Secure Clustering in  Industrial Wireless Sensor Networks",
    "abstract": "Traditional machine learning techniques have been widely used to establish the trust management systems. However, the scale of training dataset can significantly affect the security performances of the systems, while it is a great challenge to detect malicious nodes due to the absence of labeled data regarding novel attacks. To address this issue, this paper presents a generative adversarial network (GAN) based trust management mechanism for Industrial Wireless Sensor Networks (IWSNs). First, type-2 fuzzy logic is adopted to evaluate the reputation of sensor nodes while alleviating the uncertainty problem. Then, trust vectors are collected to train a GAN-based codec structure, which is used for further malicious node detection. Moreover, to avoid normal nodes being isolated from the network permanently due to error detections, a GAN-based trust redemption model is constructed to enhance the resilience of trust management. Based on the latest detection results, a trust model update method is developed to adapt to the dynamic industrial environment. The proposed trust management mechanism is finally applied to secure clustering for reliable and real-time data transmission, and simulation results show that it achieves a high detection rate up to 96%, as well as a low false positive rate below 8%. ",
    "url": "https://arxiv.org/abs/2210.07707",
    "authors": [
      "Liu Yang",
      "Simon X. Yang",
      "Yun Li",
      "Yinzhi Lu",
      "Tan Guo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.07715",
    "title": "Not All Neighbors Are Worth Attending to: Graph Selective Attention  Networks for Semi-supervised Learning",
    "abstract": "Graph attention networks (GATs) are powerful tools for analyzing graph data from various real-world scenarios. To learn representations for downstream tasks, GATs generally attend to all neighbors of the central node when aggregating the features. In this paper, we show that a large portion of the neighbors are irrelevant to the central nodes in many real-world graphs, and can be excluded from neighbor aggregation. Taking the cue, we present Selective Attention (SA) and a series of novel attention mechanisms for graph neural networks (GNNs). SA leverages diverse forms of learnable node-node dissimilarity to acquire the scope of attention for each node, from which irrelevant neighbors are excluded. We further propose Graph selective attention networks (SATs) to learn representations from the highly correlated node features identified and investigated by different SA mechanisms. Lastly, theoretical analysis on the expressive power of the proposed SATs and a comprehensive empirical study of the SATs on challenging real-world datasets against state-of-the-art GNNs are presented to demonstrate the effectiveness of SATs. ",
    "url": "https://arxiv.org/abs/2210.07715",
    "authors": [
      "Tiantian He",
      "Haicang Zhou",
      "Yew-Soon Ong",
      "Gao Cong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07719",
    "title": "A Lightweight Moving Target Defense Framework for Multi-purpose Malware  Affecting IoT Devices",
    "abstract": "Malware affecting Internet of Things (IoT) devices is rapidly growing due to the relevance of this paradigm in real-world scenarios. Specialized literature has also detected a trend towards multi-purpose malware able to execute different malicious actions such as remote control, data leakage, encryption, or code hiding, among others. Protecting IoT devices against this kind of malware is challenging due to their well-known vulnerabilities and limitation in terms of CPU, memory, and storage. To improve it, the moving target defense (MTD) paradigm was proposed a decade ago and has shown promising results, but there is a lack of IoT MTD solutions dealing with multi-purpose malware. Thus, this work proposes four MTD mechanisms changing IoT devices' network, data, and runtime environment to mitigate multi-purpose malware. Furthermore, it presents a lightweight and IoT-oriented MTD framework to decide what, when, and how the MTD mechanisms are deployed. Finally, the efficiency and effectiveness of the framework and MTD mechanisms are evaluated in a real-world scenario with one IoT spectrum sensor affected by multi-purpose malware. ",
    "url": "https://arxiv.org/abs/2210.07719",
    "authors": [
      "Jan von der Assen",
      "Alberto Huertas Celdr\u00e1n",
      "Pedro Miguel S\u00e1nchez S\u00e1nchez",
      "Jordan Cede\u00f1o",
      "G\u00e9r\u00f4me Bovet",
      "Gregorio Mart\u00ednez P\u00e9rez",
      "Burkhard Stiller"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07745",
    "title": "Confidence estimation of classification based on the distribution of the  neural network output layer",
    "abstract": "One of the most common problems preventing the application of prediction models in the real world is lack of generalization: The accuracy of models, measured in the benchmark does repeat itself on future data, e.g. in the settings of real business. There is relatively little methods exist that estimate the confidence of prediction models. In this paper, we propose novel methods that, given a neural network classification model, estimate uncertainty of particular predictions generated by this model. Furthermore, we propose a method that, given a model and a confidence level, calculates a threshold that separates prediction generated by this model into two subsets, one of them meets the given confidence level. In contrast to other methods, the proposed methods do not require any changes on existing neural networks, because they simply build on the output logit layer of a common neural network. In particular, the methods infer the confidence of a particular prediction based on the distribution of the logit values corresponding to this prediction. The proposed methods constitute a tool that is recommended for filtering predictions in the process of knowledge extraction, e.g. based on web scrapping, where predictions subsets are identified that maximize the precision on cost of the recall, which is less important due to the availability of data. The method has been tested on different tasks including relation extraction, named entity recognition and image classification to show the significant increase of accuracy achieved. ",
    "url": "https://arxiv.org/abs/2210.07745",
    "authors": [
      "Abdel Aziz Taha",
      "Leonhard Hennig",
      "Petr Knoth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.07747",
    "title": "Online Learning of Caching and Recommendation Policies in a Multi-BS  Cellular Networks",
    "abstract": "Mobile edge computing is a key technology for the future wireless networks and hence, the efficiency of a cache-placement algorithm is important to seek the cache content which satisfies the maximum user demands. Since recommendations personalizes an individual's choices, it is responsible for a significant percentage of user requests, and hence recommendation can be utilized to maximize the overall cache hit rate. Hence, in this work, joint optimization of both recommendation and caching is proposed. The influence of recommendation on the popularity of a file is modelled using a conditional probability distribution. To this end, the concept of probability matrix is introduced and a Bayesian based model, specifically Dirichlet distribution is used to predict and estimate the content request probability and hence the average cache hit is derived. Joint recommendation and caching algorithm is presented to maximize the average cache hits. Subsequently, theoretical guarantees are provided on the performance of the algorithm. Also, a heterogeneous network consisting of M small base stations and one macro base station is also presented. Finally, simulation results confirm the efficiency of the proposed algorithms in terms of average cache hit rate, delay and throughput. ",
    "url": "https://arxiv.org/abs/2210.07747",
    "authors": [
      "S. Krishnendu",
      "B. N. Bharath",
      "Vimal Bhatia"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.07750",
    "title": "Bandwidth-efficient distributed neural network architectures with  application to body sensor networks",
    "abstract": "In this paper, we describe a conceptual design methodology to design distributed neural network architectures that can perform efficient inference within sensor networks with communication bandwidth constraints. The different sensor channels are distributed across multiple sensor devices, which have to exchange data over bandwidth-limited communication channels to solve, e.g., a classification task. Our design methodology starts from a user-defined centralized neural network and transforms it into a distributed architecture in which the channels are distributed over different nodes. The distributed network consists of two parallel branches of which the outputs are fused at the fusion center. The first branch collects classification results from local, node-specific classifiers while the second branch compresses each node's signal and then reconstructs the multi-channel time series for classification at the fusion center. We further improve bandwidth gains by dynamically activating the compression path when the local classifications do not suffice. We validate this method on a motor execution task in an emulated EEG sensor network and analyze the resulting bandwidth-accuracy trade-offs. Our experiments show that the proposed framework enables up to a factor 20 in bandwidth reduction with minimal loss (up to 2%) in classification accuracy compared to the centralized baseline on the demonstrated motor execution task. The proposed method offers a way to smoothly transform a centralized architecture to a distributed, bandwidth-efficient network amenable for low-power sensor networks. While the application focus of this paper is on wearable brain-computer interfaces, the proposed methodology can be applied in other sensor network-like applications as well. ",
    "url": "https://arxiv.org/abs/2210.07750",
    "authors": [
      "Thomas Strypsteen",
      "Alexander Bertrand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.07760",
    "title": "Lightweight Alpha Matting Network Using Distillation-Based Channel  Pruning",
    "abstract": "Recently, alpha matting has received a lot of attention because of its usefulness in mobile applications such as selfies. Therefore, there has been a demand for a lightweight alpha matting model due to the limited computational resources of commercial portable devices. To this end, we suggest a distillation-based channel pruning method for the alpha matting networks. In the pruning step, we remove channels of a student network having fewer impacts on mimicking the knowledge of a teacher network. Then, the pruned lightweight student network is trained by the same distillation loss. A lightweight alpha matting model from the proposed method outperforms existing lightweight methods. To show superiority of our algorithm, we provide various quantitative and qualitative experiments with in-depth analyses. Furthermore, we demonstrate the versatility of the proposed distillation-based channel pruning method by applying it to semantic segmentation. ",
    "url": "https://arxiv.org/abs/2210.07760",
    "authors": [
      "Donggeun Yoon",
      "Jinsun Park",
      "Donghyeon Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07762",
    "title": "Controllable Style Transfer via Test-time Training of Implicit Neural  Representation",
    "abstract": "We propose a controllable style transfer framework based on Implicit Neural Representation (INR) that pixel-wisely controls the stylized output via test-time training. Unlike traditional image optimization methods that often suffer from unstable convergence and learning-based methods that require intensive training and have limited generalization ability, we present a model optimization framework that optimizes the neural networks during test-time with explicit loss functions for style transfer. After being test-time trained once, thanks to the flexibility of the INR-based model,our framework can precisely control the stylized images in a pixel-wise manner and freely adjust image resolution without further optimization or training. ",
    "url": "https://arxiv.org/abs/2210.07762",
    "authors": [
      "Sunwoo Kim",
      "Youngjo Min",
      "Younghun Jung",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07765",
    "title": "HGARN: Hierarchical Graph Attention Recurrent Network for Human Mobility  Prediction",
    "abstract": "Human mobility prediction is a fundamental task essential for various applications, including urban planning, transportation services, and location recommendation. Existing approaches often ignore activity information crucial for reasoning human preferences and routines, or adopt a simplified representation of the dependencies between time, activities and locations. To address these issues, we present Hierarchical Graph Attention Recurrent Network (HGARN) for human mobility prediction. Specifically, we construct a hierarchical graph based on all users' history mobility records and employ a Hierarchical Graph Attention Module to capture complex time-activity-location dependencies. This way, HGARN can learn representations with rich contextual semantics to model user preferences at the global level. We also propose a model-agnostic history-enhanced confidence (MaHec) label to focus our model on each user's individual-level preferences. Finally, we introduce a Recurrent Encoder-Decoder Module, which employs recurrent structures to jointly predict users' next activities (as an auxiliary task) and locations. For model evaluation, we test the performances of our Hgarn against existing SOTAs in recurring and explorative settings. The recurring setting focuses more on assessing models' capabilities to capture users' individual-level preferences. In contrast, the results in the explorative setting tend to reflect the power of different models to learn users' global-level preferences. Overall, our model outperforms other baselines significantly in the main, recurring, and explorative settings based on two real-world human mobility data benchmarks. Source codes of HGARN are available at https://github.com/YihongT/HGARN. ",
    "url": "https://arxiv.org/abs/2210.07765",
    "authors": [
      "Yihong Tang",
      "Junlin He",
      "Zhan Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07769",
    "title": "Flattened Graph Convolutional Networks For Recommendation",
    "abstract": "Graph Convolutional Networks (GCNs) and their variants have achieved significant performances on various recommendation tasks. However, many existing GCN models tend to perform recursive aggregations among all related nodes, which can arise severe computational burden to hinder their application to large-scale recommendation tasks. To this end, this paper proposes the flattened GCN~(FlatGCN) model, which is able to achieve superior performance with remarkably less complexity compared with existing models. Our main contribution is three-fold. First, we propose a simplified but powerful GCN architecture which aggregates the neighborhood information using one flattened GCN layer, instead of recursively. The aggregation step in FlatGCN is parameter-free such that it can be pre-computed with parallel computation to save memory and computational cost. Second, we propose an informative neighbor-infomax sampling method to select the most valuable neighbors by measuring the correlation among neighboring nodes based on a principled metric. Third, we propose a layer ensemble technique which improves the expressiveness of the learned representations by assembling the layer-wise neighborhood representations at the final layer. Extensive experiments on three datasets verify that our proposed model outperforms existing GCN models considerably and yields up to a few orders of magnitude speedup in training efficiency. ",
    "url": "https://arxiv.org/abs/2210.07769",
    "authors": [
      "Yue Xu",
      "Hao Chen",
      "Zengde Deng",
      "Yuanchen Bei",
      "Feiran Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07780",
    "title": "Federated Best Arm Identification with Heterogeneous Clients",
    "abstract": "We study best arm identification in a federated multi-armed bandit setting with a central server and multiple clients, when each client has access to a {\\em subset} of arms and each arm yields independent Gaussian observations. The {\\em reward} from an arm at any given time is defined as the average of the observations generated at this time across all the clients that have access to the arm. The end goal is to identify the best arm (the arm with the largest mean reward) of each client with the least expected stopping time, subject to an upper bound on the error probability (i.e., the {\\em fixed-confidence regime}). We provide a lower bound on the growth rate of the expected time to find the best arm of each client. Furthermore, we show that for any algorithm whose upper bound on the expected time to find the best arms matches with the lower bound up to a multiplicative constant, the ratio of any two consecutive communication time instants must be bounded, a result that is of independent interest. We then provide the first-known lower bound on the expected number of {\\em communication rounds} required to find the best arms. We propose a novel algorithm based on the well-known {\\em Track-and-Stop} strategy that communicates only at exponential time instants, and derive asymptotic upper bounds on its expected time to find the best arms and the expected number of communication rounds, where the asymptotics is one of vanishing error probabilities. ",
    "url": "https://arxiv.org/abs/2210.07780",
    "authors": [
      "Zhirui Chen",
      "P. N. Karthik",
      "Vincent Y. F. Tan",
      "Yeow Meng Chee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2210.07792",
    "title": "Robust Preference Learning for Storytelling via Contrastive  Reinforcement Learning",
    "abstract": "Controlled automated story generation seeks to generate natural language stories satisfying constraints from natural language critiques or preferences. Existing methods to control for story preference utilize prompt engineering which is labor intensive and often inconsistent. They may also use logit-manipulation methods which require annotated datasets to exist for the desired attributes. To address these issues, we first train a contrastive bi-encoder model to align stories with corresponding human critiques, named CARP, building a general purpose preference model. This is subsequently used as a reward function to fine-tune a generative language model via reinforcement learning. However, simply fine-tuning a generative language model with a contrastive reward model does not always reliably result in a story generation system capable of generating stories that meet user preferences. To increase story generation robustness we further fine-tune the contrastive reward model using a prompt-learning technique. A human participant study is then conducted comparing generations from our full system, ablations, and two baselines. We show that the full fine-tuning pipeline results in a story generator preferred over a LLM 20x as large as well as logit-based methods. This motivates the use of contrastive learning for general purpose human preference modeling. ",
    "url": "https://arxiv.org/abs/2210.07792",
    "authors": [
      "Louis Castricato",
      "Alexander Havrilla",
      "Shahbuland Matiana",
      "Michael Pieler",
      "Anbang Ye",
      "Ian Yang",
      "Spencer Frazier",
      "Mark Riedl"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.07796",
    "title": "Nobody Wants to Work Anymore: An Analysis of r/antiwork and the  Interplay between Social and Mainstream Media during the Great Resignation",
    "abstract": "r/antiwork is a Reddit community that focuses on the discussion of worker exploitation, labour rights and related left-wing political ideas (e.g. universal basic income). In late 2021, r/antiwork became the fastest growing community on Reddit, coinciding with what the mainstream media began referring to as the Great Resignation. This same media coverage was attributed with popularising the subreddit and, therefore, accelerating its growth. In this article, we explore how the r/antiwork community was affected by the exponential increase in subscribers and the media coverage that chronicled its rise. We investigate how subreddit activity changed over time, the behaviour of heavy and light users, and how the topical nature of the discourse evolved with the influx of new subscribers. We report that, despite the continuing rise of subscribers well into 2022, activity on the subreddit collapsed after January 25th 2022, when a moderator's Fox news interview was widely criticised. While many users never commented again, longer running trends of users' posting and commenting behaviour did not change. Finally, while many users expressed their discontent at the changing nature of the subreddit as it became more popular, we found no evidence of major shifts in the topical content of discussion over the period studied, with the exception of the introduction of topics related to seasonal events (e.g. holidays, such as Thanksgiving) and ongoing developments in the news (e.g. working from home and the curtailing of reproductive rights in the United States). ",
    "url": "https://arxiv.org/abs/2210.07796",
    "authors": [
      "Alan Medlar",
      "Yang Liu",
      "Dorota Glowacka"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2210.07809",
    "title": "Free Fine-tuning: A Plug-and-Play Watermarking Scheme for Deep Neural  Networks",
    "abstract": "Watermarking has been widely adopted for protecting the intellectual property (IP) of Deep Neural Networks (DNN) to defend the unauthorized distribution. Unfortunately, the popular data-poisoning DNN watermarking scheme relies on target model fine-tuning to embed watermarks, which limits its practical applications in tackling real-world tasks. Specifically, the learning of watermarks via tedious model fine-tuning on a poisoned dataset (carefully-crafted sample-label pairs) is not efficient in tackling the tasks on challenging datasets and production-level DNN model protection. To address the aforementioned limitations, in this paper, we propose a plug-and-play watermarking scheme for DNN models by injecting an independent proprietary model into the target model to serve the watermark embedding and ownership verification. In contrast to the prior studies, our proposed method by incorporating a proprietary model is free of target model fine-tuning without involving any parameters update of the target model, thus the fidelity is well preserved. Our research findings reveal that model fine-tuning with poisoned data is not prepared for the IP protection of DNN models deployed in real-world tasks and poses a new research direction toward a more thorough understanding and investigation of adopting the proprietary model for DNN watermarking. The source code and models are available at https://github.com/AntigoneRandy/PTYNet. ",
    "url": "https://arxiv.org/abs/2210.07809",
    "authors": [
      "Run Wang",
      "Jixing Ren",
      "Boheng Li",
      "Tianyi She",
      "Chehao Lin",
      "Liming Fang",
      "Jing Chen",
      "Chao Shen",
      "Lina Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.07812",
    "title": "Surface abnormality detection in medical and inspection systems using  energy variations in co-occurrence matrixes",
    "abstract": "Detection of surface defects is one of the most important issues in the field of image processing and machine vision. In this article, a method for detecting surface defects based on energy changes in co-occurrence matrices is presented. The presented method consists of two stages of training and testing. In the training phase, the co-occurrence matrix operator is first applied on healthy images and then the amount of output energy is calculated. In the following, according to the changes in the amount of energy, a suitable feature vector is defined, and with the help of it, a suitable threshold for the health of the images is obtained. Then, in the test phase, with the help of the calculated quorum, the defective parts are distinguished from the healthy ones. In the results section, the mentioned method has been applied on stone and ceramic images and its detection accuracy has been calculated and compared with some previous methods. Among the advantages of the presented method, we can mention high accuracy, low calculations and compatibility with all types of levels due to the use of the training stage. The proposed approach can be used in medical applications to detect abnormalities such as diseases. So, the performance is evaluated on 2d-hela dataset to classify cell phenotypes. The proposed approach provides about 89.56 percent accuracy on 2d-hela. ",
    "url": "https://arxiv.org/abs/2210.07812",
    "authors": [
      "Nandara K. Krishnand",
      "Akshakhi Kumar Pritoonka",
      "Faeze Kiani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07814",
    "title": "A Sequence-Aware Recommendation Method Based on Complex Networks",
    "abstract": "Online stores and service providers rely heavily on recommendation softwares to guide users through the vast amount of available products. Consequently, the field of recommender systems has attracted increased attention from the industry and academia alike, but despite this joint effort, the field still faces several challenges. For instance, most existing work models the recommendation problem as a matrix completion problem to predict the user preference for an item. This abstraction prevents the system from utilizing the rich information from the ordered sequence of user actions logged in online sessions. To address this limitation, researchers have recently developed a promising new breed of algorithms called sequence-aware recommender systems to predict the user's next action by utilizing the time series composed of the sequence of actions in an ongoing user session. This paper proposes a novel sequence-aware recommendation approach based on a complex network generated by the hidden metric space model, which combines node similarity and popularity to generate links. We build a network model from data and then use it to predict the user's subsequent actions. The network model provides an additional source of information that improves the accuracy of the recommendations. The proposed method is implemented and tested experimentally on a large dataset. The results prove that the proposed approach performs better than state-of-the-art recommendation methods. ",
    "url": "https://arxiv.org/abs/2210.07814",
    "authors": [
      "Abdullah Alhadlaq",
      "Said Kerrache",
      "Hatim Aboalsamh"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07816",
    "title": "A Recommendation Approach based on Similarity-Popularity Models of  Complex Networks",
    "abstract": "Recommender systems have become an essential tool for providers and users of online services and goods, especially with the increased use of the Internet to access information and purchase products and services. This work proposes a novel recommendation method based on complex networks generated by a similarity-popularity model to predict ones. We first construct a model of a network having users and items as nodes from observed ratings and then use it to predict unseen ratings. The prospect of producing accurate rating predictions using a similarity-popularity model with hidden metric spaces and dot-product similarity is explored. The proposed approach is implemented and experimentally compared against baseline and state-of-the-art recommendation methods on 21 datasets from various domains. The experimental results demonstrate that the proposed method produces accurate predictions and outperforms existing methods. We also show that the proposed approach produces superior results in low dimensions, proving its effectiveness for data visualization and exploration. ",
    "url": "https://arxiv.org/abs/2210.07816",
    "authors": [
      "Abdullah Alhadlaq",
      "Said Kerrache",
      "Hatim Aboalsamh"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07817",
    "title": "Discussion about Attacks and Defenses for Fair and Robust Recommendation  System Design",
    "abstract": "Information has exploded on the Internet and mobile with the advent of the big data era. In particular, recommendation systems are widely used to help consumers who struggle to select the best products among such a large amount of information. However, recommendation systems are vulnerable to malicious user biases, such as fake reviews to promote or demote specific products, as well as attacks that steal personal information. Such biases and attacks compromise the fairness of the recommendation model and infringe the privacy of users and systems by distorting data.Recently, deep-learning collaborative filtering recommendation systems have shown to be more vulnerable to this bias. In this position paper, we examine the effects of bias that cause various ethical and social issues, and discuss the need for designing the robust recommendation system for fairness and stability. ",
    "url": "https://arxiv.org/abs/2210.07817",
    "authors": [
      "Mirae Kim",
      "Simon Woo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.07822",
    "title": "Shadfa 0.1: The Iranian Movie Knowledge Graph and Graph-Embedding-Based  Recommender System",
    "abstract": "Movies are a great source of entertainment. However, the problem arises when one is trying to find the desired content within this vast amount of data which is significantly increasing every year. Recommender systems can provide appropriate algorithms to solve this problem. The content_based technique has found popularity due to the lack of available user data in most cases. Content_based recommender systems are based on the similarity of items' demographic information; Term Frequency _ Inverse Document Frequency (TF_IDF) and Knowledge Graph Embedding (KGE) are two approaches used to vectorize data to calculate these similarities. In this paper, we propose a weighted content_based movie RS by combining TF_IDF which is an appropriate approach for embedding textual data such as plot/description, and KGE which is used to embed named entities such as the director's name. The weights between features are determined using a Genetic algorithm. Additionally, the Iranian movies dataset is created by scraping data from movie_related websites. This dataset and the structure of the FarsBase KG are used to create the MovieFarsBase KG which is a component in the implementation process of the proposed content_based RS. Using precision, recall, and F1 score metrics, this study shows that the proposed approach outperforms the conventional approach that uses TF_IDF for embedding all attributes. ",
    "url": "https://arxiv.org/abs/2210.07822",
    "authors": [
      "Rayhane Pouyan",
      "Hadi Kalamati",
      "Hannane Ebrahimian",
      "Mohammad Karrabi",
      "Mohammad-R. Akbarzadeh-T"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.07828",
    "title": "Parameter-Free Average Attention Improves Convolutional Neural Network  Performance (Almost) Free of Charge",
    "abstract": "Visual perception is driven by the focus on relevant aspects in the surrounding world. To transfer this observation to the digital information processing of computers, attention mechanisms have been introduced to highlight salient image regions. Here, we introduce a parameter-free attention mechanism called PfAAM, that is a simple yet effective module. It can be plugged into various convolutional neural network architectures with a little computational overhead and without affecting model size. PfAAM was tested on multiple architectures for classification and segmentic segmentation leading to improved model performance for all tested cases. This demonstrates its wide applicability as a general easy-to-use module for computer vision tasks. The implementation of PfAAM can be found on https://github.com/nkoerb/pfaam. ",
    "url": "https://arxiv.org/abs/2210.07828",
    "authors": [
      "Nils K\u00f6rber"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07829",
    "title": "Asymmetric Student-Teacher Networks for Industrial Anomaly Detection",
    "abstract": "Industrial defect detection is commonly addressed with anomaly detection (AD) methods where no or only incomplete data of potentially occurring defects is available. This work discovers previously unknown problems of student-teacher approaches for AD and proposes a solution, where two neural networks are trained to produce the same output for the defect-free training examples. The core assumption of student-teacher networks is that the distance between the outputs of both networks is larger for anomalies since they are absent in training. However, previous methods suffer from the similarity of student and teacher architecture, such that the distance is undesirably small for anomalies. For this reason, we propose asymmetric student-teacher networks (AST). We train a normalizing flow for density estimation as a teacher and a conventional feed-forward network as a student to trigger large distances for anomalies: The bijectivity of the normalizing flow enforces a divergence of teacher outputs for anomalies compared to normal data. Outside the training distribution the student cannot imitate this divergence due to its fundamentally different architecture. Our AST network compensates for wrongly estimated likelihoods by a normalizing flow, which was alternatively used for anomaly detection in previous work. We show that our method produces state-of-the-art results on the two currently most relevant defect detection datasets MVTec AD and MVTec 3D-AD regarding image-level anomaly detection on RGB and 3D data. ",
    "url": "https://arxiv.org/abs/2210.07829",
    "authors": [
      "Marco Rudolph",
      "Tom Wehrbein",
      "Bodo Rosenhahn",
      "Bastian Wandt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07848",
    "title": "Convolutional Neural Networks: Basic Concepts and Applications in  Manufacturing",
    "abstract": "We discuss basic concepts of convolutional neural networks (CNNs) and outline uses in manufacturing. We begin by discussing how different types of data objects commonly encountered in manufacturing (e.g., time series, images, micrographs, videos, spectra, molecular structures) can be represented in a flexible manner using tensors and graphs. We then discuss how CNNs use convolution operations to extract informative features (e.g., geometric patterns and textures) from the such representations to predict emergent properties and phenomena and/or to identify anomalies. We also discuss how CNNs can exploit color as a key source of information, which enables the use of modern computer vision hardware (e.g., infrared, thermal, and hyperspectral cameras). We illustrate the concepts using diverse case studies arising in spectral analysis, molecule design, sensor design, image-based control, and multivariate process monitoring. ",
    "url": "https://arxiv.org/abs/2210.07848",
    "authors": [
      "Shengli Jiang",
      "Shiyi Qin",
      "Joshua L. Pulsipher",
      "Victor M. Zavala"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07851",
    "title": "Learning to Autonomously Reach Objects with NICO and Grow-When-Required  Networks",
    "abstract": "The act of reaching for an object is a fundamental yet complex skill for a robotic agent, requiring a high degree of visuomotor control and coordination. In consideration of dynamic environments, a robot capable of autonomously adapting to novel situations is desired. In this paper, a developmental robotics approach is used to autonomously learn visuomotor coordination on the NICO (Neuro-Inspired COmpanion) platform, for the task of object reaching. The robot interacts with its environment and learns associations between motor commands and temporally correlated sensory perceptions based on Hebbian learning. Multiple Grow-When-Required (GWR) networks are used to learn increasingly more complex motoric behaviors, by first learning how to direct the gaze towards a visual stimulus, followed by learning motor control of the arm, and finally learning how to reach for an object using eye-hand coordination. We demonstrate that the model is able to deal with an unforeseen mechanical change in the NICO's body, showing the adaptability of the proposed approach. In evaluations of our approach, we show that the humanoid robot NICO is able to reach objects with a 76% success rate. ",
    "url": "https://arxiv.org/abs/2210.07851",
    "authors": [
      "Nima Rahrakhshan",
      "Matthias Kerzel",
      "Philipp Allgeuer",
      "Nicolas Duczek",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.07860",
    "title": "Super-localization of spatial network models",
    "abstract": "Spatial network models are used as a simplified discrete representation in a wide range of applications, e.g., flow in blood vessels, elasticity of fiber based materials, and pore network models of porous materials. Nevertheless, the resulting linear systems are typically large and poorly conditioned and their numerical solution is challenging. This paper proposes a numerical homogenization technique for spatial network models which is based on the Super Localized Orthogonal Decomposition (SLOD), recently introduced for elliptic multiscale partial differential equations. It provides accurate coarse solution spaces with approximation properties independent of the smoothness of the material data. A unique selling point of the SLOD is that it constructs an almost local basis of these coarse spaces, requiring less computations on the fine scale and achieving improved sparsity on the coarse scale compared to other state-of-the-art methods. We provide an a-posteriori analysis of the proposed method and numerically confirm the method's unique localization properties. In addition, we show its applicability also for high-contrast channeled material data. ",
    "url": "https://arxiv.org/abs/2210.07860",
    "authors": [
      "Moritz Hauck",
      "Axel M\u00e5lqvist"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.07862",
    "title": "Unsupervised Dense Nuclei Detection and Segmentation with Prior  Self-activation Map For Histology Images",
    "abstract": "The success of supervised deep learning models in medical image segmentation relies on detailed annotations. However, labor-intensive manual labeling is costly and inefficient, especially in dense object segmentation. To this end, we propose a self-supervised learning based approach with a Prior Self-activation Module (PSM) that generates self-activation maps from the input images to avoid labeling costs and further produce pseudo masks for the downstream task. To be specific, we firstly train a neural network using self-supervised learning and utilize the gradient information in the shallow layers of the network to generate self-activation maps. Afterwards, a semantic-guided generator is then introduced as a pipeline to transform visual representations from PSM to pixel-level semantic pseudo masks for downstream tasks. Furthermore, a two-stage training module, consisting of a nuclei detection network and a nuclei segmentation network, is adopted to achieve the final segmentation. Experimental results show the effectiveness on two public pathological datasets. Compared with other fully-supervised and weakly-supervised methods, our method can achieve competitive performance without any manual annotations. ",
    "url": "https://arxiv.org/abs/2210.07862",
    "authors": [
      "Pingyi Chen",
      "Chenglu Zhu",
      "Zhongyi Shui",
      "Jiatong Cai",
      "Sunyi Zheng",
      "Shichuan Zhang",
      "Lin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.07871",
    "title": "One Graph to Rule them All: Using NLP and Graph Neural Networks to  analyse Tolkien's Legendarium",
    "abstract": "Natural Language Processing and Machine Learning have considerably advanced Computational Literary Studies. Similarly, the construction of co-occurrence networks of literary characters, and their analysis using methods from social network analysis and network science, have provided insights into the micro- and macro-level structure of literary texts. Combining these perspectives, in this work we study character networks extracted from a text corpus of J.R.R. Tolkien's Legendarium. We show that this perspective helps us to analyse and visualise the narrative style that characterises Tolkien's works. Addressing character classification, embedding and co-occurrence prediction, we further investigate the advantages of state-of-the-art Graph Neural Networks over a popular word embedding method. Our results highlight the large potential of graph learning in Computational Literary Studies. ",
    "url": "https://arxiv.org/abs/2210.07871",
    "authors": [
      "Vincenzo Perri",
      "Lisi Qarkaxhija",
      "Albin Zehe",
      "Andreas Hotho",
      "Ingo Scholtes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.07886",
    "title": "PedFormer: Pedestrian Behavior Prediction via Cross-Modal Attention  Modulation and Gated Multitask Learning",
    "abstract": "Predicting pedestrian behavior is a crucial task for intelligent driving systems. Accurate predictions require a deep understanding of various contextual elements that potentially impact the way pedestrians behave. To address this challenge, we propose a novel framework that relies on different data modalities to predict future trajectories and crossing actions of pedestrians from an ego-centric perspective. Specifically, our model utilizes a cross-modal Transformer architecture to capture dependencies between different data types. The output of the Transformer is augmented with representations of interactions between pedestrians and other traffic agents conditioned on the pedestrian and ego-vehicle dynamics that are generated via a semantic attentive interaction module. Lastly, the context encodings are fed into a multi-stream decoder framework using a gated-shared network. We evaluate our algorithm on public pedestrian behavior benchmarks, PIE and JAAD, and show that our model improves state-of-the-art in trajectory and action prediction by up to 22% and 13% respectively on various metrics. The advantages brought by components of our model are investigated via extensive ablation studies. ",
    "url": "https://arxiv.org/abs/2210.07886",
    "authors": [
      "Amir Rasouli",
      "Iuliia Kotseruba"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.07888",
    "title": "Guessing Random Additive Noise Decoding of Network Coded Data  Transmitted over Burst Error Channels",
    "abstract": "We consider a transmitter that encodes data packets using network coding and broadcasts coded packets. A receiver employing network decoding recovers the data packets if a sufficient number of error-free coded packets are gathered. The receiver does not abandon its efforts to recover the data packets if network decoding is unsuccessful; instead, it employs syndrome decoding (SD) in an effort to repair erroneously received coded packets, and then reattempts network decoding. Most decoding techniques, including SD, assume that errors are independently and identically distributed within received coded packets. Motivated by the guessing random additive noise decoding (GRAND) framework, we propose transversal GRAND (T-GRAND): an algorithm that exploits statistical dependence in the occurrence of errors, complements network decoding and recovers all data packets with a higher probability than SD. T-GRAND examines error vectors in order of their likelihood of occurring and altering the transmitted packets. Calculation and sorting of the likelihood values of all error vectors is a simple but computationally expensive process. To reduce the complexity of T-GRAND, we take advantage of the properties of the likelihood function and develop an efficient method, which identifies the most likely error vectors without computing and ordering their likelihoods. ",
    "url": "https://arxiv.org/abs/2210.07888",
    "authors": [
      "Ioannis Chatzigeorgiou",
      "Dmitry Savostyanov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.07889",
    "title": "Semi-supervised Learning with Network Embedding on Ambient RF Signals  for Geofencing Services",
    "abstract": "In applications such as elderly care, dementia anti-wandering and pandemic control, it is important to ensure that people are within a predefined area for their safety and well-being. We propose GEM, a practical, semi-supervised geofencing system with network embedding, which is based only on ambient radio frequency (RF) signals. GEM models measured RF signal records as a weighted bipartite graph. With APs on one side and signal records on the other, it is able to precisely capture the relationships between signal records. GEM then learns node embeddings from the graph via a novel bipartite network embedding algorithm called BiSAGE, based on a graph neural network with a novel bi-level aggregation mechanism and non-uniform neighborhood sampling. Using the learned embeddings, GEM finally builds a one-class classification model via an enhanced histogram-based algorithm for in-out detection, i.e., to detect whether the user is inside the area or not. This model also keeps on improving with newly collected signal records. We demonstrate through extensive experiments in diverse environments that GEM shows state-of-the-art performance with up to 34% improvement in F-score. BiSAGE in GEM leads to a 54% improvement in F-score, as compared to the one without BiSAGE. ",
    "url": "https://arxiv.org/abs/2210.07889",
    "authors": [
      "Weipeng Zhuo",
      "Ka Ho Chiu",
      "Jierun Chen",
      "Jiajie Tan",
      "Edmund Sumpena",
      "S.-H. Gary Chan",
      "Sangtae Ha",
      "Chul-Ho Lee"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.07895",
    "title": "GRAFICS: Graph Embedding-based Floor Identification Using Crowdsourced  RF Signals",
    "abstract": "We study the problem of floor identification for radiofrequency (RF) signal samples obtained in a crowdsourced manner, where the signal samples are highly heterogeneous and most samples lack their floor labels. We propose GRAFICS, a graph embedding-based floor identification system. GRAFICS first builds a highly versatile bipartite graph model, having APs on one side and signal samples on the other. GRAFICS then learns the low-dimensional embeddings of signal samples via a novel graph embedding algorithm named E-LINE. GRAFICS finally clusters the node embeddings along with the embeddings of a few labeled samples through a proximity-based hierarchical clustering, which eases the floor identification of every new sample. We validate the effectiveness of GRAFICS based on two large-scale datasets that contain RF signal records from 204 buildings in Hangzhou, China, and five buildings in Hong Kong. Our experiment results show that GRAFICS achieves highly accurate prediction performance with only a few labeled samples (96% in both micro- and macro-F scores) and significantly outperforms several state-of-the-art algorithms (by about 45% improvement in micro-F score and 53% in macro-F score). ",
    "url": "https://arxiv.org/abs/2210.07895",
    "authors": [
      "Weipeng Zhuo",
      "Ziqi Zhao",
      "Ka Ho Chiu",
      "Shiju Li",
      "Sangtae Ha",
      "Chul-Ho Lee",
      "S.-H. Gary Chan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.07903",
    "title": "Text Detection Forgot About Document OCR",
    "abstract": "Detection and recognition of text from scans and other images, commonly denoted as Optical Character Recognition (OCR), is a widely used form of automated document processing with a number of methods available. Advances in machine learning enabled even more challenging scenarios of text detection and recognition \"in-the-wild\" - such as detecting text on objects from photographs of complex scenes. While the state-of-the-art methods for in-the-wild text recognition are typically evaluated on complex scenes, their performance in the domain of documents has not been published. This paper compares several methods designed for in-the-wild text recognition and for document text recognition, and provides their evaluation on the domain of structured documents. The results suggest that state-of-the-art methods originally proposed for in-the-wild text detection also achieve excellent results on document text detection, outperforming available OCR methods. We argue that the application of document OCR should not be omitted in evaluation of text detection and recognition methods. ",
    "url": "https://arxiv.org/abs/2210.07903",
    "authors": [
      "Krzysztof Olejniczak",
      "Milan \u0160ulc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07906",
    "title": "Post-Training Quantization for Energy Efficient Realization of Deep  Neural Networks",
    "abstract": "The biggest challenge for the deployment of Deep Neural Networks (DNNs) close to the generated data on edge devices is their size, i.e., memory footprint and computational complexity. Both are significantly reduced with quantization. With the resulting lower word-length, the energy efficiency of DNNs increases proportionally. However, lower word-length typically causes accuracy degradation. To counteract this effect, the quantized DNN is retrained. Unfortunately, training costs up to 5000x more energy than the inference of the quantized DNN. To address this issue, we propose a post-training quantization flow without the need for retraining. For this, we investigated different quantization options. Furthermore, our analysis systematically assesses the impact of reduced word-lengths of weights and activations revealing a clear trend for the choice of word-length. Both aspects have not been systematically investigated so far. Our results are independent of the depth of the DNNs and apply to uniform quantization, allowing fast quantization of a given pre-trained DNN. We excel state-of-the-art for 6 bit by 2.2% Top-1 accuracy for ImageNet. Without retraining, our quantization to 8 bit surpasses floating-point accuracy. ",
    "url": "https://arxiv.org/abs/2210.07906",
    "authors": [
      "Cecilia Latotzke",
      "Batuhan Balim",
      "Tobias Gemmeke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07907",
    "title": "Expose Backdoors on the Way: A Feature-Based Efficient Defense against  Textual Backdoor Attacks",
    "abstract": "Natural language processing (NLP) models are known to be vulnerable to backdoor attacks, which poses a newly arisen threat to NLP models. Prior online backdoor defense methods for NLP models only focus on the anomalies at either the input or output level, still suffering from fragility to adaptive attacks and high computational cost. In this work, we take the first step to investigate the unconcealment of textual poisoned samples at the intermediate-feature level and propose a feature-based efficient online defense method. Through extensive experiments on existing attacking methods, we find that the poisoned samples are far away from clean samples in the intermediate feature space of a poisoned NLP model. Motivated by this observation, we devise a distance-based anomaly score (DAN) to distinguish poisoned samples from clean samples at the feature level. Experiments on sentiment analysis and offense detection tasks demonstrate the superiority of DAN, as it substantially surpasses existing online defense methods in terms of defending performance and enjoys lower inference costs. Moreover, we show that DAN is also resistant to adaptive attacks based on feature-level regularization. Our code is available at https://github.com/lancopku/DAN. ",
    "url": "https://arxiv.org/abs/2210.07907",
    "authors": [
      "Sishuo Chen",
      "Wenkai Yang",
      "Zhiyuan Zhang",
      "Xiaohan Bi",
      "Xu Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.07918",
    "title": "A Hybrid Partitioning Strategy for Backward Reachability of Neural  Feedback Loops",
    "abstract": "As neural networks become more integrated into the systems that we depend on for transportation, medicine, and security, it becomes increasingly important that we develop methods to analyze their behavior to ensure that they are safe to use within these contexts. The methods used in this paper seek to certify safety for closed-loop systems with neural network controllers, i.e., neural feedback loops, using backward reachability analysis. Namely, we calculate backprojection (BP) set over-approximations (BPOAs), i.e., sets of states that lead to a given target set that bounds dangerous regions of the state space. The system's safety can then be certified by checking its current state against the BPOAs. While over-approximating BPs is significantly faster than calculating exact BP sets, solving the relaxed problem leads to conservativeness. To combat conservativeness, partitioning strategies can be used to split the problem into a set of sub-problems, each less conservative than the unpartitioned problem. We introduce a hybrid partitioning method that uses both target set partitioning (TSP) and backreachable set partitioning (BRSP) to overcome a lower bound on estimation error that is present when using BRSP. Numerical results demonstrate a near order-of-magnitude reduction in estimation error compared to BRSP or TSP given the same computation time. ",
    "url": "https://arxiv.org/abs/2210.07918",
    "authors": [
      "Nicholas Rober",
      "Michael Everett",
      "Songan Zhang",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.07920",
    "title": "MOVE: Unsupervised Movable Object Segmentation and Detection",
    "abstract": "We introduce MOVE, a novel method to segment objects without any form of supervision. MOVE exploits the fact that foreground objects can be shifted locally relative to their initial position and result in realistic (undistorted) new images. This property allows us to train a segmentation model on a dataset of images without annotation and to achieve state of the art (SotA) performance on several evaluation datasets for unsupervised salient object detection and segmentation. In unsupervised single object discovery, MOVE gives an average CorLoc improvement of 7.2% over the SotA, and in unsupervised class-agnostic object detection it gives a relative AP improvement of 53% on average. Our approach is built on top of self-supervised features (e.g. from DINO or MAE), an inpainting network (based on the Masked AutoEncoder) and adversarial training. ",
    "url": "https://arxiv.org/abs/2210.07920",
    "authors": [
      "Adam Bielski",
      "Paolo Favaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07932",
    "title": "Neural Routing in Meta Learning",
    "abstract": "Meta-learning often referred to as learning-to-learn is a promising notion raised to mimic human learning by exploiting the knowledge of prior tasks but being able to adapt quickly to novel tasks. A plethora of models has emerged in this context and improved the learning efficiency, robustness, etc. The question that arises here is can we emulate other aspects of human learning and incorporate them into the existing meta learning algorithms? Inspired by the widely recognized finding in neuroscience that distinct parts of the brain are highly specialized for different types of tasks, we aim to improve the model performance of the current meta learning algorithms by selectively using only parts of the model conditioned on the input tasks. In this work, we describe an approach that investigates task-dependent dynamic neuron selection in deep convolutional neural networks (CNNs) by leveraging the scaling factor in the batch normalization (BN) layer associated with each convolutional layer. The problem is intriguing because the idea of helping different parts of the model to learn from different types of tasks may help us train better filters in CNNs, and improve the model generalization performance. We find that the proposed approach, neural routing in meta learning (NRML), outperforms one of the well-known existing meta learning baselines on few-shot classification tasks on the most widely used benchmark datasets. ",
    "url": "https://arxiv.org/abs/2210.07932",
    "authors": [
      "Jicang Cai",
      "Saeed Vahidian",
      "Weijia Wang",
      "Mohsen Joneidi",
      "Bill Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07978",
    "title": "Improving generalizability of distilled self-supervised speech  processing models under distorted settings",
    "abstract": "Self-supervised learned (SSL) speech pre-trained models perform well across various speech processing tasks. Distilled versions of SSL models have been developed to match the needs of on-device speech applications. Though having similar performance as original SSL models, distilled counterparts suffer from performance degradation even more than their original versions in distorted environments. This paper proposes to apply Cross-Distortion Mapping and Domain Adversarial Training to SSL models during knowledge distillation to alleviate the performance gap caused by the domain mismatch problem. Results show consistent performance improvements under both in- and out-of-domain distorted setups for different downstream tasks while keeping efficient model size. ",
    "url": "https://arxiv.org/abs/2210.07978",
    "authors": [
      "Kuan-Po Huang",
      "Yu-Kuan Fu",
      "Tsu-Yuan Hsu",
      "Fabian Ritter Gutierrez",
      "Fan-Lin Wang",
      "Liang-Hsuan Tseng",
      "Yu Zhang",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.07994",
    "title": "Will Emerging Millimeter-Wave Cellular Networks Cause Harmful  Interference to Weather Satellites?",
    "abstract": "We study whether realistic 5G mm-wave cellular networks would cause harmful out-of-band interference to weather satellites sensing in the 23.8 GHz band. We estimate uplink and downlink interference from a single interferer and a network of interferers in New York City, using real 3D building data and realistic antenna patterns. We perform detailed ray-tracing propagation simulations, for locations of the MetOp-B weather satellite and its scanning orientations and ground interferer antenna orientations for representative urban cell sites. In addition to the ITU-R threshold of -136 dBm/200 MHz, we propose an alternative set of harmful interference thresholds directly related to the sensitivity of the satellite sensor. Our results show that the 3GPP power leakage limits are sufficient to ensure that interference from a single 5G device is not harmful if considering the ITU-R threshold, but not if the weather prediction software can tolerate only very low interference levels. Importantly, aggregate interference resulting in practice from a 5G network with realistic network densities is often harmful, even considering the least conservative ITU-R threshold. Overall, our comprehensive coexistence study thus strongly suggests that additional engineering and/or regulatory solutions will be necessary to protect weather satellite passive sensing from mm-wave cellular network interference. ",
    "url": "https://arxiv.org/abs/2210.07994",
    "authors": [
      "Andreea Palade",
      "Andra M. Voicu",
      "Petri M\u00e4h\u00f6nen",
      "Ljiljana Simi\u0107"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.07996",
    "title": "Degeneracy is OK: Logarithmic Regret for Network Revenue Management with  Indiscrete Distributions",
    "abstract": "We study the classical Network Revenue Management (NRM) problem with accept/reject decisions and $T$ IID arrivals. We consider a distributional form where each arrival must fall under a finite number of possible categories, each with a deterministic resource consumption vector, but a random value distributed continuously over an interval. We develop an online algorithm that achieves $O(\\log^2 T)$ regret under this model, with no further assumptions. We develop another online algorithm that achieves an improved $O(\\log T)$ regret, with only a second-order growth assumption. To our knowledge, these are the first results achieving logarithmic-level regret in a continuous-distribution NRM model without further ``non-degeneracy'' assumptions. Our results are achieved via new techniques including: a new method of bounding myopic regret, a ``semi-fluid'' relaxation of the offline allocation, and an improved bound on the ``dual convergence''. ",
    "url": "https://arxiv.org/abs/2210.07996",
    "authors": [
      "Jiashuo Jiang",
      "Will Ma",
      "Jiawei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2210.08001",
    "title": "Learnable Polyphase Sampling for Shift Invariant and Equivariant  Convolutional Networks",
    "abstract": "We propose learnable polyphase sampling (LPS), a pair of learnable down/upsampling layers that enable truly shift-invariant and equivariant convolutional networks. LPS can be trained end-to-end from data and generalizes existing handcrafted downsampling layers. It is widely applicable as it can be integrated into any convolutional network by replacing down/upsampling layers. We evaluate LPS on image classification and semantic segmentation. Experiments show that LPS is on-par with or outperforms existing methods in both performance and shift consistency. For the first time, we achieve true shift-equivariance on semantic segmentation (PASCAL VOC), i.e., 100% shift consistency, outperforming baselines by an absolute 3.3%. ",
    "url": "https://arxiv.org/abs/2210.08001",
    "authors": [
      "Renan A. Rojas-Gomez",
      "Teck-Yian Lim",
      "Alexander G. Schwing",
      "Minh N. Do",
      "Raymond A. Yeh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07410",
    "title": "Quantification of entanglement with Siamese convolutional neural  networks",
    "abstract": "Quantum entanglement is a fundamental property commonly used in various quantum information protocols and algorithms. Nonetheless, the problem of quantifying entanglement has still not reached general solution for systems larger than two qubits. In this paper, we investigate the possibility of detecting entanglement with the use of the supervised machine learning method, namely the deep convolutional neural networks. We build a model consisting of convolutional layers, which is able to recognize and predict the presence of entanglement for any bipartition of the given multi-qubit system. We demonstrate that training our model on synthetically generated datasets collecting random density matrices, which either include or exclude challenging positive-under-partial-transposition entangled states (PPTES), leads to the different accuracy of the model and its possibility to detect such states. Moreover, it is shown that enforcing entanglement-preserving symmetry operations (local operations on qubit or permutations of qubits) by using triple Siamese network, can significantly increase the model performance and ability to generalize on types of states not seen during the training stage. We perform numerical calculations for 3,4 and 5-qubit systems, therefore proving the scalability of the proposed approach. ",
    "url": "https://arxiv.org/abs/2210.07410",
    "authors": [
      "Jaros\u0142aw Paw\u0142owski",
      "Mateusz Krawczyk"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.07611",
    "title": "Self-Supervised 2D/3D Registration for X-Ray to CT Image Fusion",
    "abstract": "Deep Learning-based 2D/3D registration enables fast, robust, and accurate X-ray to CT image fusion when large annotated paired datasets are available for training. However, the need for paired CT volume and X-ray images with ground truth registration limits the applicability in interventional scenarios. An alternative is to use simulated X-ray projections from CT volumes, thus removing the need for paired annotated datasets. Deep Neural Networks trained exclusively on simulated X-ray projections can perform significantly worse on real X-ray images due to the domain gap. We propose a self-supervised 2D/3D registration framework combining simulated training with unsupervised feature and pixel space domain adaptation to overcome the domain gap and eliminate the need for paired annotated datasets. Our framework achieves a registration accuracy of 1.83$\\pm$1.16 mm with a high success ratio of 90.1% on real X-ray images showing a 23.9% increase in success ratio compared to reference annotation-free algorithms. ",
    "url": "https://arxiv.org/abs/2210.07611",
    "authors": [
      "Srikrishna Jaganathan",
      "Maximilian Kukla",
      "Jian Wang",
      "Karthik Shetty",
      "Andreas Maier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07761",
    "title": "Improved automated lesion segmentation in whole-body FDG/PET-CT via  Test-Time Augmentation",
    "abstract": "Numerous oncology indications have extensively quantified metabolically active tumors using positron emission tomography (PET) and computed tomography (CT). F-fluorodeoxyglucose-positron emission tomography (FDG-PET) is frequently utilized in clinical practice and clinical drug research to detect and measure metabolically active malignancies. The assessment of tumor burden using manual or computer-assisted tumor segmentation in FDG-PET images is widespread. Deep learning algorithms have also produced effective solutions in this area. However, there may be a need to improve the performance of a pre-trained deep learning network without the opportunity to modify this network. We investigate the potential benefits of test-time augmentation for segmenting tumors from PET-CT pairings. We applied a new framework of multilevel and multimodal tumor segmentation techniques that can simultaneously consider PET and CT data. In this study, we improve the network using a learnable composition of test time augmentations. We trained U-Net and Swin U-Netr on the training database to determine how different test time augmentation improved segmentation performance. We also developed an algorithm that finds an optimal test time augmentation contribution coefficient set. Using the newly trained U-Net and Swin U-Netr results, we defined an optimal set of coefficients for test-time augmentation and utilized them in combination with a pre-trained fixed nnU-Net. The ultimate idea is to improve performance at the time of testing when the model is fixed. Averaging the predictions with varying ratios on the augmented data can improve prediction accuracy. Our code will be available at \\url{https://github.com/sepidehamiri/pet\\_seg\\_unet} ",
    "url": "https://arxiv.org/abs/2210.07761",
    "authors": [
      "Sepideh Amiri",
      "Bulat Ibragimov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07818",
    "title": "ISTA-Inspired Network for Image Super-Resolution",
    "abstract": "Deep learning for image super-resolution (SR) has been investigated by numerous researchers in recent years. Most of the works concentrate on effective block designs and improve the network representation but lack interpretation. There are also iterative optimization-inspired networks for image SR, which take the solution step as a whole without giving an explicit optimization step. This paper proposes an unfolding iterative shrinkage thresholding algorithm (ISTA) inspired network for interpretable image SR. Specifically, we analyze the problem of image SR and propose a solution based on the ISTA method. Inspired by the mathematical analysis, the ISTA block is developed to conduct the optimization in an end-to-end manner. To make the exploration more effective, a multi-scale exploitation block and multi-scale attention mechanism are devised to build the ISTA block. Experimental results show the proposed ISTA-inspired restoration network (ISTAR) achieves competitive or better performances than other optimization-inspired works with fewer parameters and lower computation complexity. ",
    "url": "https://arxiv.org/abs/2210.07818",
    "authors": [
      "Yuqing Liu",
      "Wei Zhang",
      "Weifeng Sun",
      "Zhikai Yu",
      "Jianfeng Wei",
      "Shengquan Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07880",
    "title": "Tunable Complexity Benchmarks for Evaluating Physics-Informed Neural  Networks on Coupled Ordinary Differential Equations",
    "abstract": "In this work, we assess the ability of physics-informed neural networks (PINNs) to solve increasingly-complex coupled ordinary differential equations (ODEs). We focus on a pair of benchmarks: discretized partial differential equations and harmonic oscillators, each of which has a tunable parameter that controls its complexity. Even by varying network architecture and applying a state-of-the-art training method that accounts for \"difficult\" training regions, we show that PINNs eventually fail to produce correct solutions to these benchmarks as their complexity -- the number of equations and the size of time domain -- increases. We identify several reasons why this may be the case, including insufficient network capacity, poor conditioning of the ODEs, and high local curvature, as measured by the Laplacian of the PINN loss. ",
    "url": "https://arxiv.org/abs/2210.07880",
    "authors": [
      "Alexander New",
      "Benjamin Eng",
      "Andrea C. Timm",
      "Andrew S. Gearhart"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.07931",
    "title": "Sequential Learning Of Neural Networks for Prequential MDL",
    "abstract": "Minimum Description Length (MDL) provides a framework and an objective for principled model evaluation. It formalizes Occam's Razor and can be applied to data from non-stationary sources. In the prequential formulation of MDL, the objective is to minimize the cumulative next-step log-loss when sequentially going through the data and using previous observations for parameter estimation. It thus closely resembles a continual- or online-learning problem. In this study, we evaluate approaches for computing prequential description lengths for image classification datasets with neural networks. Considering the computational cost, we find that online-learning with rehearsal has favorable performance compared to the previously widely used block-wise estimation. We propose forward-calibration to better align the models predictions with the empirical observations and introduce replay-streams, a minibatch incremental training technique to efficiently implement approximate random replay while avoiding large in-memory replay buffers. As a result, we present description lengths for a suite of image classification datasets that improve upon previously reported results by large margins. ",
    "url": "https://arxiv.org/abs/2210.07931",
    "authors": [
      "Jorg Bornschein",
      "Yazhe Li",
      "Marcus Hutter"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07936",
    "title": "Data-Limited Tissue Segmentation using Inpainting-Based Self-Supervised  Learning",
    "abstract": "Although supervised learning has enabled high performance for image segmentation, it requires a large amount of labeled training data, which can be difficult to obtain in the medical imaging field. Self-supervised learning (SSL) methods involving pretext tasks have shown promise in overcoming this requirement by first pretraining models using unlabeled data. In this work, we evaluate the efficacy of two SSL methods (inpainting-based pretext tasks of context prediction and context restoration) for CT and MRI image segmentation in label-limited scenarios, and investigate the effect of implementation design choices for SSL on downstream segmentation performance. We demonstrate that optimally trained and easy-to-implement inpainting-based SSL segmentation models can outperform classically supervised methods for MRI and CT tissue segmentation in label-limited scenarios, for both clinically-relevant metrics and the traditional Dice score. ",
    "url": "https://arxiv.org/abs/2210.07936",
    "authors": [
      "Jeffrey Dominic",
      "Nandita Bhaskhar",
      "Arjun D. Desai",
      "Andrew Schmidt",
      "Elka Rubin",
      "Beliz Gunel",
      "Garry E. Gold",
      "Brian A. Hargreaves",
      "Leon Lenchik",
      "Robert Boutin",
      "Akshay S. Chaudhari"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07980",
    "title": "Representation Theory for Geometric Quantum Machine Learning",
    "abstract": "Recent advances in classical machine learning have shown that creating models with inductive biases encoding the symmetries of a problem can greatly improve performance. Importation of these ideas, combined with an existing rich body of work at the nexus of quantum theory and symmetry, has given rise to the field of Geometric Quantum Machine Learning (GQML). Following the success of its classical counterpart, it is reasonable to expect that GQML will play a crucial role in developing problem-specific and quantum-aware models capable of achieving a computational advantage. Despite the simplicity of the main idea of GQML -- create architectures respecting the symmetries of the data -- its practical implementation requires a significant amount of knowledge of group representation theory. We present an introduction to representation theory tools from the optics of quantum learning, driven by key examples involving discrete and continuous groups. These examples are sewn together by an exposition outlining the formal capture of GQML symmetries via \"label invariance under the action of a group representation\", a brief (but rigorous) tour through finite and compact Lie group representation theory, a reexamination of ubiquitous tools like Haar integration and twirling, and an overview of some successful strategies for detecting symmetries. ",
    "url": "https://arxiv.org/abs/2210.07980",
    "authors": [
      "Michael Ragone",
      "Paolo Braccia",
      "Quynh T. Nguyen",
      "Louis Schatzki",
      "Patrick J. Coles",
      "Frederic Sauvage",
      "Martin Larocca",
      "M. Cerezo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Representation Theory (math.RT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.07992",
    "title": "A Variational Perspective on Generative Flow Networks",
    "abstract": "Generative flow networks (GFNs) are a class of models for sequential sampling of composite objects, which approximate a target distribution that is defined in terms of an energy function or a reward. GFNs are typically trained using a flow matching or trajectory balance objective, which matches forward and backward transition models over trajectories. In this work, we define variational objectives for GFNs in terms of the Kullback-Leibler (KL) divergences between the forward and backward distribution. We show that variational inference in GFNs is equivalent to minimizing the trajectory balance objective when sampling trajectories from the forward model. We generalize this approach by optimizing a convex combination of the reverse- and forward KL divergence. This insight suggests variational inference methods can serve as a means to define a more general family of objectives for training generative flow networks, for example by incorporating control variates, which are commonly used in variational inference, to reduce the variance of the gradients of the trajectory balance objective. We evaluate our findings and the performance of the proposed variational objective numerically by comparing it to the trajectory balance objective on two synthetic tasks. ",
    "url": "https://arxiv.org/abs/2210.07992",
    "authors": [
      "Heiko Zimmermann",
      "Fredrik Lindsten",
      "Jan-Willem van de Meent",
      "Christian A. Naesseth"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1908.07414",
    "title": "Sarcasm Detection using Hybrid Neural Network",
    "abstract": " Title: Sarcasm Detection using Hybrid Neural Network ",
    "url": "https://arxiv.org/abs/1908.07414",
    "authors": [
      "Rishabh Misra",
      "Prahal Arora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2003.12659",
    "title": "Semiparametric Inference For Causal Effects In Graphical Models With  Hidden Variables",
    "abstract": " Comments: 76 pages ",
    "url": "https://arxiv.org/abs/2003.12659",
    "authors": [
      "Rohit Bhattacharya",
      "Razieh Nabi",
      "Ilya Shpitser"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2101.08732",
    "title": "Self-Adaptive Training: Bridging Supervised and Self-Supervised Learning",
    "abstract": " Comments: Accepted at T-PAMI. Journal version of arXiv:2002.10319 [cs.LG] (NeurIPS2020). 22 pages, 15 figures, 13 tables ",
    "url": "https://arxiv.org/abs/2101.08732",
    "authors": [
      "Lang Huang",
      "Chao Zhang",
      "Hongyang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2105.02322",
    "title": "Reconstructing shared dynamics with a deep neural network",
    "abstract": " Title: Reconstructing shared dynamics with a deep neural network ",
    "url": "https://arxiv.org/abs/2105.02322",
    "authors": [
      "Zsigmond Benk\u0151",
      "Zolt\u00e1n Somogyv\u00e1ri"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2109.07606",
    "title": "Graph skeletonization of high-dimensional point cloud data via  topological method",
    "abstract": " Title: Graph skeletonization of high-dimensional point cloud data via  topological method ",
    "url": "https://arxiv.org/abs/2109.07606",
    "authors": [
      "Lucas Magee",
      "Yusu Wang"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ]
  },
  {
    "id": "arXiv:2110.15108",
    "title": "Generalized Anomaly Detection",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2110.15108",
    "authors": [
      "Suresh Singh",
      "Minwei Luo",
      "Yu Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2112.08125",
    "title": "Exponential Convergence of Deep Operator Networks for Elliptic Partial  Differential Equations",
    "abstract": " Title: Exponential Convergence of Deep Operator Networks for Elliptic Partial  Differential Equations ",
    "url": "https://arxiv.org/abs/2112.08125",
    "authors": [
      "Carlo Marcati",
      "Christoph Schwab"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2112.14382",
    "title": "Self-Supervised Robustifying Guidance for Monocular 3D Face  Reconstruction",
    "abstract": " Comments: Accepted by The 33rd British Machine Vision Conference (BMVC) 2022 ",
    "url": "https://arxiv.org/abs/2112.14382",
    "authors": [
      "Hitika Tiwari",
      "Min-Hung Chen",
      "Yi-Min Tsai",
      "Hsien-Kai Kuo",
      "Hung-Jen Chen",
      "Kevin Jou",
      "K. S. Venkatesh",
      "Yong-Sheng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.03169",
    "title": "FedDTG:Federated Data-Free Knowledge Distillation via Three-Player  Generative Adversarial Networks",
    "abstract": " Title: FedDTG:Federated Data-Free Knowledge Distillation via Three-Player  Generative Adversarial Networks ",
    "url": "https://arxiv.org/abs/2201.03169",
    "authors": [
      "Zhenyuan Zhang",
      "Tao Shen",
      "Jie Zhang",
      "Chao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.05819",
    "title": "Interpretable and Effective Reinforcement Learning for Attacking against  Graph-based Rumor Detection",
    "abstract": " Title: Interpretable and Effective Reinforcement Learning for Attacking against  Graph-based Rumor Detection ",
    "url": "https://arxiv.org/abs/2201.05819",
    "authors": [
      "Yuefei Lyu",
      "Xiaoyu Yang",
      "Jiaxin Liu",
      "Philip S. Yu",
      "Sihong Xie",
      "Xi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2201.12787",
    "title": "GRPE: Relative Positional Encoding for Graph Transformer",
    "abstract": " Title: GRPE: Relative Positional Encoding for Graph Transformer ",
    "url": "https://arxiv.org/abs/2201.12787",
    "authors": [
      "Wonpyo Park",
      "Woonggi Chang",
      "Donggeon Lee",
      "Juntae Kim",
      "Seung-won Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.04206",
    "title": "Covariate-informed Representation Learning to Prevent Posterior Collapse  of iVAE",
    "abstract": " Title: Covariate-informed Representation Learning to Prevent Posterior Collapse  of iVAE ",
    "url": "https://arxiv.org/abs/2202.04206",
    "authors": [
      "Young-geun Kim",
      "Ying Liu",
      "Xuexin Wei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.04798",
    "title": "Augmenting Neural Networks with Priors on Function Values",
    "abstract": " Title: Augmenting Neural Networks with Priors on Function Values ",
    "url": "https://arxiv.org/abs/2202.04798",
    "authors": [
      "Hunter Nisonoff",
      "Yixin Wang",
      "Jennifer Listgarten"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2202.07615",
    "title": "P4E: Few-Shot Event Detection as Prompt-Guided Identification and  Localization",
    "abstract": " Comments: 13 pages, updated baselines and additional experiments ",
    "url": "https://arxiv.org/abs/2202.07615",
    "authors": [
      "Sha Li",
      "Liyuan Liu",
      "Yiqing Xie",
      "Heng Ji",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.00007",
    "title": "Spatial-Temporal Attention Fusion Network for short-term passenger flow  prediction on holidays in urban rail transit systems",
    "abstract": " Comments: 26 pages, 10 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2203.00007",
    "authors": [
      "Shuxin Zhang",
      "Jinlei Zhang",
      "Lixing Yang",
      "Jiateng Yin",
      "Ziyou Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.05483",
    "title": "projUNN: efficient method for training deep networks with unitary  matrices",
    "abstract": " Title: projUNN: efficient method for training deep networks with unitary  matrices ",
    "url": "https://arxiv.org/abs/2203.05483",
    "authors": [
      "Bobak Kiani",
      "Randall Balestriero",
      "Yann LeCun",
      "Seth Lloyd"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2203.07648",
    "title": "Contrastive Learning of Sociopragmatic Meaning in Social Media",
    "abstract": " Comments: Work in progress ",
    "url": "https://arxiv.org/abs/2203.07648",
    "authors": [
      "Chiyu Zhang",
      "Muhammad Abdul-Mageed",
      "Ganesh Jawahar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.14030",
    "title": "Neural Implicit Representations for Physical Parameter Inference from a  Single Video",
    "abstract": " Comments: Published in IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023 ",
    "url": "https://arxiv.org/abs/2204.14030",
    "authors": [
      "Florian Hofherr",
      "Lukas Koestler",
      "Florian Bernard",
      "Daniel Cremers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.07384",
    "title": "Incorporating Prior Knowledge into Neural Networks through an Implicit  Composite Kernel",
    "abstract": " Comments: 21 pages, 12 figures, 3 tables, 2 algorithms, submitted to the 26th International Conference on Artificial Intelligence and Statistics (AISTATS) ",
    "url": "https://arxiv.org/abs/2205.07384",
    "authors": [
      "Ziyang Jiang",
      "Tongshu Zheng",
      "Yiling Liu",
      "David Carlson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.08356",
    "title": "DouFu: A Double Fusion Joint Learning Method For Driving Trajectory  Representation",
    "abstract": " Comments: 11 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2205.08356",
    "authors": [
      "Han Wang",
      "Zhou Huang",
      "Xiao Zhou",
      "Ganmin Yin",
      "Yi Bao",
      "Yi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2205.10343",
    "title": "Towards Understanding Grokking: An Effective Theory of Representation  Learning",
    "abstract": " Comments: Accepted by NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.10343",
    "authors": [
      "Ziming Liu",
      "Ouail Kitouni",
      "Niklas Nolte",
      "Eric J. Michaud",
      "Max Tegmark",
      "Mike Williams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Artificial Intelligence (cs.AI)",
      "Classical Physics (physics.class-ph)"
    ]
  },
  {
    "id": "arXiv:2205.11459",
    "title": "CELEST: Federated Learning for Globally Coordinated Threat Detection",
    "abstract": " Title: CELEST: Federated Learning for Globally Coordinated Threat Detection ",
    "url": "https://arxiv.org/abs/2205.11459",
    "authors": [
      "Talha Ongun",
      "Simona Boboila",
      "Alina Oprea",
      "Tina Eliassi-Rad",
      "Jason Hiser",
      "Jack Davidson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12550",
    "title": "Recognition Models to Learn Dynamics from Partial Observations with  Neural ODEs",
    "abstract": " Title: Recognition Models to Learn Dynamics from Partial Observations with  Neural ODEs ",
    "url": "https://arxiv.org/abs/2205.12550",
    "authors": [
      "Mona Buisson-Fenet",
      "Valery Morgenthaler",
      "Sebastian Trimpe",
      "Florent Di Meglio"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.13038",
    "title": "Improving Subgraph Representation Learning via Multi-View Augmentation",
    "abstract": " Title: Improving Subgraph Representation Learning via Multi-View Augmentation ",
    "url": "https://arxiv.org/abs/2205.13038",
    "authors": [
      "Yili Shen",
      "Xiao Liu",
      "Cheng-Wei Ju",
      "Jiaxu Yan",
      "Jun Yi",
      "Zhou Lin",
      "Hui Guan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13863",
    "title": "Why Robust Generalization in Deep Learning is Difficult: Perspective of  Expressive Power",
    "abstract": " Comments: 25 pages; to appear in NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.13863",
    "authors": [
      "Binghui Li",
      "Jikai Jin",
      "Han Zhong",
      "John E. Hopcroft",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.14690",
    "title": "CoNT: Contrastive Neural Text Generation",
    "abstract": " Comments: Accepted by NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.14690",
    "authors": [
      "Chenxin An",
      "Jiangtao Feng",
      "Kai Lv",
      "Lingpeng Kong",
      "Xipeng Qiu",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.15156",
    "title": "Towards Efficient 3D Object Detection with Knowledge Distillation",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.15156",
    "authors": [
      "Jihan Yang",
      "Shaoshuai Shi",
      "Runyu Ding",
      "Zhe Wang",
      "Xiaojuan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.00619",
    "title": "Graph Machine Learning for Design of High-Octane Fuels",
    "abstract": " Comments: manuscript (26 pages, 9 figures, 2 tables), supporting information (12 pages, 8 figures, 1 table) ",
    "url": "https://arxiv.org/abs/2206.00619",
    "authors": [
      "Jan G. Rittig",
      "Martin Ritzert",
      "Artur M. Schweidtmann",
      "Stefanie Winkler",
      "Jana M. Weber",
      "Philipp Morsch",
      "K. Alexander Heufer",
      "Martin Grohe",
      "Alexander Mitsos",
      "Manuel Dahmen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.01451",
    "title": "Learning Distributed and Fair Policies for Network Load Balancing as  Markov Potential Game",
    "abstract": " Title: Learning Distributed and Fair Policies for Network Load Balancing as  Markov Potential Game ",
    "url": "https://arxiv.org/abs/2206.01451",
    "authors": [
      "Zhiyuan Yao",
      "Zihan Ding"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2206.01649",
    "title": "Neural Differential Equations for Learning to Program Neural Nets  Through Continuous Learning Rules",
    "abstract": " Comments: Accepted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2206.01649",
    "authors": [
      "Kazuki Irie",
      "Francesco Faccio",
      "J\u00fcrgen Schmidhuber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.02743",
    "title": "A Neural Corpus Indexer for Document Retrieval",
    "abstract": " Comments: 19 pages, 6 figures, accepted by NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2206.02743",
    "authors": [
      "Yujing Wang",
      "Yingyan Hou",
      "Haonan Wang",
      "Ziming Miao",
      "Shibin Wu",
      "Hao Sun",
      "Qi Chen",
      "Yuqing Xia",
      "Chengmin Chi",
      "Guoshuai Zhao",
      "Zheng Liu",
      "Xing Xie",
      "Hao Allen Sun",
      "Weiwei Deng",
      "Qi Zhang",
      "Mao Yang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2206.03693",
    "title": "Autoregressive Perturbations for Data Poisoning",
    "abstract": " Comments: Accepted to NeurIPS 2022. Code available at this https URL ",
    "url": "https://arxiv.org/abs/2206.03693",
    "authors": [
      "Pedro Sandoval-Segura",
      "Vasu Singla",
      "Jonas Geiping",
      "Micah Goldblum",
      "Tom Goldstein",
      "David W. Jacobs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2206.03858",
    "title": "Rotation-Equivariant Conditional Spherical Neural Fields for Learning a  Natural Illumination Prior",
    "abstract": " Comments: NeurIPS 2022 - Project Website: jadgardner.github.io/RENI ",
    "url": "https://arxiv.org/abs/2206.03858",
    "authors": [
      "James A. D. Gardner",
      "Bernhard Egger",
      "William A. P. Smith"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.07578",
    "title": "E2V-SDE: From Asynchronous Events to Fast and Continuous Video  Reconstruction via Neural Stochastic Differential Equations",
    "abstract": " Comments: arXiv admin note: This submission has been withdrawn by arXiv administrators due to inappropriate text overlap with external sources. Additional information at this https URL ",
    "url": "https://arxiv.org/abs/2206.07578",
    "authors": [
      "Jongwan Kim",
      "DongJin Lee",
      "Byunggook Na",
      "Seongsik Park",
      "Jeonghee Jo",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2206.09642",
    "title": "Beyond IID: data-driven decision-making in heterogeneous environments",
    "abstract": " Title: Beyond IID: data-driven decision-making in heterogeneous environments ",
    "url": "https://arxiv.org/abs/2206.09642",
    "authors": [
      "Omar Besbes",
      "Will Ma",
      "Omar Mouchtaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.15258",
    "title": "Neural Surface Reconstruction of Dynamic Scenes with Monocular RGB-D  Camera",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2206.15258",
    "authors": [
      "Hongrui Cai",
      "Wanquan Feng",
      "Xuetao Feng",
      "Yan Wang",
      "Juyong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2207.01927",
    "title": "Drone Detection and Tracking in Real-Time by Fusion of Different Sensing  Modalities",
    "abstract": " Comments: Under consideration at Drones ",
    "url": "https://arxiv.org/abs/2207.01927",
    "authors": [
      "Fredrik Svanstr\u00f6m",
      "Fernando Alonso-Fernandez",
      "Cristofer Englund"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.02440",
    "title": "PAC Prediction Sets for Meta-Learning",
    "abstract": " Comments: Accepted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2207.02440",
    "authors": [
      "Sangdon Park",
      "Edgar Dobriban",
      "Insup Lee",
      "Osbert Bastani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.08803",
    "title": "Adversarial Pixel Restoration as a Pretext Task for Transferable  Perturbations",
    "abstract": " Comments: Accepted at BMVC'22 (Oral) ",
    "url": "https://arxiv.org/abs/2207.08803",
    "authors": [
      "Hashmat Shadab Malik",
      "Shahina K Kunhimon",
      "Muzammal Naseer",
      "Salman Khan",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.09397",
    "title": "Composition Theorems for Interactive Differential Privacy",
    "abstract": " Comments: To appear in NeurIPS 2022; Revised according to reviewers' feedback; Mentioned a concurrent and independent work ",
    "url": "https://arxiv.org/abs/2207.09397",
    "authors": [
      "Xin Lyu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2208.02836",
    "title": "Modeling community standards for metadata as templates makes data FAIR",
    "abstract": " Comments: 20 pages, 1 table, 5 figures ",
    "url": "https://arxiv.org/abs/2208.02836",
    "authors": [
      "Mark A. Musen",
      "Martin J. O'Connor",
      "Erik Schultes",
      "Marcos Martinez-Romero",
      "Josef Hardi",
      "John Graybeal"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2208.05516",
    "title": "Quality Not Quantity: On the Interaction between Dataset Design and  Robustness of CLIP",
    "abstract": " Comments: Added GitHub link ",
    "url": "https://arxiv.org/abs/2208.05516",
    "authors": [
      "Thao Nguyen",
      "Gabriel Ilharco",
      "Mitchell Wortsman",
      "Sewoong Oh",
      "Ludwig Schmidt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.08165",
    "title": "Towards Open-vocabulary Scene Graph Generation with Prompt-based  Finetuning",
    "abstract": " Title: Towards Open-vocabulary Scene Graph Generation with Prompt-based  Finetuning ",
    "url": "https://arxiv.org/abs/2208.08165",
    "authors": [
      "Tao He",
      "Lianli Gao",
      "Jingkuan Song",
      "Yuan-Fang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.14590",
    "title": "Multitask kernel-learning parameter prediction method for solving  time-dependent linear systems",
    "abstract": " Title: Multitask kernel-learning parameter prediction method for solving  time-dependent linear systems ",
    "url": "https://arxiv.org/abs/2208.14590",
    "authors": [
      "Kai Jiang",
      "Juan Zhang",
      "Qi Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2209.01825",
    "title": "Detecting Unjustified Assumptions in Subclasses via Elegant Objects  Representation",
    "abstract": " Title: Detecting Unjustified Assumptions in Subclasses via Elegant Objects  Representation ",
    "url": "https://arxiv.org/abs/2209.01825",
    "authors": [
      "Vitaliy Korbashov",
      "Nikolai Kudasov",
      "Mikhail Olokin",
      "Violetta Sim"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2209.03665",
    "title": "Generalized One-shot Domain Adaptation of Generative Adversarial  Networks",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2209.03665",
    "authors": [
      "Zicheng Zhang",
      "Yinglu Liu",
      "Congying Han",
      "Tiande Guo",
      "Ting Yao",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.07263",
    "title": "Robustness in deep learning: The good (width), the bad (depth), and the  ugly (initialization)",
    "abstract": " Comments: Accepted in NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2209.07263",
    "authors": [
      "Zhenyu Zhu",
      "Fanghui Liu",
      "Grigorios G Chrysos",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.08769",
    "title": "Walk-and-Relate: A Random-Walk-based Algorithm for Representation  Learning on Sparse Knowledge Graphs",
    "abstract": " Title: Walk-and-Relate: A Random-Walk-based Algorithm for Representation  Learning on Sparse Knowledge Graphs ",
    "url": "https://arxiv.org/abs/2209.08769",
    "authors": [
      "Saurav Manchanda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2209.14086",
    "title": "Momentum Gradient Descent Federated Learning with Local Differential  Privacy",
    "abstract": " Comments: There is a crucial definition error of local differential privacy ",
    "url": "https://arxiv.org/abs/2209.14086",
    "authors": [
      "Mengde Han",
      "Tianqing Zhu",
      "Wanlei Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.00563",
    "title": "AI-Assisted Discovery of Quantitative and Formal Models in Social  Science",
    "abstract": " Comments: 19 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2210.00563",
    "authors": [
      "Julia Balla",
      "Sihao Huang",
      "Owen Dugan",
      "Rumen Dangovski",
      "Marin Soljacic"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ]
  },
  {
    "id": "arXiv:2210.01078",
    "title": "Unsupervised Model Selection for Time-series Anomaly Detection",
    "abstract": " Comments: Updated affiliations. Under review ",
    "url": "https://arxiv.org/abs/2210.01078",
    "authors": [
      "Mononito Goswami",
      "Cristian Challu",
      "Laurent Callot",
      "Lenon Minorics",
      "Andrey Kan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02523",
    "title": "Dual-Domain Cross-Iteration Squeeze-Excitation Network for Sparse  Reconstruction of Brain MRI",
    "abstract": " Comments: 4 pages, 5 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2210.02523",
    "authors": [
      "Xiongchao Chen",
      "Yoshihisa Shinagawa",
      "Zhigang Peng",
      "Gerardo Hermosillo Valadez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.03372",
    "title": "Pre-trained Adversarial Perturbations",
    "abstract": " Title: Pre-trained Adversarial Perturbations ",
    "url": "https://arxiv.org/abs/2210.03372",
    "authors": [
      "Yuanhao Ban",
      "Yinpeng Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.03956",
    "title": "Robust Graph Structure Learning over Images via Multiple Statistical  Tests",
    "abstract": " Comments: Accepted by the NeurIPS 2022. Homepage: this https URL ",
    "url": "https://arxiv.org/abs/2210.03956",
    "authors": [
      "Yaohua Wang",
      "FangYi Zhang",
      "Ming Lin",
      "Senzhang Wang",
      "Xiuyu Sun",
      "Rong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04868",
    "title": "Deep object detection for waterbird monitoring using aerial imagery",
    "abstract": " Comments: Longer version of accepted short paper at 21st IEEE International Conference on Machine Learning and Applications (ICMLA'22). 7 pages, 5 figures ",
    "url": "https://arxiv.org/abs/2210.04868",
    "authors": [
      "Krish Kabra",
      "Alexander Xiong",
      "Wenbin Li",
      "Minxuan Luo",
      "William Lu",
      "Raul Garcia",
      "Dhananjay Vijay",
      "Jiahui Yu",
      "Maojie Tang",
      "Tianjiao Yu",
      "Hank Arnold",
      "Anna Vallery",
      "Richard Gibbons",
      "Arko Barman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.05479",
    "title": "Frequency-Aware Self-Supervised Monocular Depth Estimation",
    "abstract": " Comments: 8 pages, 5 figures, published to WACV2023 ",
    "url": "https://arxiv.org/abs/2210.05479",
    "authors": [
      "Xingyu Chen",
      "Thomas H. Li",
      "Ruonan Zhang",
      "Ge Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07002",
    "title": "Anonymizing Speech with Generative Adversarial Networks to Preserve  Speaker Privacy",
    "abstract": " Comments: IEEE Spoken Language Technology Workshop 2022 ",
    "url": "https://arxiv.org/abs/2210.07002",
    "authors": [
      "Sarina Meyer",
      "Pascal Tilli",
      "Pavel Denisov",
      "Florian Lux",
      "Julia Koch",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.07074",
    "title": "CLASP: Few-Shot Cross-Lingual Data Augmentation for Semantic Parsing",
    "abstract": " Comments: Accepted to AACL-IJCNLP 2022: The 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing, November 20-23, 2022. See this https URL ",
    "url": "https://arxiv.org/abs/2210.07074",
    "authors": [
      "Andy Rosenbaum",
      "Saleh Soltan",
      "Wael Hamza",
      "Amir Saffari",
      "Marco Damonte",
      "Isabel Groves"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07189",
    "title": "On Compressing Sequences for Self-Supervised Speech Models",
    "abstract": " Comments: Accepted to IEEE SLT 2022 ",
    "url": "https://arxiv.org/abs/2210.07189",
    "authors": [
      "Yen Meng",
      "Hsuan-Jui Chen",
      "Jiatong Shi",
      "Shinji Watanabe",
      "Paola Garcia",
      "Hung-yi Lee",
      "Hao Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  }
]