[
  {
    "id": "arXiv:2210.08008",
    "title": "Inductive Logical Query Answering in Knowledge Graphs",
    "abstract": "Formulating and answering logical queries is a standard communication interface for knowledge graphs (KGs). Alleviating the notorious incompleteness of real-world KGs, neural methods achieved impressive results in link prediction and complex query answering tasks by learning representations of entities, relations, and queries. Still, most existing query answering methods rely on transductive entity embeddings and cannot generalize to KGs containing new entities without retraining the entity embeddings. In this work, we study the inductive query answering task where inference is performed on a graph containing new entities with queries over both seen and unseen entities. To this end, we devise two mechanisms leveraging inductive node and relational structure representations powered by graph neural networks (GNNs). Experimentally, we show that inductive models are able to perform logical reasoning at inference time over unseen nodes generalizing to graphs up to 500% larger than training ones. Exploring the efficiency--effectiveness trade-off, we find the inductive relational structure representation method generally achieves higher performance, while the inductive node representation method is able to answer complex queries in the inference-only regime without any training on queries and scales to graphs of millions of nodes. Code is available at https://github.com/DeepGraphLearning/InductiveQE. ",
    "url": "https://arxiv.org/abs/2210.08008",
    "authors": [
      "Mikhail Galkin",
      "Zhaocheng Zhu",
      "Hongyu Ren",
      "Jian Tang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08009",
    "title": "Trajectory Prediction for Vehicle Conflict Identification at  Intersections Using Sequence-to-Sequence Recurrent Neural Networks",
    "abstract": "Surrogate safety measures in the form of conflict indicators are indispensable components of the proactive traffic safety toolbox. Conflict indicators can be classified into past-trajectory-based conflicts and predicted-trajectory-based conflicts. While the calculation of the former class of conflicts is deterministic and unambiguous, the latter category is computed using predicted vehicle trajectories and is thus more stochastic. Consequently, the accuracy of prediction-based conflicts is contingent on the accuracy of the utilized trajectory prediction algorithm. Trajectory prediction can be a challenging task, particularly at intersections where vehicle maneuvers are diverse. Furthermore, due to limitations relating to the road user trajectory extraction pipelines, accurate geometric representation of vehicles during conflict analysis is a challenging task. Misrepresented geometries distort the real distances between vehicles under observation. In this research, a prediction-based conflict identification methodology was proposed. A sequence-to-sequence Recurrent Neural Network was developed to sequentially predict future vehicle trajectories for up to 3 seconds ahead. Furthermore, the proposed network was trained using the CitySim Dataset to forecast both future vehicle positions and headings to facilitate the prediction of future bounding boxes, thus maintaining accurate vehicle geometric representations. It was experimentally determined that the proposed method outperformed frequently used trajectory prediction models for conflict analysis at intersections. A comparison between Time-to-Collision (TTC) conflict identification using vehicle bounding boxes versus the commonly used vehicle center points for geometric representation was conducted. Compared to the bounding box method, the center point approach often failed to identify TTC conflicts or underestimated their severity. ",
    "url": "https://arxiv.org/abs/2210.08009",
    "authors": [
      "Amr Abdelraouf",
      "Mohamed Abdel-Aty",
      "Zijin Wang",
      "Ou Zheng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.08011",
    "title": "Autoencoder based Anomaly Detection and Explained Fault Localization in  Industrial Cooling Systems",
    "abstract": "Anomaly detection in large industrial cooling systems is very challenging due to the high data dimensionality, inconsistent sensor recordings, and lack of labels. The state of the art for automated anomaly detection in these systems typically relies on expert knowledge and thresholds. However, data is viewed isolated and complex, multivariate relationships are neglected. In this work, we present an autoencoder based end-to-end workflow for anomaly detection suitable for multivariate time series data in large industrial cooling systems, including explained fault localization and root cause analysis based on expert knowledge. We identify system failures using a threshold on the total reconstruction error (autoencoder reconstruction error including all sensor signals). For fault localization, we compute the individual reconstruction error (autoencoder reconstruction error for each sensor signal) allowing us to identify the signals that contribute most to the total reconstruction error. Expert knowledge is provided via look-up table enabling root-cause analysis and assignment to the affected subsystem. We demonstrated our findings in a cooling system unit including 34 sensors over a 8-months time period using 4-fold cross validation approaches and automatically created labels based on thresholds provided by domain experts. Using 4-fold cross validation, we reached a F1-score of 0.56, whereas the autoencoder results showed a higher consistency score (CS of 0.92) compared to the automatically created labels (CS of 0.62) -- indicating that the anomaly is recognized in a very stable manner. The main anomaly was found by the autoencoder and automatically created labels and was also recorded in the log files. Further, the explained fault localization highlighted the most affected component for the main anomaly in a very consistent manner. ",
    "url": "https://arxiv.org/abs/2210.08011",
    "authors": [
      "Stephanie Holly",
      "Robin Heel",
      "Denis Katic",
      "Leopold Schoeffl",
      "Andreas Stiftinger",
      "Peter Holzner",
      "Thomas Kaufmann",
      "Bernhard Haslhofer",
      "Daniel Schall",
      "Clemens Heitzinger",
      "Jana Kemnitz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08031",
    "title": "Neural Attentive Circuits",
    "abstract": "Recent work has seen the development of general purpose neural architectures that can be trained to perform tasks across diverse data modalities. General purpose models typically make few assumptions about the underlying data-structure and are known to perform well in the large-data regime. At the same time, there has been growing interest in modular neural architectures that represent the data using sparsely interacting modules. These models can be more robust out-of-distribution, computationally efficient, and capable of sample-efficient adaptation to new data. However, they tend to make domain-specific assumptions about the data, and present challenges in how module behavior (i.e., parameterization) and connectivity (i.e., their layout) can be jointly learned. In this work, we introduce a general purpose, yet modular neural architecture called Neural Attentive Circuits (NACs) that jointly learns the parameterization and a sparse connectivity of neural modules without using domain knowledge. NACs are best understood as the combination of two systems that are jointly trained end-to-end: one that determines the module configuration and the other that executes it on an input. We demonstrate qualitatively that NACs learn diverse and meaningful module configurations on the NLVR2 dataset without additional supervision. Quantitatively, we show that by incorporating modularity in this way, NACs improve upon a strong non-modular baseline in terms of low-shot adaptation on CIFAR and CUBs dataset by about 10%, and OOD robustness on Tiny ImageNet-R by about 2.5%. Further, we find that NACs can achieve an 8x speedup at inference time while losing less than 3% performance. Finally, we find NACs to yield competitive results on diverse data modalities spanning point-cloud classification, symbolic processing and text-classification from ASCII bytes, thereby confirming its general purpose nature. ",
    "url": "https://arxiv.org/abs/2210.08031",
    "authors": [
      "Nasim Rahaman",
      "Martin Weiss",
      "Francesco Locatello",
      "Chris Pal",
      "Yoshua Bengio",
      "Bernhard Sch\u00f6lkopf",
      "Erran Li",
      "Nicolas Ballas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.08034",
    "title": "Empirical Network Structure of Malicious Programs",
    "abstract": "A modern binary executable is a composition of various networks. Control flow graphs are commonly used to represent an executable program in labeled datasets used for classification tasks. Control flow and term representations are widely adopted, but provide only a partial view of program semantics. This study is an empirical analysis of the networks composing malicious binaries in order to provide a complete representation of the structural properties of a program. This is accomplished by the measurement of structural properties of program networks in a malicious binary executable dataset. We demonstrate the presence of Scale-Free properties of network structure for program data dependency and control flow graphs, and show that data dependency graphs also have Small-World structural properties. We show that program data dependency graphs have a degree correlation that is structurally disassortative, and that control flow graphs have a neutral degree assortativity, indicating the use of random graphs to model the structural properties of program control flow graphs would show increased accuracy. By providing an increase in feature resolution within labeled datasets of executable programs we provide a quantitative basis to interpret the results of classifiers trained on CFG graph features. An increase in feature resolution allows for the structural properties of program classes to be analyzed for patterns as well as their component parts. By capturing a complete picture of program graphs we can enable theoretical solutions for the mapping a program's operational semantics to its structure. ",
    "url": "https://arxiv.org/abs/2210.08034",
    "authors": [
      "John Musgrave",
      "Alina Campan",
      "Temesguen Messay-Kebede",
      "David Kapp",
      "Anca Ralescu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.08041",
    "title": "Region2Vec: Community Detection on Spatial Networks Using Graph  Embedding with Node Attributes and Spatial Interactions",
    "abstract": "Community Detection algorithms are used to detect densely connected components in complex networks and reveal underlying relationships among components. As a special type of networks, spatial networks are usually generated by the connections among geographic regions. Identifying the spatial network communities can help reveal the spatial interaction patterns, understand the hidden regional structures and support regional development decision-making. Given the recent development of Graph Convolutional Networks (GCN) and its powerful performance in identifying multi-scale spatial interactions, we proposed an unsupervised GCN-based community detection method \"region2vec\" on spatial networks. Our method first generates node embeddings for regions that share common attributes and have intense spatial interactions, and then applies clustering algorithms to detect communities based on their embedding similarity and spatial adjacency. Experimental results show that while existing methods trade off either attribute similarities or spatial interactions for one another, \"region2vec\" maintains a great balance between both and performs the best when one wants to maximize both attribute similarities and spatial interactions within communities. ",
    "url": "https://arxiv.org/abs/2210.08041",
    "authors": [
      "Yunlei Liang",
      "Jiawei Zhu",
      "Wen Ye",
      "Song Gao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08042",
    "title": "Measuring Network Resilience via Geospatial Knowledge Graph: a Case  Study of the US Multi-Commodity Flow Network",
    "abstract": "Quantifying the resilience in the food system is important for food security issues. In this work, we present a geospatial knowledge graph (GeoKG)-based method for measuring the resilience of a multi-commodity flow network. Specifically, we develop a CFS-GeoKG ontology to describe geospatial semantics of a multi-commodity flow network comprehensively, and design resilience metrics that measure the node-level and network-level dependence of single-sourcing, distant, or non-adjacent suppliers/customers in food supply chains. We conduct a case study of the US state-level agricultural multi-commodity flow network with hierarchical commodity types. The results indicate that, by leveraging GeoKG, our method supports measuring both node-level and network-level resilience across space and over time and also helps discover concentration patterns of agricultural resources in the spatial network at different geographic scales. ",
    "url": "https://arxiv.org/abs/2210.08042",
    "authors": [
      "Jinmeng Rao",
      "Song Gao",
      "Michelle Miller",
      "Alfonso Morales"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08047",
    "title": "Injecting Domain Knowledge from Empirical Interatomic Potentials to  Neural Networks for Predicting Material Properties",
    "abstract": "For decades, atomistic modeling has played a crucial role in predicting the behavior of materials in numerous fields ranging from nanotechnology to drug discovery. The most accurate methods in this domain are rooted in first-principles quantum mechanical calculations such as density functional theory (DFT). Because these methods have remained computationally prohibitive, practitioners have traditionally focused on defining physically motivated closed-form expressions known as empirical interatomic potentials (EIPs) that approximately model the interactions between atoms in materials. In recent years, neural network (NN)-based potentials trained on quantum mechanical (DFT-labeled) data have emerged as a more accurate alternative to conventional EIPs. However, the generalizability of these models relies heavily on the amount of labeled training data, which is often still insufficient to generate models suitable for general-purpose applications. In this paper, we propose two generic strategies that take advantage of unlabeled training instances to inject domain knowledge from conventional EIPs to NNs in order to increase their generalizability. The first strategy, based on weakly supervised learning, trains an auxiliary classifier on EIPs and selects the best-performing EIP to generate energies to supplement the ground-truth DFT energies in training the NN. The second strategy, based on transfer learning, first pretrains the NN on a large set of easily obtainable EIP energies, and then fine-tunes it on ground-truth DFT energies. Experimental results on three benchmark datasets demonstrate that the first strategy improves baseline NN performance by 5% to 51% while the second improves baseline performance by up to 55%. Combining them further boosts performance. ",
    "url": "https://arxiv.org/abs/2210.08047",
    "authors": [
      "Zeren Shui",
      "Daniel S. Karls",
      "Mingjian Wen",
      "Ilia A. Nikiforov",
      "Ellad B. Tadmor",
      "George Karypis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2210.08057",
    "title": "Pishgu: Universal Path Prediction Architecture through Graph Isomorphism  and Attentive Convolution",
    "abstract": "Path prediction is an essential task for several real-world real-time applications, from autonomous driving and video surveillance to environmental monitoring. Most existing approaches are computation-intensive and only target a narrow domain (e.g., a specific point of view for a particular subject). However, many real-time applications demand a universal path predictor that can work across different subjects (vehicles, pedestrians), perspectives (bird's-eye, high-angle), and scenes (sidewalk, highway). This article proposes Pishgu, a universal graph isomorphism approach for attentive path prediction that accounts for environmental challenges. Pishgu captures the inter-dependencies within the subjects in each frame by taking advantage of Graph Isomorphism Networks. In addition, an attention module is adopted to represent the intrinsic relations of the subjects of interest with their surroundings. We evaluate the adaptability of our approach to multiple publicly available vehicle (bird's-eye view) and pedestrian (bird's-eye and high-angle view) path prediction datasets. Pishgu's universal solution outperforms existing domain-focused methods by producing state-of-the-art results for vehicle bird's-eye view by 42% and 61% and pedestrian high-angle views by 23% and 22% in terms of ADE and FDE, respectively. Moreover, we analyze the domain-specific details for various datasets to understand their effect on path prediction and model interpretation. Although our model is a single solution for path prediction problems and defines a new standard in multiple domains, it still has a comparable complexity to state-of-the-art models, which makes it suitable for real-world application. We also report the latency and throughput for all three domains on multiple embedded processors. ",
    "url": "https://arxiv.org/abs/2210.08057",
    "authors": [
      "Ghazal Alinezhad Noghre",
      "Vinit Katariya",
      "Armin Danesh Pazho",
      "Christopher Neff",
      "Hamed Tabkhi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.08061",
    "title": "Motion Inspired Unsupervised Perception and Prediction in Autonomous  Driving",
    "abstract": "Learning-based perception and prediction modules in modern autonomous driving systems typically rely on expensive human annotation and are designed to perceive only a handful of predefined object categories. This closed-set paradigm is insufficient for the safety-critical autonomous driving task, where the autonomous vehicle needs to process arbitrarily many types of traffic participants and their motion behaviors in a highly dynamic world. To address this difficulty, this paper pioneers a novel and challenging direction, i.e., training perception and prediction models to understand open-set moving objects, with no human supervision. Our proposed framework uses self-learned flow to trigger an automated meta labeling pipeline to achieve automatic supervision. 3D detection experiments on the Waymo Open Dataset show that our method significantly outperforms classical unsupervised approaches and is even competitive to the counterpart with supervised scene flow. We further show that our approach generates highly promising results in open-set 3D detection and trajectory prediction, confirming its potential in closing the safety gap of fully supervised systems. ",
    "url": "https://arxiv.org/abs/2210.08061",
    "authors": [
      "Mahyar Najibi",
      "Jingwei Ji",
      "Yin Zhou",
      "Charles R. Qi",
      "Xinchen Yan",
      "Scott Ettinger",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.08068",
    "title": "Whole-body tumor segmentation of 18F -FDG PET/CT using a cascaded and  ensembled convolutional neural networks",
    "abstract": "Background: A crucial initial processing step for quantitative PET/CT analysis is the segmentation of tumor lesions enabling accurate feature ex-traction, tumor characterization, oncologic staging, and image-based therapy response assessment. Manual lesion segmentation is however associated with enormous effort and cost and is thus infeasible in clinical routine. Goal: The goal of this study was to report the performance of a deep neural network designed to automatically segment regions suspected of cancer in whole-body 18F-FDG PET/CT images in the context of the AutoPET challenge. Method: A cascaded approach was developed where a stacked ensemble of 3D UNET CNN processed the PET/CT images at a fixed 6mm resolution. A refiner network composed of residual layers enhanced the 6mm segmentation mask to the original resolution. Results: 930 cases were used to train the model. 50% were histologically proven cancer patients and 50% were healthy controls. We obtained a dice=0.68 on 84 stratified test cases. Manual and automatic Metabolic Tumor Volume (MTV) were highly correlated (R2 = 0.969,Slope = 0.947). Inference time was 89.7 seconds on average. Conclusion: The proposed algorithm accurately segmented regions suspicious for cancer in whole-body 18F -FDG PET/CT images. ",
    "url": "https://arxiv.org/abs/2210.08068",
    "authors": [
      "Ludovic Sibille",
      "Xinrui Zhan",
      "Lei Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08069",
    "title": "Zonotope Domains for Lagrangian Neural Network Verification",
    "abstract": "Neural network verification aims to provide provable bounds for the output of a neural network for a given input range. Notable prior works in this domain have either generated bounds using abstract domains, which preserve some dependency between intermediate neurons in the network; or framed verification as an optimization problem and solved a relaxation using Lagrangian methods. A key drawback of the latter technique is that each neuron is treated independently, thereby ignoring important neuron interactions. We provide an approach that merges these two threads and uses zonotopes within a Lagrangian decomposition. Crucially, we can decompose the problem of verifying a deep neural network into the verification of many 2-layer neural networks. While each of these problems is provably hard, we provide efficient relaxation methods that are amenable to efficient dual ascent procedures. Our technique yields bounds that improve upon both linear programming and Lagrangian-based verification techniques in both time and bound tightness. ",
    "url": "https://arxiv.org/abs/2210.08069",
    "authors": [
      "Matt Jordan",
      "Jonathan Hayase",
      "Alexandros G. Dimakis",
      "Sewoong Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.08086",
    "title": "Knowledge Distillation approach towards Melanoma Detection",
    "abstract": "Melanoma is regarded as the most threatening among all skin cancers. There is a pressing need to build systems which can aid in the early detection of melanoma and enable timely treatment to patients. Recent methods are geared towards machine learning based systems where the task is posed as image recognition, tag dermoscopic images of skin lesions as melanoma or non-melanoma. Even though these methods show promising results in terms of accuracy, they are computationally quite expensive to train, that questions the ability of these models to be deployable in a clinical setting or memory constraint devices. To address this issue, we focus on building simple and performant models having few layers, less than ten compared to hundreds. As well as with fewer learnable parameters, 0.26 million (M) compared to 42.5M using knowledge distillation with the goal to detect melanoma from dermoscopic images. First, we train a teacher model using a ResNet-50 to detect melanoma. Using the teacher model, we train the student model known as Distilled Student Network (DSNet) which has around 0.26M parameters using knowledge distillation achieving an accuracy of 91.7%. We compare against ImageNet pre-trained models such MobileNet, VGG-16, Inception-V3, EfficientNet-B0, ResNet-50 and ResNet-101. We find that our approach works well in terms of inference runtime compared to other pre-trained models, 2.57 seconds compared to 14.55 seconds. We find that DSNet (0.26M parameters), which is 15 times smaller, consistently performs better than EfficientNet-B0 (4M parameters) in both melanoma and non-melanoma detection across Precision, Recall and F1 scores ",
    "url": "https://arxiv.org/abs/2210.08086",
    "authors": [
      "Md. Shakib Khan",
      "Kazi Nabiul Alam",
      "Abdur Rab Dhruba",
      "Hasib Zunair",
      "Nabeel Mohammed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08120",
    "title": "Towards a Fully Autonomous UAV Controller for Moving Platform Detection  and Landing",
    "abstract": "While Unmanned Aerial Vehicles (UAVs) are increasingly deployed in several missions, their inability of reliable and consistent autonomous landing poses a major setback for deploying such systems truly autonomously. In this paper we present an autonomous UAV landing system for landing on a moving platform. In contrast to existing attempts, the proposed system relies only on the camera sensor, and has been designed as lightweight as possible. The proposed system can be deployed on a low power platform as part of the drone payload, whilst being indifferent to any external communication or any other sensors. The system relies on a Neural Network (NN) based controller, for which a target and environment agnostic simulator was created, used in training and testing of the proposed system, via Reinforcement Learning (RL) and Proximal Policy optimization (PPO) to optimally control and steer the drone towards landing on the target. Through real-world testing, the system was evaluated with an average deviation of 15cm from the center of the target, for 40 landing attempts. ",
    "url": "https://arxiv.org/abs/2210.08120",
    "authors": [
      "Michalis Piponidis",
      "Panayiotis Aristodemou",
      "Theocharis Theocharides"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.08132",
    "title": "VHetNets for AI and AI for VHetNets: An Anomaly Detection Case Study for  Ubiquitous IoT",
    "abstract": "Vertical heterogenous networks (VHetNets) and artificial intelligence (AI) play critical roles in 6G and beyond networks. This article presents an AI-native VHetNets architecture to enable the synergy of VHetNets and AI, thereby supporting varieties of AI services while facilitating automatic and intelligent network management. Anomaly detection in Internet of Things (IoT) is a major AI service required by many fields, including intrusion detection, state monitoring, device-activity analysis, security supervision and so on. Conventional anomaly detection technologies mainly consider the anomaly detection as a standalone service that is independent of any other network management functionalities, which cannot be used directly in ubiquitous IoT due to the resource constrained end nodes and decentralized data distribution. In this article, we develop an AI-native VHetNets-enabled framework to provide the anomaly detection service for ubiquitous IoT, whose implementation is assisted by intelligent network management functionalities. We first discuss the possibilities of VHetNets used for distributed AI model training to provide anomaly detection service for ubiquitous IoT, i.e., VHetNets for AI. After that, we study the application of AI approaches in helping provide automatic and intelligent network management functionalities for VHetNets, i.e., AI for VHetNets, whose aim is to facilitate the efficient implementation of anomaly detection service. Finally, a case study is presented to demonstrate the efficiency and effectiveness of the proposed AI-native VHetNets-enabled anomaly detection framework. ",
    "url": "https://arxiv.org/abs/2210.08132",
    "authors": [
      "Weili Wang",
      "Omid Abbasi",
      "Halim Yanikomeroglu",
      "Chengchao Liang",
      "Lun Tang",
      "Qianbin Chen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08145",
    "title": "Self-Repetition in Abstractive Neural Summarizers",
    "abstract": "We provide a quantitative and qualitative analysis of self-repetition in the output of neural summarizers. We measure self-repetition as the number of n-grams of length four or longer that appear in multiple outputs of the same system. We analyze the behavior of three popular architectures (BART, T5, and Pegasus), fine-tuned on five datasets. In a regression analysis, we find that the three architectures have different propensities for repeating content across output summaries for inputs, with BART being particularly prone to self-repetition. Fine-tuning on more abstractive data, and on data featuring formulaic language, is associated with a higher rate of self-repetition. In qualitative analysis we find systems produce artefacts such as ads and disclaimers unrelated to the content being summarized, as well as formulaic phrases common in the fine-tuning domain. Our approach to corpus-level analysis of self-repetition may help practitioners clean up training data for summarizers and ultimately support methods for minimizing the amount of self-repetition. ",
    "url": "https://arxiv.org/abs/2210.08145",
    "authors": [
      "Nikita Salkar",
      "Thomas Trikalinos",
      "Byron C. Wallace",
      "Ani Nenkova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.08159",
    "title": "Dynamics-aware Adversarial Attack of Adaptive Neural Networks",
    "abstract": "In this paper, we investigate the dynamics-aware adversarial attack problem of adaptive neural networks. Most existing adversarial attack algorithms are designed under a basic assumption -- the network architecture is fixed throughout the attack process. However, this assumption does not hold for many recently proposed adaptive neural networks, which adaptively deactivate unnecessary execution units based on inputs to improve computational efficiency. It results in a serious issue of lagged gradient, making the learned attack at the current step ineffective due to the architecture change afterward. To address this issue, we propose a Leaded Gradient Method (LGM) and show the significant effects of the lagged gradient. More specifically, we reformulate the gradients to be aware of the potential dynamic changes of network architectures, so that the learned attack better \"leads\" the next step than the dynamics-unaware methods when network architecture changes dynamically. Extensive experiments on representative types of adaptive neural networks for both 2D images and 3D point clouds show that our LGM achieves impressive adversarial attack performance compared with the dynamic-unaware attack methods. ",
    "url": "https://arxiv.org/abs/2210.08159",
    "authors": [
      "An Tao",
      "Yueqi Duan",
      "Yingqi Wang",
      "Jiwen Lu",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08161",
    "title": "Geometric Representation Learning for Document Image Rectification",
    "abstract": "In document image rectification, there exist rich geometric constraints between the distorted image and the ground truth one. However, such geometric constraints are largely ignored in existing advanced solutions, which limits the rectification performance. To this end, we present DocGeoNet for document image rectification by introducing explicit geometric representation. Technically, two typical attributes of the document image are involved in the proposed geometric representation learning, i.e., 3D shape and textlines. Our motivation arises from the insight that 3D shape provides global unwarping cues for rectifying a distorted document image while overlooking the local structure. On the other hand, textlines complementarily provide explicit geometric constraints for local patterns. The learned geometric representation effectively bridges the distorted image and the ground truth one. Extensive experiments show the effectiveness of our framework and demonstrate the superiority of our DocGeoNet over state-of-the-art methods on both the DocUNet Benchmark dataset and our proposed DIR300 test set. The code is available at https://github.com/fh2019ustc/DocGeoNet. ",
    "url": "https://arxiv.org/abs/2210.08161",
    "authors": [
      "Hao Feng",
      "Wengang Zhou",
      "Jiajun Deng",
      "Yuechen Wang",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08168",
    "title": "MKIS-Net: A Light-Weight Multi-Kernel Network for Medical Image  Segmentation",
    "abstract": "Image segmentation is an important task in medical imaging. It constitutes the backbone of a wide variety of clinical diagnostic methods, treatments, and computer-aided surgeries. In this paper, we propose a multi-kernel image segmentation net (MKIS-Net), which uses multiple kernels to create an efficient receptive field and enhance segmentation performance. As a result of its multi-kernel design, MKIS-Net is a light-weight architecture with a small number of trainable parameters. Moreover, these multi-kernel receptive fields also contribute to better segmentation results. We demonstrate the efficacy of MKIS-Net on several tasks including segmentation of retinal vessels, skin lesion segmentation, and chest X-ray segmentation. The performance of the proposed network is quite competitive, and often superior, in comparison to state-of-the-art methods. Moreover, in some cases MKIS-Net has more than an order of magnitude fewer trainable parameters than existing medical image segmentation alternatives and is at least four times smaller than other light-weight architectures. ",
    "url": "https://arxiv.org/abs/2210.08168",
    "authors": [
      "Tariq M. Khan",
      "Muhammad Arsalan",
      "Antonio Robles-Kelly",
      "Erik Meijering"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08169",
    "title": "Self-supervised Graph Learning for Long-tailed Cognitive Diagnosis",
    "abstract": "Cognitive diagnosis is a fundamental yet critical research task in the field of intelligent education, which aims to discover the proficiency level of different students on specific knowledge concepts. Despite the effectiveness of existing efforts, previous methods always considered the mastery level on the whole students, so they still suffer from the Long Tail Effect. A large number of students who have sparse data are performed poorly in the model. To relieve the situation, we proposed a Self-supervised Cognitive Diagnosis (SCD) framework which leverages the self-supervised manner to assist the graph-based cognitive diagnosis, then the performance on those students with sparse data can be improved. Specifically, we came up with a graph confusion method that drops edges under some special rules to generate different sparse views of the graph. By maximizing the consistency of the representation on the same node under different views, the model could be more focused on long-tailed students. Additionally, we proposed an importance-based view generation rule to improve the influence of long-tailed students. Extensive experiments on real-world datasets show the effectiveness of our approach, especially on the students with sparse data. ",
    "url": "https://arxiv.org/abs/2210.08169",
    "authors": [
      "Shanshan Wang",
      "Zhen Zeng",
      "Xun Yang",
      "Xingyi Zhang"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08170",
    "title": "Attention Regularized Laplace Graph for Domain Adaptation",
    "abstract": "In leveraging manifold learning in domain adaptation (DA), graph embedding-based DA methods have shown their effectiveness in preserving data manifold through the Laplace graph. However, current graph embedding DA methods suffer from two issues: 1). they are only concerned with preservation of the underlying data structures in the embedding and ignore sub-domain adaptation, which requires taking into account intra-class similarity and inter-class dissimilarity, thereby leading to negative transfer; 2). manifold learning is proposed across different feature/label spaces separately, thereby hindering unified comprehensive manifold learning. In this paper, starting from our previous DGA-DA, we propose a novel DA method, namely Attention Regularized Laplace Graph-based Domain Adaptation (ARG-DA), to remedy the aforementioned issues. Specifically, by weighting the importance across different sub-domain adaptation tasks, we propose the Attention Regularized Laplace Graph for class-aware DA, thereby generating the attention regularized DA. Furthermore, using a specifically designed FEEL strategy, our approach dynamically unifies alignment of the manifold structures across different feature/label spaces, thus leading to comprehensive manifold learning. Comprehensive experiments are carried out to verify the effectiveness of the proposed DA method, which consistently outperforms the state-of-the-art DA methods on 7 standard DA benchmarks, i.e., 37 cross-domain image classification tasks including object, face, and digit images. An in-depth analysis of the proposed DA method is also discussed, including sensitivity, convergence, and robustness. ",
    "url": "https://arxiv.org/abs/2210.08170",
    "authors": [
      "Lingkun Luo",
      "Liming Chen",
      "Shiqiang Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08181",
    "title": "Panchromatic and Multispectral Image Fusion via Alternating Reverse  Filtering Network",
    "abstract": "Panchromatic (PAN) and multi-spectral (MS) image fusion, named Pan-sharpening, refers to super-resolve the low-resolution (LR) multi-spectral (MS) images in the spatial domain to generate the expected high-resolution (HR) MS images, conditioning on the corresponding high-resolution PAN images. In this paper, we present a simple yet effective \\textit{alternating reverse filtering network} for pan-sharpening. Inspired by the classical reverse filtering that reverses images to the status before filtering, we formulate pan-sharpening as an alternately iterative reverse filtering process, which fuses LR MS and HR MS in an interpretable manner. Different from existing model-driven methods that require well-designed priors and degradation assumptions, the reverse filtering process avoids the dependency on pre-defined exact priors. To guarantee the stability and convergence of the iterative process via contraction mapping on a metric space, we develop the learnable multi-scale Gaussian kernel module, instead of using specific filters. We demonstrate the theoretical feasibility of such formulations. Extensive experiments on diverse scenes to thoroughly verify the performance of our method, significantly outperforming the state of the arts. ",
    "url": "https://arxiv.org/abs/2210.08181",
    "authors": [
      "Keyu Yan",
      "Man Zhou",
      "Jie Huang",
      "Feng Zhao",
      "Chengjun Xie",
      "Chongyi Li",
      "Danfeng Hong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08182",
    "title": "Learning Invariant Representation and Risk Minimized for Unsupervised  Accent Domain Adaptation",
    "abstract": "Unsupervised representation learning for speech audios attained impressive performances for speech recognition tasks, particularly when annotated speech is limited. However, the unsupervised paradigm needs to be carefully designed and little is known about what properties these representations acquire. There is no guarantee that the model learns meaningful representations for valuable information for recognition. Moreover, the adaptation ability of the learned representations to other domains still needs to be estimated. In this work, we explore learning domain-invariant representations via a direct mapping of speech representations to their corresponding high-level linguistic informations. Results prove that the learned latents not only capture the articulatory feature of each phoneme but also enhance the adaptation ability, outperforming the baseline largely on accented benchmarks. ",
    "url": "https://arxiv.org/abs/2210.08182",
    "authors": [
      "Chendong Zhao",
      "Jianzong Wang",
      "Xiaoyang Qu",
      "Haoqian Wang",
      "Jing Xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.08185",
    "title": "GFlowCausal: Generative Flow Networks for Causal Discovery",
    "abstract": "Causal discovery aims to uncover causal structure among a set of variables. Score-based approaches mainly focus on searching for the best Directed Acyclic Graph (DAG) based on a predefined score function. However, most of them are not applicable on a large scale due to the limited searchability. Inspired by the active learning in generative flow networks, we propose a novel approach to learning a DAG from observational data called GFlowCausal. It converts the graph search problem to a generation problem, in which direct edges are added gradually. GFlowCausal aims to learn the best policy to generate high-reward DAGs by sequential actions with probabilities proportional to predefined rewards. We propose a plug-and-play module based on transitive closure to ensure efficient sampling. Theoretical analysis shows that this module could guarantee acyclicity properties effectively and the consistency between final states and fully-connected graphs. We conduct extensive experiments on both synthetic and real datasets, and results show the proposed approach to be superior and also performs well in a large-scale setting. ",
    "url": "https://arxiv.org/abs/2210.08185",
    "authors": [
      "Wenqian Li",
      "Yinchuan Li",
      "Shengyu Zhu",
      "Yunfeng Shao",
      "Jianye Hao",
      "Yan Pang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08189",
    "title": "Parameter-free Dynamic Graph Embedding for Link Prediction",
    "abstract": "Dynamic interaction graphs have been widely adopted to model the evolution of user-item interactions over time. There are two crucial factors when modelling user preferences for link prediction in dynamic interaction graphs: 1) collaborative relationship among users and 2) user personalized interaction patterns. Existing methods often implicitly consider these two factors together, which may lead to noisy user modelling when the two factors diverge. In addition, they usually require time-consuming parameter learning with back-propagation, which is prohibitive for real-time user preference modelling. To this end, this paper proposes FreeGEM, a parameter-free dynamic graph embedding method for link prediction. Firstly, to take advantage of the collaborative relationships, we propose an incremental graph embedding engine to obtain user/item embeddings, which is an Online-Monitor-Offline architecture consisting of an Online module to approximately embed users/items over time, a Monitor module to estimate the approximation error in real time and an Offline module to calibrate the user/item embeddings when the online approximation errors exceed a threshold. Meanwhile, we integrate attribute information into the model, which enables FreeGEM to better model users belonging to some under represented groups. Secondly, we design a personalized dynamic interaction pattern modeller, which combines dynamic time decay with attention mechanism to model user short-term interests. Experimental results on two link prediction tasks show that FreeGEM can outperform the state-of-the-art methods in accuracy while achieving over 36X improvement in efficiency. All code and datasets can be found in https://github.com/FudanCISL/FreeGEM. ",
    "url": "https://arxiv.org/abs/2210.08189",
    "authors": [
      "Jiahao Liu",
      "Dongsheng Li",
      "Hansu Gu",
      "Tun Lu",
      "Peng Zhang",
      "Ning Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.08195",
    "title": "HP-GMN: Graph Memory Networks for Heterophilous Graphs",
    "abstract": "Graph neural networks (GNNs) have achieved great success in various graph problems. However, most GNNs are Message Passing Neural Networks (MPNNs) based on the homophily assumption, where nodes with the same label are connected in graphs. Real-world problems bring us heterophily problems, where nodes with different labels are connected in graphs. MPNNs fail to address the heterophily problem because they mix information from different distributions and are not good at capturing global patterns. Therefore, we investigate a novel Graph Memory Networks model on Heterophilous Graphs (HP-GMN) to the heterophily problem in this paper. In HP-GMN, local information and global patterns are learned by local statistics and the memory to facilitate the prediction. We further propose regularization terms to help the memory learn global information. We conduct extensive experiments to show that our method achieves state-of-the-art performance on both homophilous and heterophilous graphs. ",
    "url": "https://arxiv.org/abs/2210.08195",
    "authors": [
      "Junjie Xu",
      "Enyan Dai",
      "Xiang Zhang",
      "Suhang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08197",
    "title": "DyFEn: Agent-Based Fee Setting in Payment Channel Networks",
    "abstract": "In recent years, with the development of easy to use learning environments, implementing and reproducible benchmarking of reinforcement learning algorithms has been largely accelerated by utilizing these frameworks. In this article, we introduce the Dynamic Fee learning Environment (DyFEn), an open-source real-world financial network model. It can provide a testbed for evaluating different reinforcement learning techniques. To illustrate the promise of DyFEn, we present a challenging problem which is a simultaneous multi-channel dynamic fee setting for off-chain payment channels. This problem is well-known in the Bitcoin Lightning Network and has no effective solutions. Specifically, we report the empirical results of several commonly used deep reinforcement learning methods on this dynamic fee setting task as a baseline for further experiments. To the best of our knowledge, this work proposes the first virtual learning environment based on a simulation of blockchain and distributed ledger technologies, unlike many others which are based on physics simulations or game platforms. ",
    "url": "https://arxiv.org/abs/2210.08197",
    "authors": [
      "Kiana Asgari",
      "Aida Afshar Mohammadian",
      "Mojtaba Tefagh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Finance (q-fin.MF)"
    ]
  },
  {
    "id": "arXiv:2210.08198",
    "title": "Distributionally Robust Multiclass Classification and Applications in  Deep Image Classifiers",
    "abstract": "We develop a Distributionally Robust Optimization (DRO) formulation for Multiclass Logistic Regression (MLR), which could tolerate data contaminated by outliers. The DRO framework uses a probabilistic ambiguity set defined as a ball of distributions that are close to the empirical distribution of the training set in the sense of the Wasserstein metric. We relax the DRO formulation into a regularized learning problem whose regularizer is a norm of the coefficient matrix. We establish out-of-sample performance guarantees for the solutions to our model, offering insights on the role of the regularizer in controlling the prediction error. We apply the proposed method in rendering deep Vision Transformer (ViT)-based image classifiers robust to random and adversarial attacks. Specifically, using the MNIST and CIFAR-10 datasets, we demonstrate reductions in test error rate by up to 83.5% and loss by up to 91.3% compared with baseline methods, by adopting a novel random training method. ",
    "url": "https://arxiv.org/abs/2210.08198",
    "authors": [
      "Ruidi Chen",
      "Boran Hao",
      "Ioannis Ch. Paschalidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08202",
    "title": "IBL-NeRF: Image-Based Lighting Formulation of Neural Radiance Fields",
    "abstract": "We propose IBL-NeRF, which decomposes the neural radiance fields (NeRF) of large-scale indoor scenes into intrinsic components. Previous approaches for the inverse rendering of NeRF transform the implicit volume to fit the rendering pipeline of explicit geometry, and approximate the views of segmented, isolated objects with environment lighting. In contrast, our inverse rendering extends the original NeRF formulation to capture the spatial variation of lighting within the scene volume, in addition to surface properties. Specifically, the scenes of diverse materials are decomposed into intrinsic components for image-based rendering, namely, albedo, roughness, surface normal, irradiance, and prefiltered radiance. All of the components are inferred as neural images from MLP, which can model large-scale general scenes. By adopting the image-based formulation of NeRF, our approach inherits superior visual quality and multi-view consistency for synthesized images. We demonstrate the performance on scenes with complex object layouts and light configurations, which could not be processed in any of the previous works. ",
    "url": "https://arxiv.org/abs/2210.08202",
    "authors": [
      "Changwoon Choi",
      "Juhyeon Kim",
      "Young Min Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08209",
    "title": "Large Language Models for Multi-label Propaganda Detection",
    "abstract": "The spread of propaganda through the internet has increased drastically over the past years. Lately, propaganda detection has started gaining importance because of the negative impact it has on society. In this work, we describe our approach for the WANLP 2022 shared task which handles the task of propaganda detection in a multi-label setting. The task demands the model to label the given text as having one or more types of propaganda techniques. There are a total of 22 propaganda techniques to be detected. We show that an ensemble of five models performs the best on the task, scoring a micro-F1 score of 59.73%. We also conduct comprehensive ablations and propose various future directions for this work. ",
    "url": "https://arxiv.org/abs/2210.08209",
    "authors": [
      "Tanmay Chavan",
      "Aditya Kane"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.08210",
    "title": "Providing Error Detection for Deep Learning Image Classifiers Using  Self-Explainability",
    "abstract": "This paper proposes a self-explainable Deep Learning (SE-DL) system for an image classification problem that performs self-error detection. The self-error detection is key to improving the DL system's safe operation, especially in safety-critical applications such as automotive systems. A SE-DL system outputs both the class prediction and an explanation for that prediction, which provides insight into how the system makes its predictions for humans. Additionally, we leverage the explanation of the proposed SE-DL system to detect potential class prediction errors of the system. The proposed SE-DL system uses a set of concepts to generate the explanation. The concepts are human-understandable lower-level image features in each input image relevant to the higher-level class of that image. We present a concept selection methodology for scoring all concepts and selecting a subset of them based on their contribution to the error detection performance of the proposed SE-DL system. Finally, we present different error detection schemes using the proposed SE-DL system to compare them against an error detection scheme without any SE-DL system. ",
    "url": "https://arxiv.org/abs/2210.08210",
    "authors": [
      "Mohammad Mahdi Karimi",
      "Azin Heidarshenas",
      "William W. Edmonson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08212",
    "title": "D.MCA: Outlier Detection with Explicit Micro-Cluster Assignments",
    "abstract": "How can we detect outliers, both scattered and clustered, and also explicitly assign them to respective micro-clusters, without knowing apriori how many micro-clusters exist? How can we perform both tasks in-house, i.e., without any post-hoc processing, so that both detection and assignment can benefit simultaneously from each other? Presenting outliers in separate micro-clusters is informative to analysts in many real-world applications. However, a na\\\"ive solution based on post-hoc clustering of the outliers detected by any existing method suffers from two main drawbacks: (a) appropriate hyperparameter values are commonly unknown for clustering, and most algorithms struggle with clusters of varying shapes and densities; (b) detection and assignment cannot benefit from one another. In this paper, we propose D.MCA to $\\underline{D}$etect outliers with explicit $\\underline{M}$icro-$\\underline{C}$luster $\\underline{A}$ssignment. Our method performs both detection and assignment iteratively, and in-house, by using a novel strategy that prunes entire micro-clusters out of the training set to improve the performance of the detection. It also benefits from a novel strategy that avoids clustered outliers to mask each other, which is a well-known problem in the literature. Also, D.MCA is designed to be robust to a critical hyperparameter by employing a hyperensemble \"warm up\" phase. Experiments performed on 16 real-world and synthetic datasets demonstrate that D.MCA outperforms 8 state-of-the-art competitors, especially on the explicit outlier micro-cluster assignment task. ",
    "url": "https://arxiv.org/abs/2210.08212",
    "authors": [
      "Shuli Jiang",
      "Robson Leonardo Ferreira Cordeiro",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08219",
    "title": "Unveiling the Sampling Density in Non-Uniform Geometric Graphs",
    "abstract": "A powerful framework for studying graphs is to consider them as geometric graphs: nodes are randomly sampled from an underlying metric space, and any pair of nodes is connected if their distance is less than a specified neighborhood radius. Currently, the literature mostly focuses on uniform sampling and constant neighborhood radius. However, real-world graphs are likely to be better represented by a model in which the sampling density and the neighborhood radius can both vary over the latent space. For instance, in a social network communities can be modeled as densely sampled areas, and hubs as nodes with larger neighborhood radius. In this work, we first perform a rigorous mathematical analysis of this (more general) class of models, including derivations of the resulting graph shift operators. The key insight is that graph shift operators should be corrected in order to avoid potential distortions introduced by the non-uniform sampling. Then, we develop methods to estimate the unknown sampling density in a self-supervised fashion. Finally, we present exemplary applications in which the learnt density is used to 1) correct the graph shift operator and improve performance on a variety of tasks, 2) improve pooling, and 3) extract knowledge from networks. Our experimental findings support our theory and provide strong evidence for our model. ",
    "url": "https://arxiv.org/abs/2210.08219",
    "authors": [
      "Raffaele Paolino",
      "Aleksandar Bojchevski",
      "Stephan G\u00fcnnemann",
      "Gitta Kutyniok",
      "Ron Levie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08243",
    "title": "Substructure-Atom Cross Attention for Molecular Representation Learning",
    "abstract": "Designing a neural network architecture for molecular representation is crucial for AI-driven drug discovery and molecule design. In this work, we propose a new framework for molecular representation learning. Our contribution is threefold: (a) demonstrating the usefulness of incorporating substructures to node-wise features from molecules, (b) designing two branch networks consisting of a transformer and a graph neural network so that the networks fused with asymmetric attention, and (c) not requiring heuristic features and computationally-expensive information from molecules. Using 1.8 million molecules collected from ChEMBL and PubChem database, we pretrain our network to learn a general representation of molecules with minimal supervision. The experimental results show that our pretrained network achieves competitive performance on 11 downstream tasks for molecular property prediction. ",
    "url": "https://arxiv.org/abs/2210.08243",
    "authors": [
      "Jiye Kim",
      "Seungbeom Lee",
      "Dongwoo Kim",
      "Sungsoo Ahn",
      "Jaesik Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08244",
    "title": "Extreme-Long-short Term Memory for Time-series Prediction",
    "abstract": "The emergence of Long Short-Term Memory (LSTM) solves the problems of vanishing gradient and exploding gradient in traditional Recurrent Neural Networks (RNN). LSTM, as a new type of RNN, has been widely used in various fields, such as text prediction, Wind Speed Forecast, depression prediction by EEG signals, etc. The results show that improving the efficiency of LSTM can help to improve the efficiency in other application areas. In this paper, we proposed an advanced LSTM algorithm, the Extreme Long Short-Term Memory (E-LSTM), which adds the inverse matrix part of Extreme Learning Machine (ELM) as a new \"gate\" into the structure of LSTM. This \"gate\" preprocess a portion of the data and involves the processed data in the cell update of the LSTM to obtain more accurate data with fewer training rounds, thus reducing the overall training time. In this research, the E-LSTM model is used for the text prediction task. Experimental results showed that the E-LSTM sometimes takes longer to perform a single training round, but when tested on a small data set, the new E-LSTM requires only 2 epochs to obtain the results of the 7th epoch traditional LSTM. Therefore, the E-LSTM retains the high accuracy of the traditional LSTM, whilst also improving the training speed and the overall efficiency of the LSTM. ",
    "url": "https://arxiv.org/abs/2210.08244",
    "authors": [
      "Sida Xing",
      "Feihu Han",
      "Suiyang Khoo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08251",
    "title": "Improving Your Graph Neural Networks: A High-Frequency Booster",
    "abstract": "Graph neural networks (GNNs) hold the promise of learning efficient representations of graph-structured data, and one of its most important applications is semi-supervised node classification. However, in this application, GNN frameworks tend to fail due to the following issues: over-smoothing and heterophily. The most popular GNNs are known to be focused on the message-passing framework, and recent research shows that these GNNs are often bounded by low-pass filters from a signal processing perspective. We thus incorporate high-frequency information into GNNs to alleviate this genetic problem. In this paper, we argue that the complement of the original graph incorporates a high-pass filter and propose Complement Laplacian Regularization (CLAR) for an efficient enhancement of high-frequency components. The experimental results demonstrate that CLAR helps GNNs tackle over-smoothing, improving the expressiveness of heterophilic graphs, which adds up to 3.6% improvement over popular baselines and ensures topological robustness. ",
    "url": "https://arxiv.org/abs/2210.08251",
    "authors": [
      "Jiaqi Sun",
      "Lin Zhang",
      "Shenglin Zhao",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08252",
    "title": "DI-NIDS: Domain Invariant Network Intrusion Detection System",
    "abstract": "The performance of machine learning based network intrusion detection systems (NIDSs) severely degrades when deployed on a network with significantly different feature distributions from the ones of the training dataset. In various applications, such as computer vision, domain adaptation techniques have been successful in mitigating the gap between the distributions of the training and test data. In the case of network intrusion detection however, the state-of-the-art domain adaptation approaches have had limited success. According to recent studies, as well as our own results, the performance of an NIDS considerably deteriorates when the `unseen' test dataset does not follow the training dataset distribution. In some cases, swapping the train and test datasets makes this even more severe. In order to enhance the generalisibility of machine learning based network intrusion detection systems, we propose to extract domain invariant features using adversarial domain adaptation from multiple network domains, and then apply an unsupervised technique for recognising abnormalities, i.e., intrusions. More specifically, we train a domain adversarial neural network on labelled source domains, extract the domain invariant features, and train a One-Class SVM (OSVM) model to detect anomalies. At test time, we feedforward the unlabeled test data to the feature extractor network to project it into a domain invariant space, and then apply OSVM on the extracted features to achieve our final goal of detecting intrusions. Our extensive experiments on the NIDS benchmark datasets of NFv2-CIC-2018 and NFv2-UNSW-NB15 show that our proposed setup demonstrates superior cross-domain performance in comparison to the previous approaches. ",
    "url": "https://arxiv.org/abs/2210.08252",
    "authors": [
      "Siamak Layeghy",
      "Mahsa Baktashmotlagh",
      "Marius Portmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.08262",
    "title": "Motion estimation and filtered prediction for dynamic point cloud  attribute compression",
    "abstract": "In point cloud compression, exploiting temporal redundancy for inter predictive coding is challenging because of the irregular geometry. This paper proposes an efficient block-based inter-coding scheme for color attribute compression. The scheme includes integer-precision motion estimation and an adaptive graph based in-loop filtering scheme for improved attribute prediction. The proposed block-based motion estimation scheme consists of an initial motion search that exploits geometric and color attributes, followed by a motion refinement that only minimizes color prediction error. To further improve color prediction, we propose a vertex-domain low-pass graph filtering scheme that can adaptively remove noise from predictors computed from motion estimation with different accuracy. Our experiments demonstrate significant coding gain over state-of-the-art coding methods. ",
    "url": "https://arxiv.org/abs/2210.08262",
    "authors": [
      "Haoran Hong",
      "Eduardo Pavez",
      "Antonio Ortega",
      "Ryosuke Watanabe",
      "Keisuke Nonaka"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.08270",
    "title": "Assessing the Solid Protocol in Relation to Security & Privacy  Obligations",
    "abstract": "The Solid specification aims to empower data subjects by giving them direct access control over their data across multiple applications. As governments are manifesting their interest in this framework for citizen empowerment and e-government services, security and privacy represent pivotal issues to be addressed. By analyzing the relevant legislation, notably GDPR, and international standards, namely ISO/IEC 27001:2011 and 15408, we formulate the primary security and privacy requirements for such a framework. Furthermore, we survey the current Solid protocol specifications regarding how they cover the highlighted requirements, and draw attention to potential gaps between the specifications and requirements. We also point out the contribution of recent academic work presenting novel approaches to increase the security and privacy degree provided by the Solid project. This paper has a twofold contribution to improve user awareness of how Solid can help protect their data and to present possible future research lines on Solid security and privacy enhancements. ",
    "url": "https://arxiv.org/abs/2210.08270",
    "authors": [
      "Christian Esposito",
      "Olaf Hartig",
      "Ross Horne",
      "Chang Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.08273",
    "title": "Classification of Web Phishing Kits for early detection by platform  providers",
    "abstract": "Phishing kits are tools that dark side experts provide to the community of criminal phishers to facilitate the construction of malicious Web sites. As these kits evolve in sophistication, providers of Web-based services need to keep pace with continuous complexity. We present an original classification of a corpus of over 2000 recent phishing kits according to their adopted evasion and obfuscation functions. We carry out an initial deterministic analysis of the source code of the kits to extract the most discriminant features and information about their principal authors. We then integrate this initial classification through supervised machine learning models. Thanks to the ground-truth achieved in the first step, we can demonstrate whether and which machine learning models are able to suitably classify even the kits adopting novel evasion and obfuscation techniques that were unseen during the training phase. We compare different algorithms and evaluate their robustness in the realistic case in which only a small number of phishing kits are available for training. This paper represents an initial but important step to support Web service providers and analysts in improving early detection mechanisms and intelligence operations for the phishing kits that might be installed on their platforms. ",
    "url": "https://arxiv.org/abs/2210.08273",
    "authors": [
      "Andrea Venturi",
      "Michele Colajanni",
      "Marco Ramilli",
      "Giorgio Valenziano Santangelo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08274",
    "title": "CLARE: A Semi-supervised Community Detection Algorithm",
    "abstract": "Community detection refers to the task of discovering closely related subgraphs to understand the networks. However, traditional community detection algorithms fail to pinpoint a particular kind of community. This limits its applicability in real-world networks, e.g., distinguishing fraud groups from normal ones in transaction networks. Recently, semi-supervised community detection emerges as a solution. It aims to seek other similar communities in the network with few labeled communities as training data. Existing works can be regarded as seed-based: locate seed nodes and then develop communities around seeds. However, these methods are quite sensitive to the quality of selected seeds since communities generated around a mis-detected seed may be irrelevant. Besides, they have individual issues, e.g., inflexibility and high computational overhead. To address these issues, we propose CLARE, which consists of two key components, Community Locator and Community Rewriter. Our idea is that we can locate potential communities and then refine them. Therefore, the community locator is proposed for quickly locating potential communities by seeking subgraphs that are similar to training ones in the network. To further adjust these located communities, we devise the community rewriter. Enhanced by deep reinforcement learning, it suggests intelligent decisions, such as adding or dropping nodes, to refine community structures flexibly. Extensive experiments verify both the effectiveness and efficiency of our work compared with prior state-of-the-art approaches on multiple real-world datasets. ",
    "url": "https://arxiv.org/abs/2210.08274",
    "authors": [
      "Xixi Wu",
      "Yun Xiong",
      "Yao Zhang",
      "Yizhu Jiao",
      "Caihua Shan",
      "Yiheng Sun",
      "Yangyong Zhu",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.08277",
    "title": "Deep Differentiable Logic Gate Networks",
    "abstract": "Recently, research has increasingly focused on developing efficient neural network architectures. In this work, we explore logic gate networks for machine learning tasks by learning combinations of logic gates. These networks comprise logic gates such as \"AND\" and \"XOR\", which allow for very fast execution. The difficulty in learning logic gate networks is that they are conventionally non-differentiable and therefore do not allow training with gradient descent. Thus, to allow for effective training, we propose differentiable logic gate networks, an architecture that combines real-valued logics and a continuously parameterized relaxation of the network. The resulting discretized logic gate networks achieve fast inference speeds, e.g., beyond a million images of MNIST per second on a single CPU core. ",
    "url": "https://arxiv.org/abs/2210.08277",
    "authors": [
      "Felix Petersen",
      "Christian Borgelt",
      "Hilde Kuehne",
      "Oliver Deussen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08281",
    "title": "Man-in-the-OBD: A modular, protocol agnostic firewall for automotive  dongles to enhance privacy and security",
    "abstract": "Third-party dongles for cars, e.g. from insurance companies, can extract sensitive data and even send commands to the car via the standardized OBD-II interface. Due to the lack of message authentication mechanisms, this leads to major security vulnerabilities for example regarding the connection with malicious devices. Therefore, we apply a modular, protocol-independent firewall approach by placing a man-in-the-middle between the third-party dongle and the car's OBD-II interface. With this privileged network position, we demonstrate how the data flow accessible through the OBD-II interface can be modified or restricted. We can modify the messages contents or delay the arrival of messages by using our fine-granular configurable rewriting rules, specifically designed to work protocol agnostic. We have implemented our modular approach for a configurable firewall at the OBD-II interface and successfully tested it against third-party dongles available on the market. Thus, our approach enables a security layer to enhance automotive privacy and security of dongle users, which is of high relevance due to missing message authentications on the level of the electronic control units. ",
    "url": "https://arxiv.org/abs/2210.08281",
    "authors": [
      "Felix Klement",
      "Henrich C. P\u00f6hls",
      "Stefan Katzenbeisser"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.08290",
    "title": "Prediction Calibration for Generalized Few-shot Semantic Segmentation",
    "abstract": "Generalized Few-shot Semantic Segmentation (GFSS) aims to segment each image pixel into either base classes with abundant training examples or novel classes with only a handful of (e.g., 1-5) training images per class. Compared to the widely studied Few-shot Semantic Segmentation FSS, which is limited to segmenting novel classes only, GFSS is much under-studied despite being more practical. Existing approach to GFSS is based on classifier parameter fusion whereby a newly trained novel class classifier and a pre-trained base class classifier are combined to form a new classifier. As the training data is dominated by base classes, this approach is inevitably biased towards the base classes. In this work, we propose a novel Prediction Calibration Network PCN to address this problem. Instead of fusing the classifier parameters, we fuse the scores produced separately by the base and novel classifiers. To ensure that the fused scores are not biased to either the base or novel classes, a new Transformer-based calibration module is introduced. It is known that the lower-level features are useful of detecting edge information in an input image than higher-level features. Thus, we build a cross-attention module that guides the classifier's final prediction using the fused multi-level features. However, transformers are computationally demanding. Crucially, to make the proposed cross-attention module training tractable at the pixel level, this module is designed based on feature-score cross-covariance and episodically trained to be generalizable at inference time. Extensive experiments on PASCAL-$5^{i}$ and COCO-$20^{i}$ show that our PCN outperforms the state-the-the-art alternatives by large margins. ",
    "url": "https://arxiv.org/abs/2210.08290",
    "authors": [
      "Zhihe Lu",
      "Sen He",
      "Da Li",
      "Yi-Zhe Song",
      "Tao Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08291",
    "title": "Bidirectional Semi-supervised Dual-branch CNN for Robust 3D  Reconstruction of Stereo Endoscopic Images via Adaptive Cross and Parallel  Supervisions",
    "abstract": "Semi-supervised learning via teacher-student network can train a model effectively on a few labeled samples. It enables a student model to distill knowledge from the teacher's predictions of extra unlabeled data. However, such knowledge flow is typically unidirectional, having the performance vulnerable to the quality of teacher model. In this paper, we seek to robust 3D reconstruction of stereo endoscopic images by proposing a novel fashion of bidirectional learning between two learners, each of which can play both roles of teacher and student concurrently. Specifically, we introduce two self-supervisions, i.e., Adaptive Cross Supervision (ACS) and Adaptive Parallel Supervision (APS), to learn a dual-branch convolutional neural network. The two branches predict two different disparity probability distributions for the same position, and output their expectations as disparity values. The learned knowledge flows across branches along two directions: a cross direction (disparity guides distribution in ACS) and a parallel direction (disparity guides disparity in APS). Moreover, each branch also learns confidences to dynamically refine its provided supervisions. In ACS, the predicted disparity is softened into a unimodal distribution, and the lower the confidence, the smoother the distribution. In APS, the incorrect predictions are suppressed by lowering the weights of those with low confidence. With the adaptive bidirectional learning, the two branches enjoy well-tuned supervisions from each other, and eventually converge on a consistent and more accurate disparity estimation. The experimental results on three public datasets demonstrate our superior performance over other state-of-the-arts with a decrease of averaged disparity error by at least 9.76%. ",
    "url": "https://arxiv.org/abs/2210.08291",
    "authors": [
      "Hongkuan Shi",
      "Zhiwei Wang",
      "Ying Zhou",
      "Dun Li",
      "Xin Yang",
      "Qiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08293",
    "title": "Approximate Graph Colouring and Crystals",
    "abstract": "We show that approximate graph colouring is not solved by any level of the affine integer programming (AIP) hierarchy. To establish the result, we translate the problem of exhibiting a graph fooling a level of the AIP hierarchy into the problem of constructing a highly symmetric crystal tensor. In order to prove the existence of crystals in arbitrary dimension, we provide a combinatorial characterisation for realisable systems of tensors; i.e., sets of low-dimensional tensors that can be realised as the projections of a single high-dimensional tensor. ",
    "url": "https://arxiv.org/abs/2210.08293",
    "authors": [
      "Lorenzo Ciardo",
      "Stanislav \u017divn\u00fd"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2210.08295",
    "title": "A Secure Federated Data-Driven Evolutionary Multi-objective Optimization  Algorithm",
    "abstract": "Data-driven evolutionary algorithms usually aim to exploit the information behind a limited amount of data to perform optimization, which have proved to be successful in solving many complex real-world optimization problems. However, most data-driven evolutionary algorithms are centralized, causing privacy and security concerns. Existing federated Bayesian algorithms and data-driven evolutionary algorithms mainly protect the raw data on each client. To address this issue, this paper proposes a secure federated data-driven evolutionary multi-objective optimization algorithm to protect both the raw data and the newly infilled solutions obtained by optimizing the acquisition function conducted on the server. We select the query points on a randomly selected client at each round of surrogate update by calculating the acquisition function values of the unobserved points on this client, thereby reducing the risk of leaking the information about the solution to be sampled. In addition, since the predicted objective values of each client may contain sensitive information, we mask the objective values with Diffie-Hellmann-based noise, and then send only the masked objective values of other clients to the selected client via the server. Since the calculation of the acquisition function also requires both the predicted objective value and the uncertainty of the prediction, the predicted mean objective and uncertainty are normalized to reduce the influence of noise. Experimental results on a set of widely used multi-objective optimization benchmarks show that the proposed algorithm can protect privacy and enhance security with only negligible sacrifice in the performance of federated data-driven evolutionary optimization. ",
    "url": "https://arxiv.org/abs/2210.08295",
    "authors": [
      "Qiqi Liu",
      "Yuping Yan",
      "Peter Ligeti",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.08316",
    "title": "Call Graph Evolution Analytics over a Version Series of an Evolving  Software System",
    "abstract": "Call Graph evolution analytics can aid a software engineer when maintaining or evolving a software system. This paper proposes Call Graph Evolution Analytics to extract information from an evolving call graph ECG = CG_1, CG_2,... CG_N for their version series VS = V_1, V_2, ... V_N of an evolving software system. This is done using Call Graph Evolution Rules (CGERs) and Call Graph Evolution Subgraphs (CGESs). Similar to association rule mining, the CGERs are used to capture co-occurrences of dependencies in the system. Like subgraph patterns in a call graph, the CGESs are used to capture evolution of dependency patterns in evolving call graphs. Call graph analytics on the evolution in these patterns can identify potentially affected dependencies (or procedure calls) that need attention. The experiments are done on the evolving call graphs of 10 large evolving systems to support dependency evolution management. We also consider results from a detailed study for evolving call graphs of Maven-Core's version series. ",
    "url": "https://arxiv.org/abs/2210.08316",
    "authors": [
      "Animesh Chaturvedi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.08318",
    "title": "CoRe: An Automated Pipeline for The Prediction of Liver Resection  Complexity from Preoperative CT Scans",
    "abstract": "Surgical resections are the most prevalent curative treatment for primary liver cancer. Tumors located in critical positions are known to complexify liver resections (LR). While experienced surgeons in specialized medical centers may have the necessary expertise to accurately anticipate LR complexity, and prepare accordingly, an objective method able to reproduce this behavior would have the potential to improve the standard routine of care, and avoid intra- and postoperative complications. In this article, we propose CoRe, an automated medical image processing pipeline for the prediction of postoperative LR complexity from preoperative CT scans, using imaging biomarkers. The CoRe pipeline first segments the liver, lesions, and vessels with two deep learning networks. The liver vasculature is then pruned based on a topological criterion to define the hepatic central zone (HCZ), a convex volume circumscribing the major liver vessels, from which a new imaging biomarker, BHCZ is derived. Additional biomarkers are extracted and leveraged to train and evaluate a LR complexity prediction model. An ablation study shows the HCZ-based biomarker as the central feature in predicting LR complexity. The best predictive model reaches an accuracy, F1, and AUC of 77.3, 75.4, and 84.1% respectively. ",
    "url": "https://arxiv.org/abs/2210.08318",
    "authors": [
      "Omar Ali",
      "Alexandre Bone",
      "Caterina Accardo",
      "Omar Belkouchi",
      "Marc-Michel Rohe",
      "Eric Vibert",
      "Irene Vignon-Clementel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08319",
    "title": "A Scalable Reinforcement Learning Approach for Attack Allocation in  Swarm to Swarm Engagement Problems",
    "abstract": "In this work we propose a reinforcement learning (RL) framework that controls the density of a large-scale swarm for engaging with adversarial swarm attacks. Although there is a significant amount of existing work in applying artificial intelligence methods to swarm control, analysis of interactions between two adversarial swarms is a rather understudied area. Most of the existing work in this subject develop strategies by making hard assumptions regarding the strategy and dynamics of the adversarial swarm. Our main contribution is the formulation of the swarm to swarm engagement problem as a Markov Decision Process and development of RL algorithms that can compute engagement strategies without the knowledge of strategy/dynamics of the adversarial swarm. Simulation results show that the developed framework can handle a wide array of large-scale engagement scenarios in an efficient manner. ",
    "url": "https://arxiv.org/abs/2210.08319",
    "authors": [
      "Umut Demir",
      "Nazim Kemal Ure"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08331",
    "title": "Combination Of Convolution Neural Networks And Deep Neural Networks For  Fake News Detection",
    "abstract": "Nowadays, People prefer to follow the latest news on social media, as it is cheap, easily accessible, and quickly disseminated. However, it can spread fake or unreliable, low-quality news that intentionally contains false information. The spread of fake news can have a negative effect on people and society. Given the seriousness of such a problem, researchers did their best to identify patterns and characteristics that fake news may exhibit to design a system that can detect fake news before publishing. In this paper, we have described the Fake News Challenge stage #1 (FNC-1) dataset and given an overview of the competitive attempts to build a fake news detection system using the FNC-1 dataset. The proposed model was evaluated with the FNC-1 dataset. A competitive dataset is considered an open problem and a challenge worldwide. This system's procedure implies processing the text in the headline and body text columns with different natural language processing techniques. After that, the extracted features are reduced using the elbow truncated method, finding the similarity between each pair using the soft cosine similarity method. The new feature is entered into CNN and DNN deep learning approaches. The proposed system detects all the categories with high accuracy except the disagree category. As a result, the system achieves up to 84.6 % accuracy, classifying it as the second ranking based on other competitive studies regarding this dataset. ",
    "url": "https://arxiv.org/abs/2210.08331",
    "authors": [
      "Zainab A. Jawad",
      "Ahmed J. Obaid"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.08332",
    "title": "Code Recommendation for Open Source Software Developers",
    "abstract": "Open Source Software (OSS) is forming the spines of technology infrastructures, attracting millions of talents to contribute. Notably, it is challenging and critical to consider both the developers' interests and the semantic features of the project code to recommend appropriate development tasks to OSS developers. In this paper, we formulate the novel problem of code recommendation, whose purpose is to predict the future contribution behaviors of developers given their interaction history, the semantic features of source code, and the hierarchical file structures of projects. Considering the complex interactions among multiple parties within the system, we propose CODER, a novel graph-based code recommendation framework for open source software developers. CODER jointly models microscopic user-code interactions and macroscopic user-project interactions via a heterogeneous graph and further bridges the two levels of information through aggregation on file-structure graphs that reflect the project hierarchy. Moreover, due to the lack of reliable benchmarks, we construct three large-scale datasets to facilitate future research in this direction. Extensive experiments show that our CODER framework achieves superior performance under various experimental settings, including intra-project, cross-project, and cold-start recommendation. We will release all the datasets, code, and utilities for data retrieval upon the acceptance of this work. ",
    "url": "https://arxiv.org/abs/2210.08332",
    "authors": [
      "Yiqiao Jin",
      "Yunsheng Bai",
      "Yanqiao Zhu",
      "Yizhou Sun",
      "Wei Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.08336",
    "title": "DProtoNet: Decoupling the inference module and the explanation module  enables neural networks to have better accuracy and interpretability",
    "abstract": "The interpretation of decisions made by neural networks is the focus of recent research. In the previous method, by modifying the architecture of the neural network, the network simulates the human reasoning process, that is, by finding the decision elements to make decisions, so that the network has the interpretability of the reasoning process. The specific interpretable architecture will limit the fitting space of the network, resulting in a decrease in the classification performance of the network, unstable convergence, and general interpretability. We propose DProtoNet (Decoupling Prototypical network), it stores the decision basis of the neural network by using feature masks, and it uses Multiple Dynamic Masks (MDM) to explain the decision basis for feature mask retention. It decouples the neural network inference module from the interpretation module, and removes the specific architectural limitations of the interpretable network, so that the decision-making architecture of the network retains the original network architecture as much as possible, making the neural network more expressive, and greatly improving the interpretability. Classification performance and interpretability of explanatory networks. We propose to replace the prototype learning of a single image with the prototype learning of multiple images, which makes the prototype robust, improves the convergence speed of network training, and makes the accuracy of the network more stable during the learning process. We test on multiple datasets, DProtoNet can improve the accuracy of recent advanced interpretable network models by 5% to 10%, and its classification performance is comparable to that of backbone networks without interpretability. It also achieves the state of the art in interpretability performance. ",
    "url": "https://arxiv.org/abs/2210.08336",
    "authors": [
      "Yitao Peng",
      "Yihang Liu",
      "Longzhen Yang",
      "Lianghua He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08345",
    "title": "Augmentation-Free Graph Contrastive Learning of Invariant-Discriminative  Representations",
    "abstract": "The pretasks are mainly built on mutual information estimation, which requires data augmentation to construct positive samples with similar semantics to learn invariant signals and negative samples with dissimilar semantics in order to empower representation discriminability. However, an appropriate data augmentation configuration depends heavily on lots of empirical trials such as choosing the compositions of data augmentation techniques and the corresponding hyperparameter settings. We propose an augmentation-free graph contrastive learning method, invariant-discriminative graph contrastive learning (iGCL), that does not intrinsically require negative samples. iGCL designs the invariant-discriminative loss (ID loss) to learn invariant and discriminative representations. On the one hand, ID loss learns invariant signals by directly minimizing the mean square error between the target samples and positive samples in the representation space. On the other hand, ID loss ensures that the representations are discriminative by an orthonormal constraint forcing the different dimensions of representations to be independent of each other. This prevents representations from collapsing to a point or subspace. Our theoretical analysis explains the effectiveness of ID loss from the perspectives of the redundancy reduction criterion, canonical correlation analysis, and information bottleneck principle. The experimental results demonstrate that iGCL outperforms all baselines on 5 node classification benchmark datasets. iGCL also shows superior performance for different label ratios and is capable of resisting graph attacks, which indicates that iGCL has excellent generalization and robustness. ",
    "url": "https://arxiv.org/abs/2210.08345",
    "authors": [
      "Haifeng Li",
      "Jun Cao",
      "Jiawei Zhu",
      "Qinyao Luo",
      "Silu He",
      "Xuyin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08353",
    "title": "MGNNI: Multiscale Graph Neural Networks with Implicit Layers",
    "abstract": "Recently, implicit graph neural networks (GNNs) have been proposed to capture long-range dependencies in underlying graphs. In this paper, we introduce and justify two weaknesses of implicit GNNs: the constrained expressiveness due to their limited effective range for capturing long-range dependencies, and their lack of ability to capture multiscale information on graphs at multiple resolutions. To show the limited effective range of previous implicit GNNs, We first provide a theoretical analysis and point out the intrinsic relationship between the effective range and the convergence of iterative equations used in these models. To mitigate the mentioned weaknesses, we propose a multiscale graph neural network with implicit layers (MGNNI) which is able to model multiscale structures on graphs and has an expanded effective range for capturing long-range dependencies. We conduct comprehensive experiments for both node classification and graph classification to show that MGNNI outperforms representative baselines and has a better ability for multiscale modeling and capturing of long-range dependencies. ",
    "url": "https://arxiv.org/abs/2210.08353",
    "authors": [
      "Juncheng Liu",
      "Bryan Hooi",
      "Kenji Kawaguchi",
      "Xiaokui Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08355",
    "title": "A Simple and Strong Baseline for End-to-End Neural RST-style Discourse  Parsing",
    "abstract": "To promote and further develop RST-style discourse parsing models, we need a strong baseline that can be regarded as a reference for reporting reliable experimental results. This paper explores a strong baseline by integrating existing simple parsing strategies, top-down and bottom-up, with various transformer-based pre-trained language models. The experimental results obtained from two benchmark datasets demonstrate that the parsing performance strongly relies on the pretrained language models rather than the parsing strategies. In particular, the bottom-up parser achieves large performance gains compared to the current best parser when employing DeBERTa. We further reveal that language models with a span-masking scheme especially boost the parsing performance through our analysis within intra- and multi-sentential parsing, and nuclearity prediction. ",
    "url": "https://arxiv.org/abs/2210.08355",
    "authors": [
      "Naoki Kobayashi",
      "Tsutomu Hirao",
      "Hidetaka Kamigaito",
      "Manabu Okumura",
      "Masaaki Nagata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.08362",
    "title": "PAR: Political Actor Representation Learning with Social Context and  Expert Knowledge",
    "abstract": "Modeling the ideological perspectives of political actors is an essential task in computational political science with applications in many downstream tasks. Existing approaches are generally limited to textual data and voting records, while they neglect the rich social context and valuable expert knowledge for holistic ideological analysis. In this paper, we propose \\textbf{PAR}, a \\textbf{P}olitical \\textbf{A}ctor \\textbf{R}epresentation learning framework that jointly leverages social context and expert knowledge. Specifically, we retrieve and extract factual statements about legislators to leverage social context information. We then construct a heterogeneous information network to incorporate social context and use relational graph neural networks to learn legislator representations. Finally, we train PAR with three objectives to align representation learning with expert knowledge, model ideological stance consistency, and simulate the echo chamber phenomenon. Extensive experiments demonstrate that PAR is better at augmenting political text understanding and successfully advances the state-of-the-art in political perspective detection and roll call vote prediction. Further analysis proves that PAR learns representations that reflect the political reality and provide new insights into political behavior. ",
    "url": "https://arxiv.org/abs/2210.08362",
    "authors": [
      "Shangbin Feng",
      "Zhaoxuan Tan",
      "Zilong Chen",
      "Ningnan Wang",
      "Peisheng Yu",
      "Qinghua Zheng",
      "Xiaojun Chang",
      "Minnan Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.08363",
    "title": "Data-Efficient Augmentation for Training Neural Networks",
    "abstract": "Data augmentation is essential to achieve state-of-the-art performance in many deep learning applications. However, the most effective augmentation techniques become computationally prohibitive for even medium-sized datasets. To address this, we propose a rigorous technique to select subsets of data points that when augmented, closely capture the training dynamics of full data augmentation. We first show that data augmentation, modeled as additive perturbations, improves learning and generalization by relatively enlarging and perturbing the smaller singular values of the network Jacobian, while preserving its prominent directions. This prevents overfitting and enhances learning the harder to learn information. Then, we propose a framework to iteratively extract small subsets of training data that when augmented, closely capture the alignment of the fully augmented Jacobian with labels/residuals. We prove that stochastic gradient descent applied to the augmented subsets found by our approach has similar training dynamics to that of fully augmented data. Our experiments demonstrate that our method achieves 6.3x speedup on CIFAR10 and 2.2x speedup on SVHN, and outperforms the baselines by up to 10% across various subset sizes. Similarly, on TinyImageNet and ImageNet, our method beats the baselines by up to 8%, while achieving up to 3.3x speedup across various subset sizes. Finally, training on and augmenting 50% subsets using our method on a version of CIFAR10 corrupted with label noise even outperforms using the full dataset. ",
    "url": "https://arxiv.org/abs/2210.08363",
    "authors": [
      "Tian Yu Liu",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08367",
    "title": "Active Learning with Neural Networks: Insights from Nonparametric  Statistics",
    "abstract": "Deep neural networks have great representation power, but typically require large numbers of training examples. This motivates deep active learning methods that can significantly reduce the amount of labeled training data. Empirical successes of deep active learning have been recently reported in the literature, however, rigorous label complexity guarantees of deep active learning have remained elusive. This constitutes a significant gap between theory and practice. This paper tackles this gap by providing the first near-optimal label complexity guarantees for deep active learning. The key insight is to study deep active learning from the nonparametric classification perspective. Under standard low noise conditions, we show that active learning with neural networks can provably achieve the minimax label complexity, up to disagreement coefficient and other logarithmic terms. When equipped with an abstention option, we further develop an efficient deep active learning algorithm that achieves $\\mathsf{polylog}(\\frac{1}{\\epsilon})$ label complexity, without any low noise assumptions. We also provide extensions of our results beyond the commonly studied Sobolev/H\\\"older spaces and develop label complexity guarantees for learning in Radon $\\mathsf{BV}^2$ spaces, which have recently been proposed as natural function spaces associated with neural networks. ",
    "url": "https://arxiv.org/abs/2210.08367",
    "authors": [
      "Yinglun Zhu",
      "Robert Nowak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.08371",
    "title": "Sketching for First Order Method: Efficient Algorithm for Low-Bandwidth  Channel and Vulnerability",
    "abstract": "Sketching is one of the most fundamental tools in large-scale machine learning. It enables runtime and memory saving via randomly compressing the original large problem onto lower dimensions. In this paper, we propose a novel sketching scheme for the first order method in large-scale distributed learning setting, such that the communication costs between distributed agents are saved while the convergence of the algorithms is still guaranteed. Given gradient information in a high dimension $d$, the agent passes the compressed information processed by a sketching matrix $R\\in \\R^{s\\times d}$ with $s\\ll d$, and the receiver de-compressed via the de-sketching matrix $R^\\top$ to ``recover'' the information in original dimension. Using such a framework, we develop algorithms for federated learning with lower communication costs. However, such random sketching does not protect the privacy of local data directly. We show that the gradient leakage problem still exists after applying the sketching technique by showing a specific gradient attack method. As a remedy, we prove rigorously that the algorithm will be differentially private by adding additional random noises in gradient information, which results in a both communication-efficient and differentially private first order approach for federated learning tasks. Our sketching scheme can be further generalized to other learning settings and might be of independent interest itself. ",
    "url": "https://arxiv.org/abs/2210.08371",
    "authors": [
      "Zhao Song",
      "Yitan Wang",
      "Zheng Yu",
      "Lichen Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.08375",
    "title": "Improving the Intra-class Long-tail in 3D Detection via Rare Example  Mining",
    "abstract": "Continued improvements in deep learning architectures have steadily advanced the overall performance of 3D object detectors to levels on par with humans for certain tasks and datasets, where the overall performance is mostly driven by common examples. However, even the best performing models suffer from the most naive mistakes when it comes to rare examples that do not appear frequently in the training data, such as vehicles with irregular geometries. Most studies in the long-tail literature focus on class-imbalanced classification problems with known imbalanced label counts per class, but they are not directly applicable to the intra-class long-tail examples in problems with large intra-class variations such as 3D object detection, where instances with the same class label can have drastically varied properties such as shapes and sizes. Other works propose to mitigate this problem using active learning based on the criteria of uncertainty, difficulty, or diversity. In this study, we identify a new conceptual dimension - rareness - to mine new data for improving the long-tail performance of models. We show that rareness, as opposed to difficulty, is the key to data-centric improvements for 3D detectors, since rareness is the result of a lack in data support while difficulty is related to the fundamental ambiguity in the problem. We propose a general and effective method to identify the rareness of objects based on density estimation in the feature space using flow models, and propose a principled cost-aware formulation for mining rare object tracks, which improves overall model performance, but more importantly - significantly improves the performance for rare objects (by 30.97\\% ",
    "url": "https://arxiv.org/abs/2210.08375",
    "authors": [
      "Chiyu Max Jiang",
      "Mahyar Najibi",
      "Charles R. Qi",
      "Yin Zhou",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08376",
    "title": "Variant Parallelism: Lightweight Deep Convolutional Models for  Distributed Inference on IoT Devices",
    "abstract": "Two major techniques are commonly used to meet real-time inference limitations when distributing models across resource-constrained IoT devices: (1) model parallelism (MP) and (2) class parallelism (CP). In MP, transmitting bulky intermediate data (orders of magnitude larger than input) between devices imposes huge communication overhead. Although CP solves this problem, it has limitations on the number of sub-models. In addition, both solutions are fault intolerant, an issue when deployed on edge devices. We propose variant parallelism (VP), an ensemble-based deep learning distribution method where different variants of a main model are generated and can be deployed on separate machines. We design a family of lighter models around the original model, and train them simultaneously to improve accuracy over single models. Our experimental results on six common mid-sized object recognition datasets demonstrate that our models can have 5.8-7.1x fewer parameters, 4.3-31x fewer multiply-accumulations (MACs), and 2.5-13.2x less response time on atomic inputs compared to MobileNetV2 while achieving comparable or higher accuracy. Our technique easily generates several variants of the base architecture. Each variant returns only 2k outputs 1 <= k <= (#classes/2), representing Top-k classes, instead of tons of floating point values required in MP. Since each variant provides a full-class prediction, our approach maintains higher availability compared with MP and CP in presence of failure. ",
    "url": "https://arxiv.org/abs/2210.08376",
    "authors": [
      "Navidreza Asadi",
      "Maziar Goudarzi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08388",
    "title": "RoS-KD: A Robust Stochastic Knowledge Distillation Approach for Noisy  Medical Imaging",
    "abstract": "AI-powered Medical Imaging has recently achieved enormous attention due to its ability to provide fast-paced healthcare diagnoses. However, it usually suffers from a lack of high-quality datasets due to high annotation cost, inter-observer variability, human annotator error, and errors in computer-generated labels. Deep learning models trained on noisy labelled datasets are sensitive to the noise type and lead to less generalization on the unseen samples. To address this challenge, we propose a Robust Stochastic Knowledge Distillation (RoS-KD) framework which mimics the notion of learning a topic from multiple sources to ensure deterrence in learning noisy information. More specifically, RoS-KD learns a smooth, well-informed, and robust student manifold by distilling knowledge from multiple teachers trained on overlapping subsets of training data. Our extensive experiments on popular medical imaging classification tasks (cardiopulmonary disease and lesion classification) using real-world datasets, show the performance benefit of RoS-KD, its ability to distill knowledge from many popular large networks (ResNet-50, DenseNet-121, MobileNet-V2) in a comparatively small network, and its robustness to adversarial attacks (PGD, FSGM). More specifically, RoS-KD achieves >2% and >4% improvement on F1-score for lesion classification and cardiopulmonary disease classification tasks, respectively, when the underlying student is ResNet-18 against recent competitive knowledge distillation baseline. Additionally, on cardiopulmonary disease classification task, RoS-KD outperforms most of the SOTA baselines by ~1% gain in AUC score. ",
    "url": "https://arxiv.org/abs/2210.08388",
    "authors": [
      "Ajay Jaiswal",
      "Kumar Ashutosh",
      "Justin F Rousseau",
      "Yifan Peng",
      "Zhangyang Wang",
      "Ying Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08390",
    "title": "SOCIALMAPF: Optimal and Efficient Multi-Agent Path Finding with  Strategic Agents for Social Navigation",
    "abstract": "We propose an extension to the MAPF formulation, called SocialMAPF, to account for private incentives of agents in constrained environments such as doorways, narrow hallways, and corridor intersections. SocialMAPF is able to, for instance, accurately reason about the urgent incentive of an agent rushing to the hospital over another agent's less urgent incentive of going to a grocery store; MAPF ignores such agent-specific incentives. Our proposed formulation addresses the open problem of optimal and efficient path planning for agents with private incentives. To solve SocialMAPF, we propose a new class of algorithms that use mechanism design during conflict resolution to simultaneously optimize agents' private local utilities and the global system objective. We perform an extensive array of experiments that show that optimal search-based MAPF techniques lead to collisions and increased time-to-goal in SocialMAPF compared to our proposed method using mechanism design. Furthermore, we empirically demonstrate that mechanism design results in models that maximizes agent utility and minimizes the overall time-to-goal of the entire system. We further showcase the capabilities of mechanism design-based planning by successfully deploying it in environments with static obstacles. To conclude, we briefly list several research directions using the SocialMAPF formulation, such as exploring motion planning in the continuous domain for agents with private incentives. ",
    "url": "https://arxiv.org/abs/2210.08390",
    "authors": [
      "Rohan Chandra",
      "Rahul Maligi",
      "Arya Anantula",
      "Joydeep Biswas"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.08391",
    "title": "Video in 10 Bits: Few-Bit VideoQA for Efficiency and Privacy",
    "abstract": "In Video Question Answering (VideoQA), answering general questions about a video requires its visual information. Yet, video often contains redundant information irrelevant to the VideoQA task. For example, if the task is only to answer questions similar to \"Is someone laughing in the video?\", then all other information can be discarded. This paper investigates how many bits are really needed from the video in order to do VideoQA by introducing a novel Few-Bit VideoQA problem, where the goal is to accomplish VideoQA with few bits of video information (e.g., 10 bits). We propose a simple yet effective task-specific feature compression approach to solve this problem. Specifically, we insert a lightweight Feature Compression Module (FeatComp) into a VideoQA model which learns to extract task-specific tiny features as little as 10 bits, which are optimal for answering certain types of questions. We demonstrate more than 100,000-fold storage efficiency over MPEG4-encoded videos and 1,000-fold over regular floating point features, with just 2.0-6.6% absolute loss in accuracy, which is a surprising and novel finding. Finally, we analyze what the learned tiny features capture and demonstrate that they have eliminated most of the non-task-specific information, and introduce a Bit Activation Map to visualize what information is being stored. This decreases the privacy risk of data by providing k-anonymity and robustness to feature-inversion techniques, which can influence the machine learning community, allowing us to store data with privacy guarantees while still performing the task effectively. ",
    "url": "https://arxiv.org/abs/2210.08391",
    "authors": [
      "Shiyuan Huang",
      "Robinson Piramuthu",
      "Shih-Fu Chang",
      "Gunnar A. Sigurdsson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08398",
    "title": "SPIDR: SDF-based Neural Point Fields for Illumination and Deformation",
    "abstract": "Implicit neural representations such as neural radiance fields (NeRFs) have recently emerged as a promising approach for 3D reconstruction and novel view synthesis. However, NeRF-based methods encode shape, reflectance, and illumination implicitly in their neural representations, and this makes it challenging for users to manipulate these properties in the rendered images explicitly. Existing approaches only enable limited editing of the scene and deformation of the geometry. Furthermore, no existing work enables accurate scene illumination after object deformation. In this work, we introduce SPIDR, a new hybrid neural SDF representation. SPIDR combines point cloud and neural implicit representations to enable the reconstruction of higher quality meshes and surfaces for object deformation and lighting estimation. To more accurately capture environment illumination for scene relighting, we propose a novel neural implicit model to learn environment light. To enable accurate illumination updates after deformation, we use the shadow mapping technique to efficiently approximate the light visibility updates caused by geometry editing. We demonstrate the effectiveness of SPIDR in enabling high quality geometry editing and deformation with accurate updates to the illumination of the scene. In comparison to prior work, we demonstrate significantly better rendering quality after deformation and lighting estimation. ",
    "url": "https://arxiv.org/abs/2210.08398",
    "authors": [
      "Ruofan Liang",
      "Jiahao Zhang",
      "Haoda Li",
      "Chen Yang",
      "Nandita Vijaykumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2210.08403",
    "title": "Semantic Segmentation with Active Semi-Supervised Representation  Learning",
    "abstract": "Obtaining human per-pixel labels for semantic segmentation is incredibly laborious, often making labeled dataset construction prohibitively expensive. Here, we endeavor to overcome this problem with a novel algorithm that combines semi-supervised and active learning, resulting in the ability to train an effective semantic segmentation algorithm with significantly lesser labeled data. To do this, we extend the prior state-of-the-art S4AL algorithm by replacing its mean teacher approach for semi-supervised learning with a self-training approach that improves learning with noisy labels. We further boost the neural network's ability to query useful data by adding a contrastive learning head, which leads to better understanding of the objects in the scene, and hence, better queries for active learning. We evaluate our method on CamVid and CityScapes datasets, the de-facto standards for active learning for semantic segmentation. We achieve more than 95% of the network's performance on CamVid and CityScapes datasets, utilizing only 12.1% and 15.1% of the labeled data, respectively. We also benchmark our method across existing stand-alone semi-supervised learning methods on the CityScapes dataset and achieve superior performance without any bells or whistles. ",
    "url": "https://arxiv.org/abs/2210.08403",
    "authors": [
      "Aneesh Rangnekar",
      "Christopher Kanan",
      "Matthew Hoffman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08423",
    "title": "TransVisDrone: Spatio-Temporal Transformer for Vision-based  Drone-to-Drone Detection in Aerial Videos",
    "abstract": "Drone-to-drone detection using visual feed has crucial applications like avoiding collision with other drones/airborne objects, tackling a drone attack or coordinating flight with other drones. However, the existing methods are computationally costly, follow a non-end-to-end optimization and have complex multi-stage pipeline, which make them less suitable to deploy on edge devices for real-time drone flight. In this work, we propose a simple-yet-effective framework TransVisDrone, which provides end-to-end solution with higher computational efficiency. We utilize CSPDarkNet-53 network to learn object-related spatial features and VideoSwin model to learn the spatio-temporal dependencies of drone motion which improves drone detection in challenging scenarios. Our method obtains state-of-the-art performance on three challenging real-world datasets (Average Precision@0.5IOU): NPS 0.95, FLDrones 0.75 and AOT 0.80. Apart from its superior performance, it achieves higher throughput than the prior work. We also demonstrate its deployment capability on edge-computing devices and usefulness in applications like drone-collision (encounter) detection. Code: \\url{https://github.com/tusharsangam/TransVisDrone}. ",
    "url": "https://arxiv.org/abs/2210.08423",
    "authors": [
      "Tushar Sangam",
      "Ishan Rajendrakumar Dave",
      "Waqas Sultani",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.08430",
    "title": "Explainable Causal Analysis of Mental Health on Social Media Data",
    "abstract": "With recent developments in Social Computing, Natural Language Processing and Clinical Psychology, the social NLP research community addresses the challenge of automation in mental illness on social media. A recent extension to the problem of multi-class classification of mental health issues is to identify the cause behind the user's intention. However, multi-class causal categorization for mental health issues on social media has a major challenge of wrong prediction due to the overlapping problem of causal explanations. There are two possible mitigation techniques to solve this problem: (i) Inconsistency among causal explanations/ inappropriate human-annotated inferences in the dataset, (ii) in-depth analysis of arguments and stances in self-reported text using discourse analysis. In this research work, we hypothesise that if there exists the inconsistency among F1 scores of different classes, there must be inconsistency among corresponding causal explanations as well. In this task, we fine tune the classifiers and find explanations for multi-class causal categorization of mental illness on social media with LIME and Integrated Gradient (IG) methods. We test our methods with CAMS dataset and validate with annotated interpretations. A key contribution of this research work is to find the reason behind inconsistency in accuracy of multi-class causal categorization. The effectiveness of our methods is evident with the results obtained having category-wise average scores of $81.29 \\%$ and $0.906$ using cosine similarity and word mover's distance, respectively. ",
    "url": "https://arxiv.org/abs/2210.08430",
    "authors": [
      "Chandni Saxena",
      "Muskan Garg",
      "Gunjan Saxena"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.08432",
    "title": "QStack: Re-architecting User-space Network Stack to Optimize CPU  Efficiency and Service Quality",
    "abstract": "TCP/IP network stack is irreplaceable for Web services in datacenter front-end servers, and the demand for which is growing rapidly for emerging high concurrency network service applications (including Internet, Internet of Things, mobile Internet, etc.) especially. The existing network stack schemes often face the dilemma between the data center server resource utilization (i.e., high CPU efficiency) and application service quality (i.e., low tail latency). We break this dilemma via a flexible architectural design QStack, which simultaneously achieves CPU efficiency and low tail latency in user-space network stack for front-end datacenter server. QStack proposes elastic framework and application definable full-datapath priority, such that the network stack collaboration among CPU cores horizontally and coordination across network layers in fine grained vertically on demand. We prototype QStack on commodity servers. Testbed experiments demonstrate the effectiveness of QStack over state-of-the-art user-space network stack designs. ",
    "url": "https://arxiv.org/abs/2210.08432",
    "authors": [
      "WL Zhang",
      "YF Shen",
      "H Song",
      "Zh Zhang",
      "K Liu",
      "Q Huang",
      "MY Chen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.08443",
    "title": "CLEAR: Generative Counterfactual Explanations on Graphs",
    "abstract": "Counterfactual explanations promote explainability in machine learning models by answering the question \"how should an input instance be perturbed to obtain a desired predicted label?\". The comparison of this instance before and after perturbation can enhance human interpretation. Most existing studies on counterfactual explanations are limited in tabular data or image data. In this work, we study the problem of counterfactual explanation generation on graphs. A few studies have explored counterfactual explanations on graphs, but many challenges of this problem are still not well-addressed: 1) optimizing in the discrete and disorganized space of graphs; 2) generalizing on unseen graphs; and 3) maintaining the causality in the generated counterfactuals without prior knowledge of the causal model. To tackle these challenges, we propose a novel framework CLEAR which aims to generate counterfactual explanations on graphs for graph-level prediction models. Specifically, CLEAR leverages a graph variational autoencoder based mechanism to facilitate its optimization and generalization, and promotes causality by leveraging an auxiliary variable to better identify the underlying causal model. Extensive experiments on both synthetic and real-world graphs validate the superiority of CLEAR over the state-of-the-art methods in different aspects. ",
    "url": "https://arxiv.org/abs/2210.08443",
    "authors": [
      "Jing Ma",
      "Ruocheng Guo",
      "Saumitra Mishra",
      "Aidong Zhang",
      "Jundong Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08458",
    "title": "Learning Self-Regularized Adversarial Views for Self-Supervised Vision  Transformers",
    "abstract": "Automatic data augmentation (AutoAugment) strategies are indispensable in supervised data-efficient training protocols of vision transformers, and have led to state-of-the-art results in supervised learning. Despite the success, its development and application on self-supervised vision transformers have been hindered by several barriers, including the high search cost, the lack of supervision, and the unsuitable search space. In this work, we propose AutoView, a self-regularized adversarial AutoAugment method, to learn views for self-supervised vision transformers, by addressing the above barriers. First, we reduce the search cost of AutoView to nearly zero by learning views and network parameters simultaneously in a single forward-backward step, minimizing and maximizing the mutual information among different augmented views, respectively. Then, to avoid information collapse caused by the lack of label supervision, we propose a self-regularized loss term to guarantee the information propagation. Additionally, we present a curated augmentation policy search space for self-supervised learning, by modifying the generally used search space designed for supervised learning. On ImageNet, our AutoView achieves remarkable improvement over RandAug baseline (+10.2% k-NN accuracy), and consistently outperforms sota manually tuned view policy by a clear margin (up to +1.3% k-NN accuracy). Extensive experiments show that AutoView pretraining also benefits downstream tasks (+1.2% mAcc on ADE20K Semantic Segmentation and +2.8% mAP on revisited Oxford Image Retrieval benchmark) and improves model robustness (+2.3% Top-1 Acc on ImageNet-A and +1.0% AUPR on ImageNet-O). Code and models will be available at https://github.com/Trent-tangtao/AutoView. ",
    "url": "https://arxiv.org/abs/2210.08458",
    "authors": [
      "Tao Tang",
      "Changlin Li",
      "Guangrun Wang",
      "Kaicheng Yu",
      "Xiaojun Chang",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08470",
    "title": "Class Distribution Monitoring for Concept Drift Detection",
    "abstract": "We introduce Class Distribution Monitoring (CDM), an effective concept-drift detection scheme that monitors the class-conditional distributions of a datastream. In particular, our solution leverages multiple instances of an online and nonparametric change-detection algorithm based on QuantTree. CDM reports a concept drift after detecting a distribution change in any class, thus identifying which classes are affected by the concept drift. This can be precious information for diagnostics and adaptation. Our experiments on synthetic and real-world datastreams show that when the concept drift affects a few classes, CDM outperforms algorithms monitoring the overall data distribution, while achieving similar detection delays when the drift affects all the classes. Moreover, CDM outperforms comparable approaches that monitor the classification error, particularly when the change is not very apparent. Finally, we demonstrate that CDM inherits the properties of the underlying change detector, yielding an effective control over the expected time before a false alarm, or Average Run Length (ARL$_0$). ",
    "url": "https://arxiv.org/abs/2210.08470",
    "authors": [
      "Diego Stucchi",
      "Luca Frittoli",
      "Giacomo Boracchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08472",
    "title": "Object-Attentional Untargeted Adversarial Attack",
    "abstract": "Deep neural networks are facing severe threats from adversarial attacks. Most existing black-box attacks fool target model by generating either global perturbations or local patches. However, both global perturbations and local patches easily cause annoying visual artifacts in adversarial example. Compared with some smooth regions of an image, the object region generally has more edges and a more complex texture. Thus small perturbations on it will be more imperceptible. On the other hand, the object region is undoubtfully the decisive part of an image to classification tasks. Motivated by these two facts, we propose an object-attentional adversarial attack method for untargeted attack. Specifically, we first generate an object region by intersecting the object detection region from YOLOv4 with the salient object detection (SOD) region from HVPNet. Furthermore, we design an activation strategy to avoid the reaction caused by the incomplete SOD. Then, we perform an adversarial attack only on the detected object region by leveraging Simple Black-box Adversarial Attack (SimBA). To verify the proposed method, we create a unique dataset by extracting all the images containing the object defined by COCO from ImageNet-1K, named COCO-Reduced-ImageNet in this paper. Experimental results on ImageNet-1K and COCO-Reduced-ImageNet show that under various system settings, our method yields the adversarial example with better perceptual quality meanwhile saving the query budget up to 24.16\\% compared to the state-of-the-art approaches including SimBA. ",
    "url": "https://arxiv.org/abs/2210.08472",
    "authors": [
      "Chao Zhou",
      "Yuan-Gen Wang",
      "Guopu Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08473",
    "title": "1st Place Solution in Google Universal Images Embedding",
    "abstract": "This paper presents the 1st place solution for the Google Universal Images Embedding Competition on Kaggle. The highlighted part of our solution is based on 1) A novel way to conduct training and fine-tuning; 2) The idea of a better ensemble in the pool of models that make embedding; 3) The potential trade-off between fine-tuning on high-resolution and overlapping patches; 4) The potential factors to work for the dynamic margin. Our solution reaches 0.728 in the private leader board, which achieve 1st place in Google Universal Images Embedding Competition. ",
    "url": "https://arxiv.org/abs/2210.08473",
    "authors": [
      "Shihao Shao",
      "Qinghua Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08474",
    "title": "Sentence Representation Learning with Generative Objective rather than  Contrastive Objective",
    "abstract": "Though offering amazing contextualized token-level representations, current pre-trained language models take less attention on accurately acquiring sentence-level representation during their self-supervised pre-training. However, contrastive objectives which dominate the current sentence representation learning bring little linguistic interpretability and no performance guarantee on downstream semantic tasks. We instead propose a novel generative self-supervised learning objective based on phrase reconstruction. To overcome the drawbacks of previous generative methods, we carefully model intra-sentence structure by breaking down one sentence into pieces of important phrases. Empirical studies show that our generative learning achieves powerful enough performance improvement and outperforms the current state-of-the-art contrastive methods not only on the STS benchmarks, but also on downstream semantic retrieval and reranking tasks. Our code is available at https://github.com/chengzhipanpan/PaSeR. ",
    "url": "https://arxiv.org/abs/2210.08474",
    "authors": [
      "Bohong Wu",
      "Hai Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.08478",
    "title": "Increasing Visual Awareness in Multimodal Neural Machine Translation  from an Information Theoretic Perspective",
    "abstract": "Multimodal machine translation (MMT) aims to improve translation quality by equipping the source sentence with its corresponding image. Despite the promising performance, MMT models still suffer the problem of input degradation: models focus more on textual information while visual information is generally overlooked. In this paper, we endeavor to improve MMT performance by increasing visual awareness from an information theoretic perspective. In detail, we decompose the informative visual signals into two parts: source-specific information and target-specific information. We use mutual information to quantify them and propose two methods for objective optimization to better leverage visual signals. Experiments on two datasets demonstrate that our approach can effectively enhance the visual awareness of MMT model and achieve superior results against strong baselines. ",
    "url": "https://arxiv.org/abs/2210.08478",
    "authors": [
      "Baijun Ji",
      "Tong Zhang",
      "Yicheng Zou",
      "Bojie Hu",
      "Si Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.08500",
    "title": "This Patient Looks Like That Patient: Prototypical Networks for  Interpretable Diagnosis Prediction from Clinical Text",
    "abstract": "The use of deep neural models for diagnosis prediction from clinical text has shown promising results. However, in clinical practice such models must not only be accurate, but provide doctors with interpretable and helpful results. We introduce ProtoPatient, a novel method based on prototypical networks and label-wise attention with both of these abilities. ProtoPatient makes predictions based on parts of the text that are similar to prototypical patients - providing justifications that doctors understand. We evaluate the model on two publicly available clinical datasets and show that it outperforms existing baselines. Quantitative and qualitative evaluations with medical doctors further demonstrate that the model provides valuable explanations for clinical decision support. ",
    "url": "https://arxiv.org/abs/2210.08500",
    "authors": [
      "Betty van Aken",
      "Jens-Michalis Papaioannou",
      "Marcel G. Naik",
      "Georgios Eleftheriadis",
      "Wolfgang Nejdl",
      "Felix A. Gers",
      "Alexander L\u00f6ser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.08503",
    "title": "Entropy Regularized Reinforcement Learning with Cascading Networks",
    "abstract": "Deep Reinforcement Learning (Deep RL) has had incredible achievements on high dimensional problems, yet its learning process remains unstable even on the simplest tasks. Deep RL uses neural networks as function approximators. These neural models are largely inspired by developments in the (un)supervised machine learning community. Compared to these learning frameworks, one of the major difficulties of RL is the absence of i.i.d. data. One way to cope with this difficulty is to control the rate of change of the policy at every iteration. In this work, we challenge the common practices of the (un)supervised learning community of using a fixed neural architecture, by having a neural model that grows in size at each policy update. This allows a closed form entropy regularized policy update, which leads to a better control of the rate of change of the policy at each iteration and help cope with the non i.i.d. nature of RL. Initial experiments on classical RL benchmarks show promising results with remarkable convergence on some RL tasks when compared to other deep RL baselines, while exhibiting limitations on others. ",
    "url": "https://arxiv.org/abs/2210.08503",
    "authors": [
      "Riccardo Della Vecchia",
      "Alena Shilova",
      "Philippe Preux",
      "Riad Akrour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08511",
    "title": "CDConv: A Benchmark for Contradiction Detection in Chinese Conversations",
    "abstract": "Dialogue contradiction is a critical issue in open-domain dialogue systems. The contextualization nature of conversations makes dialogue contradiction detection rather challenging. In this work, we propose a benchmark for Contradiction Detection in Chinese Conversations, namely CDConv. It contains 12K multi-turn conversations annotated with three typical contradiction categories: Intra-sentence Contradiction, Role Confusion, and History Contradiction. To efficiently construct the CDConv conversations, we devise a series of methods for automatic conversation generation, which simulate common user behaviors that trigger chatbots to make contradictions. We conduct careful manual quality screening of the constructed conversations and show that state-of-the-art Chinese chatbots can be easily goaded into making contradictions. Experiments on CDConv show that properly modeling contextual information is critical for dialogue contradiction detection, but there are still unresolved challenges that require future research. ",
    "url": "https://arxiv.org/abs/2210.08511",
    "authors": [
      "Chujie Zheng",
      "Jinfeng Zhou",
      "Yinhe Zheng",
      "Libiao Peng",
      "Zhen Guo",
      "Wenquan Wu",
      "Zhengyu Niu",
      "Hua Wu",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.08518",
    "title": "OST: Efficient One-stream Network for 3D Single Object Tracking in Point  Clouds",
    "abstract": "Although recent Siamese network-based trackers have achieved impressive perceptual accuracy for single object tracking in LiDAR point clouds, they advance with some heavy correlation operations on relation modeling and overlook the inherent merit of arbitrariness compared to multiple object tracking. In this work, we propose a radically novel one-stream network with the strength of the Transformer encoding, which avoids the correlation operations occurring in previous Siamese network, thus considerably reducing the computational effort. In particular, the proposed method mainly consists of a Template-aware Transformer Module (TTM) and a Multi-scale Feature Aggregation (MFA) module capable of fusing spatial and semantic information. The TTM stitches the specified template and the search region together and leverages an attention mechanism to establish the information flow, breaking the previous pattern of independent \\textit{extraction-and-correlation}. As a result, this module makes it possible to directly generate template-aware features that are suitable for the arbitrary and continuously changing nature of the target, enabling the model to deal with unseen categories. In addition, the MFA is proposed to make spatial and semantic information complementary to each other, which is characterized by reverse directional feature propagation that aggregates information from shallow to deep layers. Extensive experiments on KITTI and nuScenes demonstrate that our method has achieved considerable performance not only for class-specific tracking but also for class-agnostic tracking with less computation and higher efficiency. ",
    "url": "https://arxiv.org/abs/2210.08518",
    "authors": [
      "Xiantong Zhao",
      "Yinan Han",
      "Shengjing Tian",
      "Jian Liu",
      "Xiuping Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08529",
    "title": "Towards Effective Image Manipulation Detection with Proposal Contrastive  Learning",
    "abstract": "Deep models have been widely and successfully used in image manipulation detection, which aims to classify tampered images and localize tampered regions. Most existing methods mainly focus on extracting \\textit{global features} from tampered images, while neglecting the \\textit{relationships of local features} between tampered and authentic regions within a single tampered image. To exploit such spatial relationships, we propose Proposal Contrastive Learning (PCL) for effective image manipulation detection. Our PCL consists of a two-stream architecture by extracting two types of global features from RGB and noise views respectively. To further improve the discriminative power, we exploit the relationships of local features through a proxy proposal contrastive learning task by attracting/repelling proposal-based positive/negative sample pairs. Moreover, we show that our PCL can be easily adapted to unlabeled data in practice, which can reduce manual labeling costs and promote more generalizable features. Extensive experiments among several standard datasets demonstrate that our PCL can be a general module to obtain consistent improvement. ",
    "url": "https://arxiv.org/abs/2210.08529",
    "authors": [
      "Yuyuan Zeng",
      "Bowen Zhao",
      "Shanzhao Qiu",
      "Tao Dai",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08537",
    "title": "Learning 6-DoF Task-oriented Grasp Detection via Implicit Estimation and  Visual Affordance",
    "abstract": "Currently, task-oriented grasp detection approaches are mostly based on pixel-level affordance detection and semantic segmentation. These pixel-level approaches heavily rely on the accuracy of a 2D affordance mask, and the generated grasp candidates are restricted to a small workspace. To mitigate these limitations, we first construct a novel affordance-based grasp dataset and propose a 6-DoF task-oriented grasp detection framework, which takes the observed object point cloud as input and predicts diverse 6-DoF grasp poses for different tasks. Specifically, our implicit estimation network and visual affordance network in this framework could directly predict coarse grasp candidates, and corresponding 3D affordance heatmap for each potential task, respectively. Furthermore, the grasping scores from coarse grasps are combined with heatmap values to generate more accurate and finer candidates. Our proposed framework shows significant improvements compared to baselines for existing and novel objects on our simulation dataset. Although our framework is trained based on the simulated objects and environment, the final generated grasp candidates can be accurately and stably executed in real robot experiments when the object is randomly placed on a support surface. ",
    "url": "https://arxiv.org/abs/2210.08537",
    "authors": [
      "Wenkai Chen",
      "Hongzhuo Liang",
      "Zhaopeng Chen",
      "Fuchun Sun",
      "Jianwei Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.08540",
    "title": "TransAlign: Fully Automatic and Effective Entity Alignment for Knowledge  Graphs",
    "abstract": "The task of entity alignment between knowledge graphs (KGs) aims to identify every pair of entities from two different KGs that represent the same entity. Many machine learning-based methods have been proposed for this task. However, to our best knowledge, existing methods all require manually crafted seed alignments, which are expensive to obtain. In this paper, we propose the first fully automatic alignment method named TransAlign, which does not require any manually crafted seed alignments. Specifically, for predicate embeddings, TransAlign constructs a predicate-proximity-graph to automatically capture the similarity between predicates across two KGs by learning the attention of entity types. For entity embeddings, TransAlign first computes the entity embeddings of each KG independently using TransE, and then shifts the two KGs' entity embeddings into the same vector space by computing the similarity between entities based on their attributes. Thus, both predicate alignment and entity alignment can be done without manually crafted seed alignments. TransAlign is not only fully automatic, but also highly effective. Experiments using real-world KGs show that TransAlign improves the accuracy of entity alignment significantly compared to state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2210.08540",
    "authors": [
      "Rui Zhang",
      "Xiaoyan Zhao",
      "Bayu Distiawan Trisedya",
      "Min Yang",
      "Hong Cheng",
      "Jianzhong Qi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08548",
    "title": "Investigating the Robustness of Natural Language Generation from Logical  Forms via Counterfactual Samples",
    "abstract": "The aim of Logic2Text is to generate controllable and faithful texts conditioned on tables and logical forms, which not only requires a deep understanding of the tables and logical forms, but also warrants symbolic reasoning over the tables. State-of-the-art methods based on pre-trained models have achieved remarkable performance on the standard test dataset. However, we question whether these methods really learn how to perform logical reasoning, rather than just relying on the spurious correlations between the headers of the tables and operators of the logical form. To verify this hypothesis, we manually construct a set of counterfactual samples, which modify the original logical forms to generate counterfactual logical forms with rarely co-occurred table headers and logical operators. SOTA methods give much worse results on these counterfactual samples compared with the results on the original test dataset, which verifies our hypothesis. To deal with this problem, we firstly analyze this bias from a causal perspective, based on which we propose two approaches to reduce the model's reliance on the shortcut. The first one incorporates the hierarchical structure of the logical forms into the model. The second one exploits automatically generated counterfactual data for training. Automatic and manual experimental results on the original test dataset and the counterfactual dataset show that our method is effective to alleviate the spurious correlation. Our work points out the weakness of previous methods and takes a further step toward developing Logic2Text models with real logical reasoning ability. ",
    "url": "https://arxiv.org/abs/2210.08548",
    "authors": [
      "Chengyuan Liu",
      "Leilei Gan",
      "Kun Kuang",
      "Fei Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08550",
    "title": "Assessing the Optimality of LinDist3Flow for Optimal Tap Selection of  Step Voltage Regulators in Unbalanced Distribution Networks",
    "abstract": "The adoption of distributed energy resources such as photovoltaics (PVs) has increased dramatically during the previous decade. The increased penetration of PVs into distribution networks (DNs) can cause voltage fluctuations that have to be mitigated. One of the key utility assets employed to this end are step-voltage regulators (SVRs). It is desirable to include tap selection of SVRs in optimal power flow (OPF) routines, a task that turns out to be challenging because the resultant OPF problem is nonconvex with added complexities stemming from accurate SVR modeling. While several convex relaxations based on semi-definite programming (SDP) have been presented in the literature for optimal tap selection, SDP-based schemes do not scale well and are challenging to implement in large-scale planning or operational frameworks. This paper deals with the optimal tap selection (OPTS) problem for wye-connected SVRs using linear approximations of power flow equations. Specifically, the $\\textit{LinDist3Flow}$ model is adopted and the effective SVR ratio is assumed to be continuous--enabling the formulation of a problem called $\\textit{LinDist3Flow-OPTS}$, which amounts to a linear program. The scalability and optimality gap of $\\textit{LinDist3Flow-OPTS}$ are evaluated with respect to existing SDP-based and nonlinear programming techniques for optimal tap selection in three standard feeders, namely, the IEEE 13-bus, 123-bus, and 8500-node DNs. For all DNs considered, $\\textit{LinDist3Flow-OPTS}$ achieves an optimality gap of approximately $1\\%$ or less while significantly lowering the computational burden. ",
    "url": "https://arxiv.org/abs/2210.08550",
    "authors": [
      "Krishna Sandeep Ayyagari",
      "Sherin Ann Abraham",
      "Yiyun Yao",
      "Shibani Ghosh",
      "Francisco Flores-Espino",
      "Adarsh Nagarajan",
      "Nikolaos Gatsis"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.08577",
    "title": "Stochastic Occupancy Grid Map Prediction in Dynamic Scenes",
    "abstract": "This paper presents two variations of a novel stochastic prediction algorithm that enables mobile robots to accurately and robustly predict the future state of complex dynamic scenes, such as environments full of people. The proposed algorithm uses a variational autoencoder-based neural network to predict a range of possible future states of the environment. The algorithm takes full advantage of the motion of the robot itself, the motion of dynamic objects, and the geometry of static objects in the scene to improve prediction accuracy. Three different datasets collected by different robot models are used to demonstrate that the proposed algorithm is able to achieve smaller absolute error, higher structure similarity, and higher tracking accuracy than state-of-the-art prediction algorithms for video prediction tasks. Implementations of both proposed stochastic prediction algorithms are available open source at https://github.com/TempleRAIL/SOGMP. ",
    "url": "https://arxiv.org/abs/2210.08577",
    "authors": [
      "Zhanteng Xie",
      "Philip Dames"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.08579",
    "title": "Nowhere to Hide: A Lightweight Unsupervised Detector against Adversarial  Examples",
    "abstract": "Although deep neural networks (DNNs) have shown impressive performance on many perceptual tasks, they are vulnerable to adversarial examples that are generated by adding slight but maliciously crafted perturbations to benign images. Adversarial detection is an important technique for identifying adversarial examples before they are entered into target DNNs. Previous studies to detect adversarial examples either targeted specific attacks or required expensive computation. How design a lightweight unsupervised detector is still a challenging problem. In this paper, we propose an AutoEncoder-based Adversarial Examples (AEAE) detector, that can guard DNN models by detecting adversarial examples with low computation in an unsupervised manner. The AEAE includes only a shallow autoencoder but plays two roles. First, a well-trained autoencoder has learned the manifold of benign examples. This autoencoder can produce a large reconstruction error for adversarial images with large perturbations, so we can detect significantly perturbed adversarial examples based on the reconstruction error. Second, the autoencoder can filter out the small noise and change the DNN's prediction on adversarial examples with small perturbations. It helps to detect slightly perturbed adversarial examples based on the prediction distance. To cover these two cases, we utilize the reconstruction error and prediction distance from benign images to construct a two-tuple feature set and train an adversarial detector using the isolation forest algorithm. We show empirically that the AEAE is unsupervised and inexpensive against the most state-of-the-art attacks. Through the detection in these two cases, there is nowhere to hide adversarial examples. ",
    "url": "https://arxiv.org/abs/2210.08579",
    "authors": [
      "Hui Liu",
      "Bo Zhao",
      "Kehuan Zhang",
      "Peng Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.08596",
    "title": "Logical Zonotope: A Set Representation for Binary Vectors",
    "abstract": "In this paper, we propose a new set representation for binary vectors called logical zonotopes. A logical zonotope is constructed by XOR-ing a binary vector with a combination of binary vectors called generators. A logical zonotope can efficiently represent up to 2^n binary vectors using only n generators. Instead of the explicit enumeration of the zonotopes' members, logical operations over sets of binary vectors are applied directly to a zonotopes' generators. Thus, logical zonotopes can be used to greatly reduce the computational complexity of a variety of operations over sets of binary vectors, including logical operations (e.g. XOR, NAND, AND, OR) and semi-tensor products. Additionally, we show that, similar to the role classical zonotopes play for formally verifying dynamical systems defined over real vector spaces, logical zonotopes can be used to efficiently analyze the forward reachability of dynamical systems defined over binary vector spaces (e.g. logical circuits or Boolean networks). To showcase the utility of logical zonotopes, we illustrate three use cases: (1) discovering the key of a linear-feedback shift register with a linear time complexity, (2) verifying the safety of a logical vehicle intersection crossing protocol, and (3) performing reachability analysis for a high-dimensional Boolean function. ",
    "url": "https://arxiv.org/abs/2210.08596",
    "authors": [
      "Amr Alanwar",
      "Frank J. Jiang",
      "Samy Amin",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2210.08600",
    "title": "Heterogeneous Full-body Control of a Mobile Manipulator with Behavior  Trees",
    "abstract": "Integrating the heterogeneous controllers of a complex mechanical system, such as a mobile manipulator, within the same structure and in a modular way is still challenging. In this work we extend our framework based on Behavior Trees for the control of a redundant mechanical system to the problem of commanding more complex systems that involve multiple low-level controllers. This allows the integrated systems to achieve non-trivial goals that require coordination among the sub-systems. ",
    "url": "https://arxiv.org/abs/2210.08600",
    "authors": [
      "Marco Iannotta",
      "David C\u00e1ceres Dom\u00ednguez",
      "Johannes A. Stork",
      "Erik Schaffernicht",
      "Todor Stoyanov"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.08601",
    "title": "Towards Dynamic Fault Tolerance for Hardware-Implemented Artificial  Neural Networks: A Deep Learning Approach",
    "abstract": "The functionality of electronic circuits can be seriously impaired by the occurrence of dynamic hardware faults. Particularly, for digital ultra low-power systems, a reduced safety margin can increase the probability of dynamic failures. This work investigates a deep learning approach to mitigate dynamic fault impact for artificial neural networks. As a theoretic use case, image compression by means of a deep autoencoder is considered. The evaluation shows a linear dependency of the test loss to the fault injection rate during testing. If the number of training epochs is sufficiently large, our approach shows more than 2% reduction of the test loss compared to a baseline network without the need of additional hardware. At the absence of faults during testing, our approach also decreases the test loss compared to reference networks. ",
    "url": "https://arxiv.org/abs/2210.08601",
    "authors": [
      "Daniel Gregorek",
      "Nils H\u00fclsmeier",
      "Steffen Paul"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2210.08608",
    "title": "Posterior Regularized Bayesian Neural Network Incorporating Soft and  Hard Knowledge Constraints",
    "abstract": "Neural Networks (NNs) have been widely {used in supervised learning} due to their ability to model complex nonlinear patterns, often presented in high-dimensional data such as images and text. However, traditional NNs often lack the ability for uncertainty quantification. Bayesian NNs (BNNS) could help measure the uncertainty by considering the distributions of the NN model parameters. Besides, domain knowledge is commonly available and could improve the performance of BNNs if it can be appropriately incorporated. In this work, we propose a novel Posterior-Regularized Bayesian Neural Network (PR-BNN) model by incorporating different types of knowledge constraints, such as the soft and hard constraints, as a posterior regularization term. Furthermore, we propose to combine the augmented Lagrangian method and the existing BNN solvers for efficient inference. The experiments in simulation and two case studies about aviation landing prediction and solar energy output prediction have shown the knowledge constraints and the performance improvement of the proposed model over traditional BNNs without the constraints. ",
    "url": "https://arxiv.org/abs/2210.08608",
    "authors": [
      "Jiayu Huang",
      "Yutian Pang",
      "Yongming Liu",
      "Hao Yan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08627",
    "title": "Torque-Limited Manipulation Planning through Contact by Interleaving  Graph Search and Trajectory Optimization",
    "abstract": "Robots often have to perform manipulation tasks in close proximity to people. As such, it is desirable to use a robot arm that has limited joint torques so as to not injure the nearby person. Unfortunately, these limited torques then limit the payload capability of the arm. By using contact with the environment, robots can expand their reachable workspace that, otherwise, would be inaccessible due to exceeding actuator torque limits. We adapt our recently developed INSAT algorithm \\cite{insat} to tackle the problem of torque-limited whole arm manipulation planning through contact. INSAT requires no prior over contact mode sequence and no initial template or seed for trajectory optimization. INSAT achieves this by interleaving graph search to explore the manipulator joint configuration space with incremental trajectory optimizations seeded by neighborhood solutions to find a dynamically feasible trajectory through contact. We demonstrate our results on a variety of manipulators and scenarios in simulation. We also experimentally show our planner exploiting robot-environment contact for the pick and place of a payload using a Kinova Gen3 robot. In comparison to the same trajectory running in free space, we experimentally show that the utilization of bracing contacts reduces the overall torque required to execute the trajectory. ",
    "url": "https://arxiv.org/abs/2210.08627",
    "authors": [
      "Ramkumar Natarajan",
      "Garrison L.H. Johnston",
      "Nabil Simaan",
      "Maxim Likhachev",
      "Howie Choset"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.08634",
    "title": "SUPERB @ SLT 2022: Challenge on Generalization and Efficiency of  Self-Supervised Speech Representation Learning",
    "abstract": "We present the SUPERB challenge at SLT 2022, which aims at learning self-supervised speech representation for better performance, generalization, and efficiency. The challenge builds upon the SUPERB benchmark and implements metrics to measure the computation requirements of self-supervised learning (SSL) representation and to evaluate its generalizability and performance across the diverse SUPERB tasks. The SUPERB benchmark provides comprehensive coverage of popular speech processing tasks, from speech and speaker recognition to audio generation and semantic understanding. As SSL has gained interest in the speech community and showed promising outcomes, we envision the challenge to uplevel the impact of SSL techniques by motivating more practical designs of techniques beyond task performance. We summarize the results of 14 submitted models in this paper. We also discuss the main findings from those submissions and the future directions of SSL research. ",
    "url": "https://arxiv.org/abs/2210.08634",
    "authors": [
      "Tzu-hsun Feng",
      "Annie Dong",
      "Ching-Feng Yeh",
      "Shu-wen Yang",
      "Tzu-Quan Lin",
      "Jiatong Shi",
      "Kai-Wei Chang",
      "Zili Huang",
      "Haibin Wu",
      "Xuankai Chang",
      "Shinji Watanabe",
      "Abdelrahman Mohamed",
      "Shang-Wen Li",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.08645",
    "title": "3D-GMIC: an efficient deep neural network to find small objects in large  3D images",
    "abstract": "3D imaging enables a more accurate diagnosis by providing spatial information about organ anatomy. However, using 3D images to train AI models is computationally challenging because they consist of tens or hundreds of times more pixels than their 2D counterparts. To train with high-resolution 3D images, convolutional neural networks typically resort to downsampling them or projecting them to two dimensions. In this work, we propose an effective alternative, a novel neural network architecture that enables computationally efficient classification of 3D medical images in their full resolution. Compared to off-the-shelf convolutional neural networks, 3D-GMIC uses 77.98%-90.05% less GPU memory and 91.23%-96.02% less computation. While our network is trained only with image-level labels, without segmentation labels, it explains its classification predictions by providing pixel-level saliency maps. On a dataset collected at NYU Langone Health, including 85,526 patients with full-field 2D mammography (FFDM), synthetic 2D mammography, and 3D mammography (DBT), our model, the 3D Globally-Aware Multiple Instance Classifier (3D-GMIC), achieves a breast-wise AUC of 0.831 (95% CI: 0.769-0.887) in classifying breasts with malignant findings using DBT images. As DBT and 2D mammography capture different information, averaging predictions on 2D and 3D mammography together leads to a diverse ensemble with an improved breast-wise AUC of 0.841 (95% CI: 0.768-0.895). Our model generalizes well to an external dataset from Duke University Hospital, achieving an image-wise AUC of 0.848 (95% CI: 0.798-0.896) in classifying DBT images with malignant findings. ",
    "url": "https://arxiv.org/abs/2210.08645",
    "authors": [
      "Jungkyu Park",
      "Jakub Ch\u0142\u0119dowski",
      "Stanis\u0142aw Jastrz\u0119bski",
      "Jan Witowski",
      "Yanqi Xu",
      "Linda Du",
      "Sushma Gaddam",
      "Eric Kim",
      "Alana Lewin",
      "Ujas Parikh",
      "Anastasia Plaunova",
      "Sardius Chen",
      "Alexandra Millet",
      "James Park",
      "Kristine Pysarenko",
      "Shalin Patel",
      "Julia Goldberg",
      "Melanie Wegener",
      "Linda Moy",
      "Laura Heacock",
      "Beatriu Reig",
      "Krzysztof J. Geras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.08646",
    "title": "EventGraph: Event Extraction as Semantic Graph Parsing",
    "abstract": "Event extraction involves the detection and extraction of both the event triggers and corresponding event arguments. Existing systems often decompose event extraction into multiple subtasks, without considering their possible interactions. In this paper, we propose EventGraph, a joint framework for event extraction, which encodes events as graphs. We represent event triggers and arguments as nodes in a semantic graph. Event extraction therefore becomes a graph parsing problem, which provides the following advantages: 1) performing event detection and argument extraction jointly; 2) detecting and extracting multiple events from a piece of text; and 3) capturing the complicated interaction between event arguments and triggers. Experimental results on ACE2005 show that our model is competitive to state-of-the-art systems and has substantially improved the results on argument extraction. Additionally, we create two new datasets from ACE2005 where we keep the entire text spans for event arguments, instead of just the head word(s). Our code and models are released as open-source. ",
    "url": "https://arxiv.org/abs/2210.08646",
    "authors": [
      "Huiling You",
      "David Samuel",
      "Samia Touileb",
      "Lilja \u00d8vrelid"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.08654",
    "title": "Learning to Sample and Aggregate: Few-shot Reasoning over Temporal  Knowledge Graphs",
    "abstract": "In this paper, we investigate a realistic but underexplored problem, called few-shot temporal knowledge graph reasoning, that aims to predict future facts for newly emerging entities based on extremely limited observations in evolving graphs. It offers practical value in applications that need to derive instant new knowledge about new entities in temporal knowledge graphs (TKGs) with minimal supervision. The challenges mainly come from the few-shot and time shift properties of new entities. First, the limited observations associated with them are insufficient for training a model from scratch. Second, the potentially dynamic distributions from the initially observable facts to the future facts ask for explicitly modeling the evolving characteristics of new entities. We correspondingly propose a novel Meta Temporal Knowledge Graph Reasoning (MetaTKGR) framework. Unlike prior work that relies on rigid neighborhood aggregation schemes to enhance low-data entity representation, MetaTKGR dynamically adjusts the strategies of sampling and aggregating neighbors from recent facts for new entities, through temporally supervised signals on future facts as instant feedback. Besides, such a meta temporal reasoning procedure goes beyond existing meta-learning paradigms on static knowledge graphs that fail to handle temporal adaptation with large entity variance. We further provide a theoretical analysis and propose a temporal adaptation regularizer to stabilize the meta temporal reasoning over time. Empirically, extensive experiments on three real-world TKGs demonstrate the superiority of MetaTKGR over state-of-the-art baselines by a large margin. ",
    "url": "https://arxiv.org/abs/2210.08654",
    "authors": [
      "Ruijie Wang",
      "Zheng Li",
      "Dachun Sun",
      "Shengzhong Liu",
      "Jinning Li",
      "Bing Yin",
      "Tarek Abdelzaher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.08675",
    "title": "SGRAM: Improving Scene Graph Parsing via Abstract Meaning Representation",
    "abstract": "Scene graph is structured semantic representation that can be modeled as a form of graph from images and texts. Image-based scene graph generation research has been actively conducted until recently, whereas text-based scene graph generation research has not. In this paper, we focus on the problem of scene graph parsing from textual description of a visual scene. The core idea is to use abstract meaning representation (AMR) instead of the dependency parsing mainly used in previous studies. AMR is a graph-based semantic formalism of natural language which abstracts concepts of words in a sentence contrary to the dependency parsing which considers dependency relationships on all words in a sentence. To this end, we design a simple yet effective two-stage scene graph parsing framework utilizing abstract meaning representation, SGRAM (Scene GRaph parsing via Abstract Meaning representation): 1) transforming a textual description of an image into an AMR graph (Text-to-AMR) and 2) encoding the AMR graph into a Transformer-based language model to generate a scene graph (AMR-to-SG). Experimental results show the scene graphs generated by our framework outperforms the dependency parsing-based model by 11.61\\% and the previous state-of-the-art model using a pre-trained Transformer language model by 3.78\\%. Furthermore, we apply SGRAM to image retrieval task which is one of downstream tasks for scene graph, and confirm the effectiveness of scene graphs generated by our framework. ",
    "url": "https://arxiv.org/abs/2210.08675",
    "authors": [
      "Woo Suk Choi",
      "Yu-Jung Heo",
      "Byoung-Tak Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08676",
    "title": "Scale-Agnostic Super-Resolution in MRI using Feature-Based Coordinate  Networks",
    "abstract": "We propose using a coordinate network decoder for the task of super-resolution in MRI. The continuous signal representation of coordinate networks enables this approach to be scale-agnostic, i.e. one can train over a continuous range of scales and subsequently query at arbitrary resolutions. Due to the difficulty of performing super-resolution on inherently noisy data, we analyze network behavior under multiple denoising strategies. Lastly we compare this method to a standard convolutional decoder using both quantitative metrics and a radiologist study implemented in Voxel, our newly developed tool for web-based evaluation of medical images. ",
    "url": "https://arxiv.org/abs/2210.08676",
    "authors": [
      "Dave Van Veen",
      "Rogier van der Sluijs",
      "Batu Ozturkler",
      "Arjun Desai",
      "Christian Bluethgen",
      "Robert D. Boutin",
      "Marc H. Willis",
      "Gordon Wetzstein",
      "David Lindell",
      "Shreyas Vasanawala",
      "John Pauly",
      "Akshay S. Chaudhari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08679",
    "title": "Causal Inference for De-biasing Motion Estimation from Robotic  Observational Data",
    "abstract": "Robot data collected in complex real-world scenarios are often biased due to safety concerns, human preferences, and mission or platform constraints. Consequently, robot learning from such observational data poses great challenges for accurate parameter estimation. We propose a principled causal inference framework for robots to learn the parameters of a stochastic motion model using observational data. Specifically, we leverage the de-biasing functionality of the potential-outcome causal inference framework, the Inverse Propensity Weighting (IPW), and the Doubly Robust (DR) methods, to obtain a better parameter estimation of the robot's stochastic motion model. The IPW is a re-weighting approach to ensure unbiased estimation, and the DR approach further combines any two estimators to strengthen the unbiased result even if one of these estimators is biased. We then develop an approximate policy iteration algorithm using the bias-eliminated estimated state transition function. We validate our framework using both simulation and real-world experiments, and the results have revealed that the proposed causal inference-based navigation and control framework can correctly and efficiently learn the parameters from biased observational data. ",
    "url": "https://arxiv.org/abs/2210.08679",
    "authors": [
      "Junhong Xu",
      "Kai Yin",
      "Jason M. Gregory",
      "Lantao Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.08682",
    "title": "AMF-Placer 2.0: Open Source Timing-driven Analytical Mixed-size Placer  for Large-scale Heterogeneous FPGA",
    "abstract": "On modern field-programmable gate arrays (FPGAs), certain critical path portions of the designs might be prearranged into many multi-cell macros during synthesis. These movable macros with constraints of shape and resources lead to challenging mixed-size placement for FPGA designs which cannot be addressed by previous analytical placers. Moreover, general timing-driven placement algorithms are facing challenges when handling real-world application design and ultrascale FPGA architectures. In this work, we propose AMF-Placer 2.0, an open-source comprehensive timing-driven analytical mixed-size FPGA placer. It supports mixed-size placement of heterogeneous resources (e.g., LUT/FF/LUTRAM/MUX/CARRY/DSP/BRAM) on FPGA, with an interface to Xilinx Vivado. Standing upon the shoulders of AMF-Placer 1.0, AMFPlacer 2.0 is equipped with a series of new techniques for timing optimization, including a simple but effective timing model, placement-blockage-aware anchor insertion, WNS-aware timing-driven quadratic placement, and sector-guided detailed placement. Based on a set of the latest large open-source benchmarks from various domains for Xilinx Ultrascale FPGAs, experimental results indicate that critical path delays realized by AMF-Placer 2.0 are averagely 2.2% and 0.59% higher than those achieved by commercial tool Xilinx Vivavo 2020.2 and 2021.2 respectively. Meanwhile, the average runtime of placement procedure of AMF-Placer 2.0 is 14% and 8.5% higher than Xilinx Vivavo 2020.2 and 2021.2 respectively. Although limited by the absence of the exact timing model of the device, the information of design hierarchy and accurate routing feedback, AMF-Placer 2.0 is the first open-source FPGA placer which can handle the timingdriven mixed-size placement of practical complex designs with various FPGA resources and achieves the comparable quality to the latest commercial tools. ",
    "url": "https://arxiv.org/abs/2210.08682",
    "authors": [
      "Tingyuan Liang",
      "Gengjie Chen",
      "Jieru Zhao",
      "Sharad Sinha",
      "Wei Zhang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2210.08701",
    "title": "ODG-Q: Robust Quantization via Online Domain Generalization",
    "abstract": "Quantizing neural networks to low-bitwidth is important for model deployment on resource-limited edge hardware. Although a quantized network has a smaller model size and memory footprint, it is fragile to adversarial attacks. However, few methods study the robustness and training efficiency of quantized networks. To this end, we propose a new method by recasting robust quantization as an online domain generalization problem, termed ODG-Q, which generates diverse adversarial data at a low cost during training. ODG-Q consistently outperforms existing works against various adversarial attacks. For example, on CIFAR-10 dataset, ODG-Q achieves 49.2% average improvements under five common white-box attacks and 21.7% average improvements under five common black-box attacks, with a training cost similar to that of natural training (viz. without adversaries). To our best knowledge, this work is the first work that trains both quantized and binary neural networks on ImageNet that consistently improve robustness under different attacks. We also provide a theoretical insight of ODG-Q that accounts for the bound of model risk on attacked data. ",
    "url": "https://arxiv.org/abs/2210.08701",
    "authors": [
      "Chaofan Tao",
      "Ngai Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08714",
    "title": "Selective Query-guided Debiasing Network for Video Corpus Moment  Retrieval",
    "abstract": "Video moment retrieval (VMR) aims to localize target moments in untrimmed videos pertinent to a given textual query. Existing retrieval systems tend to rely on retrieval bias as a shortcut and thus, fail to sufficiently learn multi-modal interactions between query and video. This retrieval bias stems from learning frequent co-occurrence patterns between query and moments, which spuriously correlate objects (e.g., a pencil) referred in the query with moments (e.g., scene of writing with a pencil) where the objects frequently appear in the video, such that they converge into biased moment predictions. Although recent debiasing methods have focused on removing this retrieval bias, we argue that these biased predictions sometimes should be preserved because there are many queries where biased predictions are rather helpful. To conjugate this retrieval bias, we propose a Selective Query-guided Debiasing network (SQuiDNet), which incorporates the following two main properties: (1) Biased Moment Retrieval that intentionally uncovers the biased moments inherent in objects of the query and (2) Selective Query-guided Debiasing that performs selective debiasing guided by the meaning of the query. Our experimental results on three moment retrieval benchmarks (i.e., TVR, ActivityNet, DiDeMo) show the effectiveness of SQuiDNet and qualitative analysis shows improved interpretability. ",
    "url": "https://arxiv.org/abs/2210.08714",
    "authors": [
      "Sunjae Yoon",
      "Ji Woo Hong",
      "Eunseop Yoon",
      "Dahyun Kim",
      "Junyeong Kim",
      "Hee Suk Yoon",
      "Chang D. Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08715",
    "title": "ReAFFPN: Rotation-equivariant Attention Feature Fusion Pyramid Networks  for Aerial Object Detection",
    "abstract": "This paper proposes a Rotation-equivariant Attention Feature Fusion Pyramid Networks for Aerial Object Detection named ReAFFPN. ReAFFPN aims at improving the effect of rotation-equivariant features fusion between adjacent layers which suffers from the semantic and scale discontinuity. Due to the particularity of rotational equivariant convolution, general methods are unable to achieve their original effect while ensuring rotation equivariance of the network. To solve this problem, we design a new Rotation-equivariant Channel Attention which has the ability to both generate channel attention and keep rotation equivariance. Then we embed a new channel attention function into Iterative Attentional Feature Fusion (iAFF) module to realize Rotation-equivariant Attention Feature Fusion. Experimental results demonstrate that ReAFFPN achieves a better rotation-equivariant feature fusion ability and significantly improve the accuracy of the Rotation-equivariant Convolutional Networks. ",
    "url": "https://arxiv.org/abs/2210.08715",
    "authors": [
      "Chongyu Sun",
      "Yang Xu",
      "Zebin Wu",
      "Zhihui Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08730",
    "title": "Robust Bayesian state and parameter estimation framework for stochastic  dynamical systems with combined time-varying and time-invariant parameters",
    "abstract": "We consider state and parameter estimation for a dynamical system having both time-varying and time-invariant parameters. It has been shown that the robustness of the Markov Chain Monte Carlo (MCMC) algorithm for estimating time-invariant parameters alongside nonlinear filters for state estimation provided more reliable estimates than the estimates obtained solely using nonlinear filters for combined state and parameter estimation. In a similar fashion, we adopt the extended Kalman filter (EKF) for state estimation and the estimation of the time-varying system parameters, but reserve the task of estimating time-invariant parameters to the MCMC algorithm. In a standard method, we augment the state vector to include the original states of the system and the subset of the parameters that are time-varying. Each time-varying parameter is perturbed by a white noise process, and we treat the strength of this artificial noise as an additional time-invariant parameter to be estimated by MCMC, circumventing the need for manual tuning. Conventionally, both time-varying and time-invariant parameters are appended in the state vector, and thus for the purpose of estimation, both are free to vary in time. However, allowing time-invariant system parameters to vary in time introduces artificial dynamics into the system, which we avoid by treating these time-invariant parameters as static and estimating them using MCMC. Furthermore, by estimating the time-invariant parameters by MCMC, the augmented state is smaller and the nonlinearity in the ensuing state space model will tend to be weaker than in the conventional approach. We illustrate the above-described approach for a simple dynamical system in which some model parameters are time-varying, while the remaining parameters are time-invariant. ",
    "url": "https://arxiv.org/abs/2210.08730",
    "authors": [
      "Philippe Bisaillon",
      "Brandon Robinson",
      "Mohammad Khalil",
      "Chris L. Pettit",
      "Dominique Poirel",
      "Abhijit Sarkar"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2210.08735",
    "title": "Runner-Up Solution to Google Universal Image Embedding Competition 2022",
    "abstract": "Image representations are a critical building block of computer vision applications. This paper presents the 2nd place solution to the Google Universal Image Embedding Competition, which is part of the ECCV2022 instance-level recognition workshops. We use the instance-level fine-grained image classification method to complete this competition. We focus on data building and processing, model structure, and training strategies. Finally, the solution scored 0.713 on the public leaderboard and 0.709 on the private leaderboard. ",
    "url": "https://arxiv.org/abs/2210.08735",
    "authors": [
      "Xiaolong Huang",
      "QianKun Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08745",
    "title": "Row-wise LiDAR Lane Detection Network with Lane Correlation Refinement",
    "abstract": "Lane detection is one of the most important functions for autonomous driving. In recent years, deep learning-based lane detection networks with RGB camera images have shown promising performance. However, camera-based methods are inherently vulnerable to adverse lighting conditions such as poor or dazzling lighting. Unlike camera, LiDAR sensor is robust to the lighting conditions. In this work, we propose a novel two-stage LiDAR lane detection network with row-wise detection approach. The first-stage network produces lane proposals through a global feature correlator backbone and a row-wise detection head. Meanwhile, the second-stage network refines the feature map of the first-stage network via attention-based mechanism between the local features around the lane proposals, and outputs a set of new lane proposals. Experimental results on the K-Lane dataset show that the proposed network advances the state-of-the-art in terms of F1-score with 30% less GFLOPs. In addition, the second-stage network is found to be especially robust to lane occlusions, thus, demonstrating the robustness of the proposed network for driving in crowded environments. ",
    "url": "https://arxiv.org/abs/2210.08745",
    "authors": [
      "Dong-Hee Paek",
      "Kevin Tirta Wijaya",
      "Seung-Hyun Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08748",
    "title": "Dual-Curriculum Teacher for Domain-Inconsistent Object Detection in  Autonomous Driving",
    "abstract": "Object detection for autonomous vehicles has received increasing attention in recent years, where labeled data are often expensive while unlabeled data can be collected readily, calling for research on semi-supervised learning for this area. Existing semi-supervised object detection (SSOD) methods usually assume that the labeled and unlabeled data come from the same data distribution. In autonomous driving, however, data are usually collected from different scenarios, such as different weather conditions or different times in a day. Motivated by this, we study a novel but challenging domain inconsistent SSOD problem. It involves two kinds of distribution shifts among different domains, including (1) data distribution discrepancy, and (2) class distribution shifts, making existing SSOD methods suffer from inaccurate pseudo-labels and hurting model performance. To address this problem, we propose a novel method, namely Dual-Curriculum Teacher (DucTeacher). Specifically, DucTeacher consists of two curriculums, i.e., (1) domain evolving curriculum seeks to learn from the data progressively to handle data distribution discrepancy by estimating the similarity between domains, and (2) distribution matching curriculum seeks to estimate the class distribution for each unlabeled domain to handle class distribution shifts. In this way, DucTeacher can calibrate biased pseudo-labels and handle the domain-inconsistent SSOD problem effectively. DucTeacher shows its advantages on SODA10M, the largest public semi-supervised autonomous driving dataset, and COCO, a widely used SSOD benchmark. Experiments show that DucTeacher achieves new state-of-the-art performance on SODA10M with 2.2 mAP improvement and on COCO with 0.8 mAP improvement. ",
    "url": "https://arxiv.org/abs/2210.08748",
    "authors": [
      "Longhui Yu",
      "Yifan Zhang",
      "Lanqing Hong",
      "Fei Chen",
      "Zhenguo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08753",
    "title": "MCP: Self-supervised Pre-training for Personalized Chatbots with  Multi-level Contrastive Sampling",
    "abstract": "Personalized chatbots focus on endowing the chatbots with a consistent personality to behave like real users and further act as personal assistants. Previous studies have explored generating implicit user profiles from the user's dialogue history for building personalized chatbots. However, these studies only use the response generation loss to train the entire model, thus it is prone to suffer from the problem of data sparsity. Besides, they overemphasize the final generated response's quality while ignoring the correlations and fusions between the user's dialogue history, leading to rough data representations and performance degradation. To tackle these problems, we propose a self-supervised learning framework MCP for capturing better representations from users' dialogue history for personalized chatbots. Specifically, we apply contrastive sampling methods to leverage the supervised signals hidden in user dialog history, and generate the pre-training samples for enhancing the model. We design three pre-training tasks based on three types of contrastive pairs from user dialogue history, namely response pairs, sequence augmentation pairs, and user pairs. We pre-train the utterance encoder and the history encoder towards the contrastive objectives and use these pre-trained encoders for generating user profiles while personalized response generation. Experimental results on two real-world datasets show a significant improvement in our proposed model MCP compared with the existing methods. ",
    "url": "https://arxiv.org/abs/2210.08753",
    "authors": [
      "Zhaoheng Huang",
      "Zhicheng Dou",
      "Yutao Zhu",
      "Zhengyi Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08763",
    "title": "ReasonChainQA: Text-based Complex Question Answering with Explainable  Evidence Chains",
    "abstract": "The ability of reasoning over evidence has received increasing attention in question answering (QA). Recently, natural language database (NLDB) conducts complex QA in knowledge base with textual evidences rather than structured representations, this task attracts a lot of attention because of the flexibility and richness of textual evidence. However, existing text-based complex question answering datasets fail to provide explicit reasoning process, while it's important for retrieval effectiveness and reasoning interpretability. Therefore, we present a benchmark \\textbf{ReasonChainQA} with explanatory and explicit evidence chains. ReasonChainQA consists of two subtasks: answer generation and evidence chains extraction, it also contains higher diversity for multi-hop questions with varying depths, 12 reasoning types and 78 relations. To obtain high-quality textual evidences for answering complex question. Additional experiment on supervised and unsupervised retrieval fully indicates the significance of ReasonChainQA. Dataset and codes will be made publicly available upon accepted. ",
    "url": "https://arxiv.org/abs/2210.08763",
    "authors": [
      "Minjun Zhu",
      "Yixuan Weng",
      "Shizhu He",
      "Kang Liu",
      "Jun Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08765",
    "title": "Temporal Link Prediction: A Unified Framework, Taxonomy, and Review",
    "abstract": "Dynamic graphs serve as a generic abstraction and description of the evolutionary behaviors of various complex systems (e.g., social networks and communication networks). Temporal link prediction (TLP) is a classic inference task on dynamic graphs, which aims to predict possible future linkage using historical dynamic topology. The predicted future topology can be used to support some advanced applications on real-world systems (e.g., resource pre-allocation) for better system performance. This survey provides a comprehensive review of existing representative TLP methods. Concretely, we first give the formal statements regarding data models, task settings, and learning paradigms that are commonly used in related research. A hierarchical fine-grained taxonomy is further introduced to categorize existing methods in terms of their data models, learning paradigms, and techniques. From a generic perspective, we propose a unified encoder-decoder framework to formulate all the methods reviewed, where different approaches only differ in terms of some components of the unified framework. Moreover, we envision serving the community with an open-source project OpenTLP that refactors or implements some representative TLP methods using the proposed unified framework and summarizes other public sources. To conclude this survey, we also discuss some advanced topics in recent research and highlight possible future directions. ",
    "url": "https://arxiv.org/abs/2210.08765",
    "authors": [
      "Meng Qin",
      "Dit-Yan Yeung"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.08768",
    "title": "N-pad : Neighboring Pixel-based Industrial Anomaly Detection",
    "abstract": "Identifying defects in the images of industrial products has been an important task to enhance quality control and reduce maintenance costs. In recent studies, industrial anomaly detection models were developed using pre-trained networks to learn nominal representations. To employ the relative positional information of each pixel, we present \\textit{\\textbf{N-pad}}, a novel method for anomaly detection and segmentation in a one-class learning setting that includes the neighborhood of the target pixel for model training and evaluation. Within the model architecture, pixel-wise nominal distributions are estimated by using the features of neighboring pixels with the target pixel to allow possible marginal misalignment. Moreover, the centroids from clusters of nominal features are identified as a representative nominal set. Accordingly, anomaly scores are inferred based on the Mahalanobis distances and Euclidean distances between the target pixel and the estimated distributions or the centroid set, respectively. Thus, we have achieved state-of-the-art performance in MVTec-AD with AUROC of 99.37 for anomaly detection and 98.75 for anomaly segmentation, reducing the error by 34\\% compared to the next best performing model. Experiments in various settings further validate our model. ",
    "url": "https://arxiv.org/abs/2210.08768",
    "authors": [
      "JunKyu Jang",
      "Eugene Hwang",
      "Sung-Hyuk Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08770",
    "title": "Massive MIMO Channel Prediction Via Meta-Learning and Deep Denoising: Is  a Small Dataset Enough?",
    "abstract": "Accurate channel knowledge is critical in massive multiple-input multiple-output (MIMO), which motivates the use of channel prediction. Machine learning techniques for channel prediction hold much promise, but current schemes are limited in their ability to adapt to changes in the environment because they require large training overheads. To accurately predict wireless channels for new environments with reduced training overhead, we propose a fast adaptive channel prediction technique based on a meta-learning algorithm for massive MIMO communications. We exploit the model-agnostic meta-learning (MAML) algorithm to achieve quick adaptation with a small amount of labeled data. Also, to improve the prediction accuracy, we adopt the denoising process for the training data by using deep image prior (DIP). Numerical results show that the proposed MAML-based channel predictor can improve the prediction accuracy with only a few fine-tuning samples. The DIP-based denoising process gives an additional gain in channel prediction, especially in low signal-to-noise ratio regimes. ",
    "url": "https://arxiv.org/abs/2210.08770",
    "authors": [
      "Hwanjin Kim",
      "Junil Choi",
      "David J. Love"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.08772",
    "title": "Signal Processing for Implicit Neural Representations",
    "abstract": "Implicit Neural Representations (INRs) encoding continuous multi-media data via multi-layer perceptrons has shown undebatable promise in various computer vision tasks. Despite many successful applications, editing and processing an INR remains intractable as signals are represented by latent parameters of a neural network. Existing works manipulate such continuous representations via processing on their discretized instance, which breaks down the compactness and continuous nature of INR. In this work, we present a pilot study on the question: how to directly modify an INR without explicit decoding? We answer this question by proposing an implicit neural signal processing network, dubbed INSP-Net, via differential operators on INR. Our key insight is that spatial gradients of neural networks can be computed analytically and are invariant to translation, while mathematically we show that any continuous convolution filter can be uniformly approximated by a linear combination of high-order differential operators. With these two knobs, INSP-Net instantiates the signal processing operator as a weighted composition of computational graphs corresponding to the high-order derivatives of INRs, where the weighting parameters can be data-driven learned. Based on our proposed INSP-Net, we further build the first Convolutional Neural Network (CNN) that implicitly runs on INRs, named INSP-ConvNet. Our experiments validate the expressiveness of INSP-Net and INSP-ConvNet in fitting low-level image and geometry processing kernels (e.g. blurring, deblurring, denoising, inpainting, and smoothening) as well as for high-level tasks on implicit fields such as image classification. ",
    "url": "https://arxiv.org/abs/2210.08772",
    "authors": [
      "Dejia Xu",
      "Peihao Wang",
      "Yifan Jiang",
      "Zhiwen Fan",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08782",
    "title": "On powers of circular arc graphs",
    "abstract": "A class of graphs $\\mathcal{C}$ is closed under powers if for every graph $G\\in\\mathcal{C}$ and every $k\\in\\mathbb{N}$, $G^k\\in\\mathcal{C}$. Also $\\mathcal{C}$ is strongly closed under powers if for every $k\\in\\mathbb{N}$, if $G^k\\in\\mathcal{C}$, then $G^{k+1}\\in\\mathcal{C}$. It is known that circular arc graphs and proper circular arc graphs are closed under powers. But it is open whether these classes of graphs are also strongly closed under powers. In this paper we have settled these problems. ",
    "url": "https://arxiv.org/abs/2210.08782",
    "authors": [
      "Ashok Kumar Das",
      "Indrajit Paul"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2210.08784",
    "title": "Cross-layer Attention Network for Fine-grained Visual Categorization",
    "abstract": "Learning discriminative representations for subtle localized details plays a significant role in Fine-grained Visual Categorization (FGVC). Compared to previous attention-based works, our work does not explicitly define or localize the part regions of interest; instead, we leverage the complementary properties of different stages of the network, and build a mutual refinement mechanism between the mid-level feature maps and the top-level feature map by our proposed Cross-layer Attention Network (CLAN). Specifically, CLAN is composed of 1) the Cross-layer Context Attention (CLCA) module, which enhances the global context information in the intermediate feature maps with the help of the top-level feature map, thereby improving the expressive power of the middle layers, and 2) the Cross-layer Spatial Attention (CLSA) module, which takes advantage of the local attention in the mid-level feature maps to boost the feature extraction of local regions at the top-level feature maps. Experimental results show our approach achieves state-of-the-art on three publicly available fine-grained recognition datasets (CUB-200-2011, Stanford Cars and FGVC-Aircraft). Ablation studies and visualizations are provided to understand our approach. Experimental results show our approach achieves state-of-the-art on three publicly available fine-grained recognition datasets (CUB-200-2011, Stanford Cars and FGVC-Aircraft). ",
    "url": "https://arxiv.org/abs/2210.08784",
    "authors": [
      "Ranran Huang",
      "Yu Wang",
      "Huazhong Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08786",
    "title": "How \"troll\" are you? Measuring and detecting troll behavior in online  social networks",
    "abstract": "The detection of state-sponsored trolls acting in misinformation operations is an unsolved and critical challenge for the research community, with repercussions that go beyond the online realm. In this paper, we propose a novel approach for the detection of troll accounts, which consists of two steps. The first step aims at classifying trajectories of accounts' online activities as belonging to either a troll account or to an organic user account. In the second step, we exploit the classified trajectories to compute a metric, namely \"troll score\", which allows us to quantify the extent to which an account behaves like a troll. Experimental results show that our approach identifies accounts' trajectories with an AUC close to 99% and, accordingly, classify trolls and organic users with an AUC of 97%. Finally, we evaluate whether the proposed solution can be generalized to different contexts (e.g., discussions about Covid-19) and generic misbehaving users, showing promising results that will be further expanded in our future endeavors. ",
    "url": "https://arxiv.org/abs/2210.08786",
    "authors": [
      "Fatima Ezzeddine",
      "Luca Luceri",
      "Omran Ayoub",
      "Ihab Sbeity",
      "Gianluca Nogara",
      "Emilio Ferrara",
      "Silvia Giordano"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08792",
    "title": "Unifying Graph Contrastive Learning with Flexible Contextual Scopes",
    "abstract": "Graph contrastive learning (GCL) has recently emerged as an effective learning paradigm to alleviate the reliance on labelling information for graph representation learning. The core of GCL is to maximise the mutual information between the representation of a node and its contextual representation (i.e., the corresponding instance with similar semantic information) summarised from the contextual scope (e.g., the whole graph or 1-hop neighbourhood). This scheme distils valuable self-supervision signals for GCL training. However, existing GCL methods still suffer from limitations, such as the incapacity or inconvenience in choosing a suitable contextual scope for different datasets and building biased contrastiveness. To address aforementioned problems, we present a simple self-supervised learning method termed Unifying Graph Contrastive Learning with Flexible Contextual Scopes (UGCL for short). Our algorithm builds flexible contextual representations with tunable contextual scopes by controlling the power of an adjacency matrix. Additionally, our method ensures contrastiveness is built within connected components to reduce the bias of contextual representations. Based on representations from both local and contextual scopes, UGCL optimises a very simple contrastive loss function for graph representation learning. Essentially, the architecture of UGCL can be considered as a general framework to unify existing GCL methods. We have conducted intensive experiments and achieved new state-of-the-art performance in six out of eight benchmark datasets compared with self-supervised graph representation learning baselines. Our code has been open-sourced. ",
    "url": "https://arxiv.org/abs/2210.08792",
    "authors": [
      "Yizhen Zheng",
      "Yu Zheng",
      "Xiaofei Zhou",
      "Chen Gong",
      "Vincent CS Lee",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08793",
    "title": "Rethinking Trajectory Prediction via \"Team Game\"",
    "abstract": "To accurately predict trajectories in multi-agent settings, e.g. team games, it is important to effectively model the interactions among agents. Whereas a number of methods have been developed for this purpose, existing methods implicitly model these interactions as part of the deep net architecture. However, in the real world, interactions often exist at multiple levels, e.g. individuals may form groups, where interactions among groups and those among the individuals in the same group often follow significantly different patterns. In this paper, we present a novel formulation for multi-agent trajectory prediction, which explicitly introduces the concept of interactive group consensus via an interactive hierarchical latent space. This formulation allows group-level and individual-level interactions to be captured jointly, thus substantially improving the capability of modeling complex dynamics. On two multi-agent settings, i.e. team sports and pedestrians, the proposed framework consistently achieves superior performance compared to existing methods. ",
    "url": "https://arxiv.org/abs/2210.08793",
    "authors": [
      "Zikai Wei",
      "Xinge Zhu",
      "Bo Dai",
      "Dahua Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2210.08806",
    "title": "HCL-TAT: A Hybrid Contrastive Learning Method for Few-shot Event  Detection with Task-Adaptive Threshold",
    "abstract": "Conventional event detection models under supervised learning settings suffer from the inability of transfer to newly-emerged event types owing to lack of sufficient annotations. A commonly-adapted solution is to follow a identify-then-classify manner, which first identifies the triggers and then converts the classification task via a few-shot learning paradigm. However, these methods still fall far short of expectations due to: (i) insufficient learning of discriminative representations in low-resource scenarios, and (ii) trigger misidentification caused by the overlap of the learned representations of triggers and non-triggers. To address the problems, in this paper, we propose a novel Hybrid Contrastive Learning method with a Task-Adaptive Threshold (abbreviated as HCLTAT), which enables discriminative representation learning with a two-view contrastive loss (support-support and prototype-query), and devises a easily-adapted threshold to alleviate misidentification of triggers. Extensive experiments on the benchmark dataset FewEvent demonstrate the superiority of our method to achieve better results compared to the state-of-the-arts. All the code and data of this paper will be available for online public access. ",
    "url": "https://arxiv.org/abs/2210.08806",
    "authors": [
      "Ruihan Zhang",
      "Wei Wei",
      "Xian-Ling Mao",
      "Rui Fang",
      "Dangyang Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.08808",
    "title": "Towards Robust k-Nearest-Neighbor Machine Translation",
    "abstract": "k-Nearest-Neighbor Machine Translation (kNN-MT) becomes an important research direction of NMT in recent years. Its main idea is to retrieve useful key-value pairs from an additional datastore to modify translations without updating the NMT model. However, the underlying retrieved noisy pairs will dramatically deteriorate the model performance. In this paper, we conduct a preliminary study and find that this problem results from not fully exploiting the prediction of the NMT model. To alleviate the impact of noise, we propose a confidence-enhanced kNN-MT model with robust training. Concretely, we introduce the NMT confidence to refine the modeling of two important components of kNN-MT: kNN distribution and the interpolation weight. Meanwhile we inject two types of perturbations into the retrieved pairs for robust training. Experimental results on four benchmark datasets demonstrate that our model not only achieves significant improvements over current kNN-MT models, but also exhibits better robustness. Our code is available at https://github.com/DeepLearnXMU/Robust-knn-mt. ",
    "url": "https://arxiv.org/abs/2210.08808",
    "authors": [
      "Hui Jiang",
      "Ziyao Lu",
      "Fandong Meng",
      "Chulun Zhou",
      "Jie Zhou",
      "Degen Huang",
      "Jinsong Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.08811",
    "title": "CS-MLGCN : Multiplex Graph Convolutional Networks for Community Search  in Multiplex Networks",
    "abstract": "Community Search (CS) is one of the fundamental tasks in network science and has attracted much attention due to its ability to discover personalized communities with a wide range of applications. Given any query nodes, CS seeks to find a densely connected subgraph containing query nodes. Most existing approaches usually study networks with a single type of proximity between nodes, which defines a single view of a network. However, in many applications such as biological, social, and transportation networks, interactions between objects span multiple aspects, yielding networks with multiple views, called multiplex networks. Existing CS approaches in multiplex networks adopt pre-defined subgraph patterns to model the communities, which cannot find communities that do not have such pre-defined patterns in real-world networks. In this paper, we propose a query-driven graph convolutional network in multiplex networks, CS-MLGCN, that can capture flexible community structures by learning from the ground-truth communities in a data-driven fashion. CS-MLGCN first combines the local query-dependent structure and global graph embedding in each type of proximity and then uses an attention mechanism to incorporate information on different types of relations. Experiments on real-world graphs with ground-truth communities validate the quality of the solutions we obtain and the efficiency of our model. ",
    "url": "https://arxiv.org/abs/2210.08811",
    "authors": [
      "Ali Behrouz",
      "Farnoosh Hashemi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08812",
    "title": "ITSRN++: Stronger and Better Implicit Transformer Network for Continuous  Screen Content Image Super-Resolution",
    "abstract": "Nowadays, online screen sharing and remote cooperation are becoming ubiquitous. However, the screen content may be downsampled and compressed during transmission, while it may be displayed on large screens or the users would zoom in for detail observation at the receiver side. Therefore, developing a strong and effective screen content image (SCI) super-resolution (SR) method is demanded. We observe that the weight-sharing upsampler (such as deconvolution or pixel shuffle) could be harmful to sharp and thin edges in SCIs, and the fixed scale upsampler makes it inflexible to fit screens with various sizes. To solve this problem, we propose an implicit transformer network for continuous SCI SR (termed as ITSRN++). Specifically, we propose a modulation based transformer as the upsampler, which modulates the pixel features in discrete space via a periodic nonlinear function to generate features for continuous pixels. To enhance the extracted features, we further propose an enhanced transformer as the feature extraction backbone, where convolution and attention branches are utilized parallelly. Besides, we construct a large scale SCI2K dataset to facilitate the research on SCI SR. Experimental results on nine datasets demonstrate that the proposed method achieves state-of-the-art performance for SCI SR (outperforming SwinIR by 0.74 dB for x3 SR) and also works well for natural image SR. Our codes and dataset will be released upon the acceptance of this work. ",
    "url": "https://arxiv.org/abs/2210.08812",
    "authors": [
      "Sheng Shen",
      "Huanjing Yue",
      "Jingyu Yang",
      "Kun Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2210.08813",
    "title": "Test-Time Training for Graph Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) have made tremendous progress in the graph classification task. However, a performance gap between the training set and the test set has often been noticed. To bridge such gap, in this work we introduce the first test-time training framework for GNNs to enhance the model generalization capacity for the graph classification task. In particular, we design a novel test-time training strategy with self-supervised learning to adjust the GNN model for each test graph sample. Experiments on the benchmark datasets have demonstrated the effectiveness of the proposed framework, especially when there are distribution shifts between training set and test set. We have also conducted exploratory studies and theoretical analysis to gain deeper understandings on the rationality of the design of the proposed graph test time training framework (GT3). ",
    "url": "https://arxiv.org/abs/2210.08813",
    "authors": [
      "Yiqi Wang",
      "Chaozhuo Li",
      "Wei Jin",
      "Rui Li",
      "Jianan Zhao",
      "Jiliang Tang",
      "Xing Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08821",
    "title": "MoSE: Modality Split and Ensemble for Multimodal Knowledge Graph  Completion",
    "abstract": "Multimodal knowledge graph completion (MKGC) aims to predict missing entities in MKGs. Previous works usually share relation representation across modalities. This results in mutual interference between modalities during training, since for a pair of entities, the relation from one modality probably contradicts that from another modality. Furthermore, making a unified prediction based on the shared relation representation treats the input in different modalities equally, while their importance to the MKGC task should be different. In this paper, we propose MoSE, a Modality Split representation learning and Ensemble inference framework for MKGC. Specifically, in the training phase, we learn modality-split relation embeddings for each modality instead of a single modality-shared one, which alleviates the modality interference. Based on these embeddings, in the inference phase, we first make modality-split predictions and then exploit various ensemble methods to combine the predictions with different weights, which models the modality importance dynamically. Experimental results on three KG datasets show that MoSE outperforms state-of-the-art MKGC methods. Codes are available at https://github.com/OreOZhao/MoSE4MKGC. ",
    "url": "https://arxiv.org/abs/2210.08821",
    "authors": [
      "Yu Zhao",
      "Xiangrui Cai",
      "Yike Wu",
      "Haiwei Zhang",
      "Ying Zhang",
      "Guoqing Zhao",
      "Ning Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2210.08829",
    "title": "Intelligent Traffic Steering in Beyond 5G Open RAN based on LSTM Traffic  Prediction",
    "abstract": "Open radio access network (ORAN) Alliance offers a disaggregated RAN functionality built using open interface specifications between blocks. To efficiently support various competing services, \\textit{namely} enhanced mobile broadband (eMBB) and ultra-reliable and low-latency (uRLLC), the ORAN Alliance has introduced a standard approach toward more virtualized, open and intelligent networks. To realize benefits of ORAN in optimizing resource utilization, this paper studies an intelligent traffic steering (TS) scheme within the proposed disaggregated ORAN architecture. For this purpose, we propose a joint intelligent traffic prediction, flow-split distribution, dynamic user association and radio resource management (JIFDR) framework in the presence of unknown dynamic traffic demands. To adapt to dynamic environments on different time scales, we decompose the formulated optimization problem into two long-term and short-term subproblems, where the optimality of the later is strongly dependent on the optimal dynamic traffic demand. We then apply a long-short-term memory (LSTM) model to effectively solve the long-term subproblem, aiming to predict dynamic traffic demands, RAN slicing, and flow-split decisions. The resulting non-convex short-term subproblem is converted to a more computationally tractable form by exploiting successive convex approximations. Finally, simulation results are provided to demonstrate the effectiveness of the proposed algorithms compared to several well-known benchmark schemes. ",
    "url": "https://arxiv.org/abs/2210.08829",
    "authors": [
      "Fatemeh Kavehmadavani",
      "Van-Dinh Nguyen",
      "Thang X. Vu",
      "Symeon Chatzinotas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.08830",
    "title": "Disentangling Confidence Score Distribution for Out-of-Domain Intent  Detection with Energy-Based Learning",
    "abstract": "Detecting Out-of-Domain (OOD) or unknown intents from user queries is essential in a task-oriented dialog system. Traditional softmax-based confidence scores are susceptible to the overconfidence issue. In this paper, we propose a simple but strong energy-based score function to detect OOD where the energy scores of OOD samples are higher than IND samples. Further, given a small set of labeled OOD samples, we introduce an energy-based margin objective for supervised OOD detection to explicitly distinguish OOD samples from INDs. Comprehensive experiments and analysis prove our method helps disentangle confidence score distributions of IND and OOD data.\\footnote{Our code is available at \\url{https://github.com/pris-nlp/EMNLP2022-energy_for_OOD/}.} ",
    "url": "https://arxiv.org/abs/2210.08830",
    "authors": [
      "Yanan Wu",
      "Zhiyuan Zeng",
      "Keqing He",
      "Yutao Mou",
      "Pei Wang",
      "Yuanmeng Yan",
      "Weiran Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.08847",
    "title": "tegdet: An extensible Python Library for Anomaly Detection using  Time-Evolving Graphs",
    "abstract": "This paper presents a new Python library for anomaly detection in unsupervised learning approaches. The input for the library is a univariate time series representing observations of a given phenomenon. Then, it can identify anomalous epochs, i.e., time intervals where the observations are above a given percentile of a baseline distribution, defined by a dissimilarity metric. Using time-evolving graphs for the anomaly detection, the library leverages valuable information given by the inter-dependencies among data. Currently, the library implements 28 different dissimilarity metrics, and it has been designed to be easily extended with new ones. Through an API, the library exposes a complete functionality to carry out the anomaly detection. Summarizing, to the best of our knowledge, this library is the only one publicly available, that based on dynamic graphs, can be extended with other state-of-the-art anomaly detection techniques. Our experimentation shows promising results regarding the execution times of the algorithms and the accuracy of the implemented techniques. Additionally, the paper provides guidelines for setting the parameters of the detectors to improve their performance and prediction accuracy. ",
    "url": "https://arxiv.org/abs/2210.08847",
    "authors": [
      "Simona Bernardi",
      "Jos\u00e9 Merseguer",
      "Ra\u00fal Javierre"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08855",
    "title": "PeerDA: Data Augmentation via Modeling Peer Relation for Span  Identification Tasks",
    "abstract": "Span Identification (SpanID) is a family of NLP tasks that aims to detect and classify text spans. Different from previous works that merely leverage Subordinate (\\textsc{Sub}) relation about \\textit{if a span is an instance of a certain category} to train SpanID models, we explore Peer (\\textsc{Pr}) relation, which indicates that \\textit{the two spans are two different instances from the same category sharing similar features}, and propose a novel \\textbf{Peer} \\textbf{D}ata \\textbf{A}ugmentation (PeerDA) approach to treat span-span pairs with the \\textsc{Pr} relation as a kind of augmented training data. PeerDA has two unique advantages: (1) There are a large number of span-span pairs with the \\textsc{Pr} relation for augmenting the training data. (2) The augmented data can prevent over-fitting to the superficial span-category mapping by pushing SpanID models to leverage more on spans' semantics. Experimental results on ten datasets over four diverse SpanID tasks across seven domains demonstrate the effectiveness of PeerDA. Notably, seven of them achieve state-of-the-art results. ",
    "url": "https://arxiv.org/abs/2210.08855",
    "authors": [
      "Weiwen Xu",
      "Xin Li",
      "Yang Deng",
      "Lidong Bing",
      "Wai Lam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.08859",
    "title": "Social Biases in Automatic Evaluation Metrics for NLG",
    "abstract": "Many studies have revealed that word embeddings, language models, and models for specific downstream tasks in NLP are prone to social biases, especially gender bias. Recently these techniques have been gradually applied to automatic evaluation metrics for text generation. In the paper, we propose an evaluation method based on Word Embeddings Association Test (WEAT) and Sentence Embeddings Association Test (SEAT) to quantify social biases in evaluation metrics and discover that social biases are also widely present in some model-based automatic evaluation metrics. Moreover, we construct gender-swapped meta-evaluation datasets to explore the potential impact of gender bias in image caption and text summarization tasks. Results show that given gender-neutral references in the evaluation, model-based evaluation metrics may show a preference for the male hypothesis, and the performance of them, i.e. the correlation between evaluation metrics and human judgments, usually has more significant variation after gender swapping. ",
    "url": "https://arxiv.org/abs/2210.08859",
    "authors": [
      "Mingqi Gao",
      "Xiaojun Wan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08864",
    "title": "Reducing Collision Checking for Sampling-Based Motion Planning Using  Graph Neural Networks",
    "abstract": "Sampling-based motion planning is a popular approach in robotics for finding paths in continuous configuration spaces. Checking collision with obstacles is the major computational bottleneck in this process. We propose new learning-based methods for reducing collision checking to accelerate motion planning by training graph neural networks (GNNs) that perform path exploration and path smoothing. Given random geometric graphs (RGGs) generated from batch sampling, the path exploration component iteratively predicts collision-free edges to prioritize their exploration. The path smoothing component then optimizes paths obtained from the exploration stage. The methods benefit from the ability of GNNs of capturing geometric patterns from RGGs through batch sampling and generalize better to unseen environments. Experimental results show that the learned components can significantly reduce collision checking and improve overall planning efficiency in challenging high-dimensional motion planning tasks. ",
    "url": "https://arxiv.org/abs/2210.08864",
    "authors": [
      "Chenning Yu",
      "Sicun Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08870",
    "title": "Differential Evolution based Dual Adversarial Camouflage: Fooling Human  Eyes and Object Detectors",
    "abstract": "Recent studies reveal that deep neural network (DNN) based object detectors are vulnerable to adversarial attacks in the form of adding the perturbation to the images, leading to the wrong output of object detectors. Most current existing works focus on generating perturbed images, also called adversarial examples, to fool object detectors. Though the generated adversarial examples themselves can remain a certain naturalness, most of them can still be easily observed by human eyes, which limits their further application in the real world. To alleviate this problem, we propose a differential evolution based dual adversarial camouflage (DE_DAC) method, composed of two stages to fool human eyes and object detectors simultaneously. Specifically, we try to obtain the camouflage texture, which can be rendered over the surface of the object. In the first stage, we optimize the global texture to minimize the discrepancy between the rendered object and the scene images, making human eyes difficult to distinguish. In the second stage, we design three loss functions to optimize the local texture, making object detectors ineffective. In addition, we introduce the differential evolution algorithm to search for the near-optimal areas of the object to attack, improving the adversarial performance under certain attack area limitations. Besides, we also study the performance of adaptive DE_DAC, which can be adapted to the environment. Experiments show that our proposed method could obtain a good trade-off between the fooling human eyes and object detectors under multiple specific scenes and objects. ",
    "url": "https://arxiv.org/abs/2210.08870",
    "authors": [
      "Jialiang Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08879",
    "title": "Robust Planning for Human-Robot Joint Tasks with Explicit Reasoning on  Human Mental State",
    "abstract": "We consider the human-aware task planning problem where a human-robot team is given a shared task with a known objective to achieve. Recent approaches tackle it by modeling it as a team of independent, rational agents, where the robot plans for both agents' (shared) tasks. However, the robot knows that humans cannot be administered like artificial agents, so it emulates and predicts the human's decisions, actions, and reactions. Based on earlier approaches, we describe a novel approach to solve such problems, which models and uses execution-time observability conventions. Abstractly, this modeling is based on situation assessment, which helps our approach capture the evolution of individual agents' beliefs and anticipate belief divergences that arise in practice. It decides if and when belief alignment is needed and achieves it with communication. These changes improve the solver's performance: (a) communication is effectively used, and (b) robust for more realistic and challenging problems. ",
    "url": "https://arxiv.org/abs/2210.08879",
    "authors": [
      "Anthony Favier",
      "Shashank Shekhar",
      "Rachid Alami"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2210.08883",
    "title": "Social Media App Usage in Relation with PHQ-9 Depression Scores during  the COVID-19 Pandemic",
    "abstract": "With about 300 million affected people, major depressive disorder (MDD) is one of the most common diseases worldwide. During the COVID-19 pandemic, the number of cases increased even further, by 28%. Many factors may be correlated with MDD, including the excessive use of social media apps. In this paper, we investigated the relationship between the use of social media and communication apps and depressive symptoms during the COVID-19 pandemic. The pandemic and social distancing like lockdowns probably changed smartphone usage times and usage patterns. While previous studies have shown an association between depression and social media usage, we report about the situation during these special circumstances.We employed a log-linear regression to examine the association of social media and communication app usage and depression. To quantify the usage, we applied the total usage time in hours of social media apps (e.g., WhatsApp, Facebook) as well as communication apps (Phone and Messaging) within one week. To measure depressive symptoms, we used the PHQ-9 score. We discovered a significant association between the usage time and the PHQ-9 score (beta=0.0084, p-value=0.010). We conclude that social media usage is a robust marker for depression severity and future research should focus on a better understanding of the underlying causality and potential counter-measures. ",
    "url": "https://arxiv.org/abs/2210.08883",
    "authors": [
      "Lena Mulansky",
      "R\u00fcdiger Pryss",
      "Caroline Cohrdes",
      "Harald Baumeister",
      "Felix Beierle"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.08884",
    "title": "HyperDomainNet: Universal Domain Adaptation for Generative Adversarial  Networks",
    "abstract": "Domain adaptation framework of GANs has achieved great progress in recent years as a main successful approach of training contemporary GANs in the case of very limited training data. In this work, we significantly improve this framework by proposing an extremely compact parameter space for fine-tuning the generator. We introduce a novel domain-modulation technique that allows to optimize only 6 thousand-dimensional vector instead of 30 million weights of StyleGAN2 to adapt to a target domain. We apply this parameterization to the state-of-art domain adaptation methods and show that it has almost the same expressiveness as the full parameter space. Additionally, we propose a new regularization loss that considerably enhances the diversity of the fine-tuned generator. Inspired by the reduction in the size of the optimizing parameter space we consider the problem of multi-domain adaptation of GANs, i.e. setting when the same model can adapt to several domains depending on the input query. We propose the HyperDomainNet that is a hypernetwork that predicts our parameterization given the target domain. We empirically confirm that it can successfully learn a number of domains at once and may even generalize to unseen domains. Source code can be found at https://github.com/MACderRu/HyperDomainNet ",
    "url": "https://arxiv.org/abs/2210.08884",
    "authors": [
      "Aibek Alanov",
      "Vadim Titov",
      "Dmitry Vetrov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08901",
    "title": "Contrastive Language-Image Pre-Training with Knowledge Graphs",
    "abstract": "Recent years have witnessed the fast development of large-scale pre-training frameworks that can extract multi-modal representations in a unified form and achieve promising performances when transferred to downstream tasks. Nevertheless, existing approaches mainly focus on pre-training with simple image-text pairs, while neglecting the semantic connections between concepts from different modalities. In this paper, we propose a knowledge-based pre-training framework, dubbed Knowledge-CLIP, which injects semantic information into the widely used CLIP model. Through introducing knowledge-based objectives in the pre-training process and utilizing different types of knowledge graphs as training data, our model can semantically align the representations in vision and language with higher quality, and enhance the reasoning ability across scenarios and modalities. Extensive experiments on various vision-language downstream tasks demonstrate the effectiveness of Knowledge-CLIP compared with the original CLIP and competitive baselines. ",
    "url": "https://arxiv.org/abs/2210.08901",
    "authors": [
      "Xuran Pan",
      "Tianzhu Ye",
      "Dongchen Han",
      "Shiji Song",
      "Gao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08902",
    "title": "Beyond Model Interpretability: On the Faithfulness and Adversarial  Robustness of Contrastive Textual Explanations",
    "abstract": "Contrastive explanation methods go beyond transparency and address the contrastive aspect of explanations. Such explanations are emerging as an attractive option to provide actionable change to scenarios adversely impacted by classifiers' decisions. However, their extension to textual data is under-explored and there is little investigation on their vulnerabilities and limitations. This work motivates textual counterfactuals by laying the ground for a novel evaluation scheme inspired by the faithfulness of explanations. Accordingly, we extend the computation of three metrics, proximity,connectedness and stability, to textual data and we benchmark two successful contrastive methods, POLYJUICE and MiCE, on our suggested metrics. Experiments on sentiment analysis data show that the connectedness of counterfactuals to their original counterparts is not obvious in both models. More interestingly, the generated contrastive texts are more attainable with POLYJUICE which highlights the significance of latent representations in counterfactual search. Finally, we perform the first semantic adversarial attack on textual recourse methods. The results demonstrate the robustness of POLYJUICE and the role that latent input representations play in robustness and reliability. ",
    "url": "https://arxiv.org/abs/2210.08902",
    "authors": [
      "Julia El Zini",
      "Mariette Awad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2210.08914",
    "title": "A Category of Surface-Embedded Graphs",
    "abstract": "We introduce a categorical formalism for rewriting surface-embedded graphs. Such graphs can represent string diagrams in a non-symmetric setting where we guarantee that the wires do not intersect each other. The main technical novelty is a new formulation of double pushout rewriting on graphs which explicitly records the boundary of the rewrite. Using this boundary structure we can augment these graphs with a rotation system, allowing the surface topology to be incorporated. ",
    "url": "https://arxiv.org/abs/2210.08914",
    "authors": [
      "Malin Altenm\u00fcller",
      "Ross Duncan"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2210.08922",
    "title": "Joint Multilingual Knowledge Graph Completion and Alignment",
    "abstract": "Knowledge graph (KG) alignment and completion are usually treated as two independent tasks. While recent work has leveraged entity and relation alignments from multiple KGs, such as alignments between multilingual KGs with common entities and relations, a deeper understanding of the ways in which multilingual KG completion (MKGC) can aid the creation of multilingual KG alignments (MKGA) is still limited. Motivated by the observation that structural inconsistencies -- the main challenge for MKGA models -- can be mitigated through KG completion methods, we propose a novel model for jointly completing and aligning knowledge graphs. The proposed model combines two components that jointly accomplish KG completion and alignment. These two components employ relation-aware graph neural networks that we propose to encode multi-hop neighborhood structures into entity and relation representations. Moreover, we also propose (i) a structural inconsistency reduction mechanism to incorporate information from the completion into the alignment component, and (ii) an alignment seed enlargement and triple transferring mechanism to enlarge alignment seeds and transfer triples during KGs alignment. Extensive experiments on a public multilingual benchmark show that our proposed model outperforms existing competitive baselines, obtaining new state-of-the-art results on both MKGC and MKGA tasks. ",
    "url": "https://arxiv.org/abs/2210.08922",
    "authors": [
      "Vinh Tong",
      "Dat Quoc Nguyen",
      "Trung Thanh Huynh",
      "Thanh Tam Nguyen",
      "Nguyen Quoc Viet Hung",
      "Mathias Niepert"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.08928",
    "title": "Robust Variable-Speed Variable-Pitch Power Regulation of Tethered-Wing  Systems Based on Gain-Scheduled H-infinity Synthesis",
    "abstract": "This paper deals with the power regulation of tethered-wing systems while considering the robust performance and the mitigation of dynamic mechanical loads and power fluctuations. The strategy is to maximize the energy capture during low-speed wind by controlling the reeling-speed and limiting it during high-speed wind by adjusting both the tether's force and the speed. The H-infinity method is employed to synthesize the output-feedback controllers while making compromises between the control objectives. The synthesis procedure is based on a linear parameter varying (LPV) system that expresses the flexible longitudinal dynamics of the reeling-mechanism, the tether, and the kite. We carry out various simulations to demonstrate the controllers' performance, including the implementation of the control strategy in a 3-dimensional tethered-wing system simulator with a realistic turbulent wind field ",
    "url": "https://arxiv.org/abs/2210.08928",
    "authors": [
      "Mani Kakavand",
      "Amin Nikoobin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.08929",
    "title": "DE-CROP: Data-efficient Certified Robustness for Pretrained Classifiers",
    "abstract": "Certified defense using randomized smoothing is a popular technique to provide robustness guarantees for deep neural networks against l2 adversarial attacks. Existing works use this technique to provably secure a pretrained non-robust model by training a custom denoiser network on entire training data. However, access to the training set may be restricted to a handful of data samples due to constraints such as high transmission cost and the proprietary nature of the data. Thus, we formulate a novel problem of \"how to certify the robustness of pretrained models using only a few training samples\". We observe that training the custom denoiser directly using the existing techniques on limited samples yields poor certification. To overcome this, our proposed approach (DE-CROP) generates class-boundary and interpolated samples corresponding to each training sample, ensuring high diversity in the feature space of the pretrained classifier. We train the denoiser by maximizing the similarity between the denoised output of the generated sample and the original training sample in the classifier's logit space. We also perform distribution level matching using domain discriminator and maximum mean discrepancy that yields further benefit. In white box setup, we obtain significant improvements over the baseline on multiple benchmark datasets and also report similar performance under the challenging black box setup. ",
    "url": "https://arxiv.org/abs/2210.08929",
    "authors": [
      "Gaurav Kumar Nayak",
      "Ruchit Rawal",
      "Anirban Chakraborty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08936",
    "title": "S$^3$-NeRF: Neural Reflectance Field from Shading and Shadow under a  Single Viewpoint",
    "abstract": "In this paper, we address the \"dual problem\" of multi-view scene reconstruction in which we utilize single-view images captured under different point lights to learn a neural scene representation. Different from existing single-view methods which can only recover a 2.5D scene representation (i.e., a normal / depth map for the visible surface), our method learns a neural reflectance field to represent the 3D geometry and BRDFs of a scene. Instead of relying on multi-view photo-consistency, our method exploits two information-rich monocular cues, namely shading and shadow, to infer scene geometry. Experiments on multiple challenging datasets show that our method is capable of recovering 3D geometry, including both visible and invisible parts, of a scene from single-view images. Thanks to the neural reflectance field representation, our method is robust to depth discontinuities. It supports applications like novel-view synthesis and relighting. Our code and model can be found at https://ywq.github.io/s3nerf. ",
    "url": "https://arxiv.org/abs/2210.08936",
    "authors": [
      "Wenqi Yang",
      "Guanying Chen",
      "Chaofeng Chen",
      "Zhenfang Chen",
      "Kwan-Yee K. Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08951",
    "title": "Approximating Continuous Convolutions for Deep Network Compression",
    "abstract": "We present ApproxConv, a novel method for compressing the layers of a convolutional neural network. Reframing conventional discrete convolution as continuous convolution of parametrised functions over space, we use functional approximations to capture the essential structures of CNN filters with fewer parameters than conventional operations. Our method is able to reduce the size of trained CNN layers requiring only a small amount of fine-tuning. We show that our method is able to compress existing deep network models by half whilst losing only 1.86% accuracy. Further, we demonstrate that our method is compatible with other compression methods like quantisation allowing for further reductions in model size. ",
    "url": "https://arxiv.org/abs/2210.08951",
    "authors": [
      "Theo W. Costain",
      "Victor Adrian Prisacariu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08956",
    "title": "A Novel Membership Inference Attack against Dynamic Neural Networks by  Utilizing Policy Networks Information",
    "abstract": "Unlike traditional static deep neural networks (DNNs), dynamic neural networks (NNs) adjust their structures or parameters to different inputs to guarantee accuracy and computational efficiency. Meanwhile, it has been an emerging research area in deep learning recently. Although traditional static DNNs are vulnerable to the membership inference attack (MIA) , which aims to infer whether a particular point was used to train the model, little is known about how such an attack performs on the dynamic NNs. In this paper, we propose a novel MI attack against dynamic NNs, leveraging the unique policy networks mechanism of dynamic NNs to increase the effectiveness of membership inference. We conducted extensive experiments using two dynamic NNs, i.e., GaterNet, BlockDrop, on four mainstream image classification tasks, i.e., CIFAR-10, CIFAR-100, STL-10, and GTSRB. The evaluation results demonstrate that the control-flow information can significantly promote the MIA. Based on backbone-finetuning and information-fusion, our method achieves better results than baseline attack and traditional attack using intermediate information. ",
    "url": "https://arxiv.org/abs/2210.08956",
    "authors": [
      "Pan Li",
      "Peizhuo Lv",
      "Shenchen Zhu",
      "Ruigang Liang",
      "Kai Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08961",
    "title": "Determinants Influencing Intention to Use Social Commerce for Shopping  in developing countries: A Case Study of Oman",
    "abstract": "Social media has had a significant impact on our individual lives, including our behavior regarding the purchasing of daily products. This study investigates the factors influencing Omani nationals' intentions to obtain products via social commerce. The researcher surveyed 202 participants and utilized the Technology Acceptance Model to develop the theoretical framework. The data collection was analyzed statistically using an appropriate testing mechanism. Statistical methods, including Cronbach's alpha and multiple linear regression, were utilized for reliability and hypotheses testing. After analyzing the collected data and testing the hypotheses, the findings indicated that perceived usefulness, enjoyment, and ease of use of social commerce affect positively on Omani nationals' intentions to utilize social commerce for shopping. The independent variables had a statistically significant impact on the intention to use social commerce shopping for products; these explain 69.9% of the variation on customers intention to utilize social commerce for shopping. ",
    "url": "https://arxiv.org/abs/2210.08961",
    "authors": [
      "Shamma Al Harizi",
      "Maryam Al Areimi",
      "Abdul. Khalique Shaikh"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2210.08971",
    "title": "APGKT: Exploiting Associative Path on Skills Graph for Knowledge Tracing",
    "abstract": "Knowledge tracing (KT) is a fundamental task in educational data mining that mainly focuses on students' dynamic cognitive states of skills. The question-answering process of students can be regarded as a thinking process that considers the following two problems. One problem is which skills are needed to answer the question, and the other is how to use these skills in order. If a student wants to answer a question correctly, the student should not only master the set of skills involved in the question but also think and obtain the associative path on the skills graph. The nodes in the associative path refer to the skills needed and the path shows the order of using them. The associative path is referred to as the skill mode. Thus, obtaining the skill modes is the key to answering questions successfully. However, most existing KT models only focus on a set of skills, without considering the skill modes. We propose a KT model, called APGKT, that exploits skill modes. Specifically, we extract the subgraph topology of the skills involved in the question and combine the difficulty level of the skills to obtain the skill modes via encoding; then, through multi-layer recurrent neural networks, we obtain a student's higher-order cognitive states of skills, which is used to predict the student's future answering performance. Experiments on five benchmark datasets validate the effectiveness of the proposed model. ",
    "url": "https://arxiv.org/abs/2210.08971",
    "authors": [
      "Haotian Zhang",
      "Chenyang Bu",
      "Fei Liu",
      "Shuochen Liu",
      "Yuhong Zhang",
      "Xuegang Hu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08973",
    "title": "FAIR for AI: An interdisciplinary, international, inclusive, and diverse  community building perspective",
    "abstract": "A foundational set of findable, accessible, interoperable, and reusable (FAIR) principles were proposed in 2016 as prerequisites for proper data management and stewardship, with the goal of enabling the reusability of scholarly data. The principles were also meant to apply to other digital assets, at a high level, and over time, the FAIR guiding principles have been re-interpreted or extended to include the software, tools, algorithms, and workflows that produce data. FAIR principles are now being adapted in the context of AI models and datasets. Here, we present the perspectives, vision, and experiences of researchers from different countries, disciplines, and backgrounds who are leading the definition and adoption of FAIR principles in their communities of practice, and discuss outcomes that may result from pursuing and incentivizing FAIR AI research. The material for this report builds on the FAIR for AI Workshop held at Argonne National Laboratory on June 7, 2022. ",
    "url": "https://arxiv.org/abs/2210.08973",
    "authors": [
      "E.A. Huerta",
      "Ben Blaiszik",
      "L. Catherine Brinson",
      "Kristofer E. Bouchard",
      "Daniel Diaz",
      "Caterina Doglioni",
      "Javier M. Duarte",
      "Murali Emani",
      "Ian Foster",
      "Geoffrey Fox",
      "Philip Harris",
      "Lukas Heinrich",
      "Shantenu Jha",
      "Daniel S. Katz",
      "Volodymyr Kindratenko",
      "Christine R. Kirkpatrick",
      "Kati Lassila-Perini",
      "Ravi K. Madduri",
      "Mark S. Neubauer",
      "Fotis E. Psomopoulos",
      "Avik Roy",
      "Oliver R\u00fcbel",
      "Zhizhen Zhao",
      "Ruike Zhu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2210.08988",
    "title": "Heterogeneous Feature Distillation Network for SAR Image Semantic  Segmentation",
    "abstract": "Semantic segmentation for SAR (Synthetic Aperture Radar) images has attracted increasing attention in the remote sensing community recently, due to SAR's all-time and all-weather imaging capability. However, SAR images are generally more difficult to be segmented than their EO (Electro-Optical) counterparts, since speckle noises and layovers are inevitably involved in SAR images. To address this problem, we investigate how to introduce EO features to assist the training of a SAR-segmentation model, and propose a heterogeneous feature distillation network for segmenting SAR images, called HFD-Net, where a SAR-segmentation student model gains knowledge from a pre-trained EO-segmentation teacher model. In the proposed HFD-Net, both the student and teacher models employ an identical architecture but different parameter configurations, and a heterogeneous feature distillation model is explored for transferring latent EO features from the teacher model to the student model and then enhancing the ability of the student model for SAR image segmentation. In addition, a heterogeneous feature alignment module is explored to aggregate multi-scale features for segmentation in each of the student model and teacher model. Extensive experimental results on two public datasets demonstrate that the proposed HFD-Net outperforms seven state-of-the-art SAR image semantic segmentation methods. ",
    "url": "https://arxiv.org/abs/2210.08988",
    "authors": [
      "Gao Mengyu",
      "Dong Qiulei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.08994",
    "title": "Knowledge Representation for Conceptual, Motivational, and Affective  Processes in Natural Language Communication",
    "abstract": "Natural language communication is an intricate and complex process. The speaker usually begins with an intention and motivation of what is to be communicated, and what effects are expected from the communication, while taking into consideration the listener's mental model to concoct an appropriate sentence. The listener likewise has to interpret what the speaker means, and respond accordingly, also with the speaker's mental state in mind. To do this successfully, conceptual, motivational, and affective processes have to be represented appropriately to drive the language generation and understanding processes. Language processing has succeeded well with the big data approach in applications such as chatbots and machine translation. However, in human-robot collaborative social communication and in using natural language for delivering precise instructions to robots, a deeper representation of the conceptual, motivational, and affective processes is needed. This paper capitalizes on the UGALRS (Unified General Autonomous and Language Reasoning System) framework and the CD+ (Conceptual Representation Plus) representational scheme to illustrate how social communication through language is supported by a knowledge representational scheme that handles conceptual, motivational, and affective processes in a deep and general way. Though a small set of concepts, motivations, and emotions is treated in this paper, its main contribution is in articulating a general framework of knowledge representation and processing to link these aspects together in serving the purpose of natural language communication for an intelligent system. ",
    "url": "https://arxiv.org/abs/2210.08994",
    "authors": [
      "Seng-Beng Ho",
      "Zhaoxia Wang",
      "Boon-Kiat Quek",
      "Erik Cambria"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.08998",
    "title": "A Symbolic Representation of Human Posture for Interpretable Learning  and Reasoning",
    "abstract": "Robots that interact with humans in a physical space or application need to think about the person's posture, which typically comes from visual sensors like cameras and infra-red. Artificial intelligence and machine learning algorithms use information from these sensors either directly or after some level of symbolic abstraction, and the latter usually partitions the range of observed values to discretize the continuous signal data. Although these representations have been effective in a variety of algorithms with respect to accuracy and task completion, the underlying models are rarely interpretable, which also makes their outputs more difficult to explain to people who request them. Instead of focusing on the possible sensor values that are familiar to a machine, we introduce a qualitative spatial reasoning approach that describes the human posture in terms that are more familiar to people. This paper explores the derivation of our symbolic representation at two levels of detail and its preliminary use as features for interpretable activity recognition. ",
    "url": "https://arxiv.org/abs/2210.08998",
    "authors": [
      "Richard G. Freedman",
      "Joseph B. Mueller",
      "Jack Ladwig",
      "Steven Johnston",
      "Helen Wauck",
      "Ruta Wheelock",
      "Hayley Borck"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.09011",
    "title": "ANFIS-based prediction of power generation for combined cycle power  plant",
    "abstract": "This paper presents the application of an adaptive neuro-fuzzy inference system (ANFIS) to predict the generated electrical power in a combined cycle power plant. The ANFIS architecture is implemented in MATLAB through a code that utilizes a hybrid algorithm that combines gradient descent and the least square estimator to train the network. The Model is verified by applying it to approximate a nonlinear equation with three variables, the time series Mackey-Glass equation and the ANFIS toolbox in MATLAB. Once its validity is confirmed, ANFIS is implemented to forecast the generated electrical power by the power plant. The ANFIS has three inputs: temperature, pressure, and relative humidity. Each input is fuzzified by three Gaussian membership functions. The first-order Sugeno type defuzzification approach is utilized to evaluate a crisp output. Proposed ANFIS is cable of successfully predicting power generation with extremely high accuracy and being much faster than Toolbox, which makes it a promising tool for energy generation applications. ",
    "url": "https://arxiv.org/abs/2210.09011",
    "authors": [
      "Mary Pa",
      "Amin Kazemi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.09012",
    "title": "SAICL: Student Modelling with Interaction-level Auxiliary Contrastive  Tasks for Knowledge Tracing and Dropout Prediction",
    "abstract": "Knowledge tracing and dropout prediction are crucial for online education to estimate students' knowledge states or to prevent dropout rates. While traditional systems interacting with students suffered from data sparsity and overfitting, recent sample-level contrastive learning helps to alleviate this issue. One major limitation of sample-level approaches is that they regard students' behavior interaction sequences as a bundle, so they often fail to encode temporal contexts and track their dynamic changes, making it hard to find optimal representations for knowledge tracing and dropout prediction. To apply temporal context within the sequence, this study introduces a novel student modeling framework, SAICL: \\textbf{s}tudent modeling with \\textbf{a}uxiliary \\textbf{i}nteraction-level \\textbf{c}ontrastive \\textbf{l}earning. In detail, SAICL can utilize both proposed self-supervised/supervised interaction-level contrastive objectives: MilCPC (\\textbf{M}ulti-\\textbf{I}nteraction-\\textbf{L}evel \\textbf{C}ontrastive \\textbf{P}redictive \\textbf{C}oding) and SupCPC (\\textbf{Sup}ervised \\textbf{C}ontrastive \\textbf{P}redictive \\textbf{C}oding). While previous sample-level contrastive methods for student modeling are highly dependent on data augmentation methods, the SAICL is free of data augmentation while showing better performance in both self-supervised and supervised settings. By combining cross-entropy with contrastive objectives, the proposed SAICL achieved comparable knowledge tracing and dropout prediction performance with other state-of-art models without compromising inference costs. ",
    "url": "https://arxiv.org/abs/2210.09012",
    "authors": [
      "Jungbae Park",
      "Jinyoung Kim",
      "Soonwoo Kwan",
      "Sang Wan Lee"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09013",
    "title": "Knowledge Tracing for Complex Problem Solving: Granular Rank-Based  Tensor Factorization",
    "abstract": "Knowledge Tracing (KT), which aims to model student knowledge level and predict their performance, is one of the most important applications of user modeling. Modern KT approaches model and maintain an up-to-date state of student knowledge over a set of course concepts according to students' historical performance in attempting the problems. However, KT approaches were designed to model knowledge by observing relatively small problem-solving steps in Intelligent Tutoring Systems. While these approaches were applied successfully to model student knowledge by observing student solutions for simple problems, they do not perform well for modeling complex problem solving in students.M ost importantly, current models assume that all problem attempts are equally valuable in quantifying current student knowledge.However, for complex problems that involve many concepts at the same time, this assumption is deficient. In this paper, we argue that not all attempts are equivalently important in discovering students' knowledge state, and some attempts can be summarized together to better represent student performance. We propose a novel student knowledge tracing approach, Granular RAnk based TEnsor factorization (GRATE), that dynamically selects student attempts that can be aggregated while predicting students' performance in problems and discovering the concepts presented in them. Our experiments on three real-world datasets demonstrate the improved performance of GRATE, compared to the state-of-the-art baselines, in the task of student performance prediction. Our further analysis shows that attempt aggregation eliminates the unnecessary fluctuations from students' discovered knowledge states and helps in discovering complex latent concepts in the problems. ",
    "url": "https://arxiv.org/abs/2210.09013",
    "authors": [
      "Chunpai Wang",
      "Shaghayegh Sahebi",
      "Siqian Zhao",
      "Peter Brusilovsky",
      "Laura O. Moraes"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09017",
    "title": "Robust Data-Driven Moving Horizon Estimation for Linear Discrete-Time  Systems",
    "abstract": "In this paper, a robust data-driven moving horizon estimation (MHE) scheme for linear time-invariant discrete-time systems is introduced. The scheme solely relies on offline collected data without employing any system identification step. First, robust global exponential stability is proven under standard assumptions for a nominal case where the offline collected data are noise-free but the online measured outputs are corrupted by some non-vanishing measurement noise. Second, practical robust exponential stability is shown for the case where, in addition to the measurement noise in the online phase, the offline collected data are corrupted by some non-vanishing and bounded noise. The behavior of the novel robust data-driven MHE scheme is illustrated by means of a simulation example and compared to a standard model-based MHE, where the model is identified using the same offline data as for the data-driven MHE. ",
    "url": "https://arxiv.org/abs/2210.09017",
    "authors": [
      "Tobias M. Wolff",
      "Victor G. Lopez",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.09020",
    "title": "Defects of Convolutional Decoder Networks in Frequency Representation",
    "abstract": "In this paper, we prove representation bottlenecks of a cascaded convolutional decoder network, considering the capacity of representing different frequency components of an input sample. We conduct the discrete Fourier transform on each channel of the feature map in an intermediate layer of the decoder network. Then, we introduce the rule of the forward propagation of such intermediate-layer spectrum maps, which is equivalent to the forward propagation of feature maps through a convolutional layer. Based on this, we find that each frequency component in the spectrum map is forward propagated independently with other frequency components. Furthermore, we prove two bottlenecks in representing feature spectrums. First, we prove that the convolution operation, the zero-padding operation, and a set of other settings all make a convolutional decoder network more likely to weaken high-frequency components. Second, we prove that the upsampling operation generates a feature spectrum, in which strong signals repetitively appears at certain frequencies. ",
    "url": "https://arxiv.org/abs/2210.09020",
    "authors": [
      "Ling Tang",
      "Wen Shen",
      "Zhanpeng Zhou",
      "Yuefeng Chen",
      "Quanshi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.09021",
    "title": "Histopathological Image Classification based on Self-Supervised Vision  Transformer and Weak Labels",
    "abstract": "Whole Slide Image (WSI) analysis is a powerful method to facilitate the diagnosis of cancer in tissue samples. Automating this diagnosis poses various issues, most notably caused by the immense image resolution and limited annotations. WSIs commonly exhibit resolutions of 100Kx100K pixels. Annotating cancerous areas in WSIs on the pixel level is prohibitively labor-intensive and requires a high level of expert knowledge. Multiple instance learning (MIL) alleviates the need for expensive pixel-level annotations. In MIL, learning is performed on slide-level labels, in which a pathologist provides information about whether a slide includes cancerous tissue. Here, we propose Self-ViT-MIL, a novel approach for classifying and localizing cancerous areas based on slide-level annotations, eliminating the need for pixel-wise annotated training data. Self-ViT- MIL is pre-trained in a self-supervised setting to learn rich feature representation without relying on any labels. The recent Vision Transformer (ViT) architecture builds the feature extractor of Self-ViT-MIL. For localizing cancerous regions, a MIL aggregator with global attention is utilized. To the best of our knowledge, Self-ViT- MIL is the first approach to introduce self-supervised ViTs in MIL-based WSI analysis tasks. We showcase the effectiveness of our approach on the common Camelyon16 dataset. Self-ViT-MIL surpasses existing state-of-the-art MIL-based approaches in terms of accuracy and area under the curve (AUC). ",
    "url": "https://arxiv.org/abs/2210.09021",
    "authors": [
      "Ahmet Gokberk Gul",
      "Oezdemir Cetin",
      "Christoph Reich",
      "Tim Prangemeier",
      "Nadine Flinner",
      "Heinz Koeppl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09028",
    "title": "Attribute Inference Attacks in Online Multiplayer Video Games: a Case  Study on Dota2",
    "abstract": "Did you know that over 70 million of Dota2 players have their in-game data freely accessible? What if such data is used in malicious ways? This paper is the first to investigate such a problem. Motivated by the widespread popularity of video games, we propose the first threat model for Attribute Inference Attacks (AIA) in the Dota2 context. We explain how (and why) attackers can exploit the abundant public data in the Dota2 ecosystem to infer private information about its players. Due to lack of concrete evidence on the efficacy of our AIA, we empirically prove and assess their impact in reality. By conducting an extensive survey on $\\sim$500 Dota2 players spanning over 26k matches, we verify whether a correlation exists between a player's Dota2 activity and their real-life. Then, after finding such a link ($p\\!<\\!0.01$ and $\\rho>0.3$), we ethically perform diverse AIA. We leverage the capabilities of machine learning to infer real-life attributes of the respondents of our survey by using their publicly available in-game data. Our results show that, by applying domain expertise, some AIA can reach up to 98% precision and over 90% accuracy. This paper hence raises the alarm on a subtle, but concrete threat that can potentially affect the entire competitive gaming landscape. We alerted the developers of Dota2. ",
    "url": "https://arxiv.org/abs/2210.09028",
    "authors": [
      "Pier Paolo Tricomi",
      "Lisa Facciolo",
      "Giovanni Apruzzese",
      "Mauro Conti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09043",
    "title": "ST-former for short-term passenger flow prediction during COVID-19 in  urban rail transit system",
    "abstract": "Accurate passenger flow prediction of urban rail transit is essential for improving the performance of intelligent transportation systems, especially during the epidemic. How to dynamically model the complex spatiotemporal dependencies of passenger flow is the main issue in achieving accurate passenger flow prediction during the epidemic. To solve this issue, this paper proposes a brand-new transformer-based architecture called STformer under the encoder-decoder framework specifically for COVID-19. Concretely, we develop a modified self-attention mechanism named Causal-Convolution ProbSparse Self-Attention (CPSA) to model the multiple temporal dependencies of passenger flow with low computational costs. To capture the complex and dynamic spatial dependencies, we introduce a novel Adaptive Multi-Graph Convolution Network (AMGCN) by leveraging multiple graphs in a self-adaptive manner. Additionally, the Multi-source Data Fusion block fuses the passenger flow data, COVID-19 confirmed case data, and the relevant social media data to study the impact of COVID-19 to passenger flow. Experiments on real-world passenger flow datasets demonstrate the superiority of ST-former over the other eleven state-of-the-art methods. Several ablation studies are carried out to verify the effectiveness and reliability of our model structure. Results can provide critical insights for the operation of URT systems. ",
    "url": "https://arxiv.org/abs/2210.09043",
    "authors": [
      "Shuxin Zhang",
      "Jinlei Zhang",
      "Lixing Yang",
      "Chengcheng Wang",
      "Ziyou Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.09049",
    "title": "SpanProto: A Two-stage Span-based Prototypical Network for Few-shot  Named Entity Recognition",
    "abstract": "Few-shot Named Entity Recognition (NER) aims to identify named entities with very little annotated data. Previous methods solve this problem based on token-wise classification, which ignores the information of entity boundaries, and inevitably the performance is affected by the massive non-entity tokens. To this end, we propose a seminal span-based prototypical network (SpanProto) that tackles few-shot NER via a two-stage approach, including span extraction and mention classification. In the span extraction stage, we transform the sequential tags into a global boundary matrix, enabling the model to focus on the explicit boundary information. For mention classification, we leverage prototypical learning to capture the semantic representations for each labeled span and make the model better adapt to novel-class entities. To further improve the model performance, we split out the false positives generated by the span extractor but not labeled in the current episode set, and then present a margin-based loss to separate them from each prototype region. Experiments over multiple benchmarks demonstrate that our model outperforms strong baselines by a large margin. ",
    "url": "https://arxiv.org/abs/2210.09049",
    "authors": [
      "Jianing Wang",
      "Chengyu Wang",
      "Chuanqi Tan",
      "Minghui Qiu",
      "Songfang Huang",
      "Jun Huang",
      "Ming Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.09055",
    "title": "Data-driven multi-scale modeling and robust optimization of composite  structure with uncertainty quantification",
    "abstract": "It is important to accurately model materials' properties at lower length scales (micro-level) while translating the effects to the components and/or system level (macro-level) can significantly reduce the amount of experimentation required to develop new technologies. Robustness analysis of fuel and structural performance for harsh environments (such as power uprated reactor systems or aerospace applications) using machine learning-based multi-scale modeling and robust optimization under uncertainties are required. The fiber and matrix material characteristics are potential sources of uncertainty at the microscale. The stacking sequence (angles of stacking and thickness of layers) of composite layers causes meso-scale uncertainties. It is also possible for macro-scale uncertainties to arise from system properties, like the load or the initial conditions. This chapter demonstrates advanced data-driven methods and outlines the specific capability that must be developed/added for the multi-scale modeling of advanced composite materials. This chapter proposes a multi-scale modeling method for composite structures based on a finite element method (FEM) simulation driven by surrogate models/emulators based on microstructurally informed meso-scale materials models to study the impact of operational parameters/uncertainties using machine learning approaches. To ensure optimal composite materials, composite properties are optimized with respect to initial materials volume fraction using data-driven numerical algorithms. ",
    "url": "https://arxiv.org/abs/2210.09055",
    "authors": [
      "Kazuma Kobayashi",
      "Shoaib Usman",
      "Carlos Castano",
      "Ayodeji Alajo",
      "Dinesh Kumar",
      "Syed Alam"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.09060",
    "title": "An introduction to programming Physics-Informed Neural Network-based  computational solid mechanics",
    "abstract": "Physics-informed neural network (PINN) has recently gained increasing interest in computational mechanics. In this work, we present a detailed introduction to programming PINN-based computational solid mechanics. Besides, two prevailingly used physics-informed loss functions for PINN-based computational solid mechanics are summarised. Moreover, numerical examples ranging from 1D to 3D solid problems are presented to show the performance of PINN-based computational solid mechanics. The programs are built via Python coding language and TensorFlow library with step-by-step explanations. It is worth highlighting that PINN-based computational mechanics is easy to implement and can be extended for more challenging applications. This work aims to help the researchers who are interested in the PINN-based solid mechanics solver to have a clear insight into this emerging area. The programs for all the numerical examples presented in this work are available on https://github.com/JinshuaiBai/PINN_Comp_Mech. ",
    "url": "https://arxiv.org/abs/2210.09060",
    "authors": [
      "Jinshuai Bai",
      "Hyogu Jeong",
      "C. P. Batuwatta-Gamage",
      "Shusheng Xiao",
      "Qingxia Wang",
      "C.M. Rathnayaka",
      "Laith Alzubaidi",
      "Gui-Rong Liu",
      "Yuantong Gu"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2210.09071",
    "title": "Attention Attention Everywhere: Monocular Depth Prediction with Skip  Attention",
    "abstract": "Monocular Depth Estimation (MDE) aims to predict pixel-wise depth given a single RGB image. For both, the convolutional as well as the recent attention-based models, encoder-decoder-based architectures have been found to be useful due to the simultaneous requirement of global context and pixel-level resolution. Typically, a skip connection module is used to fuse the encoder and decoder features, which comprises of feature map concatenation followed by a convolution operation. Inspired by the demonstrated benefits of attention in a multitude of computer vision problems, we propose an attention-based fusion of encoder and decoder features. We pose MDE as a pixel query refinement problem, where coarsest-level encoder features are used to initialize pixel-level queries, which are then refined to higher resolutions by the proposed Skip Attention Module (SAM). We formulate the prediction problem as ordinal regression over the bin centers that discretize the continuous depth range and introduce a Bin Center Predictor (BCP) module that predicts bins at the coarsest level using pixel queries. Apart from the benefit of image adaptive depth binning, the proposed design helps learn improved depth embedding in initial pixel queries via direct supervision from the ground truth. Extensive experiments on the two canonical datasets, NYUV2 and KITTI, show that our architecture outperforms the state-of-the-art by 5.3% and 3.9%, respectively, along with an improved generalization performance by 9.4% on the SUNRGBD dataset. Code is available at https://github.com/ashutosh1807/PixelFormer.git. ",
    "url": "https://arxiv.org/abs/2210.09071",
    "authors": [
      "Ashutosh Agarwal",
      "Chetan Arora"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.09081",
    "title": "Asymptotic-Preserving Neural Networks for hyperbolic systems with  diffusive scaling",
    "abstract": "With the rapid advance of Machine Learning techniques and the deep increment of availability of scientific data, data-driven approaches have started to become progressively popular across science, causing a fundamental shift in the scientific method after proving to be powerful tools with a direct impact in many areas of society. Nevertheless, when attempting to analyze the dynamics of complex multiscale systems, the usage of standard Deep Neural Networks (DNNs) and even standard Physics-Informed Neural Networks (PINNs) may lead to incorrect inferences and predictions, due to the presence of small scales leading to reduced or simplified models in the system that have to be applied consistently during the learning process. In this Chapter, we will address these issues in light of recent results obtained in the development of Asymptotic-Preserving Neural Networks (APNNs) for hyperbolic models with diffusive scaling. Several numerical tests show how APNNs provide considerably better results with respect to the different scales of the problem when compared with standard DNNs and PINNs, especially when analyzing scenarios in which only little and scattered information is available. ",
    "url": "https://arxiv.org/abs/2210.09081",
    "authors": [
      "Giulia Bertaglia"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09082",
    "title": "A Solver-Free Framework for Scalable Learning in Neural ILP  Architectures",
    "abstract": "There is a recent focus on designing architectures that have an Integer Linear Programming (ILP) layer within a neural model (referred to as Neural ILP in this paper). Neural ILP architectures are suitable for pure reasoning tasks that require data-driven constraint learning or for tasks requiring both perception (neural) and reasoning (ILP). A recent SOTA approach for end-to-end training of Neural ILP explicitly defines gradients through the ILP black box (Paulus et al. 2021) - this trains extremely slowly, owing to a call to the underlying ILP solver for every training data point in a minibatch. In response, we present an alternative training strategy that is solver-free, i.e., does not call the ILP solver at all at training time. Neural ILP has a set of trainable hyperplanes (for cost and constraints in ILP), together representing a polyhedron. Our key idea is that the training loss should impose that the final polyhedron separates the positives (all constraints satisfied) from the negatives (at least one violated constraint or a suboptimal cost value), via a soft-margin formulation. While positive example(s) are provided as part of the training data, we devise novel techniques for generating negative samples. Our solution is flexible enough to handle equality as well as inequality constraints. Experiments on several problems, both perceptual as well as symbolic, which require learning the constraints of an ILP, show that our approach has superior performance and scales much better compared to purely neural baselines and other state-of-the-art models that require solver-based training. In particular, we are able to obtain excellent performance in 9 x 9 symbolic and visual sudoku, to which the other Neural ILP solver is not able to scale. ",
    "url": "https://arxiv.org/abs/2210.09082",
    "authors": [
      "Yatin Nandwani",
      "Rishabh Ranjan",
      "Mausam",
      "Parag Singla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09100",
    "title": "Estimating the Cost of Executing Link Traversal based SPARQL Queries",
    "abstract": "An increasing number of organisations in almost all fields have started adopting semantic web technologies for publishing their data as open, linked and interoperable (RDF) datasets, queryable through the SPARQL language and protocol. Link traversal has emerged as a SPARQL query processing method that exploits the Linked Data principles and the dynamic nature of the Web to dynamically discover data relevant for answering a query by resolving online resources (URIs) during query evaluation. However, the execution time of link traversal queries can become prohibitively high for certain query types due to the high number of resources that need to be accessed during query execution. In this paper we propose and evaluate baseline methods for estimating the evaluation cost of link traversal queries. Such methods can be very useful for deciding on-the-fly the query execution strategy to follow for a given query, thereby reducing the load of a SPARQL endpoint and increasing the overall reliability of the query service. To evaluate the performance of the proposed methods, we have created (and make publicly available) a ground truth dataset consisting of 2,425 queries. ",
    "url": "https://arxiv.org/abs/2210.09100",
    "authors": [
      "Antonis Sklavos",
      "Pavlos Fafalios",
      "Yannis Tzitzikas"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2210.09128",
    "title": "Sparse Kronecker Product Decomposition: A General Framework of Signal  Region Detection in Image Regression",
    "abstract": "This paper aims to present the first Frequentist framework on signal region detection in high-resolution and high-order image regression problems. Image data and scalar-on-image regression are intensively studied in recent years. However, most existing studies on such topics focused on outcome prediction, while the research on image region detection is rather limited, even though the latter is often more important. In this paper, we develop a general framework named Sparse Kronecker Product Decomposition (SKPD) to tackle this issue. The SKPD framework is general in the sense that it works for both matrices (e.g., 2D grayscale images) and (high-order) tensors (e.g., 2D colored images, brain MRI/fMRI data) represented image data. Moreover, unlike many Bayesian approaches, our framework is computationally scalable for high-resolution image problems. Specifically, our framework includes: 1) the one-term SKPD; 2) the multi-term SKPD; and 3) the nonlinear SKPD. We propose nonconvex optimization problems to estimate the one-term and multi-term SKPDs and develop path-following algorithms for the nonconvex optimization. The computed solutions of the path-following algorithm are guaranteed to converge to the truth with a particularly chosen initialization even though the optimization is nonconvex. Moreover, the region detection consistency could also be guaranteed by the one-term and multi-term SKPD. The nonlinear SKPD is highly connected to shallow convolutional neural networks (CNN), particular to CNN with one convolutional layer and one fully connected layer. Effectiveness of SKPDs is validated by real brain imaging data in the UK Biobank database. ",
    "url": "https://arxiv.org/abs/2210.09128",
    "authors": [
      "Sanyou Wu",
      "Long Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.09132",
    "title": "Pseudo-OOD training for robust language models",
    "abstract": "While pre-trained large-scale deep models have garnered attention as an important topic for many downstream natural language processing (NLP) tasks, such models often make unreliable predictions on out-of-distribution (OOD) inputs. As such, OOD detection is a key component of a reliable machine-learning model for any industry-scale application. Common approaches often assume access to additional OOD samples during the training stage, however, outlier distribution is often unknown in advance. Instead, we propose a post hoc framework called POORE - POsthoc pseudo-Ood REgularization, that generates pseudo-OOD samples using in-distribution (IND) data. The model is fine-tuned by introducing a new regularization loss that separates the embeddings of IND and OOD data, which leads to significant gains on the OOD prediction task during testing. We extensively evaluate our framework on three real-world dialogue systems, achieving new state-of-the-art in OOD detection. ",
    "url": "https://arxiv.org/abs/2210.09132",
    "authors": [
      "Dhanasekar Sundararaman",
      "Nikhil Mehta",
      "Lawrence Carin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.09134",
    "title": "Principled Pruning of Bayesian Neural Networks through Variational Free  Energy Minimization",
    "abstract": "Bayesian model reduction provides an efficient approach for comparing the performance of all nested sub-models of a model, without re-evaluating any of these sub-models. Until now, Bayesian model reduction has been applied mainly in the computational neuroscience community. In this paper, we formulate and apply Bayesian model reduction to perform principled pruning of Bayesian neural networks, based on variational free energy minimization. This novel parameter pruning scheme solves the shortcomings of many current state-of-the-art pruning methods that are used by the signal processing community. The proposed approach has a clear stopping criterion and minimizes the same objective that is used during training. Next to these theoretical benefits, our experiments indicate better model performance in comparison to state-of-the-art pruning schemes. ",
    "url": "https://arxiv.org/abs/2210.09134",
    "authors": [
      "Jim Beckers",
      "Bart van Erp",
      "Ziyue Zhao",
      "Kirill Kondrashov",
      "Bert de Vries"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.09136",
    "title": "SA4U: Practical Static Analysis for Unit Type Error Detection",
    "abstract": "Unit type errors, where values with physical unit types (e.g., meters, hours) are used incorrectly in a computation, are common in today's unmanned aerial system (UAS) firmware. Recent studies show that unit type errors represent over 10% of bugs in UAS firmware. Moreover, the consequences of unit type errors are severe. Over 30% of unit type errors cause UAS crashes. This paper proposes SA4U: a practical system for detecting unit type errors in real-world UAS firmware. SA4U requires no modifications to firmware or developer annotations. It deduces the unit types of program variables by analyzing simulation traces and protocol definitions. SA4U uses the deduced unit types to identify when unit type errors occur. SA4U is effective: it identified 14 previously undetected bugs in two popular open-source firmware (ArduPilot & PX4.) ",
    "url": "https://arxiv.org/abs/2210.09136",
    "authors": [
      "Max Taylor",
      "Johnathon Aurand",
      "Feng Qin",
      "Xiaorui Wang",
      "Brandon Henry",
      "Xiangyu Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2210.09147",
    "title": "PARTIME: Scalable and Parallel Processing Over Time with Deep Neural  Networks",
    "abstract": "In this paper, we present PARTIME, a software library written in Python and based on PyTorch, designed specifically to speed up neural networks whenever data is continuously streamed over time, for both learning and inference. Existing libraries are designed to exploit data-level parallelism, assuming that samples are batched, a condition that is not naturally met in applications that are based on streamed data. Differently, PARTIME starts processing each data sample at the time in which it becomes available from the stream. PARTIME wraps the code that implements a feed-forward multi-layer network and it distributes the layer-wise processing among multiple devices, such as Graphics Processing Units (GPUs). Thanks to its pipeline-based computational scheme, PARTIME allows the devices to perform computations in parallel. At inference time this results in scaling capabilities that are theoretically linear with respect to the number of devices. During the learning stage, PARTIME can leverage the non-i.i.d. nature of the streamed data with samples that are smoothly evolving over time for efficient gradient computations. Experiments are performed in order to empirically compare PARTIME with classic non-parallel neural computations in online learning, distributing operations on up to 8 NVIDIA GPUs, showing significant speedups that are almost linear in the number of devices, mitigating the impact of the data transfer overhead. ",
    "url": "https://arxiv.org/abs/2210.09147",
    "authors": [
      "Enrico Meloni",
      "Lapo Faggi",
      "Simone Marullo",
      "Alessandro Betti",
      "Matteo Tiezzi",
      "Marco Gori",
      "Stefano Melacci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09153",
    "title": "Face Pasting Attack",
    "abstract": "Cujo AI and Adversa AI hosted the MLSec face recognition challenge. The goal was to attack a black box face recognition model with targeted attacks. The model returned the confidence of the target class and a stealthiness score. For an attack to be considered successful the target class has to have the highest confidence among all classes and the stealthiness has to be at least 0.5. In our approach we paste the face of a target into a source image. By utilizing position, scaling, rotation and transparency attributes we reached 3rd place. Our approach took approximately 200 queries per attack for the final highest score and about ~7.7 queries minimum for a successful attack. The code is available at https://github.com/bunni90/ FacePastingAttack ",
    "url": "https://arxiv.org/abs/2210.09153",
    "authors": [
      "Niklas Bunzel",
      "Lukas Graner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09167",
    "title": "How do we get there? Evaluating transformer neural networks as cognitive  models for English past tense inflection",
    "abstract": "There is an ongoing debate on whether neural networks can grasp the quasi-regularities in languages like humans. In a typical quasi-regularity task, English past tense inflections, the neural network model has long been criticized that it learns only to generalize the most frequent pattern, but not the regular pattern, thus can not learn the abstract categories of regular and irregular and is dissimilar to human performance. In this work, we train a set of transformer models with different settings to examine their behavior on this task. The models achieved high accuracy on unseen regular verbs and some accuracy on unseen irregular verbs. The models' performance on the regulars is heavily affected by type frequency and ratio but not token frequency and ratio, and vice versa for the irregulars. The different behaviors on the regulars and irregulars suggest that the models have some degree of symbolic learning on the regularity of the verbs. In addition, the models are weakly correlated with human behavior on nonce verbs. Although the transformer model exhibits some level of learning on the abstract category of verb regularity, its performance does not fit human data well, suggesting that it might not be a good cognitive model. ",
    "url": "https://arxiv.org/abs/2210.09167",
    "authors": [
      "Xiaomeng Ma",
      "Lingyu Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.09186",
    "title": "Implicit models, latent compression, intrinsic biases, and cheap lunches  in community detection",
    "abstract": "The task of community detection, which aims to partition a network into clusters of nodes to summarize its large-scale structure, has spawned the development of many competing algorithms with varying objectives. Some community detection methods are inferential, explicitly deriving the clustering objective through a probabilistic generative model, while other methods are descriptive, dividing a network according to an objective motivated by a particular application, making it challenging to compare these methods on the same scale. Here we present a solution to this problem that associates any community detection objective, inferential or descriptive, with its corresponding implicit network generative model. This allows us to compute the description length of a network and its partition under arbitrary objectives, providing a principled measure to compare the performance of different algorithms without the need for \"ground truth\" labels. Our approach also gives access to instances of the community detection problem that are optimal to any given algorithm, and in this way reveals intrinsic biases in popular descriptive methods, explaining their tendency to overfit. Using our framework, we compare a number of community detection methods on artificial networks, and on a corpus of over 500 structurally diverse empirical networks. We find that more expressive community detection methods exhibit consistently superior compression performance on structured data instances, without having degraded performance on a minority of situations where more specialized algorithms perform optimally. Our results undermine the implications of the \"no free lunch\" theorem for community detection, both conceptually and in practice, since it is confined to unstructured data instances, unlike relevant community detection problems which are structured by requirement. ",
    "url": "https://arxiv.org/abs/2210.09186",
    "authors": [
      "Tiago P. Peixoto",
      "Alec Kirkley"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.09187",
    "title": "Nonlinear Detection of Voltage Source Converter Control Systems in Wind  Farms Based on Higher-Order Spectral Analysis",
    "abstract": "In recent years, the sub-synchronous oscillation (SSO) accidents caused by wind power have received extensive attention. A method is needed to detect the nonlinearity of the collected equal-amplitude accident waveform record. The theory of higher-order statistics (HOS) has become a powerful nonlinear detection tool since 1960s. However, HOS analysis was most applied in condition monitoring and fault diagnosis of mechanical equipment, even in the power system and wind farms. This paper focuses on the VSC control systems in wind farms and classifies the nonlinearity based on HOS analysis. First, the traditional describing function is extended to obtain more frequency domain information, and hereby the harmonic characteristics of bilateral and the unilateral saturation hard limit are studied. Then the bispectrum and trispectrum are introduced as HOS, which are extended into bicoherence and tricoherence spectrums to eliminate the effects from linear parts in the VSC control system. The effectiveness of nonlinear detection and classification based on HOS is strictly proved and its detailed calculation and estimation process is listed. Finally, the proposed method is demonstrated and further discussed through simulation results. ",
    "url": "https://arxiv.org/abs/2210.09187",
    "authors": [
      "Zetian Zheng",
      "Chen Shen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.09194",
    "title": "Marksman Backdoor: Backdoor Attacks with Arbitrary Target Class",
    "abstract": "In recent years, machine learning models have been shown to be vulnerable to backdoor attacks. Under such attacks, an adversary embeds a stealthy backdoor into the trained model such that the compromised models will behave normally on clean inputs but will misclassify according to the adversary's control on maliciously constructed input with a trigger. While these existing attacks are very effective, the adversary's capability is limited: given an input, these attacks can only cause the model to misclassify toward a single pre-defined or target class. In contrast, this paper exploits a novel backdoor attack with a much more powerful payload, denoted as Marksman, where the adversary can arbitrarily choose which target class the model will misclassify given any input during inference. To achieve this goal, we propose to represent the trigger function as a class-conditional generative model and to inject the backdoor in a constrained optimization framework, where the trigger function learns to generate an optimal trigger pattern to attack any target class at will while simultaneously embedding this generative backdoor into the trained model. Given the learned trigger-generation function, during inference, the adversary can specify an arbitrary backdoor attack target class, and an appropriate trigger causing the model to classify toward this target class is created accordingly. We show empirically that the proposed framework achieves high attack performance while preserving the clean-data performance in several benchmark datasets, including MNIST, CIFAR10, GTSRB, and TinyImageNet. The proposed Marksman backdoor attack can also easily bypass existing backdoor defenses that were originally designed against backdoor attacks with a single target class. Our work takes another significant step toward understanding the extensive risks of backdoor attacks in practice. ",
    "url": "https://arxiv.org/abs/2210.09194",
    "authors": [
      "Khoa D. Doan",
      "Yingjie Lao",
      "Ping Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.09204",
    "title": "ArtFacePoints: High-resolution Facial Landmark Detection in Paintings  and Prints",
    "abstract": "Facial landmark detection plays an important role for the similarity analysis in artworks to compare portraits of the same or similar artists. With facial landmarks, portraits of different genres, such as paintings and prints, can be automatically aligned using control-point-based image registration. We propose a deep-learning-based method for facial landmark detection in high-resolution images of paintings and prints. It divides the task into a global network for coarse landmark prediction and multiple region networks for precise landmark refinement in regions of the eyes, nose, and mouth that are automatically determined based on the predicted global landmark coordinates. We created a synthetically augmented facial landmark art dataset including artistic style transfer and geometric landmark shifts. Our method demonstrates an accurate detection of the inner facial landmarks for our high-resolution dataset of artworks while being comparable for a public low-resolution artwork dataset in comparison to competing methods. ",
    "url": "https://arxiv.org/abs/2210.09204",
    "authors": [
      "Aline Sindel",
      "Andreas Maier",
      "Vincent Christlein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.09222",
    "title": "MMTSA: Multimodal Temporal Segment Attention Network for Efficient Human  Activity Recognition",
    "abstract": "Multimodal sensors (e.g., visual, non-visual, and wearable) provide complementary information to develop robust perception systems for recognizing activities. However, most existing algorithms use dense sampling and heterogeneous sub-network to extract unimodal features and fuse them at the end of their framework, which causes data redundancy, lack of complementary multimodal information and high computational cost. In this paper, we propose a new novel multimodal neural architecture based on RGB and IMU wearable sensors (e.g., accelerometer, gyroscope) for human activity recognition called Multimodal Temporal Segment Attention Network (MMTSA). MMTSA first employs a multimodal data isomorphism mechanism based on Gramian Angular Field (GAF) and then applies a novel multimodal sparse sampling method to reduce redundancy. Moreover, we propose an inter-segment attention module in MMTSA to fuse multimodal features effectively and efficiently. We demonstrate the importance of imu data imaging and attention mechanism in human activity recognition by rigorous evaluation on three public datasets, and achieve superior improvements ($11.13\\%$ on the MMAct dataset) than the previous state-of-the-art methods. The code is available at: https://github.com/THU-CS-PI/MMTSA. ",
    "url": "https://arxiv.org/abs/2210.09222",
    "authors": [
      "Ziqi Gao",
      "Jianguo Chen",
      "Junliang Xing",
      "Shwetak Patel",
      "Yuanchun Shi",
      "Xin Liu",
      "Yuntao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09224",
    "title": "Self-Supervised Learning Through Efference Copies",
    "abstract": "Self-supervised learning (SSL) methods aim to exploit the abundance of unlabelled data for machine learning (ML), however the underlying principles are often method-specific. An SSL framework derived from biological first principles of embodied learning could unify the various SSL methods, help elucidate learning in the brain, and possibly improve ML. SSL commonly transforms each training datapoint into a pair of views, uses the knowledge of this pairing as a positive (i.e. non-contrastive) self-supervisory sign, and potentially opposes it to unrelated, (i.e. contrastive) negative examples. Here, we show that this type of self-supervision is an incomplete implementation of a concept from neuroscience, the Efference Copy (EC). Specifically, the brain also transforms the environment through efference, i.e. motor commands, however it sends to itself an EC of the full commands, i.e. more than a mere SSL sign. In addition, its action representations are likely egocentric. From such a principled foundation we formally recover and extend SSL methods such as SimCLR, BYOL, and ReLIC under a common theoretical framework, i.e. Self-supervision Through Efference Copies (S-TEC). Empirically, S-TEC restructures meaningfully the within- and between-class representations. This manifests as improvement in recent strong SSL baselines in image classification, segmentation, object detection, and in audio. These results hypothesize a testable positive influence from the brain's motor outputs onto its sensory representations. ",
    "url": "https://arxiv.org/abs/2210.09224",
    "authors": [
      "Franz Scherr",
      "Qinghai Guo",
      "Timoleon Moraitis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2210.09230",
    "title": "Security and Privacy in Big Data Sharing: State-of-the-Art and Research  Directions",
    "abstract": "Big Data Sharing (BDS) refers to the act of the data owners to share data so that users can find, access and use data according to the agreement. In recent years, BDS has been an emerging topic due to its wide applications, such as big data trading and cross-domain data analytics. However, as the multiple parties are involved in a BDS platform, the issue of security and privacy violation arises. There have been a number of solutions for enhancing security and preserving privacy at different big data operations (e.g., data operation, data searching, data sharing and data outsourcing). To the best of our knowledge, there is no existing survey that has particularly focused on the broad and systematic developments of these security and privacy solutions. In this study, we conduct a comprehensive survey of the state-of-the-art solutions introduced to tackle security and privacy issues in BDS. For a better understanding, we first introduce a general model for BDS and identify the security and privacy requirements. We discuss and classify the state-of-the-art security and privacy solutions for BDS according to the identified requirements. Finally, based on the insights gained, we present and discuss new promising research directions. ",
    "url": "https://arxiv.org/abs/2210.09230",
    "authors": [
      "Houda Ferradi",
      "Jiannong Cao",
      "Shan Jiang",
      "Yinfeng Cao",
      "Divya Saxena"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.09257",
    "title": "Turbocharging Solution Concepts: Solving NEs, CEs and CCEs with Neural  Equilibrium Solvers",
    "abstract": "Solution concepts such as Nash Equilibria, Correlated Equilibria, and Coarse Correlated Equilibria are useful components for many multiagent machine learning algorithms. Unfortunately, solving a normal-form game could take prohibitive or non-deterministic time to converge, and could fail. We introduce the Neural Equilibrium Solver which utilizes a special equivariant neural network architecture to approximately solve the space of all games of fixed shape, buying speed and determinism. We define a flexible equilibrium selection framework, that is capable of uniquely selecting an equilibrium that minimizes relative entropy, or maximizes welfare. The network is trained without needing to generate any supervised training data. We show remarkable zero-shot generalization to larger games. We argue that such a network is a powerful component for many possible multiagent algorithms. ",
    "url": "https://arxiv.org/abs/2210.09257",
    "authors": [
      "Luke Marris",
      "Ian Gemp",
      "Thomas Anthony",
      "Andrea Tacchetti",
      "Siqi Liu",
      "Karl Tuyls"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ]
  },
  {
    "id": "arXiv:2210.09267",
    "title": "CramNet: Camera-Radar Fusion with Ray-Constrained Cross-Attention for  Robust 3D Object Detection",
    "abstract": "Robust 3D object detection is critical for safe autonomous driving. Camera and radar sensors are synergistic as they capture complementary information and work well under different environmental conditions. Fusing camera and radar data is challenging, however, as each of the sensors lacks information along a perpendicular axis, that is, depth is unknown to camera and elevation is unknown to radar. We propose the camera-radar matching network CramNet, an efficient approach to fuse the sensor readings from camera and radar in a joint 3D space. To leverage radar range measurements for better camera depth predictions, we propose a novel ray-constrained cross-attention mechanism that resolves the ambiguity in the geometric correspondences between camera features and radar features. Our method supports training with sensor modality dropout, which leads to robust 3D~object detection, even when a camera or radar sensor suddenly malfunctions on a vehicle. We demonstrate the effectiveness of our fusion approach through extensive experiments on the RADIATE dataset, one of the few large-scale datasets that provide radar radio frequency imagery. A camera-only variant of our method achieves competitive performance in monocular 3D~object detection on the Waymo Open Dataset. ",
    "url": "https://arxiv.org/abs/2210.09267",
    "authors": [
      "Jyh-Jing Hwang",
      "Henrik Kretzschmar",
      "Joshua Manela",
      "Sean Rafferty",
      "Nicholas Armstrong-Crews",
      "Tiffany Chen",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.09269",
    "title": "Identification, Amplification and Measurement: A bridge to Gaussian  Differential Privacy",
    "abstract": "Gaussian differential privacy (GDP) is a single-parameter family of privacy notions that provides coherent guarantees to avoid the exposure of sensitive individual information. Despite the extra interpretability and tighter bounds under composition GDP provides, many widely used mechanisms (e.g., the Laplace mechanism) inherently provide GDP guarantees but often fail to take advantage of this new framework because their privacy guarantees were derived under a different background. In this paper, we study the asymptotic properties of privacy profiles and develop a simple criterion to identify algorithms with GDP properties. We propose an efficient method for GDP algorithms to narrow down possible values of an optimal privacy measurement, $\\mu$ with an arbitrarily small and quantifiable margin of error. For non GDP algorithms, we provide a post-processing procedure that can amplify existing privacy guarantees to meet the GDP condition. As applications, we compare two single-parameter families of privacy notions, $\\epsilon$-DP, and $\\mu$-GDP, and show that all $\\epsilon$-DP algorithms are intrinsically also GDP. Lastly, we show that the combination of our measurement process and the composition theorem of GDP is a powerful and convenient tool to handle compositions compared to the traditional standard and advanced composition theorems. ",
    "url": "https://arxiv.org/abs/2210.09269",
    "authors": [
      "Yi Liu",
      "Ke Sun",
      "Linglong Kong",
      "Bei Jiang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.09277",
    "title": "Unsupervised Optimal Power Flow Using Graph Neural Networks",
    "abstract": "Optimal power flow (OPF) is a critical optimization problem that allocates power to the generators in order to satisfy the demand at a minimum cost. Solving this problem exactly is computationally infeasible in the general case. In this work, we propose to leverage graph signal processing and machine learning. More specifically, we use a graph neural network to learn a nonlinear parametrization between the power demanded and the corresponding allocation. We learn the solution in an unsupervised manner, minimizing the cost directly. In order to take into account the electrical constraints of the grid, we propose a novel barrier method that is differentiable and works on initially infeasible points. We show through simulations that the use of GNNs in this unsupervised learning context leads to solutions comparable to standard solvers while being computationally efficient and avoiding constraint violations most of the time. ",
    "url": "https://arxiv.org/abs/2210.09277",
    "authors": [
      "Damian Owerko",
      "Fernando Gama",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.09290",
    "title": "Automated Identification of Tree Species by Bark Texture Classification  Using Convolutional Neural Networks",
    "abstract": "Identification of tree species plays a key role in forestry related tasks like forest conservation, disease diagnosis and plant production. There had been a debate regarding the part of the tree to be used for differentiation, whether it should be leaves, fruits, flowers or bark. Studies have proven that bark is of utmost importance as it will be present despite seasonal variations and provides a characteristic identity to a tree by variations in the structure. In this paper, a deep learning based approach is presented by leveraging the method of computer vision to classify 50 tree species, on the basis of bark texture using the BarkVN-50 dataset. This is the maximum number of trees being considered for bark classification till now. A convolutional neural network(CNN), ResNet101 has been implemented using transfer-learning based technique of fine tuning to maximise the model performance. The model produced an overall accuracy of >94% during the evaluation. The performance validation has been done using K-Fold Cross Validation and by testing on unseen data collected from the Internet, this proved the model's generalization capability for real-world uses. ",
    "url": "https://arxiv.org/abs/2210.09290",
    "authors": [
      "Sahil Faizal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.09293",
    "title": "Learning Texture Transformer Network for Light Field Super-Resolution",
    "abstract": "Hand-held light field cameras suffer from low spatial resolution due to the inherent spatio-angular tradeoff. In this paper, we propose a method to improve the spatial resolution of light field images with the aid of the Texture Transformer Network (TTSR). The proposed method consists of three modules: the first module produces an all-in focus high-resolution perspective image which serves as a reference image for the second module, i.e. TTSR, which in turn produces a high-resolution light field. The last module refines the spatial resolution by imposing a light field prior. The results demonstrate around 4 dB to 6 dB PSNR gain over a bicubically resized light field image ",
    "url": "https://arxiv.org/abs/2210.09293",
    "authors": [
      "Javeria Shabbir",
      "M. Zeshan Alam",
      "M. Umair Mukati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.09296",
    "title": "3rd Place Solution for Google Universal Image Embedding",
    "abstract": "This paper presents the 3rd place solution to the Google Universal Image Embedding Competition on Kaggle. We use ViT-H/14 from OpenCLIP for the backbone of ArcFace, and trained in 2 stage. 1st stage is done with freezed backbone, and 2nd stage is whole model training. We achieve 0.692 mean Precision @5 on private leaderboard. Code available at https://github.com/YasumasaNamba/google-universal-image-embedding ",
    "url": "https://arxiv.org/abs/2210.09296",
    "authors": [
      "Nobuaki Aoki",
      "Yasumasa Namba"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.09297",
    "title": "Neural Contact Fields: Tracking Extrinsic Contact with Tactile Sensing",
    "abstract": "We present Neural Contact Fields, a method that brings together neural fields and tactile sensing to address the problem of tracking extrinsic contact between object and environment. Knowing where the external contact occurs is a first step towards methods that can actively control it in facilitating downstream manipulation tasks. Prior work for localizing environmental contacts typically assume a contact type (e.g. point or line), does not capture contact/no-contact transitions, and only works with basic geometric-shaped objects. Neural Contact Fields are the first method that can track arbitrary multi-modal extrinsic contacts without making any assumptions about the contact type. Our key insight is to estimate the probability of contact for any 3D point in the latent space of object shapes, given vision-based tactile inputs that sense the local motion resulting from the external contact. In experiments, we find that Neural Contact Fields are able to localize multiple contact patches without making any assumptions about the geometry of the contact, and capture contact/no-contact transitions for known categories of objects with unseen shapes in unseen environment configurations. In addition to Neural Contact Fields, we also release our YCB-Extrinsic-Contact dataset of simulated extrinsic contact interactions to enable further research in this area. Project repository: https://github.com/carolinahiguera/NCF ",
    "url": "https://arxiv.org/abs/2210.09297",
    "authors": [
      "Carolina Higuera",
      "Siyuan Dong",
      "Byron Boots",
      "Mustafa Mukadam"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.09298",
    "title": "What Makes Convolutional Models Great on Long Sequence Modeling?",
    "abstract": "Convolutional models have been widely used in multiple domains. However, most existing models only use local convolution, making the model unable to handle long-range dependency efficiently. Attention overcomes this problem by aggregating global information but also makes the computational complexity quadratic to the sequence length. Recently, Gu et al. [2021] proposed a model called S4 inspired by the state space model. S4 can be efficiently implemented as a global convolutional model whose kernel size equals the input sequence length. S4 can model much longer sequences than Transformers and achieve significant gains over SoTA on several long-range tasks. Despite its empirical success, S4 is involved. It requires sophisticated parameterization and initialization schemes. As a result, S4 is less intuitive and hard to use. Here we aim to demystify S4 and extract basic principles that contribute to the success of S4 as a global convolutional model. We focus on the structure of the convolution kernel and identify two critical but intuitive principles enjoyed by S4 that are sufficient to make up an effective global convolutional model: 1) The parameterization of the convolutional kernel needs to be efficient in the sense that the number of parameters should scale sub-linearly with sequence length. 2) The kernel needs to satisfy a decaying structure that the weights for convolving with closer neighbors are larger than the more distant ones. Based on the two principles, we propose a simple yet effective convolutional model called Structured Global Convolution (SGConv). SGConv exhibits strong empirical performance over several tasks: 1) With faster speed, SGConv surpasses S4 on Long Range Arena and Speech Command datasets. 2) When plugging SGConv into standard language and vision models, it shows the potential to improve both efficiency and performance. ",
    "url": "https://arxiv.org/abs/2210.09298",
    "authors": [
      "Yuhong Li",
      "Tianle Cai",
      "Yi Zhang",
      "Deming Chen",
      "Debadeepta Dey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.09305",
    "title": "Thinking Two Moves Ahead: Anticipating Other Users Improves Backdoor  Attacks in Federated Learning",
    "abstract": "Federated learning is particularly susceptible to model poisoning and backdoor attacks because individual users have direct control over the training data and model updates. At the same time, the attack power of an individual user is limited because their updates are quickly drowned out by those of many other users. Existing attacks do not account for future behaviors of other users, and thus require many sequential updates and their effects are quickly erased. We propose an attack that anticipates and accounts for the entire federated learning pipeline, including behaviors of other clients, and ensures that backdoors are effective quickly and persist even after multiple rounds of community updates. We show that this new attack is effective in realistic scenarios where the attacker only contributes to a small fraction of randomly sampled rounds and demonstrate this attack on image classification, next-word prediction, and sentiment analysis. ",
    "url": "https://arxiv.org/abs/2210.09305",
    "authors": [
      "Yuxin Wen",
      "Jonas Geiping",
      "Liam Fowl",
      "Hossein Souri",
      "Rama Chellappa",
      "Micah Goldblum",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.06747",
    "title": "DCANet: Differential Convolution Attention Network for RGB-D Semantic  Segmentation",
    "abstract": "Combining RGB images and the corresponding depth maps in semantic segmentation proves the effectiveness in the past few years. Existing RGB-D modal fusion methods either lack the non-linear feature fusion ability or treat both modal images equally, regardless of the intrinsic distribution gap or information loss. Here we find that depth maps are suitable to provide intrinsic fine-grained patterns of objects due to their local depth continuity, while RGB images effectively provide a global view. Based on this, we propose a pixel differential convolution attention (DCA) module to consider geometric information and local-range correlations for depth data. Furthermore, we extend DCA to ensemble differential convolution attention (EDCA) which propagates long-range contextual dependencies and seamlessly incorporates spatial distribution for RGB data. DCA and EDCA dynamically adjust convolutional weights by pixel difference to enable self-adaptive in local and long range, respectively. A two-branch network built with DCA and EDCA, called Differential Convolutional Network (DCANet), is proposed to fuse local and global information of two-modal data. Consequently, the individual advantage of RGB and depth data are emphasized. Our DCANet is shown to set a new state-of-the-art performance for RGB-D semantic segmentation on two challenging benchmark datasets, i.e., NYUDv2 and SUN-RGBD. ",
    "url": "https://arxiv.org/abs/2210.06747",
    "authors": [
      "Lizhi Bai",
      "Jun Yang",
      "Chunqi Tian",
      "Yaoru Sun",
      "Maoyu Mao",
      "Yanjun Xu",
      "Weirong Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08004",
    "title": "Misaligned orientations of 4f optical neural network for image  classification accuracy on various datasets",
    "abstract": "In recent years, the optical 4f system has drawn much attention in building high-speed and ultra-low-power optical neural networks (ONNs). Most optical systems suffer from the misalignment of the optical devices during installment. The performance of ONN based on the optical 4f system (4f-ONN) is considered sensitive to the misalignment in the optical path introduced. In order to comprehensively investigate the influence caused by the misalignment, we proposed a method for estimating the performance of a 4f-ONN in response to various misalignment in the context of the image classification task.The misalignment in numerical simulation is estimated by manipulating the optical intensity distributions in the fourth focus plane in the 4f system. Followed by a series of physical experiments to validate the simulation results. Using our method to test the impact of misalignment of 4f system on the classification accuracy of two popular image classification datasets, MNIST and Quickdraw16. On both datasets, we found that the performances of 4f-ONN generally degraded dramatically as the positioning error increased. Different positioning error tolerance in the misalignment orientations was observed over the two datasets. Classification performance could be preserved by positioning errors up to 200 microns in a specific direction. ",
    "url": "https://arxiv.org/abs/2210.08004",
    "authors": [
      "Yanbing Liu",
      "Wei Li",
      "Kun Cheng",
      "Xun Liu",
      "Wei Yang"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.08016",
    "title": "Prediction of drug effectiveness in rheumatoid arthritis patients based  on machine learning algorithms",
    "abstract": "Rheumatoid arthritis (RA) is an autoimmune condition caused when patients' immune system mistakenly targets their own tissue. Machine learning (ML) has the potential to identify patterns in patient electronic health records (EHR) to forecast the best clinical treatment to improve patient outcomes. This study introduced a \\textbf{D}rug \\textbf{R}esponse \\textbf{P}rediction (DRP) framework with two main goals: 1) design a data processing pipeline to extract information from tabular clinical data, and then preprocess it for functional use, and 2) predict RA patient's responses to drugs and evaluate classification models' performance. We propose a novel two-stage ML framework based on European Alliance of Associations for Rheumatology (EULAR) criteria cutoffs to model drug effectiveness. Our model Stacked-Ensemble DRP was developed and cross-validated using data from 425 RA patients. The evaluation used a subset of 124 patients (30\\%) from the same data source. In the evaluation of the test set, two-stage DRP leads to improved classification accuracy over other end-to-end classification models for binary classification. Our proposed method provides a complete pipeline to predict disease activity scores and identify the group that does not respond well to anti-TNF treatments, thus showing promise in supporting clinical decisions based on EHR information. Codes and sample fictional datasets to test our model are given at \\url{ https://github.com/Gaskell-1206/Ensemble_DRP}. ",
    "url": "https://arxiv.org/abs/2210.08016",
    "authors": [
      "Shengjia Chen",
      "Nikunj Gupta",
      "Woodward B. Galbraith",
      "Valay Shah",
      "Jacopo Cirrone"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2210.08135",
    "title": "Quantum Network Utility Maximization",
    "abstract": "Network Utility Maximization (NUM) is a mathematical framework that has endowed researchers with powerful methods for designing and analyzing classical communication protocols. NUM has also enabled the development of distributed algorithms for solving the resource allocation problem, while at the same time providing certain guarantees, e.g., that of fair treatment, to the users of a network. We extend here the notion of NUM to quantum networks, and propose three quantum utility functions -- each incorporating a different entanglement measure. We aim both to gain an understanding of some of the ways in which quantum users may perceive utility, as well as to explore structured and theoretically-motivated methods of simultaneously servicing multiple users in distributed quantum systems. Using our quantum NUM constructions, we develop an optimization framework for networks that use the single-photon scheme for entanglement generation, which enables us to solve the resource allocation problem while exploring rate-fidelity tradeoffs within the network topologies that we consider. We learn that two of our utility functions, which are based on distillable entanglement and secret key fraction, are in close agreement with each other and produce similar solutions to the optimization problems we study. Our third utility, based on entanglement negativity, has more favorable mathematical properties, and tends to place a higher value on the rate at which users receive entangled resources, compared to the two previous utilities, which put a higher emphasis on end-to-end fidelity. These contrasting behaviors thus provide ideas regarding the suitability of quantum network utility definitions to different quantum applications. ",
    "url": "https://arxiv.org/abs/2210.08135",
    "authors": [
      "Gayane Vardoyan",
      "Stephanie Wehner"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2210.08326",
    "title": "Distributionally Robust Causal Inference with Observational Data",
    "abstract": "We consider the estimation of average treatment effects in observational studies without the standard assumption of unconfoundedness. We propose a new framework of robust causal inference under the general observational study setting with the possible existence of unobserved confounders. Our approach is based on the method of distributionally robust optimization and proceeds in two steps. We first specify the maximal degree to which the distribution of unobserved potential outcomes may deviate from that of obsered outcomes. We then derive sharp bounds on the average treatment effects under this assumption. Our framework encompasses the popular marginal sensitivity model as a special case and can be extended to the difference-in-difference and regression discontinuity designs as well as instrumental variables. Through simulation and empirical studies, we demonstrate the applicability of the proposed methodology to real-world settings. ",
    "url": "https://arxiv.org/abs/2210.08326",
    "authors": [
      "Dimitris Bertsimas",
      "Kosuke Imai",
      "Michael Lingzhi Li"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.08516",
    "title": "A lower bound for the smallest eigenvalue of a graph and an application  to the associahedron graph",
    "abstract": "In this paper, we obtain a lower bound for the smallest eigenvalue of a regular graph containing many copies of a smaller fixed subgraph. This generalizes a result of Aharoni, Alon, and Berger in which the subgraph is a triangle. We apply our results to obtain a lower bound on the smallest eigenvalue of the associahedron graph, and we prove that this bound gives the correct order of magnitude of this eigenvalue. We also survey what is known regarding the second-largest eigenvalue of the associahedron graph. ",
    "url": "https://arxiv.org/abs/2210.08516",
    "authors": [
      "Sebastian M. Cioab\u0103",
      "Vishal Gupta"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2210.08566",
    "title": "Theory for Equivariant Quantum Neural Networks",
    "abstract": "Most currently used quantum neural network architectures have little-to-no inductive biases, leading to trainability and generalization issues. Inspired by a similar problem, recent breakthroughs in classical machine learning address this crux by creating models encoding the symmetries of the learning task. This is materialized through the usage of equivariant neural networks whose action commutes with that of the symmetry. In this work, we import these ideas to the quantum realm by presenting a general theoretical framework to understand, classify, design and implement equivariant quantum neural networks. As a special implementation, we show how standard quantum convolutional neural networks (QCNN) can be generalized to group-equivariant QCNNs where both the convolutional and pooling layers are equivariant under the relevant symmetry group. Our framework can be readily applied to virtually all areas of quantum machine learning, and provides hope to alleviate central challenges such as barren plateaus, poor local minima, and sample complexity. ",
    "url": "https://arxiv.org/abs/2210.08566",
    "authors": [
      "Quynh T. Nguyen",
      "Louis Schatzki",
      "Paolo Braccia",
      "Michael Ragone",
      "Patrick J. Coles",
      "Frederic Sauvage",
      "Martin Larocca",
      "M. Cerezo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.08620",
    "title": "Twin-width of Planar Graphs is at most 8",
    "abstract": "The structural parameter twin-width was introduced by Bonnet et al. in [FOCS 2020], and already this first paper included an asymptotic argument bounding the twin-width of planar graphs by a non-explicit constant. Quite recently, we have seen first small explicit upper bounds of 183 by Jacob and Pilipczuk [arXiv, January 2022, also WG'22], 583 by Bonnet et al. [arXiv, February 2022], of 37 by Bekos et al. [arXiv, April 2022], and of 9 by the first author [arXiv, June 2022]. We further elaborate on the approach used in the last paper and improve the upper bound to 8. This is already very close to the currently best lower bound of 7 by Kr\\'al and Lamaison [arXiv,September 2022]. ",
    "url": "https://arxiv.org/abs/2210.08620",
    "authors": [
      "Petr Hlin\u011bn\u00fd",
      "Jan Jedelsk\u00fd"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2210.08629",
    "title": "A Note On $\\ell$-Rauzy Graphs for the Infinite Fibonacci Word",
    "abstract": "The $\\ell$-Rauzy graph of order $k$ for any infinite word is a directed graph in which an arc $(v_1,v_2)$ is formed if the concatenation of the word $v_1$ and the suffix of $v_2$ of length $k-\\ell$ is a subword of the infinite word. In this paper, we consider one of the important aperiodic recurrent words, the infinite Fibonacci word for discussion. We prove a few basic properties of the $\\ell$-Rauzy graph of the infinite Fibonacci word. We also prove that the $\\ell$-Rauzy graphs for the infinite Fibonacci word are strongly connected. ",
    "url": "https://arxiv.org/abs/2210.08629",
    "authors": [
      "Rajavel Praveen M",
      "Rama R"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2210.08721",
    "title": "RbX: Region-based explanations of prediction models",
    "abstract": "We introduce region-based explanations (RbX), a novel, model-agnostic method to generate local explanations of scalar outputs from a black-box prediction model using only query access. RbX is based on a greedy algorithm for building a convex polytope that approximates a region of feature space where model predictions are close to the prediction at some target point. This region is fully specified by the user on the scale of the predictions, rather than on the scale of the features. The geometry of this polytope - specifically the change in each coordinate necessary to escape the polytope - quantifies the local sensitivity of the predictions to each of the features. These \"escape distances\" can then be standardized to rank the features by local importance. RbX is guaranteed to satisfy a \"sparsity axiom,\" which requires that features which do not enter into the prediction model are assigned zero importance. At the same time, real data examples and synthetic experiments show how RbX can more readily detect all locally relevant features than existing methods. ",
    "url": "https://arxiv.org/abs/2210.08721",
    "authors": [
      "Ismael Lemhadri",
      "Harrison H. Li",
      "Trevor Hastie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.08868",
    "title": "Cerebrovascular Segmentation via Vessel Oriented Filtering Network",
    "abstract": "Accurate cerebrovascular segmentation from Magnetic Resonance Angiography (MRA) and Computed Tomography Angiography (CTA) is of great significance in diagnosis and treatment of cerebrovascular pathology. Due to the complexity and topology variability of blood vessels, complete and accurate segmentation of vascular network is still a challenge. In this paper, we proposed a Vessel Oriented Filtering Network (VOF-Net) which embeds domain knowledge into the convolutional neural network. We design oriented filters for blood vessels according to vessel orientation field, which is obtained by orientation estimation network. Features extracted by oriented filtering are injected into segmentation network, so as to make use of the prior information that the blood vessels are slender and curved tubular structure. Experimental results on datasets of CTA and MRA show that the proposed method is effective for vessel segmentation, and embedding the specific vascular filter improves the segmentation performance. ",
    "url": "https://arxiv.org/abs/2210.08868",
    "authors": [
      "Zhanqiang Guo",
      "Yao Luan",
      "Jianjiang Feng",
      "Wangsheng Lu",
      "Yin Yin",
      "Guangming Yang",
      "Jie Zhou"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08955",
    "title": "Monitoring edge-geodetic sets: hardness and graph products",
    "abstract": "Foucaud, Krishna and Lekshmi recently introduced the concept of monitoring edge-geodetic sets in graphs, and a related graph invariant. These are sets of vertices such that the removal of any edge changes the distance between some pair of vertices in the set. They studied the minimum possible size of such a set in a given graph, which we call the monitoring edge-geodetic number. We show that the decision problem for the monitoring edge-geodetic number is NP-complete. We also give best-possible upper and lower bounds for the Cartesian and strong products of two graphs. These bounds establish the exact value in many cases, including many new examples of graphs whose only monitoring edge-geodetic set is the whole vertex set. ",
    "url": "https://arxiv.org/abs/2210.08955",
    "authors": [
      "John Haslegrave"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ]
  },
  {
    "id": "arXiv:2210.08989",
    "title": "Finding community structure using the ordered random graph model",
    "abstract": "Visualization of the adjacency matrix enables us to capture macroscopic features of a network when the matrix elements are aligned properly. Community structure, a network consisting of several densely connected components, is a particularly important feature, and the structure can be identified through the adjacency matrix when it is close to a block-diagonal form. However, classical ordering algorithms for matrices fail to align matrix elements such that the community structure is visible. In this study, we propose an ordering algorithm based on the maximum-likelihood estimate of the ordered random graph model. We show that the proposed method allows us to more clearly identify community structures than the existing ordering algorithms. ",
    "url": "https://arxiv.org/abs/2210.08989",
    "authors": [
      "Masaki Ochi",
      "Tatsuro Kawamoto"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.09023",
    "title": "Ratio convergence rates for Euclidean first-passage percolation:  Applications to the graph infinity Laplacian",
    "abstract": "In this paper we prove the first quantitative convergence rates for the graph infinity Laplace equation for length scales at the connectivity threshold. In the graph-based semi-supervised learning community this equation is also known as Lipschitz learning. The graph infinity Laplace equation is characterized by the metric on the underlying space, and convergence rates follow from convergence rates for graph distances. At the connectivity threshold, this problem is related to Euclidean first passage percolation, which is concerned with the Euclidean distance function $d_{h}(x,y)$ on a homogeneous Poisson point process on $\\mathbb{R}^d$, where admissible paths have step size at most $h>0$. Using a suitable regularization of the distance function and subadditivity we prove that ${d_{h_s}(0,se_1)}/ s \\to \\sigma$ as $s\\to\\infty$ almost surely where $\\sigma \\geq 1$ is a dimensional constant and $h_s\\gtrsim \\log(s)^\\frac{1}{d}$. A convergence rate is not available due to a lack of approximate superadditivity when $h_s\\to \\infty$. Instead, we prove convergence rates for the ratio $\\frac{d_{h}(0,se_1)}{d_{h}(0,2se_1)}\\to \\frac{1}{2}$ when $h$ is frozen and does not depend on $s$. Combining this with the techniques that we developed in (Bungert, Calder, Roith, IMA Journal of Numerical Analysis, 2022), we show that this notion of ratio convergence is sufficient to establish uniform convergence rates for solutions of the graph infinity Laplace equation at percolation length scales. ",
    "url": "https://arxiv.org/abs/2210.09023",
    "authors": [
      "Leon Bungert",
      "Jeff Calder",
      "Tim Roith"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.09054",
    "title": "On the Identifiability and Estimation of Causal Location-Scale Noise  Models",
    "abstract": "We study the class of location-scale or heteroscedastic noise models (LSNMs), in which the effect $Y$ can be written as a function of the cause $X$ and a noise source $N$ independent of $X$, which may be scaled by a positive function $g$ over the cause, i.e., $Y = f(X) + g(X)N$. Despite the generality of the model class, we show the causal direction is identifiable up to some pathological cases. To empirically validate these theoretical findings, we propose two estimators for LSNMs: an estimator based on (non-linear) feature maps, and one based on probabilistic neural networks. Both model the conditional distribution of $Y$ given $X$ as a Gaussian parameterized by its natural parameters. Since the neural network approach can fit functions of arbitrary complexity, it has an edge over the feature map-based approach in terms of empirical performance. When the feature maps are correctly specified, however, we can prove that our estimator is jointly concave, which allows us to derive stronger guarantees for the cause-effect identification task. ",
    "url": "https://arxiv.org/abs/2210.09054",
    "authors": [
      "Alexander Immer",
      "Christoph Schultheiss",
      "Julia E. Vogt",
      "Bernhard Sch\u00f6lkopf",
      "Peter B\u00fchlmann",
      "Alexander Marx"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09141",
    "title": "Data Subsampling for Bayesian Neural Networks",
    "abstract": "Markov Chain Monte Carlo (MCMC) algorithms do not scale well for large datasets leading to difficulties in Neural Network posterior sampling. In this paper, we apply a generalization of the Metropolis Hastings algorithm that allows us to restrict the evaluation of the likelihood to small mini-batches in a Bayesian inference context. Since it requires the computation of a so-called \"noise penalty\" determined by the variance of the training loss function over the mini-batches, we refer to this data subsampling strategy as Penalty Bayesian Neural Networks - PBNNs. Its implementation on top of MCMC is straightforward, as the variance of the loss function merely reduces the acceptance probability. Comparing to other samplers, we empirically show that PBNN achieves good predictive performance for a given mini-batch size. Varying the size of the mini-batches enables a natural calibration of the predictive distribution and provides an inbuilt protection against overfitting. We expect PBNN to be particularly suited for cases when data sets are distributed across multiple decentralized devices as typical in federated learning. ",
    "url": "https://arxiv.org/abs/2210.09141",
    "authors": [
      "Eiji Kawasaki",
      "Markus Holzmann"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09211",
    "title": "Conditional Neural Processes for Molecules",
    "abstract": "Neural processes (NPs) are models for transfer learning with properties reminiscent of Gaussian Processes (GPs). They are adept at modelling data consisting of few observations of many related functions on the same input space and are trained by minimizing a variational objective, which is computationally much less expensive than the Bayesian updating required by GPs. So far, most studies of NPs have focused on low-dimensional datasets which are not representative of realistic transfer learning tasks. Drug discovery is one application area that is characterized by datasets consisting of many chemical properties or functions which are sparsely observed, yet depend on shared features or representations of the molecular inputs. This paper applies the conditional neural process (CNP) to DOCKSTRING, a dataset of docking scores for benchmarking ML models. CNPs show competitive performance in few-shot learning tasks relative to supervised learning baselines common in QSAR modelling, as well as an alternative model for transfer learning based on pre-training and refining neural network regressors. We present a Bayesian optimization experiment which showcases the probabilistic nature of CNPs and discuss shortcomings of the model in uncertainty quantification. ",
    "url": "https://arxiv.org/abs/2210.09211",
    "authors": [
      "Miguel Garcia-Ortegon",
      "Andreas Bender",
      "Sergio Bacallado"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09226",
    "title": "A Fault Detection Scheme Utilizing Convolutional Neural Network for PV  Solar Panels with High Accuracy",
    "abstract": "Solar energy is one of the most dependable renewable energy technologies, as it is feasible almost everywhere globally. However, improving the efficiency of a solar PV system remains a significant challenge. To enhance the robustness of the solar system, this paper proposes a trained convolutional neural network (CNN) based fault detection scheme to divide the images of photovoltaic modules. For binary classification, the algorithm classifies the input images of PV cells into two categories (i.e. faulty or normal). To further assess the network's capability, the defective PV cells are organized into shadowy, cracked, or dusty cells, and the model is utilized for multiple classifications. The success rate for the proposed CNN model is 91.1% for binary classification and 88.6% for multi-classification. Thus, the proposed trained CNN model remarkably outperforms the CNN model presented in a previous study which used the same datasets. The proposed CNN-based fault detection model is straightforward, simple and effective and could be applied in the fault detection of solar panel. ",
    "url": "https://arxiv.org/abs/2210.09226",
    "authors": [
      "Mary Pa",
      "Amin Kazemi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.09295",
    "title": "Virtual-Reality based Vestibular Ocular Motor Screening for Concussion  Detection using Machine-Learning",
    "abstract": "Sport-related concussion (SRC) depends on sensory information from visual, vestibular, and somatosensory systems. At the same time, the current clinical administration of Vestibular/Ocular Motor Screening (VOMS) is subjective and deviates among administrators. Therefore, for the assessment and management of concussion detection, standardization is required to lower the risk of injury and increase the validation among clinicians. With the advancement of technology, virtual reality (VR) can be utilized to advance the standardization of the VOMS, increasing the accuracy of testing administration and decreasing overall false positive rates. In this paper, we experimented with multiple machine learning methods to detect SRC on VR-generated data using VOMS. In our observation, the data generated from VR for smooth pursuit (SP) and the Visual Motion Sensitivity (VMS) tests are highly reliable for concussion detection. Furthermore, we train and evaluate these models, both qualitatively and quantitatively. Our findings show these models can reach high true-positive-rates of around 99.9 percent of symptom provocation on the VR stimuli-based VOMS vs. current clinical manual VOMS. ",
    "url": "https://arxiv.org/abs/2210.09295",
    "authors": [
      "Khondker Fariha Hossain",
      "Sharif Amit Kamran",
      "Prithul Sarker",
      "Philip Pavilionis",
      "Isayas Adhanom",
      "Nicholas Murray",
      "Alireza Tavakkoli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:0711.2010",
    "title": "A Polynomial Time Algorithm for Graph Isomorphism",
    "abstract": " Title: A Polynomial Time Algorithm for Graph Isomorphism ",
    "url": "https://arxiv.org/abs/0711.2010",
    "authors": [
      "Reiner Czerwinski"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2005.08454",
    "title": "Reliability and Robustness analysis of Machine Learning based Phishing  URL Detectors",
    "abstract": " Comments: Accepted in Transactions of Dependable and Secure Computing (SI-Reliability and Robustness in AI-Based Cybersecurity Solutions) ",
    "url": "https://arxiv.org/abs/2005.08454",
    "authors": [
      "Bushra Sabir",
      "M. Ali Babar",
      "Raj Gaire",
      "Alsharif Abuadbba"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2007.10785",
    "title": "Automated Detection and Forecasting of COVID-19 using Deep Learning  Techniques: A Review",
    "abstract": " Title: Automated Detection and Forecasting of COVID-19 using Deep Learning  Techniques: A Review ",
    "url": "https://arxiv.org/abs/2007.10785",
    "authors": [
      "Afshin Shoeibi",
      "Marjane Khodatars",
      "Roohallah Alizadehsani",
      "Navid Ghassemi",
      "Mahboobeh Jafari",
      "Parisa Moridian",
      "Ali Khadem",
      "Delaram Sadeghi",
      "Sadiq Hussain",
      "Assef Zare",
      "Zahra Alizadeh Sani",
      "Javad Bazeli",
      "Fahime Khozeimeh",
      "Abbas Khosravi",
      "Saeid Nahavandi",
      "U. Rajendra Acharya",
      "Juan M. Gorriz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2010.11740",
    "title": "Robust Low-tubal-rank Tensor Completion based on Tensor Factorization  and Maximum Correntopy Criterion",
    "abstract": " Title: Robust Low-tubal-rank Tensor Completion based on Tensor Factorization  and Maximum Correntopy Criterion ",
    "url": "https://arxiv.org/abs/2010.11740",
    "authors": [
      "Yicong He",
      "George K. Atia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2011.10850",
    "title": "Robust Data Hiding Using Inverse Gradient Attention",
    "abstract": " Comments: 9 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2011.10850",
    "authors": [
      "Honglei Zhang",
      "Hu Wang",
      "Yuanzhouhan Cao",
      "Chunhua Shen",
      "Yidong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2012.07975",
    "title": "Learning Visual Robotic Control Efficiently with Contrastive  Pre-training and Data Augmentation",
    "abstract": " Title: Learning Visual Robotic Control Efficiently with Contrastive  Pre-training and Data Augmentation ",
    "url": "https://arxiv.org/abs/2012.07975",
    "authors": [
      "Albert Zhan",
      "Ruihan Zhao",
      "Lerrel Pinto",
      "Pieter Abbeel",
      "Michael Laskin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2101.12690",
    "title": "Towards Generalising Neural Implicit Representations",
    "abstract": " Comments: ECCVW 2022 ",
    "url": "https://arxiv.org/abs/2101.12690",
    "authors": [
      "Theo W. Costain",
      "Victor Adrian Prisacariu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2102.04211",
    "title": "Challenging Social Media Threats using Collective Well-being Aware  Recommendation Algorithms and an Educational Virtual Companion",
    "abstract": " Title: Challenging Social Media Threats using Collective Well-being Aware  Recommendation Algorithms and an Educational Virtual Companion ",
    "url": "https://arxiv.org/abs/2102.04211",
    "authors": [
      "Dimitri Ognibene",
      "Davide Taibi",
      "Udo Kruschwitz",
      "Rodrigo Souza Wilkens",
      "Davinia Hernandez-Leo",
      "Emily Theophilou",
      "Lidia Scifo",
      "Rene Alejandro Lobo",
      "Francesco Lomonaco",
      "Sabrina Eimler",
      "H. Ulrich Hoppe",
      "Nils Malzahn"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2105.10867",
    "title": "EXoN: EXplainable encoder Network",
    "abstract": " Title: EXoN: EXplainable encoder Network ",
    "url": "https://arxiv.org/abs/2105.10867",
    "authors": [
      "SeungHwan An",
      "Hosik Choi",
      "Jong-June Jeon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.16028",
    "title": "Real-world Video Deblurring: A Benchmark Dataset and An Efficient  Recurrent Neural Network",
    "abstract": " Comments: Accepted by IJCV (extended version of ECCV2020) ",
    "url": "https://arxiv.org/abs/2106.16028",
    "authors": [
      "Zhihang Zhong",
      "Ye Gao",
      "Yinqiang Zheng",
      "Bo Zheng",
      "Imari Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.00065",
    "title": "Model Preserving Compression for Neural Networks",
    "abstract": " Comments: 26 pages, 15 figures. To be published in Advances in Neural Information Processing Systems 35 ",
    "url": "https://arxiv.org/abs/2108.00065",
    "authors": [
      "Jerry Chee",
      "Megan Renz",
      "Anil Damle",
      "Christopher De Sa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2108.01578",
    "title": "SPG-VTON: Semantic Prediction Guidance for Multi-pose Virtual Try-on",
    "abstract": " Title: SPG-VTON: Semantic Prediction Guidance for Multi-pose Virtual Try-on ",
    "url": "https://arxiv.org/abs/2108.01578",
    "authors": [
      "Bingwen Hu",
      "Ping Liu",
      "Zhedong Zheng",
      "Mingwu Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2109.03560",
    "title": "X-GOAL: Multiplex Heterogeneous Graph Prototypical Contrastive Learning",
    "abstract": " Comments: Accepted by CIKM'2022 ",
    "url": "https://arxiv.org/abs/2109.03560",
    "authors": [
      "Baoyu Jing",
      "Shengyu Feng",
      "Yuejia Xiang",
      "Xi Chen",
      "Yu Chen",
      "Hanghang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2109.04352",
    "title": "PhysGNN: A Physics-Driven Graph Neural Network Based Model for  Predicting Soft Tissue Deformation in Image-Guided Neurosurgery",
    "abstract": " Comments: Accepted to the main track of NeurIPS 2022. Camera-ready version ",
    "url": "https://arxiv.org/abs/2109.04352",
    "authors": [
      "Yasmin Salehi",
      "Dennis Giannacopoulos"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.03605",
    "title": "Robust Feature-Level Adversaries are Interpretability Tools",
    "abstract": " Comments: Code available at this https URL ",
    "url": "https://arxiv.org/abs/2110.03605",
    "authors": [
      "Stephen Casper",
      "Max Nadeau",
      "Dylan Hadfield-Menell",
      "Gabriel Kreiman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.05740",
    "title": "Temporal Abstraction in Reinforcement Learning with the Successor  Representation",
    "abstract": " Comments: 69 pages, 30 figures ",
    "url": "https://arxiv.org/abs/2110.05740",
    "authors": [
      "Marlos C. Machado",
      "Andre Barreto",
      "Doina Precup",
      "Michael Bowling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2110.05781",
    "title": "BERTraffic: BERT-based Joint Speaker Role and Speaker Change Detection  for Air Traffic Control Communications",
    "abstract": " Comments: To be published in the 2022 IEEE Spoken Language Technology Workshop (SLT) (SLT 2022) ",
    "url": "https://arxiv.org/abs/2110.05781",
    "authors": [
      "Juan Zuluaga-Gomez",
      "Seyyed Saeed Sarfjoo",
      "Amrutha Prasad",
      "Iuliia Nigmatulina",
      "Petr Motlicek",
      "Karel Ondrej",
      "Oliver Ohneiser",
      "Hartmut Helmke"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2110.14553",
    "title": "GenURL: A General Framework for Unsupervised Representation Learning",
    "abstract": " Comments: Tech report (revision) with 12 pages and 14 figures ",
    "url": "https://arxiv.org/abs/2110.14553",
    "authors": [
      "Siyuan Li",
      "Zicheng Liu",
      "Zelin Zang",
      "Di Wu",
      "Zhiyuan Chen",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2111.00841",
    "title": "Free Probability for predicting the performance of feed-forward fully  connected neural networks",
    "abstract": " Comments: 20 pages, many figures ; v1: Preliminary version ; v2: Added numerical benchmarks, and changed presentation; v3: Accepted in Neurips2022 ",
    "url": "https://arxiv.org/abs/2111.00841",
    "authors": [
      "Reda Chhaibi",
      "Tariq Daouda",
      "Ezechiel Kahn"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ]
  },
  {
    "id": "arXiv:2111.11840",
    "title": "Subgraph Permutation Equivariant Networks",
    "abstract": " Comments: Automorphism equivariant update function on sub-graphs ",
    "url": "https://arxiv.org/abs/2111.11840",
    "authors": [
      "Joshua Mitton",
      "Roderick Murray-Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2111.14971",
    "title": "Classification of animal sounds in a hyperdiverse rainforest using  Convolutional Neural Networks",
    "abstract": " Title: Classification of animal sounds in a hyperdiverse rainforest using  Convolutional Neural Networks ",
    "url": "https://arxiv.org/abs/2111.14971",
    "authors": [
      "Yuren Sun",
      "Tatiana Midori Maeda",
      "Claudia Solis-Lemus",
      "Daniel Pimentel-Alarcon",
      "Zuzana Burivalova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.04388",
    "title": "A graph representation based on fluid diffusion model for data analysis:  theoretical aspects and enhanced community detection",
    "abstract": " Comments: 30 pages, 25 figures ",
    "url": "https://arxiv.org/abs/2112.04388",
    "authors": [
      "Andrea Marinoni",
      "Christian Jutten",
      "Mark Girolami"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.04585",
    "title": "MASTAF: A Model-Agnostic Spatio-Temporal Attention Fusion Network for  Few-shot Video Classification",
    "abstract": " Comments: WACV 2023 ",
    "url": "https://arxiv.org/abs/2112.04585",
    "authors": [
      "Rex Liu",
      "Huanle Zhang",
      "Hamed Pirsiavash",
      "Xin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.04607",
    "title": "Constrained Mean Shift Using Distant Yet Related Neighbors for  Representation Learning",
    "abstract": " Comments: Code is available at this https URL arXiv admin note: text overlap with arXiv:2110.10309 ",
    "url": "https://arxiv.org/abs/2112.04607",
    "authors": [
      "KL Navaneet",
      "Soroush Abbasi Koohpayegani",
      "Ajinkya Tejankar",
      "Kossar Pourahmadi",
      "Akshayvarun Subramanya",
      "Hamed Pirsiavash"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2112.15348",
    "title": "Training Recurrent Neural Networks by Sequential Least Squares and the  Alternating Direction Method of Multipliers",
    "abstract": " Comments: 23 pages, 4 figures. Submitted for publication ",
    "url": "https://arxiv.org/abs/2112.15348",
    "authors": [
      "Alberto Bemporad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2201.04545",
    "title": "On generalization bounds for deep networks based on loss surface  implicit regularization",
    "abstract": " Comments: To appear in IEEE Transaction on Information Theory ",
    "url": "https://arxiv.org/abs/2201.04545",
    "authors": [
      "Masaaki Imaizumi",
      "Johannes Schmidt-Hieber"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.05575",
    "title": "Reasoning Through Memorization: Nearest Neighbor Knowledge Graph  Embeddings",
    "abstract": " Comments: Work in progress ",
    "url": "https://arxiv.org/abs/2201.05575",
    "authors": [
      "Ningyu Zhang",
      "Xin Xie",
      "Xiang Chen",
      "Xu Cheng",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.07199",
    "title": "Invariant Representation Driven Neural Classifier for Anti-QCD Jet  Tagging",
    "abstract": " Comments: 32 pages, 15 figures. To appear in the Journal of High Energy Physics ",
    "url": "https://arxiv.org/abs/2201.07199",
    "authors": [
      "Taoli Cheng",
      "Aaron Courville"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ]
  },
  {
    "id": "arXiv:2201.12437",
    "title": "Mobile Robot Manipulation using Pure Object Detection",
    "abstract": " Comments: WACV 2023 ",
    "url": "https://arxiv.org/abs/2201.12437",
    "authors": [
      "Brent Griffin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.01336",
    "title": "Exploring Transformer Backbones for Heterogeneous Treatment Effect  Estimation",
    "abstract": " Title: Exploring Transformer Backbones for Heterogeneous Treatment Effect  Estimation ",
    "url": "https://arxiv.org/abs/2202.01336",
    "authors": [
      "Yi-Fan Zhang",
      "Hanlin Zhang",
      "Zachary C. Lipton",
      "Li Erran Li",
      "Eric P. Xing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.01341",
    "title": "Robust Binary Models by Pruning Randomly-initialized Networks",
    "abstract": " Comments: Accepted as NeurIPS 2022 paper ",
    "url": "https://arxiv.org/abs/2202.01341",
    "authors": [
      "Chen Liu",
      "Ziqi Zhao",
      "Sabine S\u00fcsstrunk",
      "Mathieu Salzmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.04777",
    "title": "Exact Solutions of a Deep Linear Network",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2202.04777",
    "authors": [
      "Liu Ziyin",
      "Botao Li",
      "Xiangming Meng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.08370",
    "title": "CAREER: Transfer Learning for Economic Prediction of Labor Sequence Data",
    "abstract": " Title: CAREER: Transfer Learning for Economic Prediction of Labor Sequence Data ",
    "url": "https://arxiv.org/abs/2202.08370",
    "authors": [
      "Keyon Vafa",
      "Emil Palikot",
      "Tianyu Du",
      "Ayush Kanodia",
      "Susan Athey",
      "David M. Blei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ]
  },
  {
    "id": "arXiv:2202.10643",
    "title": "Equivariant Graph Hierarchy-Based Neural Networks",
    "abstract": " Comments: 20 pages ",
    "url": "https://arxiv.org/abs/2202.10643",
    "authors": [
      "Jiaqi Han",
      "Wenbing Huang",
      "Tingyang Xu",
      "Yu Rong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.12104",
    "title": "A Transformer-based Network for Deformable Medical Image Registration",
    "abstract": " Comments: 12 pages, 7 figures, 25 conferences ",
    "url": "https://arxiv.org/abs/2202.12104",
    "authors": [
      "Yibo Wang",
      "Wen Qian",
      "Xuming Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.04703",
    "title": "LEMON: LanguagE ModeL for Negative Sampling of Knowledge Graph  Embeddings",
    "abstract": " Title: LEMON: LanguagE ModeL for Negative Sampling of Knowledge Graph  Embeddings ",
    "url": "https://arxiv.org/abs/2203.04703",
    "authors": [
      "Md Rashad Al Hasan Rony",
      "Mirza Mohtashim Alam",
      "Semab Ali",
      "Jens Lehmann",
      "Sahar Vahdati"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2203.07738",
    "title": "DICS-Net: Dictionary-guided Implicit-Component-Supervision Network for  Few-Shot Classification",
    "abstract": " Title: DICS-Net: Dictionary-guided Implicit-Component-Supervision Network for  Few-Shot Classification ",
    "url": "https://arxiv.org/abs/2203.07738",
    "authors": [
      "Shuai Shao",
      "Lei Xing",
      "Weifeng Liu",
      "Yanjiang Wang",
      "Baodi Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.11933",
    "title": "A Prompt Array Keeps the Bias Away: Debiasing Vision-Language Models  with Adversarial Learning",
    "abstract": " Comments: 17 pages, 4 figures, 7 tables. For code and trained token embeddings, see this https URL; Changed to use ACL layout, added joint training with comparison figure; This paper is accepted for publication at AACL 2022, the official version of record is in the ACL Anthology ",
    "url": "https://arxiv.org/abs/2203.11933",
    "authors": [
      "Hugo Berg",
      "Siobhan Mackenzie Hall",
      "Yash Bhalgat",
      "Wonsuk Yang",
      "Hannah Rose Kirk",
      "Aleksandar Shtedritski",
      "Max Bain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2204.02553",
    "title": "RODD: A Self-Supervised Approach for Robust Out-of-Distribution  Detection",
    "abstract": " Comments: Accepted in CVPR Art of Robustness Workshop Proceedings ",
    "url": "https://arxiv.org/abs/2204.02553",
    "authors": [
      "Umar Khalid",
      "Ashkan Esmaeili",
      "Nazmul Karim",
      "Nazanin Rahnavard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.07054",
    "title": "BrainGB: A Benchmark for Brain Network Analysis with Graph Neural  Networks",
    "abstract": " Comments: In submission to IEEE Transactions on Medical Imaging ",
    "url": "https://arxiv.org/abs/2204.07054",
    "authors": [
      "Hejie Cui",
      "Wei Dai",
      "Yanqiao Zhu",
      "Xuan Kan",
      "Antonio Aodong Chen Gu",
      "Joshua Lukemire",
      "Liang Zhan",
      "Lifang He",
      "Ying Guo",
      "Carl Yang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2204.07615",
    "title": "TabNAS: Rejection Sampling for Neural Architecture Search on Tabular  Datasets",
    "abstract": " Comments: NeurIPS 2022; 30 pages, 15 figures, 7 tables ",
    "url": "https://arxiv.org/abs/2204.07615",
    "authors": [
      "Chengrun Yang",
      "Gabriel Bender",
      "Hanxiao Liu",
      "Pieter-Jan Kindermans",
      "Madeleine Udell",
      "Yifeng Lu",
      "Quoc Le",
      "Da Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2204.08152",
    "title": "Back to the Future: Bidirectional Information Decoupling Network for  Multi-turn Dialogue Modeling",
    "abstract": " Comments: Accepted by EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2204.08152",
    "authors": [
      "Yiyang Li",
      "Hai Zhao",
      "Zhuosheng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2204.09113",
    "title": "Representation of short distances in structurally sparse graphs",
    "abstract": " Comments: 33 pages, no figures; v3: Added an improved approximation subject to VC-dimension constraints and an application for the approximation of distance domination and independence number ",
    "url": "https://arxiv.org/abs/2204.09113",
    "authors": [
      "Zden\u011bk Dvo\u0159\u00e1k"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2204.10321",
    "title": "Future Object Detection with Spatiotemporal Transformers",
    "abstract": " Comments: 14 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2204.10321",
    "authors": [
      "Adam Tonderski",
      "Joakim Johnander",
      "Christoffer Petersson",
      "Kalle \u00c5str\u00f6m"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.13822",
    "title": "HashNWalk: Hash and Random Walk Based Anomaly Detection in Hyperedge  Streams",
    "abstract": " Comments: Accepted in IJCAI 2022 ",
    "url": "https://arxiv.org/abs/2204.13822",
    "authors": [
      "Geon Lee",
      "Minyoung Choe",
      "Kijung Shin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2205.05775",
    "title": "CSI-fingerprinting Indoor Localization via Attention-Augmented Residual  Convolutional Neural Network",
    "abstract": " Comments: 32 pages, Added references in section 2,3; Added explanations for some academic terms; Corrected typos; Added experiments in section 5, previous results unchanged; is under review for possible publication ",
    "url": "https://arxiv.org/abs/2205.05775",
    "authors": [
      "Bowen Zhang",
      "Houssem Sifaou",
      "Geoffrey Ye Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.09459",
    "title": "Neural Network Architecture Beyond Width and Depth",
    "abstract": " Title: Neural Network Architecture Beyond Width and Depth ",
    "url": "https://arxiv.org/abs/2205.09459",
    "authors": [
      "Zuowei Shen",
      "Haizhao Yang",
      "Shijun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.10041",
    "title": "Posterior Refinement Improves Sample Efficiency in Bayesian Neural  Networks",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.10041",
    "authors": [
      "Agustinus Kristiadi",
      "Runa Eschenhagen",
      "Philipp Hennig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.10686",
    "title": "Post-breach Recovery: Protection against White-box Adversarial Examples  for Leaked DNN Models",
    "abstract": " Title: Post-breach Recovery: Protection against White-box Adversarial Examples  for Leaked DNN Models ",
    "url": "https://arxiv.org/abs/2205.10686",
    "authors": [
      "Shawn Shan",
      "Wenxin Ding",
      "Emily Wenger",
      "Haitao Zheng",
      "Ben Y. Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.10732",
    "title": "Robust Flow-based Conformal Inference (FCI) with Statistical Guarantee",
    "abstract": " Title: Robust Flow-based Conformal Inference (FCI) with Statistical Guarantee ",
    "url": "https://arxiv.org/abs/2205.10732",
    "authors": [
      "Youhui Ye",
      "Meimei Liu",
      "Xin Xing"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10762",
    "title": "How sensitive are translation systems to extra contexts? Mitigating  gender bias in Neural Machine Translation models through relevant contexts",
    "abstract": " Comments: EMNLP Findings 2022 ",
    "url": "https://arxiv.org/abs/2205.10762",
    "authors": [
      "Shanya Sharma",
      "Manan Dey",
      "Koustuv Sinha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.10852",
    "title": "Relphormer: Relational Graph Transformer for Knowledge Graph  Representations",
    "abstract": " Comments: Work in progress ",
    "url": "https://arxiv.org/abs/2205.10852",
    "authors": [
      "Zhen Bi",
      "Siyuan Cheng",
      "Jing Chen",
      "Xiaozhuan Liang",
      "Ningyu Zhang",
      "Feiyu Xiong",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.12331",
    "title": "Certified Robustness Against Natural Language Attacks by Causal  Intervention",
    "abstract": " Title: Certified Robustness Against Natural Language Attacks by Causal  Intervention ",
    "url": "https://arxiv.org/abs/2205.12331",
    "authors": [
      "Haiteng Zhao",
      "Chang Ma",
      "Xinshuai Dong",
      "Anh Tuan Luu",
      "Zhi-Hong Deng",
      "Hanwang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2205.13328",
    "title": "How Powerful are K-hop Message Passing Graph Neural Networks",
    "abstract": " Comments: Accepted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.13328",
    "authors": [
      "Jiarui Feng",
      "Yixin Chen",
      "Fuhai Li",
      "Anindya Sarkar",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.13634",
    "title": "BagFlip: A Certified Defense against Data Poisoning",
    "abstract": " Comments: Neurips 2022 ",
    "url": "https://arxiv.org/abs/2205.13634",
    "authors": [
      "Yuhao Zhang",
      "Aws Albarghouthi",
      "Loris D'Antoni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14552",
    "title": "Staggered Rollout Designs Enable Causal Inference Under Interference  Without Network Knowledge",
    "abstract": " Comments: 28 pages, 6 figures, accepted to Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS 2022) ",
    "url": "https://arxiv.org/abs/2205.14552",
    "authors": [
      "Mayleen Cortez",
      "Matthew Eichhorn",
      "Christina Lee Yu"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.00518",
    "title": "Efficient Scheduling of Data Augmentation for Deep Reinforcement  Learning",
    "abstract": " Comments: arXiv admin note: substantial text overlap with arXiv:2102.08581 ",
    "url": "https://arxiv.org/abs/2206.00518",
    "authors": [
      "Byungchan Ko",
      "Jungseul Ok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.01535",
    "title": "Rethinking and Scaling Up Graph Contrastive Learning: An Extremely  Efficient Approach with Group Discrimination",
    "abstract": " Comments: Accepted in NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2206.01535",
    "authors": [
      "Yizhen Zheng",
      "Shirui Pan",
      "Vincent Cs Lee",
      "Yu Zheng",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.01724",
    "title": "SNAKE: Shape-aware Neural 3D Keypoint Field",
    "abstract": " Comments: Accepted by NeurIPS 2022. Codes are available at this https URL ",
    "url": "https://arxiv.org/abs/2206.01724",
    "authors": [
      "Chengliang Zhong",
      "Peixing You",
      "Xiaoxue Chen",
      "Hao Zhao",
      "Fuchun Sun",
      "Guyue Zhou",
      "Xiaodong Mu",
      "Chuang Gan",
      "Wenbing Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.01913",
    "title": "Neural Lyapunov Control of Unknown Nonlinear Systems with Stability  Guarantees",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2206.01913",
    "authors": [
      "Ruikun Zhou",
      "Thanin Quartz",
      "Hans De Sterck",
      "Jun Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2206.02013",
    "title": "Causal Discovery in Heterogeneous Environments Under the Sparse  Mechanism Shift Hypothesis",
    "abstract": " Comments: NeurIPS 2022 camera-ready version. JvK and BS are shared last authors. 10 pages + Bibliography + Appendix (26 pages total) ",
    "url": "https://arxiv.org/abs/2206.02013",
    "authors": [
      "Ronan Perry",
      "Julius von K\u00fcgelgen",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.02063",
    "title": "Active Bayesian Causal Inference",
    "abstract": " Comments: NeurIPS 2022 camera-ready version. RP & JvK are shared last authors. 10 pages + Bibliography + Appendix (34 pages total) ",
    "url": "https://arxiv.org/abs/2206.02063",
    "authors": [
      "Christian Toth",
      "Lars Lorch",
      "Christian Knoll",
      "Andreas Krause",
      "Franz Pernkopf",
      "Robert Peharz",
      "Julius von K\u00fcgelgen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.02927",
    "title": "Spectral Bias Outside the Training Set for Deep Networks in the Kernel  Regime",
    "abstract": " Comments: 38 pages, 1 figure, to be published in NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2206.02927",
    "authors": [
      "Benjamin Bowman",
      "Guido Montufar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.07902",
    "title": "On Privacy and Personalization in Cross-Silo Federated Learning",
    "abstract": " Comments: NeurIPS 2022, 37 pages ",
    "url": "https://arxiv.org/abs/2206.07902",
    "authors": [
      "Ziyu Liu",
      "Shengyuan Hu",
      "Zhiwei Steven Wu",
      "Virginia Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.08129",
    "title": "Trajectory-guided Control Prediction for End-to-end Autonomous Driving:  A Simple yet Strong Baseline",
    "abstract": " Comments: Accepted at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2206.08129",
    "authors": [
      "Penghao Wu",
      "Xiaosong Jia",
      "Li Chen",
      "Junchi Yan",
      "Hongyang Li",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2206.08496",
    "title": "Self-Supervised Contrastive Pre-Training For Time Series via  Time-Frequency Consistency",
    "abstract": " Comments: Accepted by NeruIPS 2022; 32pages (14 pages main paper + 18 pages supplementary materials). Code: this https URL ",
    "url": "https://arxiv.org/abs/2206.08496",
    "authors": [
      "Xiang Zhang",
      "Ziyuan Zhao",
      "Theodoros Tsiligkaridis",
      "Marinka Zitnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.09319",
    "title": "TrafficFlowGAN: Physics-informed Flow based Generative Adversarial  Network for Uncertainty Quantification",
    "abstract": " Title: TrafficFlowGAN: Physics-informed Flow based Generative Adversarial  Network for Uncertainty Quantification ",
    "url": "https://arxiv.org/abs/2206.09319",
    "authors": [
      "Zhaobin Mo",
      "Yongjie Fu",
      "Daran Xu",
      "Xuan Di"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.10071",
    "title": "BOND: Benchmarking Unsupervised Outlier Node Detection on Static  Attributed Graphs",
    "abstract": " Comments: NeurIPS 2022. Benchmark available at this https URL ",
    "url": "https://arxiv.org/abs/2206.10071",
    "authors": [
      "Kay Liu",
      "Yingtong Dou",
      "Yue Zhao",
      "Xueying Ding",
      "Xiyang Hu",
      "Ruitong Zhang",
      "Kaize Ding",
      "Canyu Chen",
      "Hao Peng",
      "Kai Shu",
      "Lichao Sun",
      "Jundong Li",
      "George H. Chen",
      "Zhihao Jia",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2206.10910",
    "title": "SpA-Former: Transformer image shadow detection and removal via spatial  attention",
    "abstract": " Title: SpA-Former: Transformer image shadow detection and removal via spatial  attention ",
    "url": "https://arxiv.org/abs/2206.10910",
    "authors": [
      "Xiao Feng Zhang",
      "Chao Chen Gu",
      "Shan Ying Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.11168",
    "title": "Ordered Subgraph Aggregation Networks",
    "abstract": " Comments: Accepted at NeurIPS 2022. Fixed link to code repository ",
    "url": "https://arxiv.org/abs/2206.11168",
    "authors": [
      "Chendi Qian",
      "Gaurav Rattan",
      "Floris Geerts",
      "Christopher Morris",
      "Mathias Niepert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.11707",
    "title": "Cooperative Hybrid Networks with Active Relays and RISs for B5G:  Applications, Challenges, and Research Directions",
    "abstract": " Comments: 10 pages, 6 figures. This work has been submitted to the IEEE for a possible publication ",
    "url": "https://arxiv.org/abs/2206.11707",
    "authors": [
      "Zaid Abdullah",
      "Steven Kisseleff",
      "Wallace Alves Martins",
      "Gaojie Chen",
      "Luca Sanguinetti",
      "Konstantinos Ntontin",
      "Anastasios Papazafeiropoulos",
      "Symeon Chatzinotas",
      "Bjorn Ottersten"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2206.12558",
    "title": "FastBVP-Net: a lightweight pulse simulation network for measuring heart  rhythm via facial videos",
    "abstract": " Comments: 8 pages, 2figures ",
    "url": "https://arxiv.org/abs/2206.12558",
    "authors": [
      "Jialiang Zhuang",
      "Yuheng Chen",
      "Yun Zhang",
      "Xiujuan Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.13597",
    "title": "NeuRIS: Neural Reconstruction of Indoor Scenes Using Normal Priors",
    "abstract": " Title: NeuRIS: Neural Reconstruction of Indoor Scenes Using Normal Priors ",
    "url": "https://arxiv.org/abs/2206.13597",
    "authors": [
      "Jiepeng Wang",
      "Peng Wang",
      "Xiaoxiao Long",
      "Christian Theobalt",
      "Taku Komura",
      "Lingjie Liu",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.14254",
    "title": "No imputation without representation",
    "abstract": " Title: No imputation without representation ",
    "url": "https://arxiv.org/abs/2206.14254",
    "authors": [
      "Oliver Urs Lenz",
      "Daniel Peralta",
      "Chris Cornelis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.14820",
    "title": "Strong Lensing Source Reconstruction Using Continuous Neural Fields",
    "abstract": " Comments: 9+2 pages, 3+2 figures, Spotlight at the Machine Learning for Astrophysics Workshop at ICML 2022; v2, references added ",
    "url": "https://arxiv.org/abs/2206.14820",
    "authors": [
      "Siddharth Mishra-Sharma",
      "Ge Yang"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2206.15476",
    "title": "AnoShift: A Distribution Shift Benchmark for Unsupervised Anomaly  Detection",
    "abstract": " Title: AnoShift: A Distribution Shift Benchmark for Unsupervised Anomaly  Detection ",
    "url": "https://arxiv.org/abs/2206.15476",
    "authors": [
      "Marius Dragoi",
      "Elena Burceanu",
      "Emanuela Haller",
      "Andrei Manolache",
      "Florin Brad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.00411",
    "title": "Adversarial Robustness is at Odds with Lazy Training",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2207.00411",
    "authors": [
      "Yunjuan Wang",
      "Enayat Ullah",
      "Poorya Mianjy",
      "Raman Arora"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2207.03433",
    "title": "Semi-supervised Object Detection via Virtual Category Learning",
    "abstract": " Comments: ECCV2022 Oral ",
    "url": "https://arxiv.org/abs/2207.03433",
    "authors": [
      "Changrui Chen",
      "Kurt Debattista",
      "Jungong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.05579",
    "title": "Are We Building on the Rock? On the Importance of Data Preprocessing for  Code Summarization",
    "abstract": " Title: Are We Building on the Rock? On the Importance of Data Preprocessing for  Code Summarization ",
    "url": "https://arxiv.org/abs/2207.05579",
    "authors": [
      "Lin Shi",
      "Fangwen Mu",
      "Xiao Chen",
      "Song Wang",
      "Junjie Wang",
      "Ye Yang",
      "Ge Li",
      "Xin Xia",
      "Qing Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2207.09081",
    "title": "Generalizing Goal-Conditioned Reinforcement Learning with Variational  Causal Reasoning",
    "abstract": " Comments: Accepted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2207.09081",
    "authors": [
      "Wenhao Ding",
      "Haohong Lin",
      "Bo Li",
      "Ding Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2207.09531",
    "title": "LR-Net: A Block-based Convolutional Neural Network for Low-Resolution  Image Classification",
    "abstract": " Comments: Submitted to Iranian Journal of Science and Technology, Transactions of Electrical Engineering. Containing 7 pages, 5 figures and 2 tables ",
    "url": "https://arxiv.org/abs/2207.09531",
    "authors": [
      "Ashkan Ganj",
      "Mohsen Ebadpour",
      "Mahdi Darvish",
      "Hamid Bahador"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2207.10265",
    "title": "FOCUS: Fairness via Agent-Awareness for Federated Learning on  Heterogeneous Data",
    "abstract": " Title: FOCUS: Fairness via Agent-Awareness for Federated Learning on  Heterogeneous Data ",
    "url": "https://arxiv.org/abs/2207.10265",
    "authors": [
      "Wenda Chu",
      "Chulin Xie",
      "Boxin Wang",
      "Linyi Li",
      "Lang Yin",
      "Han Zhao",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ]
  },
  {
    "id": "arXiv:2207.10774",
    "title": "Focused Decoding Enables 3D Anatomical Detection by Transformers",
    "abstract": " Title: Focused Decoding Enables 3D Anatomical Detection by Transformers ",
    "url": "https://arxiv.org/abs/2207.10774",
    "authors": [
      "Bastian Wittmann",
      "Fernando Navarro",
      "Suprosanna Shit",
      "Bjoern Menze"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.12849",
    "title": "Bessel Equivariant Networks for Inversion of Transmission Effects in  Multi-Mode Optical Fibres",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2207.12849",
    "authors": [
      "Joshua Mitton",
      "Simon Peter Mekhail",
      "Miles Padgett",
      "Daniele Faccio",
      "Marco Aversa",
      "Roderick Murray-Smith"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2208.02724",
    "title": "Disentangled Representation Learning for RF Fingerprint Extraction under  Unknown Channel Statistics",
    "abstract": " Title: Disentangled Representation Learning for RF Fingerprint Extraction under  Unknown Channel Statistics ",
    "url": "https://arxiv.org/abs/2208.02724",
    "authors": [
      "Renjie Xie",
      "Wei Xu",
      "Jiabao Yu",
      "Aiqun Hu",
      "Derrick Wing Kwan Ng",
      "A. Lee Swindlehurst"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.05895",
    "title": "Shielding Federated Learning Systems against Inference Attacks with ARM  TrustZone",
    "abstract": " Comments: This publication incorporates results from the VEDLIoT project, which received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No 957197 ",
    "url": "https://arxiv.org/abs/2208.05895",
    "authors": [
      "Aghiles Ait Messaoud",
      "Sonia Ben Mokhtar",
      "Vlad Nitu",
      "Valerio Schiavoni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.07734",
    "title": "Self-supervision is not magic: Understanding Data Augmentation in Image  Anomaly Detection",
    "abstract": " Comments: 14 pages ",
    "url": "https://arxiv.org/abs/2208.07734",
    "authors": [
      "Jaemin Yoo",
      "Tiancheng Zhao",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2208.07905",
    "title": "Reshi: Recommending Resources for Scientific Workflow Tasks on  Heterogeneous Infrastructures",
    "abstract": " Comments: Paper accepted in 41st IEEE International Performance Computing and Communications Conference (IPCCC 2022) ",
    "url": "https://arxiv.org/abs/2208.07905",
    "authors": [
      "Jonathan Bader",
      "Fabian Lehmann",
      "Alexander Groth",
      "Lauritz Thamsen",
      "Dominik Scheinert",
      "Jonathan Will",
      "Ulf Leser",
      "Odej Kao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2208.08738",
    "title": "RFLA: Gaussian Receptive Field based Label Assignment for Tiny Object  Detection",
    "abstract": " Comments: ECCV2022 ",
    "url": "https://arxiv.org/abs/2208.08738",
    "authors": [
      "Chang Xu",
      "Jinwang Wang",
      "Wen Yang",
      "Huai Yu",
      "Lei Yu",
      "Gui-Song Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.10224",
    "title": "Friendly Noise against Adversarial Noise: A Powerful Defense against  Data Poisoning Attacks",
    "abstract": " Title: Friendly Noise against Adversarial Noise: A Powerful Defense against  Data Poisoning Attacks ",
    "url": "https://arxiv.org/abs/2208.10224",
    "authors": [
      "Tian Yu Liu",
      "Yu Yang",
      "Baharan Mirzasoleiman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.11064",
    "title": "Multi-Modal Representation Learning with Self-Adaptive Threshold for  Commodity Verification",
    "abstract": " Title: Multi-Modal Representation Learning with Self-Adaptive Threshold for  Commodity Verification ",
    "url": "https://arxiv.org/abs/2208.11064",
    "authors": [
      "Chenchen Han",
      "Heng Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.13780",
    "title": "Autoinverse: Uncertainty Aware Inversion of Neural Networks",
    "abstract": " Comments: Accepted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2208.13780",
    "authors": [
      "Navid Ansari",
      "Hans-Peter Seidel",
      "Nima Vahidi Ferdowsi",
      "Vahid Babaei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.01170",
    "title": "First Hitting Diffusion Models for Generating Manifold, Graph and  Categorical Data",
    "abstract": " Title: First Hitting Diffusion Models for Generating Manifold, Graph and  Categorical Data ",
    "url": "https://arxiv.org/abs/2209.01170",
    "authors": [
      "Mao Ye",
      "Lemeng Wu",
      "Qiang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.03592",
    "title": "Multi-Granularity Prediction for Scene Text Recognition",
    "abstract": " Comments: Accepted by ECCV2022 ",
    "url": "https://arxiv.org/abs/2209.03592",
    "authors": [
      "Peng Wang",
      "Cheng Da",
      "Cong Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.03753",
    "title": "Improved Robust Algorithms for Learning with Discriminative Feature  Feedback",
    "abstract": " Comments: Fixed typos ",
    "url": "https://arxiv.org/abs/2209.03753",
    "authors": [
      "Sivan Sabato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2209.03895",
    "title": "IDIAPers @ Causal News Corpus 2022: Efficient Causal Relation  Identification Through a Prompt-based Few-shot Approach",
    "abstract": " Comments: To be published in CASE@EMNLP 2022 (5th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text) ",
    "url": "https://arxiv.org/abs/2209.03895",
    "authors": [
      "Sergio Burdisso",
      "Juan Zuluaga-Gomez",
      "Esau Villatoro-Tello",
      "Martin Fajcik",
      "Muskaan Singh",
      "Pavel Smrz",
      "Petr Motlicek"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.07376",
    "title": "Understanding Deep Neural Function Approximation in Reinforcement  Learning via $\u03b5$-Greedy Exploration",
    "abstract": " Comments: Accepted by NeurIPS22 ",
    "url": "https://arxiv.org/abs/2209.07376",
    "authors": [
      "Fanghui Liu",
      "Luca Viano",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.07736",
    "title": "Extrapolation and Spectral Bias of Neural Nets with Hadamard Product: a  Polynomial Net Study",
    "abstract": " Title: Extrapolation and Spectral Bias of Neural Nets with Hadamard Product: a  Polynomial Net Study ",
    "url": "https://arxiv.org/abs/2209.07736",
    "authors": [
      "Yongtao Wu",
      "Zhenyu Zhu",
      "Fanghui Liu",
      "Grigorios G Chrysos",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.09407",
    "title": "DetCLIP: Dictionary-Enriched Visual-Concept Paralleled Pre-training for  Open-world Detection",
    "abstract": " Comments: Accepted to NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2209.09407",
    "authors": [
      "Lewei Yao",
      "Jianhua Han",
      "Youpeng Wen",
      "Xiaodan Liang",
      "Dan Xu",
      "Wei Zhang",
      "Zhenguo Li",
      "Chunjing Xu",
      "Hang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.09502",
    "title": "GAMA: Generative Adversarial Multi-Object Scene Attacks",
    "abstract": " Comments: Accepted at NeurIPS 2022; First two authors contributed equally; Includes Supplementary Material ",
    "url": "https://arxiv.org/abs/2209.09502",
    "authors": [
      "Abhishek Aich",
      "Calvin-Khang Ta",
      "Akash Gupta",
      "Chengyu Song",
      "Srikanth V. Krishnamurthy",
      "M. Salman Asif",
      "Amit K. Roy-Chowdhury"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.11134",
    "title": "Neural Networks Base on Power Method and Inverse Power Method for  Solving Linear Eigenvalue Problems",
    "abstract": " Title: Neural Networks Base on Power Method and Inverse Power Method for  Solving Linear Eigenvalue Problems ",
    "url": "https://arxiv.org/abs/2209.11134",
    "authors": [
      "Qihong Yang",
      "Yangtao Deng",
      "Yu Yang",
      "Qiaolin He",
      "Shiquan Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.11233",
    "title": "Evaluating Latent Space Robustness and Uncertainty of EEG-ML Models  under Realistic Distribution Shifts",
    "abstract": " Comments: NeurIPS 2022 camera ready version. Code available at this https URL tl;dr - We develop model diagnostic measures to identify failure modes of EEG-ML models before deployment without access to out-of-distribution data. Keywords - dataset shift, EEG, representation learning, robustness, latent space, uncertainty quantification, distribution shift ",
    "url": "https://arxiv.org/abs/2209.11233",
    "authors": [
      "Neeraj Wagh",
      "Jionghao Wei",
      "Samarth Rawal",
      "Brent M. Berry",
      "Yogatheesan Varatharajah"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.12573",
    "title": "Digital Audio Forensics: Blind Human Voice Mimicry Detection",
    "abstract": " Comments: 11 pages, 4 figures (6 if you count subfigures), 2 tables ",
    "url": "https://arxiv.org/abs/2209.12573",
    "authors": [
      "Sahar Al Ajmi",
      "Khizar Hayat",
      "Alaa M. Al Obaidi",
      "Naresh Kumar",
      "Munaf Najmuldeen",
      "Baptiste Magnier"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2209.13645",
    "title": "PearNet: A Pearson Correlation-based Graph Attention Network for Sleep  Stage Recognition",
    "abstract": " Title: PearNet: A Pearson Correlation-based Graph Attention Network for Sleep  Stage Recognition ",
    "url": "https://arxiv.org/abs/2209.13645",
    "authors": [
      "Jianchao Lu",
      "Yuzhe Tian",
      "Shuang Wang",
      "Michael Sheng",
      "Xi Zheng"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.13657",
    "title": "Suture Thread Spline Reconstruction from Endoscopic Images for Robotic  Surgery with Reliability-driven Keypoint Detection",
    "abstract": " Comments: Submitted to ICRA ",
    "url": "https://arxiv.org/abs/2209.13657",
    "authors": [
      "Neelay Joglekar",
      "Fei Liu",
      "Ryan Orosco",
      "Michael Yip"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2209.13727",
    "title": "Deep Learning Based Detection of Enlarged Perivascular Spaces on Brain  MRI",
    "abstract": " Title: Deep Learning Based Detection of Enlarged Perivascular Spaces on Brain  MRI ",
    "url": "https://arxiv.org/abs/2209.13727",
    "authors": [
      "Tanweer Rashid",
      "Hangfan Liu",
      "Jeffrey B. Ware",
      "Karl Li",
      "Jose Rafael Romero",
      "Elyas Fadaee",
      "Ilya M. Nasrallah",
      "Saima Hilal",
      "R. Nick Bryan",
      "Timothy M. Hughes",
      "Christos Davatzikos",
      "Lenore Launer",
      "Sudha Seshadri",
      "Susan R. Heckbert",
      "Mohamad Habes"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.13964",
    "title": "Graph Soft-Contrastive Learning via Neighborhood Ranking",
    "abstract": " Title: Graph Soft-Contrastive Learning via Neighborhood Ranking ",
    "url": "https://arxiv.org/abs/2209.13964",
    "authors": [
      "Zhiyuan Ning",
      "Pengfei Wang",
      "Pengyang Wang",
      "Ziyue Qiao",
      "Wei Fan",
      "Denghui Zhang",
      "Yi Du",
      "Yuanchun Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.14171",
    "title": "Programmable and Customized Intelligence for Traffic Steering in 5G  Networks Using Open RAN Architectures",
    "abstract": " Comments: 15 pages, 2 algorithms, 1 table, 11 figures, 42 references ",
    "url": "https://arxiv.org/abs/2209.14171",
    "authors": [
      "Andrea Lacava",
      "Michele Polese",
      "Rajarajan Sivaraj",
      "Rahul Soundrarajan",
      "Bhawani Shanker Bhati",
      "Tarunjeet Singh",
      "Tommaso Zugno",
      "Francesca Cuomo",
      "Tommaso Melodia"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2209.14754",
    "title": "On Physics-Informed Neural Networks for Quantum Computers",
    "abstract": " Comments: Updated the previous work section and abstract, fixed typos, and changed the title ",
    "url": "https://arxiv.org/abs/2209.14754",
    "authors": [
      "Stefano Markidis"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.00423",
    "title": "Improved Algorithms for Neural Active Learning",
    "abstract": " Comments: NeurIPS 2022, 34 Pages ",
    "url": "https://arxiv.org/abs/2210.00423",
    "authors": [
      "Yikun Ban",
      "Yuheng Zhang",
      "Hanghang Tong",
      "Arindam Banerjee",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.02841",
    "title": "Detecting Irregular Network Activity with Adversarial Learning and  Expert Feedback",
    "abstract": " Comments: 12 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2210.02841",
    "authors": [
      "Gopikrishna Rathinavel",
      "Nikhil Muralidhar",
      "Timothy O'Shea",
      "Naren Ramakrishnan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.03069",
    "title": "A Better Way to Decay: Proximal Gradient Training Algorithms for Neural  Nets",
    "abstract": " Title: A Better Way to Decay: Proximal Gradient Training Algorithms for Neural  Nets ",
    "url": "https://arxiv.org/abs/2210.03069",
    "authors": [
      "Liu Yang",
      "Jifan Zhang",
      "Joseph Shenouda",
      "Dimitris Papailiopoulos",
      "Kangwook Lee",
      "Robert D. Nowak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.03501",
    "title": "Towards Multi-Modal Sarcasm Detection via Hierarchical Congruity  Modeling with Knowledge Enhancement",
    "abstract": " Comments: Accepted by EMNLP2022 ",
    "url": "https://arxiv.org/abs/2210.03501",
    "authors": [
      "Hui Liu",
      "Wenya Wang",
      "Haoliang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.03526",
    "title": "A Unified Hard-Constraint Framework for Solving Geometrically Complex  PDEs",
    "abstract": " Comments: 10 pages, 5 figures, NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2210.03526",
    "authors": [
      "Songming Liu",
      "Zhongkai Hao",
      "Chengyang Ying",
      "Hang Su",
      "Jun Zhu",
      "Ze Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.03543",
    "title": "A2: Efficient Automated Attacker for Boosting Adversarial Training",
    "abstract": " Comments: Accepted by NeurIPS2022 ",
    "url": "https://arxiv.org/abs/2210.03543",
    "authors": [
      "Zhuoer Xu",
      "Guanghui Zhu",
      "Changhua Meng",
      "Shiwen Cui",
      "Zhenzhe Ying",
      "Weiqiang Wang",
      "Ming GU",
      "Yihua Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04267",
    "title": "Spread Love Not Hate: Undermining the Importance of Hateful Pre-training  for Hate Speech Detection",
    "abstract": " Title: Spread Love Not Hate: Undermining the Importance of Hateful Pre-training  for Hate Speech Detection ",
    "url": "https://arxiv.org/abs/2210.04267",
    "authors": [
      "Omkar Gokhale",
      "Aditya Kane",
      "Shantanu Patankar",
      "Tanmay Chavan",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04578",
    "title": "Is your noise correction noisy? PLS: Robustness to label noise with two  stage detection",
    "abstract": " Comments: 9 pages 4 figures. Accepted at WACV 2023 ",
    "url": "https://arxiv.org/abs/2210.04578",
    "authors": [
      "Paul Albert",
      "Eric Arazo",
      "Tarun Krishna",
      "Noel E. O'Connor",
      "Kevin McGuinness"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05189",
    "title": "Neural Networks are Decision Trees",
    "abstract": " Comments: This paper has significant overlaps with some other papers, kindly read &cite others that are indicated in last paragraph of Introduction section ",
    "url": "https://arxiv.org/abs/2210.05189",
    "authors": [
      "Caglar Aytekin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05236",
    "title": "Planning Assembly Sequence with Graph Transformer",
    "abstract": " Comments: Submitted to ICRA2023 ",
    "url": "https://arxiv.org/abs/2210.05236",
    "authors": [
      "Lin Ma",
      "Jiangtao Gong",
      "Hao Xu",
      "Hao Chen",
      "Hao Zhao",
      "Wenbing Huang",
      "Guyue Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.05889",
    "title": "Building Heterogeneous Cloud System for Machine Learning Inference",
    "abstract": " Title: Building Heterogeneous Cloud System for Machine Learning Inference ",
    "url": "https://arxiv.org/abs/2210.05889",
    "authors": [
      "Baolin Li",
      "Siddharth Samsi",
      "Vijay Gadepally",
      "Devesh Tiwari"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06346",
    "title": "Predicting the clinical citation count of biomedical papers using  multilayer perceptron neural network",
    "abstract": " Comments: 25 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2210.06346",
    "authors": [
      "Xin Li",
      "Xuli Tang",
      "Qikai Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06681",
    "title": "Brain Network Transformer",
    "abstract": " Comments: Accepted to NeurIPS 2022. The previous version is accepted for Workshop ICML-IMLH 2022 (Oral, no proceedings) ",
    "url": "https://arxiv.org/abs/2210.06681",
    "authors": [
      "Xuan Kan",
      "Wei Dai",
      "Hejie Cui",
      "Zilong Zhang",
      "Ying Guo",
      "Carl Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.06909",
    "title": "HoechstGAN: Virtual Lymphocyte Staining Using Generative Adversarial  Networks",
    "abstract": " Comments: Accepted at IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023 ",
    "url": "https://arxiv.org/abs/2210.06909",
    "authors": [
      "Georg W\u00f6lflein",
      "In Hwa Um",
      "David J Harrison",
      "Ognjen Arandjelovi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2210.07032",
    "title": "Prompt-based Connective Prediction Method for Fine-grained Implicit  Discourse Relation Recognition",
    "abstract": " Comments: Findings of EMNLP 2022 Accepted ",
    "url": "https://arxiv.org/abs/2210.07032",
    "authors": [
      "Hao Zhou",
      "Man Lan",
      "Yuanbin Wu",
      "Yuefeng Chen",
      "Meirong Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.07632",
    "title": "Stability of Decentralized Queueing Networks Beyond Complete Bipartite  Cases",
    "abstract": " Comments: Accepted by the 18th Conference on Web and Internet Economics (WINE 2022) ",
    "url": "https://arxiv.org/abs/2210.07632",
    "authors": [
      "Hu Fu",
      "Qun Hu",
      "Jia'nan Lin"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2210.07762",
    "title": "Controllable Style Transfer via Test-time Training of Implicit Neural  Representation",
    "abstract": " Comments: Project Page: this https URL ",
    "url": "https://arxiv.org/abs/2210.07762",
    "authors": [
      "Sunwoo Kim",
      "Youngjo Min",
      "Younghun Jung",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07780",
    "title": "Federated Best Arm Identification with Heterogeneous Clients",
    "abstract": " Title: Federated Best Arm Identification with Heterogeneous Clients ",
    "url": "https://arxiv.org/abs/2210.07780",
    "authors": [
      "Zhirui Chen",
      "P. N. Karthik",
      "Vincent Y. F. Tan",
      "Yeow Meng Chee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ]
  },
  {
    "id": "arXiv:2210.07809",
    "title": "Free Fine-tuning: A Plug-and-Play Watermarking Scheme for Deep Neural  Networks",
    "abstract": " Title: Free Fine-tuning: A Plug-and-Play Watermarking Scheme for Deep Neural  Networks ",
    "url": "https://arxiv.org/abs/2210.07809",
    "authors": [
      "Run Wang",
      "Jixing Ren",
      "Boheng Li",
      "Tianyi She",
      "Chenhao Lin",
      "Liming Fang",
      "Jing Chen",
      "Chao Shen",
      "Lina Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.07811",
    "title": "SAILOR: Scaling Anchors via Insights into Latent Object Representation",
    "abstract": " Comments: WACV 2023; code is available at this https URL ",
    "url": "https://arxiv.org/abs/2210.07811",
    "authors": [
      "Du\u0161an Mali\u0107",
      "Christian Fruhwirth-Reisinger",
      "Horst Possegger",
      "Horst Bischof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.07851",
    "title": "Learning to Autonomously Reach Objects with NICO and Grow-When-Required  Networks",
    "abstract": " Comments: Accepted at the 2022 IEEE-RAS International Conference on Humanoid Robots (Humanoids 2022) ",
    "url": "https://arxiv.org/abs/2210.07851",
    "authors": [
      "Nima Rahrakhshan",
      "Matthias Kerzel",
      "Philipp Allgeuer",
      "Nicolas Duczek",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  }
]