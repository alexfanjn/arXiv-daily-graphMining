[
  {
    "id": "arXiv:2210.12170",
    "title": "Discovering Differences in the Representation of People using  Contextualized Semantic Axes",
    "abstract": "A common paradigm for identifying semantic differences across social and temporal contexts is the use of static word embeddings and their distances. In particular, past work has compared embeddings against \"semantic axes\" that represent two opposing concepts. We extend this paradigm to BERT embeddings, and construct contextualized axes that mitigate the pitfall where antonyms have neighboring representations. We validate and demonstrate these axes on two people-centric datasets: occupations from Wikipedia, and multi-platform discussions in extremist, men's communities over fourteen years. In both studies, contextualized semantic axes can characterize differences among instances of the same word type. In the latter study, we show that references to women and the contexts around them have become more detestable over time. ",
    "url": "https://arxiv.org/abs/2210.12170",
    "authors": [
      "Li Lucy",
      "Divya Tadimeti",
      "David Bamman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.12177",
    "title": "An unsupervised latent/output physics-informed convolutional-LSTM  network for solving partial differential equations using peridynamic  differential operator",
    "abstract": "This study presents a novel unsupervised convolutional Neural Network (NN) architecture with nonlocal interactions for solving Partial Differential Equations (PDEs). The nonlocal Peridynamic Differential Operator (PDDO) is employed as a convolutional filter for evaluating derivatives the field variable. The NN captures the time-dynamics in smaller latent space through encoder-decoder layers with a Convolutional Long-short Term Memory (ConvLSTM) layer between them. The ConvLSTM architecture is modified by employing a novel activation function to improve the predictive capability of the learning architecture for physics with periodic behavior. The physics is invoked in the form of governing equations at the output of the NN and in the latent (reduced) space. By considering a few benchmark PDEs, we demonstrate the training performance and extrapolation capability of this novel NN architecture by comparing against Physics Informed Neural Networks (PINN) type solvers. It is more capable of extrapolating the solution for future timesteps than the other existing architectures. ",
    "url": "https://arxiv.org/abs/2210.12177",
    "authors": [
      "A. Mavi",
      "A.C. Bekar",
      "E. Haghighat",
      "E. Madenci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.12179",
    "title": "The Dark Side of AutoML: Towards Architectural Backdoor Search",
    "abstract": "This paper asks the intriguing question: is it possible to exploit neural architecture search (NAS) as a new attack vector to launch previously improbable attacks? Specifically, we present EVAS, a new attack that leverages NAS to find neural architectures with inherent backdoors and exploits such vulnerability using input-aware triggers. Compared with existing attacks, EVAS demonstrates many interesting properties: (i) it does not require polluting training data or perturbing model parameters; (ii) it is agnostic to downstream fine-tuning or even re-training from scratch; (iii) it naturally evades defenses that rely on inspecting model parameters or training data. With extensive evaluation on benchmark datasets, we show that EVAS features high evasiveness, transferability, and robustness, thereby expanding the adversary's design spectrum. We further characterize the mechanisms underlying EVAS, which are possibly explainable by architecture-level ``shortcuts'' that recognize trigger patterns. This work raises concerns about the current practice of NAS and points to potential directions to develop effective countermeasures. ",
    "url": "https://arxiv.org/abs/2210.12179",
    "authors": [
      "Ren Pang",
      "Changjiang Li",
      "Zhaohan Xi",
      "Shouling Ji",
      "Ting Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12184",
    "title": "A New Perspective for Understanding Generalization Gap of Deep Neural  Networks Trained with Large Batch Sizes",
    "abstract": "Deep neural networks (DNNs) are typically optimized using various forms of mini-batch gradient descent algorithm. A major motivation for mini-batch gradient descent is that with a suitably chosen batch size, available computing resources can be optimally utilized (including parallelization) for fast model training. However, many works report the progressive loss of model generalization when the training batch size is increased beyond some limits. This is a scenario commonly referred to as generalization gap. Although several works have proposed different methods for alleviating the generalization gap problem, a unanimous account for understanding generalization gap is still lacking in the literature. This is especially important given that recent works have observed that several proposed solutions for generalization gap problem such learning rate scaling and increased training budget do not indeed resolve it. As such, our main exposition in this paper is to investigate and provide new perspectives for the source of generalization loss for DNNs trained with a large batch size. Our analysis suggests that large training batch size results in increased near-rank loss of units' activation (i.e. output) tensors, which consequently impacts model optimization and generalization. Extensive experiments are performed for validation on popular DNN models such as VGG-16, residual network (ResNet-56) and LeNet-5 using CIFAR-10, CIFAR-100, Fashion-MNIST and MNIST datasets. ",
    "url": "https://arxiv.org/abs/2210.12184",
    "authors": [
      "Oyebade K. Oyedotun",
      "Konstantinos Papadopoulos",
      "Djamila Aouada"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12185",
    "title": "Attention-Based Scattering Network for Satellite Imagery",
    "abstract": "Multi-channel satellite imagery, from stacked spectral bands or spatiotemporal data, have meaningful representations for various atmospheric properties. Combining these features in an effective manner to create a performant and trustworthy model is of utmost importance to forecasters. Neural networks show promise, yet suffer from unintuitive computations, fusion of high-level features, and may be limited by the quantity of available data. In this work, we leverage the scattering transform to extract high-level features without additional trainable parameters and introduce a separation scheme to bring attention to independent input channels. Experiments show promising results on estimating tropical cyclone intensity and predicting the occurrence of lightning from satellite imagery. ",
    "url": "https://arxiv.org/abs/2210.12185",
    "authors": [
      "Jason Stock",
      "Chuck Anderson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12187",
    "title": "Syntactic Surprisal From Neural Models Predicts, But Underestimates,  Human Processing Difficulty From Syntactic Ambiguities",
    "abstract": "Humans exhibit garden path effects: When reading sentences that are temporarily structurally ambiguous, they slow down when the structure is disambiguated in favor of the less preferred alternative. Surprisal theory (Hale, 2001; Levy, 2008), a prominent explanation of this finding, proposes that these slowdowns are due to the unpredictability of each of the words that occur in these sentences. Challenging this hypothesis, van Schijndel & Linzen (2021) find that estimates of the cost of word predictability derived from language models severely underestimate the magnitude of human garden path effects. In this work, we consider whether this underestimation is due to the fact that humans weight syntactic factors in their predictions more highly than language models do. We propose a method for estimating syntactic predictability from a language model, allowing us to weigh the cost of lexical and syntactic predictability independently. We find that treating syntactic predictability independently from lexical predictability indeed results in larger estimates of garden path. At the same time, even when syntactic predictability is independently weighted, surprisal still greatly underestimate the magnitude of human garden path effects. Our results support the hypothesis that predictability is not the only factor responsible for the processing cost associated with garden path sentences. ",
    "url": "https://arxiv.org/abs/2210.12187",
    "authors": [
      "Suhas Arehalli",
      "Brian Dillon",
      "Tal Linzen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12196",
    "title": "Augmentation by Counterfactual Explanation -- Fixing an Overconfident  Classifier",
    "abstract": "A highly accurate but overconfident model is ill-suited for deployment in critical applications such as healthcare and autonomous driving. The classification outcome should reflect a high uncertainty on ambiguous in-distribution samples that lie close to the decision boundary. The model should also refrain from making overconfident decisions on samples that lie far outside its training distribution, far-out-of-distribution (far-OOD), or on unseen samples from novel classes that lie near its training distribution (near-OOD). This paper proposes an application of counterfactual explanations in fixing an over-confident classifier. Specifically, we propose to fine-tune a given pre-trained classifier using augmentations from a counterfactual explainer (ACE) to fix its uncertainty characteristics while retaining its predictive performance. We perform extensive experiments with detecting far-OOD, near-OOD, and ambiguous samples. Our empirical results show that the revised model have improved uncertainty measures, and its performance is competitive to the state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2210.12196",
    "authors": [
      "Sumedha Singla",
      "Nihal Murali",
      "Forough Arabshahi",
      "Sofia Triantafyllou",
      "Kayhan Batmanghelich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12209",
    "title": "Motion Policy Networks",
    "abstract": "Collision-free motion generation in unknown environments is a core building block for robot manipulation. Generating such motions is challenging due to multiple objectives; not only should the solutions be optimal, the motion generator itself must be fast enough for real-time performance and reliable enough for practical deployment. A wide variety of methods have been proposed ranging from local controllers to global planners, often being combined to offset their shortcomings. We present an end-to-end neural model called Motion Policy Networks (M$\\pi$Nets) to generate collision-free, smooth motion from just a single depth camera observation. M$\\pi$Nets are trained on over 3 million motion planning problems in over 500,000 environments. Our experiments show that M$\\pi$Nets are significantly faster than global planners while exhibiting the reactivity needed to deal with dynamic scenes. They are 46% better than prior neural planners and more robust than local control policies. Despite being only trained in simulation, M$\\pi$Nets transfer well to the real robot with noisy partial point clouds. Code and data are publicly available at https://mpinets.github.io. ",
    "url": "https://arxiv.org/abs/2210.12209",
    "authors": [
      "Adam Fishman",
      "Adithyavairan Murali",
      "Clemens Eppner",
      "Bryan Peele",
      "Byron Boots",
      "Dieter Fox"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.12213",
    "title": "SpaBERT: A Pretrained Language Model from Geographic Data for Geo-Entity  Representation",
    "abstract": "Named geographic entities (geo-entities for short) are the building blocks of many geographic datasets. Characterizing geo-entities is integral to various application domains, such as geo-intelligence and map comprehension, while a key challenge is to capture the spatial-varying context of an entity. We hypothesize that we shall know the characteristics of a geo-entity by its surrounding entities, similar to knowing word meanings by their linguistic context. Accordingly, we propose a novel spatial language model, SpaBERT, which provides a general-purpose geo-entity representation based on neighboring entities in geospatial data. SpaBERT extends BERT to capture linearized spatial context, while incorporating a spatial coordinate embedding mechanism to preserve spatial relations of entities in the 2-dimensional space. SpaBERT is pretrained with masked language modeling and masked entity prediction tasks to learn spatial dependencies. We apply SpaBERT to two downstream tasks: geo-entity typing and geo-entity linking. Compared with the existing language models that do not use spatial context, SpaBERT shows significant performance improvement on both tasks. We also analyze the entity representation from SpaBERT in various settings and the effect of spatial coordinate embedding. ",
    "url": "https://arxiv.org/abs/2210.12213",
    "authors": [
      "Zekun Li",
      "Jina Kim",
      "Yao-Yi Chiang",
      "Muhao Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.12214",
    "title": "Optimizing Bilingual Neural Transducer with Synthetic Code-switching  Text Generation",
    "abstract": "Code-switching describes the practice of using more than one language in the same sentence. In this study, we investigate how to optimize a neural transducer based bilingual automatic speech recognition (ASR) model for code-switching speech. Focusing on the scenario where the ASR model is trained without supervised code-switching data, we found that semi-supervised training and synthetic code-switched data can improve the bilingual ASR system on code-switching speech. We analyze how each of the neural transducer's encoders contributes towards code-switching performance by measuring encoder-specific recall values, and evaluate our English/Mandarin system on the ASCEND data set. Our final system achieves 25% mixed error rate (MER) on the ASCEND English/Mandarin code-switching test set -- reducing the MER by 2.1% absolute compared to the previous literature -- while maintaining good accuracy on the monolingual test sets. ",
    "url": "https://arxiv.org/abs/2210.12214",
    "authors": [
      "Thien Nguyen",
      "Nathalie Tran",
      "Liuhui Deng",
      "Thiago Fraga da Silva",
      "Matthew Radzihovsky",
      "Roger Hsiao",
      "Henry Mason",
      "Stefan Braun",
      "Erik McDermott",
      "Dogan Can",
      "Pawel Swietojanski",
      "Lyan Verwimp",
      "Sibel Oyman",
      "Tresi Arvizo",
      "Honza Silovsky",
      "Arnab Ghoshal",
      "Mathieu Martel",
      "Bharat Ram Ambati",
      "Mohamed Ali"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.12215",
    "title": "Gui at MixMT 2022 : English-Hinglish: An MT approach for translation of  code mixed data",
    "abstract": "Code-mixed machine translation has become an important task in multilingual communities and extending the task of machine translation to code mixed data has become a common task for these languages. In the shared tasks of WMT 2022, we try to tackle the same for both English + Hindi to Hinglish and Hinglish to English. The first task dealt with both Roman and Devanagari script as we had monolingual data in both English and Hindi whereas the second task only had data in Roman script. To our knowledge, we achieved one of the top ROUGE-L and WER scores for the first task of Monolingual to Code-Mixed machine translation. In this paper, we discuss the use of mBART with some special pre-processing and post-processing (transliteration from Devanagari to Roman) for the first task in detail and the experiments that we performed for the second task of translating code-mixed Hinglish to monolingual English. ",
    "url": "https://arxiv.org/abs/2210.12215",
    "authors": [
      "Akshat Gahoi",
      "Jayant Duneja",
      "Anshul Padhi",
      "Shivam Mangale",
      "Saransh Rajput",
      "Tanvi Kamble",
      "Dipti Misra Sharma",
      "Vasudeva Varma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12218",
    "title": "SEIFER: Scalable Edge Inference for Deep Neural Networks",
    "abstract": "Edge inference is becoming ever prevalent through its applications from retail to wearable technology. Clusters of networked resource-constrained edge devices are becoming common, yet there is no production-ready orchestration system for deploying deep learning models over such edge networks which adopts the robustness and scalability of the cloud. We present SEIFER, a framework utilizing a standalone Kubernetes cluster to partition a given DNN and place these partitions in a distributed manner across an edge network, with the goal of maximizing inference throughput. The system is node fault-tolerant and automatically updates deployments based on updates to the model's version. We provide a preliminary evaluation of a partitioning and placement algorithm that works within this framework, and show that we can improve the inference pipeline throughput by 200% by utilizing sufficient numbers of resource-constrained nodes. We have implemented SEIFER in open-source software that is publicly available to the research community. ",
    "url": "https://arxiv.org/abs/2210.12218",
    "authors": [
      "Arjun Parthasarathy",
      "Bhaskar Krishnamachari"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.12219",
    "title": "Partitioning and Placement of Deep Neural Networks on Distributed Edge  Devices to Maximize Inference Throughput",
    "abstract": "Edge inference has become more widespread, as its diverse applications range from retail to wearable technology. Clusters of networked resource-constrained edge devices are becoming common, yet no system exists to split a DNN across these clusters while maximizing the inference throughput of the system. We present an algorithm which partitions DNNs and distributes them across a set of edge devices with the goal of minimizing the bottleneck latency and therefore maximizing inference throughput. The system scales well to systems of different node memory capacities and numbers of nodes. We find that we can reduce the bottleneck latency by 10x over a random algorithm and 35% over a greedy joint partitioning-placement algorithm. Furthermore we find empirically that for the set of representative models we tested, the algorithm produces results within 9.2% of the optimal bottleneck latency. ",
    "url": "https://arxiv.org/abs/2210.12219",
    "authors": [
      "Arjun Parthasarathy",
      "Bhaskar Krishnamachari"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.12228",
    "title": "EDUKG: a Heterogeneous Sustainable K-12 Educational Knowledge Graph",
    "abstract": "Web and artificial intelligence technologies, especially semantic web and knowledge graph (KG), have recently raised significant attention in educational scenarios. Nevertheless, subject-specific KGs for K-12 education still lack sufficiency and sustainability from knowledge and data perspectives. To tackle these issues, we propose EDUKG, a heterogeneous sustainable K-12 Educational Knowledge Graph. We first design an interdisciplinary and fine-grained ontology for uniformly modeling knowledge and resource in K-12 education, where we define 635 classes, 445 object properties, and 1314 datatype properties in total. Guided by this ontology, we propose a flexible methodology for interactively extracting factual knowledge from textbooks. Furthermore, we establish a general mechanism based on our proposed generalized entity linking system for EDUKG's sustainable maintenance, which can dynamically index numerous heterogeneous resources and data with knowledge topics in EDUKG. We further evaluate EDUKG to illustrate its sufficiency, richness, and variability. We publish EDUKG with more than 252 million entities and 3.86 billion triplets. Our code and data repository is now available at https://github.com/THU-KEG/EDUKG. ",
    "url": "https://arxiv.org/abs/2210.12228",
    "authors": [
      "Bowen Zhao",
      "Jiuding Sun",
      "Bin Xu",
      "Xingyu Lu",
      "Yuchen Li",
      "Jifan Yu",
      "Minghui Liu",
      "Tingjian Zhang",
      "Qiuyang Chen",
      "Hanming Li",
      "Lei Hou",
      "Juanzi Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12229",
    "title": "Deep Reinforcement Learning for Stabilization of Large-scale  Probabilistic Boolean Networks",
    "abstract": "The ability to direct a Probabilistic Boolean Network (PBN) to a desired state is important to applications such as targeted therapeutics in cancer biology. Reinforcement Learning (RL) has been proposed as a framework that solves a discrete-time optimal control problem cast as a Markov Decision Process. We focus on an integrative framework powered by a model-free deep RL method that can address different flavours of the control problem (e.g., with or without control inputs; attractor state or a subset of the state space as the target domain). The method is agnostic to the distribution of probabilities for the next state, hence it does not use the probability transition matrix. The time complexity is linear on the time steps, or interactions between the agent (deep RL) and the environment (PBN), during training. Indeed, we explore the scalability of the deep RL approach to (set) stabilization of large-scale PBNs and demonstrate successful control on large networks, including a metastatic melanoma PBN with 200 nodes. ",
    "url": "https://arxiv.org/abs/2210.12229",
    "authors": [
      "Sotiris Moschoyiannis",
      "Evangelos Chatzaroulas",
      "Vytenis Sliogeris",
      "Yuhu Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2210.12230",
    "title": "Programming Bare-Metal Accelerators with Heterogeneous Threading Models:  A Case Study of Matrix-3000",
    "abstract": "As the hardware industry moves towards using specialized heterogeneous many-cores to avoid the effects of the power wall, software developers are finding it hard to deal with the complexity of these systems. This article shares our experience when developing a programming model and its supporting compiler and libraries for Matrix-3000, which is designed for next-generation exascale supercomputers but has a complex memory hierarchy and processor organization. To assist its software development, we developed a software stack from scratch that includes a low-level programming interface and a high-level OpenCL compiler. Our low-level programming model offers native programming support for using the bare-metal accelerators of Matrix-3000, while the high-level model allows programmers to use the OpenCL programming standard. We detail our design choices and highlight the lessons learned from developing systems software to enable the programming of bare-metal accelerators. Our programming models have been deployed to the production environment of an exascale prototype system. ",
    "url": "https://arxiv.org/abs/2210.12230",
    "authors": [
      "Jianbin Fang",
      "Peng Zhang",
      "Chun Huang",
      "Tao Tang",
      "Kai Lu",
      "Ruibo Wang",
      "Zheng Wang"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ]
  },
  {
    "id": "arXiv:2210.12232",
    "title": "\"If sighted people know, I should be able to know:\" Privacy Perceptions  of Bystanders with Visual Impairments around Camera-based Technology",
    "abstract": "Camera-based technology can be privacy-invasive, especially for bystanders who can be captured by the cameras but do not have direct control or access to the devices. The privacy threats become even more significant to bystanders with visual impairments (BVI) since they cannot visually discover the use of cameras nearby and effectively avoid being captured. While some prior research has studied visually impaired people's privacy concerns as direct users of camera-based assistive technologies, no research has explored their unique privacy perceptions and needs as bystanders. We conducted an in-depth interview study with 16 visually impaired participants to understand BVI's privacy concerns, expectations, and needs in different camera usage scenarios. A preliminary survey with 90 visually impaired respondents and 96 sighted controls was conducted to compare BVI and sighted bystanders' general attitudes towards cameras and elicit camera usage scenarios for the interview study. Our research revealed BVI's unique privacy challenges and perceptions around cameras, highlighting their needs for privacy awareness and protection. We summarized design considerations for future privacy-enhancing technologies to fulfill BVI's privacy needs. ",
    "url": "https://arxiv.org/abs/2210.12232",
    "authors": [
      "Yuhang Zhao",
      "Yaxing Yao",
      "Jiaru Fu",
      "Nihan Zhou"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2210.12233",
    "title": "TCAB: A Large-Scale Text Classification Attack Benchmark",
    "abstract": "We introduce the Text Classification Attack Benchmark (TCAB), a dataset for analyzing, understanding, detecting, and labeling adversarial attacks against text classifiers. TCAB includes 1.5 million attack instances, generated by twelve adversarial attacks targeting three classifiers trained on six source datasets for sentiment analysis and abuse detection in English. Unlike standard text classification, text attacks must be understood in the context of the target classifier that is being attacked, and thus features of the target classifier are important as well. TCAB includes all attack instances that are successful in flipping the predicted label; a subset of the attacks are also labeled by human annotators to determine how frequently the primary semantics are preserved. The process of generating attacks is automated, so that TCAB can easily be extended to incorporate new text attacks and better classifiers as they are developed. In addition to the primary tasks of detecting and labeling attacks, TCAB can also be used for attack localization, attack target labeling, and attack characterization. TCAB code and dataset are available at https://react-nlp.github.io/tcab/. ",
    "url": "https://arxiv.org/abs/2210.12233",
    "authors": [
      "Kalyani Asthana",
      "Zhouhang Xie",
      "Wencong You",
      "Adam Noack",
      "Jonathan Brophy",
      "Sameer Singh",
      "Daniel Lowd"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12239",
    "title": "Auto-Encoder Neural Network Incorporating X-Ray Fluorescence Fundamental  Parameters with Machine Learning",
    "abstract": "We consider energy-dispersive X-ray Fluorescence (EDXRF) applications where the fundamental parameters method is impractical such as when instrument parameters are unavailable. For example, on a mining shovel or conveyor belt, rocks are constantly moving (leading to varying angles of incidence and distances) and there may be other factors not accounted for (like dust). Neural networks do not require instrument and fundamental parameters but training neural networks requires XRF spectra labelled with elemental composition, which is often limited because of its expense. We develop a neural network model that learns from limited labelled data and learns to invert a forward model. The forward model uses transition energies and probabilities of all elements and parameterized distributions to approximate other fundamental and instrument parameters. We evaluate the model and baseline models on a rock dataset from a lithium mine and identify which elements are appropriate for this method. This model demonstrates the potential to calibrate a neural network in a noisy environment where labelled data is limited. ",
    "url": "https://arxiv.org/abs/2210.12239",
    "authors": [
      "Matthew Dirks",
      "David Poole"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12247",
    "title": "Benchmarking GPU and TPU Performance with Graph Neural Networks",
    "abstract": "Many artificial intelligence (AI) devices have been developed to accelerate the training and inference of neural networks models. The most common ones are the Graphics Processing Unit (GPU) and Tensor Processing Unit (TPU). They are highly optimized for dense data representations. However, sparse representations such as graphs are prevalent in many domains, including science. It is therefore important to characterize the performance of available AI accelerators on sparse data. This work analyzes and compares the GPU and TPU performance training a Graph Neural Network (GNN) developed to solve a real-life pattern recognition problem. Characterizing the new class of models acting on sparse data may prove helpful in optimizing the design of deep learning libraries and future AI accelerators. ",
    "url": "https://arxiv.org/abs/2210.12247",
    "authors": [
      "xiangyang Ju",
      "Yunsong Wang",
      "Daniel Murnane",
      "Nicholas Choma",
      "Steven Farrell",
      "Paolo Calafiura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12257",
    "title": "Efficient Automatic Machine Learning via Design Graphs",
    "abstract": "Despite the success of automated machine learning (AutoML), which aims to find the best design, including the architecture of deep networks and hyper-parameters, conventional AutoML methods are computationally expensive and hardly provide insights into the relations of different model design choices. To tackle the challenges, we propose FALCON, an efficient sample-based method to search for the optimal model design. Our key insight is to model the design space of possible model designs as a design graph, where the nodes represent design choices, and the edges denote design similarities. FALCON features 1) a task-agnostic module, which performs message passing on the design graph via a Graph Neural Network (GNN), and 2) a task-specific module, which conducts label propagation of the known model performance information on the design graph. Both modules are combined to predict the design performances in the design space, navigating the search direction. We conduct extensive experiments on 27 node and graph classification tasks from various application domains, and an image classification task on the CIFAR-10 dataset. We empirically show that FALCON can efficiently obtain the well-performing designs for each task using only 30 explored nodes. Specifically, FALCON has a comparable time cost with the one-shot approaches while achieving an average improvement of 3.3% compared with the best baselines. ",
    "url": "https://arxiv.org/abs/2210.12257",
    "authors": [
      "Shirley Wu",
      "Jiaxuan You",
      "Jure Leskovec",
      "Rex Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12262",
    "title": "Group Distributionally Robust Reinforcement Learning with Hierarchical  Latent Variables",
    "abstract": "One key challenge for multi-task Reinforcement learning (RL) in practice is the absence of task indicators. Robust RL has been applied to deal with task ambiguity, but may result in over-conservative policies. To balance the worst-case (robustness) and average performance, we propose Group Distributionally Robust Markov Decision Process (GDR-MDP), a flexible hierarchical MDP formulation that encodes task groups via a latent mixture model. GDR-MDP identifies the optimal policy that maximizes the expected return under the worst-possible qualified belief over task groups within an ambiguity set. We rigorously show that GDR-MDP's hierarchical structure improves distributional robustness by adding regularization to the worst possible outcomes. We then develop deep RL algorithms for GDR-MDP for both value-based and policy-based RL methods. Extensive experiments on Box2D control tasks, MuJoCo benchmarks, and Google football platforms show that our algorithms outperform classic robust training algorithms across diverse environments in terms of robustness under belief uncertainties. Demos are available on our project page (\\url{https://sites.google.com/view/gdr-rl/home}). ",
    "url": "https://arxiv.org/abs/2210.12262",
    "authors": [
      "Mengdi Xu",
      "Peide Huang",
      "Yaru Niu",
      "Visak Kumar",
      "Jielin Qiu",
      "Chao Fang",
      "Kuan-Hui Lee",
      "Xuewei Qi",
      "Henry Lam",
      "Bo Li",
      "Ding Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12268",
    "title": "An Exploration of Neural Radiance Field Scene Reconstruction: Synthetic,  Real-world and Dynamic Scenes",
    "abstract": "This project presents an exploration into 3D scene reconstruction of synthetic and real-world scenes using Neural Radiance Field (NeRF) approaches. We primarily take advantage of the reduction in training and rendering time of neural graphic primitives multi-resolution hash encoding, to reconstruct static video game scenes and real-world scenes, comparing and observing reconstruction detail and limitations. Additionally, we explore dynamic scene reconstruction using Neural Radiance Fields for Dynamic Scenes(D-NeRF). Finally, we extend the implementation of D-NeRF, originally constrained to handle synthetic scenes to also handle real-world dynamic scenes. ",
    "url": "https://arxiv.org/abs/2210.12268",
    "authors": [
      "Benedict Quartey",
      "Tuluhan Akbulut",
      "Wasiwasi Mgonzo",
      "Zheng Xin Yong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.12282",
    "title": "Bridging the Gap Between Target Networks and Functional Regularization",
    "abstract": "Bootstrapping is behind much of the successes of Deep Reinforcement Learning. However, learning the value function via bootstrapping often leads to unstable training due to fast-changing target values. Target Networks are employed to stabilize training by using an additional set of lagging parameters to estimate the target values. Despite the popularity of Target Networks, their effect on the optimization is still misunderstood. In this work, we show that they act as an implicit regularizer. This regularizer has disadvantages such as being inflexible and non convex. To overcome these issues, we propose an explicit Functional Regularization that is a convex regularizer in function space and can easily be tuned. We analyze the convergence of our method theoretically and empirically demonstrate that replacing Target Networks with the more theoretically grounded Functional Regularization approach leads to better sample efficiency and performance improvements. ",
    "url": "https://arxiv.org/abs/2210.12282",
    "authors": [
      "Alexandre Piche",
      "Valentin Thomas",
      "Joseph Marino",
      "Rafael Pardinas",
      "Gian Maria Marconi",
      "Christopher Pal",
      "Mohammad Emtiyaz Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12285",
    "title": "Exploring Representation-Level Augmentation for Code Search",
    "abstract": "Code search, which aims at retrieving the most relevant code fragment for a given natural language query, is a common activity in software development practice. Recently, contrastive learning is widely used in code search research, where many data augmentation approaches for source code (e.g., semantic-preserving program transformation) are proposed to learn better representations. However, these augmentations are at the raw-data level, which requires additional code analysis in the preprocessing stage and additional training costs in the training stage. In this paper, we explore augmentation methods that augment data (both code and query) at representation level which does not require additional data processing and training, and based on this we propose a general format of representation-level augmentation that unifies existing methods. Then, we propose three new augmentation methods (linear extrapolation, binary interpolation, and Gaussian scaling) based on the general format. Furthermore, we theoretically analyze the advantages of the proposed augmentation methods over traditional contrastive learning methods on code search. We experimentally evaluate the proposed representation-level augmentation methods with state-of-the-art code search models on a large-scale public dataset consisting of six programming languages. The experimental results show that our approach can consistently boost the performance of the studied code search models. Our source code is available at https://github.com/Alex-HaochenLi/RACS. ",
    "url": "https://arxiv.org/abs/2210.12285",
    "authors": [
      "Haochen Li",
      "Chunyan Miao",
      "Cyril Leung",
      "Yanxian Huang",
      "Yuan Huang",
      "Hongyu Zhang",
      "Yanlin Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12310",
    "title": "Tools for Extracting Spatio-Temporal Patterns in Meteorological Image  Sequences: From Feature Engineering to Attention-Based Neural Networks",
    "abstract": "Atmospheric processes involve both space and time. This is why human analysis of atmospheric imagery can often extract more information from animated loops of image sequences than from individual images. Automating such an analysis requires the ability to identify spatio-temporal patterns in image sequences which is a very challenging task, because of the endless possibilities of patterns in both space and time. In this paper we review different concepts and techniques that are useful to extract spatio-temporal context specifically for meteorological applications. In this survey we first motivate the need for these approaches in meteorology using two applications, solar forecasting and detecting convection from satellite imagery. Then we provide an overview of many different concepts and techniques that are helpful for the interpretation of meteorological image sequences, such as (1) feature engineering methods to strengthen the desired signal in the input, using meteorological knowledge, classic image processing, harmonic analysis and topological data analysis (2) explain how different convolution filters (2D/3D/LSTM-convolution) can be utilized strategically in convolutional neural network architectures to find patterns in both space and time (3) discuss the powerful new concept of 'attention' in neural networks and the powerful abilities it brings to the interpretation of image sequences (4) briefly survey strategies from unsupervised, self-supervised and transfer learning to reduce the need for large labeled datasets. We hope that presenting an overview of these tools - many of which are underutilized - will help accelerate progress in this area. ",
    "url": "https://arxiv.org/abs/2210.12310",
    "authors": [
      "Akansha Singh Bansal",
      "Yoonjin Lee",
      "Kyle Hilburn",
      "Imme Ebert-Uphoff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12314",
    "title": "A Benchmark Study of Contrastive Learning for Arabic Social Meaning",
    "abstract": "Contrastive learning (CL) brought significant progress to various NLP tasks. Despite this progress, CL has not been applied to Arabic NLP to date. Nor is it clear how much benefits it could bring to particular classes of tasks such as those involved in Arabic social meaning (e.g., sentiment analysis, dialect identification, hate speech detection). In this work, we present a comprehensive benchmark study of state-of-the-art supervised CL methods on a wide array of Arabic social meaning tasks. Through extensive empirical analyses, we show that CL methods outperform vanilla finetuning on most tasks we consider. We also show that CL can be data efficient and quantify this efficiency. Overall, our work allows us to demonstrate the promise of CL methods, including in low-resource settings. ",
    "url": "https://arxiv.org/abs/2210.12314",
    "authors": [
      "Md Tawkat Islam Khondaker",
      "El Moatez Billah Nagoudi",
      "AbdelRahim Elmadany",
      "Muhammad Abdul-Mageed",
      "Laks V.S. Lakshmanan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12316",
    "title": "Learning Vector-Quantized Item Representation for Transferable  Sequential Recommenders",
    "abstract": "Recently, the generality of natural language text has been leveraged to develop transferable recommender systems. The basic idea is to employ pre-trained language model (PLM) to encode item text into item representations. Despite the promising transferability, the binding between item text and item representations might be too tight, leading to potential problems such as over-emphasizing text similarity and exaggerating domain gaps. To address this issue, this paper proposes VQ-Rec, a novel approach to learning Vector-Quantized item representations for transferable sequential Recommender. The major novelty of our approach lies in the new item representation scheme: it first maps item text into a vector of discrete indices (called item code), and then employs these indices to lookup the code embedding table for deriving item representations. Such a scheme can be denoted as \"text -> code -> representation\". Based on this representation scheme, we further propose an enhanced contrastive pre-training approach, using semi-synthetic and mixed-domain code representations as hard negatives. Furthermore, we design a new cross-domain fine-tuning method based on a differentiable permutation-based network. Extensive experiments conducted on six public benchmarks demonstrate the effectiveness of the proposed approach, in both cross-domain and cross-platform settings. ",
    "url": "https://arxiv.org/abs/2210.12316",
    "authors": [
      "Yupeng Hou",
      "Zhankui He",
      "Julian McAuley",
      "Wayne Xin Zhao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12321",
    "title": "A Comprehensive Comparison of Neural Networks as Cognitive Models of  Inflection",
    "abstract": "Neural networks have long been at the center of a debate around the cognitive mechanism by which humans process inflectional morphology. This debate has gravitated into NLP by way of the question: Are neural networks a feasible account for human behavior in morphological inflection? We address that question by measuring the correlation between human judgments and neural network probabilities for unknown word inflections. We test a larger range of architectures than previously studied on two important tasks for the cognitive processing debate: English past tense, and German number inflection. We find evidence that the Transformer may be a better account of human behavior than LSTMs on these datasets, and that LSTM features known to increase inflection accuracy do not always result in more human-like behavior. ",
    "url": "https://arxiv.org/abs/2210.12321",
    "authors": [
      "Adam Wiemerslage",
      "Shiran Dudy",
      "Katharina Kann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12335",
    "title": "Guided contrastive self-supervised pre-training for automatic speech  recognition",
    "abstract": "Contrastive Predictive Coding (CPC) is a representation learning method that maximizes the mutual information between intermediate latent representations and the output of a given model. It can be used to effectively initialize the encoder of an Automatic Speech Recognition (ASR) model. We present a novel modification of CPC called Guided Contrastive Predictive Coding (GCPC). Our proposed method maximizes the mutual information between representations from a prior-knowledge model and the output of the model being pre-trained, allowing prior knowledge injection during pre-training. We validate our method on 3 ASR tasks: German, French and English. Our method outperforms CPC pre-training on all three datasets, reducing the Word Error Rate (WER) by 4.44%, 6.55% and 15.43% relative on the German, French and English (Librispeech) tasks respectively, compared to training from scratch, while CPC pre-training only brings 2.96%, 1.01% and 14.39% relative WER reduction respectively. ",
    "url": "https://arxiv.org/abs/2210.12335",
    "authors": [
      "Aparna Khare",
      "Minhua Wu",
      "Saurabhchand Bhati",
      "Jasha Droppo",
      "Roland Maas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.12338",
    "title": "Open-domain Question Answering via Chain of Reasoning over Heterogeneous  Knowledge",
    "abstract": "We propose a novel open-domain question answering (ODQA) framework for answering single/multi-hop questions across heterogeneous knowledge sources. The key novelty of our method is the introduction of the intermediary modules into the current retriever-reader pipeline. Unlike previous methods that solely rely on the retriever for gathering all evidence in isolation, our intermediary performs a chain of reasoning over the retrieved set. Specifically, our method links the retrieved evidence with its related global context into graphs and organizes them into a candidate list of evidence chains. Built upon pretrained language models, our system achieves competitive performance on two ODQA datasets, OTT-QA and NQ, against tables and passages from Wikipedia. In particular, our model substantially outperforms the previous state-of-the-art on OTT-QA with an exact match score of 47.3 (45 % relative gain). ",
    "url": "https://arxiv.org/abs/2210.12338",
    "authors": [
      "Kaixin Ma",
      "Hao Cheng",
      "Xiaodong Liu",
      "Eric Nyberg",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12342",
    "title": "Detection of Risk Predictors of COVID-19 Mortality with Classifier  Machine Learning Models Operated with Routine Laboratory Biomarkers",
    "abstract": "Early evaluation of patients who require special care and high death expectancy in COVID-19 and effective determination of relevant biomarkers on large sample groups are important to reduce mortality. This study aimed to reveal the routine blood value predictors of COVID-19 mortality and to determine the lethal risk levels of these predictors during the disease process. The dataset of the study consists of 38 routine blood values of 2597 patients who died (n = 233) and recovered (n = 2364) from COVID-19 in August-December, 2021. In this study, histogram-based gradient boosting (HGB) model was the most successful mashine learning classifier in detecting living and deceased COVID-19 patients (with squared F1 metrics F1^2 = 1). The most efficient binary combinations with procalcitonin were obtained with D-dimer, ESR, D.Bil and ferritin. The HGB model operated with these couples correctly detected almost all of the patients who survived and died. (precision > 0.98, recall > 0.98, F1^2 > 0.98). Furthermore, in the HGB model operated with a single feature, the most efficient features were Procalcitonin (F1^2 = 0.96) and ferritin (F1^2 = 0.91). In addition, according to the two-threshold approach ferritin values between 376.2 mkg/L and 396.0 mkg/L (F1^2 = 0.91) and procalcitonin values between 0.2 mkg/L and 5.2 mkg/L (F1^2 = 0.95) were found to be fatal risk levels for COVID-19. Considering all the results, we suggest that many features combined with these features, especially procalcitonin and ferritin, operated with the HGB model, can be used to achieve very successful results in the classification of those who live and die from COVID-19.Moreover, we strongly recommend that clinicians consider the critical levels we have found for procalcitonin and ferritin properties to reduce the lethality of COVID-19 disease. ",
    "url": "https://arxiv.org/abs/2210.12342",
    "authors": [
      "Mehmet Tahir Huyut",
      "Andrei Velichko",
      "Maksim Belyaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2210.12345",
    "title": "Neural Sound Field Decomposition with Super-resolution of Sound  Direction",
    "abstract": "Sound field decomposition predicts waveforms in arbitrary directions using signals from a limited number of microphones as inputs. Sound field decomposition is fundamental to downstream tasks, including source localization, source separation, and spatial audio reproduction. Conventional sound field decomposition methods such as Ambisonics have limited spatial decomposition resolution. This paper proposes a learning-based Neural Sound field Decomposition (NeSD) framework to allow sound field decomposition with fine spatial direction resolution, using recordings from microphone capsules of a few microphones at arbitrary positions. The inputs of a NeSD system include microphone signals, microphone positions, and queried directions. The outputs of a NeSD include the waveform and the presence probability of a queried position. We model the NeSD systems respectively with different neural networks, including fully connected, time delay, and recurrent neural networks. We show that the NeSD systems outperform conventional Ambisonics and DOANet methods in sound field decomposition and source localization on speech, music, and sound events datasets. Demos are available at https://www.youtube.com/watch?v=0GIr6doj3BQ. ",
    "url": "https://arxiv.org/abs/2210.12345",
    "authors": [
      "Qiuqiang Kong",
      "Shilei Liu",
      "Junjie Shi",
      "Xuzhou Ye",
      "Yin Cao",
      "Qiaoxi Zhu",
      "Yong Xu",
      "Yuxuan Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.12347",
    "title": "Quantifying Complexity: An Object-Relations Approach to Complex Systems",
    "abstract": "The best way to model, understand, and quantify the information contained in complex systems is an open question in physics, mathematics, and computer science. The uncertain relationship between entropy and complexity further complicates this question. With ideas drawn from the object-relations theory of psychology, this paper develops an object-relations model of complex systems which generalizes to systems of all types, including mathematical operations, machines, biological organisms, and social structures. The resulting Complex Information Entropy (CIE) equation is a robust method to quantify complexity across various contexts. The paper also describes algorithms to iteratively update and improve approximate solutions to the CIE equation, to recursively infer the composition of complex systems, and to discover the connections among objects across different lengthscales and timescales. Applications are discussed in the fields of engineering design, atomic and molecular physics, chemistry, materials science, neuroscience, psychology, sociology, ecology, economics, and medicine. ",
    "url": "https://arxiv.org/abs/2210.12347",
    "authors": [
      "Stephen Casey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2210.12348",
    "title": "A Task-aware Dual Similarity Network for Fine-grained Few-shot Learning",
    "abstract": "The goal of fine-grained few-shot learning is to recognize sub-categories under the same super-category by learning few labeled samples. Most of the recent approaches adopt a single similarity measure, that is, global or local measure alone. However, for fine-grained images with high intra-class variance and low inter-class variance, exploring global invariant features and discriminative local details is quite essential. In this paper, we propose a Task-aware Dual Similarity Network(TDSNet), which applies global features and local patches to achieve better performance. Specifically, a local feature enhancement module is adopted to activate the features with strong discriminability. Besides, task-aware attention exploits the important patches among the entire task. Finally, both the class prototypes obtained by global features and discriminative local patches are employed for prediction. Extensive experiments on three fine-grained datasets demonstrate that the proposed TDSNet achieves competitive performance by comparing with other state-of-the-art algorithms. ",
    "url": "https://arxiv.org/abs/2210.12348",
    "authors": [
      "Yan Qi",
      "Han Sun",
      "Ningzhong Liu",
      "Huiyu Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12352",
    "title": "NeuPhysics: Editable Neural Geometry and Physics from Monocular Videos",
    "abstract": "We present a method for learning 3D geometry and physics parameters of a dynamic scene from only a monocular RGB video input. To decouple the learning of underlying scene geometry from dynamic motion, we represent the scene as a time-invariant signed distance function (SDF) which serves as a reference frame, along with a time-conditioned deformation field. We further bridge this neural geometry representation with a differentiable physics simulator by designing a two-way conversion between the neural field and its corresponding hexahedral mesh, enabling us to estimate physics parameters from the source video by minimizing a cycle consistency loss. Our method also allows a user to interactively edit 3D objects from the source video by modifying the recovered hexahedral mesh, and propagating the operation back to the neural field representation. Experiments show that our method achieves superior mesh and video reconstruction of dynamic scenes compared to competing Neural Field approaches, and we provide extensive examples which demonstrate its ability to extract useful 3D representations from videos captured with consumer-grade cameras. ",
    "url": "https://arxiv.org/abs/2210.12352",
    "authors": [
      "Yi-Ling Qiao",
      "Alexander Gao",
      "Ming C. Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12365",
    "title": "NeuroCounterfactuals: Beyond Minimal-Edit Counterfactuals for Richer  Data Augmentation",
    "abstract": "While counterfactual data augmentation offers a promising step towards robust generalization in natural language processing, producing a set of counterfactuals that offer valuable inductive bias for models remains a challenge. Most existing approaches for producing counterfactuals, manual or automated, rely on small perturbations via minimal edits, resulting in simplistic changes. We introduce NeuroCounterfactuals, designed as loose counterfactuals, allowing for larger edits which result in naturalistic generations containing linguistic diversity, while still bearing similarity to the original document. Our novel generative approach bridges the benefits of constrained decoding, with those of language model adaptation for sentiment steering. Training data augmentation with our generations results in both in-domain and out-of-domain improvements for sentiment classification, outperforming even manually curated counterfactuals, under select settings. We further present detailed analyses to show the advantages of NeuroCounterfactuals over approaches involving simple, minimal edits. ",
    "url": "https://arxiv.org/abs/2210.12365",
    "authors": [
      "Phillip Howard",
      "Gadi Singer",
      "Vasudev Lal",
      "Yejin Choi",
      "Swabha Swayamdipta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12367",
    "title": "Precisely the Point: Adversarial Augmentations for Faithful and  Informative Text Generation",
    "abstract": "Though model robustness has been extensively studied in language understanding, the robustness of Seq2Seq generation remains understudied. In this paper, we conduct the first quantitative analysis on the robustness of pre-trained Seq2Seq models. We find that even current SOTA pre-trained Seq2Seq model (BART) is still vulnerable, which leads to significant degeneration in faithfulness and informativeness for text generation tasks. This motivated us to further propose a novel adversarial augmentation framework, namely AdvSeq, for generally improving faithfulness and informativeness of Seq2Seq models via enhancing their robustness. AdvSeq automatically constructs two types of adversarial augmentations during training, including implicit adversarial samples by perturbing word representations and explicit adversarial samples by word swapping, both of which effectively improve Seq2Seq robustness. Extensive experiments on three popular text generation tasks demonstrate that AdvSeq significantly improves both the faithfulness and informativeness of Seq2Seq generation under both automatic and human evaluation settings. ",
    "url": "https://arxiv.org/abs/2210.12367",
    "authors": [
      "Wenhao Wu",
      "Wei Li",
      "Jiachen Liu",
      "Xinyan Xiao",
      "Sujian Li",
      "Yajuan Lyu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12383",
    "title": "Stance Detection and Open Research Avenues",
    "abstract": "This tutorial aims to cover the state-of-the-art on stance detection and address open research avenues for interested researchers and practitioners. Stance detection is a recent research topic where the stance towards a given target or target set is determined based on the given content and there are significant application opportunities of stance detection in various domains. The tutorial comprises two parts where the first part outlines the fundamental concepts, problems, approaches, and resources of stance detection, while the second part covers open research avenues and application areas of stance detection. The tutorial will be a useful guide for researchers and practitioners of stance detection, social media analysis, information retrieval, and natural language processing. ",
    "url": "https://arxiv.org/abs/2210.12383",
    "authors": [
      "Dilek K\u00fc\u00e7\u00fck",
      "Fazli Can"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12384",
    "title": "The Devil is in the Conflict: Disentangled Information Graph Neural  Networks for Fraud Detection",
    "abstract": "Graph-based fraud detection has heretofore received considerable attention. Owning to the great success of Graph Neural Networks (GNNs), many approaches adopting GNNs for fraud detection has been gaining momentum. However, most existing methods are based on the strong inductive bias of homophily, which indicates that the context neighbors tend to have same labels or similar features. In real scenarios, fraudsters often engage in camouflage behaviors in order to avoid detection system. Therefore, the homophilic assumption no longer holds, which is known as the inconsistency problem. In this paper, we argue that the performance degradation is mainly attributed to the inconsistency between topology and attribute. To address this problem, we propose to disentangle the fraud network into two views, each corresponding to topology and attribute respectively. Then we propose a simple and effective method that uses the attention mechanism to adaptively fuse two views which captures data-specific preference. In addition, we further improve it by introducing mutual information constraints for topology and attribute. To this end, we propose a Disentangled Information Graph Neural Network (DIGNN) model, which utilizes variational bounds to find an approximate solution to our proposed optimization objective function. Extensive experiments demonstrate that our model can significantly outperform stateof-the-art baselines on real-world fraud detection datasets. ",
    "url": "https://arxiv.org/abs/2210.12384",
    "authors": [
      "Zhixun Li",
      "Dingshuo Chen",
      "Qiang Liu",
      "Shu Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.12389",
    "title": "Neural Distortion Fields for Spatial Calibration of Wide Field-of-View  Near-Eye Displays",
    "abstract": "We propose a spatial calibration method for wide Field-of-View (FoV) Near-Eye Displays (NEDs) with complex image distortions. Image distortions in NEDs can destroy the reality of the virtual object and cause sickness. To achieve distortion-free images in NEDs, it is necessary to establish a pixel-by-pixel correspondence between the viewpoint and the displayed image. Designing compact and wide-FoV NEDs requires complex optical designs. In such designs, the displayed images are subject to gaze-contingent, non-linear geometric distortions, which explicit geometric models can be difficult to represent or computationally intensive to optimize. To solve these problems, we propose Neural Distortion Field (NDF), a fully-connected deep neural network that implicitly represents display surfaces complexly distorted in spaces. NDF takes spatial position and gaze direction as input and outputs the display pixel coordinate and its intensity as perceived in the input gaze direction. We synthesize the distortion map from a novel viewpoint by querying points on the ray from the viewpoint and computing a weighted sum to project output display coordinates into an image. Experiments showed that NDF calibrates an augmented reality NED with 90$^{\\circ}$ FoV with about 3.23 pixel (5.8 arcmin) median error using only 8 training viewpoints. Additionally, we confirmed that NDF calibrates more accurately than the non-linear polynomial fitting, especially around the center of the FoV. ",
    "url": "https://arxiv.org/abs/2210.12389",
    "authors": [
      "Yuichi Hiroi",
      "Kiyosato Someya",
      "Yuta Itoh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.12396",
    "title": "ADDMU: Detection of Far-Boundary Adversarial Examples with Data and  Model Uncertainty Estimation",
    "abstract": "Adversarial Examples Detection (AED) is a crucial defense technique against adversarial attacks and has drawn increasing attention from the Natural Language Processing (NLP) community. Despite the surge of new AED methods, our studies show that existing methods heavily rely on a shortcut to achieve good performance. In other words, current search-based adversarial attacks in NLP stop once model predictions change, and thus most adversarial examples generated by those attacks are located near model decision boundaries. To surpass this shortcut and fairly evaluate AED methods, we propose to test AED methods with \\textbf{F}ar \\textbf{B}oundary (\\textbf{FB}) adversarial examples. Existing methods show worse than random guess performance under this scenario. To overcome this limitation, we propose a new technique, \\textbf{ADDMU}, \\textbf{a}dversary \\textbf{d}etection with \\textbf{d}ata and \\textbf{m}odel \\textbf{u}ncertainty, which combines two types of uncertainty estimation for both regular and FB adversarial example detection. Our new method outperforms previous methods by 3.6 and 6.0 \\emph{AUC} points under each scenario. Finally, our analysis shows that the two types of uncertainty provided by \\textbf{ADDMU} can be leveraged to characterize adversarial examples and identify the ones that contribute most to model's robustness in adversarial training. ",
    "url": "https://arxiv.org/abs/2210.12396",
    "authors": [
      "Fan Yin",
      "Yao Li",
      "Cho-Jui Hsieh",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12397",
    "title": "MetaASSIST: Robust Dialogue State Tracking with Meta Learning",
    "abstract": "Existing dialogue datasets contain lots of noise in their state annotations. Such noise can hurt model training and ultimately lead to poor generalization performance. A general framework named ASSIST has recently been proposed to train robust dialogue state tracking (DST) models. It introduces an auxiliary model to generate pseudo labels for the noisy training set. These pseudo labels are combined with vanilla labels by a common fixed weighting parameter to train the primary DST model. Notwithstanding the improvements of ASSIST on DST, tuning the weighting parameter is challenging. Moreover, a single parameter shared by all slots and all instances may be suboptimal. To overcome these limitations, we propose a meta learning-based framework MetaASSIST to adaptively learn the weighting parameter. Specifically, we propose three schemes with varying degrees of flexibility, ranging from slot-wise to both slot-wise and instance-wise, to convert the weighting parameter into learnable functions. These functions are trained in a meta-learning manner by taking the validation set as meta data. Experimental results demonstrate that all three schemes can achieve competitive performance. Most impressively, we achieve a state-of-the-art joint goal accuracy of 80.10% on MultiWOZ 2.4. ",
    "url": "https://arxiv.org/abs/2210.12397",
    "authors": [
      "Fanghua Ye",
      "Xi Wang",
      "Jie Huang",
      "Shenghui Li",
      "Samuel Stern",
      "Emine Yilmaz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12398",
    "title": "NeARportation: A Remote Real-time Neural Rendering Framework",
    "abstract": "While the presentation of photo-realistic appearance plays a major role in immersion in an augmented virtuality environment, displaying the photo-realistic appearance of real objects remains a challenging problem. Recent developments in photogrammetry have facilitated the incorporation of real objects into virtual space. However, photo-realistic photogrammetry requires a dedicated measurement environment, and there is a trade-off between measurement cost and quality. Furthermore, even with photo-realistic appearance measurements, there is a trade-off between rendering quality and framerate. There is no framework that could resolve these trade-offs and easily provide a photo-realistic appearance in real-time. Our NeARportation framework combines server-client bidirectional communication and neural rendering to resolve these trade-offs. Neural rendering on the server receives the client's head posture and generates a novel-view image with realistic appearance reproduction, which is streamed onto the client's display. By applying our framework to a stereoscopic display, we confirmed that it could display a high-fidelity appearance on full-HD stereo videos at 35-40 frames-per-second (fps), according to the user's head motion. ",
    "url": "https://arxiv.org/abs/2210.12398",
    "authors": [
      "Yuichi Hiroi",
      "Yuta Itoh",
      "Jun Rekimoto"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2210.12401",
    "title": "PcMSP: A Dataset for Scientific Action Graphs Extraction from  Polycrystalline Materials Synthesis Procedure Text",
    "abstract": "Scientific action graphs extraction from materials synthesis procedures is important for reproducible research, machine automation, and material prediction. But the lack of annotated data has hindered progress in this field. We demonstrate an effort to annotate Polycrystalline Materials Synthesis Procedures (PcMSP) from 305 open access scientific articles for the construction of synthesis action graphs. This is a new dataset for material science information extraction that simultaneously contains the synthesis sentences extracted from the experimental paragraphs, as well as the entity mentions and intra-sentence relations. A two-step human annotation and inter-annotator agreement study guarantee the high quality of the PcMSP corpus. We introduce four natural language processing tasks: sentence classification, named entity recognition, relation classification, and joint extraction of entities and relations. Comprehensive experiments validate the effectiveness of several state-of-the-art models for these challenges while leaving large space for improvement. We also perform the error analysis and point out some unique challenges that require further investigation. We will release our annotation scheme, the corpus, and codes to the research community to alleviate the scarcity of labeled data in this domain. ",
    "url": "https://arxiv.org/abs/2210.12401",
    "authors": [
      "Xianjun Yang",
      "Ya Zhuo",
      "Julia Zuo",
      "Xinlu Zhang",
      "Stephen Wilson",
      "Linda Petzold"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12402",
    "title": "DIGMN: Dynamic Intent Guided Meta Network for Differentiated User  Engagement Forecasting in Online Professional Social Platforms",
    "abstract": "User engagement prediction plays a critical role for designing interaction strategies to grow user engagement and increase revenue in online social platforms. Through the in-depth analysis of the real-world data from the world's largest professional social platforms, i.e., LinkedIn, we find that users expose diverse engagement patterns, and a major reason for the differences in user engagement patterns is that users have different intents. That is, people have different intents when using LinkedIn, e.g., applying for jobs, building connections, or checking notifications, which shows quite different engagement patterns. Meanwhile, user intents and the corresponding engagement patterns may change over time. Although such pattern differences and dynamics are essential for user engagement prediction, differentiating user engagement patterns based on user dynamic intents for better user engagement forecasting has not received enough attention in previous works. In this paper, we proposed a Dynamic Intent Guided Meta Network (DIGMN), which can explicitly model user intent varying with time and perform differentiated user engagement forecasting. Specifically, we derive some interpretable basic user intents as prior knowledge from data mining and introduce prior intents in explicitly modeling dynamic user intent. Furthermore, based on the dynamic user intent representations, we propose a meta predictor to perform differentiated user engagement forecasting. Through a comprehensive evaluation on LinkedIn anonymous user data, our method outperforms state-of-the-art baselines significantly, i.e., 2.96% and 3.48% absolute error reduction, on coarse-grained and fine-grained user engagement prediction tasks, respectively, demonstrating the effectiveness of our method. ",
    "url": "https://arxiv.org/abs/2210.12402",
    "authors": [
      "Feifan Li",
      "Lun Du",
      "Qiang Fu",
      "Shi Han",
      "Yushu Du",
      "Guangming Lu",
      "Zi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12415",
    "title": "ALT: Breaking the Wall between Graph and Operator Level Optimizations  for Deep Learning Compilation",
    "abstract": "Deep learning models rely on highly optimized tensor libraries for efficient inference on heterogeneous hardware. Current deep compilers typically predetermine layouts of tensors and then optimize loops of operators. However, such unidirectional and one-off workflow strictly separates graph-level optimization and operator-level optimization into different system layers, missing opportunities for unified tuning. This paper proposes ALT, a compiler that performs joint graph- and operator-level optimizations for deep models. JOG provides a generic transformation module to manipulate layouts and loops with easy-to-use primitive functions. JOG further integrates an auto-tuning module that jointly optimizes graph-level data layouts and operator-level loops while guaranteeing efficiency. Experimental results show that JOG significantly outperforms state-of-the-art compilers (e.g., Ansor) in terms of both single operator performance (e.g., 1.5x speedup on average) and end-to-end inference performance (e.g., 1.4x speedup on average). ",
    "url": "https://arxiv.org/abs/2210.12415",
    "authors": [
      "Zhiying Xu",
      "Jiafan Xu",
      "Hongding Peng",
      "Wei Wang",
      "Xiaoliang Wang",
      "Haoran Wan",
      "Haipeng Dai",
      "Yixu Xu",
      "Hao Cheng",
      "Kun Wang",
      "Guihai Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.12427",
    "title": "Hard Gate Knowledge Distillation -- Leverage Calibration for Robust and  Reliable Language Model",
    "abstract": "In knowledge distillation, a student model is trained with supervisions from both knowledge from a teacher and observations drawn from a training data distribution. Knowledge of a teacher is considered a subject that holds inter-class relations which send a meaningful supervision to a student; hence, much effort has been put to find such knowledge to be distilled. In this paper, we explore a question that has been given little attention: \"when to distill such knowledge.\" The question is answered in our work with the concept of model calibration; we view a teacher model not only as a source of knowledge but also as a gauge to detect miscalibration of a student. This simple and yet novel view leads to a hard gate knowledge distillation scheme that switches between learning from a teacher model and training data. We verify the gating mechanism in the context of natural language generation at both the token-level and the sentence-level. Empirical comparisons with strong baselines show that hard gate knowledge distillation not only improves model generalization, but also significantly lowers model calibration error. ",
    "url": "https://arxiv.org/abs/2210.12427",
    "authors": [
      "Dongkyu Lee",
      "Zhiliang Tian",
      "Yingxiu Zhao",
      "Ka Chun Cheung",
      "Nevin L. Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.12430",
    "title": "Speech Emotion Recognition via an Attentive Time-Frequency Neural  Network",
    "abstract": "Spectrogram is commonly used as the input feature of deep neural networks to learn the high(er)-level time-frequency pattern of speech signal for speech emotion recognition (SER). \\textcolor{black}{Generally, different emotions correspond to specific energy activations both within frequency bands and time frames on spectrogram, which indicates the frequency and time domains are both essential to represent the emotion for SER. However, recent spectrogram-based works mainly focus on modeling the long-term dependency in time domain, leading to these methods encountering the following two issues: (1) neglecting to model the emotion-related correlations within frequency domain during the time-frequency joint learning; (2) ignoring to capture the specific frequency bands associated with emotions.} To cope with the issues, we propose an attentive time-frequency neural network (ATFNN) for SER, including a time-frequency neural network (TFNN) and time-frequency attention. Specifically, aiming at the first issue, we design a TFNN with a frequency-domain encoder (F-Encoder) based on the Transformer encoder and a time-domain encoder (T-Encoder) based on the Bidirectional Long Short-Term Memory (Bi-LSTM). The F-Encoder and T-Encoder model the correlations within frequency bands and time frames, respectively, and they are embedded into a time-frequency joint learning strategy to obtain the time-frequency patterns for speech emotions. Moreover, to handle the second issue, we also adopt time-frequency attention with a frequency-attention network (F-Attention) and a time-attention network (T-Attention) to focus on the emotion-related frequency band ranges and time frame ranges, which can enhance the discriminability of speech emotion features. ",
    "url": "https://arxiv.org/abs/2210.12430",
    "authors": [
      "Cheng Lu",
      "Wenming Zheng",
      "Hailun Lian",
      "Yuan Zong",
      "Chuangao Tang",
      "Sunan Li",
      "Yan Zhao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.12438",
    "title": "Algorithms with Prediction Portfolios",
    "abstract": "The research area of algorithms with predictions has seen recent success showing how to incorporate machine learning into algorithm design to improve performance when the predictions are correct, while retaining worst-case guarantees when they are not. Most previous work has assumed that the algorithm has access to a single predictor. However, in practice, there are many machine learning methods available, often with incomparable generalization guarantees, making it hard to pick a best method a priori. In this work we consider scenarios where multiple predictors are available to the algorithm and the question is how to best utilize them. Ideally, we would like the algorithm's performance to depend on the quality of the best predictor. However, utilizing more predictions comes with a cost, since we now have to identify which prediction is the best. We study the use of multiple predictors for a number of fundamental problems, including matching, load balancing, and non-clairvoyant scheduling, which have been well-studied in the single predictor setting. For each of these problems we introduce new algorithms that take advantage of multiple predictors, and prove bounds on the resulting performance. ",
    "url": "https://arxiv.org/abs/2210.12438",
    "authors": [
      "Michael Dinitz",
      "Sungjin Im",
      "Thomas Lavastida",
      "Benjamin Moseley",
      "Sergei Vassilvitskii"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2210.12459",
    "title": "There Is No Standard Answer: Knowledge-Grounded Dialogue Generation with  Adversarial Activated Multi-Reference Learning",
    "abstract": "Knowledge-grounded conversation (KGC) shows excellent potential to deliver an engaging and informative response. However, existing approaches emphasize selecting one golden knowledge given a particular dialogue context, overlooking the one-to-many phenomenon in dialogue. As a result, the existing paradigm limits the diversity of knowledge selection and generation. To this end, we establish a multi-reference KGC dataset and propose a series of metrics to systematically assess the one-to-many efficacy of existing KGC models. Furthermore, to extend the hypothesis space of knowledge selection to enhance the mapping relationship between multiple knowledge and multiple responses, we devise a span-based variational model and optimize the model in a wake-sleep style with an ameliorated evidence lower bound objective to learn the one-to-many generalization. Both automatic and human evaluations demonstrate the efficacy of our approach. ",
    "url": "https://arxiv.org/abs/2210.12459",
    "authors": [
      "Xueliang Zhao",
      "Tingchen Fu",
      "Chongyang Tao",
      "Rui Yan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12460",
    "title": "Collaborative Reasoning on Multi-Modal Semantic Graphs for  Video-Grounded Dialogue Generation",
    "abstract": "We study video-grounded dialogue generation, where a response is generated based on the dialogue context and the associated video. The primary challenges of this task lie in (1) the difficulty of integrating video data into pre-trained language models (PLMs) which presents obstacles to exploiting the power of large-scale pre-training; and (2) the necessity of taking into account the complementarity of various modalities throughout the reasoning process. Although having made remarkable progress in video-grounded dialogue generation, existing methods still fall short when it comes to integrating with PLMs in a way that allows information from different modalities to complement each other. To alleviate these issues, we first propose extracting pertinent information from videos and turning it into reasoning paths that are acceptable to PLMs. Additionally, we propose a multi-agent reinforcement learning method to collaboratively perform reasoning on different modalities (i.e., video and dialogue context). Empirical experiment results on two public datasets indicate that the proposed model can significantly outperform state-of-the-art models by large margins on both automatic and human evaluations. ",
    "url": "https://arxiv.org/abs/2210.12460",
    "authors": [
      "Xueliang Zhao",
      "Yuxuan Wang",
      "Chongyang Tao",
      "Chenshuo Wang",
      "Dongyan Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12492",
    "title": "NeuroMapper: In-browser Visualizer for Neural Network Training",
    "abstract": "We present our ongoing work NeuroMapper, an in-browser visualization tool that helps machine learning (ML) developers interpret the evolution of a model during training, providing a new way to monitor the training process and visually discover reasons for suboptimal training. While most existing deep neural networks (DNNs) interpretation tools are designed for already-trained model, NeuroMapper scalably visualizes the evolution of the embeddings of a model's blocks across training epochs, enabling real-time visualization of 40,000 embedded points. To promote the embedding visualizations' spatial coherence across epochs, NeuroMapper adapts AlignedUMAP, a recent nonlinear dimensionality reduction technique to align the embeddings. With NeuroMapper, users can explore the training dynamics of a Resnet-50 model, and adjust the embedding visualizations' parameters in real time. NeuroMapper is open-sourced at https://github.com/poloclub/NeuroMapper and runs in all modern web browsers. A demo of the tool in action is available at: https://poloclub.github.io/NeuroMapper/. ",
    "url": "https://arxiv.org/abs/2210.12492",
    "authors": [
      "Zhiyan Zhou",
      "Kevin Li",
      "Haekyu Park",
      "Megan Dass",
      "Austin Wright",
      "Nilaksh Das",
      "Duen Horng Chau"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12506",
    "title": "Self-supervised Graph-based Point-of-interest Recommendation",
    "abstract": "The exponential growth of Location-based Social Networks (LBSNs) has greatly stimulated the demand for precise location-based recommendation services. Next Point-of-Interest (POI) recommendation, which aims to provide personalised POI suggestions for users based on their visiting histories, has become a prominent component in location-based e-commerce. Recent POI recommenders mainly employ self-attention mechanism or graph neural networks to model complex high-order POI-wise interactions. However, most of them are merely trained on the historical check-in data in a standard supervised learning manner, which fail to fully explore each user's multi-faceted preferences, and suffer from data scarcity and long-tailed POI distribution, resulting in sub-optimal performance. To this end, we propose a Self-s}upervised Graph-enhanced POI Recommender (S2GRec) for next POI recommendation. In particular, we devise a novel Graph-enhanced Self-attentive layer to incorporate the collaborative signals from both global transition graph and local trajectory graphs to uncover the transitional dependencies among POIs and capture a user's temporal interests. In order to counteract the scarcity and incompleteness of POI check-ins, we propose a novel self-supervised learning paradigm in \\ssgrec, where the trajectory representations are contrastively learned from two augmented views on geolocations and temporal transitions. Extensive experiments are conducted on three real-world LBSN datasets, demonstrating the effectiveness of our model against state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2210.12506",
    "authors": [
      "Yang Li",
      "Tong Chen",
      "Peng-Fei Zhang",
      "Zi Huang",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12517",
    "title": "Exploring The Landscape of Distributional Robustness for Question  Answering Models",
    "abstract": "We conduct a large empirical evaluation to investigate the landscape of distributional robustness in question answering. Our investigation spans over 350 models and 16 question answering datasets, including a diverse set of architectures, model sizes, and adaptation methods (e.g., fine-tuning, adapter tuning, in-context learning, etc.). We find that, in many cases, model variations do not affect robustness and in-distribution performance alone determines out-of-distribution performance. Moreover, our findings indicate that i) zero-shot and in-context learning methods are more robust to distribution shifts than fully fine-tuned models; ii) few-shot prompt fine-tuned models exhibit better robustness than few-shot fine-tuned span prediction models; iii) parameter-efficient and robustness enhancing training methods provide no significant robustness improvements. In addition, we publicly release all evaluations to encourage researchers to further analyze robustness trends for question answering models. ",
    "url": "https://arxiv.org/abs/2210.12517",
    "authors": [
      "Anas Awadalla",
      "Mitchell Wortsman",
      "Gabriel Ilharco",
      "Sewon Min",
      "Ian Magnusson",
      "Hannaneh Hajishirzi",
      "Ludwig Schmidt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12523",
    "title": "How Real is Real: Evaluating the Robustness of Real-World Super  Resolution",
    "abstract": "Image super-resolution (SR) is a field in computer vision that focuses on reconstructing high-resolution images from the respective low-resolution image. However, super-resolution is a well-known ill-posed problem as most methods rely on the downsampling method performed on the high-resolution image to form the low-resolution image to be known. Unfortunately, this is not something that is available in real-life super-resolution applications such as increasing the quality of a photo taken on a mobile phone. In this paper we will evaluate multiple state-of-the-art super-resolution methods and gauge their performance when presented with various types of real-life images and discuss the benefits and drawbacks of each method. We also introduce a novel dataset, WideRealSR, containing real images from a wide variety of sources. Finally, through careful experimentation and evaluation, we will present a potential solution to alleviate the generalization problem which is imminent in most state-of-the-art super-resolution models. ",
    "url": "https://arxiv.org/abs/2210.12523",
    "authors": [
      "Athiya Deviyani",
      "Efe Sinan Hoplamaz",
      "Alan Savio Paul"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.12524",
    "title": "Efficient Hair Style Transfer with Generative Adversarial Networks",
    "abstract": "Despite the recent success of image generation and style transfer with Generative Adversarial Networks (GANs), hair synthesis and style transfer remain challenging due to the shape and style variability of human hair in in-the-wild conditions. The current state-of-the-art hair synthesis approaches struggle to maintain global composition of the target style and cannot be used in real-time applications due to their high running costs on high-resolution portrait images. Therefore, We propose a novel hairstyle transfer method, called EHGAN, which reduces computational costs to enable real-time processing while improving the transfer of hairstyle with better global structure compared to the other state-of-the-art hair synthesis methods. To achieve this goal, we train an encoder and a low-resolution generator to transfer hairstyle and then, increase the resolution of results with a pre-trained super-resolution model. We utilize Adaptive Instance Normalization (AdaIN) and design our novel Hair Blending Block (HBB) to obtain the best performance of the generator. EHGAN needs around 2.7 times and over 10,000 times less time consumption than the state-of-the-art MichiGAN and LOHO methods respectively while obtaining better photorealism and structural similarity to the desired style than its competitors. ",
    "url": "https://arxiv.org/abs/2210.12524",
    "authors": [
      "Muhammed Pektas",
      "Baris Gecer",
      "Aybars Ugur"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.12531",
    "title": "Why Do You Feel This Way? Summarizing Triggers of Emotions in Social  Media Posts",
    "abstract": "Crises such as the COVID-19 pandemic continuously threaten our world and emotionally affect billions of people worldwide in distinct ways. Understanding the triggers leading to people's emotions is of crucial importance. Social media posts can be a good source of such analysis, yet these texts tend to be charged with multiple emotions, with triggers scattering across multiple sentences. This paper takes a novel angle, namely, emotion detection and trigger summarization, aiming to both detect perceived emotions in text, and summarize events and their appraisals that trigger each emotion. To support this goal, we introduce CovidET (Emotions and their Triggers during Covid-19), a dataset of ~1,900 English Reddit posts related to COVID-19, which contains manual annotations of perceived emotions and abstractive summaries of their triggers described in the post. We develop strong baselines to jointly detect emotions and summarize emotion triggers. Our analyses show that CovidET presents new challenges in emotion-specific summarization, as well as multi-emotion detection in long social media posts. ",
    "url": "https://arxiv.org/abs/2210.12531",
    "authors": [
      "Hongli Zhan",
      "Tiberiu Sosea",
      "Cornelia Caragea",
      "Junyi Jessy Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.12538",
    "title": "Compressing multidimensional weather and climate data into neural  networks",
    "abstract": "Weather and climate simulations produce petabytes of high-resolution data that are later analyzed by researchers in order to understand climate change or severe weather. We propose a new method of compressing this multidimensional weather and climate data: a coordinate-based neural network is trained to overfit the data, and the resulting parameters are taken as a compact representation of the original grid-based data. While compression ratios range from 300x to more than 3,000x, our method outperforms the state-of-the-art compressor SZ3 in terms of weighted RMSE, MAE. It can faithfully preserve important large scale atmosphere structures and does not introduce artifacts. When using the resulting neural network as a 790x compressed dataloader to train the WeatherBench forecasting model, its RMSE increases by less than 2%. The three orders of magnitude compression democratizes access to high-resolution climate data and enables numerous new research directions. ",
    "url": "https://arxiv.org/abs/2210.12538",
    "authors": [
      "Langwen Huang",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2210.12540",
    "title": "EntityCS: Improving Zero-Shot Cross-lingual Transfer with Entity-Centric  Code Switching",
    "abstract": "Accurate alignment between languages is fundamental for improving cross-lingual pre-trained language models (XLMs). Motivated by the natural phenomenon of code-switching (CS) in multilingual speakers, CS has been used as an effective data augmentation method that offers language alignment at word- or phrase-level, in contrast to sentence-level via parallel instances. Existing approaches either use dictionaries or parallel sentences with word-alignment to generate CS data by randomly switching words in a sentence. However, such methods can be suboptimal as dictionaries disregard semantics, and syntax might become invalid after random word switching. In this work, we propose EntityCS, a method that focuses on Entity-level Code-Switching to capture fine-grained cross-lingual semantics without corrupting syntax. We use Wikidata and the English Wikipedia to construct an entity-centric CS corpus by switching entities to their counterparts in other languages. We further propose entity-oriented masking strategies during intermediate model training on the EntityCS corpus for improving entity prediction. Evaluation of the trained models on four entity-centric downstream tasks shows consistent improvements over the baseline with a notable increase of 10% in Fact Retrieval. We release the corpus and models to assist research on code-switching and enriching XLMs with external knowledge. ",
    "url": "https://arxiv.org/abs/2210.12540",
    "authors": [
      "Chenxi Whitehouse",
      "Fenia Christopoulou",
      "Ignacio Iacobacci"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12584",
    "title": "MR-Based Electrical Property Reconstruction Using Physics-Informed  Neural Networks",
    "abstract": "Electrical properties (EP), namely permittivity and electric conductivity, dictate the interactions between electromagnetic waves and biological tissue. EP can be potential biomarkers for pathology characterization, such as cancer, and improve therapeutic modalities, such radiofrequency hyperthermia and ablation. MR-based electrical properties tomography (MR-EPT) uses MR measurements to reconstruct the EP maps. Using the homogeneous Helmholtz equation, EP can be directly computed through calculations of second order spatial derivatives of the measured magnetic transmit or receive fields $(B_{1}^{+}, B_{1}^{-})$. However, the numerical approximation of derivatives leads to noise amplifications in the measurements and thus erroneous reconstructions. Recently, a noise-robust supervised learning-based method (DL-EPT) was introduced for EP reconstruction. However, the pattern-matching nature of such network does not allow it to generalize for new samples since the network's training is done on a limited number of simulated data. In this work, we leverage recent developments on physics-informed deep learning to solve the Helmholtz equation for the EP reconstruction. We develop deep neural network (NN) algorithms that are constrained by the Helmholtz equation to effectively de-noise the $B_{1}^{+}$ measurements and reconstruct EP directly at an arbitrarily high spatial resolution without requiring any known $B_{1}^{+}$ and EP distribution pairs. ",
    "url": "https://arxiv.org/abs/2210.12584",
    "authors": [
      "Xinling Yu",
      "Jos\u00e9 E. C. Serrall\u00e9s",
      "Ilias I. Giannakopoulos",
      "Ziyue Liu",
      "Luca Daniel",
      "Riccardo Lattanzi",
      "Zheng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Biological Physics (physics.bio-ph)"
    ]
  },
  {
    "id": "arXiv:2210.12593",
    "title": "Single Image Super-Resolution via a Dual Interactive Implicit Neural  Network",
    "abstract": "In this paper, we introduce a novel implicit neural network for the task of single image super-resolution at arbitrary scale factors. To do this, we represent an image as a decoding function that maps locations in the image along with their associated features to their reciprocal pixel attributes. Since the pixel locations are continuous in this representation, our method can refer to any location in an image of varying resolution. To retrieve an image of a particular resolution, we apply a decoding function to a grid of locations each of which refers to the center of a pixel in the output image. In contrast to other techniques, our dual interactive neural network decouples content and positional features. As a result, we obtain a fully implicit representation of the image that solves the super-resolution problem at (real-valued) elective scales using a single model. We demonstrate the efficacy and flexibility of our approach against the state of the art on publicly available benchmark datasets. ",
    "url": "https://arxiv.org/abs/2210.12593",
    "authors": [
      "Quan H. Nguyen",
      "William J. Beksi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.12598",
    "title": "GANI: Global Attacks on Graph Neural Networks via Imperceptible Node  Injections",
    "abstract": "Graph neural networks (GNNs) have found successful applications in various graph-related tasks. However, recent studies have shown that many GNNs are vulnerable to adversarial attacks. In a vast majority of existing studies, adversarial attacks on GNNs are launched via direct modification of the original graph such as adding/removing links, which may not be applicable in practice. In this paper, we focus on a realistic attack operation via injecting fake nodes. The proposed Global Attack strategy via Node Injection (GANI) is designed under the comprehensive consideration of an unnoticeable perturbation setting from both structure and feature domains. Specifically, to make the node injections as imperceptible and effective as possible, we propose a sampling operation to determine the degree of the newly injected nodes, and then generate features and select neighbors for these injected nodes based on the statistical information of features and evolutionary perturbations obtained from a genetic algorithm, respectively. In particular, the proposed feature generation mechanism is suitable for both binary and continuous node features. Extensive experimental results on benchmark datasets against both general and defended GNNs show strong attack performance of GANI. Moreover, the imperceptibility analyses also demonstrate that GANI achieves a relatively unnoticeable injection on benchmark datasets. ",
    "url": "https://arxiv.org/abs/2210.12598",
    "authors": [
      "Junyuan Fang",
      "Haixian Wen",
      "Jiajing Wu",
      "Qi Xuan",
      "Zibin Zheng",
      "Chi K. Tse"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.12606",
    "title": "Nash Equilibria and Pitfalls of Adversarial Training in Adversarial  Robustness Games",
    "abstract": "Adversarial training is a standard technique for training adversarially robust models. In this paper, we study adversarial training as an alternating best-response strategy in a 2-player zero-sum game. We prove that even in a simple scenario of a linear classifier and a statistical model that abstracts robust vs. non-robust features, the alternating best response strategy of such game may not converge. On the other hand, a unique pure Nash equilibrium of the game exists and is provably robust. We support our theoretical results with experiments, showing the non-convergence of adversarial training and the robustness of Nash equilibrium. ",
    "url": "https://arxiv.org/abs/2210.12606",
    "authors": [
      "Maria-Florina Balcan",
      "Rattana Pukdee",
      "Pradeep Ravikumar",
      "Hongyang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2210.12607",
    "title": "Learning to Perform Complex Tasks through Compositional Fine-Tuning of  Language Models",
    "abstract": "How to usefully encode compositional task structure has long been a core challenge in AI. Recent work in chain of thought prompting has shown that for very large neural language models (LMs), explicitly demonstrating the inferential steps involved in a target task may improve performance over end-to-end learning that focuses on the target task alone. However, chain of thought prompting has significant limitations due to its dependency on huge pretrained LMs. In this work, we present compositional fine-tuning (CFT): an approach based on explicitly decomposing a target task into component tasks, and then fine-tuning smaller LMs on a curriculum of such component tasks. We apply CFT to recommendation tasks in two domains, world travel and local dining, as well as a previously studied inferential task (sports understanding). We show that CFT outperforms end-to-end learning even with equal amounts of data, and gets consistently better as more component tasks are modeled via fine-tuning. Compared with chain of thought prompting, CFT performs at least as well using LMs only 7.4% of the size, and is moreover applicable to task domains for which data are not available during pretraining. ",
    "url": "https://arxiv.org/abs/2210.12607",
    "authors": [
      "Victor S. Bursztyn",
      "David Demeter",
      "Doug Downey",
      "Larry Birnbaum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12622",
    "title": "Facial De-occlusion Network for Virtual Telepresence Systems",
    "abstract": "To see what is not in the image is one of the broader missions of computer vision. Technology to inpaint images has made significant progress with the coming of deep learning. This paper proposes a method to tackle occlusion specific to human faces. Virtual presence is a promising direction in communication and recreation for the future. However, Virtual Reality (VR) headsets occlude a significant portion of the face, hindering the photo-realistic appearance of the face in the virtual world. State-of-the-art image inpainting methods for de-occluding the eye region does not give usable results. To this end, we propose a working solution that gives usable results to tackle this problem enabling the use of the real-time photo-realistic de-occluded face of the user in VR settings. ",
    "url": "https://arxiv.org/abs/2210.12622",
    "authors": [
      "Surabhi Gupta",
      "Ashwath Shetty",
      "Avinash Sharma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12637",
    "title": "Neural Eigenfunctions Are Structured Representation Learners",
    "abstract": "In this paper, we introduce a scalable method for learning structured, adaptive-length deep representations. Our approach is to train neural networks such that they approximate the principal eigenfunctions of a kernel. We show that, when the kernel is derived from positive relations in a contrastive learning setup, our method outperforms a number of competitive baselines in visual representation learning and transfer learning benchmarks, and importantly, produces structured representations where the order of features indicates degrees of importance. We demonstrate using such representations as adaptive-length codes in image retrieval systems. By truncation according to feature importance, our method requires up to 16$\\times$ shorter representation length than leading self-supervised learning methods to achieve similar retrieval performance. We further apply our method to graph data and report strong results on a node representation learning benchmark with more than one million nodes. ",
    "url": "https://arxiv.org/abs/2210.12637",
    "authors": [
      "Zhijie Deng",
      "Jiaxin Shi",
      "Hao Zhang",
      "Peng Cui",
      "Cewu Lu",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12662",
    "title": "Improving Chinese Named Entity Recognition by Search Engine Augmentation",
    "abstract": "Compared with English, Chinese suffers from more grammatical ambiguities, like fuzzy word boundaries and polysemous words. In this case, contextual information is not sufficient to support Chinese named entity recognition (NER), especially for rare and emerging named entities. Semantic augmentation using external knowledge is a potential way to alleviate this problem, while how to obtain and leverage external knowledge for the NER task remains a challenge. In this paper, we propose a neural-based approach to perform semantic augmentation using external knowledge from search engine for Chinese NER. In particular, a multi-channel semantic fusion model is adopted to generate the augmented input representations, which aggregates external related texts retrieved from the search engine. Experiments have shown the superiority of our model across 4 NER datasets, including formal and social media language contexts, which further prove the effectiveness of our approach. ",
    "url": "https://arxiv.org/abs/2210.12662",
    "authors": [
      "Qinghua Mao",
      "Jiatong Li",
      "Kui Meng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.12669",
    "title": "Meta Learning of Interface Conditions for Multi-Domain Physics-Informed  Neural Networks",
    "abstract": "Physics-informed neural networks (PINNs) are emerging as popular mesh-free solvers for partial differential equations (PDEs). Recent extensions decompose the domain, applying different PINNs to solve the equation in each subdomain and aligning the solution at the interface of the subdomains. Hence, they can further alleviate the problem complexity, reduce the computational cost, and allow parallelization. However, the performance of the multi-domain PINNs is sensitive to the choice of the interface conditions for solution alignment. While quite a few conditions have been proposed, there is no suggestion about how to select the conditions according to specific problems. To address this gap, we propose META Learning of Interface Conditions (METALIC), a simple, efficient yet powerful approach to dynamically determine the optimal interface conditions for solving a family of parametric PDEs. Specifically, we develop two contextual multi-arm bandit models. The first one applies to the entire training procedure, and online updates a Gaussian process (GP) reward surrogate that given the PDE parameters and interface conditions predicts the solution error. The second one partitions the training into two stages, one is the stochastic phase and the other deterministic phase; we update a GP surrogate for each phase to enable different condition selections at the two stages so as to further bolster the flexibility and performance. We have shown the advantage of METALIC on four bench-mark PDE families. ",
    "url": "https://arxiv.org/abs/2210.12669",
    "authors": [
      "Shibo Li",
      "Michael Penwarden",
      "Robert M. Kirby",
      "Shandian Zhe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2210.12674",
    "title": "Towards Generalizable and Robust Text-to-SQL Parsing",
    "abstract": "Text-to-SQL parsing tackles the problem of mapping natural language questions to executable SQL queries. In practice, text-to-SQL parsers often encounter various challenging scenarios, requiring them to be generalizable and robust. While most existing work addresses a particular generalization or robustness challenge, we aim to study it in a more comprehensive manner. In specific, we believe that text-to-SQL parsers should be (1) generalizable at three levels of generalization, namely i.i.d., zero-shot, and compositional, and (2) robust against input perturbations. To enhance these capabilities of the parser, we propose a novel TKK framework consisting of Task decomposition, Knowledge acquisition, and Knowledge composition to learn text-to-SQL parsing in stages. By dividing the learning process into multiple stages, our framework improves the parser's ability to acquire general SQL knowledge instead of capturing spurious patterns, making it more generalizable and robust. Experimental results under various generalization and robustness settings show that our framework is effective in all scenarios and achieves state-of-the-art performance on the Spider, SParC, and CoSQL datasets. Code can be found at https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/tkk. ",
    "url": "https://arxiv.org/abs/2210.12674",
    "authors": [
      "Chang Gao",
      "Bowen Li",
      "Wenxuan Zhang",
      "Wai Lam",
      "Binhua Li",
      "Fei Huang",
      "Luo Si",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12681",
    "title": "Rethinking Rotation in Self-Supervised Contrastive Learning: Adaptive  Positive or Negative Data Augmentation",
    "abstract": "Rotation is frequently listed as a candidate for data augmentation in contrastive learning but seldom provides satisfactory improvements. We argue that this is because the rotated image is always treated as either positive or negative. The semantics of an image can be rotation-invariant or rotation-variant, so whether the rotated image is treated as positive or negative should be determined based on the content of the image. Therefore, we propose a novel augmentation strategy, adaptive Positive or Negative Data Augmentation (PNDA), in which an original and its rotated image are a positive pair if they are semantically close and a negative pair if they are semantically different. To achieve PNDA, we first determine whether rotation is positive or negative on an image-by-image basis in an unsupervised way. Then, we apply PNDA to contrastive learning frameworks. Our experiments showed that PNDA improves the performance of contrastive learning. The code is available at \\url{ https://github.com/AtsuMiyai/rethinking_rotation}. ",
    "url": "https://arxiv.org/abs/2210.12681",
    "authors": [
      "Atsuyuki Miyai",
      "Qing Yu",
      "Daiki Ikami",
      "Go Irie",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12682",
    "title": "Photo-realistic Neural Domain Randomization",
    "abstract": "Synthetic data is a scalable alternative to manual supervision, but it requires overcoming the sim-to-real domain gap. This discrepancy between virtual and real worlds is addressed by two seemingly opposed approaches: improving the realism of simulation or foregoing realism entirely via domain randomization. In this paper, we show that the recent progress in neural rendering enables a new unified approach we call Photo-realistic Neural Domain Randomization (PNDR). We propose to learn a composition of neural networks that acts as a physics-based ray tracer generating high-quality renderings from scene geometry alone. Our approach is modular, composed of different neural networks for materials, lighting, and rendering, thus enabling randomization of different key image generation components in a differentiable pipeline. Once trained, our method can be combined with other methods and used to generate photo-realistic image augmentations online and significantly more efficiently than via traditional ray-tracing. We demonstrate the usefulness of PNDR through two downstream tasks: 6D object detection and monocular depth estimation. Our experiments show that training with PNDR enables generalization to novel scenes and significantly outperforms the state of the art in terms of real-world transfer. ",
    "url": "https://arxiv.org/abs/2210.12682",
    "authors": [
      "Sergey Zakharov",
      "Rares Ambrus",
      "Vitor Guizilini",
      "Wadim Kehl",
      "Adrien Gaidon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.12686",
    "title": "Holistic Interaction Transformer Network for Action Detection",
    "abstract": "Actions are about how we interact with the environment, including other people, objects, and ourselves. In this paper, we propose a novel multi-modal Holistic Interaction Transformer Network (HIT) that leverages the largely ignored, but critical hand and pose information essential to most human actions. The proposed \"HIT\" network is a comprehensive bi-modal framework that comprises an RGB stream and a pose stream. Each of them separately models person, object, and hand interactions. Within each sub-network, an Intra-Modality Aggregation module (IMA) is introduced that selectively merges individual interaction units. The resulting features from each modality are then glued using an Attentive Fusion Mechanism (AFM). Finally, we extract cues from the temporal context to better classify the occurring actions using cached memory. Our method significantly outperforms previous approaches on the J-HMDB, UCF101-24, and MultiSports datasets. We also achieve competitive results on AVA. The code will be available at https://github.com/joslefaure/HIT. ",
    "url": "https://arxiv.org/abs/2210.12686",
    "authors": [
      "Gueter Josmy Faure",
      "Min-Hung Chen",
      "Shang-Hong Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.12689",
    "title": "Face Emotion Recognization Using Dataset Augmentation Based on Neural  Network",
    "abstract": "Facial expression is one of the most external indications of a person's feelings and emotions. In daily conversation, according to the psychologist, only 7\\% and 38\\% of information is communicated through words and sounds respective, while up to 55\\% is through facial expression. It plays an important role in coordinating interpersonal relationships. Ekman and Friesen recognized six essential emotions in the nineteenth century depending on a cross-cultural study, which indicated that people feel each basic emotion in the same fashion despite culture. As a branch of the field of analyzing sentiment, facial expression recognition offers broad application prospects in a variety of domains, including the interaction between humans and computers, healthcare, and behavior monitoring. Therefore, many researchers have devoted themselves to facial expression recognition. In this paper, an effective hybrid data augmentation method is used. This approach is operated on two public datasets, and four benchmark models see some remarkable results. ",
    "url": "https://arxiv.org/abs/2210.12689",
    "authors": [
      "Mengyu Rao",
      "Ruiyi Bao",
      "Liangshun Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12690",
    "title": "DyCSC: Modeling the Evolutionary Process of Dynamic Networks Based on  Cluster Structure",
    "abstract": "Temporal networks are an important type of network whose topological structure changes over time. Compared with methods on static networks, temporal network embedding (TNE) methods are facing three challenges: 1) it cannot describe the temporal dependence across network snapshots; 2) the node embedding in the latent space fails to indicate changes in the network topology; and 3) it cannot avoid a lot of redundant computation via parameter inheritance on a series of snapshots. To this end, we propose a novel temporal network embedding method named Dynamic Cluster Structure Constraint model (DyCSC), whose core idea is to capture the evolution of temporal networks by imposing a temporal constraint on the tendency of the nodes in the network to a given number of clusters. It not only generates low-dimensional embedding vectors for nodes but also preserves the dynamic nonlinear features of temporal networks. Experimental results on multiple realworld datasets have demonstrated the superiority of DyCSC for temporal graph embedding, as it consistently outperforms competing methods by significant margins in multiple temporal link prediction tasks. Moreover, the ablation study further validates the effectiveness of the proposed temporal constraint. ",
    "url": "https://arxiv.org/abs/2210.12690",
    "authors": [
      "Shanfan Zhang",
      "Zhan Bu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.12706",
    "title": "Robust Adaptive Prescribed-Time Control for Parameter-Varying Nonlinear  Systems",
    "abstract": "It is an interesting open problem to achieve adaptive prescribed-time control for strict-feedback systems with unknown and fast or even abrupt time-varying parameters. In this paper we present a solution with the aid of several design and analysis innovations. First, by using a spatiotemporal transformation, we convert the original system operational over finite time interval into one operational over infinite time interval, allowing for Lyapunov asymptotic design and recasting prescribed-time stabilization on finite time domain into asymptotic stabilization on infinite time domain. Second, to deal with time-varying parameters with unknown variation boundaries, we use congelation of variables method and establish three separate adaptive laws for parameter estimation (two for the unknown parameters in the feedback path and one for the unknown parameter in the input path), in doing so we utilize two tuning functions to eliminate over-parametrization. Third, to achieve asymptotic convergence for the transformed system, we make use of nonlinear damping design and non-regressor-based design to cope with time-varying perturbations, and finally, we derive the prescribed-time control scheme from the asymptotic controller via inverse temporal-scale transformation. The boundedness of all closed-loop signals and control input is proved rigorously through Lyapunov analysis, squeeze theorem, and two novel lemmas built upon the method of variation of constants. Numerical simulation verifies the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2210.12706",
    "authors": [
      "Hefu Ye",
      "Yongduan Song"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.12714",
    "title": "Generative Knowledge Graph Construction: A Review",
    "abstract": "Generative Knowledge Graph Construction (KGC) refers to those methods that leverage the sequence-to-sequence framework for building knowledge graphs, which is flexible and can be adapted to widespread tasks. In this study, we summarize the recent compelling progress in generative knowledge graph construction. We present the advantages and weaknesses of each paradigm in terms of different generation targets and provide theoretical insight and empirical analysis. Based on the review, we suggest promising research directions for the future. Our contributions are threefold: (1) We present a detailed, complete taxonomy for the generative KGC methods; (2) We provide a theoretical and empirical analysis of the generative KGC methods; (3) We propose several research directions that can be developed in the future. ",
    "url": "https://arxiv.org/abs/2210.12714",
    "authors": [
      "Hongbin Ye",
      "Ningyu Zhang",
      "Hui Chen",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12727",
    "title": "Additive Interventions Yield Robust Multi-Domain Machine Translation  Models",
    "abstract": "Additive interventions are a recently-proposed mechanism for controlling target-side attributes in neural machine translation. In contrast to tag-based approaches which manipulate the raw source sequence, interventions work by directly modulating the encoder representation of all tokens in the sequence. We examine the role of additive interventions in a large-scale multi-domain machine translation setting and compare its performance in various inference scenarios. We find that while the performance difference is small between intervention-based systems and tag-based systems when the domain label matches the test domain, intervention-based systems are robust to label error, making them an attractive choice under label uncertainty. Further, we find that the superiority of single-domain fine-tuning comes under question when training data size is scaled, contradicting previous findings. ",
    "url": "https://arxiv.org/abs/2210.12727",
    "authors": [
      "Elijah Rippeth",
      "Matt Post"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12733",
    "title": "Self-supervised Amodal Video Object Segmentation",
    "abstract": "Amodal perception requires inferring the full shape of an object that is partially occluded. This task is particularly challenging on two levels: (1) it requires more information than what is contained in the instant retina or imaging sensor, (2) it is difficult to obtain enough well-annotated amodal labels for supervision. To this end, this paper develops a new framework of Self-supervised amodal Video object segmentation (SaVos). Our method efficiently leverages the visual information of video temporal sequences to infer the amodal mask of objects. The key intuition is that the occluded part of an object can be explained away if that part is visible in other frames, possibly deformed as long as the deformation can be reasonably learned. Accordingly, we derive a novel self-supervised learning paradigm that efficiently utilizes the visible object parts as the supervision to guide the training on videos. In addition to learning type prior to complete masks for known types, SaVos also learns the spatiotemporal prior, which is also useful for the amodal task and could generalize to unseen types. The proposed framework achieves the state-of-the-art performance on the synthetic amodal segmentation benchmark FISHBOWL and the real world benchmark KINS-Video-Car. Further, it lends itself well to being transferred to novel distributions using test-time adaptation, outperforming existing models even after the transfer to a new distribution. ",
    "url": "https://arxiv.org/abs/2210.12733",
    "authors": [
      "Jian Yao",
      "Yuxin Hong",
      "Chiyu Wang",
      "Tianjun Xiao",
      "Tong He",
      "Francesco Locatello",
      "David Wipf",
      "Yanwei Fu",
      "Zheng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12737",
    "title": "Granger Causality for Predictability in Dynamic Mode Decomposition",
    "abstract": "The dynamic mode decomposition (DMD) technique extracts the dominant modes characterizing the innate dynamical behavior of the system within the measurement data. For appropriate identification of dominant modes from the measurement data, the DMD algorithm necessitates ensuring the quality of the input measurement data sequences. On that account, for validating the usability of the dataset for the DMD algorithm, the paper proposed two conditions: Persistence of excitation (PE) and the Granger Causality Test (GCT). The virtual data sequences are designed with the hankel matrix representation such that the dimensions of the subspace spanning the essential system modes are increased with the addition of new state variables. The PE condition provides the lower bound for the trajectory length, and the GCT provides the order of the model. Satisfying the PE condition enables estimating an approximate linear model, but the predictability with the identified model is only assured with the temporal causation among data searched with GCT. The proposed methodology is validated with the application for coherency identification (CI) in a multi-machine power system (MMPS), an essential phenomenon in transient stability analysis. The significance of PE condition and GCT is demonstrated through various case studies implemented on 22 bus six generator system. ",
    "url": "https://arxiv.org/abs/2210.12737",
    "authors": [
      "G. Revati",
      "Syed Shadab",
      "K. Sonam",
      "S. R. Wagh",
      "N. M. Singh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.12739",
    "title": "Functional Indirection Neural Estimator for Better Out-of-distribution  Generalization",
    "abstract": "The capacity to achieve out-of-distribution (OOD) generalization is a hallmark of human intelligence and yet remains out of reach for machines. This remarkable capability has been attributed to our abilities to make conceptual abstraction and analogy, and to a mechanism known as indirection, which binds two representations and uses one representation to refer to the other. Inspired by these mechanisms, we hypothesize that OOD generalization may be achieved by performing analogy-making and indirection in the functional space instead of the data space as in current methods. To realize this, we design FINE (Functional Indirection Neural Estimator), a neural framework that learns to compose functions that map data input to output on-the-fly. FINE consists of a backbone network and a trainable semantic memory of basis weight matrices. Upon seeing a new input-output data pair, FINE dynamically constructs the backbone weights by mixing the basis weights. The mixing coefficients are indirectly computed through querying a separate corresponding semantic memory using the data pair. We demonstrate empirically that FINE can strongly improve out-of-distribution generalization on IQ tasks that involve geometric transformations. In particular, we train FINE and competing models on IQ tasks using images from the MNIST, Omniglot and CIFAR100 datasets and test on tasks with unseen image classes from one or different datasets and unseen transformation rules. FINE not only achieves the best performance on all tasks but also is able to adapt to small-scale data scenarios. ",
    "url": "https://arxiv.org/abs/2210.12739",
    "authors": [
      "Kha Pham",
      "Hung Le",
      "Man Ngo",
      "Truyen Tran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12752",
    "title": "UIA-ViT: Unsupervised Inconsistency-Aware Method based on Vision  Transformer for Face Forgery Detection",
    "abstract": "Intra-frame inconsistency has been proved to be effective for the generalization of face forgery detection. However, learning to focus on these inconsistency requires extra pixel-level forged location annotations. Acquiring such annotations is non-trivial. Some existing methods generate large-scale synthesized data with location annotations, which is only composed of real images and cannot capture the properties of forgery regions. Others generate forgery location labels by subtracting paired real and fake images, yet such paired data is difficult to collected and the generated label is usually discontinuous. To overcome these limitations, we propose a novel Unsupervised Inconsistency-Aware method based on Vision Transformer, called UIA-ViT, which only makes use of video-level labels and can learn inconsistency-aware feature without pixel-level annotations. Due to the self-attention mechanism, the attention map among patch embeddings naturally represents the consistency relation, making the vision Transformer suitable for the consistency representation learning. Based on vision Transformer, we propose two key components: Unsupervised Patch Consistency Learning (UPCL) and Progressive Consistency Weighted Assemble (PCWA). UPCL is designed for learning the consistency-related representation with progressive optimized pseudo annotations. PCWA enhances the final classification embedding with previous patch embeddings optimized by UPCL to further improve the detection performance. Extensive experiments demonstrate the effectiveness of the proposed method. ",
    "url": "https://arxiv.org/abs/2210.12752",
    "authors": [
      "Wanyi Zhuang",
      "Qi Chu",
      "Zhentao Tan",
      "Qiankun Liu",
      "Haojie Yuan",
      "Changtao Miao",
      "Zixiang Luo",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12758",
    "title": "Beta R-CNN: Looking into Pedestrian Detection from Another Perspective",
    "abstract": "Recently significant progress has been made in pedestrian detection, but it remains challenging to achieve high performance in occluded and crowded scenes. It could be attributed mostly to the widely used representation of pedestrians, i.e., 2D axis-aligned bounding box, which just describes the approximate location and size of the object. Bounding box models the object as a uniform distribution within the boundary, making pedestrians indistinguishable in occluded and crowded scenes due to much noise. To eliminate the problem, we propose a novel representation based on 2D beta distribution, named Beta Representation. It pictures a pedestrian by explicitly constructing the relationship between full-body and visible boxes, and emphasizes the center of visual mass by assigning different probability values to pixels. As a result, Beta Representation is much better for distinguishing highly-overlapped instances in crowded scenes with a new NMS strategy named BetaNMS. What's more, to fully exploit Beta Representation, a novel pipeline Beta R-CNN equipped with BetaHead and BetaMask is proposed, leading to high detection performance in occluded and crowded scenes. ",
    "url": "https://arxiv.org/abs/2210.12758",
    "authors": [
      "Zixuan Xu",
      "Banghuai Li",
      "Ye Yuan",
      "Anhong Dang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12785",
    "title": "An Improved RaftStereo Trained with A Mixed Dataset for the Robust  Vision Challenge 2022",
    "abstract": "Stereo-matching is a fundamental problem in computer vision. Despite recent progress by deep learning, improving the robustness is ineluctable when deploying stereo-matching models to real-world applications. Different from the common practices, i.e., developing an elaborate model to achieve robustness, we argue that collecting multiple available datasets for training is a cheaper way to increase generalization ability. Specifically, this report presents an improved RaftStereo trained with a mixed dataset of seven public datasets for the robust vision challenge (denoted as iRaftStereo_RVC). When evaluated on the training sets of Middlebury, KITTI-2015, and ETH3D, the model outperforms its counterparts trained with only one dataset, such as the popular Sceneflow. After fine-tuning the pre-trained model on the three datasets of the challenge, it ranks at 2nd place on the stereo leaderboard, demonstrating the benefits of mixed dataset pre-training. ",
    "url": "https://arxiv.org/abs/2210.12785",
    "authors": [
      "Hualie Jiang",
      "Rui Xu",
      "Wenjie Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12789",
    "title": "Clustering-based Tile Embedding (CTE): A General Representation for  Level Design with Skewed Tile Distributions",
    "abstract": "There has been significant research interest in Procedural Level Generation via Machine Learning (PLGML), applying ML techniques to automated level generation. One recent trend is in the direction of learning representations for level design via embeddings, such as tile embeddings. Tile Embeddings are continuous vector representations of game levels unifying their visual, contextual and behavioural information. However, the original tile embedding struggled to generate levels with skewed tile distributions. For instance, Super Mario Bros. (SMB) wherein a majority of tiles represent the background. To remedy this, we present a modified tile embedding representation referred to as Clustering-based Tile Embedding (CTE). Further, we employ clustering to discretize the continuous CTE representation and present a novel two-step level generation to leverage both these representations. We evaluate the performance of our approach in generating levels for seen and unseen games with skewed tile distributions and outperform the original tile embeddings. ",
    "url": "https://arxiv.org/abs/2210.12789",
    "authors": [
      "Mrunal Jadhav",
      "Matthew Guzdial"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12795",
    "title": "Realistic Data Augmentation Framework for Enhancing Tabular Reasoning",
    "abstract": "Existing approaches to constructing training data for Natural Language Inference (NLI) tasks, such as for semi-structured table reasoning, are either via crowdsourcing or fully automatic methods. However, the former is expensive and time-consuming and thus limits scale, and the latter often produces naive examples that may lack complex reasoning. This paper develops a realistic semi-automated framework for data augmentation for tabular inference. Instead of manually generating a hypothesis for each table, our methodology generates hypothesis templates transferable to similar tables. In addition, our framework entails the creation of rational counterfactual tables based on human written logical constraints and premise paraphrasing. For our case study, we use the InfoTabs, which is an entity-centric tabular inference dataset. We observed that our framework could generate human-like tabular inference examples, which could benefit training data augmentation, especially in the scenario with limited supervision. ",
    "url": "https://arxiv.org/abs/2210.12795",
    "authors": [
      "Dibyakanti Kumar",
      "Vivek Gupta",
      "Soumya Sharma",
      "Shuo Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12808",
    "title": "Flow-Level Packet Loss Detection via Sketch Decomposition and Matrix  Optimization",
    "abstract": "For cloud service providers, fine-grained packet loss detection across data centers is crucial in improving their service level and increasing business income. However, the inability to obtain sufficient measurements makes it difficult owing to the fundamental limit that the wide-area network links responsible for communication are not under their management. Moreover, millisecond-level delay jitter and clock synchronization errors in the WAN disable many tools that perform well in data center networks on this issue. Therefore, there is an urgent need to develop a new tool or method. In this work, we propose SketchDecomp, a novel loss detection method, from a mathematical perspective that has never been considered before. Its key is to decompose sketches upstream and downstream into several sub-sketches and builds a low-rank matrix optimization model to solve them. Extensive experiments on the test bed demonstrate its superiority. ",
    "url": "https://arxiv.org/abs/2210.12808",
    "authors": [
      "Zhenyu Ming",
      "Wei Zhang",
      "Yanwei Xu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.12810",
    "title": "Code4Struct: Code Generation for Few-Shot Structured Prediction from  Natural Language",
    "abstract": "Large Language Model (LLM) trained on the mixture of text and code has demonstrated impressive capability in translating natural language (NL) into structured code. In this work, we propose Code4Struct to leverage such text-to-structure translation capability to tackle structured prediction tasks in NLP. For example, Event Argument Extraction (EAE) aims to convert text into event-argument structures that can be represented as a class object using code. This alignment between structures and code enables us to take advantage of Programming Language (PL) features such as inheritance and type annotation to introduce external knowledge or add constraints with ease. We exploit the analogy between PL and NLP problems, and, as a case study, we use Code4Struct to tackle the EAE task using code generation. We ask a LLM to generate code to instantiate an event class with predicted arguments given a NL sentence. Despite only using 50 training instances for each event type, Code4Struct is comparable to fully-supervised models trained on 4,202 event instances and, when given the same 50-shot data, outperforms current state-of-the-art (SOTA) by 20.8% absolute F1. When prompted with hierarchical event types implemented using inheritance, Code4Struct can predict arguments for low-resource event types using 10-shot training instances from its sibling event type and outperforms zero-shot baseline by 12% absolute F1. ",
    "url": "https://arxiv.org/abs/2210.12810",
    "authors": [
      "Xingyao Wang",
      "Sha Li",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12846",
    "title": "EUREKA: EUphemism Recognition Enhanced through Knn-based methods and  Augmentation",
    "abstract": "We introduce EUREKA, an ensemble-based approach for performing automatic euphemism detection. We (1) identify and correct potentially mislabelled rows in the dataset, (2) curate an expanded corpus called EuphAug, (3) leverage model representations of Potentially Euphemistic Terms (PETs), and (4) explore using representations of semantically close sentences to aid in classification. Using our augmented dataset and kNN-based methods, EUREKA was able to achieve state-of-the-art results on the public leaderboard of the Euphemism Detection Shared Task, ranking first with a macro F1 score of 0.881. Our code is available at https://github.com/sedrickkeh/EUREKA. ",
    "url": "https://arxiv.org/abs/2210.12846",
    "authors": [
      "Sedrick Scott Keh",
      "Rohit K. Bharadwaj",
      "Emmy Liu",
      "Simone Tedeschi",
      "Varun Gangal",
      "Roberto Navigli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12852",
    "title": "1st Place Solution of The Robust Vision Challenge (RVC) 2022 Semantic  Segmentation Track",
    "abstract": "This report describes the winner solution to the semantic segmentation task of the Robust Vision Challenge on ECCV 2022. Our method adopts the FAN-B-Hybrid model as the encoder and uses Segformer as the segmentation framework. The model is trained on a combined dataset containing images from 9 datasets (ADE20K, Cityscapes, Mapillary Vistas, ScanNet, VIPER, Wilddash2, IDD, BDD, and COCO) with a simple dataset balancing strategy. All the original labels are projected to a 256-class unified label space, and the model is trained with naive cross-entropy loss. Without significant hyperparameters tuning or any specific loss weighting, our solution ranks 1st on all the required semantic segmentation benchmarks from multiple domains (ADE20K, Cityscapes, Mapillary Vistas, ScanNet, VIPER, and Wilddash2). Our method could be served as a strong baseline for the multi-domain segmentation task and our codebase could be helpful to future work. Code will be available at https://github.com/lambert-x/RVC_Segmentation. ",
    "url": "https://arxiv.org/abs/2210.12852",
    "authors": [
      "Junfei Xiao",
      "Zhichao Xu",
      "Shiyi Lan",
      "Zhiding Yu",
      "Alan Yuille",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12870",
    "title": "Imbalanced Class Data Performance Evaluation and Improvement using Novel  Generative Adversarial Network-based Approach: SSG and GBO",
    "abstract": "Class imbalance in a dataset is one of the major challenges that can significantly impact the performance of machine learning models resulting in biased predictions. Numerous techniques have been proposed to address class imbalanced problems, including, but not limited to, Oversampling, Undersampling, and cost-sensitive approaches. Due to its ability to generate synthetic data, oversampling techniques such as the Synthetic Minority Oversampling Technique (SMOTE) is among the most widely used methodology by researchers. However, one of SMOTE's potential disadvantages is that newly created minor samples may overlap with major samples. As an effect, the probability of ML models' biased performance towards major classes increases. Recently, generative adversarial network (GAN) has garnered much attention due to its ability to create almost real samples. However, GAN is hard to train even though it has much potential. This study proposes two novel techniques: GAN-based Oversampling (GBO) and Support Vector Machine-SMOTE-GAN (SSG) to overcome the limitations of the existing oversampling approaches. The preliminary computational result shows that SSG and GBO performed better on the expanded imbalanced eight benchmark datasets than the original SMOTE. The study also revealed that the minor sample generated by SSG demonstrates Gaussian distributions, which is often difficult to achieve using original SMOTE. ",
    "url": "https://arxiv.org/abs/2210.12870",
    "authors": [
      "Md Manjurul Ahsan",
      "Md Shahin Ali",
      "Zahed Siddique"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12871",
    "title": "Tighter Abstract Queries in Neural Network Verification",
    "abstract": "Neural networks have become critical components of reactive systems in various domains within computer science. Despite their excellent performance, using neural networks entails numerous risks that stem from our lack of ability to understand and reason about their behavior. Due to these risks, various formal methods have been proposed for verifying neural networks; but unfortunately, these typically struggle with scalability barriers. Recent attempts have demonstrated that abstraction-refinement approaches could play a significant role in mitigating these limitations; but these approaches can often produce networks that are so abstract, that they become unsuitable for verification. To deal with this issue, we present CEGARETTE, a novel verification mechanism where both the system and the property are abstracted and refined simultaneously. We observe that this approach allows us to produce abstract networks which are both small and sufficiently accurate, allowing for quick verification times while avoiding a large number of refinement steps. For evaluation purposes, we implemented CEGARETTE as an extension to the recently proposed CEGAR-NN framework. Our results are very promising, and demonstrate a significant improvement in performance over multiple benchmarks. ",
    "url": "https://arxiv.org/abs/2210.12871",
    "authors": [
      "Elazar Cohen",
      "Yizhak Yisrael Elboher",
      "Clark Barrett",
      "Guy Katz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.12872",
    "title": "Socio-cognitive Optimization of Time-delay Control Problems using  Evolutionary Metaheuristics",
    "abstract": "Metaheuristics are universal optimization algorithms which should be used for solving difficult problems, unsolvable by classic approaches. In this paper we aim at constructing novel socio-cognitive metaheuristic based on castes, and apply several versions of this algorithm to optimization of time-delay system model. Besides giving the background and the details of the proposed algorithms we apply them to optimization of selected variants of the problem and discuss the results. ",
    "url": "https://arxiv.org/abs/2210.12872",
    "authors": [
      "Piotr Kipinski",
      "Hubert Guzowski",
      "Aleksandra Urbanczyk",
      "Maciej Smolka",
      "Marek Kisiel-Dorohinicki",
      "Aleksander Byrski",
      "Zuzana Kominkova Oplatkova",
      "Roman Senkerik",
      "Libor Pekar",
      "Radek Matusu",
      "Frantisek Gazdos"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.12873",
    "title": "FLIP: A Provable Defense Framework for Backdoor Mitigation in Federated  Learning",
    "abstract": "Federated Learning (FL) is a distributed learning paradigm that enables different parties to train a model together for high quality and strong privacy protection. In this scenario, individual participants may get compromised and perform backdoor attacks by poisoning the data (or gradients). Existing work on robust aggregation and certified FL robustness does not study how hardening benign clients can affect the global model (and the malicious clients). In this work, we theoretically analyze the connection among cross-entropy loss, attack success rate, and clean accuracy in this setting. Moreover, we propose a trigger reverse engineering based defense and show that our method can achieve robustness improvement with guarantee (i.e., reducing the attack success rate) without affecting benign accuracy. We conduct comprehensive experiments across different datasets and attack settings. Our results on eight competing SOTA defense methods show the empirical superiority of our method on both single-shot and continuous FL backdoor attacks. ",
    "url": "https://arxiv.org/abs/2210.12873",
    "authors": [
      "Kaiyuan Zhang",
      "Guanhong Tao",
      "Qiuling Xu",
      "Siyuan Cheng",
      "Shengwei An",
      "Yingqi Liu",
      "Shiwei Feng",
      "Guangyu Shen",
      "Pin-Yu Chen",
      "Shiqing Ma",
      "Xiangyu Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12877",
    "title": "A Secure Design Pattern Approach Toward Tackling Lateral-Injection  Attacks",
    "abstract": "Software weaknesses that create attack surfaces for adversarial exploits, such as lateral SQL injection (LSQLi) attacks, are usually introduced during the design phase of software development. Security design patterns are sometimes applied to tackle these weaknesses. However, due to the stealthy nature of lateral-based attacks, employing traditional security patterns to address these threats is insufficient. Hence, we present SEAL, a secure design that extrapolates architectural, design, and implementation abstraction levels to delegate security strategies toward tackling LSQLi attacks. We evaluated SEAL using case study software, where we assumed the role of an adversary and injected several attack vectors tasked with compromising the confidentiality and integrity of its database. Our evaluation of SEAL demonstrated its capacity to address LSQLi attacks. ",
    "url": "https://arxiv.org/abs/2210.12877",
    "authors": [
      "Chidera Biringa",
      "G\u00f6khan Kul"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.12887",
    "title": "Retrieval Augmentation for Commonsense Reasoning: A Unified Approach",
    "abstract": "A common thread of retrieval-augmented methods in the existing literature focuses on retrieving encyclopedic knowledge, such as Wikipedia, which facilitates well-defined entity and relation spaces that can be modeled. However, applying such methods to commonsense reasoning tasks faces two unique challenges, i.e., the lack of a general large-scale corpus for retrieval and a corresponding effective commonsense retriever. In this paper, we systematically investigate how to leverage commonsense knowledge retrieval to improve commonsense reasoning tasks. We proposed a unified framework of retrieval-augmented commonsense reasoning (called RACo), including a newly constructed commonsense corpus with over 20 million documents and novel strategies for training a commonsense retriever. We conducted experiments on four different commonsense reasoning tasks. Extensive evaluation results showed that our proposed RACo can significantly outperform other knowledge-enhanced method counterparts, achieving new SoTA performance on the CommonGen and CREAK leaderboards. ",
    "url": "https://arxiv.org/abs/2210.12887",
    "authors": [
      "Wenhao Yu",
      "Chenguang Zhu",
      "Zhihan Zhang",
      "Shuohang Wang",
      "Zhuosheng Zhang",
      "Yuwei Fang",
      "Meng Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.12899",
    "title": "SpikeSim: An end-to-end Compute-in-Memory Hardware Evaluation Tool for  Benchmarking Spiking Neural Networks",
    "abstract": "SNNs are an active research domain towards energy efficient machine intelligence. Compared to conventional ANNs, SNNs use temporal spike data and bio-plausible neuronal activation functions such as Leaky-Integrate Fire/Integrate Fire (LIF/IF) for data processing. However, SNNs incur significant dot-product operations causing high memory and computation overhead in standard von-Neumann computing platforms. Today, In-Memory Computing (IMC) architectures have been proposed to alleviate the \"memory-wall bottleneck\" prevalent in von-Neumann architectures. Although recent works have proposed IMC-based SNN hardware accelerators, the following have been overlooked- 1) the adverse effects of crossbar non-ideality on SNN performance due to repeated analog dot-product operations over multiple time-steps, 2) hardware overheads of essential SNN-specific components such as the LIF/IF and data communication modules. To this end, we propose SpikeSim, a tool that can perform realistic performance, energy, latency and area evaluation of IMC-mapped SNNs. SpikeSim consists of a practical monolithic IMC architecture called SpikeFlow for mapping SNNs. Additionally, the non-ideality computation engine (NICE) and energy-latency-area (ELA) engine performs hardware-realistic evaluation of SpikeFlow-mapped SNNs. Based on 65nm CMOS implementation and experiments on CIFAR10, CIFAR100 and TinyImagenet datasets, we find that the LIF/IF neuronal module has significant area contribution (>11% of the total hardware area). We propose SNN topological modifications leading to 1.24x and 10x reduction in the neuronal module's area and the overall energy-delay-product value, respectively. Furthermore, in this work, we perform a holistic comparison between IMC implemented ANN and SNNs and conclude that lower number of time-steps are the key to achieve higher throughput and energy-efficiency for SNNs compared to 4-bit ANNs. ",
    "url": "https://arxiv.org/abs/2210.12899",
    "authors": [
      "Abhishek Moitra",
      "Abhiroop Bhattacharjee",
      "Runcong Kuang",
      "Gokul Krishnan",
      "Yu Cao",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12903",
    "title": "Gallery Filter Network for Person Search",
    "abstract": "In person search, we aim to localize a query person from one scene in other gallery scenes. The cost of this search operation is dependent on the number of gallery scenes, making it beneficial to reduce the pool of likely scenes. We describe and demonstrate the Gallery Filter Network (GFN), a novel module which can efficiently discard gallery scenes from the search process, and benefit scoring for persons detected in remaining scenes. We show that the GFN is robust under a range of different conditions by testing on different retrieval sets, including cross-camera, occluded, and low-resolution scenarios. In addition, we develop the base SeqNeXt person search model, which improves and simplifies the original SeqNet model. We show that the SeqNeXt+GFN combination yields significant performance gains over other state-of-the-art methods on the standard PRW and CUHK-SYSU person search datasets. To aid experimentation for this and other models, we provide standardized tooling for the data processing and evaluation pipeline typically used for person search research. ",
    "url": "https://arxiv.org/abs/2210.12903",
    "authors": [
      "Lucas Jaffe",
      "Avideh Zakhor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12905",
    "title": "Visualizing the Obvious: A Concreteness-based Ensemble Model for Noun  Property Prediction",
    "abstract": "Neural language models encode rich knowledge about entities and their relationships which can be extracted from their representations using probing. Common properties of nouns (e.g., red strawberries, small ant) are, however, more challenging to extract compared to other types of knowledge because they are rarely explicitly stated in texts. We hypothesize this to mainly be the case for perceptual properties which are obvious to the participants in the communication. We propose to extract these properties from images and use them in an ensemble model, in order to complement the information that is extracted from language models. We consider perceptual properties to be more concrete than abstract properties (e.g., interesting, flawless). We propose to use the adjectives' concreteness score as a lever to calibrate the contribution of each source (text vs. images). We evaluate our ensemble model in a ranking task where the actual properties of a noun need to be ranked higher than other non-relevant properties. Our results show that the proposed combination of text and images greatly improves noun property prediction compared to powerful text-based language models. ",
    "url": "https://arxiv.org/abs/2210.12905",
    "authors": [
      "Yue Yang",
      "Artemis Panagopoulou",
      "Marianna Apidianaki",
      "Mark Yatskar",
      "Chris Callison-Burch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12906",
    "title": "Iterative Detection and Decoding for Cell-Free Massive Multiuser MIMO  with LDPC Codes",
    "abstract": "This paper proposes an iterative detection and decoding (IDD) scheme for a cell free massive multiple input multiple output (CF-mMIMO) system. Users send coded data to the access points (APs), which is jointly detected at central processing unit (CPU). The symbols are exchanged iteratively in the form of log likelihood ratios (LLRs) between the detector and the low-density parity check codes (LPDC) decoder, increasing the coded system's performance. We propose a list-based multi-feedback diversity with successive interference cancellation (MF-SIC) to improve the performance of the CF-mMIMO. Furthermore, the proposed detector is compared with the parallel interference cancellation (PIC) and MF-PIC schemes. Finally, the bit error rate (BER) performance of CF-mMIMO is compared with the co-located mMIMO (Col-mMIMO). ",
    "url": "https://arxiv.org/abs/2210.12906",
    "authors": [
      "T. Ssettumba",
      "R. Di Renna",
      "L. Landau",
      "R. C. de Lamare"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.12914",
    "title": "A Novel Adaptive Causal Sampling Method for Physics-Informed Neural  Networks",
    "abstract": "Physics-Informed Neural Networks (PINNs) have become a kind of attractive machine learning method for obtaining solutions of partial differential equations (PDEs). Training PINNs can be seen as a semi-supervised learning task, in which only exact values of initial and boundary points can be obtained in solving forward problems, and in the whole spatio-temporal domain collocation points are sampled without exact labels, which brings training difficulties. Thus the selection of collocation points and sampling methods are quite crucial in training PINNs. Existing sampling methods include fixed and dynamic types, and in the more popular latter one, sampling is usually controlled by PDE residual loss. We point out that it is not sufficient to only consider the residual loss in adaptive sampling and sampling should obey temporal causality. We further introduce temporal causality into adaptive sampling and propose a novel adaptive causal sampling method to improve the performance and efficiency of PINNs. Numerical experiments of several PDEs with high-order derivatives and strong nonlinearity, including Cahn Hilliard and KdV equations, show that the proposed sampling method can improve the performance of PINNs with few collocation points. We demonstrate that by utilizing such a relatively simple sampling method, prediction performance can be improved up to two orders of magnitude compared with state-of-the-art results with almost no extra computation cost, especially when points are limited. ",
    "url": "https://arxiv.org/abs/2210.12914",
    "authors": [
      "Jia Guo",
      "Haifeng Wang",
      "Chenping Hou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.12915",
    "title": "Robust Ellipse Fitting Based on Maximum Correntropy Criterion With  Variable Center",
    "abstract": "The presence of outliers can significantly degrade the performance of ellipse fitting methods. We develop an ellipse fitting method that is robust to outliers based on the maximum correntropy criterion with variable center (MCC-VC), where a Laplacian kernel is used. For single ellipse fitting, we formulate a non-convex optimization problem to estimate the kernel bandwidth and center and divide it into two subproblems, each estimating one parameter. We design sufficiently accurate convex approximation to each subproblem such that computationally efficient closed-form solutions are obtained. The two subproblems are solved in an alternate manner until convergence is reached. We also investigate coupled ellipses fitting. While there exist multiple ellipses fitting methods that can be used for coupled ellipses fitting, we develop a couple ellipses fitting method by exploiting the special structure. Having unknown association between data points and ellipses, we introduce an association vector for each data point and formulate a non-convex mixed-integer optimization problem to estimate the data associations, which is approximately solved by relaxing it into a second-order cone program. Using the estimated data associations, we extend the proposed method to achieve the final coupled ellipses fitting. The proposed method is shown to have significantly better performance over the existing methods in both simulated data and real images. ",
    "url": "https://arxiv.org/abs/2210.12915",
    "authors": [
      "Wei Wang",
      "Gang Wang",
      "Chenlong Hu",
      "K. C. Ho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12916",
    "title": "Explaining epsilon in differential privacy through the lens of  information theory",
    "abstract": "The study of leakage measures for privacy has been a subject of intensive research and is an important aspect of understanding how privacy leaks occur in computer programs. Differential privacy has been a focal point in the privacy community for some years and yet its leakage characteristics are not completely understood. In this paper we bring together two areas of research -- information theory and the g-leakage framework of quantitative information flow (QIF) -- to give an operational interpretation for the epsilon parameter of differential privacy. We find that epsilon emerges as a capacity measure in both frameworks; via (log)-lift, a popular measure in information theory; and via max-case g-leakage, which describes the leakage of any system to Bayesian adversaries modelled using ``worst-case'' assumptions under the QIF framework. Our characterisation resolves an important question of interpretability of epsilon and consolidates a number of disparate results covering the literature of both information theory and quantitative information flow. ",
    "url": "https://arxiv.org/abs/2210.12916",
    "authors": [
      "Natasha Fernandes",
      "Annabelle McIver",
      "Parastoo Sadeghi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.12918",
    "title": "Unsupervised Object Representation Learning using Translation and  Rotation Group Equivariant VAE",
    "abstract": "In many imaging modalities, objects of interest can occur in a variety of locations and poses (i.e. are subject to translations and rotations in 2d or 3d), but the location and pose of an object does not change its semantics (i.e. the object's essence). That is, the specific location and rotation of an airplane in satellite imagery, or the 3d rotation of a chair in a natural image, or the rotation of a particle in a cryo-electron micrograph, do not change the intrinsic nature of those objects. Here, we consider the problem of learning semantic representations of objects that are invariant to pose and location in a fully unsupervised manner. We address shortcomings in previous approaches to this problem by introducing TARGET-VAE, a translation and rotation group-equivariant variational autoencoder framework. TARGET-VAE combines three core innovations: 1) a rotation and translation group-equivariant encoder architecture, 2) a structurally disentangled distribution over latent rotation, translation, and a rotation-translation-invariant semantic object representation, which are jointly inferred by the approximate inference network, and 3) a spatially equivariant generator network. In comprehensive experiments, we show that TARGET-VAE learns disentangled representations without supervision that significantly improve upon, and avoid the pathologies of, previous methods. When trained on images highly corrupted by rotation and translation, the semantic representations learned by TARGET-VAE are similar to those learned on consistently posed objects, dramatically improving clustering in the semantic latent space. Furthermore, TARGET-VAE is able to perform remarkably accurate unsupervised pose and location inference. We expect methods like TARGET-VAE will underpin future approaches for unsupervised object generation, pose prediction, and object detection. ",
    "url": "https://arxiv.org/abs/2210.12918",
    "authors": [
      "Alireza Nasiri",
      "Tristan Bepler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12924",
    "title": "OLLA: Decreasing the Memory Usage of Neural Networks by Optimizing the  Lifetime and Location of Arrays",
    "abstract": "The size of deep neural networks has grown exponentially in recent years. Unfortunately, hardware devices have not kept pace with the rapidly increasing memory requirements. To cope with this, researchers have turned to techniques such as spilling and recomputation, which increase training time, or reduced precision and model pruning, which can affect model accuracy. We present OLLA, an algorithm that optimizes the lifetime and memory location of the tensors used to train neural networks. Our method reduces the memory usage of existing neural networks, without needing any modification to the models or their training procedures. We formulate the problem as a joint integer linear program (ILP). We present several techniques to simplify the encoding of the problem, and enable our approach to scale to the size of state-of-the-art neural networks using an off-the-shelf ILP solver. We experimentally demonstrate that OLLA only takes minutes if not seconds to allow the training of neural networks using one-third less memory on average. ",
    "url": "https://arxiv.org/abs/2210.12924",
    "authors": [
      "Benoit Steiner",
      "Mostafa Elhoushi",
      "Jacob Kahn",
      "James Hegarty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12925",
    "title": "TIARA: Multi-grained Retrieval for Robust Question Answering over Large  Knowledge Bases",
    "abstract": "Pre-trained language models (PLMs) have shown their effectiveness in multiple scenarios. However, KBQA remains challenging, especially regarding coverage and generalization settings. This is due to two main factors: i) understanding the semantics of both questions and relevant knowledge from the KB; ii) generating executable logical forms with both semantic and syntactic correctness. In this paper, we present a new KBQA model, TIARA, which addresses those issues by applying multi-grained retrieval to help the PLM focus on the most relevant KB contexts, viz., entities, exemplary logical forms, and schema items. Moreover, constrained decoding is used to control the output space and reduce generation errors. Experiments over important benchmarks demonstrate the effectiveness of our approach. TIARA outperforms previous SOTA, including those using PLMs or oracle entity annotations, by at least 4.1 and 1.1 F1 points on GrailQA and WebQuestionsSP, respectively. ",
    "url": "https://arxiv.org/abs/2210.12925",
    "authors": [
      "Yiheng Shu",
      "Zhiwei Yu",
      "Yuhan Li",
      "B\u00f6rje F. Karlsson",
      "Tingting Ma",
      "Yuzhong Qu",
      "Chin-Yew Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.12926",
    "title": "Exploring Euphemism Detection in Few-Shot and Zero-Shot Settings",
    "abstract": "This work builds upon the Euphemism Detection Shared Task proposed in the EMNLP 2022 FigLang Workshop, and extends it to few-shot and zero-shot settings. We demonstrate a few-shot and zero-shot formulation using the dataset from the shared task, and we conduct experiments in these settings using RoBERTa and GPT-3. Our results show that language models are able to classify euphemistic terms relatively well even on new terms unseen during training, indicating that it is able to capture higher-level concepts related to euphemisms. ",
    "url": "https://arxiv.org/abs/2210.12926",
    "authors": [
      "Sedrick Scott Keh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.12928",
    "title": "GFlowOut: Dropout with Generative Flow Networks",
    "abstract": "Bayesian Inference offers principled tools to tackle many critical problems with modern neural networks such as poor calibration and generalization, and data inefficiency. However, scaling Bayesian inference to large architectures is challenging and requires restrictive approximations. Monte Carlo Dropout has been widely used as a relatively cheap way for approximate Inference and to estimate uncertainty with deep neural networks. Traditionally, the dropout mask is sampled independently from a fixed distribution. Recent works show that the dropout mask can be viewed as a latent variable, which can be inferred with variational inference. These methods face two important challenges: (a) the posterior distribution over masks can be highly multi-modal which can be difficult to approximate with standard variational inference and (b) it is not trivial to fully utilize sample-dependent information and correlation among dropout masks to improve posterior estimation. In this work, we propose GFlowOut to address these issues. GFlowOut leverages the recently proposed probabilistic framework of Generative Flow Networks (GFlowNets) to learn the posterior distribution over dropout masks. We empirically demonstrate that GFlowOut results in predictive distributions that generalize better to out-of-distribution data, and provide uncertainty estimates which lead to better performance in downstream tasks. ",
    "url": "https://arxiv.org/abs/2210.12928",
    "authors": [
      "Dianbo Liu",
      "Moksh Jain",
      "Bonaventure Dossou",
      "Qianli Shen",
      "Salem Lahlou",
      "Anirudh Goyal",
      "Nikolay Malkin",
      "Chris Emezue",
      "Dinghuai Zhang",
      "Nadhir Hassen",
      "Xu Ji",
      "Kenji Kawaguchi",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.12930",
    "title": "Social norms of fairness with reputation-based role assignment in the  dictator game",
    "abstract": "A vast body of experiments share the view that social norms are major factors for the emergence of fairness in a population of individuals playing the dictator game (DG). Recently, to explore which social norms are conducive to sustaining cooperation has obtained considerable concern. However, thus far few studies have investigated how social norms influence the evolution of fairness by means of indirect reciprocity. In this study, we propose an indirect reciprocal model of the DG and consider that an individual can be assigned as the dictator due to its good reputation. We investigate the `leading eight' norms and all second-order social norms by a two-timescale theoretical analysis. We show that when role assignment is based on reputation, four of the `leading eight' norms, including stern judging and simple standing, lead to a high level of fairness, which increases with the selection intensity. Our work also reveals that not only the correct treatment of making a fair split with good recipients but also distinguishing unjustified unfair split from justified unfair split matters in elevating the level of fairness. ",
    "url": "https://arxiv.org/abs/2210.12930",
    "authors": [
      "Qing Li",
      "Songtao Li",
      "Yanling Zhang",
      "Xiaojie Chen",
      "Shuo Yang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ]
  },
  {
    "id": "arXiv:2210.12936",
    "title": "Selecting and Composing Learning Rate Policies for Deep Neural Networks",
    "abstract": "The choice of learning rate (LR) functions and policies has evolved from a simple fixed LR to the decaying LR and the cyclic LR, aiming to improve the accuracy and reduce the training time of Deep Neural Networks (DNNs). This paper presents a systematic approach to selecting and composing an LR policy for effective DNN training to meet desired target accuracy and reduce training time within the pre-defined training iterations. It makes three original contributions. First, we develop an LR tuning mechanism for auto-verification of a given LR policy with respect to the desired accuracy goal under the pre-defined training time constraint. Second, we develop an LR policy recommendation system (LRBench) to select and compose good LR policies from the same and/or different LR functions through dynamic tuning, and avoid bad choices, for a given learning task, DNN model and dataset. Third, we extend LRBench by supporting different DNN optimizers and show the significant mutual impact of different LR policies and different optimizers. Evaluated using popular benchmark datasets and different DNN models (LeNet, CNN3, ResNet), we show that our approach can effectively deliver high DNN test accuracy, outperform the existing recommended default LR policies, and reduce the DNN training time by 1.6$\\sim$6.7$\\times$ to meet a targeted model accuracy. ",
    "url": "https://arxiv.org/abs/2210.12936",
    "authors": [
      "Yanzhao Wu",
      "Ling Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12940",
    "title": "Heterogeneous Information Crossing on Graphs for Session-based  Recommender Systems",
    "abstract": "Recommender systems are fundamental information filtering techniques to recommend content or items that meet users' personalities and potential needs. As a crucial solution to address the difficulty of user identification and unavailability of historical information, session-based recommender systems provide recommendation services that only rely on users' behaviors in the current session. However, most existing studies are not well-designed for modeling heterogeneous user behaviors and capturing the relationships between them in practical scenarios. To fill this gap, in this paper, we propose a novel graph-based method, namely Heterogeneous Information Crossing on Graphs (HICG). HICG utilizes multiple types of user behaviors in the sessions to construct heterogeneous graphs, and captures users' current interests with their long-term preferences by effectively crossing the heterogeneous information on the graphs. In addition, we also propose an enhanced version, named HICG-CL, which incorporates contrastive learning (CL) technique to enhance item representation ability. By utilizing the item co-occurrence relationships across different sessions, HICG-CL improves the recommendation performance of HICG. We conduct extensive experiments on three real-world recommendation datasets, and the results verify that (i) HICG achieves the state-of-the-art performance by utilizing multiple types of behaviors on the heterogeneous graph. (ii) HICG-CL further significantly improves the recommendation performance of HICG by the proposed contrastive learning module. ",
    "url": "https://arxiv.org/abs/2210.12940",
    "authors": [
      "Xiaolin Zheng",
      "Rui Wu",
      "Zhongxuan Han",
      "Chaochao Chen",
      "Linxun Chen",
      "Bing Han"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12941",
    "title": "Are we really making much progress in unsupervised graph outlier  detection? Revisiting the problem with new insight and superior method",
    "abstract": "A large number of studies on Graph Outlier Detection (GOD) have emerged in recent years due to its wide applications, in which Unsupervised Node Outlier Detection (UNOD) on attributed networks is an important area. UNOD focuses on detecting two kinds of typical outliers in graphs: the structural outlier and the contextual outlier. Most existing works conduct the experiments based on the datasets with injected outliers. However, we find that the most widely-used outlier injection approach has a serious data leakage issue. By only utilizing such data leakage, a simple approach can achieve the state-of-the-art performance in detecting outliers. In addition, we observe that most existing algorithms have performance drops with varied injection settings. The other major issue is on balanced detection performance between the two types of outliers, which has not been considered by existing studies. In this paper, we analyze the cause of the data leakage issue in depth since the injection approach is a building block to advance UNOD. Moreover, we devise a novel variance-based model to detect structural outliers, which is more robust to different injection settings. On top of this, we propose a new framework, Variance-based Graph Outlier Detection (VGOD), which combines our variance-based model and attribute reconstruction model to detect outliers in a balanced way. Finally, we conduct extensive experiments to demonstrate the effectiveness and the efficiency of VGOD. The results on 5 real-world datasets validate that VGOD achieves not only the best performance in detecting outliers but also a balanced detection performance between structural and contextual outliers. ",
    "url": "https://arxiv.org/abs/2210.12941",
    "authors": [
      "Yihong Huang",
      "Liping Wang",
      "Fan Zhang",
      "Xuemin Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12945",
    "title": "Revisiting Sparse Convolutional Model for Visual Recognition",
    "abstract": "Despite strong empirical performance for image classification, deep neural networks are often regarded as ``black boxes'' and they are difficult to interpret. On the other hand, sparse convolutional models, which assume that a signal can be expressed by a linear combination of a few elements from a convolutional dictionary, are powerful tools for analyzing natural images with good theoretical interpretability and biological plausibility. However, such principled models have not demonstrated competitive performance when compared with empirically designed deep networks. This paper revisits the sparse convolutional modeling for image classification and bridges the gap between good empirical performance (of deep learning) and good interpretability (of sparse convolutional models). Our method uses differentiable optimization layers that are defined from convolutional sparse coding as drop-in replacements of standard convolutional layers in conventional deep neural networks. We show that such models have equally strong empirical performance on CIFAR-10, CIFAR-100, and ImageNet datasets when compared to conventional neural networks. By leveraging stable recovery property of sparse modeling, we further show that such models can be much more robust to input corruptions as well as adversarial perturbations in testing through a simple proper trade-off between sparse regularization and data reconstruction terms. Source code can be found at https://github.com/Delay-Xili/SDNet. ",
    "url": "https://arxiv.org/abs/2210.12945",
    "authors": [
      "Xili Dai",
      "Mingyang Li",
      "Pengyuan Zhai",
      "Shengbang Tong",
      "Xingjian Gao",
      "Shao-Lun Huang",
      "Zhihui Zhu",
      "Chong You",
      "Yi Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12947",
    "title": "IT-RUDA: Information Theory Assisted Robust Unsupervised Domain  Adaptation",
    "abstract": "Distribution shift between train (source) and test (target) datasets is a common problem encountered in machine learning applications. One approach to resolve this issue is to use the Unsupervised Domain Adaptation (UDA) technique that carries out knowledge transfer from a label-rich source domain to an unlabeled target domain. Outliers that exist in either source or target datasets can introduce additional challenges when using UDA in practice. In this paper, $\\alpha$-divergence is used as a measure to minimize the discrepancy between the source and target distributions while inheriting robustness, adjustable with a single parameter $\\alpha$, as the prominent feature of this measure. Here, it is shown that the other well-known divergence-based UDA techniques can be derived as special cases of the proposed method. Furthermore, a theoretical upper bound is derived for the loss in the target domain in terms of the source loss and the initial $\\alpha$-divergence between the two domains. The robustness of the proposed method is validated through testing on several benchmarked datasets in open-set and partial UDA setups where extra classes existing in target and source datasets are considered as outliers. ",
    "url": "https://arxiv.org/abs/2210.12947",
    "authors": [
      "Shima Rashidi",
      "Ruwan Tennakoon",
      "Aref Miri Rekavandi",
      "Papangkorn Jessadatavornwong",
      "Amanda Freis",
      "Garret Huff",
      "Mark Easton",
      "Adrian Mouritz",
      "Reza Hoseinnezhad",
      "Alireza Bab-Hadiashar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12952",
    "title": "Ares: A System-Oriented Wargame Framework for Adversarial ML",
    "abstract": "Since the discovery of adversarial attacks against machine learning models nearly a decade ago, research on adversarial machine learning has rapidly evolved into an eternal war between defenders, who seek to increase the robustness of ML models against adversarial attacks, and adversaries, who seek to develop better attacks capable of weakening or defeating these defenses. This domain, however, has found little buy-in from ML practitioners, who are neither overtly concerned about these attacks affecting their systems in the real world nor are willing to trade off the accuracy of their models in pursuit of robustness against these attacks. In this paper, we motivate the design and implementation of Ares, an evaluation framework for adversarial ML that allows researchers to explore attacks and defenses in a realistic wargame-like environment. Ares frames the conflict between the attacker and defender as two agents in a reinforcement learning environment with opposing objectives. This allows the introduction of system-level evaluation metrics such as time to failure and evaluation of complex strategies such as moving target defenses. We provide the results of our initial exploration involving a white-box attacker against an adversarially trained defender. ",
    "url": "https://arxiv.org/abs/2210.12952",
    "authors": [
      "Farhan Ahmed",
      "Pratik Vaishnavi",
      "Kevin Eykholt",
      "Amir Rahmati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.12954",
    "title": "Message Passing-Based Joint User Activity Detection and Channel  Estimation for Temporally-Correlated Massive Access",
    "abstract": "This paper studies the temporally-correlated massive access system where a large number of users communicate with the base station sporadically and continue transmitting data in the following frames in high probability when being active. To exploit both the sparsity and the temporal correlations in the user activities, we formulate the joint user activity detection and channel estimation problem in multiple consecutive frames as a dynamic compressed sensing (DCS) problem. Particularly, the problem is proposed to be solved under Bayesian inference to fully utilize the channel statistics and the activity evolution process. The hybrid generalized approximate message passing (HyGAMP) framework is leveraged to design a HyGAMP-DCS algorithm, which can nearly achieve the Bayesian optimality with efficient computations. Specifically, a GAMP part for channel estimation and an MP part for activity likelihood update are included in the proposed algorithm, then the extrinsic information is exchanged between them for performance enhancement. Moveover, we develop the expectation maximization HyGAMP-DCS (EM-HyGAMP-DCS) algorithm to adaptively learn the hyperparameters during the estimation procedure when the system statistics are unavailable. Particularly, the analytical tool of state evolution is provided to find the appropriate hyperparameter initialization that ensures EM-HyGAMP-DCS to achieve satisfied performance and fast convergence. From the simulation results, it is validated that our proposed algorithm can significantly outperform the existing methods. ",
    "url": "https://arxiv.org/abs/2210.12954",
    "authors": [
      "Weifeng Zhu",
      "Meixia Tao",
      "Xiaojun Yuan",
      "Yunfeng Guan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.12971",
    "title": "Holistically-Attracted Wireframe Parsing: From Supervised to  Self-Supervised Learning",
    "abstract": "This paper presents Holistically-Attracted Wireframe Parsing (HAWP) for 2D images using both fully supervised and self-supervised learning paradigms. At the core is a parsimonious representation that encodes a line segment using a closed-form 4D geometric vector, which enables lifting line segments in wireframe to an end-to-end trainable holistic attraction field that has built-in geometry-awareness, context-awareness and robustness. The proposed HAWP consists of three components: generating line segment and end-point proposal, binding line segment and end-point, and end-point-decoupled lines-of-interest verification. For self-supervised learning, a simulation-to-reality pipeline is exploited in which a HAWP is first trained using synthetic data and then used to ``annotate\" wireframes in real images with Homographic Adaptation. With the self-supervised annotations, a HAWP model for real images is trained from scratch. In experiments, the proposed HAWP achieves state-of-the-art performance in both the Wireframe dataset and the YorkUrban dataset in fully-supervised learning. It also demonstrates a significantly better repeatability score than prior arts with much more efficient training in self-supervised learning. Furthermore, the self-supervised HAWP shows great potential for general wireframe parsing without onerous wireframe labels. ",
    "url": "https://arxiv.org/abs/2210.12971",
    "authors": [
      "Nan Xue",
      "Tianfu Wu",
      "Song Bai",
      "Fu-Dong Wang",
      "Gui-Song Xia",
      "Liangpei Zhang",
      "Philip H.S. Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12974",
    "title": "Investigating Neuron Disturbing in Fusing Heterogeneous Neural Networks",
    "abstract": "Fusing deep learning models trained on separately located clients into a global model in a one-shot communication round is a straightforward implementation of Federated Learning. Although current model fusion methods are shown experimentally valid in fusing neural networks with almost identical architectures, they are rarely theoretically analyzed. In this paper, we reveal the phenomenon of neuron disturbing, where neurons from heterogeneous local models interfere with each other mutually. We give detailed explanations from a Bayesian viewpoint combining the data heterogeneity among clients and properties of neural networks. Furthermore, to validate our findings, we propose an experimental method that excludes neuron disturbing and fuses neural networks via adaptively selecting a local model, called AMS, to execute the prediction according to the input. The experiments demonstrate that AMS is more robust in data heterogeneity than general model fusion and ensemble methods. This implies the necessity of considering neural disturbing in model fusion. Besides, AMS is available for fusing models with varying architectures as an experimental algorithm, and we also list several possible extensions of AMS for future work. ",
    "url": "https://arxiv.org/abs/2210.12974",
    "authors": [
      "Biao Zhang",
      "Peng Xiao",
      "Shuqin Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.12989",
    "title": "Robust Object Detection in Remote Sensing Imagery with Noisy and Sparse  Geo-Annotations (Full Version)",
    "abstract": "Recently, the availability of remote sensing imagery from aerial vehicles and satellites constantly improved. For an automated interpretation of such data, deep-learning-based object detectors achieve state-of-the-art performance. However, established object detectors require complete, precise, and correct bounding box annotations for training. In order to create the necessary training annotations for object detectors, imagery can be georeferenced and combined with data from other sources, such as points of interest localized by GPS sensors. Unfortunately, this combination often leads to poor object localization and missing annotations. Therefore, training object detectors with such data often results in insufficient detection performance. In this paper, we present a novel approach for training object detectors with extremely noisy and incomplete annotations. Our method is based on a teacher-student learning framework and a correction module accounting for imprecise and missing annotations. Thus, our method is easy to use and can be combined with arbitrary object detectors. We demonstrate that our approach improves standard detectors by 37.1\\% $AP_{50}$ on a noisy real-world remote-sensing dataset. Furthermore, our method achieves great performance gains on two datasets with synthetic noise. Code is available at \\url{https://github.com/mxbh/robust_object_detection}. ",
    "url": "https://arxiv.org/abs/2210.12989",
    "authors": [
      "Maximilian Bernhard",
      "Matthias Schubert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13004",
    "title": "On representation of natural image patches",
    "abstract": "Starting from the first principle I derive an unsupervised learning method named even code to model local statistics of natural images. The first version uses orthogonal bases with independent states to model simple probability distribution of a few pixels. The second version uses a microscopic loss function to learn a nonlinear sparse binary representation of image patches. The distance in the binary representation space reflects image patch similarity. The learned model also has local edge detecting and orientation selective units like early visual systems. ",
    "url": "https://arxiv.org/abs/2210.13004",
    "authors": [
      "Cheng Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2210.13005",
    "title": "Towards Out-of-Distribution Sequential Event Prediction: A Causal  Treatment",
    "abstract": "The goal of sequential event prediction is to estimate the next event based on a sequence of historical events, with applications to sequential recommendation, user behavior analysis and clinical treatment. In practice, the next-event prediction models are trained with sequential data collected at one time and need to generalize to newly arrived sequences in remote future, which requires models to handle temporal distribution shift from training to testing. In this paper, we first take a data-generating perspective to reveal a negative result that existing approaches with maximum likelihood estimation would fail for distribution shift due to the latent context confounder, i.e., the common cause for the historical events and the next event. Then we devise a new learning objective based on backdoor adjustment and further harness variational inference to make it tractable for sequence learning problems. On top of that, we propose a framework with hierarchical branching structures for learning context-specific representations. Comprehensive experiments on diverse tasks (e.g., sequential recommendation) demonstrate the effectiveness, applicability and scalability of our method with various off-the-shelf models as backbones. ",
    "url": "https://arxiv.org/abs/2210.13005",
    "authors": [
      "Chenxiao Yang",
      "Qitian Wu",
      "Qingsong Wen",
      "Zhiqiang Zhou",
      "Liang Sun",
      "Junchi Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.13014",
    "title": "Geometric Knowledge Distillation: Topology Compression for Graph Neural  Networks",
    "abstract": "We study a new paradigm of knowledge transfer that aims at encoding graph topological information into graph neural networks (GNNs) by distilling knowledge from a teacher GNN model trained on a complete graph to a student GNN model operating on a smaller or sparser graph. To this end, we revisit the connection between thermodynamics and the behavior of GNN, based on which we propose Neural Heat Kernel (NHK) to encapsulate the geometric property of the underlying manifold concerning the architecture of GNNs. A fundamental and principled solution is derived by aligning NHKs on teacher and student models, dubbed as Geometric Knowledge Distillation. We develop non- and parametric instantiations and demonstrate their efficacy in various experimental settings for knowledge distillation regarding different types of privileged topological information and teacher-student schemes. ",
    "url": "https://arxiv.org/abs/2210.13014",
    "authors": [
      "Chenxiao Yang",
      "Qitian Wu",
      "Junchi Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13024",
    "title": "Investigating the detection of Tortured Phrases in Scientific Literature",
    "abstract": "With the help of online tools, unscrupulous authors can today generate a pseudo-scientific article and attempt to publish it. Some of these tools work by replacing or paraphrasing existing texts to produce new content, but they have a tendency to generate nonsensical expressions. A recent study introduced the concept of 'tortured phrase', an unexpected odd phrase that appears instead of the fixed expression. E.g. counterfeit consciousness instead of artificial intelligence. The present study aims at investigating how tortured phrases, that are not yet listed, can be detected automatically. We conducted several experiments, including non-neural binary classification, neural binary classification and cosine similarity comparison of the phrase tokens, yielding noticeable results. ",
    "url": "https://arxiv.org/abs/2210.13024",
    "authors": [
      "Puthineath Lay",
      "Martin Lentschat",
      "Cyril Labb\u00e9"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2210.13028",
    "title": "Generalised Likelihood Ratio Testing Adversaries through the  Differential Privacy Lens",
    "abstract": "Differential Privacy (DP) provides tight upper bounds on the capabilities of optimal adversaries, but such adversaries are rarely encountered in practice. Under the hypothesis testing/membership inference interpretation of DP, we examine the Gaussian mechanism and relax the usual assumption of a Neyman-Pearson-Optimal (NPO) adversary to a Generalized Likelihood Test (GLRT) adversary. This mild relaxation leads to improved privacy guarantees, which we express in the spirit of Gaussian DP and $(\\varepsilon, \\delta)$-DP, including composition and sub-sampling results. We evaluate our results numerically and find them to match the theoretical upper bounds. ",
    "url": "https://arxiv.org/abs/2210.13028",
    "authors": [
      "Georgios Kaissis",
      "Alexander Ziller",
      "Stefan Kolek Martinez de Azagra",
      "Daniel Rueckert"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)"
    ]
  },
  {
    "id": "arXiv:2210.13029",
    "title": "Multilingual Auxiliary Tasks Training: Bridging the Gap between  Languages for Zero-Shot Transfer of Hate Speech Detection Models",
    "abstract": "Zero-shot cross-lingual transfer learning has been shown to be highly challenging for tasks involving a lot of linguistic specificities or when a cultural gap is present between languages, such as in hate speech detection. In this paper, we highlight this limitation for hate speech detection in several domains and languages using strict experimental settings. Then, we propose to train on multilingual auxiliary tasks -- sentiment analysis, named entity recognition, and tasks relying on syntactic information -- to improve zero-shot transfer of hate speech detection models across languages. We show how hate speech detection models benefit from a cross-lingual {\\em knowledge proxy} brought by auxiliary tasks fine-tuning and highlight these tasks' positive impact on bridging the hate speech linguistic and cultural gap between languages. ",
    "url": "https://arxiv.org/abs/2210.13029",
    "authors": [
      "Syrielle Montariol",
      "Arij Riabi",
      "Djam\u00e9 Seddah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.13030",
    "title": "Self-supervised Rewiring of Pre-trained Speech Encoders: Towards Faster  Fine-tuning with Less Labels in Speech Processing",
    "abstract": "Pre-trained speech Transformers have facilitated great success across various speech processing tasks. However, fine-tuning these encoders for downstream tasks require sufficiently large training data to converge or to achieve state-of-the-art. In text domain this has been partly attributed to sub-optimality of the representation space in pre-trained Transformers. In this work, we take a sober look into pre-trained speech encoders and rewire their representation space without requiring any task-specific labels. Our method utilises neutrally synthesised version of audio inputs along with frame masking to construct positive pairs for contrastive self-supervised learning. When used for augmenting the wav2vec 2 encoder, we observe consistent improvement of isotropy in the representation space. Our experiments on 6 speech processing tasks, exhibit a significant convergence speedup during task fine-tuning as well as consistent task improvement, specially in low-resource settings. ",
    "url": "https://arxiv.org/abs/2210.13030",
    "authors": [
      "Hao Yang",
      "Jinming Zhao",
      "Gholamreza Haffari",
      "Ehsan Shareghi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.13034",
    "title": "Subspace-based Set Operations on a Pre-trained Word Embedding Space",
    "abstract": "Word embedding is a fundamental technology in natural language processing. It is often exploited for tasks using sets of words, although standard methods for representing word sets and set operations remain limited. If we can leverage the advantage of word embedding for such set operations, we can calculate sentence similarity and find words that effectively share a concept with a given word set in a straightforward way. In this study, we formulate representations of sets and set operations in a pre-trained word embedding space. Inspired by \\textit{quantum logic}, we propose a novel formulation of set operations using subspaces in a pre-trained word embedding space. Based on our definitions, we propose two metrics based on the degree to which a word belongs to a set and the similarity between embedding two sets. Our experiments with Text Concept Set Retrieval and Semantic Textual Similarity tasks demonstrated the effectiveness of our proposed method. ",
    "url": "https://arxiv.org/abs/2210.13034",
    "authors": [
      "Yoichi Ishibashi",
      "Sho Yokoi",
      "Katsuhito Sudoh",
      "Satoshi Nakamura"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13041",
    "title": "Learning Neural Radiance Fields from Multi-View Geometry",
    "abstract": "We present a framework, called MVG-NeRF, that combines classical Multi-View Geometry algorithms and Neural Radiance Fields (NeRF) for image-based 3D reconstruction. NeRF has revolutionized the field of implicit 3D representations, mainly due to a differentiable volumetric rendering formulation that enables high-quality and geometry-aware novel view synthesis. However, the underlying geometry of the scene is not explicitly constrained during training, thus leading to noisy and incorrect results when extracting a mesh with marching cubes. To this end, we propose to leverage pixelwise depths and normals from a classical 3D reconstruction pipeline as geometric priors to guide NeRF optimization. Such priors are used as pseudo-ground truth during training in order to improve the quality of the estimated underlying surface. Moreover, each pixel is weighted by a confidence value based on the forward-backward reprojection error for additional robustness. Experimental results on real-world data demonstrate the effectiveness of this approach in obtaining clean 3D meshes from images, while maintaining competitive performances in novel view synthesis. ",
    "url": "https://arxiv.org/abs/2210.13041",
    "authors": [
      "Marco Orsingher",
      "Paolo Zani",
      "Paolo Medici",
      "Massimo Bertozzi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13043",
    "title": "Data-IQ: Characterizing subgroups with heterogeneous outcomes in tabular  data",
    "abstract": "High model performance, on average, can hide that models may systematically underperform on subgroups of the data. We consider the tabular setting, which surfaces the unique issue of outcome heterogeneity - this is prevalent in areas such as healthcare, where patients with similar features can have different outcomes, thus making reliable predictions challenging. To tackle this, we propose Data-IQ, a framework to systematically stratify examples into subgroups with respect to their outcomes. We do this by analyzing the behavior of individual examples during training, based on their predictive confidence and, importantly, the aleatoric (data) uncertainty. Capturing the aleatoric uncertainty permits a principled characterization and then subsequent stratification of data examples into three distinct subgroups (Easy, Ambiguous, Hard). We experimentally demonstrate the benefits of Data-IQ on four real-world medical datasets. We show that Data-IQ's characterization of examples is most robust to variation across similarly performant (yet different) models, compared to baselines. Since Data-IQ can be used with any ML model (including neural networks, gradient boosting etc.), this property ensures consistency of data characterization, while allowing flexible model selection. Taking this a step further, we demonstrate that the subgroups enable us to construct new approaches to both feature acquisition and dataset selection. Furthermore, we highlight how the subgroups can inform reliable model usage, noting the significant impact of the Ambiguous subgroup on model generalization. ",
    "url": "https://arxiv.org/abs/2210.13043",
    "authors": [
      "Nabeel Seedat",
      "Jonathan Crabb\u00e9",
      "Ioana Bica",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.13057",
    "title": "Certifying Induced Subgraphs in Large Graphs",
    "abstract": "We introduce I/O-optimal certifying algorithms for bipartite graphs, as well as for the classes of split, threshold, bipartite chain, and trivially perfect graphs. When the input graph is a class member, the certifying algorithm returns a certificate that characterizes this class. Otherwise, it returns a forbidden induced subgraph as a certificate for non-membership. On a graph with $n$ vertices and $m$ edges, our algorithms take optimal $O(\\text{sort}(n + m))$ I/Os in the worst case or with high probability for bipartite chain graphs, and the certificates are returned in optimal I/Os. We give implementations for split and threshold graphs and provide an experimental evaluation. ",
    "url": "https://arxiv.org/abs/2210.13057",
    "authors": [
      "Ulrich Meyer",
      "Hung Tran",
      "Konstantinos Tsakalidis"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2210.13083",
    "title": "Scalable Representation Learning in Linear Contextual Bandits with  Constant Regret Guarantees",
    "abstract": "We study the problem of representation learning in stochastic contextual linear bandits. While the primary concern in this domain is usually to find realizable representations (i.e., those that allow predicting the reward function at any context-action pair exactly), it has been recently shown that representations with certain spectral properties (called HLS) may be more effective for the exploration-exploitation task, enabling LinUCB to achieve constant (i.e., horizon-independent) regret. In this paper, we propose BanditSRL, a representation learning algorithm that combines a novel constrained optimization problem to learn a realizable representation with good spectral properties with a generalized likelihood ratio test to exploit the recovered representation and avoid excessive exploration. We prove that BanditSRL can be paired with any no-regret algorithm and achieve constant regret whenever an HLS representation is available. Furthermore, BanditSRL can be easily combined with deep neural networks and we show how regularizing towards HLS representations is beneficial in standard benchmarks. ",
    "url": "https://arxiv.org/abs/2210.13083",
    "authors": [
      "Andrea Tirinzoni",
      "Matteo Papini",
      "Ahmed Touati",
      "Alessandro Lazaric",
      "Matteo Pirotta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13084",
    "title": "Full-Text Argumentation Mining on Scientific Publications",
    "abstract": "Scholarly Argumentation Mining (SAM) has recently gained attention due to its potential to help scholars with the rapid growth of published scientific literature. It comprises two subtasks: argumentative discourse unit recognition (ADUR) and argumentative relation extraction (ARE), both of which are challenging since they require e.g. the integration of domain knowledge, the detection of implicit statements, and the disambiguation of argument structure. While previous work focused on dataset construction and baseline methods for specific document sections, such as abstract or results, full-text scholarly argumentation mining has seen little progress. In this work, we introduce a sequential pipeline model combining ADUR and ARE for full-text SAM, and provide a first analysis of the performance of pretrained language models (PLMs) on both subtasks. We establish a new SotA for ADUR on the Sci-Arg corpus, outperforming the previous best reported result by a large margin (+7% F1). We also present the first results for ARE, and thus for the full AM pipeline, on this benchmark dataset. Our detailed error analysis reveals that non-contiguous ADUs as well as the interpretation of discourse connectors pose major challenges and that data annotation needs to be more consistent. ",
    "url": "https://arxiv.org/abs/2210.13084",
    "authors": [
      "Arne Binder",
      "Bhuvanesh Verma",
      "Leonhard Hennig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.13088",
    "title": "Your Router is My Prober: Measuring IPv6 Networks via ICMP Rate Limiting  Side Channels",
    "abstract": "Active Internet measurements face challenges when some measurements require many remote vantage points. In this paper, we propose a novel technique for measuring remote IPv6 networks via side channels in ICMP rate limiting, a required function for IPv6 nodes to limit the rate at which ICMP error messages are generated. This technique, iVantage, can to some extent use 1.1M remote routers distributed in 9.5k autonomous systems and 182 countries as our \"vantage points\". We apply iVantage to two different, but both challenging measurement tasks: 1) measuring the deployment of inbound source address validation (ISAV) and 2) measuring reachability between arbitrary Internet nodes. We accomplish these two tasks from only one local vantage point without controlling the targets or relying on other services within the target networks. Our large-scale ISAV measurements cover ~50% of all IPv6 autonomous systems and find ~79% of them are vulnerable to spoofing, which is the most large-scale measurement study of IPv6 ISAV to date. Our method for reachability measurements achieves over 80% precision and recall in our evaluation. Finally, we perform an Internet-wide measurement of the ICMP rate limiting implementations, present a detailed discussion on ICMP rate limiting, particularly the potential security and privacy risks in the mechanism of ICMP rate limiting, and provide possible mitigation measures. We make our code available to the community. ",
    "url": "https://arxiv.org/abs/2210.13088",
    "authors": [
      "Long Pan",
      "Jiahai Yang",
      "Lin He",
      "Zhiliang Wang",
      "Leyao Nie",
      "Guanglei Song",
      "Yaozhong Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.13107",
    "title": "An Analytical Estimation of Spiking Neural Networks Energy Efficiency",
    "abstract": "Spiking Neural Networks are a type of neural networks where neurons communicate using only spikes. They are often presented as a low-power alternative to classical neural networks, but few works have proven these claims to be true. In this work, we present a metric to estimate the energy consumption of SNNs independently of a specific hardware. We then apply this metric on SNNs processing three different data types (static, dynamic and event-based) representative of real-world applications. As a result, all of our SNNs are 6 to 8 times more efficient than their FNN counterparts. ",
    "url": "https://arxiv.org/abs/2210.13107",
    "authors": [
      "Edgar Lemaire",
      "Loic Cordone",
      "Andrea Castagnetti",
      "Pierre-Emmanuel Novac",
      "Jonathan Courtois",
      "Benoit Miramond"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2210.13108",
    "title": "Heat Demand Forecasting with Multi-Resolutional Representation of  Heterogeneous Temporal Ensemble",
    "abstract": "One of the primal challenges faced by utility companies is ensuring efficient supply with minimal greenhouse gas emissions. The advent of smart meters and smart grids provide an unprecedented advantage in realizing an optimised supply of thermal energies through proactive techniques such as load forecasting. In this paper, we propose a forecasting framework for heat demand based on neural networks where the time series are encoded as scalograms equipped with the capacity of embedding exogenous variables such as weather, and holiday/non-holiday. Subsequently, CNNs are utilized to predict the heat load multi-step ahead. Finally, the proposed framework is compared with other state-of-the-art methods, such as SARIMAX and LSTM. The quantitative results from retrospective experiments show that the proposed framework consistently outperforms the state-of-the-art baseline method with real-world data acquired from Denmark. A minimal mean error of 7.54% for MAPE and 417kW for RMSE is achieved with the proposed framework in comparison to all other methods. ",
    "url": "https://arxiv.org/abs/2210.13108",
    "authors": [
      "Adithya Ramachandran",
      "Satyaki Chatterjee",
      "Siming Bayer",
      "Andreas Maier",
      "Thorkil Flensmark"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13110",
    "title": "On DoS Resiliency Analysis of Networked Control Systems: Trade-Off  Between Jamming Actions and Network Delays",
    "abstract": "This letter deals with the problem of quantifying resiliency of Networked Control Systems (NCSs) to Denial-of-Service (DoS) attacks and variable network delays. Internal exponential stability and $\\mathcal{L}_2$ external stability are studied. The closed-loop system is augmented with an auxiliary timer variable and analyzed in a hybrid system framework. Lyapunov-like conditions are given to ensure $0$-input global exponential stability and $\\mathcal{L}_2$ external stability. A computationally affordable algorithm based on linear matrix inequalities is devised to provide trade-off curves between maximum length of DoS attacks and largest network delays. Finally, the effectiveness of the proposed approach is shown in a numerical example. ",
    "url": "https://arxiv.org/abs/2210.13110",
    "authors": [
      "Roberto Merco",
      "Francesco Ferrante",
      "Pierluigi Pisu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.13124",
    "title": "Cipherfix: Mitigating Ciphertext Side-Channel Attacks in Software",
    "abstract": "Trusted execution environments are quickly rising in popularity as they enable to run workloads in the cloud without having to trust cloud service providers, by offering additional hardware-assisted security guarantees. One key mechanism for server-grade TEEs is main memory encryption, as it not only prevents system-level attackers from reading the TEE's content, but also provides protection against physical, off-chip attackers. The recent Cipherleaks attacks show that the memory encryption system of AMD SEV-SNP and potentially other TEEs are vulnerable to a new kind of attack, dubbed the ciphertext side-channel. The ciphertext side-channel allows to leak secret data from TEE-protected implementations by analyzing ciphertext patterns exhibited due to deterministic memory encryption. It cannot be mitigated by current best practices like data-oblivious constant-time code. As these ciphertext leakages are inherent to deterministic memory encryption, a hardware fix on existing systems is unlikely. Thus, in this paper, we present a software-based, drop-in solution that can harden existing binaries such that they can be safely executed under TEEs vulnerable to ciphertext side-channels. We combine taint tracking with both static and dynamic binary instrumentation to find sensitive memory locations and prevent the leakage by masking secret data before it gets written to memory. This way, although the memory encryption remains deterministic, we destroy any secret-dependent patterns in encrypted memory. We show that our proof-of-concept implementation can protect constant-time EdDSA and ECDSA implementations against ciphertext side-channels. ",
    "url": "https://arxiv.org/abs/2210.13124",
    "authors": [
      "Jan Wichelmann",
      "Anna P\u00e4tschke",
      "Luca Wilke",
      "Thomas Eisenbarth"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.13136",
    "title": "Path association rule mining",
    "abstract": "Graph association rule mining is a data mining technique used for discovering regularities in graph data. In this study, we propose a novel concept, {\\it path association rule mining}, to discover the correlations of path patterns that frequently appear in a given graph. Reachability path patterns (i.e., existence of paths from a vertex to another vertex) are applied in our concept to discover diverse regularities. We show that the problem is NP-hard, and we develop an efficient algorithm in which the anti-monotonic property is used on path patterns. Subsequently, we develop approximation and parallelization techniques to efficiently and scalably discover rules. We use real-life graphs to experimentally verify the effective ",
    "url": "https://arxiv.org/abs/2210.13136",
    "authors": [
      "Yuya Sasaki"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ]
  },
  {
    "id": "arXiv:2210.13148",
    "title": "DAGformer: Directed Acyclic Graph Transformer",
    "abstract": "In many fields, such as natural language processing and computer vision, the Transformer architecture has become the standard. Recently, the Transformer architecture has also attracted a growing amount of interest in graph representation learning since it naturally overcomes some graph neural network (GNNs) restrictions. In this work, we focus on a special yet widely used class of graphs-DAGs. We propose the directed acyclic graph Transformer, DAGformer, a Transformer architecture that processes information according to the reachability relation defined by the partial order. DAGformer is simple and flexible, allowing it to be used with various transformer-based models. We show that our architecture achieves state-of-the-art performance on representative DAG datasets, outperforming all previous approaches. ",
    "url": "https://arxiv.org/abs/2210.13148",
    "authors": [
      "Yuankai Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.13149",
    "title": "Binary Graph Convolutional Network with Capacity Exploration",
    "abstract": "The current success of Graph Neural Networks (GNNs) usually relies on loading the entire attributed graph for processing, which may not be satisfied with limited memory resources, especially when the attributed graph is large. This paper pioneers to propose a Binary Graph Convolutional Network (Bi-GCN), which binarizes both the network parameters and input node attributes and exploits binary operations instead of floating-point matrix multiplications for network compression and acceleration. Meanwhile, we also propose a new gradient approximation based back-propagation method to properly train our Bi-GCN. According to the theoretical analysis, our Bi-GCN can reduce the memory consumption by an average of ~31x for both the network parameters and input data, and accelerate the inference speed by an average of ~51x, on three citation networks, i.e., Cora, PubMed, and CiteSeer. Besides, we introduce a general approach to generalize our binarization method to other variants of GNNs, and achieve similar efficiencies. Although the proposed Bi-GCN and Bi-GNNs are simple yet efficient, these compressed networks may also possess a potential capacity problem, i.e., they may not have enough storage capacity to learn adequate representations for specific tasks. To tackle this capacity problem, an Entropy Cover Hypothesis is proposed to predict the lower bound of the width of Bi-GNN hidden layers. Extensive experiments have demonstrated that our Bi-GCN and Bi-GNNs can give comparable performances to the corresponding full-precision baselines on seven node classification datasets and verified the effectiveness of our Entropy Cover Hypothesis for solving the capacity problem. ",
    "url": "https://arxiv.org/abs/2210.13149",
    "authors": [
      "Junfu Wang",
      "Yuanfang Guo",
      "Liang Yang",
      "Yunhong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13150",
    "title": "A PAC-Bayesian Generalization Bound for Equivariant Networks",
    "abstract": "Equivariant networks capture the inductive bias about the symmetry of the learning task by building those symmetries into the model. In this paper, we study how equivariance relates to generalization error utilizing PAC Bayesian analysis for equivariant networks, where the transformation laws of feature spaces are determined by group representations. By using perturbation analysis of equivariant networks in Fourier domain for each layer, we derive norm-based PAC-Bayesian generalization bounds. The bound characterizes the impact of group size, and multiplicity and degree of irreducible representations on the generalization error and thereby provide a guideline for selecting them. In general, the bound indicates that using larger group size in the model improves the generalization error substantiated by extensive numerical experiments. ",
    "url": "https://arxiv.org/abs/2210.13150",
    "authors": [
      "Arash Behboodi",
      "Gabriele Cesa",
      "Taco Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.13153",
    "title": "Reachability-Aware Laplacian Representation in Reinforcement Learning",
    "abstract": "In Reinforcement Learning (RL), Laplacian Representation (LapRep) is a task-agnostic state representation that encodes the geometry of the environment. A desirable property of LapRep stated in prior works is that the Euclidean distance in the LapRep space roughly reflects the reachability between states, which motivates the usage of this distance for reward shaping. However, we find that LapRep does not necessarily have this property in general: two states having small distance under LapRep can actually be far away in the environment. Such mismatch would impede the learning process in reward shaping. To fix this issue, we introduce a Reachability-Aware Laplacian Representation (RA-LapRep), by properly scaling each dimension of LapRep. Despite the simplicity, we demonstrate that RA-LapRep can better capture the inter-state reachability as compared to LapRep, through both theoretical explanations and experimental results. Additionally, we show that this improvement yields a significant boost in reward shaping performance and also benefits bottleneck state discovery. ",
    "url": "https://arxiv.org/abs/2210.13153",
    "authors": [
      "Kaixin Wang",
      "Kuangqi Zhou",
      "Jiashi Feng",
      "Bryan Hooi",
      "Xinchao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.13184",
    "title": "DPU-v2: Energy-efficient execution of irregular directed acyclic graphs",
    "abstract": "A growing number of applications like probabilistic machine learning, sparse linear algebra, robotic navigation, etc., exhibit irregular data flow computation that can be modeled with directed acyclic graphs (DAGs). The irregularity arises from the seemingly random connections of nodes, which makes the DAG structure unsuitable for vectorization on CPU or GPU. Moreover, the nodes usually represent a small number of arithmetic operations that cannot amortize the overhead of launching tasks/kernels for each node, further posing challenges for parallel execution. To enable energy-efficient execution, this work proposes DAG processing unit (DPU) version 2, a specialized processor architecture optimized for irregular DAGs with static connectivity. It consists of a tree-structured datapath for efficient data reuse, a customized banked register file, and interconnects tuned to support irregular register accesses. DPU-v2 is utilized effectively through a targeted compiler that systematically maps operations to the datapath, minimizes register bank conflicts, and avoids pipeline hazards. Finally, a design space exploration identifies the optimal architecture configuration that minimizes the energy-delay product. This hardware-software co-optimization approach results in a speedup of 1.4$\\times$, 3.5$\\times$, and 14$\\times$ over a state-of-the-art DAG processor ASIP, a CPU, and a GPU, respectively, while also achieving a lower energy-delay product. In this way, this work takes an important step toward enabling an embedded execution of emerging DAG workloads. ",
    "url": "https://arxiv.org/abs/2210.13184",
    "authors": [
      "Nimish Shah",
      "Wannes Meert",
      "Marian Verhelst"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ]
  },
  {
    "id": "arXiv:2210.13186",
    "title": "Meta Input: How to Leverage Off-the-Shelf Deep Neural Networks",
    "abstract": "These days, although deep neural networks (DNNs) have achieved a noticeable progress in a wide range of research area, it lacks the adaptability to be employed in the real-world applications because of the environment discrepancy problem. Such a problem originates from the difference between training and testing environments, and it is widely known that it causes serious performance degradation, when a pretrained DNN model is applied to a new testing environment. Therefore, in this paper, we introduce a novel approach that allows end-users to exploit pretrained DNN models in their own testing environment without modifying the models. To this end, we present a \\textit{meta input} which is an additional input transforming the distribution of testing data to be aligned with that of training data. The proposed meta input can be optimized with a small number of testing data only by considering the relation between testing input data and its output prediction. Also, it does not require any knowledge of the network's internal architecture and modification of its weight parameters. Then, the obtained meta input is added to testing data in order to shift the distribution of testing data to that of originally used training data. As a result, end-users can exploit well-trained models in their own testing environment which can differ from the training environment. We validate the effectiveness and versatility of the proposed meta input by showing the robustness against the environment discrepancy through the comprehensive experiments with various tasks. ",
    "url": "https://arxiv.org/abs/2210.13186",
    "authors": [
      "Minsu Kim",
      "Youngjoon Yu",
      "Sungjune Park",
      "Yong Man Ro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13191",
    "title": "Navigating the challenges in creating complex data systems: a  development philosophy",
    "abstract": "In this perspective, we argue that despite the democratization of powerful tools for data science and machine learning over the last decade, developing the code for a trustworthy and effective data science system (DSS) is getting harder. Perverse incentives and a lack of widespread software engineering (SE) skills are among many root causes we identify that naturally give rise to the current systemic crisis in reproducibility of DSSs. We analyze why SE and building large complex systems is, in general, hard. Based on these insights, we identify how SE addresses those difficulties and how we can apply and generalize SE methods to construct DSSs that are fit for purpose. We advocate two key development philosophies, namely that one should incrementally grow -- not biphasically plan and build -- DSSs, and one should always employ two types of feedback loops during development: one which tests the code's correctness and another that evaluates the code's efficacy. ",
    "url": "https://arxiv.org/abs/2210.13191",
    "authors": [
      "S\u00f6ren Dittmer",
      "Michael Roberts",
      "Julian Gilbey",
      "Ander Biguri",
      "AIX-COVNET Collaboration",
      "Jacobus Preller",
      "James H.F. Rudd",
      "John A.D. Aston",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13212",
    "title": "A Dimension-Augmented Physics-Informed Neural Network (DaPINN) with High  Level Accuracy and Efficiency",
    "abstract": "Physics-informed neural networks (PINNs) have been widely applied in different fields due to their effectiveness in solving partial differential equations (PDEs). However, the accuracy and efficiency of PINNs need to be considerably improved for scientific and commercial use. To address this issue, we systematically propose a novel dimension-augmented physics-informed neural network (DaPINN), which simultaneously and significantly improves the accuracy and efficiency of the PINN. In the DaPINN model, we introduce inductive bias in the neural network to enhance network generalizability by adding a special regularization term to the loss function. Furthermore, we manipulate the network input dimension by inserting additional sample features and incorporating the expanded dimensionality in the loss function. Moreover, we verify the effectiveness of power series augmentation, Fourier series augmentation and replica augmentation, in both forward and backward problems. In most experiments, the error of DaPINN is 1$\\sim$2 orders of magnitude lower than that of PINN. The results show that the DaPINN outperforms the original PINN in terms of both accuracy and efficiency with a reduced dependence on the number of sample points. We also discuss the complexity of the DaPINN and its compatibility with other methods. ",
    "url": "https://arxiv.org/abs/2210.13212",
    "authors": [
      "Weilong Guan",
      "Kaihan Yang",
      "Yinsheng Chen",
      "Zhong Guan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2210.13225",
    "title": "Biologically Plausible Variational Policy Gradient with Spiking  Recurrent Winner-Take-All Networks",
    "abstract": "One stream of reinforcement learning research is exploring biologically plausible models and algorithms to simulate biological intelligence and fit neuromorphic hardware. Among them, reward-modulated spike-timing-dependent plasticity (R-STDP) is a recent branch with good potential in energy efficiency. However, current R-STDP methods rely on heuristic designs of local learning rules, thus requiring task-specific expert knowledge. In this paper, we consider a spiking recurrent winner-take-all network, and propose a new R-STDP method, spiking variational policy gradient (SVPG), whose local learning rules are derived from the global policy gradient and thus eliminate the need for heuristic designs. In experiments of MNIST classification and Gym InvertedPendulum, our SVPG achieves good training performance, and also presents better robustness to various kinds of noises than conventional methods. ",
    "url": "https://arxiv.org/abs/2210.13225",
    "authors": [
      "Zhile Yang",
      "Shangqi Guo",
      "Ying Fang",
      "Jian K. Liu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2210.13235",
    "title": "Chaos Theory and Adversarial Robustness",
    "abstract": "Neural Networks, being susceptible to adversarial attacks, should face a strict level of scrutiny before being deployed in critical or adversarial applications. This paper uses ideas from Chaos Theory to explain, analyze, and quantify the degree to which Neural Networks are susceptible to or robust against adversarial attacks. Our results show that susceptibility to attack grows significantly with the depth of the model, which has significant safety implications for the design of Neural Networks for production environments. We also demonstrate how to quickly and easily approximate the certified robustness radii for extremely large models, which until now has been computationally infeasible to calculate directly, as well as show a clear relationship between our new susceptibility metric and post-attack accuracy. ",
    "url": "https://arxiv.org/abs/2210.13235",
    "authors": [
      "Jonathan S. Kent"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2210.13263",
    "title": "Driver Locations Harvesting Attack on pRide",
    "abstract": "Privacy preservation in Ride-Hailing Services (RHS) is intended to protect privacy of drivers and riders. pRide, published in IEEE Trans. Vehicular Technology 2021, is a prediction based privacy-preserving RHS protocol to match riders with an optimum driver. In the protocol, the Service Provider (SP) homomorphically computes Euclidean distances between encrypted locations of drivers and rider. Rider selects an optimum driver using decrypted distances augmented by a new-ride-emergence prediction. To improve the effectiveness of driver selection, the paper proposes an enhanced version where each driver gives encrypted distances to each corner of her grid. To thwart a rider from using these distances to launch an inference attack, the SP blinds these distances before sharing them with the rider. In this work, we propose a passive attack where an honest-but-curious adversary rider who makes a single ride request and receives the blinded distances from SP can recover the constants used to blind the distances. Using the unblinded distances, rider to driver distance and Google Nearest Road API, the adversary can obtain the precise locations of responding drivers. We conduct experiments with random on-road driver locations for four different cities. Our experiments show that we can determine the precise locations of at least 80% of the drivers participating in the enhanced pRide protocol. ",
    "url": "https://arxiv.org/abs/2210.13263",
    "authors": [
      "Shyam Murthy",
      "Srinivas Vivek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.13281",
    "title": "Analyzing the Use of Influence Functions for Instance-Specific Data  Filtering in Neural Machine Translation",
    "abstract": "Customer feedback can be an important signal for improving commercial machine translation systems. One solution for fixing specific translation errors is to remove the related erroneous training instances followed by re-training of the machine translation system, which we refer to as instance-specific data filtering. Influence functions (IF) have been shown to be effective in finding such relevant training examples for classification tasks such as image classification, toxic speech detection and entailment task. Given a probing instance, IF find influential training examples by measuring the similarity of the probing instance with a set of training examples in gradient space. In this work, we examine the use of influence functions for Neural Machine Translation (NMT). We propose two effective extensions to a state of the art influence function and demonstrate on the sub-problem of copied training examples that IF can be applied more generally than handcrafted regular expressions. ",
    "url": "https://arxiv.org/abs/2210.13281",
    "authors": [
      "Tsz Kin Lam",
      "Eva Hasler",
      "Felix Hieber"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.13305",
    "title": "BoundED: Neural Boundary and Edge Detection in 3D Point Clouds via Local  Neighborhood Statistics",
    "abstract": "Extracting high-level structural information from 3D point clouds is challenging but essential for tasks like urban planning or autonomous driving requiring an advanced understanding of the scene at hand. Existing approaches are still not able to produce high-quality results consistently while being fast enough to be deployed in scenarios requiring interactivity. We propose to utilize a novel set of features describing the local neighborhood on a per-point basis via first and second order statistics as input for a simple and compact classification network to distinguish between non-edge, sharp-edge, and boundary points in the given data. Leveraging this feature embedding enables our algorithm to outperform the state-of-the-art techniques in terms of quality and processing time. ",
    "url": "https://arxiv.org/abs/2210.13305",
    "authors": [
      "Lukas Bode",
      "Michael Weinmann",
      "Reinhard Klein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2210.13312",
    "title": "Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs",
    "abstract": "Social intelligence and Theory of Mind (ToM), i.e., the ability to reason about the different mental states, intents, and reactions of all people involved, allow humans to effectively navigate and understand everyday social interactions. As NLP systems are used in increasingly complex social situations, their ability to grasp social dynamics becomes crucial. In this work, we examine the open question of social intelligence and Theory of Mind in modern NLP systems from an empirical and theory-based perspective. We show that one of today's largest language models (GPT-3; Brown et al., 2020) lacks this kind of social intelligence out-of-the box, using two tasks: SocialIQa (Sap et al., 2019), which measures models' ability to understand intents and reactions of participants of social interactions, and ToMi (Le et al., 2019), which measures whether models can infer mental states and realities of participants of situations. Our results show that models struggle substantially at these Theory of Mind tasks, with well-below-human accuracies of 55% and 60% on SocialIQa and ToMi, respectively. To conclude, we draw on theories from pragmatics to contextualize this shortcoming of large language models, by examining the limitations stemming from their data, neural architecture, and training paradigms. Challenging the prevalent narrative that only scale is needed, we posit that person-centric NLP approaches might be more effective towards neural Theory of Mind. ",
    "url": "https://arxiv.org/abs/2210.13312",
    "authors": [
      "Maarten Sap",
      "Ronan LeBras",
      "Daniel Fried",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.13317",
    "title": "Planning Coordinated Human-Robot Motions with Neural Network Full-Body  Prediction Models",
    "abstract": "Numerical optimization has become a popular approach to plan smooth motion trajectories for robots. However, when sharing space with humans, balancing properly safety, comfort and efficiency still remains challenging. This is notably the case because humans adapt their behavior to that of the robot, raising the need for intricate planning and prediction. In this paper, we propose a novel optimization-based motion planning algorithm, which generates robot motions, while simultaneously maximizing the human trajectory likelihood under a data-driven predictive model. Considering planning and prediction together allows us to formulate objective and constraint functions in the joint human-robot state space. Key to the approach are added latent space modifiers to a differentiable human predictive model based on a dedicated recurrent neural network. These modifiers allow to change the human prediction within motion optimization. We empirically evaluate our method using the publicly available MoGaze dataset. Our results indicate that the proposed framework outperforms current baselines for planning handover trajectories and avoiding collisions between a robot and a human. Our experiments demonstrate collaborative motion trajectories, where both, the human prediction and the robot plan, adapt to each other. ",
    "url": "https://arxiv.org/abs/2210.13317",
    "authors": [
      "Philipp Kratzer",
      "Marc Toussaint",
      "Jim Mainprice"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.13356",
    "title": "Robust Self-Supervised Learning with Lie Groups",
    "abstract": "Deep learning has led to remarkable advances in computer vision. Even so, today's best models are brittle when presented with variations that differ even slightly from those seen during training. Minor shifts in the pose, color, or illumination of an object can lead to catastrophic misclassifications. State-of-the art models struggle to understand how a set of variations can affect different objects. We propose a framework for instilling a notion of how objects vary in more realistic settings. Our approach applies the formalism of Lie groups to capture continuous transformations to improve models' robustness to distributional shifts. We apply our framework on top of state-of-the-art self-supervised learning (SSL) models, finding that explicitly modeling transformations with Lie groups leads to substantial performance gains of greater than 10% for MAE on both known instances seen in typical poses now presented in new poses, and on unknown instances in any pose. We also apply our approach to ImageNet, finding that the Lie operator improves performance by almost 4%. These results demonstrate the promise of learning transformations to improve model robustness. ",
    "url": "https://arxiv.org/abs/2210.13356",
    "authors": [
      "Mark Ibrahim",
      "Diane Bouchacourt",
      "Ari Morcos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13358",
    "title": "Novelty Detection in Time Series via Weak Innovations Representation: A  Deep Learning Approach",
    "abstract": "We consider novelty detection in time series with unknown and nonparametric probability structures. A deep learning approach is proposed to causally extract an innovations sequence consisting of novelty samples statistically independent of all past samples of the time series. A novelty detection algorithm is developed for the online detection of novel changes in the probability structure in the innovations sequence. A minimax optimality under a Bayes risk measure is established for the proposed novelty detection method, and its robustness and efficacy are demonstrated in experiments using real and synthetic datasets. ",
    "url": "https://arxiv.org/abs/2210.13358",
    "authors": [
      "Xinyi Wang",
      "Mei-jen Lee",
      "Qing Zhao",
      "Lang Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.13361",
    "title": "NASA: Neural Architecture Search and Acceleration for Hardware Inspired  Hybrid Networks",
    "abstract": "Multiplication is arguably the most cost-dominant operation in modern deep neural networks (DNNs), limiting their achievable efficiency and thus more extensive deployment in resource-constrained applications. To tackle this limitation, pioneering works have developed handcrafted multiplication-free DNNs, which require expert knowledge and time-consuming manual iteration, calling for fast development tools. To this end, we propose a Neural Architecture Search and Acceleration framework dubbed NASA, which enables automated multiplication-reduced DNN development and integrates a dedicated multiplication-reduced accelerator for boosting DNNs' achievable efficiency. Specifically, NASA adopts neural architecture search (NAS) spaces that augment the state-of-the-art one with hardware-inspired multiplication-free operators, such as shift and adder, armed with a novel progressive pretrain strategy (PGP) together with customized training recipes to automatically search for optimal multiplication-reduced DNNs; On top of that, NASA further develops a dedicated accelerator, which advocates a chunk-based template and auto-mapper dedicated for NASA-NAS resulting DNNs to better leverage their algorithmic properties for boosting hardware efficiency. Experimental results and ablation studies consistently validate the advantages of NASA's algorithm-hardware co-design framework in terms of achievable accuracy and efficiency tradeoffs. Codes are available at https://github.com/RICE-EIC/NASA. ",
    "url": "https://arxiv.org/abs/2210.13361",
    "authors": [
      "Huihong Shi",
      "Haoran You",
      "Yang Zhao",
      "Zhongfeng Wang",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13371",
    "title": "Time-Varying ALIP Model and Robust Foot-Placement Control for  Underactuated Bipedal Robot Walking on a Swaying Rigid Surface",
    "abstract": "Controller design for bipedal walking on dynamic rigid surfaces (DRSes), which are rigid surfaces moving in the inertial frame (e.g., ships and airplanes), remains largely uninvestigated. This paper introduces a hierarchical control approach that achieves stable underactuated bipedal robot walking on a horizontally oscillating DRS. The highest layer of our approach is a real-time motion planner that generates desired global behaviors (i.e., the center of mass trajectories and footstep locations) by stabilizing a reduced-order robot model. One key novelty of this layer is the derivation of the reduced-order model by analytically extending the angular momentum based linear inverted pendulum (ALIP) model from stationary to horizontally moving surfaces. The other novelty is the development of a discrete-time foot-placement controller that exponentially stabilizes the hybrid, linear, time-varying ALIP model. The middle layer of the proposed approach is a walking pattern generator that translates the desired global behaviors into the robot's full-body reference trajectories for all directly actuated degrees of freedom. The lowest layer is an input-output linearizing controller that exponentially tracks those full-body reference trajectories based on the full-order, hybrid, nonlinear robot dynamics. Simulations of planar underactuated bipedal walking on a swaying DRS confirm that the proposed framework ensures the walking stability under different DRS motions and gait types. ",
    "url": "https://arxiv.org/abs/2210.13371",
    "authors": [
      "Yuan Gao",
      "Yukai Gong",
      "Victor Paredes",
      "Ayonga Hereid",
      "Yan Gu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.13388",
    "title": "Focused Concatenation for Context-Aware Neural Machine Translation",
    "abstract": "A straightforward approach to context-aware neural machine translation consists in feeding the standard encoder-decoder architecture with a window of consecutive sentences, formed by the current sentence and a number of sentences from its context concatenated to it. In this work, we propose an improved concatenation approach that encourages the model to focus on the translation of the current sentence, discounting the loss generated by target context. We also propose an additional improvement that strengthen the notion of sentence boundaries and of relative sentence distance, facilitating model compliance to the context-discounted objective. We evaluate our approach with both average-translation quality metrics and contrastive test sets for the translation of inter-sentential discourse phenomena, proving its superiority to the vanilla concatenation approach and other sophisticated context-aware systems. ",
    "url": "https://arxiv.org/abs/2210.13388",
    "authors": [
      "Lorenzo Lupo",
      "Marco Dinarelli",
      "Laurent Besacier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.13391",
    "title": "Explaining Translationese: why are Neural Classifiers Better and what do  they Learn?",
    "abstract": "Recent work has shown that neural feature- and representation-learning, e.g. BERT, achieves superior performance over traditional manual feature engineering based approaches, with e.g. SVMs, in translationese classification tasks. Previous research did not show $(i)$ whether the difference is because of the features, the classifiers or both, and $(ii)$ what the neural classifiers actually learn. To address $(i)$, we carefully design experiments that swap features between BERT- and SVM-based classifiers. We show that an SVM fed with BERT representations performs at the level of the best BERT classifiers, while BERT learning and using handcrafted features performs at the level of an SVM using handcrafted features. This shows that the performance differences are due to the features. To address $(ii)$ we use integrated gradients and find that $(a)$ there is indication that information captured by hand-crafted features is only a subset of what BERT learns, and $(b)$ part of BERT's top performance results are due to BERT learning topic differences and spurious correlations with translationese. ",
    "url": "https://arxiv.org/abs/2210.13391",
    "authors": [
      "Kwabena Amponsah-Kaakyire",
      "Daria Pylypenko",
      "Josef van Genabith",
      "Cristina Espa\u00f1a-Bonet"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.13404",
    "title": "Contrastive Representation Learning for Gaze Estimation",
    "abstract": "Self-supervised learning (SSL) has become prevalent for learning representations in computer vision. Notably, SSL exploits contrastive learning to encourage visual representations to be invariant under various image transformations. The task of gaze estimation, on the other hand, demands not just invariance to various appearances but also equivariance to the geometric transformations. In this work, we propose a simple contrastive representation learning framework for gaze estimation, named Gaze Contrastive Learning (GazeCLR). GazeCLR exploits multi-view data to promote equivariance and relies on selected data augmentation techniques that do not alter gaze directions for invariance learning. Our experiments demonstrate the effectiveness of GazeCLR for several settings of the gaze estimation task. Particularly, our results show that GazeCLR improves the performance of cross-domain gaze estimation and yields as high as 17.2% relative improvement. Moreover, the GazeCLR framework is competitive with state-of-the-art representation learning methods for few-shot evaluation. The code and pre-trained models are available at https://github.com/jswati31/gazeclr. ",
    "url": "https://arxiv.org/abs/2210.13404",
    "authors": [
      "Swati Jindal",
      "Roberto Manduchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.13414",
    "title": "Thermodynamics-informed neural networks for physically realistic mixed  reality",
    "abstract": "The imminent impact of immersive technologies in society urges for active research in real-time and interactive physics simulation for virtual worlds to be realistic. In this context, realistic means to be compliant to the laws of physics. In this paper we present a method for computing the dynamic response of (possibly non-linear and dissipative) deformable objects induced by real-time user interactions in mixed reality using deep learning. The graph-based architecture of the method ensures the thermodynamic consistency of the predictions, whereas the visualization pipeline allows a natural and realistic user experience. Two examples of virtual solids interacting with virtual or physical solids in mixed reality scenarios are provided to prove the performance of the method. ",
    "url": "https://arxiv.org/abs/2210.13414",
    "authors": [
      "Quercus Hern\u00e1ndez",
      "Alberto Bad\u00edas",
      "Francisco Chinesta",
      "El\u00edas Cueto"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ]
  },
  {
    "id": "arXiv:2210.13428",
    "title": "PseudoAugment: Learning to Use Unlabeled Data for Data Augmentation in  Point Clouds",
    "abstract": "Data augmentation is an important technique to improve data efficiency and save labeling cost for 3D detection in point clouds. Yet, existing augmentation policies have so far been designed to only utilize labeled data, which limits the data diversity. In this paper, we recognize that pseudo labeling and data augmentation are complementary, thus propose to leverage unlabeled data for data augmentation to enrich the training data. In particular, we design three novel pseudo-label based data augmentation policies (PseudoAugments) to fuse both labeled and pseudo-labeled scenes, including frames (PseudoFrame), objecta (PseudoBBox), and background (PseudoBackground). PseudoAugments outperforms pseudo labeling by mitigating pseudo labeling errors and generating diverse fused training scenes. We demonstrate PseudoAugments generalize across point-based and voxel-based architectures, different model capacity and both KITTI and Waymo Open Dataset. To alleviate the cost of hyperparameter tuning and iterative pseudo labeling, we develop a population-based data augmentation framework for 3D detection, named AutoPseudoAugment. Unlike previous works that perform pseudo-labeling offline, our framework performs PseudoAugments and hyperparameter tuning in one shot to reduce computational cost. Experimental results on the large-scale Waymo Open Dataset show our method outperforms state-of-the-art auto data augmentation method (PPBA) and self-training method (pseudo labeling). In particular, AutoPseudoAugment is about 3X and 2X data efficient on vehicle and pedestrian tasks compared to prior arts. Notably, AutoPseudoAugment nearly matches the full dataset training results, with just 10% of the labeled run segments on the vehicle detection task. ",
    "url": "https://arxiv.org/abs/2210.13428",
    "authors": [
      "Zhaoqi Leng",
      "Shuyang Cheng",
      "Benjamin Caine",
      "Weiyue Wang",
      "Xiao Zhang",
      "Jonathon Shlens",
      "Mingxing Tan",
      "Dragomir Anguelov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13432",
    "title": "FCM: Forgetful Causal Masking Makes Causal Language Models Better  Zero-Shot Learners",
    "abstract": "Large language models (LLM) trained using the next-token-prediction objective, such as GPT3 and PaLM, have revolutionized natural language processing in recent years by showing impressive zero-shot and few-shot capabilities across a wide range of tasks. In this work, we propose a simple technique that significantly boosts the performance of LLMs without adding computational cost. Our key observation is that, by performing the next token prediction task with randomly selected past tokens masked out, we can improve the quality of the learned representations for downstream language understanding tasks. We hypothesize that randomly masking past tokens prevents over-attending to recent tokens and encourages attention to tokens in the distant past. By randomly masking input tokens in the PaLM model, we show that we can significantly improve 1B and 8B PaLM's zero-shot performance on the SuperGLUE benchmark from 55.7 to 59.2 and from 61.6 to 64.0, respectively. Our largest 8B model matches the score of PaLM with an average score of 64, despite the fact that PaLM is trained on a much larger dataset (780B tokens) of high-quality conversation and webpage data, while ours is trained on the smaller C4 dataset (180B tokens). Experimental results show that our method also improves PaLM's zero and few-shot performance on a diverse suite of tasks, including commonsense reasoning, natural language inference and cloze completion. Moreover, we show that our technique also helps representation learning, significantly improving PaLM's finetuning results. ",
    "url": "https://arxiv.org/abs/2210.13432",
    "authors": [
      "Hao Liu",
      "Xinyang Geng",
      "Lisa Lee",
      "Igor Mordatch",
      "Sergey Levine",
      "Sharan Narang",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.13440",
    "title": "Reliability-Aware Prediction via Uncertainty Learning for Person Image  Retrieval",
    "abstract": "Current person image retrieval methods have achieved great improvements in accuracy metrics. However, they rarely describe the reliability of the prediction. In this paper, we propose an Uncertainty-Aware Learning (UAL) method to remedy this issue. UAL aims at providing reliability-aware predictions by considering data uncertainty and model uncertainty simultaneously. Data uncertainty captures the ``noise\" inherent in the sample, while model uncertainty depicts the model's confidence in the sample's prediction. Specifically, in UAL, (1) we propose a sampling-free data uncertainty learning method to adaptively assign weights to different samples during training, down-weighting the low-quality ambiguous samples. (2) we leverage the Bayesian framework to model the model uncertainty by assuming the parameters of the network follow a Bernoulli distribution. (3) the data uncertainty and the model uncertainty are jointly learned in a unified network, and they serve as two fundamental criteria for the reliability assessment: if a probe is high-quality (low data uncertainty) and the model is confident in the prediction of the probe (low model uncertainty), the final ranking will be assessed as reliable. Experiments under the risk-controlled settings and the multi-query settings show the proposed reliability assessment is effective. Our method also shows superior performance on three challenging benchmarks under the vanilla single query settings. ",
    "url": "https://arxiv.org/abs/2210.13440",
    "authors": [
      "Zhaopeng Dou",
      "Zhongdao Wang",
      "Weihua Chen",
      "Yali Li",
      "Shengjin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12158",
    "title": "Graph Coloring via Neural Networks for Haplotype Assembly and Viral  Quasispecies Reconstruction",
    "abstract": "Understanding genetic variation, e.g., through mutations, in organisms is crucial to unravel their effects on the environment and human health. A fundamental characterization can be obtained by solving the haplotype assembly problem, which yields the variation across multiple copies of chromosomes. Variations among fast evolving viruses that lead to different strains (called quasispecies) are also deciphered with similar approaches. In both these cases, high-throughput sequencing technologies that provide oversampled mixtures of large noisy fragments (reads) of genomes, are used to infer constituent components (haplotypes or quasispecies). The problem is harder for polyploid species where there are more than two copies of chromosomes. State-of-the-art neural approaches to solve this NP-hard problem do not adequately model relations among the reads that are important for deconvolving the input signal. We address this problem by developing a new method, called NeurHap, that combines graph representation learning with combinatorial optimization. Our experiments demonstrate substantially better performance of NeurHap in real and synthetic datasets compared to competing approaches. ",
    "url": "https://arxiv.org/abs/2210.12158",
    "authors": [
      "Hansheng Xue",
      "Vaibhav Rajan",
      "Yu Lin"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12161",
    "title": "Task-Based Assessment for Neural Networks: Evaluating Undersampled MRI  Reconstructions based on Human Observer Signal Detection",
    "abstract": "Recent research has explored using neural networks to reconstruct undersampled magnetic resonance imaging (MRI) data. Because of the complexity of the artifacts in the reconstructed images, there is a need to develop task-based approaches of image quality. Common metrics for evaluating image quality like the normalized root mean squared error (NRMSE) and structural similarity (SSIM) are global metrics which average out impact of subtle features in the images. Using measures of image quality which incorporate a subtle signal for a specific task allow for image quality assessment which locally evaluates the effect of undersampling on a signal. We used a U-Net to reconstruct under-sampled images with 2x, 3x, 4x and 5x fold 1-D undersampling rates. Cross validation was performed for a 500 and a 4000 image training set with both structural similarity (SSIM) and mean squared error (MSE) losses. A two alternative forced choice (2-AFC) observer study was carried out for detecting a subtle signal (small blurred disk) from images with the 4000 image training set. We found that for both loss functions and training set sizes, the human observer performance on the 2-AFC studies led to a choice of a 2x undersampling but the SSIM and NRMSE led to a choice of a 3x undersampling. For this task, SSIM and NRMSE led to an overestimate of the achievable undersampling using a U-Net before a steep loss of image quality when compared to the performance of human observers in the detection of a subtle lesion. ",
    "url": "https://arxiv.org/abs/2210.12161",
    "authors": [
      "Joshua D. Herman",
      "Rachel E. Roca",
      "Alexandra G. O'Neill",
      "Marcus L. Wong",
      "Sajan G. Lingala",
      "Angel R. Pineda"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12194",
    "title": "GraphNeT: Graph neural networks for neutrino telescope event  reconstruction",
    "abstract": "GraphNeT is an open-source python framework aimed at providing high quality, user friendly, end-to-end functionality to perform reconstruction tasks at neutrino telescopes using graph neural networks (GNNs). GraphNeT makes it fast and easy to train complex models that can provide event reconstruction with state-of-the-art performance, for arbitrary detector configurations, with inference times that are orders of magnitude faster than traditional reconstruction techniques. GNNs from GraphNeT are flexible enough to be applied to data from all neutrino telescopes, including future projects such as IceCube extensions or P-ONE. This means that GNN-based reconstruction can be used to provide state-of-the-art performance on most reconstruction tasks in neutrino telescopes, at real-time event rates, across experiments and physics analyses, with vast potential impact for neutrino and astro-particle physics. ",
    "url": "https://arxiv.org/abs/2210.12194",
    "authors": [
      "Andreas S\u00f8gaard",
      "Rasmus F. \u00d8rs\u00f8e",
      "Leon Bozianu",
      "Morten Holm",
      "Kaare Endrup Iversen",
      "Tim Guggenmos",
      "Martin Ha Minh",
      "Philipp Eller",
      "Troels C. Petersen"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ]
  },
  {
    "id": "arXiv:2210.12331",
    "title": "Deep Multi-Branch CNN Architecture for Early Alzheimer's Detection from  Brain MRIs",
    "abstract": "Alzheimer's disease (AD) is a neuro-degenerative disease that can cause dementia and result severe reduction in brain function inhibiting simple tasks especially if no preventative care is taken. Over 1 in 9 Americans suffer from AD induced dementia and unpaid care for people with AD related dementia is valued at $271.6 billion. In this paper, we first review other approaches that could be used for early detection of AD. We then give an overview of our dataset that was from the Alzheimer's Disease Neuroimaging Initiative (ADNI) and propose a deep Convolutional Neural Network (CNN) architecture consisting of 7,866,819 parameters. This model has three different length convolutional branches each comprised of different kernel sizes that can predict whether a patient is non-demented, mild-demented, or moderately-demented with a 99.05% three class accuracy. ",
    "url": "https://arxiv.org/abs/2210.12331",
    "authors": [
      "Paul K. Mandal",
      "Rakesh Mahto"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12363",
    "title": "Bayesian Convolutional Deep Sets with Task-Dependent Stationary Prior",
    "abstract": "Convolutional deep sets are the architecture of a deep neural network (DNN) that can model stationary stochastic process. This architecture uses the kernel smoother and the DNN to construct the translation equivariant functional representations, and thus reflects the inductive bias of the stationarity into DNN. However, since this architecture employs the kernel smoother known as the non-parametric model, it may produce ambiguous representations when the number of data points is not given sufficiently. To remedy this issue, we introduce Bayesian convolutional deep sets that construct the random translation equivariant functional representations with stationary prior. Furthermore, we present how to impose the task-dependent prior for each dataset because a wrongly imposed prior forms an even worse representation than that of the kernel smoother. We validate the proposed architecture and its training on various experiments with time-series and image datasets. ",
    "url": "https://arxiv.org/abs/2210.12363",
    "authors": [
      "Yohan Jung",
      "Jinkyoo Park"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2210.12497",
    "title": "Deep Linear Networks for Matrix Completion -- An Infinite Depth Limit",
    "abstract": "The deep linear network (DLN) is a model for implicit regularization in gradient based optimization of overparametrized learning architectures. Training the DLN corresponds to a Riemannian gradient flow, where the Riemannian metric is defined by the architecture of the network and the loss function is defined by the learning task. We extend this geometric framework, obtaining explicit expressions for the volume form, including the case when the network has infinite depth. We investigate the link between the Riemannian geometry and the training asymptotics for matrix completion with rigorous analysis and numerics. We propose that implicit regularization is a result of bias towards high state space volume. ",
    "url": "https://arxiv.org/abs/2210.12497",
    "authors": [
      "Nadav Cohen",
      "Govind Menon",
      "Zsolt Veraszto"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12548",
    "title": "JoJoNet: Joint-contrast and Joint-sampling-and-reconstruction Network  for Multi-contrast MRI",
    "abstract": "Multi-contrast Magnetic Resonance Imaging (MRI) generates multiple medical images with rich and complementary information for routine clinical use; however, it suffers from a long acquisition time. Recent works for accelerating MRI, mainly designed for single contrast, may not be optimal for multi-contrast scenario since the inherent correlations among the multi-contrast images are not exploited. In addition, independent reconstruction of each contrast usually does not translate to optimal performance of downstream tasks. Motivated by these aspects, in this paper we design an end-to-end framework for accelerating multi-contrast MRI which simultaneously optimizes the entire MR imaging workflow including sampling, reconstruction and downstream tasks to achieve the best overall outcomes. The proposed framework consists of a sampling mask generator for each image contrast and a reconstructor exploiting the inter-contrast correlations with a recurrent structure which enables the information sharing in a holistic way. The sampling mask generator and the reconstructor are trained jointly across the multiple image contrasts. The acceleration ratio of each image contrast is also learnable and can be driven by a downstream task performance. We validate our approach on a multi-contrast brain dataset and a multi-contrast knee dataset. Experiments show that (1) our framework consistently outperforms the baselines designed for single contrast on both datasets; (2) our newly designed recurrent reconstruction network effectively improves the reconstruction quality for multi-contrast images; (3) the learnable acceleration ratio improves the downstream task performance significantly. Overall, this work has potentials to open up new avenues for optimizing the entire multi-contrast MR imaging workflow. ",
    "url": "https://arxiv.org/abs/2210.12548",
    "authors": [
      "Lin Zhao",
      "Xiao Chen",
      "Eric Z. Chen",
      "Yikang Liu",
      "Dinggang Shen",
      "Terrence Chen",
      "Shanhui Sun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12578",
    "title": "Feedback Assisted Adversarial Learning to Improve the Quality of  Cone-beam CT Images",
    "abstract": "Unsupervised image translation using adversarial learning has been attracting attention to improve the image quality of medical images. However, adversarial training based on the global evaluation values of discriminators does not provide sufficient translation performance for locally different image features. We propose adversarial learning with a feedback mechanism from a discriminator to improve the quality of CBCT images. This framework employs U-net as the discriminator and outputs a probability map representing the local discrimination results. The probability map is fed back to the generator and used for training to improve the image translation. Our experiments using 76 corresponding CT-CBCT images confirmed that the proposed framework could capture more diverse image features than conventional adversarial learning frameworks and produced synthetic images with pixel values close to the reference image and a correlation coefficient of 0.93. ",
    "url": "https://arxiv.org/abs/2210.12578",
    "authors": [
      "Takumi Hase",
      "Megumi Nakao",
      "Mitsuhiro Nakamura",
      "Tetsuya Matsuda"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12675",
    "title": "The geodesic cover problem for butterfly networks",
    "abstract": "A geodesic cover, also known as an isometric path cover, of a graph is a set of geodesics which cover the vertex set of the graph. An edge geodesic cover of a graph is a set of geodesics which cover the edge set of the graph. The geodesic (edge) cover number of a graph is the cardinality of a minimum (edge) geodesic cover. The (edge) geodesic cover problem of a graph is to find the (edge) geodesic cover number of the graph. Surprisingly, only partial solutions for these problems are available for most situations. In this paper we demonstrate that the geodesic cover number of the $r$-dimensional butterfly is $\\lceil (2/3)2^r\\rceil$ and that its edge geodesic cover number is $2^r$. ",
    "url": "https://arxiv.org/abs/2210.12675",
    "authors": [
      "Paul Manuel",
      "Sandi Klavzar",
      "R. Prabha",
      "Andrew Arokiaraj"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2210.12707",
    "title": "Accelerating the training of single-layer binary neural networks using  the HHL quantum algorithm",
    "abstract": "Binary Neural Networks are a promising technique for implementing efficient deep models with reduced storage and computational requirements. The training of these is however, still a compute-intensive problem that grows drastically with the layer size and data input. At the core of this calculation is the linear regression problem. The Harrow-Hassidim-Lloyd (HHL) quantum algorithm has gained relevance thanks to its promise of providing a quantum state containing the solution of a linear system of equations. The solution is encoded in superposition at the output of a quantum circuit. Although this seems to provide the answer to the linear regression problem for the training neural networks, it also comes with multiple, difficult-to-avoid hurdles. This paper shows, however, that useful information can be extracted from the quantum-mechanical implementation of HHL, and used to reduce the complexity of finding the solution on the classical side. ",
    "url": "https://arxiv.org/abs/2210.12707",
    "authors": [
      "Sonia Lopez Alarcon",
      "Cory Merkel",
      "Martin Hoffnagle",
      "Sabrina Ly",
      "Alejandro Pozas-Kerstjens"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12731",
    "title": "Joint Rigid Motion Correction and Sparse-View CT via Self-Calibrating  Neural Field",
    "abstract": "Neural Radiance Field (NeRF) has widely received attention in Sparse-View (SV) CT reconstruction problems as a self-supervised deep learning framework. NeRF-based SVCT methods model the desired CT image as a continuous function that maps coordinates to intensities and then train a Multi-Layer Perceptron (MLP) to learn the function by minimizing loss on the SV measurement. Thanks to the continuous representation provided by NeRF, the function can be approximated well and thus the high-quality CT image is reconstructed. However, existing NeRF-based SVCT methods strictly suppose there is completely no relative motion during the CT acquisition because they require accurate projection poses to simulate the X-rays that scan the SV sinogram. Therefore, these methods suffer from severe performance drops for real SVCT imaging with motion. To this end, this work proposes a self-calibrating neural field that recovers the artifacts-free image from the rigid motion-corrupted SV measurement without using any external data. Specifically, we parametrize the coarse projection poses caused by rigid motion as trainable variables and then jointly optimize these variables and the MLP. We perform numerical experiments on a public COVID-19 CT dataset. The results indicate that our model significantly outperforms two latest NeRF-based methods for SVCT reconstruction with four different levels of rigid motion. ",
    "url": "https://arxiv.org/abs/2210.12731",
    "authors": [
      "Qing Wu",
      "Xin Li",
      "Hongjiang Wei",
      "Jingyi Yu",
      "Yuyao Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12740",
    "title": "HiFi-WaveGAN: Generative Adversarial Network with Auxiliary  Spectrogram-Phase Loss for High-Fidelity Singing Voice Generation",
    "abstract": "Entertainment-oriented singing voice synthesis (SVS) requires a vocoder to generate high-fidelity (e.g. 48kHz) audio. However, most text-to-speech (TTS) vocoders cannot work well in this scenario even if the neural vocoder for TTS has achieved significant progress. In this paper, we propose HiFi-WaveGAN which is designed for synthesizing the 48kHz high-quality singing voices from the full-band mel-spectrogram in real-time. Specifically, it consists of a generator improved from WaveNet, a multi-period discriminator same to HiFiGAN, and a multi-resolution spectrogram discriminator borrowed from UnivNet. To better reconstruct the high-frequency part from the full-band mel-spectrogram, we design a novel auxiliary spectrogram-phase loss to train the neural network, which can also accelerate the training process. The experimental result shows that our proposed HiFi-WaveGAN significantly outperforms other neural vocoders such as Parallel WaveGAN (PWG) and HiFiGAN in the mean opinion score (MOS) metric for the 48kHz SVS task. And a comparative study of HiFi-WaveGAN with/without phase loss term proves that phase loss indeed improves the training speed. Besides, we also compare the spectrogram generated by our HiFi-WaveGAN and PWG, which shows our HiFi-WaveGAN has a more powerful ability to model the high-frequency parts. ",
    "url": "https://arxiv.org/abs/2210.12740",
    "authors": [
      "Chunhui Wang",
      "Chang Zeng",
      "Xing He"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.12767",
    "title": "Falsehoods that ML researchers believe about OOD detection",
    "abstract": "Modelling the density $p(x)$ by probabilistic generative models is an intuitive way to detect out-of-distribution (OOD) data, but it fails in the deep learning context. In this paper, we list some falsehoods that machine learning researchers believe about density-based OOD detection. Many recent works have proposed likelihood-ratio-based methods to `fix' this issue. We propose a framework, the OOD proxy framework, to unify these methods, and we argue that likelihood ratio is a principled method for OOD detection and not a mere `fix'. Finally, we discuss the relationship between domain detection and semantics. ",
    "url": "https://arxiv.org/abs/2210.12767",
    "authors": [
      "Andi Zhang",
      "Damon Wischik"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12791",
    "title": "O-type Stars Stellar Parameter Estimation Using Recurrent Neural  Networks",
    "abstract": "In this paper, we present a deep learning system approach to estimating luminosity, effective temperature, and surface gravity of O-type stars using the optical region of the stellar spectra. In previous work, we compare a set of machine learning and deep learning algorithms in order to establish a reliable way to fit a stellar model using two methods: the classification of the stellar spectra models and the estimation of the physical parameters in a regression-type task. Here we present the process to estimate individual physical parameters from an artificial neural network perspective with the capacity to handle stellar spectra with a low signal-to-noise ratio (S/N), in the $<$20 S/N boundaries. The development of three different recurrent neural network systems, the training process using stellar spectra models, the test over nine different observed stellar spectra, and the comparison with estimations in previous works are presented. Additionally, characterization methods for stellar spectra in order to reduce the dimensionality of the input data for the system and optimize the computational resources are discussed. ",
    "url": "https://arxiv.org/abs/2210.12791",
    "authors": [
      "Miguel Flores R.",
      "Luis J. Corral",
      "Celia R. Fierro-Santill\u00e1n",
      "Silvana G. Navarro"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12869",
    "title": "Robust Hypothesis Testing with Moment Constrained Uncertainty Sets",
    "abstract": "The problem of robust binary hypothesis testing is studied. Under both hypotheses, the data-generating distributions are assumed to belong to uncertainty sets constructed through moments; in particular, the sets contain distributions whose moments are centered around the empirical moments obtained from training samples. The goal is to design a test that performs well under all distributions in the uncertainty sets, i.e., minimize the worst-case error probability over the uncertainty sets. In the finite-alphabet case, the optimal test is obtained. In the infinite-alphabet case, a tractable approximation to the worst-case error is derived that converges to the optimal value using finite samples from the alphabet. A test is further constructed to generalize to the entire alphabet. An exponentially consistent test for testing batch samples is also proposed. Numerical results are provided to demonstrate the performance of the proposed robust tests. ",
    "url": "https://arxiv.org/abs/2210.12869",
    "authors": [
      "Akshayaa Magesh",
      "Zhongchang Sun",
      "Venugopal V. Veeravalli",
      "Shaofeng Zou"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.12884",
    "title": "Computing the minimum distance of the $C(\\mathbb{O}_{3,6})$ polar  Orthogonal Grassmann code with elementary methods",
    "abstract": "The polar orthogonal Grassmann code $C(\\mathbb{O}_{3,6})$ is the linear code associated to the Grassmann embedding of the Dual Polar space of $Q^+(5,q)$. In this manuscript we study the minimum distance of this embedding. We prove that the minimum distance of the polar orthogonal Grassmann code $C(\\mathbb{O}_{3,6})$ is $q^3-q^3$ for $q$ odd and $q^3$ for $q$ even. Our technique is based on partitioning the orthogonal space into different sets such that on each partition the code $C(\\mathbb{O}_{3,6})$ is identified with evaluations of determinants of skew--symmetric matrices. Our bounds come from elementary algebraic methods counting the zeroes of particular classes of polynomials. We expect our techniques may be applied to other polar Grassmann codes. ",
    "url": "https://arxiv.org/abs/2210.12884",
    "authors": [
      "Sarah Gregory",
      "Fernando Pi\u00f1ero-Gonz\u00e1lez",
      "Doel Rivera-Laboy",
      "Lani Southern"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)",
      "Algebraic Geometry (math.AG)"
    ]
  },
  {
    "id": "arXiv:2210.13012",
    "title": "CMU-Net: A Strong ConvMixer-based Medical Ultrasound Image Segmentation  Network",
    "abstract": "U-Net and its extended segmentation model have achieved great success in medical image segmentation tasks. However, due to the inherent local characteristics of ordinary convolution operations, the encoder cannot effectively extract the global context information. In addition, simple skip connection cannot capture salient features. In this work, we propose a full convolutional segmentation network (CMU-Net) which incorporate hybrid convolution and multi-scale attention gate. The ConvMixer module is to mix distant spatial locations for extracting the global context information. Moreover, the multi-scale attention gate can help to emphasize valuable features and achieve efficient skip connections. Evaluations on open-source breast ultrasound images and private thyroid ultrasound image datasets show that CMU-Net achieves an average IOU of 73.27% and 84.75%, F1-value is 84.16% and 91.71%. The code is available at https://github.com/FengheTan9/CMU-Net. ",
    "url": "https://arxiv.org/abs/2210.13012",
    "authors": [
      "Fenghe Tang",
      "Lingtao Wang",
      "Chunping Ning",
      "Min Xian",
      "Jianrui Ding"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13144",
    "title": "Weak-Supervised Dysarthria-invariant Features for Spoken Language  Understanding using an FHVAE and Adversarial Training",
    "abstract": "The scarcity of training data and the large speaker variation in dysarthric speech lead to poor accuracy and poor speaker generalization of spoken language understanding systems for dysarthric speech. Through work on the speech features, we focus on improving the model generalization ability with limited dysarthric data. Factorized Hierarchical Variational Auto-Encoders (FHVAE) trained unsupervisedly have shown their advantage in disentangling content and speaker representations. Earlier work showed that the dysarthria shows in both feature vectors. Here, we add adversarial training to bridge the gap between the control and dysarthric speech data domains. We extract dysarthric and speaker invariant features using weak supervision. The extracted features are evaluated on a Spoken Language Understanding task and yield a higher accuracy on unseen speakers with more severe dysarthria compared to features from the basic FHVAE model or plain filterbanks. ",
    "url": "https://arxiv.org/abs/2210.13144",
    "authors": [
      "Jinzi Qi",
      "Hugo Van hamme"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.13206",
    "title": "Multiplicity-adjusted bootstrap tilting lower confidence bounds for  conditional prediction performance measures",
    "abstract": "In machine learning, the selection of a promising model from a potentially large number of competing models and the assessment of its generalization performance are critical tasks that need careful consideration. Typically, model selection and evaluation are strictly separated endeavors, splitting the sample at hand into a training, validation, and evaluation set, and only compute a single confidence interval for the prediction performance of the final selected model. We however propose an algorithm how to compute valid lower confidence bounds for multiple models that have been selected based on their prediction performances in the evaluation set by interpreting the selection problem as a simultaneous inference problem. We use bootstrap tilting and a maxT-type multiplicity correction. The approach is universally applicable for any combination of prediction models, any model selection strategy, and any prediction performance measure that accepts weights. We conducted various simulation experiments which show that our proposed approach yields lower confidence bounds that are at least comparably good as bounds from standard approaches, and that reliably reach the nominal coverage probability. In addition, especially when sample size is small, our proposed approach yields better performing prediction models than the default selection of only one model for evaluation does. ",
    "url": "https://arxiv.org/abs/2210.13206",
    "authors": [
      "Pascal Rink",
      "Werner Brannath"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13271",
    "title": "ECG Artifact Removal from Single-Channel Surface EMG Using Fully  Convolutional Networks",
    "abstract": "Electrocardiogram (ECG) artifact contamination often occurs in surface electromyography (sEMG) applications when the measured muscles are in proximity to the heart. Previous studies have developed and proposed various methods, such as high-pass filtering, template subtraction and so forth. However, these methods remain limited by the requirement of reference signals and distortion of original sEMG. This study proposed a novel denoising method to eliminate ECG artifacts from the single-channel sEMG signals using fully convolutional networks (FCN). The proposed method adopts a denoise autoencoder structure and powerful nonlinear mapping capability of neural networks for sEMG denoising. We compared the proposed approach with conventional approaches, including high-pass filters and template subtraction, on open datasets called the Non-Invasive Adaptive Prosthetics database and MIT-BIH normal sinus rhythm database. The experimental results demonstrate that the FCN outperforms conventional methods in sEMG reconstruction quality under a wide range of signal-to-noise ratio inputs. ",
    "url": "https://arxiv.org/abs/2210.13271",
    "authors": [
      "Kuan-Chen Wang",
      "Kai-Chun Liu",
      "Sheng-Yu Peng",
      "Yu Tsao"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13300",
    "title": "Designing Universal Causal Deep Learning Models: The Case of  Infinite-Dimensional Dynamical Systems from Stochastic Analysis",
    "abstract": "Deep learning (DL) is becoming indispensable to contemporary stochastic analysis and finance; nevertheless, it is still unclear how to design a principled DL framework for approximating infinite-dimensional causal operators. This paper proposes a \"geometry-aware\" solution to this open problem by introducing a DL model-design framework that takes a suitable infinite-dimensional linear metric spaces as inputs and returns a universal sequential DL models adapted to these linear geometries: we call these models Causal Neural Operators (CNO). Our main result states that the models produced by our framework can uniformly approximate on compact sets and across arbitrarily finite-time horizons H\\\"older or smooth trace class operators which causally map sequences between given linear metric spaces. Consequentially, we deduce that a single CNO can efficiently approximate the solution operator to a broad range of SDEs, thus allowing us to simultaneously approximate predictions from families of SDE models, which is vital to computational robust finance. We deduce that the CNO can approximate the solution operator to most stochastic filtering problems, implying that a single CNO can simultaneously filter a family of partially observed stochastic volatility models. ",
    "url": "https://arxiv.org/abs/2210.13300",
    "authors": [
      "Luca Galimberti",
      "Giulia Livieri",
      "Anastasis Kratsios"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)"
    ]
  },
  {
    "id": "arXiv:2210.13318",
    "title": "Time-Domain Speech Enhancement for Robust Automatic Speech Recognition",
    "abstract": "It has been shown that the intelligibility of noisy speech can be improved by speech enhancement algorithms. However, speech enhancement has not been established as an effective front-end for robust automatic speech recognition (ASR) in comparison with an ASR model trained on noisy speech directly. The divide between speech enhancement and ASR impedes the progress of robust ASR systems especially as speech enhancement has made big strides in recent years. In this work, we focus on eliminating such divide with an ARN (attentive recurrent network) based time-domain enhancement model. The proposed system fully decouples speech enhancement and an acoustic model trained only on clean speech. Results on the CHiME-2 corpus show that ARN enhanced speech translates to improved ASR results. The proposed system achieves $6.28\\%$ average word error rate, outperforming the previous best by $19.3\\%$. ",
    "url": "https://arxiv.org/abs/2210.13318",
    "authors": [
      "Yufeng Yang",
      "Ashutosh Pandey",
      "DeLiang Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.13327",
    "title": "Deep Kronecker Network",
    "abstract": "We propose Deep Kronecker Network (DKN), a novel framework designed for analyzing medical imaging data, such as MRI, fMRI, CT, etc. Medical imaging data is different from general images in at least two aspects: i) sample size is usually much more limited, ii) model interpretation is more of a concern compared to outcome prediction. Due to its unique nature, general methods, such as convolutional neural network (CNN), are difficult to be directly applied. As such, we propose DKN, that is able to i) adapt to low sample size limitation, ii) provide desired model interpretation, and iii) achieve the prediction power as CNN. The DKN is general in the sense that it not only works for both matrix and (high-order) tensor represented image data, but also could be applied to both discrete and continuous outcomes. The DKN is built on a Kronecker product structure and implicitly imposes a piecewise smooth property on coefficients. Moreover, the Kronecker structure can be written into a convolutional form, so DKN also resembles a CNN, particularly, a fully convolutional network (FCN). Furthermore, we prove that with an alternating minimization algorithm, the solutions of DKN are guaranteed to converge to the truth geometrically even if the objective function is highly nonconvex. Interestingly, the DKN is also highly connected to the tensor regression framework proposed by Zhou et al. (2010), where a CANDECOMP/PARAFAC (CP) low-rank structure is imposed on tensor coefficients. Finally, we conduct both classification and regression analyses using real MRI data from the Alzheimer's Disease Neuroimaging Initiative (ADNI) to demonstrate the effectiveness of DKN. ",
    "url": "https://arxiv.org/abs/2210.13327",
    "authors": [
      "Long Feng",
      "Guang Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13379",
    "title": "Ranking nodes in directed networks via continuous-time quantum walks",
    "abstract": "Four new centrality measures for directed networks based on unitary, continuous-time quantum walks (CTQW) in $n$ dimensions -- where $n$ is the number of nodes -- are presented, tested and discussed. The main idea behind these methods consists in re-casting the classical HITS and PageRank algorithms as eigenvector problems for symmetric matrices, and using these symmetric matrices as Hamiltonians for CTQWs, in order to obtain a unitary evolution operator. The choice of the initial state is also crucial. Two options were tested: a vector with uniform occupation and a vector weighted w.r.t.~in- or out-degrees (for authority and hub centrality, respectively). Two methods are based on a HITS-derived Hamiltonian, and two use a PageRank-derived Hamiltonian. Centrality scores for the nodes are defined as the average occupation values. All the methods have been tested on a set of small, simple graphs in order to spot possible evident drawbacks, and then on a larger number of artificially generated larger-sized graphs, in order to draw a comparison with classical HITS and PageRank. Numerical results show that, despite some pathologies found in three of the methods when analyzing small graphs, all the methods are effective in finding the first and top ten nodes in larger graphs. We comment on the results and offer some insight into the good accordance between classical and quantum approaches. ",
    "url": "https://arxiv.org/abs/2210.13379",
    "authors": [
      "Paola Boito",
      "Roberto Grena"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.13430",
    "title": "Data-Driven Stabilizing and Robust Control of Discrete-Time Linear  Systems with Error in Variables",
    "abstract": "This work presents a sum-of-squares (SOS) based framework to perform data-driven stabilization and robust control tasks on discrete-time linear systems where the full-state observations are corrupted by L-infinity bounded measurement noise (error in variable setting). Certificates of state-feedback superstability or quadratic stability of all plants in a consistency set are provided by solving a feasibility program formed by polynomial nonnegativity constraints. Under mild compactness and data-collection assumptions, SOS tightenings in rising degree will converge to recover the true superstabilizing controller, with slight conservatism introduced for quadratic stabilizability. The performance of this SOS method is improved through the application of a theorem of alternatives while retaining tightness, in which the unknown noise variables are eliminated from the consistency set description. This SOS feasibility method is extended to provide worst-case-optimal robust controllers under H2 control costs. The consistency set description may be broadened to include cases where the data and process are affected by a combination of L-infinity bounded measurement, process, and input noise. Further generalizations include varying noise sets, non-uniform sampling, and switched systems stabilization. ",
    "url": "https://arxiv.org/abs/2210.13430",
    "authors": [
      "Jared Miller",
      "Tianyu Dai",
      "Mario Sznaier"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2210.13438",
    "title": "High Fidelity Neural Audio Compression",
    "abstract": "We introduce a state-of-the-art real-time, high-fidelity, audio codec leveraging neural networks. It consists in a streaming encoder-decoder architecture with quantized latent space trained in an end-to-end fashion. We simplify and speed-up the training by using a single multiscale spectrogram adversary that efficiently reduces artifacts and produce high-quality samples. We introduce a novel loss balancer mechanism to stabilize training: the weight of a loss now defines the fraction of the overall gradient it should represent, thus decoupling the choice of this hyper-parameter from the typical scale of the loss. Finally, we study how lightweight Transformer models can be used to further compress the obtained representation by up to 40%, while staying faster than real time. We provide a detailed description of the key design choices of the proposed model including: training objective, architectural changes and a study of various perceptual loss functions. We present an extensive subjective evaluation (MUSHRA tests) together with an ablation study for a range of bandwidths and audio domains, including speech, noisy-reverberant speech, and music. Our approach is superior to the baselines methods across all evaluated settings, considering both 24 kHz monophonic and 48 kHz stereophonic audio. Code and models are available at github.com/facebookresearch/encodec. ",
    "url": "https://arxiv.org/abs/2210.13438",
    "authors": [
      "Alexandre D\u00e9fossez",
      "Jade Copet",
      "Gabriel Synnaeve",
      "Yossi Adi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:1606.04671",
    "title": "Progressive Neural Networks",
    "abstract": " Title: Progressive Neural Networks ",
    "url": "https://arxiv.org/abs/1606.04671",
    "authors": [
      "Andrei A. Rusu",
      "Neil C. Rabinowitz",
      "Guillaume Desjardins",
      "Hubert Soyer",
      "James Kirkpatrick",
      "Koray Kavukcuoglu",
      "Razvan Pascanu",
      "Raia Hadsell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1903.09668",
    "title": "Data Augmentation for Bayesian Deep Learning",
    "abstract": " Title: Data Augmentation for Bayesian Deep Learning ",
    "url": "https://arxiv.org/abs/1903.09668",
    "authors": [
      "Yuexi Wang",
      "Nicholas G. Polson",
      "Vadim O. Sokolov"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:1911.03867",
    "title": "A Modular Deep Learning Pipeline for Galaxy-Scale Strong Gravitational  Lens Detection and Modeling",
    "abstract": " Title: A Modular Deep Learning Pipeline for Galaxy-Scale Strong Gravitational  Lens Detection and Modeling ",
    "url": "https://arxiv.org/abs/1911.03867",
    "authors": [
      "Sandeep Madireddy",
      "Nesar Ramachandra",
      "Nan Li",
      "James Butler",
      "Prasanna Balaprakash",
      "Salman Habib",
      "Katrin Heitmann",
      "LSST Dark Energy Science Collaboration"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2101.07354",
    "title": "Exact Recovery of Community Structures Using DeepWalk and Node2vec",
    "abstract": " Title: Exact Recovery of Community Structures Using DeepWalk and Node2vec ",
    "url": "https://arxiv.org/abs/2101.07354",
    "authors": [
      "Yichi Zhang",
      "Minh Tang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2104.11893",
    "title": "LGD-GCN: Local and Global Disentangled Graph Convolutional Networks",
    "abstract": " Title: LGD-GCN: Local and Global Disentangled Graph Convolutional Networks ",
    "url": "https://arxiv.org/abs/2104.11893",
    "authors": [
      "Jingwei Guo",
      "Kaizhu Huang",
      "Xinping Yi",
      "Rui Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2106.11696",
    "title": "Diversity-aware $k$-median : Clustering with fair center representation",
    "abstract": " Comments: To appear in ECML-PKDD 2021 ",
    "url": "https://arxiv.org/abs/2106.11696",
    "authors": [
      "Suhas Thejaswi",
      "Bruno Ordozgoiti",
      "Aristides Gionis"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2107.06093",
    "title": "A generalized hypothesis test for community structure in networks",
    "abstract": " Title: A generalized hypothesis test for community structure in networks ",
    "url": "https://arxiv.org/abs/2107.06093",
    "authors": [
      "Eric Yanchenko",
      "Srijan Sengupta"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2109.04381",
    "title": "Copy-Move Image Forgery Detection Based on Evolving Circular Domains  Coverage",
    "abstract": " Comments: Accepted by Multimedia Tools and Applications ",
    "url": "https://arxiv.org/abs/2109.04381",
    "authors": [
      "Shilin Lu",
      "Xinghong Hu",
      "Chengyou Wang",
      "Lu Chen",
      "Shulu Han",
      "Yuejia Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2110.09902",
    "title": "Toward Understanding Convolutional Neural Networks from Volterra  Convolution Perspective",
    "abstract": " Title: Toward Understanding Convolutional Neural Networks from Volterra  Convolution Perspective ",
    "url": "https://arxiv.org/abs/2110.09902",
    "authors": [
      "Tenghui Li",
      "Guoxu Zhou",
      "Yuning Qiu",
      "Qibin Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.04871",
    "title": "KGE-CL: Contrastive Learning of Tensor Decomposition Based Knowledge  Graph Embeddings",
    "abstract": " Title: KGE-CL: Contrastive Learning of Tensor Decomposition Based Knowledge  Graph Embeddings ",
    "url": "https://arxiv.org/abs/2112.04871",
    "authors": [
      "Zhiping Luo",
      "Wentao Xu",
      "Weiqing Liu",
      "Jiang Bian",
      "Jian Yin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2112.05567",
    "title": "An Annotation-based Approach for Finding Bugs in Neural Network Programs",
    "abstract": " Comments: New experiments added (lots of new content) ",
    "url": "https://arxiv.org/abs/2112.05567",
    "authors": [
      "Mohammad Rezaalipour",
      "Carlo A. Furia"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ]
  },
  {
    "id": "arXiv:2201.01443",
    "title": "Neural KEM: A Kernel Method with Deep Coefficient Prior for PET Image  Reconstruction",
    "abstract": " Comments: arXiv admin note: text overlap with arXiv:2110.01174 ",
    "url": "https://arxiv.org/abs/2201.01443",
    "authors": [
      "Siqi Li",
      "Kuang Gong",
      "Ramsey D. Badawi",
      "Edward J. Kim",
      "Jinyi Qi",
      "Guobao Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2201.02009",
    "title": "PAEG: Phrase-level Adversarial Example Generation for Neural Machine  Translation",
    "abstract": " Comments: 13 pages ",
    "url": "https://arxiv.org/abs/2201.02009",
    "authors": [
      "Juncheng Wan",
      "Jian Yang",
      "Shuming Ma",
      "Dongdong Zhang",
      "Weinan Zhang",
      "Yong Yu",
      "Zhoujun Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2201.08193",
    "title": "TextHacker: Learning based Hybrid Local Search Algorithm for Text  Hard-label Adversarial Attack",
    "abstract": " Comments: Accepted by EMNLP 2022 Findings, Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2201.08193",
    "authors": [
      "Zhen Yu",
      "Xiaosen Wang",
      "Wanxiang Che",
      "Kun He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2201.13086",
    "title": "Securing Federated Sensitive Topic Classification against Poisoning  Attacks",
    "abstract": " Title: Securing Federated Sensitive Topic Classification against Poisoning  Attacks ",
    "url": "https://arxiv.org/abs/2201.13086",
    "authors": [
      "Tianyue Chu",
      "Alvaro Garcia-Recuero",
      "Costas Iordanou",
      "Georgios Smaragdakis",
      "Nikolaos Laoutaris"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2202.00293",
    "title": "Phase diagram of Stochastic Gradient Descent in high-dimensional  two-layer neural networks",
    "abstract": " Comments: 28 pages ",
    "url": "https://arxiv.org/abs/2202.00293",
    "authors": [
      "Rodrigo Veiga",
      "Ludovic Stephan",
      "Bruno Loureiro",
      "Florent Krzakala",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.02947",
    "title": "Parallel Successive Learning for Dynamic Distributed Model Training over  Heterogeneous Wireless Networks",
    "abstract": " Title: Parallel Successive Learning for Dynamic Distributed Model Training over  Heterogeneous Wireless Networks ",
    "url": "https://arxiv.org/abs/2202.02947",
    "authors": [
      "Seyyedali Hosseinalipour",
      "Su Wang",
      "Nicolo Michelusi",
      "Vaneet Aggarwal",
      "Christopher G. Brinton",
      "David J. Love",
      "Mung Chiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2202.11479",
    "title": "Listen to Interpret: Post-hoc Interpretability for Audio Networks with  NMF",
    "abstract": " Comments: Accepted at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2202.11479",
    "authors": [
      "Jayneel Parekh",
      "Sanjeel Parekh",
      "Pavlo Mozharovskyi",
      "Florence d'Alch\u00e9-Buc",
      "Ga\u00ebl Richard"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2202.12459",
    "title": "APEACH: Attacking Pejorative Expressions with Analysis on  Crowd-Generated Hate Speech Evaluation Datasets",
    "abstract": " Comments: 11pages, 6 figures ",
    "url": "https://arxiv.org/abs/2202.12459",
    "authors": [
      "Kichang Yang",
      "Wonjun Jang",
      "Won Ik Cho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.08118",
    "title": "Representation Learning for Resource-Constrained Keyphrase Generation",
    "abstract": " Comments: EMNLP 2022 (Findings) ",
    "url": "https://arxiv.org/abs/2203.08118",
    "authors": [
      "Di Wu",
      "Wasi Uddin Ahmad",
      "Sunipa Dev",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2203.13530",
    "title": "Multimodal Pre-training Based on Graph Attention Network for Document  Understanding",
    "abstract": " Title: Multimodal Pre-training Based on Graph Attention Network for Document  Understanding ",
    "url": "https://arxiv.org/abs/2203.13530",
    "authors": [
      "Zhenrong Zhang",
      "Jiefeng Ma",
      "Jun Du",
      "Licheng Wang",
      "Jianshu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.05289",
    "title": "Towards Online Domain Adaptive Object Detection",
    "abstract": " Comments: Accepted to WACV 2023 ",
    "url": "https://arxiv.org/abs/2204.05289",
    "authors": [
      "Vibashan VS",
      "Poojan Oza",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.07667",
    "title": "Just Fine-tune Twice: Selective Differential Privacy for Large Language  Models",
    "abstract": " Comments: EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2204.07667",
    "authors": [
      "Weiyan Shi",
      "Ryan Shea",
      "Si Chen",
      "Chiyuan Zhang",
      "Ruoxi Jia",
      "Zhou Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2204.10293",
    "title": "A Hierarchical N-Gram Framework for Zero-Shot Link Prediction",
    "abstract": " Comments: Published as a conference paper at EMNLP Findings 2022 ",
    "url": "https://arxiv.org/abs/2204.10293",
    "authors": [
      "Mingchen Li",
      "Junfan Chen",
      "Samuel Mensah",
      "Nikolaos Aletras",
      "Xiulong Yang",
      "Yang Ye"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2204.11824",
    "title": "Semi-Parametric Neural Image Synthesis",
    "abstract": " Comments: NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2204.11824",
    "authors": [
      "Andreas Blattmann",
      "Robin Rombach",
      "Kaan Oktay",
      "Jonas M\u00fcller",
      "Bj\u00f6rn Ommer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2204.13221",
    "title": "TranSHER: Translating Knowledge Graph Embedding with Hyper-Ellipsoidal  Restriction",
    "abstract": " Comments: EMNLP 2022. v2 updated for EMNLP camera-ready ",
    "url": "https://arxiv.org/abs/2204.13221",
    "authors": [
      "Yizhi Li",
      "Wei Fan",
      "Chao Liu",
      "Chenghua Lin",
      "Jiang Qian"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2204.14017",
    "title": "Backdoor Attacks in Federated Learning by Rare Embeddings and Gradient  Ensembling",
    "abstract": " Comments: Accepted to EMNLP 2022, 9 pages and Appendix ",
    "url": "https://arxiv.org/abs/2204.14017",
    "authors": [
      "KiYoon Yoo",
      "Nojun Kwak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.00165",
    "title": "NeuralEF: Deconstructing Kernels by Deep Neural Networks",
    "abstract": " Comments: International Conference on Machine Learning (ICML), 2022 ",
    "url": "https://arxiv.org/abs/2205.00165",
    "authors": [
      "Zhijie Deng",
      "Jiaxin Shi",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.00968",
    "title": "Detection Recovery in Online Multi-Object Tracking with Sparse Graph  Tracker",
    "abstract": " Comments: Accepted to WACV 2023 ",
    "url": "https://arxiv.org/abs/2205.00968",
    "authors": [
      "Jeongseok Hyun",
      "Myunggu Kang",
      "Dongyoon Wee",
      "Dit-Yan Yeung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.03116",
    "title": "Longitudinal cardio-respiratory fitness prediction through wearables in  free-living environments",
    "abstract": " Comments: Accepted in Nature Digital Medicine, 16 pages ",
    "url": "https://arxiv.org/abs/2205.03116",
    "authors": [
      "Dimitris Spathis",
      "Ignacio Perez-Pozuelo",
      "Tomas I. Gonzales",
      "Yu Wu",
      "Soren Brage",
      "Nicholas Wareham",
      "Cecilia Mascolo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.09076",
    "title": "On the complexity of recognizing Stick, BipHook and Max Point-Tolerance  graphs",
    "abstract": " Comments: 24 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2205.09076",
    "authors": [
      "Irena Rusu"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ]
  },
  {
    "id": "arXiv:2205.09612",
    "title": "CLCNet: Rethinking of Ensemble Modeling with Classification Confidence  Network",
    "abstract": " Title: CLCNet: Rethinking of Ensemble Modeling with Classification Confidence  Network ",
    "url": "https://arxiv.org/abs/2205.09612",
    "authors": [
      "Yao-Ching Yu",
      "Shi-Jinn Horng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.13496",
    "title": "Censored Quantile Regression Neural Networks for Distribution-Free  Survival Analysis",
    "abstract": " Title: Censored Quantile Regression Neural Networks for Distribution-Free  Survival Analysis ",
    "url": "https://arxiv.org/abs/2205.13496",
    "authors": [
      "Tim Pearce",
      "Jong-Hyeon Jeong",
      "Yichen Jia",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.14094",
    "title": "Failure Detection in Medical Image Classification: A Reality Check and  Benchmarking Testbed",
    "abstract": " Comments: Published in Transactions on Machine Learning Research (10/2022) ",
    "url": "https://arxiv.org/abs/2205.14094",
    "authors": [
      "Melanie Bernhardt",
      "Fabio De Sousa Ribeiro",
      "Ben Glocker"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2205.15234",
    "title": "Few-Shot Adaptation of Pre-Trained Networks for Domain Shift",
    "abstract": " Comments: Accepted to IJCAI 2022 ",
    "url": "https://arxiv.org/abs/2205.15234",
    "authors": [
      "Wenyu Zhang",
      "Li Shen",
      "Wanyue Zhang",
      "Chuan-Sheng Foo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.15466",
    "title": "Data Banzhaf: A Robust Data Valuation Framework for Machine Learning",
    "abstract": " Title: Data Banzhaf: A Robust Data Valuation Framework for Machine Learning ",
    "url": "https://arxiv.org/abs/2205.15466",
    "authors": [
      "Jiachen T. Wang",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2205.15827",
    "title": "Robust Anytime Learning of Markov Decision Processes",
    "abstract": " Comments: Accepted at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2205.15827",
    "authors": [
      "Marnix Suilen",
      "Thiago D. Sim\u00e3o",
      "David Parker",
      "Nils Jansen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.15947",
    "title": "Evaluating Robustness to Dataset Shift via Parametric Robustness Sets",
    "abstract": " Comments: NeurIPS 2022; Equal Contribution by Nikolaj/Michael, order determined by coin flip ",
    "url": "https://arxiv.org/abs/2205.15947",
    "authors": [
      "Nikolaj Thams",
      "Michael Oberst",
      "David Sontag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.00274",
    "title": "Point-Teaching: Weakly Semi-Supervised Object Detection with Point  Annotations",
    "abstract": " Title: Point-Teaching: Weakly Semi-Supervised Object Detection with Point  Annotations ",
    "url": "https://arxiv.org/abs/2206.00274",
    "authors": [
      "Yongtao Ge",
      "Qiang Zhou",
      "Xinlong Wang",
      "Zhibin Wang",
      "Hao Li",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.00719",
    "title": "Dataset Distillation using Neural Feature Regression",
    "abstract": " Comments: NeurIPS 2022 camera-ready version ",
    "url": "https://arxiv.org/abs/2206.00719",
    "authors": [
      "Yongchao Zhou",
      "Ehsan Nezhadarya",
      "Jimmy Ba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.01520",
    "title": "A Survey on Computationally Efficient Neural Architecture Search",
    "abstract": " Comments: 20 pages, 7 figures ",
    "url": "https://arxiv.org/abs/2206.01520",
    "authors": [
      "Shiqing Liu",
      "Haoyu Zhang",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2206.01900",
    "title": "Estimating counterfactual treatment outcomes over time in complex  multi-agent scenarios",
    "abstract": " Comments: 13 pages, 6 figures. Part of this paper will be presented in SIGSPATIAL 2022 ",
    "url": "https://arxiv.org/abs/2206.01900",
    "authors": [
      "Keisuke Fujii",
      "Koh Takeuchi",
      "Atsushi Kuribayashi",
      "Naoya Takeishi",
      "Yoshinobu Kawahara",
      "Kazuya Takeda"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.02829",
    "title": "RORL: Robust Offline Reinforcement Learning via Conservative Smoothing",
    "abstract": " Comments: Accepted by Advances in Neural Information Processing Systems (NeurIPS) 2022 ",
    "url": "https://arxiv.org/abs/2206.02829",
    "authors": [
      "Rui Yang",
      "Chenjia Bai",
      "Xiaoteng Ma",
      "Zhaoran Wang",
      "Chongjie Zhang",
      "Lei Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.04777",
    "title": "Trimmed Maximum Likelihood Estimation for Robust Learning in Generalized  Linear Models",
    "abstract": " Title: Trimmed Maximum Likelihood Estimation for Robust Learning in Generalized  Linear Models ",
    "url": "https://arxiv.org/abs/2206.04777",
    "authors": [
      "Pranjal Awasthi",
      "Abhimanyu Das",
      "Weihao Kong",
      "Rajat Sen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.05904",
    "title": "Superiority of GNN over NN in generalizing bandlimited functions",
    "abstract": " Title: Superiority of GNN over NN in generalizing bandlimited functions ",
    "url": "https://arxiv.org/abs/2206.05904",
    "authors": [
      "A. Martina Neuman",
      "Rongrong Wang",
      "Yuying Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.07551",
    "title": "Unknown-Aware Domain Adversarial Learning for Open-Set Domain Adaptation",
    "abstract": " Comments: Accepted at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2206.07551",
    "authors": [
      "JoonHo Jang",
      "Byeonghu Na",
      "DongHyeok Shin",
      "Mingi Ji",
      "Kyungwoo Song",
      "Il-Chul Moon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2206.11769",
    "title": "Single-phase deep learning in cortico-cortical networks",
    "abstract": " Comments: Accepted to 36th Conference on Neural Information Processing Systems (NeurIPS 2022). 22 pages, 9 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2206.11769",
    "authors": [
      "Will Greedy",
      "Heng Wei Zhu",
      "Joseph Pemberton",
      "Jack Mellor",
      "Rui Ponte Costa"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2206.13307",
    "title": "Robust and Secure Resource Allocation for ISAC Systems: A Novel  Optimization Framework for Variable-Length Snapshots",
    "abstract": " Comments: 38 pages, 12 figures ",
    "url": "https://arxiv.org/abs/2206.13307",
    "authors": [
      "Dongfang Xu",
      "Xianghao Yu",
      "Derrick Wing Kwan Ng",
      "Anke Schmeink",
      "Robert Schober"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.00531",
    "title": "Masked Autoencoder for Self-Supervised Pre-training on Lidar Point  Clouds",
    "abstract": " Title: Masked Autoencoder for Self-Supervised Pre-training on Lidar Point  Clouds ",
    "url": "https://arxiv.org/abs/2207.00531",
    "authors": [
      "Georg Hess",
      "Johan Jaxing",
      "Elias Svensson",
      "David Hagerman",
      "Christoffer Petersson",
      "Lennart Svensson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.02505",
    "title": "Pure Transformers are Powerful Graph Learners",
    "abstract": " Comments: 26 pages, 8 figures ",
    "url": "https://arxiv.org/abs/2207.02505",
    "authors": [
      "Jinwoo Kim",
      "Tien Dat Nguyen",
      "Seonwoo Min",
      "Sungjun Cho",
      "Moontae Lee",
      "Honglak Lee",
      "Seunghoon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.03526",
    "title": "Reinforcement Learning-based Joint User Scheduling and Link  Configuration in Millimeter-wave Networks",
    "abstract": " Comments: 17 pages, 10 Figures ",
    "url": "https://arxiv.org/abs/2207.03526",
    "authors": [
      "Yi Zhang",
      "Robert W. Heath Jr"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2207.09209",
    "title": "FLDetector: Defending Federated Learning Against Model Poisoning Attacks  via Detecting Malicious Clients",
    "abstract": " Comments: Accepted by KDD 2022 (Research Track) ",
    "url": "https://arxiv.org/abs/2207.09209",
    "authors": [
      "Zaixi Zhang",
      "Xiaoyu Cao",
      "Jinyuan Jia",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2207.11620",
    "title": "Instant Neural Representation for Interactive Volume Rendering",
    "abstract": " Comments: This manuscript was submitted to IEEE VIS 2022 (March 31 2022), then resubmitted to IEEE TVCG (October 21 2022). We have modified our manuscript in response to previous reviews. There is also a supplementary video for this manuscript, which can be accessed via this link: this https URL ",
    "url": "https://arxiv.org/abs/2207.11620",
    "authors": [
      "Qi Wu",
      "David Bauer",
      "Michael J. Doyle",
      "Kwan-Liu Ma"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.01320",
    "title": "Compound Density Networks for Risk Prediction using Electronic Health  Records",
    "abstract": " Comments: 8 pages, 6 figures, accepted at IEEE BIBM 2022 ",
    "url": "https://arxiv.org/abs/2208.01320",
    "authors": [
      "Yuxi Liu",
      "Shaowen Qin",
      "Zhenhao Zhang",
      "Wei Shao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.04749",
    "title": "Where's the Learning in Representation Learning for Compositional  Semantics and the Case of Thematic Fit",
    "abstract": " Comments: Published in Blackbox NLP workshop, EMNLP 2022. 12 pages including Appendices, 1 figure (with 6 sub-figures) ",
    "url": "https://arxiv.org/abs/2208.04749",
    "authors": [
      "Mughilan Muthupari",
      "Samrat Halder",
      "Asad Sayeed",
      "Yuval Marton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2208.06120",
    "title": "Bayesian Inference with Latent Hamiltonian Neural Networks",
    "abstract": " Comments: Added code repository (this https URL) ",
    "url": "https://arxiv.org/abs/2208.06120",
    "authors": [
      "Somayajulu L. N. Dhulipala",
      "Yifeng Che",
      "Michael D. Shields"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2208.07715",
    "title": "Hyperparameter Optimization of Generative Adversarial Network Models for  High-Energy Physics Simulations",
    "abstract": " Comments: Submitted to Computing and Software for Big Science (October 19, 2022) ",
    "url": "https://arxiv.org/abs/2208.07715",
    "authors": [
      "Vincent Dumont",
      "Xiangyang Ju",
      "Juliane Mueller"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.09027",
    "title": "GraTO: Graph Neural Network Framework Tackling Over-smoothing with  Neural Architecture Search",
    "abstract": " Comments: accepted at CIKM2022 ",
    "url": "https://arxiv.org/abs/2208.09027",
    "authors": [
      "Xinshun Feng",
      "Herun Wan",
      "Shangbin Feng",
      "Hongrui Wang",
      "Jun Zhou",
      "Qinghua Zheng",
      "Minnan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.14508",
    "title": "Swin-transformer-yolov5 For Real-time Wine Grape Bunch Detection",
    "abstract": " Comments: 30 pages; 15 figures;Corresponding author: Xin Zhang Department of Agricultural and Biological Engineering Mississippi State University Mississippi State, MS 39762, USA (xzhang@abe.msstate.edu) ",
    "url": "https://arxiv.org/abs/2208.14508",
    "authors": [
      "Shenglian Lu",
      "Xiaoyu Liu",
      "Zixaun He",
      "Manoj Karkee",
      "Xin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.03735",
    "title": "Beyond Double Ascent via Recurrent Neural Tangent Kernel in Sequential  Recommendation",
    "abstract": " Title: Beyond Double Ascent via Recurrent Neural Tangent Kernel in Sequential  Recommendation ",
    "url": "https://arxiv.org/abs/2209.03735",
    "authors": [
      "Ruihong Qiu",
      "Zi Huang",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2209.07235",
    "title": "Sound and Complete Verification of Polynomial Networks",
    "abstract": " Comments: Accepted in NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2209.07235",
    "authors": [
      "Elias Abad Rocamora",
      "Mehmet Fatih Sahin",
      "Fanghui Liu",
      "Grigorios G Chrysos",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2209.11827",
    "title": "One-Shot Reachability Analysis of Neural Network Dynamical Systems",
    "abstract": " Comments: The introduction is updated ",
    "url": "https://arxiv.org/abs/2209.11827",
    "authors": [
      "Shaoru Chen",
      "Victor M. Preciado",
      "Mahyar Fazlyab"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2209.12702",
    "title": "End-to-End Lyrics Recognition with Self-supervised Learning",
    "abstract": " Comments: 4 pages, 2 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2209.12702",
    "authors": [
      "Xiangyu Zhang",
      "Shuyue Stella Li",
      "Zhanhong He",
      "Roberto Togneri",
      "Leibny Paola Garcia"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2209.13232",
    "title": "A Survey on Graph Neural Networks and Graph Transformers in Computer  Vision: A Task-Oriented Perspective",
    "abstract": " Comments: Preprint ",
    "url": "https://arxiv.org/abs/2209.13232",
    "authors": [
      "Chaoqi Chen",
      "Yushuang Wu",
      "Qiyuan Dai",
      "Hong-Yu Zhou",
      "Mutian Xu",
      "Sibei Yang",
      "Xiaoguang Han",
      "Yizhou Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.02202",
    "title": "A new family of Constitutive Artificial Neural Networks towards  automated model discovery",
    "abstract": " Comments: 31 pages, 14 figures ",
    "url": "https://arxiv.org/abs/2210.02202",
    "authors": [
      "Kevin Linka",
      "Ellen Kuhl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)"
    ]
  },
  {
    "id": "arXiv:2210.03102",
    "title": "Ambiguous Images With Human Judgments for Robust Visual Event  Classification",
    "abstract": " Comments: 10 pages, NeurIPS 2022 Datasets and Benchmarks Track ",
    "url": "https://arxiv.org/abs/2210.03102",
    "authors": [
      "Kate Sanders",
      "Reno Kriz",
      "Anqi Liu",
      "Benjamin Van Durme"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.03221",
    "title": "PQLM -- Multilingual Decentralized Portable Quantum Language Model for  Privacy Protection",
    "abstract": " Comments: 5 pages, 3 figures, 3 tables ",
    "url": "https://arxiv.org/abs/2210.03221",
    "authors": [
      "Shuyue Stella Li",
      "Xiangyu Zhang",
      "Shu Zhou",
      "Hongchao Shu",
      "Ruixing Liang",
      "Hexin Liu",
      "Leibny Paola Garcia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Quantum Physics (quant-ph)"
    ]
  },
  {
    "id": "arXiv:2210.03739",
    "title": "Dual-Stage Deeply Supervised Attention-based Convolutional Neural  Networks for Mandibular Canal Segmentation in CBCT Scans",
    "abstract": " Comments: 7 Pages ",
    "url": "https://arxiv.org/abs/2210.03739",
    "authors": [
      "Azka Rehman",
      "Muhammad Usman",
      "Rabeea Jawaid",
      "Shi Sub Byon",
      "Sung Hyun Kim",
      "Byoung Dai Lee",
      "Byung il Lee",
      "Yeong Gil Shin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.03956",
    "title": "Robust Graph Structure Learning over Images via Multiple Statistical  Tests",
    "abstract": " Comments: Accepted by the NeurIPS 2022. Homepage: this https URL ",
    "url": "https://arxiv.org/abs/2210.03956",
    "authors": [
      "Yaohua Wang",
      "FangYi Zhang",
      "Ming Lin",
      "Senzhang Wang",
      "Xiuyu Sun",
      "Rong Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.04561",
    "title": "A Comprehensive Survey of Data Augmentation in Visual Reinforcement  Learning",
    "abstract": " Comments: A well-classified paper list that will be continuously updated can be found at this https URL ",
    "url": "https://arxiv.org/abs/2210.04561",
    "authors": [
      "Guozheng Ma",
      "Zhen Wang",
      "Zhecheng Yuan",
      "Xueqian Wang",
      "Bo Yuan",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.04633",
    "title": "CAT-probing: A Metric-based Approach to Interpret How Pre-trained Models  for Programming Language Attend Code Structure",
    "abstract": " Comments: Accepted by EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2210.04633",
    "authors": [
      "Nuo Chen",
      "Qiushi Sun",
      "Renyu Zhu",
      "Xiang Li",
      "Xuesong Lu",
      "Ming Gao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2210.04700",
    "title": "Bio-inspired Algorithms in the Optimisation of Wireless Sensor Networks",
    "abstract": " Title: Bio-inspired Algorithms in the Optimisation of Wireless Sensor Networks ",
    "url": "https://arxiv.org/abs/2210.04700",
    "authors": [
      "Joana Matos",
      "Carine M. Rebello",
      "Erbet A. Costa",
      "Luana P. Queiroz",
      "Maria Joao B. Regufe",
      "Idelfonso B.R. Nogueira"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.04870",
    "title": "SMiLE: Schema-augmented Multi-level Contrastive Learning for Knowledge  Graph Link Prediction",
    "abstract": " Comments: Accepted to Findings of EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2210.04870",
    "authors": [
      "Miao Peng",
      "Ben Liu",
      "Qianqian Xie",
      "Wenjie Xu",
      "Hua Wang",
      "Min Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.05674",
    "title": "Semi-supervised detection of structural damage using Variational  Autoencoder and a One-Class Support Vector Machine",
    "abstract": " Title: Semi-supervised detection of structural damage using Variational  Autoencoder and a One-Class Support Vector Machine ",
    "url": "https://arxiv.org/abs/2210.05674",
    "authors": [
      "Andrea Pollastro",
      "Giusiana Testa",
      "Antonio Bilotta",
      "Roberto Prevete"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.06983",
    "title": "Denoising Masked AutoEncoders are Certifiable Robust Vision Learners",
    "abstract": " Title: Denoising Masked AutoEncoders are Certifiable Robust Vision Learners ",
    "url": "https://arxiv.org/abs/2210.06983",
    "authors": [
      "Quanlin Wu",
      "Hang Ye",
      "Yuntian Gu",
      "Huishuai Zhang",
      "Di He",
      "Liwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07128",
    "title": "Language Models of Code are Few-Shot Commonsense Learners",
    "abstract": " Comments: EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2210.07128",
    "authors": [
      "Aman Madaan",
      "Shuyan Zhou",
      "Uri Alon",
      "Yiming Yang",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.07428",
    "title": "A comparative study of the performance of different search algorithms on  FOON graphs",
    "abstract": " Title: A comparative study of the performance of different search algorithms on  FOON graphs ",
    "url": "https://arxiv.org/abs/2210.07428",
    "authors": [
      "Kumar Shashwat"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.08016",
    "title": "Prediction of drug effectiveness in rheumatoid arthritis patients based  on machine learning algorithms",
    "abstract": " Comments: 13 pages, 5 figures, to be published in ICBBE 2022 ",
    "url": "https://arxiv.org/abs/2210.08016",
    "authors": [
      "Shengjia Chen",
      "Nikunj Gupta",
      "Woodward B. Galbraith",
      "Valay Shah",
      "Jacopo Cirrone"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ]
  },
  {
    "id": "arXiv:2210.08291",
    "title": "Bidirectional Semi-supervised Dual-branch CNN for Robust 3D  Reconstruction of Stereo Endoscopic Images via Adaptive Cross and Parallel  Supervisions",
    "abstract": " Comments: 11 pages ",
    "url": "https://arxiv.org/abs/2210.08291",
    "authors": [
      "Hongkuan Shi",
      "Zhiwei Wang",
      "Ying Zhou",
      "Dun Li",
      "Xin Yang",
      "Qiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.08998",
    "title": "A Symbolic Representation of Human Posture for Interpretable Learning  and Reasoning",
    "abstract": " Comments: Accepted for presentation at the AAAI 2022 Fall Symposium Series, in the symposium for Artificial Intelligence for Human-Robot Interaction ",
    "url": "https://arxiv.org/abs/2210.08998",
    "authors": [
      "Richard G. Freedman",
      "Joseph B. Mueller",
      "Jack Ladwig",
      "Steven Johnston",
      "David McDonald",
      "Helen Wauck",
      "Ruta Wheelock",
      "Hayley Borck"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.09364",
    "title": "Probabilistic Categorical Adversarial Attack & Adversarial Training",
    "abstract": " Title: Probabilistic Categorical Adversarial Attack & Adversarial Training ",
    "url": "https://arxiv.org/abs/2210.09364",
    "authors": [
      "Pengfei He",
      "Han Xu",
      "Jie Ren",
      "Yuxuan Wan",
      "Zitao Liu",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.10358",
    "title": "Leveraging a New Spanish Corpus for Multilingual and Crosslingual  Metaphor Detection",
    "abstract": " Comments: To be published in CoNLL 2022 ",
    "url": "https://arxiv.org/abs/2210.10358",
    "authors": [
      "Elisa Sanchez-Bayona",
      "Rodrigo Agerri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.10488",
    "title": "Attribution and Obfuscation of Neural Text Authorship: A Data Mining  Perspective",
    "abstract": " Title: Attribution and Obfuscation of Neural Text Authorship: A Data Mining  Perspective ",
    "url": "https://arxiv.org/abs/2210.10488",
    "authors": [
      "Adaku Uchendu",
      "Thai Le",
      "Dongwon Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.10972",
    "title": "A Multimodal Sensor Fusion Framework Robust to Missing Modalities for  Person Recognition",
    "abstract": " Comments: Accepted for ACM Multimedia Asia, 2022 ",
    "url": "https://arxiv.org/abs/2210.10972",
    "authors": [
      "Vijay John",
      "Yasutomo Kawanishi"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11018",
    "title": "An Attention-Guided and Wavelet-Constrained Generative Adversarial  Network for Infrared and Visible Image Fusion",
    "abstract": " Title: An Attention-Guided and Wavelet-Constrained Generative Adversarial  Network for Infrared and Visible Image Fusion ",
    "url": "https://arxiv.org/abs/2210.11018",
    "authors": [
      "Xiaowen Liu",
      "Renhua Wang",
      "Hongtao Huo",
      "Xin Yang",
      "Jing Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ]
  },
  {
    "id": "arXiv:2210.11035",
    "title": "PointTAD: Multi-Label Temporal Action Detection with Learnable Query  Points",
    "abstract": " Comments: NeurIPS 2022 camera ready version ",
    "url": "https://arxiv.org/abs/2210.11035",
    "authors": [
      "Jing Tan",
      "Xiaotong Zhao",
      "Xintian Shi",
      "Bin Kang",
      "Limin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.11060",
    "title": "Doc2Bot: Accessing Heterogeneous Documents via Conversational Bots",
    "abstract": " Comments: 17 pages, 14 figures. Accepted by Findings of EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2210.11060",
    "authors": [
      "Haomin Fu",
      "Yeqin Zhang",
      "Haiyang Yu",
      "Jian Sun",
      "Fei Huang",
      "Luo Si",
      "Yongbin Li",
      "Cam-Tu Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.11269",
    "title": "Accurate Extrinsic Prediction of Physical Systems Using Transformers",
    "abstract": " Comments: 13 pages, 10 figures, submitted at SIAM Data Mining 23 (SDM23) ",
    "url": "https://arxiv.org/abs/2210.11269",
    "authors": [
      "Arnaud Pannatier",
      "Kyle Matoba",
      "Fran\u00e7ois Fleuret"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ]
  },
  {
    "id": "arXiv:2210.12023",
    "title": "A Causal Framework to Quantify the Robustness of Mathematical Reasoning  with Language Models",
    "abstract": " Comments: A shorter version of the paper was accepted at the MATH-AI Workshop at NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2210.12023",
    "authors": [
      "Alessandro Stolfo",
      "Zhijing Jin",
      "Kumar Shridhar",
      "Bernhard Sch\u00f6lkopf",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  }
]