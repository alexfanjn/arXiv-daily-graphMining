[
  {
    "id": "arXiv:2210.13457",
    "title": "Mixed Precision Quantization to Tackle Gradient Leakage Attacks in  Federated Learning",
    "abstract": "Federated Learning (FL) enables collaborative model building among a large number of participants without the need for explicit data sharing. But this approach shows vulnerabilities when privacy inference attacks are applied to it. In particular, in the event of a gradient leakage attack, which has a higher success rate in retrieving sensitive data from the model gradients, FL models are at higher risk due to the presence of communication in their inherent architecture. The most alarming thing about this gradient leakage attack is that it can be performed in such a covert way that it does not hamper the training performance while the attackers backtrack from the gradients to get information about the raw data. Two of the most common approaches proposed as solutions to this issue are homomorphic encryption and adding noise with differential privacy parameters. These two approaches suffer from two major drawbacks. They are: the key generation process becomes tedious with the increasing number of clients, and noise-based differential privacy suffers from a significant drop in global model accuracy. As a countermeasure, we propose a mixed-precision quantized FL scheme, and we empirically show that both of the issues addressed above can be resolved. In addition, our approach can ensure more robustness as different layers of the deep model are quantized with different precision and quantization modes. We empirically proved the validity of our method with three benchmark datasets and found a minimal accuracy drop in the global model after applying quantization. ",
    "url": "https://arxiv.org/abs/2210.13457",
    "authors": [
      "Pretom Roy Ovi",
      "Emon Dey",
      "Nirmalya Roy",
      "Aryya Gangopadhyay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13461",
    "title": "Active Predictive Coding: A Unified Neural Framework for Learning  Hierarchical World Models for Perception and Planning",
    "abstract": "Predictive coding has emerged as a prominent model of how the brain learns through predictions, anticipating the importance accorded to predictive learning in recent AI architectures such as transformers. Here we propose a new framework for predictive coding called active predictive coding which can learn hierarchical world models and solve two radically different open problems in AI: (1) how do we learn compositional representations, e.g., part-whole hierarchies, for equivariant vision? and (2) how do we solve large-scale planning problems, which are hard for traditional reinforcement learning, by composing complex action sequences from primitive policies? Our approach exploits hypernetworks, self-supervised learning and reinforcement learning to learn hierarchical world models that combine task-invariant state transition networks and task-dependent policy networks at multiple abstraction levels. We demonstrate the viability of our approach on a variety of vision datasets (MNIST, FashionMNIST, Omniglot) as well as on a scalable hierarchical planning problem. Our results represent, to our knowledge, the first demonstration of a unified solution to the part-whole learning problem posed by Hinton, the nested reference frames problem posed by Hawkins, and the integrated state-action hierarchy learning problem in reinforcement learning. ",
    "url": "https://arxiv.org/abs/2210.13461",
    "authors": [
      "Rajesh P. N. Rao",
      "Dimitrios C. Gklezakos",
      "Vishwas Sathish"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ]
  },
  {
    "id": "arXiv:2210.13463",
    "title": "Adversarial Pretraining of Self-Supervised Deep Networks: Past, Present  and Future",
    "abstract": "In this paper, we review adversarial pretraining of self-supervised deep networks including both convolutional neural networks and vision transformers. Unlike the adversarial training with access to labeled examples, adversarial pretraining is complicated as it only has access to unlabeled examples. To incorporate adversaries into pretraining models on either input or feature level, we find that existing approaches are largely categorized into two groups: memory-free instance-wise attacks imposing worst-case perturbations on individual examples, and memory-based adversaries shared across examples over iterations. In particular, we review several representative adversarial pretraining models based on Contrastive Learning (CL) and Masked Image Modeling (MIM), respectively, two popular self-supervised pretraining methods in literature. We also review miscellaneous issues about computing overheads, input-/feature-level adversaries, as well as other adversarial pretraining approaches beyond the above two groups. Finally, we discuss emerging trends and future directions about the relations between adversarial and cooperative pretraining, unifying adversarial CL and MIM pretraining, and the trade-off between accuracy and robustness in adversarial pretraining. ",
    "url": "https://arxiv.org/abs/2210.13463",
    "authors": [
      "Guo-Jun Qi",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13464",
    "title": "Graph Reinforcement Learning-based CNN Inference Offloading in Dynamic  Edge Computing",
    "abstract": "This paper studies the computational offloading of CNN inference in dynamic multi-access edge computing (MEC) networks. To address the uncertainties in communication time and Edge servers' available capacity, we use early-exit mechanism to terminate the computation earlier to meet the deadline of inference tasks. We design a reward function to trade off the communication, computation and inference accuracy, and formulate the offloading problem of CNN inference as a maximization problem with the goal of maximizing the average inference accuracy and throughput in long term. To solve the maximization problem, we propose a graph reinforcement learning-based early-exit mechanism (GRLE), which outperforms the state-of-the-art work, deep reinforcement learning-based online offloading (DROO) and its enhanced method, DROO with early-exit mechanism (DROOE), under different dynamic scenarios. The experimental results show that GRLE achieves the average accuracy up to 3.41x over graph reinforcement learning (GRL) and 1.45x over DROOE, which shows the advantages of GRLE for offloading decision-making in dynamic MEC. ",
    "url": "https://arxiv.org/abs/2210.13464",
    "authors": [
      "Nan Li",
      "Alexandros Iosifidis",
      "Qi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.13468",
    "title": "Fast and Low-Memory Deep Neural Networks Using Binary Matrix  Factorization",
    "abstract": "Despite the outstanding performance of deep neural networks in different applications, they are still computationally extensive and require a great number of memories. This motivates more research on reducing the resources required for implementing such networks. An efficient approach addressed for this purpose is matrix factorization, which has been shown to be effective on different networks. In this paper, we utilize binary matrix factorization and show its great efficiency in reducing the required number of resources in deep neural networks. In effect, this technique can lead to the practical implementation of such networks. ",
    "url": "https://arxiv.org/abs/2210.13468",
    "authors": [
      "Alireza Bordbar",
      "Mohammad Hossein Kahaei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.13497",
    "title": "Subspace Recovery from Heterogeneous Data with Non-isotropic Noise",
    "abstract": "Recovering linear subspaces from data is a fundamental and important task in statistics and machine learning. Motivated by heterogeneity in Federated Learning settings, we study a basic formulation of this problem: the principal component analysis (PCA), with a focus on dealing with irregular noise. Our data come from $n$ users with user $i$ contributing data samples from a $d$-dimensional distribution with mean $\\mu_i$. Our goal is to recover the linear subspace shared by $\\mu_1,\\ldots,\\mu_n$ using the data points from all users, where every data point from user $i$ is formed by adding an independent mean-zero noise vector to $\\mu_i$. If we only have one data point from every user, subspace recovery is information-theoretically impossible when the covariance matrices of the noise vectors can be non-spherical, necessitating additional restrictive assumptions in previous work. We avoid these assumptions by leveraging at least two data points from each user, which allows us to design an efficiently-computable estimator under non-spherical and user-dependent noise. We prove an upper bound for the estimation error of our estimator in general scenarios where the number of data points and amount of noise can vary across users, and prove an information-theoretic error lower bound that not only matches the upper bound up to a constant factor, but also holds even for spherical Gaussian noise. This implies that our estimator does not introduce additional estimation error (up to a constant factor) due to irregularity in the noise. We show additional results for a linear regression problem in a similar setup. ",
    "url": "https://arxiv.org/abs/2210.13497",
    "authors": [
      "John Duchi",
      "Vitaly Feldman",
      "Lunjia Hu",
      "Kunal Talwar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.13507",
    "title": "Causal Explanation for Reinforcement Learning: Quantifying State and  Temporal Importance",
    "abstract": "Explainability plays an increasingly important role in machine learning. Because reinforcement learning (RL) involves interactions between states and actions over time, explaining an RL policy is more challenging than that of supervised learning. Furthermore, humans view the world from causal lens and thus prefer causal explanations over associational ones. Therefore, in this paper, we develop a causal explanation mechanism that quantifies the causal importance of states on actions and such importance over time. Moreover, via a series of simulation studies including crop irrigation, Blackjack, collision avoidance, and lunar lander, we demonstrate the advantages of our mechanism over state-of-the-art associational methods in terms of RL policy explanation. ",
    "url": "https://arxiv.org/abs/2210.13507",
    "authors": [
      "Xiaoxiao Wang",
      "Fanyu Meng",
      "Zhaodan Kong",
      "Xin Chen",
      "Xin Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13534",
    "title": "Classification of Misinformation in New Articles using Natural Language  Processing and a Recurrent Neural Network",
    "abstract": "This paper seeks to address the classification of misinformation in news articles using a Long Short Term Memory Recurrent Neural Network. Articles were taken from 2018; a year that was filled with reporters writing about President Donald Trump, Special Counsel Robert Mueller, the Fifa World Cup, and Russia. The model presented successfully classifies these articles with an accuracy score of 0.779944. We consider this to be successful because the model was trained on articles that included languages other than English as well as incomplete, or fragmented, articles. ",
    "url": "https://arxiv.org/abs/2210.13534",
    "authors": [
      "Brendan Cunha",
      "Lydia Manikonda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13537",
    "title": "Private Online Prediction from Experts: Separations and Faster Rates",
    "abstract": "Online prediction from experts is a fundamental problem in machine learning and several works have studied this problem under privacy constraints. We propose and analyze new algorithms for this problem that improve over the regret bounds of the best existing algorithms for non-adaptive adversaries. For approximate differential privacy, our algorithms achieve regret bounds of $\\tilde{O}(\\sqrt{T \\log d} + \\log d/\\varepsilon)$ for the stochastic setting and $\\tilde O(\\sqrt{T \\log d} + T^{1/3} \\log d/\\varepsilon)$ for oblivious adversaries (where $d$ is the number of experts). For pure DP, our algorithms are the first to obtain sub-linear regret for oblivious adversaries in the high-dimensional regime $d \\ge T$. Moreover, we prove new lower bounds for adaptive adversaries. Our results imply that unlike the non-private setting, there is a strong separation between the optimal regret for adaptive and non-adaptive adversaries for this problem. Our lower bounds also show a separation between pure and approximate differential privacy for adaptive adversaries where the latter is necessary to achieve the non-private $O(\\sqrt{T})$ regret. ",
    "url": "https://arxiv.org/abs/2210.13537",
    "authors": [
      "Hilal Asi",
      "Vitaly Feldman",
      "Tomer Koren",
      "Kunal Talwar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.13554",
    "title": "Weight Fixing Networks",
    "abstract": "Modern iterations of deep learning models contain millions (billions) of unique parameters, each represented by a b-bit number. Popular attempts at compressing neural networks (such as pruning and quantisation) have shown that many of the parameters are superfluous, which we can remove (pruning) or express with less than b-bits (quantisation) without hindering performance. Here we look to go much further in minimising the information content of networks. Rather than a channel or layer-wise encoding, we look to lossless whole-network quantisation to minimise the entropy and number of unique parameters in a network. We propose a new method, which we call Weight Fixing Networks (WFN) that we design to realise four model outcome objectives: i) very few unique weights, ii) low-entropy weight encodings, iii) unique weight values which are amenable to energy-saving versions of hardware multiplication, and iv) lossless task-performance. Some of these goals are conflicting. To best balance these conflicts, we combine a few novel (and some well-trodden) tricks; a novel regularisation term, (i, ii) a view of clustering cost as relative distance change (i, ii, iv), and a focus on whole-network re-use of weights (i, iii). Our Imagenet experiments demonstrate lossless compression using 56x fewer unique weights and a 1.9x lower weight-space entropy than SOTA quantisation approaches. ",
    "url": "https://arxiv.org/abs/2210.13554",
    "authors": [
      "Christopher Subia-Waud",
      "Srinandan Dasmahapatra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13569",
    "title": "Characterizing Verbatim Short-Term Memory in Neural Language Models",
    "abstract": "When a language model is trained to predict natural language sequences, its prediction at each moment depends on a representation of prior context. What kind of information about the prior context can language models retrieve? We tested whether language models could retrieve the exact words that occurred previously in a text. In our paradigm, language models (transformers and an LSTM) processed English text in which a list of nouns occurred twice. We operationalized retrieval as the reduction in surprisal from the first to the second list. We found that the transformers retrieved both the identity and ordering of nouns from the first list. Further, the transformers' retrieval was markedly enhanced when they were trained on a larger corpus and with greater model depth. Lastly, their ability to index prior tokens was dependent on learned attention patterns. In contrast, the LSTM exhibited less precise retrieval, which was limited to list-initial tokens and to short intervening texts. The LSTM's retrieval was not sensitive to the order of nouns and it improved when the list was semantically coherent. We conclude that transformers implemented something akin to a working memory system that could flexibly retrieve individual token representations across arbitrary delays; conversely, the LSTM maintained a coarser and more rapidly-decaying semantic gist of prior tokens, weighted toward the earliest items. ",
    "url": "https://arxiv.org/abs/2210.13569",
    "authors": [
      "Kristijan Armeni",
      "Christopher Honey",
      "Tal Linzen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.13575",
    "title": "Does Self-Rationalization Improve Robustness to Spurious Correlations?",
    "abstract": "Rationalization is fundamental to human reasoning and learning. NLP models trained to produce rationales along with predictions, called self-rationalization models, have been investigated for their interpretability and utility to end-users. However, the extent to which training with human-written rationales facilitates learning remains an under-explored question. We ask whether training models to self-rationalize can aid in their learning to solve tasks for the right reasons. Specifically, we evaluate how training self-rationalization models with free-text rationales affects robustness to spurious correlations in fine-tuned encoder-decoder and decoder-only models of six different sizes. We evaluate robustness to spurious correlations by measuring performance on 1) manually annotated challenge datasets and 2) subsets of original test sets where reliance on spurious correlations would fail to produce correct answers. We find that while self-rationalization can improve robustness to spurious correlations in low-resource settings, it tends to hurt robustness in higher-resource settings. Furthermore, these effects depend on model family and size, as well as on rationale content. Together, our results suggest that explainability can come at the cost of robustness; thus, appropriate care should be taken when training self-rationalizing models with the goal of creating more trustworthy models. ",
    "url": "https://arxiv.org/abs/2210.13575",
    "authors": [
      "Alexis Ross",
      "Matthew E. Peters",
      "Ana Marasovi\u0107"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.13582",
    "title": "Causal Analysis on the Anchor Store Effect in a Location-based Social  Network",
    "abstract": "A particular phenomenon of interest in Retail Economics is the spillover effect of anchor stores (specific stores with a reputable brand) to non-anchor stores in terms of customer traffic. Prior works in this area rely on small and survey-based datasets that are often confidential or expensive to collect on a large scale. Also, very few works study the underlying causal mechanisms between factors that underpin the spillover effect. In this work, we analyse the causal relationship between anchor stores and customer traffic to non-anchor stores and employ a propensity score matching framework to investigate this effect more efficiently. First of all, to demonstrate the effect, we leverage open and mobile data from London Datastore and Location-Based Social Networks (LBSNs) such as Foursquare. We then perform a large-scale empirical analysis on customer visit patterns from anchor stores to non-anchor stores(e.g., non-chain restaurants) located in the Greater London area as a case study. By studying over 600 neighbourhoods in the GreaterLondon Area, we find that anchor stores cause a 14.2-26.5% increase in customer traffic for the non-anchor stores reinforcing the established economic theory. Moreover, we evaluate the efficiency of our methodology by studying the confounder balance, dose difference and performance of matching framework on synthetic data. Through this work, we point decision-makers in the retail industry to a more systematic approach to estimate the anchor store effect and pave the way for further research to discover more complex causal relationships underlying this effect with open data. ",
    "url": "https://arxiv.org/abs/2210.13582",
    "authors": [
      "Anish K. Vallapuram",
      "Young D. Kwon",
      "Lik-Hang Lee",
      "Fengli Xu",
      "Pan Hui"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.13583",
    "title": "Learning Latent Structural Causal Models",
    "abstract": "Causal learning has long concerned itself with the accurate recovery of underlying causal mechanisms. Such causal modelling enables better explanations of out-of-distribution data. Prior works on causal learning assume that the high-level causal variables are given. However, in machine learning tasks, one often operates on low-level data like image pixels or high-dimensional vectors. In such settings, the entire Structural Causal Model (SCM) -- structure, parameters, \\textit{and} high-level causal variables -- is unobserved and needs to be learnt from low-level data. We treat this problem as Bayesian inference of the latent SCM, given low-level data. For linear Gaussian additive noise SCMs, we present a tractable approximate inference method which performs joint inference over the causal variables, structure and parameters of the latent SCM from random, known interventions. Experiments are performed on synthetic datasets and a causally generated image dataset to demonstrate the efficacy of our approach. We also perform image generation from unseen interventions, thereby verifying out of distribution generalization for the proposed causal model. ",
    "url": "https://arxiv.org/abs/2210.13583",
    "authors": [
      "Jithendaraa Subramanian",
      "Yashas Annadani",
      "Ivaxi Sheth",
      "Nan Rosemary Ke",
      "Tristan Deleu",
      "Stefan Bauer",
      "Derek Nowrouzezahrai",
      "Samira Ebrahimi Kahou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2210.13594",
    "title": "Datavoidant: An AI System for Addressing Political Data Voids on Social  Media",
    "abstract": "The limited information (data voids) on political topics relevant to underrepresented communities has facilitated the spread of disinformation. Independent journalists who combat disinformation in underrepresented communities have reported feeling overwhelmed because they lack the tools necessary to make sense of the information they monitor and address the data voids. In this paper, we present a system to identify and address political data voids within underrepresented communities. Armed with an interview study, indicating that the independent news media has the potential to address them, we designed an intelligent collaborative system, called Datavoidant. Datavoidant uses state-of-the-art machine learning models and introduces a novel design space to provide independent journalists with a collective understanding of data voids to facilitate generating content to cover the voids. We performed a user interface evaluation with independent news media journalists (N=22). These journalists reported that Datavoidant's features allowed them to more rapidly while easily having a sense of what was taking place in the information ecosystem to address the data voids. They also reported feeling more confident about the content they created and the unique perspectives they had proposed to cover the voids. We conclude by discussing how Datavoidant enables a new design space wherein individuals can collaborate to make sense of their information ecosystem and actively devise strategies to prevent disinformation. ",
    "url": "https://arxiv.org/abs/2210.13594",
    "authors": [
      "Claudia Flores-Saviaga",
      "Shangbin Feng",
      "Saiph Savage"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2210.13604",
    "title": "The Robustness Limits of SoTA Vision Models to Natural Variation",
    "abstract": "Recent state-of-the-art vision models introduced new architectures, learning paradigms, and larger pretraining data, leading to impressive performance on tasks such as classification. While previous generations of vision models were shown to lack robustness to factors such as pose, it's unclear the extent to which this next generation of models are more robust. To study this question, we develop a dataset of more than 7 million images with controlled changes in pose, position, background, lighting, and size. We study not only how robust recent state-of-the-art models are, but also the extent to which models can generalize variation in factors when they're present during training. We consider a catalog of recent vision models, including vision transformers (ViT), self-supervised models such as masked autoencoders (MAE), and models trained on larger datasets such as CLIP. We find out-of-the-box, even today's best models are not robust to common changes in pose, size, and background. When some samples varied during training, we found models required a significant portion of diversity to generalize -- though eventually robustness did improve. When diversity is only seen for some classes however, we found models did not generalize to other classes, unless the classes were very similar to those seen varying during training. We hope our work will shed further light on the blind spots of SoTA models and spur the development of more robust vision models. ",
    "url": "https://arxiv.org/abs/2210.13604",
    "authors": [
      "Mark Ibrahim",
      "Quentin Garrido",
      "Ari Morcos",
      "Diane Bouchacourt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13605",
    "title": "GliTr: Glimpse Transformers with Spatiotemporal Consistency for Online  Action Prediction",
    "abstract": "Many online action prediction models observe complete frames to locate and attend to informative subregions in the frames called glimpses and recognize an ongoing action based on global and local information. However, in applications with constrained resources, an agent may not be able to observe the complete frame, yet must still locate useful glimpses to predict an incomplete action based on local information only. In this paper, we develop Glimpse Transformers (GliTr), which observe only narrow glimpses at all times, thus predicting an ongoing action and the following most informative glimpse location based on the partial spatiotemporal information collected so far. In the absence of a ground truth for the optimal glimpse locations for action recognition, we train GliTr using a novel spatiotemporal consistency objective: We require GliTr to attend to the glimpses with features similar to the corresponding complete frames (i.e. spatial consistency) and the resultant class logits at time t equivalent to the ones predicted using whole frames up to t (i.e. temporal consistency). Inclusion of our proposed consistency objective yields ~10% higher accuracy on the Something-Something-v2 (SSv2) dataset than the baseline cross-entropy objective. Overall, despite observing only ~33% of the total area per frame, GliTr achieves 53.02%and 93.91% accuracy on the SSv2 and Jester datasets, respectively. ",
    "url": "https://arxiv.org/abs/2210.13605",
    "authors": [
      "Samrudhdhi B Rangrej",
      "Kevin J Liang",
      "Tal Hassner",
      "James J Clark"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13631",
    "title": "On the Robustness of Dataset Inference",
    "abstract": "Machine learning (ML) models are costly to train as they can require a significant amount of data, computational resources and technical expertise. Thus, they constitute valuable intellectual property that needs protection from adversaries wanting to steal them. Ownership verification techniques allow the victims of model stealing attacks to demonstrate that a suspect model was in fact stolen from theirs. Although a number of ownership verification techniques based on watermarking or fingerprinting have been proposed, most of them fall short either in terms of security guarantees (well-equipped adversaries can evade verification) or computational cost. A fingerprinting technique introduced at ICLR '21, Dataset Inference (DI), has been shown to offer better robustness and efficiency than prior methods. The authors of DI provided a correctness proof for linear (suspect) models. However, in the same setting, we prove that DI suffers from high false positives (FPs) -- it can incorrectly identify an independent model trained with non-overlapping data from the same distribution as stolen. We further prove that DI also triggers FPs in realistic, non-linear suspect models. We then confirm empirically that DI leads to FPs, with high confidence. Second, we show that DI also suffers from false negatives (FNs) -- an adversary can fool DI by regularising a stolen model's decision boundaries using adversarial training, thereby leading to an FN. To this end, we demonstrate that DI fails to identify a model adversarially trained from a stolen dataset -- the setting where DI is the hardest to evade. Finally, we discuss the implications of our findings, the viability of fingerprinting-based ownership verification in general, and suggest directions for future work. ",
    "url": "https://arxiv.org/abs/2210.13631",
    "authors": [
      "Sebastian Szyller",
      "Rui Zhang",
      "Jian Liu",
      "N. Asokan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.13635",
    "title": "Toward an Intelligent Tutoring System for Argument Mining in Legal Texts",
    "abstract": "We propose an adaptive environment (CABINET) to support caselaw analysis (identifying key argument elements) based on a novel cognitive computing framework that carefully matches various machine learning (ML) capabilities to the proficiency of a user. CABINET supports law students in their learning as well as professionals in their work. The results of our experiments focused on the feasibility of the proposed framework are promising. We show that the system is capable of identifying a potential error in the analysis with very low false positives rate (2.0-3.5%), as well as of predicting the key argument element type (e.g., an issue or a holding) with a reasonably high F1-score (0.74). ",
    "url": "https://arxiv.org/abs/2210.13635",
    "authors": [
      "Hannes Westermann",
      "Jaromir Savelka",
      "Vern R. Walker",
      "Kevin D. Ashley",
      "Karim Benyekhlef"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13638",
    "title": "Learning Robust Real-World Dexterous Grasping Policies via Implicit  Shape Augmentation",
    "abstract": "Dexterous robotic hands have the capability to interact with a wide variety of household objects to perform tasks like grasping. However, learning robust real world grasping policies for arbitrary objects has proven challenging due to the difficulty of generating high quality training data. In this work, we propose a learning system (ISAGrasp) for leveraging a small number of human demonstrations to bootstrap the generation of a much larger dataset containing successful grasps on a variety of novel objects. Our key insight is to use a correspondence-aware implicit generative model to deform object meshes and demonstrated human grasps in order to generate a diverse dataset of novel objects and successful grasps for supervised learning, while maintaining semantic realism. We use this dataset to train a robust grasping policy in simulation which can be deployed in the real world. We demonstrate grasping performance with a four-fingered Allegro hand in both simulation and the real world, and show this method can handle entirely new semantic classes and achieve a 79% success rate on grasping unseen objects in the real world. ",
    "url": "https://arxiv.org/abs/2210.13638",
    "authors": [
      "Zoey Qiuyu Chen",
      "Karl Van Wyk",
      "Yu-Wei Chao",
      "Wei Yang",
      "Arsalan Mousavian",
      "Abhishek Gupta",
      "Dieter Fox"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.13641",
    "title": "NeRF-SLAM: Real-Time Dense Monocular SLAM with Neural Radiance Fields",
    "abstract": "We propose a novel geometric and photometric 3D mapping pipeline for accurate and real-time scene reconstruction from monocular images. To achieve this, we leverage recent advances in dense monocular SLAM and real-time hierarchical volumetric neural radiance fields. Our insight is that dense monocular SLAM provides the right information to fit a neural radiance field of the scene in real-time, by providing accurate pose estimates and depth-maps with associated uncertainty. With our proposed uncertainty-based depth loss, we achieve not only good photometric accuracy, but also great geometric accuracy. In fact, our proposed pipeline achieves better geometric and photometric accuracy than competing approaches (up to 179% better PSNR and 86% better L1 depth), while working in real-time and using only monocular images. ",
    "url": "https://arxiv.org/abs/2210.13641",
    "authors": [
      "Antoni Rosinol",
      "John J. Leonard",
      "Luca Carlone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13646",
    "title": "Depth Monocular Estimation with Attention-based Encoder-Decoder Network  from Single Image",
    "abstract": "Depth information is the foundation of perception, essential for autonomous driving, robotics, and other source-constrained applications. Promptly obtaining accurate and efficient depth information allows for a rapid response in dynamic environments. Sensor-based methods using LIDAR and RADAR obtain high precision at the cost of high power consumption, price, and volume. While due to advances in deep learning, vision-based approaches have recently received much attention and can overcome these drawbacks. In this work, we explore an extreme scenario in vision-based settings: estimate a depth map from one monocular image severely plagued by grid artifacts and blurry edges. To address this scenario, We first design a convolutional attention mechanism block (CAMB) which consists of channel attention and spatial attention sequentially and insert these CAMBs into skip connections. As a result, our novel approach can find the focus of current image with minimal overhead and avoid losses of depth features. Next, by combining the depth value, the gradients of X axis, Y axis and diagonal directions, and the structural similarity index measure (SSIM), we propose our novel loss function. Moreover, we utilize pixel blocks to accelerate the computation of the loss function. Finally, we show, through comprehensive experiments on two large-scale image datasets, i.e. KITTI and NYU-V2, that our method outperforms several representative baselines. ",
    "url": "https://arxiv.org/abs/2210.13646",
    "authors": [
      "Xin Zhang",
      "Rabab Abdelfattah",
      "Yuqi Song",
      "Samuel A. Dauchert",
      "Xiaofeng wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13647",
    "title": "Temporally Disentangled Representation Learning",
    "abstract": "Recently in the field of unsupervised representation learning, strong identifiability results for disentanglement of causally-related latent variables have been established by exploiting certain side information, such as class labels, in addition to independence. However, most existing work is constrained by functional form assumptions such as independent sources or further with linear transitions, and distribution assumptions such as stationary, exponential family distribution. It is unknown whether the underlying latent variables and their causal relations are identifiable if they have arbitrary, nonparametric causal influences in between. In this work, we establish the identifiability theories of nonparametric latent causal processes from their nonlinear mixtures under fixed temporal causal influences and analyze how distribution changes can further benefit the disentanglement. We propose \\textbf{\\texttt{TDRL}}, a principled framework to recover time-delayed latent causal variables and identify their relations from measured sequential data under stationary environments and under different distribution shifts. Specifically, the framework can factorize unknown distribution shifts into transition distribution changes under fixed and time-varying latent causal relations, and under observation changes in observation. Through experiments, we show that time-delayed latent causal influences are reliably identified and that our approach considerably outperforms existing baselines that do not correctly exploit this modular representation of changes. Our code is available at: \\url{https://github.com/weirayao/tdrl}. ",
    "url": "https://arxiv.org/abs/2210.13647",
    "authors": [
      "Weiran Yao",
      "Guangyi Chen",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.13650",
    "title": "ReaRev: Adaptive Reasoning for Question Answering over Knowledge Graphs",
    "abstract": "Knowledge Graph Question Answering (KGQA) involves retrieving entities as answers from a Knowledge Graph (KG) using natural language queries. The challenge is to learn to reason over question-relevant KG facts that traverse KG entities and lead to the question answers. To facilitate reasoning, the question is decoded into instructions, which are dense question representations used to guide the KG traversals. However, if the derived instructions do not exactly match the underlying KG information, they may lead to reasoning under irrelevant context. Our method, termed ReaRev, introduces a new way to KGQA reasoning with respect to both instruction decoding and execution. To improve instruction decoding, we perform reasoning in an adaptive manner, where KG-aware information is used to iteratively update the initial instructions. To improve instruction execution, we emulate breadth-first search (BFS) with graph neural networks (GNNs). The BFS strategy treats the instructions as a set and allows our method to decide on their execution order on the fly. Experimental results on three KGQA benchmarks demonstrate the ReaRev's effectiveness compared with previous state-of-the-art, especially when the KG is incomplete or when we tackle complex questions. Our code is publicly available at https://github.com/cmavro/ReaRev_KGQA. ",
    "url": "https://arxiv.org/abs/2210.13650",
    "authors": [
      "Costas Mavromatis",
      "George Karypis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.13660",
    "title": "SpacePhish: The Evasion-space of Adversarial Attacks against Phishing  Website Detectors using Machine Learning",
    "abstract": "Existing literature on adversarial Machine Learning (ML) focuses either on showing attacks that break every ML model, or defenses that withstand most attacks. Unfortunately, little consideration is given to the actual \\textit{cost} of the attack or the defense. Moreover, adversarial samples are often crafted in the \"feature-space\", making the corresponding evaluations of questionable value. Simply put, the current situation does not allow to estimate the actual threat posed by adversarial attacks, leading to a lack of secure ML systems. We aim to clarify such confusion in this paper. By considering the application of ML for Phishing Website Detection (PWD), we formalize the \"evasion-space\" in which an adversarial perturbation can be introduced to fool a ML-PWD -- demonstrating that even perturbations in the \"feature-space\" are useful. Then, we propose a realistic threat model describing evasion attacks against ML-PWD that are cheap to stage, and hence intrinsically more attractive for real phishers. Finally, we perform the first statistically validated assessment of state-of-the-art ML-PWD against 12 evasion attacks. Our evaluation shows (i) the true efficacy of evasion attempts that are more likely to occur; and (ii) the impact of perturbations crafted in different evasion-spaces. Our realistic evasion attempts induce a statistically significant degradation (3-10% at $p\\!<$0.05), and their cheap cost makes them a subtle threat. Notably, however, some ML-PWD are immune to our most realistic attacks ($p$=0.22). Our contribution paves the way for a much needed re-assessment of adversarial attacks against ML systems for cybersecurity. ",
    "url": "https://arxiv.org/abs/2210.13660",
    "authors": [
      "Giovanni Apruzzese",
      "Mauro Conti",
      "Ying Yuan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.13662",
    "title": "Analyzing Privacy Leakage in Machine Learning via Multiple Hypothesis  Testing: A Lesson From Fano",
    "abstract": "Differential privacy (DP) is by far the most widely accepted framework for mitigating privacy risks in machine learning. However, exactly how small the privacy parameter $\\epsilon$ needs to be to protect against certain privacy risks in practice is still not well-understood. In this work, we study data reconstruction attacks for discrete data and analyze it under the framework of multiple hypothesis testing. We utilize different variants of the celebrated Fano's inequality to derive upper bounds on the inferential power of a data reconstruction adversary when the model is trained differentially privately. Importantly, we show that if the underlying private data takes values from a set of size $M$, then the target privacy parameter $\\epsilon$ can be $O(\\log M)$ before the adversary gains significant inferential power. Our analysis offers theoretical evidence for the empirical effectiveness of DP against data reconstruction attacks even at relatively large values of $\\epsilon$. ",
    "url": "https://arxiv.org/abs/2210.13662",
    "authors": [
      "Chuan Guo",
      "Alexandre Sablayrolles",
      "Maziar Sanjabi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.13681",
    "title": "BSDF Importance Baking: A Lightweight Neural Solution to Importance  Sampling Parametric BSDFs",
    "abstract": "Parametric BSDFs (Bidirectional Scattering Distribution Functions) are pervasively used because of their flexibility to represent a large variety of material appearances by simply tuning the parameters. While efficient evaluation of parametric BSDFs has been well-studied, high-quality importance sampling techniques for parametric BSDFs are still scarce. Existing sampling strategies either heavily rely on approximations and result in high variance, or solely perform sampling on a portion of the whole BSDF slice. Moreover, many of the sampling approaches are specifically paired with certain types of BSDFs. In this paper, we seek an efficient and general way for importance sampling parametric BSDFs. We notice that the nature of importance sampling is the mapping between a uniform distribution and the target distribution. Specifically, when BSDF parameters are given, the mapping that performs importance sampling on a BSDF slice can be simply recorded as a 2D image that we name as importance map. Following this observation, we accurately precompute the importance maps using a mathematical tool named optimal transport. Then we propose a lightweight neural network to efficiently compress the precomputed importance maps. In this way, we have completely brought parametric BSDF importance sampling to the precomputation stage, avoiding heavy runtime computation. Since this process is similar to light baking where a set of images are precomputed, we name our method importance baking. Together with a BSDF evaluation network and a PDF (probability density function) query network, our method enables full MIS without any revision to the rendering pipeline. Our method essentially performs perfect importance sampling. Compared with previous methods, we demonstrate reduced noise levels on rendering results with a rich set of appearances, including both conductors and dielectrics with anisotropic roughness. ",
    "url": "https://arxiv.org/abs/2210.13681",
    "authors": [
      "Yaoyi Bai",
      "Songyin Wu",
      "Zheng Zeng",
      "Beibei Wang",
      "Ling-Qi Yan"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ]
  },
  {
    "id": "arXiv:2210.13686",
    "title": "FedGRec: Federated Graph Recommender System with Lazy Update of Latent  Embeddings",
    "abstract": "Recommender systems are widely used in industry to improve user experience. Despite great success, they have recently been criticized for collecting private user data. Federated Learning (FL) is a new paradigm for learning on distributed data without direct data sharing. Therefore, Federated Recommender (FedRec) systems are proposed to mitigate privacy concerns to non-distributed recommender systems. However, FedRec systems have a performance gap to its non-distributed counterpart. The main reason is that local clients have an incomplete user-item interaction graph, thus FedRec systems cannot utilize indirect user-item interactions well. In this paper, we propose the Federated Graph Recommender System (FedGRec) to mitigate this gap. Our FedGRec system can effectively exploit the indirect user-item interactions. More precisely, in our system, users and the server explicitly store latent embeddings for users and items, where the latent embeddings summarize different orders of indirect user-item interactions and are used as a proxy of missing interaction graph during local training. We perform extensive empirical evaluations to verify the efficacy of using latent embeddings as a proxy of missing interaction graph; the experimental results show superior performance of our system compared to various baselines. A short version of the paper is presented in \\href{https://federated-learning.org/fl-neurips-2022/}{the FL-NeurIPS'22 workshop}. ",
    "url": "https://arxiv.org/abs/2210.13686",
    "authors": [
      "Junyi Li",
      "Heng Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13701",
    "title": "Rich Knowledge Sources Bring Complex Knowledge Conflicts: Recalibrating  Models to Reflect Conflicting Evidence",
    "abstract": "Question answering models can use rich knowledge sources -- up to one hundred retrieved passages and parametric knowledge in the large-scale language model (LM). Prior work assumes information in such knowledge sources is consistent with each other, paying little attention to how models blend information stored in their LM parameters with that from retrieved evidence documents. In this paper, we simulate knowledge conflicts (i.e., where parametric knowledge suggests one answer and different passages suggest different answers) and examine model behaviors. We find retrieval performance heavily impacts which sources models rely on, and current models mostly rely on non-parametric knowledge in their best-performing settings. We discover a troubling trend that contradictions among knowledge sources affect model confidence only marginally. To address this issue, we present a new calibration study, where models are discouraged from presenting any single answer when presented with multiple conflicting answer candidates in retrieved evidences. ",
    "url": "https://arxiv.org/abs/2210.13701",
    "authors": [
      "Hung-Ting Chen",
      "Michael J.Q. Zhang",
      "Eunsol Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.13705",
    "title": "An Effective Deep Network for Head Pose Estimation without Keypoints",
    "abstract": "Human head pose estimation is an essential problem in facial analysis in recent years that has a lot of computer vision applications such as gaze estimation, virtual reality, and driver assistance. Because of the importance of the head pose estimation problem, it is necessary to design a compact model to resolve this task in order to reduce the computational cost when deploying on facial analysis-based applications such as large camera surveillance systems, AI cameras while maintaining accuracy. In this work, we propose a lightweight model that effectively addresses the head pose estimation problem. Our approach has two main steps. 1) We first train many teacher models on the synthesis dataset - 300W-LPA to get the head pose pseudo labels. 2) We design an architecture with the ResNet18 backbone and train our proposed model with the ensemble of these pseudo labels via the knowledge distillation process. To evaluate the effectiveness of our model, we use AFLW-2000 and BIWI - two real-world head pose datasets. Experimental results show that our proposed model significantly improves the accuracy in comparison with the state-of-the-art head pose estimation methods. Furthermore, our model has the real-time speed of $\\sim$300 FPS when inferring on Tesla V100. ",
    "url": "https://arxiv.org/abs/2210.13705",
    "authors": [
      "Chien Thai",
      "Viet Tran",
      "Minh Bui",
      "Huong Ninh",
      "Hai Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13709",
    "title": "InForecaster: Forecasting Influenza Hemagglutinin Mutations Through the  Lens of Anomaly Detection",
    "abstract": "The influenza virus hemagglutinin is an important part of the virus attachment to the host cells. The hemagglutinin proteins are one of the genetic regions of the virus with a high potential for mutations. Due to the importance of predicting mutations in producing effective and low-cost vaccines, solutions that attempt to approach this problem have recently gained a significant attention. A historical record of mutations have been used to train predictive models in such solutions. However, the imbalance between mutations and the preserved proteins is a big challenge for the development of such models that needs to be addressed. Here, we propose to tackle this challenge through anomaly detection (AD). AD is a well-established field in Machine Learning (ML) that tries to distinguish unseen anomalies from the normal patterns using only normal training samples. By considering mutations as the anomalous behavior, we could benefit existing rich solutions in this field that have emerged recently. Such methods also fit the problem setup of extreme imbalance between the number of unmutated vs. mutated training samples. Motivated by this formulation, our method tries to find a compact representation for unmutated samples while forcing anomalies to be separated from the normal ones. This helps the model to learn a shared unique representation between normal training samples as much as possible, which improves the discernibility and detectability of mutated samples from the unmutated ones at the test time. We conduct a large number of experiments on four publicly available datasets, consisting of 3 different hemagglutinin protein datasets, and one SARS-CoV-2 dataset, and show the effectiveness of our method through different standard criteria. ",
    "url": "https://arxiv.org/abs/2210.13709",
    "authors": [
      "Ali Garjani",
      "Atoosa Malemir Chegini",
      "Mohammadreza Salehi",
      "Alireza Tabibzadeh",
      "Parastoo Yousefi",
      "Mohammad Hossein Razizadeh",
      "Moein Esghaei",
      "Maryam Esghaei",
      "Mohammad Hossein Rohban"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ]
  },
  {
    "id": "arXiv:2210.13710",
    "title": "Motif-Backdoor: Rethinking the Backdoor Attack on Graph Neural Networks  via Motifs",
    "abstract": "Graph neural network (GNN) with a powerful representation capability has been widely applied to various areas, such as biological gene prediction, social recommendation, etc. Recent works have exposed that GNN is vulnerable to the backdoor attack, i.e., models trained with maliciously crafted training samples are easily fooled by patched samples. Most of the proposed studies launch the backdoor attack using a trigger that either is the randomly generated subgraph (e.g., erd\\H{o}s-r\\'enyi backdoor) for less computational burden, or the gradient-based generative subgraph (e.g., graph trojaning attack) to enable a more effective attack. However, the interpretation of how is the trigger structure and the effect of the backdoor attack related has been overlooked in the current literature. Motifs, recurrent and statistically significant sub-graphs in graphs, contain rich structure information. In this paper, we are rethinking the trigger from the perspective of motifs, and propose a motif-based backdoor attack, denoted as Motif-Backdoor. It contributes from three aspects. (i) Interpretation: it provides an in-depth explanation for backdoor effectiveness by the validity of the trigger structure from motifs, leading to some novel insights, e.g., using subgraphs that appear less frequently in the graph as the trigger can achieve better attack performance. (ii) Effectiveness: Motif-Backdoor reaches the state-of-the-art (SOTA) attack performance in both black-box and defensive scenarios. (iii) Efficiency: based on the graph motif distribution, Motif-Backdoor can quickly obtain an effective trigger structure without target model feedback or subgraph model generation. Extensive experimental results show that Motif-Backdoor realizes the SOTA performance on three popular models and four public datasets compared with five baselines. ",
    "url": "https://arxiv.org/abs/2210.13710",
    "authors": [
      "Haibin Zheng",
      "Haiyang Xiong",
      "Jinyin Chen",
      "Haonan Ma",
      "Guohan Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.13715",
    "title": "PALT: Parameter-Lite Transfer of Language Models for Knowledge Graph  Completion",
    "abstract": "This paper presents a parameter-lite transfer learning approach of pretrained language models (LM) for knowledge graph (KG) completion. Instead of finetuning, which modifies all LM parameters, we only tune a few new parameters while keeping the original LM parameters fixed. We establish this via reformulating KG completion as a \"fill-in-the-blank\" task, and introducing a parameter-lite encoder on top of the original LMs. We show that, by tuning far fewer parameters than finetuning, LMs transfer non-trivially to most tasks and reach competitiveness with prior state-of-the-art approaches. For instance, we outperform the fully finetuning approaches on a KG completion benchmark by tuning only 1% of the parameters. The code and datasets are available at \\url{https://github.com/yuanyehome/PALT}. ",
    "url": "https://arxiv.org/abs/2210.13715",
    "authors": [
      "Jianhao Shen",
      "Chenguang Wang",
      "Ye Yuan",
      "Jiawei Han",
      "Heng Ji",
      "Koushik Sen",
      "Ming Zhang",
      "Dawn Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.13718",
    "title": "Facial Action Units Detection Aided by Global-Local Expression Embedding",
    "abstract": "Since Facial Action Unit (AU) annotations require domain expertise, common AU datasets only contain a limited number of subjects. As a result, a crucial challenge for AU detection is addressing identity overfitting. We find that AUs and facial expressions are highly associated, and existing facial expression datasets often contain a large number of identities. In this paper, we aim to utilize the expression datasets without AU labels to facilitate AU detection. Specifically, we develop a novel AU detection framework aided by the Global-Local facial Expressions Embedding, dubbed GLEE-Net. Our GLEE-Net consists of three branches to extract identity-independent expression features for AU detection. We introduce a global branch for modeling the overall facial expression while eliminating the impacts of identities. We also design a local branch focusing on specific local face regions. The combined output of global and local branches is firstly pre-trained on an expression dataset as an identity-independent expression embedding, and then finetuned on AU datasets. Therefore, we significantly alleviate the issue of limited identities. Furthermore, we introduce a 3D global branch that extracts expression coefficients through 3D face reconstruction to consolidate 2D AU descriptions. Finally, a Transformer-based multi-label classifier is employed to fuse all the representations for AU detection. Extensive experiments demonstrate that our method significantly outperforms the state-of-the-art on the widely-used DISFA, BP4D and BP4D+ datasets. ",
    "url": "https://arxiv.org/abs/2210.13718",
    "authors": [
      "Zhipeng Hu",
      "Wei Zhang",
      "Lincheng Li",
      "Yu Ding",
      "Wei Chen",
      "Zhigang Deng",
      "Xin Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.13743",
    "title": "Online Cross-Layer Knowledge Distillation on Graph Neural Networks with  Deep Supervision",
    "abstract": "Graph neural networks (GNNs) have become one of the most popular research topics in both academia and industry communities for their strong ability in handling irregular graph data. However, large-scale datasets are posing great challenges for deploying GNNs in edge devices with limited resources and model compression techniques have drawn considerable research attention. Existing model compression techniques such as knowledge distillation (KD) mainly focus on convolutional neural networks (CNNs). Only limited attempts have been made recently for distilling knowledge from GNNs in an offline manner. As the performance of the teacher model does not necessarily improve as the number of layers increases in GNNs, selecting an appropriate teacher model will require substantial efforts. To address these challenges, we propose a novel online knowledge distillation framework called Alignahead++ in this paper. Alignahead++ transfers structure and feature information in a student layer to the previous layer of another simultaneously trained student model in an alternating training procedure. Meanwhile, to avoid over-smoothing problem in GNNs, deep supervision is employed in Alignahead++ by adding an auxiliary classifier in each intermediate layer to prevent the collapse of the node feature embeddings. Experimental results on four datasets including PPI, Cora, PubMed and CiteSeer demonstrate that the student performance is consistently boosted in our collaborative training framework without the supervision of a pre-trained teacher model and its effectiveness can generally be improved by increasing the number of students. ",
    "url": "https://arxiv.org/abs/2210.13743",
    "authors": [
      "Jiongyu Guo",
      "Defang Chen",
      "Can Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.13749",
    "title": "AugCSE: Contrastive Sentence Embedding with Diverse Augmentations",
    "abstract": "Data augmentation techniques have been proven useful in many applications in NLP fields. Most augmentations are task-specific, and cannot be used as a general-purpose tool. In our work, we present AugCSE, a unified framework to utilize diverse sets of data augmentations to achieve a better, general purpose, sentence embedding model. Building upon the latest sentence embedding models, our approach uses a simple antagonistic discriminator that differentiates the augmentation types. With the finetuning objective borrowed from domain adaptation, we show that diverse augmentations, which often lead to conflicting contrastive signals, can be tamed to produce a better and more robust sentence representation. Our methods achieve state-of-the-art results on downstream transfer tasks and perform competitively on semantic textual similarity tasks, using only unsupervised data. ",
    "url": "https://arxiv.org/abs/2210.13749",
    "authors": [
      "Zilu Tang",
      "Muhammed Yusuf Kocyigit",
      "Derry Wijaya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.13752",
    "title": "Aboveground carbon biomass estimate with Physics-informed deep network",
    "abstract": "The global carbon cycle is a key process to understand how our climate is changing. However, monitoring the dynamics is difficult because a high-resolution robust measurement of key state parameters including the aboveground carbon biomass (AGB) is required. Here, we use deep neural network to generate a wall-to-wall map of AGB within the Continental USA (CONUS) with 30-meter spatial resolution for the year 2021. We combine radar and optical hyperspectral imagery, with a physical climate parameter of SIF-based GPP. Validation results show that a masked variation of UNet has the lowest validation RMSE of 37.93 $\\pm$ 1.36 Mg C/ha, as compared to 52.30 $\\pm$ 0.03 Mg C/ha for random forest algorithm. Furthermore, models that learn from SIF-based GPP in addition to radar and optical imagery reduce validation RMSE by almost 10% and the standard deviation by 40%. Finally, we apply our model to measure losses in AGB from the recent 2021 Caldor wildfire in California, and validate our analysis with Sentinel-based burn index. ",
    "url": "https://arxiv.org/abs/2210.13752",
    "authors": [
      "Juan Nathaniel",
      "Levente J. Klein",
      "Campbell D. Watson",
      "Gabrielle Nyirjesy",
      "Conrad M. Albrecht"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ]
  },
  {
    "id": "arXiv:2210.13762",
    "title": "Towards Robust Recommender Systems via Triple Cooperative Defense",
    "abstract": "Recommender systems are often susceptible to well-crafted fake profiles, leading to biased recommendations. The wide application of recommender systems makes studying the defense against attack necessary. Among existing defense methods, data-processing-based methods inevitably exclude normal samples, while model-based methods struggle to enjoy both generalization and robustness. Considering the above limitations, we suggest integrating data processing and robust model and propose a general framework, Triple Cooperative Defense (TCD), which cooperates to improve model robustness through the co-training of three models. Specifically, in each round of training, we sequentially use the high-confidence prediction ratings (consistent ratings) of any two models as auxiliary training data for the remaining model, and the three models cooperatively improve recommendation robustness. Notably, TCD adds pseudo label data instead of deleting abnormal data, which avoids the cleaning of normal data, and the cooperative training of the three models is also beneficial to model generalization. Through extensive experiments with five poisoning attacks on three real-world datasets, the results show that the robustness improvement of TCD significantly outperforms baselines. It is worth mentioning that TCD is also beneficial for model generalizations. ",
    "url": "https://arxiv.org/abs/2210.13762",
    "authors": [
      "Qingyang Wang",
      "Defu Lian",
      "Chenwang Wu",
      "Enhong Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.13768",
    "title": "GLIF: A Unified Gated Leaky Integrate-and-Fire Neuron for Spiking Neural  Networks",
    "abstract": "Spiking Neural Networks (SNNs) have been studied over decades to incorporate their biological plausibility and leverage their promising energy efficiency. Throughout existing SNNs, the leaky integrate-and-fire (LIF) model is commonly adopted to formulate the spiking neuron and evolves into numerous variants with different biological features. However, most LIF-based neurons support only single biological feature in different neuronal behaviors, limiting their expressiveness and neuronal dynamic diversity. In this paper, we propose GLIF, a unified spiking neuron, to fuse different bio-features in different neuronal behaviors, enlarging the representation space of spiking neurons. In GLIF, gating factors, which are exploited to determine the proportion of the fused bio-features, are learnable during training. Combining all learnable membrane-related parameters, our method can make spiking neurons different and constantly changing, thus increasing the heterogeneity and adaptivity of spiking neurons. Extensive experiments on a variety of datasets demonstrate that our method obtains superior performance compared with other SNNs by simply changing their neuronal formulations to GLIF. In particular, we train a spiking ResNet-19 with GLIF and achieve $77.35\\%$ top-1 accuracy with six time steps on CIFAR-100, which has advanced the state-of-the-art. Codes are available at \\url{https://github.com/Ikarosy/Gated-LIF}. ",
    "url": "https://arxiv.org/abs/2210.13768",
    "authors": [
      "Xingting Yao",
      "Fanrong Li",
      "Zitao Mo",
      "Jian Cheng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13770",
    "title": "The Virality of Hate Speech on Social Media",
    "abstract": "Online hate speech is responsible for violent attacks such as, e.g., the Pittsburgh synagogue shooting in 2018, thereby posing a significant threat to vulnerable groups and society in general. However, little is known about what makes hate speech on social media go viral. In this paper, we collected N = 25,219 Twitter cascades with 65,946 retweets and classify them as hateful vs. normal. Using a generalized linear regression, we then estimate differences in the spread of hateful vs. normal content based on author and content variables. We thereby identify important determinants that explain differences in the spreading of hateful vs. normal content. For example, hateful content authored by verified users is disproportionally more likely to go viral than hateful content from non-verified ones: hateful content from a verified user (as opposed to normal content) has a 3.5 times larger cascade size, a 3.2 times longer cascade lifetime, and a 1.2 times larger structural virality. Altogether, we offer novel insights into the virality of hate speech on social media. ",
    "url": "https://arxiv.org/abs/2210.13770",
    "authors": [
      "Abdurahman Maarouf",
      "Nicolas Pr\u00f6llochs",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.13795",
    "title": "Line Graph Contrastive Learning for Link Prediction",
    "abstract": "Link prediction task aims to predict the connection of two nodes in the network. Existing works mainly predict links by node pairs similarity measurements. However, if the local structure doesn't meet such measurement assumption, the algorithms' performance will deteriorate rapidly. To overcome these limitations, we propose a Line Graph Contrastive Learning (LGCL) method to obtain multiview information. Our framework obtains a subgraph view by h-hop subgraph sampling with target node pairs as the center. After transforming the sampled subgraph into a line graph, the edge embedding information is directly accessible, and the link prediction task is converted into a node classification task. Then, different graph convolution operators learn representations from double perspectives. Finally, contrastive learning is adopted to balance the subgraph representations of these perspectives via maximizing mutual information. With experiments on six public datasets, LGCL outperforms current benchmarks on link prediction tasks and shows better generalization performance and robustness. ",
    "url": "https://arxiv.org/abs/2210.13795",
    "authors": [
      "Zehua Zhang",
      "Shilin Sun",
      "Guixiang Ma",
      "Caiming Zhong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.13801",
    "title": "Deep Boosting Robustness of DNN-based Image Watermarking via DBMark",
    "abstract": "In this paper, we present DBMark, a new end-to-end digital image watermarking framework to deep boost the robustness of DNN-based image watermarking. The key novelty is the synergy of the Invertible Neural Networks(INNs) and effective watermark features generation. The framework generates watermark features with redundancy and error correction ability through message processing, synergized with the powerful information embedding and extraction capabilities of Invertible Neural Networks to achieve higher robustness and invisibility. Extensive experiment results demonstrate the superiority of the proposed framework compared with the state-of-the-art ones under various distortions. ",
    "url": "https://arxiv.org/abs/2210.13801",
    "authors": [
      "Guanhui Ye",
      "Jiashi Gao",
      "Wei Xie",
      "Bo Yin",
      "Xuetao Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.13805",
    "title": "Improving Speech Representation Learning via Speech-level and  Phoneme-level Masking Approach",
    "abstract": "Recovering the masked speech frames is widely applied in speech representation learning. However, most of these models use random masking in the pre-training. In this work, we proposed two kinds of masking approaches: (1) speech-level masking, making the model to mask more speech segments than silence segments, (2) phoneme-level masking, forcing the model to mask the whole frames of the phoneme, instead of phoneme pieces. We pre-trained the model via these two approaches, and evaluated on two downstream tasks, phoneme classification and speaker recognition. The experiments demonstrated that the proposed masking approaches are beneficial to improve the performance of speech representation. ",
    "url": "https://arxiv.org/abs/2210.13805",
    "authors": [
      "Xulong Zhang",
      "Jianzong Wang",
      "Ning Cheng",
      "Kexin Zhu",
      "Jing Xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.13815",
    "title": "FocusedCleaner: Sanitizing Poisoned Graphs for Robust GNN-based Node  Classification",
    "abstract": "Recently, a lot of research attention has been devoted to exploring Web security, a most representative topic is the adversarial robustness of graph mining algorithms. Especially, a widely deployed adversarial attacks formulation is the graph manipulation attacks by modifying the relational data to mislead the Graph Neural Networks' (GNNs) predictions. Naturally, an intrinsic question one would ask is whether we can accurately identify the manipulations over graphs - we term this problem as poisoned graph sanitation. In this paper, we present FocusedCleaner, a poisoned graph sanitation framework consisting of two modules: bi-level structural learning and victim node detection. In particular, the structural learning module will reserve the attack process to steadily sanitize the graph while the detection module provides the \"focus\" - a narrowed and more accurate search region - to structural learning. These two modules will operate in iterations and reinforce each other to sanitize a poisoned graph step by step. Extensive experiments demonstrate that FocusedCleaner outperforms the state-of-the-art baselines both on poisoned graph sanitation and improving robustness. ",
    "url": "https://arxiv.org/abs/2210.13815",
    "authors": [
      "Yulin Zhu",
      "Liang Tong",
      "Kai Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.13821",
    "title": "Salient Object Detection via Dynamic Scale Routing",
    "abstract": "Recent research advances in salient object detection (SOD) could largely be attributed to ever-stronger multi-scale feature representation empowered by the deep learning technologies. The existing SOD deep models extract multi-scale features via the off-the-shelf encoders and combine them smartly via various delicate decoders. However, the kernel sizes in this commonly-used thread are usually \"fixed\". In our new experiments, we have observed that kernels of small size are preferable in scenarios containing tiny salient objects. In contrast, large kernel sizes could perform better for images with large salient objects. Inspired by this observation, we advocate the \"dynamic\" scale routing (as a brand-new idea) in this paper. It will result in a generic plug-in that could directly fit the existing feature backbone. This paper's key technical innovations are two-fold. First, instead of using the vanilla convolution with fixed kernel sizes for the encoder design, we propose the dynamic pyramid convolution (DPConv), which dynamically selects the best-suited kernel sizes w.r.t. the given input. Second, we provide a self-adaptive bidirectional decoder design to accommodate the DPConv-based encoder best. The most significant highlight is its capability of routing between feature scales and their dynamic collection, making the inference process scale-aware. As a result, this paper continues to enhance the current SOTA performance. Both the code and dataset are publicly available at https://github.com/wuzhenyubuaa/DPNet. ",
    "url": "https://arxiv.org/abs/2210.13821",
    "authors": [
      "Zhenyu Wu",
      "Shuai Li",
      "Chenglizhao Chen",
      "Hong Qin",
      "Aimin Hao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13830",
    "title": "Wikinformetrics: Construction and description of an open Wikipedia  knowledge graph dataset for informetric purposes",
    "abstract": "Wikipedia is one of the most visited websites in the world and is also a frequent subject of scientific research. However, the analytical possibilities of Wikipedia information have not yet been analyzed considering at the same time both a large volume of pages and attributes. The main objective of this work is to offer a methodological framework and an open knowledge graph for the informetric large-scale study of Wikipedia. Features of Wikipedia pages are compared with those of scientific publications to highlight the (di)similarities between the two types of documents. Based on this comparison, different analytical possibilities that Wikipedia and its various data sources offer are explored, ultimately offering a set of metrics meant to study Wikipedia from different analytical dimensions. In parallel, a complete dedicated dataset of the English Wikipedia was built (and shared) following a relational model. Finally, a descriptive case study is carried out on the English Wikipedia dataset to illustrate the analytical potential of the knowledge graph and its metrics. ",
    "url": "https://arxiv.org/abs/2210.13830",
    "authors": [
      "Wenceslao Arroyo-Machado",
      "Daniel Torres-Salinas",
      "Rodrigo Costas"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ]
  },
  {
    "id": "arXiv:2210.13835",
    "title": "Synthetic Data Supervised Salient Object Detection",
    "abstract": "Although deep salient object detection (SOD) has achieved remarkable progress, deep SOD models are extremely data-hungry, requiring large-scale pixel-wise annotations to deliver such promising results. In this paper, we propose a novel yet effective method for SOD, coined SODGAN, which can generate infinite high-quality image-mask pairs requiring only a few labeled data, and these synthesized pairs can replace the human-labeled DUTS-TR to train any off-the-shelf SOD model. Its contribution is three-fold. 1) Our proposed diffusion embedding network can address the manifold mismatch and is tractable for the latent code generation, better matching with the ImageNet latent space. 2) For the first time, our proposed few-shot saliency mask generator can synthesize infinite accurate image synchronized saliency masks with a few labeled data. 3) Our proposed quality-aware discriminator can select highquality synthesized image-mask pairs from noisy synthetic data pool, improving the quality of synthetic data. For the first time, our SODGAN tackles SOD with synthetic data directly generated from the generative model, which opens up a new research paradigm for SOD. Extensive experimental results show that the saliency model trained on synthetic data can achieve $98.4\\%$ F-measure of the saliency model trained on the DUTS-TR. Moreover, our approach achieves a new SOTA performance in semi/weakly-supervised methods, and even outperforms several fully-supervised SOTA methods. Code is available at https://github.com/wuzhenyubuaa/SODGAN ",
    "url": "https://arxiv.org/abs/2210.13835",
    "authors": [
      "Zhenyu Wu",
      "Lin Wang",
      "Wei Wang",
      "Tengfei Shi",
      "Chenglizhao Chen",
      "Aimin Hao",
      "Shuo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13836",
    "title": "Deconfounding Legal Judgment Prediction for European Court of Human  Rights Cases Towards Better Alignment with Experts",
    "abstract": "This work demonstrates that Legal Judgement Prediction systems without expert-informed adjustments can be vulnerable to shallow, distracting surface signals that arise from corpus construction, case distribution, and confounding factors. To mitigate this, we use domain expertise to strategically identify statistically predictive but legally irrelevant information. We adopt adversarial training to prevent the system from relying on it. We evaluate our deconfounded models by employing interpretability techniques and comparing to expert annotations. Quantitative experiments and qualitative analysis show that our deconfounded model consistently aligns better with expert rationales than baselines trained for prediction only. We further contribute a set of reference expert annotations to the validation and testing partitions of an existing benchmark dataset of European Court of Human Rights cases. ",
    "url": "https://arxiv.org/abs/2210.13836",
    "authors": [
      "T.Y.S.S Santosh",
      "Shanshan Xu",
      "Oana Ichim",
      "Matthias Grabmair"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.13845",
    "title": "DialogConv: A Lightweight Fully Convolutional Network for Multi-view  Response Selection",
    "abstract": "Current end-to-end retrieval-based dialogue systems are mainly based on Recurrent Neural Networks or Transformers with attention mechanisms. Although promising results have been achieved, these models often suffer from slow inference or huge number of parameters. In this paper, we propose a novel lightweight fully convolutional architecture, called DialogConv, for response selection. DialogConv is exclusively built on top of convolution to extract matching features of context and response. Dialogues are modeled in 3D views, where DialogConv performs convolution operations on embedding view, word view and utterance view to capture richer semantic information from multiple contextual views. On the four benchmark datasets, compared with state-of-the-art baselines, DialogConv is on average about 8.5x smaller in size, and 79.39x and 10.64x faster on CPU and GPU devices, respectively. At the same time, DialogConv achieves the competitive effectiveness of response selection. ",
    "url": "https://arxiv.org/abs/2210.13845",
    "authors": [
      "Yongkang Liu",
      "Shi Feng",
      "Wei Gao",
      "Daling Wang",
      "Yifei Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.13848",
    "title": "Connectivity-Aware Contract for Incentivizing IoT Devices in Complex  Wireless Blockchain Networks",
    "abstract": "Blockchain is considered to be the critical backbone technology for secure and trusted Internet of Things (IoT) on the future 6G network.However, the IoT network is usually with the complex wireless environment, where the communication is not reliable and the connectivity is complicated. Deploying a blockchain system in the complex wireless IoT network is challenging. Due to the limited resources, complex wireless environment and the property of self-interest, IoT devices do not have the internal motivation to consume energy and time to maintain the blockchain. Furthermore, existing incentive mechanism in blockchain is not compatible well with the wireless IoT network. In this paper, to incentivize IoT devices to join the construction of the wireless blockchain network, we propose a multi dimentional contract which optimizes the blockchain utility while addressing the issues of adverse selection and moral hazard. Specifically, the proposed contract not only considers the IoT devices' hash rate and transmission power, but also explores the network connectivity from the perspective of the network complexity. We incestigate the impact of these factors on energy consumption and the block confirmation probability by the experiments under different network sizes and average link probability. Numerical results demonstrate that our proposed contract mechanism is feasible and effective. Compared with the contract with adverse selection, the proposed contract improves blockchain utility by 35%, which is closer to the perfect information contract. ",
    "url": "https://arxiv.org/abs/2210.13848",
    "authors": [
      "Weiyi Wang",
      "Jin Chen",
      "Yutao Jiao",
      "Jiawen Kang",
      "Wenting Dai",
      "Yuhua Xu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.13856",
    "title": "A Framework for Collaborative Multi-Robot Mapping using Spectral Graph  Wavelets",
    "abstract": "The exploration of large-scale unknown environments can benefit from the deployment of multiple robots for collaborative mapping. Each robot explores a section of the environment and communicates onboard pose estimates and maps to a central server to build an optimized global multi-robot map. Naturally, inconsistencies can arise between onboard and server estimates due to onboard odometry drift, failures, or degeneracies. The mapping server can correct and overcome such failure cases using computationally expensive operations such as inter-robot loop closure detection and multi-modal mapping. However, the individual robots do not benefit from the collaborative map if the mapping server provides no feedback. Although server updates from the multi-robot map can greatly alleviate the robotic mission strategically, most existing work lacks them, due to their associated computational and bandwidth-related costs. Motivated by this challenge, this paper proposes a novel collaborative mapping framework that enables global mapping consistency among robots and the mapping server. In particular, we propose graph spectral analysis, at different spatial scales, to detect structural differences between robot and server graphs, and to generate necessary constraints for the individual robot pose graphs. Our approach specifically finds the nodes that correspond to the drift's origin rather than the nodes where the error becomes too large. We thoroughly analyze and validate our proposed framework using several real-world multi-robot field deployments where we show improvements of the onboard system up to 90\\% and can recover the onboard estimation from localization failures and even from the degeneracies within its estimation. ",
    "url": "https://arxiv.org/abs/2210.13856",
    "authors": [
      "Lukas Bernreiter",
      "Shehryar Khattak",
      "Lionel Ott",
      "Roland Siegwart",
      "Marco Hutter",
      "Cesar Cadena"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.13858",
    "title": "LAB: Learnable Activation Binarizer for Binary Neural Networks",
    "abstract": "Binary Neural Networks (BNNs) are receiving an upsurge of attention for bringing power-hungry deep learning towards edge devices. The traditional wisdom in this space is to employ sign() for binarizing featuremaps. We argue and illustrate that sign() is a uniqueness bottleneck, limiting information propagation throughout the network. To alleviate this, we propose to dispense sign(), replacing it with a learnable activation binarizer (LAB), allowing the network to learn a fine-grained binarization kernel per layer - as opposed to global thresholding. LAB is a novel universal module that can seamlessly be integrated into existing architectures. To confirm this, we plug it into four seminal BNNs and show a considerable performance boost at the cost of tolerable increase in delay and complexity. Finally, we build an end-to-end BNN (coined as LAB-BNN) around LAB, and demonstrate that it achieves competitive performance on par with the state-of-the-art on ImageNet. ",
    "url": "https://arxiv.org/abs/2210.13858",
    "authors": [
      "Sieger Falkena",
      "Hadi Jamali-Rad",
      "Jan van Gemert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13861",
    "title": "SUPR: A Sparse Unified Part-Based Human Representation",
    "abstract": "Statistical 3D shape models of the head, hands, and fullbody are widely used in computer vision and graphics. Despite their wide use, we show that existing models of the head and hands fail to capture the full range of motion for these parts. Moreover, existing work largely ignores the feet, which are crucial for modeling human movement and have applications in biomechanics, animation, and the footwear industry. The problem is that previous body part models are trained using 3D scans that are isolated to the individual parts. Such data does not capture the full range of motion for such parts, e.g. the motion of head relative to the neck. Our observation is that full-body scans provide important information about the motion of the body parts. Consequently, we propose a new learning scheme that jointly trains a full-body model and specific part models using a federated dataset of full-body and body-part scans. Specifically, we train an expressive human body model called SUPR (Sparse Unified Part-Based Human Representation), where each joint strictly influences a sparse set of model vertices. The factorized representation enables separating SUPR into an entire suite of body part models. Note that the feet have received little attention and existing 3D body models have highly under-actuated feet. Using novel 4D scans of feet, we train a model with an extended kinematic tree that captures the range of motion of the toes. Additionally, feet deform due to ground contact. To model this, we include a novel non-linear deformation function that predicts foot deformation conditioned on the foot pose, shape, and ground contact. We train SUPR on an unprecedented number of scans: 1.2 million body, head, hand and foot scans. We quantitatively compare SUPR and the separated body parts and find that our suite of models generalizes better than existing models. SUPR is available at this http URL ",
    "url": "https://arxiv.org/abs/2210.13861",
    "authors": [
      "Ahmed A. A. Osman",
      "Timo Bolkart",
      "Dimitrios Tzionas",
      "Michael J. Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13879",
    "title": "Proximal Mean Field Learning in Shallow Neural Networks",
    "abstract": "Recent mean field interpretations of learning dynamics in over-parameterized neural networks offer theoretical insights on the empirical success of first order optimization algorithms in finding global minima of the nonconvex risk landscape. In this paper, we explore applying mean field learning dynamics as a computational algorithm, rather than as an analytical tool. Specifically, we design a Sinkhorn regularized proximal algorithm to approximate the distributional flow from the learning dynamics in the mean field regime over weighted point clouds. In this setting, a contractive fixed point recursion computes the time-varying weights, numerically realizing the interacting Wasserstein gradient flow of the parameter distribution supported over the neuronal ensemble. An appealing aspect of the proposed algorithm is that the measure-valued recursions allow meshless computation. We demonstrate the proposed computational framework of interacting weighted particle evolution on binary and multi-class classification. Our algorithm performs gradient descent of the free energy associated with the risk functional. ",
    "url": "https://arxiv.org/abs/2210.13879",
    "authors": [
      "Alexis Teter",
      "Iman Nodozi",
      "Abhishek Halder"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.13900",
    "title": "Deep nurbs -- admissible neural networks",
    "abstract": "In this study, we propose a new numerical scheme for physics-informed neural networks (PINNs) that enables precise and inexpensive solution for partial differential equations (PDEs) in case of arbitrary geometries while strictly enforcing Dirichlet boundary conditions. The proposed approach combines admissible NURBS parametrizations required to define the physical domain and the Dirichlet boundary conditions with a PINN solver. The fundamental boundary conditions are automatically satisfied in this novel Deep NURBS framework. We verified our new approach using two-dimensional elliptic PDEs when considering arbitrary geometries, including non-Lipschitz domains. Compared to the classical PINN solver, the Deep NURBS estimator has a remarkably high convergence rate for all the studied problems. Moreover, a desirable accuracy was realized for most of the studied PDEs using only one hidden layer of neural networks. This novel approach is considered to pave the way for more effective solutions for high-dimensional problems by allowing for more realistic physics-informed statistical learning to solve PDE-based variational problems. ",
    "url": "https://arxiv.org/abs/2210.13900",
    "authors": [
      "Hamed Saidaoui",
      "Luis Espath",
      "R\u00e1ul Tempone"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.13907",
    "title": "Finding Early Adopters of Innovation in Social Network",
    "abstract": "Social networks play a fundamental role in the diffusion of innovation through peers' influence on adoption. Thus, network position including a wide range of network centrality measures have been used to describe individuals' affinity to adopt an innovation and their ability to propagate diffusion. Yet, social networks are assortative in terms of susceptibility and influence and in terms of network centralities as well. This makes the identification of influencers difficult especially since susceptibility and centrality does not always go hand in hand. Here we propose the Top Candidate algorithm, an expert recommendation method, to rank individuals based on their perceived expertise, which resonates well with the assortative nature of innovators and early adopters. Leveraging adoption data from two online social networks that are assortative in terms of adoption but represent different levels of assortativity of network centralities, we demonstrate that the Top Candidate ranking is more efficient in capturing early adopters than other widely used indices. Top Candidate nodes adopt earlier and have higher reach among innovators, early adopters and early majority than nodes highlighted by other methods. These results suggest that the Top Candidate method can identify good seeds for influence maximization campaigns on social networks. ",
    "url": "https://arxiv.org/abs/2210.13907",
    "authors": [
      "Bal\u00e1zs R. Sziklai",
      "Bal\u00e1zs Lengyel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2210.13915",
    "title": "Towards Formal Approximated Minimal Explanations of Neural Networks",
    "abstract": "With the rapid growth of machine learning, deep neural networks (DNNs) are now being used in numerous domains. Unfortunately, DNNs are \"black-boxes\", and cannot be interpreted by humans, which is a substantial concern in safety-critical systems. To mitigate this issue, researchers have begun working on explainable AI (XAI) methods, which can identify a subset of input features that are the cause of a DNN's decision for a given input. Most existing techniques are heuristic, and cannot guarantee the correctness of the explanation provided. In contrast, recent and exciting attempts have shown that formal methods can be used to generate provably correct explanations. Although these methods are sound, the computational complexity of the underlying verification problem limits their scalability; and the explanations they produce might sometimes be overly complex. Here, we propose a novel approach to tackle these limitations. We (1) suggest an efficient, verification-based method for finding minimal explanations, which constitute a provable approximation of the global, minimum explanation; (2) show how DNN verification can assist in calculating lower and upper bounds on the optimal explanation; (3) propose heuristics that significantly improve the scalability of the verification process; and (4) suggest the use of bundles, which allows us to arrive at more succinct and interpretable explanations. Our evaluation shows that our approach significantly outperforms state-of-the-art techniques, and produces explanations that are more useful to humans. We thus regard this work as a step toward leveraging verification technology in producing DNNs that are more reliable and comprehensible. ",
    "url": "https://arxiv.org/abs/2210.13915",
    "authors": [
      "Shahaf Bassan",
      "Guy Katz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ]
  },
  {
    "id": "arXiv:2210.13917",
    "title": "Connective Reconstruction-based Novelty Detection",
    "abstract": "Detection of out-of-distribution samples is one of the critical tasks for real-world applications of computer vision. The advancement of deep learning has enabled us to analyze real-world data which contain unexplained samples, accentuating the need to detect out-of-distribution instances more than before. GAN-based approaches have been widely used to address this problem due to their ability to perform distribution fitting; however, they are accompanied by training instability and mode collapse. We propose a simple yet efficient reconstruction-based method that avoids adding complexities to compensate for the limitations of GAN models while outperforming them. Unlike previous reconstruction-based works that only utilize reconstruction error or generated samples, our proposed method simultaneously incorporates both of them in the detection task. Our model, which we call \"Connective Novelty Detection\" has two subnetworks, an autoencoder, and a binary classifier. The autoencoder learns the representation of the positive class by reconstructing them. Then, the model creates negative and connected positive examples using real and generated samples. Negative instances are generated via manipulating the real data, so their distribution is close to the positive class to achieve a more accurate boundary for the classifier. To boost the robustness of the detection to reconstruction error, connected positive samples are created by combining the real and generated samples. Finally, the binary classifier is trained using connected positive and negative examples. We demonstrate a considerable improvement in novelty detection over state-of-the-art methods on MNIST and Caltech-256 datasets. ",
    "url": "https://arxiv.org/abs/2210.13917",
    "authors": [
      "Seyyed Morteza Hashemi",
      "Parvaneh Aliniya",
      "Parvin Razzaghi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.13923",
    "title": "A Comparative Attention Framework for Better Few-Shot Object Detection  on Aerial Images",
    "abstract": "Few-Shot Object Detection (FSOD) methods are mainly designed and evaluated on natural image datasets such as Pascal VOC and MS COCO. However, it is not clear whether the best methods for natural images are also the best for aerial images. Furthermore, direct comparison of performance between FSOD methods is difficult due to the wide variety of detection frameworks and training strategies. Therefore, we propose a benchmarking framework that provides a flexible environment to implement and compare attention-based FSOD methods. The proposed framework focuses on attention mechanisms and is divided into three modules: spatial alignment, global attention, and fusion layer. To remain competitive with existing methods, which often leverage complex training, we propose new augmentation techniques designed for object detection. Using this framework, several FSOD methods are reimplemented and compared. This comparison highlights two distinct performance regimes on aerial and natural images: FSOD performs worse on aerial images. Our experiments suggest that small objects, which are harder to detect in the few-shot setting, account for the poor performance. Finally, we develop a novel multiscale alignment method, Cross-Scales Query-Support Alignment (XQSA) for FSOD, to improve the detection of small objects. XQSA outperforms the state-of-the-art significantly on DOTA and DIOR. ",
    "url": "https://arxiv.org/abs/2210.13923",
    "authors": [
      "Pierre Le Jeune",
      "Anissa Mokraoui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13932",
    "title": "CoLoC: Conditioned Localizer and Classifier for Sound Event Localization  and Detection",
    "abstract": "In this article, we describe Conditioned Localizer and Classifier (CoLoC) which is a novel solution for Sound Event Localization and Detection (SELD). The solution constitutes of two stages: the localization is done first and is followed by classification conditioned by the output of the localizer. In order to resolve the problem of the unknown number of sources we incorporate the idea borrowed from Sequential Set Generation (SSG). Models from both stages are SELDnet-like CRNNs, but with single outputs. Conducted reasoning shows that such two single-output models are fit for SELD task. We show that our solution improves on the baseline system in most metrics on the STARSS22 Dataset. ",
    "url": "https://arxiv.org/abs/2210.13932",
    "authors": [
      "S\u0142awomir Kapka",
      "Jakub Tkaczuk"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.13941",
    "title": "Structural analysis of water networks",
    "abstract": "Liquid water, besides being fundamental for life on Earth, has long fascinated scientists due to several anomalies. Different hypotheses have been put forward to explain these peculiarities. The most accredited one foresees the presence in the supercooled region of two phases at different densities: the low-density liquid phase and the high-density liquid phase. In our previous work [Faccio et al., J. Mol. Liq. 355 (2022): 118922], we showed that it is possible to identify these two forms in water networks through a computational approach based on molecular dynamics simulation and on the calculation of the total communicability of the associated graph, in which the nodes correspond to water molecules and the edges represent the connections (interactions) between molecules. In this paper, we present a more in-depth investigation of the application of graph-theory based approaches to the analysis of the structure of water networks. In particular, we investigate different connectivity and centrality measures and we report on the use of a variety of global metrics aimed at giving a topological and geometrical characterization of liquid water. ",
    "url": "https://arxiv.org/abs/2210.13941",
    "authors": [
      "Michele Benzi",
      "Isabella Daidone",
      "Chiara Faccio",
      "Laura Zanetti-Polzi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2210.13945",
    "title": "Comparing neural network training performance between Elixir and Python",
    "abstract": "With a wide range of libraries focused on the machine learning market, such as TensorFlow, NumPy, Pandas, Keras, and others, Python has made a name for itself as one of the main programming languages. In February 2021, Jos\\'e Valim and Sean Moriarity published the first version of the Numerical Elixir (Nx) library, a library for tensor operations written in Elixir. Nx aims to allow the language be a good choice for GPU-intensive operations. This work aims to compare the results of Python and Elixir on training convolutional neural networks (CNN) using MNIST and CIFAR-10 datasets, concluding that Python achieved overall better results, and that Elixir is already a viable alternative. ",
    "url": "https://arxiv.org/abs/2210.13945",
    "authors": [
      "Lucas C. Tavano",
      "Lucas K. Amin",
      "Adolfo Gustavo Serra-Seca-Neto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ]
  },
  {
    "id": "arXiv:2210.13956",
    "title": "HiddenGems: Efficient safety boundary detection with active learning",
    "abstract": "Evaluating safety performance in a resource-efficient way is crucial for the development of autonomous systems. Simulation of parameterized scenarios is a popular testing strategy but parameter sweeps can be prohibitively expensive. To address this, we propose HiddenGems: a sample-efficient method for discovering the boundary between compliant and non-compliant behavior via active learning. Given a parameterized scenario, one or more compliance metrics, and a simulation oracle, HiddenGems maps the compliant and non-compliant domains of the scenario. The methodology enables critical test case identification, comparative analysis of different versions of the system under test, as well as verification of design objectives. We evaluate HiddenGems on a scenario with a jaywalker crossing in front of an autonomous vehicle and obtain compliance boundary estimates for collision, lane keep, and acceleration metrics individually and in combination, with 6 times fewer simulations than a parameter sweep. We also show how HiddenGems can be used to detect and rectify a failure mode for an unprotected turn with 86% fewer simulations. ",
    "url": "https://arxiv.org/abs/2210.13956",
    "authors": [
      "Aleksandar Petrov",
      "Carter Fang",
      "Khang Minh Pham",
      "You Hong Eng",
      "James Guo Ming Fu",
      "Scott Drew Pendleton"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.13978",
    "title": "Boosting the Cycle Counting Power of Graph Neural Networks with  I$^2$-GNNs",
    "abstract": "Message Passing Neural Networks (MPNNs) are a widely used class of Graph Neural Networks (GNNs). The limited representational power of MPNNs inspires the study of provably powerful GNN architectures. However, knowing one model is more powerful than another gives little insight about what functions they can or cannot express. It is still unclear whether these models are able to approximate specific functions such as counting certain graph substructures, which is essential for applications in biology, chemistry and social network analysis. Motivated by this, we propose to study the counting power of Subgraph MPNNs, a recent and popular class of powerful GNN models that extract rooted subgraphs for each node, assign the root node a unique identifier and encode the root node's representation within its rooted subgraph. Specifically, we prove that Subgraph MPNNs fail to count more-than-4-cycles at node level, implying that node representations cannot correctly encode the surrounding substructures like ring systems with more than four atoms. To overcome this limitation, we propose I$^2$-GNNs to extend Subgraph MPNNs by assigning different identifiers for the root node and its neighbors in each subgraph. I$^2$-GNNs' discriminative power is shown to be strictly stronger than Subgraph MPNNs and partially stronger than the 3-WL test. More importantly, I$^2$-GNNs are proven capable of counting all 3, 4, 5 and 6-cycles, covering common substructures like benzene rings in organic chemistry, while still keeping linear complexity. To the best of our knowledge, it is the first linear-time GNN model that can count 6-cycles with theoretical guarantees. We validate its counting power in cycle counting tasks and demonstrate its competitive performance in molecular prediction benchmarks. ",
    "url": "https://arxiv.org/abs/2210.13978",
    "authors": [
      "Yinan Huang",
      "Xingang Peng",
      "Jianzhu Ma",
      "Muhan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13979",
    "title": "Meta-learning Pathologies from Radiology Reports using Variance Aware  Prototypical Networks",
    "abstract": "Large pretrained Transformer-based language models like BERT and GPT have changed the landscape of Natural Language Processing (NLP). However, fine tuning such models still requires a large number of training examples for each target task, thus annotating multiple datasets and training these models on various downstream tasks becomes time consuming and expensive. In this work, we propose a simple extension of the Prototypical Networks for few-shot text classification. Our main idea is to replace the class prototypes by Gaussians and introduce a regularization term that encourages the examples to be clustered near the appropriate class centroids. Experimental results show that our method outperforms various strong baselines on 13 public and 4 internal datasets. Furthermore, we use the class distributions as a tool for detecting potential out-of-distribution (OOD) data points during deployment. ",
    "url": "https://arxiv.org/abs/2210.13979",
    "authors": [
      "Arijit Sehanobish",
      "Kawshik Kannan",
      "Nabila Abraham",
      "Anasuya Das",
      "Benjamin Odry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.13982",
    "title": "Hindering Adversarial Attacks with Implicit Neural Representations",
    "abstract": "We introduce the Lossy Implicit Network Activation Coding (LINAC) defence, an input transformation which successfully hinders several common adversarial attacks on CIFAR-$10$ classifiers for perturbations up to $\\epsilon = 8/255$ in $L_\\infty$ norm and $\\epsilon = 0.5$ in $L_2$ norm. Implicit neural representations are used to approximately encode pixel colour intensities in $2\\text{D}$ images such that classifiers trained on transformed data appear to have robustness to small perturbations without adversarial training or large drops in performance. The seed of the random number generator used to initialise and train the implicit neural representation turns out to be necessary information for stronger generic attacks, suggesting its role as a private key. We devise a Parametric Bypass Approximation (PBA) attack strategy for key-based defences, which successfully invalidates an existing method in this category. Interestingly, our LINAC defence also hinders some transfer and adaptive attacks, including our novel PBA strategy. Our results emphasise the importance of a broad range of customised attacks despite apparent robustness according to standard evaluations. LINAC source code and parameters of defended classifier evaluated throughout this submission are available: https://github.com/deepmind/linac ",
    "url": "https://arxiv.org/abs/2210.13982",
    "authors": [
      "Andrei A. Rusu",
      "Dan A. Calian",
      "Sven Gowal",
      "Raia Hadsell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ]
  },
  {
    "id": "arXiv:2210.13988",
    "title": "Attention Based Relation Network for Facial Action Units Recognition",
    "abstract": "Facial action unit (AU) recognition is essential to facial expression analysis. Since there are highly positive or negative correlations between AUs, some existing AU recognition works have focused on modeling AU relations. However, previous relationship-based approaches typically embed predefined rules into their models and ignore the impact of various AU relations in different crowds. In this paper, we propose a novel Attention Based Relation Network (ABRNet) for AU recognition, which can automatically capture AU relations without unnecessary or even disturbing predefined rules. ABRNet uses several relation learning layers to automatically capture different AU relations. The learned AU relation features are then fed into a self-attention fusion module, which aims to refine individual AU features with attention weights to enhance the feature robustness. Furthermore, we propose an AU relation dropout strategy and AU relation loss (AUR-Loss) to better model AU relations, which can further improve AU recognition. Extensive experiments show that our approach achieves state-of-the-art performance on the DISFA and DISFA+ datasets. ",
    "url": "https://arxiv.org/abs/2210.13988",
    "authors": [
      "Yao Wei",
      "Haoxiang Wang",
      "Mingze Sun",
      "Jiawang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.13992",
    "title": "SphNet: A Spherical Network for Semantic Pointcloud Segmentation",
    "abstract": "Semantic segmentation for robotic systems can enable a wide range of applications, from self-driving cars and augmented reality systems to domestic robots. We argue that a spherical representation is a natural one for egocentric pointclouds. Thus, in this work, we present a novel framework exploiting such a representation of LiDAR pointclouds for the task of semantic segmentation. Our approach is based on a spherical convolutional neural network that can seamlessly handle observations from various sensor systems (e.g., different LiDAR systems) and provides an accurate segmentation of the environment. We operate in two distinct stages: First, we encode the projected input pointclouds to spherical features. Second, we decode and back-project the spherical features to achieve an accurate semantic segmentation of the pointcloud. We evaluate our method with respect to state-of-the-art projection-based semantic segmentation approaches using well-known public datasets. We demonstrate that the spherical representation enables us to provide more accurate segmentation and to have a better generalization to sensors with different field-of-view and number of beams than what was seen during training. ",
    "url": "https://arxiv.org/abs/2210.13992",
    "authors": [
      "Lukas Bernreiter",
      "Lionel Ott",
      "Roland Siegwart",
      "Cesar Cadena"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.13996",
    "title": "Report on the energy consumption of the IOTA 2.0 prototype network  (GoShimmer 0.8.3) under different testing scenarios",
    "abstract": "The high energy consumption of proof of work-based distributed ledgers has become an important environmental concern. Bitcoin, for example, consumes as much energy in a year as a developed country. Alternative consensus mechanisms, such as proof of stake, have been shown to use drastically less energy than proof of work-based DLTs. For example, the IOTA DLT, built upon a directed acyclic graph (DAG) architecture, uses an alternative consensus mechanism that requires significantly less energy than other DLTs. Because the (DLT) space is constantly and rapidly evolving, the question of how much energy DLTs actually consume demands to be continuously studied and answered. Previous research into the energy consumption of the IOTA network has shown that an optimization in the overall protocol correlates to an optimization in energy consumption. The planned IOTA 2.0 update, built upon the GoShimmer research prototype, promises to further optimize the protocol by removing the network's centralized Coordinator. This report presents the results of measuring the energy consumption of a private GoShimmer network while comparing these findings to previous research into the current mainnet, which is called Chrysalis. The main findings of this report are that the IOTA 2.0 research prototype shows both improvements and increase in the energy consumption metrics compared to the Chrysalis network. Additionally, this report defines a model to estimate the total annual energy consumption of an IOTA network. This model should be significant for future research as it enables a way to estimate the total cost of running the IOTA network as well as its carbon emissions. Moreover, having an annual power consumption metric allows for better objective comparisons to different DLTs. ",
    "url": "https://arxiv.org/abs/2210.13996",
    "authors": [
      "Louis Helmer",
      "Andreas Penzkofer"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.14011",
    "title": "Are All Spurious Features in Natural Language Alike? An Analysis through  a Causal Lens",
    "abstract": "The term `spurious correlations' has been used in NLP to informally denote any undesirable feature-label correlations. However, a correlation can be undesirable because (i) the feature is irrelevant to the label (e.g. punctuation in a review), or (ii) the feature's effect on the label depends on the context (e.g. negation words in a review), which is ubiquitous in language tasks. In case (i), we want the model to be invariant to the feature, which is neither necessary nor sufficient for prediction. But in case (ii), even an ideal model (e.g. humans) must rely on the feature, since it is necessary (but not sufficient) for prediction. Therefore, a more fine-grained treatment of spurious features is needed to specify the desired model behavior. We formalize this distinction using a causal model and probabilities of necessity and sufficiency, which delineates the causal relations between a feature and a label. We then show that this distinction helps explain results of existing debiasing methods on different spurious features, and demystifies surprising results such as the encoding of spurious features in model representations after debiasing. ",
    "url": "https://arxiv.org/abs/2210.14011",
    "authors": [
      "Nitish Joshi",
      "Xiang Pan",
      "He He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14012",
    "title": "Gradient-based Weight Density Balancing for Robust Dynamic Sparse  Training",
    "abstract": "Training a sparse neural network from scratch requires optimizing connections at the same time as the weights themselves. Typically, the weights are redistributed after a predefined number of weight updates, removing a fraction of the parameters of each layer and inserting them at different locations in the same layers. The density of each layer is determined using heuristics, often purely based on the size of the parameter tensor. While the connections per layer are optimized multiple times during training, the density of each layer typically remains constant. This leaves great unrealized potential, especially in scenarios with a high sparsity of 90% and more. We propose Global Gradient-based Redistribution, a technique which distributes weights across all layers - adding more weights to the layers that need them most. Our evaluation shows that our approach is less prone to unbalanced weight distribution at initialization than previous work and that it is able to find better performing sparse subnetworks at very high sparsity levels. ",
    "url": "https://arxiv.org/abs/2210.14012",
    "authors": [
      "Mathias Parger",
      "Alexander Ertl",
      "Paul Eibensteiner",
      "Joerg H. Mueller",
      "Martin Winter",
      "Markus Steinberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14016",
    "title": "Shortest Edit Path Crossover: A Theory-driven Solution to the  Permutation Problem in Evolutionary Neural Architecture Search",
    "abstract": "Evolutionary algorithms (EAs) have gained attention recently due to their success in neural architecture search (NAS). However, whereas traditional EAs draw much power from crossover operations, most evolutionary NAS methods deploy only mutation operators. The main reason is the permutation problem: The mapping between genotype and phenotype in traditional graph representations is many-to-one, leading to a disruptive effect of standard crossover. This work conducts the first theoretical analysis of the behaviors of crossover and mutation in the NAS context, and proposes a new crossover operator based on the shortest edit path (SEP) in graph space. The SEP crossover is shown to overcome the permutation problem, and as a result, offspring generated by the SEP crossover is theoretically proved to have a better expected improvement in terms of graph edit distance to global optimum, compared to mutation and standard crossover. Experiments further show that the SEP crossover significantly outperforms mutation and standard crossover on three state-of-the-art NAS benchmarks. The SEP crossover therefore allows taking full advantage of evolution in NAS, and potentially other similar design problems as well. ",
    "url": "https://arxiv.org/abs/2210.14016",
    "authors": [
      "Xin Qiu",
      "Risto Miikkulainen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.14018",
    "title": "A White-Box Adversarial Attack Against a Digital Twin",
    "abstract": "Recent research has shown that Machine Learning/Deep Learning (ML/DL) models are particularly vulnerable to adversarial perturbations, which are small changes made to the input data in order to fool a machine learning classifier. The Digital Twin, which is typically described as consisting of a physical entity, a virtual counterpart, and the data connections in between, is increasingly being investigated as a means of improving the performance of physical entities by leveraging computational techniques, which are enabled by the virtual counterpart. This paper explores the susceptibility of Digital Twin (DT), a virtual model designed to accurately reflect a physical object using ML/DL classifiers that operate as Cyber Physical Systems (CPS), to adversarial attacks. As a proof of concept, we first formulate a DT of a vehicular system using a deep neural network architecture and then utilize it to launch an adversarial attack. We attack the DT model by perturbing the input to the trained model and show how easily the model can be broken with white-box attacks. ",
    "url": "https://arxiv.org/abs/2210.14018",
    "authors": [
      "Wilson Patterson",
      "Ivan Fernandez",
      "Subash Neupane",
      "Milan Parmar",
      "Sudip Mittal",
      "Shahram Rahimi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14056",
    "title": "Unsupervised Anomaly Detection for Auditing Data and Impact of  Categorical Encodings",
    "abstract": "In this paper, we introduce the Vehicle Claims dataset, consisting of fraudulent insurance claims for automotive repairs. The data belongs to the more broad category of Auditing data, which includes also Journals and Network Intrusion data. Insurance claim data are distinctively different from other auditing data (such as network intrusion data) in their high number of categorical attributes. We tackle the common problem of missing benchmark datasets for anomaly detection: datasets are mostly confidential, and the public tabular datasets do not contain relevant and sufficient categorical attributes. Therefore, a large-sized dataset is created for this purpose and referred to as Vehicle Claims (VC) dataset. The dataset is evaluated on shallow and deep learning methods. Due to the introduction of categorical attributes, we encounter the challenge of encoding them for the large dataset. As One Hot encoding of high cardinal dataset invokes the \"curse of dimensionality\", we experiment with GEL encoding and embedding layer for representing categorical attributes. Our work compares competitive learning, reconstruction-error, density estimation and contrastive learning approaches for Label, One Hot, GEL encoding and embedding layer to handle categorical values. ",
    "url": "https://arxiv.org/abs/2210.14056",
    "authors": [
      "Ajay Chawda",
      "Stefanie Grimm",
      "Marius Kloft"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.14064",
    "title": "Learning Low Dimensional State Spaces with Overparameterized Recurrent  Neural Network",
    "abstract": "Overparameterization in deep learning typically refers to settings where a trained Neural Network (NN) has representational capacity to fit the training data in many ways, some of which generalize well, while others do not. In the case of Recurrent Neural Networks (RNNs), there exists an additional layer of overparameterization, in the sense that a model may exhibit many solutions that generalize well for sequence lengths seen in training, some of which extrapolate to longer sequences, while others do not. Numerous works studied the tendency of Gradient Descent (GD) to fit overparameterized NNs with solutions that generalize well. On the other hand, its tendency to fit overparameterized RNNs with solutions that extrapolate has been discovered only lately, and is far less understood. In this paper, we analyze the extrapolation properties of GD when applied to overparameterized linear RNNs. In contrast to recent arguments suggesting an implicit bias towards short-term memory, we provide theoretical evidence for learning low dimensional state spaces, which can also model long-term memory. Our result relies on a dynamical characterization which shows that GD (with small step size and near-zero initialization) strives to maintain a certain form of balancedness, as well as on tools developed in the context of the moment problem from statistics (recovery of a probability distribution from its moments). Experiments corroborate our theory, demonstrating extrapolation via learning low dimensional state spaces with both linear and non-linear RNNs ",
    "url": "https://arxiv.org/abs/2210.14064",
    "authors": [
      "Edo Cohen-Karlik",
      "Itamar Menuhin-Gruman",
      "Nadav Cohen",
      "Raja Giryes",
      "Amir Globerson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14080",
    "title": "Learning Individual Treatment Effects under Heterogeneous Interference  in Networks",
    "abstract": "Estimates of individual treatment effects from networked observational data are attracting increasing attention these days. One major challenge in network scenarios is the violation of the stable unit treatment value assumption (SUTVA), which assumes that the treatment assignment of a unit does not influence others' outcomes. In network data, due to interference, the outcome of a unit is influenced not only by its treatment (i.e., direct effects) but also by others' treatments (i.e., spillover effects). Furthermore, the influences from other units are always heterogeneous (e.g., friends with similar interests affect a person differently than friends with different interests). In this paper, we focus on the problem of estimating individual treatment effects (both direct and spillover effects) under heterogeneous interference. To address this issue, we propose a novel Dual Weighting Regression (DWR) algorithm by simultaneously learning attention weights that capture the heterogeneous interference and sample weights to eliminate the complex confounding bias in networks. We formulate the entire learning process as a bi-level optimization problem. In theory, we present generalization error bounds for individual treatment effect estimation. Extensive experiments on four benchmark datasets demonstrate that the proposed DWR algorithm outperforms state-of-the-art methods for estimating individual treatment effects under heterogeneous interference. ",
    "url": "https://arxiv.org/abs/2210.14080",
    "authors": [
      "Ziyu Zhao",
      "Kun Kuang",
      "Ruoxuan Xiong",
      "Fei Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2210.14085",
    "title": "Audio MFCC-gram Transformers for respiratory insufficiency detection in  COVID-19",
    "abstract": "This work explores speech as a biomarker and investigates the detection of respiratory insufficiency (RI) by analyzing speech samples. Previous work \\cite{spira2021} constructed a dataset of respiratory insufficiency COVID-19 patient utterances and analyzed it by means of a convolutional neural network achieving an accuracy of $87.04\\%$, validating the hypothesis that one can detect RI through speech. Here, we study how Transformer neural network architectures can improve the performance on RI detection. This approach enables construction of an acoustic model. By choosing the correct pretraining technique, we generate a self-supervised acoustic model, leading to improved performance ($96.53\\%$) of Transformers for RI detection. ",
    "url": "https://arxiv.org/abs/2210.14085",
    "authors": [
      "Marcelo Matheus Gauy",
      "Marcelo Finger"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.14129",
    "title": "A Deep Fourier Residual Method for solving PDEs using Neural Networks",
    "abstract": "When using Neural Networks as trial functions to numerically solve PDEs, a key choice to be made is the loss function to be minimised, which should ideally correspond to a norm of the error. In multiple problems, this error norm coincides with--or is equivalent to--the $H^{-1}$-norm of the residual; however, it is often difficult to accurately compute it. This work assumes rectangular domains and proposes the use of a Discrete Sine/Cosine Transform to accurately and efficiently compute the $H^{-1}$ norm. The resulting Deep Fourier-based Residual (DFR) method efficiently and accurately approximate solutions to PDEs. This is particularly useful when solutions lack $H^{2}$ regularity and methods involving strong formulations of the PDE fail. We observe that the $H^1$-error is highly correlated with the discretised loss during training, which permits accurate error estimation via the loss. ",
    "url": "https://arxiv.org/abs/2210.14129",
    "authors": [
      "Jamie M. Taylor",
      "David Pardo",
      "Ignacio Muga"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ]
  },
  {
    "id": "arXiv:2210.14136",
    "title": "PolyHope: Dataset Creation for a Two-Level Hope Speech Detection Task  from Tweets",
    "abstract": "Hope is characterized as openness of spirit toward the future, a desire, expectation, and wish for something to happen or to be true that remarkably affects human's state of mind, emotions, behaviors, and decisions. Hope is usually associated with concepts of desired expectations and possibility/probability concerning the future. Despite its importance, hope has rarely been studied as a social media analysis task. This paper presents a hope speech dataset that classifies each tweet first into \"Hope\" and \"Not Hope\", then into three fine-grained hope categories: \"Generalized Hope\", \"Realistic Hope\", and \"Unrealistic Hope\" (along with \"Not Hope\"). English tweets in the first half of 2022 were collected to build this dataset. Furthermore, we describe our annotation process and guidelines in detail and discuss the challenges of classifying hope and the limitations of the existing hope speech detection corpora. In addition, we reported several baselines based on different learning approaches, such as traditional machine learning, deep learning, and transformers, to benchmark our dataset. We evaluated our baselines using weighted-averaged and macro-averaged F1-scores. Observations show that a strict process for annotator selection and detailed annotation guidelines enhanced the dataset's quality. This strict annotation process resulted in promising performance for simple machine learning classifiers with only bi-grams; however, binary and multiclass hope speech detection results reveal that contextual embedding models have higher performance in this dataset. ",
    "url": "https://arxiv.org/abs/2210.14136",
    "authors": [
      "Fazlourrahman Balouchzahi",
      "Grigori Sidorov",
      "Alexander Gelbukh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14140",
    "title": "Contrastive Search Is What You Need For Neural Text Generation",
    "abstract": "Generating text with autoregressive language models (LMs) is of great importance to many natural language processing (NLP) applications. Previous solutions for this task often produce text that contains degenerative expressions or lacks semantic consistency. Recently, Su et al. introduced a new decoding method, contrastive search, based on the isotropic representation space of the language model and obtained new state of the art on various benchmarks. Additionally, Su et al. argued that the representations of autoregressive LMs (e.g. GPT-2) are intrinsically anisotropic which is also shared by previous study. Therefore, to ensure the language model follows an isotropic distribution, Su et al. proposed a contrastive learning scheme, SimCTG, which calibrates the language model's representations through additional training. In this study, we first answer the question: \"Are autoregressive LMs really anisotropic?\". To this end, we extensively evaluate the isotropy of LMs across 16 major languages. Surprisingly, we find that the anisotropic problem only exists in the two specific English GPT-2-small/medium models. On the other hand, all other evaluated LMs are naturally isotropic which is in contrast to the conclusion drawn by previous studies. Based on our findings, we further assess the contrastive search decoding method using off-the-shelf LMs on four generation tasks across 16 languages. Our experimental results demonstrate that contrastive search significantly outperforms previous decoding methods without any additional training. More notably, on 12 out of 16 evaluated languages, contrastive search performs comparably with human-level performances as judged by human evaluations. ",
    "url": "https://arxiv.org/abs/2210.14140",
    "authors": [
      "Yixuan Su",
      "Nigel Collier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.14153",
    "title": "Detection of Real-time DeepFakes in Video Conferencing with Active  Probing and Corneal Reflection",
    "abstract": "The COVID pandemic has led to the wide adoption of online video calls in recent years. However, the increasing reliance on video calls provides opportunities for new impersonation attacks by fraudsters using the advanced real-time DeepFakes. Real-time DeepFakes pose new challenges to detection methods, which have to run in real-time as a video call is ongoing. In this paper, we describe a new active forensic method to detect real-time DeepFakes. Specifically, we authenticate video calls by displaying a distinct pattern on the screen and using the corneal reflection extracted from the images of the call participant's face. This pattern can be induced by a call participant displaying on a shared screen or directly integrated into the video-call client. In either case, no specialized imaging or lighting hardware is required. Through large-scale simulations, we evaluate the reliability of this approach under a range in a variety of real-world imaging scenarios. ",
    "url": "https://arxiv.org/abs/2210.14153",
    "authors": [
      "Hui Guo",
      "Xin Wang",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.14162",
    "title": "Commonsense Knowledge from Scene Graphs for Textual Environments",
    "abstract": "Text-based games are becoming commonly used in reinforcement learning as real-world simulation environments. They are usually imperfect information games, and their interactions are only in the textual modality. To challenge these games, it is effective to complement the missing information by providing knowledge outside the game, such as human common sense. However, such knowledge has only been available from textual information in previous works. In this paper, we investigate the advantage of employing commonsense reasoning obtained from visual datasets such as scene graph datasets. In general, images convey more comprehensive information compared with text for humans. This property enables to extract commonsense relationship knowledge more useful for acting effectively in a game. We compare the statistics of spatial relationships available in Visual Genome (a scene graph dataset) and ConceptNet (a text-based knowledge) to analyze the effectiveness of introducing scene graph datasets. We also conducted experiments on a text-based game task that requires commonsense reasoning. Our experimental results demonstrated that our proposed methods have higher and competitive performance than existing state-of-the-art methods. ",
    "url": "https://arxiv.org/abs/2210.14162",
    "authors": [
      "Tsunehiko Tanaka",
      "Daiki Kimura",
      "Michiaki Tatsubori"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.14163",
    "title": "Multi-Granularity Cross-Modality Representation Learning for Named  Entity Recognition on Social Media",
    "abstract": "Named Entity Recognition (NER) on social media refers to discovering and classifying entities from unstructured free-form content, and it plays an important role for various applications such as intention understanding and user recommendation. With social media posts tending to be multimodal, Multimodal Named Entity Recognition (MNER) for the text with its accompanying image is attracting more and more attention since some textual components can only be understood in combination with visual information. However, there are two drawbacks in existing approaches: 1) Meanings of the text and its accompanying image do not match always, so the text information still plays a major role. However, social media posts are usually shorter and more informal compared with other normal contents, which easily causes incomplete semantic description and the data sparsity problem. 2) Although the visual representations of whole images or objects are already used, existing methods ignore either fine-grained semantic correspondence between objects in images and words in text or the objective fact that there are misleading objects or no objects in some images. In this work, we solve the above two problems by introducing the multi-granularity cross-modality representation learning. To resolve the first problem, we enhance the representation by semantic augmentation for each word in text. As for the second issue, we perform the cross-modality semantic interaction between text and vision at the different vision granularity to get the most effective multimodal guidance representation for every word. Experiments show that our proposed approach can achieve the SOTA or approximate SOTA performance on two benchmark datasets of tweets. The code, data and the best performing models are available at https://github.com/LiuPeiP-CS/IIE4MNER ",
    "url": "https://arxiv.org/abs/2210.14163",
    "authors": [
      "Peipei Liu",
      "Gaosheng Wang",
      "Hong Li",
      "Jie Liu",
      "Yimo Ren",
      "Hongsong Zhu",
      "Limin Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2210.14164",
    "title": "Model-Free Prediction of Adversarial Drop Points in 3D Point Clouds",
    "abstract": "Adversarial attacks pose serious challenges for deep neural network (DNN)-based analysis of various input signals. In the case of 3D point clouds, methods have been developed to identify points that play a key role in the network decision, and these become crucial in generating existing adversarial attacks. For example, a saliency map approach is a popular method for identifying adversarial drop points, whose removal would significantly impact the network decision. Generally, methods for identifying adversarial points rely on the deep model itself in order to determine which points are critically important for the model's decision. This paper aims to provide a novel viewpoint on this problem, in which adversarial points can be predicted independently of the model. To this end, we define 14 point cloud features and use multiple linear regression to examine whether these features can be used for model-free adversarial point prediction, and which combination of features is best suited for this purpose. Experiments show that a suitable combination of features is able to predict adversarial points of three different networks -- PointNet, PointNet++, and DGCNN -- significantly better than a random guess. The results also provide further insight into DNNs for point cloud analysis, by showing which features play key roles in their decision-making process. ",
    "url": "https://arxiv.org/abs/2210.14164",
    "authors": [
      "Hanieh Naderi",
      "Chinthaka Dinesh",
      "Ivan V. Bajic",
      "Shohreh Kasaei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14169",
    "title": "Weakly Supervised Data Augmentation Through Prompting for Dialogue  Understanding",
    "abstract": "Dialogue understanding tasks often necessitate abundant annotated data to achieve good performance and that presents challenges in low-resource settings. To alleviate this barrier, we explore few-shot data augmentation for dialogue understanding by prompting large pre-trained language models and present a novel approach that iterates on augmentation quality by applying weakly-supervised filters. We evaluate our methods on the emotion and act classification tasks in DailyDialog and the intent classification task in Facebook Multilingual Task-Oriented Dialogue. Models fine-tuned on our augmented data mixed with few-shot ground truth data are able to approach or surpass existing state-of-the-art performance on both datasets. For DailyDialog specifically, using 10% of the ground truth data we outperform the current state-of-the-art model which uses 100% of the data. ",
    "url": "https://arxiv.org/abs/2210.14169",
    "authors": [
      "Maximillian Chen",
      "Alexandros Papangelis",
      "Chenyang Tao",
      "Andy Rosenbaum",
      "Seokhwan Kim",
      "Yang Liu",
      "Zhou Yu",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14188",
    "title": "MOFormer: Self-Supervised Transformer model for Metal-Organic Framework  Property Prediction",
    "abstract": "Metal-Organic Frameworks (MOFs) are materials with a high degree of porosity that can be used for applications in energy storage, water desalination, gas storage, and gas separation. However, the chemical space of MOFs is close to an infinite size due to the large variety of possible combinations of building blocks and topology. Discovering the optimal MOFs for specific applications requires an efficient and accurate search over an enormous number of potential candidates. Previous high-throughput screening methods using computational simulations like DFT can be time-consuming. Such methods also require optimizing 3D atomic structure of MOFs, which adds one extra step when evaluating hypothetical MOFs. In this work, we propose a structure-agnostic deep learning method based on the Transformer model, named as MOFormer, for property predictions of MOFs. The MOFormer takes a text string representation of MOF (MOFid) as input, thus circumventing the need of obtaining the 3D structure of hypothetical MOF and accelerating the screening process. Furthermore, we introduce a self-supervised learning framework that pretrains the MOFormer via maximizing the cross-correlation between its structure-agnostic representations and structure-based representations of crystal graph convolutional neural network (CGCNN) on >400k publicly available MOF data. Using self-supervised learning allows the MOFormer to intrinsically learn 3D structural information though it is not included in the input. Experiments show that pretraining improved the prediction accuracy of both models on various downstream prediction tasks. Furthermore, we revealed that MOFormer can be more data-efficient on quantum-chemical property prediction than structure-based CGCNN when training data is limited. Overall, MOFormer provides a novel perspective on efficient MOF design using deep learning. ",
    "url": "https://arxiv.org/abs/2210.14188",
    "authors": [
      "Zhonglin Cao",
      "Rishikesh Magar",
      "Yuyang Wang",
      "Amir Barati Farimani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ]
  },
  {
    "id": "arXiv:2210.14189",
    "title": "Benchmarking Graph Neural Networks for Internet Routing Data",
    "abstract": "The Internet is composed of networks, called Autonomous Systems (or, ASes), interconnected to each other, thus forming a large graph. While both the AS-graph is known and there is a multitude of data available for the ASes (i.e., node attributes), the research on applying graph machine learning (ML) methods on Internet data has not attracted a lot of attention. In this work, we provide a benchmarking framework aiming to facilitate research on Internet data using graph-ML and graph neural network (GNN) methods. Specifically, we compile a dataset with heterogeneous node/AS attributes by collecting data from multiple online sources, and preprocessing them so that they can be easily used as input in GNN architectures. Then, we create a framework/pipeline for applying GNNs on the compiled data. For a set of tasks, we perform a benchmarking of different GNN models (as well as, non-GNN ML models) to test their efficiency; our results can serve as a common baseline for future research and provide initial insights for the application of GNNs on Internet data. ",
    "url": "https://arxiv.org/abs/2210.14189",
    "authors": [
      "Dimitrios Panteleimon Giakatos",
      "Sofia Kostoglou",
      "Pavlos Sermpezis",
      "Athena Vakali"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.13453",
    "title": "A multi-category inverse design neural network and its application to  diblock copolymers",
    "abstract": "In this work, we design a multi-category inverse design neural network to map ordered periodic structure to physical parameters. The neural network model consists of two parts, a classifier and Structure-Parameter-Mapping (SPM) subnets. The classifier is used to identify structure, and the SPM subnets are used to predict physical parameters for desired structures. We also present an extensible reciprocal-space data augmentation method to guarantee the rotation and translation invariant of periodic structures. We apply the proposed network model and data augmentation method to two-dimensional diblock copolymers based on the Landau-Brazovskii model. Results show that the multi-category inverse design neural network is high accuracy in predicting physical parameters for desired structures. Moreover, the idea of multi-categorization can also be extended to other inverse design problems. ",
    "url": "https://arxiv.org/abs/2210.13453",
    "authors": [
      "Dan Wei",
      "Tiejun Zhou",
      "Yunqing Huang",
      "Kai Jiang"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13595",
    "title": "DilatedSegNet: A Deep Dilated Segmentation Network for Polyp  Segmentation",
    "abstract": "Colorectal cancer (CRC) is the second leading cause of cancer-related death worldwide. Excision of polyps during colonoscopy helps reduce mortality and morbidity for CRC. Powered by deep learning, computer-aided diagnosis (CAD) systems can detect regions in the colon overlooked by physicians during colonoscopy. Lacking high accuracy and real-time speed are the essential obstacles to be overcome for successful clinical integration of such systems. While literature is focused on improving accuracy, the speed parameter is often ignored. Toward this critical need, we intend to develop a novel real-time deep learning-based architecture, DilatedSegNet, to perform polyp segmentation on the fly. DilatedSegNet is an encoder-decoder network that uses pre-trained ResNet50 as the encoder from which we extract four levels of feature maps. Each of these feature maps is passed through a dilated convolution pooling (DCP) block. The outputs from the DCP blocks are concatenated and passed through a series of four decoder blocks that predicts the segmentation mask. The proposed method achieves a real-time operation speed of 33.68 frames per second with an average dice coefficient of 0.90 and mIoU of 0.83. Additionally, we also provide heatmap along with the qualitative results that shows the explanation for the polyp location, which increases the trustworthiness of the method. The results on the publicly available Kvasir-SEG and BKAI-IGH datasets suggest that DilatedSegNet can give real-time feedback while retaining a high \\ac{DSC}, indicating high potential for using such models in real clinical settings in the near future. The GitHub link of the source code can be found here: \\url{https://github.com/nikhilroxtomar/DilatedSegNet}. ",
    "url": "https://arxiv.org/abs/2210.13595",
    "authors": [
      "Nikhil Kumar Tomar",
      "Debesh Jha",
      "Ulas Bagci"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.13721",
    "title": "Multi-modal Dynamic Graph Network: Coupling Structural and Functional  Connectome for Disease Diagnosis and Classification",
    "abstract": "Multi-modal neuroimaging technology has greatlly facilitated the efficiency and diagnosis accuracy, which provides complementary information in discovering objective disease biomarkers. Conventional deep learning methods, e.g. convolutional neural networks, overlook relationships between nodes and fail to capture topological properties in graphs. Graph neural networks have been proven to be of great importance in modeling brain connectome networks and relating disease-specific patterns. However, most existing graph methods explicitly require known graph structures, which are not available in the sophisticated brain system. Especially in heterogeneous multi-modal brain networks, there exists a great challenge to model interactions among brain regions in consideration of inter-modal dependencies. In this study, we propose a Multi-modal Dynamic Graph Convolution Network (MDGCN) for structural and functional brain network learning. Our method benefits from modeling inter-modal representations and relating attentive multi-model associations into dynamic graphs with a compositional correspondence matrix. Moreover, a bilateral graph convolution layer is proposed to aggregate multi-modal representations in terms of multi-modal associations. Extensive experiments on three datasets demonstrate the superiority of our proposed method in terms of disease classification, with the accuracy of 90.4%, 85.9% and 98.3% in predicting Mild Cognitive Impairment (MCI), Parkinson's disease (PD), and schizophrenia (SCHZ) respectively. Furthermore, our statistical evaluations on the correspondence matrix exhibit a high correspondence with previous evidence of biomarkers. ",
    "url": "https://arxiv.org/abs/2210.13721",
    "authors": [
      "Yanwu Yang",
      "Xutao Guo",
      "Zhikai Chang",
      "Chenfei Ye",
      "Yang Xiang",
      "Ting Ma"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13741",
    "title": "Deep Neural Networks as the Semi-classical Limit of Topological Quantum  Neural Networks: The problem of generalisation",
    "abstract": "Deep Neural Networks miss a principled model of their operation. A novel framework for supervised learning based on Topological Quantum Field Theory that looks particularly well suited for implementation on quantum processors has been recently explored. We propose the use of this framework for understanding the problem of generalization in Deep Neural Networks. More specifically, in this approach Deep Neural Networks are viewed as the semi-classical limit of Topological Quantum Neural Networks. A framework of this kind explains easily the overfitting behavior of Deep Neural Networks during the training step and the corresponding generalization capabilities. ",
    "url": "https://arxiv.org/abs/2210.13741",
    "authors": [
      "Antonino Marciano",
      "Deen Chen",
      "Filippo Fabrocini",
      "Chris Fields",
      "Matteo Lulli",
      "Emanuele Zappala"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Geometric Topology (math.GT)"
    ]
  },
  {
    "id": "arXiv:2210.13771",
    "title": "Disentangled Speech Representation Learning for One-Shot Cross-lingual  Voice Conversion Using $\u03b2$-VAE",
    "abstract": "We propose an unsupervised learning method to disentangle speech into content representation and speaker identity representation. We apply this method to the challenging one-shot cross-lingual voice conversion task to demonstrate the effectiveness of the disentanglement. Inspired by $\\beta$-VAE, we introduce a learning objective that balances between the information captured by the content and speaker representations. In addition, the inductive biases from the architectural design and the training dataset further encourage the desired disentanglement. Both objective and subjective evaluations show the effectiveness of the proposed method in speech disentanglement and in one-shot cross-lingual voice conversion. ",
    "url": "https://arxiv.org/abs/2210.13771",
    "authors": [
      "Hui Lu",
      "Disong Wang",
      "Xixin Wu",
      "Zhiyong Wu",
      "Xunying Liu",
      "Helen Meng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.13773",
    "title": "Variational Bayesian Inference Clustering Based Joint User Activity and  Data Detection for Grant-Free Random Access in mMTC",
    "abstract": "Tailor-made for massive connectivity and sporadic access, grant-free random access has become a promising candidate access protocol for massive machine-type communications (mMTC). Compared with conventional grant-based protocols, grant-free random access skips the exchange of scheduling information to reduce the signaling overhead, and facilitates sharing of access resources to enhance access efficiency. However, some challenges remain to be addressed in the receiver design, such as unknown identity of active users and multi-user interference (MUI) on shared access resources. In this work, we deal with the problem of joint user activity and data detection for grant-free random access. Specifically, the approximate message passing (AMP) algorithm is first employed to mitigate MUI and decouple the signals of different users. Then, we extend the data symbol alphabet to incorporate the null symbols from inactive users. In this way, the joint user activity and data detection problem is formulated as a clustering problem under the Gaussian mixture model. Furthermore, in conjunction with the AMP algorithm, a variational Bayesian inference based clustering (VBIC) algorithm is developed to solve this clustering problem. Simulation results show that, compared with state-of-art solutions, the proposed AMP-combined VBIC (AMP-VBIC) algorithm achieves a significant performance gain in detection accuracy. ",
    "url": "https://arxiv.org/abs/2210.13773",
    "authors": [
      "Zhaoji Zhang",
      "Qinghua Guo",
      "Ying Li",
      "Ming Jin",
      "Chongwen Huang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2210.13817",
    "title": "Online model error correction with neural networks in the incremental  4D-Var framework",
    "abstract": "Recent studies have demonstrated that it is possible to combine machine learning with data assimilation to reconstruct the dynamics of a physical model partially and imperfectly observed. Data assimilation is used to estimate the system state from the observations, while machine learning computes a surrogate model of the dynamical system based on those estimated states. The surrogate model can be defined as an hybrid combination where a physical model based on prior knowledge is enhanced with a statistical model estimated by a neural network. The training of the neural network is typically done offline, once a large enough dataset of model state estimates is available. By contrast, with online approaches the surrogate model is improved each time a new system state estimate is computed. Online approaches naturally fit the sequential framework encountered in geosciences where new observations become available with time. In a recent methodology paper, we have developed a new weak-constraint 4D-Var formulation which can be used to train a neural network for online model error correction. In the present article, we develop a simplified version of that method, in the incremental 4D-Var framework adopted by most operational weather centres. The simplified method is implemented in the ECMWF Object-Oriented Prediction System, with the help of a newly developed Fortran neural network library, and tested with a two-layer two-dimensional quasi geostrophic model. The results confirm that online learning is effective and yields a more accurate model error correction than offline learning. Finally, the simplified method is compatible with future applications to state-of-the-art models such as the ECMWF Integrated Forecasting System. ",
    "url": "https://arxiv.org/abs/2210.13817",
    "authors": [
      "Alban Farchi",
      "Marcin Chrust",
      "Marc Bocquet",
      "Patrick Laloyaux",
      "Massimo Bonavita"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.13882",
    "title": "A deep learning approach for brain tumor detection using magnetic  resonance imaging",
    "abstract": "The growth of abnormal cells in the brain's tissue causes brain tumors. Brain tumors are considered one of the most dangerous disorders in children and adults. It develops quickly, and the patient's survival prospects are slim if not appropriately treated. Proper treatment planning and precise diagnoses are essential to improving a patient's life expectancy. Brain tumors are mainly diagnosed using magnetic resonance imaging (MRI). As part of a convolution neural network (CNN)-based illustration, an architecture containing five convolution layers, five max-pooling layers, a Flatten layer, and two dense layers has been proposed for detecting brain tumors from MRI images. The proposed model includes an automatic feature extractor, modified hidden layer architecture, and activation function. Several test cases were performed, and the proposed model achieved 98.6% accuracy and 97.8% precision score with a low cross-entropy rate. Compared with other approaches such as adjacent feature propagation network (AFPNet), mask region-based CNN (mask RCNN), YOLOv5, and Fourier CNN (FCNN), the proposed model has performed better in detecting brain tumors. ",
    "url": "https://arxiv.org/abs/2210.13882",
    "authors": [
      "Al-Akhir Nayan",
      "Ahamad Nokib Mozumder",
      "Md. Rakibul Haque",
      "Fahim Hossain Sifat",
      "Khan Raqib Mahmud",
      "Abul Kalam Al Azad",
      "Muhammad Golam Kibria"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14007",
    "title": "MEW-UNet: Multi-axis representation learning in frequency domain for  medical image segmentation",
    "abstract": "Recently, Visual Transformer (ViT) has been widely used in various fields of computer vision due to applying self-attention mechanism in the spatial domain to modeling global knowledge. Especially in medical image segmentation (MIS), many works are devoted to combining ViT and CNN, and even some works directly utilize pure ViT-based models. However, recent works improved models in the aspect of spatial domain while ignoring the importance of frequency domain information. Therefore, we propose Multi-axis External Weights UNet (MEW-UNet) for MIS based on the U-shape architecture by replacing self-attention in ViT with our Multi-axis External Weights block. Specifically, our block performs a Fourier transform on the three axes of the input feature and assigns the external weight in the frequency domain, which is generated by our Weights Generator. Then, an inverse Fourier transform is performed to change the features back to the spatial domain. We evaluate our model on four datasets and achieve state-of-the-art performances. In particular, on the Synapse dataset, our method outperforms MT-UNet by 10.15mm in terms of HD95. Code is available at https://github.com/JCruan519/MEW-UNet. ",
    "url": "https://arxiv.org/abs/2210.14007",
    "authors": [
      "Jiacheng Ruan",
      "Mingye Xie",
      "Suncheng Xiang",
      "Ting Liu",
      "Yuzhuo Fu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.14044",
    "title": "SeismicNet: Physics-informed neural networks for seismic wave modeling  in semi-infinite domain",
    "abstract": "There has been an increasing interest in integrating physics knowledge and machine learning for modeling dynamical systems. However, very limited studies have been conducted on seismic wave modeling tasks. A critical challenge is that these geophysical problems are typically defined in large domains (i.e., semi-infinite), which leads to high computational cost. In this paper, we present a novel physics-informed neural network (PINN) model for seismic wave modeling in semi-infinite domain without the nedd of labeled data. In specific, the absorbing boundary condition is introduced into the network as a soft regularizer for handling truncated boundaries. In terms of computational efficiency, we consider a sequential training strategy via temporal domain decomposition to improve the scalability of the network and solution accuracy. Moreover, we design a novel surrogate modeling strategy for parametric loading, which estimates the wave propagation in semin-infinite domain given the seismic loading at different locations. Various numerical experiments have been implemented to evaluate the performance of the proposed PINN model in the context of forward modeling of seismic wave propagation. In particular, we define diverse material distributions to test the versatility of this approach. The results demonstrate excellent solution accuracy under distinctive scenarios. ",
    "url": "https://arxiv.org/abs/2210.14044",
    "authors": [
      "Pu Ren",
      "Chengping Rao",
      "Hao Sun",
      "Yang Liu"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ]
  },
  {
    "id": "arXiv:2210.14090",
    "title": "EBEN: Extreme bandwidth extension network applied to speech signals  captured with noise-resilient microphones",
    "abstract": "In this paper, we present Extreme Bandwidth Extension Network (EBEN), a generative adversarial network (GAN) that enhances audio measured with noise-resilient microphones. This type of capture equipment suppresses ambient noise at the expense of speech bandwidth, thereby requiring signal enhancement techniques to recover the wideband speech signal. EBEN leverages a multiband decomposition of the raw captured speech to decrease the data time-domain dimensions, and give better control over the full-band signal. This multiband representation is fed to a U-Net-like model, which adopts a combination of feature and adversarial losses to recover an enhanced audio signal. We also benefit from this original representation in the proposed discriminator architecture. Our approach can achieve state-of-the-art results with a lightweight generator and real-time compatible operation. ",
    "url": "https://arxiv.org/abs/2210.14090",
    "authors": [
      "Julien Hauret",
      "Thomas Joubaud",
      "V\u00e9ronique Zimpfer",
      "\u00c9ric Bavu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.14152",
    "title": "SleepMore: Sleep Prediction at Scale via Multi-Device WiFi Sensing",
    "abstract": "The availability of commercial wearable trackers equipped with features to monitor sleep duration and quality has enabled more useful sleep health monitoring applications and analyses. However, much research has reported the challenge of long-term user retention in sleep monitoring through these modalities. Since modern Internet users own multiple mobile devices, our work explores the possibility of employing ubiquitous mobile devices and passive WiFi sensing techniques to predict sleep duration as the fundamental measure for complementing long-term sleep monitoring initiatives. In this paper, we propose SleepMore, an accurate and easy-to-deploy sleep-tracking approach based on machine learning over the user's WiFi network activity. It first employs a semi-personalized random forest model with an infinitesimal jackknife variance estimation method to classify a user's network activity behavior into sleep and awake states per minute granularity. Through a moving average technique, the system uses these state sequences to estimate the user's nocturnal sleep period and its uncertainty rate. Uncertainty quantification enables SleepMore to overcome the impact of noisy WiFi data that can yield large prediction errors. We validate SleepMore using data from a month-long user study involving 46 college students and draw comparisons with the Oura Ring wearable. Beyond the college campus, we evaluate SleepMore on non-student users of different housing profiles. Our results demonstrate that SleepMore produces statistically indistinguishable sleep statistics from the Oura ring baseline for predictions made within a 5% uncertainty rate. These errors range between 15-28 minutes for determining sleep time and 7-29 minutes for determining wake time, proving statistically significant improvements over prior work. Our in-depth analysis explains the sources of errors. ",
    "url": "https://arxiv.org/abs/2210.14152",
    "authors": [
      "Camellia Zakaria",
      "Gizem Yilmaz",
      "Priyanka Mammen",
      "Michael Chee",
      "Prashant Shenoy",
      "Rajesh Balan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.14184",
    "title": "Learning Ability of Interpolating Convolutional Neural Networks",
    "abstract": "It is frequently observed that overparameterized neural networks generalize well. Regarding such phenomena, existing theoretical work mainly devotes to linear settings or fully connected neural networks. This paper studies learning ability of an important family of deep neural networks, deep convolutional neural networks (DCNNs), under underparameterized and overparameterized settings. We establish the best learning rates of underparameterized DCNNs without parameter restrictions presented in the literature. We also show that, by adding well defined layers to an underparameterized DCNN, we can obtain some interpolating DCNNs that maintain the good learning rates of the underparameterized DCNN. This result is achieved by a novel network deepening scheme designed for DCNNs. Our work provides theoretical verification on how overfitted DCNNs generalize well. ",
    "url": "https://arxiv.org/abs/2210.14184",
    "authors": [
      "Tian-Yi Zhou",
      "Xiaoming Huo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:1710.04656",
    "title": "Behavioral Communities and the Atomic Structure of Networks",
    "abstract": " Title: Behavioral Communities and the Atomic Structure of Networks ",
    "url": "https://arxiv.org/abs/1710.04656",
    "authors": [
      "Matthew O. Jackson",
      "Evan C. Storms"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2004.07671",
    "title": "Isomorphism Testing for Graphs Excluding Small Minors",
    "abstract": " Comments: 33 pages, 7 figures, full version of a paper accepted at FOCS 2020; second version improves the presentation of the results ",
    "url": "https://arxiv.org/abs/2004.07671",
    "authors": [
      "Martin Grohe",
      "Daniel Neuen",
      "Daniel Wiebking"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ]
  },
  {
    "id": "arXiv:2010.12676",
    "title": "A Differentiable Relaxation of Graph Segmentation and Alignment for AMR  Parsing",
    "abstract": " Title: A Differentiable Relaxation of Graph Segmentation and Alignment for AMR  Parsing ",
    "url": "https://arxiv.org/abs/2010.12676",
    "authors": [
      "Chunchuan Lyu",
      "Shay B. Cohen",
      "Ivan Titov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2101.07518",
    "title": "BANet: Blur-aware Attention Networks for Dynamic Scene Deblurring",
    "abstract": " Comments: TIP 2022, Code: this https URL ",
    "url": "https://arxiv.org/abs/2101.07518",
    "authors": [
      "Fu-Jen Tsai",
      "Yan-Tsung Peng",
      "Yen-Yu Lin",
      "Chung-Chi Tsai",
      "Chia-Wen Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2102.06626",
    "title": "Do-calculus enables estimation of causal effects in partially observed  biomolecular pathways",
    "abstract": " Comments: this https URL ",
    "url": "https://arxiv.org/abs/2102.06626",
    "authors": [
      "Sara Mohammad-Taheri",
      "Jeremy Zucker",
      "Charles Tapley Hoyt",
      "Karen Sachs",
      "Vartika Tewari",
      "Robert Ness",
      "and Olga Vitek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2102.09683",
    "title": "Community Structure Recovery and Interaction Probability Estimation for  Gossip Opinion Dynamics",
    "abstract": " Title: Community Structure Recovery and Interaction Probability Estimation for  Gossip Opinion Dynamics ",
    "url": "https://arxiv.org/abs/2102.09683",
    "authors": [
      "Yu Xing",
      "Xingkang He",
      "Haitao Fang",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ]
  },
  {
    "id": "arXiv:2103.15510",
    "title": "Photoacoustic image synthesis with generative adversarial networks",
    "abstract": " Comments: 10 pages, 6 figures, 2 tables, update with paper published at Photoacoustics ",
    "url": "https://arxiv.org/abs/2103.15510",
    "authors": [
      "Melanie Schellenberg",
      "Janek Gr\u00f6hl",
      "Kris K. Dreher",
      "Jan-Hinrich N\u00f6lke",
      "Niklas Holzwarth",
      "Minu D. Tizabi",
      "Alexander Seitel",
      "Lena Maier-Hein"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2104.09570",
    "title": "Extracting Temporal Event Relation with Syntax-guided Graph Transformer",
    "abstract": " Title: Extracting Temporal Event Relation with Syntax-guided Graph Transformer ",
    "url": "https://arxiv.org/abs/2104.09570",
    "authors": [
      "Shuaicheng Zhang",
      "Lifu Huang",
      "Qiang Ning"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2107.06304",
    "title": "Privacy Vulnerability of Split Computing to Data-Free Model Inversion  Attacks",
    "abstract": " Comments: A new data-free inversion method to reverse neural networks and get input from intermediate feature maps. BMVC'22 ",
    "url": "https://arxiv.org/abs/2107.06304",
    "authors": [
      "Xin Dong",
      "Hongxu Yin",
      "Jose M. Alvarez",
      "Jan Kautz",
      "Pavlo Molchanov",
      "H.T. Kung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2108.04718",
    "title": "Sampling-Based Approximations to Minimum Bayes Risk Decoding for Neural  Machine Translation",
    "abstract": " Comments: EMNLP 2022 camera-ready ",
    "url": "https://arxiv.org/abs/2108.04718",
    "authors": [
      "Bryan Eikema",
      "Wilker Aziz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2110.01822",
    "title": "Verified eigenvalue and eigenvector computations using complex moments  and the Rayleigh$\\unicode{x2013}$Ritz procedure for generalized Hermitian  eigenvalue problems",
    "abstract": " Comments: 23 pages, 4 figures ",
    "url": "https://arxiv.org/abs/2110.01822",
    "authors": [
      "Akira Imakura",
      "Keiichi Morikuni",
      "Akitoshi Takayasu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2111.02168",
    "title": "Graph Neural Networks for Nomination and Representation Learning of Web  Elements",
    "abstract": " Comments: 12 pages, 8 figures, 3 tables, under review ",
    "url": "https://arxiv.org/abs/2111.02168",
    "authors": [
      "Alexandra Hotti",
      "Riccardo Sven Risuleo",
      "Stefan Magureanu",
      "Aref Moradi",
      "Jens Lagergren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ]
  },
  {
    "id": "arXiv:2111.02295",
    "title": "The Parameterized Complexity of the Survivable Network Design Problem",
    "abstract": " Title: The Parameterized Complexity of the Survivable Network Design Problem ",
    "url": "https://arxiv.org/abs/2111.02295",
    "authors": [
      "Andreas Emil Feldmann",
      "Anish Mukherjee",
      "Erik Jan van Leeuwen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2111.04066",
    "title": "Fast sampling via spectral independence beyond bounded-degree graphs",
    "abstract": " Title: Fast sampling via spectral independence beyond bounded-degree graphs ",
    "url": "https://arxiv.org/abs/2111.04066",
    "authors": [
      "Ivona Bez\u00e1kov\u00e1",
      "Andreas Galanis",
      "Leslie Ann Goldberg",
      "Daniel \u0160tefankovi\u010d"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2111.10984",
    "title": "Topological Regularization for Dense Prediction",
    "abstract": " Title: Topological Regularization for Dense Prediction ",
    "url": "https://arxiv.org/abs/2111.10984",
    "authors": [
      "Deqing Fu",
      "Bradley J. Nelson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ]
  },
  {
    "id": "arXiv:2112.05253",
    "title": "MAGMA -- Multimodal Augmentation of Generative Models through  Adapter-based Finetuning",
    "abstract": " Comments: 13 pages, 6 figures, 2 tables. Minor improvements. Accepted at EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2112.05253",
    "authors": [
      "Constantin Eichenberg",
      "Sidney Black",
      "Samuel Weinbach",
      "Letitia Parcalabescu",
      "Anette Frank"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2201.09862",
    "title": "Learning to Act with Affordance-Aware Multimodal Neural SLAM",
    "abstract": " Comments: Accepted by IROS 2022 ",
    "url": "https://arxiv.org/abs/2201.09862",
    "authors": [
      "Zhiwei Jia",
      "Kaixiang Lin",
      "Yizhou Zhao",
      "Qiaozi Gao",
      "Govind Thattai",
      "Gaurav Sukhatme"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2201.11624",
    "title": "LiteLSTM Architecture for Deep Recurrent Neural Networks",
    "abstract": " Comments: Accepted in the IEEE International Symposium on Circuits and Systems (ISCAS) 2022 ",
    "url": "https://arxiv.org/abs/2201.11624",
    "authors": [
      "Nelly Elsayed",
      "Zag ElSayed",
      "Anthony S. Maida"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2202.06934",
    "title": "Slicing Aided Hyper Inference and Fine-tuning for Small Object Detection",
    "abstract": " Comments: Presented at ICIP 2022, 5 pages, 4 figures, 2 tables ",
    "url": "https://arxiv.org/abs/2202.06934",
    "authors": [
      "Fatih Cagatay Akyon",
      "Sinan Onur Altinuc",
      "Alptekin Temizel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2202.10036",
    "title": "Guided Visual Attention Model Based on Interactions Between Top-down and  Bottom-up Information for Robot Pose Prediction",
    "abstract": " Title: Guided Visual Attention Model Based on Interactions Between Top-down and  Bottom-up Information for Robot Pose Prediction ",
    "url": "https://arxiv.org/abs/2202.10036",
    "authors": [
      "Hyogo Hiruma",
      "Hiroki Mori",
      "Hiroshi Ito",
      "Tetsuya Ogata"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2202.11099",
    "title": "Rotationally Equivariant Super-Resolution of Velocity Fields in  Two-Dimensional Fluids Using Convolutional Neural Networks",
    "abstract": " Title: Rotationally Equivariant Super-Resolution of Velocity Fields in  Two-Dimensional Fluids Using Convolutional Neural Networks ",
    "url": "https://arxiv.org/abs/2202.11099",
    "authors": [
      "Yuki Yasuda",
      "Ryo Onishi"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ]
  },
  {
    "id": "arXiv:2202.12498",
    "title": "Diffeomorphic Image Registration with Neural Velocity Field",
    "abstract": " Title: Diffeomorphic Image Registration with Neural Velocity Field ",
    "url": "https://arxiv.org/abs/2202.12498",
    "authors": [
      "Kun Han",
      "Shanlin sun",
      "Xiangyi Yan",
      "Chenyu You",
      "Hao Tang",
      "Junayed Naushad",
      "Haoyu Ma",
      "Deying Kong",
      "Xiaohui Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.05406",
    "title": "Disentangled Multimodal Representation Learning for Recommendation",
    "abstract": " Comments: IEEE Transactions on Multimedia (TMM) ",
    "url": "https://arxiv.org/abs/2203.05406",
    "authors": [
      "Fan Liu",
      "Huilin Chen",
      "Zhiyong Cheng",
      "Anan Liu",
      "Liqiang Nie",
      "Mohan Kankanhalli"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ]
  },
  {
    "id": "arXiv:2203.07738",
    "title": "GCT: Graph Co-Training for Semi-Supervised Few-Shot Learning",
    "abstract": " Title: GCT: Graph Co-Training for Semi-Supervised Few-Shot Learning ",
    "url": "https://arxiv.org/abs/2203.07738",
    "authors": [
      "Shuai Shao",
      "Lei Xing",
      "Weifeng Liu",
      "Yanjiang Wang",
      "Baodi Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2203.10115",
    "title": "Introducing causal inference in the energy-efficient building design  process",
    "abstract": " Comments: 20 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2203.10115",
    "authors": [
      "Xia Chen",
      "Jimmy Abualdenien",
      "Manav Mahan Singh",
      "Andr\u00e9 Borrmann",
      "Philipp Geyer"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ]
  },
  {
    "id": "arXiv:2203.16288",
    "title": "Region of Interest focused MRI to Synthetic CT Translation using  Regression and Classification Multi-task Network",
    "abstract": " Comments: Submitted to Physics in Medicine & Biology ",
    "url": "https://arxiv.org/abs/2203.16288",
    "authors": [
      "Sandeep Kaushik",
      "Mikael Bylund",
      "Cristina Cozzini",
      "Dattesh Shanbhag",
      "Steven F Petit",
      "Jonathan J Wyatt",
      "Marion I Menzel",
      "Carolin Pirkl",
      "Bhairav Mehta",
      "Vikas Chauhan",
      "Kesavadas Chandrasekharan",
      "Joakim Jonsson",
      "Tufve Nyholm",
      "Florian Wiesinger",
      "Bjoern Menze"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ]
  },
  {
    "id": "arXiv:2204.01888",
    "title": "ConceptExplainer: Interactive Explanation for Deep Neural Networks from  a Concept Perspective",
    "abstract": " Comments: 9 pages, 6 figures ",
    "url": "https://arxiv.org/abs/2204.01888",
    "authors": [
      "Jinbin Huang",
      "Aditi Mishra",
      "Bum Chul Kwon",
      "Chris Bryan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ]
  },
  {
    "id": "arXiv:2205.10293",
    "title": "DELATOR: Money Laundering Detection via Multi-Task Learning on Large  Transaction Graphs",
    "abstract": " Comments: Accepted for publication in the 2022 IEEE International Conference on Big Data (IEEE BigData) as a short paper ",
    "url": "https://arxiv.org/abs/2205.10293",
    "authors": [
      "Henrique S. Assump\u00e7\u00e3o",
      "Fabr\u00edcio Souza",
      "Leandro Lacerda Campos",
      "Vin\u00edcius T. de Castro Pires",
      "Paulo M. Laurentys de Almeida",
      "Fabricio Murai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ]
  },
  {
    "id": "arXiv:2205.12604",
    "title": "Leveraging QA Datasets to Improve Generative Data Augmentation",
    "abstract": " Title: Leveraging QA Datasets to Improve Generative Data Augmentation ",
    "url": "https://arxiv.org/abs/2205.12604",
    "authors": [
      "Dheeraj Mekala",
      "Tu Vu",
      "Timo Schick",
      "Jingbo Shang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2205.12674",
    "title": "Training Language Models with Memory Augmentation",
    "abstract": " Comments: EMNLP 2022. Our code and models are available at this https URL v2 added updated results on machine translation, enwik8 and domain adaptation ",
    "url": "https://arxiv.org/abs/2205.12674",
    "authors": [
      "Zexuan Zhong",
      "Tao Lei",
      "Danqi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2205.12840",
    "title": "SALAD: Source-free Active Label-Agnostic Domain Adaptation for  Classification, Segmentation and Detection",
    "abstract": " Title: SALAD: Source-free Active Label-Agnostic Domain Adaptation for  Classification, Segmentation and Detection ",
    "url": "https://arxiv.org/abs/2205.12840",
    "authors": [
      "Divya Kothandaraman",
      "Sumit Shekhar",
      "Abhilasha Sancheti",
      "Manoj Ghuhan",
      "Tripti Shukla",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2205.14926",
    "title": "CalFAT: Calibrated Federated Adversarial Training with Label Skewness",
    "abstract": " Comments: Accepted to the Conference on the Advances in Neural Information Processing Systems (NeurIPS) 2022 ",
    "url": "https://arxiv.org/abs/2205.14926",
    "authors": [
      "Chen Chen",
      "Yuchen Liu",
      "Xingjun Ma",
      "Lingjuan Lyu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2205.15884",
    "title": "An Effective and Efficient Evolutionary Algorithm for Many-Objective  Optimization",
    "abstract": " Comments: 25 pages, 5 figures, to appear in Information Sciences ",
    "url": "https://arxiv.org/abs/2205.15884",
    "authors": [
      "Yani Xue",
      "Miqing Li",
      "Xiaohui Liu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2206.00133",
    "title": "Pre-training via Denoising for Molecular Property Prediction",
    "abstract": " Title: Pre-training via Denoising for Molecular Property Prediction ",
    "url": "https://arxiv.org/abs/2206.00133",
    "authors": [
      "Sheheryar Zaidi",
      "Michael Schaarschmidt",
      "James Martens",
      "Hyunjik Kim",
      "Yee Whye Teh",
      "Alvaro Sanchez-Gonzalez",
      "Peter Battaglia",
      "Razvan Pascanu",
      "Jonathan Godwin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.03687",
    "title": "A Unified Model for Multi-class Anomaly Detection",
    "abstract": " Comments: Accepted by NeurIPS 2022 ",
    "url": "https://arxiv.org/abs/2206.03687",
    "authors": [
      "Zhiyuan You",
      "Lei Cui",
      "Yujun Shen",
      "Kai Yang",
      "Xin Lu",
      "Yu Zheng",
      "Xinyi Le"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.07571",
    "title": "Efficient decoding up to a constant fraction of the code length for  asymptotically good quantum codes",
    "abstract": " Comments: 43 pages ",
    "url": "https://arxiv.org/abs/2206.07571",
    "authors": [
      "Anthony Leverrier",
      "Gilles Z\u00e9mor"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Information Theory (cs.IT)"
    ]
  },
  {
    "id": "arXiv:2206.07758",
    "title": "Reconstructing Training Data from Trained Neural Networks",
    "abstract": " Comments: Project page: this https URL ",
    "url": "https://arxiv.org/abs/2206.07758",
    "authors": [
      "Niv Haim",
      "Gal Vardi",
      "Gilad Yehudai",
      "Ohad Shamir",
      "Michal Irani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.09065",
    "title": "Free-form Lesion Synthesis Using a Partial Convolution Generative  Adversarial Network for Enhanced Deep Learning Liver Tumor Segmentation",
    "abstract": " Comments: The paper is under review by JACMP-Journal of Applied Medical Physics ",
    "url": "https://arxiv.org/abs/2206.09065",
    "authors": [
      "Yingao Liu",
      "Fei Yang",
      "Yidong Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2206.12038",
    "title": "BYOL-S: Learning Self-supervised Speech Representations by Bootstrapping",
    "abstract": " Comments: Submitted to HEAR-PMLR 2021 ",
    "url": "https://arxiv.org/abs/2206.12038",
    "authors": [
      "Gasser Elbanna",
      "Neil Scheidwasser-Clow",
      "Mikolaj Kegler",
      "Pierre Beckmann",
      "Karl El Hajal",
      "Milos Cernak"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2206.14486",
    "title": "Beyond neural scaling laws: beating power law scaling via data pruning",
    "abstract": " Comments: Oral @ NeurIPS 2022 (camera ready version) ",
    "url": "https://arxiv.org/abs/2206.14486",
    "authors": [
      "Ben Sorscher",
      "Robert Geirhos",
      "Shashank Shekhar",
      "Surya Ganguli",
      "Ari S. Morcos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2206.14774",
    "title": "TweetNLP: Cutting-Edge Natural Language Processing for Social Media",
    "abstract": " Comments: EMNLP 2022 Demo paper. TweetNLP: this https URL ",
    "url": "https://arxiv.org/abs/2206.14774",
    "authors": [
      "Jose Camacho-Collados",
      "Kiamehr Rezaee",
      "Talayeh Riahi",
      "Asahi Ushio",
      "Daniel Loureiro",
      "Dimosthenis Antypas",
      "Joanne Boisson",
      "Luis Espinosa-Anke",
      "Fangyu Liu",
      "Eugenio Mart\u00ednez-C\u00e1mara",
      "Gonzalo Medina",
      "Thomas Buhrmann",
      "Leonardo Neves",
      "Francesco Barbieri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2207.00377",
    "title": "Anisotropic, Sparse and Interpretable Physics-Informed Neural Networks  for PDEs",
    "abstract": " Comments: 10 pages, 17 figures ",
    "url": "https://arxiv.org/abs/2207.00377",
    "authors": [
      "Amuthan A. Ramabathiran",
      "Prabhu Ramachandran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.04248",
    "title": "A Statistically-Based Approach to Feedforward Neural Network Model  Selection",
    "abstract": " Title: A Statistically-Based Approach to Feedforward Neural Network Model  Selection ",
    "url": "https://arxiv.org/abs/2207.04248",
    "authors": [
      "Andrew McInerney",
      "Kevin Burke"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2207.08080",
    "title": "Neural Color Operators for Sequential Image Retouching",
    "abstract": " Comments: Accepted to ECCV 2022. Code is available at this https URL ",
    "url": "https://arxiv.org/abs/2207.08080",
    "authors": [
      "Yili Wang",
      "Xin Li",
      "Kun Xu",
      "Dongliang He",
      "Qi Zhang",
      "Fu Li",
      "Errui Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.02369",
    "title": "Deep VULMAN: A Deep Reinforcement Learning-Enabled Cyber Vulnerability  Management Framework",
    "abstract": " Comments: 12 pages, 3 figures ",
    "url": "https://arxiv.org/abs/2208.02369",
    "authors": [
      "Soumyadeep Hore",
      "Ankit Shah",
      "Nathaniel D. Bastian"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ]
  },
  {
    "id": "arXiv:2208.04171",
    "title": "Object Detection Using Sim2Real Domain Randomization for Robotic  Applications",
    "abstract": " Comments: Published in IEEE Transactions on Robotics (T-RO) ",
    "url": "https://arxiv.org/abs/2208.04171",
    "authors": [
      "D\u00e1niel Horv\u00e1th",
      "G\u00e1bor Erd\u0151s",
      "Zolt\u00e1n Istenes",
      "Tom\u00e1\u0161 Horv\u00e1th",
      "S\u00e1ndor F\u00f6ldi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2208.05140",
    "title": "Self-supervised Co-learning of Uncurated Images and Reports Enables  Oversight AI in Radiology",
    "abstract": " Title: Self-supervised Co-learning of Uncurated Images and Reports Enables  Oversight AI in Radiology ",
    "url": "https://arxiv.org/abs/2208.05140",
    "authors": [
      "Sangjoon Park",
      "Eun Sun Lee",
      "Kyung Sook Shin",
      "Jeong Eun Lee",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2208.08401",
    "title": "Conformal Inference for Online Prediction with Arbitrary Distribution  Shifts",
    "abstract": " Comments: 29 pages, 10 figures ",
    "url": "https://arxiv.org/abs/2208.08401",
    "authors": [
      "Isaac Gibbs",
      "Emmanuel Cand\u00e8s"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2209.02250",
    "title": "Spatio-Temporal Action Detection Under Large Motion",
    "abstract": " Comments: 10 pages, 5 figures, 5 tables ",
    "url": "https://arxiv.org/abs/2209.02250",
    "authors": [
      "Gurkirt Singh",
      "Vasileios Choutas",
      "Suman Saha",
      "Fisher Yu",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2209.05598",
    "title": "Learning Causal Discovery",
    "abstract": " Comments: 15 main pages, 9 figures. Will be submitted to TMLR ",
    "url": "https://arxiv.org/abs/2209.05598",
    "authors": [
      "Xinyue Wang",
      "Konrad Paul Kording"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ]
  },
  {
    "id": "arXiv:2209.11820",
    "title": "Expanding the Deployment Envelope of Behavior Prediction via Adaptive  Meta-Learning",
    "abstract": " Comments: 12 pages, 13 figures, 2 tables. Fixed links and references to the appendix ",
    "url": "https://arxiv.org/abs/2209.11820",
    "authors": [
      "Boris Ivanovic",
      "James Harrison",
      "Marco Pavone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ]
  },
  {
    "id": "arXiv:2210.00597",
    "title": "Composition of Differential Privacy & Privacy Amplification by  Subsampling",
    "abstract": " Title: Composition of Differential Privacy & Privacy Amplification by  Subsampling ",
    "url": "https://arxiv.org/abs/2210.00597",
    "authors": [
      "Thomas Steinke"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.01787",
    "title": "Rethinking Lipschitz Neural Networks and Certified Robustness: A Boolean  Function Perspective",
    "abstract": " Comments: 37 pages; to appear in NeurIPS 2022 (Oral) ",
    "url": "https://arxiv.org/abs/2210.01787",
    "authors": [
      "Bohang Zhang",
      "Du Jiang",
      "Di He",
      "Liwei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ]
  },
  {
    "id": "arXiv:2210.02835",
    "title": "Sequentially Swapping Tokens: Further on Graph Classes",
    "abstract": " Comments: 28 pages, 15 figures, SOFSEM 2023 ",
    "url": "https://arxiv.org/abs/2210.02835",
    "authors": [
      "Hironori Kiya",
      "Yuto Okada",
      "Hirotaka Ono",
      "Yota Otachi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ]
  },
  {
    "id": "arXiv:2210.05189",
    "title": "Neural Networks are Decision Trees",
    "abstract": " Title: Neural Networks are Decision Trees ",
    "url": "https://arxiv.org/abs/2210.05189",
    "authors": [
      "Caglar Aytekin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.06175",
    "title": "Exploring Efficient-tuning Methods in Self-supervised Speech Models",
    "abstract": " Comments: SLT 2022 ",
    "url": "https://arxiv.org/abs/2210.06175",
    "authors": [
      "Zih-Ching Chen",
      "Chin-Lun Fu",
      "Chih-Ying Liu",
      "Shang-Wen Li",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ]
  },
  {
    "id": "arXiv:2210.07189",
    "title": "On Compressing Sequences for Self-Supervised Speech Models",
    "abstract": " Comments: Accepted to IEEE SLT 2022 ",
    "url": "https://arxiv.org/abs/2210.07189",
    "authors": [
      "Yen Meng",
      "Hsuan-Jui Chen",
      "Jiatong Shi",
      "Shinji Watanabe",
      "Paola Garcia",
      "Hung-yi Lee",
      "Hao Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.08870",
    "title": "Differential Evolution based Dual Adversarial Camouflage: Fooling Human  Eyes and Object Detectors",
    "abstract": " Title: Differential Evolution based Dual Adversarial Camouflage: Fooling Human  Eyes and Object Detectors ",
    "url": "https://arxiv.org/abs/2210.08870",
    "authors": [
      "Jialiang Sun",
      "Tingsong Jiang",
      "Wen Yao",
      "Donghua Wang",
      "Xiaoqian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.10664",
    "title": "Deep Multi-Representation Model for Click-Through Rate Prediction",
    "abstract": " Title: Deep Multi-Representation Model for Click-Through Rate Prediction ",
    "url": "https://arxiv.org/abs/2210.10664",
    "authors": [
      "Shereen Elsayed",
      "Lars Schmidt-Thieme"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.10879",
    "title": "G-Augment: Searching for the Meta-Structure of Data Augmentation  Policies for ASR",
    "abstract": " Comments: 6 pages, accepted at SLT 2022. Updated with copyright ",
    "url": "https://arxiv.org/abs/2210.10879",
    "authors": [
      "Gary Wang",
      "Ekin D.Cubuk",
      "Andrew Rosenberg",
      "Shuyang Cheng",
      "Ron J. Weiss",
      "Bhuvana Ramabhadran",
      "Pedro J. Moreno",
      "Quoc V. Le",
      "Daniel S. Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ]
  },
  {
    "id": "arXiv:2210.11498",
    "title": "Balanced Adversarial Training: Balancing Tradeoffs between Fickleness  and Obstinacy in NLP Models",
    "abstract": " Comments: EMNLP 2022 ",
    "url": "https://arxiv.org/abs/2210.11498",
    "authors": [
      "Hannah Chen",
      "Yangfeng Ji",
      "David Evans"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.11744",
    "title": "AfroLID: A Neural Language Identification Tool for African Languages",
    "abstract": " Comments: To appear at EMNLP 2022 Main conference ",
    "url": "https://arxiv.org/abs/2210.11744",
    "authors": [
      "Ife Adebara",
      "AbdelRahim Elmadany",
      "Muhammad Abdul-Mageed",
      "Alcides Alcoba Inciarte"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ]
  },
  {
    "id": "arXiv:2210.12229",
    "title": "Deep Reinforcement Learning for Stabilization of Large-scale  Probabilistic Boolean Networks",
    "abstract": " Title: Deep Reinforcement Learning for Stabilization of Large-scale  Probabilistic Boolean Networks ",
    "url": "https://arxiv.org/abs/2210.12229",
    "authors": [
      "Sotiris Moschoyiannis",
      "Evangelos Chatzaroulas",
      "Vytenis Sliogeris",
      "Yuhu Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ]
  },
  {
    "id": "arXiv:2210.12310",
    "title": "Tools for Extracting Spatio-Temporal Patterns in Meteorological Image  Sequences: From Feature Engineering to Attention-Based Neural Networks",
    "abstract": " Comments: The paper is submitted for review to the EDS Journal ",
    "url": "https://arxiv.org/abs/2210.12310",
    "authors": [
      "Akansha Singh Bansal",
      "Yoonjin Lee",
      "Kyle Hilburn",
      "Imme Ebert-Uphoff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ]
  },
  {
    "id": "arXiv:2210.12415",
    "title": "ALT: Breaking the Wall between Graph and Operator Level Optimizations  for Deep Learning Compilation",
    "abstract": " Title: ALT: Breaking the Wall between Graph and Operator Level Optimizations  for Deep Learning Compilation ",
    "url": "https://arxiv.org/abs/2210.12415",
    "authors": [
      "Zhiying Xu",
      "Jiafan Xu",
      "Hongding Peng",
      "Wei Wang",
      "Xiaoliang Wang",
      "Haoran Wan",
      "Haipeng Dai",
      "Yixu Xu",
      "Hao Cheng",
      "Kun Wang",
      "Guihai Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ]
  },
  {
    "id": "arXiv:2210.13029",
    "title": "Multilingual Auxiliary Tasks Training: Bridging the Gap between  Languages for Zero-Shot Transfer of Hate Speech Detection Models",
    "abstract": " Comments: Accepted to Findings of AACL-IJCNLP 2022 ",
    "url": "https://arxiv.org/abs/2210.13029",
    "authors": [
      "Syrielle Montariol",
      "Arij Riabi",
      "Djam\u00e9 Seddah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ]
  },
  {
    "id": "arXiv:2210.13088",
    "title": "Your Router is My Prober: Measuring IPv6 Networks via ICMP Rate Limiting  Side Channels",
    "abstract": " Title: Your Router is My Prober: Measuring IPv6 Networks via ICMP Rate Limiting  Side Channels ",
    "url": "https://arxiv.org/abs/2210.13088",
    "authors": [
      "Long Pan",
      "Jiahai Yang",
      "Lin He",
      "Zhiliang Wang",
      "Leyao Nie",
      "Guanglei Song",
      "Yaozhong Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ]
  },
  {
    "id": "arXiv:2210.13148",
    "title": "DAGformer: Directed Acyclic Graph Transformer",
    "abstract": " Title: DAGformer: Directed Acyclic Graph Transformer ",
    "url": "https://arxiv.org/abs/2210.13148",
    "authors": [
      "Yuankai Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ]
  },
  {
    "id": "arXiv:2210.13416",
    "title": "A Continuous Convolutional Trainable Filter for Modelling Unstructured  Data",
    "abstract": " Title: A Continuous Convolutional Trainable Filter for Modelling Unstructured  Data ",
    "url": "https://arxiv.org/abs/2210.13416",
    "authors": [
      "Dario Coscia",
      "Laura Meneghetti",
      "Nicola Demo",
      "Giovanni Stabile",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ]
  },
  {
    "id": "arXiv:2210.13430",
    "title": "Data-Driven Stabilizing and Robust Control of Discrete-Time Linear  Systems with Error in Variables",
    "abstract": " Comments: 27 pages, 1 figure, 9 tables ",
    "url": "https://arxiv.org/abs/2210.13430",
    "authors": [
      "Jared Miller",
      "Tianyu Dai",
      "Mario Sznaier"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ]
  }
]